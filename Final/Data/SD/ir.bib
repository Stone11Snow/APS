@article{Losada201856,
title = {"A rank fusion approach based on score distributions for prioritizing relevance assessments in information retrieval evaluation "},
journal = {"Information Fusion "},
volume = {"39"},
number = {""},
pages = {"56 - 71"},
year = {"2018"},
note = {""},
issn = {"1566-2535"},
doi = {"https://doi.org/10.1016/j.inffus.2017.04.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1566253516301786"},
author = {"David E. Losada and Javier Parapar and Alvaro Barreiro"},
keywords = {"Rank fusion", "Information retrieval", "Evaluation", "Pooling", "Score distributions", "Pseudo-relevance "},
abstract = {"Abstract In this paper we study how to prioritize relevance assessments in the process of creating an Information Retrieval test collection. A test collection consists of a set of queries, a document collection, and a set of relevance assessments. For each query, only a sample of documents from the collection can be manually assessed for relevance. Multiple retrieval strategies are typically used to obtain such sample of documents. And rank fusion plays a fundamental role in creating the sample by combining multiple search results. We propose effective rank fusion models that are adapted to the characteristics of this evaluation task. Our models are based on the distribution of retrieval scores supplied by the search systems and our experiments show that this formal approach leads to natural and competitive solutions when compared to state of the art methods. We also demonstrate the benefits of including pseudo-relevance evidence into the estimation of the score distribution models. "} 
}
@article{Piras201750,
title = {"Information fusion in content based image retrieval: A comprehensive overview "},
journal = {"Information Fusion "},
volume = {"37"},
number = {""},
pages = {"50 - 60"},
year = {"2017"},
note = {""},
issn = {"1566-2535"},
doi = {"https://doi.org/10.1016/j.inffus.2017.01.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1566253517300076"},
author = {"Luca Piras and Giorgio Giacinto"},
keywords = {"Information fusion", "Content based image retrieval "},
abstract = {"Abstract An ever increasing part of communication between persons involve the use of pictures, due to the cheap availability of powerful cameras on smartphones, and the cheap availability of storage space. The rising popularity of social networking applications such as Facebook, Twitter, Instagram, and of instant messaging applications, such as WhatsApp, WeChat, is the clear evidence of this phenomenon, due to the opportunity of sharing in real-time a pictorial representation of the context each individual is living in. The media rapidly exploited this phenomenon, using the same channel, either to publish their reports, or to gather additional information on an event through the community of users. While the real-time use of images is managed through metadata associated with the image (i.e., the timestamp, the geolocation, tags, etc.), their retrieval from an archive might be far from trivial, as an image bears a rich semantic content that goes beyond the description provided by its metadata. It turns out that after more than 20 years of research on Content-Based Image Retrieval (CBIR), the giant increase in the number and variety of images available in digital format is challenging the research community. It is quite easy to see that any approach aiming at facing such challenges must rely on different image representations that need to be conveniently fused in order to adapt to the subjectivity of image semantics. This paper offers a journey through the main information fusion ingredients that a recipe for the design of a \{CBIR\} system should include to meet the demanding needs of users. "} 
}
@article{Alhabashneh201718,
title = {"Fuzzy rule based profiling approach for enterprise information seeking and retrieval "},
journal = {"Information Sciences "},
volume = {"394–395"},
number = {""},
pages = {"18 - 37"},
year = {"2017"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.12.040"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025516322605"},
author = {"Obada Alhabashneh and Rahat Iqbal and Faiyaz Doctor and Anne James"},
keywords = {"Enterprise search", "Enterprise information seeking &amp; retrieval", "Personalised information retrieval", "Fuzzy logic, Expert search", "Rulebased summarisation", "Fuzzy profiling "},
abstract = {"Abstract With the exponential growth of information available on the Internet and various organisational intranets there is a need for profile based information seeking and retrieval (IS&amp;R) systems. These systems should be able to support users with their context-aware information needs. This paper presents a new approach for enterprise IS&amp;R systems using fuzzy logic to develop task, user and document profiles to model user information seeking behaviour. Relevance feedback was captured from real users engaged in IS&amp;R tasks. The feedback was used to develop a linear regression model for predicting document relevancy based on implicit relevance indicators. Fuzzy relevance profiles were created using Term Frequency and Inverse Document Frequency (TF-IDF) analysis for the successful user queries. Fuzzy rule based summarisation was used to integrate the three profiles into a unified index reflecting the semantic weight of the query terms related to the task, user and document. The unified index was used to select the most relevant documents and experts related to the query topic. The overall performance of the system was evaluated based on standard precision and recall metrics which show significant improvements in retrieving relevant documents in response to user queries. "} 
}
@article{Losada20171005,
title = {"Multi-armed bandits for adjudicating documents in pooling-based evaluation of information retrieval systems "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"5"},
pages = {"1005 - 1025"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2017.04.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316305660"},
author = {"David E. Losada and Javier Parapar and Alvaro Barreiro"},
keywords = {"Information retrieval", "Evaluation", "Pooling", "Reinforcement learning", "Multi-armed bandits "},
abstract = {"Abstract Evaluating Information Retrieval systems is crucial to making progress in search technologies. Evaluation is often based on assembling reference collections consisting of documents, queries and relevance judgments done by humans. In large-scale environments, exhaustively judging relevance becomes infeasible. Instead, only a pool of documents is judged for relevance. By selectively choosing documents from the pool we can optimize the number of judgments required to identify a given number of relevant documents. We argue that this iterative selection process can be naturally modeled as a reinforcement learning problem and propose innovative and formal adjudication methods based on multi-armed bandits. Casting document judging as a multi-armed bandit problem is not only theoretically appealing, but also leads to highly effective adjudication methods. Under this bandit allocation framework, we consider stationary and non-stationary models and propose seven new document adjudication methods (five stationary methods and two non-stationary variants). Our paper also reports a series of experiments performed to thoroughly compare our new methods against current adjudication methods. This comparative study includes existing methods designed for pooling-based evaluation and existing methods designed for metasearch. Our experiments show that our theoretically grounded adjudication methods can substantially minimize the assessment effort. "} 
}
@article{Sarrouti201796,
title = {"A passage retrieval method based on probabilistic information retrieval model and \{UMLS\} concepts in biomedical question answering "},
journal = {"Journal of Biomedical Informatics "},
volume = {"68"},
number = {""},
pages = {"96 - 103"},
year = {"2017"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2017.03.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046417300503"},
author = {"Mourad Sarrouti and Said Ouatik El Alaoui"},
keywords = {"Biomedical question answering system", "Biomedical passage retieval", "Probabilistic information retrieval model", "Unified medical language system", "Natural language processing", "Biomedical informatics "},
abstract = {"AbstractBackground and Objective Passage retrieval, the identification of top-ranked passages that may contain the answer for a given biomedical question, is a crucial component for any biomedical question answering (QA) system. Passage retrieval in open-domain \{QA\} is a longstanding challenge widely studied over the last decades. However, it still requires further efforts in biomedical QA. In this paper, we present a new biomedical passage retrieval method based on Stanford CoreNLP sentence/passage length, probabilistic information retrieval (IR) model and \{UMLS\} concepts. Methods In the proposed method, we first use our document retrieval system based on PubMed search engine and \{UMLS\} similarity to retrieve relevant documents to a given biomedical question. We then take the abstracts from the retrieved documents and use Stanford CoreNLP for sentence splitter to make a set of sentences, i.e., candidate passages. Using stemmed words and \{UMLS\} concepts as features for the \{BM25\} model, we finally compute the similarity scores between the biomedical question and each of the candidate passages and keep the N top-ranked ones. Results Experimental evaluations performed on large standard datasets, provided by the BioASQ challenge, show that the proposed method achieves good performances compared with the current state-of-the-art methods. The proposed method significantly outperforms the current state-of-the-art methods by an average of 6.84% in terms of mean average precision (MAP). Conclusion We have proposed an efficient passage retrieval method which can be used to retrieve relevant passages in biomedical \{QA\} systems with high mean average precision. "} 
}
@article{Datta201781,
title = {"Multimodal Retrieval using Mutual Information based Textual Query Reformulation "},
journal = {"Expert Systems with Applications "},
volume = {"68"},
number = {""},
pages = {"81 - 92"},
year = {"2017"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2016.09.039"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417416305292"},
author = {"Deepanwita Datta and Shubham Varma and Ravindranath Chowdary C. and Sanjay K. Singh"},
keywords = {"Multimodal Retrieval", "Query Reformulation", "Keyphrase Extraction", "Mutual Information", "Fisher-LDA "},
abstract = {"Abstract Multimodal Retrieval is a well-established approach for image retrieval. Usually, images are accompanied by text caption along with associated documents describing the image. Textual query expansion as a form of enhancing image retrieval is a relatively less explored area. In this paper, we first study the effect of expanding textual query on both image and its associated text retrieval. Our study reveals that judicious expansion of textual query through keyphrase extraction can lead to better results, either in terms of text-retrieval or both image and text-retrieval. To establish this, we use two well-known keyphrase extraction techniques based on tf-idf and KEA. While query expansion results in increased retrieval efficiency, it is imperative that the expansion be semantically justified. So, we propose a graph-based keyphrase extraction model that captures the relatedness between words in terms of both mutual information and relevance feedback. Most of the existing works have stressed on bridging the semantic gap by using textual and visual features, either in combination or individually. The way these text and image features are combined determines the efficacy of any retrieval. For this purpose, we adopt Fisher-LDA to adjudge the appropriate weights for each modality. This provides us with an intelligent decision-making process favoring the feature set to be infused into the final query. Our proposed algorithm is shown to supersede the previously mentioned keyphrase extraction algorithms for query expansion significantly. A rigorous set of experiments performed on ImageCLEF-2011 Wikipedia Retrieval task dataset validates our claim that capturing the semantic relation between words through Mutual Information followed by expansion of a textual query using relevance feedback can simultaneously enhance both text and image retrieval. "} 
}
@article{Jiang2017,
title = {"Psychologically inspired visual information storage and retrieval modeling for multiclass image classification "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.09.126"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217302515"},
author = {"Ying Jiang and Yanjiang Wang"},
keywords = {"SIFT", "Sparse coding", "Psychological memory modeling", "Information storage", "Information retrieval", "Image classification "},
abstract = {"Abstract The computer vision research aims to enable the computers to recognize visual images as easily as human. Studies have shown that human could segregate target from its surrounding environment, which is intimately associated with the brain memory mechanism. However, it is not quite clear about how the visual images are stored and retrieved in the human brain. In this paper, we propose a psychologically visual information storage and retrieval model (PVISRM) based on sparse coding and probabilistic decision theory. First, the dense scale invariant feature transform (SIFT) algorithm is applied to extract the features of visual images and then the extracted features are represented by sparse coding. In the storage procedure, each component of the feature vector is correctly copied with certain probability generated by an exponential distribution. For retrieval, the likelihood ratio between the probe image feature vector and that of each studied image is calculated based on probabilistic theory. Then the category likelihood ratio between the probe image and each category is obtained by adding the ratio values of all images belonging to the same category. Finally, the Bayesian decision rule for image classification is presented. Experimental results show that the proposed \{PVISRM\} model can obtain good classification performance and outperforms the \{SVM\} approach. "} 
}
@article{Kulik201629,
title = {"Factographic Information Retrieval for Communication in Multicultural Society "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"236"},
number = {""},
pages = {"29 - 33"},
year = {"2016"},
note = {"International Conference on Communication in Multicultural Society, \{CMSC\} 2015, 6-8 December 2015, Moscow, Russian Federation "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2016.12.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S187704281631641X"},
author = {"Sergey Kulik"},
keywords = {"Information retrieval", "communication", "recommendatory list", "pattern recognition", "factographic information", "effectiveness "},
abstract = {"Abstract A factographic information retrieval with human involvement which consists of two stages is given detailed consideration in this paper. In the first stage, the retrieval without direct human involvement is implemented. In the second stage, the retrieval assumes the human involvement. This retrieval includes a pattern recognition algorithm, and they are implemented for retrieval only one document among the variety of similar documents. An analytical model of the retrieval block is developed. This model is presented by effectiveness indicator: average length of the recommendatory list provided by the retrieval block enabling the human operator to take the final decision. "} 
}
@article{Marrara2016,
title = {"Aggregation operators in Information Retrieval "},
journal = {"Fuzzy Sets and Systems "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0165-0114"},
doi = {"https://doi.org/10.1016/j.fss.2016.12.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165011416304596"},
author = {"Stefania Marrara and Gabriella Pasi and Marco Viviani"},
keywords = {"Aggregation operators", "Information Retrieval", "Indexing", "Query languages", "Multidimensional relevance assessment", "Metasearch", "OWA operators", "Copulas", "Choquet integrals "},
abstract = {"Abstract Information Retrieval is a complex task, which deals with both the subjectivity related to the user's needs and the uncertainty and vagueness that characterize the retrieval process. For this reason, deciding to which extent a document is relevant to a user's needs is not easy, and it strongly depends on several dimensions such as topicality, novelty, user's context, and so on. One of the most straightforward ways to interpret this activity is as a Multi-Criteria Decision Making (MCDM) problem, in which the choice of appropriate aggregation operators can play an important role in various tasks related to, or characterizing the \{IR\} process. This article aims to provide a presentation of the main approaches that in the literature have made use of aggregation operators in Information Retrieval. "} 
}
@article{Beinert2017,
title = {"Enforcing uniqueness in one-dimensional phase retrieval by additional signal information in time domain "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2016.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520316300975"},
author = {"Robert Beinert and Gerlind Plonka"},
keywords = {"Discrete one-dimensional phase retrieval for complex signals", "Compact support", "Additional magnitude and phase information in time domain "},
abstract = {"Abstract Considering the ambiguousness of the discrete-time phase retrieval problem to recover a signal from its Fourier intensities, one can ask the question: what additional information about the unknown signal do we need to select the correct solution within the large solution set? Based on a characterization of the occurring ambiguities, we investigate different a priori conditions in order to reduce the number of ambiguities or even to receive a unique solution. Particularly, if we have access to additional magnitudes of the unknown signal in the time domain, we can show that almost all signals with finite support can be uniquely recovered. Moreover, we prove that an analogous result can be obtained by exploiting additional phase information. "} 
}
@article{Zhong2017214,
title = {"Information verification and encryption based on phase retrieval with sparsity constraints and optical inference "},
journal = {"Optics and Lasers in Engineering "},
volume = {"88"},
number = {""},
pages = {"214 - 220"},
year = {"2017"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616301890"},
author = {"Shenlu Zhong and Mengjiao Li and Xiajie Tang and Weiqing He and Xiaogang Wang"},
keywords = {"Optical encryption", "Information authentication", "Phase retrieval", "Phase encoding "},
abstract = {"Abstract A novel optical information verification and encryption method is proposed based on inference principle and phase retrieval with sparsity constraints. In this method, a target image is encrypted into two phase-only masks (POMs), which comprise sparse phase data used for verification. Both of the two \{POMs\} need to be authenticated before being applied for decrypting. The target image can be optically reconstructed when the two authenticated \{POMs\} are Fourier transformed and convolved by the correct decryption key, which is also generated in encryption process. No holographic scheme is involved in the proposed optical verification and encryption system and there is also no problem of information disclosure in the two authenticable POMs. Numerical simulation results demonstrate the validity and good performance of this new proposed method. "} 
}
@article{Li2016,
title = {"Toward single-server private information retrieval protocol via learning with errors "},
journal = {"Journal of Information Security and Applications "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"2214-2126"},
doi = {"https://doi.org/10.1016/j.jisa.2016.11.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S2214212616301363"},
author = {"Zengpeng Li and Chunguang Ma and Ding Wang and Gang Du"},
keywords = {"Private information retrieval", "Homomorphic encryption", "Multi-bit symmetric encryption", "Learning with errors "},
abstract = {"Abstract At \{FOCS2011\} Brakerski and Vaikuntanathan proposed a single-server LWE-based private information retrieval (abbreviated as PIR) protocol with a security reduction to hard standard lattice problems and nearly optimal communication complexity. However, Brakerski just described a generic \{PIR\} protocol that utilized a somewhat homomorphic encryption and an arbitrary symmetric encryption as building blocks, he did not instantiate the generic construction. In this work, we first modify Brakerski's construction without the evaluating key and construct a new \{PIR\} model. Moreover, we instantiate our new model via matrix \{FHE\} first proposed by Ryo et al. at \{PKC2015\} and vector symmetric encryption scheme proposed in this work as building block. Then we optimize the Response operations and several other aspects of the scheme. "} 
}
@article{Guezouli2016155,
title = {"CAS-based information retrieval in semi-structured documents: \{CASISS\} model "},
journal = {"Journal of Innovation in Digital Ecosystems "},
volume = {"3"},
number = {"2"},
pages = {"155 - 162"},
year = {"2016"},
note = {""},
issn = {"2352-6645"},
doi = {"https://doi.org/10.1016/j.jides.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S235266451630027X"},
author = {"Larbi Guezouli and Hassane Essafi"},
keywords = {"CASISS", "Information retrieval", "Semi-structured information processing "},
abstract = {"Abstract This paper aims to address the assessment the similarity between documents or pieces of documents. For this purpose we have developed \{CASISS\} (CAlculation of \{SImilarity\} of Semi-Structured documents) method to quantify how two given texts are similar. The method can be employed in wide area of applications including content reuse detection which is a hot and challenging topic. It can be also used to increase the accuracy of the information retrieval process by taking into account not only the presence of query terms in the given document (Content Only search — CO) but also the topology (position continuity) of these terms (based on Content And Structure Search — CAS). Tracking the origin of the information in social media, copy right management, plagiarism detection, social media mining and monitoring, digital forensic are among other applications require tools such as \{CASISS\} to measure, with a high accuracy, the content overlap between two documents. \{CASISS\} identify elements of semi-structured documents using elements descriptors. Each semi-structured document is pre-processed before the extraction of a set of elements descriptors, which characterize the content of the elements. "} 
}
@article{Kauer2016282,
title = {"Using information retrieval for sentiment polarity prediction "},
journal = {"Expert Systems with Applications "},
volume = {"61"},
number = {""},
pages = {"282 - 289"},
year = {"2016"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2016.05.038"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417416302627"},
author = {"Anderson Uilian Kauer and Viviane P. Moreira"},
keywords = {"Sentiment analysis", "Opinion mining", "Information retrieval", "Polarity classification", "Twitter "},
abstract = {"Abstract Social networks such as Twitter are used by millions of people who express their opinions on a variety of topics. Consequently, these media are constantly being examined by sentiment analysis systems which aim at classifying the posts as positive or negative. Given the variety of topics discussed and the short length of the posts, the standard approach of using the words as features for machine learning algorithms results in sparse vectors. In this work, we propose using features derived from the ranking generated by an Information Retrieval System in response to a query consisting of the post that needs to be classified. Our system can be fully automatic, has only 24 features, and does not depend on expensive resources. Experiments on real datasets have shown that a classifier that relies solely on these features outperforms established baselines and can reach accuracies comparable to the state-of-the-art approaches which are more costly. "} 
}
@article{Soulier20161122,
title = {"MineRank: Leveraging users’ latent roles for unsupervised collaborative information retrieval "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"6"},
pages = {"1122 - 1141"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316301145"},
author = {"Laure Soulier and Lynda Tamine and Chirag Shah"},
keywords = {"Collaborative information retrieval", "Unsupervised role mining", "Latent role", "User study "},
abstract = {"Abstract Research on collaborative information retrieval (CIR) has shown positive impacts of collaboration on retrieval effectiveness in the case of complex and/or exploratory tasks. The synergic effect of accomplishing something greater than the sum of its individual components is reached through the gathering of collaborators’ complementary skills. However, these approaches often lack the consideration that collaborators might refine their skills and actions throughout the search session, and that a flexible system mediation guided by collaborators’ behaviors should dynamically adapt to this situation in order to optimize search effectiveness. In this article, we propose a new unsupervised collaborative ranking algorithm which leverages collaborators’ actions for (1) mining their latent roles in order to extract their complementary search behaviors; and (2) ranking documents with respect to the latent role of collaborators. Experiments using two user studies with respectively 25 and 10 pairs of collaborators demonstrate the benefit of such an unsupervised method driven by collaborators’ behaviors throughout the search session. Also, a qualitative analysis of the identified latent role is proposed to explain an over-learning noticed in one of the datasets. "} 
}
@article{PérezRodríguez201672,
title = {"Architecture of a concept-based information retrieval system for educational resources "},
journal = {"Science of Computer Programming "},
volume = {"129"},
number = {""},
pages = {"72 - 91"},
year = {"2016"},
note = {"Special issue on eLearning Software Architectures "},
issn = {"0167-6423"},
doi = {"https://doi.org/10.1016/j.scico.2016.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167642316300314"},
author = {"Roberto Pérez-Rodríguez and Luis Anido-Rifón and Miguel Gómez-Carballa and Marcos Mouriño-García"},
keywords = {"Exploratory search", "Information retrieval", "Bag-of-concepts (BoC) representation", "Software architecture "},
abstract = {"Abstract Internet searches that occur in learning contexts are very different in nature from traditional “lookup” or “known item” searches: students usually perform searches to gather information about or master a certain topic, and the search engine is used as an aid in the exploration of a domain of knowledge. This paper presents \{SDE\} (Search Discover Explore), an exploratory search engine for educational resources that was built on top of the knowledge provided by Wikipedia: the set of its articles provides the search space (the set of topics that users can investigate), and the relationships between Wikipedia articles inform the suggestions that the search engine provides to students to go deeper in the exploration of a certain domain of knowledge. \{SDE\} indexes several hundreds of thousands of educational resources from high-quality Web sources, such as Project Gutenberg and Open Education Europe, among many others. This paper also reports the results of the evaluation of \{SDE\} by experts in Technology Enhanced Learning in several workshops that took place across Europe in the context of the European \{FP7\} project iTEC. These results enable us to conclude that the exploratory search paradigm, making use of knowledge mined from Wikipedia, is a very promising approach for building information retrieval systems to be used in learning contexts. "} 
}
@article{Anastasiades2016194,
title = {"Information-centric content retrieval for delay-tolerant networks "},
journal = {"Computer Networks "},
volume = {"107, Part 2"},
number = {""},
pages = {"194 - 207"},
year = {"2016"},
note = {"Mobile Wireless Networks "},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2016.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128616300718"},
author = {"Carlos Anastasiades and Tobias Schmid and Jürg Weber and Torsten Braun"},
keywords = {"Information-centric", "Delay-tolerant", "Agent-based content retrieval", "Wireless routing", "DTN", "CCN "},
abstract = {"Abstract The shift from host-centric to information-centric networking (ICN) promises seamless communication in mobile networks. However, most existing works either consider well-connected networks with high node density or introduce modifications to \{ICN\} message processing for delay-tolerant networking (DTN). In this work, we present agent-based content retrieval, which provides information-centric \{DTN\} support as an application module without modifications to \{ICN\} message processing. This enables flexible interoperability in changing environments. If no content source can be found via wireless multi-hop routing, requesters may exploit the mobility of neighbor nodes (called agents) by delegating content retrieval to them. Agents that receive a delegation and move closer to content sources can retrieve data and return it back to requesters. We show that agent-based content retrieval may be even more efficient in scenarios where multi-hop communication is possible. Furthermore, we show that broadcast communication may not be necessarily the best option since dynamic unicast requests have little overhead and can better exploit short contact times between nodes (no broadcast delays required for duplicate suppression). "} 
}
@article{Flores2016840,
title = {"Assessing the impact of Stemming Accuracy on Information Retrieval – A multilingual perspective "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"5"},
pages = {"840 - 854"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316300358"},
author = {"Felipe N. Flores and Viviane P. Moreira"},
keywords = {"Stemming", "Information Retrieval", "Evaluation", "Multilingual "},
abstract = {"Abstract The quality of stemming algorithms is typically measured in two different ways: (i) how accurately they map the variant forms of a word to the same stem; or (ii) how much improvement they bring to Information Retrieval systems. In this article, we evaluate various stemming algorithms, in four languages, in terms of accuracy and in terms of their aid to Information Retrieval. The aim is to assess whether the most accurate stemmers are also the ones that bring the biggest gain in Information Retrieval. Experiments in English, French, Portuguese, and Spanish show that this is not always the case, as stemmers with higher error rates yield better retrieval quality. As a byproduct, we also identified the most accurate stemmers and the best for Information Retrieval purposes. "} 
}
@article{Wang2016379,
title = {"A Part-Of-Speech term weighting scheme for biomedical information retrieval "},
journal = {"Journal of Biomedical Informatics "},
volume = {"63"},
number = {""},
pages = {"379 - 389"},
year = {"2016"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2016.08.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046416301125"},
author = {"Yanshan Wang and Stephen Wu and Dingcheng Li and Saeed Mehrabi and Hongfang Liu"},
keywords = {"Biomedical information retrieval", "Natural language processing", "Part-Of-Speech", "Bag-of-word", "Markov random field "},
abstract = {"Abstract In the era of digitalization, information retrieval (IR), which retrieves and ranks documents from large collections according to users’ search queries, has been popularly applied in the biomedical domain. Building patient cohorts using electronic health records (EHRs) and searching literature for topics of interest are some \{IR\} use cases. Meanwhile, natural language processing (NLP), such as tokenization or Part-Of-Speech (POS) tagging, has been developed for processing clinical documents or biomedical literature. We hypothesize that \{NLP\} can be incorporated into \{IR\} to strengthen the conventional \{IR\} models. In this study, we propose two NLP-empowered \{IR\} models, POS-BoW and POS-MRF, which incorporate automatic POS-based term weighting schemes into bag-of-word (BoW) and Markov Random Field (MRF) \{IR\} models, respectively. In the proposed models, the POS-based term weights are iteratively calculated by utilizing a cyclic coordinate method where golden section line search algorithm is applied along each coordinate to optimize the objective function defined by mean average precision (MAP). In the empirical experiments, we used the data sets from the Medical Records track in Text \{REtrieval\} Conference (TREC) 2011 and 2012 and the Genomics track in \{TREC\} 2004. The evaluation on \{TREC\} 2011 and 2012 Medical Records tracks shows that, for the POS-BoW models, the mean improvement rates for \{IR\} evaluation metrics, MAP, bpref, and P$10, are 10.88%, 4.54%, and 3.82%, compared to the BoW models; and for the POS-MRF models, these rates are 13.59%, 8.20%, and 8.78%, compared to the \{MRF\} models. Additionally, we experimentally verify that the proposed weighting approach is superior to the simple heuristic and frequency based weighting approaches, and validate our \{POS\} category selection. Using the optimal weights calculated in this experiment, we tested the proposed models on the \{TREC\} 2004 Genomics track and obtained average of 8.63% and 10.04% improvement rates for POS-BoW and POS-MRF, respectively. These significant improvements verify the effectiveness of leveraging \{POS\} tagging for biomedical \{IR\} tasks. "} 
}
@article{Lv2016737,
title = {"Enhanced context-based document relevance assessment and ranking for improved information retrieval to support environmental decision making "},
journal = {"Advanced Engineering Informatics "},
volume = {"30"},
number = {"4"},
pages = {"737 - 750"},
year = {"2016"},
note = {""},
issn = {"1474-0346"},
doi = {"https://doi.org/10.1016/j.aei.2016.08.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1474034616302658"},
author = {"Xuan Lv and Nora M. El-Gohary"},
keywords = {"Information retrieval", "Context-based relevance assessment", "Context-enhanced document ranking", "Vector space model", "Statistical language model", "Project environmental review "},
abstract = {"Abstract There is a need for enhanced context-based document relevance assessment and ranking to facilitate the retrieval of more relevant information for supporting environmental decision making. This paper proposes a new context-based relevance assessment method, which allows for enhanced context representation and context-based document relevance recognition through: (1) a context-aware and deep semantic concept indexing approach, and (2) a deep and semantically-sensitive relevance estimation approach. The proposed relevance assessment method was integrated into two widely-used document ranking models [vector space model (VSM) and statistical language model (SLM)], resulting in two improved ranking methods: (1) a context-enhanced VSM-based method, and (2) a context-enhanced SLM-based method. The two context-enhanced document ranking methods were evaluated in retrieving webpages that are relevant to transportation project environmental review. The two context-enhanced methods were compared with each other and with their provenance methods (i.e., original \{VSM\} and SLM) in terms of mean precision (MP) and mean average precision (MAP). The context-enhanced VSM-based method outperformed the context-enhanced SLM-based method on every metric. It achieved 48% MAP, 79% \{MP\} at the top 10 retrieved documents, and over 65% \{MP\} at the top 50 retrieved documents, on the testing data. It also showed significant improvement over the state-of-the-art keyword-based \{VSM\} method. "} 
}
@article{Ghosh2016873,
title = {"Improving Information Retrieval Performance on \{OCRed\} Text in the Absence of Clean Text Ground Truth "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"5"},
pages = {"873 - 884"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645731630036X"},
author = {"Kripabandhu Ghosh and Anirban Chakraborty and Swapan Kumar Parui and Prasenjit Majumder"},
keywords = {"Information Retrieval", "OCR error", "Word co-occurrence "},
abstract = {"Abstract \{OCR\} errors in text harm information retrieval performance. Much research has been reported on modelling and correction of Optical Character Recognition (OCR) errors. Most of the prior work employ language dependent resources or training texts in studying the nature of errors. However, not much research has been reported that focuses on improving retrieval performance from erroneous text in the absence of training data. We propose a novel approach for detecting \{OCR\} errors and improving retrieval performance from the erroneous corpus in a situation where training samples are not available to model errors. In this paper we propose a method that automatically identifies erroneous term variants in the noisy corpus, which are used for query expansion, in the absence of clean text. We employ an effective combination of contextual information and string matching techniques. Our proposed approach automatically identifies the erroneous variants of query terms and consequently leads to improvement in retrieval performance through query expansion. Our proposed approach does not use any training data or any language specific resources like thesaurus for identification of error variants. It also does not expend any knowledge about the language except that the word delimiter is blank space. We have tested our approach on erroneous Bangla (Bengali in English) and Hindi \{FIRE\} collections, and also on \{TREC\} Legal \{IIT\} \{CDIP\} and \{TREC\} 5 Confusion track English corpora. Our proposed approach has achieved statistically significant improvements over the state-of-the-art baselines on most of the datasets. "} 
}
@article{Nzomo2016495,
title = {"Multilingual Information Retrieval &amp; Use: Perceptions and Practices Amongst Bi/Multilingual Academic Users "},
journal = {"The Journal of Academic Librarianship "},
volume = {"42"},
number = {"5"},
pages = {"495 - 502"},
year = {"2016"},
note = {""},
issn = {"0099-1333"},
doi = {"https://doi.org/10.1016/j.acalib.2016.06.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0099133316300969"},
author = {"Peggy Nzomo and Isola Ajiferuke and Liwen Vaughan and Pamela McKenzie"},
keywords = {"Multilingual information retrieval", "Multilingual information access tools", "User perception", "User experience", "International students", "Bi/multilingual users "},
abstract = {"Abstract In recent years, technological advancements in Natural Language Processing (NLP) such as machine translation have made it possible for users to access information in multiple languages, even those in which they may not be proficient. The current study investigated the information searching behavior of bi/multilingual academic users, and examined their practices and perceptions regarding searching for information on the Internet and on electronic databases. Bi/multilingual students were recruited from a Canadian university and a community college both located in London, Ontario. A total of 250 (N = 250) students completed a web survey through a link that was embedded in an invitation e-mail. Results showed that though advancements in \{NLP\} technology have alleviated some of the linguistic related challenges that some bi/multilingual academic users face while searching for information online, language barriers do still exist for some especially at the query formulation stage. The study found that an increase in Multilingual Information Access (MLIA) tools on electronic databases coupled with appropriate information literacy instruction could be helpful in further alleviating language barriers. "} 
}
@article{Liu201795,
title = {"Fusion of color histogram and LBP-based features for texture image retrieval and classification "},
journal = {"Information Sciences "},
volume = {"390"},
number = {""},
pages = {"95 - 111"},
year = {"2017"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2017.01.025"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025517301159"},
author = {"Peizhong Liu and Jing-Ming Guo and Kosin Chamnongthai and Heri Prasetyo"},
keywords = {"Color information feature", "Image retrieval", "Image classification", "Local binary pattern "},
abstract = {"Abstract The Local Binary Pattern (LBP) operator and its variants play an important role as the image feature extractor in the textural image retrieval and classification. The LBP-based operator extracts the textural information of an image by considering the neighboring pixel values. A single or join histogram can be derived from the \{LBP\} code which can be used as an image feature descriptor in some applications. However, the LBP-based feature is not a good candidate in capturing the color information of an image, making it is less suitable for measuring the similarity of color images with rich color information. This work overcomes this problem by adding an additional color feature, namely Color Information Feature (CIF), along with the LBP-based feature in the image retrieval and classification systems. The \{CIF\} and LBP-based feature adequately represent the color and texture features. As documented in the experimental result, the hybrid \{CIF\} and LBP-based feature presents a promising result and outperforms the existing methods over several image databases. Thus, it can be a very competitive candidate in retrieval and classification application. "} 
}
@article{Pandey2016506,
title = {"Content-based image retrieval embedded with agglomerative clustering built on information loss "},
journal = {"Computers & Electrical Engineering "},
volume = {"54"},
number = {""},
pages = {"506 - 521"},
year = {"2016"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2016.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790616300660"},
author = {"Shreelekha Pandey and Pritee Khanna"},
keywords = {"Content-based image retrieval", "Hierarchical agglomerative clustering", "Loss of information", "Cluster validity measures "},
abstract = {"Abstract This work presents a Content-Based Image Retrieval (CBIR) system embedded with a clustering technique to retrieve images similar to query image. This cluster-based \{CBIR\} system utilizes an agglomerative hierarchical clustering to group images into visually separable clusters within the dataset. The proposed clustering does not utilize any background data either related to the semantics of images or the number of clusters formed. At each intermediate step, a representative image is chosen to denote a cluster. This image represents all images in a cluster and hence, there is some loss of information, which is tracked and combined with proportional reduction in error method to automatically get the number of clusters. Experimental results obtained show the efficiency of the clustering algorithm. Image retrieval results are also presented to show efficacy of the developed system in retrieving semantically more similar images. "} 
}
@article{Vilares2016646,
title = {"Studying the effect and treatment of misspelled queries in Cross-Language Information Retrieval "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"4"},
pages = {"646 - 657"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.12.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315001478"},
author = {"Jesús Vilares and Miguel A. Alonso and Yerai Doval and Manuel Vilares"},
keywords = {"Misspelled queries", "Cross-Language Information Retrieval", "Machine translation", "Spelling correction", "Character n-grams "},
abstract = {"Abstract In contrast with their monolingual counterparts, little attention has been paid to the effects that misspelled queries have on the performance of Cross-Language Information Retrieval (CLIR) systems. The present work makes a first attempt to fill this gap by extending our previous work on monolingual retrieval in order to study the impact that the progressive addition of misspellings to input queries has, this time, on the output of \{CLIR\} systems. Two approaches for dealing with this problem are analyzed in this paper. Firstly, the use of automatic spelling correction techniques for which, in turn, we consider two algorithms: the first one for the correction of isolated words and the second one for a correction based on the linguistic context of the misspelled word. The second approach to be studied is the use of character n-grams both as index terms and translation units, seeking to take advantage of their inherent robustness and language-independence. All these approaches have been tested on a from-Spanish-to-English \{CLIR\} system, that is, Spanish queries on English documents. Real, user-generated spelling errors have been used under a methodology that allows us to study the effectiveness of the different approaches to be tested and their behavior when confronted with different error rates. The results obtained show the great sensitiveness of classic word-based approaches to misspelled queries, although spelling correction techniques can mitigate such negative effects. On the other hand, the use of character n-grams provides great robustness against misspellings. "} 
}
@article{Evangelopoulos201616,
title = {"Evaluating information retrieval using document popularity: An implementation on MapReduce "},
journal = {"Engineering Applications of Artificial Intelligence "},
volume = {"51"},
number = {""},
pages = {"16 - 23"},
year = {"2016"},
note = {"Mining the Humanities: Technologies and Applications "},
issn = {"0952-1976"},
doi = {"https://doi.org/10.1016/j.engappai.2016.01.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0952197616000270"},
author = {"Xenophon Evangelopoulos and Victor Giannakouris-Salalidis and Lazaros Iliadis and Christos Makris and Yannis Plegas and Antonia Plerou and Spyros Sioutas"},
keywords = {"Information retrieval", "Evaluation", "Metrics", "User behaviour", "MapReduce", "Cosine similarity "},
abstract = {"Abstract Over the last few years, one major research direction of information retrieval includes user behaviour prediction. For that reason many models have been proposed aiming at the accurate evaluation of information retrieval systems and the best prediction of web search users׳ behaviour. In this paper we propose a new evaluation metric for information retrieval systems which employs two relevance factors; a relevance judgement grade and a popularity grade that represents users׳ vote for a document. We show that this new metric performs better than other evaluation metrics when expressing user behaviour. Moreover, in order to test the performance of our metric on different and scalable ranking algorithms, we develop a pairwise text similarity algorithm using cosine similarity, implemented on the MapReduce model, and then perform experiments on rankings generated by the algorithm. "} 
}
@article{RodriguezOrtiz2016,
title = {"Determinants to trigger memory reconsolidation: The role of retrieval and updating information "},
journal = {"Neurobiology of Learning and Memory "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2016.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S107474271630380X"},
author = {"Carlos J. Rodriguez-Ortiz and Federico Bermúdez-Rattoni"},
keywords = {"Memory retrieval", "Memory expression", "Memory updating", "Memory reconsolidation "},
abstract = {"Abstract Long-term memories can undergo destabilization/restabilization processes, collectively called reconsolidation. However, the parameters that trigger memory reconsolidation are poorly understood and are a matter of intense investigation. Particularly, memory retrieval is widely held as requisite to initiate reconsolidation. This assumption makes sense since only relevant cues will induce reconsolidation of a specific memory. However, recent studies show that pharmacological inhibition of retrieval does not avoid memory from undergoing reconsolidation, indicating that memory reconsolidation occurs through a process that can be dissociated from retrieval. We propose that retrieval is not a unitary process but has two dissociable components; one leading to the expression of memory and the other to reconsolidation, referred herein as executer and integrator respectively. The executer would lead to the behavioral expression of the memory. This component would be the one disrupted on the studies that show reconsolidation independence from retrieval. The integrator would deal with reconsolidation. This component of retrieval would lead to long-term memory destabilization when specific conditions are met. We think that an important number of reports are consistent with the hypothesis that reconsolidation is only initiated when updating information is acquired. We suggest that the integrator would initiate reconsolidation to integrate updating information into long-term memory. "} 
}
@article{Saoud2016115,
title = {"Integrating social profile to improve the source selection and the result merging process in distributed information retrieval "},
journal = {"Information Sciences "},
volume = {"336"},
number = {""},
pages = {"115 - 128"},
year = {"2016"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.12.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515009019"},
author = {"Zakaria Saoud and Samir Kechid"},
keywords = {"Information retrieval", "Social profile", "Folksonomy", "Source selection process", "Merging process "},
abstract = {"Abstract In this paper we present a new personalized approach, which integrates a social profile into a distributed search system. Most previous studies on distributed information retrieval are based on textual information, and rarely consider any social information. Based on this observation, we propose an approach which exploits the social profile and the different relations between social entities. We believe that this method can: (i) enhance a query expansion, (ii) personalize and improve both the source selection and the result merging process in distributed information retrieval systems. "} 
}
@article{SesagiriRaamkumar2017577,
title = {"Using author-specified keywords in building an initial reading list of research papers in scientific paper retrieval and recommender systems "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"3"},
pages = {"577 - 594"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.12.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316301042"},
author = {"Aravind Sesagiri Raamkumar and Schubert Foo and Natalie Pang"},
keywords = {"Reading list", "Literature review", "Digital libraries", "Scientific paper information retrieval", "Author-specified keywords", "Scientific paper recommender systems "},
abstract = {"Abstract An initial reading list is prepared by researchers at the start of literature review for getting an overview of the research performed in a particular area. Prior studies have taken the approach of merely recommending seminal or popular papers to aid researchers in such a task. In this paper, we present an alternative technique called the \{AKR\} (Author-specified Keywords based Retrieval) technique for providing popular, recent, survey and a diverse set of papers as a part of the initial reading list. The \{AKR\} technique is based on a novel coverage value that has its calculation centered on author-specified keywords. We performed an offline evaluation experiment with four variants of the \{AKR\} technique along with three state-of-the-art approaches involving collaborative filtering and graph ranking algorithms. Findings show that the Hyperlink-Induced Topic Search (HITS) enhanced variant of the \{AKR\} technique performs better than other techniques, satisfying most requirements for a reading list. A user evaluation study was conducted with 132 researchers to gauge user interest on the proposed technique using 14 evaluation measures. Results show that (i) students group are more satisfied with the recommended papers than staff group, (ii) popularity measure is strongly correlated with the output quality measures and (iii) the measures familiarity, usefulness and ‘agreeability on a good list’ were found to be strong predictors for user satisfaction. The \{AKR\} technique provides scope for extension in future information retrieval (IR) and content-based recommender systems (RS) studies. "} 
}
@article{Arslan2016326,
title = {"DeASCIIfication approach to handle diacritics in Turkish information retrieval "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"2"},
pages = {"326 - 339"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.08.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315001053"},
author = {"Ahmet Arslan"},
keywords = {"Accents", "DeASCIIfier", "Diacritics restoration", "Risk-sensitive evaluation", "Stemming", "Turkish information retrieval "},
abstract = {"Abstract The absence of diacritics in text documents or search queries is a serious problem for Turkish information retrieval because it creates homographic ambiguity. Thus, the inappropriate handling of diacritics reduces the retrieval performance in search engines. A straightforward solution to this problem is to normalize tokens by replacing diacritic characters with their American Standard Code for Information Interchange (ASCII) counterparts. However, this so-called \{ASCIIfication\} produces either synthetic words that are not legitimate Turkish words or legitimate words with meanings that are completely different from those of the original words. These non-valid synthetic words cannot be processed by morphological analysis components (such as stemmers or lemmatizers), which expect the input to be valid Turkish words. By contrast, synthetic words are not a problem when no stemmer or a simple first-n-characters-stemmer is used in the text analysis pipeline. This difference emphasizes the notion of the diacritic sensitivity of stemmers. In this study, we propose and evaluate an alternative solution based on the application of deASCIIfication, which restores accented letters in query terms or text documents. Our risk-sensitive evaluation results showed that the diacritics restoration approach yielded more effective and robust results compared with normalizing tokens to remove diacritics. "} 
}
@article{Bouadjenek20161,
title = {"Social networks and information retrieval, how are they converging? A survey, a taxonomy and an analysis of social information retrieval approaches and platforms "},
journal = {"Information Systems "},
volume = {"56"},
number = {""},
pages = {"1 - 18"},
year = {"2016"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2015.07.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S030643791500160X"},
author = {"Mohamed Reda Bouadjenek and Hakim Hacid and Mokrane Bouzeghoub"},
keywords = {"Information Retrieval", "Social networks", "Social Information Retrieval", "Social search", "Social recommendation "},
abstract = {"Abstract There is currently a number of research work performed in the area of bridging the gap between Information Retrieval (IR) and Online Social Networks (OSN). This is mainly done by enhancing the \{IR\} process with information coming from social networks, a process called Social Information Retrieval (SIR). The main question one might ask is What would be the benefits of using social information (no matter whether it is content or structure) into the information retrieval process and how is this currently done? With the growing number of efforts towards the combination of \{IR\} and social networks, it is necessary to build a clearer picture of the domain and synthesize the efforts in a structured and meaningful way. This paper reviews different efforts in this domain. It intends to provide a clear understanding of the issues as well as a clear structure of the contributions. More precisely, we propose (i) to review some of the most important contributions in this domain to understand the principles of SIR, (ii) a taxonomy to categorize these contributions, and finally, (iii) an analysis of some of these contributions and tools with respect to several criteria, which we believe are crucial to design an effective \{SIR\} approach. This paper is expected to serve researchers and practitioners as a reference to help them structuring the domain, position themselves and, ultimately, help them to propose new contributions or improve existing ones. "} 
}
@article{Vilares2016136,
title = {"On the feasibility of character n-grams pseudo-translation for Cross-Language Information Retrieval tasks "},
journal = {"Computer Speech & Language "},
volume = {"36"},
number = {""},
pages = {"136 - 164"},
year = {"2016"},
note = {""},
issn = {"0885-2308"},
doi = {"https://doi.org/10.1016/j.csl.2015.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0885230815000935"},
author = {"Jesús Vilares and Manuel Vilares and Miguel A. Alonso and Michael P. Oakes"},
keywords = {"Cross-Language Information Retrieval", "Character n-grams", "Alignment algorithms for Machine Translation "},
abstract = {"Abstract The field of Cross-Language Information Retrieval relates techniques close to both the Machine Translation and Information Retrieval fields, although in a context involving characteristics of its own. The present study looks to widen our knowledge about the effectiveness and applicability to that field of non-classical translation mechanisms that work at character n-gram level. For the purpose of this study, an n-gram based system of this type has been developed. This system requires only a bilingual machine-readable dictionary of n-grams, automatically generated from parallel corpora, which serves to translate queries previously n-grammed in the source language. n-Gramming is then used as an approximate string matching technique to perform monolingual text retrieval on the set of n-grammed documents in the target language. The tests for this work have been performed on \{CLEF\} collections for seven European languages, taking English as the target language. After an initial tuning phase in order to analyze the most effective way for its application, the results obtained, close to the upper baseline, not only confirm the consistency across languages of this kind of character n-gram based approaches, but also constitute a further proof of their validity and applicability, these not being tied to a given implementation. "} 
}
@article{Madankar2016845,
title = {"Information Retrieval System and Machine Translation: A Review "},
journal = {"Procedia Computer Science "},
volume = {"78"},
number = {""},
pages = {"845 - 850"},
year = {"2016"},
note = {"1st International Conference on Information Security &amp; Privacy 2015 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.02.071"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916000739"},
author = {"Mangala Madankar and M.B. Chandak and Nekita Chavhan"},
keywords = {"Information Retrieval", "Cross Language Information Retrieval", "Multilanguage Information Retrieval", "Multilingual Indian Language", "Machine Translation "},
abstract = {"Abstract In this paper we introduce some of the most important areas of information retrieval i.e. Cross-lingual Information Retrieval (CLIR), Multi-lingual Information Retrieval (MLIR), Machine translation approaches and techniques. In today's growing nation, local database storage and retrieval is essential for the developing countries. \{CLIR\} deals with asking queries in one language and demand for retrieving documents in another language. \{MLIR\} deals with asking questions in one or more languages and retrieving documents in one or more different languages. Machine translation plays an important role to achieve the \{CLIR\} and \{MLIR\} system. "} 
}
@article{Rahimi2016299,
title = {"Extracting translations from comparable corpora for Cross-Language Information Retrieval using the language modeling framework "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"2"},
pages = {"299 - 318"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.08.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315001028"},
author = {"Razieh Rahimi and Azadeh Shakery and Irwin King"},
keywords = {"Translation model", "Bilingual lexicon", "Comparable corpora", "Cross-Language Information Retrieval", "Language modeling framework "},
abstract = {"Abstract A main challenge in Cross-Language Information Retrieval (CLIR) is to estimate a proper translation model from available translation resources, since translation quality directly affects the retrieval performance. Among different translation resources, we focus on obtaining translation models from comparable corpora, because they provide appropriate translations for both languages and domains with limited linguistic resources. In this paper, we employ a two-step approach to build an effective translation model from comparable corpora, without requiring any additional linguistic resources, for the \{CLIR\} task. In the first step, translations are extracted by deriving correlations between source–target word pairs. These correlations are used to estimate word translation probabilities in the second step. We propose a language modeling approach for the first step, where modeling based on probability distribution provides two key advantages. First, our approach can be tuned easier in comparison with heuristically adjusted previous work. Second, it provides a principled basis for integrating additional lexical and translational relations to improve the accuracy of translations from comparable corpora. As an indication, we integrate monolingual relations of word co-occurrences into the process of translation extraction, which helps to extract more reliable translations for low-frequency words in a comparable corpus. Experimental results on an English–Persian comparable corpus show that our method outperforms the previous approaches in terms of both translation quality and the performance of CLIR. Indeed, the proposed method is naturally applicable to any comparable corpus, regardless of its languages. In addition, we demonstrate the significant impact of word translation probabilities, estimated in the second step of our approach, on the performance of CLIR. "} 
}
@article{Abramovici2016294,
title = {"A Semantic Information Retrieval Framework within the Scope of IPS2-PLM "},
journal = {"Procedia \{CIRP\} "},
volume = {"47"},
number = {""},
pages = {"294 - 299"},
year = {"2016"},
note = {"Product-Service Systems across Life Cycle "},
issn = {"2212-8271"},
doi = {"https://doi.org/10.1016/j.procir.2016.03.083"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212827116300531"},
author = {"Michael Abramovici and Philip Gebus and Jens Christian Göbel and Hoang Bao Dang"},
keywords = {"IPS2", "Semantic Information Retrieval", "IPS2-PLM", "Semantic Search "},
abstract = {"Abstract The Product Lifecycle Management (PLM) approach faces new challenges if transferred for Industrial Product Service Systems (IPS2). The vast amount of heterogeneous data generated throughout an IPS2's lifecycle complicates the retrieval of required information for \{IPS2\} actors. However, these actors’ risky decisions determine an IPS2's success during use phase. Thus, an approach is needed that supports actors in finding targeted information. This paper presents a framework that utilizes semantic and text mining techniques in order to improve the information retrieval process in IPS2-PLM and to allow \{IPS2\} actors to focus on their value-adding tasks rather than spending a lot of time for finding information. "} 
}
@article{Sharma2016434,
title = {"Exploiting Wikipedia \{API\} for Hindi-english Cross-language Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"89"},
number = {""},
pages = {"434 - 440"},
year = {"2016"},
note = {"Twelfth International Conference on Communication Networks, \{ICCN\} 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, \{ICDMW\} 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, \{ICISP\} 2016, August 19-21, 2016, Bangalore, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.06.094"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916311590"},
author = {"Vijay Kumar Sharma and Namita Mittal"},
keywords = {"Cross-Language Information Retrieval", "Inter-Wiki Link", "Wikipedia \{API\} "},
abstract = {"Abstract The rapidly increasing demographics of the internet population and the abundance of multilingual content on the web increased the communication in multiple languages. Most of the people use their regional languages to express their needs and the language diversity becomes a great barrier. Cross-Language Information Retrieval (CLIR) provides a solution for that language barrier which allows a user to ask a query in the native language and get the relevant documents in the different language. In this paper, we proposed a Wikipedia \{API\} based query translation approach. Queries are tokenized and multi-words query terms are created using N-gram technique. Wikipedia title and inter-wiki link features are exploited for query translation. Target language documents are retrieved using vector space retrieval model and \{BM25\} retrieval algorithm. Experiment results shows that the proposed approach achieves better results without exploiting any language resources. "} 
}
@article{Ehsan20161004,
title = {"Candidate document retrieval for cross-lingual plagiarism detection using two-level proximity information "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"6"},
pages = {"1004 - 1017"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.04.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316300784"},
author = {"Nava Ehsan and Azadeh Shakery"},
keywords = {"Candidate document retrieval", "Cross-language plagiarism detection", "Text segmentation", "Proximity-based retrieval "},
abstract = {"Abstract The rapid growth of documents in different languages, the increased accessibility of electronic documents, and the availability of translation tools have caused cross-lingual plagiarism detection research area to receive increasing attention in recent years. The task of cross-language plagiarism detection entails two main steps: candidate retrieval and assessing pairwise document similarity. In this paper we examine candidate retrieval, where the goal is to find potential source documents of a suspicious text. Our proposed method for cross-language plagiarism detection is a keyword-focused approach. Since plagiarism usually happens in parts of the text, there is a requirement to segment the texts into fragments to detect local similarity. Therefore we propose a topic-based segmentation algorithm to convert the suspicious document to a set of related passages. After that, we use a proximity-based model to retrieve documents with the best matching passages. Experiments show promising results for this important phase of cross-language plagiarism detection. "} 
}
@incollection{Papy20161,
title = {"1 - Information Retrieval, Web and Interoperability "},
editor = {"Papy, Fabrice "},
booktitle = {"Digital Libraries "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2016"},
pages = {"1 - 28"},
isbn = {"978-1-78548-045-4"},
doi = {"https://doi.org/10.1016/B978-1-78548-045-4.50001-5"},
url = {"http://www.sciencedirect.com/science/article/pii/B9781785480454500015"},
author = {"Fabrice Papy"},
keywords = {"Computer science", "Digital use", "HTTP", "Information retrieval", "Interoperability", "IR specificity", "IS specificity", "Repositories", "Technical documentation", "WordPress data model "},
abstract = {"Abstract: Widespread access to the Internet and its most commonly used services, such as electronic mail, Web and, most recently, digital social networks, has led to a trivialization of information retrieval (IR) practices [GRI 11, \{DIN\} 14, \{DIN\} 07, \{CIA\} 05, \{ASS\} 02], which were in the recent past reserved for information specialists (journalists, information officers, guards, archivists, librarians, etc.) [CAT 01, \{DUF\} 01, \{LEF\} 00]. Having been introduced to the general public by the free access general search engines, \{IR\} was for several years delegated to a group of Internet surfers at the mercy of these automated indexing and retrieval systems with basic mechanisms1, which can precisely and rapidly list a large part of the visible document production in the Web of documents [LEW 08, \{CHI\} 07, \{RIE\} 06, \{LEL\} 99]. "} 
}
@article{Vechtomova20171062,
title = {"Disambiguating context-dependent polarity of words: An information retrieval approach "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"5"},
pages = {"1062 - 1079"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2017.03.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316305416"},
author = {"Olga Vechtomova"},
keywords = {"Sentiment analysis", "Polarity disambiguation", "Word polarity", "Context-dependent polarity of words "},
abstract = {"Abstract The paper introduces PolaritySim – a novel approach to disambiguating context-dependent sentiment polarity of words. The task of resolving the polarity of a given word instance as positive or negative is addressed as an information retrieval problem. At the pre-processing stage, a vector of context features is built for each word w based on all its occurrences in the positive polarity corpus (consumer reviews with high ratings) and another vector – on its contexts in the negative polarity corpus (reviews with low ratings). Lexico-syntactic context features are automatically generated from dependency parse graphs of the sentences containing the word. These two vectors are treated as “documents”, one with positive and one with negative polarity. To resolve the contextual polarity of a specific instance of the word w in a given sentence, its context feature vector is built in the same way, and is treated as the “query”. An information retrieval (IR) model is then applied to calculate the similarity of the “query” to each of the two “documents”, with the polarity of the best matching “document” attributed to the “query”. The method uses no prior polarity sentiment lexicons or purposefully annotated training datasets. The only external resource used is a readily available corpus of user-rated reviews. Evaluation on different domains shows more effective performance compared to state-of-the-art baselines, Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB) classifiers, on three out of four datasets. PolaritySim, \{SVM\} and \{MNB\} were also evaluated with an out-of-domain training corpus. The results indicate that PolaritySim is more effective and robust when used with an out-of-domain corpus compared to \{SVM\} and MNB. We conclude that an \{IR\} based approach can be an effective and robust alternative to machine learning approaches for disambiguating word-level polarity using either within-domain, or out-of-domain training corpora. "} 
}
@article{Bittl20171,
title = {"Privacy conserving low volume information retrieval from backbone services in \{VANETs\} "},
journal = {"Vehicular Communications "},
volume = {"9"},
number = {""},
pages = {"1 - 7"},
year = {"2017"},
note = {""},
issn = {"2214-2096"},
doi = {"https://doi.org/10.1016/j.vehcom.2017.02.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S2214209616301413"},
author = {"Sebastian Bittl"},
keywords = {"VANET", "Privacy", "Security "},
abstract = {"Abstract Mobile ad hoc networks are of high interest in research and practice, especially as realizations in the automotive domain. Wireless data exchange, safety critical use cases and privacy requirements impose tough challenges on applied security mechanisms. Well studied solutions are available for direct communication between nodes. However, also time critical data retrieval from backbone services is required for many use cases, like the delivery of pseudonym certificates. This topic has not been looked at in detail in prior work. We show that the approach proposed in standards bears significant drawbacks. High effort in the input message validation process causes a denial of service weakness of backbone services. Moreover, request messages contain removable data sets making them unnecessarily long, which leads to high bandwidth requirements for reliable communication between backbone and mobile node. Thus, we propose a new data retrieval scheme increasing robustness of the backbone to denial of service attacks and decreasing length of nodes' request messages. The conducted evaluation shows good usability of the approach. "} 
}
@article{Yang20153206,
title = {"Reductions between private information retrieval and oblivious transfer at the quantum level "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"126"},
number = {"21"},
pages = {"3206 - 3209"},
year = {"2015"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.07.149"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615007020"},
author = {"Yu-Guang Yang and Si-Jia Sun and Qing-Xiang Pan and Peng Xu"},
keywords = {"Private information retrieval", "Oblivious transfer", "Reduction "},
abstract = {"Abstract Although private information retrieval and oblivious transfer are equivalent in classical cryptography, we show that the existence of secure quantum private information retrieval is necessary but not sufficient for secure quantum oblivious transfer, which provides a strong evidence of nonequivalence of two flavors of oblivious transfer at the quantum level. "} 
}
@article{Sender2015565,
title = {"An Intervention Program for Improving Writing and Information Retrieval among Students with Ambidexterity "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"209"},
number = {""},
pages = {"565 - 571"},
year = {"2015"},
note = {"The 3rd International Conference "EDUCATION, REFLECTION, DEVELOPMENT", 3th - 4th July, 2015 "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2015.11.288"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877042815056359"},
author = {"Yael Sender"},
keywords = {"Ambidexterity", "Writing skill", "Information Retrieval", "Brain plasticity", "Training "},
abstract = {"Abstract This research deals with 1% of the population who is defined as ambidextrous who characterized by slow writing pace, information retrieval and sequence memorizing and had a gap in their academic achievements. This study refers to a unique intervention program called \{ATP\} (ambidexterity training program) which examined the effect of it on ambidextrous students (7-16) through routine training A.T.P included drawing, meant to strengthen the middle-line crossing, writing sequences of the Hebrew alphabet (for older students also English alphabet) and number sequences in order to improve the verbal fluency, and copying a paragraph (30 words) in order to improve writing pace. "} 
}
@article{Kanoje20165,
title = {"User Profiling for University Recommender System Using Automatic Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"78"},
number = {""},
pages = {"5 - 12"},
year = {"2016"},
note = {"1st International Conference on Information Security &amp; Privacy 2015 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.02.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916000041"},
author = {"Sumitkumar Kanoje and Debajyoti Mukhopadhyay and Sheetal Girase"},
keywords = {"User Profiling", "Information Retrieval", "Data Mining "},
abstract = {"Abstract User Profiling is the process of Extracting, Integrating and Identifying the keyword based information to generate a structured Profile and then visualizing the knowledge out of these findings. User profiling helps personalizing a system to work according to user. Therefore user profiling or personalization is one of the major concepts used for accessing the user relevant information, which can be used to solve the difficult problems of recommender system like classification and ranking of items in accordance with an individual's interest. In this paper we focus on the problem of user profiling in which we aim at finding, extracting and integrating keyword based information from various web sources to generate a structured profile. Further we do some experiments on the profiled information to generate knowledge out of it. "} 
}
@article{MoránReyes2016109,
title = {"Methods and trends of biomedical and genomic information retrieval based on semantic relations of thesauri and MeSH "},
journal = {"Investigación Bibliotecológica: Archivonomía, Bibliotecología e Información "},
volume = {"30"},
number = {"68, Supplement"},
pages = {"109 - 123"},
year = {"2016"},
note = {""},
issn = {"0187-358X"},
doi = {"https://doi.org/10.1016/j.ibbai.2016.06.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0187358X16300326"},
author = {"Ariel Antonio Morán Reyes and Catalina Naumis Peña"},
keywords = {"Library Science and Terminology", "Automated Information Retrieval", "Medical Subjects Headings", "Thesauri", "Bibliotecología y terminología", "Recuperación de información automatizada", "Encabezamientos de temas médicos", "Tesauros "},
abstract = {"\{ABSTRACT\} In the field of genomic science and medicine in general, there are two methods of retrieving information from documents, namely: 1) through the combined use of associations determined by the Medical Subject Headings, and 2) by employing specific terminologies, such as those in folksonomies, alternative medical-genomic terms in use in the general language, or acronyms or apocopes from the genomics field. To some extent, many thinkers in matters of indexing hold that the combination of two methods may be the best approach. While few authors advocate for keeping the structure of controlled vocabularies, built up over many years of content interpretation, unchanged, there are numerous proposals for expanding the search horizons of thesauri, whether through social cataloging, algorithmic domain analyses that contrast indicators or the semantic web, using markers of meaningful semantic lexicons contained in digitized text. "} 
}
@article{TK2017223,
title = {"An efficient and secure information retrieval framework for content centric networks "},
journal = {"Journal of Parallel and Distributed Computing "},
volume = {"104"},
number = {""},
pages = {"223 - 233"},
year = {"2017"},
note = {""},
issn = {"0743-7315"},
doi = {"https://doi.org/10.1016/j.jpdc.2017.01.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0743731517300436"},
author = {"Ashwin Kumar T.K. and Johnson P. Thomas and Saikiran Parepally"},
keywords = {"Content centric networks", "Security", "NOSQL", "Network utilization", "Role-based access "},
abstract = {"Abstract Content centric networking is a new networking architecture designed to work with existing network architecture and protocols. In content centric networks emphasis is on data rather than its location. Content centric networks, support data caching in intermediate nodes that allows them to serve future request. This results in more efficient content delivery. As data is cached at various intermediate nodes, the owner of the data has no control over the data. Data stored in intermediate nodes can be vulnerable and be exploited by the intermediate nodes, malicious users and intruders, who do not have legitimate access to these data. In addition to this entire data is being broadcasted by the intermediate nodes whenever they receive a request for that corresponding data. This utilizes a substantial portion of the network bandwidth. To address these issues we propose a framework in this paper that (1) efficiently organizes data that is cached in intermediate nodes using a \{NOSQL\} (Not Only SQL) graph database, (2) reduces the network utilization, (3) secures all the data transferred across content centric networks, such that only owners of the data can provide access to the consumers of their data and (4) provides role-based access to the consumers, and reduces complications in key distribution and management. Our experimental results indicate that our framework is able to reduce network utilization by over 79% in the best-case scenario and by over 65% in the worst-case scenario. "} 
}
@article{Souvignet2016100,
title = {"OntoADR a semantic resource describing adverse drug reactions to support searching, coding, and information retrieval "},
journal = {"Journal of Biomedical Informatics "},
volume = {"63"},
number = {""},
pages = {"100 - 107"},
year = {"2016"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2016.06.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046416300533"},
author = {"Julien Souvignet and Gunnar Declerck and Hadyl Asfari and Marie-Christine Jaulent and Cédric Bousquet"},
keywords = {"Knowledge representation", "Pharmacovigilance", "Biological ontologies", "Terminological reasoning", "Data retrieval "},
abstract = {"AbstractIntroduction Efficient searching and coding in databases that use terminological resources requires that they support efficient data retrieval. The Medical Dictionary for Regulatory Activities (MedDRA) is a reference terminology for several countries and organizations to code adverse drug reactions (ADRs) for pharmacovigilance. Ontologies that are available in the medical domain provide several advantages such as reasoning to improve data retrieval. The field of pharmacovigilance does not yet benefit from a fully operational ontology to formally represent the MedDRA terms. Our objective was to build a semantic resource based on formal description logic to improve MedDRA term retrieval and aid the generation of on-demand custom groupings by appropriately and efficiently selecting terms: OntoADR. Methods The method consists of the following steps: (1) mapping between MedDRA terms and SNOMED-CT, (2) generation of semantic definitions using semi-automatic methods, (3) storage of the resource and (4) manual curation by pharmacovigilance experts. Results We built a semantic resource for \{ADRs\} enabling a new type of semantics-based term search. OntoADR adds new search capabilities relative to previous approaches, overcoming the usual limitations of computation using lightweight description logic, such as the intractability of unions or negation queries, bringing it closer to user needs. Our automated approach for defining MedDRA terms enabled the association of at least one defining relationship with 67% of preferred terms. The curation work performed on our sample showed an error level of 14% for this automated approach. We tested OntoADR in practice, which allowed us to build custom groupings for several medical topics of interest. Discussion The methods we describe in this article could be adapted and extended to other terminologies which do not benefit from a formal semantic representation, thus enabling better data retrieval performance. Our custom groupings of MedDRA terms were used while performing signal detection, which suggests that the graphical user interface we are currently implementing to process OntoADR could be usefully integrated into specialized pharmacovigilance software that rely on MedDRA. "} 
}
@article{Reyes2016109,
title = {"Métodos y tendencias de recuperación de información biomédica y genómica basados en las relaciones semánticas de los tesauros y los MeSH "},
journal = {"Investigación Bibliotecológica: Archivonomía, Bibliotecología e Información "},
volume = {"30"},
number = {"68"},
pages = {"109 - 123"},
year = {"2016"},
note = {""},
issn = {"0187-358X"},
doi = {"https://doi.org/10.1016/j.ibbai.2016.02.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0187358X16000071"},
author = {"Ariel Antonio Morán Reyes and Catalina Naumis Peña"},
keywords = {"Bibliotecología y terminología", "Recuperación de información automatizada", "Encabezamientos de temas médicos", "Tesauros", "Library Science and Terminology", "Automated Information Retrieval", "Medical Subjects Headings", "Thesauri "},
abstract = {"\{ABSTRACT\} There are two methods of retrieving information from documents in the field of genomic science and medicine in general, namely: 1) through the combined use of associations determined by the Medical Subject Headings, and 2) by employing specific terminologies, such as in folksonomies, alternative medical-genomic terms in use in the general language, or acronyms or apocopes from the genomics field. To some extent, many thinkers and indexers hold that the combination of two methods may be the best approach. While few authors advocate for keeping the structure of controlled vocabularies, built up over many years of content interpretation, unchanged, there are numerous proposals for expanding the search horizons of thesauri, whether through social cataloging, algorithmic domain analyses that contrast indicators or the semantic web using markers of meaningful semantic lexicons contained in digitized text. "} 
}
@article{MataRivera2015829,
title = {"A collaborative learning approach for geographic information retrieval based on social networks "},
journal = {"Computers in Human Behavior "},
volume = {"51, Part B"},
number = {""},
pages = {"829 - 842"},
year = {"2015"},
note = {"Computing for Human Learning, Behaviour and Collaboration in the Social and Mobile Networks Era "},
issn = {"0747-5632"},
doi = {"https://doi.org/10.1016/j.chb.2014.11.069"},
url = {"http://www.sciencedirect.com/science/article/pii/S0747563214006876"},
author = {"Felix Mata-Rivera and Miguel Torres-Ruiz and Giovanni Guzmán and Marco Moreno-Ibarra and Rolando Quintero"},
keywords = {"Geographic information retrieval", "GIScience collaborative learning", "Query contextualization", "Matching-query layers", "Ontology "},
abstract = {"Abstract Nowadays, spatial and temporal data play an important role in social networks. These data are distributed and dispersed in several heterogeneous data sources. These peculiarities make that geographic information retrieval being a non-trivial task, considering that the spatial data are often unstructured and built by different collaborative communities from social networks. The problem arises when user queries are performed with different levels of semantic granularity. This fact is very typical in social communities, where users have different levels of expertise. In this paper, a novelty approach based on three matching-query layers driven by ontologies on the heterogeneous data sources is presented. A technique of query contextualization is proposed for addressing to available heterogeneous data sources including social networks. It consists of contextualizing a query in which whether a data source does not contain a relevant result, other sources either provide an answer or in the best case, each one adds a relevant answer to the set of results. This approach is a collaborative learning system based on experience level of users in different domains. The retrieval process is achieved from three domains: temporal, geographical and social, which are involved in the user-content context. The work is oriented towards defining a \{GIScience\} collaborative learning for geographic information retrieval, using social networks, web and geodatabases. "} 
}
@article{Greving2015291,
title = {"Counter-regulation online: Threat biases retrieval of information during Internet search "},
journal = {"Computers in Human Behavior "},
volume = {"50"},
number = {""},
pages = {"291 - 298"},
year = {"2015"},
note = {""},
issn = {"0747-5632"},
doi = {"https://doi.org/10.1016/j.chb.2015.03.077"},
url = {"http://www.sciencedirect.com/science/article/pii/S0747563215002782"},
author = {"Hannah Greving and Kai Sassenberg"},
keywords = {"Threat", "Internet search", "Retrieval", "Counter-regulation", "Self-relevant information "},
abstract = {"Abstract The Internet is one of the main information sources. It is frequently used to gather information in self-relevant domains, such as health. Self-relevant information is likely to be accompanied by certain affective and motivational states. For instance, individuals may be afraid to be seriously ill and, thus, feel threatened. Threat is known to elicit preferential processing of positive information. Therefore, we predicted that under threat more positive search terms are retrieved from memory and more positive information is retrieved from already encoded online information than in a control condition. Two experiments supported this prediction. Thus, information processing during Internet search is positively biased under threat. This positive bias can satisfy coping needs, but can at the same time have a negative impact on subsequent behavior and decisions. "} 
}
@article{Ali2016539,
title = {"Image retrieval by addition of spatial information based on histograms of triangular regions "},
journal = {"Computers & Electrical Engineering "},
volume = {"54"},
number = {""},
pages = {"539 - 550"},
year = {"2016"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2016.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790616300726"},
author = {"Nouman Ali and Khalid Bashir Bajwa and Robert Sablatnig and Zahid Mehmood"},
keywords = {"Content-based image retrieval", "Histogram of triangles", "Dense features", "Image classification", "Deep belief networks", "Support vector machines "},
abstract = {"Abstract The compositional and content attributes of images carry information that enhances the performance of image retrieval. Standard images are constructed by following the rule of thirds that divides an image into nine equal parts by placing objects or regions of interest at the intersecting lines of the grid. An image represents regions and objects that are in a spatial semantic relationship with respect to each other. While the Bag of Features (BoF) representation is commonly used for image retrieval, it lacks spatial information. In this paper, we present two novel image representation methods based on the histograms of triangles, which add spatial information to the inverted index of BoF representation. Histograms of triangles are computed at two levels, by dividing an image into two and four triangles that are evaluated separately. Extensive experiments and comparisons conducted on two datasets demonstrate that the proposed image representations enhance the performance of image retrieval. "} 
}
@article{Vogelsang2016356,
title = {"Goal-directed mechanisms that constrain retrieval predict subsequent memory for new “foil” information "},
journal = {"Neuropsychologia "},
volume = {"89"},
number = {""},
pages = {"356 - 363"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2016.07.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393216302603"},
author = {"David A. Vogelsang and Heidi M. Bonnici and Zara M. Bergström and Charan Ranganath and Jon S. Simons"},
keywords = {"Episodic retrieval", "fMRI", "Subsequent memory, foils, left inferior frontal gyrus "},
abstract = {"Abstract To remember a previous event, it is often helpful to use goal-directed control processes to constrain what comes to mind during retrieval. Behavioral studies have demonstrated that incidental learning of new “foil” words in a recognition test is superior if the participant is trying to remember studied items that were semantically encoded compared to items that were non-semantically encoded. Here, we applied subsequent memory analysis to fMRI data to understand the neural mechanisms underlying the “foil effect”. Participants encoded information during deep semantic and shallow non-semantic tasks and were tested in a subsequent blocked memory task to examine how orienting retrieval towards different types of information influences the incidental encoding of new words presented as foils during the memory test phase. To assess memory for foils, participants performed a further surprise old/new recognition test involving foil words that were encountered during the previous memory test blocks as well as completely new words. Subsequent memory effects, distinguishing successful versus unsuccessful incidental encoding of foils, were observed in regions that included the left inferior frontal gyrus and posterior parietal cortex. The left inferior frontal gyrus exhibited disproportionately larger subsequent memory effects for semantic than non-semantic foils, and significant overlap in activity during semantic, but not non-semantic, initial encoding and foil encoding. The results suggest that orienting retrieval towards different types of foils involves re-implementing the neurocognitive processes that were involved during initial encoding. "} 
}
@article{Wu20151,
title = {"Modeling query-document dependencies with topic language models for information retrieval "},
journal = {"Information Sciences "},
volume = {"312"},
number = {""},
pages = {"1 - 12"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.03.056"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515002212"},
author = {"Meng-Sung Wu"},
keywords = {"Topic model", "Information retrieval", "Query-document relevance", "Latent Dirichlet allocation "},
abstract = {"Abstract This paper addresses deficiencies in current information retrieval models by integrating the concept of relevance into the generation model using various topical aspects of the query. The models are adapted from the latent Dirichlet allocation model, but differ in the way that the notation of query-document relevance is introduced in the modeling framework. In the first method, query terms are added to relevant documents in the training of the latent Dirichlet allocation model. In the second method, the latent Dirichlet allocation model is expanded to deal with relevant query terms. The topic of each term within a given document may be sampled using either the normal document-specific mixture weights in \{LDA\} using query-specific mixture weights. We also developed an efficient method based on the Gibbs sampling technique for parameter estimation. Experiment results based on the Text \{REtrieval\} Conference Corpus (TREC) demonstrate the superiority of the proposed models. "} 
}
@article{Yao2017135,
title = {"Supervised Coarse-to-Fine Semantic Hashing for cross-media retrieval "},
journal = {"Digital Signal Processing "},
volume = {"63"},
number = {""},
pages = {"135 - 144"},
year = {"2017"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2017.01.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200417300064"},
author = {"Tao Yao and Xiangwei Kong and Haiyan Fu and Qi Tian"},
keywords = {"Cross-modal retrieval", "Coarse-to-fine semantic information", "Hashing", "Inter-category and intra-category "},
abstract = {"Abstract Due to its storage efficiency and fast query speed, cross-media hashing methods have attracted much attention for retrieving semantically similar data over heterogeneous datasets. Supervised hashing methods, which utilize the labeled information to promote the quality of hashing functions, achieve promising performance. However, the existing supervised methods generally focus on utilizing coarse semantic information between samples (e.g. similar or dissimilar), and ignore fine semantic information between samples which may degrade the quality of hashing functions. Accordingly, in this paper, we propose a supervised hashing method for cross-media retrieval which utilizes the coarse-to-fine semantic similarity to learn a sharing space. The inter-category and intra-category semantic similarity are effectively preserved in the sharing space. Then an iterative descent scheme is proposed to achieve an optimal relaxed solution, and hashing codes can be generated by quantizing the relaxed solution. At last, to further improve the discrimination of hashing codes, an orthogonal rotation matrix is learned by minimizing the quantization loss while preserving the optimality of the relaxed solution. Extensive experiments on widely used Wiki and NUS-WIDE datasets demonstrate that the proposed method outperforms the existing methods. "} 
}
@article{Farokhzadian2015570,
title = {"Information seeking and retrieval skills of nurses: Nurses readiness for evidence based practice in hospitals of a medical university in Iran "},
journal = {"International Journal of Medical Informatics "},
volume = {"84"},
number = {"8"},
pages = {"570 - 577"},
year = {"2015"},
note = {""},
issn = {"1386-5056"},
doi = {"https://doi.org/10.1016/j.ijmedinf.2015.03.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1386505615000805"},
author = {"Jamileh Farokhzadian and Reza Khajouei and Leila Ahmadian"},
keywords = {"Decision-making", "Evidence based practice", "Information seeking behavior", "Information storage and retrieval", "Information literacy", "Nurses", "Iran "},
abstract = {"AbstractBackground With the explosion of medical information, and emergence of evidence-based practice (EBP) in healthcare system, searching, retrieving and selecting information for clinical decision-making are becoming required skills for nurses. Aims The aims of this study were to examine the use of different medical information resources by nurses and their information searching and retrieving skills in the context of EBP. Method A descriptive, cross-sectional study was conducted in four teaching hospitals in Iran. Data were collected from 182 nurses using a questionnaire in 2014. Results The nurses indicated that they use more human and printed resources than electronic resources to seek information (mean = 2.83, \{SD\} = 1.5; mean = 2.77, \{SD\} = 1.07; and mean = 2.13, \{SD\} = 0.88, respectively). To search online resources, the nurses use quick/basic search features more frequently (mean = 2.45, \{SD\} = 1.15) than other search features such as advanced search, index browsing and MeSH term searching. (1.74 ≤ mean ≤ 2.30, \{SD\} = 1.01). At least 80% of the nurses were not aware of the purpose or function of search operators such as Boolean and proximity operators. In response to the question measuring skills of the nurses in developing an effective search statement by using Boolean operators, only 20% of them selected the more appropriate statement, using some synonyms of the concepts in a given subject. Conclusion The study showed that the information seeking and retrieval skills of the nurses were poor and there were clear deficits in the use of updated information resources. To compensate their \{EBP\} incompetency, nurses may resort to human resources. In order to use the latest up to date evidence independently, nurses need to improve their information literacy. To reach this goal, clinical librarians, health information specialists, nursing faculties, and clinical nurse educators and mentors can play key roles by providing educational programs. Providing access to online resources in clinical wards can also encourage nurses to learn and use these resources. "} 
}
@article{Mauri20171,
title = {"Up-to-date key retrieval for information centric networking "},
journal = {"Computer Networks "},
volume = {"112"},
number = {""},
pages = {"1 - 11"},
year = {"2017"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2016.10.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128616303668"},
author = {"Giulia Mauri and Giacomo Verticale"},
keywords = {"Information centric networking", "Named data networking", "Digital signature", "Public key updating", "Key revocation", "CRL", "OCSP "},
abstract = {"Abstract Information Centric Networking (ICN) leverages in-network caching to provide efficient data distribution and better performance by replicating contents in multiple nodes to bring content nearer the users. Since contents are stored and replicated into node caches, the content validity must be assured end-to-end. Each content object carries a digital signature to provide a proof of its integrity, authenticity, and provenance. However, the use of digital signatures requires a key management infrastructure to manage the key life cycle. To perform a proper signature verification, a node needs to know whether the signing key is valid or it has been revoked. This paper discusses how to retrieve up-to-date signing keys in the \{ICN\} scenario. In the usual public key infrastructure, the Certificate Revocation Lists (CRL) or the Online Certificate Status Protocol (OCSP) enable applications to obtain the revocation status of a certificate. However, the push-based distribution of Certificate Revocation Lists and the request/response paradigm of Online Certificate Status Protocol should be fit in the mechanism of named-data. We consider three possible approaches to distribute up-to-date keys in a similar way to the current \{CRL\} and OCSP. Then, we suggest a fourth protocol leveraging a set of distributed notaries, which naturally fits the \{ICN\} scenario. Finally, we evaluate the number and size of exchanged messages of each solution, and then we compare the methods considering the perceived latency by the end nodes and the throughput on the network links. "} 
}
@article{Vichivanives2015998,
title = {"Temple Information Retrieval System using Quick Response Code via Mobile Application "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"197"},
number = {""},
pages = {"998 - 1005"},
year = {"2015"},
note = {"7th World Conference on Educational Sciences "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2015.07.292"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877042815042937"},
author = {"Rujijan Vichivanives and Sakolphak Ralangarm"},
keywords = {"information retrieval system", "quick response code", "mobile application", "smartphone "},
abstract = {"Abstract Purpose of this research was to develop a searching technology application based on the Android operating system and the utilization of Quick Response Code (QR code) technology as main data storage. The scope of the information searching was limited to locating temples within the districts of Dusit and PhraNakorn of the Bangkok Metropolitan Area. The developer considered the importance of communication through detailed data collection and gathering so that the users of this application could obtain concise and complete information. The result of this research project was that tourists could use the ability of smart devices to scan the \{QR\} code via the developed application that subsequently processed and rendered various information, including pictures, history and details of the requested temple inquiries on the displays. The assessment results on the viewpoints of two hundred tourist users in the average of the overall picture was at 4.20, which should be considered to be a good level. The researcher's suggestion was to extend methods of information searching to increase speed, accuracy and correct information to produce maximum benefits and effectiveness that users of this application could expect to receive. "} 
}
@article{Junnila2015354,
title = {"Information retrieval with unambiguous output "},
journal = {"Information and Computation "},
volume = {"242"},
number = {""},
pages = {"354 - 368"},
year = {"2015"},
note = {""},
issn = {"0890-5401"},
doi = {"https://doi.org/10.1016/j.ic.2015.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0890540115000449"},
author = {"Ville Junnila and Tero Laihonen"},
keywords = {"Associative memory", "Information retrieval", "Extremal graph", "Covering code", "Forced vertex", "Algorithmic complexity "},
abstract = {"Abstract The main problem in information storage has previously been how large amounts of data can be stored. However, the technological development over the years has been able to give rather satisfactory answers to this problem. Recently, the focus has shifted towards determining how stored information can be efficiently retrieved. This problem is addressed in an article by E. Yaakobi and J. Bruck (2012), where information retrieval in associative memories is studied. In this paper, we focus on the case where the retrieved information unit is unambiguous. In particular, we present characterizations and study various extremal properties of such associative memories. Moreover, the algorithmic complexity of certain naturally rising problems is considered. "} 
}
@article{Wu201520,
title = {"A geometric framework for data fusion in information retrieval "},
journal = {"Information Systems "},
volume = {"50"},
number = {""},
pages = {"20 - 35"},
year = {"2015"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2015.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437915000113"},
author = {"Shengli Wu and Fabio Crestani"},
keywords = {"Database searching", "Geometric modeling", "Information retrieval", "Data fusion "},
abstract = {"Abstract Data fusion in information retrieval has been investigated by many researchers and a number of data fusion methods have been proposed. However, problems such as why data fusion can increase effectiveness and favorable conditions for the use of data fusion methods are poorly resolved at best. In this paper, we formally describe data fusion under a geometric framework, in which each component result returned from an information retrieval system for a given query is represented as a point in a multi-dimensional space. The Euclidean distance is the measure by which the effectiveness and similarity of search results are judged. This allows us to explain all component results and fused results using geometrical principles. In such a framework, score-based data fusion becomes a deterministic problem. Several interesting features of the centroid-based data fusion method and the linear combination method are discussed. Nevertheless, in retrieval evaluation, ranking-based measures are the most popular. Therefore, this paper investigates the relation and correlation between the Euclidean distance and several typical ranking-based measures. We indeed find that a very strong correlation exists between these. It means that the theorems and observations obtained using the Euclidean distance remain valid when ranking-based measures are used. The proposed framework enables us to have a better understanding of score-based data fusion and use score-based data fusion methods more precisely and effectively in various ways. "} 
}
@article{Hanauer2015290,
title = {"Supporting information retrieval from electronic health records: A report of University of Michigan’s nine-year experience in developing and using the Electronic Medical Record Search Engine (EMERSE) "},
journal = {"Journal of Biomedical Informatics "},
volume = {"55"},
number = {""},
pages = {"290 - 300"},
year = {"2015"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2015.05.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046415000829"},
author = {"David A. Hanauer and Qiaozhu Mei and James Law and Ritu Khanna and Kai Zheng"},
keywords = {"Electronic health records (E05.318.308.940.968.625.500)", "Search engine (L01.470.875)", "Information storage and retrieval (L01.470) "},
abstract = {"AbstractObjective This paper describes the University of Michigan’s nine-year experience in developing and using a full-text search engine designed to facilitate information retrieval (IR) from narrative documents stored in electronic health records (EHRs). The system, called the Electronic Medical Record Search Engine (EMERSE), functions similar to Google but is equipped with special functionalities for handling challenges unique to retrieving information from medical text. Materials and methods Key features that distinguish \{EMERSE\} from general-purpose search engines are discussed, with an emphasis on functions crucial to (1) improving medical \{IR\} performance and (2) assuring search quality and results consistency regardless of users’ medical background, stage of training, or level of technical expertise. Results Since its initial deployment, \{EMERSE\} has been enthusiastically embraced by clinicians, administrators, and clinical and translational researchers. To date, the system has been used in supporting more than 750 research projects yielding 80 peer-reviewed publications. In several evaluation studies, \{EMERSE\} demonstrated very high levels of sensitivity and specificity in addition to greatly improved chart review efficiency. Discussion Increased availability of electronic data in healthcare does not automatically warrant increased availability of information. The success of \{EMERSE\} at our institution illustrates that free-text \{EHR\} search engines can be a valuable tool to help practitioners and researchers retrieve information from \{EHRs\} more effectively and efficiently, enabling critical tasks such as patient case synthesis and research data abstraction. Conclusion EMERSE, available free of charge for academic use, represents a state-of-the-art medical \{IR\} tool with proven effectiveness and user acceptance. "} 
}
@article{Kauppi2015288,
title = {"Towards brain-activity-controlled information retrieval: Decoding image relevance from \{MEG\} signals "},
journal = {"NeuroImage "},
volume = {"112"},
number = {""},
pages = {"288 - 298"},
year = {"2015"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2014.12.079"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811915000026"},
author = {"Jukka-Pekka Kauppi and Melih Kandemir and Veli-Matti Saarinen and Lotta Hirvenkari and Lauri Parkkonen and Arto Klami and Riitta Hari and Samuel Kaski"},
keywords = {"Bayesian classification", "Image relevance", "Implicit relevance feedback", "Information retrieval", "Magnetoencephalography", "Gaze signal", "Gaussian processes "},
abstract = {"Abstract We hypothesize that brain activity can be used to control future information retrieval systems. To this end, we conducted a feasibility study on predicting the relevance of visual objects from brain activity. We analyze both magnetoencephalographic (MEG) and gaze signals from nine subjects who were viewing image collages, a subset of which was relevant to a predetermined task. We report three findings: i) the relevance of an image a subject looks at can be decoded from \{MEG\} signals with performance significantly better than chance, ii) fusion of gaze-based and MEG-based classifiers significantly improves the prediction performance compared to using either signal alone, and iii) non-linear classification of the \{MEG\} signals using Gaussian process classifiers outperforms linear classification. These findings break new ground for building brain-activity-based interactive image retrieval systems, as well as for systems utilizing feedback both from brain activity and eye movements. "} 
}
@article{MorenoSchneider2017201,
title = {"Combining heterogeneous sources in an interactive multimedia content retrieval model "},
journal = {"Expert Systems with Applications "},
volume = {"69"},
number = {""},
pages = {"201 - 213"},
year = {"2017"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2016.10.049"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417416305917"},
author = {"Julián Moreno-Schneider and Paloma Martínez and José L. Martínez-Fernández"},
keywords = {"Multimodal information retrieval", "User adaptation", "Retrieval engines", "Rule-based expert systems "},
abstract = {"Abstract Interactive multimodal information retrieval systems (IMIR) increase the capabilities of traditional search systems, by adding the ability to retrieve information of different types (modes) and from different sources. This article describes a formal model for interactive multimodal information retrieval. This model includes formal and widespread definitions of each component of an \{IMIR\} system. A use case that focuses on information retrieval regarding sports validates the model, by developing a prototype that implements a subset of the features of the model. Adaptive techniques applied to the retrieval functionality of \{IMIR\} systems have been defined by analysing past interactions using decision trees, neural networks, and clustering techniques. This model includes a strategy for selecting sources and combining the results obtained from every source. After modifying the strategy of the prototype for selecting sources, the system is re-evaluated using classification techniques. This evaluation compares the normalised discounted cumulative gain (NDCG) measure obtained using two different approaches: the multimodal system using a baseline strategy based on predefined rules as a source selection strategy, and the same multimodal system with the functionality adapted by past user interactions. In the adapted system, a final value of 81,54% was obtained for the NDCG. "} 
}
@article{Jiang2017,
title = {"Internet cross-media retrieval based on deep learning "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2017.02.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320317300482"},
author = {"Bin Jiang and Jiachen Yang and Zhihan Lv and Kun Tian and Qinggang Meng and Yan Yan"},
keywords = {"Cross-media retrieval", "Deep learning", "Feature extracting", "Multimedia information "},
abstract = {"Abstract With the development of Internet, multimedia information such as image and video is widely used. Therefore, how to find the required multimedia data quickly and accurately in a large number of resources, has become a research focus in the field of information process. In this paper, we propose a real time internet cross-media retrieval method based on deep learning. As an innovation, we have made full improvement in feature extracting and distance detection. After getting a large amount of image feature vectors, we sort the elements in the vector according to their contribution and then eliminate unnecessary features. Experiments show that our method can achieve high precision in image-text cross media retrieval, using less retrieval time. This method has a great application space in the field of cross media retrieval. "} 
}
@article{Kolassa2017202,
title = {"Soil moisture retrieval from AMSR-E and \{ASCAT\} microwave observation synergy. Part 2: Product evaluation "},
journal = {"Remote Sensing of Environment "},
volume = {"195"},
number = {""},
pages = {"202 - 217"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.04.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717301694"},
author = {"J. Kolassa and P. Gentine and C. Prigent and F. Aires and S.H. Alemohammad"},
keywords = {"Satellite retrieval", "Soil moisture", "Surface hydrology", "Active/passive microwave", "Sensor synergy "},
abstract = {"Abstract A neural network (NN) soil moisture retrieval product computed from the synergy of AMSR-E brightness temperature and \{ASCAT\} backscatter observations is evaluated against in situ soil moisture observations from the International Soil Moisture Network (ISMN). The skill of the \{NN\} retrieval is compared to that of the ESA-CCI soil moisture retrieval as well as modeled soil moisture fields from ERA-interim/land. The \{NN\} retrieval is able to capture the observed soil moisture temporal variations with a station-average correlation and anomaly correlation of 0.45 and 0.35, respectively. For most ground stations the model obtained a higher temporal correlation skill, with average correlation and anomaly correlation values of 0.53 and 0.46, respectively. For stations in data-sparse regions, the \{NN\} retrieval showed a slightly better performance than the model, illustrating the potential of soil moisture retrievals to inform models in data-sparse areas. A time series analysis further showed that the retrieval is well able to capture soil moisture variability outside of active precipitation phases, such as the soil moisture behavior during the dry down phase. Compared to the ESA-CCI retrieval, the \{NN\} methodology obtained higher correlations, as a result of its ability to use the complementary information provided by the active and passive microwave sensors. A global evaluation of the retrieval errors through a triple collocation analysis with \{SMOS\} and \{GLDAS\} soil moisture estimates showed that the errors are high in energy limited regions, where the \{NN\} retrieval appears to be lacking input information. In the data-sparse regions of Africa and South America, the triple collocation analysis confirmed the higher skill of the \{NN\} retrieval compared to the model. "} 
}
@article{Tamine2017332,
title = {"On the impact of domain expertise on query formulation, relevance assessment and retrieval performance in clinical settings "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"2"},
pages = {"332 - 350"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645731630303X"},
author = {"Lynda Tamine and Cecile Chouquet"},
keywords = {"Medical information retrieval", "Domain expertise", "Query formulations Relevance assessment", "Retrieval performance "},
abstract = {"Abstract The large volumes of medical information available on the web may provide answers for a wide range of users attempting to solve health-related problems. While experts generally utilize reliable resources for diagnosis search and professional development, novices utilize different (social) web resources to obtain information that helps them manage their health or the health of people who they care for. A diverse number of related search topics address clinical diagnosis, advice searching, information sharing, connecting with experts, etc. This paper focuses on the extent to which expertise can impact clinical query formulation, document relevance assessment and retrieval performance in the context of tailoring retrieval models and systems to experts vs. non-experts. The results show that medical domain expertise 1) plays an important role in the lexical representations of information needs; 2) significantly influences the perception of relevance even among users with similar levels of expertise and 3) reinforces the idea that a single ground truth does not exist, thereby leading to the variability of system rankings with respect to the level of user’s expertise. The findings of this study presents opportunities for the design of personalized health-related \{IR\} systems, but also for providing insights about the evaluation of such systems. "} 
}
@article{Endres201713,
title = {"Enhancing learning by retrieval: Enriching free recall with elaborative prompting "},
journal = {"Learning and Instruction "},
volume = {"49"},
number = {""},
pages = {"13 - 20"},
year = {"2017"},
note = {""},
issn = {"0959-4752"},
doi = {"https://doi.org/10.1016/j.learninstruc.2016.11.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0959475216302547"},
author = {"Tino Endres and Shana Carpenter and Alf Martin and Alexander Renkl"},
keywords = {"Learning by retrieval", "Retrieval practice", "Elaborative retrieval", "Learning journals", "Learning strategies", "Testing effect "},
abstract = {"Abstract It is well-established in memory research that retrieval fosters learning. When applying this effect in education, it is an important question which type of retrieval task works best. Several studies have shown that learning is enhanced by linking new information with prior knowledge. A potential approach to making retrieval more effective, therefore, is to enrich retrieval instructions with the requirement to elaborate on the learning contents and link them to what is already known. In this study, we compared a free recall condition, as used in many studies on learning by retrieval, with a prompted recall condition in which learners were required to recall the information and apply it to their lives. Fifty-six undergraduate students were randomly assigned to one of these two conditions. They learned from a video-recorded lecture. One week later, learning outcomes were assessed by a posttest measuring fact recall and comprehension of the contents from the video lecture. Learners in the prompted recall group, compared to the free recall group, used more elaborative strategies in response to the recall task and achieved better comprehension scores. The effect on comprehension was mediated by the use of elaborative strategies. This pattern of results supports the constructive retrieval hypothesis, stating that retrieval is most effective when it involves constructive elaboration of the contents being learned. Our findings also encourage the use of pedagogical tasks in classroom teaching that combine elaboration and retrieval. "} 
}
@article{Roelle2017142,
title = {"Effects of incorporating retrieval into learning tasks: The complexity of the tasks matters "},
journal = {"Learning and Instruction "},
volume = {"49"},
number = {""},
pages = {"142 - 156"},
year = {"2017"},
note = {""},
issn = {"0959-4752"},
doi = {"https://doi.org/10.1016/j.learninstruc.2017.01.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0959475217300622"},
author = {"Julian Roelle and Kirsten Berthold"},
keywords = {"Retrieval-based learning", "Retrieval practice", "Adjunct questions", "Expository texts "},
abstract = {"Abstract In an experiment with N = 192 university students, we examined whether the effects of incorporating retrieval into learning tasks depend on the learning tasks' complexity. The learning tasks consisted of adjunct questions that were provided together with expository texts relating to the domain of chemistry. We varied (a) whether the adjunct questions required the learners to summarize (low complexity) or generate inferences on the basis of provided information (high complexity) and (b) whether the adjunct questions were implemented in a closed-book style that required learners to engage in retrieval or in an open-book style that did not require learners to engage in retrieval while responding to the questions. Afterwards, all learners took either an immediate or a delayed criterion test. We found that the effect of incorporating retrieval depended on the complexity of the adjunct questions; the net benefit of incorporating retrieval was higher for the low complexity ones. "} 
}
@article{Gupta20151223,
title = {"A new fuzzy logic based ranking function for efficient Information Retrieval system "},
journal = {"Expert Systems with Applications "},
volume = {"42"},
number = {"3"},
pages = {"1223 - 1234"},
year = {"2015"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2014.09.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S095741741400548X"},
author = {"Yogesh Gupta and Ashish Saini and A.K. Saxena"},
keywords = {"Information Retrieval", "Fuzzy Logic Controller", "Precision", "Recall", "Ranking function "},
abstract = {"Abstract The relevant documents from large data sets are retrieved with the help of ranking function in Information Retrieval system. In this paper, a new fuzzy logic based ranking function is proposed and implemented to enhance the performance of Information Retrieval system. The proposed ranking function is based on the computation of different terms of term-weighting schema such as term frequency, inverse document frequency and normalization. Fuzzy logic is used at two levels to compute relevance score of a document with respect to the query in present work. All the experiments are performed on \{CACM\} and \{CISI\} benchmark data sets. The experimental results reveal that the performance of our proposed ranking function is much better than the fuzzy based ranking function developed by Rubens along with other widely used ranking function Okapi-BM25 in terms of precision, recall and F-measure. "} 
}
@article{Chithra2015381,
title = {"Music Information Retrieval for Polyphonic Signals Using Hidden Markov Model "},
journal = {"Procedia Computer Science "},
volume = {"46"},
number = {""},
pages = {"381 - 387"},
year = {"2015"},
note = {"Proceedings of the International Conference on Information and Communication Technologies, \{ICICT\} 2014, 3-5 December 2014 at Bolgatty Palace &amp; Island Resort, Kochi, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.02.034"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915000988"},
author = {"S. Chithra and M.S. Sinith and A. Gayathri"},
keywords = {"Hidden Markov Model", "Music Information Retrieval. "},
abstract = {"Abstract Now-a-days, almost all music can be easily accessed via the Internet, but at the same time music can be hard to find. This has created the demand for intelligent music retrieval which allows the user to access the songs that he or she likes. The idea of music information retrieval is basically used in music search systems. In a music search system there will be a huge database of songs. For an efficient music search system, when a particular song in the database is requested, the song has to be correctly identified and retrieved from the database. Music information retrieval for polyphonic music is presented here. "} 
}
@article{Yu2017235,
title = {"Exploiting the complementary strengths of multi-layer \{CNN\} features for image retrieval "},
journal = {"Neurocomputing "},
volume = {"237"},
number = {""},
pages = {"235 - 241"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216314734"},
author = {"Wei Yu and Kuiyuan Yang and Hongxun Yao and Xiaoshuai Sun and Pengfei Xu"},
keywords = {"Image retrieval", "CNN", "Multi-level features "},
abstract = {"Abstract Deep convolutional neural networks have demonstrated breakthrough accuracies for image classification. A series of feature extractors learned from \{CNN\} have been used in other computer vision tasks. However, \{CNN\} features of different layers aim to encode different-level information. High-layer features care more about semantic information but less detail information, while low-layer features contain more detail information but suffer from the problem of background clutter and semantic ambiguity. We propose to exploit complementary strengths of different layers in a simple but effective way. A mapping function is designed to highlight the effectiveness of low-layer similarity, when measuring fine-grained similarity between query image and its nearest neighbors with similar semantic. Extensive experiments show that our method can achieve competitive performance on popular retrieval benchmarks. Extensive experiments show that the proposed method outperforms the features extracted from single layers and their direct concatenations. Meanwhile, our method achieves competitive performance on popular retrieval benchmarks. "} 
}
@article{Remi2015676,
title = {"Domain Ontology Driven Fuzzy Semantic Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"46"},
number = {""},
pages = {"676 - 681"},
year = {"2015"},
note = {"Proceedings of the International Conference on Information and Communication Technologies, \{ICICT\} 2014, 3-5 December 2014 at Bolgatty Palace &amp; Island Resort, Kochi, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.02.122"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915001866"},
author = {"S. Remi and S.C. Varghese"},
keywords = {"Domain Ontology", "Fuzzy Search", "Information Retrieval", "Semantic Query Processing", "Semantic Web "},
abstract = {"Abstract With the exponential growth in web content, the answers provided by traditional search engines by query specific keywords to content has resulted in markedly high recall and low precision. Semantic information retrieval can enhance the relevancy of search results by understanding search intention and the contextual meaning of terms as they are entered by the user. In this paper, a novel method for supporting semantic information retrieval is proposed by building a domain specific ontology. A prototype of a fuzzy semantic search engine is developed and the results are compared with that of a traditional search engine. "} 
}
@article{Islam2017102,
title = {"Content-based image retrieval based on multiple extended fuzzy-rough framework "},
journal = {"Applied Soft Computing "},
volume = {"57"},
number = {""},
pages = {"102 - 117"},
year = {"2017"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2017.03.036"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494617301606"},
author = {"Sk Mazharul Islam and Minakshi Banerjee and Siddhartha Bhattacharyya and Susanta Chakraborty"},
keywords = {"Fuzzy-rough set", "Feature selection", "Upper approximation", "Content-based image retrieval", "MPEG-7 image descriptors "},
abstract = {"Abstract This paper presents a content-based image retrieval (CBIR) system with applications in one general purpose and two face image databases using two MPEG-7 image descriptors. The proposed method uses several sophisticated fuzzy-rough feature selection methods and combines the results of these methods to obtain a prominent feature subset for image representation for a particular query. Next, fuzzy-rough upper approximation of the target set (relevant list of images) with respect to the entire database that is represented by the prominent feature subset, is computed for retrieval and ranking. The information table on which every feature selection method works is small in size. Main reasons of performance boost of the proposed method are twofold. One is efficient feature subsets selection. The other reason is the fuzzy-indiscernibility relation based fuzzy-rough framework for computing upper-approximation which supports the approximate equality or similarity sense of CBIR. Fuzzy-rough upper approximation possibly adds more similar images in the relevant list from boundary region to expand the relevant list. The effectiveness of the proposed method is supported by the comparative results obtained from several single dimensionality reduction method, several clustering based retrieval techniques and also tested for face image retrieval. "} 
}
@article{Huang2017255,
title = {"BHCR: \{RSVP\} target retrieval \{BCI\} framework coupling with \{CNN\} by a Bayesian method "},
journal = {"Neurocomputing "},
volume = {"238"},
number = {""},
pages = {"255 - 268"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.01.061"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217301698"},
author = {"Liangtao Huang and Yaqun Zhao and Ying Zeng and Zhimin Lin"},
keywords = {"Brain-computer interface (BCI)", "Electroencephalogram (EEG)", "Rapid serial visual presentation (RSVP)", "Target image retrieval", "Convolutional neural network (CNN)", "Bayesian brain-computer interaction, "},
abstract = {"Abstract To combine the complementary strengths of human vision (HV) and computer vision (CV) in target image retrieval, we proposed a brain-computer interface framework, Bayesian HV-CV Retrieval (BHCR), which couples \{HV\} with \{CV\} by a Bayesian method to retrieve target images in rapid serial visual presentation (RSVP) sequences. To construct a well-suited electroencephalogram (EEG) decoding module for BHCR, we conducted a comparative inspection on the selection of classification algorithms, and adopted linear discriminant analysis and random forests as a feature extraction method and classification algorithm, respectively. We also introduced a \{CV\} system based on convolutional neural network (CNN) as a component of BHCR. A Bayesian brain-computer interaction (BBCI) module was carefully designed so that for each presented image, a Bayesian model that takes \{HV\} insight as prior information and \{CV\} insights as sample information is built up to present retrieval results. Unlike existing HV-CV coupled works that usually require extra manual labor, \{BHCR\} directly enhanced retrieval performance with the help of \{CV\} insights. As an auxiliary work and a natural extension of BHCR, we then proposed a probability propagation scheme that incorporates \{EEG\} decoding insights to improve the \{CV\} system and a one-shot image database retrieval scheme. We demonstrated the effectiveness of \{BHCR\} by extensive experiments and simulations on both the entire framework and its sub-components. The results showed the following: (1) The performance of \{BHCR\} was significantly better than the EEG-only mechanism in both receiver operating characteristic (ROC) and classification aspects; (2) The robustness of \{BHCR\} was ensured by its process flow and the steady performances of its sub-components. "} 
}
@article{Tang201762,
title = {"Zero-knowledge GPS-free data replication and retrieval scheme in mobile ad hoc networks using double-ruling and landmark-labeling techniques "},
journal = {"Computer Networks "},
volume = {"118"},
number = {""},
pages = {"62 - 77"},
year = {"2017"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2017.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128617300749"},
author = {"Yao-Jen Tang and Jian-Jhih Kuo and Ming-Jer Tsai"},
keywords = {"Data replication and retrieval", "Mobile ad hoc network", "GPS-free", "Double-ruling "},
abstract = {"Abstract Using the double-ruling technique, many data replication and retrieval schemes achieve low data retrieval latency. However, these schemes require Global Positioning System (GPS) in mobile ad hoc networks (MANETs). In this paper, we propose a zero-knowledge double-ruling-based GPS-free data replication and retrieval scheme (MobiMark) in MANETs. Our primary idea is to label the landmarks with the grid-like structure in the network using the landmark-labeling, dynamically designate the node that is the nearest to a landmark as the landmark broker, and transmit the consumers’ interests (or producers’ data) to all horizontal (or vertical) landmark brokers using the double-ruling technique. Simulations show that MobiMark achieves good performance in terms of data retrieval rate and data retrieval latency. In addition, we also develop a theoretical analysis for MobiMark to obtain the upper bound of the hop distance between the consumer and the landmark broker with the consumer’s interest in a square region where the nodes are uniformly and densely distributed and have equal transmission ranges. "} 
}
@article{Chifu201516,
title = {"Word sense discrimination in information retrieval: A spectral clustering-based approach "},
journal = {"Information Processing & Management "},
volume = {"51"},
number = {"2"},
pages = {"16 - 31"},
year = {"2015"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2014.10.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457314001046"},
author = {"Adrian-Gabriel Chifu and Florentina Hristea and Josiane Mothe and Marius Popescu"},
keywords = {"Information retrieval", "Word sense disambiguation", "Word sense discrimination", "Spectral clustering", "High precision "},
abstract = {"Abstract Word sense ambiguity has been identified as a cause of poor precision in information retrieval (IR) systems. Word sense disambiguation and discrimination methods have been defined to help systems choose which documents should be retrieved in relation to an ambiguous query. However, the only approaches that show a genuine benefit for word sense discrimination or disambiguation in \{IR\} are generally supervised ones. In this paper we propose a new unsupervised method that uses word sense discrimination in IR. The method we develop is based on spectral clustering and reorders an initially retrieved document list by boosting documents that are semantically similar to the target query. For several \{TREC\} ad hoc collections we show that our method is useful in the case of queries which contain ambiguous terms. We are interested in improving the level of precision after 5, 10 and 30 retrieved documents (P$5, P$10, P$30) respectively. We show that precision can be improved by 8% above current state-of-the-art baselines. We also focus on poor performing queries. "} 
}
@article{Balasubramaniam2015135,
title = {"Hybrid Fuzzy-ontology Design Using \{FCA\} Based Clustering for Information Retrieval in Semantic Web "},
journal = {"Procedia Computer Science "},
volume = {"50"},
number = {""},
pages = {"135 - 142"},
year = {"2015"},
note = {"Big Data, Cloud and Computing Challenges "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.075"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915005761"},
author = {"K. Balasubramaniam"},
keywords = {"Fuzzy Ontology Generation framework (FOGA)", "Keyword Matching", "Semantic Web", "Hybrid \{FOGA\} with keyword", "Information Retrieval Method. "},
abstract = {"Abstract Ontology is a way to represent the domain knowledge into a human understandable and machine readable format. It is used as one of the major knowledge representation mechanism for semantic web. Introducing the ontology knowledge provides more relevant search results for the users information need. To deal with uncertain information, the mechanism supported by the regular ontology may not be adequate and the requirement for new technique arises. Fuzzy based methods are the proven methods to interpret the uncertain information. The combination of Fuzzy and Ontology based information retrieval provides better results as they mainly deal with the semantics and the uncertainty of information. Keyword matching is one another widely used method which matches the input keywords with the existing information domain to find the best match results. When the input queries are complex the fuzzy ontology based information retrieval which respects the user's keyword and the domain produces more accurate results. This work enlarges the fuzzy ontology knowledge results along with the input queries and keyword matching. The given algorithm is a hybrid technique based on matching extracted instances from the input queries and in information domain. Overall, compared to the existing query models supported by fuzzy ontology or keyword based models the hybrid ontology with keyword matching is sufficient and easy way to retrieve the documents in semantic web. The performance of the hybrid ontology approach is measured using improved precision, recall and f-measure values. "} 
}
@article{Shi2017130,
title = {"Synergy of \{MODIS\} and \{AATSR\} for better retrieval of aerosol optical depth and land surface directional reflectance "},
journal = {"Remote Sensing of Environment "},
volume = {"195"},
number = {""},
pages = {"130 - 141"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.04.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717301608"},
author = {"Shuaiyi Shi and Tianhai Cheng and Xingfa Gu and Hao Chen and Hong Guo and Ying Wang and Fangwen Bao and Binren Xu and Wannan Wang and Xin Zuo and Can Meng and Xiaochuan Zhang"},
keywords = {"AATSR", "AOD", "BRDF", "Individual swath retrieval", "Gradient optimization method", "Remote sensing "},
abstract = {"Abstract This paper presents a new algorithm to simultaneously retrieve Aerosol Optical Depth (AOD) and land surface Bidirectional Reflectance Distribution Function (BRDF) from Advanced Along-Track Scanning Radiometer (AATSR) by adopting gradient optimization method. Different from traditional method the approach presented here can perform simultaneous retrieval from each individual \{AATSR\} swath rather than multiple days. A theoretical sensitivity study proves the proposed method is insensitive to the distortion of initial BRDF. The presented algorithm is tested on \{AATSR\} data around four different Aerosol Robotic Network (AERONET) sites representing various types of land surface. Compared with the four selected \{AERONET\} sites' \{AOD\} and BRDF-derived albedo from AERONET-based Surface Reflectance Validation Network (ASRVN) data in corresponding four \{AERONET\} sites, the presented algorithm proves considerable accuracy for various type of land surface with correlation of \{AOD\} ranging from 0.647 to 0.911 and correlation of BRDF-derived albedo ranging from 0.483 to 0.944. The intersensor comparison with Moderate Resolution Imaging Spectroradiometer (MODIS) 3 km \{AOD\} dark target product reveals high coverage rate of the presented method especially in bright surface or nonvegetation area and the correlation between the two sensors reaches up to 0.967. The improved estimation of \{BRDF\} from \{AATSR\} retrieval in \{AERONET\} Beijing site is compared with \{MODIS\} \{MCD43B1\} product. The relative differences in hemispherical albedo calculated from average \{BRDF\} shape function parameters between \{AATSR\} and \{MODIS\} product are 1.33%, 1.52%, 2.60% and 4.28% at 550 nm, 670 nm, 870 nm and 1600 nm respectively. "} 
}
@article{Ma2017148,
title = {"A new method of content based medical image retrieval and its applications to \{CT\} imaging sign retrieval "},
journal = {"Journal of Biomedical Informatics "},
volume = {"66"},
number = {""},
pages = {"148 - 158"},
year = {"2017"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2017.01.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046417300023"},
author = {"Ling Ma and Xiabi Liu and Yan Gao and Yanfeng Zhao and Xinming Zhao and Chunwu Zhou"},
keywords = {"Medical image retrieval", "Content-based image retrieval", "Lung \{CT\} images", "Semantic information", "Visual information", "Shortest path", "Common \{CT\} Imaging Signs of Lung Diseases (CISLs) "},
abstract = {"Abstract This paper proposes a new method of content based medical image retrieval through considering fused, context-sensitive similarity. Firstly, we fuse the semantic and visual similarities between the query image and each image in the database as their pairwise similarities. Then, we construct a weighted graph whose nodes represent the images and edges measure their pairwise similarities. By using the shortest path algorithm over the weighted graph, we obtain a new similarity measure, context-sensitive similarity measure, between the query image and each database image to complete the retrieval process. Actually, we use the fused pairwise similarity to narrow down the semantic gap for obtaining a more accurate pairwise similarity measure, and spread it on the intrinsic data manifold to achieve the context-sensitive similarity for a better retrieval performance. The proposed method has been evaluated on the retrieval of the Common \{CT\} Imaging Signs of Lung Diseases (CISLs) and achieved not only better retrieval results but also the satisfactory computation efficiency. "} 
}
@article{Zhang2017399,
title = {"\{SIFT\} Matching with \{CNN\} Evidences for Particular Object Retrieval "},
journal = {"Neurocomputing "},
volume = {"238"},
number = {""},
pages = {"399 - 409"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.01.081"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217302680"},
author = {"Guixuan Zhang and Zhi Zeng and Shuwu Zhang and Yuan Zhang and Wanchun Wu"},
keywords = {"Particular object retrieval", "Bag-of-words", "SIFT matching", "Convolutional neural networks "},
abstract = {"Abstract Many object instance retrieval systems are typically based on matching of local features, such as SIFT. However, these local descriptors serve as low-level clues, which are not sufficiently distinctive to prevent false matches. Recently, deep convolutional neural networks (CNN) have shown their promise as a semantic-aware representation for many computer vision tasks. In this paper, we propose a novel approach to employ \{CNN\} evidences to improve the \{SIFT\} matching accuracy, which plays a critical role in improving the object retrieval performance. To weaken the interference of noise, we extract compact \{CNN\} representations from a number of generic object regions. Then a query-adaptive method is proposed to choose appropriate \{CNN\} evidence to verify each pre-matched \{SIFT\} pair. Two different visual matching verification functions are introduced and evaluated. Moreover, we investigate the suitability of fine-tuning the \{CNN\} for our proposed approach. Extensive experiments on benchmark datasets demonstrate the effectiveness of our method for particular object retrieval. Our results compare favorably to the state-of-the-art methods with acceptable memory usage and query time. "} 
}
@article{Vishwakarma2015815,
title = {"Monolingual Information Retrieval using Terrier: \{FIRE\} 2010 Experiments Based on N-gram Indexing "},
journal = {"Procedia Computer Science "},
volume = {"57"},
number = {""},
pages = {"815 - 820"},
year = {"2015"},
note = {"3rd International Conference on Recent Trends in Computing 2015 (ICRTC-2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.07.484"},
url = {"http://www.sciencedirect.com/science/article/pii/S187705091502013X"},
author = {"Santosh K. Vishwakarma and Kamaljit I. Lakhtaria and Divya Bhatnagar and Akhilesh K. Sharma"},
keywords = {"Information Retrieval", "N-gram", "MAP", "Pruning", "Hindi Monolingual "},
abstract = {"Abstract N-gram based indexing technique has been proved as a useful technique for efficient document retrieval. We applied the n-gram approach and performed experiments in Hindi language text collections. The experiments are performed on the dataset of \{FIRE\} 2010 Hindi text collections. We used the Terrier open search engine for experimental purpose. Our experiments state that 4-gram gives the best results among all n-grams of different length. The results show an increase in value of mean average precision. "} 
}
@article{Li20177,
title = {"Secret shared multiple-image encryption based on row scanning compressive ghost imaging and phase retrieval in the Fresnel domain "},
journal = {"Optics and Lasers in Engineering "},
volume = {"96"},
number = {""},
pages = {"7 - 16"},
year = {"2017"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2017.04.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816617300052"},
author = {"Xianye Li and Xiangfeng Meng and Yurong Wang and Xiulun Yang and Yongkai Yin and Xiang Peng and Wenqi He and Guoyan Dong and Hongyi Chen"},
keywords = {"Compressive ghost imaging", "Phase retrieval", "Threshold secret sharing "},
abstract = {"Abstract A multiple-image encryption method is proposed that is based on row scanning compressive ghost imaging, (t, n) threshold secret sharing, and phase retrieval in the Fresnel domain. In the encryption process, after wavelet transform and Arnold transform of the target image, the ciphertext matrix can be first detected using a bucket detector. Based on a (t, n) threshold secret sharing algorithm, the measurement key used in the row scanning compressive ghost imaging can be decomposed and shared into two pairs of sub-keys, which are then reconstructed using two phase-only mask (POM) keys with fixed pixel values, placed in the input plane and transform plane 2 of the phase retrieval scheme, respectively; and the other \{POM\} key in the transform plane 1 can be generated and updated by the iterative encoding of each plaintext image. In each iteration, the target image acts as the input amplitude constraint in the input plane. During decryption, each plaintext image possessing all the correct keys can be successfully decrypted by measurement key regeneration, compression algorithm reconstruction, inverse wavelet transformation, and Fresnel transformation. Theoretical analysis and numerical simulations both verify the feasibility of the proposed method. "} 
}
@article{Zhang2017154,
title = {"Image retrieval using the extended salient region "},
journal = {"Information Sciences "},
volume = {"399"},
number = {""},
pages = {"154 - 182"},
year = {"2017"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2017.03.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025517305790"},
author = {"Jing Zhang and Shengwei Feng and Da Li and Yongwei Gao and Zhihua Chen and Yubo Yuan"},
keywords = {"Extended salient region", "Region matching", "MLAP", "Image retrieval", "Image processing "},
abstract = {"Abstract The salient region is the most important part of an image. The salient portion in images also attracts the most attention when people search for images in large-scale datasets. However, to improve image retrieval accuracy, considering only the most salient object in an image is insufficient because the background also influences the accuracy of image retrieval. To address this issue, this paper proposes a novel concept called the extended salient region (ESR). First, the salient region of an input image is detected using a Region Contrast (RC) algorithm. Then, a polar coordinate system is constructed; the centroid of the salient region is set as the pole. Next, the regions surrounding the salient region are determined by the neighboring regions, moving in a counterclockwise direction. The resulting combination of the salient region and its surrounding regions is defined as the ESR. We extract the visual content from the \{ESR\} using the well-known Bag of Words (BoW) model based on Gabor, \{SIFT\} and \{HSVH\} features and propose a graph model of the visual content nodes to represent the input image. Then, we design a novel algorithm to perform matching between two images. We also define a new similarity measure by combining the similarities of the salient region and the surrounding regions using weights. Finally, to better evaluate the image retrieval accuracy, an improved measure called the mean label average precision (MLAP) is proposed. The results of experiments on three benchmark datasets (Corel, \{TU\} Darmstadt, and Caltech 101) demonstrate that our proposed \{ESR\} model and region-matching algorithm are highly effective at image retrieval, and can achieve more accurate query results than current state-of-the-art methods. "} 
}
@article{Celik20171,
title = {"Content based image retrieval with sparse representations and local feature descriptors : A comparative study "},
journal = {"Pattern Recognition "},
volume = {"68"},
number = {""},
pages = {"1 - 13"},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2017.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320317301048"},
author = {"Ceyhun Celik and Hasan Sakir Bilge"},
keywords = {"Content based image retrieval", "Local feature descriptor", "Sparse representation", "Dictionary learning", "Coefficient learning "},
abstract = {"Abstract Content Based Image Retrieval (CBIR) has been widely studied in the last two decades. Unlike text based image retrieval techniques, visual properties of images are used to obtain high level semantic information in CBIR. There is a gap between low level features and high level semantic information. This is called semantic gap and it is the most important problem in CBIR. The visual properties were extracted from low level features such as color, shape, texture and spatial information in early days. Local Feature Descriptors (LFDs) are more successful to increase performance of \{CBIR\} system. Then, a semantic bridge is built with high level semantic information. Sparse Representations (SRs) have become popular to achieve this aim in the last years. In this study, \{CBIR\} models that use \{LFDs\} and \{SRs\} in literature are investigated in detail. The \{SRs\} and \{LFD\} extraction algorithms are tested and compared within a \{CBIR\} framework for different scenarios. Scale Invariant Feature Transform (SIFT), Speeded-Up Robust Features (SURF), Histograms of Oriented Gradients (HoG), Local Binary Pattern (LBP) and Local Ternary Pattern (LTP) are used to extract \{LFDs\} from images. Random Features, K-Means and K-Singular Value Decomposition (K-SVD) algorithms are used for dictionary learning and Orthogonal Matching Pursuit (OMP), Homotopy, Lasso, Elastic Net, Parallel Coordinate Descent (PCD) and Separable Surrogate Function (SSF) are used for coefficient learning. Finally, three methods recently proposed in literature (Online Dictionary Learning (ODL), Locality-constrained Linear Coding (LLC) and Feature-based Sparse Representation (FBSR)) are also tested and compared with our framework results. All test results are presented and discussed. As a conclusion, the most successful approach in our framework is to use \{LLC\} for Coil20 data set and \{FBSR\} for Corel1000 data set. We obtain 89% and 58% Mean Average Precision (MAP) for Coil20 and Corel1000, respectively. "} 
}
@article{Glavaš20146904,
title = {"Event graphs for information retrieval and multi-document summarization "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"15"},
pages = {"6904 - 6916"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2014.04.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417414001985"},
author = {"Goran Glavaš and Jan Šnajder"},
keywords = {"Event extraction", "Information extraction", "Information retrieval", "Multi-document summarization", "Natural language processing "},
abstract = {"Abstract With the number of documents describing real-world events and event-oriented information needs rapidly growing on a daily basis, the need for efficient retrieval and concise presentation of event-related information is becoming apparent. Nonetheless, the majority of information retrieval and text summarization methods rely on shallow document representations that do not account for the semantics of events. In this article, we present event graphs, a novel event-based document representation model that filters and structures the information about events described in text. To construct the event graphs, we combine machine learning and rule-based models to extract sentence-level event mentions and determine the temporal relations between them. Building on event graphs, we present novel models for information retrieval and multi-document summarization. The information retrieval model measures the similarity between queries and documents by computing graph kernels over event graphs. The extractive multi-document summarization model selects sentences based on the relevance of the individual event mentions and the temporal structure of events. Experimental evaluation shows that our retrieval model significantly outperforms well-established retrieval models on event-oriented test collections, while the summarization model outperforms competitive models from shared multi-document summarization tasks. "} 
}
@article{Zhao2017166,
title = {"Spatial pyramid deep hashing for large-scale image retrieval "},
journal = {"Neurocomputing "},
volume = {"243"},
number = {""},
pages = {"166 - 173"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.03.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217305167"},
author = {"Wanqing Zhao and Hangzai Luo and Jinye Peng and Jianping Fan"},
keywords = {"Image retrieval", "Hashing learning", "Convolutional neural networks", "Spatial pyramid structure "},
abstract = {"Abstract Effective feature representations and similarity measurements are crucial for large-scale image retrieval, and conventional methods often learn hash functions from a predefined hand-crafted feature space. Meanwhile, the spatial structure in raw images always lost in most previous methods. Encouraged by the recent advances in convolutional neural networks (CNNs), a novel Spatial Pyramid Deep Hashing (SPDH) algorithm is developed for the task of fast image retrieval. In our \{SPDH\} algorithm, the \{CNN\} with a spatial pyramid pooling and a locally-connected layer with binary activation functions is utilized to build the end-to-end relation between the raw image data and the binary hashing codes for fast indexing. Different from the fully-connected layer, the locally-connected layer can consider each local spatial bin as an independent unit and only connect the local bin to preserve the spatial pyramid structure for hash codes. The learning of both the hash function and the feature representations are jointly optimized via backward propagation with classification or similarity loss function on the large-scale labeled dataset such as ImageNet. Moreover, a spatial pyramid binary pattern matching algorithm is developed to achieve partial local similar matching among the images. Our experimental results have shown that our \{SPDH\} method can outperform several state-of-the-art hashing algorithms on the CIFAR-10, \{SIVAL\} and the Oxford buildings datasets. "} 
}
@article{Tempel2017143,
title = {"Retrieval-induced forgetting is retrieval-modality specific: Evidence from motor memory "},
journal = {"Cognition "},
volume = {"162"},
number = {""},
pages = {"143 - 152"},
year = {"2017"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2017.02.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010027717300379"},
author = {"Tobias Tempel and Christian Frings"},
keywords = {"Motor memory", "Body movement", "Retrieval-induced forgetting", "Inhibition "},
abstract = {"Abstract Three experiments examined the impact of matching retrieval modality at retrieval practice and at test on retrieval-induced forgetting. Participants learned sequential finger movements to be performed either with the left or with the right index finger. Subsequently, they selectively practiced half the items of one hand. A final recall test then assessed memory for all initially learned items. We contrasted different retrieval modalities. In Experiment 1, retrieval practice pertained to motor responses in one experimental condition but it pertained to visual sequence displays in another condition. The final recall test was motoric in both conditions. In Experiment 2, retrieval practice always pertained to visual sequence displays but the final recall test either pertained to motor responses or to visual sequence displays. Retrieval-induced forgetting emerged only when the modality of the final recall test matched the modality of retrieval practice. In Experiment 3, retrieval practice either involved executing motor sequences with the same finger as in the learning phase or participants had to use the opposite hand for indicating sequences. An effector change for retrieval practice eliminated retrieval-induced forgetting in a test requiring the execution of motor sequences again with the same finger as in the learning phase. We suggest that retrieval-induced forgetting occurred as a consequence of retrieval-modality-specific inhibition. "} 
}
@article{Thangaraj20148225,
title = {"An architectural design for effective information retrieval in semantic web "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"18"},
pages = {"8225 - 8233"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2014.07.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417414004151"},
author = {"M. Thangaraj and G. Sujatha"},
keywords = {"Information retrieval", "Semantic web", "Semantic search", "Ontology", "Semantic query "},
abstract = {"Abstract The current web \{IR\} system retrieves relevant information only based on the keywords which is inadequate for that vast amount of data. It provides limited capabilities to capture the concepts of the user needs and the relation between the keywords. These limitations lead to the idea of the user conceptual search which includes concepts and meanings. This study deals with the Semantic Based Information Retrieval System for a semantic web search and presented with an improved algorithm to retrieve the information in a more efficient way. This architecture takes as input a list of plain keywords provided by the user and the query is converted into semantic query. This conversion is carried out with the help of the domain concepts of the pre-existing domain ontologies and a third party thesaurus and discover semantic relationship between them in runtime. The relevant information for the semantic query is retrieved and ranked according to the relevancy with the help of an improved algorithm. The performance analysis shows that the proposed system can improve the accuracy and effectiveness for retrieving relevant web documents compared to the existing systems. "} 
}
@article{Fadaei2017274,
title = {"Local derivative radial patterns: A new texture descriptor for content-based image retrieval "},
journal = {"Signal Processing "},
volume = {"137"},
number = {""},
pages = {"274 - 286"},
year = {"2017"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2017.02.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168417300695"},
author = {"Sadegh Fadaei and Rassoul Amirfattahi and Mohammad Reza Ahmadzadeh"},
keywords = {"Content-based image retrieval (CBIR)", "Texture descriptor", "Local patterns", "Local derivative radial pattern (LDRP) "},
abstract = {"Abstract In this paper, we propose a novel local pattern descriptor called Local Derivative Radial Pattern (LDRP) for texture representation in content-based image retrieval. All prior local patterns are based on gray-level difference of pixels located in a square or circle. Since many of the actual textures can be represented by intensity relationship of pixels along a line, these methods do not have a suitable ability to represent texture information. In prior methods, difference between referenced pixel and its adjacent pixel is encoded with two, three or four values which leads to information loss of the image. The proposed \{LDRP\} is based on gray-level difference of pixels along a line and their weighted combinations. In addition, multi-level coding in different directions is used instead of binary coding. The performance of the proposed method is compared with prior methods including local binary pattern (LBP), local ternary pattern (LTP), local derivative pattern (LDP), local tetra pattern (LTrP) and local vector pattern (LVP). The proposed \{LDRP\} outperforms all mentioned prior methods by at least 3.82% and 5.17% in terms of average precision on Brodatz and VisTex databases, respectively. "} 
}
@article{Zhang20141574,
title = {"A novel image retrieval method based on hybrid information descriptors "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"7"},
pages = {"1574 - 1587"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.06.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314001151"},
author = {"Ming Zhang and Ke Zhang and Qinghe Feng and Jianzhong Wang and Jun Kong and Yinghua Lu"},
keywords = {"Hybrid information descriptors (HIDs)", "Mutual information descriptors (MIDs)", "Self information descriptors (SIDs)", "Visual perception mechanism", "Image feature spaces", "Multi-scale analysis", "Content-based image retrieval (CBIR)", "Feature fusion "},
abstract = {"Abstract In this paper, we propose a novel image retrieval method called hybrid information descriptors (HIDs) consisting of mutual information descriptors (MIDs) and self information descriptors (SIDs). Based on the physiological structure of human eyes and visual perception mechanism, \{HIDs\} are designed to explore the internal correlations among different image feature spaces with image structure and multi-scale analysis, not only characterizing the low-level features, such as color, shape and texture, but also imitating the process of visual information transfer and perception in high-level understanding with the help of the proposed visual optimization model for feature fusion. Comparing with other existing methods applied to content-based image retrieval (CBIR) on four datasets, the usefulness and effectiveness of the \{HIDs\} are shown. Extensive experimental results can also demonstrate this. "} 
}
@article{Khwaileh2017140,
title = {"Lexical retrieval after Arabic aphasia: Syntactic access and predictors of spoken naming "},
journal = {"Journal of Neurolinguistics "},
volume = {"42"},
number = {""},
pages = {"140 - 155"},
year = {"2017"},
note = {""},
issn = {"0911-6044"},
doi = {"https://doi.org/10.1016/j.jneuroling.2017.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0911604416300781"},
author = {"Tariq Khwaileh and Richard Body and Ruth Herbert"},
keywords = {"Aphasia", "Anomia", "Arabic", "Lexical retrieval", "Syntax", "Word grammar", "Determiner", "Noun phrase", "Spoken production", "Picture naming", "Predictors", "Determinants", "Psycholinguistics", "Neurolinguistics "},
abstract = {"Abstract Research into anomia has been carried out in English and many Indo-European languages extensively, but not in Arabic. Previous studies have investigated predictors of successful lexical retrieval after anomia, and access to syntax during lexical retrieval. The aim of the current study is to examine impaired lexical retrieval in Arabic at two levels: predictors of lexical retrieval, and access to syntax during lexical retrieval, via checking whether syntactic cueing (using the definite article/əl-/'the' prior to nouns) facilitates noun retrieval in Arabic aphasia, with regard to naming speed and accuracy, and establishing the determinants of aphasic noun retrieval in Arabic. Three participants with anomia following \{CVA\} named 186 pictures from a published Arabic database in two conditions: bare noun condition, and determiner + noun condition. Participants' accuracy and reaction times were compared in both conditions. Furthermore, a multiple regression analysis was carried out to test the effect of psycholinguistic variables (visual complexity, name agreement, age of acquisition, imageability and other intrinsic variables) on successful lexical retrieval to determine predictors of Arabic noun retrieval after anomia. The production of the determiner + noun in picture naming facilitated spoken naming in all three participants. Nouns produced with the determiner were produced faster and more accurately than their counterparts produced without the determiner. The two participants with agrammatism produced morpho-syntactic errors in the bare noun condition, but not in the determiner + noun condition, suggesting that the determiner sets up a noun phrase frame with a slot for the noun to be filled, resulting in responses that are faster and more accurate. Age of acquisition and imageability were the only two variables that had influence across the participants. These results have theoretical and clinical implications for lexical retrieval models. "} 
}
@article{Gómez2017,
title = {"Information retrieval from interval-valued fuzzy automata through Kα operators "},
journal = {"Fuzzy Sets and Systems "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0165-0114"},
doi = {"https://doi.org/10.1016/j.fss.2017.03.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165011417301379"},
author = {"M. Gómez and I. Lizasoain and C. Moreno"},
keywords = {"Interval-valued fuzzy sets", "Fuzzy finite state machines", "Fuzzy finite transition systems", "Atanassov's K α operators", "Fuzzy transformation semigroups "},
abstract = {"Abstract In this paper, fuzzy finite transition systems and fuzzy transformation semigroups are analyzed when the truth structure is the set of all the closed real subintervals contained in [ 0 , 1 ] . Our approach involves the application of interval-valued fuzzy sets techniques in order to retrieve the information given by the transition functions of the considered automata. In particular, a characterization of those Atanassov's K α operators which provide a fuzzy transformation semigroup starting from an interval-valued fuzzy automaton is achieved. Conversely, different ways of getting an interval-valued fuzzy transformation semigroup starting from two real fuzzy automata are compared. "} 
}
@article{Smeaton2014118,
title = {"Multimedia information retrieval and environmental monitoring: Shared perspectives on data fusion "},
journal = {"Ecological Informatics "},
volume = {"23"},
number = {""},
pages = {"118 - 125"},
year = {"2014"},
note = {"Special Issue on Multimedia in Ecology and Environment "},
issn = {"1574-9541"},
doi = {"https://doi.org/10.1016/j.ecoinf.2013.10.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574954113000988"},
author = {"Alan F. Smeaton and Edel O'Connor and Fiona Regan"},
keywords = {"Sensor data fusion", "Multimedia information retrieval", "Trust and reputation framework", "Environmental monitoring "},
abstract = {"Abstract Computer-based remote monitoring of our environment is increasingly based on combining data derived from in-situ-sensors with data derived from remote sources, such as satellite images or CCTV. In such deployments it is necessary to continuously monitor the accuracy of each of the sensor data streams so that we can account for sudden failures of sensors, or errors due to calibration drive or biofouling. In multimedia information retrieval (MMIR), we search through archives of multimedia artefacts like video programs, by implementing several independent retrieval systems or agents, and we combine the outputs of each retrieval agent in order to generate an overall ranking. In this paper we draw parallels between these seemingly very different applications and show how they share several similarities. In the case of environmental monitoring we also need some mechanism by which we can establish the trust and reputation of each contributing sensor, though this is something we do not need in MMIR. In this paper we present an outline of a trust and reputation framework we have developed and deployed for monitoring the performance of sensors in a heterogeneous sensor network. "} 
}
@article{Eder2014226,
title = {"Postdonation Information and Blood Component Retrievals: Realigning Blood Center and Hospital Actions Based on Risk Assessment "},
journal = {"Transfusion Medicine Reviews "},
volume = {"28"},
number = {"4"},
pages = {"226 - 234"},
year = {"2014"},
note = {""},
issn = {"0887-7963"},
doi = {"https://doi.org/10.1016/j.tmrv.2014.09.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0887796314000728"},
author = {"Anne F. Eder and Mindy Goldman"},
keywords = {"Postdonation information", "Recall", "Market withdrawal", "Retrieval "},
abstract = {"Abstract Blood centers often receive information from individuals after blood donation that should have resulted in their deferral and may attempt to retrieve distributed blood components that did not meet all quality standards and regulations. Typically, the information is discovered or reported only after the components from the donation have been transfused. Blood centers may notify the transfusion service and provide a statement of the potential risk, if any, associated with the blood components, but the transfusion service must decide if further investigation, notification of the transfusing physician, or counseling of the patient is warranted. Currently, postdonation information (PDI) affects an estimated 1 in 600 donations in the United States. Despite the regularity with which \{PDI\} occurs, there has been little analysis of the main sources of PDI, associated transfusion risk, or the actual benefit of various actions taken as a result of PDI. However, blood centers attempt to retrieve thousands of components each year for PDI: actions that can cause confusion, concern, and complaints from hospitals and transfusion services. Postdonation information is largely a reflection of the inherent limitations of the current donor screening process, which is error-prone and uses broad, precautionary questions to guard against theoretical or extremely remote risks. This article reviews the most commonly reported \{PDI\} and available information on the possible risk associated with the transfused components from the involved donations, to formulate a framework for blood center retrieval actions and hospital notification that is consistent with current regulations and commensurate with the likelihood of adverse outcomes associated with the most commonly reported PDI. "} 
}
@article{Soulier2014752,
title = {"On domain expertise-based roles in collaborative information retrieval "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"5"},
pages = {"752 - 774"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2014.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457314000302"},
author = {"Laure Soulier and Lynda Tamine and Wahiba Bahsoun"},
keywords = {"Collaborative information retrieval", "Domain expertise", "Ranking model", "Learning-method "},
abstract = {"Abstract Collaborative information retrieval involves retrieval settings in which a group of users collaborates to satisfy the same underlying need. One core issue of collaborative \{IR\} models involves either supporting collaboration with adapted tools or developing \{IR\} models for a multiple-user context and providing a ranked list of documents adapted for each collaborator. In this paper, we introduce the first document-ranking model supporting collaboration between two users characterized by roles relying on different domain expertise levels. Specifically, we propose a two-step ranking model: we first compute a document-relevance score, taking into consideration domain expertise-based roles. We introduce specificity and novelty factors into language-model smoothing, and then we assign, via an Expectation–Maximization algorithm, documents to the best-suited collaborator. Our experiments employ a simulation-based framework of collaborative information retrieval and show the significant effectiveness of our model at different search levels. "} 
}
@article{Wang201714,
title = {"Separable vocabulary and feature fusion for image retrieval based on sparse representation "},
journal = {"Neurocomputing "},
volume = {"236"},
number = {""},
pages = {"14 - 22"},
year = {"2017"},
note = {"Good Practices in Multimedia Modeling "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.08.106"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216313807"},
author = {"Yanhong Wang and Yigang Cen and Ruizhen Zhao and Yi Cen and Shaohai Hu and Viacheslav Voronin and Hengyou Wang"},
keywords = {"Separable vocabulary", "Sparse representation", "Feature fusion", "Image retrieval "},
abstract = {"Abstract Visual vocabulary is the core of the Bag-of-visual-words (BOW) model in image retrieval. In order to ensure the retrieval accuracy, a large vocabulary is always used in traditional methods. However, a large vocabulary will lead to a low recall. In order to improve recall, vocabularies with medium sizes are proposed, but they will lead to a low accuracy. To address these two problems, we propose a new method for image retrieval based on feature fusion and sparse representation over separable vocabulary. Firstly, a large vocabulary is generated on the training dataset. Secondly, the vocabulary is separated into a number of vocabularies with medium sizes. Thirdly, for a given query image, we adopt sparse representation to select a vocabulary for retrieval. In the proposed method, the large vocabulary can guarantee a relatively high accuracy, while the vocabularies with medium sizes are responsible for high recall. Also, in order to reduce quantization error and improve recall, sparse representation scheme is used for visual words quantization. Moreover, both the local features and the global features are fused to improve the recall. Our proposed method is evaluated on two benchmark datasets, i.e., Coil20 and Holidays. Experiments show that our proposed method achieves good performance. "} 
}
@article{Huang2017123,
title = {"Cross-media retrieval by exploiting fine-grained correlation at entity level "},
journal = {"Neurocomputing "},
volume = {"236"},
number = {""},
pages = {"123 - 133"},
year = {"2017"},
note = {"Good Practices in Multimedia Modeling "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.07.067"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216313819"},
author = {"Lei Huang and Yuxin Peng"},
keywords = {"Cross-media retrieval", "Entity level", "Fine-grained correlation", "Distance-preserving entity projection "},
abstract = {"Abstract Cross-media retrieval is to submit data of any media type, and get semantically relevant results of different media types. Most existing approaches project low-level features of cross-media data onto a unified feature space. However, some of these feature spaces usually have no explicit semantics, which ignore the intrinsic semantic information contained in the original media content. The others only have coarse-grained semantics suffering from the ambiguity of high-level concepts, because the coarse-grained correlation between low-level features and high-level concepts is simply utilized. Hence, the aforementioned approaches cannot generate the descriptive representation of media content, leading to reduced effectiveness to measure the semantic similarities among cross-media data. To address the above problems, we propose a novel approach to cross-media retrieval by exploiting the fine-grained correlation at the entity level and generating the unified descriptive representation. Concretely, the proposed approach first constructs an entity level with fine-grained semantics between low-level features and high-level concepts. Second, by minimizing (maximizing) the distances between media content with positive (negative) correlation at the entity level, we learn the distance-preserving entity projections (DPEP) and generate the unified descriptive representation of media content. Experimental results on two publicly available datasets demonstrate the effectiveness of our approach. "} 
}
@article{Olmedo2017103,
title = {"Debiased non-Bayesian retrieval: A novel approach to \{SMOS\} Sea Surface Salinity "},
journal = {"Remote Sensing of Environment "},
volume = {"193"},
number = {""},
pages = {"103 - 126"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.02.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300822"},
author = {"Estrella Olmedo and Justino Martínez and Antonio Turiel and Joaquim Ballabrera-Poy and Marcos Portabella"},
keywords = {"Soil moisture and ocean salinity (SMOS)", "Sea Surface Salinity", "Salinity retrieval", "Remote sensing", "Physical oceanography "},
abstract = {"Abstract The Soil Moisture and Ocean Salinity (SMOS) mission has provided a unique remote sensing capability for observing key variables of the hydrological cycle, such as the Sea Surface Salinity (SSS). However, due to some limitations related to the instrument interferometric concept and its challenging data processing, \{SMOS\} \{SSS\} maps still display significant artifacts and biases, especially close to the coast, mainly due to the presence of Radio Frequency Interferences (RFI) and Land-sea contamination (LSC). In this paper, a new methodology for filtering salinity retrievals and correcting for spatial biases is introduced and validated. "} 
}
@article{Negm2017203,
title = {"PREFCA: A portal retrieval engine based on formal concept analysis "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"1"},
pages = {"203 - 222"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316303569"},
author = {"Eman Negm and Samir AbdelRahman and Reem Bahgat"},
keywords = {"Information retrieval", "Formal concept analysis", "Network analysis", "Portal retrieval "},
abstract = {"Abstract The web is a network of linked sites whereby each site either forms a physical portal or a standalone page. In the former case, the portal presents an access point to its embedded web pages that coherently present a specific topic. In the latter case, there are millions of standalone web pages, that are scattered throughout the web, having the same topic and could be conceptually linked together to form virtual portals. Search engines have been developed to help users in reaching the adequate pages in an efficient and effective manner. All the known current search engine techniques rely on the web page as the basic atomic search unit. They ignore the conceptual links, that reveal the implicit web related meanings, among the retrieved pages. However, building a semantic model for the whole portal may contain more semantic information than a model of scattered individual pages. In addition, user queries can be poor and contain imprecise terms that do not reflect the real user intention. Consequently, retrieving the standalone individual pages that are directly related to the query may not satisfy the user’s need. In this paper, we propose PREFCA, a Portal Retrieval Engine based on Formal Concept Analysis that relies on the portal as the main search unit. \{PREFCA\} consists of three phases: First, the information extraction phase that is concerned with extracting portal’s semantic data. Second, the formal concept analysis phase that utilizes formal concept analysis to discover the conceptual links among portal and attributes. Finally, the information retrieval phase where we propose a portal ranking method to retrieve ranked pairs of portals and embedded pages. Additionally, we apply the network analysis rules to output some portal characteristics. We evaluated \{PREFCA\} using two data sets, namely the Forum for Information Retrieval Evaluation 2010 and ClueWeb09 (category B) test data, for physical and virtual portals respectively. \{PREFCA\} proves higher F-measure accuracy, better Mean Average Precision ranking and comparable network analysis and efficiency results than other search engine approaches, namely Term Frequency Inverse Document Frequency (TF-IDF), Latent Semantic Analysis (LSA), and \{BM25\} techniques. As well, it gains high Mean Average Precision in comparison with learning to rank techniques. Moreover, \{PREFCA\} also gains better reach time than Carrot as a well-known topic-based search engine. "} 
}
@article{Angelini2014394,
title = {"VIRTUE: A visual tool for information retrieval performance evaluation and failure analysis "},
journal = {"Journal of Visual Languages & Computing "},
volume = {"25"},
number = {"4"},
pages = {"394 - 413"},
year = {"2014"},
note = {""},
issn = {"1045-926X"},
doi = {"https://doi.org/10.1016/j.jvlc.2013.12.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1045926X13001006"},
author = {"Marco Angelini and Nicola Ferro and Giuseppe Santucci and Gianmaria Silvello"},
keywords = {"Information retrieval", "Experimental evaluation", "Visual analytics", "Performance analysis", "Failure analysis "},
abstract = {"Abstract Objective: Information Retrieval (IR) is strongly rooted in experimentation where new and better ways to measure and interpret the behavior of a system are key to scientific advancement. This paper presents an innovative visualization environment: Visual Information Retrieval Tool for Upfront Evaluation (VIRTUE), which eases and makes more effective the experimental evaluation process. Methods: \{VIRTUE\} supports and improves performance analysis and failure analysis. Performance analysis: \{VIRTUE\} offers interactive visualizations based on well-known \{IR\} metrics allowing us to explore system performances and to easily grasp the main problems of the system. Failure analysis: \{VIRTUE\} develops visual features and interaction, allowing researchers and developers to easily spot critical regions of a ranking and grasp possible causes of a failure. Results: \{VIRTUE\} was validated through a user study involving \{IR\} experts. The study reports on (a) the scientific relevance and innovation and (b) the comprehensibility and efficacy of the visualizations. Conclusion: \{VIRTUE\} eases the interaction with experimental results, supports users in the evaluation process and reduces the user effort. Practice: \{VIRTUE\} will be used by \{IR\} analysts to analyze and understand experimental results. Implications: \{VIRTUE\} improves the state-of-the-art in the evaluation practice and integrates visualization and \{IR\} research fields in an innovative way. "} 
}
@article{JiménezNoblejas201415,
title = {"Recuperación y visualización de información en Web of Science y Scopus: una aproximación práctica "},
journal = {"Investigación Bibliotecológica: Archivonomía, Bibliotecología e Información "},
volume = {"28"},
number = {"64"},
pages = {"15 - 31"},
year = {"2014"},
note = {""},
issn = {"0187-358X"},
doi = {"https://doi.org/10.1016/S0187-358X(14)70907-4"},
url = {"http://www.sciencedirect.com/science/article/pii/S0187358X14709074"},
author = {"Cristina Jiménez Noblejas and Antonio Perianes Rodríguez"},
keywords = {"Web of Science", "Scopus", "Recuperación de Información", "Interfaces Gráficas de Usuario", "Web of Science", "Scopus", "Information Retrieval", "Graphical User Interfaces "},
abstract = {"Abstract The emergence of Scopus (Elsevier) in November 2004 marked a major shift in the international market of databases exerting pressure on the monopoly traditionally held by Web of Science (Thomson Reuters). This paper aims to carry out an analysis of the graphical interfaces of both products as a key factor in the process of information retrieval and visualization. The methodology entails the execution of a series of searches in order to understand the respective performances of Scopus and Web of Science when put through the paces of searching, locating and retrieving information. Although the two databases exhibit deficiencies, results show that Scopus more effectively meets informational requirements in the indexing process by author. "} 
}
@article{Ren201726,
title = {"Rapid three-dimensional scene modeling by sketch retrieval and auto-arrangement "},
journal = {"Computers & Graphics "},
volume = {"64"},
number = {""},
pages = {"26 - 36"},
year = {"2017"},
note = {"Cyberworlds 2016 "},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2017.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849317300183"},
author = {"Pu Ren and Yachun Fan and Mingquan Zhou and Zhe Wang and Guoguang Du and Lu Qian"},
keywords = {"Automatic layout", "Game development", "Simulated annealing", "Sketch-based retrieval", "Three-dimensional outdoor scene "},
abstract = {"Abstract The existing three-dimensional (3D) object layout methods are focused mainly on indoor scenes and they are limited for outdoor applications. In this study, we propose a data-driven method for outdoor scene modeling by using fast retrieval and automatic optimization layout techniques. Unlike the current methods, we first employ an improved manifold ranking algorithm in the sketch-based 3D model retrieval stage, which achieves higher accuracy. Next, according to the particular properties of outdoor architectures, specialized constraints are then proposed to define an energy function, which meets both the functional and aesthetic requirements. Finally, we cast the auto-arrangement as a combinatorial optimization problem, which we solve using an optimization algorithm. In contrast to the earlier version of this method, which was presented at Cyberworlds 2016, this extended version combines simulated annealing and particle swarm optimization algorithms, which have the advantages of rapid convergence and avoiding becoming trapped by local minima. Our experimental results demonstrate that the proposed method is more intuitive and effective for modeling 3D scenes, and can be employed in the actual development of game scenes. "} 
}
@article{Bore2017139,
title = {"Efficient retrieval of arbitrary objects from long-term robot observations "},
journal = {"Robotics and Autonomous Systems "},
volume = {"91"},
number = {""},
pages = {"139 - 150"},
year = {"2017"},
note = {""},
issn = {"0921-8890"},
doi = {"https://doi.org/10.1016/j.robot.2016.12.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0921889016308466"},
author = {"Nils Bore and Rares Ambrus and Patric Jensfelt and John Folkesson"},
keywords = {"Mapping", "Mobile robotics", "Point cloud", "Segmentation", "Retrieval "},
abstract = {"Abstract We present a novel method for efficient querying and retrieval of arbitrarily shaped objects from large amounts of unstructured 3D point cloud data. Our approach first performs a convex segmentation of the data after which local features are extracted and stored in a feature dictionary. We show that the representation allows efficient and reliable querying of the data. To handle arbitrarily shaped objects, we propose a scheme which allows incremental matching of segments based on similarity to the query object. Further, we adjust the feature metric based on the quality of the query results to improve results in a second round of querying. We perform extensive qualitative and quantitative experiments on two datasets for both segmentation and retrieval, validating the results using ground truth data. Comparison with other state of the art methods further enforces the validity of the proposed method. Finally, we also investigate how the density and distribution of the local features within the point clouds influence the quality of the results. "} 
}
@article{Zhang2014825,
title = {"A heuristic approach for λ-representative information retrieval from large-scale data "},
journal = {"Information Sciences "},
volume = {"277"},
number = {""},
pages = {"825 - 841"},
year = {"2014"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.03.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514003016"},
author = {"Jin Zhang and Qiang Wei and Guoqing Chen"},
keywords = {"Information retrieval", "Information representativeness", "Web search", "Heuristic algorithm "},
abstract = {"Abstract Retrieving representative information from large-scale data becomes an important research issue nowadays, especially in the context of mobile business/search where the screen size and navigability are limited. This paper focuses on certain aspects of representativeness in database queries and web search, and proposes an approach to extracting a subset of results from original search results in light of high coverage and low redundancy. In the paper, the notion of λ-represent is introduced, which enables us to describe the λ-represent relationship between the sets of data objects. Then, the λ-representative problem is formulated as an extension of the typical set covering problem, which leads to developing a heuristic approach (namely, LamRep) to coping with the problem effectively and efficiently. Notably, LamRep is incorporated with a “vote” mechanism, enhanced with an algorithmic acceleration strategy. Data experiments on benchmark data and a real-world example show that LamRep outperforms the other approaches. "} 
}
@article{Xia2017195,
title = {"EPCBIR: An efficient and privacy-preserving content-based image retrieval scheme in cloud computing "},
journal = {"Information Sciences "},
volume = {"387"},
number = {""},
pages = {"195 - 204"},
year = {"2017"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.12.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025516321971"},
author = {"Zhihua Xia and Neal N. Xiong and Athanasios V. Vasilakos and Xingming Sun"},
keywords = {"Searchable encryption", "Content-based image retrieval", "Secure k-nearest neighbors algorithm", "Locality-sensitive hashing "},
abstract = {"Abstract The content-based image retrieval (CBIR) has been widely studied along with the increasing importance of images in our daily life. Compared with the text documents, images consume much more storage and thus are very suitable to be stored on the cloud servers. The outsourcing of \{CBIR\} to the cloud servers can be a very typical service in cloud computing. For the privacy-preserving purposes, sensitive images, such as medical and personal images, need to be encrypted before being outsourced, which will cause the \{CBIR\} technologies in plaintext domain unusable. In this paper, we propose a scheme that supports \{CBIR\} over the encrypted images without revealing the sensitive information to the cloud server. Firstly, the feature vectors are extracted to represent the corresponding images. Then, the pre-filter tables are constructed with the locality-sensitive hashing to increase the search efficiency. Next, the feature vectors are protected by the secure k-nearest neighbor (kNN) algorithm. The security analysis and experiments show the security and efficiency of the proposed scheme. "} 
}
@article{Sun2017156,
title = {"GeoFairy: Towards a one-stop and location based Service for Geospatial Information Retrieval "},
journal = {"Computers, Environment and Urban Systems "},
volume = {"62"},
number = {""},
pages = {"156 - 167"},
year = {"2017"},
note = {""},
issn = {"0198-9715"},
doi = {"https://doi.org/10.1016/j.compenvurbsys.2016.11.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S019897151630388X"},
author = {"Ziheng Sun and Liping Di and Gil Heo and Chen Zhang and Hui Fang and Peng Yue and Lili Jiang and Xicheng Tan and Liying Guo and Li Lin"},
keywords = {"One-stop service", "LBS", "Geospatial web service", "Geospatial cloud", "Geospatial mobile application "},
abstract = {"Abstract It is still a great challenge to efficiently deliver dynamic and heterogeneous Earth observation (EO) information to users based on their real time locations. However, the rapidly evolving techniques create a chance to meet the challenge. This paper proposes a framework to realize a one-stop and location based service (LBS) for geospatial information (GI) retrieval on mobile platforms. The framework originally integrates a number of state-of-the-art techniques with geospatial data resources and let them cooperate together to provide a robust and highly available LBS. Cloud platform is used to deploy the server module. A location enabled load balancing algorithm is presented to balance the cloud instance \{VMs\} on behalf of LBS. A system named GeoFairy is implemented. It provides a one-stop service for gathering and delivering twelve kinds of \{GI\} on real time locations. Two Apps are built for the major mobile ecosystems: iOS and Android. Many tests, including a stress test, have been made via a number of mobile devices at various locations. The results demonstrate that GeoFairy is capable of one-stop delivering real-time \{GI\} to users and significantly reducing costs on information searching and retrieving. This feature is very helpful in many scenarios such as disaster responding and military actions. This research paves a way on both theoretical and practical aspects for researchers and developers to realize operational mobile applications for one stop and location based \{GI\} retrieval. "} 
}
@article{Pecina2014165,
title = {"Adaptation of machine translation for multilingual information retrieval in the medical domain "},
journal = {"Artificial Intelligence in Medicine "},
volume = {"61"},
number = {"3"},
pages = {"165 - 185"},
year = {"2014"},
note = {"Text Mining and Information Analysis of Health Documents "},
issn = {"0933-3657"},
doi = {"https://doi.org/10.1016/j.artmed.2014.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0933365714000062"},
author = {"Pavel Pecina and Ondřej Dušek and Lorraine Goeuriot and Jan Hajič and Jaroslava Hlaváčová and Gareth J.F. Jones and Liadh Kelly and Johannes Leveling and David Mareček and Michal Novák and Martin Popel and Rudolf Rosa and Aleš Tamchyna and Zdeňka Urešová"},
keywords = {"Statistical machine translation", "Domain adaptation of statistical machine translation", "Intelligent training data selection for machine translation", "Compound splitting", "Cross-language information retrieval", "Medical query translation "},
abstract = {"AbstractObjective We investigate machine translation (MT) of user search queries in the context of cross-lingual information retrieval (IR) in the medical domain. The main focus is on techniques to adapt \{MT\} to increase translation quality; however, we also explore \{MT\} adaptation to improve effectiveness of cross-lingual IR. Methods and data Our \{MT\} system is Moses, a state-of-the-art phrase-based statistical machine translation system. The \{IR\} system is based on the \{BM25\} retrieval model implemented in the Lucene search engine. The \{MT\} techniques employed in this work include in-domain training and tuning, intelligent training data selection, optimization of phrase table configuration, compound splitting, and exploiting synonyms as translation variants. The \{IR\} methods include morphological normalization and using multiple translation variants for query expansion. The experiments are performed and thoroughly evaluated on three language pairs: Czech–English, German–English, and French–English. \{MT\} quality is evaluated on data sets created within the Khresmoi project and \{IR\} effectiveness is tested on the \{CLEF\} eHealth 2013 data sets. Results The search query translation results achieved in our experiments are outstanding – our systems outperform not only our strong baselines, but also Google Translate and Microsoft Bing Translator in direct comparison carried out on all the language pairs. The baseline \{BLEU\} scores increased from 26.59 to 41.45 for Czech–English, from 23.03 to 40.82 for German–English, and from 32.67 to 40.82 for French–English. This is a 55% improvement on average. In terms of the \{IR\} performance on this particular test collection, a significant improvement over the baseline is achieved only for French–English. For Czech–English and German–English, the increased \{MT\} quality does not lead to better \{IR\} results. Conclusions Most of the \{MT\} techniques employed in our experiments improve \{MT\} of medical search queries. Especially the intelligent training data selection proves to be very successful for domain adaptation of MT. Certain improvements are also obtained from German compound splitting on the source language side. Translation quality, however, does not appear to correlate with the \{IR\} performance – better translation does not necessarily yield better retrieval. We discuss in detail the contribution of the individual techniques and state-of-the-art features and provide future research directions. "} 
}
@article{Chiu2014412,
title = {"Topic knowledge map and knowledge structure constructions with genetic algorithm, information retrieval, and multi-dimension scaling method "},
journal = {"Knowledge-Based Systems "},
volume = {"67"},
number = {""},
pages = {"412 - 428"},
year = {"2014"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2014.03.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705114000914"},
author = {"Deng-Yiv Chiu and Ya-Chen Pan"},
keywords = {"Knowledge structure", "Topic knowledge map", "Information retrieval", "Genetic algorithm", "Independent chi-square", "Multi-dimension scaling "},
abstract = {"Abstract This work presents a novel automated approach to construct topic knowledge maps with knowledge structures, followed by its application to an internationally renowned journal. Knowledge structures are diagrams showing the important components of knowledge in study. Knowledge maps identify the locations of objects and illustrate the relationship among objects. In our study, the important components derived from knowledge structures are used as objects to be spotted in a topic knowledge map. The purpose of our knowledge structures is to find out the major topics serving as subjects of article collections as well as related methods employed in the published papers. The purpose of topic knowledge maps is to transform high-dimensional objects (topic, paper, and cited frequency) into a 2-dimensional space to help understand complicated relatedness among high-dimensional objects, such as the related degree between an article and a topic. First, we adopt independent chi-square test to examine the independence of topics and apply genetic algorithm to choose topics selection with best fitness value to construct knowledge structures. Additionally, high-dimensional relationships among objects are transformed into a 2-dimensional space using the multi-dimension scaling method. The optimal transformation coordinate matrix is also determined by using a genetic algorithm to preserve the original relations among objects and construct appropriate topic knowledge maps. "} 
}
@article{Sigov2017489,
title = {"Improving the Quality of Bionic Resource Retrieval by Visualizing a Specific Bionic-oriented Thesaurus "},
journal = {"Procedia Computer Science "},
volume = {"103"},
number = {""},
pages = {"489 - 494"},
year = {"2017"},
note = {"\{XII\} International Symposium Intelligent Systems 2016, \{INTELS\} 2016, 5-7 October 2016, Moscow, Russia "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2017.01.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050917300339"},
author = {"A. Sigov and V. Baranyuk and V. Nechaev and A. Melikhov and O. Smirnova"},
keywords = {"intellectual system", "bionics", "bionic technologies", "knowledge engineering", "information retrieval thesaurus "},
abstract = {"Abstract This article describes the ability to improve the quality of information resources of search through the use of a specialized thesaurus. The possibilities of using a graphical representation of a thesaurus in the field of bionics and bionic technology, as well as the approach used for automated formation of a multilingual thesaurus primary are considered. "} 
}
@article{Luo201788,
title = {"Prelimbic cortex extracellular signal-regulated kinase 1/2 activation is required for memory retrieval of long-term inhibitory avoidance "},
journal = {"Brain Research "},
volume = {"1661"},
number = {""},
pages = {"88 - 99"},
year = {"2017"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2017.02.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899317300616"},
author = {"Fei Luo and Jian Zheng and Xuan Sun and Wei-ke Deng and Bao ming Li and Fang Liu"},
keywords = {"Medial prefrontal cortex", "Memory retrieval", "Inhibitory avoidance", "ERK", "CREB", "Rat "},
abstract = {"Abstract Neural mechanism underlying memory retrieval has been extensively studied in the hippocampus and amygdala. However, little is known about the role of medial prefrontal cortex in long-term memory retrieval. We evaluate this issue in one-trial step-through inhibitory avoidance (IA) paradigm. Our results showed that, 1) inactivation of mPFC by local infusion of GABAA-receptor agonist muscimol caused severe deficits in retrieval of 1-day and 7-day but had no effects on 2-h inhibitory avoidance memory; 2) the protein level of phosphorylated-ERK1/2 in mPFC were significantly increased following retrieval of 1-day and 7-day \{IA\} memory, so did the numbers of phosphorylated-ERK (pERK) and phosphorylated-CREB (pCREB) labeled neurons; 3) intra-mPFC infusion of \{ERK\} kinase inhibitor \{PD98095\} significantly reduced phosphorylated ERK1/2 levels and phosphorylated-ERK1/2 and phosphorylated-CREB labeled cells, and severely impaired retrieval of 7-day \{IA\} memory when the drugs were administrated 30 min prior to test. The present study provides evidence that retrieval of long-lasting memory for inhibitory avoidance requires mPFC and involves the ERK-CREB signaling cascade. "} 
}
@article{Attia201490,
title = {"An Enhanced Multi-view Fuzzy Information Retrieval Model based on Linguistics "},
journal = {"\{IERI\} Procedia "},
volume = {"7"},
number = {""},
pages = {"90 - 95"},
year = {"2014"},
note = {"International Conference on Applied Computing, Computer Science, and Computer Engineering (ICACC 2013) "},
issn = {"2212-6678"},
doi = {"https://doi.org/10.1016/j.ieri.2014.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212667814000343"},
author = {"Zeinab E. Attia and Ahmed M. Gadallah and Hesham M. Hefny"},
keywords = {"Fuzzy Ontology", "Fuzzy Ontology Information retrieval", "Information Retrieval", "document ranking", "Linguistic based query answering system. "},
abstract = {"Abstract The paper proposes a linguistic based multi-view fuzzy ontology information retrieval model. It deals with multi-view linguistic based queries in multi domains. Such linguistics are user defined, reflecting his subjective view. The model also proposes a ranking algorithm that ranks the set of relevant documents according to some criteria such as their relevance degree, confidence degree, and updating degree. "} 
}
@article{Hill2017,
title = {"Retrieval and clinical analysis of distraction-based dual growing rod constructs for early onset scoliosis "},
journal = {"The Spine Journal "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1529-9430"},
doi = {"https://doi.org/10.1016/j.spinee.2017.04.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S1529943017301778"},
author = {"Genevieve Hill and Srinidhi Nagaraja and Behrooz A. Akbarnia and Jeff Pawelek and Paul Sponseller and Peter Sturm and John Emans and Pablo Bonangelino and Joshua Cockrum and William Kane and Maureen Dreher"},
keywords = {"retrieval analysis", "growing rod", "pediatric", "spinal instrumentation", "early onset scoliosis", "fractography", "failure analysis", "growth friendly technique "},
abstract = {"AbstractBackground Growing rod constructs are an important contribution for treating patients with Early Onset Scoliosis. These devices experience high failure rates, including rod fractures. Purpose The objective of this study was to identify the failure mechanism of retrieved growing rods, and to identify differences between patients with failed and intact constructs. Study Design/Setting Growing rod patients who had implant removal and were previously enrolled in a multicenter registry were eligible for this study. Patient Sample Forty (40) dual-rod constructs were retrieved from 36 patients across four centers, and 34 of those constructs met the inclusion criteria. Eighteen (18) constructs failed due to rod fracture. Sixteen (16) intact constructs were removed due to final fusion (n = 7), implant exchange (n = 5), infection (n = 2), or implant prominence (n = 2). Outcome Measures Analyses of clinical registry data, radiographs, and retrievals. Methods Retrievals were analyzed with microscopic imaging (optical and scanning electron microscopy) for areas of mechanical failure, damage, and corrosion. Failure analyses were conducted on the fracture surfaces to identify failure mechanism(s). Statistical analyses were performed to determine significant differences between the failed and intact groups. Results The failed rods fractured due to bending fatigue under flexion motion. Construct configuration and loading dictate high bending stresses at three distinct locations along the construct: 1) mid-construct, 2) adjacent to the tandem connector, or 3) adjacent to the distal anchor foundation. In addition, high torques used to insert set screws may create an initiation point for fatigue. Syndromic scoliosis, prior rod fractures, increase in patient weight, and rigid constructs consisting of tandem connectors and multiple crosslinks were associated with failure. Conclusions This is the first study to examine retrieved, failed growing rod implants across multiple centers. Our analysis found that rod fractures are due to bending fatigue, and that stress concentrations play an important role in rod fractures. Recommendations are made regarding surgical technique such as use of torque-limiting wrenches and/or not exceeding the prescribed torques. Additional recommendations include frequent rod replacement in select patients during scheduled surgeries. "} 
}
@article{Zhang2014199,
title = {"Bias–variance analysis in estimating true query model for information retrieval "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"1"},
pages = {"199 - 217"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2013.08.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457313000940"},
author = {"Peng Zhang and Dawei Song and Jun Wang and Yuexian Hou"},
keywords = {"Information retrieval", "Query language model", "Bias–variance "},
abstract = {"Abstract The estimation of query model is an important task in language modeling (LM) approaches to information retrieval (IR). The ideal estimation is expected to be not only effective in terms of high mean retrieval performance over all queries, but also stable in terms of low variance of retrieval performance across different queries. In practice, however, improving effectiveness can sacrifice stability, and vice versa. In this paper, we propose to study this tradeoff from a new perspective, i.e., the bias–variance tradeoff, which is a fundamental theory in statistics. We formulate the notion of bias–variance regarding retrieval performance and estimation quality of query models. We then investigate several estimated query models, by analyzing when and why the bias–variance tradeoff will occur, and how the bias and variance can be reduced simultaneously. A series of experiments on four \{TREC\} collections have been conducted to systematically evaluate our bias–variance analysis. Our approach and results will potentially form an analysis framework and a novel evaluation strategy for query language modeling. "} 
}
@article{tagkey2017A1,
title = {"Editorial – patent information, Intellectual Property (IP) management and information retrieval "},
journal = {"World Patent Information "},
volume = {"48"},
number = {""},
pages = {"A1 - A4"},
year = {"2017"},
note = {""},
issn = {"0172-2190"},
doi = {"https://doi.org/10.1016/j.wpi.2017.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0172219017300327"},
key = {"tagkey2017A1"} 
}
@article{Hashemi2014384,
title = {"Mining a Persian–English comparable corpus for cross-language information retrieval "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"2"},
pages = {"384 - 398"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2013.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457313001027"},
author = {"Homa B. Hashemi and Azadeh Shakery"},
keywords = {"Comparable corpora", "Cross-language information retrieval", "Term association network", "Translation validity check "},
abstract = {"Abstract Knowledge acquisition and bilingual terminology extraction from multilingual corpora are challenging tasks for cross-language information retrieval. In this study, we propose a novel method for mining high quality translation knowledge from our constructed Persian–English comparable corpus, University of Tehran Persian–English Comparable Corpus (UTPECC). We extract translation knowledge based on Term Association Network (TAN) constructed from term co-occurrences in same language as well as term associations in different languages. We further propose a post-processing step to do term translation validity check by detecting the mistranslated terms as outliers. Evaluation results on two different data sets show that translating queries using \{UTPECC\} and using the proposed methods significantly outperform simple dictionary-based methods. Moreover, the experimental results show that our methods are especially effective in translating Out-Of-Vocabulary terms and also expanding query words based on their associated terms. "} 
}
@article{Mu201424,
title = {"Explicitly integrating MeSH thesaurus help into health information retrieval systems: An empirical user study "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"1"},
pages = {"24 - 40"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2013.03.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645731300068X"},
author = {"Xiangming Mu and Kun Lu and Hohyon Ryu"},
keywords = {"Health information retrieval", "MeSH terms", "MeSH Browser", "Usability", "User experience", "Interface design "},
abstract = {"Abstract When consumers search for health information, a major obstacle is their unfamiliarity with the medical terminology. Even though medical thesauri such as the Medical Subject Headings (MeSH) and related tools (e.g., the MeSH Browser) were created to help consumers find medical term definitions, the lack of direct and explicit integration of these help tools into a health retrieval system prevented them from effectively achieving their objectives. To explore this issue, we conducted an empirical study with two systems: One is a simple interface system supporting query-based searching; the other is an augmented system with two new components supporting MeSH term searching and MeSH tree browsing. A total of 45 subjects were recruited to participate in the study. The results indicated that the augmented system is more effective than the simple system in terms of improving user-perceived topic familiarity and question–answer performance, even though we did not find users spend more time on the augmented system. The two new MeSH help components played a critical role in participants’ health information retrieval and were found to allow them to develop new search strategies. The findings of the study enhanced our understanding of consumers’ search behaviors and shed light on the design of future health information retrieval systems. "} 
}
@article{Dankar2014497,
title = {"Efficient Private Information Retrieval for Geographical Aggregation "},
journal = {"Procedia Computer Science "},
volume = {"37"},
number = {""},
pages = {"497 - 502"},
year = {"2014"},
note = {"The 5th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2014)/ The 4th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2014)/ Affiliated Workshops "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2014.08.074"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050914010394"},
author = {"Fida K. Dankar and Khaled El Emam and Stan Matwin"},
keywords = {"private information retrieval", "privacy", "k-anonymity. "},
abstract = {"Abstract Knowledge of patients’ location information (postal/zip codes) is critical in public health research. However, the inclusion of location information makes it easier to determine the identity of the individuals in the data sets. An efficient way to anonymize location information is through aggregation. In order to aggregate the locations efficiently, the data holder needs to know the locations’ adjacency information. A location adjacency matrix is big, and requires constant updates, thus it cannot be stored at the data holder's end. A possible solution would be to have the adjacency matrix stored on a cloud server, the data holder can then query the required adjacency records. However, queries reveal information on patients’ locations, thus, we need to privately query the cloud server's database. Existing private information retrieval protocols are inefficient for our context, therefore, in this paper, we present an efficient protocol to privately query the server's database for adjacency information and thus preserving patients’ privacy. "} 
}
@article{Ahamed2016289,
title = {"An intelligent web search framework for performing efficient retrieval of data "},
journal = {"Computers & Electrical Engineering "},
volume = {"56"},
number = {""},
pages = {"289 - 299"},
year = {"2016"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2016.09.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790616304335"},
author = {"B. Bazeer Ahamed and T. Ramkumar"},
keywords = {"Web content", "Search engines", "Web data", "Multiple data source", "Information retrieval "},
abstract = {"Abstract There are numerous search engines available in today's world to search and retrieve the required information. However retrieval of meaningful and appropriate formation as per the user requirement is always a challenging task. The foremost intention of any search engine is to provide the information with in a quick span of time. Since the nature of data available in World-Wide-Web shows heterogeneity in common and the sources of data are also distinct with each other, issues pertaining to schema structure and data representational are also there. In such circumstances, to eliminate inconsistencies and for enabling seamless integration of multiple data sources while retrieving web data, an efficient web search mechanism that fulfils the customer requirement is always needed. To enable the integration of multiple data sources while performing efficient retrieval of web data, an intelligent web search framework has been proposed in this paper. "} 
}
@article{DiBuccio2014342,
title = {"Detecting verbose queries and improving information retrieval "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"2"},
pages = {"342 - 360"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2013.09.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457313001003"},
author = {"Emanuele Di Buccio and Massimo Melucci and Federica Moro"},
keywords = {"Information retrieval", "Verbose queries", "Query modification", "Query expansion "},
abstract = {"Abstract Although most of the queries submitted to search engines are composed of a few keywords and have a length that ranges from three to six words, more than 15% of the total volume of the queries are verbose, introduce ambiguity and cause topic drifts. We consider verbosity a different property of queries from length since a verbose query is not necessarily long, it might be succinct and a short query might be verbose. This paper proposes a methodology to automatically detect verbose queries and conditionally modify queries. The methodology proposed in this paper exploits state-of-the-art classification algorithms, combines concepts from a large linguistic database and uses a topic gisting algorithm we designed for verbose query modification purposes. Our experimental results have been obtained using the \{TREC\} Robust track collection, thirty topics classified by difficulty degree, four queries per topic classified by verbosity and length, and human assessment of query verbosity. Our results suggest that the methodology for query modification conditioned to query verbosity detection and topic gisting is significantly effective and that query modification should be refined when topic difficulty and query verbosity are considered since these two properties interact and query verbosity is not straightforwardly related to query length. "} 
}
@article{Goswami2017454,
title = {"Exploring the space of information retrieval term scoring functions "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"2"},
pages = {"454 - 472"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.11.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316306100"},
author = {"Parantapa Goswami and Eric Gaussier and Massih-Reza Amini"},
keywords = {"\{IR\} theory", "Function generation", "Automatic discovery", "IR constraints "},
abstract = {"Abstract In this paper we are interested in finding good \{IR\} scoring functions by exploring the space of all possible \{IR\} functions. Earlier approaches to do so however only explore a small sub-part of the space, with no control on which part is explored and which is not. We aim here at a more systematic exploration by first defining a grammar to generate possible \{IR\} functions up to a certain length (the length being related to the number of elements, variables and operations, involved in a function), and second by relying on \{IR\} heuristic constraints to prune the search space and filter out bad scoring functions. The obtained candidate scoring functions are tested on various standard \{IR\} collections and several simple but promising functions are identified. We perform extensive experiments to compare these functions with classical \{IR\} models. It is observed that these functions are yielding either better or comparable results. We also compare the performance of functions satisfying \{IR\} heuristic constraints and those which do not; the former set of functions clearly outperforms the latter, which shows the validity of \{IR\} heuristic constraints to design new \{IR\} models. "} 
}
@article{VicenteLópez2016127,
title = {"Use of textual and conceptual profiles for personalized retrieval of political documents "},
journal = {"Knowledge-Based Systems "},
volume = {"112"},
number = {""},
pages = {"127 - 141"},
year = {"2016"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2016.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705116303203"},
author = {"Eduardo Vicente-López and Luis M. de Campos and Juan M. Fernández-Luna and Juan F. Huete"},
keywords = {"User profile", "Personalization", "Information retrieval", "Privacy-enhanced", "E-Government "},
abstract = {"Abstract The amount of information we are exposed to on a daily basis is increasing exponentially. Besides, Information Retrieval Systems (IRSs) return the same results for a given query regardless of who submitted it. In order to address the problems of finding useful, relevant information and adapting the results to the user, the use of personalization techniques is now more necessary than ever. They are not, however, particularly popular in live environments as users remain unconvinced about their reliability and, more importantly, are concerned about privacy issues. We have developed and compared six generic user profile representations in order to improve the personalization process and address the problem of privacy. We propose a new weighting scheme to build the profiles and a new personalization technique to join the advantages of some of the previous profiles. A comprehensive evaluation study of the proposed generic user profiles was performed and this revealed very good personalization performance results and some interesting conclusions about their use in a political context, more specifically with official documents from the Andalusian Parliament. "} 
}
@incollection{Karpicke2017,
title = {"Retrieval-Based Learning: A Decade of Progress "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.21055-9"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245210559"},
author = {"Jeffrey D. Karpicke"},
keywords = {"Learning", "Learning strategies", "Meaningful learning", "Memory", "Retrieval-based learning", "Retrieval practice", "Testing effect "},
abstract = {"Abstract This chapter provides a comprehensive review of the past decade of research on retrieval-based learning. It describes common approaches used to study retrieval practice and outlines theoretical accounts of retrieval-based learning. This chapter reviews research that has manipulated initial retrieval practice activities in a wide variety of ways, extended the benefits of retrieval practice to final assessments that measure educationally meaningful learning outcomes, and generalized retrieval-based learning across learner populations, to different types of materials, and to authentic educational contexts. "} 
}
@article{Theologou2017,
title = {"Part-based 3D object retrieval via multi-label optimization "},
journal = {"Computer Vision and Image Understanding "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2017.04.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314217300681"},
author = {"Panagiotis Theologou and Ioannis Pratikakis and Theoharis Theoharis"},
keywords = {"3D object retrieval", "3D mesh segmentation", "Part-based representation "},
abstract = {"Abstract This paper deals with the problem of 3D object retrieval using a part-based representation. The premise in this context is that similar objects will consist of similar parts. A part-based representation is proposed, where each object is segmented, and represented as a labeled graph, with nodes corresponding to parts, and edges connecting adjacent parts. The calculation of the distance between two segmented objects is formulated as a multi-label optimization problem, taking into account the aforementioned graphs. The proposed method achieves comparable performance to the state-of-the-art on several datasets, while it has a clear advantage in the case of articulated objects. "} 
}
@article{Song2014366,
title = {"An effective query recommendation approach using semantic strategies for intelligent information retrieval "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"2"},
pages = {"366 - 372"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2013.07.052"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417413005393"},
author = {"Wei Song and Jiu Zhen Liang and Xiao Long Cao and Soon Cheol Park"},
keywords = {"Query recommendation", "Genetic algorithm", "Knowledge discovery", "Clustering", "Information retrieval "},
abstract = {"Abstract With the explosive growth of web information, search engines have become the mainstream tools of information retrieval (IR). However, a notable problem emerged in the current \{IR\} systems is that the input queries are usually too short and too ambiguous to express their actual idea which largely affects the performance of \{IR\} systems. In this study, a novel query recommendation technology which suggests a list of related queries is proposed to resolve these problems. The query concepts can be firstly extracted from the web-snippets of the search result returned by the input query. A bipartite graph is subsequently built to identify the related queries, and the query similarity can be calculated by such bipartite graph. Moreover, by analyzing the \{URLs\} clicked by users, we find that some tokens appeared in \{URLs\} are very meaningful, especial for some typical topic-based pages. Therefore, these potential tokens which can provide a brief description from the subject of the \{URL\} are also considered. In order to reveal the real semantics between queries, the approach TF-IQF model is further discussed, and three features of a query, i.e. clicked documents, associated query and reversed query, are utilized in our approach in depth. Such a method could hopefully acquire the comprehensive idea of a query. To investigate how these three features could be used effectively for query recommendation in search engine, we adopt the benchmark evaluation criterions in our experiments, and the experimental results show its promising results in comparison with state of the art methods. "} 
}
@article{Akmal201491,
title = {"Ontology-based similarity for product information retrieval "},
journal = {"Computers in Industry "},
volume = {"65"},
number = {"1"},
pages = {"91 - 107"},
year = {"2014"},
note = {""},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2013.07.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166361513001590"},
author = {"Suriati Akmal and Li-Hsing Shih and Rafael Batres"},
keywords = {"Semantic similarity", "Ontology", "Product information retrieval", "Formal concept analysis "},
abstract = {"Abstract Product development of today is becoming increasingly knowledge intensive. Specifically, design teams face considerable challenges in making effective use of increasing amounts of information. In order to support product information retrieval and reuse, one approach is to use case-based reasoning (CBR) in which problems are solved “by using or adapting solutions to old problems.” In CBR, a case includes both a representation of the problem and a solution to that problem. Case-based reasoning uses similarity measures to identify cases which are more relevant to the problem to be solved. However, most non-numeric similarity measures are based on syntactic grounds, which often fail to produce good matches when confronted with the meaning associated to the words they compare. To overcome this limitation, ontologies can be used to produce similarity measures that are based on semantics. This paper presents an ontology-based approach that can determine the similarity between two classes using feature-based similarity measures that replace features with attributes. The proposed approach is evaluated against other existing similarities. Finally, the effectiveness of the proposed approach is illustrated with a case study on product–service–system design problems. "} 
}
@article{Moulin2014260,
title = {"Fisher Linear Discriminant Analysis for text-image combination in multimedia information retrieval "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"1"},
pages = {"260 - 269"},
year = {"2014"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2013.06.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320313002550"},
author = {"Christophe Moulin and Christine Largeron and Christophe Ducottet and Mathias Géry and Cécile Barat"},
keywords = {"Multimedia information retrieval", "Textual and visual information", "Bag-of-words", "Parameters learning", "Fischer \{LDA\} "},
abstract = {"Abstract With multimedia information retrieval, combining different modalities – text, image, audio or video provides additional information and generally improves the overall system performance. For this purpose, the linear combination method is presented as simple, flexible and effective. However, it requires to choose the weight assigned to each modality. This issue is still an open problem and is addressed in this paper. Our approach, based on Fisher Linear Discriminant Analysis, aims to learn these weights for multimedia documents composed of text and images. Text and images are both represented with the classical bag-of-words model. Our method was tested over the ImageCLEF datasets 2008 and 2009. Results demonstrate that our combination approach not only outperforms the use of the single textual modality but provides a nearly optimal learning of the weights with an efficient computation. Moreover, it is pointed out that the method allows to combine more than two modalities without increasing the complexity and thus the computing time. "} 
}
@article{Wang2017,
title = {"View-based 3D object retrieval with discriminative views "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.06.095"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217306628"},
author = {"Dong Wang and Bin Wang and Sicheng Zhao and Hongxun Yao and Hong liu"},
keywords = {"Discriminative view", "Semantic view", "Reverse sum-min distance", "3D object retrieval "},
abstract = {"Abstract View-based 3D object retrieval techniques have become increasingly important in various fields, and lots of ingenious studies have promoted the development of retrieval performance from different aspects. In this paper, we focus on the 2D projective views that represent the 3D objects and propose a boosting approach by evaluating the discriminative ability of each object’s views. The dissimilarity between views’ semantic and discriminative ability is firstly investigated through classification performance. We then propose a simple, robust and effective measurement to study the view’s discriminative ability. By employing the proposed reverse distance metric, we utilize the discriminative information for many to many view set matching. The proposed algorithm is then employed with various features to boost the multi-model graph learning based retrieval method. We compare our approach with several state of the art methods on ETH-80 dataset and National Taiwan University 3D model dataset. The results demonstrate the effectiveness of our method and its excellent boosting performance. "} 
}
@article{DaoThiThuy201730,
title = {"An efficient semantic – Related image retrieval method "},
journal = {"Expert Systems with Applications "},
volume = {"72"},
number = {""},
pages = {"30 - 41"},
year = {"2017"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2016.12.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417416306777"},
author = {"Quynh Dao Thi Thuy and Quynh Nguyen Huu and Canh Phuong Van and Tao Ngo Quoc"},
keywords = {"Content-based image retrieval", "Semantic-related image", "Semantic weight", "Importance of feature "},
abstract = {"Abstract Many previous techniques were designed to retrieve semantic images in a certain neighborhood of the query image and thus bypassing the semantically related images in the whole feature space. Several recently methods were designed to retrieve semantically related images in the entire feature space but with low precision. In this paper, we propose a Semantic – Related Image Retrieval method (SRIR), which can retrieve semantic images spread in the entire feature space with high precision. Our method takes advantage of the user feedback to determine the semantic importance of each query and the importance of each feature. In addition, the retrieval time of our method does not increase with the number of user feedback. We also provide experimental results to demonstrate the effectiveness of our method. "} 
}
@article{Roy2017,
title = {"Date-field retrieval in scene image and video frames using text enhancement and shape coding "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.08.141"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217306689"},
author = {"Partha Pratim Roy and Ayan Kumar Bhunia and Umapada Pal"},
keywords = {"Date-based indexing", "Scene text and video text retrieval", "Date extraction", "Date spotting", "Hidden Markov model "},
abstract = {"Abstract Text recognition in scene image and video frames is difficult because of low resolution, blur, background noise, etc. Since traditional \{OCRs\} do not perform well in such images, information retrieval using keywords could be an alternative way to index/retrieve such text information. Date is a useful piece of information which has various applications including date-wise videos/scene searching, indexing or retrieval. This paper presents a date spotting based information retrieval system for natural scene image and video frames where text appears with complex backgrounds. We propose a line based date spotting approach using hidden Markov model (HMM) which is used to detect the date information in a given text. Different date models are searched from a line without segmenting characters or words. Given a text line image in RGB, we apply an efficient gray image conversion to enhance the text information. Wavelet decomposition and gradient sub-bands are used to enhance text information in gray scale. Next, pyramid histogram of oriented gradient (PHOG) feature has been extracted from gray image and binary images for date-spotting framework. Binary and gray image features are combined by \{MLP\} based tandem approach. Finally, to boost the performance further, a shape coding based scheme is used to combine the similar shape characters in same class during word spotting. For our experiment, three different date models have been constructed to search similar date information having numeric dates that contains numeral values and punctuations and semi-numeric that contains dates with numerals along with months in scene/video text. We have tested our system on 1648 text lines and the results show the effectiveness of our proposed date spotting approach. "} 
}
@article{Long20171074,
title = {"Contextually Mediated Spontaneous Retrieval Is Specific to the Hippocampus "},
journal = {"Current Biology "},
volume = {"27"},
number = {"7"},
pages = {"1074 - 1079"},
year = {"2017"},
note = {""},
issn = {"0960-9822"},
doi = {"https://doi.org/10.1016/j.cub.2017.02.054"},
url = {"http://www.sciencedirect.com/science/article/pii/S0960982217302257"},
author = {"Nicole M. Long and Michael R. Sperling and Gregory A. Worrell and Kathryn A. Davis and Robert E. Gross and Bradley C. Lega and Barbara C. Jobst and Sameer A. Sheth and Kareem Zaghloul and Joel M. Stein and Michael J. Kahana"},
keywords = {"iEEG", "free recall", "episodic memory", "retrieval", "context "},
abstract = {"Summary Although it is now well established that the hippocampus supports memory encoding [1, 2], little is known about hippocampal activity during spontaneous memory retrieval. Recent intracranial electroencephalographic (iEEG) work has shown that hippocampal activity during encoding predicts subsequent temporal organization of memories [3], supporting a role in contextual binding. It is an open question, however, whether the hippocampus similarly supports contextually mediated processes during retrieval. Here, we analyzed iEEG recordings obtained from 215 epilepsy patients as they performed a free recall task. To identify neural activity specifically associated with contextual retrieval, we compared correct recalls, intrusions (incorrect recall of either items from prior lists or items not previously studied), and deliberations (matched periods during recall when no items came to mind). Neural signals that differentiate correct recalls from both other retrieval classes reflect contextual retrieval, as correct recalls alone arise from the correct context. We found that in the hippocampus, high-frequency activity (HFA, 44–100 Hz), a proxy for neural activation [4], was greater prior to correct recalls relative to the other retrieval classes, with no differentiation between intrusions and deliberations. This pattern was not observed in other memory-related cortical regions, including DLPFC, thus supporting a specific hippocampal contribution to contextually mediated memory retrieval. "} 
}
@article{Zamorano2017,
title = {"Memory retrieval re-activates Erk1/2 signaling in the same set of \{CA1\} neurons recruited during conditioning "},
journal = {"Neuroscience "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0306-4522"},
doi = {"https://doi.org/10.1016/j.neuroscience.2017.03.034"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306452217302002"},
author = {"Cristina Zamorano and Jordi Fernández and Daniel R. Storm and Xavier Carné and Carlos Sindreu"},
keywords = {"memory retrieval", "contextual fear", "Erk1/2 signaling", "neuron", "hippocampus "},
abstract = {"Abstract The hippocampus enables a range of behaviors through its intrinsic circuits and concerted actions with other brain regions. One such important function is the retrieval of episodic memories. How hippocampal cells support retrieval of contextual fear memory remains largely unclear. Here we monitored phospho-activation of extracellular-regulated kinase (Erk1/2) across neuronal populations of the hippocampus to find that \{CA1\} pyramidal neurons, but not cells in \{CA3\} or dentate gyrus, specifically respond to retrieval of an aversive context. In contrast, retrieval of a neutral context that fails to elicit a threat response did not activate Erk1/2. Moreover, retrieval preferentially re-activated Erk1/2 in the same set of \{CA1\} neurons previously activated during conditioning in a context-specific manner. By confining drug inhibition within dorsal CA1, we established the crucial role for Erk1/2 activity in retrieval of long-term memory, as well as in amygdala activation associated with fear expression. These data provide functional evidence that Erk1/2 signaling in \{CA1\} encodes a specific neural representation of contextual memory with emotional value. "} 
}
@article{Chang2017150,
title = {"Image multiplexing and authentication based on double phase retrieval in fresnel transform domain "},
journal = {"Optics Communications "},
volume = {"389"},
number = {""},
pages = {"150 - 158"},
year = {"2017"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2016.11.061"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401816310434"},
author = {"Hsuan-Ting Chang and Che-Hsian Lin and Chien-Yue Chen"},
keywords = {"Image multiplexing", "Manipulations of wavelength and position", "Double-phase retrieval algorithm", "Phase-locked system", "Authentication system", "Computer simulation "},
abstract = {"Abstract An image multiplexing and authentication method based on the double-phase retrieval algorithm (DPRA) with the manipulations of wavelength and position in the Fresnel transform (FrT) domain is proposed in this study. The \{DPRA\} generates two matched phase-only functions (POFs) in the different planes so that the corresponding image can be reconstructed at the output plane. Given a number of target images, all the sets of matched \{POFs\} are used to generate the phase-locked system through the phase modulation and synthesis to achieve the multiplexing purpose. To reconstruct a target image, the corresponding phase key and all the correct parameters in the FrT are required. Therefore, the authentication system with high-level security can be achieved. The computer simulation verifies the validity of the proposed method and also shows good resistance to the crosstalk among the reconstructed images. "} 
}
@article{Dahak201787,
title = {"A probabilistic model to exploit user expectations in \{XML\} information retrieval "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"1"},
pages = {"87 - 105"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.06.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316302278"},
author = {"Fouad Dahak and Mohand Boughanem and Amar Balla"},
keywords = {"Priors", "Element importance", "User browsing map", "Language model "},
abstract = {"Abstract The main objective of this paper is to exploit a new source of evidence derived from the document hierarchical structure for \{XML\} information retrieval. We consider that the structure of \{XML\} document is an important source of prior knowledge, and the structural features of an element may influence the user to consider that element as relevant. We build a probabilistic model to estimate the probability that the structural characteristics of an element attract user to explore the content of this element and consider it as relevant. This probability reflects the context importance. We propose a simple, well-motivated probabilistic model to estimate the context importance. Finally, we demonstrate the effectiveness of the context importance through comprehensive experimental studies carried out on \{IEEE\} \{XML\} document collection. Experimental results show that the proposed approach outperforms models exploiting other sources of evidence. "} 
}
@article{King2017,
title = {"Influence of response bias and internal/external source on lateral posterior parietal successful retrieval activity "},
journal = {"Cortex "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2017.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945217301168"},
author = {"Danielle R. King and Michael B. Miller"},
keywords = {"Source memory", "Reality monitoring", "Parietal", "Successful retrieval", "Response bias "},
abstract = {"Abstract In studies of recognition memory, regions of the lateral posterior parietal cortex exhibit greater activity (as indexed by the fMRI \{BOLD\} signal) during correct recognition of “old” (studied) items than correct rejection of “new” (unstudied) items. This effect appears to be source-sensitive, with greater activity associated with recognition of perceived than imagined events. Parietal successful retrieval activity also varies with response bias, or the tendency to be conservative about making “old” judgments. Here, we examined whether differences in response bias associated with recognition judgments of perceived and imagined events could account for source-based differences in \{LPPC\} activity. Participants perceived and imagined items in response to cue words and then at test, made recognition judgments in blocks that knowingly contained either a high or low proportion of old to new trials. While participants were indeed more conservative when making judgments about perceived than imagined events, the neuroimaging results demonstrated that response bias and source effects occurred in non-overlapping parietal regions. These findings suggest that source-based differences in \{LPPC\} activity cannot be explained by differences in response bias associated with recognizing perceived and imagined events. "} 
}
@article{Arnett201722,
title = {"Subject encodings and retrieval interference "},
journal = {"Journal of Memory and Language "},
volume = {"93"},
number = {""},
pages = {"22 - 54"},
year = {"2017"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2016.07.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X1630064X"},
author = {"Nathan Arnett and Matthew Wagers"},
keywords = {"Syntax", "Retrieval", "Interference", "Subjecthood", "Parsing", "Eye-tracking "},
abstract = {"Abstract Interference has been identified as a cause of processing difficulty in linguistic dependencies, such as the subject-verb relation (Van Dyke and Lewis, 2003). However, while mounting evidence implicates retrieval interference in sentence processing, the nature of the retrieval cues involved - and thus the source of difficulty - remains largely unexplored. Three experiments used self-paced reading and eyetracking to examine the ways in which the retrieval cues provided at a verb characterize subjects. Syntactic theory has identified a number of properties correlated with subjecthood, both phrase-structural and thematic. Findings replicate and extend previous findings of interference at a verb from additional subjects, but indicate that retrieval outcomes are relativized to the syntactic domain in which the retrieval occurs. One, the cues distinguish between thematic subjects in verbal and nominal domains. Two, within the verbal domain, retrieval is sensitive to abstract syntactic properties associated with subjects and their clauses. We argue that the processing at a verb requires cue-driven retrieval, and that the retrieval cues utilize abstract grammatical properties which may reflect parser expectations. "} 
}
@article{Garimella2015631,
title = {"Image Retrieval: Information and Rough Set Theories "},
journal = {"Procedia Computer Science "},
volume = {"54"},
number = {""},
pages = {"631 - 637"},
year = {"2015"},
note = {"Eleventh International Conference on Communication Networks, \{ICCN\} 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Data Mining and Warehousing, \{ICDMW\} 2015, August 21-23, 2015, Bangalore, India Eleventh International Conference on Image and Signal Processing, \{ICISP\} 2015, August 21-23, 2015, Bangalore, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.06.073"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915013976"},
author = {"Rama Murthy Garimella and Moncef Gabbouj and Iftikhar Ahmad"},
keywords = {"Hierarchical features", "Normalized histogram", "Roughset", "K-L divergence", "Image Retrieval. "},
abstract = {"Abstract In this research paper, we propose novel features based on information theory for image retrieval. We propose the novel concept of “probabilistic filtering”. We propose a hybrid approach for image retrieval that combines annotation approach with content based image retrieval approach. Also rough set theory is proposed as a tool for audio/video object retrieval from multi-media databases. "} 
}
@article{Rupprecht2017259,
title = {"Retrieval-induced versus context-induced forgetting: Can restudy preceded by context change simulate retrieval-induced forgetting? "},
journal = {"Journal of Memory and Language "},
volume = {"93"},
number = {""},
pages = {"259 - 275"},
year = {"2017"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2016.10.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X16301681"},
author = {"Julia Rupprecht and Karl-Heinz T. Bäuml"},
keywords = {"Episodic memory", "Retrieval-induced forgetting", "Context change", "Inhibition "},
abstract = {"Abstract Retrieval-induced forgetting (RIF) refers to the finding that retrieval practice on a subset of studied items can induce later forgetting of related unpracticed items. The context account of RIF, which attributes \{RIF\} to a mismatch of study context and reinstated context at test for the unpracticed items, claims that \{RIF\} effects can be simulated by restudy trials when these trials are preceded by context change. To test this proposal, we compared across three experiments effects of retrieval practice and of restudy trials preceded by context change, employing both recall and item recognition testing. We found retrieval practice to impair both recall and recognition of unpracticed items, which is consistent with prior work. In contrast, restudy preceded by context change impaired recall but not recognition of the items. These findings suggest that restudy preceded by context change cannot simulate RIF, which challenges the context account of RIF. The results are consistent with the view of a critical role of retrieval and inhibition in RIF. "} 
}
@article{Wais2017178,
title = {"Retrieval of high-fidelity memory arises from distributed cortical networks "},
journal = {"NeuroImage "},
volume = {"149"},
number = {""},
pages = {"178 - 189"},
year = {"2017"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2017.01.062"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811917300848"},
author = {"Peter E. Wais and Sahar Jahanikia and Daniel Steiner and Craig E.L. Stark and Adam Gazzaley"},
keywords = {"Functional networks", "Episodic retrieval", "fMRI", "Cognitive control", "Mnemonic discrimination "},
abstract = {"Abstract Medial temporal lobe (MTL) function is well established as necessary for memory of facts and events. It is likely that lateral cortical regions critically guide cognitive control processes to tune in high-fidelity details that are most relevant for memory retrieval. Here, convergent results from functional and structural \{MRI\} show that retrieval of detailed episodic memory arises from lateral cortical—MTL networks, including regions of inferior frontal and angular gyrii. Results also suggest that recognition of items based on low-fidelity, generalized information, rather than memory arising from retrieval of relevant episodic details, is not associated with functional connectivity between \{MTL\} and lateral cortical regions. Additionally, individual differences in microstructural properties in white matter pathways, associated with distributed MTL-cortical networks, are positively correlated with better performance on a mnemonic discrimination task. "} 
}
@article{Li2017118,
title = {"Color texture image retrieval based on Gaussian copula models of Gabor wavelets "},
journal = {"Pattern Recognition "},
volume = {"64"},
number = {""},
pages = {"118 - 129"},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2016.10.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320316303478"},
author = {"Chaorong Li and Yuanyuan Huang and Lihong Zhu"},
keywords = {"Color Texture retrieval", "Image representation", "Copula model", "Gabor wavelets "},
abstract = {"Abstract Color texture retrieval is a hot research area in image analysis. In this paper, we propose an efficient color texture retrieval method by using copula model based on Gabor wavelets. When Gabor wavelets are used to decompose color image, three types of dependence exist in the decomposed subbands of Gabor wavelets: color dependence, scale dependence and direction dependence. We analyze these dependencies and then capture them by using Gaussian copula function. Four copula schemes are developed, and accordingly four \{KLDs\} (Kullback-Leibler distances) of the copula schemes are introduced for color texture image retrieval. The evaluations of the proposed method are performed on several color texture databases including two large texture databases \{ALOT\} and STex. Experimental results demonstrate the proposed method has better performance than the state-of-the-art retrieval methods. "} 
}
@article{Wang201786,
title = {"Improving feature matching strategies for efficient image retrieval "},
journal = {"Signal Processing: Image Communication "},
volume = {"53"},
number = {""},
pages = {"86 - 94"},
year = {"2017"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2017.02.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S092359651730022X"},
author = {"Lei Wang and Hanli Wang"},
keywords = {"Image retrieval", "Feature matching", "Twin Feature", "Similarity maximal matching", "Dynamic normalization "},
abstract = {"Abstract A number of state-of-the-art image retrieval systems have been built upon non-aggregated techniques such as Hamming Embedding (HE) and Selective Match Kernel (SMK). However, the retrieval performances of these techniques are directly affected by the quality of feature matching during the search process. In general, undesirable matched results appear mainly due to the following three aspects: (1) the locality of local features, (2) the quantization errors and (3) the phenomenon of burstiness. In this paper, starting from the framework of SMK, an in-depth study of the integration of Twin Feature (TF) and Similarity Maximal Matching (SMM) is fully investigated. To be specific, two effective modifications based on \{TF\} and \{SMM\} are proposed to further improve the quality of feature matching. On one hand, the original float vectors of \{TF\} are replaced with efficient binary signatures, which achieve relatively high efficiency and comparable accuracy of retrieval. On the other hand, Dynamic Normalization (DN) is designed to effectively control the impact of penalization generated by \{SMM\} and improve the performance with almost no extra cost. At last, an efficient image retrieval system is designed and realized based on a cloud-based heterogeneous computing framework through Apache Spark and multiple \{GPUs\} to deal with large-scale tasks. Experimental results demonstrate that the proposed system can greatly refine the visual matching process and improve image retrieval results. "} 
}
@article{Piyush20171895,
title = {"Retrieval of cloud ice water path using \{SAPHIR\} on board Megha-Tropiques over the tropical ocean "},
journal = {"Advances in Space Research "},
volume = {"59"},
number = {"7"},
pages = {"1895 - 1906"},
year = {"2017"},
note = {""},
issn = {"0273-1177"},
doi = {"https://doi.org/10.1016/j.asr.2017.01.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0273117717300522"},
author = {"Durgesh Nandan Piyush and Jayesh Goyal and J. Srinivasan"},
keywords = {"Megha Tropiques", "SAPHIR", "Ice water path", "Water vapor absorption band", "Retrieval "},
abstract = {"Abstract The \{SAPHIR\} sensor onboard Megha-Tropiques (MT) measures the earth emitted radiation at frequencies near the water vapor absorption band. \{SAPHIR\} operates in six frequencies ranging from 183 ± 0.1 to 183 ± 11 GHz. These frequencies have been used to retrieve cloud ice water path (IWP) at a very high resolution. A method to retrieve \{IWP\} over the Indian ocean region is attempted in this study. The study is in two parts, in first part a radiative transfer based simulation is carried out to give an insight of using \{SAPHIR\} frequency channels for \{IWP\} retrieval, in the next part the real observations of \{SAPHIR\} and TRMM-TMI was used for \{IWP\} retrieval. The concurrent observations of \{SAPHIR\} brightness temperatures (Tbs) and \{TRMM\} \{TMI\} \{IWP\} were used in the development of the retrieval algorithm. An Eigen Vector analysis was done to identify weight of each channel in retrieving IWP; following this a two channel regression based algorithm was developed. The \{SAPHIR\} channels which are away from the water vapor absorption band were used to avoid possible water vapor contamination. When the retrieval is compared with independent test dataset, it gives a correlation of 0.80 and \{RMSE\} of 3.5%. \{SAPHIR\} derived \{IWP\} has been compared with other available global \{IWP\} products such as TMI, MSPPS, CloudSat and GPM-GMI qualitatively as well as quantitatively. \{PDF\} comparison of \{SAPHIR\} derived \{IWP\} found to have good agreement with CloudSat. Zonal mean comparison with recently launched \{GMI\} shows the strength of this algorithm. "} 
}
@article{Tang2017,
title = {"Supervised deep hashing for scalable face image retrieval "},
journal = {"Pattern Recognition "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2017.03.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320317301383"},
author = {"Jinhui Tang and Zechao Li and Xiang Zhu"},
keywords = {"Image retrieval", "Supervised hashing", "Binary codes", "Deep learning "},
abstract = {"Abstract Hashing has been widely utilized for Approximate Nearest Neighbor (ANN) search due to its fast retrieval speed and low storage cost. In this work, we propose a novel supervised hashing method for scalable face image retrieval, i.e., Deep Hashing based on Classification and Quantization errors (DHCQ), by simultaneously learning feature representations of images, hash codes and classifiers. The supervised information and the deep architecture are collaboratively explored. Specifically, a deep convolutional network is introduced to learn discriminative feature representations, which are directly used to generate hash codes and predict labels of images. The quantization errors and the prediction errors jointly guide the learning of the deep network. They are highly interrelated and promoted each other. It is worth noting that the proposed method is a general hashing method and can be applied to the general image retrieval task. Extensive experiments on two face image datasets and one general image dataset demonstrate the effectiveness of the proposed method compared with several state-of-the-art hashing methods. "} 
}
@article{Pan2017150,
title = {"Application of a Markov Chain Monte Carlo algorithm for snow water equivalent retrieval from passive microwave measurements "},
journal = {"Remote Sensing of Environment "},
volume = {"192"},
number = {""},
pages = {"150 - 165"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.02.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300573"},
author = {"Jinmei Pan and Michael T. Durand and Benjamin J. Vander Jagt and Desheng Liu"},
keywords = {"Passive microwave remote sensing", "Snow water equivalent", "Retrieval algorithm "},
abstract = {"Abstract Recent applications of passive microwave remote sensing techniques to estimate snow water equivalent (SWE) increasingly rely on the comprehension of microwave emission theories, instead of traditional empirical fitting approaches. In this study, an advanced \{SWE\} retrieval algorithm based on the Markov Chain Monte Carlo method was developed. This method samples the posterior multiple-layer snow properties according to the likelihood of the brightness temperature (TB) simulation with the actual \{TB\} observations. The Microwave Emission Model of Layered Snowpacks with improved Born approximation (MEMLS-IBA) was used as the observation model. Using a globally applicable method to produce prior estimates of snow properties, the retrieval approach is called the Bayesian Algorithm for \{SWE\} Estimation with Passive Microwave measurements (BASE-PM), and was applied on 48 snowpits at Sodankylä, Finland; Churchill, Canada and Colorado, US. The result shows that the root mean squared (RMS) error of the retrieved \{SWE\} is 42.7 mm excluding two outliers, and is 30.8 mm if the outliers as well as six deep snowpits from Colorado are excluded. This accuracy approximately meets the 30-mm requirement of Integrated Global Observing Strategy for shallow snow. The poor performance for the outlier and deep snowpits is explained. Additional experiments using more accurate priors show that \{SWE\} retrieval accuracy can be improved with local snowcover knowledge, e.g. if historical snowpit measurements or snow process model simulations are available. "} 
}
@article{Tiwari201773,
title = {"Histogram refinement for texture descriptor based image retrieval "},
journal = {"Signal Processing: Image Communication "},
volume = {"53"},
number = {""},
pages = {"73 - 85"},
year = {"2017"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2017.01.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596517300164"},
author = {"Ashwani Kumar Tiwari and Vivek Kanhangad and Ram Bilas Pachori"},
keywords = {"Histogram refinement", "Local binary patterns", "Local derivative patterns", "Local ternary patterns", "Texture descriptors", "Content-based image retrieval "},
abstract = {"Abstract Texture descriptors such as local binary patterns (LBP) have been successfully employed for feature extraction in image retrieval algorithms because of their high discriminating ability and computational efficiency. In this paper, we propose histogram feature refinement methods for enhancing performance of texture descriptor based content-based image retrieval (CBIR) systems. In the proposed approach for histogram refinement, each pixel in the query and database images is classified into one of the two categories based on the analysis of pixel values in its neighborhood. Local patterns corresponding to two sets of pixels are used to generate two histogram features for each image, effectively resulting in splitting of the original global histogram of texture descriptors into two based on the category of each pixel. Resulting histograms are then concatenated to form a single histogram feature. This study also explores three hybrid frameworks for histogram refinement in \{CBIR\} systems. Comparison of histogram features corresponding to query and database images are performed using the relative l 1 distance metric. Performance evaluation on three publicly available benchmark image databases namely, \{GHIM\} 10000, \{COREL\} 1000 database, and Brodatz texture database shows that performances of existing texture descriptor based approaches improve considerably when the proposed histogram feature refinement is incorporated. Specifically, the average precision rate is improved by 6.02%, 5.69%, 4.79%, and 4.21% for LBP, local derivative pattern (LDP), local ternary pattern (LTP), and local tetra pattern (LTrP) descriptors, respectively on \{GHIM\} 10000 database. The proposed histogram refinement approaches also provide performance improvement for other texture descriptors considered in this study. "} 
}
@article{Rosburg2014123,
title = {"Retrieving self-vocalized information: An event-related potential (ERP) study on the effect of retrieval orientation "},
journal = {"Brain and Cognition "},
volume = {"92"},
number = {""},
pages = {"123 - 132"},
year = {"2014"},
note = {""},
issn = {"0278-2626"},
doi = {"https://doi.org/10.1016/j.bandc.2014.10.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0278262614001663"},
author = {"Timm Rosburg and Mikael Johansson and Volker Sprondel and Axel Mecklinger"},
keywords = {"Episodic memory", "Reality monitoring", "Event-related potential (ERP)", "Source memory", "Strategic retrieval "},
abstract = {"Abstract Retrieval orientation refers to a pre-retrieval process and conceptualizes the specific form of processing that is applied to a retrieval cue. In the current event-related potential (ERP) study, we sought to find evidence for an involvement of the auditory cortex when subjects attempt to retrieve vocalized information, and hypothesized that adopting retrieval orientation would be beneficial for retrieval accuracy. During study, participants saw object words that they subsequently vocalized or visually imagined. At test, participants had to identify object names of one study condition as targets and to reject object names of the second condition together with new items. Target category switched after half of the test trials. Behaviorally, participants responded less accurately and more slowly to targets of the vocalize condition than to targets of the imagine condition. \{ERPs\} to new items varied at a single left electrode (T7) between 500 and 800 ms, indicating a moderate retrieval orientation effect in the subject group as a whole. However, whereas the effect was strongly pronounced in participants with high retrieval accuracy, it was absent in participants with low retrieval accuracy. A current source density (CSD) mapping of the retrieval orientation effect indicated a source over left temporal regions. Independently from retrieval accuracy, the \{ERP\} retrieval orientation effect was surprisingly also modulated by test order. Findings are suggestive for an involvement of the auditory cortex in retrieval attempts of vocalized information and confirm that adopting retrieval orientation is potentially beneficial for retrieval accuracy. The effects of test order on retrieval-related processes might reflect a stronger focus on the newness of items in the more difficult test condition when participants started with this condition. "} 
}
@article{Mourão201535,
title = {"Multimodal medical information retrieval with unsupervised rank fusion "},
journal = {"Computerized Medical Imaging and Graphics "},
volume = {"39"},
number = {""},
pages = {"35 - 45"},
year = {"2015"},
note = {"Medical visual information analysis and retrieval "},
issn = {"0895-6111"},
doi = {"https://doi.org/10.1016/j.compmedimag.2014.05.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895611114000664"},
author = {"André Mourão and Flávio Martins and João Magalhães"},
keywords = {"Medical search", "Search interfaces", "Assisted query formulation", "Multimodal retrieval", "Data fusion "},
abstract = {"Abstract Modern medical information retrieval systems are paramount to manage the insurmountable quantities of clinical data. These systems empower health care experts in the diagnosis of patients and play an important role in the clinical decision process. However, the ever-growing heterogeneous information generated in medical environments poses several challenges for retrieval systems. We propose a medical information retrieval system with support for multimodal medical case-based retrieval. The system supports medical information discovery by providing multimodal search, through a novel data fusion algorithm, and term suggestions from a medical thesaurus. Our search system compared favorably to other systems in 2013 ImageCLEFMedical. "} 
}
@article{Rajput201738,
title = {"Optical double image security using random phase fractional Fourier domain encoding and phase-retrieval algorithm "},
journal = {"Optics Communications "},
volume = {"388"},
number = {""},
pages = {"38 - 46"},
year = {"2017"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2016.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401816309671"},
author = {"Sudheesh K. Rajput and Naveen K. Nishchal"},
keywords = {"Image encryption", "Double random phase encoding", "Fractional Fourier transform", "Phase retrieval algorithm", "Phase truncation "},
abstract = {"Abstract We propose a novel security scheme based on the double random phase fractional domain encoding (DRPE) and modified Gerchberg-Saxton (G-S) phase retrieval algorithm for securing two images simultaneously. Any one of the images to be encrypted is converted into a phase-only image using modified G-S algorithm and this function is used as a key for encrypting another image. The original images are retrieved employing the concept of known-plaintext attack and following the \{DRPE\} decryption steps with all correct keys. The proposed scheme is also used for encryption of two color images with the help of convolution theorem and phase-truncated fractional Fourier transform. With some modification, the scheme is extended for simultaneous encryption of gray-scale and color images. As a proof-of-concept, simulation results have been presented for securing two gray-scale images, two color images, and simultaneous gray-scale and color images. "} 
}
@article{Zhu2017229,
title = {"Integration of semantic and visual hashing for image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"44"},
number = {""},
pages = {"229 - 235"},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.08.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316301729"},
author = {"Songhao Zhu and Dongliang Jin and Zhiwei Liang and Qiang Wang and Yajie Sun and Guozheng Xu"},
keywords = {"Image retrieval", "Semantic similarity", "Visual structure", "Hashing code "},
abstract = {"Abstract With the rapid proliferation of large-scale web images, recent years have witnessed more and more images labeled with user-provided tags, which leads to considerable effort made on hashing based image retrieval in huge databases. Current research efforts focus mostly on learning semantic hashing functions which design compact binary codes to map semantically similar images into similar codes; however the visual similarity is not well explored for constructing semantic hashing functions. Here a novel approach is proposed to learn hashing functions that preserve semantic and visual similarity between images. Specifically, semantic hashing codes are first learned by leveraging the similarity between textual structure and visual structure; then, the maximum entropy principle is exploited to achieve compact binary codes; finally, the function decay principle is introduced to remove noisy visual attributes. Experimental results conducted on a widely-used image dataset demonstrate the superior performance of the proposed method over the examined state-of-the-art techniques. "} 
}
@article{Rodriguez201610,
title = {"Improving information retrieval in functional analysis "},
journal = {"Computers in Biology and Medicine "},
volume = {"79"},
number = {""},
pages = {"10 - 20"},
year = {"2016"},
note = {""},
issn = {"0010-4825"},
doi = {"https://doi.org/10.1016/j.compbiomed.2016.09.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S001048251630244X"},
author = {"Juan C. Rodriguez and Germán A. González and Cristóbal Fresno and Andrea S. Llera and Elmer A. Fernández"},
keywords = {"Big omics data", "Gene set enrichment analysis", "Functional class scoring", "Over representation analysis", "Singular enrichment analysis", "Biological insight", "Knowledge discovery", "Breast cancer", "R framework "},
abstract = {"Abstract Transcriptome analysis is essential to understand the mechanisms regulating key biological processes and functions. The first step usually consists of identifying candidate genes; to find out which pathways are affected by those genes, however, functional analysis (FA) is mandatory. The most frequently used strategies for this purpose are Gene Set and Singular Enrichment Analysis (GSEA and SEA) over Gene Ontology. Several statistical methods have been developed and compared in terms of computational efficiency and/or statistical appropriateness. However, whether their results are similar or complementary, the sensitivity to parameter settings, or possible bias in the analyzed terms has not been addressed so far. Here, two \{GSEA\} and four \{SEA\} methods and their parameter combinations were evaluated in six datasets by comparing two breast cancer subtypes with well-known differences in genetic background and patient outcomes. We show that \{GSEA\} and \{SEA\} lead to different results depending on the chosen statistic, model and/or parameters. Both approaches provide complementary results from a biological perspective. Hence, an Integrative Functional Analysis (IFA) tool is proposed to improve information retrieval in FA. It provides a common gene expression analytic framework that grants a comprehensive and coherent analysis. Only a minimal user parameter setting is required, since the best SEA/GSEA alternatives are integrated. \{IFA\} utility was demonstrated by evaluating four prostate cancer and the \{TCGA\} breast cancer microarray datasets, which showed its biological generalization capabilities. "} 
}
@article{Helmy20151071,
title = {"Health, Food and User's Profile Ontologies for Personalized Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"52"},
number = {""},
pages = {"1071 - 1076"},
year = {"2015"},
note = {"The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.05.114"},
url = {"http://www.sciencedirect.com/science/article/pii/S187705091500914X"},
author = {"Tarek Helmy and Ahmed Al-Nazer and Saeed Al-Bukhitan and Ali Iqbal"},
keywords = {"Ontology Integration", "Semanic Web", "Personalized Retrieval. "},
abstract = {"Abstract As we aim to retrieve personalized information to user's queries related to food, health and nutrition domains such as “Is apple good for people with heart diseases?”, “How much honey can be taken by a diabetic patient?”, “What are the health benefits of eating pineapple?” and “What are the fruits that contain the daily need quantity of calcium?” The information retrieval system needs to integrate ontologies from different domains such as food, nutrition, health (diseases, body parts, body functions) and recipe in order to answer such kind of queries. In addition, to support multilingual queries, the system and ontologies require aggregation of information from multi-level ontologies. Also, to achieve high relevancy and coverage we need to use ontologies that have comprehensive and rich vocabularies. Moreover, to make effective use for the annotation, ontologies concept names should be unique and self-contained. The main focus of this paper is to integrate ontologies from food, health and nutrition domains to help the personalized information systems to retrieve food and heath recommendations based on the user's health conditions and food preferences. Such ontologies that satisfy these requirements do not explicitly exist. Therefore, we were challenged to develop these ontologies by creating, integrating and reusing some of the existing ontologies to meet our requirements. "} 
}
@article{Ma201729,
title = {"Manifold-ranking embedded order preserving hashing for image semantic retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"44"},
number = {""},
pages = {"29 - 39"},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2017.01.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320317300123"},
author = {"Lei Ma and Hongliang Li and Fanman Meng and Qingbo Wu and Linfeng Xu"},
keywords = {"Manifold ranking", "Hashing", "Image semantic retrieval "},
abstract = {"Abstract Due to the storage and computational efficiency of hashing technology, it has proven a valuable tool for large scale similarity search. In many cases, the large scale data in real-world lie near some (unknown) low-dimensional and non-linear manifold. Moreover, Manifold Ranking approach can preserve the global topological structure of the data set more effectively than Euclidean Distance-based Ranking approach, which fails to preserve the semantic relevance degree. However, most existing hashing methods ignore the global topological structure of the data set. The key issue is how to incorporate the global topological structure of data set into learning effective hashing function. In this paper, we propose a novel unsupervised hashing approach, namely Manifold-Ranking Embedded Order Preserving Hashing (MREOPH). A manifold ranking loss is introduced to solve the issue of global topological structure preserving. An order preserving loss is introduced to ensure the consistency between manifold ranking and hamming ranking. A hypercubic quantization loss is introduced to learn discrete binary codes. The information theoretic regularization term is taken into consideration for preserving desirable properties of hash codes. Finally, we integrate them in a joint optimization framework for minimizing the information loss in each processing. Experimental results on three datasets for semantic search clearly demonstrate the effectiveness of the proposed method. "} 
}
@article{Wang201729,
title = {"Learning and retrieval processes predict fluid intelligence over and above working memory "},
journal = {"Intelligence "},
volume = {"61"},
number = {""},
pages = {"29 - 36"},
year = {"2017"},
note = {""},
issn = {"0160-2896"},
doi = {"https://doi.org/10.1016/j.intell.2016.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S016028961630232X"},
author = {"Tengfei Wang and Xuezhu Ren and Karl Schweizer"},
keywords = {"Learning", "Long-term memory retrieval", "Working memory", "Fluid intelligence "},
abstract = {"Abstract Previous studies have shown that the ability to learn and the ability to retrieve relevant information from long-term memory are closely related to fluid intelligence. However, it remains unclear whether the effect of learning and retrieval processes on intelligence is unique or merely due to the variance shared with working memory. The current study attempted to achieve a relatively purified representation of learning and retrieval processes and to examine whether they predict fluid intelligence beyond working memory. A sample of 220 university students completed a rule-based learning task, the Posner task, two working memory tasks and two fluid intelligence scales. Fixed-links models were used to separate the core processes representing learning and retrieval from the auxiliary processes and to link them with fluid intelligence. Results showed that the learning and retrieval processes contributed significantly to fluid intelligence (r = 0.38 and − 0.35 respectively). More importantly, both learning and retrieval processes were still predictive of fluid intelligence when working memory was controlled for. These results suggest that the ability to learn abstract rules and the efficiency of retrieving information from long-term memory are two essential components underlying fluid intelligence in addition to working memory. "} 
}
@article{Guo2017,
title = {"SOR: An optimized semantic ontology retrieval algorithm for heterogeneous multimedia big data "},
journal = {"Journal of Computational Science "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1877-7503"},
doi = {"https://doi.org/10.1016/j.jocs.2017.02.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S187775031730176X"},
author = {"Kehua Guo and Zhonghe Liang and Yayuan Tang and Tao Chi"},
keywords = {"Ontology", "Semantic-based retrieval", "MapReduce", "Multimedia big data", "Big data retrieval", "Retrieval algorithm "},
abstract = {"Abstract Semantic information can express the search intentions of users, and this approach has become an important tool in the field of information retrieval. To support semantic-based multimedia retrieval in big data environment, this paper presents an optimized algorithm called semantic ontology retrieval (SOR), which uses big data processing tools to store and retrieve ontologies from heterogeneous multimedia data. First, the background of semantic extraction and ontology representation for multimedia big data are addressed. Second, the methodology of SOR, including the model definition and retrieval algorithm, is proposed. Third, for parallel processing \{SOR\} in distributed nodes, a MapReduce-based retrieval framework is presented. Finally, to achieve high retrieval precision and good user experience, a user feedback scheme is designed. The experimental results illustrate that \{SOR\} is suitable for semantic-based retrieval for heterogeneous multimedia big data. "} 
}
@article{Zhang20171663,
title = {"Avoiding errors attributable to topography in GPS-IR snow depth retrievals "},
journal = {"Advances in Space Research "},
volume = {"59"},
number = {"6"},
pages = {"1663 - 1669"},
year = {"2017"},
note = {""},
issn = {"0273-1177"},
doi = {"https://doi.org/10.1016/j.asr.2016.12.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0273117716307530"},
author = {"Shuangcheng Zhang and Xiaolei Wang and Qin Zhang"},
keywords = {"GPS-IR", "Snow depth retrievals", "Surface fluctuation "},
abstract = {"Abstract Global Positioning System (GPS) interferometric reflectometry represents a potential source of new snow data for climate scientists and water managers with spatial and temporal sensitivity. Generally, the snow layer fluctuation is considered to be correlated with the ground surface fluctuation. The reflector heights in terms of the signal-to-noise ratio (SNR) are quite close to the vertical distance between the antenna and the ground or snow level at the corresponding Fresnel zone. The reflector heights at different zones were represented by a grid model in this work, which can reflect and overcome some of the problems caused by the topography. The proposed method for snow depth retrievals looks for good quality reflector height values of the horizontal reflecting zone in the grid model, and with this method improvements in snow depth retrieval accuracy were achieved (RMSE: 7.40 cm, Corr.: 0.99) compared to the \{PBO\} \{H2O\} group calculation results (RMSE: 16.58 cm, Corr.: 0.99). "} 
}
@article{Larrosa2017,
title = {"Retrieval under stress decreases the long-term expression of a human declarative memory via reconsolidation "},
journal = {"Neurobiology of Learning and Memory "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2017.03.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742717300370"},
author = {"Pablo Nicolás Fernández Larrosa and Alejandro Ojea and Ignacio Ojea and Victor Alejandro Molina and María Aurelia Zorrilla-Zubilete and Alejandro Delorenzi"},
keywords = {"Memory", "Retrieval", "Memory expression", "Reconsolidation", "Reactivation "},
abstract = {"Abstract Acute stress impairs memory retrieval of several types of memories. An increase in glucocorticoids, several minutes after stressful events, is described as essential to the impairing retrieval-effects of stressors. Moreover, memory retrieval under stress can have long-term consequences. Through what process does the reactivated memory under stress, despite the disrupting retrieval effects, modify long-term memories? The reconsolidation hypothesis proposes that a previously consolidated memory reactivated by a reminder enters a vulnerability phase (labilization) during which it is transiently sensitive to modulation, followed by a re-stabilization phase. However, previous studies show that the expression of memories during reminder sessions is not a condition to trigger the reconsolidation process since unexpressed memories can be reactivated and labilized. Here we evaluate whether it is possible to reactivate-labilize a memory under the impairing-effects of a mild stressor. We used a paradigm of human declarative memory whose reminder structure allows us to differentiate between a reactivated-labile memory state and a reactivated but non-labile state. Subjects memorized a list of five cue-syllables associated with their respective response-syllables. Seventy-two hours later, results showed that the retrieval of the paired-associate memory was impaired when tested 20 min after a mild stressor (cold pressor stress (CPS)) administration, coincident with cortisol levels increase. Then, we investigated the long-term effects of \{CPS\} administration prior to the reminder session. Under conditions where the reminder initiates the reconsolidation process, \{CPS\} impaired the long-term memory expression tested 24 h later. In contrast, \{CPS\} did not show effects when administered before a reminder session that does not trigger reconsolidation. Results showed that memory reactivation-labilization occurs even when retrieval was impaired. Memory reactivation under stress could hinder -via reconsolidation- the probability of the traces to be expressed in the long term. "} 
}
@article{Song2017,
title = {"Quantization-based hashing: a general framework for scalable image and video retrieval "},
journal = {"Pattern Recognition "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2017.03.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320317301322"},
author = {"Jingkuan Song and Lianli Gao and Li Liu and Xiaofeng Zhu and Nicu Sebe"},
keywords = {"Hashing", "Pseudo labels", "Multimedia retrieval "},
abstract = {"Abstract Nowadays, due to the exponential growth of user generated images and videos, there is an increasing interest in learning-based hashing methods. In computer vision, the hash functions are learned in such a way that the hash codes can preserve essential properties of the original space (or label information). Then the Hamming distance of the hash codes can approximate the data similarity. On the other hand, vector quantization methods quantize the data into different clusters based on the criteria of minimal quantization error, and then perform the search using look-up tables. While hashing methods using Hamming distance can achieve faster search speed, their accuracy is often outperformed by quantization methods with the same code length, due to the low quantization error and more flexible distance lookups. To improve the effectiveness of the hashing methods, in this work, we propose Quantization-based Hashing (QBH), a general framework which incorporates the advantages of quantization error reduction methods into conventional property preserving hashing methods. The learned hash codes simultaneously preserve the properties in the original space and reduce the quantization error, and thus can achieve better performance. Furthermore, the hash functions and a quantizer can be jointly learned and iteratively updated in a unified framework, which can be readily used to generate hash codes or quantize new data points. Importantly, \{QBH\} is a generic framework that can be integrated to different property preserving hashing methods and quantization strategies, and we apply \{QBH\} to both unsupervised and supervised hashing models as showcases in this paper. Experimental results on three large-scale unlabeled datasets (i.e., SIFT1M, GIST1M, and SIFT1B), three labeled datastes (i.e., ESPGAME, \{IAPRTC\} and MIRFLICKR) and one video dataset (UQ_VIDEO) demonstrate the superior performance of our \{QBH\} over existing unsupervised and supervised hashing methods. "} 
}
@article{Kalloubi2016138,
title = {"Microblog semantic context retrieval system based on linked open data and graph-based theory "},
journal = {"Expert Systems with Applications "},
volume = {"53"},
number = {""},
pages = {"138 - 148"},
year = {"2016"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2016.01.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417416000300"},
author = {"Fahd Kalloubi and El Habib Nfaoui and Omar El beqqali"},
keywords = {"Information retrieval", "Semantic similarity", "Linked open data", "DBpedia", "Named entity linking", "Graph centrality "},
abstract = {"Abstract Microblogging platforms have emerged as large collections of short documents. In fact, the provision of an effective way to retrieve short text presents a significant research challenge owing to several factors: creative language usage, high contextualization, the informal nature of micro blog posts and the limited length of this form of communication. Thus, micro blogging retrieval systems suffer from the problems of data sparseness and the semantic gap. This makes it inadequate to accurately meet users’ information needs because users compose tweets using few terms and without query terms inside; thus, many relevant tweets will not be retrieved. To overcome the problems of data sparseness and the semantic gap, recent studies on content-based microblog searching have focused on adding semantics to micro posts by linking short text to knowledge bases resources. Moreover, previous studies use bag-of-concepts representation by linking named entities to their corresponding knowledge base concepts. However, bag-of-concepts representation considers only concepts that match named entities and supposes that all concepts are equivalent and independent. Thus, in this paper, we present a graph-of-concepts method that considers the relationships among concepts that match named entities in short text and their related concepts and contextualizes each concept in the graph by leveraging the linked nature of \{DBpedia\} as a Linked Open Data knowledge base and graph-based centrality theory. Furthermore, we propose a similarity measure that computes the similarity between two graphs (query-tweet) by considering the relationships between the contextualized concepts. Finally, we introduce some experiment results, using a real Twitter dataset, to expose the effectiveness of our system. "} 
}
@article{Alsmadi2017,
title = {"An efficient similarity measure for content based image retrieval using memetic algorithm "},
journal = {"Egyptian Journal of Basic and Applied Sciences "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2314-808X"},
doi = {"https://doi.org/10.1016/j.ejbas.2017.02.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S2314808X16300628"},
author = {"Mutasem K. Alsmadi"},
keywords = {"Color signature", "Color texture", "Content based image retrieval (CBIR)", "Neutrosophic", "Memetic algorithm", "Shape feature", "Similarity measure "},
abstract = {"Abstract Content based image retrieval (CBIR) systems work by retrieving images which are related to the query image (QI) from huge databases. The available \{CBIR\} systems extract limited feature sets which confine the retrieval efficacy. In this work, extensive robust and important features were extracted from the images database and then stored in the feature repository. This feature set is composed of color signature with the shape and color texture features. Where, features are extracted from the given \{QI\} in the similar fashion. Consequently, a novel similarity evaluation using a meta-heuristic algorithm called a memetic algorithm (genetic algorithm with great deluge) is achieved between the features of the \{QI\} and the features of the database images. Our proposed \{CBIR\} system is assessed by inquiring number of images (from the test dataset) and the efficiency of the system is evaluated by calculating precision-recall value for the results. The results were superior to other state-of-the-art \{CBIR\} systems in regard to precision. "} 
}
@article{Xu201745,
title = {"Large-scale image retrieval with supervised sparse hashing "},
journal = {"Neurocomputing "},
volume = {"229"},
number = {""},
pages = {"45 - 53"},
year = {"2017"},
note = {"Advances in computing techniques for big medical image data "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.05.109"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216313741"},
author = {"Yan Xu and Fumin Shen and Xing Xu and Lianli Gao and Yuan Wang and Xiao Tan"},
keywords = {"Learning based hashing", "Medical", "Sparsity", "Image retrieval "},
abstract = {"Abstract In recent years, learning based hashing becomes an attractive technique in large-scale image retrieval due to its low storage and computation cost. Hashing methods map each high-dimensional vector onto a low-dimensional hamming space by projection operators. However, when processing high dimensional data retrieval, many existing methods including hashing cost a majority of time on projection operators. In this paper, we solve this problem by implementing a sparsity regularizer. On one hand, due to the sparse property of the projection matrix, our method effectively lower both the storage and computation cost. On the other hand, we reduce the effective number of parameters involved in the learned projection matrix according to sparsity regularizer, which helps avoid overfitting problem. Without relaxing binary constraints, an iterative scheme jointly optimizing the objective function directly was given, which helps to obtain effective and efficient binary codes. We evaluate our method on three databases and compare it with some state-of-the-art hashing methods. Experimental results demonstrate that our method outperforms the comparison approaches. "} 
}
@article{Parrens201773,
title = {"Considering combined or separated roughness and vegetation effects in soil moisture retrievals "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"55"},
number = {""},
pages = {"73 - 86"},
year = {"2017"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2016.11.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243416301866"},
author = {"Marie Parrens and Jean-Pierre Wigneron and Philippe Richaume and Ahmad Al Bitar and Arnaud Mialon and Roberto Fernandez-Moran and Amen Al-Yaari and Peggy O’Neill and Yann Kerr"},
keywords = {"Soil moisture", "Soil roughness", "SMOS", "L-band", "Retrievals", "Optical vegetation depth "},
abstract = {"Abstract For more than six years, the Soil Moisture and Ocean Salinity (SMOS) mission has provided multi angular and full-polarization brightness temperature (TB) measurements at L-band. Geophysical products such as soil moisture (SM) and vegetation optical depth at nadir (τnad) are retrieved by an operational algorithm using \{TB\} observations at different angles of incidence and polarizations. However, the quality of the retrievals depends on several surface effects, such as vegetation, soil roughness and texture, etc. In the microwave forward emission model used in the retrievals (L-band Microwave Emission Model, L-MEB), soil roughness is modelled with a semi-empirical equation using four main parameters (Qr, Hr, Nrp, with p = H or V polarizations). At present, these parameters are calibrated with data provided by airborne studies and in situ measurements made at a local scale that is not necessarily representative of the large \{SMOS\} footprints (43 km on average) at global scale. In this study, we evaluate the impact of the calibrated values of Nrp and Hr on the \{SM\} and τnad retrievals based on \{SMOS\} \{TB\} measurements (SMOS Level 3 product) over the Soil Climate Analysis Network (SCAN) network located in North America over five years (2011–2015). In this study, Qr was set equal to zero and we assumed that NrH = NrV. The retrievals were performed by varying Nrp from −1 to 2 by steps of 1 and Hr from 0 to 0.6 by steps of 0.1. At satellite scale, the results show that combining vegetation and roughness effects in a single parameter provides the best results in terms of soil moisture retrievals, as evaluated against the in situ \{SM\} data. Even though our retrieval approach was very simplified, as we did not account for pixel heterogeneity, the accuracy we obtained in the \{SM\} retrievals was almost systematically better than those of the Level 3 product. Improved results were also obtained in terms of optical depth retrievals. These new results may have key consequences in terms of calibration of roughness effects within the algorithms of the \{SMOS\} (ESA) and the \{SMAP\} (NASA) space missions. "} 
}
@article{Bril2017258,
title = {"EOF-based regression algorithm for the fast retrieval of atmospheric \{CO2\} total column amount from the \{GOSAT\} observations "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"189"},
number = {""},
pages = {"258 - 266"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316304484"},
author = {"Аndrey Bril and Shamil Maksyutov and Dmitry Belikov and Sergey Oshchepkov and Yukio Yoshida and Nicholas M. Deutscher and David Griffith and Frank Hase and Rigel Kivi and Isamu Morino and Justus Notholt and David F. Pollard and Ralf Sussmann and Voltaire A. Velazco and Thorsten Warneke"},
keywords = {"Carbon dioxide", "Retrieval algorithm", "Empirical orthogonal function", "GOSAT", "TCCON "},
abstract = {"Abstract This paper presents a novel retrieval algorithm for the rapid retrieval of the carbon dioxide total column amounts from high resolution spectra in the short wave infrared (SWIR) range observations by the Greenhouse gases Observing Satellite (GOSAT). The algorithm performs \{EOF\} (Empirical Orthogonal Function)-based decomposition of the measured spectral radiance and derives the relationship of limited number of the decomposition coefficients in terms of the principal components with target gas amount and a priori data such as airmass, surface pressure, etc. The regression formulae for retrieving target gas amounts are derived using training sets of collocated \{GOSAT\} and ground-based observations. The precision/accuracy characteristics of the algorithm are analyzed by the comparison of the retrievals with those from the Total Carbon Column Observing Network (TCCON) measurements and with the modeled data, and appear similar to those achieved by full-physics retrieval algorithms. "} 
}
@article{Millman201464,
title = {"Mismatch and lexical retrieval gestures are associated with visual information processing, verbal production, and symptomatology in youth at high risk for psychosis "},
journal = {"Schizophrenia Research "},
volume = {"158"},
number = {"1–3"},
pages = {"64 - 68"},
year = {"2014"},
note = {""},
issn = {"0920-9964"},
doi = {"https://doi.org/10.1016/j.schres.2014.06.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0920996414002989"},
author = {"Zachary B. Millman and James Goss and Jason Schiffman and Johana Mejias and Tina Gupta and Vijay A. Mittal"},
keywords = {"Gesture", "UHR", "Prodromale cognition", "Lexical retrieval", "Speech–gesture mismatches "},
abstract = {"AbstractIntroduction Gesture is integrally linked with language and cognitive systems, and recent years have seen a growing attention to these movements in patients with schizophrenia. To date, however, there have been no investigations of gesture in youth at ultra high risk (UHR) for psychosis. Examining gesture in \{UHR\} individuals may help to elucidate other widely recognized communicative and cognitive deficits in this population and yield new clues for treatment development. Method In this study, mismatch (indicating semantic incongruency between the content of speech and a given gesture) and retrieval (used during pauses in speech while a person appears to be searching for a word or idea) gestures were evaluated in 42 \{UHR\} individuals and 36 matched healthy controls. Cognitive functions relevant to gesture production (i.e., speed of visual information processing and verbal production) as well as positive and negative symptomatologies were assessed. Results Although the overall frequency of cases exhibiting these behaviors was low, \{UHR\} individuals produced substantially more mismatch and retrieval gestures than controls. The \{UHR\} group also exhibited significantly poorer verbal production performance when compared with controls. In the patient group, mismatch gestures were associated with poorer visual processing speed and elevated negative symptoms, while retrieval gestures were associated with higher speed of visual information-processing and verbal production, but not symptoms. Conclusions Taken together these findings indicate that gesture abnormalities are present in individuals at high risk for psychosis. While mismatch gestures may be closely related to disease processes, retrieval gestures may be employed as a compensatory mechanism. "} 
}
@article{Cui2017,
title = {"Hybrid textual-visual relevance learning for content-based image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2017.03.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320317300731"},
author = {"Chaoran Cui and Peiguang Lin and Xiushan Nie and Yilong Yin and Qingfeng Zhu"},
keywords = {"Content-based image retrieval", "Tag completion", "Semantics modeling", "Rank aggregation", "Sparse linear method "},
abstract = {"Abstract Learning effective relevance measures plays a crucial role in improving the performance of content-based image retrieval (CBIR) systems. Despite extensive research efforts for decades, how to discover and incorporate semantic information of images still poses a formidable challenge to real-world \{CBIR\} systems. In this paper, we propose a novel hybrid textual-visual relevance learning method, which mines textual relevance from image tags and combines textual relevance and visual relevance for CBIR. To alleviate the sparsity and unreliability of tags, we first perform tag completion to fill the missing tags as well as correct noisy tags of images. Then, we capture users’ semantic cognition to images by representing each image as a probability distribution over the permutations of tags. Finally, instead of early fusion, a ranking aggregation strategy is adopted to sew up textual relevance and visual relevance seamlessly. Extensive experiments on two benchmark datasets well verified the promise of our approach. "} 
}
@article{Elash201775,
title = {"The sensitivity to polarization in stratospheric aerosol retrievals from limb scattered sunlight measurements "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"189"},
number = {""},
pages = {"75 - 85"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.11.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316304976"},
author = {"B.J. Elash and A.E. Bourassa and L.A. Rieger and S.R. Dueck and D.J. Zawada and D.A. Degenstein"},
keywords = {"Stratosphere", "Aerosol", "Limb scattering", "Retrieval", "Polarization "},
abstract = {"Abstract Satellite measurements of limb scattered sunlight at visible and near infrared wavelengths have been used successfully for several years to retrieve the vertical profile of stratospheric aerosol extinction coefficient. The existing satellite measurements are of the total radiance, with very little knowledge or impact of the polarization state of the limb radiance. Recently proposed instrument concepts for stratospheric aerosol profiling have been designed to measure the linearly polarized radiance. Yet, to date, the impact of the polarized measurement on the retrievals has not been systematically studied. Here we use a fully spherical, multiple scattering radiative transfer model to perform a sensitivity study on the effects of the polarized measurement on stratospheric aerosol extinction retrievals through specific investigations of the aerosol signal fraction in polarized measurements, potential retrieval bias, and achievable precision. In this study,we simulate both total and linearly polarized measurements, for a wide range of limb viewing geometries that are encountered in typical low earth orbits and for various aerosol loading scenarios. The orientation of the linear polarization with respect to the horizon is also studied. Taking into account instrument signal to noise levels it is found that in general, the linear polarization can be used as effectively as the total radiance measurement, with consideration of instrument signal to noise capabilities; however the horizontal polarization is more promising in terms of signal magnitude. "} 
}
@article{Gao2017,
title = {"Real-time social media retrieval with spatial, temporal and social constraints "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.11.078"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217304484"},
author = {"Lianli Gao and Yuan Wang and Dongsheng Li and Junming Shao and Jingkuan Song"},
keywords = {"Social media retrieval", "Inverted index", "Interval-at-a-time "},
abstract = {"Abstract Search in social network is continuously being expanded to enhance user experience. Besides basic textual retrieval, users can also search based on features such as spatial proximity, temporal freshness and/or social closeness. To efficiently process each advanced query type, customized indexing mechanisms have been developed. However, such mechanisms only perform well for the query types that they were designed for; moreover, they are not readily adaptable to support other query types. In this paper, we propose an interval-at-a-time (IAAT) framework as a first attempt to provide a one-size-fits-all solution to social media retrieval with spatial, temporal and social constraints. In addition, the algorithm relies on inverted index only, which makes it compatible with conventional search engines. The inverted lists are sorted by document id and the insertion is very fast because only append operation is involved. Experiments conducted on two large-scale Twitter datasets show that though \{IAAT\} is a unified strategy, it performs better than most of the state-of-the-art customized solutions in a variety of query types. "} 
}
@article{Liu2017,
title = {"3D models retrieval algorithm based on multimodal data "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.06.087"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217302564"},
author = {"Anan Liu and Wenhui Li and Weizhi Nie and Yuting Su"},
keywords = {"3D model retrieval", "Multimodal", "Multimodal fusion "},
abstract = {"Abstract With the development of computer vision in recent year, 3D models have been utilized in many applications, such as virtual reality, medical surgical, geographic information system. With the growth of 3D models, it is necessary to develop effective 3D model retrieval methods for data management. In this paper, we proposed a novel algorithm based on multimodal 3D model data to handle model retrieval problem. First, we extract structure information and visual information from each virtual 3D model. Then, a universal graph matching is employed to handle similarity measure in different modals respectively. Finally, a simple statistical model is utilized to handle similarity measure and finish retrieval process. The final comparing experiments demonstrate the superiority of our approach. "} 
}
@article{Li2017,
title = {"Kernel based latent semantic sparse hashing for large-scale retrieval from heterogeneous data sources "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.11.081"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217304538"},
author = {"Xiangpeng Li and Lianli Gao and Xing Xu and Jie Shao and Fumin Shen and Jingkuan Song"},
keywords = {"Hashing", "Cross-modal retrieval", "Sparse coding", "Matrix factorization", "Kernel method "},
abstract = {"Abstract Recent years, we have witnessed the growing popularity of integrating nearest neighbor search with hashing for effective and efficient similarity search. However, most of the previous cross-modal hashing methods didn’t consider the semantic correlation between multi-modal representations and directly project the heterogeneous data into a joint space using a linear projection. To address these challenges and bridge the semantic gap more efficiently. We proposed a method named kernel based latent semantic sparse hashing (KLSSH) in this paper. We firstly capture high-level latent semantic information and then use the equivalence between optimizing the code inner products and the Hamming distances. More specifically, \{KLSSH\} firstly employs sparse coding for obtaining primary latent features of image and matrix factorization for generating features of text concepts to learn latent semantic features in a high level abstraction space. Next, it maps the latent semantic feature to compact binary codes using kernel method. Kernel scheme ensures to sequentially and efficiently train the hash functions one bit at a time and then generate very short and discriminative hash codes. Moreover, it reduces the quantization loss obviously at the same time and makes the retrieval performance better. Experiments conducted on three benchmark multi-modal datasets demonstrate the superiority of our proposed method compared with the state-of-the-art techniques. "} 
}
@article{Tabia2017,
title = {"Learning shape retrieval from different modalities "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.01.101"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217304617"},
author = {"Hedi Tabia and Hamid Laga"},
keywords = {"Multimodal 3D retrieval", "Convolutional Neural Networks", "3D shape", "Object retrieval", "Sketch retrieval "},
abstract = {"Abstract We propose in this paper a new framework for 3D shape retrieval using queries of different modalities, which can include 3D models, images and sketches. The main scientific challenge is that different modalities have different representations and thus lie in different spaces. Moreover, the features that can be extracted from 2D images or 2D sketches are often different from those that can be computed from 3D models. Our solution is a new method based on Convolutional Neural Networks (CNN) that embeds all these entities into a common space. We propose a novel 3D shape descriptor based on local \{CNN\} features encoded using vectors of locally aggregated descriptors instead of conventional global CNN. Using a kernel function computed from 3D shape similarity, we build a target space in which wild images and sketches can be projected via two different CNNs. With this construction, matching can be performed in the common target space between same entities (sketch–sketch, image–image and 3D shape–3D shape) and more importantly across different entities (sketch-image, sketch-3D shape and image-3D shape). We demonstrate the performance of the proposed framework using different benchmarks including large scale \{SHREC\} 3D datasets. "} 
}
@article{Chen2017,
title = {"Supervised hashing with adaptive discrete optimization for multimedia retrieval "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.10.088"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217304526"},
author = {"Sixiu Chen and Fumin Shen and Yang Yang and Xing Xu and Jingkuan Song"},
keywords = {"Hashing", "Adaptive discrete optimization", "Multimedia retrieval "},
abstract = {"Abstract Hashing techniques show significant advantage in dealing with enormous high-dimensional image and multimedia data. Specifically, learning based hashing methods attract a lot of attention from researchers thanks to its great performance in image retrieval. But discrete constraint problem of learning based hashing methods makes the optimization extremely difficult, which can be shown to be \{NP\} hard. Thus, most of learning based hashing methods relax the constraint and get a suboptimal result. Recently, some researchers propose discrete optimization hashing techniques to learn hash bits without any relaxation and achieve promising results. But, discrete optimization hashing method like Supervised Discrete Hashing (SDH) roughly renews all binary codes and leads to a time-consuming problem. In this paper, we propose an adaptive discrete cyclic coordinate descent (ACC) method to effectively solve discrete optimization problem. The specific objective of our study is to boost the efficiency of discrete hash optimization with equivalent performance. We evaluate the proposed method on image and multimedia databases: CIFAR-10, NUS-WIDE and MIRFLickr-25k and show that our method achieves speed-up over compared the state-of-the-art methods, while having on-par and in some cases even better performance. "} 
}
@article{Moen2017181,
title = {"Selective attention meets spontaneous recognition memory: Evidence for effects at retrieval "},
journal = {"Consciousness and Cognition "},
volume = {"49"},
number = {""},
pages = {"181 - 189"},
year = {"2017"},
note = {""},
issn = {"1053-8100"},
doi = {"https://doi.org/10.1016/j.concog.2017.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053810016302124"},
author = {"Katherine C. Moen and Jeremy K. Miller and Marianne E. Lloyd"},
keywords = {"Selective attention", "Recognition memory", "Test order", "Encoding", "Retrieval "},
abstract = {"Abstract Previous research on the effects of Divided Attention on recognition memory have shown consistent impairments during encoding but more variable effects at retrieval. The present study explored whether effects of Selective Attention at retrieval and subsequent testing were parallel to those of Divided Attention. Participants studied a list of pictures and then had a recognition memory test that included both full attention and selective attention (the to be responded to object was overlaid atop a blue outlined object) trials. All participants then completed a second recognition memory test. The results of 2 experiments suggest that subsequent tests consistently show impacts of the status of the ignored stimulus, and that having an initial test changes performance on a later test. The results are discussed in relation to effect of attention on memory more generally as well as spontaneous recognition memory research. "} 
}
@article{Lian201711,
title = {"Transfer orthogonal sparsifying transform learning for phase retrieval "},
journal = {"Digital Signal Processing "},
volume = {"62"},
number = {""},
pages = {"11 - 25"},
year = {"2017"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2016.10.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S105120041630183X"},
author = {"Qiusheng Lian and Baoshun Shi and Shuzhen Chen"},
keywords = {"Sparsifying transform learning", "Phase retrieval", "Image processing", "Transfer learning "},
abstract = {"Abstract The phase retrieval (PR) problem of recovering an image from its Fourier magnitudes is an important issue. Several \{PR\} algorithms have been proposed to address this problem. Recent efforts of exploiting sparsity were developed to improve the performance of \{PR\} algorithms, such as the reconstruction quality, robustness to noise, and convergence behavior. In this paper, we propose a novel sparsity-based algorithm, which can adaptively learn an orthogonal sparsifying transform, and reconstruct the image simultaneously from the Fourier magnitudes. However, the estimated images at the early iterations are extremely bad. Training samples from these images cannot provide much useful information for sparsifying transform learning. To avoid unnecessary updating, an orthogonal sparsifying transform learning method based on transfer learning is proposed. Through transfer learning, we transfer the fixed sparsifying transform to an adaptive one. We apply this new sparsifying transform learning method to PR, and exploit the alternating directions method of multipliers (ADMM) technique to solve the formulated problem. Since the learnt sparsifying transform is adaptive to data, it favors better sparsity. Using this learnt sparsifying transform for image reconstruction can improve the reconstruction quality at low oversampling ratios. Experimental results show that the proposed \{PR\} algorithm can improve nearly 6 dB compared with the recently proposed PR-TIHP- l 1 algorithm in terms of the average \{PSNR\} (Peak Signal to Noise Ratio) at oversampling ratio 2.47, 2.53, 2.59. Moreover, our algorithm is robust to noise and has better convergence behavior heuristically. "} 
}
@article{Qin2017104,
title = {"Fast action retrieval from videos via feature disaggregation "},
journal = {"Computer Vision and Image Understanding "},
volume = {"156"},
number = {""},
pages = {"104 - 116"},
year = {"2017"},
note = {"Image and Video Understanding in Big Data "},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2016.09.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314216301436"},
author = {"Jie Qin and Li Liu and Mengyang Yu and Yunhong Wang and Ling Shao"},
keywords = {"Similarity search", "Video retrieval", "Feature disaggregation", "Learning based hashing "},
abstract = {"Abstract Learning based hashing methods, which aim at learning similarity-preserving binary codes for efficient nearest neighbor search, have been actively studied recently. A majority of the approaches address hashing problems for image collections. However, due to the extra temporal information, videos are usually represented by much higher dimensional (thousands or even more) features compared with images, causing high computational complexity for conventional hashing schemes. In this paper, we propose a simple and efficient hashing scheme for high-dimensional video data. This method, called Disaggregation Hashing (DH), exploits the correlations among different feature dimensions. An intuitive feature disaggregation method is first proposed, followed by a novel hashing algorithm based on different feature clusters. Additionally, a kernelized version of \{DH\} is proposed for better performance. We demonstrate the efficiency and effectiveness of our method by theoretical analysis and exploring its application on action retrieval from video databases. Extensive experiments show the superiority of our binary coding scheme over state-of-the-art hashing methods. "} 
}
@article{Berthier2017235,
title = {"Simultaneous \{CT\} angiography and whole-body \{CT\} is an effective imaging approach before multiorgan retrieval "},
journal = {"Diagnostic and Interventional Imaging "},
volume = {"98"},
number = {"3"},
pages = {"235 - 243"},
year = {"2017"},
note = {""},
issn = {"2211-5684"},
doi = {"https://doi.org/10.1016/j.diii.2016.05.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211568416301516"},
author = {"E. Berthier and C. Ridereau-Zins and L. Dubé and P. Tchouante and C. Nedelcu and S. Lasocki and C. Aubé"},
keywords = {"Computed tomography", "Organ donation", "Donor selection. Multiorgan retrieval "},
abstract = {"AbstractPurpose To assess the role of whole-body computed tomography (CT) for determining morphological suitability before multiorgan retrieval (MOR) in brain dead patients. Materials and methods Fifty-one clinically brain dead patients (21 women, 30 men; mean age 61 year ± 15) were included in this prospective, single center study. All patients had \{CT\} angiography of the brain and whole-body \{CT\} examination. \{CT\} images were evaluated for the presence of morphological abnormalities of lungs, liver and other abdominal organs and presence of vascular anatomical variants. The results of \{CT\} examinations were compared to intraoperative findings observed during organ harvesting and/or the results of histopathological analysis of biopsy specimens. The impact of whole-body \{CT\} examination on the harvesting process was evaluated. Results Ninety-five percent of vascular anatomical variants that were found intraoperatively were depicted on CT. \{CT\} density measurements predicted surgical finding of steatosis in 80% of patients. Whole-body \{CT\} changed the \{MOR\} strategy in 21/51 patients (41%) including 3 \{MOR\} cancellations and 8 grafts refusals, whereas organ harvesting was continued in 10 patients after histopathological analysis was performed. Conclusion Selection of potential graft donors using whole-body \{CT\} is reliable and improves graft selection during MOR. "} 
}
@article{Tauber2017,
title = {"Does Covert Retrieval Benefit Learning of Key-Term Definitions? "},
journal = {"Journal of Applied Research in Memory and Cognition "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2211-3681"},
doi = {"https://doi.org/10.1016/j.jarmac.2016.10.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211368116301292"},
author = {"Sarah K. Tauber and Amber E. Witherby and John Dunlosky and Katherine A. Rawson and Adam L. Putnam and Henry L. Roediger III"},
keywords = {"Covert retrieval", "Retrieval practice", "Key-term definitions", "Monitoring of learning", "Metacognition "},
abstract = {"Even though retrieval practice typically has a robust, positive influence on memory, response format (overt vs. covert retrieval) may moderate its effect when students learn complex material. Overt retrieval is likely to promote exhaustive retrieval, whereas covert retrieval may not be exhaustive for familiar key terms. In two experiments, students were instructed to study key-term definitions and were asked to practice retrieval overtly, to practice retrieval covertly, or to restudy the definitions. Students also made metacognitive judgments. A final criterion test was administered two days later. Students’ final recall was greater after overt retrieval practice than after covert retrieval practice or restudy, with a continuously cumulating meta-analysis establishing the effect as moderate in size (pooled d = 0.43). Thus, response format does matter for learning definitions of key terms, supporting the recommendation that students use overt retrieval when using retrieval practice as a strategy to learn complex materials. "} 
}
@article{Bu2017,
title = {"3D shape recognition and retrieval based on multi-modality deep learning "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.06.088"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217302576"},
author = {"Shuhui Bu and Lei Wang and Pengcheng Han and Zhenbao Liu and Ke Li"},
keywords = {"3D shape", "Recognition", "Retrieval", "Deep learning", "Multi modality "},
abstract = {"Abstract For 3D shape analysis, an effective and efficient feature is the key to popularize its applications in 3D domain where the major challenge lies in designing an effective high-level feature. The three-dimensional shape contains various useful information including visual information, geometric relationships, and other type properties. Thus the strategy of exploring these characteristics is the core of extracting effective 3D shape features. In this paper, we propose a novel 3D feature learning framework which combines different modality data effectively to promote the discriminability of uni-modal feature by using deep learning. The geometric information and visual information are extracted by Convolutional Neural Networks (CNNs) and Convolutional Deep Belief Networks (CDBNs), respectively, and then two independent Deep Belief Networks (DBNs) are employed to learn high-level features from geometric and visual features. Finally, a Restricted Boltzmann Machine (RBM) is trained for mining the deep correlations between different modalities. Extensive experiments demonstrate that the proposed framework achieves better performance. "} 
}
@article{Carpenter2017128,
title = {"The role of mediator strength in learning from retrieval "},
journal = {"Journal of Memory and Language "},
volume = {"92"},
number = {""},
pages = {"128 - 141"},
year = {"2017"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2016.06.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X16300535"},
author = {"Shana K. Carpenter and Kam Leung Yeung"},
keywords = {"Testing effect", "Retrieval practice", "Elaborative retrieval", "Mediators "},
abstract = {"Abstract Previous studies have provided support for the idea that information activated during retrieval can act as a mediator that facilitates later recall of a target. Evidence for this has been obtained from a paradigm involving independent cues in which participants initially learn cue-target pairs through retrieval (Mother: _____) or restudying (Mother: Child), and later show stronger benefits of retrieval over restudy in recalling targets from final test cues that are strongly related to the original cue (Father: _____) compared to cues that are unrelated to the original cues (Birth: _____). The current study used a new paradigm to explore the role of mediators in learning from retrieval by comparing the advantage of retrieval over restudying for cue-target pairs that varied in mediator strength (i.e., the strength of the strongest first associate to the cue). Across three experiments, items higher in mediator strength (e.g., Chalk: Crayon, with Chalk producing its strongest first associate Board at a rate of .69) produced stronger testing effects than items lower in mediator strength (e.g., Soup: Onion, with Soup producing its strongest first associate Chicken at a rate of .10). Item analyses revealed that mediator strength was positively associated with final test recall of items learned through retrieval but not through restudying, and this relationship held after controlling for other linguistic properties of the cues. "} 
}
@article{Patricio2017202,
title = {"\{M1\} muscarinic receptors are necessary for retrieval of remote context fear memory "},
journal = {"Physiology & Behavior "},
volume = {"169"},
number = {""},
pages = {"202 - 207"},
year = {"2017"},
note = {""},
issn = {"0031-9384"},
doi = {"https://doi.org/10.1016/j.physbeh.2016.12.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031938416306217"},
author = {"Rafael Rodisanski Patricio and Juliana Carlota Kramer Soares and Maria Gabriela Menezes Oliveira"},
keywords = {"Fear conditioning", "Inhibitory avoidance", "Memory retrieval", "Remote memory", "M1 receptor", "Acetylcholine "},
abstract = {"Abstract Several studies have investigated the transition of consolidation of recent memory to remote memory in aversively motivated tasks, such as contextual fear conditioning (CFC) and inhibitory avoidance (IA). However, the mechanisms that serve the retrieval of remote memories, has not yet been fully understood. Some evidences suggest that the central cholinergic system appears be involved in the modulation of these processes. Therefore, the present study aimed to investigate the effects of a pre-test administration of dicyclomine, a high-affinity \{M1\} muscarinic receptor antagonist, on the retrieval of remote memories in fear conditioning and \{IA\} tasks. Male Wistar rats were trained, and after 1 or 28 days, the rats received dicyclomine (16 or 32 mg/kg, intraperitoneally, i.p.) and were tested in CFC, tone fear conditioning (TFC) and \{IA\} tasks. At both time intervals, 32 mg/kg dicyclomine induced impairment of CFC. In \{TFC\} task only the performance of the rats 28 days after training was impaired. The \{IA\} task was not affected in any of the studied intervals. These findings suggest a differential contribution of muscarinic receptors on recent and remote memories retrieval revealing a more generalized role in remote memory. "} 
}
@article{Bansal2016330,
title = {"Design and development of semantic web-based system for computer science domain-specific information retrieval "},
journal = {"Perspectives in Science "},
volume = {"8"},
number = {""},
pages = {"330 - 333"},
year = {"2016"},
note = {"Recent Trends in Engineering and Material Sciences "},
issn = {"2213-0209"},
doi = {"https://doi.org/10.1016/j.pisc.2016.04.067"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213020916300891"},
author = {"Ritika Bansal and Sonal Chawla"},
keywords = {"Semantic Web", "Ontology", "SPARQL", "Protégé", "QUEPY "},
abstract = {"Summary In semantic web-based system, the concept of ontology is used to search results by contextual meaning of input query instead of keyword matching. From the research literature, there seems to be a need for a tool which can provide an easy interface for complex queries in natural language that can retrieve the domain-specific information from the ontology. This research paper proposes an \{IRSCSD\} system (Information retrieval system for computer science domain) as a solution. This system offers advanced querying and browsing of structured data with search results automatically aggregated and rendered directly in a consistent user-interface, thus reducing the manual effort of users. So, the main objective of this research is design and development of semantic web-based system for integrating ontology towards domain-specific retrieval support. Methodology followed is a piecemeal research which involves the following stages. First Stage involves the designing of framework for semantic web-based system. Second stage builds the prototype for the framework using Protégé tool. Third Stage deals with the natural language query conversion into \{SPARQL\} query language using Python-based \{QUEPY\} framework. Fourth Stage involves firing of converted \{SPARQL\} queries to the ontology through Apache's Jena \{API\} to fetch the results. Lastly, evaluation of the prototype has been done in order to ensure its efficiency and usability. Thus, this research paper throws light on framework development for semantic web-based system that assists in efficient retrieval of domain-specific information, natural language query interpretation into semantic web language, creation of domain-specific ontology and its mapping with related ontology. This research paper also provides approaches and metrics for ontology evaluation on prototype ontology developed to study the performance based on accessibility of required domain-related information. "} 
}
@incollection{Bäuml2017,
title = {"Retrieval-Induced Remembering and Forgetting "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.21048-1"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245210481"},
author = {"Karl-Heinz T. Bäuml and Oliver Kliegl"},
keywords = {"Age", "Blocking", "Context change", "Context reactivation", "Individual differences", "Inhibition", keywords =Output interference", "Retrieval practice", "Retrieval-induced forgetting", "Retrieval-induced remembering", "Selective retrieval", "Testing effect", "Two faces of retrieval", "Working memory capacity "},
abstract = {"Abstract Selectively retrieving a subset of previously studied information enhances memory of the retrieved information but can cause forgetting of nonretrieved information. This chapter reviews the literature on such retrieval-induced forgetting (RIF), asking whether the forgetting depends on testing format, is retrieval specific and interference dependent, is modulated by retention interval after selective retrieval, and varies between individuals. The most prominent theoretical accounts of \{RIF\} are introduced and evaluated against the empirical findings. Also some more recent studies are reviewed, which indicate that, under certain conditions, selective retrieval can also improve memory of the nonretrieved information. "} 
}
@article{Strunk2017,
title = {"Age-related changes in neural oscillations supporting context memory retrieval "},
journal = {"Cortex "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2017.01.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945217300345"},
author = {"Jonathan Strunk and Taylor James and Jason Arndt and Audrey Duarte"},
keywords = {"Context memory", "Retrieval", "Aging", "Theta", "Beta "},
abstract = {"Abstract Recent evidence suggests that directing attention toward single item-context associations during encoding improves young and older adults' context memory performance and reduces demands on executive functions during retrieval. In everyday situations, there are many event features competing for our attention, and our ability to successfully recover those details may depend on our ability to ignore others. Failures of selective attention may contribute to older adults' context memory impairments. In the current electroencephalogram (EEG) study, we assessed the effects of age on processes supporting successful context memory retrieval of selectively attended features as indexed by neural oscillations. During encoding, young and older adults were directed to attend to a picture of an object and its relationship to one of two concurrently presented contextual details: a color or scene. At retrieval, we tested their memory for the object, its attended and unattended context features, and their confidence for both the attended and unattended features. Both groups showed greater memory for attended than unattended contextual features. However, older adults showed evidence of hyper-binding between attended and unattended context features while the young adults did not. \{EEG\} results in the theta band suggest that young and older adults recollect similar amounts of information but brain-behavior correlations suggest that this information was supportive of contextual memory performance, particularly for young adults. By contrast, sustained beta desynchronization, indicative of sensory reactivation and episodic reconstruction, was correlated with contextual memory performance for older adults only. We conclude that older adults' inhibition deficits during encoding reduced the selectivity of their contextual memories, which led to reliance on executive functions like episodic reconstruction to support successful memory retrieval. "} 
}
@article{Kundu2017209,
title = {"Interactive radiographic image retrieval system "},
journal = {"Computer Methods and Programs in Biomedicine "},
volume = {"139"},
number = {""},
pages = {"209 - 220"},
year = {"2017"},
note = {""},
issn = {"0169-2607"},
doi = {"https://doi.org/10.1016/j.cmpb.2016.10.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169260716301766"},
author = {"Malay Kumar Kundu and Manish Chowdhury and Sudeb Das"},
keywords = {"Content based medical image retrieval", "Pulse couple neural network", "Multiscale geometric analysis", "Relevance feedback", "Fuzzy logic", "Radiographic images "},
abstract = {"AbstractBackground and Objective Content based medical image retrieval (CBMIR) systems enable fast diagnosis through quantitative assessment of the visual information and is an active research topic over the past few decades. Most of the state-of-the-art \{CBMIR\} systems suffer from various problems: computationally expensive due to the usage of high dimensional feature vectors and complex classifier/clustering schemes. Inability to properly handle the “semantic gap” and the high intra-class versus inter-class variability problem of the medical image database (like radiographic image database). This yields an exigent demand for developing highly effective and computationally efficient retrieval system. Methods We propose a novel interactive two-stage \{CBMIR\} system for diverse collection of medical radiographic images. Initially, Pulse Coupled Neural Network based shape features are used to find out the most probable (similar) image classes using a novel “similarity positional score” mechanism. This is followed by retrieval using Non-subsampled Contourlet Transform based texture features considering only the images of the pre-identified classes. Maximal information compression index is used for unsupervised feature selection to achieve better results. To reduce the semantic gap problem, the proposed system uses a novel fuzzy index based relevance feedback mechanism by incorporating subjectivity of human perception in an analytic manner. Results Extensive experiments were carried out to evaluate the effectiveness of the proposed \{CBMIR\} system on a subset of Image Retrieval in Medical Applications (IRMA)-2009 database consisting of 10,902 labeled radiographic images of 57 different modalities. We obtained overall average precision of around 98% after only 2–3 iterations of relevance feedback mechanism. We assessed the results by comparisons with some of the state-of-the-art \{CBMIR\} systems for radiographic images. Conclusions Unlike most of the existing \{CBMIR\} systems, in the proposed two-stage hierarchical framework, main importance is given on constructing efficient and compact feature vector representation, search-space reduction and handling the “semantic gap” problem effectively, without compromising the retrieval performance. Experimental results and comparisons show that the proposed system performs efficiently in the radiographic medical image retrieval field. "} 
}
@article{Xu2017164,
title = {"A privacy-preserving content-based image retrieval method in cloud environment "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"43"},
number = {""},
pages = {"164 - 172"},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2017.01.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S104732031730007X"},
author = {"Yanyan Xu and Jiaying Gong and Lizhi Xiong and Zhengquan Xu and Jinwei Wang and Yun-qing Shi"},
keywords = {"Privacy-preserving", "Image retrieval", "Secure search", "Orthogonal decomposition "},
abstract = {"Abstract In order to protect data privacy, image with sensitive or private information needs to be encrypted before being outsourced to a cloud service provider. However, this causes difficulties in image retrieval and data management. A privacy-preserving content-based image retrieval method based on orthogonal decomposition is proposed in the paper. The image is divided into two different components, for which encryption and feature extraction are executed separately. As a result, cloud server can extract features from an encrypted image directly and compare them with the features of the queried images, so that users can thus obtain the image. Different from other methods, the proposed method has no special requirements to encryption algorithms, which makes it more universal and can be applied in different scenarios. Experimental results prove that the proposed method can achieve better security and better retrieval performance. "} 
}
@article{Bursa2015126,
title = {"Information retrieval from hospital information system: Increasing effectivity using swarm intelligence "},
journal = {"Journal of Applied Logic "},
volume = {"13"},
number = {"2, Part A"},
pages = {"126 - 137"},
year = {"2015"},
note = {"SI: \{SOCO12\} "},
issn = {"1570-8683"},
doi = {"https://doi.org/10.1016/j.jal.2014.11.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1570868314000809"},
author = {"Miroslav Bursa and Lenka Lhotska and Vaclav Chudacek and Jiri Spilka and Petr Janku and Lukas Hruban"},
keywords = {"Swarm intelligence", "Ant colony", "Textual data mining", "Medical record processing", "Hospital information system "},
abstract = {"Abstract This paper details the process of mining information from a hospital information system that has been designed approximately 15 years ago. The information is distributed within database tables in large textual attributes with a free structure. Information retrieval from these information is necessary for complementing cardiotocography signals with additional information that is to be implemented in a decision support system. The basic statistical overview (n-gram analysis) helped with the insight into data structure, however more sophisticated methods have to be used as human (and expert) processing of the whole data were out of consideration: over 620,000 text fields contained text reports in natural language with (many) typographical errors, duplicates, ambiguities, syntax errors and many (nonstandard) abbreviations. There was a strong need to efficiently determine the overall structure of the database and discover information that is important from the clinical point of view. We have used three different methods: k-means, self-organizing map and a self-organizing approach inspired by ant-colonies that performed clustering of the records. The records were visualized and revealed the most prominent information structure(s) that were consulted with medical experts and served for further mining from the database. The outcome of this task is a set of ordered or nominal attributes with a structural information that is available for rule discovery mining and automated processing for the research of asphyxia prediction during delivery. The proposed methodology has significantly reduced the processing time of loosely structured textual records for both \{IT\} and medical experts. "} 
}
@article{Guo2016122,
title = {"TMR: Towards an efficient semantic-based heterogeneous transportation media big data retrieval "},
journal = {"Neurocomputing "},
volume = {"181"},
number = {""},
pages = {"122 - 131"},
year = {"2016"},
note = {"Big Data Driven Intelligent Transportation Systems "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.06.101"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215018445"},
author = {"Kehua Guo and Ruifang Zhang and Li Kuang"},
keywords = {"Heterogeneous media retrieval", "Ontology", "Fuzzy matching", "Information retrieval", "Big data", "Intelligent transportation "},
abstract = {"Abstract In media retrieval system for intelligent transportation, media data variety and heterogeneity have been one of the most critical features. Documents with different formats may express similar semantic information, thus, searching documents reflecting users׳ intention has been a crucial and important task. For solving this problem, this paper proposes a novel semantic-based heterogeneous transportation media retrieval (TMR) approach to improve the performance. \{TMR\} supports the function of retrieving various media types such as image, video, audio and text by using a single media type. Firstly, semantic fields are extracted from the user annotating and automatic learning to express the users׳ intention. Secondly, ontology is used to represent the semantic fields of a media, and the ontology represented semantic information is saved together with the media document data. Thirdly, the semantic field adjustment process is described. Finally, fuzzy matching is employed to measure the similarity between the users׳ intention and media documents. For the returned results, we carry out the performance evaluation models in comparison with the existing approaches. Experimental result indicates the superiority of \{TMR\} in term of precision rate, computing speed, storage cost and user experience. "} 
}
@article{FernandezBeltran201672,
title = {"Latent topics-based relevance feedback for video retrieval "},
journal = {"Pattern Recognition "},
volume = {"51"},
number = {""},
pages = {"72 - 84"},
year = {"2016"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2015.09.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320315003386"},
author = {"Ruben Fernandez-Beltran and Filiberto Pla"},
keywords = {"Content-Based Video Retrieval", "Relevance feedback", "Latent topics", "Probabilistic Latent Semantic Analysis (pLSA)", "Information retrieval "},
abstract = {"Abstract This paper presents a novel Content-Based Video Retrieval approach in order to cope with the semantic gap challenge by means of latent topics. Firstly, a supervised topic model is proposed to transform the classical retrieval approach into a class discovery problem. Subsequently, a new probabilistic ranking function is deduced from that model to tackle the semantic gap between low-level features and high-level concepts. Finally, a short-term relevance feedback scheme is defined where queries can be initialised with samples from inside or outside the database. Several retrieval simulations have been carried out using three databases and seven different ranking functions to test the performance of the presented approach. Experiments revealed that the proposed ranking function is able to provide a competitive advantage within the content-based retrieval field. "} 
}
@article{Wang2017249,
title = {"Modeling intra- and inter-pair correlation via heterogeneous high-order preserving for cross-modal retrieval "},
journal = {"Signal Processing "},
volume = {"131"},
number = {""},
pages = {"249 - 260"},
year = {"2017"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2016.08.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168416301980"},
author = {"Leiquan Wang and Weichen Sun and Zhicheng Zhao and Fei Su"},
keywords = {"Cross-modal retrieval", "Heterogeneous high-order preserving", "Correlation learning", "Kernel "},
abstract = {"Abstract Cross modal (e.g., text-to-image or image-to-text) retrieval has received great attention with the flushed multi-modal social media data. It is of considerable challenge to stride across the heterogeneous gap between modalities. Existing methods project different modalities into a common space by minimizing the distance within the heterogeneous pairs (intra-pair) of the new latent space. However, the relationship among these multi-modal pairs (inter-pair) are neglected, which are beneficial to eliminate the heterogeneity. In this paper, we propose a novel algorithm based on canonical correlation analysis by considering the high-order relationship among pairs (HCCA) for cross-modal retrieval. Supervised with additional semantic labels and unsupervised without semantic labels are simultaneously considered by treating the intra- and inter-pair correlation discriminatively. Moreover, kernel tricks are also performed on \{HCCA\} to learn a non-linear projection, termed HKCCA. Extensive experiments conducted on three public datasets demonstrate the superiority of the proposed methods compared with the state-of-the-art approaches in cross modal retrieval. "} 
}
@incollection{Bäuml2017167,
title = {"Chapter Five - The Two Faces of Selective Memory Retrieval—Cognitive, Developmental, and Social Processes "},
editor = {"Brian H. Ross"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2017"},
volume = {"66"},
pages = {"167 - 209"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/bs.plm.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0079742116300196"},
author = {"Karl-Heinz T. Bäuml and Alp Aslan and Magdalena Abel"},
keywords = {"Blocking", "Context reactivation", "Episodic memory", "Inhibition", "Memory development", "Retrieval-induced facilitation", "Retrieval-induced forgetting", "Social recall "},
abstract = {"Abstract Numerous studies from the past five decades have shown that selective retrieval of some studied items can impair recall of other items. This chapter reviews more recent work, in which it is demonstrated that selective memory retrieval has two faces and that it can both impair and improve recall of other items. In this recent work, participants' access to study context during selective retrieval was experimentally manipulated and it was examined whether such manipulation influences the effects of selective retrieval. Access to study context was manipulated using listwise directed forgetting, context-dependent forgetting and time-dependent forgetting. The results consistently showed that selective retrieval impairs recall of other memories if access to study context during retrieval is largely maintained, but that selective retrieval can improve recall if study context access is impaired. The findings are explained by a two-factor account, which claims that, in general, selective retrieval does not only trigger inhibition and blocking but also triggers context reactivation processes. The proposal is that primarily inhibition and blocking operate when study context access during selective retrieval is largely maintained, whereas primarily context reactivation processes operate when study context access is impaired. Current findings on the two faces of selective retrieval are well consistent with this theoretical view. "} 
}
@article{Batur2017737,
title = {"Uyghur Printed Document Image Retrieval Based on \{SIFT\} Features "},
journal = {"Procedia Computer Science "},
volume = {"107"},
number = {""},
pages = {"737 - 742"},
year = {"2017"},
note = {"Advances in Information and Communication Technology: Proceedings of 7th International Congress of Information and Communication Technology (ICICT2017) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2017.03.157"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050917304325"},
author = {"Aliya Batur and Gulzira Tursun and Mutellip Mamut and Nurbiya Yadikar and Kurban Ubul"},
keywords = {"Document image", "Retrieval", "SIFT feature", "Distance ratio match "},
abstract = {"Abstract Image retrieval is an attractive topic in the field of information retrieval in electronic library and computer vision. This paper proposed a research in the field of Uyghur document image retrieval that using 128-dimensional \{SIFT\} features for Uyghur printed document images. Through the Euclidean distance ratio with different threshold to statistics the number of right and wrong matched points of \{SIFT\} feature key points to achieve the local feature based document image retrieval for 1000 Uyghur printed document images. Through experiment acquired around 995 right matched points of each Uyghur printed document image, where the total key points are 1418 and the 100% matching percentage, respectively. The experimental results indicate that the 128-dimension \{SIFT\} based image retrieval method is a kind of effective method for Uyghur document image. "} 
}
@article{Li201759,
title = {"Hierarchical multilevel authentication system for multiple-image based on phase retrieval and basic vector operations "},
journal = {"Optics and Lasers in Engineering "},
volume = {"89"},
number = {""},
pages = {"59 - 71"},
year = {"2017"},
note = {"3DIM-DS 2015: Optical Image Processing in the context of 3D Imaging, Metrology, and Data Security "},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.04.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616300665"},
author = {"Xianye Li and Xiangfeng Meng and Yongkai Yin and Xiulun Yang and Yurong Wang and Xiang Peng and Wenqi He and Xuemei Pan and Guoyan Dong and Hongyi Chen"},
keywords = {"Image authentication", "Phase retrieval", "Secret sharing", "Vector decomposition and composition "},
abstract = {"Abstract A hierarchical multilevel authentication system for multiple-image based on phase retrieval and basic vector operations in the Fresnel domain is proposed, by which more certification images are iteratively encoded into multiple cascaded phase masks according to different hierarchical levels. Based on the secret sharing algorithm by basic vector decomposition and composition operations, the iterated phase distributions are split into n pairs of shadow images keys (SIKs), and then distributed to n different participants (the authenticators). During each level in the high authentication process, any 2 or more participants can be gathered to reconstruct the original meaningful certification images. While in the case of each level in the low authentication process, only one authenticator who possesses a correct pair of SIKs, will gain no significant information of certification image; however, it can result in a remarkable peak output in the nonlinear correlation coefficient of the recovered image and the standard certification image, which can successfully provide an additional authentication layer for the high-level authentication. Theoretical analysis and numerical simulations both verify the feasibility of the proposed method. "} 
}
@incollection{Urcelay2017,
title = {"Retrieval From Memory☆ "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.21004-3"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245210043"},
author = {"Gonzalo P. Urcelay and Ralph R. Miller"},
keywords = {"Amnesia", "Conditioning", "Consolidation", "Cue competition", "Extinction", "Interference", "Memory", "Reconsolidation", "Retrieval", "State-dependent learning", "Theories of learning "},
abstract = {"Abstract Historically, most approaches to understanding learning and memory phenomena, particularly at the neurobiological level, have emphasized information processing that occurs during or soon after training (i.e., acquisition) as critical for observing learned changes in behavior. However, this view has been challenged by studies showing that at least part of the changes observed in behavior are due to constraints at the time of information retrieval. In this chapter, we first analyze behavioral evidence suggesting that retrieval processes, in addition to acquisition processes and storage mechanisms, are critical for observed changes in behavior due to past experience. Then we discuss theoretical approaches that emphasize retrieval processes to explain learning and memory. "} 
}
@article{Song201714,
title = {"A privacy-preserved full-text retrieval algorithm over encrypted data for cloud storage applications "},
journal = {"Journal of Parallel and Distributed Computing "},
volume = {"99"},
number = {""},
pages = {"14 - 27"},
year = {"2017"},
note = {""},
issn = {"0743-7315"},
doi = {"https://doi.org/10.1016/j.jpdc.2016.05.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0743731516300533"},
author = {"Wei Song and Bing Wang and Qian Wang and Zhiyong Peng and Wenjing Lou and Yihui Cui"},
keywords = {"Cloud computing", "Privacy-preserved full-text retrieval", "Hierarchical Bloom filter tree index", "Membership entropy "},
abstract = {"Abstract As Cloud Computing becomes prevalent, more and more sensitive information has been outsourced into cloud. A straightforward methodology that can protect data privacy is to encrypt the data before outsourcing. Recently, many searchable encryption schemes have been proposed to allow users to execute keyword-based search over encrypted data. However, it is different for users to exactly find all the interested files from the huge amounts of data by relying solely on keyword-based search. In information retrieval domain, full-text retrieval is an efficient information retrieval technology that allows efficient searches over massive amount of web data. Unfortunately, when applied in the cloud paradigm, full-text retrieval over encrypted cloud data have not been well studied. The full-text retrieval service requires extracting all the words in the contents of documents. The huge scale of index words cannot be efficiently supported by the existing searchable encryption schemes. Moreover, to protect user’s privacy, a privacy-preserved full-text retrieval index is required. These problems make efficient full-text retrieval over a large amount of encrypted cloud data a very challenging task. In this paper, we first establish a set of strict privacy requirements for full-text retrieval in cloud storage systems. To address the challenging problem, we design a Bloom filter based tree index. Our scheme fine-tunes the similarity between the query and encrypted documents by proposing the membership entropies of index words. Our scheme is provably secure through our security analysis. We demonstrate the effectiveness and efficiency of the proposed scheme through extensive experimental evaluation. The experimental results manifest the search operation can be done in 60 milliseconds using an off-the-shelf moderate PC. "} 
}
@article{Moral2017963,
title = {"A visual UML-based conceptual model of information-seeking by computer science researchers "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"4"},
pages = {"963 - 988"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.10.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645731630560X"},
author = {"Cristian Moral and Angelica De Antonio and Xavier Ferre"},
keywords = {"Information-seeking process", "Visual conceptual model", "Information retrieval", "Human-computer interaction", "Qualitative study analysis", "UML "},
abstract = {"Abstract The information-seeking process carried out by researchers is complex and full of different variables. We have represented this complexity for computer science researchers in the form of a conceptual model. The model is presented in a visual form using the \{UML\} modeling language, since it allows conveying all the complexity present in such a process with greater clarity. It has been obtained after carrying out two qualitative studies —a focus group and semi-structured interviews— with computer science researchers. The proposed overall model is composed of 4 sub-models: of the documents used in the process, of the tasks undertaken, of the user, and of the information-seeking process context. The conceptual model proposed can serve for the purpose of better understanding the information-seeking process, for example for librarians or for software designers wanting to provide a support to such task. It can also be useful as a framework to characterize different software solutions aimed to information-seeking in research activities, and to compare them. "} 
}
@article{Chen2017537,
title = {"An intelligent annotation-based image retrieval system based on \{RDF\} descriptions "},
journal = {"Computers & Electrical Engineering "},
volume = {"58"},
number = {""},
pages = {"537 - 550"},
year = {"2017"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2016.09.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S004579061630413X"},
author = {"Hua Chen and Antoine Trouve and Kazuaki J Murakami and Akira Fukuda"},
keywords = {"Image retrieval", "Image annotation", "Semantic image retrieval", "RDF "},
abstract = {"Abstract In this paper, we aim at improving text-based image search using Semantic Web technologies. We introduce our notions of concept and instance in order to better express the semantics of images, and present an intelligent annotation-based image retrieval system. We test our approach on the Flickr8k dataset. From the provided captions, we generate annotations at three levels (sentence, concept and instance). These annotations are stored as \{RDF\} triples and can be queried to find images. The experimental results show that using concepts and instances to annotate images flexibly can improve the intelligence of the image retrieval system: (1) with annotations at concept level, it enables to create semantic links between concepts and then addresses many challenges, such as the problems of synonyms and homonyms; (2) with annotations at instance level, it can count things (e.g., “two people”, “three animals”) or identify a same concept. "} 
}
@article{Nguyen201771,
title = {"Intra-relation or inter-relation?: Exploiting social information for Web document summarization "},
journal = {"Expert Systems with Applications "},
volume = {"76"},
number = {""},
pages = {"71 - 84"},
year = {"2017"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2017.01.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417417300325"},
author = {"Minh-Tien Nguyen and Minh-Le Nguyen"},
keywords = {"Data mining", "Information retrieval", "Document summarization", "Social context summarization", "RTE", "Ranking", "Unsupervised learning "},
abstract = {"Abstract Traditional summarization methods only use the internal information of a Web document while ignoring its social information such as tweets from Twitter, which can provide a perspective viewpoint for readers towards an event. This paper proposes a framework named SoRTESum to take the advantages of social information such as document content reflection to extract summary sentences and social messages. In order to do that, the summarization was formulated in two steps: scoring and ranking. In the scoring step, the score of a sentence or social message is computed by using intra-relation and inter-relation which integrate the support of local and social information in a mutual reinforcement form. To calculate these relations, 16 features are proposed. After scoring, the summarization is generated by selecting top m ranked sentences and social messages. SoRTESum was extensively evaluated on two datasets. Promising results show that: (i) SoRTESum obtains significant improvements of ROUGE-scores over state-of-the-art baselines and competitive results with the learning to rank approach trained by RankBoost and (ii) combining intra-relation and inter-relation benefits single-document summarization. "} 
}
@article{Tu2017276,
title = {"A peptide-retrieval strategy enables significant improvement of quantitative performance without compromising confidence of identification "},
journal = {"Journal of Proteomics "},
volume = {"152"},
number = {""},
pages = {"276 - 282"},
year = {"2017"},
note = {""},
issn = {"1874-3919"},
doi = {"https://doi.org/10.1016/j.jprot.2016.11.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S1874391916305000"},
author = {"Chengjian Tu and Shichen Shen and Quanhu Sheng and Yu Shyr and Jun Qu"},
keywords = {"MS1-based quantification", "Peptide-retrieval strategy", "Spectral counting "},
abstract = {"Abstract Reliable quantification of low-abundance proteins in complex proteomes is challenging largely owing to the limited number of spectra/peptides identified. In this study we developed a straightforward method to improve the quantitative accuracy and precision of proteins by strategically retrieving the less confident peptides that were previously filtered out using the standard target-decoy search strategy. The filtered-out MS/MS spectra matched to confidently-identified proteins were recovered, and the peptide-spectrum-match \{FDR\} were re-calculated and controlled at a confident level of \{FDR\} ≤ 1%, while protein \{FDR\} maintained at ~ 1%. We evaluated the performance of this strategy in both spectral count- and ion current-based methods. &gt; 60% increase of total quantified spectra/peptides was respectively achieved for analyzing a spike-in sample set and a public dataset from CPTAC. Incorporating the peptide retrieval strategy significantly improved the quantitative accuracy and precision, especially for low-abundance proteins (e.g. one-hit proteins). Moreover, the capacity of confidently discovering significantly-altered proteins was also enhanced substantially, as demonstrated with two spike-in datasets. In summary, improved quantitative performance was achieved by this peptide recovery strategy without compromising confidence of protein identification, which can be readily implemented in a broad range of quantitative proteomics techniques including label-free or labeling approaches. Significance We hypothesize that more quantifiable spectra and peptides in a protein, even including less confident peptides, could help reduce variations and improve protein quantification. Hence the peptide retrieval strategy was developed and evaluated in two spike-in sample sets with different LC-MS/MS variations using both MS1- and MS2-based quantitative approach. The list of confidently identified proteins using the standard target-decoy search strategy was fixed and more spectra/peptides with less confidence matched to confident proteins were retrieved. However, the total peptide-spectrum-match false discovery rate (PSM FDR) after retrieval analysis was still controlled at a confident level of \{FDR\} ≤ 1%. As expected, the penalty for occasionally incorporating incorrect peptide identifications is negligible by comparison with the improvements in quantitative performance. More quantifiable peptides, lower missing value rate, better quantitative accuracy and precision were significantly achieved for the same protein identifications by this simple strategy. This strategy is theoretically applicable for any quantitative approaches in proteomics and thereby provides more quantitative information, especially on low-abundance proteins. "} 
}
@article{Zhu2017201,
title = {"Tensor-resolved Raman spectroscopic analysis of wear-induced residual stress fields in long-term alumina hip-joint retrievals "},
journal = {"Journal of the Mechanical Behavior of Biomedical Materials "},
volume = {"66"},
number = {""},
pages = {"201 - 210"},
year = {"2017"},
note = {""},
issn = {"1751-6161"},
doi = {"https://doi.org/10.1016/j.jmbbm.2016.11.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1751616116303915"},
author = {"Wenliang Zhu and Elia Marin and Nobuhiko Sugano and Giuseppe Pezzotti"},
keywords = {"Raman spectroscopy", "alumina femoral head", "residual stress", "long term retrievals "},
abstract = {"Abstract Polarized Raman spectroscopy was applied to evaluate the full set of stress tensor components in the wear-induced residual stress fields on two long-term (&gt;20 y) (monolithic) alumina (Al2O3) femoral head retrievals coupled to polyethylene liners. The tensor-resolved residual stress state stored onto the Al2O3 ceramic head surface was found to retain “memory” of the sliding conditions in vivo and of the wear-induced consumption of the polyethylene counterpart. The evolution of tensor-resolved residual stress motifs in the three-dimensional space was examined, and key features, including exceptionally high shear stresses in one case, were uncovered. The effect of such a body of concurrent complications and malfunctioning are neither easily reproducible by in vitro simulations nor obviously obtainable through merely computational approaches. It is demonstrated here that our latest developments of Raman spectroscopic algorithms could contribute to link the joint performance with the micromechanical features that occur in real in vivo situations. "} 
}
@article{Makary201772,
title = {"Design-of-Experiments Approach to Improving Inferior Vena Cava Filter Retrieval Rates "},
journal = {"Journal of the American College of Radiology "},
volume = {"14"},
number = {"1"},
pages = {"72 - 77"},
year = {"2017"},
note = {""},
issn = {"1546-1440"},
doi = {"https://doi.org/10.1016/j.jacr.2016.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S154614401630758X"},
author = {"Mina S. Makary and Summit H. Shah and Shantanu Warhadpande and Ivan G. Vargas and James Sarbinoff and Joshua D. Dowell"},
keywords = {"Inferior vena cava filters", "filter retrieval", "clinic", "quality improvement "},
abstract = {"AbstractPurpose The association of retrievable inferior vena cava filters (IVCFs) with adverse events has led to increased interest in prompt retrieval, particularly in younger patients given the progressive nature of these complications over time. This study takes a design-of-experiments (DOE) approach to investigate methods to best improve filter retrieval rates, with a particular focus on younger (&lt;60 years) patients. Methods A \{DOE\} approach was executed in which combinations of variables were tested to best improve retrieval rates. The impact of a virtual \{IVCF\} clinic, primary care physician (PCP) letters, and discharge instructions was investigated. The decision for filter retrieval in group 1 was determined solely by the referring physician. Group 2 included those patients prospectively followed in an \{IVCF\} virtual clinic in which filter retrieval was coordinated by the interventional radiologist when clinically appropriate. In group 3, in addition to being followed through the \{IVCF\} clinic, each patient’s \{PCP\} was faxed a follow-up letter, and information regarding \{IVCF\} retrieval was added to the patient’s discharge instructions. Results A total of 10 \{IVCFs\} (8.4%) were retrieved among 119 retrievable \{IVCFs\} placed in group 1. Implementation of the \{IVCF\} clinic in group 2 significantly improved the retrieval rate to 25.3% (23 of 91 retrievable \{IVCFs\} placed, P &lt; .05). The addition of discharge instructions and \{PCP\} letters to the virtual clinic (group 3) resulted in a retrieval rate of 33.3% (17 of 51). The retrieval rates demonstrated more pronounced improvement when examining only younger patients, with retrieval rates of 11.3% (7 of 62), 29.5% (13 of 44, P &lt; .05), and 45.2% (14 of 31) for groups 1, 2, and 3, respectively. Conclusions \{DOE\} methodology is not routinely executed in health care, but it is an effective approach to evaluating clinical practice behavior and patient quality measures. In this study, implementation of the combination of a virtual clinic, \{PCP\} letters, and discharge instructions improved retrieval rates compared with a virtual clinic alone. Quality improvement strategies such as these that augment patient and referring physician knowledge on interventional radiologic procedures may ultimately improve patient safety and personalized care. "} 
}
@incollection{RoedigerIII2017,
title = {"Encoding–Retrieval Interactions "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.21036-5"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245210365"},
author = {"Henry L. Roediger III and Eylul Tekin and Oyku Uner"},
keywords = {"Context-dependent retrieval", "Encoding–retrieval paradigm", "Encoding specificity principle", "Memory experiment", "Mood-dependent retrieval", "State-dependent retrieval "},
abstract = {"Abstract The encoding–retrieval paradigm is instantiated when two (or more) conditions are manipulated during study (or encoding) and two or more types of tests are used to assess retention (retrieval tests). This type of experiment permits answers to two fundamental questions: Do effects of an encoding manipulation that occur on one test generalize across other tests? When encoding and retrieval conditions match on some dimension, does better performance occur than when they mismatch (in line with principles of encoding specificity and transfer-appropriate processing)? The encoding–retrieval paradigm is essential to progress in understanding memory. "} 
}
@article{Wang2017128,
title = {"Neural correlates of temporal context retrieval for abstract scrambled phrases: Reducing narrative and familiarity-based strategies "},
journal = {"Brain Research "},
volume = {"1655"},
number = {""},
pages = {"128 - 137"},
year = {"2017"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2016.11.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899316307661"},
author = {"Fang Wang and Rachel A. Diana"},
keywords = {"Temporal context retrieval", "Frontal cortex", "Medial temporal lobe "},
abstract = {"Abstract Temporal context, memory for the timing of events, can be assessed using non-temporal strategies such as relative familiarity or inference from a semantic narrative. Neuroimaging studies, which have previously encouraged such strategies, find similar patterns of brain regions involved in both temporal and non-temporal context memory. The present study aims to investigate whether previous findings are driven by the use of non-temporal strategies or whether the same pattern of brain regions is identified when relative familiarity and semantic narrative strategies are discouraged. We used abstract phrases (e.g. alone me leave) created by scrambling familiar three-word phrases. The words in the phrases were less concrete than the object image stimuli used in previous studies of temporal context memory (Jenkins and Ranganath, 2010) and were presented quickly while participants read each word aloud. This differed from previous studies in which participants were encouraged to use narrative strategies during encoding (Tubridy and Davachi, 2011) and was designed to discourage use of narrative strategies. The relative familiarity of the words within each phrase was similar and likely not diagnostic of word order during encoding, in order to minimize the use of relative familiarity strategies. Neuroimaging results indicate that temporal context retrieval was associated with the hippocampus, parahippocampal cortex, ventromedial prefrontal cortex, and retrosplenial cortex, which are regions consistent with the retrieval of non-temporal context in episodic memory, suggesting that previous findings were not driven entirely by non-temporal strategies but rather that temporal memory relies on similar brain regions to non-temporal memory. "} 
}
@article{Wang2017537,
title = {"Quantitative interferometric microscopy with two dimensional Hilbert transform based phase retrieval method "},
journal = {"Optics Communications "},
volume = {"383"},
number = {""},
pages = {"537 - 544"},
year = {"2017"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2016.10.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401816308707"},
author = {"Shouyu Wang and Keding Yan and Liang Xue"},
keywords = {"Quantitative interferometric microscopy", "Two dimensional Hilbert transform", "Phase retrieval "},
abstract = {"Abstract In order to obtain high contrast images and detailed descriptions of label free samples, quantitative interferometric microscopy combining with phase retrieval is designed to obtain sample phase distributions from fringes. As accuracy and efficiency of recovered phases are affected by phase retrieval methods, thus approaches owning higher precision and faster processing speed are still in demand. Here, two dimensional Hilbert transform based phase retrieval method is adopted in cellular phase imaging, it not only reserves more sample specifics compared to classical fast Fourier transform based method, but also overcomes disadvantages of traditional algorithm according to Hilbert transform which is a one dimensional processing causing phase ambiguities. Both simulations and experiments are provided, proving the proposed phase retrieval approach can acquire quantitative sample phases with high accuracy and fast speed. "} 
}
@article{Uzer201784,
title = {"The effect of cue content on retrieval from autobiographical memory "},
journal = {"Acta Psychologica "},
volume = {"172"},
number = {""},
pages = {"84 - 91"},
year = {"2017"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2016.11.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691816303699"},
author = {"Tugba Uzer and Norman R. Brown"},
keywords = {"Autobiographical memory", "Direct retrieval", "Retrieval processes "},
abstract = {"Abstract It has long been argued that personal memories are usually generated in an effortful search process in word-cueing studies. However, recent research (Uzer, Lee, &amp; Brown, 2012) shows that direct retrieval of autobiographical memories, in response to word cues, is common. This invites the question of whether direct retrieval phenomenon is generalizable beyond the standard laboratory paradigm. Here we investigated prevalence of direct retrieval of autobiographical memories cued by specific and individuated cues versus generic cues. In Experiment 1, participants retrieved memories in response to cues from their own life (e.g., the names of friends) and generic words (e.g., chair). In Experiment 2, participants provided their personal cues two or three months prior to coming to the lab (min: 75 days; max: 100 days). In each experiment, \{RT\} was measured and participants reported whether memories were directly retrieved or generated on each trial. Results showed that personal cues elicited a high rate of direct retrieval. Personal cues were more likely to elicit direct retrieval than generic word cues, and as a consequence, participants responded faster, on average, to the former than to the latter. These results challenge the constructive view of autobiographical memory and suggest that autobiographical memories consist of pre-stored event representations, which are largely governed by associative mechanisms. These demonstrations offer theoretically interesting questions such as why are we not overwhelmed with directly retrieved memories cued by everyday familiar surroundings? "} 
}
@article{Yang2017,
title = {"3D Model Retrieval using Constructive-Learning for Cross-Model Correlation "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.01.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217300747"},
author = {"Jianbai Yang and Jian Zhao and Qiang Sun"},
keywords = {"3D model retrieval", "Cross-model correlation", "Constructive-learning "},
abstract = {"Abstract With the advance of 3D technology and digital image processing technique, there have been a great number of applications of 3D models, such as virtual reality, computed aided design, and entertainment. Under such circumstance, much research attention has been spent on 3D model retrieval in recent decades. Although extensive research efforts have been dedicated to this task, it is a difficult task to explore the correlation among 3D models, which is the key issue in 3D model retrieval. In this paper, we design and implement a constructive-learning for cross-model correlation algorithm for 3D model retrieval. In this method, we first extract view features from multi-views of 3D models. To exploit the cross-model correlation, we formulate the correlation of 3D models in a hypergraph structure, where both the vertex correlation and the edge correlation are simultaneously learned in a constructive-learning process. Then, the correlation of each model to the query can be used for retrieval. To justify the performance of our proposed algorithm, we have implemented the method and tested on two datasets. We have compared it with recent state-of-the-art methods, and the results have shown superior performance of our proposed method. "} 
}
@article{Alonso2016386,
title = {"Evaluation of semantic similarity metrics applied to the automatic retrieval of medical documents: An \{UMLS\} approach "},
journal = {"Expert Systems with Applications "},
volume = {"44"},
number = {""},
pages = {"386 - 399"},
year = {"2016"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2015.09.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417415006569"},
author = {"Israel Alonso and David Contreras"},
keywords = {"Semantic similarity", "Information retrieval", "Electronic Health Record", "UMLS "},
abstract = {"Abstract One promise of current information retrieval systems is the capability to identify risk groups for certain diseases and pathologies based on the automatic analysis of vast amounts of Electronic Medical Records repositories. However, the complexity and the degree of specialization of the language used by the experts in this context, make this task both challenging and complex. In this work, we introduce a novel experimental study to evaluate the performance of the two semantic similarity metrics (Path and Intrinsic IC-Path, both widely accepted in the literature) in a real-life information retrieval situation. In order to achieve this goal and due to the lack of methodologies for this context in the literature, we propose a straightforward information retrieval system for the biomedical field based on the \{UMLS\} Metathesaurus and on semantic similarity metrics. In contrast with previous studies which focus on testbeds with limited and controlled sets of concepts, we use a large amount of information (101,712 medical documents extracted from \{TREC\} Medical Records Track 2011). Our results show that in real-life cases, both metrics display similar performance, Path (F-Measure = 0.430) e Intrinsic IC-Path (F-Measure = 0.427). Thereby we suggest that the use of Intrinsic IC-Path is not justified in real scenarios. "} 
}
@article{Sahnoun201736,
title = {"A simultaneous sparse approximation method for multidimensional harmonic retrieval "},
journal = {"Signal Processing "},
volume = {"131"},
number = {""},
pages = {"36 - 48"},
year = {"2017"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2016.07.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168416301803"},
author = {"Souleymen Sahnoun and El-Hadi Djermoune and David Brie and Pierre Comon"},
keywords = {"Multidimensional harmonic retrieval", "Frequency estimation", "Simultaneous sparse approximation", "Multigrid dictionary refinement", "Cramér–Rao lower bound "},
abstract = {"Abstract In this paper, a new method for the estimation of the parameters of multidimensional (R-D) harmonic and damped complex signals in noise is presented. The problem is formulated as R simultaneous sparse approximations of multiple 1-D signals. To get a method able to handle large size signals while maintaining a sufficient resolution, a multigrid dictionary refinement technique is associated to the simultaneous sparse approximation. The refinement procedure is proved to converge in the single R-D mode case. Then, for the general multiple modes case, the signal tensor model is decomposed in order to handle each mode separately in an iterative scheme. The proposed method does not require an association step since the estimated modes are automatically “paired”. We also derive the Cramér–Rao lower bounds of the parameters of modal R-D signals. The expressions are given in compact form in the single tone case. Finally, numerical simulations are conducted to demonstrate the effectiveness of the proposed method. "} 
}
@article{Liu2017749,
title = {"Image Retrieval Using Fused Deep Convolutional Features "},
journal = {"Procedia Computer Science "},
volume = {"107"},
number = {""},
pages = {"749 - 754"},
year = {"2017"},
note = {"Advances in Information and Communication Technology: Proceedings of 7th International Congress of Information and Communication Technology (ICICT2017) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2017.03.159"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050917304349"},
author = {"Hailong Liu and Baoan Li and Xueqiang Lv and Yue Huang"},
keywords = {"Deep learning", "Convolutional neural network", "Feature extraction", "Image retrieval", "Feature fusion "},
abstract = {"Abstract This paper proposes an image retrieval using fused deep convolutional features to solve the semantic gap between low-level features and high-level semantic features of traditional contend-based image retrieval method. Firstly, the improved network architecture LeNet-L is obtained by improving convolutional neural network LeNet-5. Then, fusing two different deep convolutional features which are extracted by LeNet-5 and AlexNet. Finally, after the fusion, the similar image is obtained through comparing the similarity between the image being retrieved and the image in database by distance function. In Corel dataset, this method is compared with the single convolutional neural network extracted features for image retrieval method, it has a higher precision and recall. The results show that this method has a better retrieval accuracy. "} 
}
@article{Sharma2016169,
title = {"An Ontology Based Framework for Retrieval of Museum Artifacts "},
journal = {"Procedia Computer Science "},
volume = {"84"},
number = {""},
pages = {"169 - 176"},
year = {"2016"},
note = {"Proceeding of the Seventh International Conference on Intelligent Human Computer Interaction (IHCI 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.04.083"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916300989"},
author = {"Manoj Kumar Sharma and Tanveer J. Siddiqui"},
keywords = {"Image retrieval", "Image analysis", "Image annotation", "Ontology", "Information retrieval", "Knowledge based system", "Knowledge sharing", "knowledge discovery "},
abstract = {"Abstract This paper proposes ontology based conceptual framework for storage and retrieval of Digitized Museum Artifacts. The proposed framework uses ontology structure for automatic image annotation. It supports semantic retrieval by combining ontological concepts, visual and textual features automatically extracted from images and their textual descriptions. The Ontology-driven analysis module automatically generates annotation for domain objects. This paper also reports a new dataset designed for its evaluation. The dataset consists of images displayed in various galleries of Allahabad museum along with their textual description. We have collected 1200 images and extracted their visual and textual features for the purpose of retrieval. "} 
}
@article{Doidge20171,
title = {"Separating content-specific retrieval from post-retrieval processing "},
journal = {"Cortex "},
volume = {"86"},
number = {""},
pages = {"1 - 10"},
year = {"2017"},
note = {"Is a "single" brain model sufficient? "},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2016.10.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945216302738"},
author = {"Amie N. Doidge and Lisa H. Evans and Jane E. Herron and Edward L. Wilding"},
keywords = {"Context reinstatement", "Episodic memory", "Content-specific retrieval", "Recollection "},
abstract = {"Abstract According to cortical reinstatement accounts, neural processes engaged at the time of encoding are re-engaged at the time of memory retrieval. The temporal precision of event-related potentials (ERPs) has been exploited to assess this possibility, and in this study \{ERPs\} were acquired while people made memory judgments to visually presented words encoded in two different ways. There were reliable differences between the scalp distributions of the signatures of successful retrieval of different contents from 300 to 1100 ms after stimulus presentation. Moreover, the scalp distributions of these content-sensitive effects changed during this period. These findings are, to our knowledge, the first demonstration in one study that \{ERPs\} reflect content-specific processing in two separable ways: first, via reinstatement, and second, via downstream processes that operate on recovered information in the service of memory judgments. "} 
}
@article{Faonio201723,
title = {"Fully leakage-resilient signatures revisited: Graceful degradation, noisy leakage, and construction in the bounded-retrieval model "},
journal = {"Theoretical Computer Science "},
volume = {"660"},
number = {""},
pages = {"23 - 56"},
year = {"2017"},
note = {""},
issn = {"0304-3975"},
doi = {"https://doi.org/10.1016/j.tcs.2016.11.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304397516306119"},
author = {"Antonio Faonio and Jesper Buus Nielsen and Daniele Venturi"},
keywords = {"Signature scheme", "Leakage resilience", "Noisy leakage", "Bounded retrieval model "},
abstract = {"Abstract We construct new leakage-resilient signature schemes. Our schemes remain unforgeable against an adversary leaking arbitrary (yet bounded) information on the entire state of the signer (sometimes known as fully leakage resilience), including the random coin tosses of the signing algorithm. The main feature of our constructions is that they offer a graceful degradation of security in situations where standard existential unforgeability is impossible. This property was recently put forward by Nielsen, Venturi, and Zottarel (PKC 2014) [19] to deal with settings in which the secret key is much larger than the size of a signature. One remarkable such case is the so-called Bounded-Retrieval Model (BRM), where one intentionally inflates the size of the secret key while keeping constant the signature size and the computational complexity of the scheme. Our main constructions have leakage rate 1 − o ( 1 ) , and are proven secure in the standard model. We additionally give a construction in the BRM, relying on a random oracle. All of our schemes are described in terms of generic building blocks, but also admit efficient instantiations under fairly standard number-theoretic assumptions. Finally, we explain how to extend some of our schemes to the setting of noisy leakage, where the only restriction on the leakage functions is that the output does not decrease the min-entropy of the secret key by too much. "} 
}
@article{Yanqing2017448,
title = {"Remote Sensing Image Content Retrieval Based on Frequency Spectral Energy "},
journal = {"Procedia Computer Science "},
volume = {"107"},
number = {""},
pages = {"448 - 453"},
year = {"2017"},
note = {"Advances in Information and Communication Technology: Proceedings of 7th International Congress of Information and Communication Technology (ICICT2017) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2017.03.088"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050917303630"},
author = {"Ding Yanqing and Yao Guoqing and Zhao Yanjie"},
keywords = {"Remote Sensing Image", "Frequency Domain Features", "Similarity Matching", "Image Retrieval "},
abstract = {"Abstract There are different research and processing methods for Image Content Retrieval. This article is described the retrieval of remote sensing images method, which is based on the image texture features of the Fourier power spectrum. Firstly, a fixed size remote sensing image unit is selected from the remote sensing image, which is converted to a spectral image by FFT, and extract the eigenvalues in the frequency domain to constitute a searchable image eigenvalue database. Secondly, the similarity between the feature and the database features are examined by the Angular Cosine Algorithm. Lastly, similarity of the resulting image are sorted to select the best match. This method converts the remote sensing image into a spectral image, and makes the selection of the eigenvalue more simple. The Angle Cosine similarity detection method with weight is used to make the similarity detection more accurate. "} 
}
@article{Srivastava201778,
title = {"Integration of wavelet transform, Local Binary Patterns and moments for content-based image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"42"},
number = {""},
pages = {"78 - 103"},
year = {"2017"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316302371"},
author = {"Prashant Srivastava and Ashish Khare"},
keywords = {"Image retrieval", "Discrete wavelet transform", "Local Binary Pattern", "Legendre moments "},
abstract = {"Abstract The proliferation of large number of images has made it necessary to develop systems for indexing and organizing images for easy access. This has made Content-Based Image Retrieval (CBIR) an important area of research in Computer Vision. This paper proposes a combination of features in multiresolution analysis framework for image retrieval. In this work, the concept of multiresolution analysis has been exploited through the use of wavelet transform. This paper combines Local Binary Pattern (LBP) with Legendre Moments at multiple resolutions of wavelet decomposition of image. First, \{LBP\} codes of Discrete Wavelet Transform (DWT) coefficients of images are computed to extract texture feature from image. The Legendre Moments of these \{LBP\} codes are then computed to extract shape feature from texture feature for constructing feature vectors. These feature vectors are used to search and retrieve visually similar images from large database. The proposed method has been tested on five benchmark datasets, namely, Corel-1K, Olivia-2688, Corel-5K, Corel-10K, and GHIM-10K, and performance of the proposed method has been measured in terms of precision and recall. The experimental results demonstrate that the proposed method outperforms some of the other state-of-the-art methods in terms of precision and recall. "} 
}
@article{Giveki2017242,
title = {"A new image feature descriptor for content based image retrieval using scale invariant feature transform and local derivative pattern "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"131"},
number = {""},
pages = {"242 - 254"},
year = {"2017"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.11.046"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616313766"},
author = {"Davar Giveki and Mohammad Ali Soltanshahi and Gholam Ali Montazer"},
keywords = {"Content based image retrieval", "SIFT", "HOG", "LBP", "LTP", "LDT "},
abstract = {"Abstract This paper presents a new methodology to retrieve images of different scenes by introducing a novel image descriptor. The proposed descriptor works with Scale Invariant Feature Transform (SIFT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Local Derivative Pattern (LDP), Local Ternary Pattern (LTP) and any other feature descriptor that can be applied on the image pixels. As the proposed descriptor considers a group of pixels together, higher level of semantic is achieved. In this work, a new image descriptor using \{SIFT\} and \{LDP\} is introduced that is able to find similarities and matches between images. The proposed descriptor produces highly discriminative features for describing image content. Four image datasets are used for evaluating our proposed descriptor. Comprehensive experiments have been conducted using various classifiers and different image features to show the superiority of the proposed method. "} 
}
@article{Leshem2017,
title = {"The discrete sign problem: Uniqueness, recovery algorithms and phase retrieval applications "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2016.12.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520316300987"},
author = {"Ben Leshem and Oren Raz and Ariel Jaffe and Boaz Nadler"},
keywords = {"Phase retrieval", "Signal reconstruction", "Compact support", "Sampling theory "},
abstract = {"Abstract In this paper we consider the following real-valued and finite dimensional specific instance of the 1-D classical phase retrieval problem. Let F ∈ R N be an N-dimensional vector, whose discrete Fourier transform has a compact support. The sign problem is to recover F from its magnitude | F | . First, in contrast to the classical 1-D phase problem which in general has multiple solutions, we prove that with sufficient over-sampling, the sign problem admits a unique solution. Next, we show that the sign problem can be viewed as a special case of a more general piecewise constant phase problem. Relying on this result, we derive a computationally efficient and robust to noise sign recovery algorithm. In the noise-free case and with a sufficiently high sampling rate, our algorithm is guaranteed to recover the true sign pattern. Finally, we present two phase retrieval applications of the sign problem: (i) vectorial phase retrieval with three measurement vectors; and (ii) recovery of two well separated 1-D objects. "} 
}
@article{Nakajima2017428,
title = {"Experimental demonstration of scanning phase retrieval by a noniterative method with a Gaussian-amplitude beam "},
journal = {"Optics Communications "},
volume = {"382"},
number = {""},
pages = {"428 - 436"},
year = {"2017"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2016.08.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401816307179"},
author = {"Nobuharu Nakajima and Masayuki Yoshino"},
keywords = {"Phase retrieval", "Scanning systems", "Coherent imaging "},
abstract = {"Abstract We present a proof-of-principle experiment of an analytic (noniterative) phase-retrieval method for coherent imaging systems under scanning illumination of a probe beam. This method allows to reconstruct the amplitude and phase distribution of a semi-transparent object over a wide area from intensities measured at three points in the Fourier plane of the object under scanning illumination of a known Gaussian-amplitude beam in the object plane. The present measurement system is very simple in contrast to ones of interferometric techniques, and also the speed of the calculation of phase retrieval in this method is faster than that in iterative algorithms since this method is based on an analytic solution to the phase retrieval. The effectiveness of this method is shown in experimental examples of the object reconstructions of a converging lens and a plastic plate for scratch standards. "} 
}
@article{Nechifor201520,
title = {"A flexible platform for synchronized measurements, data aggregation and information retrieval "},
journal = {"Electric Power Systems Research "},
volume = {"120"},
number = {""},
pages = {"20 - 31"},
year = {"2015"},
note = {"Smart Grids: World's Actual Implementations "},
issn = {"0378-7796"},
doi = {"https://doi.org/10.1016/j.epsr.2014.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378779614004076"},
author = {"Alexandru Nechifor and Mihaela Albu and Richard Hair and Vladimir Terzija"},
keywords = {"Communication infrastructure", "Data aggregation", "HTML5 visualization", "Java EE7", "OpenPDC", "Synchronized measurements "},
abstract = {"Abstract Synchronized measurements enable a number of applications, which shape most of the features of the smart grid paradigm. Phasor measurements units (PMUs) have an increasing role in power system state estimation, detection of inter-area and other low frequency oscillations, parameter identification, power system control and protection. Although standardization is in place for both information retrieval and data communication, there is a need to further optimize the way measurements obtained from sources with different reporting rates are exploited, by designing a platform flexible enough to simultaneously run in real time most of these PMU-based applications. In this paper such a platform is presented. It encompasses multiple \{PMUs\} from different vendors, manages detailed information about the measurement chain and its associated uncertainties and exploits a unique communication infrastructure with OpenPDC as the underlying layer for data fusion. It is based on a powerful Java \{EE7\} application that extends OpenPDC and represents the environment for extracting, managing and processing the information. The Java \{EE7\} application has been developed aiming for security, scalability, portability, concurrent access and big data processing. Such goals could have not been achieved without making some of the latest enterprise technologies work together. The end result can be exploited as a highly capable and interactive processing node within the grid and it also hints at important features that can be included in the upcoming \{IEEE\} C37.247 Standard for Phasor Data Concentrators for Power Systems. "} 
}
@article{Gross201737,
title = {"Improved recovery guarantees for phase retrieval from coded diffraction patterns "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"42"},
number = {"1"},
pages = {"37 - 64"},
year = {"2017"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2015.05.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520315000986"},
author = {"D. Gross and F. Krahmer and R. Kueng"},
keywords = {"Compressed sensing", "Low rank matrix recovery", "Phase retrieval", "PhaseLift", "Masked Fourier measurements", "Coded diffraction patterns", "Golfing scheme "},
abstract = {"Abstract In this work we analyze the problem of phase retrieval from Fourier measurements with random diffraction patterns. To this end, we consider the recently introduced PhaseLift algorithm, which expresses the problem in the language of convex optimization. We provide recovery guarantees which require O ( log 2 ⁡ d ) different diffraction patterns, thus improving on recent results by Candès et al. [1], which demand O ( log 4 ⁡ d ) different patterns. "} 
}
@article{Wang2017,
title = {"A quasi-current representation for information needs inspired by Two-State Vector Formalism "},
journal = {"Physica A: Statistical Mechanics and its Applications "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0378-4371"},
doi = {"https://doi.org/10.1016/j.physa.2017.04.145"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378437117304557"},
author = {"Panpan Wang and Yuexian Hou and Jingfei Li and Yazhou Zhang and Dawei Song and Wenjie Li"},
keywords = {"Information Retrieval", "Two-State Vector Formalism", "Quantum theory", "Session search "},
abstract = {"Abstract Recently, a number of quantum theory (QT)-based information retrieval (IR) models have been proposed for modeling session search task that users issue queries continuously in order to describe their evolving information needs (IN). However, the standard formalism of \{QT\} cannot provide a complete description for users’ current \{IN\} in a sense that it does not take the ‘future’ information into consideration. Therefore, to seek a more proper and complete representation for users’ IN, we construct a representation of quasi-current \{IN\} inspired by an emerging Two-State Vector Formalism (TSVF). With the enlightenment of the completeness of TSVF, a “two-state vector” derived from the ‘future’ (the current query) and the ‘history’ (the previous query) is employed to describe users’ quasi-current \{IN\} in a more complete way. Extensive experiments are conducted on the session tracks of \{TREC\} 2013 &amp; 2014, and show that our model outperforms a series of compared \{IR\} models. "} 
}
@article{Banda2015108,
title = {"Regional content-based image retrieval for solar images: Traditional versus modern methods "},
journal = {"Astronomy and Computing "},
volume = {"13"},
number = {""},
pages = {"108 - 116"},
year = {"2015"},
note = {""},
issn = {"2213-1337"},
doi = {"https://doi.org/10.1016/j.ascom.2015.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213133715000931"},
author = {"J.M. Banda and R.A. Angryk"},
keywords = {"Image retrieval", "Solar image analysis", "Computer vision", "Information retrieval", "Content-based image retrieval", "Large-scale retrieval", "Big-data analysis "},
abstract = {"Abstract This work presents an extensive evaluation between conventional (distance-based) and modern (search-engine) information retrieval techniques in the context of finding similar Solar image regions within the Solar Dynamics Observatory (SDO) mission image repository. We compare pre-computed image descriptors (image features) extracted from the \{SDO\} mission images in two very different ways: (1) similarity retrieval using multiple distance-based metrics and (2) retrieval using Lucene, a general purpose scalable retrieval engine. By transforming image descriptors into histogram-like signatures and into Lucene-compatible text strings, we are able to effectively evaluate the retrieval capabilities of both methodologies. Using the image descriptors alongside a labeled image dataset, we present an extensive evaluation under the criteria of performance, scalability and retrieval precision of experimental retrieval systems in order to determine which implementation would be ideal for a production level system. In our analysis we performed key transformations to our sample datasets to properly evaluate rotation invariance and scalability. At the end of this work we conclude which technique is the most robust and would yield the best performing system after an extensive experimental evaluation, we also point out the strengths and weaknesses of each approach and theorize on potential improvements. "} 
}
@article{Wang2015133,
title = {"An efficient algorithm for harmonic retrieval by combining blind source separation with wavelet packet decomposition "},
journal = {"Digital Signal Processing "},
volume = {"46"},
number = {""},
pages = {"133 - 150"},
year = {"2015"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2015.07.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200415002481"},
author = {"Fasong Wang and Zhongyong Wang and Rui Li and Linrang Zhang"},
keywords = {"Blind source separation (BSS)", "Harmonic retrieval", "Wavelet packet (WP)", "Mutual information (MI) "},
abstract = {"Abstract In the present paper, we propose an efficient framework and algorithm for one dimensional harmonic retrieval problem in additive colored Gaussian or non-Gaussian noise when the frequencies of the harmonic signals are closely spaced in frequency domain. Our framework utilizes the wavelet packet (WP) method to the blind source separation (BSS) based harmonic retrieval model. Firstly, we establish the \{BSS\} based harmonic retrieval model in additive noise using only one mixed channel signal, at the same time, the fundamental principle of \{BSS\} based harmonics retrieval algorithm is analyzed in detail. Then, the harmonic retrieval algorithm is developed mainly using the \{WP\} decomposition approach, where the criterion is formed as the cumulant based approximation of the mutual information (MI) for the selection of optimal sub-bands of \{WP\} decomposition with the least-dependent components between the same nodes. Simulation results show that the proposed algorithm is able to retrieve the harmonic source signals and yield good performance. "} 
}
@article{Huang2015596,
title = {"Research and application of public opinion retrieval based on user behavior modeling "},
journal = {"Neurocomputing "},
volume = {"167"},
number = {""},
pages = {"596 - 603"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.04.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215004762"},
author = {"Baocheng Huang and Guang Yu"},
keywords = {"Public opinion analysis", "Public opinion data organization", "Information retrieval "},
abstract = {"Abstract This paper designs a system of network public opinion analysis based on the specific way of “matching Topic with Opinion” which can organize public opinion data, avoid the redundant data and retain the original information structure of the opinion. And this article proposes a user model founded on the user access behavior to scientifically classify and represent the relevant theory of the users’ retrieval behavior, then to analyze and manage the retrieval results which can to provide the accurate and relevant search results of public opinion information for users. "} 
}
@article{Mitici201632,
title = {"Data retrieval time for energy-harvesting wireless sensor networks "},
journal = {"Ad Hoc Networks "},
volume = {"53"},
number = {""},
pages = {"32 - 40"},
year = {"2016"},
note = {""},
issn = {"1570-8705"},
doi = {"https://doi.org/10.1016/j.adhoc.2016.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1570870516302104"},
author = {"Mihaela Mitici and Jasper Goseling and Maurits de Graaf and Richard J. Boucherie"},
keywords = {"Wireless sensor networks", "Energy harvesting", "Data retrieval time", "Phase-type distribution", "Order statistics "},
abstract = {"Abstract We consider an ad-hoc network of wireless sensors that harvest energy from the environment and broadcasts measurements independently, at random, provided sufficient energy is available. Clients arriving at the network are interested in retrieving measurements from an arbitrary set of sensors of some fixed size s. We show that the sensors broadcast measurements according to a phase-type distribution. We determine the probability distribution of the time needed for a client to retrieve s sensor measurements. We provide a closed-form expression for the retrieval time of s sensor measurements for an asymptotically large capacity of the sensor battery or the rate at which energy is harvested. We also analyze numerically the retrieval time of s sensor measurements under various assumptions regarding the battery capacity of the sensors, the energy harvesting and consumption processes. The results provide a lower bound for the energy storage capacity of the sensors for which the retrieval time of measurements is below a targeted level. It is also shown that the ratio between the energy harvesting rate and the broadcasting rate significantly influences the retrieval time of measurements, whereas deploying sensors with large batteries does not significantly reduce the retrieval time of measurements. Numerical experiments also indicate that our theoretical results generalize to non-identical energy harvesting rates, various amount of energy consumed upon a broadcast and non-exponential distributions of the energy harvesting and broadcasting processes. "} 
}
@article{Zhu2017246,
title = {"Interpretation of users’ feedback via swarmed particles for content-based image retrieval "},
journal = {"Information Sciences "},
volume = {"375"},
number = {""},
pages = {"246 - 257"},
year = {"2017"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.09.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025516307745"},
author = {"Yingying Zhu and Jianmin Jiang and Wenlong Han and Ying Ding and Qi Tian"},
keywords = {"Relevance feedback", "User interactions", "Content-based image retrieval", "Particle swarm optimization "},
abstract = {"Abstract While providing relevance feedback (RF) by users proves to be an effective method for content-based image retrieval, how to interpret and learn from the user-provided feedback, however, remains an unsolved problem. In this paper, we propose an integrated users-feedback and learning algorithm by screening individual elements of content features and driving a group of swarmed particles inside the feature space to provide a possible solution. In comparison with the existing approaches, the proposed algorithm achieves a number of advantages, which can be highlighted as: (i) interpretation of users’ feedback is independent of both the content features and relevance feedback schemes, and hence the proposed algorithm can be applicable to any content features and relevance feedback methods; (ii) the \{RF\} interpretation is followed by a group of swarmed particles, acting as multiple agents rather than a single query image in searching for the desirable images; (iii) the proposed \{RF\} interpretation and learning is exploited not only in reweighting the content similarity measurement, but also in regrouping the database images. Extensive experiments support that our proposed algorithm outperforms the existing representative techniques, providing good potential for further research and development for a wide range of content-based image retrieval applications. "} 
}
@article{Jiang2015346,
title = {"TEII: Topic enhanced inverted index for top-k document retrieval "},
journal = {"Knowledge-Based Systems "},
volume = {"89"},
number = {""},
pages = {"346 - 358"},
year = {"2015"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2015.07.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705115002683"},
author = {"Di Jiang and Kenneth Wai-Ting Leung and Lingxiao Yang and Wilfred Ng"},
keywords = {"Topic model", "Search engine", "Information retrieval "},
abstract = {"Abstract In recent years, topic modeling is gaining significant momentum in information retrieval (IR). Researchers have found that utilizing the topic information generated through topic modeling together with traditional TF-IDF information generates superior results in document retrieval. However, in order to apply this idea to real-life \{IR\} systems, some critical problems need to be solved: how to store the topic information and how to utilize it with the TF-IDF information for efficient document retrieval. In this paper, we propose the Topic Enhanced Inverted Index (TEII) to incorporate the topic information into the inverted index for efficient top-k document retrieval. Specifically, we explore two different types of TEIIs. We first propose the incremental TEII, which includes the topic information into the traditional inverted index by adding topic-based inverted lists. The incremental \{TEII\} is beneficial for legacy \{IR\} systems, since it does not change the existing TF-IDF-based inverted lists. As a more flexible alternative, we propose the hybrid \{TEII\} to incorporate the topic information into each posting of the inverted index. In the hybrid TEII, two relaxation methods are proposed to support dynamic estimation of the upper bound impact of each posting. The hybrid \{TEII\} is highly extensible for incorporating different ranking factors and we show an extension of the hybrid \{TEII\} by considering the static quality of the documents in the corpus. Based on the incremental and hybrid TEIIs, we develop several query processing algorithms to support efficient top-k document retrieval on TEIIs. Empirical evaluation on the \{TREC\} dataset verifies the effectiveness and efficiency of the proposed index structures and query processing algorithms. "} 
}
@article{Zhiqiang2016150,
title = {"Annotation-retrieval reinforcement by visual cognition modeling on manifold "},
journal = {"Neurocomputing "},
volume = {"215"},
number = {""},
pages = {"150 - 159"},
year = {"2016"},
note = {"SI: Stereo Data "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.07.162"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216306531"},
author = {"Zeng Zhiqiang and Shi Hua and Wu Yun and Quan Zou"},
keywords = {"Image annotation", "Image retrieval", "Semantic manifold", "Co-training", "Biased Fisher discriminant analysis "},
abstract = {"Abstract While content-based image annotation and retrieval have been active research topics over the past decade, their correlation is not well exploited until recently. We argue that offline annotation and online retrieval models should be regarded as a unified long-term learner to reinforce each other. Based on this viewpoint, this paper presents an annotation-retrieval reinforcement framework, in which a dual-structured learning model is presented: the keyword-image association is learned by semantic manifold modeling while the semantic correlation between keywords is learned by Image-Word Net modeling. In keyword-image association modeling level, to effectively model keyword-image manifold, we present a manifold co-training algorithm to address the sample insufficiency problem. In manifold-based image annotation, we view annotation process as semantic feature reduction in keyword space, based on which a Biased Fisher Discriminant Analysis (BFDA) algorithm is presented for Eigen feature (keyword) selection. In semantic correlation modeling level, a novel Image-Word Net is learned from annotation training set and users' retrieval log for (1) irrelevant annotated keyword pruning; (2) semantic-level retrieval enhancement. In retrieval, our framework can effectively reveal user target by improving traditional content-based relevance feedback to linguistic-level interaction using annotation information, based on which \{BFDA\} is adopted for keyword selection. Finally, user interaction logs are adopted for manifold model updating and annotation refinement. As presented in our experiments, proposed method outperforms state-of-the-art annotation and retrieval algorithms in \{COREL\} Image databases with over 10,000 general-purpose images. "} 
}
@article{Mei2016,
title = {"Retrieval of aerosol optical properties using \{MERIS\} observations: Algorithm and some first results "},
journal = {"Remote Sensing of Environment "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.11.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716304606"},
author = {"Linlu Mei and Vladimir Rozanov and Marco Vountas and John P. Burrows and Robert C. Levy and Wolfhardt Lotz"},
keywords = {"AOT", "MERIS", "Retrieval "},
abstract = {"Abstract The \{MEdium\} Resolution Imaging Spectrometer (MERIS) instrument on board European Space Agency (ESA) Envisat made measurements from 2002 to 2012. Although \{MERIS\} was limited in spectral coverage, accurate Aerosol Optical Thickness (AOT) from \{MERIS\} data are retrieved by using appropriate additional information. We introduce a new \{AOT\} retrieval algorithm for \{MERIS\} over land surfaces, referred to as eXtensible Bremen \{AErosol\} Retrieval (XBAER). \{XBAER\} is similar to the “dark-target” (DT) retrieval algorithm used for Moderate-resolution Imaging Spectroradiometer (MODIS), in that it uses a lookup table (LUT) to match to satellite-observed reflectance and derive the AOT. Instead of a global parameterization of surface spectral reflectance, \{XBAER\} uses a set of spectral coefficients to prescribe surface properties. In this manner, \{XBAER\} is not limited to dark surfaces (vegetation) and retrieves \{AOT\} over bright surface (desert, semiarid, and urban areas). Preliminary validation of the MERIS-derived \{AOT\} and the ground-based Aerosol Robotic Network (AERONET) measurements yield good agreement, the resulting regression equation is y = (0.92x ± 0.07) + (0.05 ± 0.01) and Pearson correlation coefficient of R = 0.78. Global monthly means of \{AOT\} have been compared from XBAER, \{MODIS\} and other satellite-derived datasets. "} 
}
@article{CamposTaberner2016102,
title = {"Multitemporal and multiresolution leaf area index retrieval for operational local rice crop monitoring "},
journal = {"Remote Sensing of Environment "},
volume = {"187"},
number = {""},
pages = {"102 - 118"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.10.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716303819"},
author = {"Manuel Campos-Taberner and Francisco Javier García-Haro and Gustau Camps-Valls and Gonçal Grau-Muedra and Francesco Nutini and Alberto Crema and Mirco Boschetti"},
keywords = {"Crop monitoring", "Rice", "Leaf area index (LAI) retrieval", "PROSAIL", "Smartphone", "Gaussian process regression (GPR)", "Landsat", "SPOT5 Take5 "},
abstract = {"Abstract This paper presents an operational chain for high-resolution leaf area index (LAI) retrieval from multiresolution satellite data specifically developed for Mediterranean rice areas. The proposed methodology is based on the inversion of the \{PROSAIL\} radiative transfer model through the state-of-the-art nonlinear Gaussian process regression (GPR) method. Landsat and \{SPOT5\} data were used for multitemporal \{LAI\} retrievals at high-resolution. \{LAI\} estimates were validated using time series of in situ \{LAI\} measurements collected during the rice season in Spain and Italy. Ground \{LAI\} data were collected with smartphones using PocketLAI, a specific phone application for \{LAI\} estimation. Temporal evolution of the \{LAI\} estimates using Landsat and \{SPOT5\} data followed consistently the temporal evolution of the in situ \{LAI\} measurements acquired on several Mediterranean rice varieties. The estimates had a root-mean-square-error (RMSE) of 0.39 and 0.51 m2/m2 in Spain and 0.38 and 0.47 m2/m2 in Italy for Landsat and \{SPOT5\} respectively, with a strong correlation (R2 &gt; 0.92) for both cases. Spatial-temporal assessment of the estimated \{LAI\} from Landsat and \{SPOT5\} data confirmed the robustness and consistency of the retrieval chain. This paper demonstrates the importance of an adequate characterization of the underlying rice background in order to address changes in background condition related to water management. Results highlight the potential of the proposed chain for deriving multitemporal near real-time decametric \{LAI\} maps fundamental for operational rice crop monitoring, and demonstrate the readiness of the proposed method for the processing of data such as the recently launched Sentinel-2. "} 
}
@article{Stefanis2014100,
title = {"Frequency and recency context for the management and retrieval of personal information on mobile devices "},
journal = {"Pervasive and Mobile Computing "},
volume = {"15"},
number = {""},
pages = {"100 - 112"},
year = {"2014"},
note = {"Special Issue on Information Management in Mobile Applications "},
issn = {"1574-1192"},
doi = {"https://doi.org/10.1016/j.pmcj.2013.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574119213001119"},
author = {"Vassileios Stefanis and Athanasios Plessas and Andreas Komninos and John Garofalakis"},
keywords = {"Context", "Mobile personal information management", "Call prediction "},
abstract = {"Abstract As users store increasingly larger amounts of personal information on their mobiles, the task of retrieving such items (e.g., contacts) becomes more difficult. We show that users can be categorized by their communication patterns and that each category benefits differently from supporting contact management applications. By examining mobile user call logs, we show that it is possible to aid retrieval tasks using relatively simple heuristics and algorithms that describe usage context, using solely the dimensions of contact use frequency and recency. We compare and discuss the results of the proposed method applied on two different mobile datasets: a large dataset from \{NOKIA\} and a smaller dataset collected by ourselves. "} 
}
@article{Deep20161895,
title = {"Directional local ternary quantized extrema pattern: A new descriptor for biomedical image indexing and retrieval "},
journal = {"Engineering Science and Technology, an International Journal "},
volume = {"19"},
number = {"4"},
pages = {"1895 - 1909"},
year = {"2016"},
note = {""},
issn = {"2215-0986"},
doi = {"https://doi.org/10.1016/j.jestch.2016.05.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S221509861630088X"},
author = {"G. Deep and L. Kaur and S. Gupta"},
keywords = {"Medical imaging", "Image retrieval", "Local binary patterns (LBPs)", "Local ternary patterns (LTPs)", "Directional quantized extrema patterns", "Texture "},
abstract = {"Abstract This paper proposes a new pattern descriptor called directional local ternary quantized extrema pattern (DLTerQEP) for biomedical image indexing and retrieval. The standard local binary patterns (LBPs) and local ternary patterns (LTPs) encode the gray scale relationship between the center pixel and its surrounding neighbors in two dimensional (2D) local region of an image whereas the proposed method encodes the spatial relation between any pair of neighbors in a local region along the given directions (i.e., 0°, 45°, 90° and 135°) for a given center pixel in an image. The novelty of the proposed method is it uses ternary patterns from horizontal–vertical–diagonal–antidiagonal (HVDA7) structure of directional local extrema values of an image to encode more spatial structure information which lead to better retrieval. \{DLTerQEP\} also provides a significant increase in discriminative power by allowing larger local pattern neighborhoods. The experiments have been carried out for proving the worth of proposed algorithm on three different types of benchmark biomedical databases; (i) computed tomography (CT) scanned lung image databases named as LIDC-IDRI-CT and VIA/I-ELCAP-CT, (ii) brain magnetic resonance imaging (MRI) database named as OASIS-MRI. The results demonstrate the superiority of the proposed method in terms of average retrieval precision (ARP) and average retrieval rate (ARR) over state-of-the-art feature extraction techniques like LBP, \{LTP\} and \{LQEP\} etc. "} 
}
@article{Wu2016110,
title = {"Computing invariants of Tchebichef moments for shape based image retrieval "},
journal = {"Neurocomputing "},
volume = {"215"},
number = {""},
pages = {"110 - 117"},
year = {"2016"},
note = {"SI: Stereo Data "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.05.147"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216306385"},
author = {"Haiyong Wu and Senlin Yan"},
keywords = {"Tchebichef moments", "Invariants of Tchebichef moments", "Image retrieval", "Pattern recognition "},
abstract = {"Abstract Generally, discrete orthogonal moments are difficult to induce rotation invariants. Based on relationship between Tchebichef polynomials and power series, we propose a new algorithm to compute rotation invariants of Tchebichef moments. The translation and scale invariants of Tchebichef moments are achieved by pre-normalizing the image to a standard image. Selected invariants of Tchebichef moments form a new effective shape feature for image retrieval. The retrieval performance of the proposed descriptor is compared with radial Tchebichef moment invariants and two kinds of Zernike moment invariants. Retrieval experiment results show that the proposed shape feature is robust to deformations generated by image shape rotation and scaling. "} 
}
@article{deVes2015829,
title = {"Modeling user preferences in content-based image retrieval: A novel attempt to bridge the semantic gap "},
journal = {"Neurocomputing "},
volume = {"168"},
number = {""},
pages = {"829 - 845"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.05.041"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215007171"},
author = {"Esther de Ves and Guillermo Ayala and Xaro Benavent and Juan Domingo and Esther Dura"},
keywords = {"Semantic gap", "Proportional odds model", "Information retrieval", "Relevance feedback", "Content-based image retrieval "},
abstract = {"Abstract This paper is concerned with content-based image retrieval from a stochastic point of view. The semantic gap problem is addressed in two ways. First, a dimensional reduction is applied using the (pre-calculated) distances among images. The dimension of the reduced vector is the number of preferences that we allow the user to choose from, in this case, three levels. Second, the conditional probability distribution of the random user preference, given this reduced feature vector, is modeled using a proportional odds model. A new model is fitted at each iteration. The score used to rank the image database is based on the estimated probability function of the random preference. Additionally, some memory is incorporated in the procedure by weighting the current and previous scores. Also, a novel evaluation procedure is proposed in this work based on the empirical commutative distribution functions of the relevant and non-relevant retrieved images. Good experimental results are achieved in very different experimental setups and tested in different databases. "} 
}
@article{Chen2016379,
title = {"Image retrieval based on image-to-class similarity "},
journal = {"Pattern Recognition Letters "},
volume = {"83, Part 3"},
number = {""},
pages = {"379 - 387"},
year = {"2016"},
note = {"Efficient Shape Representation, Matching, Ranking, and its Applications "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.01.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516000295"},
author = {"Jun Chen and Yong Wang and Linbo Luo and Jin-Gang Yu and Jiayi Ma"},
keywords = {"Image retrieval", "Shape retrieval", "Matching", "Image-to-class similarity "},
abstract = {"Abstract Similar image/shape retrieval has attractedincreasing interests in recent years. A typical strategy of existing retrieval algorithms is to rank the images according to the image-to-image similarities, e.g., the similarities between the query image and the images in the database. This strategy ignores the inherent information of the class that the query image belongs to (we call it query class). To address this issue, rather than using image-to-image similarity, we propose a simple yet effective retrieval method based on exploring the image-to-class similarity. The method uses an iterative framework, where the size of the query class is progressively enlarged according to the previous retrieval results, and the ranked list is generated according to the similarities between the images in the database and the query class. This framework enables us to explore the inherent information of the query class, and hence helps to improve the retrieval accuracy. Experimental results on various datasets demonstrate that our method is able to effectively improve the image and shape retrieval accuracy compared to state-of-the-art methods. "} 
}
@article{Malizia2017608,
title = {"An ant-colony based approach for real-time implicit collaborative information seeking "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"3"},
pages = {"608 - 623"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316307269"},
author = {"Alessio Malizia and Kai A. Olsen and Tommaso Turchi and Pierluigi Crescenzi"},
keywords = {"Ant Colony Optimization", "Cooperative systems", "Evolutionary computation", "Information filtering", "Information retrieval", "Recommender systems", "World wide web "},
abstract = {"Abstract We propose an approach based on Swarm Intelligence — more specifically on Ant Colony Optimization (ACO) — to improve search engines’ performance and reduce information overload by exploiting collective users’ behavior. We designed and developed three different algorithms that employ an ACO-inspired strategy to provide implicit collaborative-seeking features in real time to search engines. The three different algorithms — NaïveRank, RandomRank, and SessionRank — leverage on different principles of \{ACO\} in order to exploit users’ interactions and provide them with more relevant results. We designed an evaluation experiment employing two widely used standard datasets of query-click logs issued to two major Web search engines. The results demonstrated how each algorithm is suitable to be employed in ranking results of different types of queries depending on users’ intent. "} 
}
@article{Zheng2016217,
title = {"Study on image retrieval based on image texture and color statistical projection "},
journal = {"Neurocomputing "},
volume = {"215"},
number = {""},
pages = {"217 - 224"},
year = {"2016"},
note = {"SI: Stereo Data "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.07.157"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216306452"},
author = {"Xiaofei Zheng and Bing Tang and Zhe Gao and Enping Liu and Wei Luo"},
keywords = {"Main hue", "Robert algorithm", "Projection histogram", "Canny edge algorithm", "Image retrieval "},
abstract = {"Abstract This article presents an image texture and hue statistical projection based retrieval. First the image is converted to \{HSI\} color model, the gray value of the image extraction, and Robert algorithm to extract the texture, then the image is divided into blocks and extracts the main color block, the main color image blocks are respectively projected in the horizontal and vertical direction of 2, get 2 projection histogram, the 2 projection histograms of the first three order center extraction distance and Robert algorithm as the features of texture, image similarity calculation. Make a very full pave the way for future Canny edge processing algorithm research of image retrieval. "} 
}
@article{Poslad2014225,
title = {"A Multi-Modal Incompleteness Ontology model (MMIO) to enhance information fusion for image retrieval "},
journal = {"Information Fusion "},
volume = {"20"},
number = {""},
pages = {"225 - 241"},
year = {"2014"},
note = {""},
issn = {"1566-2535"},
doi = {"https://doi.org/10.1016/j.inffus.2014.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1566253514000190"},
author = {"Stefan Poslad and Kraisak Kesorn"},
keywords = {"Multi-Modal Ontology", "Knowledge base", "Incomplete Ontology", "Visual and textual information fusion "},
abstract = {"Abstract A significant effort by researchers has advanced the ability of computers to understand, index and annotate images. This entails automatic domain specific knowledge-base (KB) construction and metadata extraction from visual information and any associated textual information. However, it is challenging to fuse visual and textual information and build a complete domain-specific \{KB\} for image annotation due to several factors such as: the ambiguity of natural language to describe image features; the semantic gap when using image features to represent visual content and the incompleteness of the metadata in the KB. Typically the \{KB\} is based upon a domain specific Ontology. However, it is not an easy task to extract the data needed from annotations and images, and then to automatically process these and transform them into an integrated Ontology model, because of the ambiguity of terms and because of image processing algorithm errors. As such, it is difficult to construct a complete \{KB\} covering a specific domain of knowledge. This paper presents a Multi-Modal Incompleteness Ontology-based (MMIO) system for image retrieval based upon fusing two derived indices. The first index exploits low-level features extracted from images. A novel technique is proposed to represent the semantics of visual content, by restructuring visual word vectors into an Ontology model by computing the distance between the visual word features and concept features, the so called concept range. The second index relies on a textual description which is processed to extract and recognise the concepts, properties, or instances that are defined in an Ontology. The two indexes are fused into a single indexing model, which is used to enhance the image retrieval efficiency. Nonetheless, this rich index may not be sufficient to find the desired images. Therefore, a Latent Semantic Indexing (LSI) algorithm is exploited to search for similar words to those used in a query. As a result, it is possible to retrieve images with a query using (similar) words that do not appear in the caption. The efficiency of the \{KB\} is validated experimentally with respect to three criteria, correctness, multimodality, and robustness. The results show that the multi-modal metadata in the proposed \{KB\} could be utilised efficiently. An additional experiment demonstrates that \{LSI\} can handle an incomplete \{KB\} effectively. Using LSI, the system can still retrieve relevant images when information in the Ontology is missing, leading to an enhanced retrieval performance. "} 
}
@article{Cao201651,
title = {"Similarity based leaf image retrieval using multiscale R-angle description "},
journal = {"Information Sciences "},
volume = {"374"},
number = {""},
pages = {"51 - 64"},
year = {"2016"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.09.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025516308088"},
author = {"Jie Cao and Bin Wang and Douglas Brown"},
keywords = {"Plant identification", "Shape description", "Invariant features", "Shape matching", "Leaf image retrieval "},
abstract = {"Abstract Leaf image identification is a significant and challenging application of computer vision and image processing. A central issue associated with this task is how to effectively and efficiently describe the leaf images and measure their similarities. In this paper, a novel shape descriptor termed R-angle is proposed. R-angle describes the curvature of the contour by measuring the angle between the intersections of the shape contour with a circle of radius R centered at points sampled around the contour. It is intrinsically invariant to group transforms including scaling, rotation and translation. Varying the parameter R of the proposed R-angle naturally introduces the notation of scale, which we leverage to provide a coarse-to-fine description of the local curvature. A local scale arrangement is proposed by taking the distance between each contour point and the center of the shape to be the maximum scale for a given contour point. Two matching schemes, including L1-norm matching and dynamic programming based matching, are applied to measure the similarities of the leaf shapes. The retrieval experiments conducted on two challenging leaf image datasets indicate that the proposed method significantly outperforms the state-of-the-art methods for leaf identification. An additional experiment on an animal dataset also indicates its potential for general shape recognition. "} 
}
@article{Liu2016423,
title = {"Improving retrieval of plane geometry figure with learning to rank "},
journal = {"Pattern Recognition Letters "},
volume = {"83, Part 3"},
number = {""},
pages = {"423 - 429"},
year = {"2016"},
note = {"Efficient Shape Representation, Matching, Ranking, and its Applications "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.05.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516301040"},
author = {"Lu Liu and Xiaoqing Lu and Yuan Liao and Yongtao Wang and Zhi Tang"},
keywords = {"Learning to rank", "Ranking optimization", "Shape retrieval", "Plane geometry figure", "Feature selection "},
abstract = {"Abstract Educational images are increasingly becoming available online, but an effective method to search for such images is nonexistent, particularly for graph-based digital resources. This paper focuses on plane geometry figure (PGF) retrieval with ranking optimization to retrieve relevant digital geometry materials. A learning to rank model is introduced to rearrange the unsatisfactory order of highly similar \{PGFs\} in retrieval results. Moreover, to enhance the retrieval accuracy and efficiency, we perform feature selection for ranking according to the quality and redundancy of several specific types of \{PGF\} features. We perform retrieval experiments and evaluations on two \{PGF\} datasets, and results show that our \{PGF\} retrieval method improves figure retrieval accuracy better than existing methods. "} 
}
@article{Li201611775,
title = {"Image retrieval via balance-evolution artificial bee colony algorithm and lateral inhibition "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"24"},
pages = {"11775 - 11785"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.09.085"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616311044"},
author = {"Bai Li and Changjun Zhou and Hong Liu and Ya Li and Hongxin Cao"},
keywords = {"Image retrieval", "Metaheuristics", "Lateral inhibition", "Artificial bee colony", "Overall degradation "},
abstract = {"Abstract Image retrieval is a fundamental issue in pattern recognition. In this work, lateral inhibition (LI) model is adopted as a pre-processing step, which widens the gray level gradients so as to facilitate the image retrieval scheme. In searching for a perfect match between a predefined template and a reference image, we adopt metaheuristic algorithms for good seach capability. Artificial bee colony (ABC) algorithm is a bio-inspired optimization technique, which imitates the foraging behavior of honey bee swarms. It is well known that the algorithm is good at exploration but poor at exploitation. We present balance-evolution artificial bee colony (BE-ABC) algorithm that aims to strike a balance between exploration and exploitation rather than just focusing on improving the latter. BE-ABC algorithm adaptively manipulates the search intensity at the exploration and exploitation stages during the iterations. Besides that, it incorporates an overall degradation procedure to prevent premature convergence. Simulation results confirm that BE-ABC algorithm is more capable than several state-of-the-art metaheuristic algorithms in this image retrieval scheme. "} 
}
@article{Chen2017221,
title = {"Optical image conversion and encryption by diffraction, phase retrieval algorithm and incoherent superposition "},
journal = {"Optics and Lasers in Engineering "},
volume = {"88"},
number = {""},
pages = {"221 - 232"},
year = {"2017"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.08.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616301865"},
author = {"Linfei Chen and Guojun Chang and Bingyu He and Haidan Mao and Daomu Zhao"},
keywords = {"Optical image encryption", "Fresnel diffraction", "Phase retrieval algorithm", "Incoherent superposition "},
abstract = {"Abstract In this paper, an optical encryption system is proposed based on tricolor principle, Fresnel diffraction, and phase iterative algorithms. Different from the traditional encryption system, the encrypted image of this system is a color image and the plaintext of it is a gray image, which can achieve the combination of a color image and a gray image and the conversion of one image to another image. Phase masks can be generated by using the phase iterative algorithms in this paper. The six phase masks and the six diffracting distances are all essential keys in the process of decryption, which can greatly enhance the system security. Numerical simulations are shown to prove the possibility and safety of the method. "} 
}
@article{Diémoz20161759,
title = {"A single-image retrieval method for edge illumination X-ray phase-contrast imaging: Application and noise analysis "},
journal = {"Physica Medica "},
volume = {"32"},
number = {"12"},
pages = {"1759 - 1764"},
year = {"2016"},
note = {""},
issn = {"1120-1797"},
doi = {"https://doi.org/10.1016/j.ejmp.2016.07.093"},
url = {"http://www.sciencedirect.com/science/article/pii/S1120179716302265"},
author = {"Paul C. Diémoz and Fabio A. Vittoria and Charlotte K. Hagen and Marco Endrizzi and Paola Coan and Alberto Bravin and Ulrich H. Wagner and Christoph Rau and Ian K. Robinson and Alessandro Olivo"},
keywords = {"Phase-contrast imaging", "Edge illumination", "Fast imaging", "Phase retrieval "},
abstract = {"AbstractPurpose Edge illumination (EI) X-ray phase-contrast imaging (XPCI) has been under development at University College London in recent years, and has shown great potential for both laboratory and synchrotron applications. In this work, we propose a new acquisition and processing scheme. Contrary to existing retrieval methods for EI, which require as input two images acquired in different setup configurations, the proposed approach can retrieve an approximate map of the X-ray phase from a single image, thus significantly simplifying the acquisition procedure and reducing data collection times. Methods The retrieval method is analytically derived, based on the assumption of a quasi-homogeneous object, i.e. an object featuring a constant ratio between refractive index and absorption coefficient. The noise properties of the input and retrieved images are also theoretically analyzed under the developed formalism. The method is applied to experimental synchrotron images of a biological object. Results The experimental results show that the method can provide high-quality images, where the “edge” signal typical of \{XPCI\} images is transformed to an “area” contrast that enables an easier interpretation of the sample geometry. Moreover, the retrieved images confirm that the method is highly stable against noise. Conclusions We anticipate that the developed approach will become the method of choice for a variety of applications of \{EI\} XPCI, thanks to its ability to simplify the acquisition procedure and reduce acquisitions time and dose to the sample. Future work will focus on the adaptation of the method to computed tomography and to polychromatic radiation from X-ray tubes. "} 
}
@article{Djidja2016,
title = {"Antigen retrieval prior to on-tissue digestion of formalin-fixed paraffin-embedded tumour tissue sections yields oxidation of proline residues "},
journal = {"Biochimica et Biophysica Acta (BBA) - Proteins and Proteomics "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"1570-9639"},
doi = {"https://doi.org/10.1016/j.bbapap.2016.11.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S1570963916302588"},
author = {"Marie-Claude Djidja and Emmanuelle Claude and Peter Scriven and David W. Allen and Vikki A. Carolan and Malcolm R. Clench"},
keywords = {"MALDI", "Imaging", "FFPE", "Antigen retrieval", "Proline oxidation "},
abstract = {"Abstract MALDI-mass spectrometry imaging (MALDI-MSI) has been shown to allow the study of protein distribution and identification directly within formalin-fixed paraffin-embedded (FFPE) tissue sections. However, direct protein identification from tissue sections remains challenging due to signal interferences and/or existing post-translational or other chemical modifications. The use of antigen retrieval (AR) has been demonstrated for unlocking proteins prior to in situ enzymatic digestion and MALDI-MSI analysis of \{FFPE\} tissue sections. In the work reported here, the identification of proline oxidation, which may occur when performing the \{AR\} protocol, is described. This facilitated and considerably increased the number of identified peptides when adding proline oxidation as a variable modification to the \{MASCOT\} search criteria. This article is part of a Special Issue entitled: \{MALDI\} Imaging, edited by Dr. Corinna Henkel and Prof. Peter Hoffmann. "} 
}
@article{Lin2016241,
title = {"The distributed system for inverted multi-index visual retrieval "},
journal = {"Neurocomputing "},
volume = {"215"},
number = {""},
pages = {"241 - 249"},
year = {"2016"},
note = {"SI: Stereo Data "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.11.131"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216306427"},
author = {"Xianming Lin and Yunhang Shen and Ling Cai and Rongrong Ji"},
keywords = {"Distributed inverted multi-index", "APC-PQ", "Visual retrieval "},
abstract = {"Abstract With the explosive growth of visual databases, it is infeasible to maintain the huge indexing structures within the memory of a single server. In this paper, a distributed visual retrieval system based on inverted multi-index is proposed to generate a huge codebook with very low memory consumption and time cost. In order to improve the performance of product quantization, a vector space decomposition strategy is performed by affinity propagation clustering. In the meantime, a distributed framework is introduced to inverted multi-index to improve the time efficiency. Our works are validated on the large scale database of \{INRIA\} Holidays and Flickr 1M. The results of our experiments indicate that the performance of \{PQ\} is greatly improved and the visual retrieval system is speeded up at comparable precision. "} 
}
@article{Daines2017274,
title = {"Does Achieving High Flexion Increase Polyethylene Damage in Posterior-Stabilized Knees? A Retrieval Study "},
journal = {"The Journal of Arthroplasty "},
volume = {"32"},
number = {"1"},
pages = {"274 - 279"},
year = {"2017"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2016.07.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540316303643"},
author = {"Steven B. Daines and Chelsea N. Koch and Steven B. Haas and Geoffrey H. Westrich and Timothy M. Wright"},
keywords = {"range of motion", "total knee arthroplasty", "polyethylene wear", "posterior-stabilized knees", "retrieval analysis "},
abstract = {"AbstractBackground Increased range of motion to higher degrees of flexion following total knee arthroplasty has been postulated to increase implant damage and revision rates, even in designs modified to accommodate high flexion. Methods We examined posterior-stabilized and high-flexion retrieved tibial inserts to look for differences in polyethylene surface damage with light microscopy and 3D deviation with laser scanning between inserts from patients who achieved a high degree of flexion (≥120° postoperatively) and inserts from patients who did not reach a high degree of flexion. Results No differences were found in damage scores on the articular and backside surfaces, except for abrasion in the posterior articular regions, or in 3D deviations between patients who reached a high degree of flexion and patients who did not. These results were independent of the reason for revision. Conclusion In our series, reaching a high degree of flexion did not influence surface damage or 3D deviation of the polyethylene inserts. "} 
}
@article{Boysen2016691,
title = {"A survey on single crane scheduling in automated storage/retrieval systems "},
journal = {"European Journal of Operational Research "},
volume = {"254"},
number = {"3"},
pages = {"691 - 704"},
year = {"2016"},
note = {""},
issn = {"0377-2217"},
doi = {"https://doi.org/10.1016/j.ejor.2016.04.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0377221716302272"},
author = {"Nils Boysen and Konrad Stephan"},
keywords = {"Warehousing", "Automated storage/retrieval systems", "Crane scheduling", "Classification "},
abstract = {"Abstract This paper addresses the scheduling of a single storage/retrieval machine (or crane) in automated storage/retrieval systems (ASRSs). A novel classification scheme is presented for precisely defining different versions of the crane scheduling problem, when varying the layout of the ASRS, the characteristics of the storage and retrieval requests, and the objective function. This classification scheme is then applied for presenting different (known and novel) exact algorithms and complexity proofs for a variety of crane scheduling problems, for reviewing the literature, and for identifying future research needs. "} 
}
@article{Alaei201647,
title = {"Logo and seal based administrative document image retrieval: A survey "},
journal = {"Computer Science Review "},
volume = {"22"},
number = {""},
pages = {"47 - 63"},
year = {"2016"},
note = {""},
issn = {"1574-0137"},
doi = {"https://doi.org/10.1016/j.cosrev.2016.09.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574013715300186"},
author = {"Alireza Alaei and Partha Pratim Roy and Umapada Pal"},
keywords = {"Administrative document image", "Logo", "Seal", "Detection", "Recognition", "Retrieval "},
abstract = {"Abstract With the advance of technology, business offices and organizations together with their clients create a massive amount of administrative documents every day. Administrative documents commonly contain some salient entities such as logos, stamps or seals as the means of their authentication and proprietorship. These salient entities provide quite discriminative information, which can effectively be used for different tasks of document image retrieval, classification and recognition in document-based applications. Thus, proper detection/recognition of these entities in document images increases the performance of such applications in terms of document retrieval, classification, and recognition. To present the state-of-the-art research on the retrieval of administrative document images, this paper deals with a survey of administrative document image retrieval in relation to seals and logos. All the available datasets, feature extraction and classification techniques for logo and seal detection/recognition are discussed systematically. The shortcomings of the present technologies on logo and seal based document processing are also highlighted. Avenues of the future works are further given for the benefit of readers. To the best of authors’ knowledge, there is no survey on administrative document image retrieval and hence the authors hope that this work will be helpful to the researchers of the document analysis community. "} 
}
@article{Li2016345,
title = {"A 3D shape retrieval method for orthogonal fringe projection based on a combination of variational image decomposition and variational mode decomposition "},
journal = {"Optics and Lasers in Engineering "},
volume = {"86"},
number = {""},
pages = {"345 - 355"},
year = {"2016"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.06.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616301257"},
author = {"Biyuan Li and Chen Tang and Xinjun Zhu and Xia Chen and Yonggang Su and Yuanxue Cai"},
keywords = {"Orthogonal fringe projection", "Variational image decomposition", "Variational mode decomposition", "Shape retrieval", "Fourier transform "},
abstract = {"Abstract The orthogonal fringe projection technique has as wide as long practical application nowadays. In this paper, we propose a 3D shape retrieval method for orthogonal composite fringe projection based on a combination of variational image decomposition (VID) and variational mode decomposition (VMD). We propose a new image decomposition model to extract the orthogonal fringe. Then we introduce the \{VMD\} method to separate the horizontal and vertical fringe from the orthogonal fringe. Lastly, the 3D shape information is obtained by the differential 3D shape retrieval method (D3D). We test the proposed method on a simulated pattern and two actual objects with edges or abrupt changes in height, and compare with the recent, related and advanced differential 3D shape retrieval method (D3D) in terms of both quantitative evaluation and visual quality. The experimental results have demonstrated the validity of the proposed method. "} 
}
@article{Beyeler2016348,
title = {"Divergent Routing of Positive and Negative Information from the Amygdala during Memory Retrieval "},
journal = {"Neuron "},
volume = {"90"},
number = {"2"},
pages = {"348 - 361"},
year = {"2016"},
note = {""},
issn = {"0896-6273"},
doi = {"https://doi.org/10.1016/j.neuron.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0896627316001835"},
author = {"Anna Beyeler and Praneeth Namburi and Gordon F. Glober and Clémence Simonnet and Gwendolyn G. Calhoon and Garrett F. Conyers and Robert Luck and Craig P. Wildes and Kay M. Tye"},

abstract = {"Summary Although the basolateral amygdala (BLA) is known to play a critical role in the formation of memories of both positive and negative valence, the coding and routing of valence-related information is poorly understood. Here, we recorded \{BLA\} neurons during the retrieval of associative memories and used optogenetic-mediated phototagging to identify populations of neurons that synapse in the nucleus accumbens (NAc), the central amygdala (CeA), or ventral hippocampus (vHPC). We found that despite heterogeneous neural responses within each population, the proportions of BLA-NAc neurons excited by reward predictive cues and of BLA-CeA neurons excited by aversion predictive cues were higher than within the entire BLA. Although the BLA-vHPC projection is known to drive behaviors of innate negative valence, these neurons did not preferentially code for learned negative valence. Together, these findings suggest that valence encoding in the \{BLA\} is at least partially mediated via divergent activity of anatomically defined neural populations. "} 
}
@article{Shen201614,
title = {"Semi-paired hashing for cross-view retrieval "},
journal = {"Neurocomputing "},
volume = {"213"},
number = {""},
pages = {"14 - 23"},
year = {"2016"},
note = {"Binary Representation Learning in Computer Vision "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.01.121"},
url = {"http://www.sciencedirect.com/science/article/pii/S092523121630724X"},
author = {"Xiaobo Shen and Quan-Sen Sun and Yun-Hao Yuan"},
keywords = {"Hashing", "Semi-paired", "Cross-view", "Retrieval "},
abstract = {"Abstract Hashing techniques have been widely applied in the large-scale cross-view retrieval tasks due to the significant advantage of hash codes in computation and storage efficiency. Most existing cross-view hashing methods can only handle fully-paired scenarios, where all samples from different views are paired. However, such full pairwise correspondences may not be available in practical applications. In this paper, we propose a novel hashing method, named semi-paired hashing (SPH), to deal with a more challenging cross-view retrieval task, where only partial pairwise correspondences are provided in advance. Specifically, \{SPH\} aims to preserve within-view similarity and cross-view correlation among multi-view data. Similarity structure within each view is obtained via anchor graph. As limited samples are paired, correlation between unpaired samples is exploited via a simple yet effective approach, which estimates cross-view correlation by partial cross-view pairwise information and within-view similarity structure. Besides, we further incorporate two regression terms between original features and target binary codes to reduce the quantization loss. An efficient iterative algorithm is presented to simultaneously solve hash functions and binary codes. Extensive experiments on two benchmark datasets demonstrate the superiority of \{SPH\} over the state-of-the-art methods, especially in the semi-paired scenarios. "} 
}
@article{Efremenko2016167,
title = {"A stochastic cloud model for cloud and ozone retrievals from \{UV\} measurements "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"184"},
number = {""},
pages = {"167 - 179"},
year = {"2016"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.07.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316301911"},
author = {"Dmitry S. Efremenko and Olena Schüssler and Adrian Doicu and Diego Loyola"},
keywords = {"Stochastic radiative transfer", "Ozone retrieval", "Cloud retrieval "},
abstract = {"Abstract The new generation of satellite instruments provides measurements in and around the Oxygen A-band on a global basis and with a relatively high spatial resolution. These data are commonly used for the determination of cloud properties. A stochastic model and radiative transfer model, previously developed by the authors, is used as the forward model component in retrievals of cloud parameters and ozone total and partial columns. The cloud retrieval algorithm combines local and global optimization routines, and yields a retrieval accuracy of about 1% and a fast computational time. Retrieved parameters are the cloud optical thickness and the cloud-top height. It was found that the use of the independent pixel approximation instead of the stochastic cloud model leads to large errors in the retrieved cloud parameters, as well as, in the retrieved ozone height resolved partial columns. The latter can be reduced by using the stochastic cloud model to compute the optimal value of the regularization parameter in the framework of Tikhonov regularization. "} 
}
@article{Tasse201657,
title = {"How well do saliency-based features perform for shape retrieval? "},
journal = {"Computers & Graphics "},
volume = {"59"},
number = {""},
pages = {"57 - 67"},
year = {"2016"},
note = {""},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2016.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849316300346"},
author = {"Flora Ponjou Tasse and Jiří Kosinka and Neil Dodgson"},
keywords = {"Shape retrieval", "Salient features", "Keypoints", "Bag of features "},
abstract = {"Abstract Sparse features have been successfully used in shape retrieval, by encoding feature descriptors into global shape signatures. We investigate how sparse features based on saliency models affect retrieval and provide recommendations on good saliency models for shape retrieval. Our results show that randomly selecting points on the surface produces better retrieval performance than using any of the evaluated salient keypoint detection, including ground-truth. We discuss the reasons for and implications of this unexpected result. "} 
}
@article{Concha201695,
title = {"Retrieval of color producing agents in Case 2 waters using Landsat 8 "},
journal = {"Remote Sensing of Environment "},
volume = {"185"},
number = {""},
pages = {"95 - 107"},
year = {"2016"},
note = {"Landsat 8 Science Results "},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.03.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716301109"},
author = {"Javier A. Concha and John R. Schott"},
keywords = {"Landsat 8", "Color producing agents", "CPAs", "Case 2 waters", "Retrieval "},
abstract = {"Abstract New approaches need to be considered to solve the current high demand for color producing agent (CPA) retrievals over inland and coastal waters (Case 2 waters). Traditional retrieval algorithms are known to fail over highly turbid Case 2 waters because they were developed specifically for the open ocean (Case 1 waters). Landsat 8 provides an improved signal-to-noise ratio (SNR) and a new spectral coastal aerosol band in the blue. This additional information provides means to tackle this retrieval endeavor. A look-up-table (LUT) and spectrum-matching methodology was implemented to simultaneously retrieve CPAs, taking advantage of Landsat 8's new features. A \{LUT\} of spectral remote-sensing reflectances (Rrs) with different concentrations of \{CPAs\} was produced using the in-water radiative transfer model HydroLight. A model-based empirical line method (MoB-ELM) algorithm was developed to atmospherically correct the Landsat 8 imagery and allow direct comparison with the \{LUT\} of Rrs. This MoB-ELM atmospheric correction algorithm uses pseudo-invariant features (PIFs) from the image, ground-truth data and the HydroLight model. The retrieval algorithm was applied over three Landsat 8 scenes and shows a normalized root mean squared error (NRMSE) of about 14% for chlorophyll-a, 11% for total suspended solids (TSS), and 7% for colored dissolved organic matter (CDOM) when compared with ground-truth data. The \{CPA\} concentration maps exhibit expected trends of low concentrations in clear water and higher concentrations in turbid water. These results demonstrate that the developed algorithm allows the simultaneous mapping of concentration of all \{CPAs\} in Case 2 waters and over areas where the traditional algorithms fail or are not available due to spatial resolution. Therefore, this study shows that the Landsat 8 satellite can be utilized over Case 2 waters as long as a careful atmospheric correction is applied. "} 
}
@article{Chandrasekhar2016426,
title = {"A practical guide to \{CNNs\} and Fisher Vectors for image instance retrieval "},
journal = {"Signal Processing "},
volume = {"128"},
number = {""},
pages = {"426 - 439"},
year = {"2016"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2016.05.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168416300846"},
author = {"Vijay Chandrasekhar and Jie Lin and Olivier Morère and Hanlin Goh and Antoine Veillard"},
keywords = {"Convolutional neural networks", "Fisher Vectors", "Image instance retrieval "},
abstract = {"Abstract With deep learning becoming the dominant approach in computer vision, the use of representations extracted from Convolutional Neural Nets (CNNs) is quickly gaining ground on Fisher Vectors (FVs) as favoured state-of-the-art global image descriptors for image instance retrieval. While the good performance of \{CNNs\} for image classification are unambiguously recognised, which of the two has the upper hand in the image retrieval context is not entirely clear yet. We propose a comprehensive study that systematically evaluates \{FVs\} and \{CNNs\} for image instance retrieval. The first part compares the performances of \{FVs\} and \{CNNs\} on multiple publicly available data sets and for multiple criteria. We show that no descriptor is systematically better than the other and that performance gains can usually be obtained by using both types together. The second part of the study focuses on the impact of geometrical transformations. We show that performance of \{CNNs\} can quickly degrade in the presence of certain transformations and propose a number of ways to incorporate the required invariances in the \{CNN\} pipeline. Our findings are organised as a reference guide offering practically useful and simply implementable guidelines to anyone looking for state-of-the-art global descriptors best suited to their specific image instance retrieval problem. "} 
}
@article{Liu2016894,
title = {"Margin-based two-stage supervised hashing for image retrieval "},
journal = {"Neurocomputing "},
volume = {"214"},
number = {""},
pages = {"894 - 901"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.07.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S092523121630769X"},
author = {"Ye Liu and Yan Pan and Hanjiang Lai and Cong Liu and Jian Yin"},
keywords = {"Deep learning", "Image retrieval", "Image hashing", "Neural network", "Optimization algorithm "},
abstract = {"Abstract Similarity-preserving hashing is a widely used method for nearest neighbor search in large-scale image retrieval. Recently, supervised hashing methods are appealing in that they learn compact hash codes with fewer bits by incorporating supervised information. In this paper, we propose a new two-stage supervised hashing methods which decomposes the hash learning process into a stage of learning approximate hash codes followed by a stage of learning hash functions. In the first stage, we propose a margin-based objective to find approximate hash codes such that a pair of hash codes associating to a pair of similar (dissimilar) images has sufficiently small (large) Hamming distance. This objective results in a challenging optimization problem. We develop a coordinate descent algorithm to efficiently solve this optimization problem. In the second stage, we use convolutional neural networks to learn hash functions. We conduct extensive evaluations on several benchmark datasets with different kinds of images. The results show that the proposed margin-based hashing method has substantial improvement upon the state-of-the-art supervised or unsupervised hashing methods. "} 
}
@article{Xu2016191,
title = {"Learning unified binary codes for cross-modal retrieval via latent semantic hashing "},
journal = {"Neurocomputing "},
volume = {"213"},
number = {""},
pages = {"191 - 203"},
year = {"2016"},
note = {"Binary Representation Learning in Computer Vision "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.11.133"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216307184"},
author = {"Xing Xu and Li He and Atsushi Shimada and Rin-ichiro Taniguchi and Huimin Lu"},
keywords = {"Cross-modal retrieval", "Hashing", "Binary representation", "Sparse coding", "Matrix factorization "},
abstract = {"Abstract Nowadays the amount of multimedia data such as images and text is growing exponentially on social websites, arousing the demand of effective and efficient cross-modal retrieval. The cross-modal hashing based methods have attracted considerable attention recently as they can learn efficient binary codes for heterogeneous data, which enables large-scale similarity search. Generally, to effectively construct the cross-correlation between different modalities, these methods try to find a joint abstraction space where the heterogeneous data can be projected. Then a quantization rule is applied to convert the abstraction representation to binary codes. However, these methods may not effectively bridge the semantic gap through the latent abstraction space because they fail to capture latent information between heterogeneous data. In addition, most of these methods apply the simplest quantization scheme (i.e. sign function) which may cause information loss of the abstraction representation and result in inferior binary codes. To address these challenges, in this paper, we present a novel cross-modal hashing based method that generates unified binary codes combining different modalities. Specifically, we first extract semantic features from the modalities of images and text to capture latent information. Then these semantic features are projected to a joint abstraction space. Finally, the abstraction space is rotated to produce better unified binary codes with much less quantization loss, while preserving the locality structure of projected data. We integrate the binary code learning procedures above to develop an iterative algorithm for optimal solutions. Moreover, we further exploit the useful class label information to reduce the semantic gap between different modalities to benefit the binary code learning. Extensive experiments on four multimedia datasets show that the proposed binary coding schemes outperform several other state-of-the-art methods under cross-modal scenarios. "} 
}
@article{Zhao201512,
title = {"Image encryption using fingerprint as key based on phase retrieval algorithm and public key cryptography "},
journal = {"Optics and Lasers in Engineering "},
volume = {"72"},
number = {""},
pages = {"12 - 17"},
year = {"2015"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2015.03.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S014381661500072X"},
author = {"Tieyu Zhao and Qiwen Ran and Lin Yuan and Yingying Chi and Jing Ma"},
keywords = {"Image encryption", "Information authentication", "Asymmetric cryptosystem", "Phase retrieval "},
abstract = {"Abstract In this paper, a novel image encryption system with fingerprint used as a secret key is proposed based on the phase retrieval algorithm and \{RSA\} public key algorithm. In the system, the encryption keys include the fingerprint and the public key of \{RSA\} algorithm, while the decryption keys are the fingerprint and the private key of \{RSA\} algorithm. If the users share the fingerprint, then the system will meet the basic agreement of asymmetric cryptography. The system is also applicable for the information authentication. The fingerprint as secret key is used in both the encryption and decryption processes so that the receiver can identify the authenticity of the ciphertext by using the fingerprint in decryption process. Finally, the simulation results show the validity of the encryption scheme and the high robustness against attacks based on the phase retrieval technique. "} 
}
@article{Liu2016257,
title = {"Efficient data retrieval method for similar plasma waveforms in \{EAST\} "},
journal = {"Fusion Engineering and Design "},
volume = {"112"},
number = {""},
pages = {"257 - 260"},
year = {"2016"},
note = {""},
issn = {"0920-3796"},
doi = {"https://doi.org/10.1016/j.fusengdes.2016.09.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0920379616305786"},
author = {"Ying Liu and Jianjun Huang and Huasheng Zhou and Fan Wang and Feng Wang"},
keywords = {"EAST", "Plasma waveform", "Similarity retrieval", "Data mining", "Pattern recognition "},
abstract = {"Abstract Fusion research relies highly on data analysis due to its massive-sized database. In the present work, we propose an efficient method for searching and retrieving similar plasma waveforms in Experimental Advanced Superconducting Tokamak (EAST). Based on Piecewise Linear Aggregate Approximation (PLAA) for extracting feature values, the searching process is accomplished in two steps. The first one is coarse searching to narrow down the search space, which is carried out by means of bounding envelope. The second step is fine searching to retrieval similar waveforms, which is implemented by the angle distance. The proposed method is tested in \{EAST\} databases and turns out to have good performance in retrieving similar waveforms. "} 
}
@article{Sun2016,
title = {"Associative retrieval in spatial big data based on spreading activation with semantic ontology "},
journal = {"Future Generation Computer Systems "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0167-739X"},
doi = {"https://doi.org/10.1016/j.future.2016.10.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167739X16304137"},
author = {"Shengtao Sun and Weijing Song and Albert Y. Zomaya and Yang Xiang and Kim-Kwang Raymond Choo and Tejal Shah and Lizhe Wang"},
keywords = {"Big data", "Associative retrieval", "Spreading activation", "Ontology model", "Semantic inference "},
abstract = {"Abstract The opportunities associated with big data have helped generate significant interest, and big data analytics has emerged as an important area of study for both practitioners and researchers. For example, traditional cause–effect analysis and conditional retrieval fall short in dealing with data that are so large and complex. Associative retrieval, on the other hand, has been identified as a potential technique for big data. In this paper, we integrate the spreading activation (SA) algorithm and the ontology model in order to promote the associative retrieval of big data. In our approach, constraints based on variant weights of semantic links are considered with the aim of improving the spreading-activation process and ensuring the accuracy of search results. Semantic inference rules are also introduced to the \{SA\} algorithm to find latent spreading path and help obtain results which are more relevant. Our theoretical and experimental analysis demonstrate the utility of this approach. "} 
}
@article{Singh2016225,
title = {"A fast and efficient image retrieval system based on color and texture features "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"41"},
number = {""},
pages = {"225 - 238"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316302085"},
author = {"Chandan Singh and Kanwal Preet Kaur"},
keywords = {"Image retrieval", "Color histogram", "Texture feature", "BDIP", "BVLC "},
abstract = {"Abstract We propose a fast and efficient image retrieval system based on color and texture features. The color features are represented by color histograms and texture features are represented by block difference of inverse probabilities (BDIP) and block variation of local correlation coefficients (BVLC). It is observed that color features in combination with the texture features derived on the brightness component provides approximately similar results when color features are combined with the texture features using all three components of color, but with much less processing time. An analysis of various distance measures reveals that the square-chord distance measure outperforms the other prominent distance measures for the proposed method. Detailed experimental analysis is carried out using precision and recall on four datasets: Corel-5K, Corel-10K, \{UKbench\} and Holidays. The time analysis is also performed to compare processing speeds of the proposed method with the existing similar best methods. "} 
}
@article{Wauters2016325,
title = {"A decomposition approach to dual shuttle automated storage and retrieval systems "},
journal = {"Computers & Industrial Engineering "},
volume = {"101"},
number = {""},
pages = {"325 - 337"},
year = {"2016"},
note = {""},
issn = {"0360-8352"},
doi = {"https://doi.org/10.1016/j.cie.2016.09.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360835216303539"},
author = {"Tony Wauters and Fulgencia Villa and Jan Christiaens and Ramon Alvarez-Valdes and Greet Vanden Berghe"},
keywords = {"Logistics", "Automated storage and retrieval systems", "Warehouse", "Heuristics", "Decomposition", "Control policies", "Dual shuttle "},
abstract = {"Abstract Automated Storage and Retrieval Systems (AS/RS) have become vital in today’s distribution and production environments, however it remains necessary to equip them with more efficient operational control policies. Motivated by real situations encountered by companies employing AS/RS, the present paper studies a miniload AS/RS system, with a dual shuttle crane in which a set of storage and retrieval requests must be scheduled such that the prioritized waiting time is minimized. Dual shuttle cranes have received minimal academic attention and thus continue to pose new problems that must be solved. The miniload AS/RS problem is addressed by decomposing it into a location assignment and sequencing problem. Different heuristic strategies are introduced for making the assignments, while a general mathematical model and efficient branch and bound procedure are proposed for optimizing the sequence. Additionally, a fast metaheuristic capable of solving larger instances is also developed. A set of real-world based benchmarks with varying characteristics is generated to evaluate the proposed methods. Very small instances prove the only for which optimal sequences are found in reasonable calculation time. Experimental results demonstrate the effectiveness of the heuristic decomposition method. "} 
}
@article{Chen2016721,
title = {"3D model retrieval by sample based alignment "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"40, Part B"},
number = {""},
pages = {"721 - 731"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.08.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316301766"},
author = {"Zong-Yao Chen and Wei-Chao Lin and Chih-Fong Tsai and Shih-Wen Ke"},
keywords = {"Multimedia", "Retrieval", "3D model", "Continuous Principal Component Analysis (CPCA)", "LightField Descriptors (LFD) "},
abstract = {"Abstract In 3D model retrieval, preprocessing of 3D models is needed, in which alignment is a key factor that significantly affects retrieval performance. In particular, the anti-rotation image feature can obtain the alignment effect of 3D model views. In practice, the focus of many users of 3D models is not just on retrieval performance, but the use of aligned models for different purposes. In this paper, we propose a method, namely Sample Based Alignment (SBA) for better 3D model alignment and retrieval. In SBA, given a class, a sample model is used as the target for alignment, after which each 3D model in this class is then aligned one by one, i.e., the 3D model is actually rotated. Our experimental results, based on two 3D model datasets and performance comparisons with other methods, demonstrate the superiority of the \{SBA\} method over state-of-the-art methods in terms of 3D model retrieval and classification. "} 
}
@article{Espín201651,
title = {"No effects of psychosocial stress on memory retrieval in non-treated young students with Generalized Social Phobia "},
journal = {"Psychoneuroendocrinology "},
volume = {"73"},
number = {""},
pages = {"51 - 62"},
year = {"2016"},
note = {""},
issn = {"0306-4530"},
doi = {"https://doi.org/10.1016/j.psyneuen.2016.07.211"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306453016304541"},
author = {"Laura Espín and Mónica Marquina and Vanesa Hidalgo and Alicia Salvador and Jesús Gómez-Amor"},
keywords = {"Generalized Social Phobia", "Salivary cortisol", "TSST", "Sex differences", "Memory retrieval "},
abstract = {"Abstract Generalized Social Phobia (GSP) is a common anxiety disorder that produces clear social life disruptions. There is no consensus on the specific processes involved in its development, but the role of the hypothalamic-pituitary-adrenal (HPA) axis has been suggested. This study analyzed the effects of the cortisol response to the Trier Social Stress Test (TSST) on the memory retrieval of pictures with different emotional valences in 45 non-treated young students with \{GSP\} and 50 non-anxious (NA) subjects (mean = 19.35 years, \{SD\} = 0.18). No differences were found in the cortisol response of \{GSP\} and \{NA\} subjects to the \{TSST\} and control sessions. In addition, psychosocial stress impaired memory retrieval in both the \{GSP\} and \{NA\} groups, with no differences between them. Regarding the sex factor, no effects were found in the cortisol response to the TSST. However, during the encoding session, \{GSP\} men had higher cortisol levels than \{GSP\} women and \{NA\} subjects. There was also a significant interaction between sex and stress exposure on memory retrieval. Women recognized more unpleasant and neutral pictures than men; however, under stress, the women’s advantage disappeared, and the men’s performance improved. Sex also interacted with social phobia on positive mood, with \{GSP\} women exposed to the \{TSST\} showing the lowest positive mood. These results suggest that \{GSP\} subjects do not present an \{HPA\} axis sensitization to psychosocial stress, and they emphasize the importance of Sex in understanding stress effects on memory. "} 
}
@article{Masoumi2016339,
title = {"A spectral graph wavelet approach for nonrigid 3D shape retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"83, Part 3"},
number = {""},
pages = {"339 - 348"},
year = {"2016"},
note = {"Efficient Shape Representation, Matching, Ranking, and its Applications "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.04.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516300617"},
author = {"Majid Masoumi and Chunyuan Li and A. Ben Hamza"},
keywords = {"Shape retrieval", "Spectral graph wavelet", "Geodesic kernel", "Bag-of-features "},
abstract = {"Abstract In this paper, we propose a spectral graph wavelet approach for 3D shape retrieval using the bag-of-features paradigm. In an effort to capture both local and global characteristics of a 3D shape, we present a three-step feature description framework. Local descriptors are first extracted via the spectral graph wavelet transform having the Mexican hat wavelet as a generating kernel. Then, mid-level features are obtained by embedding local descriptors into the visual vocabulary space using the soft-assignment coding step of the bag-of-features model. A global descriptor is subsequently constructed by aggregating mid-level features weighted by a geodesic exponential kernel, resulting in a matrix representation that describes the frequency of appearance of nearby codewords in the vocabulary. Then, we compare the global descriptor of a query to all global descriptors of the shapes in the dataset using a dissimilarity measure and find the closest shape. Experimental results on two standard 3D shape benchmarks demonstrate the effectiveness of the proposed shape retrieval approach in comparison with state-of-the-art methods. "} 
}
@article{Qin2016751,
title = {"An ontology-based semantic retrieval approach for heterogeneous 3D \{CAD\} models "},
journal = {"Advanced Engineering Informatics "},
volume = {"30"},
number = {"4"},
pages = {"751 - 768"},
year = {"2016"},
note = {""},
issn = {"1474-0346"},
doi = {"https://doi.org/10.1016/j.aei.2016.10.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1474034616300891"},
author = {"Feiwei Qin and Shuming Gao and Xiaoling Yang and Ming Li and Jing Bai"},
keywords = {"Model retrieval", "Semantic-based retrieval", "Heterogeneous", "Ontology "},
abstract = {"Abstract Many types of heterogeneous \{CAD\} models created by previous product development activities are stored in enterprise databases. Searching reusable \{CAD\} models for engineer design requirements is still very difficult. In this paper, we propose an ontology-based semantic retrieval approach for heterogeneous 3D \{CAD\} models by using semantic web theory and information retrieval theory. By exploiting layered feature ontology and ontology mapping, a uniform description for heterogeneous \{CAD\} models is generated as semantic descriptor. Meanwhile, to improve the representative ability, several heuristic rules are constructed with the aid of \{SWRL\} language and ontology reasoning is acted on the semantic descriptors, which makes our retrieval system achieve better performance. Furthermore, multi-mode similarity measurement is carried out to meet engineers’ diversified requirements. We demonstrate the feasibility and effectiveness of our approach through experiments on heterogeneous 3D \{CAD\} model library. "} 
}
@article{Pedronette2016357,
title = {"A graph-based ranked-list model for unsupervised distance learning on shape retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"83, Part 3"},
number = {""},
pages = {"357 - 367"},
year = {"2016"},
note = {"Efficient Shape Representation, Matching, Ranking, and its Applications "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.05.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516301052"},
author = {"Daniel Carlos Guimarães Pedronette and Jurandy Almeida and Ricardo da S. Torres"},
keywords = {"Shape retrieval", "Ranking methods", "Graph-based approaches "},
abstract = {"Abstract Several re-ranking algorithms have been proposed recently. Some effective approaches are based on complex graph-based diffusion processes, which usually are time consuming and therefore inappropriate for real-world large scale shape collections. In this paper, we introduce a novel graph-based approach for iterative distance learning in shape retrieval tasks. The proposed method is based on the combination of graphs defined in terms of multiple ranked lists. The efficiency of the method is guaranteed by the use of only top positions of ranked lists in the definition of graphs that encode reciprocal references. Effectiveness analysis performed in three widely used shape datasets demonstrate that the proposed graph-based ranked-list model yields significant gains (up to +55.52%) when compared with the use of shape descriptors in isolation. Furthermore, the proposed method also yields comparable or superior effectiveness scores when compared with several state-of-the-art approaches. "} 
}
@article{Ankudowich2016103,
title = {"Changes in the modulation of brain activity during context encoding vs. context retrieval across the adult lifespan "},
journal = {"NeuroImage "},
volume = {"139"},
number = {""},
pages = {"103 - 113"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.06.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916302713"},
author = {"E. Ankudowich and S. Pasvanis and M.N. Rajah"},
keywords = {"Lifespan", "Aging", "Episodic memory", "Encoding", "Retrieval", "fMRI "},
abstract = {"Abstract Age-related deficits in context memory may arise from neural changes underlying both encoding and retrieval of context information. Although age-related functional changes in the brain regions supporting context memory begin at midlife, little is known about the functional changes with age that support context memory encoding and retrieval across the adult lifespan. We investigated how age-related functional changes support context memory across the adult lifespan by assessing linear changes with age during successful context encoding and retrieval. Using functional magnetic resonance imaging (fMRI), we compared young, middle-aged and older adults during both encoding and retrieval of spatial and temporal details of faces. Multivariate behavioral partial least squares (B-PLS) analysis of fMRI data identified a pattern of whole-brain activity that correlated with a linear age term and a pattern of whole-brain activity that was associated with an age-by-memory phase (encoding vs. retrieval) interaction. Further investigation of this latter effect identified three main findings: 1) reduced phase-related modulation in bilateral fusiform gyrus, left superior/anterior frontal gyrus and right inferior frontal gyrus that started at midlife and continued to older age, 2) reduced phase-related modulation in bilateral inferior parietal lobule that occurred only in older age, and 3) changes in phase-related modulation in older but not younger adults in left middle frontal gyrus and bilateral parahippocampal gyrus that was indicative of age-related over-recruitment. We conclude that age-related reductions in context memory arise in midlife and are related to changes in perceptual recollection and changes in fronto-parietal retrieval monitoring. "} 
}
@article{Freitas2016303,
title = {"\{TSS\} &amp; TSB: Tensor scale descriptors within circular sectors for fast shape retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"83, Part 3"},
number = {""},
pages = {"303 - 311"},
year = {"2016"},
note = {"Efficient Shape Representation, Matching, Ranking, and its Applications "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.06.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516301234"},
author = {"Anderson M. Freitas and Ricardo da S. Torres and Paulo A.V. Miranda"},
keywords = {"Shape descriptor", "Shape matching", "Shape similarity", "Content-based image retrieval", "Tensor scale "},
abstract = {"Abstract We propose two novel region-based descriptors for shape-based image retrieval and analysis, which are built upon an extended tensor scale based on the Euclidean Distance Transform (EDT). First the tensor scale algorithm is applied to extract local structure thickness, orientation, and anisotropy as represented by the largest ellipse within a homogeneous region centered at each image pixel. In this work, we extend the local orientation to 360°. Then, for the first proposed descriptor, named Tensor Scale Sector descriptor (TSS), the local distributions of relative orientations within circular sectors are used to compose a fixed-length feature vector for a region-based representation. For the second method, named Tensor Scale Band descriptor (TSB), we consider histograms of relative orientations for each circular concentric band to compose a fixed-length feature vector with linear time matching. Experimental results with MPEG-7 and \{MNIST\} datasets are presented to illustrate and validate the methods. \{TSS\} can achieve high retrieval values comparable to state-of-the-art methods, which usually rely on time-consuming correspondence optimization algorithms, but uses a simpler and faster distance function, while the even faster linear complexity of \{TSB\} leads to a suitable and better solution for very large shape collections. "} 
}
@article{Zheng2016109,
title = {"Practicing more retrieval routes leads to greater memory retention "},
journal = {"Acta Psychologica "},
volume = {"169"},
number = {""},
pages = {"109 - 118"},
year = {"2016"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2016.05.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691816301093"},
author = {"Jun Zheng and Wei Zhang and Tongtong Li and Zhaomin Liu and Liang Luo"},
keywords = {"Retrieval variability", "Retrieval routes", "Memory retention "},
abstract = {"Abstract A wealth of research has shown that retrieval practice plays a significant role in improving memory retention. The current study focused on one simple yet rarely examined question: would repeated retrieval using two different retrieval routes or using the same retrieval route twice lead to greater long-term memory retention? Participants elaborately learned 22 Japanese-Chinese translation word pairs using two different mediators. Half an hour after the initial study phase, the participants completed two retrieval sessions using either one mediator (Tm1Tm1) or two different mediators (Tm1Tm2). On the final test, which was performed 1 week after the retrieval practice phase, the participants received only the cue with a request to report the mediator (M1 or M2) followed by the target (Experiment 1) or only the mediator (M1 or M2) with a request to report the target (Experiment 2). The results of Experiment 1 indicated that the participants who practiced under the Tm1Tm2 condition exhibited greater target retention than those who practiced under the Tm1Tm1 condition. This difference in performance was due to the significant disadvantage in mediator retrieval and decoding of the unpracticed mediator under the Tm1Tm1 condition. Although mediators were provided to participants on the final test in Experiment 2, decoding of the unpracticed mediators remained less effective than decoding of the practiced mediators. We conclude that practicing multiple retrieval routes leads to greater memory retention than focusing on a single retrieval route. Thus, increasing retrieval variability during repeated retrieval practice indeed significantly improves long-term retention in a delay test. "} 
}
@article{Kasiri2016561,
title = {"The Impact of Task Complexity on Cognitive Processes of \{L2\} Writers and Writing Quality: The Case of Writing Expertise, L1, and Lexical Retrieval "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"232"},
number = {""},
pages = {"561 - 568"},
year = {"2016"},
note = {"International Conference on Teaching and Learning English as an Additional Language, GlobELT 2016, 14-17 April 2016, Antalya, Turkey "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2016.10.077"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877042816313106"},
author = {"Forough Kasiri and Ali Mohammad Fazilatfar"},
keywords = {"Task complexity", "Cognitive writing processes", "Text quality", "Writing expertise", "L1 &amp; \{L2\} writing", "Lexical retrieval "},
abstract = {"Abstract This study scrutinized the effect of task complexity on cognitive processes of \{L2\} writers with respect to \{L2\} writing expertise, speed of lexical retrieval, L1, and text quality. Sixty \{TEFL\} students with different writing expertise completed a computerized Written Productive Translation, as well as three \{L1\} and \{L2\} argumentative writing tasks, manipulated in regard to resource-dispersing dimensions followed-up by retrospective questionnaires. The texts were analysed in terms of accuracy, fluency, and syntactic complexity. Running \{MANOVA\} indicated that task complexity had no effect on fluency, accuracy, and syntactic complexity. However, the speed of retrieval was remarkably affected by writer's expertise. Moreover, there was no difference between \{L2\} and \{L1\} writing processes. The upshot essentially substantiated Cummins⿿ (1978) Interdependence Hypothesis, and Kellogg's (1990) Overload hypothesis while laying a great stress on the rate of lexical retrieval for improvement of writing expertise. "} 
}
@article{Xiaofeng2016210,
title = {"Prior knowledge level dissociates effects of retrieval practice and elaboration "},
journal = {"Learning and Individual Differences "},
volume = {"51"},
number = {""},
pages = {"210 - 214"},
year = {"2016"},
note = {""},
issn = {"1041-6080"},
doi = {"https://doi.org/10.1016/j.lindif.2016.09.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S104160801630214X"},
author = {"Ma Xiaofeng and Yang Xiao-e and Li Yanru and Zhou AiBao"},
keywords = {"Prior knowledge level", "Retrieval practice", "Elaboration", "Episodic context account "},
abstract = {"Abstract Prior knowledge level varies between individuals and influences the effectiveness of learning strategies. This study tested the influence of prior knowledge level on effects of retrieval practice and elaboration. Psychology major students (more familiarity with psychology key terms) and non-psychology major students (less familiarity with psychology key terms) learned five lists of psychology key terms under three conditions: retrieval practice, elaboration, and control. The result revealed an interaction between prior knowledge level and learning strategy. There was no significant difference in proportion of final recall between psychology major students and non-psychology major students in the retrieval practice condition, but proportion of final recall was notably higher in psychology major students than non-psychology major students in the elaboration condition. Therefore, prior knowledge level influenced effects of retrieval practice and elaboration due to differences in their underlying mechanisms, supporting the episodic context account. "} 
}
@article{Tu201699,
title = {"Topic modeling and improvement of image representation for large-scale image retrieval "},
journal = {"Information Sciences "},
volume = {"366"},
number = {""},
pages = {"99 - 120"},
year = {"2016"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.05.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S002002551630353X"},
author = {"Nguyen Anh Tu and Dong-Luong Dinh and Mostofa Kamal Rasel and Young-Koo Lee"},
keywords = {"Topic modeling", "Probabilistic graphical model", "Image retrieval", "Image representation", "Image coding", "Bag-of-visual words "},
abstract = {"Abstract In this paper, we present a new visual search system for finding similar images in a large database. However, there are a number of challenges regarding the robustness of the image representations and the efficiency of the retrieval framework. To tackle these challenges, we first propose an encoding technique based on soft-assignment of local features to convert an entire image into a single vector, which is a compact and discriminative representation. This encoded vector is suitable for most types of efficient indexing methods to produce an initial result. To compensate for the lack of incorporating geometric and object-related information during the encoding scheme, we then propose a probabilistic topic model to formalize the spatial structure among the local features. Moreover, the topic model allows us to effectively extract the object and background regions from the image. This is performed by a Markov Chain Monte Carlo algorithm for approximate inference. Finally, benefiting from the extracted objects in each image, we present a re-ranking scheme to automatically refine the initial search results. Our proposed retrieval framework has two major advantages: i) an aggregation strategy through soft-assignment improves the discriminative power of the representation, which has a determinative effect on the retrieval precision; and ii) the probabilistic latent topic model enables us to not only gain insight into the spatial structure of the image, but also handle a large variation in the object appearance. The experimental results from four benchmark datasets show that our approach provides competitive accuracy, and runs about ten times faster. Our studies also verify that proposed approach works effectively on large-scale databases of millions of images. "} 
}
@article{Bhandarkar2016991,
title = {"Archiving and retrieval of experimental data using \{SAN\} based centralized storage system for SST-1 "},
journal = {"Fusion Engineering and Design "},
volume = {"112"},
number = {""},
pages = {"991 - 994"},
year = {"2016"},
note = {""},
issn = {"0920-3796"},
doi = {"https://doi.org/10.1016/j.fusengdes.2016.05.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0920379616303775"},
author = {"Manisha Bhandarkar and Harish Masand and Aveg Kumar and Kirit Patel and Jasraj Dhongde and Hitesh Gulati and Kirti Mahajan and Hitesh Chudasama and Subrata Pradhan"},
keywords = {"Storage area network", "GFS", "RAID", "Tiered storage", "Archival", "Retrieval "},
abstract = {"Abstract \{SAN\} (Storage Area Network, a high-speed, block level storage device) based centralized data storage system of SST-1 (Steady State superconducting Tokamak) has envisaged to address the need of availability of SST-1 operation &amp; experimental data centrally for archival as well as retrieval [2]. Considering the initial data volume requirement, ∼10 \{TB\} (Terabytes) capacity of \{SAN\} based data storage system has configured/installed with optical fiber backbone with compatibility considerations of existing Ethernet network of SST-1. The \{SAN\} based data storage system has been designed/configured with 3-tiered architecture and \{GFS\} (Global File System) cluster file system with multipath support. Tier-1 is of ∼3 \{TB\} (frequent access and low data storage capacity) comprises of Fiber channel (FC) based hard disks for optimum throughput. Tier-2 is of ∼6 \{TB\} (less frequent access and high data storage capacity) comprises of \{SATA\} based hard disks. Tier-3 will be planned later to store offline historical data. In the \{SAN\} configuration two tightly coupled storage servers (with cluster configuration) are working together to achieve increase performance, reliability, distribute workload and provides access to the files from any server regardless of the physical location of the file. Different \{RAID\} (Redundant Array of Independent Disks) groups are created with both, \{FC\} and \{SATA\} hard disks to increase reliability, security and performance of the storage system. The adopted \{SAN\} based data storage for SST-1 is a modular, robust, and allows future expandability. The storage modules can be added as and when required without changing the existing storage architecture. The data read/write time of the configured system is adequate enough to cater the present throughput requirements of individual subsystems. Sufficient redundancy in terms of hardware has been incorporated to assure the uninterrupted experimental data availability 24 × 7 within intranet. The installed storage system can be expanded up to ∼100 \{TB\} of capacity with the existing controller pair presents in the \{SAN\} configuration. "} 
}
@article{Pedronette201666,
title = {"A correlation graph approach for unsupervised manifold learning in image retrieval tasks "},
journal = {"Neurocomputing "},
volume = {"208"},
number = {""},
pages = {"66 - 79"},
year = {"2016"},
note = {"SI: BridgingSemantic "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.03.081"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216304726"},
author = {"Daniel Carlos Guimarães Pedronette and Ricardo da S. Torres"},
keywords = {"Content-based image retrieval", "Unsupervised manifold learning", "Correlation graph", "Strongly connected components "},
abstract = {"Abstract Effectively measuring the similarity among images is a challenging problem in image retrieval tasks due to the difficulty of considering the dataset manifold. This paper presents an unsupervised manifold learning algorithm that takes into account the intrinsic dataset geometry for defining a more effective distance among images. The dataset structure is modeled in terms of a Correlation Graph (CG) and analyzed using Strongly Connected Components (SCCs). While the Correlation Graph adjacency provides a precise but strict similarity relationship, the Strongly Connected Components analysis expands these relationships considering the dataset geometry. A large and rigorous experimental evaluation protocol was conducted for different image retrieval tasks. The experiments were conducted in different datasets involving various image descriptors. Results demonstrate that the manifold learning algorithm can significantly improve the effectiveness of image retrieval systems. The presented approach yields better results in terms of effectiveness than various methods recently proposed in the literature. "} 
}
@article{Guo2016151,
title = {"Combined retrieval: A convenient and precise approach for Internet image retrieval "},
journal = {"Information Sciences "},
volume = {"358–359"},
number = {""},
pages = {"151 - 163"},
year = {"2016"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2016.04.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025516302304"},
author = {"Kehua Guo and Ruifang Zhang and Zhurong Zhou and Yayuan Tang and Li Kuang"},
keywords = {"Internet image retrieval", "Retrieval intention", "User experience", "Perceptual hash", "Image search engine "},
abstract = {"Abstract In Internet image retrieval, returned results may fail to satisfy the retrieval intentions of users because of noisy annotations. Solving the ambiguity in image retrieval by combining text features and visual information has been a challenging problem. In this paper, we propose a convenient and precise approach for Internet image retrieval called combined retrieval (CR), which costs minimized extra feedback to retrieve more results reflecting the query intentions of users. \{CR\} is used as a plug-in to commercial image search engines, such as Google and Bing, which are defined as host image search engines (HISE). First, in the returned result from HISE, document analysis is utilized to construct the image categories based on the Wikipedia categorical index. Returned images will be automatically categorized, and a convenient interface is provided for user feedback. Second, we describe the re-retrieval algorithm in which image data combined with particular text information will be sent to the \{HISE\} for re-retrieval. Finally, a perceptual hash based re-rank algorithm to optimize the returned images is proposed. Experimental results indicate that \{CR\} can significantly improve the retrieval performance with minimum effort and can provide a notably convenient user experience. "} 
}
@article{Cheng2016111,
title = {"Encrypted \{JPEG\} image retrieval using block-wise feature comparison "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"40, Part A"},
number = {""},
pages = {"111 - 117"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.06.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316301080"},
author = {"Hang Cheng and Xinpeng Zhang and Jiang Yu and Yuan Zhang"},
keywords = {"Image retrieval", "Image encryption", "JPEG image", "Feature descriptor "},
abstract = {"Abstract This paper proposes a novel scheme for encrypted \{JPEG\} image retrieval, which includes image encryption and retrieval phases. Using the scheme, the content owner encrypts \{JPEG\} images by jointly applying permutation cipher and stream cipher to their corresponding bit-streams, and then transmits encrypted versions to a database server. With an encrypted query image, although the server learns nothing about the plaintext content, it may extract local statistical feature of intra-block \{AC\} coefficients using a new feature descriptor. Subsequently, exploiting block-wise feature comparison, the server can measure the similarity between encrypted query image and database image. After that, the encrypted images with plaintext content similar to the query image are returned to the authorized user. Experimental results show that the proposed scheme can ensure both format compliance and file size preservation while providing effective retrieval service in encrypted domain. "} 
}
@article{Zhang2016684,
title = {"Multi-scale object retrieval via learning on graph from multimodal data "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"684 - 692"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.05.053"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216304908"},
author = {"Yongsheng Zhang and Tsuyoshi Yamamoto and Yoshinori Dobashi"},
keywords = {"Object retrieval", "Multi-scale", "Learning on graph", "Multimodal data "},
abstract = {"Abstract Object retrieval has attracted much research attention in recent years. Confronting object retrieval, how to estimate the relevance among objects is a challenging task. In this paper, we focus on view-based object retrieval and propose a multi-scale object retrieval algorithm via learning on graph from multimodal data. In our work, shape features are extracted from each view of objects. The relevance among objects is formulated in a hypergraph structure, where the distance of different views in the feature space is employed to generate the connection in the hypergraph. To achieve better representation performance, we propose a multi-scale hypergraph structure to model object correlations. The learning on graph is conducted to estimate the optimal relevance among these objects, which are used for object retrieval. To evaluate the performance of the proposed method, we conduct experiments on the National Taiwan University dataset and the \{ETH\} dataset. Experimental results and comparisons with the state-of-the-art methods demonstrate the effectiveness of the proposed method. "} 
}
@article{FernandezBeltran20151,
title = {"Incremental probabilistic Latent Semantic Analysis for video retrieval "},
journal = {"Image and Vision Computing "},
volume = {"38"},
number = {""},
pages = {"1 - 12"},
year = {"2015"},
note = {""},
issn = {"0262-8856"},
doi = {"https://doi.org/10.1016/j.imavis.2015.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0262885615000335"},
author = {"Ruben Fernandez-Beltran and Filiberto Pla"},
keywords = {"Content-based Video Retrieval", "Latent topics", "probabilistic Latent Semantic Analysis (pLSA)", "Relevance Feedback", "Information retrieval "},
abstract = {"Abstract Recent research trends in Content-based Video Retrieval have shown topic models as an effective tool to deal with the semantic gap challenge. In this scenario, this paper has a dual target: (1) it is aimed at studying how the use of different topic models (pLSA, \{LDA\} and FSTM) affects video retrieval performance; (2) a novel incremental topic model (IpLSA) is presented in order to cope with incremental scenarios in an effective and efficient way. A comprehensive comparison among these four topic models using two different retrieval systems and two reference benchmarking video databases is provided. Experiments revealed that pLSA is the best model in sparse conditions, \{LDA\} tend to outperform the rest of the models in a dense space and IpLSA is able to work properly in both cases. "} 
}
@article{Qi2016838,
title = {"Quality biased multimedia data retrieval in microblogs "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"40, Part B"},
number = {""},
pages = {"838 - 846"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316301742"},
author = {"Shuhan Qi and Peiguang Jing and Xuan Wang and Liqiang Nie"},
keywords = {"Microblog retrieval", "Quality model", "Multiview embedding "},
abstract = {"Abstract With the rapid development of social media platforms, huge amount of user generated contents (UGC) are generated ceaselessly. In recent years, content based microblog retrieval has attracted extensive research attention. Effective microblog retrieval services complex analysis of short text and multimedia contents. In this paper, we present a quality biased multimedia microblog retrieval framework. First, we develop an anchor graph based multiview embedding framework which maps the multimedia content features into a unified latent space. Then, the content matching scores of testing microblogs related to the query are obtained by a Markov random field. Further, we employ an quality model to incorporate both microblog quality and content matching. As compared with the state-of-art methods, experimental results demonstrate the effectiveness of the proposed approach. "} 
}
@article{Farinella201623,
title = {"Retrieval and classification of food images "},
journal = {"Computers in Biology and Medicine "},
volume = {"77"},
number = {""},
pages = {"23 - 39"},
year = {"2016"},
note = {""},
issn = {"0010-4825"},
doi = {"https://doi.org/10.1016/j.compbiomed.2016.07.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010482516301822"},
author = {"Giovanni Maria Farinella and Dario Allegra and Marco Moltisanti and Filippo Stanco and Sebastiano Battiato"},
keywords = {"Food retrieval", "Food classification", "Food representation", "Textons", "Anti-Textons "},
abstract = {"Abstract Automatic food understanding from images is an interesting challenge with applications in different domains. In particular, food intake monitoring is becoming more and more important because of the key role that it plays in health and market economies. In this paper, we address the study of food image processing from the perspective of Computer Vision. As first contribution we present a survey of the studies in the context of food image processing from the early attempts to the current state-of-the-art methods. Since retrieval and classification engines able to work on food images are required to build automatic systems for diet monitoring (e.g., to be embedded in wearable cameras), we focus our attention on the aspect of the representation of the food images because it plays a fundamental role in the understanding engines. The food retrieval and classification is a challenging task since the food presents high variableness and an intrinsic deformability. To properly study the peculiarities of different image representations we propose the UNICT-FD1200 dataset. It was composed of 4754 food images of 1200 distinct dishes acquired during real meals. Each food plate is acquired multiple times and the overall dataset presents both geometric and photometric variabilities. The images of the dataset have been manually labeled considering 8 categories: Appetizer, Main Course, Second Course, Single Course, Side Dish, Dessert, Breakfast, Fruit. We have performed tests employing different representations of the state-of-the-art to assess the related performances on the UNICT-FD1200 dataset. Finally, we propose a new representation based on the perceptual concept of Anti-Textons which is able to encode spatial information between Textons outperforming other representations in the context of food retrieval and Classification. "} 
}
@article{Ellis2017S356,
title = {"(1088) - The \{ERO\} Form: The European Retrieval of Organs Initiative to Standardise Essential Information "},
journal = {"The Journal of Heart and Lung Transplantation "},
volume = {"36"},
number = {"4, Supplement"},
pages = {"S356 - "},
year = {"2017"},
note = {"\{ISHLT\} 37th Annual Meeting and Scientific Sessions "},
issn = {"1053-2498"},
doi = {"https://doi.org/10.1016/j.healun.2017.01.1000"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053249817310252"},
author = {"C. Ellis and K. Morley"} 

}
@article{Zhao201533,
title = {"Topic-centric and semantic-aware retrieval system for internet of things "},
journal = {"Information Fusion "},
volume = {"23"},
number = {""},
pages = {"33 - 42"},
year = {"2015"},
note = {""},
issn = {"1566-2535"},
doi = {"https://doi.org/10.1016/j.inffus.2014.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1566253514000062"},
author = {"Feng Zhao and Zheng Sun and Hai Jin"},
keywords = {"Internet of things", "Information retrieval", "Knowledge network", "Topic centric", "Semantic awareness "},
abstract = {"Abstract The Internet of things (IoT) has been considered as one of the promising paradigms that can allow people and objects to seamlessly interact. So far, numerous applications and services have been proposed, such as retrieval service. The retrieval, however, faces a big challenge in IoT because the data belongs to different domains and user interaction with the surrounding environment is constrained. This paper proposes Acrost, a retrieval system based on topic discovery and semantic awareness in IoT environment. The initial contents with interesting information is obtained through the combination of two topic centric collectors. The metadata is extracted by aggregating regular expression-based and conditional random fields-based approaches. Moreover, the semantic-aware retrieval is achieved by parsing the query and ranking the relevance of contents. In addition, we present a case study on academic conference retrieval to validate the proposed approaches. Experimental results show that the proposed system can significantly improve the response time and efficiency of topic self-adaptive retrieval manner. "} 
}
@article{Koyano2016518,
title = {"Laminar Module Cascade from Layer 5 to 6 Implementing Cue-to-Target Conversion for Object Memory Retrieval in the Primate Temporal Cortex "},
journal = {"Neuron "},
volume = {"92"},
number = {"2"},
pages = {"518 - 529"},
year = {"2016"},
note = {""},
issn = {"0896-6273"},
doi = {"https://doi.org/10.1016/j.neuron.2016.09.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0896627316305839"},
author = {"Kenji W. Koyano and Masaki Takeda and Teppei Matsui and Toshiyuki Hirabayashi and Yohei Ohashi and Yasushi Miyashita"},
keywords = {"monkey", "temporal cortex", "MRI", "memory retrieval", "cortical layer", "microcircuit", "laminar localization "},
abstract = {"Summary The cerebral cortex computes through the canonical microcircuit that connects six stacked layers; however, how cortical processing streams operate in vivo, particularly in the higher association cortex, remains elusive. By developing a novel MRI-assisted procedure that reliably localizes recorded single neurons at resolution of six individual layers in monkey temporal cortex, we show that transformation of representations from a cued object to a to-be-recalled object occurs at the infragranular layer in a visual cued-recall task. This cue-to-target conversion started in layer 5 and was followed by layer 6. Finally, a subset of layer 6 neurons exclusively encoding the sought target became phase-locked to surrounding field potentials at theta frequency, suggesting that this coordinated cell assembly implements cortical long-distance outputs of the recalled target. Thus, this study proposes a link from local computation spanning laminar modules of the temporal cortex to the brain-wide network for memory retrieval in primates. "} 
}
@article{Guillaume2016942,
title = {"Anesthésie topique par gel de lidocaïne intravaginal pour ponction ovocytaire : retour d’expérience "},
journal = {"Journal de Gynécologie Obstétrique et Biologie de la Reproduction "},
volume = {"45"},
number = {"8"},
pages = {"942 - 947"},
year = {"2016"},
note = {""},
issn = {"0368-2315"},
doi = {"https://doi.org/10.1016/j.jgyn.2016.05.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0368231516300382"},
author = {"A. Guillaume and E. Schuller-Dufour and V. Faitot and O. Pirrello and C. Rongières and J. Ohl and I. Nisand and K. Bettahar"},
keywords = {"ésAnalgésie", "Gel de lidocaine", "Ponction ovocytaire", "Analgesia", "Lidocaine gel", "Oocyte retrieval "},
abstract = {"Summary A recent adverse effect of a paracervical block (cardiac arrest) occurred during an oocyte retrieval (OR), forcing us to reconsider our pain management during OR. Since then, we decided to use intravaginal lidocaine gel as analgesia during OR. Objectives To evaluate the pain during \{OR\} after intravaginal lidocaine gel analgesia and to evaluate the motivations of women choosing this technique. Methods A monocentric observational study was performed on 200 patients. Pain was measured using a numeric pain scale during and after oocyte retrieval. The tolerance of the procedure was evaluated through a patient questionnaire. Results Median maximal pain was 5 ± 2.3 (0–10) per-retrieval and 3 ± 2.2 (0–10) post-retrieval. The procedure was considered bearable by 85.5% of the patients and 81.5% of them would choose this method in case of new oocyte retrieval. No adverse effect occurred during the study. Conclusion The use of intravaginal lidocaine gel seems an acceptable analgesia alternative during oocyte retrieval. "} 
}
@article{Wang2016387,
title = {"Deep sketch feature for cross-domain image retrieval "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"387 - 397"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.04.046"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216303198"},
author = {"Xinggang Wang and Xiong Duan and Xiang Bai"},
keywords = {"Sketch recognition", "Image retrieval", "Deep learning "},
abstract = {"Abstract Deep learning has been proven to be very effective for various image recognition tasks, e.g., image classification, semantic segmentation, image retrieval, shape classification, etc. However, existing works on deep learning for image recognition mainly focus on either natural image data or binary shape data. In this paper, we show that deep convolutional neural networks (DCNN) is also suitable for cross-domain image recognition, i.e., using sketch as query to retrieve natural images in a large dataset. To solve this kind of cross-domain problem, we propose to train \{CNN\} jointly using image data and sketch data in a novel way. The learned deep feature is effective for cross-domain image retrieval – using simple Euclidean distance on the learned feature can significantly outperform the previous state-of-the-arts. In addition, we find that pre-training and a feasible data-argumentation for \{DCNN\} can largely surpass human-level performance in the standard sketch classification benchmark. "} 
}
@article{Li2016202,
title = {"SERVE: Soft and Equalized Residual \{VEctors\} for image retrieval "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"202 - 212"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.04.047"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216303253"},
author = {"Jun Li and Chang Xu and Mingming Gong and Junliang Xing and Wankou Yang and Changyin Sun"},
keywords = {"SERVE", "Manifolds", "Multi-graph embedding", "Graph ensemble", "Image retrieval "},
abstract = {"Abstract In the last decade, a wide variety of image signatures, e.g., Bag-of-Visual-Words (BOVW), Fisher Vector (FV), and Vector of Locally Aggregated Descriptor (VLAD), have been developed for effective image retrieval. These image signatures, however, are either computationally expensive or simplified for the purpose of trading accuracy for efficiency. To simultaneously guarantee efficiency and effectiveness, we propose a novel image signature termed Soft and Equalized Residual \{VEctors\} (SERVE) which is more discriminatively formulated and maintains higher accuracy. It improves \{VLAD\} by encoding the variability in within-cluster feature points into the summation of Residual Vectors (RV) while manifesting superiority in computational efficiency over FV. To find the latent low-dimensional manifolds underlying in the \{SERVE\} feature space, we propose to partition the original feature space into separate subspaces by random projections and employ multi-graph embedding to obtain additional performance gain. In particular, we make use of two fusion strategies for graph ensemble to generate a holistic representation. Extensive empirical studies carried out on the three retrieval-specific public benchmarks reveal that our method outperforms existing state-of-the-art methods and provides a promising paradigm for the image retrieval task. "} 
}
@article{deVes201699,
title = {"A novel dynamic multi-model relevance feedback procedure for content-based image retrieval "},
journal = {"Neurocomputing "},
volume = {"208"},
number = {""},
pages = {"99 - 107"},
year = {"2016"},
note = {"SI: BridgingSemantic "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.02.073"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216304751"},
author = {"Esther de Ves and Xaro Benavent and Inmacula Coma and Guillermo Ayala"},
keywords = {"Semantic Gap", "Principal Component Analysis", "Multimedia Retrieval", "Relevance feedback "},
abstract = {"Abstract This paper deals with the problem of image retrieval in large databases with a big semantic gap by a relevance feedback procedure. We present a novel algorithm for modelling the users׳s preferences in the content-based image retrieval system. The proposed algorithm considers the probability of an image belonging to the set of those sought by the user, and estimates the parameters of several local logistic regression models whose inputs are the low-level image features. A Principal Component Analysis method is applied to the original vector to reduce its high dimensionality. The relevance probabilities predicted by these local models are combined by means of a weighted average. These weights are obtained according to the variance explained by the group of principal components used for each local model. These models are dynamically estimated in each iteration of the relevance feedback algorithm until the user is satisfied. This novel procedure has been tested in a collection with a large semantic gap, the Wikipedia collection. Two types of experiments have been performed, one with an automatic user and another with a typical user. The method is compared to some recent similar approaches in literature, obtaining very good performance in terms of the \{MAP\} evaluation measure. "} 
}
@article{He201626,
title = {"A framework of query expansion for image retrieval based on knowledge base and concept similarity "},
journal = {"Neurocomputing "},
volume = {"204"},
number = {""},
pages = {"26 - 32"},
year = {"2016"},
note = {"Big Learning in Social Media AnalyticsContaining a selection of papers from the 2014 International Conference on Security, Pattern Analysis, and Cybernetics (ICSPAC2014) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.11.102"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216300972"},
author = {"Yuanfeng He and Yuanxi Li and Jiajia Lei and C.H.C Leung"},
keywords = {"Image retrieval", "Knowledge base", "Query expansion "},
abstract = {"Abstract We study several semantic concept-based query expansion and re-ranking scheme and compare different ontology-based expansion methods in image search and retrieval. To improve the query expansion efficiency and accuracy, we employ the \{CYC\} knowledge base to generate the expansion candidate concepts, while filter and rank the expansion results by calculating concept similarities using the Semantic Relatedness Metrics. Using our knowledge-based query expansion in image retrieval, the efficiency and accuracy has been improved. "} 
}
@article{Huang2015197,
title = {"A repeating pattern based Query-by-Humming fuzzy system for polyphonic melody retrieval "},
journal = {"Applied Soft Computing "},
volume = {"33"},
number = {""},
pages = {"197 - 206"},
year = {"2015"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2015.04.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494615002252"},
author = {"Yo-Ping Huang and Shin-Liang Lai and Frode Eika Sandnes"},
keywords = {"Fuzzy inference system", "Content-based music information retrieval", "Query-by-Humming", "Repeating pattern", "Pitch contour "},
abstract = {"Abstract Query-by-Humming involves retrieving music with a melody that matches the hummed query. An improved Query-by-Humming system for extracting pitch contour information based on a fuzzy inference model is introduced. In addition, an improved content-based music repeating pattern extraction model is introduced. Our bar-indexing method can extract the melody, identify repeating patterns and handle polyphonic \{MIDI\} files. To verify the effectiveness of the system, 15 volunteers recorded queries that were fed as input to the system and the longest common subsequence (LCS) was used to identify the most related top N matches. The system achieves 70% accuracy among the top 5 items retrieved. "} 
}
@article{Bhaumik20161008,
title = {"Hybrid soft computing approaches to content based video retrieval: A brief review "},
journal = {"Applied Soft Computing "},
volume = {"46"},
number = {""},
pages = {"1008 - 1029"},
year = {"2016"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2016.03.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494616301314"},
author = {"Hrishikesh Bhaumik and Siddhartha Bhattacharyya and Mausumi Das Nath and Susanta Chakraborty"},
keywords = {"Content-based video retrieval", "Video segmentation", "Soft computing", "Hybrid soft computing "},
abstract = {"Abstract There has been an unrestrained growth of videos on the Internet due to proliferation of multimedia devices. These videos are mostly stored in unstructured repositories which pose enormous challenges for the task of both image and video retrieval. Users aim to retrieve videos of interest having content which is relevant to their need. Traditionally, low-level visual features have been used for content based video retrieval (CBVR). Consequently, a gap existed between these low-level features and the high level semantic content. The semantic differential was partially bridged by proliferation of research on interest point detectors and descriptors, which represented mid-level features of the content. The computational time and human interaction involved in the classical approaches for \{CBVR\} are quite cumbersome. In order to increase the accuracy, efficiency and effectiveness of the retrieval process, researchers resorted to soft computing paradigms. The entire retrieval task was automated to a great extent using individual soft computing components. Due to voluminous growth in the size of multimedia databases, augmented by an exponential rise in the number of users, integration of two or more soft computing techniques was desirable for enhanced efficiency and accuracy of the retrieval process. The hybrid approaches serve to enhance the overall performance and robustness of the system with reduced human interference. This article is targeted to focus on the relevant hybrid soft computing techniques which are in practice for content-based image and video retrieval. "} 
}
@article{Sciammarella2016100,
title = {"Mathematical models utilized in the retrieval of displacement information encoded in fringe patterns "},
journal = {"Optics and Lasers in Engineering "},
volume = {"77"},
number = {""},
pages = {"100 - 111"},
year = {"2016"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2015.07.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S014381661500189X"},
author = {"Cesar A. Sciammarella and Luciano Lamberti"},
keywords = {"Fringe pattern analysis", "Basic mathematical models for detection and recovery of displacements", "Phase and amplitude modulation", "Hilbert transform", "Multiphase methods and in-quadrature signals analysis "},
abstract = {"Abstract All the techniques that measure displacements, whether in the range of visible optics or any other form of field methods, require the presence of a carrier signal. A carrier signal is a wave form modulated (modified) by an input, deformation of the medium. A carrier is tagged to the medium under analysis and deforms with the medium. The wave form must be known both in the unmodulated and the modulated conditions. There are two basic mathematical models that can be utilized to decode the information contained in the carrier, phase modulation or frequency modulation, both are closely connected. Basic problems connected to the detection and recovery of displacement information that are common to all optical techniques will be analyzed in this paper, focusing on the general theory common to all the methods independently of the type of signal utilized. The aspects discussed are those that have practical impact in the process of data gathering and data processing. "} 
}
@article{Doria2016424,
title = {"Structured patterns retrieval using a metric attractor network: Application to fingerprint recognition "},
journal = {"Physica A: Statistical Mechanics and its Applications "},
volume = {"457"},
number = {""},
pages = {"424 - 436"},
year = {"2016"},
note = {""},
issn = {"0378-4371"},
doi = {"https://doi.org/10.1016/j.physa.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378437116002685"},
author = {"Felipe Doria and Rubem Erichsen Jr. and Mario González and Francisco B. Rodríguez and Ángel Sánchez and David Dominguez"},
keywords = {"Attractor network", "Small-world", "Fingerprint retrieval", "Neurodynamics", "Structured patterns "},
abstract = {"Abstract The ability of a metric attractor neural networks (MANN) to learn structured patterns is analyzed. In particular we consider collections of fingerprints, which present some local features, rather than being modeled by random patterns. The network retrieval proved to be robust to varying the pattern activity, the threshold strategy, the topological arrangement of the connections, and for several types of noisy configuration. We found that the lower the fingerprint patterns activity is, the higher the load ratio and retrieval quality are. A simplified theoretical framework, for the unbiased case, is developed as a function of five parameters: the load ratio, the finiteness connectivity, the density degree of the network, randomness ratio, and the spatial pattern correlation. Linked to the latter appears a new neural dynamics variable: the spatial neural correlation. The theory agrees quite well with the experimental results. "} 
}
@article{Zhu201641,
title = {"Deep Learning Representation using Autoencoder for 3D Shape Retrieval "},
journal = {"Neurocomputing "},
volume = {"204"},
number = {""},
pages = {"41 - 50"},
year = {"2016"},
note = {"Big Learning in Social Media AnalyticsContaining a selection of papers from the 2014 International Conference on Security, Pattern Analysis, and Cybernetics (ICSPAC2014) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.08.127"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216301047"},
author = {"Zhuotun Zhu and Xinggang Wang and Song Bai and Cong Yao and Xiang Bai"},
keywords = {"3D Shape Matching", "3D Shape Retrieval", "Autoencoder", "Shape Representation "},
abstract = {"Abstract We study the problem of how to build a deep learning representation for 3D shape. Deep learning has shown to be very effective in variety of visual applications, such as image classification and object detection. However, it has not been successfully applied to 3D shape recognition. This is because 3D shape has complex structure in 3D space and there are limited number of 3D shapes for feature learning. To address these problems, we project 3D shapes into 2D space and use autoencoder for feature learning on the 2D images. High accuracy 3D shape retrieval performance is obtained by aggregating the features learned on 2D images. In addition, we show the proposed deep learning feature is complementary to conventional local image descriptors. By combing the global deep learning representation and the local descriptor representation, our method can obtain the state-of-the-art performance on 3D shape retrieval benchmarks. "} 
}
@article{Tang2015215,
title = {"A lattice-based approach for chemical structural retrieval "},
journal = {"Engineering Applications of Artificial Intelligence "},
volume = {"39"},
number = {""},
pages = {"215 - 222"},
year = {"2015"},
note = {""},
issn = {"0952-1976"},
doi = {"https://doi.org/10.1016/j.engappai.2014.12.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S095219761400298X"},
author = {"Peng Tang and Siu Cheung Hui and Alvis C.M. Fong"},
keywords = {"Formal concept analysis", "Chemical structural similarity retrieval", "Latticed-based information retrieval", "Chemical concept lattice "},
abstract = {"Abstract Searching for chemical structures with similar structural and functional information of organic chemicals is an important part of the drug discovery process. However, the current chemical structural retrieval methods have focused mainly on finding chemicals with similar structures to the input chemical structural query, and tend to ignore the functional features which are important for determining the chemical property and activity of the chemicals. In this paper, we propose a lattice-based approach for chemical structural retrieval. The proposed lattice-based approach is based on Formal Concept Analysis. It retrieves chemical structures that have functional groups and interactions between functional groups similar to the chemical structural query. The performance of the proposed lattice-based approach is evaluated and its promising performance results have shown that the proposed approach is effective for chemical structural retrieval. "} 
}
@article{deChastelaine2016164,
title = {"The neural correlates of recollection and retrieval monitoring: Relationships with age and recollection performance "},
journal = {"NeuroImage "},
volume = {"138"},
number = {""},
pages = {"164 - 175"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.04.071"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916301227"},
author = {"Marianne de Chastelaine and Julia T. Mattson and Tracy H. Wang and Brian E. Donley and Michael D. Rugg"},
keywords = {"Aging", "Core recollection network", "Episodic memory", "Retrieval", "Associative recognition", "fMRI "},
abstract = {"Abstract The relationships between age, retrieval-related neural activity, and episodic memory performance were investigated in samples of young (18–29 yrs), middle-aged (43–55 yrs) and older (63–76 yrs) healthy adults. Participants underwent fMRI scanning during an associative recognition test that followed a study task performed on visually presented word pairs. Test items comprised pairs of intact (studied pairs), rearranged (items studied on different trials) and new words. fMRI recollection effects were operationalized as greater activity for studied pairs correctly endorsed as intact than for pairs incorrectly endorsed as rearranged. The reverse contrast was employed to identify retrieval monitoring effects. Robust recollection effects were identified in the core recollection network, comprising the hippocampus, along with parahippocampal and posterior cingulate cortex, left angular gyrus and medial prefrontal cortex. Retrieval monitoring effects were identified in the anterior cingulate and right dorsolateral prefrontal cortex. Neither recollection effects within the core network, nor the monitoring effects differed significantly across the age groups after controlling for individual differences in associative recognition performance. Whole brain analyses did however identify three clusters outside of these regions where recollection effects were greater in the young than in the other age groups. Across-participant regression analyses indicated that the magnitude of hippocampal and medial prefrontal cortex recollection effects, and both of the prefrontal monitoring effects, correlated significantly with memory performance. None of these correlations were moderated by age. The findings suggest that the relationships between memory performance and functional activity in regions consistently implicated in successful recollection and retrieval monitoring are stable across much of the healthy adult lifespan. "} 
}
@article{Oh201570,
title = {"Cluster-based query expansion using external collections in medical information retrieval "},
journal = {"Journal of Biomedical Informatics "},
volume = {"58"},
number = {""},
pages = {"70 - 79"},
year = {"2015"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2015.09.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046415002117"},
author = {"Heung-Seon Oh and Yuchul Jung"},
keywords = {"Query expansion", "External collections", "Language models "},
abstract = {"Abstract Utilizing external collections to improve retrieval performance is challenging research because various test collections are created for different purposes. Improving medical information retrieval has also gained much attention as various types of medical documents have become available to researchers ever since they started storing them in machine processable formats. In this paper, we propose an effective method of utilizing external collections based on the pseudo relevance feedback approach. Our method incorporates the structure of external collections in estimating individual components in the final feedback model. Extensive experiments on three medical collections (TREC CDS, \{CLEF\} eHealth, and OHSUMED) were performed, and the results were compared with a representative expansion approach utilizing the external collections to show the superiority of our method. "} 
}
@article{Chiang201677,
title = {"Common and differential electrophysiological mechanisms underlying semantic object memory retrieval probed by features presented in different stimulus types "},
journal = {"International Journal of Psychophysiology "},
volume = {"106"},
number = {""},
pages = {"77 - 86"},
year = {"2016"},
note = {""},
issn = {"0167-8760"},
doi = {"https://doi.org/10.1016/j.ijpsycho.2016.06.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167876016301143"},
author = {"Hsueh-Sheng Chiang and Justin Eroh and Jeffrey S. Spence and Michael A. Motes and Mandy J. Maguire and Daniel C. Krawczyk and Matthew R. Brier and John Hart Jr. and Michael A. Kraut"},
keywords = {"EEG", "Semantics", "Memory retrieval", "Neural oscillations "},
abstract = {"Abstract How the brain combines the neural representations of features that comprise an object in order to activate a coherent object memory is poorly understood, especially when the features are presented in different modalities (visual vs. auditory) and domains (verbal vs. nonverbal). We examined this question using three versions of a modified Semantic Object Retrieval Test, where object memory was probed by a feature presented as a written word, a spoken word, or a picture, followed by a second feature always presented as a visual word. Participants indicated whether each feature pair elicited retrieval of the memory of a particular object. Sixteen subjects completed one of the three versions (N = 48 in total) while their \{EEG\} were recorded simultaneously. We analyzed \{EEG\} data in four separate frequency bands (delta: 1–4 Hz, theta: 4–7 Hz; alpha: 8–12 Hz; beta: 13–19 Hz) using a multivariate data-driven approach. We found that alpha power time-locked to response was modulated by both cross-modality (visual vs. auditory) and cross-domain (verbal vs. nonverbal) probing of semantic object memory. In addition, retrieval trials showed greater changes in all frequency bands compared to non-retrieval trials across all stimulus types in both response-locked and stimulus-locked analyses, suggesting dissociable neural subcomponents involved in binding object features to retrieve a memory. We conclude that these findings support both modality/domain-dependent and modality/domain-independent mechanisms during semantic object memory retrieval. "} 
}
@article{Song20161193,
title = {"High Temporal Resolution Rainfall Information Retrieval from Tipping-bucket Rain Gauge Measurements "},
journal = {"Procedia Engineering "},
volume = {"154"},
number = {""},
pages = {"1193 - 1200"},
year = {"2016"},
note = {"12th International Conference on Hydroinformatics (HIC 2016) - Smart Water for the Future "},
issn = {"1877-7058"},
doi = {"https://doi.org/10.1016/j.proeng.2016.07.525"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877705816319142"},
author = {"Yang Song and Dawei Han and Miguel A. Rico-Ramirez"},
keywords = {"Rainfall rate", "Disdrometer", "Tipping-Bucket rain gauge", "ANN", "CSA", "MLR", "Pattern Classification ; "},
abstract = {"Abstract Disdrometer can play a vital role in restoring detailed rainfall process by providing rainfall at a high temporal resolution. Rainfall rate derived from the widely used “Tipping-Bucket rain gauge” usually neglects its temporal variation especially during the low rainfall intensity periods. This study explores a heuristic artificial neural networks (ANN) approach along with the conventional Cubic Spline Algorithm (CSA) and Multivariate Linear Regression method (MLR) for high temporal resolution rainfall rate retrieval for the period of 2007 to 2009 at Chilbolton, U.K. The Supervised Levenberg-Marquardt backpropagation algorithm and the K-folds cross-validation method are integrated in a feed-forward neural network as to implicitly detect complex nonlinear relationships and to avoid model overfitting. Results indicate \{ANN\} is performing equivalently well with \{CSA\} after training, however, with poor generalisation in test due to low correlation between input and target data, as well as the curse of dimensionality in optimum model complexity selection. \{MLR\} can be an alternative approach in rainfall rate estimation but it highly depends on the data quality. "} 
}
@article{Bottrighi2016212,
title = {"Trace retrieval for business process operational support "},
journal = {"Expert Systems with Applications "},
volume = {"55"},
number = {""},
pages = {"212 - 221"},
year = {"2016"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2015.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417415007939"},
author = {"Alessio Bottrighi and Luca Canensi and Giorgio Leonardi and Stefania Montani and Paolo Terenziani"},
keywords = {"Trace retrieval", "Case based reasoning", "Operational support "},
abstract = {"Abstract Operational support assists users while process instances are being executed, by making predictions about the instance completion, or recommending suitable actions, resources or routing decisions, on the basis of the already completed instances, stored as execution traces in the event log. In this paper, we propose a case-based retrieval approach to business process management operational support, where log traces are exploited as cases. Once past traces have been retrieved, classical statistical techniques can be applied to them, to support prediction and recommendation. The framework enables the user to submit queries able to express complex patterns exhibited by the current process instance. Such queries can be composed by several simple patterns (i.e., single actions, or direct sequences of actions), separated by delays (i.e., actions we do not care about). Delays can also be imprecise (i.e., the number of actions can be given as a range). The tool also relies on a tree structure, adopted as an index for a quick retrieval from the available event log. Our approach is highly innovative with respect to the existing literature panorama, since it is the first work that exploits case-based retrieval techniques in the operational support context; moreover, the possibility of retrieving traces by querying complex patterns and the indexing strategy are major departures also with respect to other existing trace retrieval tools proposed in the case based reasoning area. Thanks to its characteristics and methodological solutions, the tool implements operational support tasks in a flexible and efficient way, as demonstrated by our experimental results. "} 
}
@article{Du2016813,
title = {"Local structure learning in high resolution remote sensing image retrieval "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"813 - 822"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.05.061"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216305148"},
author = {"Zhongxiang Du and Xuelong Li and Xiaoqiang Lu"},
keywords = {"High resolution remote sensing image retrieval", "Lipschitz smooth", "Manifold structure "},
abstract = {"Abstract High resolution remote sensing image captured by the satellites or the aircraft is of great help for military and civilian applications. In recent years, with an increasing amount of high resolution remote sensing images, it becomes more and more urgent to find a way to retrieve them. In this case, a few methods based on the statistical information of the local features are proposed, which have achieved good performances. However, most of the methods do not take the topological structure of the features into account. In this paper, we propose a new method to represent these images, by taking the structural information into consideration. The main contributions of this paper include: (1) mapping the features into a manifold space by a Lipschitz smooth function to enhance the representation ability of the features; (2) training an anchor set with several regularization constrains to get the intrinsic manifold structure. In the experiments, the method is applied to two challenging remote sensing image datasets: \{UC\} Merced land use dataset and Sydney dataset. Compared to the state-of-the-art approaches, the proposed method can achieve a more robust and commendable performance. "} 
}
@article{McDonough20157,
title = {"Retrieval monitoring is influenced by information value: The interplay between importance and confidence on false memory "},
journal = {"Acta Psychologica "},
volume = {"161"},
number = {""},
pages = {"7 - 17"},
year = {"2015"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2015.07.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691815300366"},
author = {"Ian M. McDonough and Dung C. Bui and Michael C. Friedman and Alan D. Castel"},
keywords = {"False memory", "Heuristics", "Memory", "Metamemory", "Word recognition", "Value "},
abstract = {"Abstract The perceived value of information can influence one's motivation to successfully remember that information. This study investigated how information value can affect memory search and evaluation processes (i.e., retrieval monitoring). In Experiment 1, participants studied unrelated words associated with low, medium, or high values. Subsequent memory tests required participants to selectively monitor retrieval for different values. False memory effects were smaller when searching memory for high-value than low-value words, suggesting that people more effectively monitored more important information. In Experiment 2, participants studied semantically-related words, and the need for retrieval monitoring was reduced at test by using inclusion instructions (i.e., endorsement of any word related to the studied words) compared with standard instructions. Inclusion instructions led to increases in false recognition for low-value, but not for high-value words, suggesting that under standard-instruction conditions retrieval monitoring was less likely to occur for important information. Experiment 3 showed that words retrieved with lower confidence were associated with more effective retrieval monitoring, suggesting that the quality of the retrieved memory influenced the degree and effectiveness of monitoring processes. Ironically, unless encouraged to do so, people were less likely to carefully monitor important information, even though people want to remember important memories most accurately. "} 
}
@article{Li201581,
title = {"Diversity-aware retrieval of medical records "},
journal = {"Computers in Industry "},
volume = {"69"},
number = {""},
pages = {"81 - 91"},
year = {"2015"},
note = {"Special Issue: Information Technologies for Enhanced Healthcare "},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2014.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166361514001742"},
author = {"Jianqiang Li and Chunchen Liu and Bo Liu and Rui Mao and Yongcai Wang and Shi Chen and Ji-Jiang Yang and Hui Pan and Qing Wang"},
keywords = {"Medical search", "Query understanding", "Search result diversification", "Medical information retrieval "},
abstract = {"Abstract The widely adoption of Electronic Medical Records (EMRs) causes an explosive growth of the medical and clinical data. It makes the medical search technologies become critical to find useful patient information in the large medical dataset. However, the high quality medical search is a challenging task, in particular due to the inherent complexity and ambiguity of medical terminology. In this paper, by exploiting the uncertainty in ambiguous medical queries, we propose a novel semantic-based approach to achieve the diversity-aware retrieval of EMRs, i.e., both the relevance and novelty are considered for \{EMR\} ranking. With the support of medical domain ontologies, we first mine all the potential semantics (concepts and relations between them) from a user query and consume them to model the multiple query aspects. Then, we propose a novel diversification strategy, which considers not only the aspect importance but also the aspect similarity, to perform the diversity-aware \{EMR\} ranking. A real-world pilot study, which utilizes the proposed medical search approach to improve the second use of the EMRs, is reported. We believe that our experience can serve as an important reference for the development of similar applications in a medical data utilization and sharing environment. "} 
}
@article{Raposo2016309,
title = {"Framing memories: How the retrieval query format shapes the neural bases of remembering "},
journal = {"Neuropsychologia "},
volume = {"89"},
number = {""},
pages = {"309 - 319"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2016.06.036"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393216302354"},
author = {"Ana Raposo and Sofia Frade and Mara Alves"},
keywords = {"Source remembering", "Retrieval query format", "Prefrontal cortex", "fMRI "},
abstract = {"Abstract The way memory questions are framed influences the information that is searched, retrieved, and monitored during remembering. This fMRI study aimed at clarifying how the format of the retrieval query shapes the neural basis of source recollection. During encoding, participants made semantic (pleasantness) or perceptual (number of letters) judgments about words. Subsequently, in a source memory test, the retrieval query was manipulated such that for half of the items from each encoding task, the retrieval query emphasized the semantic source (i.e., semantic query format: “Is this word from the pleasantness task?”), whereas for the other half the retrieval query emphasized the alternate, perceptual source (i.e., perceptual query format: “Is this word from the letter task?”). The results showed that the semantic query format was associated with higher source recognition than the perceptual query format. This behavioral advantage was accompanied by increased activation in several regions associated to controlled semantic elaboration and monitoring of internally-generated features about the past event. In particular, for items semantically encoded, the semantic query, relative to the perceptual query, induced activation in medial prefrontal cortex (PFC), hippocampal, parahippocampal and middle temporal cortex. Conversely, for items perceptually encoded, the semantic query recruited the lateral \{PFC\} and occipital-fusiform areas. Interestingly, the semantic format also influenced the processing of new items, eliciting greater L lateral and medial \{PFC\} activation. In contrast, the perceptual query format (versus the semantic format) only prompted greater activation in R orbitofrontal cortex and the R inferior parietal lobe, for items encoded in a perceptual manner and for new items, respectively. The results highlight the role of the retrieval query format in source remembering, showing that the retrieval query that emphasizes the semantic source promotes the use of semantic strategies via medial and L lateral \{PFC\} activations. These frontal activations are accompanied by differential recruitment of more posterior regions, depending on the type of information that had been encoded. "} 
}
@article{Fitchett20151,
title = {"An empirical characterisation of file retrieval "},
journal = {"International Journal of Human-Computer Studies "},
volume = {"74"},
number = {""},
pages = {"1 - 13"},
year = {"2015"},
note = {""},
issn = {"1071-5819"},
doi = {"https://doi.org/10.1016/j.ijhcs.2014.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S107158191400127X"},
author = {"Stephen Fitchett and Andy Cockburn"},
keywords = {"Personal information management", "Retrieval", "Files", "Navigation", "Search "},
abstract = {"Abstract Retrieving files on personal computers is a fundamental component of interaction, yet there is surprisingly little empirical data characterising how it is carried out in realistic settings. We developed software, called FileMonitor, to dynamically record users׳ file retrieval activities, including data describing the files retrieved and the tools used to retrieve them. We then deployed the system in a four week log study of 26 participants׳ actual file retrievals on their personal computers. Follow-up interviews contextualised the findings. Results are presented in two sections focusing on the files (the number of files, patterns of revisitation, file types, etc.) and on the interface mechanisms used to retrieve them (file browsers, search tools, ‘recent files’ lists, etc.). We conclude by discussing implications for the design of next-generation file retrieval interfaces. "} 
}
@article{Ramezani2016607,
title = {"A novel video recommendation system based on efficient retrieval of human actions "},
journal = {"Physica A: Statistical Mechanics and its Applications "},
volume = {"457"},
number = {""},
pages = {"607 - 623"},
year = {"2016"},
note = {""},
issn = {"0378-4371"},
doi = {"https://doi.org/10.1016/j.physa.2016.03.101"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378437116300991"},
author = {"Mohsen Ramezani and Farzin Yaghmaee"},
keywords = {"Recommender systems", "Content based retrieval", "Human actions", "Action representation", "Fuzzy dissimilarity measure "},
abstract = {"Abstract In recent years, fast growth of online video sharing eventuated new issues such as helping users to find their requirements in an efficient way. Hence, Recommender Systems (RSs) are used to find the users’ most favorite items. Finding these items relies on items or users similarities. Though, many factors like sparsity and cold start user impress the recommendation quality. In some systems, attached tags are used for searching items (e.g. videos) as personalized recommendation. Different views, incomplete and inaccurate tags etc. can weaken the performance of these systems. Considering the advancement of computer vision techniques can help improving RSs. To this end, content based search can be used for finding items (here, videos are considered). In such systems, a video is taken from the user to find and recommend a list of most similar videos to the query one. Due to relating most videos to humans, we present a novel low complex scalable method to recommend videos based on the model of included action. This method has recourse to human action retrieval approaches. For modeling human actions, some interest points are extracted from each action and their motion information are used to compute the action representation. Moreover, a fuzzy dissimilarity measure is presented to compare videos for ranking them. The experimental results on HMDB, UCFYT, \{UCF\} sport and \{KTH\} datasets illustrated that, in most cases, the proposed method can reach better results than most used methods. "} 
}
@article{Plessas201751,
title = {"Field evaluation of context aware adaptive interfaces for efficient mobile contact retrieval "},
journal = {"Pervasive and Mobile Computing "},
volume = {"35"},
number = {""},
pages = {"51 - 64"},
year = {"2017"},
note = {""},
issn = {"1574-1192"},
doi = {"https://doi.org/10.1016/j.pmcj.2016.04.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574119216300347"},
author = {"Athanasios Plessas and Vassileios Stefanis and Andreas Komninos and John Garofalakis"},
keywords = {"Context awareness", "Mobile personal information management", "Mobile user interfaces "},
abstract = {"Abstract Our paper discusses the implementation and field evaluation of a context-aware mobile contact retrieval application. We examine the performance of our underlying prediction algorithm in real world conditions and report on the suitability of our hybrid interface design, as a replacement for traditional contact retrieval interfaces (e.g. phonebook and recent call list). We find that users are best served by an alphabetical ordering of prediction matches and show that hybrid interface designs can provide a modest benefit in users’ ability to find a contact, in cases of non-successful predictions. We also discuss users’ alternative strategies for retrieval in such cases. "} 
}
@article{NovilloOrtiz201746,
title = {"Availability of information in Public Health on the Internet: An analysis of national health authorities in the Spanish-speaking Latin American and Caribbean countries "},
journal = {"International Journal of Medical Informatics "},
volume = {"100"},
number = {""},
pages = {"46 - 55"},
year = {"2017"},
note = {""},
issn = {"1386-5056"},
doi = {"https://doi.org/10.1016/j.ijmedinf.2017.01.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S1386505617300138"},
author = {"David Novillo-Ortiz and Tony Hernández-Pérez and Francesc Saigí-Rubió"},
keywords = {"Online health information", "Information retrieval", "Health communication", "Google", "Health information search", "Medical informatics "},
abstract = {"AbstractIntroduction Access to reliable and quality health information and appropriate medical advice can contribute to a dramatic reduction in the mortality figures of countries. The governments of the Americas are faced with the opportunity to continue working on this challenge, and their institutional presence on their websites should play a key role in this task. In a setting where the access to information is essential to both health professionals and citizens, it is relevant to analyze the role of national health authorities. Given that search engines play such a key role in the access to health information, it is important to specifically know – in connection to national health authorities – whether health information offered is easily available to the population, and whether this information is well-ranked in search engines. Methods Quantitative methods were used to gather data on the institutional presence of national health authorities on the web. An exploratory and descriptive research served to analyze and interpret data and information obtained quantitatively from different perspectives, including an analysis by country, and also by leading causes of death. A total of 18 web pages were analyzed. Information on leading causes of death was searched on websites of national health authorities in the week of August 10–14, 2015. Results The probability of finding information of national health authorities on the 10 leading causes of death in a country, among the top 10 results on Google, is 6.66%. Additionally, ten out the 18 countries under study (55%) do not have information ranked among the top results in Google when searching for the selected terms. Additionally, a total of 33 websites represent the sources of information with the highest visibility for all the search strategies in each country on Google for the ten leading causes of death in a country. Two websites, the National Library of Medicine and Wikipedia, occur as a result with visibility in the total of eighteen countries of the sample. Conclusions Taking into consideration that providing reliable and quality information on these topics to the population should be one of the priorities of national health authorities, these results suggest that national health authorities need to take measures to try to better position their contents. "} 
}
@article{Li20166479,
title = {"\{XCO2\} retrieval algorithm in short-wave infrared spectrum and validation with \{TCCON\} data "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"16"},
pages = {"6479 - 6483"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.04.074"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616303497"},
author = {"Yanfen Li and Chunmin Zhang and Dongdong Liu and Jie Chen and Piao Rong and Xingying Zhang and Shupeng Wang"},
keywords = {"GF_VRTM", "GOSAT-FTS", "XCO2 retrieval", "TCCON data", "Validation "},
abstract = {"Abstract Based on the optimal estimation method, the global carbon dioxide hyperspectral remote sensing inversion system GF_VRTM is established for the greenhouse gas carbon dioxide remote sensing detection of GF-5 satellite. The period of April 2013 to April 2014 GOSAT-FTS observations over \{TCCON\} site Tsukba are simulated by GF_VRTM, and the retrieval results are compared with GOSAT-FTS products and \{TCCON\} XCO2. The mean residuals between the GOSAT-measured and GF_VRTM-simulated spectra are nearly zero for the O2-A band and \{WCO2\} band over the spectral ranges. The average and standard deviation of ΔXCO2 between GF_VRTM retrievals and GOSAT-FTS \{L2\} products are evaluated to be −1.63 and 1.78 ppm for the whole period, and the average and standard deviation of ΔXCO2 between GF_VRTM retrievals and \{TCCON\} data are evaluated to be −0.38 and 2.25 ppm for the whole period. The accuracy of the GF_VRTM retrieval is less than 1% based on the validation results with GOSAT-FTS \{L2\} products and \{TCCON\} data. "} 
}
@article{Zhou20169911,
title = {"Speckle phase retrieval and transmission matrix obtaining of turbid media "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"20"},
pages = {"9911 - 9916"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.07.091"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616308579"},
author = {"Libin Zhou and Bin Zhuang and Hao Sun and Zhengquan He and Manli Hu and Xueguang Qiao"},
keywords = {"Imaging through turbid media", "Phase retrieval", "Speckle", "Multiple scattering", "Image reconstruction techniques "},
abstract = {"Abstract Previous research has demonstrated that distorted images caused by turbid media can be reconstructed by turbid lens imaging (TLI) method. In this way, it’s critical to accurately obtain the transmission matrix (TM) of turbid media. In this letter, we propose an improved method which is still based on Hilbert transform to get the transmission matrices, but it will use four images for each transmission matrix element to eliminate the influence of speckle intensity variation. In addition, a Hanning window filter is introduced to reduce the white Gaussian noise of original images to improve the result of \{TLI\} method. "} 
}
@article{Llimona2017,
title = {"Infobarris: una herramienta interactiva para monitorizar y divulgar información sobre la salud y sus determinantes en los barrios de Barcelona "},
journal = {"Gaceta Sanitaria "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0213-9111"},
doi = {"https://doi.org/10.1016/j.gaceta.2017.01.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S021391111730081X"},
author = {"Pere Llimona and Glòria Pérez and Maica Rodríguez-Sanz and Ana M. Novoa and Albert Espelt and Patricia Garcia de Olalla and Carme Borrell"},
keywords = {"Barrios", "Indicadores del estado de salud", "Características sociales", "Desigualdades en salud", keywords =Sistemas de información", "Almacenamiento y recuperación de información", "Neighbourhoods", "Health status indicators", "Social characteristics", "Health inequalities", "Information systems", "Information storage and retrieval "},
abstract = {"Resumen Para conocer la salud de la población es necesario realizar un análisis conjunto y continuado de su estado de salud y de sus determinantes. El objetivo de esta nota de campo es describir el desarrollo y el funcionamiento de la herramienta Infobarris, que permite visualizar una amplia batería de indicadores y determinantes de la salud de la población de la ciudad de Barcelona según el barrio de residencia. Para el desarrollo de Infobarris se ha usado una metodología ágil que permite el desarrollo de un proyecto de forma iterativa e incremental en etapas: selección de indicadores, diseño del prototipo, desarrollo de la herramienta de visualización, carga de datos, revisión y mejora de la herramienta. Infobarris permite la visualización interactiva de 64 indicadores de salud y de sus determinantes, mediante gráficos, mapas y tablas, lo que facilita la vigilancia de la salud y de sus determinantes en los barrios de la ciudad de Barcelona. Abstract In order to know about the health of the population, it is necessary to perform a systematic and continuous analysis of their health status and social and economic health determinants. The objective of this paper is to describe the development and implementation of the Infobarris tool, which allows to visualize a wide battery of indicators and social determinants of health by neighbourhoods in the city of Barcelona (Spain). For the development of the Infobarris tool, we used an agile methodology that allows the development of a project in iterative and incremental stages, which are the following: selection of indicators, design of the prototype, development of the tool, data loading, and tool review and improvements. Infobarris displays 64 indicators of health and its determinants through graphics, maps and tables, in a friendly, interactive and attractive way, which facilitates health surveillance in the neighbourhoods of Barcelona. "} 
}
@article{Mehrabi201654,
title = {"Fast content access and retrieval of \{JPEG\} compressed images "},
journal = {"Signal Processing: Image Communication "},
volume = {"46"},
number = {""},
pages = {"54 - 59"},
year = {"2016"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2016.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596516300625"},
author = {"Mahdi Mehrabi and Farzad Zargari and Mohammad Ghanbari and Mohammad Amin Shayegan"},
keywords = {"\{JPEG\} images", "Fast content access", "DC image", "Image retrieval", "Compressed domain "},
abstract = {"Abstract Fast content access and content based retrieval of images are among the common web and signal processing applications; on the other hand, \{JPEG\} is the dominant format for image compression in a wide range of applications. In this paper, a simple and fast method for content access and retrieval of \{JPEG\} coded images is presented which does not require complete decompression of coded images. The presented method uses \{DCT\} coefficients of coded blocks in the \{JPEG\} bit stream to extract average values of various size picture blocks namely \{DC\} values. The \{DC\} values provide an approximation of the coded image, which can be employed to construct a lower resolution picture or color histogram of the \{JPEG\} coded image for retrieval and other applications without full decompression of the image. "} 
}
@article{Chen2016,
title = {"Fourier phase retrieval with a single mask by Douglas–Rachford algorithms "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2016.07.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520316300410"},
author = {"Pengwen Chen and Albert Fannjiang"},
keywords = {"Phase retrieval", "Coded diffraction pattern", "Douglas–Rachford algorithm", "Geometric convergence", "Spectral gap "},
abstract = {"Abstract The Fourier-domain Douglas–Rachford (FDR) algorithm is analyzed for phase retrieval with a single random mask. Since the uniqueness of phase retrieval solution requires more than a single oversampled coded diffraction pattern, the extra information is imposed in either of the following forms: 1) the sector condition on the object; 2) another oversampled diffraction pattern, coded or uncoded. For both settings, the uniqueness of projected fixed point is proved and for setting 2) the local, geometric convergence is derived with a rate given by a spectral gap condition. Numerical experiments demonstrate global, power-law convergence of \{FDR\} from arbitrary initialization for both settings as well as for 3 or more coded diffraction patterns without oversampling. In practice, the geometric convergence can be recovered from the power-law regime by a simple projection trick, resulting in highly accurate reconstruction from generic initialization. "} 
}
@article{Daniel2016120,
title = {"Differential involvement of glutamatergic and catecholaminergic activity within the amygdala during taste aversion retrieval on memory expression and updating "},
journal = {"Behavioural Brain Research "},
volume = {"307"},
number = {""},
pages = {"120 - 125"},
year = {"2016"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2016.03.038"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432816301784"},
author = {"Osorio-Gómez Daniel and Guzmán-Ramos Kioko and Bermúdez-Rattoni Federico"},
keywords = {"Retrieval", "Glutamate", "Dopamine", "Norepinephrine", "Memory updating", "Microdialysis "},
abstract = {"Abstract During memory retrieval, consolidated memories are expressed and destabilized in order to maintain or update information through a memory reconsolidation process. Despite the key role of the amygdala during memory acquistion and consolidation, the participation of neurotransmitter signals in memory retrieval is poorly understood. Hence, we used conditioned taste aversion and in vivo microdialysis to evaluate changes in glutamate, norepinephrine and dopamine concentrations within the amygdala during memory retrieval. We observed that exposure to an aversive-conditioned stimulus induced an augmentation in glutamate, norepinephrine and dopamine levels within the amygdala, while exposure to a familiar and safe stimulus did not induce changes in these neurotransmitters levels. Also, we evaluated the amygdalar blockade of α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA), N-methyl-d-aspartate (NMDA), β-adrenergic and dopamine \{D1\} receptors in memory retrieval and updating. Results showed that during retrieval, behavioural expression was impaired by intra-amygdalar blockade of \{AMPA\} and β-adrenergic receptors, whereas NMDA, \{D1\} and β-adrenergic receptors blockade hindered memory updating. In summary, during conditioned taste aversion retrieval there was an increase in the extracellular levels of glutamate, norepinephrine and dopamine within the amygdala, and their receptors activity were differentially involved in the behavioural expression and memory updating during retrieval. "} 
}
@article{Pan2016753,
title = {"A two-stage shape retrieval (TSR) method with global and local features "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"38"},
number = {""},
pages = {"753 - 762"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.04.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316300530"},
author = {"Xiaqing Pan and Sachin Chachada and C.-C. Jay Kuo"},
keywords = {"2D shape retrieval", "Shape representation", "MPEG-7 shape dataset", "Kimia99 dataset", "Tari1000 dataset "},
abstract = {"Abstract A robust two-stage shape retrieval (TSR) method is proposed to address the 2D shape retrieval problem. Most state-of-the-art shape retrieval methods are based on local features matching and ranking. Their retrieval performance is not robust since they may retrieve globally dissimilar shapes in high ranks. To overcome this challenge, we decompose the decision process into two stages. In the first irrelevant cluster filtering (ICF) stage, we consider both global and local features and use them to predict the relevance of gallery shapes with respect to the query. Irrelevant shapes are removed from the candidate shape set. After that, a local-features-based matching and ranking (LMR) method follows in the second stage. We apply the proposed \{TSR\} system to MPEG-7, Kimia99 and Tari1000 three datasets and show that it outperforms all other existing methods. The robust retrieval performance of the \{TSR\} system is demonstrated. "} 
}
@article{Weng201671,
title = {"Asymmetric hashing with multi-bit quantization for image retrieval "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"71 - 77"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.04.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216303022"},
author = {"Zhenyu Weng and Ziqiang Sun and Yuesheng Zhu"},
keywords = {"Image retrieval", "Asymmetric hashing", "Multi-bit quantization "},
abstract = {"Abstract In the hashing approaches with multi-bit quantization, each projected dimension is divided into multiple regions indexed with multiple bits to preserve the neighborhood structure of the data. However, the query is processed in binary, and the distances between the adjacent regions are usually assumed to be equal, resulting in the accuracy loss of the computed distance between the data and the query. To tackle the above problems, in this paper an approach is proposed to process the query and the data asymmetrically. By representing the data with the expectation value of the region where the data belong and preserving the query in original form, the distance between the query and the data can be computed accurately. A specific asymmetric approach with non-parametric multi-bit quantization is further developed for the \{PCA\} (Principle Component Analysis) hashing method. With the special consideration of \{PCA\} characteristic, every projected dimension is adaptively divided into a certain number of the regions according to the minimal variance. The results of the experiments have shown that the better performance can be obtained in the asymmetric hashing approach with multi-bit quantization than that in the other approaches, and can be improved further in the specific asymmetric approach with non-parametric multi-bit quantization with respect to the \{PCA\} hashing method. "} 
}
@article{Zhang2016105,
title = {"Statistical modeling for automatic image indexing and retrieval "},
journal = {"Neurocomputing "},
volume = {"207"},
number = {""},
pages = {"105 - 119"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.04.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216302946"},
author = {"Baopeng Zhang and Hangzai Luo and Jianping Fan"},
keywords = {"Statistical image modeling", "Statistical concept modeling", "Adaptive \{EM\} algorithm", "Partial similarity matching", "Automatic image indexing and retrieval "},
abstract = {"Abstract In this paper, a statistical modeling algorithm is developed to achieve automatic detection of object classes and image concepts via partial similarity matching. For a given image, its statistical image model is automatically learned by using a finite mixture model to approximate the distribution of its image pixels in the 10-dimensional feature space. Such statistical image modeling process can also achieve automatic image segmentation implicitly. To achieve more precise matching between the mixture components and the local distributions of the relevant image pixels, an adaptive \{EM\} algorithm is developed to simultaneously select the model structure (i.e., the optimal number of mixture components) and estimate the model parameters (i.e., locations and statistical properties of the mixture components) according to the local distributions of the relevant image pixels. For a given image concept or object class of interest, its statistical concept model is automatically learned from the statistical image models for the labeled training images. Finally, similarity matching for automatic detection of object classes and image concepts is treated as a partial model matching problem, i.e., matching between the statistical image model for a given test image and all the statistical concept models for the object classes and image concepts of interest. Our experimental results have demonstrated that our statistical modeling algorithm can achieve very competitive results on both automatic image segmentation and classification. "} 
}
@article{Mourtzis2016472,
title = {"An Inference-based Knowledge Reuse Framework for Historical Product and Production Information Retrieval "},
journal = {"Procedia \{CIRP\} "},
volume = {"41"},
number = {""},
pages = {"472 - 477"},
year = {"2016"},
note = {"Research and Innovation in Manufacturing: Key Enabling Technologies for the Factories of the Future - Proceedings of the 48th \{CIRP\} Conference on Manufacturing Systems "},
issn = {"2212-8271"},
doi = {"https://doi.org/10.1016/j.procir.2015.12.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212827115011051"},
author = {"Dimitris Mourtzis and Michael Doukas and Christos Giannoulis"},
keywords = {"Knowledge reuse", "Inference", "Manufacturing "},
abstract = {"Abstract The reuse of past knowledge constitutes a key factor for improving manufacturing performance, during design, planning, and operational phases. However, valuable knowledge generated and associated to products and processes on a daily basis, remains implicit and its reusability is confined to a specific machine operator or within legacy \{IT\} databases. The work proposed in this paper introduces a framework to enable reusability of manufacturing knowledge through inference rules applied on manufacturing ontologies. Initially, a mechanism is used to access a Relational Database Management System (RDBMS) and through a rule-based approach, it exports the analogous ontological schema. The ontology constitutes the knowledge base and is stored in a knowledge repository. An inference engine is then used to query this repository and derive additional assertions, which are entailed from the base schema, on product, process, and resource. The method is developed in a web app, which offers to the users the capability to create, activate, and share rules and results on engineering topics. The effectiveness of the framework is validated using a real industrial case from a high-precision mould-making SME. "} 
}
@article{Savelonas2016114,
title = {"Fisher encoding of differential fast point feature histograms for partial 3D object retrieval "},
journal = {"Pattern Recognition "},
volume = {"55"},
number = {""},
pages = {"114 - 124"},
year = {"2016"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2016.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320316000595"},
author = {"Michalis A. Savelonas and Ioannis Pratikakis and Konstantinos Sfikas"},
keywords = {"3D object retrieval", "Partial matching", "Local descriptors", "Fisher encoding "},
abstract = {"Abstract Partial 3D object retrieval has attracted intense research efforts due to its potential for a wide range of applications, such as 3D object repair and predictive digitization. This work introduces a partial 3D object retrieval method, applicable on both point clouds and structured 3D models, which is based on a shape matching scheme combining local shape descriptors with their Fisher encodings. Experiments on the \{SHREC\} 2013 large-scale benchmark dataset for partial object retrieval, as well as on the publicly available Hampson pottery dataset, demonstrate that the proposed method outperforms seven recently evaluated partial retrieval methods. "} 
}
@article{Xing2015619,
title = {"Emotion-driven Chinese folk music-image retrieval based on DE-SVM "},
journal = {"Neurocomputing "},
volume = {"148"},
number = {""},
pages = {"619 - 627"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.08.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214010212"},
author = {"Baixi Xing and Kejun Zhang and Shouqian Sun and Lekai Zhang and Zenggui Gao and Jiaxi Wang and Shi Chen"},
keywords = {"Music emotion recognition", "Image emotion recognition", "Differential Evolutionary algorithm", "Support vector machine", "Back propagation", "Cross-media information retrieval "},
abstract = {"Abstract In this study, we attempt to explore cross-media retrieval between music and image data based on the emotional correlation. Emotion feature analytic could be the bridge of cross-media retrieval, since emotion represents the user׳s perspective and effectively meets the user׳s retrieval need. Currently, there is little research about the emotion correlation of different multimedia data (e.g. image or music). We propose a promising model based on Differential Evolutionary-Support Vector Machine (DE-SVM) to build up the emotion-driven cross-media retrieval system between Chinese folk image and Chinese folk music. In this work, we first build up the Chinese Folk Music Library and Chinese Folk Image Library.Second, we compare Back Propagation(BP), Linear Regression(LR) and Differential Evolutionary-Support Vector Machine (DE-SVM), and find that DE-SVM has the best performance. Then we conduct DE-SVM to build the optimal model for music/image emotion recognition. Finally, an Emotion-driven Chinese Folk Music-Image Exploring System based on DE-SVM is developed and experiment results show our method is effective in terms of retrieval performance. "} 
}
@article{Zhang201640,
title = {"3D object retrieval with multi-feature collaboration and bipartite graph matching "},
journal = {"Neurocomputing "},
volume = {"195"},
number = {""},
pages = {"40 - 49"},
year = {"2016"},
note = {"Learning for Medical Imaging "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.09.118"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216000990"},
author = {"Yan Zhang and Feng Jiang and Seungmin Rho and Shaohui Liu and Debin Zhao and Rongrong Ji"},
keywords = {"View-based retrieval", "Multi-feature", "Bipartite graph "},
abstract = {"Abstract In this paper, we propose a novel 3D object retrieval with features collaboration and bipartite graph matching strategies. We explored the essential characters of 3D object in a view-based retrieval framework, which extracts complement descriptors from both the contour and the interior region of 3D object effectively. Specifically, a greedy bipartite graph matching algorithm is employed. With the bipartite graph matching and feature concatenation, significant performance improvement is achieved in the 3D object retrieval task. The proposed method is evaluated by the third party on the data set comprising more than 500 3D objects and achieves the best performance for SHREC’15 challenge. "} 
}
@article{Benetello201611,
title = {"The dissociability of lexical retrieval and morphosyntactic processes for nouns and verbs: A functional and anatomoclinical study "},
journal = {"Brain and Language "},
volume = {"159"},
number = {""},
pages = {"11 - 22"},
year = {"2016"},
note = {""},
issn = {"0093-934X"},
doi = {"https://doi.org/10.1016/j.bandl.2016.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0093934X15301784"},
author = {"Annalisa Benetello and Chiara Finocchiaro and Rita Capasso and Erminio Capitani and Marcella Laiacona and Stefano Magon and Gabriele Miceli"},
keywords = {"Noun/verb dissociations", "Noun/verb retrieval impairment", "Nominal/verbal morphosyntactic impairment", "Fronto-temporal verb network "},
abstract = {"Abstract Nouns and verbs can dissociate following brain damage, at both lexical retrieval and morphosyntactic processing levels. In order to document the range and the neural underpinnings of behavioral dissociations, twelve aphasics with disproportionate difficulty naming objects or actions were asked to apply phonologically identical morphosyntactic transformations to nouns and verbs. Two subjects with poor object naming and 2/10 with poor action naming made no morphosyntactic errors at all. Six of 10 subjects with poor action naming showed disproportionate or no morphosyntactic difficulties for verbs. Morphological errors on nouns and verbs correlated at the group level, but in individual cases a selective impairment of verb morphology was observed. Poor object and action naming with spared morphosyntax were associated with non-overlapping lesions (inferior occipitotemporal and fronto-temporal, respectively). Poor verb morphosyntax was observed with frontal-temporal lesions affecting white matter tracts deep to the insula, possibly disrupting the interaction of nodes in a fronto-temporal network. "} 
}
@article{Lazri2016106,
title = {"A satellite rainfall retrieval technique over northern Algeria based on the probability of rainfall intensities classification from MSG-SEVIRI "},
journal = {"Journal of Atmospheric and Solar-Terrestrial Physics "},
volume = {"147"},
number = {""},
pages = {"106 - 120"},
year = {"2016"},
note = {""},
issn = {"1364-6826"},
doi = {"https://doi.org/10.1016/j.jastp.2016.07.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S1364682616301857"},
author = {"Mourad Lazri and Soltane Ameur"},
keywords = {"\{MSG\} SEVIRI", "Rainfall retrieval", "Rainfall intensities "},
abstract = {"Abstract In this paper, an algorithm based on the probability of rainfall intensities classification for rainfall estimation from Meteosat Second Generation/Spinning Enhanced Visible and Infrared Imager (MSG-SEVIRI) has been developed. The classification scheme uses various spectral parameters of \{SEVIRI\} that provide information about cloud top temperature and optical and microphysical cloud properties. The presented method is developed and trained for the north of Algeria. The calibration of the method is carried out using as a reference rain classification fields derived from radar for rainy season from November 2006 to March 2007. Rainfall rates are assigned to rain areas previously identified and classified according to the precipitation formation processes. The comparisons between satellite-derived precipitation estimates and validation data show that the developed scheme performs reasonably well. Indeed, the correlation coefficient presents a significant level (r:0.87). The values of POD, \{POFD\} and \{FAR\} are 80%, 13% and 25%, respectively. Also, for a rainfall estimation of about 614 mm, the RMSD, Bias, \{MAD\} and \{PD\} indicate 102.06(mm), 2.18(mm), 68.07(mm) and 12.58, respectively. "} 
}
@article{Li20165430,
title = {"An evolutionary approach for image retrieval based on lateral inhibition "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"13"},
pages = {"5430 - 5438"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.02.056"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616301206"},
author = {"Bai Li"},
keywords = {"Image retrieval", "Lateral inhibition", "Numerical optimization", "Evolutionary algorithm", "Artificial bee colony algorithm "},
abstract = {"Abstract Image retrieval refers to searching for specific pattern when browsing digital images in large databases. It is a fundamental topic in visual pattern recognition. The original image retrieval scheme is converted into a 2-dimensional optimization problem, during which image enhancement, a preprocessing step, is implemented to ease the template matching procedure. Image enhancement is achieved via lateral inhibition. Fundamental issues in this topic are investigated in this paper: (1) whether it is sensible to adopt an evolutionary algorithm to search for the best-match result, given that the concerned optimization problem has merely two dimensions; (2) how lateral inhibition takes effect to facilitate image retrieval. According to our comparative experimental results, there is no evidence that indicates lateral inhibition makes any subtle effort to ease the best-match optimization process. This paper also provides theoretical analyses regarding the evolutionary algorithm adopted. "} 
}
@article{Kaothanthong201614,
title = {"Distance interior ratio: A new shape signature for 2D shape retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"78"},
number = {""},
pages = {"14 - 21"},
year = {"2016"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.03.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516300332"},
author = {"Natsuda Kaothanthong and Jinhee Chun and Takeshi Tokuyama"},
keywords = {"Shape signature", "Shape retrieval", "Homometric pair "},
abstract = {"Abstract In this work, we propose a shape signature named Distance Interior Ratio (DIR) that utilizes intersection pattern of the distribution of line segments with the shape. To improve the efficiency of the histogram-based shape signature, we present a histogram alignment method for adjusting the interval of the histogram according to the distance distribution. The experimental result shows a 3.25% improvement using the proposed histogram alignment. When compared to other shape signatures, our experimental result gives a 77.69% retrieval rate using \{MPEG7\} Part B dataset [Latecki, et al. (2000)[14]]. "} 
}
@article{Herron201624,
title = {"Electrophysiological evidence for flexible goal-directed cue processing during episodic retrieval "},
journal = {"NeuroImage "},
volume = {"132"},
number = {""},
pages = {"24 - 31"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.02.025"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916001324"},
author = {"Jane E. Herron and Lisa H. Evans and Edward L. Wilding"},
keywords = {"Event-related potentials", "Episodic memory", "Cue processing", "Retrieval orientation", "Content specificity", "Task-switching", "Preparatory processing "},
abstract = {"Abstract A widely held assumption is that memory retrieval is aided by cognitive control processes that are engaged flexibly in service of memory retrieval and memory decisions. While there is some empirical support for this view, a notable exception is the absence of evidence for the flexible use of retrieval control in functional neuroimaging experiments requiring frequent switches between tasks with different cognitive demands. This absence is troublesome in so far as frequent switches between tasks mimic some of the challenges that are typically placed on memory outside the laboratory. In this experiment we instructed participants to alternate frequently between three episodic memory tasks requiring item recognition or retrieval of one of two different kinds of contextual information encoded in a prior study phase (screen location or encoding task). Event-related potentials (ERPs) elicited by unstudied items in the two tasks requiring retrieval of study context were reliably different, demonstrating for the first time that \{ERPs\} index task-specific processing of retrieval cues when retrieval goals change frequently. The inclusion of the item recognition task was a novel and important addition in this study, because only the \{ERPs\} elicited by unstudied items in one of the two context conditions diverged from those in the item recognition condition. This outcome constrains functional interpretations of the differences that emerged between the two context conditions and emphasises the utility of this baseline in functional imaging studies of retrieval processing operations. "} 
}
@article{Ruocco201592,
title = {"Geo-temporal distribution of tag terms for event-related image retrieval "},
journal = {"Information Processing & Management "},
volume = {"51"},
number = {"1"},
pages = {"92 - 110"},
year = {"2015"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2014.09.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457314000867"},
author = {"Massimiliano Ruocco and Heri Ramampiaro"},
keywords = {"Information retrieval", "Spatial profile", "Tag relatedness", "Query expansion", "Event retrieval", "Social media retrieval "},
abstract = {"Abstract Media sharing applications, such as Flickr and Panoramio, contain a large amount of pictures related to real life events. For this reason, the development of effective methods to retrieve these pictures is important, but still a challenging task. Recognizing this importance, and to improve the retrieval effectiveness of tag-based event retrieval systems, we propose a new method to extract a set of geographical tag features from raw geo-spatial profiles of user tags. The main idea is to use these features to select the best expansion terms in a machine learning-based query expansion approach. Specifically, we apply rigorous statistical exploratory analysis of spatial point patterns to extract the geo-spatial features. We use the features both to summarize the spatial characteristics of the spatial distribution of a single term, and to determine the similarity between the spatial profiles of two terms – i.e., term-to-term spatial similarity. To further improve our approach, we investigate the effect of combining our geo-spatial features with temporal features on choosing the expansion terms. To evaluate our method, we perform several experiments, including well-known feature analyzes. Such analyzes show how much our proposed geo-spatial features contribute to improve the overall retrieval performance. The results from our experiments demonstrate the effectiveness and viability of our method. "} 
}
@article{Pandey2016571,
title = {"A semantics and image retrieval system for hierarchical image databases "},
journal = {"Information Processing & Management "},
volume = {"52"},
number = {"4"},
pages = {"571 - 591"},
year = {"2016"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315001429"},
author = {"Shreelekha Pandey and Pritee Khanna and Haruo Yokota"},
keywords = {"Content based image retrieval", "Semantic assignment", "Clustering", "Visual search space", "Indexing of visual features "},
abstract = {"Abstract This work presents a content based semantics and image retrieval system for semantically categorized hierarchical image databases. Each module is designed with an aim to develop a system that works closer to human perception. Images are mapped to a multidimensional feature space, where images belonging a semantic are clustered and indexed to acquire its efficient representation. This helps in handling the existing variability or heterogeneity within this semantic. Adaptive combinations of the obtained depictions are utilized by the branch selection and pruning algorithms to identify some closer semantics and select only a part of the large hierarchical search space for actual search. So obtained search space is finally used to retrieve desired semantics and similar images corresponding to them. The system is evaluated in terms of accuracy of the retrieved semantics and precision-recall curves. Experiments show promising semantics and image retrieval results on hierarchical image databases. The results reported with non-hierarchical but categorized image databases further prove the efficacy of the proposed system. "} 
}
@article{Ceriotti2016342,
title = {"Control of asteroid retrieval trajectories to libration point orbits "},
journal = {"Acta Astronautica "},
volume = {"126"},
number = {""},
pages = {"342 - 353"},
year = {"2016"},
note = {"Space Flight Safety "},
issn = {"0094-5765"},
doi = {"https://doi.org/10.1016/j.actaastro.2016.03.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0094576515300138"},
author = {"Matteo Ceriotti and Joan Pau Sanchez"},
keywords = {"Asteroid", "Retrieval", "Control", "Trajectory", "Libration-point orbits", "Transfer "},
abstract = {"Abstract The fascinating idea of shepherding asteroids for science and resource utilization is being considered as a credible concept in a not too distant future. Past studies identified asteroids which could be efficiently injected into manifolds which wind onto periodic orbits around collinear Lagrangian points of the Sun-Earth system. However, the trajectories are unstable, and errors in the capture maneuver would lead to complete mission failure, with potential danger of collision with the Earth, if uncontrolled. This paper investigates the controllability of some asteroids along the transfers and the periodic orbits, assuming the use of a solar-electric low-thrust system shepherding the asteroid. Firstly, an analytical approach is introduced to estimate the stability of the trajectories from a dynamical point of view; then, a numerical control scheme based on a linear quadratic regulator is proposed, where the gains are optimized for each trajectory through a genetic algorithm. A stochastic simulation with a Monte Carlo approach is used to account for different perturbed initial conditions and the epistemic uncertainty on the asteroid mass. Results show that only a small subset of the considered combinations of trajectories/asteroids are reliably controllable, and therefore controllability must be taken into account in the selection of potential targets. "} 
}
@article{Zhang2016255,
title = {"Thermal energy storage and retrieval characteristics of a molten-salt latent heat thermal energy storage system "},
journal = {"Applied Energy "},
volume = {"173"},
number = {""},
pages = {"255 - 271"},
year = {"2016"},
note = {""},
issn = {"0306-2619"},
doi = {"https://doi.org/10.1016/j.apenergy.2016.04.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306261916304615"},
author = {"P. Zhang and F. Ma and X. Xiao"},
keywords = {"Latent heat thermal energy storage", "Nitrate molten salt", "Nickel foam", "Heat transfer characteristics", "Thermal energy storage and retrieval "},
abstract = {"Abstract In the present study, a shell-and-tube latent heat thermal energy storage (LHTES) system is built using the eutectic molten salt as the phase change material (PCM) to make an efficient use of solar energy at medium-temperature of around 200.0 °C. The nickel foam is embedded in pure \{PCM\} (molten salt) to form composite \{PCM\} to improve the performance of the \{LHTES\} system through enhancing the effective thermal conductivity of the PCM. The performances of the systems using pure molten salt and composite \{PCM\} are investigated both experimentally and numerically. The oil is used as the heat transfer fluid (HTF) and the influence of mass flow rate of the \{HTF\} on the thermal energy storage and retrieval is investigated in the experiments. The charging and discharging time durations, mean power and energy efficiency are estimated to evaluate the performance of the \{LHTES\} system. Meanwhile, a three-dimensional (3D) numerical model is developed based on the enthalpy-porosity model and two-temperature energy equations to investigate the thermal energy storage and retrieval of the \{LHTES\} system, and the detailed heat transfer characteristics during the melting/solidification of the \{PCM\} are understood. The results indicate that encapsulating molten salt with nickel foam to enhance the effective thermal conductivity of the \{PCM\} can improve the performance of the \{LHTES\} system. The information provided in the present study will be helpful for the \{LHTES\} system design, construction and application using molten salt for solar energy storage. "} 
}
@article{Derczynski2015786,
title = {"Time and information retrieval: Introduction to the special issue "},
journal = {"Information Processing & Management "},
volume = {"51"},
number = {"6"},
pages = {"786 - 790"},
year = {"2015"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315000539"},
author = {"Leon Derczynski and Jannik Strötgen and Ricardo Campos and Omar Alonso"} 

}
@article{Wang2016256,
title = {"A new SVM-based relevance feedback image retrieval using probabilistic feature and weighted kernel function "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"38"},
number = {""},
pages = {"256 - 275"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.03.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316300128"},
author = {"Xiang-Yang Wang and Lin-Lin Liang and Wei-Yi Li and Dong-Ming Li and Hong-Ying Yang"},
keywords = {"Content-based image retrieval", "Relevance feedback", "Support vector machine", "Adapted Gaussian mixture models", "Kernel function weighting "},
abstract = {"Abstract Relevance feedback (RF) is an effective approach to bridge the gap between low-level visual features and high-level semantic meanings in content-based image retrieval (CBIR). The support vector machine (SVM) based \{RF\} mechanisms have been used in different fields of image retrieval, but they often treat all positive and negative feedback samples equally, which will inevitably degrade the effectiveness of SVM-based \{RF\} approaches for CBIR. In fact, positive and negative feedback samples, different positive feedback samples, and different negative feedback samples all always have distinct properties. Moreover, each feedback interaction process is usually tedious and time-consuming because of complex visual features, so if too many times of iteration of feedback are asked, users may be impatient to interact with the \{CBIR\} system. To overcome the above limitations, we propose a new SVM-based \{RF\} approach using probabilistic feature and weighted kernel function in this paper. Firstly, the probabilistic features of each image are extracted by using principal components analysis (PCA) and the adapted Gaussian mixture models (AGMM) based dimension reduction, and the similarity is computed by employing Kullback–Leibler divergence. Secondly, the positive feedback samples and negative feedback samples are marked, and all feedback samples’ weight values are computed by utilizing the samples-based Relief feature weighting. Finally, the \{SVM\} kernel function is modified dynamically according to the feedback samples’ weight values. Extensive simulations on large databases show that the proposed algorithm is significantly more effective than the state-of-the-art approaches. "} 
}
@article{Miller201641,
title = {"The influence of retrieval practice on metacognition: The contribution of analytic and non-analytic processes "},
journal = {"Consciousness and Cognition "},
volume = {"42"},
number = {""},
pages = {"41 - 50"},
year = {"2016"},
note = {""},
issn = {"1053-8100"},
doi = {"https://doi.org/10.1016/j.concog.2016.03.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S105381001630037X"},
author = {"Tyler M. Miller and Lisa Geraci"},
keywords = {"Metacognition", "Overconfidence", "Retrieval practice", "Inferential processes "},
abstract = {"Abstract People may change their memory predictions after retrieval practice using naïve theories of memory and/or by using subjective experience – analytic and non-analytic processes respectively. The current studies disentangled contributions of each process. In one condition, learners studied paired-associates, made a memory prediction, completed a short-run of retrieval practice and made a second prediction. In another condition, judges read about a yoked learners’ retrieval practice performance but did not participate in retrieval practice and therefore, could not use non-analytic processes for the second prediction. In Study 1, learners reduced their predictions following moderately difficult retrieval practice whereas judges increased their predictions. In Study 2, learners made lower adjusted predictions than judges following both easy and difficult retrieval practice. In Study 3, judge-like participants used analytic processes to report adjusted predictions. Overall, the results suggested non-analytic processes play a key role for participants to reduce their predictions after retrieval practice. "} 
}
@article{Lu2014703,
title = {"3D model retrieval and classification by semi-supervised learning with content-based similarity "},
journal = {"Information Sciences "},
volume = {"281"},
number = {""},
pages = {"703 - 713"},
year = {"2014"},
note = {"Multimedia Modeling "},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.03.079"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514003703"},
author = {"Ke Lu and Qian Wang and Jian Xue and Weiguo Pan"},
keywords = {"3D model retrieval", "3D model recognition", "Distance measure", "Disjoint information", "Semi-supervised learning "},
abstract = {"Abstract The rapid development of 3D digital technology has led to an increasing volume of 3D model data. In addressing the management of such large scale data, effective content-based 3D model retrieval and recognition methods are highly desirable. In 3D model retrieval and recognition tasks, the distance measure between two 3D models plays an important role. In this paper, we propose a novel 3D model retrieval and recognition method that employs both a distance histogram and 3D moment invariants as features that are invariant to 3D object scaling, translation, and rotation. Disjoint information is used to measure the distance between the feature histograms, and the Euclidean distance is applied in calculating the distance between two moment features. These measures are then combined as the 3D model distance. Using this distance measure, the relationships between all 3D models in the dataset are formulated as a graph structure. A semi-supervised learning process is then conducted to estimate the relevance among the 3D models, and this is employed for 3D model retrieval and classification. To evaluate the effectiveness of the proposed method, we conduct experiments on two datasets. Experimental results and a comparison with state-of-the-art methods demonstrate that the proposed method achieves improved performance for 3D model retrieval and recognition tasks. "} 
}
@article{Mardones2016641,
title = {"Leveraging similarities and structure for dense representations combination in image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"38"},
number = {""},
pages = {"641 - 657"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.04.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316300451"},
author = {"Tomás Mardones and Héctor Allende and Claudio Moraga"},
keywords = {"Content-based image retrieval", "Fisher Vector", "Global dense representation", "Image search", "Graph based combination", "Re-ranking", "Product Quantization "},
abstract = {"Abstract This paper addresses the problem of content-based image retrieval in a large-scale setting. Recently several graph-based image retrieval systems have been proposed to fuse different representations, with excellent results. However, most of them use one very precise representation, which does not scale as well as global dense representations with an increasing number of images, hurting time and memory requirements as the database grows. We researched how to attain a comparable precision, while greatly reducing the memory and time requirements by avoiding the use of a main precise representation. To accomplish this objective, we proposed a novel graph-based query fusion approach—where we combined several compact representations based on aggregating local descriptors such as Fisher Vectors—using distance and neighborhood information jointly to evaluate the individual importance of each element in a query adaptive manner. The performance was analyzed in different time and memory constrained scenarios, ranging from less than a second to several seconds for the complete search process while needing only a fraction of the memory compared to other similar performing methods. Experiments were performed on 4 public datasets, namely UKBench, Holidays, Corel-5K and MIRFLICKR-1M, obtaining state-of-the-art effectiveness. "} 
}
@article{Iwamura201692,
title = {"Involvement of hippocampal \{NMDA\} receptors in retrieval of spontaneous object recognition memory in rats "},
journal = {"Behavioural Brain Research "},
volume = {"307"},
number = {""},
pages = {"92 - 99"},
year = {"2016"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2016.03.048"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432816301851"},
author = {"Etsushi Iwamura and Kazuo Yamada and Yukio Ichitani"},
keywords = {"Spontaneous object recognition memory", "Retrieval", "Hippocampus", "NMDA receptor", "AMPA receptor", "Rats "},
abstract = {"Abstract The involvement of hippocampal N-methyl-d-aspartate (NMDA) receptors in the retrieval process of spontaneous object recognition memory was investigated. The spontaneous object recognition test consisted of three phases. In the sample phase, rats were exposed to two identical objects several (2–5) times in the arena. After the sample phase, various lengths of delay intervals (24 h-6 weeks) were inserted (delay phase). In the test phase in which both the familiar and the novel objects were placed in the arena, rats’ novel object exploration behavior under the hippocampal treatment of \{NMDA\} receptor antagonist, AP5, or vehicle was observed. With 5 exposure sessions in the sample phase (experiment 1), \{AP5\} treatment in the test phase significantly decreased discrimination ratio when the delay was 3 weeks but not when it was one week. On the other hand, with 2 exposure sessions in the sample phase (experiment 2) in which even vehicle-injected control animals could not discriminate the novel object from the familiar one with a 3 week delay, \{AP5\} treatment significantly decreased discrimination ratio when the delay was one week, but not when it was 24 h. Additional experiment (experiment 3) showed that the hippocampal treatment of an α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) receptor antagonist, NBQX, decreased discrimination ratio with all delay intervals tested (24 h-3 weeks). Results suggest that hippocampal \{NMDA\} receptors play an important role in the retrieval of spontaneous object recognition memory especially when the memory trace weakens. "} 
}
@article{deGraaf201675,
title = {"How organisation of architecture documentation affects architectural knowledge retrieval "},
journal = {"Science of Computer Programming "},
volume = {"121"},
number = {""},
pages = {"75 - 99"},
year = {"2016"},
note = {"Special Issue on Knowledge-based Software Engineering "},
issn = {"0167-6423"},
doi = {"https://doi.org/10.1016/j.scico.2015.10.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167642315003172"},
author = {"K.A. de Graaf and P. Liang and A. Tang and H. van Vliet"},
keywords = {"Software architecture documentation", "Architectural knowledge retrieval", "Software ontologies", "Semantic wiki", "Ontology-based documentation "},
abstract = {"Abstract A common approach to software architecture documentation in industry projects is the use of file-based documents. This approach offers a single-dimensional arrangement of the architectural knowledge. Knowledge retrieval from file-based architecture documentation is efficient if the organisation of knowledge supports the needs of the readers; otherwise it can be difficult. In this paper, we compare the organisation and retrieval of architectural knowledge in a file-based documentation approach and an ontology-based documentation approach. The ontology-based approach offers a multi-dimensional organisation of architectural knowledge by means of a software ontology and semantic wiki, whereas file-based documentation typically uses hierarchical organisation by directory structure and table of content. We conducted case studies in two companies to study the efficiency and effectiveness of retrieving architectural knowledge from the different organisations of knowledge. We found that the use of better knowledge organisation correlates with the efficiency and effectiveness of \{AK\} retrieval. Professionals who used the knowledge organisation found this beneficial. "} 
}
@article{Butler2016237,
title = {"Visual imagery in autobiographical memory: The role of repeated retrieval in shifting perspective "},
journal = {"Consciousness and Cognition "},
volume = {"42"},
number = {""},
pages = {"237 - 253"},
year = {"2016"},
note = {""},
issn = {"1053-8100"},
doi = {"https://doi.org/10.1016/j.concog.2016.03.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053810016300472"},
author = {"Andrew C. Butler and Heather J. Rice and Cynthia L. Wooldridge and David C. Rubin"},
keywords = {"Autobiographical memory", "Visual imagery", "Visual perspective", "Retrieval "},
abstract = {"Abstract Recent memories are generally recalled from a first-person perspective whereas older memories are often recalled from a third-person perspective. We investigated how repeated retrieval affects the availability of visual information, and whether it could explain the observed shift in perspective with time. In Experiment 1, participants performed mini-events and nominated memories of recent autobiographical events in response to cue words. Next, they described their memory for each event and rated its phenomenological characteristics. Over the following three weeks, they repeatedly retrieved half of the mini-event and cue-word memories. No instructions were given about how to retrieve the memories. In Experiment 2, participants were asked to adopt either a first- or third-person perspective during retrieval. One month later, participants retrieved all of the memories and again provided phenomenology ratings. When first-person visual details from the event were repeatedly retrieved, this information was retained better and the shift in perspective was slowed. "} 
}
@article{Eskevich20141021,
title = {"Exploring speech retrieval from meetings using the \{AMI\} corpus "},
journal = {"Computer Speech & Language "},
volume = {"28"},
number = {"5"},
pages = {"1021 - 1044"},
year = {"2014"},
note = {""},
issn = {"0885-2308"},
doi = {"https://doi.org/10.1016/j.csl.2013.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0885230813001186"},
author = {"Maria Eskevich and Gareth J.F. Jones"},
keywords = {"Speech retrieval", "Recall-focused information retrieval", "Informal spoken content search", "Retrieval unit segmentation "},
abstract = {"Abstract Increasing amounts of informal spoken content are being collected, e.g. recordings of meetings, lectures and personal data sources. The amount of this content being captured and the difficulties of manually searching audio data mean that efficient automated search tools are of increasing importance if its full potential is to be realized. Much existing work on speech search has focused on retrieval of clearly defined document units in ad hoc search tasks. We investigate search of informal speech content using an extended version of the \{AMI\} meeting collection. A retrieval collection was constructed by augmenting the \{AMI\} corpus with a set of ad hoc search requests and manually identified relevant regions of the recorded meetings. Unlike standard ad hoc information retrieval focussing primarily on precision, we assume a recall-focused search scenario of a user seeking to retrieve a particular incident occurring within meetings relevant to the query. We explore the relationship between automatic speech recognition (ASR) accuracy, automated segmentation of the meeting into retrieval units and retrieval behaviour with respect to both precision and recall. Experimental retrieval results show that while averaged retrieval effectiveness is generally comparable in terms of precision for automatically extracted segments for manual content transcripts and \{ASR\} transcripts with high recognition accuracy, segments with poor recognition quality become very hard to retrieve and may fall below the retrieval rank position to which a user is willing search. These changes impact on system effectiveness for recall-focused search tasks. Varied \{ASR\} quality across the relevant and non-relevant data means that the rank of some well-recognized relevant segments is actually promoted for \{ASR\} transcripts compared to manual ones. This effect is not revealed by the averaged precision based retrieval evaluation metrics typically used for evaluation of speech retrieval. However such variations in the ranks of relevant segments can impact considerably on the experience of the user in terms of the order in which retrieved content is presented. Analysis of our results reveals that while relevant longer segments are generally more robust to \{ASR\} errors, and consequentially retrieved at higher ranks, this is often at the expense of the user needing to engage in longer content playback to locate the relevant content in the audio recording. Our overall conclusion being that it is desirable to minimize the length of retrieval units containing relevant content while seeking to maintain high ranking of these items. "} 
}
@article{Guo2016143,
title = {"Image retrieval using indexed histogram of Void-and-Cluster Block Truncation Coding "},
journal = {"Signal Processing "},
volume = {"123"},
number = {""},
pages = {"143 - 156"},
year = {"2016"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2015.11.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168415003898"},
author = {"Jing-Ming Guo and Heri Prasetyo and Hua Lee and Chen-Chieh Yao"},
keywords = {"Content-based image retrieval", "Ordered Dither Block Truncation Coding", "Similarity weight", "Feature reweighting", "Relevance feedback "},
abstract = {"Abstract This paper presents a simple approach to improve the image retrieval accuracy in the Void-and-Cluster Block Truncation Coding compressed domain. The proposed approach directly derives an image descriptor from the Ordered Dither Block Truncation Coding (ODBTC) data stream without performing the decoding process. The Color Histogram Feature (CHF) is generated from the two \{ODBTC\} color quantizer, while the Halftoning Local Derivative Pattern (HLDP) is constructed from the \{ODBTC\} bitmap image. The similarity between two images are measured from their \{CHF\} and \{HLDP\} features. Three schemes are involved to improve the image retrieval accuracy, including the similarity weight optimization, feature reweighting, and user relevance feedback optimization. An evolutionary stochastic algorithm is exploited to optimize the similarity weight and feature weight in the nearest neighbor distance computation, as well as in the query update of relevance feedback optimization. Section 5 shows that the proposed scheme yields a promising result, and thus it can be a very effective candidate in addressing the content-based image retrieval and image classification task. "} 
}
@article{James201666,
title = {"Age-related deficits in selective attention during encoding increase demands on episodic reconstruction during context retrieval: An \{ERP\} study "},
journal = {"Neuropsychologia "},
volume = {"86"},
number = {""},
pages = {"66 - 79"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2016.04.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393216301178"},
author = {"Taylor James and Jonathan Strunk and Jason Arndt and Audrey Duarte"},
keywords = {"Attention", "Context memory", "Retrieval", "Aging", "ERPs", "LPN "},
abstract = {"Abstract Previous event-related potential (ERP) and neuroimaging evidence suggests that directing attention toward single item-context associations compared to intra-item features at encoding improves context memory performance and reduces demands on strategic retrieval operations in young and older adults. In everyday situations, however, there are multiple event features competing for our attention. It is not currently known how selectively attending to one contextual feature while attempting to ignore another influences context memory performance and the processes that support successful retrieval in the young and old. We investigated this issue in the current \{ERP\} study. Young and older participants studied pictures of objects in the presence of two contextual features: a color and a scene, and their attention was directed to the object's relationship with one of those contexts. Participants made context memory decisions for both attended and unattended contexts and rated their confidence in those decisions. Behavioral results showed that while both groups were generally successful in applying selective attention during context encoding, older adults were less confident in their context memory decisions for attended features and showed greater dependence in context memory accuracy for attended and unattended contextual features (i.e., hyper-binding). \{ERP\} results were largely consistent between age groups but older adults showed a more pronounced late posterior negativity (LPN) implicated in episodic reconstruction processes. We conclude that age-related suppression deficits during encoding result in reduced selectivity in context memory, thereby increasing subsequent demands on episodic reconstruction processes when sought after details are not readily retrieved. "} 
}
@article{Atsak2016207,
title = {"Glucocorticoids mediate stress-induced impairment of retrieval of stimulus-response memory "},
journal = {"Psychoneuroendocrinology "},
volume = {"67"},
number = {""},
pages = {"207 - 215"},
year = {"2016"},
note = {""},
issn = {"0306-4530"},
doi = {"https://doi.org/10.1016/j.psyneuen.2016.02.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306453016300361"},
author = {"Piray Atsak and Friederike M. Guenzel and Deniz Kantar-Gok and Ioannis Zalachoras and Piraye Yargicoglu and Onno C. Meijer and Gina L. Quirarte and Oliver T. Wolf and Lars Schwabe and Benno Roozendaal"},
keywords = {"Stimulus-response memory", "Striatum", "Retrieval", "Stress", "Glucocorticoids", "Metyrapone "},
abstract = {"Abstract Acute stress and elevated glucocorticoid hormone levels are well known to impair the retrieval of hippocampus-dependent ‘declarative’ memory. Recent findings suggest that stress might also impair the retrieval of non-hippocampal memories. In particular, stress shortly before retention testing was shown to impair the retrieval of striatal stimulus-response associations in humans. However, the mechanism underlying this stress-induced retrieval impairment of non-hippocampal stimulus-response memory remains elusive. In the present study, we investigated whether an acute elevation in glucocorticoid levels mediates the impairing effects of stress on retrieval of stimulus-response memory. Male Sprague-Dawley rats were trained on a stimulus-response task in an eight-arm radial maze until they learned to associate a stimulus, i.e., cue, with a food reward in one of the arms. Twenty-four hours after successful acquisition, they received a systemic injection of vehicle, corticosterone (1 mg/kg), the corticosterone-synthesis inhibitor metyrapone (35 mg/kg) or were left untreated 1 h before retention testing. We found that the corticosterone injection impaired the retrieval of stimulus-response memory. We further found that the systemic injection procedure per se was stressful as the vehicle administration also increased plasma corticosterone levels and impaired the retrieval of stimulus-response memory. However, memory retrieval was not impaired when rats were tested 2 min after the systemic vehicle injection, before any stress-induced elevation in corticosterone levels had occurred. Moreover, metyrapone treatment blocked the effect of injection stress on both plasma corticosterone levels and memory retrieval impairment, indicating that the endogenous corticosterone response mediates the stress-induced memory retrieval impairment. None of the treatments affected rats’ locomotor activity or motivation to search for the food reward within the maze. These findings show that stress may affect memory processes beyond the hippocampus and that these stress effects are due to the action of glucocorticoids. "} 
}
@article{Nie201640,
title = {"3D object retrieval based on sparse coding in weak supervision "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"37"},
number = {""},
pages = {"40 - 45"},
year = {"2016"},
note = {"Weakly supervised learning and its applications "},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.06.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001108"},
author = {"Wei-Zhi Nie and An-An Liu and Yu-Ting Su"},
keywords = {"3D model retrieval", "Sparse representation", "Dictionary learning", "Fisher discrimination", "Weak supervision", "Characteristic view extraction", "Similarity measure", "View-based model "},
abstract = {"Abstract With the rapid development of computer vision and digital capture equipment, we can easily record the 3D information of objects. In the recent years, more and more 3D data are generated, which makes it desirable to develop effective 3D retrieval algorithms. In this paper, we apply the sparse coding method in a weakly supervision manner to address 3D model retrieval. First, each 3D object, which is represented by a set of 2D images, is used to learn dictionary. Then, sparse coding is used to compute the reconstruction residual for each query object. Finally, the residual between the query model and the candidate model is used for 3D model retrieval. In the experiment, ETH, \{NTU\} and \{ALOL\} dataset are used to evaluate the performance of the proposed method. The results demonstrate the superiority of the proposed method. "} 
}
@incollection{Chatterjee201795,
title = {"Chapter E - Organization of Information "},
editor = {"Chatterjee, Amitabha "},
booktitle = {"Elements of Information Organization and Dissemination "},
publisher = {"Chandos Publishing"},
edition = {""},
address = {""},
year = {"2017"},
pages = {"95 - 98"},
isbn = {"978-0-08-102025-8"},
doi = {"https://doi.org/10.1016/B978-0-08-102025-8.00005-3"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780081020258000053"},
author = {"Amitabha Chatterjee"},
keywords = {"Information organization", "documentation work", "information need identification", "information retrieval aid "},
abstract = {"Abstract For providing efficient, effective, and speedy information service, the information collected from the information sources need to be properly organized. The activities relating to such organization may be called information organization or documentation work. There are two phases of information organization, viz., identification of user need and compilation of information retrieval aids/IACR products. There are different varieties of information retrieval aids/IACR products. Compilation of information retrieval aids/IACR products mainly proceeds in three stages: identification and location of relevant literature, analysis of relevant literature, and organization of analyzed information. Presently, information retrieval aids/IACR products are brought out not only by libraries/information centers, but also many commercial publishers. "} 
}
@article{Yao2016250,
title = {"Semantic consistency hashing for cross-modal retrieval "},
journal = {"Neurocomputing "},
volume = {"193"},
number = {""},
pages = {"250 - 259"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.02.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S092523121600196X"},
author = {"Tao Yao and Xiangwei Kong and Haiyan Fu and Qi Tian"},
keywords = {"Cross-modal retrieval", "Semantic consistency", "Hashing", "Non-negative matrix factorization", "Neighbor preserving "},
abstract = {"Abstract The task of cross-modal retrieval is to query similar objects in dataset of multi-modality, such as using text to query images and vice versa. However, most of existing works suffer from high computational complexity and storage cost in large-scale applications. Recently, hashing method mapping the high-dimensional data to compact binary codes has attracted a lot of concerns due to its efficiency and low storage cost over large-scale dataset. In this paper, we propose a Semantic Consistency Hashing (SCH) method for cross-modal retrieval. \{SCH\} learns a shared semantic space simultaneously taking both inter-modal and intra-modal semantic correlations into account. In order to preserve the inter-modal semantic consistency, an identical representation is learned using non-negative matrix factorization for the samples with different modalities. Meanwhile, neighbor preserving algorithm is adopted to preserve the semantic consistency in each modality. In addition, an effective optimal algorithm is proposed to reduce the time complexity from traditional O ( N 2 ) or higher to O(N). Extensive experiments on two public datasets demonstrate that the proposed approach significantly outperforms the existing schemes. "} 
}
@article{Zhao201673,
title = {"A novel image retrieval method based on multi-trend structure descriptor "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"38"},
number = {""},
pages = {"73 - 81"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2016.02.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320316300049"},
author = {"Meng Zhao and Huaxiang Zhang and Jiande Sun"},
keywords = {"Multi-trend structure descriptor", "Image retrieval", "Visual perception mechanism", "Local descriptor "},
abstract = {"Abstract This paper proposes an image feature representation method, namely Multi-Trend Structure Descriptor (MTSD), which is built based on the local and multi-trend structures. The local structures can be regarded as the basic units for image analysis, and the multi-trend structures are introduced to explore the correlation among pixels in local structures according to the information change of pixels. The visual information such as color, edge orientation and intensity map are considered and quantized, and with the local structure as a bridge, we use multi-trend to detect color, edge orientation and intensity map respectively for feature extraction. \{MTSD\} can characterize not only the low-level features, such as color, shape and texture, but also the local spatial structure information. We evaluate the performance of the proposed algorithm on Corel and Caltech datasets, and experimental results demonstrate that, \{MTSD\} significantly outperforms texton co-occurrence matrix, multi-texton histogram, micro-structure descriptor and saliency structure histogram. "} 
}
@article{Mills2015283,
title = {"Enhancing computer literacy and information retrieval skills: A rural and remote nursing and midwifery workforce study "},
journal = {"Collegian "},
volume = {"22"},
number = {"3"},
pages = {"283 - 289"},
year = {"2015"},
note = {""},
issn = {"1322-7696"},
doi = {"https://doi.org/10.1016/j.colegn.2014.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1322769614000213"},
author = {"Jane Mills and Karen Francis and Margaret McLeod and Mohammad Al-Motlaq"},
keywords = {"Australian rural nurses and midwives", "Health care informatics", "Continuing professional development", "Currency of practice "},
abstract = {"Summary Nurses and midwives collectively, represent the largest workforce category in rural and remote areas of Australia. Maintaining currency of practice and attaining annual licensure with the Australian Health Practitioners Regulatory Authority (AHPRA) present challenges for individual nurses and midwives and for their health service managers. Engagement with information and communication technologies, in order for geographically isolated clinicians to access ongoing education and training, is considered a useful strategy to address such challenges. This paper presents a pre- and post-test study design. It examines the impact of an online continuing professional development (CPD) program on Australian rural nurses and midwives. The aims of the program were to increase basic skill acquisition in the utilisation of common computer software, the use of the Internet and the enhancement of email communication. Findings from the study demonstrate that participants who complete a relevant \{CPD\} program gain confidence in the use of information and communication technologies. Further, increased confidence leads to increased access to contemporary, reliable and important health care information on the Internet, in addition to clinicians adopting email as a regular method of communication. Health care employers commonly assume employees are skilled users of information and communication technologies. However, findings from this study contradict such assumptions. It is argued in the recommendations that health care employees should be given regular access to \{CPD\} programs designed to introduce them to information and communication technologies. Developing knowledge and skills in this area has the potential to improve staff productivity, raise health care standards and improve patient outcomes. "} 
}
@article{Nikitidou2015776,
title = {"Retrieval of surface solar irradiance, based on satellite-derived cloud information, in Greece "},
journal = {"Energy "},
volume = {"90, Part 1"},
number = {""},
pages = {"776 - 783"},
year = {"2015"},
note = {""},
issn = {"0360-5442"},
doi = {"https://doi.org/10.1016/j.energy.2015.07.103"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360544215009986"},
author = {"E. Nikitidou and A. Kazantzidis and P. Tzoumanikas and V. Salamalikis and A.F. Bais"},
keywords = {"Solar energy", "Global horizontal irradiance", "Direct normal irradiance", "Clouds", "Satellite "},
abstract = {"Abstract Cloud properties derived from the \{SEVIRI\} (Spinning Enhanced Visible and Infrared Imager) instrument, on board the \{MSG\} (Meteosat Second Generation) satellite, have been used to retrieve the surface global solar irradiance incident on a horizontal surface \{GHI\} (global horizontal irradiance) and the \{DNI\} (direct normal irradiance) with a temporal resolution of 15 min. The daily amount of solar energy as well as monthly and annual sums, are estimated. Based on a 6-year study period (2008–2013), a monthly climatology is derived. Results are compared with ground-based measurements in Greece. Comparison shows a general good agreement between satellite and ground data, with the highest differences occurring in cases of broken or very thick cloudiness. The highest collected monthly solar energy values are found during summer months, in Southern Peloponnese, Crete and Cyclades islands, and exceed 250 kWh m−2. The annual average energy for \{GHI\} is 1400–1500 kWh m−2 in Northern Greece and up to 1900 kWh m−2 in Southern Peloponnese, Crete and the islands. For DNI, values increase to about 9% in Northern Greece and around 15% in Southern Greece. "} 
}
@article{Zhu201683,
title = {"Large-scale video copy retrieval with temporal-concentration \{SIFT\} "},
journal = {"Neurocomputing "},
volume = {"187"},
number = {""},
pages = {"83 - 91"},
year = {"2016"},
note = {"Recent Developments on Deep Big Vision "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.09.114"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215017336"},
author = {"Yingying Zhu and Xiaoyan Huang and Qiang Huang and Qi Tian"},
keywords = {"Video copy retrieval", "SIFT", "Spatio-temporal features", "Frame validation "},
abstract = {"Abstract The scale-invariant feature transform (SIFT) feature plays a very important role in multimedia content analysis, such as near-duplicate image and video retrieval. However, the storage and query costs of \{SIFT\} become unbearable for large-scale databases. In this paper, \{SIFT\} features are robustly encoded with temporal information by tracking the \{SIFT\} to generate temporal-concentration \{SIFT\} (TCSIFT), which highly compresses the quantity of local features to reduce visual redundancy, and keeps the advantages of \{SIFT\} as much as possible at the same time. On the basis of TCSIFT, a novel framework for large-scale video copy retrieval is proposed in which the processes of retrieval and validation are implemented at the feature and frame level. Experimental results for two different datasets, i.e., CC_WEB_VIDEO and TRECVID, demonstrate that our method can yield comparable accuracy, compact storage size, and more efficient execution time, as well as adapt to various video transformations. "} 
}
@article{Kragel201760,
title = {"Similar patterns of neural activity predict memory function during encoding and retrieval "},
journal = {"NeuroImage "},
volume = {"155"},
number = {""},
pages = {"60 - 71"},
year = {"2017"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2017.03.042"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811917302549"},
author = {"James E. Kragel and Youssef Ezzyat and Michael R. Sperling and Richard Gorniak and Gregory A. Worrell and Brent M. Berry and Cory Inman and Jui-Jui Lin and Kathryn A. Davis and Sandhitsu R. Das and Joel M. Stein and Barbara C. Jobst and Kareem A. Zaghloul and Sameer A. Sheth and Daniel S. Rizzuto and Michael J. Kahana"},
keywords = {"iEEG", "MVPA", "Free recall", "Episodic memory "},
abstract = {"Abstract Neural networks that span the medial temporal lobe (MTL), prefrontal cortex, and posterior cortical regions are essential to episodic memory function in humans. Encoding and retrieval are supported by the engagement of both distinct neural pathways across the cortex and common structures within the medial temporal lobes. However, the degree to which memory performance can be determined by neural processing that is common to encoding and retrieval remains to be determined. To identify neural signatures of successful memory function, we administered a delayed free-recall task to 187 neurosurgical patients implanted with subdural or intraparenchymal depth electrodes. We developed multivariate classifiers to identify patterns of spectral power across the brain that independently predicted successful episodic encoding and retrieval. During encoding and retrieval, patterns of increased high frequency activity in prefrontal, MTL, and inferior parietal cortices, accompanied by widespread decreases in low frequency power across the brain predicted successful memory function. Using a cross-decoding approach, we demonstrate the ability to predict memory function across distinct phases of the free-recall task. Furthermore, we demonstrate that classifiers that combine information from both encoding and retrieval states can outperform task-independent models. These findings suggest that the engagement of a core memory network during either encoding or retrieval shapes the ability to remember the past, despite distinct neural interactions that facilitate encoding and retrieval. "} 
}
@article{Saneifar2014937,
title = {"Enhancing passage retrieval in log files by query expansion based on explicit and pseudo relevance feedback "},
journal = {"Computers in Industry "},
volume = {"65"},
number = {"6"},
pages = {"937 - 951"},
year = {"2014"},
note = {""},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2014.02.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S016636151400044X"},
author = {"Hassan Saneifar and Stéphane Bonniol and Pascal Poncelet and Mathieu Roche"},
keywords = {"Information retrieval", "Passage retrieval", "Question answering", "Query enrichment", "Context learning", "Log files "},
abstract = {"Abstract Passage retrieval is usually defined as the task of searching for passages which may contain the answer for a given query. While these approaches are very efficient when dealing with texts, applied to log files (i.e. semi-structured data containing both numerical and symbolic information) they usually provide irrelevant or useless results. Nevertheless one appealing way for improving the results could be to consider query expansions that aim at adding automatically or semi-automatically additional information in the query to improve the reliability and accuracy of the returned results. In this paper, we present a new approach for enhancing the relevancy of queries during a passage retrieval in log files. It is based on two relevance feedback steps. In the first one, we determine the explicit relevance feedback by identifying the context of the requested information within a learning process. The second step is a new kind of pseudo relevance feedback. Based on a novel term weighting measure it aims at assigning a weight to terms according to their relatedness to queries. This measure, called \{TRQ\} (Term Relatedness to Query), is used to identify the most relevant expansion terms. The main advantage of our approach is that is can be applied both on log files and documents from general domains. Experiments conducted on real data from logs and documents show that our query expansion protocol enables retrieval of relevant passages. "} 
}
@article{Danelakis2016174,
title = {"An effective methodology for dynamic 3D facial expression retrieval "},
journal = {"Pattern Recognition "},
volume = {"52"},
number = {""},
pages = {"174 - 185"},
year = {"2016"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2015.10.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S003132031500391X"},
author = {"Antonios Danelakis and Theoharis Theoharis and Ioannis Pratikakis and Panagiotis Perakis"},
keywords = {"Dynamic 3D mesh sequence", "3D object retrieval", "4D facial expression retrieval", "4D facial expression recognition "},
abstract = {"Abstract The problem of facial expression recognition in dynamic sequences of 3D face scans has received a significant amount of attention in the recent past whereas the problem of retrieval in this type of data has not. A novel retrieval methodology for such data is introduced in this paper. The proposed methodology automatically detects specific facial landmarks and uses them to create a descriptor. This descriptor is the concatenation of three sub-descriptors which capture topological as well as geometric information of the 3D face scans. The motivation behind the proposed hybrid facial expression descriptor is the fact that some facial expressions, like happiness and surprise, are characterized by obvious changes in the mouth topology while others, like anger, fear and sadness, produce geometric but no significant topological changes. The proposed retrieval scheme exploits the Dynamic Time Warping technique in order to compare descriptors corresponding to different 3D facial sequences. A detailed evaluation of the introduced retrieval scheme is presented showing that it outperforms previous state-of-the-art retrieval schemes. Experiments have been conducted using the six prototypical expressions of the standard dataset BU-4DFE and the eight prototypical expressions of the recently available dataset BP4D-Spontaneous. Finally, a majority voting scheme based on the retrieval results is used to achieve unsupervised dynamic 3D facial expression recognition. The achieved classification accuracy is comparable to the state-of-the-art supervised dynamic 3D facial expression recognition techniques. "} 
}
@article{Hurson201620,
title = {"Energy-efficient algorithms for data retrieval from indexed parallel broadcast channels "},
journal = {"Sustainable Computing: Informatics and Systems "},
volume = {"10"},
number = {""},
pages = {"20 - 35"},
year = {"2016"},
note = {""},
issn = {"2210-5379"},
doi = {"https://doi.org/10.1016/j.suscom.2016.03.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S2210537915300032"},
author = {"Ali R. Hurson and Sahra Sedigh Sarvestani and Mike Wisely"},
keywords = {"Algorithm/protocol design and analysis", "Query processing", "Retrieval models", "Ubiquitous computing", "Energy management", "Broadcasting "},
abstract = {"Abstract Constraints on the energy, bandwidth, and connectivity of mobile devices and wireless communication medium complicate the timely and reliable access to public data. Energy is often the most stringent constraint, necessitating techniques that facilitate operation in energy-saving modes. Broadcasting, typically over parallel channels, has proven to be an effective method for dissemination of public data to mobile devices. However, the employment of parallel channels introduces challenges associated with channel switching and conflicts due to concurrent accesses to multiple data items that ultimately increase energy consumption and response time. The detrimental effects on energy consumption and response time can be alleviated by scheduling the retrieval of data items in an order that reduces the number of passes over the air channels and channel switching between the parallel channels. In this paper, several scheduling algorithms are proposed and analyzed that achieve the aforementioned objectives. To further improve energy consumption and response time, the scope of our scheduling algorithms has been enhanced by replication of popular data items. The proposed scheduling algorithms, both with and without replication, have been simulated, and simulation results are presented and analyzed. These results show that the proposed scheduling algorithms, compared to some heuristic based methods, have greater impact in reducing energy consumption and response time. This reduction is shown to be more pronounced with replication of data items. "} 
}
@article{Jasiewicz201562,
title = {"GeoPAT: A toolbox for pattern-based information retrieval from large geospatial databases "},
journal = {"Computers & Geosciences "},
volume = {"80"},
number = {""},
pages = {"62 - 73"},
year = {"2015"},
note = {""},
issn = {"0098-3004"},
doi = {"https://doi.org/10.1016/j.cageo.2015.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0098300415000758"},
author = {"Jarosław Jasiewicz and Paweł Netzel and Tomasz Stepinski"},
keywords = {"Pattern analysis", "Query-by-example", "Large geospatial datasets", "Similarity", "Image classification", "GRASS \{GIS\} "},
abstract = {"Abstract Geospatial Pattern Analysis Toolbox (GeoPAT) is a collection of \{GRASS\} \{GIS\} modules for carrying out pattern-based geospatial analysis of images and other spatial datasets. The need for pattern-based analysis arises when images/rasters contain rich spatial information either because of their very high resolution or their very large spatial extent. Elementary units of pattern-based analysis are scenes – patches of surface consisting of a complex arrangement of individual pixels (patterns). GeoPAT modules implement popular \{GIS\} algorithms, such as query, overlay, and segmentation, to operate on the grid of scenes. To achieve these capabilities GeoPAT includes a library of scene signatures – compact numerical descriptors of patterns, and a library of distance functions – providing numerical means of assessing dissimilarity between scenes. Ancillary GeoPAT modules use these functions to construct a grid of scenes or to assign signatures to individual scenes having regular or irregular geometries. Thus GeoPAT combines knowledge retrieval from patterns with mapping tasks within a single integrated \{GIS\} environment. GeoPAT is designed to identify and analyze complex, highly generalized classes in spatial datasets. Examples include distinguishing between different styles of urban settlements using \{VHR\} images, delineating different landscape types in land cover maps, and mapping physiographic units from DEM. The concept of pattern-based spatial analysis is explained and the roles of all modules and functions are described. A case study example pertaining to delineation of landscape types in a subregion of \{NLCD\} is given. Performance evaluation is included to highlight GeoPAT's applicability to very large datasets. The GeoPAT toolbox is available for download from http://sil.uc.edu/. "} 
}
@article{Li201683,
title = {"Retrieval of precipitable water vapor using \{MFRSR\} and comparison with other multisensors over the semi-arid area of northwest China "},
journal = {"Atmospheric Research "},
volume = {"172–173"},
number = {""},
pages = {"83 - 94"},
year = {"2016"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2015.12.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809515004056"},
author = {"Xia Li and Lei Zhang and Xianjie Cao and Jiannong Quan and Tianhe Wang and Jiening Liang and Jinsen Shi"},
keywords = {"MFRSR", "Precipitable water vapor", "Retrieval algorithm", "Comparison "},
abstract = {"Abstract Precipitable water vapor (PWV) was retrieved using direct solar irradiance at 938 nm measured by a multifilter rotating shadowband radiometer (MFRSR) at the Semi-Arid Climate and Environment Observatory of Lanzhou University (SACOL) located in the semi-arid area of northwest China from August 2007 to June 2010. Measurement also occurred at Zhangye, China, at the Atmosphere Radiation Measurements (ARM) Program's Ancillary Facility during the dust period from April to June 2008. The line-by-line radiative transfer model (LBLRTM) code combined with the \{HITRAN\} 2004 spectral database is used to model the water vapor spectral transmittance throughout the 938-nm spectral response of \{MFRSR\} in the retrieval algorithm. Gaussian fitting is proposed to determine the daily calibration constant at the top of atmosphere for a long-term series under an obvious annual change in solar radiation. \{PWV\} retrieved by \{MFRSR\} over \{SACOL\} shows that 90% of \{PWV\} values are smaller than 1.52 cm, and \{PWV\} distribution has a seasonal variation, with maximum in summer and minimum in winter. The comparisons between \{MFRSR\} and other measurements show a better agreement between \{MFRSR\} and sunphotometer (AERONET's Cimel) \{PWV\} retrievals with relative bias of 2.9% and \{RMS\} difference of 9.1% than between \{MFRSR\} and microwave radiometer (MWR) with relative bias of 10% and \{RMS\} difference of 23% over SACOL, and an excellent agreement between \{MFRSR\} and sunphotometer with relative bias of 0.56% and \{RMS\} difference of 6.1% over Zhangye. To verify satellite \{PWV\} products over the semi-arid area of northwest China, the comparisons of \{PWV\} from \{MODIS\} and \{AIRS\} with \{MFRSR\} suggest that the agreement between satellite and \{MFRSR\} \{PWV\} retrievals is not as good as that between \{MFRSR\} and other ground-based instruments. \{MODIS\} appears to slightly underestimate \{PWV\} in a dry atmosphere but overestimate \{PWV\} in a moist atmosphere against MFRSR. A method is proposed to correct \{MODIS\} \{PWV\} products. \{AIRS\} \{PWV\} products relative to \{MFRSR\} show a systematic underestimation. "} 
}
@article{Johnson2015300,
title = {"Episodic retrieval involves early and sustained effects of reactivating information from encoding "},
journal = {"NeuroImage "},
volume = {"106"},
number = {""},
pages = {"300 - 310"},
year = {"2015"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2014.11.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811914009306"},
author = {"Jeffrey D. Johnson and Mason H. Price and Emily K. Leiker"},
keywords = {"Episodic memory", "Recognition", "EEG", "Reinstatement", "Reactivation", "Confidence "},
abstract = {"Abstract Several fMRI studies have shown a correspondence between the brain regions activated during encoding and retrieval, consistent with the view that memory retrieval involves hippocampally-mediated reinstatement of cortical activity. With the limited temporal resolution of fMRI, the precise timing of such reactivation is unclear, calling into question the functional significance of these effects. Whereas reactivation influencing retrieval should emerge with neural correlates of retrieval success, that signifying post-retrieval monitoring would trail retrieval. The present study employed \{EEG\} to provide a temporal landmark of retrieval success from which we could investigate the sub-trial time course of reactivation. Pattern-classification analyses revealed that early-onsetting reactivation differentiated the outcome of recognition-memory judgments and was associated with individual differences in behavioral accuracy, while reactivation was also evident in a sustained form later in the trial. The \{EEG\} findings suggest that, whereas prior fMRI findings could be interpreted as reflecting the contribution of reinstatement to retrieval success, they could also indicate the maintenance of episodic information in service of post-retrieval evaluation. "} 
}
@article{Lewenstein201694,
title = {"Document retrieval with one wildcard "},
journal = {"Theoretical Computer Science "},
volume = {"635"},
number = {""},
pages = {"94 - 101"},
year = {"2016"},
note = {""},
issn = {"0304-3975"},
doi = {"https://doi.org/10.1016/j.tcs.2016.05.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304397516301608"},
author = {"Moshe Lewenstein and J. Ian Munro and Yakov Nekrich and Sharma V. Thankachan"},
keywords = {"Document retrieval", "String searching", "Wildcards", "Compressed data structures "},
abstract = {"Abstract In this paper we extend several well-known document listing problems to the case when documents contain a substring that approximately matches the query pattern. We study the scenario when the query string can contain a wildcard symbol that matches any alphabet symbol; all documents that match a query pattern with one wildcard must be enumerated. We describe a linear space data structure that reports all documents containing a substring P in O ( | P | + σ log ⁡ log ⁡ log ⁡ n + docc ) time, where σ is the alphabet size and docc is the number of listed documents. We also describe a succinct solution for this problem, as well as a solution for an extension of this problem. Furthermore our approach enables us to obtain an O ( n σ ) -space data structure that enumerates all documents containing both a pattern P 1 and a pattern P 2 in the special case when P 1 and P 2 differ in one symbol. "} 
}
@article{Bayramoglu201613,
title = {"Comparison of 3D local and global descriptors for similarity retrieval of range data "},
journal = {"Neurocomputing "},
volume = {"184"},
number = {""},
pages = {"13 - 27"},
year = {"2016"},
note = {"RoLoD: Robust Local Descriptors for Computer Vision 2014 "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.08.105"},
url = {"http://www.sciencedirect.com/science/article/pii/S092523121501841X"},
author = {"Neslihan Bayramoglu and A. Aydın Alatan"},
keywords = {"Range data retrieval", "Local descriptors", "Global descriptors", "Similarity indexing", "Single view depth data description "},
abstract = {"Abstract Recent improvements in scanning technologies such as consumer penetration of RGB-D cameras lead obtaining and managing range image databases practical. Hence, the need for describing and indexing such data arises. In this study, we focus on similarity indexing of range data among a database of range objects (range-to-range retrieval) by employing only single view depth information. We utilize feature based approaches both on local and global scales. However, the emphasis is on the local descriptors with their global representations. A comparative study with extensive experimental results is presented. In addition, we introduce a publicly available range object database which is large and has a high diversity that is suitable for similarity retrieval applications. The simulation results indicate competitive performance between local and global methods. While better complexity trade-off can be achieved with the global techniques, local methods perform better in distinguishing different parts of incomplete depth data. "} 
}
@article{Farruggia2014243,
title = {"A text based indexing system for mammographic image retrieval and classification "},
journal = {"Future Generation Computer Systems "},
volume = {"37"},
number = {""},
pages = {"243 - 251"},
year = {"2014"},
note = {"Special Section: Innovative Methods and Algorithms for Advanced Data-Intensive ComputingSpecial Section: Semantics, Intelligent processing and services for big dataSpecial Section: Advances in Data-Intensive Modelling and SimulationSpecial Section: Hybrid Intelligence for Growing Internet and its Applications "},
issn = {"0167-739X"},
doi = {"https://doi.org/10.1016/j.future.2014.02.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167739X14000338"},
author = {"Alfonso Farruggia and Rosario Magro and Salvatore Vitabile"},
keywords = {"Information retrieval", "Medical documents indexing and classification", "Medical images indexing and classification "},
abstract = {"Abstract In modern medical systems huge amount of text, words, images and videos are produced and stored in ad hoc databases. Medical community needs to extract precise information from that large amount of data. Currently \{ICT\} approaches do not provide a methodology for content-based medical images retrieval and classification. On the other hand, from the Internet of Things (IoT) perspective, the \{ICT\} medical data can be produced by several devices. Produced data complies with all Big Data features and constraints. The IoT guidelines put at the center of the system a new smart software to manage and transform Big Data in a new understanding form. This paper describes a text based indexing system for mammographic images retrieval and classification. The system deals with text (structured reports) and images (mammograms) mining and classification in a typical Department of Radiology. \{DICOM\} structured reports, containing free text for medical diagnosis, have been analyzed and labeled in order to classify the corresponding mammographic images. Information Retrieval process is based on some text manipulation techniques, such as light semantic analysis, stop-word removing, and light medical natural language processing. The system includes also a Search Engine module, based on a Bayes Naive Classifier. The experimental results provide interesting performance in terms of Specificity and Sensibility. Two more indexes have been computed in order to assess the system robustness: the A z (Area under \{ROC\} Curve) index and the σ A z ( A z standard error) index. The dataset is composed of healthy and pathological \{DICOM\} structured reports. Two use case scenarios are presented and described to prove the effectiveness of the proposed approach. "} 
}
@article{Yang201670,
title = {"Metric learning based object recognition and retrieval "},
journal = {"Neurocomputing "},
volume = {"190"},
number = {""},
pages = {"70 - 81"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.01.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216000795"},
author = {"Jianyu Yang and Haoran Xu"},
keywords = {"Metric learning", "Object recognition", "Object retrieval", "Robot learning", "Intelligent analysis "},
abstract = {"Abstract Object recognition and retrieval is an important topic in intelligent robotics and pattern recognition, where an effective recognition engine plays an important role. To achieve a good performance, we propose a metric learning based object recognition algorithm. To represent the invariant object features, including local shape details and global body parts, a novel multi-scale invariant descriptor is proposed. Different types of invariant features are represented in multiple scales, which makes the following metric learning algorithm effective. To reduce the effect of noise and improve the computing efficiency, an adaptive discrete contour evolution method is also proposed to extract the salient feature points of object. The recognition algorithm is explored based on metric learning method and the object features are summarized as histograms inspired from the Bag of Words (BoW). The metric learning methods are employed to learn object features according to their scales. The proposed method is invariant to rotation, scale variation, intra-class variation, articulated deformation and partial occlusion. The recognition process is fast and robust for noise. This method is evaluated on multiple benchmark datasets and the comparable experimental results indicate the effectiveness of our method. "} 
}
@article{Ward201585,
title = {"A prosody-based vector-space model of dialog activity for information retrieval "},
journal = {"Speech Communication "},
volume = {"68"},
number = {""},
pages = {"85 - 96"},
year = {"2015"},
note = {""},
issn = {"0167-6393"},
doi = {"https://doi.org/10.1016/j.specom.2015.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167639315000059"},
author = {"Nigel G. Ward and Steven D. Werner and Fernando Garcia and Emilio Sanchis"},
keywords = {"Search", "Speech", "Audio", "Similarity judgments", "Similarity metrics", "Principal components analysis "},
abstract = {"Abstract Search in audio archives is a challenging problem. Using prosodic information to help find relevant content has been proposed as a complement to word-based retrieval, but its utility has been an open question. We propose a new way to use prosodic information in search, based on a vector-space model, where each point in time maps to a point in a vector space whose dimensions are derived from numerous prosodic features of the local context. Point pairs that are close in this vector space are frequently similar, not only in terms of the dialog activities, but also in topic. Using proximity in this space as an indicator of similarity, we built support for a query-by-example function. Searchers were happy to use this function, and it provided value on a large testset. Prosody-based retrieval did not perform as well as word-based retrieval, but the two sources of information were often non-redundant and in combination they sometimes performed better than either separately. "} 
}
@article{Yu201656,
title = {"Study of high temperature targets identification and temperature retrieval experimental model in \{SWIR\} remote sensing based Landsat8 "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"46"},
number = {""},
pages = {"56 - 62"},
year = {"2016"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2015.11.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243415300593"},
author = {"Yifan Yu and Lixin Xing and Jun Pan and Lijun Jiang and Hualiang Yu"},
keywords = {"SWIR", "High temperature targets", "Temperature retrieval", "Theoretical framework", "Experimental model", "Landsat8 "},
abstract = {"Abstract For surface features in short-wave infrared (SWIR, 1.3–3.0 μm) in remote sensing imagery, pixel values depict the total energy including reflection and emission. For surface features at normal temperature in \{SWIR\} band, emission energy can be ignored. While for surface features at high temperature in \{SWIR\} band, emission energy is equal to or even higher than the reflection energy. So remote sensing imagery of \{SWIR\} band can be used to separate emission and reflection energy as well as to realize temperature retrieval of high temperature targets. In this study, the seventh band (SWIR band) of Landsat8 \{OLI\} remote sensing imagery is used to perform the theoretical model research for temperature retrieval of high temperature targets. In the meantime, it is also used with the corresponding observation experiment of synchronization satellite to check the theoretical model. The result shows that the radiant flux density for mixed pixels with high temperature targets is higher than adjacent pixels without high temperature targets. Thus, the high temperature pixels can be identified in \{SWIR\} band. The retrieval results of temperature and fractional area for high temperature targets are consistent with reality. In the study, the result illustrates that it is effective to identify high temperature targets in remote sensing imagery of \{SWIR\} band and the model is appropriate for temperature retrieval use. "} 
}
@article{Liu2017366,
title = {"An improved physical split-window algorithm for precipitable water vapor retrieval exploiting the water vapor channel observations "},
journal = {"Remote Sensing of Environment "},
volume = {"194"},
number = {""},
pages = {"366 - 378"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.03.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717301347"},
author = {"Hailei Liu and Shihao Tang and Juyang Hu and Shenglan Zhang and Xiaobo Deng"},
keywords = {"PWV", "Geostationary satellites", "SVISSR", "MODIS", "Emissivity "},
abstract = {"Abstract This paper presents a new atmospheric precipitable water vapor (PWV) retrieval method based on three thermal infrared band observations from geostationary satellites. The proposed method is similar to the traditional physical split-window (PSW) retrieval technique, but a water vapor channel observation near 6.7 μm was included. Sensitivity analyses and simulation retrievals were carried out respectively according to the instrument characteristics of the Stretched Visible and Infrared Spin Scan Radiometer onboard FengYun-2G (SVISSR/FY-2G) and the Moderate Resolution Imaging Spectroradiometer aboard Terra (MODIS/Terra). The results indicate that the proposed 3-band algorithm can significantly reduce \{PWV\} retrieval errors caused by surface emissivity uncertainty and observation errors, especially in dry atmospheric conditions (i.e., \{PWV\} &lt; 2 cm). The proposed algorithm was validated using SVISSR/FY-2G and MODIS/Terra observations, and was compared with radiosonde and \{GPS\} PWV. The determination coefficient (R2), root mean square error (RMSE), and bias between the \{SVISSR\} retrieved \{PWV\} and the radiosonde \{PWV\} are 0.87, 0.43 cm and 0.14 cm, respectively. The R2, \{RMSE\} and bias of the \{MODIS\} retrieved \{PWV\} are 0.89, 0.10 cm and − 0.042 cm, respectively, which are slightly better than the \{MODIS\} \{L2\} thermal infrared and near-infrared \{PWV\} products. "} 
}
@article{Li20164422,
title = {"\{CO2\} retrieval model and analysis in short-wave infrared spectrum "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"10"},
pages = {"4422 - 4425"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.01.144"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616001935"},
author = {"Yanfen Li and Chunmin Zhang and Dongdong Liu and Jie Chen and Piao Rong and Xingying Zhang and Shupeng Wang"},
keywords = {"GF_VRTM", "GOSAT-FTS", "XCO2 retrieval", "Error analysis "},
abstract = {"Abstract The global carbon dioxide hyperspectral remote sensing inversion system GF_VRTM is established for the greenhouse gas carbon dioxide remote sensing detection of GF-5 satellite. The validation and error analysis of global inversion is performed by using GF_VRTM with 21 June 2013 observation data of GOSAT-FTS in this study. The simulation results show that the \{CO2\} averaged column concentrations (XCO2) overall trends are basically identical between GF_VRTM retrievals and GOSAT-FTS observations. There are 138 exposure points in whole observation points, and the relative error less than 2% is about 85%. The mean square error is 5.00 ppm, but the global average error is 1.09 ppm. If the assumption that GOSAT-FTS observation data is true, GF_VRTM satisfies the average precision requirements (less than 1%) of \{XCO2\} global inversion. For the results of the comparison, the minimum error scenario and maximum error scenario are selected for error analysis. Error sources are smooth error, measurement noise error, the forward model parameter error and forward model error, respectively. For the minimum error scenario and maximum error scenario, the relative error of \{XCO2\} inversion caused by smooth error and measurement noise error are 0.44% and −1.62%, respectively, and the relative error of \{XCO2\} inversion caused by the forward model parameter error are −0.43% and −1.53%, respectively. At the same time, the forward model error is ignored. "} 
}
@incollection{Kornell2016183,
title = {"Chapter Five - How Retrieval Attempts Affect Learning: A Review and Synthesis "},
editor = {"Brian H. Ross"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2016"},
volume = {"65"},
pages = {"183 - 215"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/bs.plm.2016.03.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0079742116000165"},
author = {"Nate Kornell and Kalif E. Vaughn"},
keywords = {"Learning", "Memory", "Metacognitive awareness", "Retrieval attempt", "Retrieval success", "Search set theory", "Test-enhanced learning "},
abstract = {"Abstract Attempting to recall information from memory (ie, retrieval practice) has been shown to enhance learning across a wide variety of materials, learners, and experimental conditions. We examine the moderating effects of what is arguably the most fundamental distinction to be made about retrieval: whether a retrieval attempt results in success or failure. After reviewing research on this topic, we conclude that retrieval practice is beneficial even when the retrieval attempt is unsuccessful. This finding appears to hold true in a variety of laboratory and real-world contexts and applies to learners across the lifespan. Based on these findings we outline a two-stage model in which learning from retrieval involves (1) a retrieval attempt and then (2) processing the answer. We then turn to a second issue: Does retrieval success even matter for learning? Recent findings suggest that retrieval failure followed by feedback leads to the same amount of learning as retrieval success. In light of these findings, we propose that separate mechanisms are not needed to explain the effect of retrieval success and retrieval failure on learning. We then review existing theories of retrieval and comment on their compatibility with extant data, and end with theoretical conclusions for researchers as well as practical advice for learners and teachers. "} 
}
@article{Ma201664,
title = {"Sketch retrieval via local dense stroke features "},
journal = {"Image and Vision Computing "},
volume = {"46"},
number = {""},
pages = {"64 - 73"},
year = {"2016"},
note = {""},
issn = {"0262-8856"},
doi = {"https://doi.org/10.1016/j.imavis.2015.11.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0262885615001389"},
author = {"Chao Ma and Xiaokang Yang and Chongyang Zhang and Xiang Ruan and Ming-Hsuan Yang"},
keywords = {"Sketch retrieval", "Stroke feature", "Poisson based histogram of orientation "},
abstract = {"Abstract Sketch retrieval aims at retrieving the most similar sketches from a large database based on one hand-drawn query. Successful retrieval hinges on an effective representation of sketch images and an efficient search method. In this paper, we propose a representation scheme which takes sketch strokes into account with local features, thereby facilitating efficient retrieval with codebooks. Stroke features are detected via densely sampled points on stroke lines with crucial corners as anchor points, from which local gradients are enhanced and described by a quantized histogram of gradients. A codebook is organized in a hierarchical vocabulary tree, which maintains structural information of visual words and enables efficient retrieval in sub-linear time. Experimental results on three data sets demonstrate the merits of the proposed algorithm for effective and efficient sketch retrieval. "} 
}
@article{Duan2017107,
title = {"A framework for the retrieval of all-weather land surface temperature at a high spatial resolution from polar-orbiting thermal infrared and passive microwave data "},
journal = {"Remote Sensing of Environment "},
volume = {"195"},
number = {""},
pages = {"107 - 117"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.04.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S003442571730158X"},
author = {"Si-Bo Duan and Zhao-Liang Li and Pei Leng"},
keywords = {"Land surface temperature", "All-weather", "Thermal infrared", "Passive microwave", "Subsurface temperature "},
abstract = {"Abstract Land surface temperature (LST) is an important parameter associated with the land-atmosphere interface. Satellite remote sensing is the most effective method of measuring \{LST\} at regional and global scales. Satellite thermal infrared (TIR) measurements are widely used to retrieve \{LST\} with high accuracy and high spatial resolution but are limited to cloud-free conditions due to their inability to penetrate clouds. By contrast, satellite passive microwave (PMW) measurements are capable of penetrating clouds and providing data regardless of the cloud conditions. However, \{PMW\} measurements have limitations, such as a low spatial resolution and low temperature retrieval accuracy. Furthermore, temperature retrieval from \{PMW\} measurements yields the subsurface temperature, which differs from the \{LST\} retrieved from \{TIR\} measurements (skin temperature). This study proposes a framework for the retrieval of all-weather \{LST\} at a high spatial resolution by combining the advantages of \{TIR\} and \{PMW\} measurements. Compared to the \{MODIS\} \{LST\} product, the all-weather \{LST\} reflects the spatial variations in \{LST\} accurately. In situ \{LST\} measurements at four sites in an arid area of northwest China were used to evaluate the accuracy of the all-weather LST. The root mean square error of the \{LST\} under cloud-free conditions was approximately 2 K, whereas that of the \{LST\} under cloudy conditions varied from 3.5 K to 4.4 K. The results indicate that the all-weather \{LST\} retrieval algorithm can provide an \{LST\} dataset with reasonable accuracy and a high spatial resolution under clear and cloudy conditions. "} 
}
@article{Vrieling201719,
title = {"Spatially detailed retrievals of spring phenology from single-season high-resolution image time series "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"59"},
number = {""},
pages = {"19 - 30"},
year = {"2017"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2017.02.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243417300478"},
author = {"Anton Vrieling and Andrew K. Skidmore and Tiejun Wang and Michele Meroni and Bruno J. Ens and Kees Oosterbeek and Brian O’Connor and Roshanak Darvishzadeh and Marco Heurich and Anita Shepherd and Marc Paganini"},
keywords = {"Phenology", "Multi-temporal analysis", "NDVI time series", "Multi-source imagery", "Spatial resolution", "Landscape variability", "Saltmarsh", "Agriculture "},
abstract = {"Abstract Vegetation indices derived from satellite image time series have been extensively used to estimate the timing of phenological events like season onset. Medium spatial resolution (≥250 m) satellite sensors with daily revisit capability are typically employed for this purpose. In recent years, phenology is being retrieved at higher resolution (≤30 m) in response to increasing availability of high-resolution satellite data. To overcome the reduced acquisition frequency of such data, previous attempts involved fusion between high- and medium-resolution data, or combinations of multi-year acquisitions in a single phenological reconstruction. The objectives of this study are to demonstrate that phenological parameters can now be retrieved from single-season high-resolution time series, and to compare these retrievals against those derived from multi-year high-resolution and single-season medium-resolution satellite data. The study focuses on the island of Schiermonnikoog, the Netherlands, which comprises a highly-dynamic saltmarsh, dune vegetation, and agricultural land. Combining \{NDVI\} series derived from atmospherically-corrected images from RapidEye (5 m-resolution) and the \{SPOT5\} Take5 experiment (10m-resolution) acquired between March and August 2015, phenological parameters were estimated using a function fitting approach. We then compared results with phenology retrieved from four years of 30 m Landsat 8 \{OLI\} data, and single-year 100 m Proba-V and 250 m \{MODIS\} temporal composites of the same period. Retrieved phenological parameters from combined RapidEye/SPOT5 displayed spatially consistent results and a large spatial variability, providing complementary information to existing vegetation community maps. Retrievals that combined four years of Landsat observations into a single synthetic year were affected by the inclusion of years with warmer spring temperatures, whereas adjustment of the average phenology to 2015 observations was only feasible for a few pixels due to cloud cover around phenological transition dates. The Proba-V and \{MODIS\} phenology retrievals scaled poorly relative to their high-resolution equivalents, indicating that medium-resolution phenology retrievals need to be interpreted with care, particularly in landscapes with fine-scale land cover variability. "} 
}
@article{Wang2016691,
title = {"Adaptive multi-view feature selection for human motion retrieval "},
journal = {"Signal Processing "},
volume = {"120"},
number = {""},
pages = {"691 - 701"},
year = {"2016"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.11.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414005520"},
author = {"Zhao Wang and Yinfu Feng and Tian Qi and Xiaosong Yang and Jian J. Zhang"},
keywords = {"Human motion retrieval", "Feature selection", "Multi-view learning", "Trace ratio minimization problem "},
abstract = {"Abstract Human motion retrieval plays an important role in many motion data based applications. In the past, many researchers tended to use a single type of visual feature as data representation. Because different visual feature describes different aspects about motion data, and they have dissimilar discriminative power with respect to one particular class of human motion, it led to poor retrieval performance. Thus, it would be beneficial to combine multiple visual features together for motion data representation. In this article, we present an Adaptive Multi-view Feature Selection (AMFS) method for human motion retrieval. Specifically, we first use a local linear regression model to automatically learn multiple view-based Laplacian graphs for preserving the local geometric structure of motion data. Then, these graphs are combined together with a non-negative view-weight vector to exploit the complementary information between different features. Finally, in order to discard the redundant and irrelevant feature components from the original high-dimensional feature representation, we formulate the objective function of \{AMFS\} as a general trace ratio optimization problem, and design an effective algorithm to solve the corresponding optimization problem. Extensive experiments on two public human motion database, i.e., \{HDM05\} and \{MSR\} Action3D, demonstrate the effectiveness of the proposed \{AMFS\} over the state-of-art methods for motion data retrieval. The scalability with large motion dataset, and insensitivity with the algorithm parameters, make our method can be widely used in real-world applications. "} 
}
@article{Allani20161428,
title = {"A Knowledge-based Image Retrieval System Integrating Semantic and Visual Features "},
journal = {"Procedia Computer Science "},
volume = {"96"},
number = {""},
pages = {"1428 - 1436"},
year = {"2016"},
note = {"Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 20th International Conference KES-2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.08.188"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916319986"},
author = {"Olfa Allani and Hajer Baazaoui Zghal and Nedra Mellouli and Herman Akdag"},
keywords = {"image retrieval", "region", "ontology module "},
abstract = {"Abstract The main limitations of the existing high level image retrieval approaches concern the high dependance on an external reliable resource (domain ontologies, learning sets, etc.) and a model for mapping semantic and visual information. In this paper, we propose an image retrieval system integrating semantic and visual features. The idea is to automatically build a modular ontology for semantic information and organize visual features in a graph-based model. Both elements are then combined together in a same component called “pattern” used for retrieval. The system has been implemented and the obtained results show that our proposal enables an improvement in the retrieval task. "} 
}
@article{Kumar201637,
title = {"Adapting content-based image retrieval techniques for the semantic annotation of medical images "},
journal = {"Computerized Medical Imaging and Graphics "},
volume = {"49"},
number = {""},
pages = {"37 - 45"},
year = {"2016"},
note = {""},
issn = {"0895-6111"},
doi = {"https://doi.org/10.1016/j.compmedimag.2016.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895611116300015"},
author = {"Ashnil Kumar and Shane Dyer and Jinman Kim and Changyang Li and Philip H.W. Leong and Michael Fulham and Dagan Feng"},
keywords = {"Image annotation", "Content-based image retrieval", "Computed tomography", "Liver", "ImageCLEF "},
abstract = {"Abstract The automatic annotation of medical images is a prerequisite for building comprehensive semantic archives that can be used to enhance evidence-based diagnosis, physician education, and biomedical research. Annotation also has important applications in the automatic generation of structured radiology reports. Much of the prior research work has focused on annotating images with properties such as the modality of the image, or the biological system or body region being imaged. However, many challenges remain for the annotation of high-level semantic content in medical images (e.g., presence of calcification, vessel obstruction, etc.) due to the difficulty in discovering relationships and associations between low-level image features and high-level semantic concepts. This difficulty is further compounded by the lack of labelled training data. In this paper, we present a method for the automatic semantic annotation of medical images that leverages techniques from content-based image retrieval (CBIR). \{CBIR\} is a well-established image search technology that uses quantifiable low-level image features to represent the high-level semantic content depicted in those images. Our method extends \{CBIR\} techniques to identify or retrieve a collection of labelled images that have similar low-level features and then uses this collection to determine the best high-level semantic annotations. We demonstrate our annotation method using retrieval via weighted nearest-neighbour retrieval and multi-class classification to show that our approach is viable regardless of the underlying retrieval strategy. We experimentally compared our method with several well-established baseline techniques (classification and regression) and showed that our method achieved the highest accuracy in the annotation of liver computed tomography (CT) images. "} 
}
@article{Kolassa20161,
title = {"Soil moisture retrieval from AMSR-E and \{ASCAT\} microwave observation synergy. Part 1: Satellite data analysis "},
journal = {"Remote Sensing of Environment "},
volume = {"173"},
number = {""},
pages = {"1 - 14"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.11.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715302005"},
author = {"J. Kolassa and P. Gentine and C. Prigent and F. Aires"},
keywords = {"Satellite retrieval", "Soil moisture", "Surface hydrology", "Active/passive microwave", "Sensor synergy "},
abstract = {"Abstract A study is performed to analyze the daily retrieval of soil moisture from the synergy of active and passive microwave data using observations from the \{ASCAT\} scatterometer and AMSR-E radiometer. The objective is to identify the information provided by each sensor and to analyze preprocessing methods – such as the day/night average, diurnal difference and microwave polarization difference index for AMSR-E and the incidence angle normalization and backscatter temporal index for \{ASCAT\} – to maximize the amount of soil moisture information extracted. Additionally, the data fusion and a posteriori synergy methodologies are compared to determine how to optimally exploit this combined information. This study is performed using a neural network (NN) to estimate soil moisture from a set of AMSR-E and \{ASCAT\} observations. ERA-interim/Land surface soil moisture fields are used to train the \{NN\} as well as to evaluate the performance of the different retrieval input datasets. It is shown that using the AMSR-E 7 GHz, 11 GHz, 19 \{GHz\} and 37 \{GHz\} channels with the three preprocessing methods highlights various surface contributions in the signal, in particular the soil moisture and surface temperature information, and greatly helps the retrieval in disentangling them. For ASCAT, the synergy effect is less significant and data preprocessed with the two methods analyzed yields very similar information. The information provided by the active and passive microwave sensors is found to be very complementary, such that a soil moisture retrieval using the combined active and passive information shows a significant improvement between 5% and 19% in the temporal correlation and a reduction of the retrieval uncertainty by 7%. The improvement in the spatial structure is smaller with a correlation increase of 2%. It is demonstrated that the choice of synergy method strongly impacts the retrieval improvement that can be achieved. Data fusion methods are shown to be better suited than a posteriori combination methods, due to their ability to exploit information complementarity. These results could help improve future active/passive soil moisture retrievals, such as from the Soil Moisture Active/Passive (SMAP) mission, through the application of similar preprocessing and synergy methods in order to better extract the soil moisture information provided. "} 
}
@article{Charles2016225,
title = {"A novel local mesh color texture pattern for image retrieval system "},
journal = {"\{AEU\} - International Journal of Electronics and Communications "},
volume = {"70"},
number = {"3"},
pages = {"225 - 233"},
year = {"2016"},
note = {""},
issn = {"1434-8411"},
doi = {"https://doi.org/10.1016/j.aeue.2015.11.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S1434841115003349"},
author = {"Yesubai Rubavathi Charles and Ravi Ramraj"},
keywords = {"Local mesh color texture pattern", "Image retrieval system", "Opponent color channel", "Local binary pattern", "I1QCb color space "},
abstract = {"Abstract This manuscript contributes a new feature descriptor local mesh color texture pattern (LMCTP) by merging color and local spatial information for image retrieval system. The intended method combines the various features from a mixture of color spaces, the local mesh patterns of the input image. \{LMCTP\} descriptor discriminates information between the spatial color textural patterns of multi-spectral channels within the local region. It determines the relationship between surrounding neighbors of the opponent color channel. Beside this, a merged color space, I1QCb, is constructed by combining the \{I1\} part of the \{I1I2I3\} color space and the chromatic component images, Cb and Q, of the \{YCbCr\} and \{YIQ\} color spaces correspondingly so as to exploit the effect of joint color texture feature. The \{I1QCb\} color space, whose component of images having matching characteristics, increases the distinctive power for retrieval system. Then opponent color spaces I1Q, \{QCb\} and \{I1Cb\} are utilized for the capturing of \{LMCTP\} features. The feasibility of the proposed framework is experiments on benchmark databases such as \{MIT\} VisTex database (DB1), Corel 1000 database (DB2). Experimental study shows that the proposed pattern gives average retrieval precision of 99.8 for \{DB1\} and 76.5 for DB2, respectively. "} 
}
@article{Sarafis2016150,
title = {"Online training of concept detectors for image retrieval using streaming clickthrough data "},
journal = {"Engineering Applications of Artificial Intelligence "},
volume = {"51"},
number = {""},
pages = {"150 - 162"},
year = {"2016"},
note = {"Mining the Humanities: Technologies and Applications "},
issn = {"0952-1976"},
doi = {"https://doi.org/10.1016/j.engappai.2016.01.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S095219761600021X"},
author = {"Ioannis Sarafis and Christos Diou and Anastasios Delopoulos"},
keywords = {"Clickthrough data", "Online learning", "Image retrieval", "Label noise", "Fuzzy SVM", "LASVM "},
abstract = {"Abstract Clickthrough data from image search engines provide a massive and continuously generated source of user feedback that can be used to model how the search engine users perceive the visual content. Image clickthrough data have been successfully used to build concept detectors without any manual annotation effort, although the generated annotations suffer from labeling errors. Previous research efforts therefore focused on modeling the sample uncertainty in order to improve concept detector effectiveness. In this paper, we study the problem in an online learning setting using streaming clickthrough data where each click is treated seperately when it becomes available; the concept detector model is therefore continuously updated without batch retraining. We argue that sample uncertainty can be incorporated in the online learning setting by exploiting the repetitions of incoming clicks at the classifier level, where these act as an implicit importance weighting mechanism. For online concept detector training we use the \{LASVM\} algorithm. The inferred weighting approximates the solution of batch trained concept detectors using weighted \{SVM\} variants that are known to achieve improved performance and high robustness to noise compared to the standard SVM. Furthermore, we evaluate methods for selecting negative samples using a small number of candidates sampled locally from the incoming stream of clicks. The selection criteria aim at drastically improving the performance and the convergence speed of the online concept detectors. To validate our arguments we conduct experiments for 30 concepts on the Clickture-Lite dataset. The experimental results demonstrate that: (a) the proposed online approach produces effective and noise resilient concept detectors that can take advantage of streaming clickthrough data and achieve performance that is equivalent to Fuzzy \{SVM\} concept detectors with sample weights and 78.6% improved compared to standard \{SVM\} concept detectors; and (b) the selection criteria speed up convergence and improve effectiveness compared to random negative sampling even for a small number of available clicks (up to 134% after 100 clicks). "} 
}
@article{Bala2016101,
title = {"Local texton \{XOR\} patterns: A new feature descriptor for content-based image retrieval "},
journal = {"Engineering Science and Technology, an International Journal "},
volume = {"19"},
number = {"1"},
pages = {"101 - 112"},
year = {"2016"},
note = {""},
issn = {"2215-0986"},
doi = {"https://doi.org/10.1016/j.jestch.2015.06.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S221509861500110X"},
author = {"Anu Bala and Tajinder Kaur"},
keywords = {"Texton", "Local \{XOR\} patterns", "Local binary patterns", "Histogram", "Texture", "Image retrieval "},
abstract = {"Abstract In this paper, a novel feature descriptor, local texton \{XOR\} patterns (LTxXORP) is proposed for content-based image retrieval. The proposed method collects the texton \{XOR\} pattern which gives the structure of the query image or database image. First, the \{RGB\} (red, green, blue) color image is converted into \{HSV\} (hue, saturation and value) color space. Second, the V color space is divided into overlapping subblocks of size 2 × 2 and textons are collected based on the shape of the textons. Then, exclusive \{OR\} (XOR) operation is performed on the texton image between the center pixel and its surrounding neighbors. Finally, the feature vector is constructed based on the \{LTxXORPs\} and \{HSV\} histograms. The performance of the proposed method is evaluated by testing on benchmark database, Corel-1K, Corel-5K and Corel-10K in terms of precision, recall, average retrieval precision (ARP) and average retrieval rate (ARR). The results after investigation show a significant improvement as compared to the state-of-the-art features for image retrieval. "} 
}
@article{Fang201611,
title = {"An agility-oriented and fuzziness-embedded semantic model for collaborative cloud service search, retrieval and recommendation "},
journal = {"Future Generation Computer Systems "},
volume = {"56"},
number = {""},
pages = {"11 - 26"},
year = {"2016"},
note = {""},
issn = {"0167-739X"},
doi = {"https://doi.org/10.1016/j.future.2015.09.025"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167739X15003052"},
author = {"Daren Fang and Xiaodong Liu and Imed Romdhani and Pooyan Jamshidi and Claus Pahl"},
keywords = {"Cloud computing", "Service agility", "Semantic model", "Service discovery", "Ontology evolution", "Knowledge retrieval "},
abstract = {"Abstract Cloud computing enables a revolutionary paradigm of consuming \{ICT\} services. However, due to the inadequately described service information, users often feel confused while trying to find the optimal services. Although some approaches are proposed to deal with cloud service retrieval and recommendation issues, they would only work for certain restricted scenarios in dealing with basic service specifications. Indeed, the missing extent is that most of the cloud services are “agile” whilst there are many vague service terms and descriptions. This paper proposes an agility-oriented and fuzziness-embedded cloud service ontology model, which adopts agility-centric design along with \{OWL2\} (Web Ontology Language) fuzzy extensions. The captured cloud service specifications are maintained in an open and collaborative manner, as the fuzziness in the model accepts rating updates from users on the fly. The model enables comprehensive service specification by capturing cloud concept details and their interactions, even across multiple service categories and abstraction levels. Utilizing the model as a knowledge base, a service recommendation system prototype is developed. Case studies demonstrate that the approach can outperform existing practices by achieving effective service search, retrieval and recommendation outcomes. "} 
}
@article{Uzer2016144,
title = {"Retrieving autobiographical memories: How different retrieval strategies associated with different cues explain reaction time differences "},
journal = {"Acta Psychologica "},
volume = {"164"},
number = {""},
pages = {"144 - 150"},
year = {"2016"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2016.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S000169181630004X"},
author = {"Tugba Uzer"},
keywords = {"Generative retrieval", "Emotion", "Autobiographical memory "},
abstract = {"Abstract Previous research has shown that memories cued by concrete concepts, such as objects, are retrieved faster than those cued by more abstract concepts, such as emotions. This effect has been explained by the fact that more memories are directly retrieved from object versus emotion cues. In the present study, we tested whether \{RT\} differences between memories cued by emotion versus object terms occur not only because object cues elicit direct retrieval of more memories (Uzer, Lee, &amp; Brown, 2012), but also because of differences in memory generation in response to emotions versus objects. One hundred university students retrieved memories in response to basic-level (e.g. orange), superordinate-level (e.g. plant), and emotion (e.g. surprised) cues. Retrieval speed was measured and participants reported whether memories were directly retrieved or generated on each trial. Results showed that memories were retrieved faster in response to basic-level versus superordinate-level and emotion cues because a) basic-level cues elicited more directly retrieved memories, and b) generating memories was more difficult when cues were abstract versus concrete. These results suggest that generative retrieval is a cue generation process in which additional cues that provide contextual information including the target event are produced. Memories are retrieved more slowly in response to emotion cues in part because emotion labels are less effective cues of appropriate contextual information. This particular finding is inconsistent with the idea that emotion is a primary organizational unit for autobiographical memories. In contrast, the difficulty of emotional memory generation implies that emotions represent low-level event information in the organization of autobiographical memory. "} 
}
@article{Xiao2016702,
title = {"Fast view-based 3D model retrieval via unsupervised multiple feature fusion and online projection learning "},
journal = {"Signal Processing "},
volume = {"120"},
number = {""},
pages = {"702 - 713"},
year = {"2016"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.11.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414005593"},
author = {"Jun Xiao and Yinfu Feng and Mingming Ji and Yueting Zhuang"},
keywords = {"View-based 3D model retrieval", "Multiple feature fusion", "Online projection learning", "Out-of-sample "},
abstract = {"Abstract Since each visual feature only reflects a unique characteristic about a 3-dimensional (3D) model and different visual features have diverse discriminative power in model representation, it would be beneficial to fuse multiple visual features in 3D model retrieval. To this end, we propose a fast view-based 3D model retrieval framework in this article. This framework comprises two parts: the first one is an Unsupervised Multiple Feature Fusion algorithm (UMFF), which is used to learn a compact yet discriminative feature representation from the original multiple visual features; and the second one is an efficient Online Projection Learning algorithm (OPL), which is designed to fast transfer the input multiple visual features of a newcome model into its corresponding low-dimensional feature representation. In this framework, many existing ranking algorithms such as the simple distance-based ranking method can be directly adopted for sorting all 3D models in the database using the learned new feature representation and returning the top ranked models to the user. Extensive experiments on two public 3D model databases demonstrate the efficiency and the effectiveness of the proposed approach over its competitors. The proposed framework cannot only dramatically improve the retrieval performance but also reduce the computational cost in dealing with the newcome models. "} 
}
@article{Li20168,
title = {"Multiscale shape context and re-ranking for deformable shape retrieval "},
journal = {"Computers & Graphics "},
volume = {"54"},
number = {""},
pages = {"8 - 17"},
year = {"2016"},
note = {"Special Issue on CAD/Graphics 2015 "},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2015.07.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849315001053"},
author = {"Zongmin Li and Zhenzhong Kuang and Yujie Liu and Jiayan Wang"},
keywords = {"3D shape retrieval", "Multiscale shape context", "Local descriptor", "BOW", "Re-ranking "},
abstract = {"Abstract This paper proposes a distinct multiscale shape context (MSC) method for isometric 3D shape description and retrieval. For each feature point, a \{MSC\} descriptor is devised to capture the multiple spatial information on the basis of the intrinsic shape context, which is advantageous in solving the domain offset deficiency for intra-class shapes. Different from the traditional shape context method, the \{MSC\} descriptor is built based on the charts without angular bins and the shape distributions in local domains, which makes it not only simple but also efficient. To reduce the cost of shape representation, we detect a sparse set of feature points and design an improved bags-of-word model to encode the \{MSC\} descriptors. For retrieval improvement, an efficient while robust re-ranking algorithm by metric mapping is designed to alleviate the errors of the feature space. Finally, the experimental results have demonstrated significant performance gains on two public benchmarks. "} 
}
@article{Kwon2017386,
title = {"Hierarchically linked infinite hidden Markov model based trajectory analysis and semantic region retrieval in a trajectory dataset "},
journal = {"Expert Systems with Applications "},
volume = {"78"},
number = {""},
pages = {"386 - 395"},
year = {"2017"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2017.02.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417417301082"},
author = {"Yongjin Kwon and Kyuchang Kang and Junho Jin and Jinyoung Moon and Jongyoul Park"},
keywords = {"Trajectory analysis", "Semantic regions", "Nonparametric Bayesian models", "Infinite hidden Markov models", "Sticky extensions "},
abstract = {"Abstract With an increasing attempt of finding latent semantics in a video dataset, trajectories have become key components since they intrinsically include concise characteristics of object movements. An approach to analyze a trajectory dataset has concentrated on semantic region retrieval, which extracts some regions in which have their own patterns of object movements. Semantic region retrieval has become an important topic since the semantic regions are useful for various applications, such as activity analysis. The previous literatures, however, have just revealed semantically relevant points, rather than actual regions, and have less consideration of temporal dependency of observations in a trajectory. In this paper, we propose a novel model for trajectory analysis and semantic region retrieval. We first extend the meaning of semantic regions that can cover actual regions. We build a model for the extended semantic regions based on a hierarchically linked infinite hidden Markov model, which can capture the temporal dependency between adjacent observations, and retrieve the semantic regions from a trajectory dataset. In addition, we propose a sticky extension to diminish redundant semantic regions that occur in a non-sticky model. The experimental results demonstrate that our models well extract semantic regions from a real trajectory dataset. "} 
}
@article{Mizusaki2017279,
title = {"Learning and retrieval behavior in recurrent neural networks with pre-synaptic dependent homeostatic plasticity "},
journal = {"Physica A: Statistical Mechanics and its Applications "},
volume = {"479"},
number = {""},
pages = {"279 - 286"},
year = {"2017"},
note = {""},
issn = {"0378-4371"},
doi = {"https://doi.org/10.1016/j.physa.2017.02.035"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378437117301759"},
author = {"Beatriz E.P. Mizusaki and Everton J. Agnes and Rubem Erichsen Jr. and Leonardo G. Brunnet"},
keywords = {"Synaptic plasticity", "Spike pattern", "Spike timing", "Recurrent network", "Homeostatic plasticity "},
abstract = {"Abstract The plastic character of brain synapses is considered to be one of the foundations for the formation of memories. There are numerous kinds of such phenomenon currently described in the literature, but their role in the development of information pathways in neural networks with recurrent architectures is still not completely clear. In this paper we study the role of an activity-based process, called pre-synaptic dependent homeostatic scaling, in the organization of networks that yield precise-timed spiking patterns. It encodes spatio-temporal information in the synaptic weights as it associates a learned input with a specific response. We introduce a correlation measure to evaluate the precision of the spiking patterns and explore the effects of different inhibitory interactions and learning parameters. We find that large learning periods are important in order to improve the network learning capacity and discuss this ability in the presence of distinct inhibitory currents. "} 
}
@article{Feng2016225,
title = {"A software system for automated identification and retrieval of moth images based on wing attributes "},
journal = {"Pattern Recognition "},
volume = {"51"},
number = {""},
pages = {"225 - 241"},
year = {"2016"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2015.09.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S003132031500343X"},
author = {"Linan Feng and Bir Bhanu and John Heraty"},
keywords = {"Entomological image identification and retrieval", "Semantically related visual attributes", "Attribute co-occurrence pattern detection "},
abstract = {"Abstract Manually collecting, identifying, archiving and retrieving specimen images is an expensive and time-consuming work for entomologists. There is a clear need to introduce fast systems integrated with modern image processing and analysis algorithms to accelerate the process. In this paper, we describe the development of an automated moth species identification and retrieval system (SPIR) using computer vision and pattern recognition techniques. The core of the system is a probabilistic model that infers Semantically Related Visual (SRV) attributes from low-level visual features of moth images in the training set, where moth wings are segmented into information-rich patches from which the local features are extracted, and the \{SRV\} attributes are provided by human experts as ground-truth. For the large amount of unlabeled test images in the database or added into the database later on, an automated identification process is evoked to translate the detected salient regions of low-level visual features on the moth wings into meaningful semantic \{SRV\} attributes. We further propose a novel network analysis based approach to explore and utilize the co-occurrence patterns of \{SRV\} attributes as contextual cues to improve individual attribute detection accuracy. Working with a small set of labeled training images, the approach constructs a network with nodes representing the \{SRV\} attributes and weighted edges denoting the co-occurrence correlation. A fast modularity maximization algorithm is proposed to detect the co-occurrence patterns as communities in the network. A random walk process working on the discovered co-occurrence patterns is applied to refine the individual attribute detection results. The effectiveness of the proposed approach is evaluated in automated moth identification and attribute-based image retrieval. In addition, a novel image descriptor called \{SRV\} attribute signature is introduced to record the visual and semantic properties of an image and is used to compare image similarity. Experiments are performed on an existing entomology database to illustrate the capabilities of our proposed system. We observed that the system performance is improved by the \{SRV\} attribute representation and their co-occurrence patterns. "} 
}
@article{Rajendran2015179,
title = {"MOSS-IR: Multi-Ontology Based Search System for Information Retrieval in E-health Domain "},
journal = {"Procedia Computer Science "},
volume = {"47"},
number = {""},
pages = {"179 - 187"},
year = {"2015"},
note = {"Graph Algorithms, High Performance Implementations and Its Applications ( \{ICGHIA\} 2014 ) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.03.196"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915004640"},
author = {"V. Viji Rajendran and S. Swamynathan"},
keywords = {"Ontology", "Semantic Web", "Query expansion", "Reasoning. "},
abstract = {"Abstract With the development of the Semantic Web, ontology has become the crucial means for representing concepts in various domains of interest. Although the current search engines return results based on keyword search and page ranking, human intervention is still required to select the most relevant document. Hence to overcome the disadvantages with the current search scenario, this paper proposes search based on multiple ontologies to make information retrieval efficient. It rewrites the user query by adding semantic information, after consulting multiple ontologies. "} 
}
@article{Du2016354,
title = {"Online soil moisture retrieval and sharing using geospatial web-enabled BDS-R service "},
journal = {"Computers and Electronics in Agriculture "},
volume = {"121"},
number = {""},
pages = {"354 - 367"},
year = {"2016"},
note = {""},
issn = {"0168-1699"},
doi = {"https://doi.org/10.1016/j.compag.2016.01.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0168169916000107"},
author = {"Wenying Du and Nengcheng Chen and Songhua Yan"},
keywords = {"Beidou signal", "Soil moisture", "Online retrieval", "Sharing", "Sensor web "},
abstract = {"Abstract Global navigation satellite system-reflectometry (GNSS-R) signals have recently being used in the monitoring of soil moisture (SM) due to their high availability and widespread existence. GNSS-R signal-based online \{SM\} retrieval and real-time product sharing has advantages over other methods because it features the instant and automatic retrieval of SM, and low-latency \{SM\} product publishing and sharing, enabling a notable decrease in human and material resource consumption and a timely \{SM\} product delivery; however, prior to this manuscript, there has not been a study describing how to do it. This paper uses one type of GNSS-R signals, the Beidou navigation satellite system-reflectometry (BDS-R) signal, as the data source and proposes a geospatial web-enabled BDS-R (GWEB) service. This method tackles the problems of \{SM\} retrieval and sharing by implementing the original BDS-R signal publishing, the online \{SM\} retrieval, and the \{SM\} product sharing. In the \{GWEB\} service, a web processing service is adopted to encapsulate the \{SM\} retrieval algorithm, and a sensor observation service is applied to publish the original BDS-R observations and the \{SM\} products. Signals of the Baoxie BDS-R \{SM\} monitoring station in Wuhan, China for the period of November 17, 2014 to November 24, 2014 are used as input in the validation experiment, and the \{SM\} products are demonstrated in the sharing platform. Meanwhile, the BDS-R derived \{SM\} products are compared with the corresponding \{SM\} values measured by ground soil hygrometers, indicating the feasibility of the service for online \{SM\} retrieval and sharing. "} 
}
@article{Wang2016272,
title = {"High speed moire based phase retrieval method for quantitative phase imaging of thin objects without phase unwrapping or aberration compensation "},
journal = {"Optics Communications "},
volume = {"359"},
number = {""},
pages = {"272 - 278"},
year = {"2016"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2015.09.100"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401815301796"},
author = {"Shouyu Wang and Keding Yan and Liang Xue"},
keywords = {"Phase retrieval", "Quantitative interferometric microscopy", "Phase distribution measurements "},
abstract = {"Abstract Phase retrieval composed of phase extracting and unwrapping is of great significance in different occasions, such as fringe projection based profilometry, quantitative interferometric microscopy and moire detections. Compared to phase extracting, phase unwrapping occupies most time consuming in phase retrieval, and it becomes an obstacle to realize real time measurements. In order to increase the calculation efficiency of phase retrieval as well as simplify its procedures, here, a high speed moire based phase retrieval method is proposed which is capable of calculating quantitative phase distributions without phase unwrapping or aberration compensation. We demonstrate the capability of the presented phase retrieval method by both theoretical analysis and experiments. It is believed that the proposed method will be useful in real time phase observations and measurements. "} 
}
@article{Hussain2016571,
title = {"Robust Pre-processing Technique Based on Saliency Detection for Content Based Image Retrieval Systems "},
journal = {"Procedia Computer Science "},
volume = {"85"},
number = {""},
pages = {"571 - 580"},
year = {"2016"},
note = {"International Conference on Computational Modelling and Security (CMS 2016) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.05.223"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916305713"},
author = {"Chesti Altaff Hussain and D.Venkata Rao and S.Aruna Masthani"},
keywords = {"Visual Saliency", "Perceptual quality", "Segmentation", "Content based image retrieval", "Scale Invariant transform", "Quaternion transform. "},
abstract = {"Abstract The perceptual quality which attracts viewer attention by making the objects differ from its neighbours is said to be Visual saliency. They concentrate on the region of interest. The paper aims at improving the performance of content based image retrieval using saliency detection approach. Several methods have been developed to extract the saliency information from an image. We use the state of the art Quaternion transform for to detect the saliency. The paper focuses on the content based image retrieval systems based on scale invariant feature transform and region segmentation. Experimental results prove that the proposed technique outperforms the existing techniques and produce better retrieval results. "} 
}
@article{Huang2016590,
title = {"Three-dimensional \{CAD\} Model Retrieval Algorithm Based on Ontology "},
journal = {"Procedia \{CIRP\} "},
volume = {"56"},
number = {""},
pages = {"590 - 593"},
year = {"2016"},
note = {"The 9th International Conference on Digital Enterprise Technology – Intelligent Manufacturing in the Knowledge Economy Era "},
issn = {"2212-8271"},
doi = {"https://doi.org/10.1016/j.procir.2016.10.116"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212827116311088"},
author = {"Mingcong Huang and Shaocun Sui and Wenping Mou and Shusheng Zhang and Wenjun Cao"},
keywords = {"\{CAD\} model retrieval", "reuse", "semantic ontology", "MBD "},
abstract = {"Abstract For resolving problems such as how the user implement three-dimensional \{CAD\} model retrievals and how to reuse the retrieval results during the smart process planning, this paper present an ontology-based algorithm for three-dimensional \{CAD\} model retrieval. The \{CAD\} model is segmented into several relevant sub-parts. Then, attach semantic descriptions and annotations to these sub-parts. Finally, evaluate the similarity of the models based on the semantic ontology 3D \{CAD\} model. The experimental results show the efficiency of this method to meet the requirements of engineering retrieval and reuse of design and manufacture. "} 
}
@article{Nagarajan2015101,
title = {"Fuzzy Ontology Based Multi-Modal Semantic Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"48"},
number = {""},
pages = {"101 - 106"},
year = {"2015"},
note = {"International Conference on Computer, Communication and Convergence (ICCC 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.157"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915006663"},
author = {"G. Nagarajan and R.I. Minu"},
keywords = {"Ontology", "Knowledge representation", "Semantic Analysis", "OWL", "Machine Learning", "Computer Vision "},
abstract = {"Abstract Lack of today's technology of information retrieval system is the semantic between the information resources. The semantic can be expressed for a resource using the underlying technology of ontology. So the main objective of this paper is to design an information retrieval system for both text and image data using the concept of ontology. The main focus of this paper is to improve information retrieval for sports events using Ontologies. As it is complex problem, it is addressed into the following sub-problems in this paper. (1) Integrating domain knowledge and images using fuzzy ontology and Retrieving the required Muti-modal information using fuzzy rule set. (2) Providing image semantic by constructing visual codebook for affine covariant-Semantic segmented patches. (3) Analysing the discriminative power of each visual word using the probabilistic latent semantic and quantizing them using the Chi-Square test. In this work, the domain of Sports is considered for creating both Low-level visual ontology for certain sport event images and also for building a high-level domain ontology from the information on web. These two Ontologies are integrated using Fuzzy concepts. "} 
}
@article{Rupprecht201697,
title = {"Retrieval-induced forgetting in item recognition: Retrieval specificity revisited "},
journal = {"Journal of Memory and Language "},
volume = {"86"},
number = {""},
pages = {"97 - 118"},
year = {"2016"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2015.09.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X1500114X"},
author = {"Julia Rupprecht and Karl-Heinz T. Bäuml"},
keywords = {"Episodic memory", "Retrieval-induced forgetting", "Inhibition", "Blocking", "Recognition "},
abstract = {"Abstract Retrieval-induced forgetting (RIF) refers to the finding that retrieval practice on a subset of studied items can induce later forgetting of related unpracticed items. Although previous studies indicated that \{RIF\} is retrieval specific – i.e., it arises after retrieval practice but not after reexposure cycles -, the results of more recent work suggest otherwise, indicating that some reexposure formats can induce \{RIF\} very similar to how retrieval practice does. Whereas this prior work employed recall at test, here we revisited retrieval specificity of \{RIF\} employing item recognition. The results of three experiments are reported, which examined the effects of retrieval practice and some of the recently suggested reexposure formats on unpracticed items’ recognition. In each of these experiments, we showed \{RIF\} after retrieval practice but did not find any evidence for RIF-like forgetting after reexposure. These findings demonstrate retrieval specificity of \{RIF\} in item recognition, challenging strength-based accounts of \{RIF\} and indicating a critical role of inhibition in RIF. Together with the results from the recent recall studies, which we replicated in three further experiments, the present findings are consistent with a two-factor account of RIF, which assigns a role for both inhibition and strength-based blocking in RIF. While both inhibition and blocking may contribute to \{RIF\} in certain recall formats, only inhibition may induce \{RIF\} in item recognition. "} 
}
@article{Zhang201675,
title = {"Dictionary pruning with visual word significance for medical image retrieval "},
journal = {"Neurocomputing "},
volume = {"177"},
number = {""},
pages = {"75 - 88"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215016616"},
author = {"Fan Zhang and Yang Song and Weidong Cai and Alexander G. Hauptmann and Sidong Liu and Sonia Pujol and Ron Kikinis and Michael J. Fulham and David Dagan Feng and Mei Chen"},
keywords = {"Medical image retrieval", "BoVW", "Dictionary pruning "},
abstract = {"Abstract Content-based medical image retrieval (CBMIR) is an active research area for disease diagnosis and treatment but it can be problematic given the small visual variations between anatomical structures. We propose a retrieval method based on a bag-of-visual-words (BoVW) to identify discriminative characteristics between different medical images with Pruned Dictionary based on Latent Semantic Topic description. We refer to this as the PD-LST retrieval. Our method has two main components. First, we calculate a topic-word significance value for each visual word given a certain latent topic to evaluate how the word is connected to this latent topic. The latent topics are learnt, based on the relationship between the images and words, and are employed to bridge the gap between low-level visual features and high-level semantics. These latent topics describe the images and words semantically and can thus facilitate more meaningful comparisons between the words. Second, we compute an overall-word significance value to evaluate the significance of a visual word within the entire dictionary. We designed an iterative ranking method to measure overall-word significance by considering the relationship between all latent topics and words. The words with higher values are considered meaningful with more significant discriminative power in differentiating medical images. We evaluated our method on two public medical imaging datasets and it showed improved retrieval accuracy and efficiency. "} 
}
@incollection{MuñozSabater2016351,
title = {"Chapter 18 - Soil Moisture Retrievals Based on Active and Passive Microwave Data: State-of-the-Art and Operational Applications "},
editor = {"Srivastava, Prashant K. and Petropoulos, George P.  and Kerr, Yann H. "},
booktitle = {"Satellite Soil Moisture Retrieval "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2016"},
pages = {"351 - 378"},
isbn = {"978-0-12-803388-3"},
doi = {"https://doi.org/10.1016/B978-0-12-803388-3.00018-8"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128033883000188"},
author = {"J. Muñoz-Sabater and A. Al Bitar and L. Brocca"},
keywords = {"soil moisture", "microwave active data", "microwave passive data", "retrievals", "operational "},
abstract = {"Abstract This chapter provides a description of current operational applications using state-of-the-art soil moisture retrievals from active and passive remote sensing data. Both types of observations have demonstrated to contain useful information of shallow land variables. In particular, this chapter focuses on how soil moisture retrievals are used at the operational level to derive flood, drought, and landslides warnings, as well as its use in coupled land-atmospheric models. An overview of the caveats in the production and applications of the retrievals is also provided. The chapter ends by providing perspectives of these novel applications. "} 
}
@incollection{Zhang2016237,
title = {"Chapter 8 - Hashing-based large-scale medical image retrieval for computer-aided diagnosis "},
editor = {"Wu, Guorong and Shen, Dinggang  and Sabuncu, Mert R. "},
booktitle = {"Machine Learning and Medical Imaging "},
publisher = {"Academic Press"},
edition = {""},
address = {""},
year = {"2016"},
pages = {"237 - 255"},
isbn = {"978-0-12-804076-8"},
doi = {"https://doi.org/10.1016/B978-0-12-804076-8.00008-6"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128040768000086"},
author = {"X. Zhang and S. Zhang"},
keywords = {"Image retrieval", "Large scale", "Big data", "Medical imaging informatics", "Histopathological images "},
abstract = {"Abstract With the ever-increasing amount of annotated medical data, large-scale, data-driven methods provide the promise of bridging the semantic gap between images and diagnoses. Our goal is to increase the scale at which interactive systems can be effective for knowledge discovery in potentially massive databases of medical images. In particular, we investigate large-scale medical image retrieval techniques, with histopathological images as the use case. In this chapter, we present hashing methods to bridge the semantic gap. With a small amount of supervised information, our method can compress a high-dimensional image feature vector into tens of bits with informative signatures preserved, and these binary codes are indexed into a hash table for real-time retrieval. We validate the hashing-based image retrieval framework on several thousands of images of breast microscopic tissues for both image classification and retrieval. Our framework achieves high search accuracy and promising computational efficiency, comparing favorably with other commonly used methods. "} 
}
@article{Qi2016101,
title = {"Object retrieval with image graph traversal-based re-ranking "},
journal = {"Signal Processing: Image Communication "},
volume = {"41"},
number = {""},
pages = {"101 - 114"},
year = {"2016"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2015.12.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596515002180"},
author = {"Siyuan Qi and Yupin Luo"},
keywords = {"Image graph traversal", "Image attribute", "Object retrieval", "Re-ranking "},
abstract = {"Abstract The topic of this paper is the retrieval of a particular object. A graph traversal-based re-ranking framework for the baseline bag-of-words (BOW) approach is proposed. For an image, we consider not only its similarity with the query image, but also the relationship between other dataset images. We integrate these information as image attributes via an extended image graph and propose a graph traversal algorithm to efficiently obtain their values. By comprehensively considering these attributes, we propose an attribute similarity measure for re-ranking, which brings much performance improvement. We further use our method for the multiple-query retrieval with a simple extension of the virtual query. The experimental results show that our method significantly improve the baseline approach and achieves competitive performance compared with the other state-of-the-art methods. Additionally, our re-ranking method requires only a little extra memory space and time costs. "} 
}
@article{Schalie2016125,
title = {"Global \{SMOS\} Soil Moisture Retrievals from The Land Parameter Retrieval Model "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"45, Part B"},
number = {""},
pages = {"125 - 134"},
year = {"2016"},
note = {"Advances in the Validation and Application of Remotely Sensed Soil Moisture - Part 1 "},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2015.08.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243415300179"},
author = {"R.van der Schalie and Y.H. Kerr and J.P. Wigneron and N.J. Rodríguez-Fernández and A. Al-Yaari and R.A.M.de Jeu"},
keywords = {"Remote sensing", "Passive microwave radiometry", "Soil moisture", "Soil moisture and ocean salinity (SMOS)", "Land Parameter Retrieval Model (LPRM) "},
abstract = {"Abstract A recent study by Van der Schalie et al. (2015) showed good results for applying the Land Parameter Retrieval Model (LPRM) on \{SMOS\} observations over southeast Australia and optimizing and evaluating the retrieved soil moisture (θ in m3 m−3) against ground measurements from the OzNet sites. In this study, the \{LPRM\} parameterization is globally updated for \{SMOS\} against modelled θ from MERRA-Land (MERRA) and ERA-Interim/Land (ERA) over the period of July 2010–December 2010, mainly focusing on two parameters: the single scattering albedo (ω) and the roughness (h). The Pearson's coefficient of correlation (r) increased rapidly when increasing the ω up to 0.12 and reached a steady state from thereon, no significant spatial pattern was found in the estimation of the single scattering albedo, which could be an artifact of the used parameter estimation procedure, and a single value of 0.12 was therefore used globally. The h was defined as a function of θ and varied slightly for the different angle bins, with maximum values of 1.1–1.3 as the angle changes from 42.5° to 57.5°.This resulted in an average r of 0.51 and 0.47, with a bias (m3 m−3) of −0.02 and −0.01 and an unbiased root mean square error (ubrmse in m3 m−3) of 0.054 and 0.056 against \{MERRA\} (ascending and descending). For \{ERA\} this resulted in an r of 0.61 and 0.53, with a bias of −0.03 and an ubrmse 0.055 and 0.059. The resulting parameterization was then used to run \{LPRM\} on \{SMOS\} observations over the period of July 2010–December 2013 and evaluated against \{SMOS\} Level 3 (L3) θ and available in situ measurements from the International Soil Moisture Network (ISMN). The comparison with \{L3\} shows that the \{LPRM\} θ retrievals are very similar, with for the ascending set very high r of over 0.9 in large parts of the globe, with an overall average of 0.85 and the descending set performing less with an average of 0.74, mainly due to the negative r over the Sahara. The mean bias is 0.03, with an ubrmse of 0.038 and 0.044. In this study there are three major areas where the \{LPRM\} retrievals do not perform well: very dry sandy areas, densely forested areas and over high latitudes, which are all known limitations of LPRM. The comparison against in situ measurement from the \{ISMN\} give very similar results, with average r for \{LPRM\} of 0.65 and 0.61 (0.64 and 0.59 for L3) for the ascending and descending sets, while having a comparable bias and ubrmse over the different networks. This shows that \{LPRM\} used on \{SMOS\} observations produce θ retrievals with a similar quality as the \{SMOS\} \{L3\} product. "} 
}
@article{Jeon201629,
title = {"Automatic \{CAD\} model retrieval based on design documents using semantic processing and rule processing "},
journal = {"Computers in Industry "},
volume = {"77"},
number = {""},
pages = {"29 - 47"},
year = {"2016"},
note = {""},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2016.01.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S016636151630001X"},
author = {"Sang Min Jeon and Jae Hyun Lee and Gyeong June Hahm and Hyo Won Suh"},
keywords = {"\{CAD\} model retrieval", "Semantic representation", "Rule processing", "Domain ontology", "Design document", "Reverse-Engineering "},
abstract = {"Abstract Reuse of \{CAD\} model is important for manufacturing companies where similar products are produced. If existing \{CAD\} models have design information related to the design of a new product, their reuse saves costs and reduces time of product design. Since design documents generated in the early design stage contain product specifications and design directions for new product design, they can be used as input queries to retrieve existing \{CAD\} models. In this paper, we propose an approach to retrieving \{CAD\} models with design documents. A major challenge of the proposed approach was reduction of semantic gap between design documents and \{CAD\} models because design documents generated in the early design stage contain abstract design descriptions, while \{CAD\} models contain detailed design descriptions. In order to reduce the semantic gap between \{CAD\} models and design documents, we adopt semantic processing and rule processing. During the semantic processing, semantic representations are generated from the text in \{CAD\} models and text in design documents using a domain ontology and shallow natural language processing (NLP). Hidden design information is extracted from \{CAD\} models and design documents based on rule processing. The experimental results show that the proposed approach can outperform the keyword-based approach which does not overcome semantic gap. "} 
}
@article{An2016215,
title = {"Scalable attribute-driven face image retrieval "},
journal = {"Neurocomputing "},
volume = {"172"},
number = {""},
pages = {"215 - 224"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.09.098"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215006128"},
author = {"Le An and Changjian Zou and Liyan Zhang and Bradley Denney"},
keywords = {"Face image retrieval", "Attribute", "Scalability", "Binary quantization", "Re-ranking "},
abstract = {"Abstract In recent years an explosion of online multimedia data has been witnessed. As an example, abundant photos recording every aspect of human life are available through social media. Among tremendous amount of photos, a significant fraction contains human faces. Faces are usually salient features of the photos. To understand and extract useful information from such gigantic data corpus, efficient and effective retrieval algorithms are demanded. Most face retrieval techniques rely on low-level image features to compare faces based on visual similarity. However, as humans we tend to simplify the recognition task by utilizing human attributes such as gender or race to help differentiate people on a higher semantic level. In this paper, we propose to use human attributes as high-level semantic cues to determine people׳s identities. To this end, we develop discriminative image features with attribute information encoded to achieve more accurate face image retrieval. To guarantee scalability, we propose using a binary coding scheme for the proposed attributed-based features. A re-ranking step after initial retrieval is incorporated to further improve the retrieval performance. We demonstrate the superiority of the proposed method compared to state-of-the-art on the \{LFW\} and Pubfig face datasets. "} 
}
@article{Meyer2016424,
title = {"Comparison of four machine learning algorithms for their applicability in satellite-based optical rainfall retrievals "},
journal = {"Atmospheric Research "},
volume = {"169, Part B"},
number = {""},
pages = {"424 - 433"},
year = {"2016"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2015.09.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809515003014"},
author = {"Hanna Meyer and Meike Kühnlein and Tim Appelhans and Thomas Nauss"},
keywords = {"Machine learning", "Rainfall retrieval", "Rainfall rate", "Rainfall area", "MSG \{SEVIRI\} "},
abstract = {"Abstract Machine learning (ML) algorithms have successfully been demonstrated to be valuable tools in satellite-based rainfall retrievals which show the practicability of using \{ML\} algorithms when faced with high dimensional and complex data. Moreover, recent developments in parallel computing with \{ML\} present new possibilities for training and prediction speed and therefore make their usage in real-time systems feasible. This study compares four \{ML\} algorithms — random forests (RF), neural networks (NNET), averaged neural networks (AVNNET) and support vector machines (SVM) — for rainfall area detection and rainfall rate assignment using \{MSG\} \{SEVIRI\} data over Germany. Satellite-based proxies for cloud top height, cloud top temperature, cloud phase and cloud water path serve as predictor variables. The results indicate an overestimation of rainfall area delineation regardless of the \{ML\} algorithm (averaged bias = 1.8) but a high probability of detection ranging from 81% (SVM) to 85% (NNET). On a 24-hour basis, the performance of the rainfall rate assignment yielded \{R2\} values between 0.39 (SVM) and 0.44 (AVNNET). Though the differences in the algorithms' performance were rather small, \{NNET\} and \{AVNNET\} were identified as the most suitable algorithms. On average, they demonstrated the best performance in rainfall area delineation as well as in rainfall rate assignment. NNET's computational speed is an additional advantage in work with large datasets such as in remote sensing based rainfall retrievals. However, since no single algorithm performed considerably better than the others we conclude that further research in providing suitable predictors for rainfall is of greater necessity than an optimization through the choice of the \{ML\} algorithm. "} 
}
@article{Kneen201653,
title = {"Interpretation of satellite retrievals of PM2.5 over the southern African Interior "},
journal = {"Atmospheric Environment "},
volume = {"128"},
number = {""},
pages = {"53 - 64"},
year = {"2016"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2015.12.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1352231015305884"},
author = {"Melanie A. Kneen and David J. Lary and William A. Harrison and Harold J. Annegarn and Tom H. Brikowski"},
keywords = {"Regional air pollution", "PM2.5 particulate matter", "Aerosol retrievals", "Aerosol climatology", "SeaWIFS", "MODIS "},
abstract = {"Abstract A case study is presented for using an unsupervised classification (Self-Organizing Map) of a global PM2.5 data product assembled from satellite retrievals (SeaWIFS, \{MODIS\} Terra and \{MODIS\} Aqua) and ground observations. The PM2.5 data products are available, on a daily basis, from August 1997 to the present, with 10 km resolutions and global coverage. In this study, a sub-set of the PM2.5 retrievals (collected over the southern African Interior) has been averaged over ten-day intervals for a period of ten years. These averaged sub-sets have been clustered using self-organizing maps to generate spatial and seasonal “PM2.5 climates” and air quality interpretations over southern Africa. Results are an indirect validation of the satellite based data product against available regional ground-based and airborne studies. The final PM2.5 aerosol climatology shows that the data product provides credible PM2.5 estimates for a region that is lacking routine aerosol monitoring data. "} 
}
@article{Bodmann2016,
title = {"Algorithms and error bounds for noisy phase retrieval with low-redundancy frames "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2016.03.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520316000282"},
author = {"Bernhard G. Bodmann and Nathaniel Hammen"},
keywords = {"Phase retrieval", "Frames", "Phase propagation", "Stability", "Low redundancy", "Polynomials", "Trigonometric polynomials", "Hilbert spaces with reproducing kernel "},
abstract = {"Abstract The main objective of this paper is to find algorithms accompanied by explicit error bounds for phase retrieval from noisy magnitudes of frame coefficients when the underlying frame has a low redundancy. We achieve these goals with frames consisting of N = 6 d − 3 vectors spanning a d-dimensional complex Hilbert space. The two algorithms we use, phase propagation or the kernel method, are polynomial time in the dimension d. To ensure a successful approximate recovery, we assume that the noise is sufficiently small compared to the squared norm of the vector to be recovered. In this regime, we derive an explicit error bound that is inverse proportional to the signal-to-noise ratio, with a constant of proportionality that depends only on the dimension d. Properties of the reproducing kernel space of complex polynomials and of trigonometric polynomials are central in our error estimates. "} 
}
@article{Dimitrovski2016851,
title = {"Improving bag-of-visual-words image retrieval with predictive clustering trees "},
journal = {"Information Sciences "},
volume = {"329"},
number = {""},
pages = {"851 - 865"},
year = {"2016"},
note = {"Special issue on Discovery Science "},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.05.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515003709"},
author = {"Ivica Dimitrovski and Dragi Kocev and Suzana Loskovska and Sašo Džeroski"},
keywords = {"Image retrieval", "Feature extraction", "Visual codebook", "Predictive clustering "},
abstract = {"Abstract The recent overwhelming increase in the amount of available visual information, especially digital images, has brought up a pressing need to develop efficient and accurate systems for image retrieval. State-of-the-art systems for image retrieval use the bag-of-visual-words representation of images. However, the computational bottleneck in all such systems is the construction of the visual codebook, i.e., obtaining the visual words. This is typically performed by clustering hundreds of thousands or millions of local descriptors, where the resulting clusters correspond to visual words. Each image is then represented by a histogram of the distribution of its local descriptors across the codebook. The major issue in retrieval systems is that by increasing the sizes of the image databases, the number of local descriptors to be clustered increases rapidly: Thus, using conventional clustering techniques is infeasible. Considering this, we propose to construct the visual codebook by using predictive clustering trees (PCTs), which can be constructed and executed efficiently and have good predictive performance. Moreover, to increase the stability of the model, we propose to use random forests of predictive clustering trees. We create a random forest of \{PCTs\} that represents both the codebook and the indexing structure. We evaluate the proposed improvement of the bag-of-visual-words approach on three reference datasets and two additional datasets of 100 K images and 1 M images, compare it to two state-of-the-art methods based on approximate k-means and extremely randomized tree ensembles. The results reveal that the proposed method produces a visual codebook with superior discriminative power and thus better retrieval performance while maintaining excellent computational efficiency. "} 
}
@article{Wang20168,
title = {"Asymmetric optical image encryption based on an improved amplitude–phase retrieval algorithm "},
journal = {"Optics and Lasers in Engineering "},
volume = {"78"},
number = {""},
pages = {"8 - 16"},
year = {"2016"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2015.09.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816615002110"},
author = {"Y. Wang and C. Quan and C.J. Tay"},
keywords = {"Optical encryption", "Asymmetric cryptosystem", "Phase retrieval "},
abstract = {"Abstract We propose a new asymmetric optical image encryption scheme based on an improved amplitude–phase retrieval algorithm. Using two random phase masks that serve as public encryption keys, an iterative amplitude and phase retrieval process is employed to encode a primary image into a real-valued ciphertext. The private keys generated in the encryption process are used to perform one-way phase modulations. The decryption process is implemented optically using conventional double random phase encoding architecture. Numerical simulations are presented to demonstrate the feasibility and robustness of the proposed system. The results illustrate that the computing efficiency of the proposed method is improved and the number of iterations required is much less than that of the cryptosystem based on the Yang–Gu algorithm. "} 
}
@article{Raghuwanshi201650,
title = {"Texture image retrieval using adaptive tetrolet transforms "},
journal = {"Digital Signal Processing "},
volume = {"48"},
number = {""},
pages = {"50 - 57"},
year = {"2016"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2015.09.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200415002717"},
author = {"Ghanshyam Raghuwanshi and Vipin Tyagi"},
keywords = {"Tetrolet transform", "Texture image retrieval", "Content-based image retrieval", "Image search "},
abstract = {"Abstract This paper proposes a novel technique for texture image retrieval based on tetrolet transforms. Tetrolets provide fine texture information due to its different way of analysis. Tetrominoes are applied at each decomposition level of an image and best combination of tetrominoes is selected, which better shows the geometry of an image at each level. All three high pass components of the decomposed image at each level are used as input values for feature extraction. A feature vector is created by taking standard deviation in combination with energy at each subband. Retrieval performance in terms of accuracy is tested on group of texture images taken from benchmark databases: Brodatz and VisTex. Experimental results indicate that the proposed method achieves 78.80% retrieval accuracy on group of texture images \{D1\} (taken from Brodatz), 84.41% on group \{D2\} (taken from VisTex) and 77.41% on rotated texture image group \{D3\} (rotated images from Brodatz). "} 
}
@article{Shekar2016828,
title = {"Video Clip Retrieval Based on \{LBP\} Variance "},
journal = {"Procedia Computer Science "},
volume = {"89"},
number = {""},
pages = {"828 - 835"},
year = {"2016"},
note = {"Twelfth International Conference on Communication Networks, \{ICCN\} 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, \{ICDMW\} 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, \{ICISP\} 2016, August 19-21, 2016, Bangalore, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.06.068"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916311334"},
author = {"B.H. Shekar and K.P. Uma and K. Raghurama Holla"},
keywords = {"Content Based Retrieval", "Local Binary Pattern Variance", "Multimedia", "Query by Example "},
abstract = {"Abstract Advancement in technology has made the acquisition and storage of multimedia data easy and inexpensive to the end user. However for effective use of the information available in the multimedia, efficient and accurate retrieval methods are required. Multimedia based retrieval systems extensively used texture based approach to interpret and recognize a scene image. The texture of an image provides clue to the orientation, smoothness, symmetry, shape, regularity and coarness of the surface. The Local Binary Pattern Variance (LBPV) is a texture feature where variance in contrast acts as adaptive factor during computation of local binary pattern (LBP) histogram. The \{LBP\} combines both structural and statistical approaches to texture analysis. This paper proposes an \{LBP\} Variance based approach to visual content based video retrieval. The proposed approach uses query by example paradigm for retrieving similar clips from the video. Experiments conducted on \{TRECVID\} dataset shows the efficacy of proposed approach. "} 
}
@article{Zingla2016225,
title = {"Short Query Expansion for Microblog Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"96"},
number = {""},
pages = {"225 - 234"},
year = {"2016"},
note = {"Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 20th International Conference KES-2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.08.135"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916319366"},
author = {"Meriem Amina Zingla and Latiri Chiraz and Yahya Slimani"},
keywords = {"Short query expansion", "Microblog retrieval", "Wikipedia", "DBpedia", "TREC microblog "},
abstract = {"Abstract Twitter has emerged as the most popular among microblogging service providers. The content provided in Twitter is large, diverse, and huge in quantity. Given the increasing amount of information available through such microblogging sites, it would be interesting to be able to retrieve useful tweets in response to a given information need. However, Twitter's subscribers often have many difficulties dealing with its content. Especially in searching for tweets that satisfy their information needs. This problem becomes more complicated when the user-defined queries are short and precise. This paper deals with short and precise queries problem for micoblog retrieval. We expand short queries by semantically related terms extracted from Wikipedia, \{DBpedia\} and unstructured texts using textmining techniques. Experiments on \{TREC\} 2011 microblog collection show significant improvement in the retrieval performance. "} 
}
@article{Yang20161797,
title = {"Improved cloud phase retrieval approaches for China's FY-3A/VIRR multi-channel data using Artificial Neural Networks "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"4"},
pages = {"1797 - 1803"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.11.084"},
url = {"http://www.sciencedirect.com/science/article/pii/S003040261501709X"},
author = {"Chunping Yang and Jing Guo"},
keywords = {"Cloud phase retrieval", "FY-3A/VIRR", "Artificial Neural Network", "Back-propagation", "Self-organizing feature map "},
abstract = {"Abstract Retrieving cloud phase accurately is important for cloud parameter studies, weather forecasting, and climate change research. Consequently, the purpose of this study is to develop better and more accurate cloud phase retrieval approaches to upgrade the current threshold technique used for China's second-generation polar-orbit meteorological satellite FengYun-3A (FY-3A). In this paper, improved cloud phase retrieval approaches using a supervised Back-Propagation Neural Network (BP-NN), and an unsupervised Self-Organizing Feature Map Neural Network (SOFM-NN) were proposed and investigated. The results of this study indicated that the two \{ANN\} approaches are satisfactory in discriminating cloud phase using FY-3A/Visible and InfRared Radiometer (VIRR) multi-channel data, and the average accuracy rates for the BP-NN approach are 93.50%, 93.81%, 94.25%, and 93.38% for the winter, spring, summer, and fall season categories, respectively, while for the SOFM-NN approach, rates are 91.93%, 92.08%, 92.63%, and 91.97%, respectively. The BP-NN approach performs slightly better than the SOFM-NN approach. Moreover, the two \{ANN\} approaches are found to perform more accurately than the current FY-3A operational product. Therefore, our work demonstrated that the \{ANN\} approaches provide an attractive alternative for cloud phase retrieval that could potentially be used to upgrade the current threshold technique used for the FY-3A operational product. "} 
}
@article{Roy2017173,
title = {"A multi-tier linking approach to analyze performance of autonomous vehicle-based storage and retrieval systems "},
journal = {"Computers & Operations Research "},
volume = {"83"},
number = {""},
pages = {"173 - 188"},
year = {"2017"},
note = {""},
issn = {"0305-0548"},
doi = {"https://doi.org/10.1016/j.cor.2017.02.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0305054817300503"},
author = {"Debjit Roy and Ananth Krishnamurthy and Sunderesh S. Heragu and Charles Malmborg"},
keywords = {"AVS/RS", "Integrated queuing model", "Linking algorithm", "Embedded Markov chains", "Semi-open queues "},
abstract = {"Abstract To improve operational flexibility, throughput capacity, and responsiveness in order fulfillment operations, several distribution centers are implementing autonomous vehicle-based storage and retrieval system (AVS/RS) in their high-density storage areas. In such systems, vehicles are self-powered to travel in horizontal directions (x- and y- axes), and use lifts or conveyors for vertical motion (z-axis). In this research, we propose a multi-tier queuing modeling framework for the performance analysis of such vehicle-based warehouse systems. We develop an embedded Markov chain based analysis approach to estimate the first and second moment of inter-departure times from the load-dependent station within a semi-open queuing network. The linking solution approach uses traffic process approximations to analyze the performance of sub-models corresponding to individual tiers (semi-open queues) and the vertical transfer units (open queues). These sub-models are linked to form an integrated queuing network model, which is solved using an iterative algorithm. Performance estimates such as expected transaction cycle times and resource (vehicle and vertical transfer unit) utilization are determined using this algorithm, and can be used to evaluate a variety of design configurations during the conceptualization phase. "} 
}
@article{Lechuga201561,
title = {"Further evidence that concept mapping is not better than repeated retrieval as a tool for learning from texts "},
journal = {"Learning and Instruction "},
volume = {"40"},
number = {""},
pages = {"61 - 68"},
year = {"2015"},
note = {""},
issn = {"0959-4752"},
doi = {"https://doi.org/10.1016/j.learninstruc.2015.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0959475215300232"},
author = {"M. Teresa Lechuga and Juana M. Ortega-Tudela and Carlos J. Gómez-Ariza"},
keywords = {"Retrieval practice", "Testing effect", "Conceptual learning", "Concept mapping "},
abstract = {"Abstract Karpicke and Blunt (2011) showed in college students that retrieval practice produced more learning from educational texts than concept mapping on a 1-week delayed test. This finding is surprising since concept mapping is thought to involve elaborative processing. Hence, the present study (N = 84; 76 females) aimed to examine whether the advantage of repeated retrieval remains when concept mapping is performed by ad hoc trained students or students who regularly utilise concept maps to prepare for exams. While the results essentially replicate Karpicke and Blunt's finding which shows that retrieval practice leads to better overall performance than concept mapping, this effect was less pronounced for people with experience using this technique than it was for trained participants. These findings point to the need to take retrieval-based learning into account in educational settings as well as to further investigate the conditions that may make retrieval activities more effective than concept mapping. "} 
}
@article{Jiang2016146,
title = {"A hierarchal BoW for image retrieval by enhancing feature salience "},
journal = {"Neurocomputing "},
volume = {"175, Part A"},
number = {""},
pages = {"146 - 154"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.10.044"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215015039"},
author = {"Fan Jiang and Hai-Miao Hu and Jin Zheng and Bo Li"},
keywords = {"Image retrieval", "Hierarchal BoW", "Feature salience enhancement", "Query model "},
abstract = {"Abstract Retrieving images with multiple features is an active research topic on boosting the performance of existing content-based image retrieval methods. The promising bags-of-words (BoW) models involve multiple features by applying feature fusion strategies in the early stage of image indexing. However, due to the different data forms of features, a simple joint may not guarantee a high retrieval performance. Moreover, a fused feature is not flexible enough to adapt to the variety of images. In order to avoid the submergence of feature salience, this letter proposes a hierarchal BoW to represent each feature in an individual codebook for obtaining the undisturbed ranks from each feature. Moreover, for feature salience enhancement, a query model based on ordinary-least-squared (OLS) regression is established for rank aggregation. The query model weighs each feature according to its retrieval performance and then selects the target images. The experimental results demonstrate that the proposed method improves the accuracy compared to the state-of-the-arts, meanwhile it maintains the stability. "} 
}
@article{Meshram2016509,
title = {"Hybrid Swarm Intelligence Method for Post Clustering Content Based Image Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"79"},
number = {""},
pages = {"509 - 515"},
year = {"2016"},
note = {"Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.03.065"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916001964"},
author = {"Shubhangi P. Meshram and Anuradha D. Thakare and Santwana Gudadhe"},
keywords = {"Content Based Image Retrieval (CBIR)", "Image Clustering", "Ant Colony Optimization (ACO)", "Particle Swarm Optimization (PSO)", "Hybrid ACPSO. "},
abstract = {"Abstract Content Based Image Retrieval is one of the most promising method for image retrieval where searching and retrieving images from large scale image database is a critical task. In Content Based Image Retrieval many visual feature like color, shape, and texture are extracted in order to match query image with stored database images. Matching the query image with each image of large scale database results in large number of disc scans which in turns slows down the systems performance. The proposed work suggested an approach for post clustering Content Based Image Retrieval, in which the database images are clustered into optimized clusters for further retrieval process. Various clustering algorithms are implemented and results are compared. Among all, it is found that hybrid \{ACPSO\} algorithm performs better over basic algorithms like k-means, ACO, \{PSO\} etc. Hybrid \{ACPSO\} has the capability to produce good cluster initialization and form global clustering. This paper discusses work-in-progress where we have implemented till clustering module and intermediate results are produced. These resulted clusters will further be used for effective Content Based Image Retrieval. "} 
}
@article{HöschlIV201672,
title = {"Robust histogram-based image retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"69"},
number = {""},
pages = {"72 - 81"},
year = {"2016"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2015.10.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865515003633"},
author = {"Cyril Höschl IV and Jan Flusser"},
keywords = {"Image retrieval", "Noisy image", "Histogram", "Convolution", "Moments", "Invariants "},
abstract = {"Abstract We present a histogram-based image retrieval method which is designed specifically for noisy query images. The images are retrieved according to histogram similarity. To reach high robustness to noise, the histograms are described by newly proposed features which are insensitive to a Gaussian additive noise in the original images. The advantage of the new method is proved theoretically and demonstrated experimentally on real data. "} 
}
@article{Ma20162396,
title = {"Spherical mirror testing by phase retrieval wavefront sensor "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"4"},
pages = {"2396 - 2400"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.09.159"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615012280"},
author = {"Xinxue Ma and Jianli Wang"},
keywords = {"Phase retrieval", "Wavefront sensor", "Spherical mirror", "Zernike polynomial", "Aberration "},
abstract = {"Abstract In order to verify the estimated wavefront ability of the phase retrieval wavefront sensor (PRWS), a measured spherical mirror of experiment platform was set up with the method of PRWS. \{PRWS\} technology is based on the focal plane image information wavefront solver in the focal plane wavefront measured technology, whose principle is sampling a number of the given defocus images; get the wavefront phase information by solving the optical system wavefront with Fourier optical diffractive theory and mathematics optimization. In order to validate the veracity of PRWS, both the \{PRWS\} measurement results and \{ZYGO\} interferometer measurement results were compared; experimental results demonstrate that agreement is obtained among the errors distribution, \{PV\} value and \{RMS\} value of \{ZYGO\} interferometer, so \{PRWS\} technology can effectively estimate the aberrations of spherical mirror. "} 
}
@article{Zidi2014213,
title = {"An Ontology-based Personalized Retrieval Model Using Case Base Reasoning "},
journal = {"Procedia Computer Science "},
volume = {"35"},
number = {""},
pages = {"213 - 222"},
year = {"2014"},
note = {"Knowledge-Based and Intelligent Information &amp; Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2014.08.101"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050914010667"},
author = {"Amir Zidi and Amna Bouhana and Mourad Abed and Afef Fekih"},
keywords = {"Case base reasoning", "ontology", "personalized search", "information retrieval", "query formulation. "},
abstract = {"Abstract A novel ontology-Based Personalized Retrieval model using the Case Base Reasoning (CBR) tool is designed and presented in this paper. The proposed approach is aimed at achieving a scalable and user friendly data retrieval system with high retrieval performance where search results are ranked based on user preferences. The proposed retrieval framework integrates the advantages of two methods, a content-based method (ontology) to represent data and a case-based method (CBR) to personalize the search process and to provide users with alternative documents recommendations. To analyze the performance of the proposed approach, computer experiments are carried out using recall-precision curve and average precision (AP) metric. The performance of our approach is then compared to a framework that uses the classic vector space model. Results clearly indicate the strength of the proposed approach as well as its ability to accurately retrieve pertinent information. The proposed approach is particularly promising in applicable related to city logistics, especially in the field of itinerary research for urban freight transport. "} 
}
@article{Uittenhove2016289,
title = {"Fast automated counting procedures in addition problem solving: When are they used and why are they mistaken for retrieval? "},
journal = {"Cognition "},
volume = {"146"},
number = {""},
pages = {"289 - 303"},
year = {"2016"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2015.10.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S001002771530086X"},
author = {"Kim Uittenhove and Catherine Thevenot and Pierre Barrouillet"},
keywords = {"Problem solving", "Retrieval", "Arithmetic", "Association", "Numerical cognition "},
abstract = {"Abstract Contrary to a widespread assumption, a recent study suggested that adults do not solve very small additions by directly retrieving their answer from memory, but rely instead on highly automated and fast counting procedures (Barrouillet &amp; Thevenot, 2013). The aim of the present study was to test the hypothesis that these automated compiled procedures are restricted to small quantities that do not exceed the size of the focus of attention (i.e., 4 elements). For this purpose, we analyzed the response times of ninety adult participants when solving the 81 additions with operands from 1 to 9. Even when focusing on small problems (i.e. with sums ⩽10) reported by participants as being solved by direct retrieval, chronometric analyses revealed a strong size effect. Response times increased linearly with the magnitude of the operands testifying for the involvement of a sequential multistep procedure. However, this size effect was restricted to the problems involving operands from 1 to 4, whereas the pattern of response times for other small problems was compatible with a retrieval hypothesis. These findings suggest that very fast responses routinely interpreted as reflecting direct retrieval of the answer from memory actually subsume compiled automated procedures that are faster than retrieval and deliver their answer while the subject remains unaware of their process, mistaking them for direct retrieval from long-term memory. "} 
}
@article{DeSimone2016194,
title = {"Does retrieval frequency account for the pattern of autobiographical memory loss in early Alzheimer's disease patients? "},
journal = {"Neuropsychologia "},
volume = {"80"},
number = {""},
pages = {"194 - 200"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.11.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215302384"},
author = {"Maria Stefania De Simone and Lucia Fadda and Roberta Perri and Marta Aloisi and Carlo Caltagirone and Giovanni Augusto Carlesimo"},
keywords = {"Alzheimer's disease", "Autobiographical memory interview", "Multiple trace theory", "Retrieval frequency", "Cortical reallocation theory "},
abstract = {"Abstract Episodic autobiographical memory (ABM) has been found to be impaired from the early stage of Alzheimer's disease (AD). Previous works have focused on how \{ABM\} decreases over the lifespan, but no study has deeply investigated whether the extent of episodic autobiographical amnesia is mediated by the retrieval frequency of the episodic trace itself. The aim of the present study was to determine whether the frequency of trace retrieval has an effect on the quality of autobiographical incidents recall and whether the extent of this contribution changes over time. For this purpose, the episodic component of \{ABM\} was assessed in patients in the early stage of \{AD\} through a questionnaire which allowed evaluating memory of past personal incidents as a function of both their age of acquisition and retrieval frequency. We found that both \{AD\} patients and healthy controls took advantage of greater retrieval frequency across all time segments, because of their better memory performance on frequently retrieved episodes than less frequently retrieved ones. Although in the \{AD\} group the retrieval frequency effect (i.e., higher scores on the episodes rated as more frequently retrieved) was found in all time segments, the extent of its beneficial effect on memory performance was temporally-graded and inversely related to the time course. Our findings provide new evidence that the combined action of both age of memory and retrieval frequency could provide a valuable framework for predicting patterns of \{ABM\} loss, at least in early \{AD\} patients. In line with the Multiple Trace Theory, we speculated that retrieval frequency protects episodic trace recall against hippocampal damage by reinforcing the neural representation of personal context-rich memories, which consequently are easier to access and recall. Furthermore, the age of memory should change the amplitude of this beneficial effect as a function of the remoteness of the trace. "} 
}
@article{Leão201642,
title = {"Diazepam effects on aversive memory retrieval and extinction: Role of anxiety levels "},
journal = {"Pharmacology Biochemistry and Behavior "},
volume = {"141"},
number = {""},
pages = {"42 - 49"},
year = {"2016"},
note = {""},
issn = {"0091-3057"},
doi = {"https://doi.org/10.1016/j.pbb.2015.11.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0091305715301003"},
author = {"Anderson H.F.F. Leão and Alícia Cabral and Geison S. Izídio and Alessandra M. Ribeiro and Regina H. Silva"},
keywords = {"Memory", "Retrieval", "Extinction", "Anxiety", "Benzodiazepine", "One-trial tolerance "},
abstract = {"Abstract Benzodiazepines (BDZs) are anxiolytic drugs that impair memory acquisition. Previous studies using the plus-maze discriminative avoidance task (PMDAT, which assesses memory and anxiety concomitantly) indicated that the effects of \{BDZs\} on anxiety and acquisition are related to each other. The possible influence of the anxiolytic action of \{BDZs\} on their effects on memory retrieval and extinction are poorly understood. This is relevant considering the relationship between aversive memories and anxiety disorders. We designed a modified protocol of \{PMDAT\} that evaluates anxiety during retrieval and extinction of the task. Male Wistar rats were trained in the \{PMDAT\} (plus-maze with two open and two enclosed arms) using a standard or a modified protocol. In the standard protocol, the aversive stimuli were presented in one of the enclosed arms during training, and the animal had free access to the whole apparatus. In the modified protocol, the open arms were blocked with glass walls. Twenty-four hours after training, the animals subjected to each of the protocols were treated with saline or 2.0 mg/kg of diazepam (DZP) 30 min before the test. There was a third session in the maze (retest) 24 h after the test. During the test, \{DZP\} impaired and improved retrieval in rats that had been trained in the standard and the modified protocol when compared to the respective saline-treated groups. In addition, treatment with \{DZP\} prior to the test induced anxiolysis, but only in the animals that were not pre-exposed to the open arms of the apparatus (modified protocol). In these animals, \{DZP\} impaired extinction, which was evaluated during retest session. The impairing effect of \{DZP\} on extinction seems to be related to its anxiolytic action during the test (extinction learning). Further, we suggest that aversive memory retrieval depends on both the treatment and the arousal elicited by exposure to the apparatus. "} 
}
@article{Bellana201624,
title = {"Laterality effects in functional connectivity of the angular gyrus during rest and episodic retrieval "},
journal = {"Neuropsychologia "},
volume = {"80"},
number = {""},
pages = {"24 - 34"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215302190"},
author = {"Buddhika Bellana and Zhongxu Liu and John A.E. Anderson and Morris Moscovitch and Cheryl L. Grady"},
keywords = {"Angular gyrus", "Episodic memory", "Default mode network", "Retrieval", "Rest", "Functional connectivity", "Recollection network "},
abstract = {"AbstractIntroduction The angular gyrus (AG) is consistently reported in neuroimaging studies of episodic memory retrieval and is a fundamental node within the default mode network (DMN). Its specific contribution to episodic memory is debated, with some suggesting it is important for the subjective experience of episodic recollection, rather than retrieval of objective episodic details. Across studies of episodic retrieval, the left \{AG\} is recruited more reliably than the right. We explored functional connectivity of the right and left \{AG\} with the \{DMN\} during rest and retrieval to assess whether connectivity could provide insight into the nature of this laterality effect. Methods Using data from the publically available 1000 Functional Connectome Project, 8 min of resting fMRI data from 180 healthy young adults were analysed. Whole-brain functional connectivity at rest was measured using a seed-based Partial Least Squares (seed-PLS) approach (McIntosh and Lobaugh, 2004) with bilateral \{AG\} seeds. A subsequent analysis used 6-min of rest and 6-min of unconstrained, silent retrieval of autobiographical events from a new sample of 20 younger adults. Analysis of this dataset took a more targeted approach to functional connectivity analysis, consisting of univariate pairwise correlations restricted to nodes of the DMN. Results The seed-PLS analysis resulted in two Latent Variables that together explained ~86% of the shared cross-block covariance. The first \{LV\} revealed a common network consistent with the \{DMN\} and engaging the \{AG\} bilaterally, whereas the second \{LV\} revealed a less robust, yet significant, laterality effect in connectivity – the left \{AG\} was more strongly connected to the DMN. Univariate analyses of the second sample again revealed better connectivity between the left \{AG\} and the \{DMN\} at rest. However, during retrieval the left \{AG\} was more strongly connected than the right to non-medial temporal (MTL) nodes of the DMN, and \{MTL\} nodes were more strongly connected to the right AG. Discussion The multivariate analysis of resting connectivity revealed that the left and right \{AG\} show similar connectivity with the DMN. Only after accounting for this commonality were we able to detect a left laterality effect in \{DMN\} connectivity. Further probing with univariate connectivity analyses during retrieval demonstrates that the left preference we observe is restricted to the non-MTL regions of the DMN, whereas the right \{AG\} shows significantly better connectivity with the MTL. These data suggest bilateral involvement of the \{AG\} during retrieval, despite the focus on the left \{AG\} in the literature. Furthermore, the results suggest that the contribution of the left \{AG\} to retrieval may be separable from that of the MTL, consistent with a role for the left \{AG\} in the subjective aspects of recollection in memory, whereas the \{MTL\} and the right \{AG\} may contribute to objective recollection of specific memory details. "} 
}
@incollection{DeSmedt2016219,
title = {"Chapter 9 - Individual Differences in Arithmetic Fact Retrieval "},
editor = {"Berch, Daniel B. and Geary, David C.  and Koepke, Kathleen Mann "},
booktitle = {"Development of Mathematical Cognition "},
publisher = {"Academic Press"},
edition = {""},
address = {"San Diego"},
year = {"2016"},
pages = {"219 - 243"},
series = {"Mathematical Cognition and Learning"},
isbn = {"978-0-12-801871-2"},
doi = {"https://doi.org/10.1016/B978-0-12-801871-2.00009-5"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128018712000095"},
author = {"Bert De Smedt"},
keywords = {"Arithmetic fact retrieval", "Individual differences", "Numerical magnitude processing", "Phonological processing", "Educational neuroscience", "Inferior parietal cortex", "Fronto-parietal network "},
abstract = {"Abstract In this chapter I summarize research on individual differences in arithmetic fact retrieval through the lens of educational neuroscience. By generating predictions about underlying cognitive processes based on neuroimaging data, developmental behavioral studies have revealed that symbolic numerical magnitude processing plays a unique role in children’s early arithmetic facts acquisition. Such studies also suggest that phonological processing might play a role in fact retrieval. Other studies in educational neuroscience point to the recruitment of a widespread brain network during fact retrieval, including the prefrontal cortex, inferior parietal cortex, and the medial temporal lobe. The fact that the organization of this network changes over time highlights the continuing need for developmental imaging studies. "} 
}
@article{Deep2016954,
title = {"Biomedical Image Indexing and Retrieval Descriptors: A Comparative Study "},
journal = {"Procedia Computer Science "},
volume = {"85"},
number = {""},
pages = {"954 - 961"},
year = {"2016"},
note = {"International Conference on Computational Modelling and Security (CMS 2016) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.05.287"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916306378"},
author = {"Gagan Deep and Lakhwinder Kaur and Savita Gupta"},
keywords = {"Medical imaging", "Image retrieval", "Local binary pattern (LBP)", "Local ternary pattern (LTP)", "local mesh ternary pattern", "directional local ternary quantized extrema pattern", "Texture "},
abstract = {"Abstract This paper focuses on the comparison of two new proposed pattern descriptors i.e., local mesh ternary pattern (LMeTerP) and directional local ternary quantized extrema pattern (DLTerQEP) for biomedical image indexing and retrieval. The standard local binary patterns (LBP) and local ternary patterns (LTP) encode the gray scale relationship between the center pixel and its surrounding neighbors in two dimensional (2D) local region of an image whereas the former descriptor encodes the gray scale relationship among the neighbors for a given center pixel with three selected directions of mess patterns which is generated from 2D image and later descriptor encodes the spatial relation between any pair of neighbors in a local region along the given directions (i.e., 0̊, 45̊, 90̊ and 135̊) for a given center pixel in an image. The novelty of the proposed descriptors is that they use ternary patterns from images to encode more spatial structure information which lead to better retrieval. The experimental results demonstrate the superiority of the new techniques in terms of average retrieval precision (ARP) and average retrieval rate (ARR) over state-of-the-art feature extraction techniques (like LBP, LTP, LQEP, \{LMeP\} etc.) on three different types of benchmark biomedical databases. "} 
}
@article{Corcoran201693,
title = {"Analysis of coherent activity between retrosplenial cortex, hippocampus, thalamus, and anterior cingulate cortex during retrieval of recent and remote context fear memory "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"127"},
number = {""},
pages = {"93 - 101"},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2015.11.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742715002282"},
author = {"Kevin A. Corcoran and Brendan J. Frick and Jelena Radulovic and Leslie M. Kay"},
keywords = {"Retrosplenial cortex", "Fear", "Coherence", "Local field potential", "Retrieval", "Extinction "},
abstract = {"Abstract Memory for contextual fear conditioning relies upon the retrosplenial cortex (RSC) regardless of how long ago conditioning occurred, whereas areas connected to the RSC, such as the dorsal hippocampus (DH) and anterior cingulate cortex (ACC) appear to play time-limited roles. To better understand whether these brain regions functionally interact during memory processing and how the passage of time affects these interactions, we simultaneously recorded local field potentials (LFPs) from these three regions as well as anterior dorsal thalamus (ADT), which provides one of the strongest inputs to RSC, and measured coherence of oscillatory activity within the theta (4–12 Hz) and gamma (30–80 Hz) frequency bands. We identified changes of theta coherence related to encoding, retrieval, and extinction of context fear, whereas changes in gamma coherence were restricted to fear extinction. Specifically, exposure to a novel context and retrieval of recently acquired fear conditioning memory were associated with increased theta coherence between \{RSC\} and all three other structures. In contrast, RSC–DH and RSC–ADT theta coherence were decreased in mice that successfully retrieved, relative to mice that failed to retrieve, remote memory. Greater RSC–ADT theta and gamma coherence were observed during recent, compared to remote, extinction of freezing responses. Thus, the degree of coherence between \{RSC\} and connected brain areas may predict and contribute to context memory retrieval and retrieval-related phenomena such as fear extinction. Importantly, although theta coherence in this circuit increases during memory encoding and retrieval of recent memory, failure to decrease RSC–DH theta coherence might be linked to retrieval deficit in the long term, and possibly contribute to aberrant memory processing characteristic of neuropsychiatric disorders. "} 
}
@article{Wang2015,
title = {"Phase retrieval with the reverse projection method in the presence of object's scattering "},
journal = {"Radiation Physics and Chemistry "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2015"},
note = {""},
issn = {"0969-806X"},
doi = {"https://doi.org/10.1016/j.radphyschem.2015.12.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S0969806X15301535"},
author = {"Zhili Wang and Kun Gao and Dajiang Wang"},
keywords = {"X-ray imaging", "Grating interferometry", "Reverse projection", "Phase retrieval "},
abstract = {"Abstract X-ray grating interferometry can provide substantially increased contrast over traditional attenuation-based techniques in biomedical applications, and therefore novel and complementary information. Recently, special attention has been paid to quantitative phase retrieval in X-ray grating interferometry, which is mandatory to perform phase tomography, to achieve material identification, etc. An innovative approach, dubbed “Reverse Projection” (RP), has been developed for quantitative phase retrieval. The \{RP\} method abandons grating scanning completely, and is thus advantageous in terms of higher efficiency and reduced radiation damage. Therefore, it is expected that this novel method would find its potential in preclinical and clinical implementations. Strictly speaking, the reverse projection method is applicable for objects exhibiting only absorption and refraction. In this contribution, we discuss the phase retrieval with the reverse projection method for general objects with absorption, refraction and scattering simultaneously. Especially, we investigate the influence of the object's scattering on the retrieved refraction signal. Both theoretical analysis and numerical experiments are performed. The results show that the retrieved refraction signal is the product of object's refraction and scattering signals for small values. In the case of a strong scattering, the reverse projection method cannot provide reliable phase retrieval. Those presented results will guide the use of the reverse projection method for future practical applications, and help to explain some possible artifacts in the retrieved images and/or reconstructed slices. "} 
}
@article{Zhang2017331,
title = {"Biomass retrieval from L-band polarimetric \{UAVSAR\} backscatter and \{PRISM\} stereo imagery "},
journal = {"Remote Sensing of Environment "},
volume = {"194"},
number = {""},
pages = {"331 - 346"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.03.034"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717301384"},
author = {"Zhiyu Zhang and Wenjian Ni and Guoqing Sun and Wenli Huang and Kenneth J. Ranson and Bruce D. Cook and Zhifeng Guo"},
keywords = {"Forest biomass", "Canopy height", "Radar", "UAVSAR", "Prism", "Stereo imagery", "Incidence angle "},
abstract = {"Abstract The forest above-ground biomass (AGB) and spatial distribution of vegetation elements have profound effects on the productivity and biodiversity of terrestrial ecosystems. In this paper, we evaluated biomass estimation from L-band Synthetic Aperture Radar (SAR) data acquired by National Aeronautics and Space Administration (NASA) Uninhabited Aerial Vehicle \{SAR\} (UAVSAR) and the improvement of accuracy by adding canopy height information derived from stereo imagery acquired by Japan Aerospace Exploration Agency (JAXA) Panchromatic Remote Sensing Instrument for Stereo Mapping (PRISM) on-board the Advanced Land Observing Satellite (ALOS). Various models for prediction of forest biomass from \{UAVSAR\} data were investigated at pixel sizes of 1/4 ha (50 m × 50 m) and 1 ha. The variance inflation factor (VIF) was calculated for each of the explanatory variables in multivariable regression models to assess the multi-collinearity between explanatory variables. In addition, the t- and p-values were used to interpret the significance of the coefficients of each explanatory variables. The R2, Root Mean Square Error (RMSE), bias and Akaike information criterion (AIC), and leave-one-out cross-validation (LOOCV) and bootstrapping were used to validate models. At 1/4-ha scale, the \{R2\} and \{RMSE\} of biomass estimation from a model using a single track of polarimetric \{UAVSAR\} data were 0.59 and 52.08 Mg/ha. With canopy height from \{PRISM\} as additional independent variable, \{R2\} increased to 0.76 and \{RMSE\} decreased to 39.74 Mg/ha (28.24%). At 1-ha scale, the \{RMSE\} of biomass estimation based on \{UAVSAR\} data of a single track was 39.42 Mg/ha with a \{R2\} of 0.77. With the canopy height from PRISM, \{R2\} increased to 0.86 and \{RMSE\} decreased to 29.47 Mg/ha (20.18%). The models using \{UAVSAR\} data alone underestimated biomass at levels above ~ 150 Mg/ha showing the saturation phenomenon. Adding canopy height from \{PRISM\} stereo imagery significantly improved the biomass estimation and elevated the saturation level in estimating biomass. Combined use of \{UAVSAR\} data acquired from opposite directions (odd and even tracks) slightly improved the biomass estimation. Combined use of \{UAVSAR\} data acquired from opposite directions (odd and even tracks) slightly improved the biomass estimation at 1/4-ha scale, \{R2\} increased from 0.59 to 0.66 and \{RMSE\} reduced from 52.08 to 48.57 Mg/ha. Averaging multiple acquisitions of \{UAVSAR\} data from the same look azimuth direction did not improve biomass estimation. A biomass map derived from NASA's \{LVIS\} (Laser Vegetation Imaging System) waveform data was used as a reference for evaluation of the biomass maps from these models. The study has also shown that the errors decreased when deciduous, evergreen, and mixed forests were modeled separately but the improvement was not significant. "} 
}
@incollection{Harrington2016375,
title = {"Chapter 18 - Advanced Retrieval Operations "},
editor = {"Harrington, Jan L. "},
booktitle = {"Relational Database Design and Implementation (Fourth edition) "},
publisher = {"Morgan Kaufmann"},
edition = {"Fourth edition"},
address = {"Boston"},
year = {"2016"},
pages = {"375 - 398"},
isbn = {"978-0-12-804399-8"},
doi = {"https://doi.org/10.1016/B978-0-12-804399-8.00018-1"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128043998000181"},
author = {"Jan L. Harrington"},
keywords = {"SQL", "SQL retrieval", "SQL UNION", "SQL EXISTS", "SQL EXCEPT", "SQL INSTERSECT", "SQL arithmetic", "SQL string manipulation", "SQL date manipulation", "SQL time manipulation "},
abstract = {"Abstract This chapter covers advanced retrieval operations such as unions, negative queries, special operators (EXISTS, EXCEPT, \{AND\} INTERSECTION), arithmetic in \{SQL\} queries, string manipulation, and date and time manipulation. "} 
}
@article{Lupinetti2016472,
title = {"Automatic Extraction of Assembly Component Relationships for Assembly Model Retrieval "},
journal = {"Procedia \{CIRP\} "},
volume = {"50"},
number = {""},
pages = {"472 - 477"},
year = {"2016"},
note = {"26th \{CIRP\} Design Conference "},
issn = {"2212-8271"},
doi = {"https://doi.org/10.1016/j.procir.2016.04.148"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212827116303882"},
author = {"Katia Lupinetti and Franca Giannini and Marina Monti and Jean-Philippe Pernot"},
keywords = {"Contact analysis", "Degree of freedom detection", "Assembly model retrieval "},
abstract = {"Abstract Even if during the Product Design Process, assembly models are described in terms of their constitutive components and associated relationships, only the position of each component is often stored within the Digital Mock-Up. Thus, the mating information are lost. However, these relationships are crucial for many applications, such as retrieval, assembly planning and finite element simulations. In this paper, we propose a method for the detection and use of the mating relationships for assembly model retrieval. The proposed approach detects and analyses the interferences between parts to compute their degree of freedom and kinematic pairs. To support the retrieval of assembly models, the extracted information are formalized and capitalized in a newly proposed hierarchical assembly model descriptor. Results of the application of the method are also provided to show the system capabilities. Moreover, considering that a same joint can be defined in multiple ways, this work provides also a method for retrieving assemblies in a dataset according to the part relationships and their class of equivalence. "} 
}
@article{Sokic201682,
title = {"Phase preserving Fourier descriptor for shape-based image retrieval "},
journal = {"Signal Processing: Image Communication "},
volume = {"40"},
number = {""},
pages = {"82 - 96"},
year = {"2016"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2015.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596515001897"},
author = {"Emir Sokic and Samim Konjicija"},
keywords = {"Content based image retrieval", "Fourier descriptors", "Phase", "Nominal orientation", "Pseudomirror points "},
abstract = {"Abstract Shape is one of the most important discriminative elements for the content based image retrieval and the most challenging for quantification and description. Fourier descriptors are a very efficient shape description method used in shape-based image retrieval tasks. In order to achieve invariance under rotation and starting point change, most Fourier descriptor implementations disregard the phase of Fourier coefficients, consequently losing valuable information about the shape. This paper proposes a novel method of extracting Fourier descriptors that preserve the phase of Fourier coefficients. We introduce specific points, called pseudomirror points, and use them as a shape orientation reference. They facilitate the extraction of phase-preserving Fourier descriptors which are invariant under translation, scaling, rotation and starting point change. The proposed descriptor was tested on four popular benchmarking datasets: \{MPEG7\} CE-1 Set B, Swedish leaf, ETH-80 and Kimia99 datasets. Performance and computational complexity measures indicate that the proposed method outperforms other state-of-the-art phase-based Fourier descriptors. In addition, it outperforms other state-of-the-art magnitude-based Fourier descriptors, and many non-Fourier based shape description methods in terms of performance – complexity ratio. "} 
}
@article{Wang2016199,
title = {"Semantic Boosting Cross-Modal Hashing for efficient multimedia retrieval "},
journal = {"Information Sciences "},
volume = {"330"},
number = {""},
pages = {"199 - 210"},
year = {"2016"},
note = {"SI\:Visual Info Communication "},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.10.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515007562"},
author = {"Ke Wang and Jun Tang and Nian Wang and Ling Shao"},
keywords = {"Cross-modal hashing", "Multimedia retrieval", "Boosting "},
abstract = {"Abstract Cross-modal hashing aims to embed data from different modalities into a common low-dimensional Hamming space, which serves as an important part in cross-modal retrieval. Although many linear projection methods were proposed to map cross-modal data into a common abstract space, the semantic similarity between cross-modal data was often ignored. To address this issue, we put forward a novel cross-modal hashing method named Semantic Boosting Cross-Modal Hashing (SBCMH). To preserve the semantic similarity, we first apply multi-class logistic regression to project heterogeneous data into a semantic space, respectively. To further narrow the semantic gap between different modalities, we then use a joint boosting framework to learn hash functions, and finally transform the mapped data representations into a measurable binary subspace. Comparative experiments on two public datasets demonstrate the effectiveness of the proposed SBCMH. "} 
}
@article{Jyothi2016141,
title = {"Integrated Multiple Features for Tumor Image Retrieval Using Classifier and Feedback Methods "},
journal = {"Procedia Computer Science "},
volume = {"85"},
number = {""},
pages = {"141 - 148"},
year = {"2016"},
note = {"International Conference on Computational Modelling and Security (CMS 2016) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.05.200"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916305488"},
author = {"B. Jyothi and Y. MadhaveeLatha and P.G. Krishna Mohan and V.S.K. Reddy"},
keywords = {"Content based image retrieval", "Multiple features ;SVM Classifier ;Relevance feedback. "},
abstract = {"Abstract The content based image retrieval method greatly assists in retrieving medical images close to the query image from a large database basing on their visual features. This paper presents an effective approach in which the region of the object is extracted with the help of multiple features ignoring the background of the object by employing edge following segmentation method followed by extracting texture and shape characteristics of the images. The former is extracted with the help of Steerable filter at different orientations and radial Chebyshev moments are used for extracting the later. Initially the images similar to the query image are extracted from a large group of medical images. Then the search is by accelerating the retrieval process with the help of Support Vector Machine (SVM) classifier. The performance of the retrieval system is enhanced by adapting the subjective feedback method. The experimental results show that the proposed region based multiple features and integrated with classifier and subjective feedback method yields better results than classical retrieval systems. "} 
}
@article{Labarre201763,
title = {"Surface roughness retrieval by inversion of the Hapke model: A multiscale approach "},
journal = {"Icarus "},
volume = {"290"},
number = {""},
pages = {"63 - 80"},
year = {"2017"},
note = {""},
issn = {"0019-1035"},
doi = {"https://doi.org/10.1016/j.icarus.2017.02.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0019103516304833"},
author = {"S. Labarre and C. Ferrari and S. Jacquemoud"},
keywords = {"Earth", "Geological processes", "Photometry "},
abstract = {"Abstract Surface roughness is a key property of soils that controls many surface processes and influences the scattering of incident electromagnetic waves at a wide range of scales. Hapke (2012b) designed a photometric model providing an approximate analytical solution of the Bidirectional Reflectance Distribution Function (BRDF) of a particulate medium: he introduced the effect of surface roughness as a correction factor of the \{BRDF\} of a smooth surface. This photometric roughness is defined as the mean slope angle of the facets composing the surface, integrated over all scales from the grain size to the local topography. Yet its physical meaning is still a question at issue, as the scale at which it occurs is not clearly defined. This work aims at better understanding the relative influence of roughness scales on soil \{BRDF\} and to test the ability of the Hapke model to retrieve a roughness that depicts effectively the ground truth. We apply a wavelet transform on millimeter digital terrain models (DTM) acquired over volcanic terrains. This method allows splitting the frequency band of a signal in several sub-bands, each corresponding to a spatial scale. We demonstrate that sub-centimeter surface features dominate both the integrated roughness and the \{BRDF\} shape. We investigate the suitability of the Hapke model for surface roughness retrieval by inversion on optical data. A global sensitivity analysis of the model shows that soil \{BRDF\} is very sensitive to surface roughness, nearly as much as the single scattering albedo according to the phase angle, but also that these two parameters are strongly correlated. Based on these results, a simplified two-parameter model depending on surface albedo and roughness is proposed. Inversion of this model on \{BRDF\} data simulated by a ray-tracing code over natural targets shows a good estimation of surface roughness when the assumptions of the model are verified, with a priori knowledge on surface albedo. "} 
}
@article{Maillet2016142,
title = {"From mind wandering to involuntary retrieval: Age-related differences in spontaneous cognitive processes "},
journal = {"Neuropsychologia "},
volume = {"80"},
number = {""},
pages = {"142 - 156"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.11.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215302323"},
author = {"David Maillet and Daniel L. Schacter"},
keywords = {"Aging", "Spontaneous cognition", "Mind-wandering", "Involuntary autobiographical retrieval", "Intrusive thoughts", "Prospective memory "},
abstract = {"Abstract The majority of studies that have investigated the effects of healthy aging on cognition have focused on age-related differences in voluntary and deliberately engaged cognitive processes. Yet many forms of cognition occur spontaneously, without any deliberate attempt at engaging them. In this article we review studies that have assessed age-related differences in four such types of spontaneous thought processes: mind-wandering, involuntary autobiographical memory, intrusive thoughts, and spontaneous prospective memory retrieval. These studies suggest that older adults exhibit a reduction in frequency of both mind-wandering and involuntary autobiographical memory, whereas findings regarding intrusive thoughts have been more mixed. Additionally, there is some preliminary evidence that spontaneous prospective memory retrieval may be relatively preserved in aging. We consider the roles of age-related differences in cognitive resources, motivation, current concerns and emotional regulation in accounting for these findings. We also consider age-related differences in the neural correlates of spontaneous cognitive processes. "} 
}
@article{Pooja2017,
title = {"Improved shape matching and retrieval using robust histograms of spatially distributed points and angular radial transform "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2017.04.102"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402617305193"},
author = {"Pooja"},
keywords = {"Histograms of spatially distributed points (HSDP)", "Angular radial transform (ART)", "Shape matching", "Precision and recall "},
abstract = {"Abstract In this paper, the problem of shape based image retrieval is addressed by proposing a hybrid shape descriptor. The proposed descriptor conforms to human visual perception along with its low computational complexity. Since global features are related to the holistic characteristics of images, whereas local features describe the finer details within objects of images, in the proposed hybrid descriptor both global and local features of images are used to describe the entire aspects of image shape. For global features extraction, we use angular radial transform, which is also adopted by MPEG-7 as a region based shape descriptor. On the other hand, for local feature extraction, a novel local descriptor is proposed, which is referred to as histograms of spatially distributed points (HSDP). It is based on two components: radial distance and differential coefficient, which are used to build 2D histograms. Global and local features are combined using effective distance measures viz. Min-Max and Bray-Curtis. Their superiority is validated by experimental results. Apart from that, an extensive range of image databases is employed to assess the performance of the proposed hybrid descriptor. These databases represent several characteristics of shape such as partial occlusion, distortion, subject change, gray scale objects, rotated and noise affected objects, unstructured images, trademarks, blurred images, Corel images, etc. The results of wide range of experiments reveal that the fusion of \{ART\} and \{HSDP\} significantly improves the image retrieval accuracy and provides a robust and invariant solution for effective shape matching. "} 
}
@article{Xu2016826,
title = {"Multiple-instance learning based decision neural networks for image retrieval and classification "},
journal = {"Neurocomputing "},
volume = {"171"},
number = {""},
pages = {"826 - 836"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.07.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215010012"},
author = {"Yeong-Yuh Xu"},
keywords = {"Multiple instance learning", "Content based image retrieval", "Image classification", "Neural networks", "Multiple-instance learning based decision neural networks", "MI-BDNN "},
abstract = {"Abstract The revolutionary Internet and digital technologies have spawned a need for technology that can organize abundantly available digital images for easy categorization and retrieval. Hence, content-based image retrieval (CBIR) has become one of the most active research areas for the last few decades. However, it is still an open issue to narrow down the gap between the high level semantics in the human minds and the low level features computable by machines. This paper proposes a multiple-instance learning based decision neural network (MI-BDNN) that attempts to bridge the semantic ga in CBIR. Multiple-instance learning (MIL) is a variation of supervised learning, where the training set is composed of many bags, and each bag contains many instances. If a bag contains at least one positive instance, it is labelled as a positive bag; otherwise, it is labelled as a negative bag. A novel discriminant function and learning schemes are employed in the MI-BDNN to learn the concept from the training bags. The proposed approach considers the image retrieval problem as a \{MIL\} problem, where a user׳s preferred image concept is learned by training MI-BDNN with a set of exemplar images, each of which is labelled as conceptual related (positive) or conceptual unrelated (negative) image. The MI-BDNN based \{CBIR\} system is developed, and the results of the experiments showed that MI-BDNN can successfully be used for real image retrieval and classification problems. "} 
}
@article{Zeng2016673,
title = {"Image retrieval using spatiograms of colors quantized by Gaussian Mixture Models "},
journal = {"Neurocomputing "},
volume = {"171"},
number = {""},
pages = {"673 - 684"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.07.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215009820"},
author = {"Shan Zeng and Rui Huang and Haibing Wang and Zhen Kang"},
keywords = {"Image retrieval", "Color quantization", "Spatiogram", "Gauss Mixture Model", "Jensen–Shannon Divergence "},
abstract = {"Abstract In this paper we propose a novel image representation method that characterizes an image as a spatiogram--a generalized histogram--of colors quantized by Gaussian Mixture Models (GMMs). First, we quantize the color space using a GMM, which is learned by the Expectation-Maximization (EM) algorithm from the training images. The number of Gaussian components (i.e., the number of quantized color bins) is determined automatically according to the Bayesian Information Criterion (BIC). Second, we incorporate the spatiogram representation with the quantized Gaussian mixture color model. Intuitively, a spatiogram is a histogram in which the distribution of colors is spatially weighted by the locations of the pixels contributing to each color bin. We have modified the spatiogram representation to fit our framework, which employs Gaussian color components instead of discrete color bins. Finally, the comparison between two images is achieved by measuring the similarity between two spatiograms, for which purpose we propose a new measurement adopting the Jensen–Shannon Divergence (JSD). We applied the new image representation and comparison method to the image retrieval task. The experiments on several publicly available \{COREL\} image datasets demonstrate the effectiveness of our proposed image representation for image retrieval. "} 
}
@article{Angel201653,
title = {"Neural correlates of successful memory retrieval in aging: Do executive functioning and task difficulty matter? "},
journal = {"Brain Research "},
volume = {"1631"},
number = {""},
pages = {"53 - 71"},
year = {"2016"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2015.10.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899315007465"},
author = {"Lucie Angel and Christine Bastin and Sarah Genon and Eric Salmon and Séverine Fay and Evelyne Balteau and Pierre Maquet and André Luxen and Michel Isingrini and Fabienne Collette"},
keywords = {"FMRI", "Aging", "Retrieval success", "Task difficulty", "Executive functioning "},
abstract = {"Abstract The current experiment aimed to explore age differences in brain activity associated with successful memory retrieval in older adults with different levels of executive functioning, at different levels of task demand. Memory performance and fMRI activity during a recognition task were compared between a young group and two older groups characterized by a low (old-low group) vs. high (old-high group) level of executive functioning. Participants first encoded pictures, presented once (Hard condition) or twice (Easy condition), and then completed a recognition memory task. Old-low adults had poorer memory performance than the two other groups, which did not differ, in both levels of task demands. In the Easy condition, even though older adults demonstrated reduced activity compared to young adults in several regions, they also showed additional activations in the right superior frontal gyrus and right parietal lobule (positively correlated to memory accuracy) for the old-high group and in the right precuneus (negatively correlated to memory accuracy), right anterior cingulate gyrus and right supramarginal gyrus for the old-low group. In the Hard condition, some regions were also more activated in the young group than in the older groups. Vice versa, old-high participants demonstrated more activity than either the young or the old-low group in the right frontal gyrus, associated with more accurate memory performance, and in the left frontal gyrus. In sum, the present study clearly showed that age differences in the neural correlates of retrieval success were modulated by task difficulty, as suggested by the \{CRUNCH\} model, but also by interindividual variability, in particular regarding executive functioning. "} 
}
@article{Nambiar2015297,
title = {"Shape Context for soft biometrics in person re-identification and database retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"68, Part 2"},
number = {""},
pages = {"297 - 305"},
year = {"2015"},
note = {"Special Issue on “Soft Biometrics” "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2015.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865515002019"},
author = {"Athira Nambiar and Alexandre Bernardino and Jacinto Nascimento"},
keywords = {"Multimedia", "Soft biometrics", "Shape Context", "Re-Identification", "Silhouettes", "Retrieval", "Surveillance "},
abstract = {"Abstract We introduce a novel descriptor for the analysis of pedestrians and its applications to person re-identification and database retrieval. A Shape Context descriptor of the head-torso region of persons’ silhouettes is shown to have a very good discrimination ability and application to re-identification. For database retrieval using human queries, we train a map from the Shape Context to interpretable soft biometric quantities that can be reasoned about by humans. We show that a good linear correlation exists between Shape Context descriptors and soft biometrics quantities in the upper human torso and illustrate its application to retrieval in databases from human queries. Shape Context to biometrics maps are learned from virtual avatars rendered by computer graphics engines, to circumvent the need for time-consuming manual labelling of data sets. We obtained promising results of Shape Context based person re-identification and database retrieval from human compliant description of biometric traits, in both synthetic data and real imagery. "} 
}
@article{Xu2016326,
title = {"A derivative method of phase retrieval based on two interferograms with an unknown phase shift "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"1"},
pages = {"326 - 330"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.10.055"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615014102"},
author = {"Yuanyuan Xu and Yawei Wang and Ying Ji and Weifeng Jin and Min Bu and Minjie Liang and Hao Han"},
keywords = {"Phase retrieval", "Two-step phase-shifting interferometry", "Derivative", "Random phase distribution", "Phase objects "},
abstract = {"Abstract Phase retrieval is one of the important study fields in the optical metrology of phase objects. In this paper, a rapid derivative method of phase retrieval is proposed that can both extract phase and determine an unknown phase shift based on two-step phase-shifting interferometry (PSI). By numerically calculating the first-order derivatives of two \{PSI\} images with the random phase distribution, one can directly obtain the quantitative phase image, without the need for dealing with the background term and reference intensity. We give the method with the theory, and illustrate it using the simulations of a ball and a red blood cell (RBC) and an optical experiment of a polystyrene sphere. From which, the effectiveness and accuracy of this method is verified, but the error of the experimental result is larger than that of the simulated result. "} 
}
@article{Kuribayashi201742,
title = {"Optimal retrieval method to estimate ozone vertical profile in the mesosphere and lower thermosphere (MLT) region from submillimeter-wave limb emission spectra "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"192"},
number = {""},
pages = {"42 - 52"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2017.01.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316306677"},
author = {"K. Kuribayashi and N. Yoshida and H. Jin and Y.J. Orsolini and Y. Kasai"},
keywords = {"SMILES", "Ozone", "MLT region "},
abstract = {"Abstract Spectrum width and intensity of ozone (O3) observed in the \{MLT\} region behaves quite differently than in the stratosphere for submillimeter-wave limb emission spectroscopic observation. For example, \{O3\} spectra in the stratosphere are stronger during the day than at night. Conversely, spectra in the \{MLT\} region at night are stronger than those occurring during the day due to diurnal variations in \{O3\} behavior. These opposing behaviors cause problems, including oscillations and inaccuracies particularly for \{O3\} vertical profiles in the \{MLT\} region retrieved with an application of one retrieval procedure for the entire vertical range (stratosphere to thermosphere). Recently, we developed an optimal retrieval method for \{O3\} in the \{MLT\} region for spectra, observed by the Superconducting Submillimeter-Wave Limb-Emission Sounder (SMILES) instrument on the International Space Station. Optimizations were performed for frequency window range, retrieval vertical range, vertical grids, and a priori information for \{O3\} and temperature. Precision and accuracy were evaluated by error analysis and comparisons with previous products. The random error was estimated to be about 5% and 35% in the mesosphere and lower thermosphere, respectively, for nighttime \{O3\} profiles in the \{MLT\} region. The total systematic error was about 6% in the \{MLT\} region. Certain improvements for both random noise (from 50% to 35%) and systematic error (from 10% to 6%) were obtained. We succeeded in revealing the positive correlation between \{O3\} and ClO at nighttime in the upper mesosphere using the optimized \{O3\} profiles; furthermore, its chemical mechanism was explained quantitatively. "} 
}
@article{Bhandari2016391,
title = {"An Innovative Remote Sensing Image Retrieval Techniques Based on Haar Wavelet-LTRP and \{ANFIS\} "},
journal = {"Procedia Computer Science "},
volume = {"79"},
number = {""},
pages = {"391 - 401"},
year = {"2016"},
note = {"Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.03.051"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916001824"},
author = {"Kiran Ashok Bhandari and R. Manthalkar Ramchandra"},
keywords = {"Remote Sensing Image Retrieval (RSIR)", "Local Tetra Pattern (LTRP)", "Artificial Neural Network Fuzzy Inference System (ANFIS)", "Scene Semantic (SS). "},
abstract = {"Abstract In the existing Remote sensing image retrieval methods, the images are extracted from the remote sensing image database by means of three characteristic models they are visual features, object features and the scene feature. Although this technique achieves high retrieval accurateness, the precision value is low down. In order to enhance the efficiency and precision value even more higher a Haar wavelet based \{LTRP\} technique is proposed in this paper. To extract the object feature instead of earlier new watershed segmentation(NWS) method, Haar wavelet based \{LTRP\} technique is used. In the proposed technique, at first the visual features are removed from the images by means of the spatial spectral heterogeneity technique. Afterwards the object features are removed by applying the Haar wavelet and the object features are extracted from the wavelet band by developing \{LTRP\} method and the Extracted object features are classified by Neuro-Fuzzy system typically known as ANFIS. Subsequently Scene semantic models are used for the recovery of parallel scene images from the database. The projected \{RSIR\} system based on Haar wavelet-LTRP and \{ANFIS\} technique are executed in working platform of MATLAB. The performance is measured by utilizing a compilation of remote sensing images taken from the database. In addition the recital is examined by comparing the projected Haar wavelet-LTRP method with the \{NWSRSIR\} and the usual \{SBRSIR\} method in terms of performance estimate metrics such as precision, recall and F-Measure rate. The implementation effects show the competence of projected Haar wavelet based \{LTRP\} method in Remote sensing image retrieval method. "} 
}
@article{Li2016104,
title = {"3D human motion retrieval using graph kernels based on adaptive graph construction "},
journal = {"Computers & Graphics "},
volume = {"54"},
number = {""},
pages = {"104 - 112"},
year = {"2016"},
note = {"Special Issue on CAD/Graphics 2015 "},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2015.07.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849315001089"},
author = {"Meng Li and Howard Leung and Zhiguang Liu and Liuyang Zhou"},
keywords = {"Motion retrieval", "Adaptive graph", "Graph kernel", "Motion capture", "Multiple kernel learning "},
abstract = {"Abstract Graphs are frequently used to provide a powerful representation for structured data. However, it is still a challenging task to model 3D human motions due to its large spatio-temporal variations. This paper proposes a novel graph-based method for real time 3D human motion retrieval. Firstly, we propose a novel graph construction method which connects the joints that are deemed important for a given motion. In particular, the top-N Relative Ranges of Joint Relative Distances (RRJRD) were proposed to determine which joints should be connected in the resulting graph because these measures indicate the normalized activity levels among the joint pairs. Different motions may thus result in different graph structures so the construction of the graphs is made adaptive to the characteristics of a given motion and is able to represent a meaningful spatial structure. In addition to the spatial structure, the temporal pyramid of covariance descriptors was adopted to preserve certain level of spatio-temporal local features. The graph kernel is computed by matching the walks from each of the two graphs to be matched. Furthermore, multiple kernel learning was applied to determine the optimal weights for combining the graph kernels to measure the overall similarity between two motions. The experimental results show that our method is robust under several variations, and demonstrates superior performance in comparison to three state-of-the-art methods. "} 
}
@article{Mironică201638,
title = {"Fisher Kernel Temporal Variation-based Relevance Feedback for video retrieval "},
journal = {"Computer Vision and Image Understanding "},
volume = {"143"},
number = {""},
pages = {"38 - 51"},
year = {"2016"},
note = {"Inference and Learning of Graphical Models\: Theory and Applications in Computer Vision and Image Analysis "},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2015.10.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314215002155"},
author = {"Ionuţ Mironică and Bogdan Ionescu and Jasper Uijlings and Nicu Sebe"},
keywords = {"Relevance feedback", "Fisher Kernel representation", "Multimodal content description", "Video retrieval "},
abstract = {"Abstract This paper proposes a novel framework for Relevance Feedback based on the Fisher Kernel (FK). Specifically, we train a Gaussian Mixture Model (GMM) on the top retrieval results (without supervision) and use this to create a \{FK\} representation, which is therefore specialized in modelling the most relevant examples. We use the \{FK\} representation to explicitly capture temporal variation in video via frame-based features taken at different time intervals. While the \{GMM\} is being trained, a user selects from the top examples those which he is looking for. This feedback is used to train a Support Vector Machine on the \{FK\} representation, which is then applied to re-rank the top retrieved results. We show that our approach outperforms other state-of-the-art relevance feedback methods. Experiments were carried out on the Blip10000, UCF50, \{UCF101\} and \{ADL\} standard datasets using a broad range of multi-modal content descriptors (visual, audio, and text). "} 
}
@article{Zhang2016207,
title = {"Kernelized sparse hashing for scalable image retrieval "},
journal = {"Neurocomputing "},
volume = {"172"},
number = {""},
pages = {"207 - 214"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.02.080"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215005950"},
author = {"Yin Zhang and Weiming Lu and Yang Liu and Fei Wu"},
keywords = {"Image retrieval", "Hashing", "Sparse coding", "Kernel methods "},
abstract = {"Abstract Recently, hashing has been widely applied to large scale image retrieval applications due to its appealing query speed and low storage cost. The key idea of hashing is to learn a hash function that maps high dimensional data into compact binary codes while preserving the similarity structure in the original feature space. In this paper, we propose a new method called the Kernelized Sparse Hashing, which generates sparse hash codes with ℓ1 and non-negative regularizations. Compared to traditional hashing methods, our method only activates a small number of relevant bits on the hash code and hence provides a more compact and interpretable representation of data. Moreover, the kernel trick is introduced to capture the nonlinear similarity of features, and the local geometrical structure of data is explicitly considered in our method to improve the retrieval accuracy. Extensive experiments on three large-scale image datasets demonstrate the superior performance of our proposed method over the examined state-of-the-art techniques. "} 
}
@article{EitoBrun201450,
title = {"Knowledge dissemination patterns in the information retrieval industry: A case study for automatic classification techniques "},
journal = {"World Patent Information "},
volume = {"39"},
number = {""},
pages = {"50 - 57"},
year = {"2014"},
note = {""},
issn = {"0172-2190"},
doi = {"https://doi.org/10.1016/j.wpi.2014.06.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0172219014000957"},
author = {"Ricardo Eito-Brun"},
keywords = {"Citation analysis", "Automatic document classification", "Document clustering", "Bibliometric indicators", "Innovation capability assessment "},
abstract = {"Abstract Patents provide valuable information to identify flows in the transfer of technical knowledge and assess the innovation capabilities of the actors involved in different industries. Patent citations are also recognized as a valid tool to measure the impact of innovations and to identify key influencers in diverse activity sectors. This study analyzes a collection of U.S. patents granted in the period between 1990 and 2012 for the subject “automatic document clustering and classification”, a key technology within the Information Retrieval and Text Mining disciplines. The purpose of this research is to identify – using citation analysis – the most productive and influential companies and journals, and the patterns followed in the transfer and sharing of technical knowledge. The paper identifies the most productive organizations (those that have been granted a higher number of patents) and those with a higher impact (organizations whose patents have received a major number of citations), and compares the generated rankings with those obtained using traditional bibliometric indicators. The conclusions provide an overview of the innovation landscape in the area of study, and suggest to which extent bibliometric indicators match the conclusions obtained after analyzing productivity and impact using patent citation. "} 
}
@article{Ji201523,
title = {"Efficient semi-supervised multiple feature fusion with out-of-sample extension for 3D model retrieval "},
journal = {"Neurocomputing "},
volume = {"169"},
number = {""},
pages = {"23 - 33"},
year = {"2015"},
note = {"Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.12.112"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215006876"},
author = {"Mingming Ji and Yinfu Feng and Jun Xiao and Yueting Zhuang and Xiaosong Yang and Jian J. Zhang"},
keywords = {"3D model retrieval", "Multiple feature fusion", "Out-of-sample", "Semi-supervised learning "},
abstract = {"Abstract Multiple visual features have been proposed and used in 3-dimensional (3D) model retrieval in recent years. Since each visual feature reflects a unique characteristic about the model, they have unequal discriminative power with respect to a specific category of 3D model, and they are complementary to each other in model representation. Thus, it would be beneficial to combine multiple visual features together in 3D model retrieval. In light of this, we propose an efficient Semi-supervised Multiple Feature Fusion (SMFF) method for view-based 3D model retrieval in this paper. Specifically, We first extract multiple visual features to describe both the local and global appearance characteristics of multiple 2D projected images that are generated from 3D models. Then, \{SMFF\} is adopted to learn a more compact and discriminative low-dimensional feature representation via multiple feature fusion using both the labeled and unlabeled 3D models. Once the low-dimensional features have been learned, many existing methods such as \{SVM\} and \{KNN\} can be used in the subsequent retrieval phase. Moreover, an out-of-sample extension of \{SMFF\} is provided to calculate the low-dimensional features for the newly added 3D models in linear time. Experiments on two public 3D model datasets demonstrate that using such a learned feature representation can significantly improve the performance of 3D model retrieval and the proposed method outperforms the other competitors. "} 
}
@article{Alikas2017218,
title = {"Improved retrieval of Secchi depth for optically-complex waters using remote sensing data "},
journal = {"Ecological Indicators "},
volume = {"77"},
number = {""},
pages = {"218 - 227"},
year = {"2017"},
note = {""},
issn = {"1470-160X"},
doi = {"https://doi.org/10.1016/j.ecolind.2017.02.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S1470160X17300559"},
author = {"Krista Alikas and Susanne Kratzer"},
keywords = {"Secchi depth", "ENVISAT/MERIS", "Sentinel-3/OLCI", "Lakes", "Optically complex waters", "Water framework directive", "Environmental monitoring "},
abstract = {"Abstract Water transparency is one of the ecological indicators for describing water quality and the underwater light field which determines its productivity. In the European Water Framework Directive (WFD) as well as in the European Marine Strategy Framework Directive (MSFD) water transparency is used for ecological status classification of inland, coastal and open sea waters and it is regarded as an indicator for eutrophication in Baltic Sea management (HELCOM, 2007). We developed and compared different empirical and semi-analytical algorithms for lakes and coastal Nordic waters to retrieve Secchi depth (ZSD) from remote sensing data (MERIS, 300 m resolution). The algorithms were developed in water bodies with high coloured dissolved organic matter absorption (aCDOM(442) ranging 1.7–4.0 m−1), Chl a concentration (0.5–73 mg m−3) and total suspended matter (0.7–37.5 g m−3) and validated against an independent data set over inland and coastal waters (0.6 m &lt; \{ZSD\} &lt; 14.8 m). The results indicate that for empirical algorithms, using longer wavelengths in the visible spectrum as a reference band decreases the \{RMSE\} and increases the coefficient of determination (R2). The accuracy increased (R2 = 0.75, \{RMSE\} = 1.33 m, n = 134) when \{ZSD\} was retrieved via an empirical relationship between \{ZSD\} and Kd(490). The best agreement with in situ data was attained when \{ZSD\} was calculated via both the diffuse and the beam attenuation coefficient (R2 = 0.89, \{RMSE\} = 0.77 m, n = 89). The results demonstrate that transparency can be retrieved with high accuracy over various optical water types by the means of ocean color remote sensing, improving both the spatial and temporal coverage. The satellite derived \{ZSD\} product could be therefore used as an additional source of information for \{WFD\} and \{MSFD\} reporting purposes. "} 
}
@article{Gray2015188,
title = {"Electrically stimulating prefrontal cortex at retrieval improves recollection accuracy "},
journal = {"Cortex "},
volume = {"73"},
number = {""},
pages = {"188 - 194"},
year = {"2015"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2015.09.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945215003275"},
author = {"Stephen J. Gray and Geoffrey Brookshire and Daniel Casasanto and David A. Gallo"},
keywords = {"Brain stimulation", "tDCS", "Retrieval monitoring", "Criterial recollection", "Source memory "},
abstract = {"Abstract Neuroimaging and brain damage studies suggest that dorsolateral prefrontal cortex (dlPFC) is involved in the cognitive control of episodic recollection. If dlPFC is causally involved in retrieval, then transcranial direct current stimulation (tDCS) of this brain region should increase recollection accuracy, especially when recollection is difficult and requires cognitive control. Here, we report the first brain stimulation experiment to directly test this hypothesis. We administered tDCS to dlPFC immediately after studying to-be-learned material but just prior to recollection testing, thereby targeting retrieval processes. We found that stimulation of dlPFC significantly increased recollection accuracy, relative to a no-stimulation sham condition and also relative to active stimulation of a comparison region in left parietal cortex. There was no significant difference in the size of this increase between hemispheres. Moreover, these dlPFC stimulation effects were behaviorally selective, increasing accuracy only when participants needed to recollect difficult information. Electrically stimulating dlPFC allowed people to more accurately recollect specific details of their experiences, demonstrating a causal role of dlPFC in the retrieval of episodic memories. "} 
}
@article{Iftene2016436,
title = {"Using Semantic Resources in Image Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"96"},
number = {""},
pages = {"436 - 445"},
year = {"2016"},
note = {"Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 20th International Conference KES-2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.08.093"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916318828"},
author = {"Adrian Iftene and Baboi Alexandra-Mihaela"},
keywords = {"Image retrieval", "YAGO", "Wikipedia", "WordNet "},
abstract = {"Abstract The need of humans to socialize and share information has led to a constantly growing Web, which has become a support for social media. Every day, worldwide users are pushing multimedia data towards their family, friends and the world at large. This is the reason why, web search has also become the main method for people to fulfill their information needs. The common modality used for image search on the web is based on text, the assumption being that the tags and the textual descriptions associated with photos are powerful ways to describe and retrieve images. The results are usually obtained by simply matching the terms of the query to an index of terms associated to the images in a corpus. The efficiency of this technique depends strongly on the tags associated to pictures, as well as their accuracy. Trying to search for images with bridges in this kind of systems, the result set will only contain images explicitly annotated with this term, but will fail to include images with Pont Neuf or Ponte Vecchio, if their tags do not contain the noun bridge. In this paper, we present a system designed to perform diversification in an image retrieval system, using semantic resources like YAGO, Wikipedia and WordNet. "} 
}
@article{Tsou2017,
title = {"SER: Secure and Efficient Retrieval for Anonymous Range Query in Wireless Sensor Networks "},
journal = {"Computer Communications "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0140-3664"},
doi = {"https://doi.org/10.1016/j.comcom.2017.04.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S014036641730467X"},
author = {"Yao-Tung Tsou and Chun-Shien Lu and Sy-Yen Kuo"},
keywords = {"Anonymity", "Privacy", "Integrity", "Range query", "wireless sensor network "},
abstract = {"Abstract A two-tiered wireless sensor network, where storage nodes take charge of storing sensitive data and processing queries with respect to the sensing nodes and querists, incurs a security breach. This is because the important role of storage nodes may be (1) instructed by attackers to return fake and/or incomplete data in response to querists’ queries or (2) compromised by attackers to arbitrarily expose mass of valuable data or launch choice attacks to make authorized querists miss valuable data and disturb their decisions. Additionally, attackers may launch DoS attacks via wireless channels to storage nodes. To address the above issues, we propose a secure and efficient retrieval scheme for wireless sensor networks, namely SER, which mainly prevents attackers from gaining the valuable information stored on storage nodes, detects the compromised storage nodes when they misbehave, and efficiently verifies the querists’ privileges without knowing their identities. In addition to privacy and system analyses, we demonstrate the feasibility and efficiency of \{SER\} through experiments conducted on TelosB prototype sensor platform equipped with \{IEEE\} 802.15.4 \{TI\} wireless transceiver, and conduct comparisons with state-of-the-art methods. "} 
}
@article{Yang20153093,
title = {"Learning salient visual word for scalable mobile image retrieval "},
journal = {"Pattern Recognition "},
volume = {"48"},
number = {"10"},
pages = {"3093 - 3101"},
year = {"2015"},
note = {"Discriminative Feature Learning from Big Data for Visual Recognition "},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2014.12.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320314005287"},
author = {"Xiyu Yang and Xueming Qian and Tao Mei"},
keywords = {"Mobile image retrieval", "Scalable retrieval", "Salient visual word (SVW)", "Multiple relevant photos", "Spatial verification "},
abstract = {"Abstract Owing to the portable and excellent phone camera, people now prefer to take photos and share them in social networks with their friends. If a user wants to obtain relevant information about an image, content based image retrieval method can be utilized. Taking the limited bandwidth and instability of wireless channel into account, in this paper we propose an effective scalable mobile image retrieval approach by exploiting the advantage of mobile end that people usually take multiple photos of an object in different viewpoints and focuses. The proposed algorithm first determines the truly relevant photos according to visual similarity in mobile end, then learns salient visual words by exploring saliency from these relevant images, and finally determines the contribution order of salient visual words to carry out scalable retrieval. Moreover, to improve the retrieval performance, soft spatial verification is proposed to re-rank the results. Compared to the existing approaches of mobile image retrieval, our approach transmits less data and reduces the computational cost of spatial verification. Most importantly, when the bandwidth is limited, we can transmit only a part of features according their contributions to retrieval. Experimental results show the effectiveness of the proposed approach. "} 
}
@article{Hangarge2016441,
title = {"Gabor Wavelets Based Word Retrieval from Kannada Documents "},
journal = {"Procedia Computer Science "},
volume = {"79"},
number = {""},
pages = {"441 - 448"},
year = {"2016"},
note = {"Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.03.057"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916001885"},
author = {"Mallikarjun Hangarge and Veershetty C. and Rajmohan Pardeshi and B.V. Dhandra"},
keywords = {"Kannada word retrieval", "Gabor wavelets", "Document image retrieval", "Cosine distance "},
abstract = {"Abstract In this paper, we propose a technique for word retrieval based on Gabor wavelets. Gabor wavelets are employed to capture directional energy features of the word image. A pre-processing step is performed in order to improve the quality of the document images, at the same time word segmentation is accomplished using 294 document images. As a result, a large dataset of 45000 words is generated for experimentation. Then, Gabor wavelets are used to represent the candidate word as well as a query word. Then cosine distance is used to measure the similarity between two words, based on it, relevance of the word is estimated by generating distance ranks. Then correctly matched words are selected at different distance thresholds such as 96%, 97%, 98% and 99%. The results achieved are encouraging in terms of average precision 81.25%, average recall 82.09% and F measure 84.53% at a threshold 97%. "} 
}
@article{AlbercaReina201551,
title = {"Impact of sleep loss before learning on cortical dynamics during memory retrieval "},
journal = {"NeuroImage "},
volume = {"123"},
number = {""},
pages = {"51 - 62"},
year = {"2015"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2015.08.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811915007454"},
author = {"E. Alberca-Reina and J.L. Cantero and M. Atienza"},
keywords = {"Acute sleep restriction", "Associative memory", "EEG oscillations", "Memory retrieval", "Sleep loss "},
abstract = {"Abstract Evidence shows that sleep loss before learning decreases activation of the hippocampus during encoding and promotes forgetting. But it remains to be determined which neural systems are functionally affected during memory retrieval after one night of recovery sleep. To investigate this issue, we evaluated memory for pairs of famous people's faces with the same or different profession (i.e., semantically congruent or incongruent faces) after one night of undisturbed sleep in subjects who either underwent 4 hours of acute sleep restriction (ASR, N = 20) or who slept 8 hours the pre-training night (controls, N = 20). \{EEG\} recordings were collected during the recognition memory task in both groups, and the cortical sources generating this activity localized by applying a spatial beamforming filter in the frequency domain. Even though sleep restriction did not affect accuracy of memory performance, controls showed a much larger decrease of alpha power relative to a baseline period when compared to sleep-deprived subjects. These group differences affected a widespread frontotemporoparietal network involved in retrieval of episodic/semantic memories. Regression analyses further revealed that associative memory in the \{ASR\} group was negatively correlated with alpha power in the occipital regions, whereas the benefit of congruency in the same group was positively correlated with delta power in the left lateral prefrontal cortex. Retrieval-related decreases of alpha power have been associated with the reactivation of material-specific memory representations, whereas increases of delta power have been related to inhibition of interferences that may affect the performance of the task. We can therefore draw the conclusion that a few hours of sleep loss in the pre-training night, though insufficient to change the memory performance, is sufficient to alter the processes involved in retrieving and manipulating episodic and semantic information. "} 
}
@article{HajMohamed2015790,
title = {"Algorithm \{BOSS\} (Bag-of-Salient local Spectrums) for non-rigid and partial 3D object retrieval "},
journal = {"Neurocomputing "},
volume = {"168"},
number = {""},
pages = {"790 - 798"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.05.045"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215007213"},
author = {"Hela Haj Mohamed and Samir Belaid"},
keywords = {"3D shape retrieval", "Bag of Features", "Laplace–Beltrami operator", "Heat kernel diffusion", "Auto-diffusion distance "},
abstract = {"Abstract The aim of the proposed algorithm is to expedite three-dimensional objects indexing and retrieval. Investigating the Bag-of-Features (BoF) paradigm, we focus on a set of extracted local descriptors from 3D objects. Using scalar function calculated on the surface mesh, the algorithm extracts the salient points, and then associates each of these points with a local Fourier descriptor. The descriptor is computed on the neighboring salient points by projecting the geometry onto the first eigenvectors of Laplace–Beltrami operator. Additionally, through an offline learning step, a visual dictionary is built by clustering a large set of feature descriptors. Then, each 3D shape is described by a histogram of these visual words occurrences weighted using the number of their local descriptors. Experimental results show the highly discriminative capability of the proposed approach against rigid and non-rigid transformations, noise and geometry changes. The performance of our algorithm is also demonstrated on global and partial shape retrieval. "} 
}
@article{Gao2015471,
title = {"A Context-Aware Mobile User Behavior Based Preference Neighbor Finding Approach for Personalized Information Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"56"},
number = {""},
pages = {"471 - 476"},
year = {"2015"},
note = {"The 10th International Conference on Future Networks and Communications (FNC 2015) / The 12th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2015) Affiliated Workshops "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.07.237"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915017184"},
author = {"Qian Gao and Xiangjun Dong and Deqian Fu"},
keywords = {"Multi-Agent", "Context", "Trust Degree", "Interest Similarity Degree", "Time Attenuation ; "},
abstract = {"Abstract This paper adopts a new approach to searching the users with similarinterests by mobile network services instead of by desktop users. First, the direct trustis calculated based on the mobile users’ behavior andthe weight of the corresponding context (time and position), then an indirect trust degree calculation method is proposed according to the propagationdistance based on the theory of the six degrees of separation; secondly this paper further uses the evaluation score about a certain mobile web service given by a mobile user to calculate the preference similarity degree between different users. Finally based on the time attenuation functionit tries to find the users with similar preference,so as to make use of the neighbor users’ preference profile to dynamicallyupdate the target user's preference profile. Simulation shows that the proposed approach outperformspure sliding window methodand pure forgetting strategy method which fail totake the context mobile information into considerationin terms of Recall Ratio and Precision Ratio. "} 
}
@article{Bampas2015231,
title = {"Improved periodic data retrieval in asynchronous rings with a faulty host "},
journal = {"Theoretical Computer Science "},
volume = {"608, Part 3"},
number = {""},
pages = {"231 - 254"},
year = {"2015"},
note = {"Structural Information and Communication Complexity "},
issn = {"0304-3975"},
doi = {"https://doi.org/10.1016/j.tcs.2015.09.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304397515008488"},
author = {"Evangelos Bampas and Nikos Leonardos and Euripides Markou and Aris Pagourtzis and Matoula Petrolia"},
keywords = {"Distributed algorithm", "Mobile agent", "Periodic data retrieval", "Malicious host", "Gray hole", "Red hole", "Unreliable whiteboard "},
abstract = {"Abstract The exploration problem has been extensively studied in unsafe networks containing malicious hosts of a highly harmful nature, called black holes, which completely destroy mobile agents that visit them. In a recent work, Královič and Miklík (SIROCCO 2010, \{LNCS\} 6058, pp. 157–167) [20] considered various types of malicious host behavior in the context of the Periodic Data Retrieval problem in asynchronous ring networks with exactly one malicious host. In this problem, a team of initially co-located agents must report data from all safe nodes of the network to the homebase, infinitely often. The malicious host can choose whether to kill visiting agents or allow them to pass through (gray hole). In another variation of the model, the malicious host can, in addition, alter its whiteboard contents in order to deceive visiting agents. The goal is to design a protocol for Periodic Data Retrieval using as few agents as possible. In this paper, we present the first nontrivial lower bounds on the number of agents for Periodic Data Retrieval in asynchronous ring networks. Specifically, we show that at least 4 agents are needed when the malicious host is a gray hole, and at least 5 agents are needed when the malicious host whiteboard is unreliable. This improves the previous lower bound of 3 in both cases and answers an open question posed in the aforementioned paper. On the positive side, we propose an optimal protocol for Periodic Data Retrieval in asynchronous rings with a gray hole, which solves the problem with only 4 agents. This improves the previous upper bound of 9 agents and settles the question of the optimal number of agents in the gray-hole case. Finally, we propose a protocol with 7 agents when the whiteboard of the malicious host is unreliable, significantly improving the previously known upper bound of 27 agents. Along the way, we set forth a detailed framework for studying networks with malicious hosts of varying capabilities. "} 
}
@article{Liu201619,
title = {"Projective nonnegative matrix factorization for social image retrieval "},
journal = {"Neurocomputing "},
volume = {"172"},
number = {""},
pages = {"19 - 26"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.09.094"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215005937"},
author = {"Qiuli Liu and Zechao Li"},
keywords = {"Nonnegative matrix factorization", "Latent subspace", "Image retrieval "},
abstract = {"Abstract Increasingly many social images with tags are available on photo sharing websites. Due to the subjectivity and diversity of social tagging behaviors, noisy and missing tags for images are inevitable. To tackle this problem, this paper proposes a novel factor analysis model, named ProjecTive Nonnegative Matrix Factorization (PTNMF) with ℓ 2 , 1 -norm regularization, which introduces linear transformation and ℓ 2 , 1 -norm minimization into a joint framework of NMF. For tagging data, a new interpretation is adopted to distinguish the relevant tags and irrelevant tags instead of the typically used binary scheme. In our model, the image latent representation is assumed to be projected from its original feature representation with an orthogonal transformation matrix. The projection makes convenient to embed any images including out-of-samples into the latent space. That is, the proposed method enables to handle the out-of-sample problem. The ℓ 2 , 1 -norm regularization makes the transformation matrix suitable for selecting the effective features. Local geometry preservations of image space (tag space) are explored as constraints in order to make image similarity (tag correlation) consistent in the original space and the corresponding latent space. We investigate the performance of the proposed method on image retrieval and compare it to existing work on the challenging NUS-WIDE dataset. Extensive experiments indicate the effectiveness and potentials of the proposed method in real-world applications. "} 
}
@article{Yang20152063,
title = {"An advanced carbon dioxide retrieval algorithm for satellite measurements and its application to \{GOSAT\} observations "},
journal = {"Science Bulletin "},
volume = {"60"},
number = {"23"},
pages = {"2063 - 2066"},
year = {"2015"},
note = {""},
issn = {"2095-9273"},
doi = {"https://doi.org/10.1007/s11434-015-0953-2"},
url = {"http://www.sciencedirect.com/science/article/pii/S2095927316302602"},
author = {"Dongxu Yang and Yi Liu and Zhaonan Cai and Jianbo Deng and Jing Wang and Xi Chen"},
keywords = {"Retrieval algorithm", "Satellite remote sensing", "Carbon dioxide", "Carbon flux", "GOSAT "},
abstract = {"Abstract An advanced carbon dioxide retrieval algorithm for satellite observations has been developed at the Institute of Atmospheric Physics, Chinese Academy of Sciences. The algorithm is tested using Greenhouse gases Observing \{SATellite\} (GOSAT) \{L1B\} data and validated using the Total Column Carbon Observing Network (TCCON) measurements. The retrieved \{XCO2\} agrees well with \{TCCON\} measurements in a low bias of 0.15 ppmv and \{RMSE\} of 1.48 ppmv, and captured the seasonal variation and increasing of \{XCO2\} in Northern and Southern Hemisphere, respectively, as other measurements. "} 
}
@article{Teeter2016311,
title = {"Tribocorrosion in shoulder arthroplasty humeral component retrievals "},
journal = {"Journal of Shoulder and Elbow Surgery "},
volume = {"25"},
number = {"2"},
pages = {"311 - 315"},
year = {"2016"},
note = {""},
issn = {"1058-2746"},
doi = {"https://doi.org/10.1016/j.jse.2015.07.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S105827461500378X"},
author = {"Matthew G. Teeter and Michael J. Carroll and Gilles Walch and George S. Athwal"},
keywords = {"Shoulder arthroplasty", "humeral component", "revision", "tribocorrosion", "fretting", "corrosion", "trunnionosis", "retrieval "},
abstract = {"Background Tribocorrosion at the modular taper connections of total hip implants has been associated with trunnionosis and adverse local tissue reactions. Modularity is also widely used in shoulder arthroplasty implants, but little information exists about the potential for tribocorrosion. This study hypothesized that there would be mild or no tribocorrosion in a series of retrieved shoulder implants. Methods A total of 28 implants with a mean implantation time of 6.2 ± 6.0 years were evaluated using a validated damage scoring method. Implant tapers on the head and stem were divided into upper (deepest) and lower zones and independently scored for fretting and corrosion damage from 1 (none) to 4 (severe). Results Corrosion was present on 32% of heads and 38% of stems, whereas fretting was present on 36% of heads and 46% of stems. There was significantly greater (P = .02) corrosion in the lower zone of the retrieved stems (1.4 ± 0.5) than there was in the upper zone (1.1 ± 0.3). Correlation between the head and stem corrosion for lower zone was moderate (r = 0.41; P = .04). Discussion Tribocorrosion was present on the heads and stems of some of the retrieved shoulder implants examined in this study. The incidence of tribocorrosion in shoulder implants was lower than in reported cases of retrieved hip implants. The greatest damage was in the lower zone of the taper, where the connection may be exposed to the surrounding joint fluid. It remains to be seen whether this leads to any clinical presentation of trunnionosis. "} 
}
@article{Huang20152144,
title = {"Content-based image retrieval technology using multi-feature fusion "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"126"},
number = {"19"},
pages = {"2144 - 2148"},
year = {"2015"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.05.095"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615004088"},
author = {"Min Huang and Huazhong Shu and Yaqiong Ma and Qiuping Gong"},
keywords = {"Image retrieval", "Multi-feature", "Similarity", "Normalization", "Relevance feedback "},
abstract = {"Abstract Due to the diversity of the image content, different images have different focuses, image retrieval system based on single feature has a lower performance, and it cannot apply to all images, so an image retrieval method using multi-feature fusion is proposed. In this method, the color moment in \{RGB\} color space in combination with the color histogram in \{HSV\} color space is used for color feature extraction, the improved Zernike moments are used for shape feature extraction, and the gray level co-occurrence matrix is used for texture feature extraction, then combining these three features. Finally, respectively using color features, shape features, texture features as well as the fused features for image retrieval, the experimental results show that the image retrieval method based on multi-feature fusion has better retrieval performance. "} 
}
@article{Markonis2015774,
title = {"User-oriented evaluation of a medical image retrieval system for radiologists "},
journal = {"International Journal of Medical Informatics "},
volume = {"84"},
number = {"10"},
pages = {"774 - 783"},
year = {"2015"},
note = {""},
issn = {"1386-5056"},
doi = {"https://doi.org/10.1016/j.ijmedinf.2015.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1386505615000829"},
author = {"Dimitrios Markonis and Markus Holzer and Frederic Baroz and Rafael Luis Ruiz De Castaneda and Célia Boyer and Georg Langs and Henning Müller"},
keywords = {"Usability tests", "User-centered design", "Medical informatics applications", "Content-based image retrieval "},
abstract = {"AbstractPurpose This article reports the user-oriented evaluation of a text- and content-based medical image retrieval system. User tests with radiologists using a search system for images in the medical literature are presented. The goal of the tests is to assess the usability of the system, identify system and interface aspects that need improvement and useful additions. Another objective is to investigate the system's added value to radiology information retrieval. The study provides an insight into required specifications and potential shortcomings of medical image retrieval systems through a concrete methodology for conducting user tests. Methods User tests with a working image retrieval system of images from the biomedical literature were performed in an iterative manner, where each iteration had the participants perform radiology information seeking tasks and then refining the system as well as the user study design itself. During these tasks the interaction of the users with the system was monitored, usability aspects were measured, retrieval success rates recorded and feedback was collected through survey forms. Results In total, 16 radiologists participated in the user tests. The success rates in finding relevant information were on average 87% and 78% for image and case retrieval tasks, respectively. The average time for a successful search was below 3 min in both cases. Users felt quickly comfortable with the novel techniques and tools (after 5 to 15 min), such as content-based image retrieval and relevance feedback. User satisfaction measures show a very positive attitude toward the system's functionalities while the user feedback helped identifying the system's weak points. The participants proposed several potentially useful new functionalities, such as filtering by imaging modality and search for articles using image examples. Conclusion The iterative character of the evaluation helped to obtain diverse and detailed feedback on all system aspects. Radiologists are quickly familiar with the functionalities but have several comments on desired functionalities. The analysis of the results can potentially assist system refinement for future medical information retrieval systems. Moreover, the methodology presented as well as the discussion on the limitations and challenges of such studies can be useful for user-oriented medical image retrieval evaluation, as user-oriented evaluation of interactive system is still only rarely performed. Such interactive evaluations can be limited in effort if done iteratively and can give many insights for developing better systems. "} 
}
@article{Zeng201585,
title = {"A new image retrieval model based on monogenic signal representation "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"33"},
number = {""},
pages = {"85 - 93"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.08.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001571"},
author = {"Zhiyong Zeng and Liwei Song and Qicai Zheng and Yanling Chi"},
keywords = {"Monogenic signal representation", "Local binary pattern", "Directional texture descriptor", keywords =Content-based image retrieval", "Block-based Fisher linear discriminant", "Feature fusion", "Amplitude", "Orientation", "Phase "},
abstract = {"Abstract This paper proposes a novel image retrieval model based on monogenic signal representation. An original image is decomposed into three complementary components: amplitude, orientation and phase by monogenic signal representation. The monogenic variation in each local region and monogenic feature in each pixel are encoded, and then the statistical features of the local features encoded are calculated. In order to overcome the problem of high feature dimensionality, the local statistical features extracted from the complementary monogenic components are projected by block-based fisher discriminant analysis, which not only reduces the dimensionality of the features extracted, but also enhances its discriminative power. Finally, these features reduced are fused for effective image retrieval. Experimental results show that our scheme can effectively describe an image, and obviously improve the average retrieval precision. "} 
}
@article{Zhou201675,
title = {"Learning semantic representation with neural networks for community question answering retrieval "},
journal = {"Knowledge-Based Systems "},
volume = {"93"},
number = {""},
pages = {"75 - 83"},
year = {"2016"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2015.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705115004207"},
author = {"Guangyou Zhou and Yin Zhou and Tingting He and Wensheng Wu"},
keywords = {"Community question answering", "Question retrieval", "Text mining", "Yahoo! Answers "},
abstract = {"Abstract In community question answering (cQA), users pose queries (or questions) on portals like Yahoo! Answers which can then be answered by other users who are often knowledgeable on the subject. cQA is increasingly popular on the Web, due to its convenience and effectiveness in connecting users with queries and those with answers. In this article, we study the problem of finding previous queries (e.g., posed by other users) which may be similar to new queries, and adapting their answers as the answers to the new queries. A key challenge here is to the bridge the lexical gap between new queries and old answers. For example, “company” in the queries may correspond to “firm” in the answers. To address this challenge, past research has proposed techniques similar to machine translation that “translate” old answers to ones using the words in the new queries. However, a key limitation of these works is that they assume queries and answers are parallel texts, which is hardly true in reality. As a result, the translated or rephrased answers may not look intuitive. In this article, we propose a novel approach to learn the semantic representation of queries and answers by using a neural network architecture. The learned semantic level features are finally incorporated into a learning to rank framework. We have evaluated our approach using a large-scale data set. Results show that the approach can significantly outperform existing approaches. "} 
}
@article{Johnson201541,
title = {"Electrophysiological evidence for strategically orienting retrieval toward the specific age of a memory "},
journal = {"Brain and Cognition "},
volume = {"100"},
number = {""},
pages = {"41 - 48"},
year = {"2015"},
note = {""},
issn = {"0278-2626"},
doi = {"https://doi.org/10.1016/j.bandc.2015.09.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0278262615300245"},
author = {"Jeffrey D. Johnson and Anna K. McGhee"},
keywords = {"Episodic memory", "Remote memory", "Retrieval orientation", "EEG", "ERPs "},
abstract = {"Abstract For over a century, memory researchers have extensively studied the differences between retrieving memories that were encoded in the remote past as opposed to recently. Although this work has largely focused on the changes that these memory traces undergo over time, an unexplored issue is whether retrieval attempts and other strategic processes might be differentially oriented in order to effectively access memories of different ages. The current study addressed this issue by instructing participants to retrieve words that were encoded either one week (remote) or about 30 minutes earlier (recent). To maximize the possibility that participants adopted distinct retrieval orientations, separate blocks of the memory test employed exclusion task procedures in which the words from only one encoding period were targeted at a given time, in the face of distractors from the other period. Event-related potentials (ERPs) elicited by correctly-rejected new items were contrasted to minimize confounding effects of retrieval success. The new-item \{ERPs\} revealed differences according to the targeted week, such that the \{ERPs\} over posterior scalp were more positive-going for the recent compared to remote blocks. Furthermore, using multiple methods, these \{ERP\} effects were dissociated from differences in difficulty across the two conditions. The findings provide novel evidence that knowledge about when a memory was initially encoded leads to differences in the adoption of retrieval processing strategies. "} 
}
@article{Cogliati2015344,
title = {"Retrieval of sun-induced fluorescence using advanced spectral fitting methods "},
journal = {"Remote Sensing of Environment "},
volume = {"169"},
number = {""},
pages = {"344 - 357"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.08.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715301085"},
author = {"S. Cogliati and W. Verhoef and S. Kraft and N. Sabater and L. Alonso and J. Vicent and J. Moreno and M. Drusch and R. Colombo"},
keywords = {"Sun-induced fluorescence", "FLEX mission", "Retrieval algorithm", "Spectral fitting methods", "Full fluorescence spectrum "},
abstract = {"Abstract The \{FLuorescence\} \{EXplorer\} (FLEX) satellite mission, candidate of ESA's 8th Earth Explorer program, is explicitly optimized for detecting the sun-induced fluorescence emitted by plants. It will allow consistent measurements around the O2-B (687 nm) and O2-A (760 nm) bands, related to the red and far-red fluorescence emission peaks respectively, the photochemical reflectance index, and the structural-chemical state variables of the canopy. The sun-induced fluorescence signal, overlapped to the surface reflected radiance, can be accurately retrieved by employing the powerful spectral fitting technique. In this framework, a set of fluorescence retrieval algorithms optimized for \{FLEX\} are proposed in this study. Two main retrieval approaches were investigated: i) the optimization of the spectral fitting for retrieving fluorescence at the oxygen absorption bands; ii) the extension of the spectral fitting to a broader spectral window to retrieve the full fluorescence spectrum in the range from 670 to 780 nm. The accuracy of the retrieval algorithms is assessed by employing atmosphere-surface radiative transfer simulations obtained by coupling \{SCOPE\} and \{MODTRAN5\} codes. The simulated dataset considers more realistic conditions because it includes directional effects, and the top-of-atmosphere radiance spectra are resampled to the current specifications of the \{FLuORescence\} Imaging Spectrometer (FLORIS) planned to serve as the primary instrument aboard FLEX. The retrieval accuracy obtained at the O2-A band is strongly affected by directional effects, and better performance is found in cases where directional effects are lower. However, the best performing algorithms tested provided similar performance, the \{RMSE\} (RRMSE) is 0.044 mW m− 2 sr− 1 nm− 1 (6.2%) at the O2-A band, 0.018 mW m− 2 sr− 1 nm− 1 (2.9%) at the O2-B band, and 6.225 mW m− 2 sr− 1 (6.4%) for the spectrally integrated fluorescence emission. The promising results achieved open new perspectives extending fluorescence studies not only in limited absorption bands, but its spectral behavior in relation to different plant species, photosynthetic rates and stress occurrences. "} 
}
@article{Vipparthi2015336,
title = {"Local Gabor maximum edge position octal patterns for image retrieval "},
journal = {"Neurocomputing "},
volume = {"167"},
number = {""},
pages = {"336 - 345"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.04.062"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215005317"},
author = {"Santosh Kumar Vipparthi and Subrahmanyam Murala and S.K. Nagar and Anil Balaji Gonde"},
keywords = {"Local binary patterns (LBP)", "Image retrieval", "Feature extraction", "Octal patterns "},
abstract = {"Abstract In this paper, a new coding scheme, local Gabor maximum edge position octal patterns (LGMEPOP) is proposed for content based image retrieval. The standard local binary pattern (LBP) collects the sign edge (binary code) information between the center pixel and its surrounding neighbors in an image. Further, the concept of \{LBP\} is extended to local maximum edge binary pattern (LMEBP) which collects the sign code (binary code) using the magnitude edges. These magnitude edges are collected based on the maximum edges between the center pixel and its surrounding neighbors in an image. In this paper, we propose a new feature descriptor, octal code which is coded based on the maximum edge positions (MEP) on Gabor responses. Specially, each pixel of every Gabor response gains eight edges based on the relationship between the referenced pixel and its neighbors. \{LGMEPOP\} utilizes the first three dominant (maximum) edge positions in an octal code generation. Then, these three maximum edge positions are encoded into three-eight octal numbers to produce the LGMEPOP. Further, the \{LGMEPOP\} is classified into two categories which are named as sign maximum edge position octal pattern (SMEPOP) and magnitude maximum edge position octal pattern (MMEPOP). The \{SMEPOP\} and \{MMEPOP\} are coded based on the sign and magnitudes of dominant edges respectively. The performance of the proposed method is tested on two benchmark databases. The results after being investigated show a significant improvement as compared to other existing methods (LBP and \{LBP\} variants) in terms of average retrieval precision (ARP) and average retrieval rate (ARR) on Corel-5000 and Corel-10000 databases. "} 
}
@article{Shang201550,
title = {"Dimension reduction with meta object-groups for efficient image retrieval "},
journal = {"Neurocomputing "},
volume = {"169"},
number = {""},
pages = {"50 - 54"},
year = {"2015"},
note = {"Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.08.105"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215006840"},
author = {"Shuo Shang and Jiajun Liu and Kun Zhao and Mingrui Yang and Kai Zheng and Ji-rong Wen"},
keywords = {"Dimension reduction", "Algorithm", "Clustering", "Image retrieval "},
abstract = {"Abstract Bag-of-Word (BoW) has been a prominent form for representing visual content such as image and video in recent years, as a result of its unique capability of characterizing visual content in a picture-level while still preserving part of the object-level information. However, it is also noticed that the dimensionality of BoW is usually as high as a few hundreds or even thousands, posing a serious challenge for any application that requires efficient processing. In this paper we propose a dimension reduction method called Meta object-Group Component (MGC) to tackle this problem. \{MGC\} aims at discovering the hidden relations of objects by examining the correlations between dimensions in the BoW features and maximizing the relations of the members in a meta object-group. By exchanging message passing between object-groups, meta object-groups are identified for a dataset. A meta object-group does not only contain visually similar objects, but also includes objects that are likely to co-occur with each other. As the meta object groups are obtained, group-specific dimension reduction is performed to obtain denser representations for efficient retrieval. We evaluate the framework on the NUS-Wide image dataset with approximately 270,000 images represented by BoW features, and demonstrate its advantage over existing method. "} 
}
@article{Shanmugavadivu2016719,
title = {"FOSIR: Fuzzy-Object-Shape for Image Retrieval applications "},
journal = {"Neurocomputing "},
volume = {"171"},
number = {""},
pages = {"719 - 735"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.07.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215009911"},
author = {"P. Shanmugavadivu and P. Sumathy and A. Vadivel"},
keywords = {"Image retrieval", "Fuzzy-shape", "Geometric features", "Approximate shapes "},
abstract = {"Abstract The object present in an image is an important content and can be used in \{CBIR\} applications. Identifying and representing the shape of the object is indeed complex due to the uncertainties in the boundary of the object of interest. In this paper, we have proposed Fuzzy-Object-Shape to capture the shape of the object of interest along with the degree of impreciseness in the boundary information. The Fuzzy-Object-Shape information is extracted from each object in an image. This information provides a measure of closeness of the object of interest with well-known shapes. For each object, the fuzzy membership values are calculated and considered as feature vector. A similarity measure is proposed for measuring the degree of closeness of objects present in both query and database images. The performance of the proposed approach is compared with some of the recently proposed similar approaches. Benchmark dataset and uncontrolled dataset are used for the experiments and the performance of the proposed approach is encouraging. "} 
}
@article{Schnaser2016495,
title = {"Posterior Stabilized Polyethylene Inserts in Total Knee Arthroplasty: A Retrieval Study Comparing Conventional to High-Flexion Designs "},
journal = {"The Journal of Arthroplasty "},
volume = {"31"},
number = {"2"},
pages = {"495 - 500"},
year = {"2016"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2015.09.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540315008256"},
author = {"Erik A. Schnaser and Marcella E. Elpers and Chelsea N. Koch and Stephen B. Haas and Geoffrey H. Westrich and Timothy M. Wright"},
keywords = {"knee arthroplasty", "high flexion", "polyethylene damage", "posterior stabilized", "retrieval analysis "},
abstract = {"AbstractBackground High-flex (HF) total knee arthroplasties are modified posterior-stabilized (PS) implants designed to accommodate greater flexion. Methods We examined differences between \{HF\} and \{PS\} retrieved tibial inserts with regard to polyethylene surface damage. Twenty \{HF\} inserts from each of 3 manufacturers were matched using patient demographics with 20 \{PS\} inserts from the same manufacturers. Ranges of motion between matched patients were not different. Results Based on subjective damage scores, no differences were detected between \{HF\} and \{PS\} groups. Differences were found, however, among manufacturers, consistent with design approaches taken for \{PS\} and \{HF\} implants. Conclusion In our series, high flexion did not influence damage, although this was likely influenced by the fact that few \{HF\} patients in our study had larger range of motions than their \{PS\} counterparts. "} 
}
@article{Sui201517,
title = {"Color image encryption by using Yang-Gu mixture amplitude-phase retrieval algorithm in gyrator transform domain and two-dimensional Sine logistic modulation map "},
journal = {"Optics and Lasers in Engineering "},
volume = {"75"},
number = {""},
pages = {"17 - 26"},
year = {"2015"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2015.06.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816615001396"},
author = {"Liansheng Sui and Benqing Liu and Qiang Wang and Ye Li and Junli Liang"},
keywords = {"Color image encryption", "Two-dimensional Sine logistic modulation map", "Yang-Gu mixture amplitude-phase retrieval algorithm "},
abstract = {"Abstract A color image encryption scheme is proposed based on Yang-Gu mixture amplitude-phase retrieval algorithm and two-coupled logistic map in gyrator transform domain. First, the color plaintext image is decomposed into red, green and blue components, which are scrambled individually by three random sequences generated by using the two-dimensional Sine logistic modulation map. Second, each scrambled component is encrypted into a real-valued function with stationary white noise distribution in the iterative amplitude-phase retrieval process in the gyrator transform domain, and then three obtained functions are considered as red, green and blue channels to form the color ciphertext image. Obviously, the ciphertext image is real-valued function and more convenient for storing and transmitting. In the encryption and decryption processes, the chaotic random phase mask generated based on logistic map is employed as the phase key, which means that only the initial values are used as private key and the cryptosystem has high convenience on key management. Meanwhile, the security of the cryptosystem is enhanced greatly because of high sensitivity of the private keys. Simulation results are presented to prove the security and robustness of the proposed scheme. "} 
}
@article{Liu2015429,
title = {"Graph-based characteristic view set extraction and matching for 3D model retrieval "},
journal = {"Information Sciences "},
volume = {"320"},
number = {""},
pages = {"429 - 442"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.04.042"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515003242"},
author = {"Anan Liu and Zhongyang Wang and Weizhi Nie and Yuting Su"},
keywords = {"3D model retrieval", "Characteristic view", "Graph clustering", "Graph matching", "Rayleigh quotient maximization "},
abstract = {"Abstract In recent times, multi-view representation of the 3D model has led to extensive research in view-based methods for 3D model retrieval. However, most approaches focus on feature extraction from 2D images while ignoring the spatial information of the 3D model. In order to improve the effectiveness of view-based methods on 3D model retrieval, this paper proposes a novel method for characteristic view extraction and similarity measurement. First, the graph clustering method is used for view grouping and the random-walk algorithm is applied to adaptively update the weight of each view. The spatial information of the 3D object is utilized to construct a view-graph model, thus enabling each characteristic view to represent the discriminative visual feature in terms of specific spatial context. Next, by considering the view set as a graph model, the similarity measurement of two models can be converted into a graph matching problem. This problem is solved by mathematically formulating it as a Rayleigh quotient maximization with affinity constraints for similarity measurement. Extensive comparison experiments were conducted on the popular ETH, NTU, PSB, and MV-RED 3D model datasets. The results demonstrate the superiority of the proposed method. "} 
}
@article{Lee20151,
title = {"An \{ERP\} study of plural attraction in attachment ambiguity resolution: Evidence for retrieval interference "},
journal = {"Journal of Neurolinguistics "},
volume = {"36"},
number = {""},
pages = {"1 - 16"},
year = {"2015"},
note = {""},
issn = {"0911-6044"},
doi = {"https://doi.org/10.1016/j.jneuroling.2015.04.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0911604415000214"},
author = {"Eun-Kyung Lee and Susan M. Garnsey"},
keywords = {"Attachment ambiguity", "Agreement", "Retrieval interference", "Comprehension", "ERPs "},
abstract = {"Abstract The memory retrieval processes involved in subject–verb agreement processing in sentence comprehension were examined by recording event-related brain potentials (ERPs) while people read temporarily ambiguous relative clause structures such as The reporter shocked the advisor(s) of the politician(s) who was/were at the meeting. When the relative clause verb was singular, forcing attachment to whichever of the nouns was also singular, the presence of a nearby plural attractor noun created greater interference in the process of retrieving the verb's subject from the memory representation of the sentence so far, revealed by an increased frontal negativity when the attractor noun was plural compared to when it was singular. Crucially, attraction effects did not interact with attachment type. The data suggest that plural attraction effects may arise from retrieval interference in grammatical sentences. The data also suggest that interference from plural attractor nouns in agreement processing is just another instance of the retrieval interference effects that arise whenever it becomes necessary to search the memory representation of a sentence so far to form dependency relationships among the words in the sentence. "} 
}
@article{Verma2015224,
title = {"Center symmetric local binary co-occurrence pattern for texture, face and bio-medical image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"32"},
number = {""},
pages = {"224 - 236"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001583"},
author = {"Manisha Verma and Balasubramanian Raman"},
keywords = {"Content based image retrieval", "Local binary pattern", "Center symmetric local binary pattern", keywords =Gray level co-occurrence matrix", "Feature vector", "Texture feature", "MIT VisTex texture database", "Brodatz texture database", "ORL face database", "OASIS \{MRI\} image database "},
abstract = {"Abstract Content based image retrieval is a common problem for a large image database. Many methods have been proposed for image retrieval for some particular type of datasets. In the proposed work, a new image retrieval technique has been introduced. This technique is useful for different kind of dataset. In the proposed method, center symmetric local binary pattern has been extracted from the original image to obtain the local information. Co-occurrence of pixel pairs in local pattern map have been observed in different directions and distances using gray level co-occurrence matrix. Earlier methods have utilized histogram to extract the frequency information of local pattern map but co-occurrence of pixel pairs is more robust than frequency of patterns. The proposed method is tested on three different category of images, i.e., texture, face and medical image database and compared with typical state-of-the-art local patterns. "} 
}
@article{Mirihanage2014241,
title = {"Retrieval of three-dimensional spatial information from fast in situ two-dimensional synchrotron radiography of solidification microstructure evolution "},
journal = {"Acta Materialia "},
volume = {"81"},
number = {""},
pages = {"241 - 247"},
year = {"2014"},
note = {""},
issn = {"1359-6454"},
doi = {"https://doi.org/10.1016/j.actamat.2014.08.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S135964541400617X"},
author = {"W.U. Mirihanage and K.V. Falch and I. Snigireva and A. Snigirev and Y.J. Li and L. Arnberg and R.H. Mathiesen"},
keywords = {"Solidification", "In-situ radiography", "Synchrotron radiation "},
abstract = {"Abstract In situ synchrotron X-ray radiography of columnar dendritic growth in Al–15 wt.% Cu–9 wt.% Si–0.015 wt.% Sr alloy has been carried out with the temporal and spatial resolutions of 100 ms and 0.65 μm, respectively. Two-dimensional (2-D) projected images have been processed and analysed to retrieve three-dimensional (3-D) spatial information on the growing dendrite network, through X-ray transmission contrast differences that account for solute-composition variations in the liquid and thickness variations in the growing dendrites. The analysis elucidates the way in which gravity-driven natural convection and solute sedimentation can result in solid fractions that deviate markedly from Scheil and Lever-rule-based models, which could alter mushy zone permeability. Furthermore, the ability to render 3-D spatial details may lead to future opportunities to use 2-D radiography in the development and validation of more sophisticated 3-D models of dendritic growth. "} 
}
@article{Srinivas2015880,
title = {"Content based medical image retrieval using dictionary learning "},
journal = {"Neurocomputing "},
volume = {"168"},
number = {""},
pages = {"880 - 895"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.05.036"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215006967"},
author = {"M. Srinivas and R. Ramu Naidu and C.S. Sastry and C. Krishna Mohan"},
keywords = {"Clustering", "Content based image retrieval", "Dictionary learning", "Rotation invariance", "Sparse representation", "K-SVD", "OMP "},
abstract = {"Abstract In this paper, a clustering method using dictionary learning is proposed to group large medical databases. An approach grouping similar images into clusters that are sparsely represented by the dictionaries and learning dictionaries simultaneously via K-SVD is proposed. A query image is matched with the existing dictionaries to identify the dictionary with the sparsest representation using an Orthogonal Matching Pursuit (OMP) algorithm. Then images in the cluster associated with this dictionary are compared using a similarity measure to retrieve images similar to the query image. The main features of the method are that it requires no training data and works well on the medical databases which are not restricted to specific context. The performance of the proposed method is examined on \{IRMA\} test image database. The experimental results demonstrate the efficacy of the proposed method in the retrieval of medical images. "} 
}
@article{Bai201515,
title = {"Neural shape codes for 3D model retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"65"},
number = {""},
pages = {"15 - 21"},
year = {"2015"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2015.06.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865515001944"},
author = {"Song Bai and Xiang Bai and Wenyu Liu and Fabio Roli"},
keywords = {"Shape retrieval", "3D model", "Depth view", "CNN "},
abstract = {"Abstract The paradigm of Convolutional Neural Network (CNN) has already shown its potential for many challenging applications of computer vision, such as image classification, object detection and action recognition. In this paper, the task of 3D model retrieval is addressed by exploiting such promising paradigm. However, 3D models are usually represented with a collection of orderless points, lines and surfaces in a three dimensional space, which makes it difficult to involve the operation of convolution, pooling, etc. Yet, we propose a practical and effective way for applying \{CNN\} to 3D model retrieval, by training the network with the depth projections of 3D model. This \{CNN\} is regarded as a generic feature extractor for depth image. With large amounts of training data, the learned feature, which is called Neural Shape Codes, can handle various deformation changes that exist in shape analysis. The reported experimental results on several 3D shape benchmark datasets show the superior performance of the proposed method. "} 
}
@article{Xu2017138,
title = {"Major advances in geostationary fire radiative power (FRP) retrieval over Asia and Australia stemming from use of Himarawi-8 \{AHI\} "},
journal = {"Remote Sensing of Environment "},
volume = {"193"},
number = {""},
pages = {"138 - 149"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.02.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300834"},
author = {"Weidong Xu and Martin J. Wooster and Takayuki Kaneko and Jiangping He and Tianran Zhang and Daniel Fisher"},
keywords = {"Biomass burning", "Fire radiative power", "Himawari-8", "Geostationary "},
abstract = {"Abstract Characterising the highly variable temporal dynamics of landscape-scale fire activity is best achieved using geostationary satellites, and the Himawari-8 Advanced Himawari Imager (AHI) now provides views of Asian and Australian fires at an unprecedented 10 min temporal resolution and 2 km nadir thermal channel spatial resolution. We here develop the first processing system to identify active fires and retrieve their fire radiative power (FRP) from \{AHI\} data, based on the geostationary Fire Thermal Anomaly (FTA) algorithm and \{FRP\} retrieval method originally developed for use with Meteosat \{SEVIRI\} over Africa and Europe. This scheme detects active fires covering as little as 10− 3 to 10− 4 of an \{AHI\} pixel, and we compare performance to the same scheme applied to data from the forerunner geostationary \{MTSAT\} imager and the FengYun-2 (FY-2) Stretched Visible and Infrared Spin Scan Radiometer (S-VISSR), and also to 1 km (at nadir) polar-orbiting \{MODIS\} active fire data. We find major benefits of Himawari-8 \{AHI\} over both \{MTSAT\} and FY-2, being able to detect a substantially greater proportion of fire activity and with little impact from sensor saturation. AHI-derived \{FRP\} retrievals of detected fires show a very strong agreement and a low (3 MW) bias with respect to near-simultaneous \{MODIS\} retrievals, though fires having \{FRP\} ≤ 40 \{MW\} are undercounted by \{AHI\} due to its 4 × larger pixel area (at nadir) than MODIS. Large parts of Asia are characterised by smaller/lower \{FRP\} fires associated with e.g. agricultural residue burning, meaning many are at or below this \{AHI\} minimum \{FRP\} detection limit, and during June 2015 \{AHI\} fails to detect around 66% of the hotspots that \{MODIS\} detects when both sensors view the same area simultaneously. However, \{AHI\} provides 144 observation opportunities per day compared to 4 typical observations from MODIS, and shows a low (8%) active fire detection error of commission. We demonstrate the unique value of the geostationary \{FRP\} retrievals made from \{AHI\} data for full fire diurnal cycle assessment and for Fire Radiative Energy (FRE) calculations. We conclude that these \{FRP\} data demonstrate major benefits for studies of active fires over Asia and Australia, and expect them to become an important component of the global geostationary active fire observation system. "} 
}
@article{Liu20161183,
title = {"Fine-residual \{VLAD\} for image retrieval "},
journal = {"Neurocomputing "},
volume = {"173, Part 3"},
number = {""},
pages = {"1183 - 1191"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.08.076"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215012965"},
author = {"Ziqiong Liu and Shengjin Wang and Qi Tian"},
keywords = {"VLAD", "Image retrieval", "Residual codebook", "Fine residual "},
abstract = {"Abstract This paper revisits the vector of locally aggregated descriptors (VLAD), which aggregates the residuals of local descriptors to their cluster centers. Since \{VLAD\} usually adopts a small-size codebook, the clusters are coarse and residuals not discriminative. To address this problem, this paper proposes to generate a number of residual codebooks descended from the original clusters. After quantizing local descriptors with these codebooks, we pool the resulting secondary residuals as well as the primary ones to obtain the fine residuals. We show that, with two-step aggregation, the fine-residual \{VLAD\} has the same dimension as the original. Experiments on two image search benchmarks confirm the improved discriminative power of our method: we observe consistent superiority to the baseline and competitive performance to the state-of-the-arts. "} 
}
@article{Montazer2015221,
title = {"An improved radial basis function neural network for object image retrieval "},
journal = {"Neurocomputing "},
volume = {"168"},
number = {""},
pages = {"221 - 233"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.05.104"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215008024"},
author = {"Gholam Ali Montazer and Davar Giveki"},
keywords = {"Radial basis function neural networks (RBFNNs)", "Improved Particle Swarm Optimization", "Optimum Steepest Descent (OSD)", "Object Image Retrieval "},
abstract = {"Abstract Radial Basis Function Neural Networks (RBFNNs) have been widely used for classification and function approximation tasks. Hence, it is worthy to try improving and developing new learning algorithms for \{RBFNNs\} in order to get better results. This paper presents a new learning method for RBFNNs. An improved algorithm for center adjustment of \{RBFNNs\} and a novel algorithm for width determination have been proposed to optimize the efficiency of the Optimum Steepest Decent (OSD) algorithm. To initialize the radial basis function units more accurately, a modified approach based on Particle Swarm Optimization (PSO) is presented. The obtained results show fast convergence speed, better and same network response in fewer train data which states the generalization power of the improved neural network. The Improved PSO–OSD and Three-phased PSO–OSD algorithms have been tested on five benchmark problems and the results have been compared. Finally, using the improved radial basis function neural network we propose a new method for object image retrieval. The images to be retrieved are object images that can be divided into foreground and background. Experimental results show that the proposed method is really promising and achieves high performance. "} 
}
@article{Verrelst2015273,
title = {"Optical remote sensing and the retrieval of terrestrial vegetation bio-geophysical properties – A review "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"108"},
number = {""},
pages = {"273 - 290"},
year = {"2015"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2015.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271615001422"},
author = {"Jochem Verrelst and Gustau Camps-Valls and Jordi Muñoz-Marí and Juan Pablo Rivera and Frank Veroustraete and Jan G.P.W. Clevers and José Moreno"},
keywords = {"Bio-geophysical variables", "Parametric", "Non-parametric", "Physical", "Hybrid", "Machine learning", "Operational variable retrieval "},
abstract = {"Abstract Forthcoming superspectral satellite missions dedicated to land monitoring, as well as planned imaging spectrometers, will unleash an unprecedented data stream. The processing requirements for such large data streams involve processing techniques enabling the spatio-temporally explicit quantification of vegetation properties. Typically retrieval must be accurate, robust and fast. Hence, there is a strict requirement to identify next-generation bio-geophysical variable retrieval algorithms which can be molded into an operational processing chain. This paper offers a review of state-of-the-art retrieval methods for quantitative terrestrial bio-geophysical variable extraction using optical remote sensing imagery. We can categorize these methods into (1) parametric regression, (2) non-parametric regression, (3) physically-based and (4) hybrid methods. Hybrid methods combine generic capabilities of physically-based methods with flexible and computationally efficient methods, typically non-parametric regression methods. A review of the theoretical basis of all these methods is given first and followed by published applications. This paper focusses on: (1) retrievability of bio-geophysical variables, (2) ability to generate multiple outputs, (3) possibilities for model transparency description, (4) mapping speed, and (5) possibilities for uncertainty retrieval. Finally, the prospects of implementing these methods into future processing chains for operational retrieval of vegetation properties are presented and discussed. "} 
}
@article{Liu20152629,
title = {"A chroma texture-based method in color image retrieval "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"126"},
number = {"20"},
pages = {"2629 - 2633"},
year = {"2015"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.06.058"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615005306"},
author = {"Menglin Liu and Li Yang and Yanmei Liang"},
keywords = {"Color image retrieval", "Chroma texture", "Ranking ratio", "Recall-precision curve "},
abstract = {"Abstract Texture is an important feature generally used in the content-based image retrieval (CBIR). Traditional methods of calculating texture features ignore the texture features caused by chroma differences. A new method of calculating chroma texture features is proposed in this paper. Large numbers of experiments were performed and proved that the chroma texture feature was a very important complement to the traditional luminance texture. The effectiveness of the image retrieval is improved significantly by combination of luminance texture and chroma texture with a lower-dimensional vector. The average ranking ratio is improved by 14.57%, and there is an obvious improvement of the average recall-precision curve. "} 
}
@article{Wiater20151915,
title = {"Elucidating trends in revision reverse total shoulder arthroplasty procedures: a retrieval study evaluating clinical, radiographic, and functional outcomes data "},
journal = {"Journal of Shoulder and Elbow Surgery "},
volume = {"24"},
number = {"12"},
pages = {"1915 - 1925"},
year = {"2015"},
note = {""},
issn = {"1058-2746"},
doi = {"https://doi.org/10.1016/j.jse.2015.06.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1058274615003079"},
author = {"Brett P. Wiater and Erin A. Baker and Meagan R. Salisbury and Denise M. Koueiter and Kevin C. Baker and Betsy M. Nolan and J. Michael Wiater"},
keywords = {"Reverse total shoulder arthroplasty", "implant retrieval", "implant damage", "scapular notching "},
abstract = {"Background The purpose of this study was to explore relationships between damage modes in explanted reverse total shoulder arthroplasty (RTSA) components, patient and radiographic risk factors, and functional data to elucidate trends in \{RTSA\} failure. Methods Fifty \{RTSA\} systems, retrieved from 44 patients, with 50 polyethylene (PE) liners, 30 glenospheres, 21 glenoid baseplates, 13 modular humeral metaphases, and 17 humeral stems, were examined for damage modes, including abrasion, burnishing, dishing, embedding, scratching, and pitting. \{PE\} liners were also analyzed for delamination and edge deformation. Charts were reviewed for patient, surgical, and functional data. Pre-revision radiographs were analyzed for scapular notching and loosening. Results Average term of implantation was 20 months (range, 0-81 months). Metallic components exhibited abrasion, burnishing, dishing, pitting, and scratching. \{PE\} liners displayed all damage modes. Damage was exhibited on 93% of glenospheres and 100% of \{PE\} liners. Of 29 aseptic shoulders, 13 showed evidence of scapular notching and 5 of humeral loosening. There was a moderate correlation between radiographically observed implant failure or dissociation and \{PE\} embedding (r = 0.496; P &lt; .001). There were weak and moderate correlations between scapular notching severity and \{PE\} dishing (r = 0.496; P = .006), embedding (r = 0.468; P = .010), and delamination (r = 0.384; P = .040). Conclusions To date, this is the largest series of retrieved \{RTSA\} components and the first to relate damage modes to radiographic and clinical data. Most damage was observed on the \{PE\} liners, on both the articular surface and rim, and glenosphere components. Correlation of retrieval findings with radiographic and clinical data may help establish predictors of prostheses at risk for failure. "} 
}
@article{NuñoMoral201481,
title = {"Sistemas de acceso y consulta en los diarios digitales españoles "},
journal = {"Investigación Bibliotecológica: Archivonomía, Bibliotecología e Información "},
volume = {"28"},
number = {"62"},
pages = {"81 - 99"},
year = {"2014"},
note = {""},
issn = {"0187-358X"},
doi = {"https://doi.org/10.1016/S0187-358X(14)72567-5"},
url = {"http://www.sciencedirect.com/science/article/pii/S0187358X14725675"},
author = {"María Victoria Nuño Moral"},
keywords = {"Sistemas de recuperación", "Periódicos digitales", "Recursos multimedia", "Archivos digitales", "Information retrieval systems", "Digital newspapers", "Multimedia resources", "Digital files "},
abstract = {"Resumen Se realiza el análisis descriptivo de las formas de acceso y sistemas de consulta con que cuenta el usuario en los diarios digitales españoles desde una doble perspectiva: por un lado señalar cuáles son las formas de acceso y la tipología documental o formatos que alberga cada uno de los sitios web analizados y, por el otro, exponer las características que presentan los respectivos sistemas de búsqueda. Para su realización se ha tomado como referencia la propuesta realizada por Guallar y Abadal (2009) y se ha elaborado una plantilla de trabajo basada en la evaluación descriptiva y comparativa de la muestra seleccionada. Abstract Researchers offer a descriptive analysis of search tools access paths available to readers of Spanish online newspapers. A twin approach is used: the first examines website in terms of access tool, their typology and the format; while the second approach provides a description of web search systems. The proposal put forth by Guallar and Abadal (2009) serves as a methodological framework of a working template for making descriptive and comparative evaluations of the sample under study. "} 
}
@article{Dong201566,
title = {"Similarity-based birdcall retrieval from environmental audio "},
journal = {"Ecological Informatics "},
volume = {"29, Part 1"},
number = {""},
pages = {"66 - 76"},
year = {"2015"},
note = {""},
issn = {"1574-9541"},
doi = {"https://doi.org/10.1016/j.ecoinf.2015.07.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574954115001168"},
author = {"Xueyan Dong and Michael Towsey and Anthony Truskinger and Mark Cottman-Fields and Jinglan Zhang and Paul Roe"},
keywords = {"Birdcall retrieval", "Environmental audio", "Ridge detection", "Spectral peak tracks "},
abstract = {"Abstract Automated digital recordings are useful for large-scale temporal and spatial environmental monitoring. An important research effort has been the automated classification of calling bird species. In this paper we examine a related task, retrieval of birdcalls from a database of audio recordings, similar to a user supplied query call. Such a retrieval task can sometimes be more useful than an automated classifier. We compare three approaches to similarity-based birdcall retrieval using spectral ridge features and two kinds of gradient features, structure tensor and the histogram of oriented gradients. The retrieval accuracy of our spectral ridge method is 94% compared to 82% for the structure tensor method and 90% for the histogram of gradients method. Additionally, this approach potentially offers a more compact representation and is more computationally efficient. "} 
}
@article{Feng2015104,
title = {"Global Correlation Descriptor: A novel image representation for image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"33"},
number = {""},
pages = {"104 - 114"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.09.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001637"},
author = {"Lin Feng and Jun Wu and Shenglan Liu and Hongwei Zhang"},
keywords = {"Image retrieval", "HSV color space", "Texton detection", "Global Correlation Descriptor (GCD)", "Global Correlation Vector (GCV)", "Global Correlation Vector (DGCV)", "Feature fusion", "Structure element correlation (SEC) "},
abstract = {"Abstract The image descriptors based on multi-features fusion have better performance than that based on simple feature in content-based image retrieval (CBIR). However, these methods still have some limitations: (1) the methods that define directly texture in color space put more emphasis on color than texture feature; (2) traditional descriptors based on histogram statistics disregard the spatial correlation between structure elements; (3) the descriptors based on structure element correlation (SEC) disregard the occurring probability of structure elements. To solve these problems, we propose a novel image descriptor, called Global Correlation Descriptor (GCD), to extract color and texture feature respectively so that these features have the same effect in CBIR. In addition, we propose Global Correlation Vector (GCV) and Directional Global Correlation Vector (DGCV) which can integrate the advantages of histogram statistics and \{SEC\} to characterize color and texture features respectively. Experimental results demonstrate that \{GCD\} is more robust and discriminative than other image descriptors in CBIR. "} 
}
@article{Bouagar2015149,
title = {"Discriminative outlines parts for shape retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"33"},
number = {""},
pages = {"149 - 164"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.08.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001790"},
author = {"Saliha Bouagar and Slimane Larabi"},
keywords = {"Discriminative", "Part", "Matching", "Partial", "Shape", "Retrieval", "Outline", "descriptor "},
abstract = {"Abstract In this paper we propose a new method for shape retrieval using only discriminative parts which are sufficient for the recognition of many objects and their classes. The discriminative outline shape is firstly determined by performing psycho-visual tests and then described with geometric attributes of high curvature points located along the outline. This obtained description is invariant to scale change, rotation, mirroring and deformation. To study the performance of our approach, global approach which deals with the whole contour and partial approach which is based on the discriminative part are compared. Experiments conducted on our data set and a selection of MPEG-7 dataset demonstrated the usefulness of this approach and the results obtained are presented and discussed. "} 
}
@article{Jian2015210,
title = {"Interactive image retrieval using constraints "},
journal = {"Neurocomputing "},
volume = {"161"},
number = {""},
pages = {"210 - 219"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.02.040"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215001897"},
author = {"Meng Jian and Cheolkon Jung and Yanbo Shen and Juan Liu"},
keywords = {"Active learning", "Adaptive constraint propagation", "Interactive image retrieval", "Pairwise constraints", "Relevance feedback", "Seed propagation "},
abstract = {"Abstract The proper use of constraints improves the data clustering performance. In this paper, we propose a novel interactive image retrieval framework using constraints. First, we extract the user׳s region of interest (ROI) from queries by simple user interaction using adaptive constraints-based seed propagation (ACSP), and obtain initial retrieval results based on the ROI. Then, we improve the retrieval results by active learning from the user׳s relevance feedback using ACSP. Since \{ACSP\} is very effective in propagating the user׳s interactive information of constraints by employing a kernel learning strategy, it successfully learns the correlation between low-level image features and high-level semantics from the \{ROI\} and relevance feedbacks. Experimental results demonstrate that the proposed framework remarkably improves the image retrieval performance by ACSP-based constraint propagation in terms of both effectiveness and efficiency. "} 
}
@article{Tolias20159,
title = {"Rotation and translation covariant match kernels for image retrieval "},
journal = {"Computer Vision and Image Understanding "},
volume = {"140"},
number = {""},
pages = {"9 - 20"},
year = {"2015"},
note = {""},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2015.06.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314215001356"},
author = {"Giorgos Tolias and Andrei Bursuc and Teddy Furon and Hervé Jégou"},
keywords = {"Image retrieval", "Geometry aware aggregation", "Match kernels", "Monomial embedding "},
abstract = {"Abstract Most image encodings achieve orientation invariance by aligning the patches to their dominant orientations and translation invariance by completely ignoring patch position or by max-pooling. Albeit successful, such choices introduce too much invariance because they do not guarantee that the patches are rotated or translated consistently. In this paper, we propose a geometric-aware aggregation strategy, which jointly encodes the local descriptors together with their patch dominant angle or location. The geometric attributes are encoded in a continuous manner by leveraging explicit feature maps. Our technique is compatible with generic match kernel formulation and can be employed along with several popular encoding methods, in particular Bag-of-Words, \{VLAD\} and the Fisher vector. The method is further combined with an efficient monomial embedding to provide a codebook-free method aggregating local descriptors into a single vector representation. Invariance is achieved by efficient similarity estimation of multiple rotations or translations, offered by a simple trigonometric polynomial. This strategy is effective for image search, as shown by experiments performed on standard benchmarks for image and particular object retrieval, namely Holidays and Oxford buildings. "} 
}
@article{Lyu2015373,
title = {"Evaluation of chlorophyll-a retrieval algorithms based on \{MERIS\} bands for optically varying eutrophic inland lakes "},
journal = {"Science of The Total Environment "},
volume = {"530–531"},
number = {""},
pages = {"373 - 382"},
year = {"2015"},
note = {""},
issn = {"0048-9697"},
doi = {"https://doi.org/10.1016/j.scitotenv.2015.05.115"},
url = {"http://www.sciencedirect.com/science/article/pii/S004896971530173X"},
author = {"Heng Lyu and Xiaojun Li and Yannan Wang and Qi Jin and Kai Cao and Qiao Wang and Yunmei Li"},
keywords = {"Chlorophyll-a concentration", "Retrieval algorithms", "MERIS bands", "Optical clustering", "Accuracy evaluation "},
abstract = {"Abstract Fourteen field campaigns were conducted in five inland lakes during different seasons between 2006 and 2013, and a total of 398 water samples with varying optical characteristics were collected. The characteristics were analyzed based on remote sensing reflectance, and an automatic cluster two-step method was applied for water classification. The inland waters could be clustered into three types, which we labeled water types I, \{II\} and III. From water types I to III, the effect of the phytoplankton on the optical characteristics gradually decreased. Four chlorophyll-a retrieval algorithms for Case \{II\} water, a two-band, three-band, four-band and \{SCI\} (Synthetic Chlorophyll Index) algorithm were evaluated for three water types based on the \{MERIS\} bands. Different \{MERIS\} bands were used for the three water types in each of the four algorithms. The four algorithms had different levels of retrieval accuracy for each water type, and no single algorithm could be successfully applied to all water types. For water types I and III, the three-band algorithm performed the best, while the four-band algorithm had the highest retrieval accuracy for water type II. However, the three-band algorithm is preferable to the two-band algorithm for turbid eutrophic inland waters. The \{SCI\} algorithm is recommended for highly turbid water with a higher concentration of total suspended solids. Our research indicates that the chlorophyll-a concentration retrieval by remote sensing for optically contrasted inland water requires a specific algorithm that is based on the optical characteristics of inland water bodies to obtain higher estimation accuracy. "} 
}
@article{Sui2015184,
title = {"Double-image encryption based on Yang-Gu mixture amplitude-phase retrieval algorithm and high dimension chaotic system in gyrator domain "},
journal = {"Optics Communications "},
volume = {"354"},
number = {""},
pages = {"184 - 196"},
year = {"2015"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2015.05.071"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401815004460"},
author = {"Liansheng Sui and Benqing Liu and Qiang Wang and Ye Li and Junli Liang"},
keywords = {"Double-image encryption", "High dimension chaotic system", "Yang-Gu mixture amplitude-phase retrieval algorithm "},
abstract = {"Abstract A double-image encryption scheme is proposed based on Yang-Gu mixture amplitude-phase retrieval algorithm and high dimension chaotic system in gyrator transform domain, in which three chaotic random sequences are generated by using Chen system. First, an enlarged image constituted with two plaintext images is scrambled by using the first two sequences, and then separated into two new interim images. Second, one interim image is converted to the private phase key with the help of the third sequence, which is modulated by a random phase key generated based on logistic map. Based on this private phase key, another interim image is converted to the ciphertext with white noise distribution in the Yang-Gu amplitude-phase retrieval process. In the process of encryption and decryption, the images both in spatial domain and gyrator domain are nonlinear and disorder by using high dimension chaotic system. Moreover, the ciphertext image is only a real-valued function which is more convenient for storing and transmitting, and the security of the proposed encryption scheme is enhanced greatly because of high sensitivity of initial values of Chen system and rotation angle of gyrator transform. Extensive cryptanalysis and simulation results have demonstrated the security, validity and feasibility of the propose encryption scheme. "} 
}
@article{Li2016628,
title = {"Comparison between the \{ESFT\} and \{LBL\} simulation with enhanced \{SCIATRAN\} of orbital \{CO2\} retrieval for High-resolution Satellite "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"2"},
pages = {"628 - 633"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.10.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615013716"},
author = {"Yanfen Li and Chunmin Zhang and Dongdong Liu and Jie Chen and Piao Rong"},
keywords = {"Medium-resolution Satellite", "High-resolution Satellite", "LBL", "ESFT", "orbital \{CO2\} retrieval "},
abstract = {"Abstract The enhanced radiative transfer model \{SCIATRAN\} completes the simulation from the single point to the orbital data. There are 69 points locating at a global scale. The \{ESFT\} and \{LBL\} modes are implemented in the enhanced \{SCIATRAN\} for Medium-resolution Satellite (SCIAMACHY) and High-resolution Satellite simulations. A comparison of their spectra, accuracy and speed has been undertaken. For SCIAMACHY, the relative errors of \{O2\} A-band (755–775 nm) and \{WCO2\} band (1560–1680 nm) for \{ESFT\} and \{LBL\} (same sampling) are far less than 1%. The speed of \{ESFT\} mode is about 1.17 times faster than \{LBL\} mode for \{O2\} A-band, about 5.24 times faster for \{WCO2\} band. For High-resolution Satellite, the relative errors of \{O2\} A-band and \{CO2\} bands for \{ESFT\} and \{LBL\} are much less than 1%, and the speed increases to about 1.09 times for \{O2\} A-band (759–769 nm) than \{LBL\} mode, about 3.83 times for \{WCO2\} band (1568–1583 nm) than \{LBL\} mode. But the speed of \{LBL\} mode increases to about 47.55 times for \{SCO2\} band (2043–2058 nm) than \{ESFT\} mode. This study provides a theoretical guide for the subsequent inversion of \{CO2\} column concentration for High-resolution Satellite. "} 
}
@article{Islam201521,
title = {"Synergistic multi-sensor and multi-frequency retrieval of cloud ice water path constrained by CloudSat collocations "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"161"},
number = {""},
pages = {"21 - 34"},
year = {"2015"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2015.03.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407315001247"},
author = {"Tanvir Islam and Prashant K. Srivastava"},
keywords = {"Satellite cloud retrieval", "Passive microwave radiometry", "Infrared and optical", "Measurements synergy", "Cloud profiling radar (CPR)", "Global precipitation measurement (GPM) "},
abstract = {"Abstract The cloud ice water path (IWP) is one of the major parameters that have a strong influence on earth׳s radiation budget. Onboard satellite sensors are recognized as valuable tools to measure the \{IWP\} in a global scale. Albeit, active sensors such as the Cloud Profiling Radar (CPR) onboard the CloudSat satellite has better capability to measure the ice water content profile, thus, its vertical integral, IWP, than any passive microwave (MW) or infrared (IR) sensors. In this study, we investigate the retrieval of \{IWP\} from \{MW\} and \{IR\} sensors, including AMSU-A, MHS, and \{HIRS\} instruments on-board the \{N19\} satellite, such that the retrieval is consistent with the CloudSat \{IWP\} estimates. This is achieved through the collocations between the passive satellite measurements and CloudSat scenes. Potential benefit of synergistic multi-sensor multi-frequency retrieval is investigated. Two modeling approaches are explored for the \{IWP\} retrieval – generalized linear model (GLM) and neural network (NN). The investigation has been carried out over both ocean and land surface types. The MW/IR synergy is found to be retrieved more accurate \{IWP\} than the individual AMSU-A, MHS, or \{HIRS\} measurements. Both \{GLM\} and \{NN\} approaches have been able to exploit the synergistic retrievals. "} 
}
@article{Cao2015180,
title = {"Robust latent semantic exploration for image retrieval in social media "},
journal = {"Neurocomputing "},
volume = {"169"},
number = {""},
pages = {"180 - 184"},
year = {"2015"},
note = {"Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.02.082"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215006682"},
author = {"Liujuan Cao and Fanglin Wang"},
keywords = {"Image retrieval", "l 2 , 1 norm", "Word-to-vector "},
abstract = {"Abstract With the speedy development of social media, more and more multimedia data are generated by users with tags associated. The tag information provides the extra cue to link multimedia data in addition to the multimedia content itself. However, the manually added tags are always with noise and not correct enough. Moreover, the semantically similar tags exist massively but cannot be accounted for well. This paper proposes a new algorithm to robustly combine multimedia content and associated tags by mining the latent semantic which takes into account the semantically similar tags. The l 2 , 1 norm is proposed to employ in latent semantic indexing for a more robust latent space, and a word-to-vector based clustering method is proposed to address the massive tags with similar meaning. The experiments on extensive data demonstrate the proposed method. Compared to the existing latent semantic based methods, the algorithm proposed a more robust model to deal with noise. "} 
}
@article{Brown20168,
title = {"Green’s function retrieval in a field of random water waves "},
journal = {"Wave Motion "},
volume = {"60"},
number = {""},
pages = {"8 - 19"},
year = {"2016"},
note = {""},
issn = {"0165-2125"},
doi = {"https://doi.org/10.1016/j.wavemoti.2015.08.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165212515001171"},
author = {"Michael G. Brown and Chuntao Lu"},
keywords = {"Green’s function retrieval", "Random wave interferometry", "Random wave field cross-correlations", "Water waves "},
abstract = {"Abstract It has recently been demonstrated using a variety of wave types that cross-correlating time series of apparently random waves measured at two locations yields an estimate of the Green’s function that describes the wave field generated at one of those locations and measured at the other. This procedure can be described as random wave interferometry. In this paper random surface gravity wave interferometry is described theoretically, demonstrated using numerical simulations, and investigated experimentally using both wavetank measurements and ocean wave measurements. Simulations and wavetank measurements are in good agreement with theoretical predictions, but the ocean-measurement-based cross correlations do not yield the predicted structure. Possible explanations are discussed. "} 
}
@article{Abel201540,
title = {"Selective memory retrieval in social groups: When silence is golden and when it is not "},
journal = {"Cognition "},
volume = {"140"},
number = {""},
pages = {"40 - 48"},
year = {"2015"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2015.03.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010027715000591"},
author = {"Magdalena Abel and Karl-Heinz T. Bäuml"},
keywords = {"Episodic memory", "Retrieval", "Social recall", "Forgetting", "Context reactivation "},
abstract = {"Abstract Previous research has shown that the selective remembering of a speaker and the resulting silences can cause forgetting of related, but unmentioned information by a listener (Cuc, Koppel, &amp; Hirst, 2007). Guided by more recent work that demonstrated both detrimental and beneficial effects of selective memory retrieval in individuals, the present research explored the effects of selective remembering in social groups when access to the encoding context at retrieval was maintained or impaired. In each of three experiments, selective retrieval by the speaker impaired recall of the listener when access to the encoding context was maintained, but it improved recall of the listener when context access was impaired. The results suggest the existence of two faces of selective memory retrieval in social groups, with a detrimental face when the encoding context is still active at retrieval and a beneficial face when it is not. The role of silence in social recall thus seems to be more complex than was indicated in prior work, and mnemonic silences on the part of a speaker can be “golden” for the memories of a listener under some circumstances, but not be “golden” under others. "} 
}
@article{AlYaari2017257,
title = {"Evaluating soil moisture retrievals from ESA's \{SMOS\} and NASA's \{SMAP\} brightness temperature datasets "},
journal = {"Remote Sensing of Environment "},
volume = {"193"},
number = {""},
pages = {"257 - 273"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.03.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717301013"},
author = {"A. Al-Yaari and J.-P. Wigneron and Y. Kerr and N. Rodriguez-Fernandez and P.E. O'Neill and T.J. Jackson and G.J.M. De Lannoy and A. Al Bitar and A. Mialon and P. Richaume and J.P. Walker and A. Mahmoodi and S. Yueh"},
keywords = {"SMOS", "SMAP", "Soil moisture", "Statistical regression "},
abstract = {"Abstract Two satellites are currently monitoring surface soil moisture (SM) using L-band observations: \{SMOS\} (Soil Moisture and Ocean Salinity), a joint \{ESA\} (European Space Agency), \{CNES\} (Centre national d'études spatiales), and \{CDTI\} (the Spanish government agency with responsibility for space) satellite launched on November 2, 2009 and \{SMAP\} (Soil Moisture Active Passive), a National Aeronautics and Space Administration (NASA) satellite successfully launched in January 2015. In this study, we used a multilinear regression approach to retrieve \{SM\} from \{SMAP\} data to create a global dataset of SM, which is consistent with \{SM\} data retrieved from SMOS. This was achieved by calibrating coefficients of the regression model using the \{CATDS\} (Centre Aval de Traitement des Données) \{SMOS\} Level 3 \{SM\} and the horizontally and vertically polarized brightness temperatures (TB) at 40° incidence angle, over the 2013–2014 period. Next, this model was applied to \{SMAP\} \{L3\} \{TB\} data from Apr 2015 to Jul 2016. The retrieved \{SM\} from \{SMAP\} (referred to here as SMAP_Reg) was compared to: (i) the operational \{SMAP\} \{L3\} \{SM\} (SMAP_SCA), retrieved using the baseline Single Channel retrieval Algorithm (SCA); and (ii) the operational \{SMOSL3\} SM, derived from the multiangular inversion of the L-MEB model (L-MEB algorithm) (SMOSL3). This inter-comparison was made against in situ soil moisture measurements from &gt; 400 sites spread over the globe, which are used here as a reference soil moisture dataset. The in situ observations were obtained from the International Soil Moisture Network (ISMN; https://ismn.geo.tuwien.ac.at/) in North of America (PBO_H2O, SCAN, SNOTEL, iRON, and USCRN), in Australia (Oznet), Africa (DAHRA), and in Europe (REMEDHUS, SMOSMANIA, FMI, and RSMN). The agreement was analyzed in terms of four classical statistical criteria: Root Mean Squared Error (RMSE), Bias, Unbiased \{RMSE\} (UnbRMSE), and correlation coefficient (R). Results of the comparison of these various products with in situ observations show that the performance of both \{SMAP\} products i.e. SMAP_SCA and SMAP_Reg is similar and marginally better to that of the \{SMOSL3\} product particularly over the PBO_H2O, SCAN, and \{USCRN\} sites. However, \{SMOSL3\} \{SM\} was closer to the in situ observations over the \{DAHRA\} and Oznet sites. We found that the correlation between all three datasets and in situ measurements is best (R &gt; 0.80) over the Oznet sites and worst (R = 0.58) over the \{SNOTEL\} sites for SMAP_SCA and over the \{DAHRA\} and \{SMOSMANIA\} sites (R = 0.51 and R = 0.45 for SMAP_Reg and SMOSL3, respectively). The Bias values showed that all products are generally dry, except over RSMN, DAHRA, and Oznet (and \{FMI\} for SMAP_SCA). Finally, our analysis provided interesting insights that can be useful to improve the consistency between \{SMAP\} and \{SMOS\} datasets. "} 
}
@article{Ramalingam2015744,
title = {"Fast retrieval of hidden data using enhanced hidden Markov model in video steganography "},
journal = {"Applied Soft Computing "},
volume = {"34"},
number = {""},
pages = {"744 - 757"},
year = {"2015"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2015.05.040"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494615003567"},
author = {"Mritha Ramalingam and Nor Ashidi Mat Isa"},
keywords = {"Video steganography", "Data hiding", "Enhanced hidden Markov model", "Conditional states", "Fast data retrieval "},
abstract = {"Abstract In the digital world, secure data communication has an important role in mass media and Internet technology. With the increase in modern malicious technologies, confidential data are exposed at a greater risk during data communication. For secured communication, recent technologies and the Internet have introduced steganography, a new way to hide data. Steganography is the growing practice of concealing data in multimedia files for secure data transfer. Nowadays, videos are more commonly chosen as cover media than other multimedia files because of the moving sequence of images and audio files. Despite its popularity, video steganography faces a significant challenge, which is a lack of a fast retrieval system of the hidden data. This study proposes a novel video steganography technique in which an enhanced hidden Markov model (EHMM) is employed to improve the speed of retrieving hidden data. \{EHMM\} mathematical formulations are used to enhance the speed of embedding and extracting secret data. The data embedding and retrieving operations were performed using the conditional states and the state transition dynamics between the video frames. The proposed \{EHMM\} is extensively evaluated using three benchmark functions, and experimental evaluations are conducted to test the speed of data retrieval using differently sized cover-videos. Results indicate that the proposed \{EHMM\} yields better results by reducing the data hiding time by 3–50%, improving the data retrieval rate by 22–77% with a minimum computational cost of 20–91%, and improving the security by 4–77% compared with state-of-the-art methods. "} 
}
@article{Kush201518,
title = {"Relation-sensitive retrieval: Evidence from bound variable pronouns "},
journal = {"Journal of Memory and Language "},
volume = {"82"},
number = {""},
pages = {"18 - 40"},
year = {"2015"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2015.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X15000224"},
author = {"Dave Kush and Jeffrey Lidz and Colin Phillips"},
keywords = {"Pronouns", "Binding", "C-command", "Memory retrieval", "Sentence processing", "Quantifiers "},
abstract = {"Abstract Formal grammatical theories make extensive use of syntactic relations (e.g. c-command, Reinhart, 1983) in the description of constraints on antecedent-anaphor dependencies. Recent research has motivated a model of processing that exploits a cue-based retrieval mechanism in content-addressable memory (e.g. Lewis, Vasishth, &amp; Van Dyke, 2006) in which item-to-item syntactic relations such as c-command are difficult to use as retrieval cues. As such, the c-command constraints of formal grammars are predicted to be poorly implemented by the retrieval mechanism. We tested whether memory access mechanisms are able to exploit relational information by investigating the processing of bound variable pronouns, a form of anaphoric dependency that imposes a c-command restriction on antecedent-pronoun relations. A quantificational \{NP\} (QP, e.g., no janitor) must c-command a pronoun in order to bind it. We contrasted the retrieval of \{QPs\} with the retrieval of referential \{NPs\} (e.g. the janitor), which can co-refer with a pronoun in the absence of c-command. In three off-line judgment studies and two eye-tracking studies, we show that referential \{NPs\} are easily accessed as antecedents, irrespective of whether they c-command the pronoun, but that quantificational \{NPs\} are accessed as antecedents only when they c-command the pronoun. These results are unexpected under theories that hold that retrieval exclusively uses a limited set of content features as retrieval cues. Our results suggest either that memory access mechanisms can make use of relational information as a guide for retrieval, or that the set of features that is used to encode syntactic relations in memory must be enriched. "} 
}
@article{Kappel201549,
title = {"Error analysis for retrieval of Venus׳ \{IR\} surface emissivity from VIRTIS/VEX measurements "},
journal = {"Planetary and Space Science "},
volume = {"113–114"},
number = {""},
pages = {"49 - 65"},
year = {"2015"},
note = {"SI:Exploration of Venus "},
issn = {"0032-0633"},
doi = {"https://doi.org/10.1016/j.pss.2015.01.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S003206331500015X"},
author = {"David Kappel and Rainer Haus and Gabriele Arnold"},
keywords = {"Venus", "Surface emissivity", "Retrieval error", "VIRTIS "},
abstract = {"Abstract Venus׳ surface emissivity data in the infrared can serve to explore the planet׳s geology. The only global data with high spectral, spatial, and temporal resolution and coverage at present is supplied by nightside emission measurements acquired by the Visible and InfraRed Thermal Imaging Spectrometer VIRTIS-M-IR ( 1.0 – 5.1 μ m ) aboard ESA׳s Venus Express. A radiative transfer simulation and a retrieval algorithm can be used to determine surface emissivity in the nightside spectral transparency windows located at 1.02, 1.10, and 1.18 μ m . To obtain satisfactory fits to measured spectra, the retrieval pipeline also determines auxiliary parameters describing cloud properties from a certain spectral range. But spectral information content is limited, and emissivity is difficult to retrieve due to strong interferences from other parameters. Based on a selection of representative synthetic VIRTIS-M-IR spectra in the range 1.0 – 2.3 μ m , this paper investigates emissivity retrieval errors that can be caused by interferences of atmospheric and surface parameters, by measurement noise, and by a priori data, and which retrieval pipeline leads to minimal errors. Retrieval of emissivity from a single spectrum is shown to fail due to extremely large errors, although the fits to the reference spectra are very good. Neglecting geologic activity, it is suggested to apply a multi-spectrum retrieval technique to retrieve emissivity relative to an initial value as a parameter that is common to several measured spectra that cover the same surface bin. Retrieved emissivity maps of targets with limited extension (a few thousand km) are then additively renormalized to remove spatially large scale deviations from the true emissivity map that are due to spatially slowly varying interfering parameters. Corresponding multi-spectrum retrieval errors are estimated by a statistical scaling of the single-spectrum retrieval errors and are listed for 25 measurement repetitions. For the best of the studied retrieval pipelines, temporally varying interfering atmospheric parameters (cloud parameters, minor gas abundances) contribute errors in the order of 3%–10% of the true emissivity, depending on the surface window, the reference spectrum, and assuming statistical independence of the parameters. Temporally constant interfering parameters that spatially vary on a scale of 100 km (surface elevation, interfering emissivities) add 9%–16%. Measurement noise with a standard deviation of 10 − 4 W / ( m 2 sr μ m ) leads to additional 1%–4%. Reasonable modifications of a priori mean values have negligible impacts. Retrieved maps are most reliable at 1.02 μ m . There is an overall tendency for better results for cases with small cloud opacity, high surface elevation, high emissivity, and small observation angle, but this depends on the emissivity window, retrieval pipeline, and measurement repetition number. Calibration, preprocessing, and simulation errors can lead to additional errors. Based on the presented results, a subsequent paper will discuss emissivity data retrieval for a selected surface target. "} 
}
@article{Ma20151,
title = {"Cost and accuracy aware scientific workflow retrieval based on distance measure "},
journal = {"Information Sciences "},
volume = {"314"},
number = {""},
pages = {"1 - 13"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.03.055"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515002200"},
author = {"Yinglong Ma and Moyi Shi and Jun Wei"},
keywords = {"Scientific workflow", "Workflow retrieval", "Distance measure", "Matrix representation "},
abstract = {"Abstract Scientific workflows have been applied in many scientific areas with the large amount of complex data computation tasks such as life science, astronomy and earth science, etc. However, most existing approaches for scientific workflow retrieval neglect some constraints of quality of services (QoS) that users are really concerned about, and fail to allow users to express and retrieve scientific workflows with arbitrary constraints based on graph structures of workflows. In this paper, we propose a novel approach for scientific workflow retrieval with cost constraints. We present a graph representation model called Cost Constrained Graph (CCG) for representing scientific workflows with cost constraints. A distance measure is defined for accurate workflow retrieval. The \{CCGs\} representing candidate workflows can be ranked by comparing the similarity among them. We also theoretically prove that this measure satisfies all the four properties of distance. Furthermore, we develop a prototype system for editing, assignment of weights, and automatic similarity computation of workflows. At last, the related experiments are made to demonstrate the usefulness and efficiency of workflow retrieval based on our approach. "} 
}
@article{Khemchandani2015444,
title = {"Color image classification and retrieval through ternary decision structure based multi-category \{TWSVM\} "},
journal = {"Neurocomputing "},
volume = {"165"},
number = {""},
pages = {"444 - 455"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.03.074"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215004427"},
author = {"Reshma Khemchandani and Pooja Saigal"},
keywords = {"Twin support vector machines", "Multi-category image classification and retrieval", "Ternary decision structure", "Cross validation", "Machine learning "},
abstract = {"Abstract In this paper, we propose Ternary Decision Structure based multi-category twin support vector machines (TDS-TWSVM) classifier. Twin support vector machines (TWSVM) formulation deals with finding non-parallel plane classifier which is obtained by solving two related Quadratic Programming Problems (QPPs). The proposed TDS-TWSVM classifier is an extension of \{TWSVM\} so as to handle multi-class data and is more efficient in terms of training and testing time of classifiers. For a K-class problem, a balanced ternary structure requires ⌈ log 3 K ⌉ comparisons for evaluating a test sample. The experimental results depict that TDS-TWSVM outperforms One-Against-All \{TWSVM\} (OAA-TWSVM) and binary tree-based \{TWSVM\} (TB-TWSVM) in terms of classification accuracy. We have shown the efficacy of the proposed algorithm via image classification and further for image retrieval. Experiments are performed on a varied range of benchmark image databases with 5-fold cross validation. "} 
}
@article{Mack2015211,
title = {"What do pauses in narrative production reveal about the nature of word retrieval deficits in PPA? "},
journal = {"Neuropsychologia "},
volume = {"77"},
number = {""},
pages = {"211 - 222"},
year = {"2015"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.08.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215301354"},
author = {"Jennifer E. Mack and Sarah D. Chandler and Aya Meltzer-Asscher and Emily Rogalski and Sandra Weintraub and M.-Marsel Mesulam and Cynthia K. Thompson"},
keywords = {"Primary progressive aphasia", "Narrative analysis", "Word retrieval deficits", "Word class effects", "Brain–behavior relationship "},
abstract = {"Abstract Naming and word-retrieval deficits, which are common characteristics of primary progressive aphasia (PPA), differentially affect production across word classes (e.g., nouns, verbs) in some patients. Individuals with the agrammatic variant (PPA-G) often show greater difficulty producing verbs whereas those with the semantic variant (PPA-S) show greater noun deficits and those with logopenic \{PPA\} (PPA-L) evince no clear-cut differences in production of the two word classes. To determine the source of these production patterns, the present study examined word-finding pauses as conditioned by lexical variables (i.e., word class, frequency, length) in narrative speech samples of individuals with PPA-S (n=12), PPA-G (n=12), PPA-L (n=11), and cognitively healthy controls (n=12). We also examined the relation between pause distribution and cortical atrophy (i.e., cortical thickness) in nine left hemisphere regions of interest (ROIs) linked to word production. Results showed higher overall pause rates for \{PPA\} compared to unimpaired controls; however, greater naming severity was not associated with increased pause rate. Across all groups, more pauses were produced before lower vs. higher frequency words, with no independent effects of word length after controlling for frequency. With regard to word class, the PPA-L group showed a higher rate of pauses prior to production of nouns compared to verbs, consistent with noun-retrieval deficits arising at the lemma level of word production. Those with PPA-G and PPA-S, like controls, produced similar pause rates across word classes; however, lexical simplification (i.e., production of higher-frequency and/or shorter words) was evident in the more-impaired word class: nouns for PPA-S and verbs for PPA-G. These patterns are consistent with conceptual and/or lemma-level impairments for PPA-S, predominantly affecting objects/nouns, and a lemma-level verb-retrieval deficit for PPA-G, with a concomitant impairment in phonological encoding and articulation affecting overall pause rates. The greater tendency to pause before nouns was correlated with atrophy in the left precentral gyrus, inferior frontal gyrus and inferior parietal lobule, whereas the greater tendency to pause before less frequent and longer words was associated with atrophy in left precentral and inferior parietal regions. "} 
}
@article{Woodcock2015152,
title = {"The dorsal prefrontal and dorsal anterior cingulate cortices exert complementary network signatures during encoding and retrieval in associative memory "},
journal = {"Behavioural Brain Research "},
volume = {"290"},
number = {""},
pages = {"152 - 160"},
year = {"2015"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2015.04.050"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432815003058"},
author = {"Eric A. Woodcock and Richard White and Vaibhav A. Diwadkar"},
keywords = {"Associative memory", "Cognitive control", "Psychophysiological interaction", "Memory encoding", "Memory retrieval "},
abstract = {"Abstract Cognitive control includes processes that facilitate execution of effortful cognitive tasks, including associative memory. Regions implicated in cognitive control during associative memory include the dorsal prefrontal (dPFC) and dorsal anterior cingulate cortex (dACC). Here we investigated the relative degrees of network-related interactions originating in the dPFC and dACC during oscillating phases of associative memory: encoding and cued retrieval. Volunteers completed an established object-location associative memory paradigm during fMRI. Psychophysiological interactions modeled modulatory network interactions from the dPFC and dACC during memory encoding and retrieval. Results were evaluated in second level analyses of variance with seed region and memory process as factors. Each seed exerted differentiable modulatory effects during encoding and retrieval. The dACC exhibited greater modulation (than the dPFC) on the fusiform and parahippocampal gyrus during encoding, while the dPFC exhibited greater modulation (than the dACC) on the fusiform, hippocampus, dPFC and basal ganglia. During retrieval, the dPFC exhibited greater modulation (than the dACC) on the parahippocampal gyrus, hippocampus, superior parietal lobule, and dPFC. The most notable finding was a seed by process interaction indicating that the dACC and the dPFC exerted complementary modulatory control on the hippocampus during each of the associative memory processes. These results provide evidence for differentiable, yet complementary, control-related modulation by the dACC and dPFC, while establishing the primacy of dPFC in exerting network control during both associative memory phases. Our approach and findings are relevant for understanding basic processes in human memory and psychiatric disorders that impact associative memory-related networks. "} 
}
@article{Wolanin2015243,
title = {"Global retrieval of marine and terrestrial chlorophyll fluorescence at its red peak using hyperspectral top of atmosphere radiance measurements: Feasibility study and first results "},
journal = {"Remote Sensing of Environment "},
volume = {"166"},
number = {""},
pages = {"243 - 261"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.05.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715300183"},
author = {"A. Wolanin and V.V. Rozanov and T. Dinter and S. Noël and M. Vountas and J.P. Burrows and A. Bracher"},
keywords = {"Sun-induced fluorescence", "Retrieval", "SCIAMACHY", "GOME-2", "Fraunhofer-line approach", "Hyperspectral remote sensing", "Ocean–atmosphere coupled radiative transfer "},
abstract = {"Abstract Chlorophyll fluorescence is directly linked to the physiology of phytoplankton or plants. Here, we present a new satellite remote sensing approach to retrieve chlorophyll fluorescence at its red peak (~ 685 nm) by using measurements from the hyperspectral instruments \{SCanning\} Imaging Absorption SpectroMeter for Atmospheric \{CHartographY\} (SCIAMACHY) and Global Ozone Monitoring Experiment-2 (GOME-2). This method, which is based on the Differential Optical Absorption Spectroscopy (DOAS) technique, was used to exploit narrow spectral structures resulting from the filling-in of the Fraunhofer Fe I line, which originates from fluorescence. The reference spectra for chlorophyll fluorescence were calculated by the coupled ocean–atmosphere radiative transfer model SCIATRAN. We compared our results on marine chlorophyll fluorescence observations with the \{MODIS\} Terra normalized Fluorescence Line Height (nFLH) product for the average of years 2003–2011 and year 2009. Our method also enables the retrieval of chlorophyll fluorescence above land vegetation scenes. The results for the fluorescence observed above terrestrial vegetation for July and December 2009 were compared to \{MODIS\} Enhanced Vegetation Index (EVI). The comparisons show good spatial agreement between different retrievals providing evidence for the good performance of our algorithm. The method presented is generic and can be applied to other hyperspectral instruments in the future. Having established the retrieval technique, extensive studies of chlorophyll fluorescence will improve global knowledge on physiology and photosynthetic efficiency, in both the marine and terrestrial realms, and its dependence on environmental factors. "} 
}
@article{Chary201523,
title = {"Paternal retrievals increase testosterone levels in both male and female California mouse (Peromyscus californicus) offspring "},
journal = {"Hormones and Behavior "},
volume = {"73"},
number = {""},
pages = {"23 - 29"},
year = {"2015"},
note = {""},
issn = {"0018-506X"},
doi = {"https://doi.org/10.1016/j.yhbeh.2015.05.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0018506X15001014"},
author = {"Mamatha C. Chary and Jayson P. Cruz and Massimo Bardi and Elizabeth A. Becker"},
keywords = {"Paternal retrievals", "Testosterone", "Paternal behavior", "Peromyscus californicus "},
abstract = {"Abstract The importance of maternal care on offspring development has received considerable attention, although more recently, researchers have begun to focus on the significance of paternal contributions. In the monogamous and bi-parental California mouse, fathers provide high levels of care, and therefore serve as a model system for studying paternal effects on behavior and underlying neuroendocrine mechanisms. Paternal retrievals in this species influence long term changes in brain (expression of arginine vasopressin—AVP) and behavior (aggression and parenting) in adult male offspring. Further, paternal retrievals induce a transient increase in testosterone (T) in male offspring, which is thought to mediate the relationship between paternal retrievals and \{AVP\} expression. Although the father–son relationship has been well characterized, few studies have examined father–daughter interactions. In California mice, paternal retrievals increase aggression in female offspring. Although T has been implicated in the regulation of female aggression, it remains unclear whether T may underlie long-term changes in female offspring aggression in response to paternal retrievals. In the current study, we examined the influence of paternal retrievals on T in both male and female offspring. Retrievals were manipulated experimentally by displacement of the pup and trunk blood was collected from retrieved, non-retrieved, and non-manipulated (baseline) pups. We found that fathers expressed similar levels of retrievals towards sons and daughters, and that T levels were elevated in retrieved, as compared to non-retrieved offspring. Similar to what has been previously described in male offspring and replicated here, female offspring that were retrieved had higher T levels than non-retrieved females. Neither females nor males experienced a change in corticosterone levels in response to retrievals suggesting offspring do not mount a stress response to paternal care. Therefore, our data suggest that paternal retrievals may serve similar functions in shaping adult behavior in both male and female offspring via modulation of hormone levels. "} 
}
@article{Montazer20151695,
title = {"Content based image retrieval system using clustered scale invariant feature transforms "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"126"},
number = {"18"},
pages = {"1695 - 1699"},
year = {"2015"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615002880"},
author = {"Gholam Ali Montazer and Davar Giveki"},
keywords = {"Content based image retrieval", "Scale invariant feature transform (SIFT)", "Cardinality matrix of cluster-sets (CMCS)", "Resultant vector of clustered \{SIFT\} features (RVCSF) "},
abstract = {"Abstract The large amounts of image collections available from a variety of sources have posed increasing technical challenges to computer systems to store/transmit and index/manage the image data to make such collections easily accessible. To search and retrieve the expected images from the database a content-based image retrieval (CBIR) system is highly demanded. \{CBIR\} extracts features of a query image and try to match them with extracted features from images in the database. This paper introduces two novel methods as image descriptors. The basis of the proposed methods is built upon scale invariant feature transform (SIFT) algorithm. After extracting image features using SIFT, k-means clustering is applied on feature matrix extracted by SIFT, and then two new kinds of dimensionality reductions are applied to make \{SIFT\} features more efficient and realistic for image retrieval problem. Using the proposed strategies we cannot only take the advantage of \{SIFT\} features but also we can highly decrease the memory storage used by \{SIFT\} features. As well as in order to compare images we do not need to run the time-consuming matching algorithm of SIFT. Finally, proposed methods are compared with two popular methods namely, color auto-correlogram and wavelet transform. As a result, our proposed retrieval system is fast and accurate and it can efficiently manage large databases. Experimental results on two popular databases, Caltech 101 (with 9144 images) and Li database (with 2360) images, show the superiority and efficiency of the proposed methods. "} 
}
@article{Nikolaeva201678,
title = {"Verb generation task: early automatic information retrieval or late effortful decision-making? "},
journal = {"International Journal of Psychophysiology "},
volume = {"108"},
number = {""},
pages = {"78 - 79"},
year = {"2016"},
note = {"Proceedings of the 18th World Congress of Psychophysiology (IOP2016) of the International Organization of Psychophysiology (IOP) Havana, Cuba August 31st to September 4th, 2016 "},
issn = {"0167-8760"},
doi = {"https://doi.org/10.1016/j.ijpsycho.2016.07.252"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167876016303737"},
author = {"Anastasia Nikolaeva and Anna Butorina and Andrey Prokofiev and Anna Pavlova and Denis Bondarev and Tatiana Stroganova"} 

}
@article{Shrivastava2015314,
title = {"An efficient technique for retrieval of color images in large databases "},
journal = {"Computers & Electrical Engineering "},
volume = {"46"},
number = {""},
pages = {"314 - 327"},
year = {"2015"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2014.11.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790614003048"},
author = {"Nishant Shrivastava and Vipin Tyagi"},
keywords = {"Image retrieval", "Feature vector", "Histogram", "Gabor filter", "CBIR "},
abstract = {"Abstract Traditional image retrieval systems match the input image by searching the whole database repeatedly for various image features. Intermediate results produced for these features are merged using data fusion techniques to produce one common output. In this paper, a new image retrieval technique is presented, which retrieves similar images in three stages. A fixed number of images is first retrieved based on their color feature similarity. The relevance of the retrieved images is further improved by matching their texture and shape features respectively. This eliminates the need of fusion and normalization techniques, which are commonly used to calculate final similarity scores. This reduces the computation time and increases the overall accuracy of the system. Moreover, in this technique, global and region features are combined to obtain better retrieval accuracy. Experimental results on two databases (COREL and CIFAR) have shown that the proposed technique produces better results while consuming less computation time for large image databases. "} 
}
@article{Liu20152554,
title = {"Content-based image retrieval using computational visual attention model "},
journal = {"Pattern Recognition "},
volume = {"48"},
number = {"8"},
pages = {"2554 - 2566"},
year = {"2015"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2015.02.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320315000539"},
author = {"Guang-Hai Liu and Jing-Yu Yang and ZuoYong Li"},
keywords = {"Image retrieval", "Gray level co-occurrence matrix", "Visual attention", "Saliency structure model", "Saliency structure histogram "},
abstract = {"Abstract It is a very challenging problem to well simulate visual attention mechanisms for content-based image retrieval. In this paper, we propose a novel computational visual attention model, namely saliency structure model, for content-based image retrieval. First, a novel visual cue, namely color volume, with edge information together is introduced to detect saliency regions instead of using the primary visual features (e.g., color, intensity and orientation). Second, the energy feature of the gray-level co-occurrence matrices is used for globally suppressing maps, instead of the local maxima normalization operator in Itti׳s model. Third, a novel image representation method, namely saliency structure histogram, is proposed to stimulate orientation-selective mechanism for image representation within \{CBIR\} framework. We have evaluated the performances of the proposed algorithm on two datasets. The experimental results clearly demonstrate that the proposed algorithm significantly outperforms the standard \{BOW\} baseline and micro-structure descriptor. "} 
}
@article{Mandal2015277,
title = {"Multi-lingual date field extraction for automatic document retrieval by machine "},
journal = {"Information Sciences "},
volume = {"314"},
number = {""},
pages = {"277 - 292"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.08.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514008342"},
author = {"Ranju Mandal and Partha Pratim Roy and Umapada Pal and Michael Blumenstein"},
keywords = {"Robot reading", "Robot retrieval of document", "Date-based indexing", "Handwritten date extraction", "Date spotting", "Multi-lingual documents "},
abstract = {"Abstract Robotic intelligence has recently received significant attention in the research community. Application of such artificial intelligence can be used to perform automatic document retrieval and interpretation by a robot through query. So, it is necessary to extract the key information from the document based on the query to produce the desired feedback. For this purpose, in this paper we propose a system for automatic date field extraction from multi-lingual (English, Devnagari and Bangla scripts) handwritten documents. The date is a key piece of information, which can be used in various robotic applications such as date-wise document indexing/retrieval. In order to design the system, first the script of the document is identified, and based on the identified script, word components of each text line are classified into month and non-month classes using word-level feature extraction and classification. Next, non-month words are segmented into individual components and labelled into one of text, digit, punctuation or contraction categories. Subsequently, the date patterns are searched using the labelled components. Both numeric and semi-numeric regular expressions have been used for date part extraction. Dynamic Time Warping (DTW) and profile feature-based approaches are used for classification of month/non-month words. Other date components such as numerals and punctuation marks are recognised using a gradient-based feature and Support Vector Machine (SVM) classifier. The experiments are performed on English, Devnagari and Bangla document datasets and the encouraging results obtained from the system indicate the effectiveness of the proposed system. "} 
}
@article{Xiao20151,
title = {"Sketch-based human motion retrieval via selected 2D geometric posture descriptor "},
journal = {"Signal Processing "},
volume = {"113"},
number = {""},
pages = {"1 - 8"},
year = {"2015"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2015.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168415000067"},
author = {"Jun Xiao and Zhangpeng Tang and Yinfu Feng and Zhidong Xiao"},
keywords = {"Motion retrieval", "Sketch-based", "Feature selection", "Computer animation "},
abstract = {"Abstract Sketch-based human motion retrieval is a hot topic in computer animation in recent years. In this paper, we present a novel sketch-based human motion retrieval method via selected 2-dimensional (2D) Geometric Posture Descriptor (2GPD). Specially, we firstly propose a rich 2D pose feature call 2D Geometric Posture Descriptor (2GPD), which is effective in encoding the 2D posture similarity by exploiting the geometric relationships among different human body parts. Since the original 2GPD is of high dimension and redundant, a semi-supervised feature selection algorithm derived from Laplacian Score is then adopted to select the most discriminative feature component of 2GPD as feature representation, and we call it as selected 2GPD. Finally, a posture-by-posture motion retrieval algorithm is used to retrieve a motion sequence by sketching several key postures. Experimental results on \{CMU\} human motion database demonstrate the effectiveness of our proposed approach. "} 
}
@article{Leng2015119,
title = {"3D object retrieval with stacked local convolutional autoencoder "},
journal = {"Signal Processing "},
volume = {"112"},
number = {""},
pages = {"119 - 128"},
year = {"2015"},
note = {"Signal Processing and Learning Methods for 3D Semantic Analysis "},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414004150"},
author = {"Biao Leng and Shuang Guo and Xiangyang Zhang and Zhang Xiong"},
keywords = {"Object representation", "Stacked local convolutional autoencoder", "3D object retrieval "},
abstract = {"Abstract The success of object recognition and retrieval is largely determined by data representation. A good feature descriptor can detect the high-level abstraction of objects, which contains much discriminative information. In this paper, a novel 3D object retrieval method is proposed based on stacked local convolutional autoencoder (SLCAE). In this approach, the greedy layerwise strategy is applied to train SLCAE, and gradient descent method is used for training each layer. After the processing of training, the representations of input data can be obtained, regarded as the features of 3D objects. The experiments are conducted on three publicly available 3D object datasets, and the results demonstrate that the proposed method can greatly improve 3D object retrieval performance, compared with several state-of-the-art methods. "} 
}
@article{Pickup20152500,
title = {"Euclidean-distance-based canonical forms for non-rigid 3D shape retrieval "},
journal = {"Pattern Recognition "},
volume = {"48"},
number = {"8"},
pages = {"2500 - 2512"},
year = {"2015"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2015.02.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320315000813"},
author = {"David Pickup and Xianfang Sun and Paul L. Rosin and Ralph R. Martin"},
keywords = {"Shape retrieval", "Canonical forms "},
abstract = {"Abstract Retrieval of 3D shapes is a challenging problem, especially for non-rigid shapes. One approach giving favourable results uses multidimensional scaling (MDS) to compute a canonical form for each mesh, after which rigid shape matching can be applied. However, a drawback of this method is that it requires geodesic distances to be computed between all pairs of mesh vertices. Due to the super-quadratic computational complexity, canonical forms can only be computed for low-resolution meshes. We suggest a linear time complexity method for computing a canonical form, using Euclidean distances between pairs of a small subset of vertices. This approach has comparable retrieval accuracy but lower time complexity than using global geodesic distances, allowing it to be used on higher resolution meshes, or for more meshes to be considered within a time budget. "} 
}
@article{Liu201425,
title = {"Retrieval of leaf area index using temporal, spectral, and angular information from multiple satellite data "},
journal = {"Remote Sensing of Environment "},
volume = {"145"},
number = {""},
pages = {"25 - 37"},
year = {"2014"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2014.01.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425714000431"},
author = {"Qiang Liu and Shunlin Liang and Zhiqiang Xiao and Hongliang Fang"},
keywords = {"Leaf area index", "Multiple sensors", "Ensemble Kalman filter", "Iterative method "},
abstract = {"Abstract The leaf area index (LAI) is one of the most critical structural parameters of the vegetation canopy in regional and global biogeochemical, ecological, and meteorological applications. Data gaps and spatial and temporal inconsistencies exist in most of the existing global \{LAI\} products derived from single-satellite data because of their limited information content. Furthermore, the accuracy of current \{LAI\} products may not meet the requirements of certain applications. Therefore, \{LAI\} retrieval from multiple satellite data is becoming popular. An existing \{LAI\} inversion scheme using the ensemble Kalman filter (EnKF) technique is further extended in this study to integrate temporal, spectral, and angular information from Moderate Resolution Imaging Spectroradiometer (MODIS), SPOT/VEGETATION, and Multi-angle Imaging Spectroradiometer (MISR) data. The recursive update of \{LAI\} climatology with the retrieved \{LAI\} and the coupling of a canopy radiative-transfer model and a dynamic process model using the EnKF technique can fill in missing data and produce a consistent accurate time-series \{LAI\} product. During each iteration, we defined a 5 ∗ 1 sliding window and compared the \{RMSEs\} in the selected window to determine the minimum. Validation results at six sites demonstrate that the combination of temporal information from multiple sensors, spectral information provided by red and near-infrared (NIR) bands, and angular information from \{MISR\} bidirectional reflectance factor (BRF) data can provide a more accurate estimate of \{LAI\} than previously available. "} 
}
@article{Vandekerckhove20152017,
title = {"The Impact of Wear and Lift-Off on Coronal Plane Alignment in \{TKA\} and Implications to Future Constrained Revision: A Retrieval Study "},
journal = {"The Journal of Arthroplasty "},
volume = {"30"},
number = {"11"},
pages = {"2017 - 2020"},
year = {"2015"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2015.05.048"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540315004490"},
author = {"Pieter-Jan T.K. Vandekerckhove and Matthew G. Teeter and Douglas D.R. Naudie and James L. Howard and Steven J. MacDonald and Brent A. Lanting"},
keywords = {"coronal plane alignment", "total knee arthroplasty", "retrieval study", "wear", "lift-off", "constrained "},
abstract = {"Abstract Current discussion exists whether to position a total knee arthroplasty (TKA) in slight undercorrection in varus osteoarthritis. The goal of this study was to analyse the effect of wear and lateral lift-off in primary \{TKA\} on coronal plane alignment and the implication to future constrained revision TKA. Seventy-six retrieved tibial inserts were analysed for the ratio of wear (RW), lateral lift-off and implications for future constrained revision surgery according to the coronal plane alignment. The \{RW\} significantly affects the coronal plane alignment in TKA. Progressive wear and lateral lift-off were seen with progressive varus alignment. However, there was no difference in constrained revision between mild varus and moderate varus aligned TKAs. "} 
}
@article{Yang2015164,
title = {"Variable neighborhood search heuristic for storage location assignment and storage/retrieval scheduling under shared storage in multi-shuttle automated storage/retrieval systems "},
journal = {"Transportation Research Part E: Logistics and Transportation Review "},
volume = {"79"},
number = {""},
pages = {"164 - 177"},
year = {"2015"},
note = {""},
issn = {"1366-5545"},
doi = {"https://doi.org/10.1016/j.tre.2015.04.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S1366554515000988"},
author = {"Peng Yang and Lixin Miao and Zhaojie Xue and Bin Ye"},
keywords = {"Shared storage", "Storage location assignment", "Storage/retrieval scheduling", "Variable neighborhood search", "Multi-shuttle AS/RS "},
abstract = {"Abstract This paper examines the joint optimization of storage location assignment and storage/retrieval scheduling in multi-shuttle automated storage/retrieval systems (AS/RSs) under shared storage, in which the reuse of empty location yielded by retrieval operation is allowed. From the view of analytical model, the advantage of operational mode under shared storage is verified. A variable neighborhood search (VNS) algorithm is developed to solve the large-sized problems. Various numerical experiments are conducted to evaluate the performance of the proposed algorithm and investigate the impact of different parameters on computational efficiency. "} 
}
@article{Dubey2015288,
title = {"Rotation and scale invariant hybrid image descriptor and retrieval "},
journal = {"Computers & Electrical Engineering "},
volume = {"46"},
number = {""},
pages = {"288 - 302"},
year = {"2015"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2015.04.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790615001391"},
author = {"Shiv Ram Dubey and Satish Kumar Singh and Rajat Kumar Singh"},
keywords = {"Structure element", "Rotation-invariant descriptor", "Scale-invariant descriptor", "Texture analysis", "Content-based image retrieval", "Color quantization "},
abstract = {"Abstract Accurate image retrieval is required to index and retrieve large number of images from huge databases. In this paper, an efficient approach is presented to encode the color and textural features of images from the local neighborhood of each pixel. The color features are extracted by quantizing the \{RGB\} color space into a single channel with reduced number of shades. The texture information is encoded with structuring patterns generated from the locally structured elements chosen as a basis. Color and textural features are fused together to construct the inherently rotation and scale-invariant hybrid image descriptor (RSHD). This fusion is carried out by extracting textural cues over each shade independently. \{RSHD\} has been tested on the Corel dataset and experimental results suggest that \{RSHD\} outperforms state-of-the-art descriptors. The performance of the \{RSHD\} is promising under rotation and scaling. It can also be effectively used under more complex image transformations. "} 
}
@article{Harris2015204,
title = {"Cue generation and memory construction in direct and generative autobiographical memory retrieval "},
journal = {"Consciousness and Cognition "},
volume = {"33"},
number = {""},
pages = {"204 - 216"},
year = {"2015"},
note = {""},
issn = {"1053-8100"},
doi = {"https://doi.org/10.1016/j.concog.2014.12.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053810014002463"},
author = {"Celia B. Harris and Akira R. O’Connor and John Sutton"},
keywords = {"Autobiographical memory", "Direct retrieval", "Generative retrieval", "Visuo-spatial perspective", "Recollective experience", "Memory reconstruction "},
abstract = {"Abstract Theories of autobiographical memory emphasise effortful, generative search processes in memory retrieval. However recent research suggests that memories are often retrieved directly, without effortful search. We investigated whether direct and generative retrieval differed in the characteristics of memories recalled, or only in terms of retrieval latency. Participants recalled autobiographical memories in response to cue words. For each memory, they reported whether it was retrieved directly or generatively, rated its visuo-spatial perspective, and judged its accompanying recollective experience. Our results indicated that direct retrieval was commonly reported and was faster than generative retrieval, replicating recent findings. The characteristics of directly retrieved memories differed from generatively retrieved memories: directly retrieved memories had higher field perspective ratings and lower observer perspective ratings. However, retrieval mode did not influence recollective experience. We discuss our findings in terms of cue generation and content construction, and the implication for reconstructive models of autobiographical memory. "} 
}
@article{Pierard201570,
title = {"Acute stress blocks the caffeine-induced enhancement of contextual memory retrieval in mice "},
journal = {"European Journal of Pharmacology "},
volume = {"761"},
number = {""},
pages = {"70 - 78"},
year = {"2015"},
note = {""},
issn = {"0014-2999"},
doi = {"https://doi.org/10.1016/j.ejphar.2015.04.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S001429991500374X"},
author = {"Chistophe Pierard and Ali Krazem and Nadia Henkous and Laurence Decorte and Daniel Béracochéa"},
keywords = {"Caffeine-stress", "Memory retrieval", "Anxiety", "Corticosterone", "Glucocorticoids "},
abstract = {"Abstract This study investigated in mice the dose-effect of caffeine on memory retrieval in non-stress and stress conditions. \{C57\} Bl/6 Jico mice learned two consecutive discriminations (D1 and D2) in a four-hole board which involved either distinct contextual (CSD) or similar contextual (SSD) cues. All mice received an i.p. injection of vehicle or caffeine (8, 16 or 32 mg/kg) 30 min before the test session. Results showed that in non-stress conditions, the 16 mg/kg caffeine dose induced a significant enhancement of \{D1\} performance in \{CSD\} but not in SSD. Hence, we studied the effect of an acute stress (electric footshocks) administered 15 min before the test session on \{D1\} performance in caffeine-treated mice. Results showed that stress significantly decreased \{D1\} performance in vehicle-treated controls and the memory-enhancing effect induced by the 16 mg/kg caffeine dose in non-stress condition is no longer observed. Interestingly, whereas caffeine-treated mice exhibited weaker concentrations of plasma corticosterone as compared to vehicles in non-stress condition, stress significantly increased plasma corticosterone concentrations in caffeine-treated mice which reached similar level to that of controls. Overall, the acute stress blocked both the endocrinological and memory retrieval enhancing effects of caffeine. "} 
}
@article{Zuo201520,
title = {"Transport of intensity phase retrieval and computational imaging for partially coherent fields: The phase space perspective "},
journal = {"Optics and Lasers in Engineering "},
volume = {"71"},
number = {""},
pages = {"20 - 32"},
year = {"2015"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2015.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816615000457"},
author = {"Chao Zuo and Qian Chen and Lei Tian and Laura Waller and Anand Asundi"},
keywords = {"Transport of intensity equation", "Phase retrieval", "Phase space", "Partial coherence", "Light field imaging "},
abstract = {"Abstract The well-known transport of intensity equation (TIE) allows the phase of a coherent field to be retrieved non-interferometrically given positive defined intensity measurements and appropriate boundary conditions. However, in many cases like the optical microscopy, the imaging systems often involve extended and polychromatic sources for which the effect of the partial coherence is not negligible. In this work, we present a phase-space formulation for the \{TIE\} for analyzing phase retrieval under partially coherent illumination. The conventional \{TIE\} is reformulated in the joint space-spatial frequency domain using Wigner distribution functions. The phase-space formulation clarifies the physical meaning of the phase of partially coherent fields, and enables explicit account of partial coherence effects on phase retrieval. The correspondence between the Wigner distribution function and the light field in geometric optics limit further enables \{TIE\} to become a simple yet effective approach to realize high-resolution light field imaging for slowly varying phase specimens, in a purely computational way. "} 
}
@article{Stengel2015363,
title = {"The Clouds Climate Change Initiative: Assessment of state-of-the-art cloud property retrieval schemes applied to \{AVHRR\} heritage measurements "},
journal = {"Remote Sensing of Environment "},
volume = {"162"},
number = {""},
pages = {"363 - 379"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2013.10.035"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425713004197"},
author = {"M. Stengel and S. Mieruch and M. Jerg and K.-G. Karlsson and R. Scheirer and B. Maddux and J.F. Meirink and C. Poulsen and R. Siddans and A. Walther and R. Hollmann"},
keywords = {"Satellite", "AVHRR", "MODIS", "Cloud retrieval", "Validation", "A-Train", "Inter-comparison "},
abstract = {"Abstract Cloud property retrievals from 3 decades of the Advanced Very High Resolution Radiometer (AVHRR) measurements provide a unique opportunity for a long-term analysis of clouds. In this study, the accuracy of AVHRR-derived cloud properties cloud mask, cloud-top height, cloud phase and cloud liquid water path is assessed using three state-of-the-art retrieval schemes. In addition, the same retrieval schemes are applied to the \{AVHRR\} heritage channels of the Moderate Resolution Imaging Spectroradiometer (MODIS) to create AVHRR-like retrievals with higher spatial resolution and based on presumably more accurate spectral calibration. The cloud property retrievals were collocated and inter-compared with observations from CloudSat, \{CALIPSO\} and AMSR-E The resulting comparison exhibited good agreement in general. The schemes provide correct cloud detection in 82 to 90% of all cloudy cases. With correct identification of clear-sky in 61 to 85% of all clear areas, the schemes are slightly biased towards cloudy conditions. The evaluation of the cloud phase classification shows correct identification of liquid clouds in 61 to 97% and a correct identification of ice clouds in 68 to 95%, demonstrating a large variability among the schemes. Cloud-top height (CTH) retrievals were of relatively similar quality with standard deviations ranging from 2.1 km to 2.7 km. Significant negative biases in these retrievals are found in particular for cirrus clouds. The biases decrease if optical depth thresholds are applied to determine the reference \{CTH\} measure. Cloud liquid water path (LWP) is also retrieved well with relative low standard deviations (20 to 28 g/m2), negative bias and high correlations. Cloud ice water path (IWP) retrievals of \{AVHRR\} and \{MODIS\} exhibit a relative high uncertainty with standard deviations between 800 and 1400 g/m2, which in relative terms exceed 100% when normalized with the mean IWP. However, the global histogram distributions of \{IWP\} were similar to the reference dataset. \{MODIS\} retrievals are for most comparisons of slightly better quality than AVHRR-based retrievals. Additionally, the choice of different near-infrared channels, 3.7 μm as opposed to 1.6 μm, can have a significant impact on the retrieval quality, most pronounced for IWP, with better accuracy for the 1.6 μm channel setup. This study presents a novel assessment of the quality of cloud properties derived from \{AVHRR\} channels, which quantifies the accuracy of the considered retrievals based on common approaches and validation data. Furthermore, it assesses the capabilities of AVHRR-like spectral information for retrieving cloud properties in the light of generating climate data records of cloud properties from three decades of \{AVHRR\} measurements. "} 
}
@article{Mineo2017,
title = {"Modulation of sensorimotor circuits during retrieval of negative Autobiographical Memories: Exploring the impact of personality dimensions "},
journal = {"Neuropsychologia "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2017.04.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393217301379"},
author = {"Ludovico Mineo and Carmen Concerto and Dhaval Patel and Tyrone Mayorga and Eileen Chusid and Carmenrita Infortuna and Eugenio Aguglia and Yasmin Sarraf and Fortunato Battaglia"},
keywords = {"Transcranial magnetic stimulation", "Sensorimotor integration", "Autobiographical Memories", "ICF", "Neuroticism "},
abstract = {"Abstract Autobiographical Memory (AM) retrieval refers to recollection of experienced past events. Previous Transcranial Magnetic Stimulation (TMS) studies have shown that presentation of emotional negative stimuli affects human motor cortex excitability resulting in larger motor evoked potentials (MEPs). Up to date no \{TMS\} studies have been carried out in order to investigate the effect of personal memories with negative emotional value on corticospinal excitability. In this study we hypothesized that negative \{AM\} retrieval will modulate corticomotor excitability and sensorimotor integration as determined by \{TMS\} neurophysiological parameters. Furthermore, we investigated whether \{TMS\} responses during retrieval of negative \{AM\} are associated with specific personality traits. Twelve healthy subjects were asked to recall either a negative or a neutral \{AM\} across two different days in a randomized order. During this memory retrieval, the following \{TMS\} parameters were recorded: MEPs; Short- interval intracortical inhibition (SICI) and Intracortical facilitation (ICF); Short-latency afferent inhibition (SAI) and Long- latency afferent inhibition (LAI). Personality traits were assessed by using the Big Five scale. Statistical analysis was performed using factorial \{ANOVAs\} and multiple linear regression models. When compared to retrieval of neutral AM, recollection of negative \{AM\} induced a larger increase in \{MEP\} amplitude, an increase in ICF, and a decrease in SAI. The neuroticism personality trait was a significant predictor of the \{MEP\} amplitude increase during retrieval of negative AM. Altogether these results indicate that cortical excitability and sensorimotor integration are selectively modulated by the valence of AM. These results provide the first \{TMS\} evidence that the modulatory effect of the \{AM\} retrieval is associated with specific personality traits. "} 
}
@article{Mohammed20154927,
title = {"Image classification and retrieval using optimized Pulse-Coupled Neural Network "},
journal = {"Expert Systems with Applications "},
volume = {"42"},
number = {"11"},
pages = {"4927 - 4936"},
year = {"2015"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2015.02.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417415001189"},
author = {"Mona Mahrous Mohammed and Amr Badr and M.B. Abdelhalim"},
keywords = {"Content-Based Image Retrieval (CBIR)", "Image classification", "Visual features", "Pulse-Coupled Neural Network (PCNN)", "Image signature", "K-Nearest Neighbor", "Genetic algorithm "},
abstract = {"Abstract Content-Based Image Retrieval (CBIR) has become a powerful tool that is used in many image applications and search engines. Thus, many techniques and approaches for \{CBIR\} were developed in literature. The \{CBIR\} approach works on the visual features of the image rather than a descriptive text. Therefore, it provides more effective and efficient retrieval. On the other hand, \{PCNN\} has proved its efficiency as an image processing tool for various tasks such as image segmentation and recognition, feature extraction, edge and object detection. This article introduces a technique for content-based image classification and retrieval using PCNN. The proposed technique uses an optimized Pulse-Coupled Neural Network (PCNN) to extract the visual features of the image in a form of a numeric vector called image signature. An optimization mechanism was applied to the \{PCNN\} parameters in order to improve the signature quality. Thus improving the classification and retrieval results. Additionally, it employs the K-Nearest Neighbor (K-NN) algorithm for classification and matching. By applying classification before retrieval, the number of images in the search space is optimized to include one category instead of multiple categories. Moreover, we developed a \{CBIR\} prototype to validate our technique. The results show that our technique can retrieve and classify images efficiently. Furthermore, we evaluated our prototype against one of the widely used techniques and it was proven that the proposed technique can enhance the search results and improve the accuracy by 3.5%. "} 
}
@article{Zhao2015110,
title = {"View-based 3D object retrieval via multi-modal graph learning "},
journal = {"Signal Processing "},
volume = {"112"},
number = {""},
pages = {"110 - 118"},
year = {"2015"},
note = {"Signal Processing and Learning Methods for 3D Semantic Analysis "},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.09.038"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414004666"},
author = {"Sicheng Zhao and Hongxun Yao and Yanhao Zhang and Yasi Wang and Shaohui Liu"},
keywords = {"3D object retrieval", "Multi-modal graph learning", "Feature fusion", "Multi-views "},
abstract = {"Abstract Content-based 3D object retrieval has wide applications in various domains, ranging from virtual reality to computer aided design and entertainment. With the rapid development of digitizing technologies, different views of 3D objects are captured, which requires for effective and efficient view-based 3D object retrieval (V3DOR) techniques. As each object is represented by a set of multiple views, \{V3DOR\} becomes a group matching problem. Most of state-of-the-art \{V3DOR\} methods use one single feature to describe a 3D object, which is often insufficient. In this paper, we propose a feature fusion method via multi-modal graph learning for view-based 3D object retrieval. Firstly, different visual features, including 2D Zernike moments, 2D Fourier descriptor and 2D Krawtchouk moments, are extracted to describe each view of a 3D object. Then the Hausdorff distance is computed to measure the similarity between two 3D objects with multiple views. Finally we construct multiple graphs based on different features and learn the optimized weights of each graph automatically for feature fusion task. Extensive experiments are conducted on the ETH-80 dataset and the National Taiwan University 3D model dataset. The results demonstrate the superior performance of the proposed method, as compared to the state-of-the-art approaches. "} 
}
@article{Choi201418,
title = {"Semantic concept-enriched dependence model for medical information retrieval "},
journal = {"Journal of Biomedical Informatics "},
volume = {"47"},
number = {""},
pages = {"18 - 27"},
year = {"2014"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2013.08.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S153204641300141X"},
author = {"Sungbin Choi and Jinwook Choi and Sooyoung Yoo and Heechun Kim and Youngho Lee"},
keywords = {"Search engine", "Term dependence model", "Ranking", "Semantic concept", "Unified medical language system "},
abstract = {"AbstractObjective In medical information retrieval research, semantic resources have been mostly used by expanding the original query terms or estimating the concept importance weight. However, implicit term-dependency information contained in semantic concept terms has been overlooked or at least underused in most previous studies. In this study, we incorporate a semantic concept-based term-dependence feature into a formal retrieval model to improve its ranking performance. Design Standardized medical concept terms used by medical professionals were assumed to have implicit dependency within the same concept. We hypothesized that, by elaborately revising the ranking algorithms to favor documents that preserve those implicit dependencies, the ranking performance could be improved. The implicit dependence features are harvested from the original query using MetaMap. These semantic concept-based dependence features were incorporated into a semantic concept-enriched dependence model (SCDM). We designed four different variants of the model, with each variant having distinct characteristics in the feature formulation method. Measurements We performed leave-one-out cross validations on both a clinical document corpus (TREC Medical records track) and a medical literature corpus (OHSUMED), which are representative test collections in medical information retrieval research. Results Our semantic concept-enriched dependence model consistently outperformed other state-of-the-art retrieval methods. Analysis shows that the performance gain has occurred independently of the concept’s explicit importance in the query. Conclusion By capturing implicit knowledge with regard to the query term relationships and incorporating them into a ranking model, we could build a more robust and effective retrieval model, independent of the concept importance. "} 
}
@article{Nurse2014561,
title = {"Designing for Digital Reading, J. Pearson, G. Buchanan, H. Thimbleby, G. Marchiononi (Ed.), in: Part of Synthesis Lectures on Information Concepts, Retrieval, and Services. Morgan and Claypool, San Rafael, \{CA\} (2014) "},
journal = {"International Journal of Information Management "},
volume = {"34"},
number = {"4"},
pages = {"561 - "},
year = {"2014"},
note = {""},
issn = {"0268-4012"},
doi = {"https://doi.org/10.1016/j.ijinfomgt.2014.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0268401214000401"},
author = {"Andrew Nurse"} 

}
@article{deFoy20151,
title = {"Estimates of power plant \{NOx\} emissions and lifetimes from \{OMI\} \{NO2\} satellite retrievals "},
journal = {"Atmospheric Environment "},
volume = {"116"},
number = {""},
pages = {"1 - 11"},
year = {"2015"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2015.05.056"},
url = {"http://www.sciencedirect.com/science/article/pii/S1352231015301291"},
author = {"Benjamin de Foy and Zifeng Lu and David G. Streets and Lok N. Lamsal and Bryan N. Duncan"},
keywords = {"Emission inventory", "Satellite retrieval", "OMI", "CEMS", "Power plant NOx", "Chemical lifetime "},
abstract = {"Abstract Isolated power plants with well characterized emissions serve as an ideal test case of methods to estimate emissions using satellite data. In this study we evaluate the Exponentially-Modified Gaussian (EMG) method and the box model method based on mass balance for estimating known \{NOx\} emissions from satellite retrievals made by the Ozone Monitoring Instrument (OMI). We consider 29 power plants in the \{USA\} which have large \{NOx\} plumes that do not overlap with other sources and which have emissions data from the Continuous Emission Monitoring System (CEMS). This enables us to identify constraints required by the methods, such as which wind data to use and how to calculate background values. We found that the lifetimes estimated by the methods are too short to be representative of the chemical lifetime. Instead, we introduce a separate lifetime parameter to account for the discrepancy between estimates using real data and those that theory would predict. In terms of emissions, the \{EMG\} method required averages from multiple years to give accurate results, whereas the box model method gave accurate results for individual ozone seasons. "} 
}
@article{Ji2015323,
title = {"A statistical design approach to unsupervised codeword selection in image retrieval "},
journal = {"Neurocomputing "},
volume = {"157"},
number = {""},
pages = {"323 - 334"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.10.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214013691"},
author = {"Ming Ji and Wei Zhao and Zheng Liu"},
keywords = {"Statistical design", "Codeword selection", "Image retrieval "},
abstract = {"Abstract Recently, the bag-of-features (BoF) representation has attracted substantial interest in large scale image retrieval. In BoF representation, images are treated as collections of local invariant descriptors. A visual codebook is constructed by quantizing the local descriptors into clusters, whose centers are called codewords. Then each image could be represented by the frequency histogram over the codebook, and existing text retrieval techniques such as inverted indexing could be applied to image retrieval. It has been recognized that the quality of the codebook is critical to the performance of BoF-based image retrieval systems, and codeword selection is therefore a fundamental problem. Many of the existing approaches for codeword selection make use of the label information of the images. However, collecting the labels of a large amount of images is very expensive. In this paper, we investigate the problem of codeword selection in the absence of labels. Inspired from the techniques of statistical design, we propose two novel unsupervised learning algorithms to select the codewords for an image retrieval system. Specifically, we assume that the relationship between the relevance score and the BoF representation of an image could be expressed by a linear regression model, and select the codewords which can improve the regression model the most. In other words, if the selected codewords are used to train the regression model, the expected prediction error can be minimized. Extensive experimental results have demonstrated the effectiveness of our proposed methods. "} 
}
@article{Price20151,
title = {"True (but not false) memories are subject to retrieval-induced forgetting in children "},
journal = {"Journal of Experimental Child Psychology "},
volume = {"133"},
number = {""},
pages = {"1 - 15"},
year = {"2015"},
note = {""},
issn = {"0022-0965"},
doi = {"https://doi.org/10.1016/j.jecp.2015.01.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022096515000211"},
author = {"Heather L. Price and Thomas L. Phenix"},
keywords = {"Retrieval-induced forgetting", "DRM paradigm", "False memories", "Children", "Cue-dependence", "Delay "},
abstract = {"Abstract Veridical and false memories of children aged 6 to 15 years were studied in two experiments with the retrieval-induced forgetting paradigm. Using the Deese–Roediger–McDermott (DRM) false memory word lists, children’s reports of true, but not false, memories showed evidence of retrieval-induced forgetting. These differences were observed across delays as long as 2 days following word list presentation. The lack of observation of retrieval-induced forgetting in children’s false memories provides evidence that a key assumption in the theory of retrieval-induced forgetting, cue independence, might not consistently apply. These experiments underscore the need for both practical and theoretically motivated study of true and false memories. "} 
}
@article{Krendl2015103,
title = {"The dissociable effects of stereotype threat on older adults’ memory encoding and retrieval "},
journal = {"Journal of Applied Research in Memory and Cognition "},
volume = {"4"},
number = {"2"},
pages = {"103 - 109"},
year = {"2015"},
note = {""},
issn = {"2211-3681"},
doi = {"https://doi.org/10.1016/j.jarmac.2015.02.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211368115000170"},
author = {"Anne C. Krendl and Nalini Ambady and Elizabeth A. Kensinger"},
keywords = {"Stereotype threat", "Aging", "Emotional memory", "Retrieval", "Encoding "},
abstract = {"Abstract The present study asks how subliminal exposure to negative stereotypes about age-related memory deficits affects older adults’ memory performance. Whereas prior research has focused on the effect of “stereotype threat” on older adults’ memory for neutral material, the present study additionally examines the effect on memory for positive and negative words, as well as whether the subliminal “threat” has a larger impact on memory performance when it occurs prior to encoding or prior to retrieval (as compared to a control condition). Results revealed that older adults’ memory impairments were most pronounced when the threat was placed prior to retrieval as compared to when the threat was placed prior to encoding or no threat occurred. Moreover, the threat specifically increased false memory rates, particularly for neutral items compared to positive and negative ones. These results emphasize that stereotype threat effects vary depending upon the phase of memory it impacts. "} 
}
@article{Kasimov2015134,
title = {"Individual strategies in the tasks of graphical retrieval of technical drawings "},
journal = {"Journal of Visual Languages & Computing "},
volume = {"28"},
number = {""},
pages = {"134 - 146"},
year = {"2015"},
note = {""},
issn = {"1045-926X"},
doi = {"https://doi.org/10.1016/j.jvlc.2014.12.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1045926X14001736"},
author = {"Denis R. Kasimov and Aleksandr V. Kuchuganov and Valeriy N. Kuchuganov"},
keywords = {"Technical drawing", "Content-based retrieval", "Matching graphs", "Search strategy "},
abstract = {"Abstract A designer׳s information need can have a lot of finer points not expressible completely by textual attributes or global aggregated image features. The purpose of the study is to develop a cognitive environment for content-based engineering drawing retrieval, allowing a user to concretize queries, to implement strategies that are most effective for the current search task. We propose meaningful customizable graphic search patterns, various comparison modes and visualization of matched elements. The presented experiments show that the approach yields good results in the sense of relevance and is comfortable in terms of controllability. The possibility to customize search patterns can result in improving retrieval precision by 10–15%. In practice, it can significantly increase the degree of automation of the design-reuse process. "} 
}
@article{Pasolli2015159,
title = {"Retrieval of Leaf Area Index in mountain grasslands in the Alps from \{MODIS\} satellite imagery "},
journal = {"Remote Sensing of Environment "},
volume = {"165"},
number = {""},
pages = {"159 - 174"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.04.027"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715001698"},
author = {"Luca Pasolli and Sarah Asam and Mariapina Castelli and Lorenzo Bruzzone and Georg Wohlfahrt and Marc Zebisch and Claudia Notarnicola"},
keywords = {"Leaf Area Index (LAI)", "Biophysical parameter retrieval", "Radiation transfer modeling", "Moderate Resolution Imaging Spectroradiometer (MODIS)", "Mountain Grassland", "Alps "},
abstract = {"Abstract This paper presents an improved algorithm for the retrieval of Leaf Area Index (LAI) from Moderate Resolution Imaging Spectroradiometer (MODIS) satellite imagery that has been specifically customized for mountain grasslands in the Alps. The main features of the proposed algorithm, which is based on the inversion of a radiative transfer model, are: i) a higher spatial resolution (250 m) with respect to the corresponding standard \{MODIS\} product and ii) tuning the model to the spectral characteristics of mountain grasslands. To quantify the effects of the features of the proposed algorithm, the approach is first applied to a \{MODIS\} reflectance data time series from 2007 up-scaled to a 1 km spatial resolution for better comparison with the standard \{MODIS\} \{LAI\} product. In the next step, the benefit of the higher spatial resolution is assessed by applying the algorithm to a series of \{MODIS\} satellite images with a spatial resolution of 250 m acquired over the central Alps in the period 2005–2007. \{LAI\} estimates were validated for both temporal consistency and accuracy using ground measurement time series collected at three different study sites in the investigated area. The results obtained demonstrate the capability of the proposed algorithm to follow the expected temporal and range dynamics of \{LAI\} in this challenging environment, showing an overall \{RMSE\} accuracy of 1.68 (m2/m2). This approach thus opens a promising avenue for the exploitation of moderate resolution satellite data for novel and more accurate monitoring studies at a regional scale in mountain environments. "} 
}
@article{Guo2015207,
title = {"An effective and economical architecture for semantic-based heterogeneous multimedia big data retrieval "},
journal = {"Journal of Systems and Software "},
volume = {"102"},
number = {""},
pages = {"207 - 216"},
year = {"2015"},
note = {""},
issn = {"0164-1212"},
doi = {"https://doi.org/10.1016/j.jss.2014.09.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0164121214002040"},
author = {"Kehua Guo and Wei Pan and Mingming Lu and Xiaoke Zhou and Jianhua Ma"},
keywords = {"Heterogeneous multimedia", "Semantic based retrieval", "Big data "},
abstract = {"Abstract Data variety has been one of the most critical features for multimedia big data. Some multimedia documents, although in different data formats and storage structures, often express similar semantic information. Therefore, the way to manage and retrieve multimedia documents reflecting users’ intent in heterogeneous big data environments has become an important issue. In this paper, we present an effective and economical architecture named \{SHMR\} (Semantic-based Heterogeneous Multimedia Retrieval), which uses low cost to store and retrieve semantic information from heterogeneous multimedia data. Firstly, the particularity of heterogeneous multimedia retrieval in big data environments is addressed. Secondly, an approach to extract and represent semantic information for heterogeneous multimedia documents is proposed. Thirdly, a NoSQL-based approach to semantic storage, in which multimedia can be parallel processed in distributed nodes is provided. Finally, a MapReduce-based retrieval algorithm is presented and a user feedback supported scheme to achieve high retrieval precision and good user experience is designed. The experimental results indicate that the retrieval performance and economic efficiency of \{SHMR\} are suitable for multimedia information retrieval in heterogeneous big data environments. "} 
}
@article{Rezac201523,
title = {"Simultaneous retrieval of T(p) and \{CO2\} \{VMR\} from two-channel non-LTE limb radiances and application to daytime SABER/TIMED measurements "},
journal = {"Journal of Atmospheric and Solar-Terrestrial Physics "},
volume = {"130–131"},
number = {""},
pages = {"23 - 42"},
year = {"2015"},
note = {""},
issn = {"1364-6826"},
doi = {"https://doi.org/10.1016/j.jastp.2015.05.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1364682615000954"},
author = {"L. Rezac and A. Kutepov and J.M. Russell III and A.G. Feofilov and J. Yue and R.A. Goldberg"},
keywords = {"Mesospheric temperature", "Composition", "Retrieval", "Inversion "},
abstract = {"Abstract The kinetic temperature, Tk, and carbon dioxide, \{CO2\} density, are key parameters that characterize the energetics and dynamics of the mesosphere and lower thermosphere (MLT) region. The Sounding of the Atmosphere using Broadband Emission Radiometry (SABER) instrument on-board the Thermosphere-Ionosphere-Mesosphere-Energetics and Dynamics (TIMED) satellite has been providing global, simultaneous measurements of limb radiance in 10 spectral channels continuously since late January 2002. In this paper we (1) present a methodology for a self-consistent simultaneous retrieval of temperature/pressure, Tk(p), and \{CO2\} volume mixing ratio (VMR) from the broadband infrared limb measurements in the 15 and 4.3 μ m channels, and (2) qualitatively describe the first results on the \{CO2\} \{VMR\} and Tk obtained from application of this technique to the \{SABER\} 15 and 4.3 μ m channels, including issues, which demand additional constraints to be applied. The self-consistent two-channel retrieval architecture updates parameters at all altitudes simultaneously, and it is built upon iterative switching between two retrieval modules, one for \{CO2\} and one for Tk. A detailed study of sensitivity, stability and convergence was carried out to validate the algorithm. The Tk/CO2 \{VMR\} distribution can be reliably retrieved without biases connected with this non-linear inverse problem starting with an initial guess as far as ±20% of \{CO2\} \{VMR\} and ±15 K from the solution (as global shift, or somewhat larger if only local deviations are considered). In polar summer toward high latitudes the retrieved \{CO2\} \{VMR\} profile shows a local peak around 90 km. We discuss details of this feature and show that: (a) it is not an algorithm artifact or instability, (b) additional a priori constraints are needed in order to obtain a physical profile and to remove this peak, and (c) several possibilities are explored as to uncover the real cause of this feature, but no firm conclusion can be reached at this time. This algorithm has been applied to all available daytime \{SABER\} measurements since 2002, and the first results of the mean \{CO2\} \{VMR\} profiles and their distribution is discussed. In particular, the \{CO2\} \{VMR\} profiles depart from a well mixed value at altitudes of 65–70 km during equinoxes at high and mid-latitudes, but in the summer hemisphere solstice period the \{SABER\} data is more consistent with a well mixed \{VMR\} conditions extend up to 87–90 km especially toward high latitudes. "} 
}
@incollection{Giannakopoulos2014211,
title = {"Chapter 8 - Music Information Retrieval "},
editor = {"Giannakopoulos, Theodoros and ,  and Pikrakis, Aggelos "},
booktitle = {"Introduction to Audio Analysis "},
publisher = {"Academic Press"},
edition = {""},
address = {"Oxford"},
year = {"2014"},
pages = {"211 - 231"},
isbn = {"978-0-08-099388-1"},
doi = {"https://doi.org/10.1016/B978-0-08-099388-1.00008-X"},
url = {"http://www.sciencedirect.com/science/article/pii/B978008099388100008X"},
author = {"Theodoros Giannakopoulos and Aggelos Pikrakis"},
keywords = {"Music thumbnailing", "Audio thumbnailing", "Meter extraction", "Tempo extraction", "Self-similarity keywords =atrix", "Content visualization", "Dimensionality reduction", "Self organizing maps", "SOMs", "Fisher linear discriminant", "FLD", "LDA", "Principal component analysis", "PCA "},
abstract = {"Abstract This chapter provides descriptions and implementations of some basic Music Information Retrieval tasks, so that the reader can gain a deeper understanding of the field. In particular, we focus on the tasks of music thumbnailing, meter/tempo induction and music content visualization. "} 
}
@article{Candès2015277,
title = {"Phase retrieval from coded diffraction patterns "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"39"},
number = {"2"},
pages = {"277 - 299"},
year = {"2015"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2014.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520314001201"},
author = {"Emmanuel J. Candès and Xiaodong Li and Mahdi Soltanolkotabi"},
keywords = {"Phase retrieval", "Diffraction", "Fourier transform", "Convex optimization", "Random matrix theory "},
abstract = {"Abstract This paper considers the question of recovering the phase of an object from intensity-only measurements, a problem which naturally appears in X-ray crystallography and related disciplines. We study a physically realistic setup where one can modulate the signal of interest and then collect the intensity of its diffraction pattern, each modulation thereby producing a sort of coded diffraction pattern. We show that PhaseLift, a recent convex programming technique, recovers the phase information exactly from a number of random modulations, which is polylogarithmic in the number of unknowns. Numerical experiments with noiseless and noisy data complement our theoretical analysis and illustrate our approach. "} 
}
@article{vanderSchalie201570,
title = {"\{SMOS\} soil moisture retrievals using the land parameter retrieval model: Evaluation over the Murrumbidgee Catchment, southeast Australia "},
journal = {"Remote Sensing of Environment "},
volume = {"163"},
number = {""},
pages = {"70 - 79"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715001029"},
author = {"R. van der Schalie and R.M. Parinussa and L.J. Renzullo and A.I.J.M. van Dijk and C.-H. Su and R.A.M. de Jeu"},
keywords = {"Remote sensing", "Passive microwave radiometry", "Soil moisture", "Soil Moisture and Ocean Salinity (SMOS)", "Land parameter retrieval model (LPRM) "},
abstract = {"Abstract The land parameter retrieval model (LPRM) is a methodology that retrieves soil moisture from low frequency dual polarized microwave measurements and has been extensively tested on C-, X- and Ku-band frequencies. Its performance on L-band is tested here by using observations from the Soil Moisture and Ocean Salinity (SMOS) satellite. These observations have potential advantages compared to higher frequencies: a low sensitivity to cloud and vegetation contamination, an increased thermal sampling depth and a greater sensitivity to soil moisture fluctuations. These features make it desirable to add SMOS-derived soil moisture retrievals to the existing European Space Agency (ESA) long-term climatological soil moisture data record, to be harmonized with other passive microwave soil moisture estimates from the LPRM. For multi-channel observations, \{LPRM\} infers the effective soil temperature (Teff) from higher frequency channels. This is not possible for a single channel mission like \{SMOS\} and therefore two alternative sources for Teff were tested: (1) MERRA-Land and (2) \{ECMWF\} numerical weather prediction systems, respectively. \{SMOS\} measures brightness temperature at a range of incidence angles, different incidence angle bins (45°, 52.5° and 60°) were tested for both ascending and descending swaths. Three \{LPRM\} algorithm parameters were optimized to match remotely sensed soil moisture with ground based observations: the single scattering albedo, roughness and polarization mixing factor. The soil moisture retrievals were optimized and evaluated against ground-based data from the Murrumbidgee Soil Moisture Monitoring Network (OzNet) in southeast Australia. The agreement with single-angle \{SMOS\} \{LPRM\} retrievals was close to the official \{SMOS\} \{L3\} product, provided the three parameters were optimized for the OzNet dataset, with linear correlation of 0.70–0.75 (0.75–0.77 for \{SMOS\} L3), root-mean-square error of 0.069–0.085 m3 m− 3 (0.084–0.106 m3 m− 3 for \{SMOS\} L3) and small bias of − 0.02–0.01 m3 m− 3 (0.03–0.06 m3 m− 3 for \{SMOS\} L3). These results suggest that the \{LPRM\} can be applied successfully to single-angle \{SMOS\} L-band observations, but further testing is required to determine if the same set of parameters can be used in other geographic areas. "} 
}
@article{Karakasis201522,
title = {"Image moment invariants as local features for content based image retrieval using the Bag-of-Visual-Words model "},
journal = {"Pattern Recognition Letters "},
volume = {"55"},
number = {""},
pages = {"22 - 27"},
year = {"2015"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2015.01.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865515000239"},
author = {"E.G. Karakasis and A. Amanatiadis and A. Gasteratos and S.A. Chatzichristofis"},
keywords = {"Bag of visual words", "Affine moment invariants", "Content based image retrieval "},
abstract = {"Abstract This paper presents an image retrieval framework that uses affine image moment invariants as descriptors of local image areas. Detailed feature vectors are generated by feeding the produced moments into a Bag-of-Visual-Words representation. Image moment invariants have been selected for their compact representation of image areas as well as due to their ability to remain unchanged under affine image transformations. Three different setups were examined in order to evaluate and discuss the overall approach. The retrieval results are promising compared with other widely used local descriptors, allowing the proposed framework to serve as a reference point for future image moment local descriptors applied to the general task of content based image retrieval. "} 
}
@article{Clos20151,
title = {"Goal- and retrieval-dependent activity in the striatum during memory recognition "},
journal = {"Neuropsychologia "},
volume = {"72"},
number = {""},
pages = {"1 - 11"},
year = {"2015"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.04.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215001578"},
author = {"Mareike Clos and Ulrike Schwarze and Sebastian Gluth and Nico Bunzeck and Tobias Sommer"},
keywords = {"fMRI", "Confidence", "Metamemory", "Perceived oldness", "Retrieval success", "Subjective value "},
abstract = {"Abstract The striatum has been associated with successful memory retrieval but the precise functional link still remains unclear. One hypothesis is that striatal activity reflects an active evaluation process of the retrieval outcome dependent on the current behavioral goals rather than being a consequence of memory reactivation. We have recently shown that the striatum also correlates with confidence in memory recognition, which could reflect high subjective value ascribed to high certainty decisions. To examine whether striatal activity during memory recognition reflects subjective value indeed, we conducted an fMRI study using a recognition memory paradigm in which the participants rated not only the recognition confidence but also indicated the pleasantness associated with the previous memory retrieval. The results demonstrated a high positive correlation between confidence and pleasantness both on the behavioral and brain activation level particularly in the striatum. As almost all of variance in the striatal confidence signal could be explained by experienced pleasantness, this part of the striatal memory recognition response probably corresponds to greater subjective value of high confidence responses. While perceived oldness was also strongly correlated with striatal activity, this activation pattern was clearly distinct from that associated with confidence and pleasantness and thus could not be explained by higher subjective value to detect “old” items. Together, these results show that at least two independent processes contribute to striatal activation in recognition memory: a more flexible evaluation response dependent on context and goals captured by memory confidence and a potentially retrieval-related response captured by perceived oldness. "} 
}
@article{SicardiSegade20141320,
title = {"Analysis of the fringes visibility generated by a lateral cyclic shear interferometer in the retrieval of the three-dimensional surface information of an object "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"125"},
number = {"3"},
pages = {"1320 - 1324"},
year = {"2014"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2013.08.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402613011741"},
author = {"Analia Sicardi-Segade and Amalia Martínez-García and Noel-Ivan Toto-Arellano and J.A. Rayas"},
keywords = {"Optical metrology", "Projected fringes", "Fringes visibility", "Interferometry", "Lateral cyclic shear interferometer "},
abstract = {"Abstract We report the evaluation of the topography of an object with projected fringes generated with a lateral cyclic shear interferometer (CSI) and we then compare the topography recovery obtained with the proposed method with the one obtained from a coordinate measuring machine (CMM). We also study how the fringes visibility along the z axis affects the retrieval. Finally, we discuss the advantages and drawbacks of this profilometry system. "} 
}
@article{Li2015190,
title = {"A geometric reasoning approach to hierarchical representation for B-rep model retrieval "},
journal = {"Computer-Aided Design "},
volume = {"62"},
number = {""},
pages = {"190 - 202"},
year = {"2015"},
note = {""},
issn = {"0010-4485"},
doi = {"https://doi.org/10.1016/j.cad.2014.05.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S001044851400102X"},
author = {"Zhi Li and Xionghui Zhou and Wei Liu"},
keywords = {"Geometric reasoning", "Hierarchical representation", "Solid model retrieval "},
abstract = {"Abstract 3D solid model similarity is dependency of many intelligent design applications, such as design reuse, part management, case-based reasoning, and cost estimation. Matching and comparing its intrinsic boundary representation (B-rep) is a critical issue to retrieval. In this paper, we proposed a geometric reasoning approach to generate hierarchy for B-rep model retrieval. We extracted the winged-edge data structure to support series algorithms for underlying geometric reasoning, which is mainly composed of 3 steps to build hierarchy: partitioning, assembling and simplifying. This hierarchical representation is featured with level of detail ( L O D ) retaining geometric and topological information which is proved to be efficient in both global and partial retrieval. Our approach is based on the standard for the exchange of product information ( S T E P ) , which is suitable for data exchange between heterogeneous \{CAD\} systems. The result of case studies from prototype implementation demonstrates its effectiveness and efficiency. "} 
}
@article{MéndezCouz201559,
title = {"Functional interactions between dentate gyrus, striatum and anterior thalamic nuclei on spatial memory retrieval "},
journal = {"Brain Research "},
volume = {"1605"},
number = {""},
pages = {"59 - 69"},
year = {"2015"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2015.02.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899315000852"},
author = {"M. Méndez-Couz and N.M. Conejo and H. González-Pardo and J.L. Arias"},
keywords = {"Spatial memory retrieval", "Cytochrome c oxidase", "Brain network", "Dentate gyrus", "Thalamus", "Extended hippocampal system "},
abstract = {"Abstract The standard model of memory system consolidation supports the temporal reorganization of brain circuits underlying long-term memory storage, including interactions between the dorsal hippocampus and extra-hippocampal structures. In addition, several brain regions have been suggested to be involved in the retrieval of spatial memory. In particular, several authors reported a possible role of the ventral portion of the hippocampus together with the thalamus or the striatum in the persistence of this type of memory. Accordingly, the present study aimed to evaluate the contribution of different cortical and subcortical brain regions, and neural networks involved in spatial memory retrieval. For this purpose, we used cytochrome c oxidase quantitative histochemistry as a reliable method to measure brain oxidative metabolism. Animals were trained in a hidden platform task and tested for memory retention immediately after the last training session; one week after completing the task, they were also tested in a memory retrieval probe. Results showed that retrieval of the previously learned task was associated with increased levels of oxidative metabolism in the prefrontal cortex, the dorsal and ventral striatum, the anterodorsal thalamic nucleus and the dentate gyrus of the dorsal and ventral hippocampus. The analysis of functional interactions between brain regions suggest that the dorsal and ventral dentate gyrus could be involved in spatial memory retrieval. In addition, the results highlight the key role of the extended hippocampal system, thalamus and striatum in this process. Our study agrees with previous ones reporting interactions between the dorsal hippocampus and the prefrontal cortex during spatial memory retrieval. Furthermore, novel activation patterns of brain networks involving the aforementioned regions were found. These functional brain networks could underlie spatial memory retrieval evaluated in the Morris water maze task. "} 
}
@article{deLeeuw2015295,
title = {"Evaluation of seven European aerosol optical depth retrieval algorithms for climate analysis "},
journal = {"Remote Sensing of Environment "},
volume = {"162"},
number = {""},
pages = {"295 - 315"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2013.04.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425713003507"},
author = {"Gerrit de Leeuw and Thomas Holzer-Popp and Suzanne Bevan and William H. Davies and Jacques Descloitres and Roy G. Grainger and Jan Griesfeller and Andreas Heckel and Stefan Kinne and Lars Klüser and Pekka Kolmonen and Pavel Litvinov and Dmytro Martynenko and Peter North and Bertrand Ovigneur and Nicolas Pascal and Caroline Poulsen and Didier Ramon and Michael Schulz and Richard Siddans and Larisa Sogacheva and Didier Tanré and Gareth E. Thomas and Timo H. Virtanen and Wolfgang von Hoyningen Huene and Marco Vountas and Simon Pinnock"},
keywords = {"Aerosol retrieval algorithms", "Aerosol optical depth", "AATSR", "MERIS", "PARASOL "},
abstract = {"Abstract Satellite data are increasingly used to provide observation-based estimates of the effects of aerosols on climate. The Aerosol-cci project, part of the European Space Agency's Climate Change Initiative (CCI), was designed to provide essential climate variables for aerosols from satellite data. Eight algorithms, developed for the retrieval of aerosol properties using data from \{AATSR\} (4), \{MERIS\} (3) and POLDER, were evaluated to determine their suitability for climate studies. The primary result from each of these algorithms is the aerosol optical depth (AOD) at several wavelengths, together with the Ångström exponent (AE) which describes the spectral variation of the \{AOD\} for a given wavelength pair. Other aerosol parameters which are possibly retrieved from satellite observations are not considered in this paper. The \{AOD\} and \{AE\} (AE only for Level 2) were evaluated against independent collocated observations from the ground-based \{AERONET\} sun photometer network and against “reference” satellite data provided by \{MODIS\} and MISR. Tools used for the evaluation were developed for daily products as produced by the retrieval with a spatial resolution of 10 × 10 km2 (Level 2) and daily or monthly aggregates (Level 3). These tools include statistics for \{L2\} and \{L3\} products compared with AERONET, as well as scoring based on spatial and temporal correlations. In this paper we describe their use in a round robin (RR) evaluation of four months of data, one month for each season in 2008. The amount of data was restricted to only four months because of the large effort made to improve the algorithms, and to evaluate the improvement and current status, before larger data sets will be processed. Evaluation criteria are discussed. Results presented show the current status of the European aerosol algorithms in comparison to both \{AERONET\} and \{MODIS\} and \{MISR\} data. The comparison leads to a preliminary conclusion that the scores are similar, including those for the references, but the coverage of \{AATSR\} needs to be enhanced and further improvements are possible for most algorithms. None of the algorithms, including the references, outperforms all others everywhere. \{AATSR\} data can be used for the retrieval of \{AOD\} and \{AE\} over land and ocean. \{PARASOL\} and one of the \{MERIS\} algorithms have been evaluated over ocean only and both algorithms provide good results. "} 
}
@article{Habibi201638,
title = {"Question answering in conversations: Query refinement using contextual and semantic information "},
journal = {"Data & Knowledge Engineering "},
volume = {"106"},
number = {""},
pages = {"38 - 51"},
year = {"2016"},
note = {""},
issn = {"0169-023X"},
doi = {"https://doi.org/10.1016/j.datak.2016.06.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169023X16300489"},
author = {"Maryam Habibi and Parvaz Mahdabi and Andrei Popescu-Belis"},
keywords = {"Query refinement", "Query expansion", "Context modeling", "Speech-based information retrieval", "Evaluation of information retrieval "},
abstract = {"Abstract This paper introduces a query refinement method applied to questions asked by users to a system during a meeting or a conversation that they have with other users. To answer the questions, the proposed method leverages the local context of the conversation along with semantic resources, either WordNet or word embeddings from word2vec. The method first represents the local context by extracting keywords from the transcript of the conversation, which is obtained from a real-time Automatic Speech Recognition (ASR) system and may contain noise. It then expands the queries with keywords that best represent the topic of the query, i.e. expansion keywords accompanied by weights indicating their topical similarity to the query. Finally, semantically related terms are added, using two options: either synonymous terms drawn from WordNet or similar words based on distributed representations in a low-dimensional word embedding space learned using word2vec. To evaluate the system, we introduce a dataset (named \{AREX\} for \{AMI\} Requests for Explanations) and an evaluation metric based on relevance judgments collected by crowdsourcing. We compare our query expansion approach with other methods, over queries from the \{AREX\} dataset, showing the superiority of our method when either manual or automatic transcripts of the \{AMI\} Meeting Corpus are used. "} 
}
@article{Wang2015132,
title = {"MARCH: Multiscale-arch-height description for mobile retrieval of leaf images "},
journal = {"Information Sciences "},
volume = {"302"},
number = {""},
pages = {"132 - 148"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.07.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514007282"},
author = {"Bin Wang and Douglas Brown and Yongsheng Gao and John La Salle"},
keywords = {"Plant identification", "Shape description", "Shape matching", "Leaf image retrieval", "Mobile leaf identification "},
abstract = {"Abstract In this paper, we propose a novel shape description method for mobile retrieval of leaf images. In this method, termed multiscale arch height (MARCH), hierarchical arch height features at different chord spans are extracted from each contour point to provide a compact, multiscale shape descriptor. Both the global and detailed features of the leaf shape can be effectively captured by the proposed algorithm. \{MARCH\} descriptors are compared using a simple L1-norm based dissimilarity measurement providing very fast shape matching. The algorithm has been tested on four publicly available leaf image datasets including the Swedish leaf dataset, the Flavia leaf dataset, the \{ICL\} leaf dataset and the scanned subset of the ImageCLEF leaf dataset. The experiments indicate that the proposed method can achieve a higher classification rate and retrieval accuracy than the state-of-the-art benchmarks with a more than 500 times faster retrieval speed. A mobile retrieval system embedding the proposed algorithms has been developed for the real application of leaf image retrieval. "} 
}
@article{Bonnì201570,
title = {"\{TMS\} evidence for a selective role of the precuneus in source memory retrieval "},
journal = {"Behavioural Brain Research "},
volume = {"282"},
number = {""},
pages = {"70 - 75"},
year = {"2015"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2014.12.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432814008286"},
author = {"Sonia Bonnì and Domenica Veniero and Chiara Mastropasqua and Viviana Ponzo and Carlo Caltagirone and Marco Bozzali and Giacomo Koch"},
keywords = {"Precuneus", "Continuous theta burst stimulation", "Source memory", "Retrieval "},
abstract = {"Abstract The posteromedial cortex including the precuneus (PC) is thought to be involved in episodic memory retrieval. Here we used continuous theta burst stimulation (cTBS) to disentangle the role of the precuneus in the recognition memory process in a sample of healthy subjects. During the encoding phase, subjects were presented with a series of colored pictures. Afterwards, during the retrieval phase, all previously presented items and a sample of new pictures were presented in black, and subjects were asked to indicate whether each item was new or old, and in the latter case to indicate the associated color. cTBS was delivered over PC, posterior parietal cortex (PPC) and vertex before the retrieval phase. The data were analyzed in terms of hits, false alarms, source errors and omissions. cTBS over the precuneus, but not over the \{PPC\} or the vertex, induced a selective decrease in source memory errors, indicating an improvement in context retrieval. All the other accuracy measurements were unchanged. These findings suggest a direct implication of the precuneus in successful context-dependent retrieval. "} 
}
@article{khodaskar2015298,
title = {"New-Fangled Alignment of Ontologies for Content Based Semantic Image Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"48"},
number = {""},
pages = {"298 - 303"},
year = {"2015"},
note = {"International Conference on Computer, Communication and Convergence (ICCC 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.185"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915006948"},
author = {"Anuja khodaskar and Siddarth Ladhake"},
keywords = {"Content based image retrieval", "Domain ontology", "Metadata ontology", "Multiple ontology", "Semantic gap "},
abstract = {"Abstract This paper highlights content based image retrieval system using alignment of ontologies. The traditional contents-based image retrieval systems using single ontology retrieve imprecise images. To overcome this weakness, proposed image retrieval system designed using core semantic multiple ontology which merges feature ontology, semantic feature ontology, user ontology and metadata ontology. Proposed content based image retrieval system reduce semantic gap and provides highly accurate, efficient and effective image retrieval result. "} 
}
@article{Rimmele2015102,
title = {"Emotional memory can be persistently weakened by suppressing cortisol during retrieval "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"119"},
number = {""},
pages = {"102 - 107"},
year = {"2015"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2015.01.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S107474271500026X"},
author = {"Ulrike Rimmele and Luciana Besedovsky and Tanja Lange and Jan Born"},
keywords = {"Cortisol", "Suppression", "Metyrapone", "Memory", "Retrieval", "Recall "},
abstract = {"Abstract Cortisol’s effects on memory follow an inverted U-shaped function such that memory retrieval is impaired with very low concentrations, presumably due to insufficient activation of high-affine mineralocorticoid receptors (MR), or with very high concentrations, due to predominant low-affine glucocorticoid receptor (GR) activation. Through corresponding changes in re-encoding, the retrieval effect of cortisol might translate into a persistent change of the retrieved memory. We tested whether partial suppression of morning cortisol synthesis by metyrapone, leading to intermediate, circadian nadir-like levels with presumed predominant \{MR\} activation, improves retrieval, particularly of emotional memory, and persistently changes the memory. In a randomized, placebo-controlled, double-blind, within-subject cross-over design, 18 men were orally administered metyrapone (1 g) vs. placebo at 4:00 \{AM\} to suppress the morning cortisol rise. Retrieval of emotional and neutral texts and pictures (learned 3 days earlier) was assessed 4 h after substance administration and a second time one week later. Metyrapone suppressed endogenous cortisol release to circadian nadir-equivalent levels at the time of retrieval testing. Contrary to our expectations, metyrapone significantly impaired free recall of emotional texts (p &lt; .05), whereas retrieval of neutral texts or pictures remained unaffected. One week later, participants still showed lower memory for emotional texts in the metyrapone than placebo condition (p &lt; .05). Our finding that suppressing morning cortisol to nadir-like concentrations not only impairs acute retrieval, but also persistently weakens emotional memories corroborates the concept that retrieval effects of cortisol produce persistent memory changes, possibly by affecting re-encoding. "} 
}
@article{Heiner20151089,
title = {"\{THA\} Retrievals: The Need to Mark the Anatomic Orientation of the Femoral Head "},
journal = {"The Journal of Arthroplasty "},
volume = {"30"},
number = {"6"},
pages = {"1089 - 1094"},
year = {"2015"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2015.01.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540315000455"},
author = {"Anneliese D. Heiner and Karen M. Kruger and Nishant M. Tikekar and John J. Callaghan and John J. Lannutti and Thomas D. Brown"},
keywords = {"damage", "femoral head", "finite element analysis", "retrieval analysis", "total hip arthroplasty", "wear "},
abstract = {"Abstract The hypothesis of this study was that the rotational orientation of femoral head damage would greatly affect the volumetric wear rate of the opposing polyethylene (PE) liner. Damage on twenty retrieved cobalt–chromium femoral heads was simulated in a validated damage-feature-based finite element model. For each individual retrieval, the anatomic orientation of the femoral head about the femoral neck axis was systematically varied, in 30° increments. The \{PE\} wear rate differential between the maximum- versus minimum-wear orientations was often sizable, as high as 7-fold. Knowing the correct femoral head anatomic orientation is therefore important when analyzing the effects of femoral head damage on \{PE\} liner wear. Surgeons retrieving modular femoral heads should routinely mark the anatomic orientation of those components. "} 
}
@incollection{Balakirsky2014245,
title = {"Chapter 15 - Algebraic Approaches to a Network-Type Private Information Retrieval "},
editor = {"Akhgar, Babak and ,  and Arabnia, Hamid R. "},
booktitle = {"Emerging Trends in \{ICT\} Security "},
publisher = {"Morgan Kaufmann"},
edition = {""},
address = {"Boston"},
year = {"2014"},
pages = {"245 - 252"},
isbn = {"978-0-12-411474-6"},
doi = {"https://doi.org/10.1016/B978-0-12-411474-6.00015-3"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780124114746000153"},
author = {"Vladimir B. Balakirsky and Anahit R. Ghazaryan"},
keywords = {"privacy", "cryptography", "networking", "encoding", "decoding "},
abstract = {"We propose a network-type scheme of private information retrieval, presented as a modification of the conventional setup, where the user is replaced with two users, the user-sender and the user-receiver. As a result of communication, the user-receiver becomes informed about the bit located at a certain position of the database, owned by the servers. Each server receives a query from the user-sender that contains information about the position in a hidden form and the server cannot disclose this position. On the basis of the query and the database, each server forms the replica, which is then transmitted to the user-receiver. By combining replicas, the user-receiver decodes the retrieved bit. We present a simple algebraic scheme where the communication complexity and the computational complexity are expressed as functions of the logarithm of the database size. The approaches allow extensions to the one-server scheme, the multi-scheme with noisy replicas of a fixed number of servers, and the authentication of a certain fragment of the database. "} 
}
@article{Atkinson201520,
title = {"Improving opinion retrieval in social media by combining features-based coreferencing and memory-based learning "},
journal = {"Information Sciences "},
volume = {"299"},
number = {""},
pages = {"20 - 31"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.12.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514011608"},
author = {"John Atkinson and Gonzalo Salas and Alejandro Figueroa"},
keywords = {"Opinion retrieval", "Memory-based learning", "Linguistic coreferencing", "Text mining", "Natural language processing", "Opinion mining "},
abstract = {"Abstract Social networks messaging typically contains a lot of implicit linguistic information partially due to restrictions on a message’s length (i.e., few named entities, short sentences, no discourse structure, etc.). This may significantly impact several applications including opinion mining, sentiment analysis, etc., as data collection tasks such as opinion retrieval tasks will fail to obtain all the relevant messages whenever the target topic, objects, or features are not explicit within the texts. In order to address these issues, in this paper a novel adaptive approach for opinion retrieval is proposed. It combines natural-language co-referencing techniques, features-based linguistic preprocessing and memory-based learning to resolving implicit co-referencing within informal opinion texts by using underlying hierarchies of thread messages. Experiments were conducted to assess the ability of the model to improve opinion retrieval by resolving implicit entities and features, showing the promise of our opinion retrieval approach when compared to state-of-the-art methods using text data from social networks. "} 
}
@article{Mohammadkhani2015209,
title = {"Glucocorticoid-induced impairment of long-term memory retrieval in female rats: Influences of estrous cycle and estrogen "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"118"},
number = {""},
pages = {"209 - 215"},
year = {"2015"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.12.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714002251"},
author = {"Raziyeh Mohammadkhani and Niloufar Darbandi and Abbas Ali Vafaei and Ali Ahmadalipour and Ali Rashidy-Pour"},
keywords = {"Corticosterone", "Estrous cycle", "Memory retrieval", "Inhibitory avoidance task "},
abstract = {"Abstract Using an inhibitory avoidance (IA) task, the effects of glucocorticoids on memory retrieval in intact and ovariectomized (OVX) female rats were investigated. Young adult female rats were trained in a one trial \{IA\} task (1-mA, 3-s footshock). The latency to reenter the dark compartment of the apparatus was recorded in the retention test performed 48 h after training. Pre-retrieval injection of corticosterone (CORT, 1, 3, and 10 mg/kg) to \{OVX\} rats impaired memory retrieval at all doses tested. Similar administration of \{CORT\} (3 mg/kg) in intact female rats impaired memory retrieval in the estrus phase (when endogenous plasma levels of estrogen are low) but not in the proestrus phase (when endogenous levels of estrogen are high). Concurrent administration of \{CORT\} (3 mg/kg) and 17-β-estradiol (15 μg/kg) in both proestrus and estrous phases impaired memory retrieval. Our findings indicate that the effects of corticosterone on memory retrieval are modulated by the estrous cycle and 17-β-estradiol. "} 
}
@incollection{Storm2015141,
title = {"Chapter Five - A Review of Retrieval-Induced Forgetting in the Contexts of Learning, Eyewitness Memory, Social Cognition, Autobiographical Memory, and Creative Cognition "},
editor = {"BRIAN H. ROSS"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2015"},
volume = {"62"},
pages = {"141 - 194"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/bs.plm.2014.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0079742114000061"},
author = {"Benjamin C. Storm and Genna Angello and Dorothy R. Buchli and Rebecca H. Koppel and Jeri L. Little and John F. Nestojko"},
keywords = {"Autobiographical memory", "Creative cognition", "Eyewitness memory", "Memory", "Retrieval-induced forgetting", "Social cognition", "Testing effects "},
abstract = {"Abstract Retrieving information from memory can cause the forgetting of other information in memory, a phenomenon referred to as retrieval-induced forgetting. Over the past 20 years, retrieval-induced forgetting has been observed in a variety of experimental contexts and has been argued to impact a number of cognitive and psychological processes. Not simply a laboratory phenomenon, retrieval-induced forgetting appears to have important implications for furthering our basic understanding of memory and behavior. In the present chapter, we provide a selective review of retrieval-induced forgetting in five contexts—learning and education, eyewitness memory, social cognition, autobiographical memory, and creative cognition—and discuss the importance of studying retrieval-induced forgetting in situations beyond the typical retrieval-practice paradigm. "} 
}
@article{khodaskar2015282,
title = {"Promising Large Scale Image Retrieval by Using Intelligent Semantic Binary Code Generation Technique "},
journal = {"Procedia Computer Science "},
volume = {"48"},
number = {""},
pages = {"282 - 287"},
year = {"2015"},
note = {"International Conference on Computer, Communication and Convergence (ICCC 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.183"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915006924"},
author = {"Anuja khodaskar and Siddarth Ladhake"},
keywords = {"Accuracy", "Content based image retrieval", "Hashing function", "Large scale database", "Retrieval time", "Web based image retrieval "},
abstract = {"Abstract A scalable content based image retrieval system for large-scale www database is designed and implemented. Million images on internet is big challenge for accurate and efficient image retrieval as per user requirement. Proposed system exploits semantic binary code generation techniques with semantic hashing function, fine and coarse similarity measure technique, automatic and manual relevance feedback technique which improve accuracy, speed of image retrieval. With dramatic growth of internet technology, scalable image retrieval system is a need of recent web based image retrieval applications such as biomedical imaging, medical diagnosis, space science application etc. Proposed system accomplish requirement of scalable, accurate and swift image retrieval system. Experimental result clearly shows that performance of image retrieval is improved in term of accuracy, efficiency and retrieval time. "} 
}
@article{Jia2015232,
title = {"Query difficulty estimation via relevance prediction for image retrieval "},
journal = {"Signal Processing "},
volume = {"110"},
number = {""},
pages = {"232 - 243"},
year = {"2015"},
note = {"Machine learning and signal processing for human pose recovery and behavior analysis "},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.07.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414003521"},
author = {"Qianghuai Jia and Xinmei Tian"},
keywords = {"Query difficulty estimation", "Image retrieval", "Average precision", "Pseudo relevance feedback", "Voting scheme "},
abstract = {"Abstract Query difficulty estimation (QDE) attempts to automatically predict the performance of the search results returned for a given query. \{QDE\} has long been of interest in text retrieval. However, few research works have been conducted in image retrieval. Existing \{QDE\} methods in image retrieval mainly explore the statistical characteristics (coherence, specificity, etc.) of the returned images to derive a value for indicating the query difficulty degree. To the best of our knowledge, little research has been done to directly estimate the real search performance, such as average precision. In this paper, we propose a novel query difficulty estimation approach which automatically estimates the average precision of the image search results. Specifically, we first adaptively select a set of query relevant and query irrelevant images for each query via modified pseudo relevance feedback. Then a simple but effective voting scheme and two estimation methods (hard estimation and soft estimation) are proposed to estimate the relevance probability of each image in the search results. Based on the images׳ relevance probabilities, the average precision for each query is derived. The experimental results on two benchmark image search datasets demonstrate the effectiveness of the proposed method. "} 
}
@article{Lu201554,
title = {"Finding more relevance: Propagating similarity on Markov random field for object retrieval "},
journal = {"Signal Processing: Image Communication "},
volume = {"32"},
number = {""},
pages = {"54 - 68"},
year = {"2015"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2015.01.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596515000168"},
author = {"Peng Lu and Xujun Peng and Xinshan Zhu and Ruifan Li"},
keywords = {"Image retrieval", "Bag-of-visual-words", "Markov random field "},
abstract = {"Abstract To retrieve objects from large corpus with high accuracy is a challenging task. In this paper, we propose a Markov random field (MRF) based probabilistic retrieval framework. In this framework, the similarities between the query image and dataset images are modeled as the likelihood and the relationships among the images in the dataset are modeled as the prior. Then, the prior and the likelihood are combined to improve retrieval performance. Further, we present an approximate belief propagation algorithm as well as a subgraph extraction algorithm for efficient inference in MRF. Finally, we design a new image retrieval system under our framework. This system can be considered as an extended bag-of-visual-words retrieval system with the probabilistic based re-ranking module. We evaluate our method on three standard datasets: Oxford-5K, Oxford-105K and Paris-6K. The experimental results show that the proposed system significantly improves the retrieval accuracy on these datasets and exceeds the state-of-the-art results. "} 
}
@article{Chen2015117,
title = {"\{ROI\} image retrieval based on multiple features of mean shift and expectation–maximisation "},
journal = {"Digital Signal Processing "},
volume = {"40"},
number = {""},
pages = {"117 - 130"},
year = {"2015"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2015.01.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200415000238"},
author = {"Wenbing Chen and Qizhou Li and Keshav Dahal"},
keywords = {"Image retrieval", "Mean shift", "EM", "Colour histogram", "Spatial distribution "},
abstract = {"Abstract In this paper, a novel region of interest (ROI) query method is proposed for image retrieval by combining a mean shift tracking (MST) algorithm and an improved expectation–maximisation (EM)-like (IEML) method. In the proposed combination, the \{MST\} is used to seek the initial location of the target candidate model and then \{IEML\} is used to adaptively change the location and scale of the target candidate model to include the relevant region and exclude the irrelevant region as far as possible. In order to improve the performance and effectiveness using \{IEML\} to track the target candidate model, a new similarity measure is built based on spatial and colour features and a new image retrieval framework for this new environment is proposed. Extensive experiments confirm that compared with the latest developed approaches, such as the generalized Hough transform (GHT) and EM-like tracking methods, our method can provide a much better performance in effectiveness. On the other hand, for the IEML, the new similarity measure model also substantially decreases computational complexity and improves the precision tracking of the target candidate model. Compared with the conventional ROI-based image retrieval methods, the most significant highlight is that the proposed method can directly find the target candidate model in the candidate image without pre-segmentation in advance. "} 
}
@article{Evans2015435,
title = {"Electrophysiological evidence for retrieval mode immediately after a task switch "},
journal = {"NeuroImage "},
volume = {"108"},
number = {""},
pages = {"435 - 440"},
year = {"2015"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2014.12.068"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811914010738"},
author = {"Lisa H. Evans and Angharad N. Williams and Edward L. Wilding"},
keywords = {"Retrieval mode", "Episodic memory", "Task-switching", "Event-related potentials (ERPs)", "Task-set", "Retrieval preparation "},
abstract = {"Abstract It has been suggested that retrieving episodic information can involve adopting a cognitive state or set: retrieval mode. In a series of studies, an event-related potential (ERP) index of retrieval mode has been identified in designs which cue participants on a trial-by-trial basis to switch between preparing for and then completing an episodic or non-episodic retrieval task. However, a confound in these studies is that along with task type the content of what is to be retrieved has varied. Here we examined whether the \{ERP\} index of retrieval mode remains when the contents of an episodic and non-episodic task are highly similar – both requiring a location judgement. In the episodic task participants indicated the screen location where words had been shown in a prior study phase (left/right/new); whereas in the perceptual task they indicated the current screen location of the word (top/middle/bottom). Consistent with previous studies the \{ERPs\} elicited while participants prepared for episodic retrieval were more positive-going at right-frontal sites than when they prepared for the perceptual task. This index was observed, however, on the first trial after participants had switched tasks, rather than on the second trial, as has been observed previously. Potential reasons for this are discussed, including the critical manipulation of similarity in contents between tasks, as well as the use of a predictable cue sequence. "} 
}
@article{Coyne2015742,
title = {"Retrieval Practice as an Effective Memory Strategy in Children and Adolescents With Traumatic Brain Injury "},
journal = {"Archives of Physical Medicine and Rehabilitation "},
volume = {"96"},
number = {"4"},
pages = {"742 - 745"},
year = {"2015"},
note = {""},
issn = {"0003-9993"},
doi = {"https://doi.org/10.1016/j.apmr.2014.09.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0003999314011290"},
author = {"Julia H. Coyne and Jacquelyn M. Borg and John DeLuca and Leslie Glass and James F. Sumowski"},
keywords = {"Memory", "Rehabilitation", "Testing effect", "Traumatic brain injury "},
abstract = {"AbstractObjective To investigate whether retrieval practice (RP) is a more effective memory strategy than restudy in children and adolescents with traumatic brain injury (TBI). Design Three × two within-subjects experiment: 3 (learning condition: massed restudy [MR], spaced restudy [SR], retrieval practice [RP]) × 2 (stimulus type: verbal paired associates [VPAs] and face-name pairs [FNPs]). The dependent measure was delayed recall of \{VPAs\} and FNPs. Setting Subacute pediatric neurorehabilitation center. Participants Pediatric survivors of \{TBI\} (N=15) aged 8 to 16 years with below-average memory. Intervention During RP, participants were quizzed on to-be-learned information (VPAs and FNPs) shortly after it was presented, such that they practiced retrieval during the learning phase. \{MR\} consisted of repeated restudy (tantamount to cramming). \{SR\} consisted of restudy trials separated in time (ie, distributed learning). Main Outcome Measures Delayed recall of 24 \{VPAs\} and 24 \{FNPs\} after a 25-minute delay. \{VPAs\} and \{FNPs\} were equally divided across 3 learning conditions (16 per condition). Results There was a large main effect of learning condition on delayed recall (P&lt;.001; ηp2=.84), with better mean recall of \{VPAs\} and \{FNPs\} studied through \{RP\} (6.23±1.39) relative to \{MR\} (3.60±1.53; P&lt;.001) and \{SR\} (4.77±1.39; P&lt;.001). Moreover, \{RP\} was the single best learning strategy for every participant. Conclusions Memory problems and related academic learning difficulties are common after pediatric TBI. Herein, we identify \{RP\} as a promising and simple strategy to support learning and improve memory in children and adolescents with TBI. Our experimental findings were quite robust and set the stage for subsequent randomized controlled trials of \{RP\} in pediatric TBI. "} 
}
@article{Jiji2015650,
title = {"Content-based image retrieval techniques for the analysis of dermatological lesions using particle swarm optimization technique "},
journal = {"Applied Soft Computing "},
volume = {"30"},
number = {""},
pages = {"650 - 662"},
year = {"2015"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2015.01.058"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494615000794"},
author = {"G. Wiselin Jiji and P. Johnson DuraiRaj"},
keywords = {"Retrieval", "Features", "Classification", "Particle swarm optimization "},
abstract = {"Abstract This method presents extraction of effective color and shape features for the analysis of dermatology images. We employ three phases of operation in order to perform efficient retrieval of images of skin lesions. Our proposed algorithm used color and shape feature vectors and the features are normalized using Min–Max normalization. Particle swarm optimization (PSO) technique for multi-class classification is used to converge the search space more efficiently. The results using receiver operating characteristic (ROC) curve proved that the proposed architecture is highly contributed to computer-aided diagnosis of skin lesions. Experiments on a set of 1450 images yielded a specificity of 98.22% and a sensitivity of 94%. Our empirical evaluation has a superior retrieval and diagnosis performance when compared to the performance of other works. We present explicit combinations of feature vectors corresponding to healthy and lesion skin. "} 
}
@incollection{Gilboa2015608,
title = {"Retrieval "},
editor = {"Wright, James D. "},
booktitle = {"International Encyclopedia of the Social & Behavioral Sciences (Second Edition) "},
publisher = {"Elsevier"},
edition = {"Second Edition"},
address = {"Oxford"},
year = {"2015"},
pages = {"608 - 612"},
isbn = {"978-0-08-097087-5"},
doi = {"https://doi.org/10.1016/B978-0-08-097086-8.51057-5"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780080970868510575"},
author = {"Asaf Gilboa"},
keywords = {"Cue description", "Direct retrieval", "Ecphory", "Encoding specificity", "Engram", "Feeling of keywords =nowing", "Feeling of rightness", "Generate-recognize", "Levels of processing", "Memory cue", "Memory trace", "Retrieval mode", "Source-constrained retrieval", "Source monitoring", "Working with memory "},
abstract = {"Abstract Retrieval refers to a set of processes that support the recovery of stored memories. At its heart is the ecphoric process that involves an interaction between memory cues and memory traces, and the conversion of ecphoric information into conscious awareness. Retrieval also involves a set of preecphoric processes that support the search for appropriate memory cues and memory traces, and a set of postecphoric monitoring and control processes that evaluate the veracity and appropriateness of retrieved memories and endorse report decisions. "} 
}
@article{Bogdanoff20151,
title = {"Sensitivity of infrared sea surface temperature retrievals to the vertical distribution of airborne dust aerosol "},
journal = {"Remote Sensing of Environment "},
volume = {"159"},
number = {""},
pages = {"1 - 13"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2014.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425714004787"},
author = {"Alec S. Bogdanoff and Douglas L. Westphal and James R. Campbell and James A. Cummings and Edward J. Hyer and Jeffrey S. Reid and Carol Anne Clayson"},
keywords = {"Dust aerosols", "Sea surface temperature", "Retrieval error", "Radiative transfer", "Infrared remote sensing "},
abstract = {"Abstract Sea surface temperature retrievals using the Advanced Very High Resolution Radiometer are highly sensitive to cloud cover and coarse mode aerosol particles such as dust. Operationally, techniques are used to flag contaminated retrievals; however, these techniques are less precise in removing dust-contaminated values. A commonly stated metric of quality for \{SST\} daytime retrievals is 0.5 °C; thus dust contents that produce errors greater than this value should be of concern. Here we report on significant correlation between potential \{SST\} error and observed aerosol optical depths (AOD) that was found in the tropical region dominated by Saharan dust. Utilizing a radiative transfer model with variable dust contents and typical vertical distributions, errors greater than the desired 0.5 °C accuracy are observed for dust \{AODs\} as low as 0.05. Errors of over 1 °C occur with 0.25 AOD. Analysis of the \{AERONET\} data from Cape Verde, which includes the Saharan Air Layer off the west coast of Africa, reveals that 90% of the days during the boreal summer are found to have \{AOD\} amounts that correspond to error greater than 0.5 °C. We found that a correction accurate within 0.25 °C requires a mean accuracy of 0.1 \{AOD\} and proper vertical placement of the dust layer within 250 m. While empirical \{SST\} retrievals often have some measure of climatological dust contamination built into them, this work shows that typical variability in dust loadings is a non-trivial error source against \{SST\} retrieval goals. "} 
}
@article{Li20151,
title = {"A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries "},
journal = {"Computer Vision and Image Understanding "},
volume = {"131"},
number = {""},
pages = {"1 - 27"},
year = {"2015"},
note = {"Special section: Large Scale Data-Driven Evaluation in Computer Vision "},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2014.10.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314214002100"},
author = {"Bo Li and Yijuan Lu and Chunyuan Li and Afzal Godil and Tobias Schreck and Masaki Aono and Martin Burtscher and Qiang Chen and Nihad Karim Chowdhury and Bin Fang and Hongbo Fu and Takahiko Furuya and Haisheng Li and Jianzhuang Liu and Henry Johan and Ryuichi Kosaka and Hitoshi Koyanagi and Ryutarou Ohbuchi and Atsushi Tatsuma and Yajuan Wan and Chaoli Zhang and Changqing Zou"},
keywords = {"3D shape retrieval", "Large-scale benchmark", "Multimodal queries", "Unified", "Performance evaluation", "Query-by-Model", "Query-by-Sketch", "SHREC "},
abstract = {"Abstract Large-scale 3D shape retrieval has become an important research direction in content-based 3D shape retrieval. To promote this research area, two Shape Retrieval Contest (SHREC) tracks on large scale comprehensive and sketch-based 3D model retrieval have been organized by us in 2014. Both tracks were based on a unified large-scale benchmark that supports multimodal queries (3D models and sketches). This benchmark contains 13680 sketches and 8987 3D models, divided into 171 distinct classes. It was compiled to be a superset of existing benchmarks and presents a new challenge to retrieval methods as it comprises generic models as well as domain-specific model types. Twelve and six distinct 3D shape retrieval methods have competed with each other in these two contests, respectively. To measure and compare the performance of the participating and other promising Query-by-Model or Query-by-Sketch 3D shape retrieval methods and to solicit state-of-the-art approaches, we perform a more comprehensive comparison of twenty-six (eighteen originally participating algorithms and eight additional state-of-the-art or new) retrieval methods by evaluating them on the common benchmark. The benchmark, results, and evaluation tools are publicly available at our websites (http://www.itl.nist.gov/iad/vug/sharp/contest/2014/Generic3D/, 2014, http://www.itl.nist.gov/iad/vug/sharp/contest/2014/SBR/, 2014). "} 
}
@article{Liu2015583,
title = {"Locality-constrained sparse patch coding for 3D shape retrieval "},
journal = {"Neurocomputing "},
volume = {"151, Part 2"},
number = {""},
pages = {"583 - 592"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.06.090"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214013927"},
author = {"Zhenbao Liu and Shuhui Bu and Junwei Han"},
keywords = {"3D shape retrieval", "Patch", "Sparse coding", "Locality constraint "},
abstract = {"Abstract 3D shape retrieval is a fundamental task in many domains such as multimedia, graphics, CAD, and amusement. In this paper, we propose a 3D object retrieval approach by effectively utilizing low-level patches of 3D shapes, which are similar as superpixels in images. These patches are first obtained by means of stably over-segmenting 3D shape, and then we adopt five representative geometric features including shape diameter function, average geodesic distance, and heat kernel signature, to characterize these low-level patches. A large number of patches collected from shapes in a dataset are encoded into patch words by virtue of locality-constrained sparse coding under the consideration of local smooth sparsity. Input query is compared with 3D models in the dataset through probability distribution of patch words. Experiments reveal that the proposed method achieves comparable retrieval performance to state-of-the-art methods. "} 
}
@article{Wang2015612,
title = {"Hypergraph based feature fusion for 3-D object retrieval "},
journal = {"Neurocomputing "},
volume = {"151, Part 2"},
number = {""},
pages = {"612 - 619"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.03.090"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214013812"},
author = {"Fanglin Wang and Jialiang Peng and Yongjie Li"},
keywords = {"3-D object retrieval", "Hypergraph learning", "Dense Kerne LBP", "Feature fusion "},
abstract = {"Abstract In view-based 3D object retrieval, each object is represented by a set of image views. 3D object retrieval becomes a group matching problem under such definition. Recent works have shown the effectiveness of hypergraph learning that computes the distance between 3D objects by solving a hypergraph structure problem. However, the single feature used in most of state-of-the-art works is often not sufficient to describe a 3D object. In this paper, we propose a feature fusion method based on hypergraph for 3D object retrieval. Besides the frequently used Zernike moments feature, we propose a Dense Kernel Local Binary Feature (DKLBP) feature for 3D object view description. A feature fusion method is proposed under the hypgraph framework. Experiments are conducted on the popular ETH-80 and National Taiwan University 3D model datatsets. Extensive experimental results show that the proposed approach has made significant performance improvement compared to other competitive approaches in recent works. "} 
}
@article{Feng201550,
title = {"Deep correspondence restricted Boltzmann machine for cross-modal retrieval "},
journal = {"Neurocomputing "},
volume = {"154"},
number = {""},
pages = {"50 - 60"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.12.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214016841"},
author = {"Fangxiang Feng and Ruifan Li and Xiaojie Wang"},
keywords = {"Cross-modal", "RBM", "Retrieval", "Deep Learning", "Multi-modal "},
abstract = {"Abstract The task of cross-modal retrieval, i.e., using a text query to search for images or vice versa, has received considerable attention with the rapid growth of multi-modal web data. Modeling the correlations between different modalities is the key to tackle this problem. In this paper, we propose a correspondence restricted Boltzmann machine (Corr-RBM) to map the original features of bimodal data, such as image and text in our setting, into a low-dimensional common space, in which the heterogeneous data are comparable. In our Corr-RBM, two \{RBMs\} built for image and text, respectively are connected at their individual hidden representation layers by a correlation loss function. A single objective function is constructed to trade off the correlation loss and likelihoods of both modalities. Through the optimization of this objective function, our Corr-RBM is able to capture the correlations between two modalities and learn the representation of each modality simultaneously. Furthermore, we construct two deep neural structures using Corr-RBM as the main building block for the task of cross-modal retrieval. A number of comparison experiments are performed on three public real-world data sets. All of our models show significantly better results than state-of-the-art models in both searching images via text query and vice versa. "} 
}
@article{Chaker2015174,
title = {"Disparity based stereo image retrieval through univariate and bivariate models "},
journal = {"Signal Processing: Image Communication "},
volume = {"31"},
number = {""},
pages = {"174 - 184"},
year = {"2015"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2014.12.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596514001829"},
author = {"A. Chaker and M. Kaaniche and A. Benazza-Benyahia"},
keywords = {"Content based image retrieval", "Wavelet domain", "Stereo pairs", "Disparity map", "Feature extraction "},
abstract = {"Abstract The widespread use of stereovision in various application fields has led to the constitution of very huge stereo image databases. Therefore, the design of effective content based image retrieval system devoted to stereo pairs becomes an issue of importance. To this end, we propose in this paper two retrieval methods which combine the visual contents of the stereo images with their corresponding disparity information. After modeling the distribution of their associated wavelet coefficients by the generalized Gaussian statistical model, the resulting distribution parameters are selected as salient features. While the two views are processed separately through a univariate modeling in the first method, the second one exploits the correlation between the views by resorting to a bivariate modeling. Experimental results show the benefits which can be drawn from the proposed retrieval approaches. "} 
}
@article{Li2015127,
title = {"Wave-front reconstruction with Hartmann–Shack sensor using a phase-retrieval method "},
journal = {"Optics Communications "},
volume = {"336"},
number = {""},
pages = {"127 - 133"},
year = {"2015"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.09.086"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814009249"},
author = {"Jing Li and Yan Gong and Hongfu Chen and Xinrong Hu"},
keywords = {"Testing", "Active or adaptive optics", "Phase retrieval", "Wave-front sensing. "},
abstract = {"Abstract We apply a phase retrieval algorithm to the intensity patterns acquired from a Hartmann–Shack wave-front sensor to measure the wave-front aberration of a deep ultraviolet lithography system. The intensity patterns are obtained with and without the micro-lens array. Thus, we avoid selecting algorithm-specific parameters such as step-size and trust-region. Simulation results show that the phase-retrieval method enhances the accuracy of wave-front reconstruction compared with the conventional wave-front slope method. The relationships between the number of iterations of the phase retrieval algorithm, the calculating time and the wave-front reconstruction error are studied. This study demonstrates that the phase-retrieval method provides more accurate estimates of aberrations in near-flat wave-fronts relative to the wave-front slope method. "} 
}
@article{LopezSanchez201730,
title = {"Retrieval of vegetation height in rice fields using polarimetric \{SAR\} interferometry with TanDEM-X data "},
journal = {"Remote Sensing of Environment "},
volume = {"192"},
number = {""},
pages = {"30 - 44"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.02.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300536"},
author = {"Juan M. Lopez-Sanchez and Fernando Vicente-Guijalba and Esra Erten and Manuel Campos-Taberner and Francisco Javier Garcia-Haro"},
keywords = {"Agriculture", "TanDEM-X", "Rice", "Synthetic aperture radar (SAR)", "PolSAR", "Interferometry", "PolInSAR", "Vegetation height "},
abstract = {"Abstract This work presents for the first time a demonstration with satellite data of polarimetric \{SAR\} interferometry (PolInSAR) applied to the retrieval of vegetation height in rice fields. Three series of dual-pol interferometric \{SAR\} data acquired with large baselines (2–3 km) by the TanDEM-X system during its science phase (April–September 2015) are exploited. A novel inversion algorithm especially suited for rice fields cultivated in flooded soil is proposed and evaluated. The validation is carried out over three test sites located in geographically different areas: Sevilla (SW Spain), Valencia (E Spain), and Ipsala (W Turkey), in which different rice types are present. Results are obtained during the whole growth cycle and demonstrate that PolInSAR is useful to produce accurate height estimates (RMSE 10–20 cm) when plants are tall enough (taller than 25–40 cm), without relying on external reference information. "} 
}
@article{khodaskar2015263,
title = {"Advanced Image Retrieval with Topical Classification Strategy "},
journal = {"Procedia Computer Science "},
volume = {"48"},
number = {""},
pages = {"263 - 268"},
year = {"2015"},
note = {"International Conference on Computer, Communication and Convergence (ICCC 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.180"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915006894"},
author = {"Anuja khodaskar and Siddarth Ladhake"},
keywords = {"Accuracy", "Classification Strategy", "Image retrieval system", "Training rules", "Retrieval time ; "},
abstract = {"Abstract This paper proposed an advanced content based image retrieval system using topical rule based classification strategy which improve retrieval performance significantly. We also present overview of image classification which highlights categories of classification, factor affecting accuracy of classification and recent applications of classification with advanced techniques and help researchers to continue their work for improving classification accuracy. The proposed classification strategy used three training rules, low level, high level and expert rules which improve classification accuracy and effectiveness, ultimately encroachment in quality of classification. Experimental result shows performance evolution in precision, accuracy and retrieval time of image retrieval. "} 
}
@article{Jenni2015374,
title = {"Content Based Image Retrieval Using Colour Strings Comparison "},
journal = {"Procedia Computer Science "},
volume = {"50"},
number = {""},
pages = {"374 - 379"},
year = {"2015"},
note = {"Big Data, Cloud and Computing Challenges "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.04.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915005335"},
author = {"Kommineni Jenni and Satria Mandala and Mohd Shahrizal Sunar"},
keywords = {"Content based image retrieval", "Image Databases: colour string coding", "strings comparison ; "},
abstract = {"Abstract Content Based Image Retrieval (CBIR) is a technique that enables a user to extract an image based on a query, from a database containing a large amount of images. A very fundamental issue in designing a content based image retrieval system is to select the image features that best represent the image contents in a database. In this paper, our proposed method mainly concentrated on database classification and efficient image representation. We present a method for content based image retrieval based on support vector machine classifier. In this method the feature extraction was done based on the colour string coding and string comparison. We succeed in transferring the images retrieval problem to strings comparison. Thus the computational complexity is decreases obviously. The image database used in our experiment contains 1800 colour images from Corel photo galleries. This \{CBIR\} approach has significantly increased the accuracy in obtaining results for image retrieval. "} 
}
@article{Wang2015620,
title = {"3D Model Retrieval with Weighted Locality-constrained Group Sparse Coding "},
journal = {"Neurocomputing "},
volume = {"151, Part 2"},
number = {""},
pages = {"620 - 625"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.03.091"},
url = {"http://www.sciencedirect.com/science/article/pii/S092523121401385X"},
author = {"Xiangyu Wang and Weizhi Nie"},
keywords = {"Locality-constrained", "Group sparse coding", "3D model retrieval "},
abstract = {"Abstract In recent years, we have witnessed a flourishing of 3D object modelling. Efficient and effective 3D model retrieval algorithms are high desired and attracted intensive research attentions. In this work, we propose a view-based 3D model retrieval algorithm based on weighted locality-constrained group sparse coding. Representative views are first selected by clustering and the corresponding weights are provided by considering the relationship among these views. By grouping the views from 3D models, a locality-constrained group sparse coding method is employed to find the reconstruction residual for each query view. The distance between query model and candidate model is taken as the weighted sum of residual. The query model is matched to the model which can best reconstruct the query model. Experimental comparisons have been conducted on the \{ETH\} 3D model dataset, and the results have demonstrated the effectiveness of the proposed method. "} 
}
@article{Kuang201513,
title = {"Retrieval of non-rigid 3D shapes from multiple aspects "},
journal = {"Computer-Aided Design "},
volume = {"58"},
number = {""},
pages = {"13 - 23"},
year = {"2015"},
note = {"Solid and Physical Modeling 2014 "},
issn = {"0010-4485"},
doi = {"https://doi.org/10.1016/j.cad.2014.08.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S001044851400164X"},
author = {"Zhenzhong Kuang and Zongmin Li and Xiaxia Jiang and Yujie Liu and Hua Li"},
keywords = {"Non-rigid shape retrieval", "Multiple aspects", "Shape representation", "Retrieval optimization", "Shape filtering "},
abstract = {"Abstract As non-rigid 3D shape plays increasingly important roles in practical applications, this paper addresses its retrieval problem by considering three aspects: shape representation, retrieval optimization, and shape filtering. (1) For shape representation, two kinds of features are considered. We first propose a new integration kernel based local descriptor, and then an efficient voting scheme is designed for shape representation. Besides, we also study the commute times as shape distributions, which grasp the spatial shape information globally. Both of them capture shape information from different viewpoints based on the same embedding basis. (2) We then study the typical problem of retrieval optimization. Prior works show poor stability under different similarity windows. To deal with this deficiency, we propose to model the problem as a distance mapping on a graph in spectral manifold space. (3) Usually, for each retrieval input, a list is returned and there may be lots of irrelevant results. We develop an algorithm to filter them out by combining multiple kernels. Finally, three public datasets are employed for performance evaluation and the results show that the studied techniques have contributed a lot in promoting the recognition rate of non-rigid 3D shapes. "} 
}
@article{GSecodeHerrera201546,
title = {"Comparing fusion techniques for the ImageCLEF 2013 medical case retrieval task "},
journal = {"Computerized Medical Imaging and Graphics "},
volume = {"39"},
number = {""},
pages = {"46 - 54"},
year = {"2015"},
note = {"Medical visual information analysis and retrieval "},
issn = {"0895-6111"},
doi = {"https://doi.org/10.1016/j.compmedimag.2014.04.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895611114000445"},
author = {"Alba G. Seco de Herrera and Roger Schaer and Dimitrios Markonis and Henning Müller"},
keywords = {"Medical case-based retrieval", "Multimodal fusion", "Visual reranking", "ImageCLEF", "MedGIFT "},
abstract = {"Abstract Retrieval systems can supply similar cases with a proven diagnosis to a new example case under observation to help clinicians during their work. The ImageCLEFmed evaluation campaign proposes a framework where research groups can compare case-based retrieval approaches. This paper focuses on the case-based task and adds results of the compound figure separation and modality classification tasks. Several fusion approaches are compared to identify the approaches best adapted to the heterogeneous data of the task. Fusion of visual and textual features is analyzed, demonstrating that the selection of the fusion strategy can improve the best performance on the case-based retrieval task. "} 
}
@article{Huang201538,
title = {"An effective subpart retrieval approach of 3D \{CAD\} models for manufacturing process reuse "},
journal = {"Computers in Industry "},
volume = {"67"},
number = {""},
pages = {"38 - 53"},
year = {"2015"},
note = {""},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2014.12.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166361514002061"},
author = {"Rui Huang and Shusheng Zhang and Xiaoliang Bai and Changhong Xu and Bo Huang"},
keywords = {"Subpart retrieval", "Manufacturing process reuse", "Structured \{MBD\} model", "Coupled machining feature cluster", "Manufacturing semantics "},
abstract = {"Abstract As a vast number of 3D \{CAD\} models associated with manufacturing processes are generated each year, retrieval of 3D \{CAD\} models for achieving manufacturing process reuse is becoming an effective strategy for engineers to generate the process plan with less time and lower cost. However, there has been little research on how to find the similar subparts for manufacturing process reuse. In this paper, a novel subpart retrieval approach of 3D \{CAD\} models for manufacturing process reuse is presented. First, coupled machining feature cluster (CMFC) is introduced to represent the 3D \{CAD\} model into structured \{MBD\} (model-based definition) model taking machining features as the carrier of manufacturing semantics. Then, part layer code and \{CMFC\} content code for accelerating subpart retrieval are given to filter out unmatched subparts efficiently. Moreover, a multilevel feature descriptor capturing different levels of information for manufacturing process planning is designed to establish the machining feature similarity assessment model. Finally, the machining feature coupled graph (MFCG) based subpart matching algorithm is presented to calculate the similarity between matched subparts. A prototype system has been developed to verify the effectiveness of the proposed approach. "} 
}
@article{Kanimozhi20151099,
title = {"An integrated approach to region based image retrieval using firefly algorithm and support vector machine "},
journal = {"Neurocomputing "},
volume = {"151, Part 3"},
number = {""},
pages = {"1099 - 1111"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.07.078"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214013332"},
author = {"T. Kanimozhi and K. Latha"},
keywords = {"Region-based image retrieval", "Support vector machine", "Firefly algorithm", "Gaussian distribution", "Particle swarm optimization", "Genetic algorithm "},
abstract = {"Abstract Intelligent image retrieval is a challenging technology in multimedia applications where bridging the gap between user׳s expectation and low level features is typically hard for computing systems. In the proposed approach, a unique method is projected which integrates support vector machine based learning with an evolutionary stochastic algorithm, called firefly algorithm as a relevance feedback approach into a region based image retrieval system. This system overcomes the semantic gap through optimized iterative learning and also provides a better exploration of solution space. Support vector machine learning automatically updates the weights of preferences for relevant images based on the both relevant and irrelevant feedback images. The firefly optimizer guides the swarm agents to move towards the cluster of relevant images in the exploration of the search space based on user׳s feedback. This research study has a focused approach to increase the performance by optimizing region feature with the firefly algorithm. The efficiency of the proposed approach is experimented on the standard subset of Corel, Caltech and Pascal database images. The performance of the proposed approach is compared with other existing retrieval methods like particle swarm optimization, genetic algorithm, support vector machine and query point movement to identify the excellence with regard to the model in terms of precision and recall. "} 
}
@incollection{Hicks2015101,
title = {"Chapter Four - Using Multidimensional Encoding and Retrieval Contexts to Enhance Our Understanding of Stochastic Dependence in Source Memory "},
editor = {"BRIAN H. ROSS"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2015"},
volume = {"62"},
pages = {"101 - 140"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/bs.plm.2014.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S007974211400005X"},
author = {"Jason L. Hicks and Jeffrey J. Starns"},
keywords = {"Context memory", "External cuing", "Feature independence", "Multidimensional source memory", "Source retrieval", "Stochastic dependence "},
abstract = {"Abstract In this chapter, we review and interpret research on multidimensional source memory paradigms. We focus in particular on research in which two source dimensions (e.g., color and location of a word stimulus), or features, or context attributes, are encoded and subsequently retrieved. We cover some of the basic empirical outcomes of interest, notably the finding of stochastic dependence among retrieval of source dimensions. Such dependence implies that retrieval of one source dimension is related to the retrievability of the other source dimension. Many research papers have established that stochastic dependence is supported by encoding factors that help bind items to context, and perhaps even context to context. Yet the finding of, and degree of, stochastic dependence at retrieval does not always relate predictably to other manipulations, such as when people are focused on one or the other source dimension in an encoding phase. Moreover, other theoretical proposals target retrieval processes, apart from encoding processes, as producing such dependence. Research that has included retrieval manipulations, such as external cuing of source dimensions at test, suggests that retrieval-specific causes of stochastic dependence have not been established. We also discuss other paradigms that are relevant to the retrieval of multiple object features and whether their retrieval is dependent or independent of one another. Mixed evidence results from this work, with some arguing for relative independence of object features, but others arguing for strong associative relationships among elements that predict somewhat all-or-none retrieval of items and their contexts or features (i.e., dependence). We attempt to integrate these various research paradigms and draw some broad, albeit tentative, conclusions about this collective work. We also suggest areas of research that should be considered as future work in multidimensional source memory. "} 
}
@article{Bandara2015582,
title = {"Towards soil property retrieval from space: An application with disaggregated satellite observations "},
journal = {"Journal of Hydrology "},
volume = {"522"},
number = {""},
pages = {"582 - 593"},
year = {"2015"},
note = {""},
issn = {"0022-1694"},
doi = {"https://doi.org/10.1016/j.jhydrol.2015.01.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022169415000359"},
author = {"Ranmalee Bandara and Jeffrey P. Walker and Christoph Rüdiger and Olivier Merlin"},
keywords = {"Soil hydraulic parameters", "Spatial retrieval", "JULES", "Land surface modelling", "DISPATCH "},
abstract = {"Summary Soil moisture plays a key role in most environmental processes, as evaporation and transpiration are heavily dependent on soil moisture variability. While it is one of the few important hydrological variables that can be directly observed, the high spatial and temporal variability makes it difficult to measure globally or even regionally. Reliance is therefore placed on land surface models to predict the evolution of soil moisture using low-resolution soil property information or typical values. But to make predictions with the required accuracy, more reliable and detailed soil parameter data are required than those currently available. This paper demonstrates the ability to retrieve soil hydraulic parameters from near-surface measurements, using Soil Moisture and Ocean Salinity (SMOS) observations disaggregated to 1 km resolution for a demonstration area the size of a single \{SMOS\} footprint. The disaggregated soil moisture product was first assessed against in-situ soil moisture observations, before testing the retrieval methodology using the disaggregated soil moisture data for individual soil columns co-located with three long-term monitoring sites in the Murrumbidgee Catchment. The retrieval methodology was then applied to the entire 40 km × 40 km demonstration area at 5 km spatial resolution. The results suggest that spatially variable soil hydraulic properties exist in the study area, while published soil texture maps show only a single soil type, meaning that a single set of soil hydraulic parameters would normally be used in soil moisture prediction models for this region. Use of a single set of soil hydraulic parameters, rather than the spatially variables ones, was estimated to have an approximate 0.06 m3/m3 impact on the soil moisture prediction. "} 
}
@article{Fu201514,
title = {"X-ray differential phase-contrast tomographic reconstruction with a phase line integral retrieval filter "},
journal = {"Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment "},
volume = {"778"},
number = {""},
pages = {"14 - 19"},
year = {"2015"},
note = {""},
issn = {"0168-9002"},
doi = {"https://doi.org/10.1016/j.nima.2014.12.103"},
url = {"http://www.sciencedirect.com/science/article/pii/S0168900215000054"},
author = {"Jian Fu and Xinhua Hu and Chen Li"},
keywords = {"X-ray computed tomography", "Phase contrast", "Image reconstruction", "Phase projection retrieval", "Filtered back-projection "},
abstract = {"Abstract We report an alternative reconstruction technique for x-ray differential phase-contrast computed tomography (DPC-CT). This approach is based on a new phase line integral projection retrieval filter, which is rooted in the derivative property of the Fourier transform and counteracts the differential nature of the DPC-CT projections. It first retrieves the phase line integral from the DPC-CT projections. Then the standard filtered back-projection (FBP) algorithms popular in x-ray absorption-contrast \{CT\} are directly applied to the retrieved phase line integrals to reconstruct the DPC-CT images. Compared with the conventional DPC-CT reconstruction algorithms, the proposed method removes the Hilbert imaginary filter and allows for the direct use of absorption-contrast \{FBP\} algorithms. Consequently, FBP-oriented image processing techniques and reconstruction acceleration softwares that have already been successfully used in absorption-contrast \{CT\} can be directly adopted to improve the DPC-CT image quality and speed up the reconstruction. "} 
}
@article{Lin2015132,
title = {"The container retrieval problem with respect to relocation "},
journal = {"Transportation Research Part C: Emerging Technologies "},
volume = {"52"},
number = {""},
pages = {"132 - 143"},
year = {"2015"},
note = {""},
issn = {"0968-090X"},
doi = {"https://doi.org/10.1016/j.trc.2015.01.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0968090X15000327"},
author = {"Dung-Ying Lin and Yen-Ju Lee and Yusin Lee"},
keywords = {"Container retrieval", "Rail mounted gantry crane (RMGC)", "Container yard", "Multi-lift", "Heuristic "},
abstract = {"Abstract The demand for container terminal yards is growing significantly faster than the supply of available land; therefore, containers are typically stacked high to better utilize the land space in container yards. However, in the process of container retrieval, non-productive reshuffling may be required to relocate the containers that are stacked on top of the target container. Container retrieval is directly related to the operational efficiency of terminals. Because the industry has become increasingly competitive, it has become critical to introduce a systematic approach to retrieving containers. In this study, we develop a heuristic that can generate feasible working plans for rail-mounted gantry cranes (RMGC) in container yards to minimize the number of container movements while taking the \{RMGC\} working time into consideration. The methodology takes into consideration the case that containers are grouped in terms of their retrieval order. Multi-lift \{RMGC\} models also are studied. Comprehensive numerical experiments reveal that the method runs faster than other methods published in the literature by several orders of magnitude; additionally, our method is able to solve instances larger than practical use. The number of movements approaches a theoretical lower bound, and the numerical results clearly demonstrate the tradeoff between the number of movements and the working time, and provide useful insights for yard planning. "} 
}
@article{KalpathyCramer201555,
title = {"Evaluating performance of biomedical image retrieval systems—An overview of the medical image retrieval task at ImageCLEF 2004–2013 "},
journal = {"Computerized Medical Imaging and Graphics "},
volume = {"39"},
number = {""},
pages = {"55 - 61"},
year = {"2015"},
note = {"Medical visual information analysis and retrieval "},
issn = {"0895-6111"},
doi = {"https://doi.org/10.1016/j.compmedimag.2014.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895611114000366"},
author = {"Jayashree Kalpathy-Cramer and Alba García Seco de Herrera and Dina Demner-Fushman and Sameer Antani and Steven Bedrick and Henning Müller"},
keywords = {"Multimodal medical retrieval", "Image retrieval", "Biomedical literature", "Content-based retrieval", "Text-based image retrieval "},
abstract = {"Abstract Medical image retrieval and classification have been extremely active research topics over the past 15 years. Within the ImageCLEF benchmark in medical image retrieval and classification, a standard test bed was created that allows researchers to compare their approaches and ideas on increasingly large and varied data sets including generated ground truth. This article describes the lessons learned in ten evaluation campaigns. A detailed analysis of the data also highlights the value of the resources created. "} 
}
@article{Simpson20153,
title = {"Literature-based biomedical image classification and retrieval "},
journal = {"Computerized Medical Imaging and Graphics "},
volume = {"39"},
number = {""},
pages = {"3 - 13"},
year = {"2015"},
note = {"Medical visual information analysis and retrieval "},
issn = {"0895-6111"},
doi = {"https://doi.org/10.1016/j.compmedimag.2014.06.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895611114000998"},
author = {"Matthew S. Simpson and Daekeun You and Md Mahmudur Rahman and Zhiyun Xue and Dina Demner-Fushman and Sameer Antani and George Thoma"},
keywords = {"Image-based retrieval", "Case-based retrieval", "Modality classification", "Compound figure separation "},
abstract = {"Abstract Literature-based image informatics techniques are essential for managing the rapidly increasing volume of information in the biomedical domain. Compound figure separation, modality classification, and image retrieval are three related tasks useful for enabling efficient access to the most relevant images contained in the literature. In this article, we describe approaches to these tasks and the evaluation of our methods as part of the 2013 medical track of ImageCLEF. In performing each of these tasks, the textual and visual features used to represent images are an important consideration often left unaddressed. Therefore, we also describe a gradient-based optimization strategy for determining meaningful combinations of features and apply the method to the image retrieval task. An evaluation of our optimization strategy indicates the method is capable of producing statistically significant improvements in retrieval performance. Furthermore, the results of the 2013 ImageCLEF evaluation demonstrate the effectiveness of our techniques. In particular, our text-based and mixed image retrieval methods ranked first among all the participating groups. "} 
}
@article{Czerniawski2015159,
title = {"Systemic lipopolysaccharide administration impairs retrieval of context–object discrimination, but not spatial, memory: Evidence for selective disruption of specific hippocampus-dependent memory functions during acute neuroinflammation "},
journal = {"Brain, Behavior, and Immunity "},
volume = {"44"},
number = {""},
pages = {"159 - 166"},
year = {"2015"},
note = {""},
issn = {"0889-1591"},
doi = {"https://doi.org/10.1016/j.bbi.2014.09.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S088915911400467X"},
author = {"Jennifer Czerniawski and Teiko Miyashita and Gail Lewandowski and John F. Guzowski"},
keywords = {"Neuroinflammation", "Memory retrieval", "Lipopolysaccharide", "Water maze", "Context discrimination", "Novel object recognition", "Hippocampus "},
abstract = {"Abstract Neuroinflammation is implicated in impairments in neuronal function and cognition that arise with aging, trauma, and/or disease. Therefore, understanding the underlying basis of the effect of immune system activation on neural function could lead to therapies for treating cognitive decline. Although neuroinflammation is widely thought to preferentially impair hippocampus-dependent memory, data on the effects of cytokines on cognition are mixed. One possible explanation for these inconsistent results is that cytokines may disrupt specific neural processes underlying some forms of memory but not others. In an earlier study, we tested the effect of systemic administration of bacterial lipopolysaccharide (LPS) on retrieval of hippocampus-dependent context memory and neural circuit function in \{CA3\} and \{CA1\} (Czerniawski and Guzowski, 2014). Paralleling impairment in context discrimination memory, we observed changes in neural circuit function consistent with disrupted pattern separation function. In the current study we tested the hypothesis that acute neuroinflammation selectively disrupts memory retrieval in tasks requiring hippocampal pattern separation processes. Male Sprague–Dawley rats given \{LPS\} systemically prior to testing exhibited intact performance in tasks that do not require hippocampal pattern separation processes: novel object recognition and spatial memory in the water maze. By contrast, memory retrieval in a task thought to require hippocampal pattern separation, context–object discrimination, was strongly impaired in LPS-treated rats in the absence of any gross effects on exploratory activity or motivation. These data show that \{LPS\} administration does not impair memory retrieval in all hippocampus-dependent tasks, and support the hypothesis that acute neuroinflammation impairs context discrimination memory via disruption of pattern separation processes in hippocampus. "} 
}
@article{Wigneron2017238,
title = {"Modelling the passive microwave signature from land surfaces: A review of recent results and application to the L-band \{SMOS\} &amp; \{SMAP\} soil moisture retrieval algorithms "},
journal = {"Remote Sensing of Environment "},
volume = {"192"},
number = {""},
pages = {"238 - 262"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.01.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300366"},
author = {"J.-P. Wigneron and T.J. Jackson and P. O'Neill and G. De Lannoy and P. de Rosnay and J.P. Walker and P. Ferrazzoli and V. Mironov and S. Bircher and J.P. Grant and M. Kurum and M. Schwank and J. Munoz-Sabater and N. Das and A. Royer and A. Al-Yaari and A. Al Bitar and R. Fernandez-Moran and H. Lawrence and A. Mialon and M. Parrens and P. Richaume and S. Delwart and Y. Kerr"},

abstract = {"Abstract Two passive microwave missions are currently operating at L-band to monitor surface soil moisture (SM) over continental surfaces. The \{SMOS\} sensor, based on an innovative interferometric technology enabling multi-angular signatures of surfaces to be measured, was launched in November 2009. The \{SMAP\} sensor, based on a large mesh reflector 6 m in diameter providing a conically scanning antenna beam with a surface incidence angle of 40°, was launched in January of 2015. Over the last decade, an intense scientific activity has focused on the development of the \{SM\} retrieval algorithms for the two missions. This activity has relied on many field (mainly tower-based) and airborne experimental campaigns, and since 2010–2011, on the \{SMOS\} and Aquarius space-borne L-band observations. It has relied too on the use of numerical, physical and semi-empirical models to simulate the microwave brightness temperature of natural scenes for a variety of scenarios in terms of system configurations (polarization, incidence angle) and soil, vegetation and climate conditions. Key components of the inversion models have been evaluated and new parameterizations of the effects of the surface temperature, soil roughness, soil permittivity, and vegetation extinction and scattering have been developed. Among others, global maps of select radiative transfer parameters have been estimated very recently. Based on this intense activity, improvements of the \{SMOS\} and \{SMAP\} \{SM\} inversion algorithms have been proposed. Some of them have already been implemented, whereas others are currently being investigated. In this paper, we present a review of the significant progress which has been made over the last decade in this field of research with a focus on L-band, and a discussion on possible applications to the \{SMOS\} and \{SMAP\} soil moisture retrieval approaches. "} 
}
@article{Murala20151502,
title = {"Spherical symmetric 3D local ternary patterns for natural, texture and biomedical image indexing and retrieval "},
journal = {"Neurocomputing "},
volume = {"149, Part C"},
number = {""},
pages = {"1502 - 1514"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.08.042"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214010868"},
author = {"Subrahmanyam Murala and Q.M. Jonathan Wu"},
keywords = {"Local binary pattern (LBP)", "Local ternary patterns (LTP)", "Texture", "Biomedical image retrieval "},
abstract = {"Abstract In this paper, we propose a new algorithm using spherical symmetric three dimensional local ternary patterns (SS-3D-LTP) for natural, texture and biomedical image retrieval applications. The existing local binary patterns (LBP), local ternary patterns (LTP), local derivative patterns (LDP), local tetra patterns (LTrP) etc., are encode the relationship between the center pixel and its surrounding neighbors in two dimensional (2D) local region of an image. The proposed method encodes the relationship between the center pixel and its surrounding neighbors with five selected directions in 3D plane which is generated from 2D image using multiresolution Gaussian filter bank. In addition, we propose the color SS-3D-LTP (CSS-3D-LTP) where we consider the \{RGB\} spaces as three planes of 3D volume. Three experiments have been carried out for proving the worth of our algorithm for natural, texture and biomedical image retrieval applications. It is further mentioned that the databases used for natural, texture and biomedical image retrieval applications are Corel-10K, Brodatz and open access series of imaging studies (OASIS) magnetic resonance databases respectively. The results after being investigated show a significant improvement in terms of their evaluation measures as compared to the start-of-art spatial as well as transform domain techniques on respective databases. "} 
}
@article{Tripathi2015815,
title = {"Visualizing and Improving the Robustness of Phase Retrieval Algorithms "},
journal = {"Procedia Computer Science "},
volume = {"51"},
number = {""},
pages = {"815 - 824"},
year = {"2015"},
note = {"International Conference On Computational Science, \{ICCS\} 2015Computational Science at the Gates of Nature "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.05.205"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915010133"},
author = {"Ashish Tripathi and Sven Leyffer and Todd Munson and Stefan M. Wild"},
keywords = {"Phase retrieval algorithms", "inverse problems", "nonlinear complex-valued optimization "},
abstract = {"Abstract Coherent x-ray diffractive imaging is a novel imaging technique that utilizes phase retrieval and nonlinear optimization methods to image matter at nanometer scales. We explore how the convergence properties of a popular phase retrieval algorithm, Fienup's HIO, behave by introducing a reduced dimensionality problem allowing us to visualize and quantify convergence to local minima and the globally optimal solution. We then introduce generalizations of \{HIO\} that improve upon the original algorithm's ability to converge to the globally optimal solution. "} 
}
@article{Hupbach201523,
title = {"Retrieval practice does not safeguard memories from interference-based forgetting "},
journal = {"Learning and Motivation "},
volume = {"49"},
number = {""},
pages = {"23 - 30"},
year = {"2015"},
note = {""},
issn = {"0023-9690"},
doi = {"https://doi.org/10.1016/j.lmot.2015.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0023969015000132"},
author = {"Almut Hupbach"},
keywords = {"Testing effect", "Retrieval practice", "Retroactive interference", "Memory reconsolidation "},
abstract = {"Abstract Retrieval enhances long-term retention. However, reactivation of a memory also renders it susceptible to modifications as shown by studies on memory reconsolidation. The present study explored whether retrieval diminishes or enhances subsequent retroactive interference (RI) and intrusions. Participants learned a list of objects. Two days later, they were either asked to recall the objects, given a subtle reminder, or were not reminded of the first learning session. Then, participants learned a second list of objects or performed a distractor task. After another two days, retention of List 1 was tested. Although retrieval enhanced List 1 memory, learning a second list impaired memory in all conditions. This shows that testing did not protect memory from RI. While a subtle reminder before List 2 learning caused List 2 items to later intrude into List 1 recall, very few such intrusions were observed in the testing and the no reminder conditions. The findings are discussed in reference to the reconsolidation account and the testing effect literature, and implications for educational practice are outlined. "} 
}
@article{Bai2017,
title = {"Adaptive hash retrieval with kernel based similarity "},
journal = {"Pattern Recognition "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2017.03.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320317301310"},
author = {"Xiao Bai and Cheng Yan and Haichuan Yang and Lu Bai and Jun Zhou and Edwin Robert Hancock"},
keywords = {"Hashing", "K-NN", "Kernel", "Binary indexing", "Normalized Euclidean distance "},
abstract = {"Abstract Indexing methods have been widely used for fast data retrieval on large scale datasets. When the data are represented by high dimensional vectors, hashing is often used as an efficient solution for approximate similarity search. When a retrieval task does not involve supervised training data, most hashing methods aim at preserving data similarity defined by a distance metric on the feature vectors. Hash codes generated by these approaches normally maintain the Hamming distance of the data in accordance with the similarity function, but ignore the local details of the distribution of data. This objective is not suitable for k-nearest neighbor search since the similarity to the nearest neighbors can vary significantly for different data samples. In this paper, we present a novel adaptive similarity measure which is consistent with k-nearest neighbor search, and prove that it leads to a valid kernel if the original similarity function is a kernel function. Next we propose a method which calculates hash codes using the kernel function. With a low-rank approximation, our hashing framework is more effective than existing methods that preserve similarity over an arbitrary kernel. The proposed similarity function, hashing framework, and their combination demonstrate significant improvement when compared with several alternative state-of-the-art methods. "} 
}
@article{Kizilirmak20148,
title = {"Trial-to-trial dynamics of selective long-term-memory retrieval with continuously changing retrieval targets "},
journal = {"Brain and Cognition "},
volume = {"90"},
number = {""},
pages = {"8 - 18"},
year = {"2014"},
note = {""},
issn = {"0278-2626"},
doi = {"https://doi.org/10.1016/j.bandc.2014.04.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0278262614000840"},
author = {"Jasmin M. Kizilirmak and Frank Rösler and Patrick H. Khader"},
keywords = {"Long-term memory", "Selective retrieval", "Cognitive control", "ERPs", "SCPs", "Slow waves "},
abstract = {"Abstract How do we control the successive retrieval of behaviorally relevant information from long-term memory (LTM) without being distracted by other potential retrieval targets associated to the same retrieval cues? Here, we approach this question by investigating the nature of trial-by-trial dynamics of selective \{LTM\} retrieval, i.e., in how far retrieval in one trial has detrimental or facilitatory effects on selective retrieval in the following trial. Participants first learned associations between retrieval cues and targets, with one cue always being linked to three targets, forming small associative networks. In successive trials, participants had to access either the same or a different target belonging to either the same or a different cue. We found that retrieval times were faster for targets that had already been relevant in the previous trial, with this facilitatory effect being substantially weaker when the associative network changed in which the targets were embedded. Moreover, staying within the same network still had a facilitatory effect even if the target changed, which became evident in a relatively higher memory performance in comparison to a network change. Furthermore, event-related brain potentials (ERPs) showed topographically and temporally dissociable correlates of these effects, suggesting that they result from combined influences of distinct processes that aid memory retrieval when relevant and irrelevant targets change their status from trial to trial. Taken together, the present study provides insight into the different processing stages of memory retrieval when fast switches between retrieval targets are required. "} 
}
@article{Liu2015110,
title = {"Indirect shape analysis for 3D shape retrieval "},
journal = {"Computers & Graphics "},
volume = {"46"},
number = {""},
pages = {"110 - 116"},
year = {"2015"},
note = {"Shape Modeling International 2014 "},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2014.09.038"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849314001265"},
author = {"Zhenbao Liu and Caili Xie and Shuhui Bu and Xiao Wang and Junwei Han and Hongwei Lin and Hao Zhang"},
keywords = {"Indirect shape analysis", "Interacting agent", "3D shape retrieval "},
abstract = {"Abstract We introduce indirect shape analysis, or ISA, where a given shape is analyzed not based on geometric or topological features computed directly from the shape itself, but by studying how external agents interact with the shape. The potential benefits of \{ISA\} are two-fold. First, agent–object interactions often reveal an object׳s function, which plays a key role in shape understanding. Second, compared to direct shape analysis, ISA, which utilizes pre-selected agents, is less affected by imperfections of, or inconsistencies between, the geometry or topology of the analyzed shapes. We employ digital human models as the external agents and develop a prototype \{ISA\} scheme for 3D shape classification and retrieval. Given a 3D model M, we compute an \{ISA\} feature vector for M by encoding how well a selected set of human models, with functional poses, can be aligned to M so as to perform the intended functions. We demonstrate the discriminability of \{ISA\} features for 3D shape retrieval and compare to state-of-the-art methods. "} 
}
@article{Luo2015264,
title = {"Improved aerosol retrieval algorithm using Landsat images and its application for \{PM10\} monitoring over urban areas "},
journal = {"Atmospheric Research "},
volume = {"153"},
number = {""},
pages = {"264 - 275"},
year = {"2015"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2014.08.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809514003536"},
author = {"Nana Luo and Man Sing Wong and Wenji Zhao and Xing Yan and Fei Xiao"},
keywords = {"AERONET", "Aerosol retrieval", "Landsat image", "PM10 concentrations "},
abstract = {"Abstract Aerosol retrieval using \{MODerate\} resolution Imaging Spectroradiometer (MODIS) has been well researched over the past decade. However, the application is limited to global- and regional-scale studies, which may not be applicable for urban areas due to its low spatial resolution. To overcome the limitation, this paper proposed an improved aerosol retrieval algorithm for Landsat images (ImAero-Landsat) at spatial resolution of 30 m. This ImAero-Landsat algorithm has been improved in the following two aspects: (i) it does not require a comprehensive look up table and thus it is more efficient in \{AOT\} retrieval; and (ii) it can be operated in both bright and dark surfaces. The derived aerosol optical thickness (AOT) images were validated with \{AErosol\} \{RObotic\} \{NETwork\} (AERONET) measurements as well as \{MODIS\} \{MOD04\} \{AOT\} products. Small root mean square errors (RMSEs) of 0.11 and 0.14 and mean absolute difference (MAD) of 0.07 and 0.11 between ImAero-Landsat AOT, with \{MODIS\} \{MOD04\} and \{AERONET\} products were observed. By correlating with ground based \{PM10\} concentrations, the ImAero-Landsat method outperforms (r2 = 0.32) than \{MOD04\} \{AOT\} products (r2 = 0.23). In addition, the accuracy of estimating \{PM10\} can be improved to r2 = 0.55 when the derived \{AOT\} was integrated with meteorological parameters. The accuracy is similar to the results derived from \{AERONET\} \{AOT\} (r2 = 0.62). This study offers a simple and accurate method to investigate aerosol optical thickness at detailed city-scale. Environmental authorities may use the derived methods for deriving aerosol distribution maps and pinpointing the sources of pollutants in urban areas. "} 
}
@article{Ford20142770,
title = {"Neural recruitment and connectivity during emotional memory retrieval across the adult life span "},
journal = {"Neurobiology of Aging "},
volume = {"35"},
number = {"12"},
pages = {"2770 - 2784"},
year = {"2014"},
note = {""},
issn = {"0197-4580"},
doi = {"https://doi.org/10.1016/j.neurobiolaging.2014.05.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S0197458014003959"},
author = {"Jaclyn H. Ford and John A. Morris and Elizabeth A. Kensinger"},
keywords = {"Memory", "Retrieval", "Aging", "fMRI", "Connectivity", "Prefrontal cortex "},
abstract = {"Abstract Although research has identified age-related changes in neural recruitment during emotional memory encoding, it is unclear whether these differences extend to retrieval. In this study, participants engaged in a recognition task during a functional magnetic resonance imaging scan. They viewed neutral titles and indicated whether each title had been presented with an image during the study phase. Neural activity and connectivity during retrieval of titles associated with positive and negative images were compared with age (treated as a continuous variable) included as a regressor of interest. Aging was associated with increased prefrontal activation for retrieval of positive and negative memories, but this pattern was more widespread for negative memories. Aging also was associated with greater negative connectivity between a left hippocampal seed region and multiple regions of prefrontal cortex, but this effect of age occurred during negative retrieval only. These findings demonstrate that age-related changes in prefrontal recruitment and connectivity during retrieval depend on memory valence. The use of a life span approach also emphasized both continuities and discontinuities in recruitment and connectivity across the adult life span, highlighting the insights to be gained from using a full life span sample. "} 
}
@article{Çelik20151,
title = {"Understanding the complexity of antigen retrieval of \{DNA\} methylation for immunofluorescence-based measurement and an approach to challenge "},
journal = {"Journal of Immunological Methods "},
volume = {"416"},
number = {""},
pages = {"1 - 16"},
year = {"2015"},
note = {""},
issn = {"0022-1759"},
doi = {"https://doi.org/10.1016/j.jim.2014.11.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022175914003524"},
author = {"Selcen Çelik"},
keywords = {"\{DNA\} methylation", "Methyl-binding proteins", "Immunofluorescence", "Antigen retrieval", "Bisulfite sequencing "},
abstract = {"Abstract Cytosine methylation (5-methylcytosine, 5meC) in the CpG-rich regions of the mammalian genome is an important epigenetic mechanism playing roles in transcription regulation and genomic stability. The abnormalities in \{DNA\} methylation can occur in various types of cancer and some genetic diseases. The measurement of \{DNA\} methylation is therefore important and there is a range of methodologies used to detect \{DNA\} methylation. Many methods based on bisulfite treatment appeared with a lack of specificity after recent discoveries of various modifications of methylated cytosine, however there are new treatments developed to overcome this limitation. Immunofluorescence is currently known to be able to specifically detect \{DNA\} methylation as it uses different antibodies against 5meC and its derivatives, but it is a semi-quantitative method. Immunofluorescence protocols commonly include fixation of cells followed by permeabilisation, antigen retrieval, and treatments with antibodies. Establishing the strategy for antigen retrieval of immunofluorescence is important to unmask epitopes (i.e. 5meC) from other proteins, and therefore to access the antigen of interest. There are many approaches used for antigen retrieval induced by acid, enzyme and/or heat. The selection of antigen retrieval method can depend on a variety of such antigen-based or cell-based conditions, since the dynamic structure of \{DNA\} and chromatin accounts for the complexity of involved proteins to mask the epitope. This review aims to specifically focus on the complexity of in situ detection of \{DNA\} methylation by immunofluorescence-based methods using antigen retrieval with the current understanding of \{DNA\} methylation mechanism, and suggests conditions for antigenic retrieval of 5meC epitope. "} 
}
@article{Zhao2015533,
title = {"Strategy for dynamic 3D depth data matching towards robust action retrieval "},
journal = {"Neurocomputing "},
volume = {"151, Part 2"},
number = {""},
pages = {"533 - 543"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.03.092"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214013940"},
author = {"Sicheng Zhao and Lujun Chen and Hongxun Yao and Yanhao Zhang and Xiaoshuai Sun"},
keywords = {"Dynamic depth data matching", "Action retrieval", "3D shape context", "Dynamic time warping", "Bag of word", "Kinect "},
abstract = {"Abstract 3D depth data, especially dynamic 3D depth data, offer several advantages over traditional intensity videos for expressing objects׳ actions, such as being useful in low light levels, resolving the silhouette ambiguity of actions, and being color and texture invariant. With the wide popularity of somatosensory equipment (Kinect for example), more and more dynamic 3D depth data are shared on the Internet, which results in an urgent need to retrieve these data efficiently and effectively. In this paper, we propose a generalized strategy for dynamic 3D depth data matching and apply this strategy in action retrieval task. Firstly, an improved 3D shape context descriptor (3DSCD) is proposed to extract features of each static depth frame. Then we employ dynamic time warping (DTW) to measure the temporal similarity between two 3D dynamic depth sequences. Experimental results on our collected dataset consisting of 170 dynamic 3D depth video clips show that the proposed 3DSCD has a rich descriptive power on depth data and that the method using 3DSCD and \{DTW\} achieves high matching accuracy. Finally, to address the matching efficiency problem, we utilize the bag of word (BoW) model to quantize the 3DSCD of each static depth frame into visual word packages. So the original feature matching problem is simplified into a two-histogram matching problem. The results demonstrate the matching efficiency of our proposed method, while still maintaining high matching accuracy. "} 
}
@article{Ekren20151152,
title = {"Warehouse Design under Class-Based Storage Policy of Shuttle-Based Storage and Retrieval System "},
journal = {"IFAC-PapersOnLine "},
volume = {"48"},
number = {"3"},
pages = {"1152 - 1154"},
year = {"2015"},
note = {"15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 "},
issn = {"2405-8963"},
doi = {"https://doi.org/10.1016/j.ifacol.2015.06.239"},
url = {"http://www.sciencedirect.com/science/article/pii/S2405896315004784"},
author = {"B.Y. Ekren and Z. Sari and T. Lerher"},
keywords = {"Automated storage and retrieval system", "SBS/RS", "class-based storage", "simulation", "automated warehouse "},
abstract = {"Abstract In this study, we aim to find out the best rack design for shuttle-based storage and retrieval system (SBS/RS) under class-based storage policy (CSP). SBS/RS is a new technology in automated storage and retrieval system (AS/RS) which is developed for high transaction environments where mini-load AS/RS crane may not be able to keep pace with the transaction rate needed over a given number of storage locations. We consider several rack design concepts in terms of number of aisles, tiers and bays in the warehouse. The performance of the system is evaluated in terms of utilizations of lifts and storage/retrieval devices and cycle times of storage/retrieval transactions. We utilize simulation for the modeling purpose. The results indicate that \{CSP\} works better under high rise warehouse design. So, this may create less number of lifts requirement in the system. Hence, the warehouse design with \{CSP\} may tend to have lower investment cost. By this study, we also aim to provide practitioners and academia a significant insight for SBS/RS design under several rack design concepts for CSP. "} 
}
@article{Navarro201569,
title = {"Bottom-k document retrieval "},
journal = {"Journal of Discrete Algorithms "},
volume = {"32"},
number = {""},
pages = {"69 - 74"},
year = {"2015"},
note = {"StringMasters 2012 &amp; 2013 Special Issue (Volume 2) "},
issn = {"1570-8667"},
doi = {"https://doi.org/10.1016/j.jda.2014.12.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S1570866714001026"},
author = {"Gonzalo Navarro and Sharma V. Thankachan"},
keywords = {"Compact data structures", "Document retrieval", "String collections "},
abstract = {"Abstract We consider the problem of retrieving the k documents from a collection of strings where a given pattern P appears least often. This has potential applications in data mining, bioinformatics, security, and big data. We show that adapting the classical linear-space solutions for this problem is trivial, but the compressed-space solutions are not easy to extend. We design a new solution for this problem that matches the best-known result when using 2 | \{CSA\} | + o ( n ) bits, where \{CSA\} is a Compressed Suffix Array. Our structure answers queries in the time needed by the \{CSA\} to find the suffix array interval of the pattern plus O ( k lg ⁡ k lg ϵ ⁡ n ) accesses to suffix array cells, for any constant ϵ &gt; 0 . "} 
}
@article{Liang2015500,
title = {"Improved snow depth retrieval by integrating microwave brightness temperature and visible/infrared reflectance "},
journal = {"Remote Sensing of Environment "},
volume = {"156"},
number = {""},
pages = {"500 - 509"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2014.10.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S003442571400426X"},
author = {"Jiayong Liang and Xiaoping Liu and Kangning Huang and Xia Li and Xun Shi and Yaning Chen and Jun Li"},
keywords = {"Snow depth retrieval", "Integration of multi-sensor data", "Support vector machine "},
abstract = {"Abstract The accuracy of snow depth retrieval by remote sensing depends heavily on the characteristics of the snow, and both passive microwave and visible/infrared sensors can contribute to the acquisition of this information. A method integrating these two remotely sensed data sets is presented in this study. Snow depth retrieval is performed using microwave brightness temperature at 19 and 37 \{GHz\} from the Special Sensor Microwave/Imager (SSM/I) and the Special Sensor Microwave Image/Sounder (SSMI/S), and visible/infrared surface reflectance from Moderate Resolution Imaging Spectroadiometer (MODIS) products. Microwave brightness temperature provides information about the volume of snow pack, and visible/infrared surface reflectance can indicate snow presence and surface grain size. With these two remote sensing data sets, snow depth is retrieved by a nonlinear data mining technique, the modified sequential minimal optimization (SMO) algorithm for support vector machine (SVM) regression. The proposed method is tested by using 16,329 records of dry snow measured at 54 meteorological stations in Xinjiang, China over an area of 1.6 million km2 from 2000 to 2009. The root mean square error (RMSE), relative \{RMSE\} and the correlation coefficient of our method are 6.21 cm, 0.64 and 0.87, respectively. These results are better than those obtained using only brightness temperature data (8.80 cm, 0.90 and 0.73), the traditional spectral polarization difference (SPD) algorithm (15.07 cm, 1.54 and 0.58), a modified Chang algorithm in \{WESTDC\} (9.80 cm, 1.00 and 0.62), or the multilayer perceptron classifier of artificial neural networks (ANN) (9.23 cm, 0.94 and 0.72). The daily snow water equivalent (SWE) retrieved by this method has an \{RMSE\} of 8.05 mm and a correlation of 0.84, which are better than those of \{NASA\} \{NSIDC\} (32.87 mm and 0.47) or Globsnow (19.07 mm and 0.59). This study demonstrates that the combination of visible/infrared surface reflectance and microwave brightness temperature via an \{SVM\} regression can provide a more accurate retrieval of snow depth. "} 
}
@article{Jones20179,
title = {"Assimilating synthetic hyperspectral sounder temperature and humidity retrievals to improve severe weather forecasts "},
journal = {"Atmospheric Research "},
volume = {"186"},
number = {""},
pages = {"9 - 25"},
year = {"2017"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809516305750"},
author = {"Thomas A. Jones and Steven Koch and Zhenglong Li"},
keywords = {"Hyperspectral sounders", "Ensemble data assimilation", "Storm-scale data assimilation", "OSSE "},
abstract = {"Abstract Assimilation of hyperspectral sounder data into numerical weather prediction (NWP) models has proven vital to generating accurate model analyses of tropospheric temperature and humidity where few conventional observations exist. Applications to storm-scale models are limited since the low temporal resolution provided by polar orbiting sensors cannot adequately sample rapidly changing environments associated with high impact weather events. To address this limitation, hyperspectral sounders have been proposed for geostationary orbiting satellites, but these have yet to be built and launched in part due to much higher engineering costs and a lack of a definite requirement for the data. This study uses an Observation System Simulation Experiment (OSSE) approach to simulate temperature and humidity profiles from a hypothetical geostationary-based sounder from a nature run of a high impact weather event on 20 May 2013. The simulated observations are then assimilated using an ensemble adjustment Kalman filter approach, testing both hourly and 15 minute cycling to determine their relative effectiveness at improving the near storm environment. Results indicate that assimilating both temperature and humidity profiles reduced mid-tropospheric both mean and standard deviation of analysis and forecast errors compared to assimilating conventional observations alone. The 15 minute cycling generally produced the lowest errors while also generating the best 2–4 hour updraft helicity forecasts of ongoing convection. This study indicates the potential for significant improvement in short-term forecasting of severe storms from the assimilation of hyperspectral geostationary satellite data. However, more studies are required using improved \{OSSE\} designs encompassing multiple storm environments and additional observation types such as radar reflectivity to fully define the effectiveness of assimilating geostationary hyperspectral observations for high impact weather forecasting applications. "} 
}
@article{Saraclar20141019,
title = {"Editorial for the special issue on spoken content retrieval "},
journal = {"Computer Speech & Language "},
volume = {"28"},
number = {"5"},
pages = {"1019 - 1020"},
year = {"2014"},
note = {""},
issn = {"0885-2308"},
doi = {"https://doi.org/10.1016/j.csl.2014.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0885230814000448"},
author = {"M. Saraclar and Ciprian Chelba and Bhuvana Ramabhadran"},
keywords = {"Speech retrieval", "Spoken document retrieval", "Spoken term detection", "Keyword search "},
abstract = {"Abstract A typical spoken content retrieval solution integrates multiple technologies that belong to the areas of automatic speech recognition and information retrieval. Due to the rich set of challenges – many of them language specific – as well as widespread impact, numerous research sites in the world are actively engaged in this research area. This special issue highlights some of the recent advances in spoken content retrieval. "} 
}
@article{Ghomri20151906,
title = {"Mathematical modeling of retrieval travel time for flow-rack automated storage and retrieval systems "},
journal = {"IFAC-PapersOnLine "},
volume = {"48"},
number = {"3"},
pages = {"1906 - 1911"},
year = {"2015"},
note = {"15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 "},
issn = {"2405-8963"},
doi = {"https://doi.org/10.1016/j.ifacol.2015.06.365"},
url = {"http://www.sciencedirect.com/science/article/pii/S2405896315006047"},
author = {"Latéfa Ghomri and Zaki Sari"},
keywords = {"Automated storage/retrieval systems", "average retrieval time", "modeling", "simulation "},
abstract = {"Abstract Automated storage/retrieval systems (AS/RS) are computer-controlled automated material handling systems, widely used in industry and warehousing systems. They have interesting advantages, the majors of which are a high throughput, efficient use of space and improvement of safety. All the disadvantages of AS/RS are related to economic factors such as high initial investments and difficulty to change layout. This implies the importance of careful design of the AS/RS by taking into account all constraints. The latter may be linked either to the AS/RS dimensions or to products. The evaluation of average travel time that the S/R machine takes to store and retrieve a product is necessary for an optimal design. The present paper is devoted to a particular configuration of AS/RS said flow-rack AS/RS. The flow-rack AS/RS consists of only one deep rack and two machines; the first is used for storing operations and the second for retrieval operations. Our aim is to model mathematically the average travel time of the retrieval machine under random storage. The mathematical model proposed hereunder is certainly function of the physical parameters of the flow-rack AS/RS such as length, width, depth, etc.; but it is also function of the variety of products stored in the system and of their proportions. The mathematical model could be useful for performance evaluation and for design considerations of the flow-rack AS/RS in real world applications. The validation of the model is done by simulation. "} 
}
@article{ArevalilloHerráez2015109,
title = {"Improving distance based image retrieval using non-dominated sorting genetic algorithm "},
journal = {"Pattern Recognition Letters "},
volume = {"53"},
number = {""},
pages = {"109 - 117"},
year = {"2015"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2014.05.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865514001561"},
author = {"Miguel Arevalillo-Herráez and Francesc J. Ferri and Salvador Moreno-Picot"},
keywords = {"Image retrieval", "Multiobjective genetic algorithm", "Relevance feedback "},
abstract = {"Abstract Relevance feedback has been adopted as a standard in Content Based Image Retrieval (CBIR). One major difficulty that algorithms have to face is to achieve and adequate balance between the exploitation of already known areas of interest and the exploration of the feature space to find other relevant areas. In this paper, we evaluate different ways to combine two existing relevance feedback methods that place unequal emphasis on exploration and exploitation, in the context of distance-based methods. The hybrid approach proposed has been evaluated by using three image databases of various sizes that use different descriptors. Results show that the hybrid technique performs better than any of the original methods, highlighting the benefits of combining exploitation and exploration in relevance feedback tasks. "} 
}
@article{Salah20151658,
title = {"Improving the Performance of a New Storage and Retrieval Machine Based on a Parallel Manipulator Using \{FMEA\} Analysis "},
journal = {"IFAC-PapersOnLine "},
volume = {"48"},
number = {"3"},
pages = {"1658 - 1663"},
year = {"2015"},
note = {"15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 "},
issn = {"2405-8963"},
doi = {"https://doi.org/10.1016/j.ifacol.2015.06.324"},
url = {"http://www.sciencedirect.com/science/article/pii/S2405896315005637"},
author = {"Bashir Salah and Omar Janeh and Tobias Bruckmann and Bernd Noche"},
keywords = {"Wire Robot based Automated Storage / Retrieval System (SGP-AS/RS)", "Failure Mode Effect Analysis (FMEA)", "Performance Improvement "},
abstract = {"Abstract Automated Storage/Retrieval Systems (AS/RS) are computer-controlled material handling systems that can automatically store and retrieve loads with high throughput. In this work, we estimate important design parameters for a newly designed storage/retrieval (SGP-AS/RS) machine based on the specific input details to come up with an optimized design solution. The new system is based on cable- driven parallel manipulator (or wire robot) technology that is similar to a parallel Stewart-Gough platform architecture. For the reliability of such a system, a Failure Mode Effect Analysis (FMEA) is carried out to find out how much reliable is this machine as a whole based on the of DIN's \{EN\} 60812 standards. This International Standard describes methods for \{FMEA\} and helps not only to optimize the machine, but also to achieve a disturbance free operation. "} 
}
@article{Ferreira2014120,
title = {"Interference resolution in face perception and name retrieval "},
journal = {"Acta Psychologica "},
volume = {"153"},
number = {""},
pages = {"120 - 128"},
year = {"2014"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2014.09.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691814002182"},
author = {"Catarina S. Ferreira and Alejandra Marful and Teresa Bajo"},
keywords = {"Face processing", "Face naming", "Inhibition", "Retrieval induced forgetting "},
abstract = {"Abstract Selective retrieval is a rather difficult task, and especially so when one attempts to retrieve personal representations such as faces or names. Retrieval of memories under strong competition conditions is pervasive in human memory and some have suggested that inhibitory control is used to overcome interference between competing stimuli. In the present study, we used the retrieval practice paradigm to investigate if competition among personal representations (such as facial features and names) is also resolved by inhibitory mechanisms. This question is theoretically relevant, since personal representations have been said to have a special status on cognition. Moreover, some models of face recognition assume that interference can arise between different representations, but that this interference would be automatically and rapidly solved, with no need for a controlled inhibitory mechanism to act. In two experiments we showed \{RIF\} for facial features and familiar names, but only when participants had to actively retrieve some information. This suggests that personal information is subject to mechanisms of inhibitory control, which could help explain everyday life difficulties in processes such as face feature recognition or name retrieval. "} 
}
@article{Su2017175,
title = {"Age is a major prognosticator in extremely low oocyte retrieval cycles "},
journal = {"Taiwanese Journal of Obstetrics and Gynecology "},
volume = {"56"},
number = {"2"},
pages = {"175 - 180"},
year = {"2017"},
note = {""},
issn = {"1028-4559"},
doi = {"https://doi.org/10.1016/j.tjog.2016.04.039"},
url = {"http://www.sciencedirect.com/science/article/pii/S1028455917300104"},
author = {"Yu-Ting Su and Pin-Yao Lin and Fu-Jen Huang and Fu-Tsai Kung and Yu-Ju Lin and Yi-Ru Tsai and Kuo-Chung Lan"},
keywords = {"age", "Bologna criteria", "embryo quality", "poor ovarian response", "stratification "},
abstract = {"AbstractObjective Clinical prognosis appears to be varied in females with poor ovarian response (POR), and poor responders defined by the Bologna criteria might not be sufficiently homogeneous. The aim of this study was to determine the major predictor of reproductive outcomes in extremely low oocyte retrieval cycles. Materials and Methods A cohort of fresh in vitro fertilization/intracytoplasmic sperm injection cycles (n = 858) was analyzed from January 2001 to September 2014. Females from whom zero, one, two, or three oocytes were retrieved following ovarian stimulation were examined. Univariate analyses were performed to determine the association of pregnancy rate with potential confounding variables. Multiple logistic regression analysis was subsequently performed to identify factors that affected the occurrence of pregnancy. Results The clinical pregnancy rate was higher in women aged &lt; 40 years, long protocol, and high embryo score in univariate analysis. After adjusting for confounding factors in multivariate analysis, the maternal age [odds ratio (OR) = 0.91], primary or secondary infertility (OR = 1.99), number of matured oocytes retrieved (OR = 0.64), and score of embryos transferred (OR = 1.39) were significantly associated with the clinical pregnancy rate per cycle and per transfer. In the age subgroup analysis, \{POR\} females aged &lt; 35 years significantly demonstrated the highest number of matured oocytes, embryo scores, and clinical pregnancy rates compared with \{POR\} females aged 35–40 years and ≥ 40 years. Conclusion This study highlights the predictive value of maternal age and embryo quality on the probability of pregnancy in females with extremely low oocyte retrieval cycles. Young females with few eggs collected can still achieve acceptable pregnancy probability as long as they have good-quality embryos. Future randomized control trials for \{POR\} using the Bologna criteria should first stratify patients into different age groups. "} 
}
@article{Wang201543,
title = {"A new SVM-based active feedback scheme for image retrieval "},
journal = {"Engineering Applications of Artificial Intelligence "},
volume = {"37"},
number = {""},
pages = {"43 - 53"},
year = {"2015"},
note = {""},
issn = {"0952-1976"},
doi = {"https://doi.org/10.1016/j.engappai.2014.08.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0952197614002115"},
author = {"Xiang-Yang Wang and Hong-Ying Yang and Yong-Wei Li and Wei-Yi Li and Jing-Wei Chen"},
keywords = {"Content-based image retrieval", "Relevance feedback", "Support vector machine", "Active learning", "Ensemble classifiers", "Output codes "},
abstract = {"Abstract Relevance feedback has emerged as a powerful tool to boost the retrieval performance in content-based image retrieval (CBIR). Support vector machine (SVM) active learning is one popular and successful technique for relevance feedback in CBIR. Despite the success, for conventional \{SVM\} active learning, the users are usually not so patience to label a large number of training instances in the relevance feedback round. To overcome this limitation, a new SVM-based active feedback using ensemble multiple classifiers is proposed in this paper. Firstly, we select the most informative images by using active learning method for user to label, and quickly learn a boundary that separates the images that satisfy the user׳s query concept from the rest of the dataset. Then, a set of moderate accurate one-class \{SVM\} classifiers are trained separately by using different sub-features vectors. Finally, we compute the weight vector of component \{SVM\} classifiers dynamically by using the parameters for positive and negative samples, and combine the results of the component classifiers to form an output code as a hypothesized solution to the overall image retrieval problem. Experiments on large databases show that the proposed algorithms are significantly more effective than the state-of-the-art approaches. "} 
}
@article{Vipparthi20148016,
title = {"Expert image retrieval system using directional local motif XoR patterns "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"17"},
pages = {"8016 - 8026"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2014.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417414003935"},
author = {"Santosh Kumar Vipparthi and S.K. Nagar"},
keywords = {"Image retrieval (IR)", "Local binary patterns (LBP)", "XoR patterns", "Motif matrix", "Database "},
abstract = {"Abstract This paper presents a new image feature descriptor, namely directional local motif XoR patterns (DLMXoRPs) for image retrieval application. The proposed motif representation is entirely different from existing motif. The \{DLMXoRP\} presents a novel technique for the calculation of motif using 1 × 3 grids. The proposed motif (1 × 3) representation is having a flexible structure; hence it can able to extract all directional information. This flexibility is not present in the existing (2 × 2) motif. Further, the XoR operation is performed on the transformed new motif images which are not present in the literature (local binary patterns (LBP) and motif co-occurrence matrix (MCM)). To elevate the benefits of DLMXoRP, we compare it with the Motif XoR pattern (MXoR) which is calculated by applying the XoR operation on existing transformed motif image. The performance of the proposed method is tested by conducting three experiments on Corel-5000, Corel-10000 and MIT-VisTex databases. The results after investigation show a significant improvement in terms of average retrieval precision (ARP) and average retrieval rate (ARR) as compared to the state-of-the-art techniques for image retrieval. "} 
}
@article{Papushoy2015156,
title = {"Image retrieval based on query by saliency content "},
journal = {"Digital Signal Processing "},
volume = {"36"},
number = {""},
pages = {"156 - 173"},
year = {"2015"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2014.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200414002802"},
author = {"Alex Papushoy and Adrian G. Bors"},
keywords = {"Content based image retrieval", "Human visual attention model", "Saliency", "Salient edges", "Earth Mover's Distance "},
abstract = {"Abstract In this research study we propose the query by saliency content retrieval (QSCR) image retrieval method which is based on human visual attention models. The proposed methodology represents a bottom-up approach considering the human attention, both locally at the level of image regions as well as globally, for the entire image. In the proposed retrieval system, each image is segmented and a set of characteristic features is calculated for each region. A weight is assigned to each region according to its perceived saliency. The proposed methodology considers not only the salient regions but also their context in the image. Localized image similarity is evaluated using an optimization method called the Earth Mover's Distance (EMD). \{EMD\} calculates inter-region distances between images and in our algorithm it considers the local saliency as well. A global image saliency, evaluated in terms of spatially-invariant salient edges, is used as an additional term in the optimization search besides the \{EMD\} distance. Experimental results are provided for three different image databases containing a wide variety of semantic categories. "} 
}
@article{Kundu2015254,
title = {"A graph-based relevance feedback mechanism in content-based image retrieval "},
journal = {"Knowledge-Based Systems "},
volume = {"73"},
number = {""},
pages = {"254 - 264"},
year = {"2015"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2014.10.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705114003761"},
author = {"Malay Kumar Kundu and Manish Chowdhury and Samuel Rota Bulò"},
keywords = {"NSCT", "Content based image retrieval", "Re-ranking", "Relevance feedback", "Feature evaluation index "},
abstract = {"Abstract Content-Based Image Retrieval (CBIR) is an important problem in the domain of digital data management. There is indeed a growing availability of images, but unfortunately the traditional metadata-based search systems are unable to properly exploit their visual information content. In this article we introduce a novel \{CBIR\} scheme that abstracts each image in the database in terms of statistical features computed using the Multi-scale Geometric Analysis (MGA) of Non-subsampled Contourlet Transform (NSCT). Noise resilience is one of the main advantages of this feature representation. To improve the retrieval performance and reduce the semantic gap, our system incorporates a Relevance Feedback (RF) mechanism that uses a graph-theoretic approach to rank the images in accordance with the user’s feedback. First, a graph of images is constructed with edges reflecting the similarity of pairs of images with respect to the proposed feature representation. Then, images are ranked at each feedback round in terms of the probability that a random walk on this graph reaches an image tagged as relevant by the user before hitting a non-relevant one. Experimental analyses on three different databases show the effectiveness of our algorithm compared to state-of-the-art approaches in particular when the images are corrupted with different types of noise. "} 
}
@article{Agarwal2014131,
title = {"Classroom-based programs of retrieval practice reduce middle school and high school students’ test anxiety "},
journal = {"Journal of Applied Research in Memory and Cognition "},
volume = {"3"},
number = {"3"},
pages = {"131 - 139"},
year = {"2014"},
note = {"Cognition and Education "},
issn = {"2211-3681"},
doi = {"https://doi.org/10.1016/j.jarmac.2014.07.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S221136811400059X"},
author = {"Pooja K. Agarwal and Laura D’Antonio and Henry L. Roediger III and Kathleen B. McDermott and Mark A. McDaniel"},
keywords = {"Retrieval practice", "Study strategies", "Test anxiety", "Middle school", "High school", "Teaching "},
abstract = {"Abstract When retrieval practice is applied in classroom settings, do K-12 students experience changes in test anxiety? To answer this question frequently asked by educators, we surveyed 1408 middle school and high school students about their study strategy preferences and their reactions to a classroom-based program of retrieval practice. For classes in which retrieval practice occurred, 92% of students reported that retrieval practice helped them learn and 72% reported that retrieval practice made them less nervous for unit tests and exams. This study is the first to examine the relationship between retrieval practice and classroom test anxiety, and self-reported study strategy use in pre-college students. In light of our results, we encourage K-12 teachers to use retrieval practice in their classrooms to reduce test anxiety and improve learning. "} 
}
@article{Chen2014133,
title = {"Iterative phase retrieval for simultaneously generating two phase-only masks with silhouette removal in interference-based optical encryption "},
journal = {"Optics Communications "},
volume = {"331"},
number = {""},
pages = {"133 - 138"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.05.064"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814005392"},
author = {"Wen Chen and Xudong Chen"},
keywords = {"Optical encryption", "Phase retrieval", "Interference "},
abstract = {"Abstract We propose a novel method using iterative phase retrieval for simultaneously generating two phase-only masks with silhouette removal in interference-based optical encryption system. Different from previous works, an iterative phase retrieval algorithm is developed for simultaneously generating two phase-only masks in the different optical paths, and no additional keys (or masks) or complementary algorithms are required. Silhouette problem inherent in conventional interference-based encryption method is fully resolved, and the higher security can be correspondingly achieved. "} 
}
@article{KriegerRedwood201424,
title = {"\{TMS\} interferes with lexical-semantic retrieval in left inferior frontal gyrus and posterior middle temporal gyrus: Evidence from cyclical picture naming "},
journal = {"Neuropsychologia "},
volume = {"64"},
number = {""},
pages = {"24 - 32"},
year = {"2014"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2014.09.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393214003194"},
author = {"Katya Krieger-Redwood and Elizabeth Jefferies"},
keywords = {"Semantic", "Selection", "Retrieval", "TMS", "Naming "},
abstract = {"Abstract We used \{TMS\} to investigate the contribution of left inferior frontal gyrus (LIFG) and posterior middle temporal gyrus (pMTG) to lexical/semantic selection and retrieval processes using a cyclical naming paradigm. Participants named pictures that were presented repeatedly across six cycles, either in semantically related or unrelated sets. Previous research has suggested that selection demands are higher for related sets, especially after repetition, since participants experience competition from the activation of semantic neighbours. In contrast, retrieval demands are greater for unrelated sets in the absence of semantic priming, particularly on the first cycle when the target names have not been previously activated. Therefore, this paradigm can reveal independent effects of (i) retrieval demands (i.e., the ease of accessing picture names from visual input) and (ii) selection/competition. We found that rTMS to \{LIFG\} and pMTG produced similar behavioural effects: stimulation of both sites disrupted picture naming performance on early cycles (when participants were less practised at producing the picture names) and for semantically-related sets (when there was the potential for increased competition and yet also facilitation from semantic neighbours). There were no effects of \{TMS\} when either retrieval or selection requirements were maximal on their own. The data therefore support the view that both \{LIFG\} and pMTG contribute to picture name retrieval, with both sites playing a critical role in mediating the semantic facilitation of naming when retrieval demands are high. "} 
}
@article{Arnholt20171363,
title = {"Do Stem Taper Microgrooves Influence Taper Corrosion in Total Hip Arthroplasty? A Matched Cohort Retrieval Study "},
journal = {"The Journal of Arthroplasty "},
volume = {"32"},
number = {"4"},
pages = {"1363 - 1373"},
year = {"2017"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2016.11.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S088354031630818X"},
author = {"Christina M. Arnholt and Daniel W. MacDonald and Richard J. Underwood and Eric P. Guyer and Clare M. Rimnac and Steven M. Kurtz and Michael A. Mont and Gregg R. Klein and Gwo-Chin Lee and Antonia F. Chen and Brian R. Hamlin and Harold E. Cates and Arthur L. Malkani and Matthew J. Kraay"},
keywords = {"mechanically assisted crevice corrosion", "fretting", "corrosion", "taper", "microgrooves "},
abstract = {"AbstractBackground Previous studies identified imprinting of the stem morphology onto the interior head bore, leading researchers to hypothesize an influence of taper topography on mechanically assisted crevice corrosion. The purpose of this study was to analyze whether microgrooved stem tapers result in greater fretting corrosion damage than smooth stem tapers. Methods A matched cohort of 120 retrieved head-stem pairs from metal-on-polyethylene bearings was created controlling for implantation time, flexural rigidity, apparent length of engagement, and head size. There were 2 groups of 60 heads each, mated with either smooth or microgrooved stem tapers. A high-precision roundness machine was used to measure and categorize the surface morphology. Fretting corrosion damage at the head-neck junction was characterized using the Higgs-Goldberg scoring method. Fourteen of the most damaged heads were analyzed for the maximum depth of material loss and focused ion beam cross-sectioned to view oxide and base metal. Results Fretting corrosion damage was not different between the 2 cohorts at the femoral head (P = .14, Mann-Whitney) or stem tapers (P = .35). There was no difference in the maximum depths of material loss between the cohorts (P = .71). Cross-sectioning revealed contact damage, signs of micro-motion, and chromium-rich oxide layers in both cohorts. Microgroove imprinting did not appear to have a different effect on the fretting corrosion behavior. Conclusion The results of this matched cohort retrieval study do not support the hypothesis that taper surfaces with microgrooved stems exhibit increased in vivo fretting corrosion damage or material release. "} 
}
@article{Goossens2014177,
title = {"The benefit of retrieval practice over elaborative restudy in primary school vocabulary learning "},
journal = {"Journal of Applied Research in Memory and Cognition "},
volume = {"3"},
number = {"3"},
pages = {"177 - 182"},
year = {"2014"},
note = {"Cognition and Education "},
issn = {"2211-3681"},
doi = {"https://doi.org/10.1016/j.jarmac.2014.05.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211368114000473"},
author = {"Nicole A.M.C. Goossens and Gino Camp and Peter P.J.L. Verkoeijen and Huib K. Tabbers and Rolf A. Zwaan"},
keywords = {"Elaborative exercises", "Memory", "Retrieval practice", "Testing effect", "Vocabulary learning "},
abstract = {"Abstract The testing effect is the phenomenon that retrieval practice of learning material after studying enhances long-term retention more than restudying. We examined retrieval practice in primary school vocabulary learning in two experiments. Nine-year-old children studied word definitions and completed exercises according to three learning conditions: pure restudy, elaborative restudy or retrieval practice. Children in the pure restudy condition reread and partly copied the definitions. In the elaborative restudy condition children reread the definitions and connected semantically related words to the target words. Children in the retrieval practice condition recalled the words based on their definitions. Overall, on the fill-in-the-blank test after one week children in the retrieval practice condition outperformed children in the other conditions, but on the multiple-choice test there were no differences. Retrieval practice may be effective for primary school vocabulary learning, but there is uncertainty about the practical value and the magnitude of the retrieval practice effect. "} 
}
@article{Tedesco201478,
title = {"Extinction, applied after retrieval of auditory fear memory, selectively increases zinc-finger protein 268 and phosphorylated ribosomal protein \{S6\} expression in prefrontal cortex and lateral amygdala "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"115"},
number = {""},
pages = {"78 - 85"},
year = {"2014"},
note = {"\{MCCS\} 2014 "},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.08.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714001610"},
author = {"Vincenzo Tedesco and Rheall F. Roquet and John DeMis and Cristiano Chiamulera and Marie-H. Monfils"},
keywords = {"Fear conditioning", "Retrieval", "Extinction", "Reconsolidation", "rpS6P", "Zif268", "Prefrontal cortex", "Amygdala "},
abstract = {"Abstract Retrieval of consolidated memories induces a labile phase during which memory can be disrupted or updated through a reconsolidation process. A central component of behavioral updating during reconsolidation using a retrieval–extinction manipulation (Ret + Ext) is the synaptic removal of a calcium-permeable-α-amino-3-hydroxyl-5-methyl-4-isoxazole-propionate receptor (CP-AMPARs) in the lateral amygdala—a metabotropic GluR1 receptor (mGluR1) dependent mechanism. In the present study, we investigate the effect of Ret + Ext on the expression of molecular markers that could play a role in the reconsolidation process. Specifically, we tested the effects of Ret + Ext on the global expression of zinc-finger 268 protein (Zif268), a marker previously found to be implicated in memory reconsolidation, to confirm its occurrence after retrieval (Ret) and Ret + Ext. We also evaluated the global expression of phosphorylated ribosomal protein \{S6\} (rpS6P), here proposed as a marker of the mGluR1-mediated memory process induced by Ret + Ext. The expression of both markers (zif268, rpS6P) was assessed by immunolocalization in prelimbic cortex (PRL), infralimbic cortex (IL), ventral subdivision of the lateral amygdala (LA) and hippocampus \{CA1\} (CA1) in fear-conditioned rats. Our results showed that retrieval and Ret + Ext, but not extinction alone, increased Zif268 expression in prefrontal cortex and lateral amygdala. Ret + Ext, but not retrieval, retrieval followed by context exposure or extinction alone, increased the expression of rpS6P in prefrontal cortex and LA. In summary, (i) Zif268 increased after retrieval confirming that reconsolidation is engaged in our conditions, (ii) Zif268 increased after Ret + Ext confirming that it does not simply reflect an extinction or reconsolidation disruption (Zif268 level of expression should be lower in both cases) and (iii) rpS6P increased after Ret + Ext, but not after extinction, suggesting, as expected, a potential mGluR1 mediated molecular mechanism specific for Ret + Ext. Together with the Zif268 increase, our results suggest that the Ret + Ext induced memory process is more similar to reconsolidation updating than extinction facilitation. "} 
}
@article{Guerrieri201563,
title = {"Evolution of the 2011 Mt. Etna ash and \{SO2\} lava fountain episodes using \{SEVIRI\} data and \{VPR\} retrieval approach "},
journal = {"Journal of Volcanology and Geothermal Research "},
volume = {"291"},
number = {""},
pages = {"63 - 71"},
year = {"2015"},
note = {""},
issn = {"0377-0273"},
doi = {"https://doi.org/10.1016/j.jvolgeores.2014.12.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0377027314003977"},
author = {"Lorenzo Guerrieri and Luca Merucci and Stefano Corradini and Sergio Pugnaghi"},
keywords = {"Remote sensing", "Thermal-infrared radiation (TIR)", "Volcanic ash and \{SO2\} retrieval", "Multispectral satellite data "},
abstract = {"Abstract In this paper an estimation is made of the temporal evolution of volcanic ash and sulfur dioxide (SO2) emissions from Mt. Etna during its eruption phases. The retrieval is performed using MSG-SEVIRI (Meteosat Second Generation — Spinning Enhanced Visible and Infra Red Imager) images in the \{TIR\} (Thermal InfraRed) spectral range. The ash and \{SO2\} plume abundance maps are computed using the Volcanic Plume Removal (VPR) procedure originally applied to \{MODIS\} (Moderate Resolution Imaging Spectroradiometer) sensors on board the \{NASA\} Terra and Aqua satellites. As test cases, two 2011 lava fountain episodes were considered. The set of parameters required by \{VPR\} for the Mt. Etna volcano, Volz type particles, and the \{SEVIRI\} sensor are presented. Once the parameters have been computed, the \{VPR\} approach requires as input only the SEVIRI-TIR radiances of the bands centered at 8.7, 10.8, and 12.0 μm, together with the plume temperature and altitude. The \{VPR\} returns maps of plume particles' effective radius, aerosol optical depth at 550 nm, and columnar abundance of ash and SO2. A new procedure for estimating wind speed and direction is also presented. Since the ash and \{SO2\} abundance maps, and wind speed at the plume altitude are known, it is possible to reconstruct the ash and \{SO2\} fluxes emitted during the eruption through time. The \{VPR\} procedure, applied to \{TIR\} \{SEVIRI\} data, allows for fast and reliable ash and \{SO2\} retrieval with high temporal resolution during both day and night, and is thus suitable for operational use during a volcanic crisis. "} 
}
@article{Wang201436,
title = {"Single-intensity-recording optical encryption technique based on phase retrieval algorithm and \{QR\} code "},
journal = {"Optics Communications "},
volume = {"332"},
number = {""},
pages = {"36 - 41"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.06.070"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814006178"},
author = {"Zhi-peng Wang and Shuai Zhang and Hong-zhao Liu and Yi Qin"},
keywords = {"Optical encryption", "Phase retrieval algorithm", "QR code", "Security "},
abstract = {"Abstract Based on phase retrieval algorithm and \{QR\} code, a new optical encryption technology that only needs to record one intensity distribution is proposed. In this encryption process, firstly, the \{QR\} code is generated from the information to be encrypted; and then the generated \{QR\} code is placed in the input plane of 4-f system to have a double random phase encryption. For only one intensity distribution in the output plane is recorded as the ciphertext, the encryption process is greatly simplified. In the decryption process, the corresponding \{QR\} code is retrieved using phase retrieval algorithm. A priori information about \{QR\} code is used as support constraint in the input plane, which helps solve the stagnation problem. The original information can be recovered without distortion by scanning the \{QR\} code. The encryption process can be implemented either optically or digitally, and the decryption process uses digital method. In addition, the security of the proposed optical encryption technology is analyzed. Theoretical analysis and computer simulations show that this optical encryption system is invulnerable to various attacks, and suitable for harsh transmission conditions. "} 
}
@article{Xia2015500,
title = {"A regularized optimization framework for tag completion and image retrieval "},
journal = {"Neurocomputing "},
volume = {"147"},
number = {""},
pages = {"500 - 508"},
year = {"2015"},
note = {"Advances in Self-Organizing Maps Subtitle of the special issue: Selected Papers from the Workshop on Self-Organizing Maps 2012 (WSOM 2012) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.06.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214007747"},
author = {"Zhaoqiang Xia and Xiaoyi Feng and Jinye Peng and Jun Wu and Jianping Fan"},
keywords = {"Tag completion", "Social image", "Non-negative matrix factorization", "Visual diversity", "Image retrieval "},
abstract = {"Abstract With the fast expansion of social image sharing websites, the tag-based image retrieval (TBIR) becomes important and prevalent for Internet users to search the social images. However, some user-provided tags of social images are too incomplete and ambiguous to facilitate the social image retrieval. In this paper, we propose a regularized optimization framework to complete the missing tags for social images (tag completion). Within the regularized optimization framework, the non-negative matrix factorization (NMF) and the holistic visual diversity minimization are used jointly to make the tag-image matrix completed as the relationships of images and tags are represented to a tag-image matrix. The non-negative matrix factorization casts the tag-image matrix into a latent low-rank space and utilizes the semantic relevance of tags to partially complete the insufficient tags. To take the visual content of images into account, the other objective term representing the holistic visual diversity is appended with the \{NMF\} to leverage the content-similar images. Moreover, to ensure the proper corrections and sparseness of tag-image matrix, two regularized factors are also included into the optimization framework. Through conducting the experiments on the benchmark image set with the adequate ground truth, we verify the effectiveness of our proposed approach. "} 
}
@article{Chen2014155,
title = {"Time course of the dependence of associative memory retrieval on the entorhinal cortex "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"116"},
number = {""},
pages = {"155 - 161"},
year = {"2014"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.10.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714001828"},
author = {"Xi Chen and Zhengli Liao and Yin Ting Wong and Yiping Guo and Jufang He"},
keywords = {"Medial temporal lobe", "Hippocampus", "Recent memory", "Remote memory", "Memory encoding and retrieval "},
abstract = {"Abstract As the gateway between the hippocampal system and the neocortex, the entorhinal cortex (EC) is hypothesized to be the hub in which the transformation of recent memory to remote memory is processed. We explored the role of the \{EC\} on the retrieval of recent and remote associative fear memory. A within-subject approach was adopted to compare the freezing rates of rats in \{EC\} intact and \{EC\} inactivated conditions following trace fear conditioning. The \{EC\} was inactivated by infusing an \{AMPA\} antagonist. The fear conditioning used a combined visual and auditory conditioned stimulus with a foot shock. On week 1 following the conditioning, the rats in the \{EC\} intact condition exhibited a freezing rate of 92.4 ± 9.5% in response to the light stimulus compared with a 6.3 ± 7.9% freezing rate in the \{EC\} inactivated condition. The freezing rates were 87.0 ± 17.8% and 4.7 ± 6.5% on week 2 in the \{EC\} intact and inactivated conditions, respectively. These results indicate that the \{EC\} participates in the retrieval of associative memory. Extinction of the fear memory was observed in the \{EC\} intact condition, as the mean freezing rate decreased to 62.7 ± 23.0% on week 4 and 41.2 ± 26.4% on week 5. However, the freezing rate increased to 26.8 ± 14.2% on week 4 and 22.3 ± 14.4% on week 5 in the \{EC\} inactivated condition. The normalized dependence of fear memory retrieval on the \{EC\} was 93.2 ± 8.3% on week 1, and significantly decreased on weeks 4 and 5. In summary, the retrieval of associative memory depends on the EC, but this dependence decreases over time. "} 
}
@article{Ji2017313,
title = {"A total precipitable water retrieval method over land using the combination of passive microwave and optical remote sensing "},
journal = {"Remote Sensing of Environment "},
volume = {"191"},
number = {""},
pages = {"313 - 327"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2017.01.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425717300408"},
author = {"Dabin Ji and Jiancheng Shi and Chuan Xiong and Tianxing Wang and Yuhuan Zhang"},
keywords = {"Total precipitable water", "Surface emissivity", "Microwave remote sensing", "Downscaling", "Passive microwave radiometer "},
abstract = {"Abstract Atmospheric water vapor plays an important role in hydrologic cycle and climate change of the Earth. A number of studies have focused on retrieval of the total precipitable water (TPW) using microwave or optical remote sensing. In this paper, the global quarter-degree gridded \{TPW\} over land was retrieved using water vapor sensitivity parameter ∆ Tb18.7/∆ Tb23.8 based on the combination of AMSR-E and \{MODIS\} observations. There are two major improvements in the retrieval algorithm, including optimization of the estimation model of surface emissivity ∆ ε18.7/∆ ε23.8 and correction of the terrain influence to the retrieval of \{TPW\} using DEM. To obtain a high resolution TPW, we also developed an algorithm to downscale the retrieved quarter-degree gridded \{TPW\} to a fine scale of 0.05° × 0.05° using \{DEM\} and NDVI. In addition, the downscaled \{TPW\} was further calibrated using high precision \{TPW\} from \{MODIS\} in the clear-sky condition to improve its accuracy. Finally, both quarter-degree and 0.05° × 0.05° gridded \{TPW\} were validated against SuomiNet \{GPS\} retrieved \{TPW\} on a global scale. The \{RMSE\} for the retrieved quarter-degree gridded global \{TPW\} is 3.45 mm, with a correlation coefficient of 0.95. In addition, the \{RMSE\} for the downscaled 0.05° × 0.05° gridded global \{TPW\} is 4.18 mm, with a correlation coefficient of 0.95. An obvious advantage of our algorithm compared with \{MODIS\} \{TPW\} product is that it can retrieve \{TPW\} under cloudy sky condition over land. The algorithm developed in this study can be easily transferred to \{AMSR2\} on board GCOM-W1 and provides the long-term global daily \{TPW\} over land since the launch of Aqua to present day to support hydrologic cycle and climate change studies. "} 
}
@article{Fakhfakh2015320,
title = {"Image Retrieval Based on Using Hamming Distance "},
journal = {"Procedia Computer Science "},
volume = {"73"},
number = {""},
pages = {"320 - 327"},
year = {"2015"},
note = {"International Conference on Advanced Wireless Information and Communication Technologies (AWICT 2015) "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2015.12.040"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050915035012"},
author = {"Sana Fakhfakh and Mohamed Tmar and Walid Mahdi"},
keywords = {"Content", "binary signature", "image retrieval", "hamming distance", "visual descriptor "},
abstract = {"Abstract The expeditious development of images volume on applications recent creates the need for emergence of new indexing and retrieval tools that facilitate access to relevant need. In this paper, we tried to create a visual vocabulary from phase extraction of descriptors such as color, texture, interest points. The method is to assign a signature to each image in collection. The extraction of signature is based on application of Haar wavelet multiscale, Harris interest points and analyzing color histogram. This signature will undergo a size reduction step by using the \{PCA\} (Principal Component Analysis). The signature of each image passes through a stage of binarization. This binary code obtained need using Hamming distance in the similarity matching. Experiments are undertaken into four data sets “Caltech101”, “Caltech256”, “ImageCLEF 2013” and “ImageCLEF 2014”. The obtained results showed effectiveness of our approach. "} 
}
@article{Schilling2014358,
title = {"Examining the costs and benefits of inhibition in memory retrieval "},
journal = {"Cognition "},
volume = {"133"},
number = {"2"},
pages = {"358 - 370"},
year = {"2014"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2014.07.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010027714001401"},
author = {"Christopher J. Schilling and Benjamin C. Storm and Michael C. Anderson"},
keywords = {"Retrieval-induced forgetting", "Inhibition", "Interference", "Stop-signal reaction time "},
abstract = {"Abstract Inhibitory control is thought to serve an adaptive function in controlling behavior, with individual differences predicting variation in numerous cognitive functions. However, inhibition is more properly construed as inducing both benefits and costs to performance. Benefits arise at the point when inhibition prevents expression of an unwanted or contextually inappropriate response; costs arise later, when access to the inhibited representation is required by other processes. Here we illustrate how failure to consider both the costs and benefits of inhibition has generated confusion in the literature on individual differences in cognitive control. Using retrieval-induced forgetting as a model case, we illustrate this by showing that changing the way that retrieval-induced forgetting is measured to allow greater expression of the benefits of inhibition together with the costs can reduce and even reverse the theoretically predicted correlation between motor and memory inhibition. Specifically, we show that when the final test in a retrieval-induced forgetting procedure employs item-specific cues (i.e., category-plus-stem cued recall and item-recognition) that better isolate the lingering costs of inhibition, better motor response inhibition (faster stop-signal reaction times) predicts greater retrieval-induced forgetting. In striking contrast, when the final test is less well controlled, allowing both the costs and benefits of inhibition to contribute, motor response inhibition has the opposite relationship with retrieval-induced forgetting. These findings underscore the importance of considering the correlated costs and benefits problem when studying individual differences in inhibitory control. More generally, they suggest that a shared inhibition mechanism may underlie people’s ability to control memories and actions. "} 
}
@article{Zhuo2014202,
title = {"A comparative study of dimensionality reduction methods for large-scale image retrieval "},
journal = {"Neurocomputing "},
volume = {"141"},
number = {""},
pages = {"202 - 210"},
year = {"2014"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.03.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214004238"},
author = {"Li Zhuo and Bo Cheng and Jing Zhang"},
keywords = {"Large-scale image retrieval", "Dimensionality reduction", "OPTIMIZED SIFT", "HSV histogram", "Vocabulary tree "},
abstract = {"Abstract “Curse of Dimensionality” is one of the important problems that Content-Based Image Retrieval (CBIR) confronts. Dimensionality reduction is an effective method to overcome it. In this paper, six commonly-used dimensionality reduction methods are compared and analyzed to examine their respective performance in image retrieval. The six methods include Principal Component Analysis (PCA), Fisher Linear Discriminant Analysis (FLDA), Local Fisher Discriminant Analysis (LFDA), Isometric Mapping (ISOMAP), Locally Linear Embedding (LLE), and Locality Preserving Projections (LPP). For comparison, Scale Invariant Feature Transform (SIFT) and color histogram in Hue, Saturation, Value (HSV) color space are firstly extracted as image features, meanwhile \{SIFT\} feature extraction procedure is optimized to reduce the number of \{SIFT\} features. Then, PCA, FLDA, LFDA, ISOMAP, LLE, and \{LPP\} are respectively applied to reduce the dimensions of feature vectors, which can be used to generate vocabulary trees. Finally, we can process large-scale image retrieval based on the inverted index built by vocabulary trees. In the experiments, the performance of various dimensionality reduction methods are analyzed comprehensively by comparing the retrieval performance, advantages and disadvantages, computational complexity and time-consuming of image retrieval. Through a series of experiments, we can conclude that dimensionality reduction method of \{LLE\} and \{LPP\} can effectively reduce computational complexity of image retrieval, while maintaining high retrieval performance. "} 
}
@article{Bridge2014154,
title = {"Active retrieval facilitates across-episode binding by modulating the content of memory "},
journal = {"Neuropsychologia "},
volume = {"63"},
number = {""},
pages = {"154 - 164"},
year = {"2014"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2014.08.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393214002875"},
author = {"Donna J. Bridge and Joel L. Voss"},
keywords = {"Retrieval", "Active learning", "ERP", "Recognition", "Binding", "Reactivation "},
abstract = {"Abstract The contents of memory can be updated when information from the current episode is bound with content retrieved from previous episodes. Little is known regarding factors that determine the memory content that is subject to this across-episode binding. We tested whether across-episode binding preferentially occurs for memory content that is currently “active” and identified relevant neural correlates. After studying objects at specific locations on scene backgrounds, subjects performed one of two retrieval tasks for the objects on different scene backgrounds. In an active condition, subjects recalled object locations, whereas subjects merely dragged objects to predetermined locations in a passive condition. Immediately following each object-location retrieval event, a novel face appeared on a blank screen. We hypothesized that the original episode content would be active in memory during face encoding in the active condition, but not in the passive condition (despite seeing the same content in both conditions). A ramification of the active condition would thus be preferential binding of original episode content to novel faces, with no such across-episode binding in the passive condition. Indeed, memory for faces was better when tested on the original background scenes in the active relative to passive condition, indicating that original episode content was bound with the active condition faces, whereas this occurred to a lesser extent for the passive condition faces. Likewise, early-onset negative \{ERP\} effects reflected binding of the face to the original episode content in the active but not the passive condition. In contrast, binding in the passive condition occurred only when faces were physically displayed on the original scenes during recognition testing, and a very similar early-onset negative \{ERP\} effect signaled binding in this condition. \{ERP\} correlates of binding were thus similar for across-episode and within-episode binding (and were distinct from other encoding and retrieval \{ERP\} signals in both cases), indicating that active retrieval modulated when binding occurred, not the nature of the binding process per se. These results suggest that active retrieval promotes binding of new information with contents of memory, whereas without active retrieval, these unrelated pieces of information might be bound only when they are physically paired. "} 
}
@article{Rashedi201426,
title = {"Long term learning in image retrieval systems using case based reasoning "},
journal = {"Engineering Applications of Artificial Intelligence "},
volume = {"35"},
number = {""},
pages = {"26 - 37"},
year = {"2014"},
note = {""},
issn = {"0952-1976"},
doi = {"https://doi.org/10.1016/j.engappai.2014.06.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0952197614001316"},
author = {"Esmat Rashedi and Hossein Nezamabadi-pour and Saeid Saryazdi"},
keywords = {"Content based image retrieval", "Relevance feedback", "Long term learning", "Case based reasoning", "Semantic frame "},
abstract = {"Abstract Relevance feedback is a powerful tool emerged to boost the retrieval performance of content based image retrieval (CBIR) systems. Short term learning (STL) and long term learning (LTL) are two learning methods of relevance feedback scheme. This paper presents a long term learning method in \{CBIR\} systems adopting case based reasoning (CBR) which is called Case-based \{LTL\} (CB-LTL). The method has two stages of learning and reasoning. In the learning stage, information extracted from retrieval sessions is saved as cases and in the reasoning stage, information of cases is utilized to improve the results of the retrieval sessions. The main components of CB-LTL method are ‘key of query’ which represents the desire of the user, a ‘trigger function’ which is used to find a similar case with a query, and ‘semantic frame’ which is a structure for saving cases. In the proposed method, cases are recorded in the case knowledge base using both low level and high level features. The information of the relevance feedback and short term learning are employed as high level features. In this paper, the general approach of CB-LTL is produced and an example of the method is implemented in a \{CBIR\} system with the similarity refinement based STL. To evaluate the proposed method, a comparative study with the “virtual feature based” \{LTL\} method is performed based on the Corel image dataset. The experimental results validate the effectiveness of Case-based \{LTL\} method empirically. "} 
}
@article{Soto2015169,
title = {"Investigation of the Case-based Reasoning Retrieval Process to Estimate Resources in Construction Projects "},
journal = {"Procedia Engineering "},
volume = {"123"},
number = {""},
pages = {"169 - 181"},
year = {"2015"},
note = {"Selected papers from Creative Construction Conference 2015 "},
issn = {"1877-7058"},
doi = {"https://doi.org/10.1016/j.proeng.2015.10.074"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877705815031756"},
author = {"Borja García De Soto and Bryan T. Adey"},
keywords = {"artificial intelligence", "case-based reasoning", "preliminary estimates", "resource estimates", "retrieval process. "},
abstract = {"Abstract Case-based reasoning (CBR) is a methodology that is seeing increasing use to make predictions during the early phases of a project. It allows estimators to exploit existing knowledge to make predictions that are considerably better than without its use. All CBR, however, is not identical, and variations in how \{CBR\} is done can affect the accuracy of the predictions. One particular area of sensitivity is the retrieval phase, i.e. the way in which the \{CBR\} determines the closeness between the new and the existing cases. In this paper, \{CBR\} is used to make estimates of resources for construction projects, and the use of the nearest neighbor technique to identify the similarity for the retrieval phase to predict the construction material quantities (CMQs) in concrete structures is investigated. Two types of distances, i.e. 1) the City-block distance and 2) the Euclidean distance, and four different types of weights, based on regression analysis and feature counting, to account for the relative importance of the different parameters, are investigated. The four different types of weights used were 1) the adjusted unstandardized coefficients from the regression models, 2) the unadjusted unstandardized coefficients from the regression models, 3) the standardized coefficients from the regression models, and 4) equal weights (i.e., feature counting), in which the weights applied are 1/k, and k is the number of parameter being compared to determine the distance. The mean absolute percentage error (MAPE) was used to evaluate each combination investigated. It was found that for a similarity threshold of 90%, the \{CBR\} methodology using the City-block distance with the adjusted unstandardized coefficients from the regression analysis models using the transformed (LN) dataset as weights, gave the best results, with a \{MAPE\} of 8.16%. The worst results were obtained from the \{CBR\} methodology using the Euclidean distance with feature counting weights, with a \{MAPE\} of 28.40%. "} 
}
@article{Anderson2017163,
title = {"Direct and generative retrieval of autobiographical memories: The roles of visual imagery and executive processes "},
journal = {"Consciousness and Cognition "},
volume = {"49"},
number = {""},
pages = {"163 - 171"},
year = {"2017"},
note = {""},
issn = {"1053-8100"},
doi = {"https://doi.org/10.1016/j.concog.2017.02.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053810016301969"},
author = {"Rachel J. Anderson and Stephen A. Dewhurst and Graham M. Dean"},
keywords = {"Autobiographical memory", "Visual imagery", "Visual working memory", "Dual task paradigm "},
abstract = {"Abstract Two experiments used a dual task methodology to investigate the role of visual imagery and executive resources in the retrieval of specific autobiographical memories. In Experiment 1, dynamic visual noise led to a reduction in the number of specific memories retrieved in response to both high and low imageability cues, but did not affect retrieval times. In Experiment 2, irrelevant pictures reduced the number of specific memories but only in response to low imageability cues. Irrelevant pictures also increased response times to both high and low imageability cues. The findings are in line with previous work suggesting that disrupting executive resources may impair generative, but not direct, retrieval of autobiographical memories. In contrast, visual distractor tasks appear to impair access to specific autobiographical memories via both the direct and generative retrieval routes, thereby highlighting the potential role of visual imagery in both pathways. "} 
}
@article{Macedo2016159,
title = {"A Health Surveillance Software Framework to deliver information on preventive healthcare strategies "},
journal = {"Journal of Biomedical Informatics "},
volume = {"62"},
number = {""},
pages = {"159 - 170"},
year = {"2016"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2016.06.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046416300454"},
author = {"Alessandra Alaniz Macedo and Juliana Tarossi Pollettini and José Augusto Baranauskas and Julia Carmona Almeida Chaves"},
keywords = {"Software framework", "Reuse", "Biomedical informatics", "Information extraction", "Retrieval and application of biomedical knowledge and information", "Recommender systems: medical records and scientific papers", "Ontology "},
abstract = {"Abstract A software framework can reduce costs related to the development of an application because it allows developers to reuse both design and code. Recently, companies and research groups have announced that they have been employing health software frameworks. This paper presents the design, proof-of-concept implementations and experimentation of the Health Surveillance Software Framework (HSSF). The \{HSSF\} is a framework that tackles the demand for the recommendation of surveillance information aiming at supporting preventive healthcare strategies. Examples of such strategies are the automatic recommendation of surveillance levels to patients in need of healthcare and the automatic recommendation of scientific literature that elucidates epigenetic problems related to patients. \{HSSF\} was created from two systems we developed in our previous work on health surveillance systems: the Automatic-SL and \{CISS\} systems. The Automatic-SL system aims to assist healthcare professionals in making decisions and in identifying children with developmental problems. The \{CISS\} service associates genetic and epigenetic risk factors related to chronic diseases with patient’s clinical records. Towards evaluating the \{HSSF\} framework, two new systems, CISS+ and CISS-SW, were created by means of abstractions and instantiations of the framework (design and code). We show that \{HSSF\} supported the development of the two new systems given that they both recommend scientific papers using medical records as queries even though they exploit different computational technologies. In an experiment using simulated patients’ medical records, we show that CISS, CISS+, and CISS-SW systems recommended more closely related and somewhat related documents than Google, Google Scholar and PubMed. Considering recall and precision measures, CISS+ surpasses CISS-SW in terms of precision. "} 
}
@article{Zhou2015205,
title = {"Automatic image–text alignment for large-scale web image indexing and retrieval "},
journal = {"Pattern Recognition "},
volume = {"48"},
number = {"1"},
pages = {"205 - 219"},
year = {"2015"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2014.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320314002465"},
author = {"Ning Zhou and Jianping Fan"},
keywords = {"Automatic image–text alignment", "Web image indexing and retrieval", "Relevance re-ranking", "Random walk", "Phrase-correlation network "},
abstract = {"Abstract In this paper, an automatic image–text alignment algorithm is developed to achieve more effective indexing and retrieval of large-scale web images by aligning web images with their most relevant auxiliary text terms or phrases. First, a large number of cross-media web pages (which contain web images and their auxiliary texts) are crawled and segmented into a set of image–text pairs (informative web images and their associated text terms or phrases). Second, near-duplicate image clustering is used to group large-scale web images into a set of clusters of near-duplicate images according to their visual similarities. The near-duplicate web images in the same cluster share similar semantics and are simultaneously associated with a same or similar set of auxiliary text terms or phrases which co-occur frequently in the relevant text blocks, thus performing near-duplicate image clustering can significantly reduce the uncertainty on the relatedness between the semantics of web images and their auxiliary text terms or phrases. Finally, random walk is performed over a phrase correlation network to achieve more precise image–text alignment by refining the relevance scores between the web images and their auxiliary text terms or phrases. Our experiments on algorithm evaluation have achieved very positive results on large-scale cross-media web pages. "} 
}
@article{Bauduin2017428,
title = {"IASI's sensitivity to near-surface carbon monoxide (CO): Theoretical analyses and retrievals on test cases "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"189"},
number = {""},
pages = {"428 - 440"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.12.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316303442"},
author = {"Sophie Bauduin and Lieven Clarisse and Michael Theunissen and Maya George and Daniel Hurtmans and Cathy Clerbaux and Pierre-François Coheur"},
keywords = {"IASI", "Carbon monoxide", "Thermal contrast", "Vertical sensitivity", "Planetary boundary layer "},
abstract = {"Abstract Separating concentrations of carbon monoxide (CO) in the boundary layer from the rest of the atmosphere with nadir satellite measurements is of particular importance to differentiate emission from transport. Although thermal infrared (TIR) satellite sounders are considered to have limited sensitivity to the composition of the near-surface atmosphere, previous studies show that they can provide information on \{CO\} close to the ground in case of high thermal contrast. In this work we investigate the capability of \{IASI\} (Infrared Atmospheric Sounding Interferometer) to retrieve near-surface \{CO\} concentrations, and we quantitatively assess the influence of thermal contrast on such retrievals. We present a 3-part analysis, which relies on both theoretical forward simulations and retrievals on real data, performed for a large range of negative and positive thermal contrast situations. First, we derive theoretically the \{IASI\} detection threshold of \{CO\} enhancement in the boundary layer, and we assess its dependence on thermal contrast. Then, using the optimal estimation formalism, we quantify the role of thermal contrast on the error budget and information content of near-surface \{CO\} retrievals. We demonstrate that, contrary to what is usually accepted, large negative thermal contrast values (ground cooler than air) lead to a better decorrelation between \{CO\} concentrations in the low and the high troposphere than large positive thermal contrast (ground warmer than the air). In the last part of the paper we use Mexico City and Barrow as test cases to contrast our theoretical predictions with real retrievals, and to assess the accuracy of \{IASI\} surface \{CO\} retrievals through comparisons to ground-based in-situ measurements. "} 
}
@article{Han2014128,
title = {"Clustering and retrieval of video shots based on natural stimulus fMRI "},
journal = {"Neurocomputing "},
volume = {"144"},
number = {""},
pages = {"128 - 137"},
year = {"2014"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2013.11.052"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214007425"},
author = {"Junwei Han and Xiang Ji and Xintao Hu and Jungong Han and Tianming Liu"},
keywords = {"Video clustering", "Video retrieval", "Functional magnetic resonance imaging", "Feature integration "},
abstract = {"Abstract Functional magnetic resonance imaging (fMRI) is a powerful tool to probe the human brain׳s perception and cognition. Besides being extensively exploited in the clinical applications, fMRI technique is also useful to human׳s ordinary life. In this paper, we investigate a novel application of leveraging fMRI techniques to video clustering and retrieval. In the proposed work, we successfully integrate semantic human-centric features derived from natural stimulus fMRI data and low-level visual-audio features to facilitate video clustering and retrieval, which is a significant innovation compared to the previous works relying on either fMRI-derived features or low-level visual-audio features. Our system consists of several algorithmic modules. First, fMRI data when the subjects are watching video shot samples are acquired. Then a newly developed brain networks localization system is employed to locate the cortical regions of interests (ROIs) for each individual subject. The functional interactions computed by wavelet transform coherence are quantified, from which the human-centric features are derived. Afterwards, the Gaussian process regression model mapping visual-audio feature space to an fMRI-derived feature space is trained, given the training samples. The trained model is then adopted to predict fMRI-derived features for videos without the fMRI data. Finally, the multi-modal spectral clustering and multi-modal ranking algorithm are adopted and proposed to integrate these two heterogeneous features for video clustering and retrieval, respectively. Our experiment on \{TRECVID\} database has demonstrated the precision of video clustering and retrieval can be substantially improved by integration of visual-audio features and fMRI-derived features. "} 
}
@article{Sun2014304,
title = {"Fractional order tension control for stable and fast tethered satellite retrieval "},
journal = {"Acta Astronautica "},
volume = {"104"},
number = {"1"},
pages = {"304 - 312"},
year = {"2014"},
note = {""},
issn = {"0094-5765"},
doi = {"https://doi.org/10.1016/j.actaastro.2014.08.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0094576514003191"},
author = {"Guanghui Sun and Z.H. Zhu"},
keywords = {"Tethered satellite", "Retrieval", "Fractional order", "Tension control", "Dynamics "},
abstract = {"Abstract The retrieval of a tethered satellite system is intrinsically unstable. This paper develops a new control strategy to retrieve the tethered satellite system stably and quickly using the fractional order control theory. The governing equation of the tethered satellite system and classic linear feedback tension control law were first reviewed and examined as a benchmark. Then, a new fractional order tension control law has been to avoid the tethered satellite winds around the main satellite near the end of retrieval by existing integer order tension control laws. The newly proposed control law has been discretized and implemented by the Laplace transform and Tustin operator. Unlike the existing integer order control laws, which are based on the feedback of current state and memoryless, the fractional order control law has the memory of previous states and thus controls the tether retrieval more smoothly while maintaining the retrieving speed. The effectiveness and advantage of the new fractional order tension control law is demonstrated numerically by comparing with its integer order counterpart. The results show that the new control law not only retrieves the subsatellite without winding around the main satellite, but also provides a better control performance with smaller in-plane libration angles. "} 
}
@article{Bäuml201416,
title = {"Memory retrieval as a self-propagating process "},
journal = {"Cognition "},
volume = {"132"},
number = {"1"},
pages = {"16 - 21"},
year = {"2014"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2014.03.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010027714000468"},
author = {"Karl-Heinz T. Bäuml and Andreas Schlichting"},
keywords = {"Episodic memory", "Retrieval-induced forgetting", "Part-set cuing", "Context", "Context reactivation "},
abstract = {"Abstract Retrieval of a subset of studied items and the presentation of those items as retrieval cues typically impair retrieval of the other items. Previous research on this self-limiting property of memory retrieval has relied heavily on short retention intervals and similar context between encoding and test. Here, we examined retrieval dynamics also after a prolonged retention interval with different spatial and social context between encoding and test, conditions that mimic people’s remembering in many situations of daily life. For both unrelated word lists and more integrated prose material, we found retrieval and cuing to impair recall of other studied items after a short retention interval, but to improve recall in the prolonged retention interval condition. The results demonstrate that retrieval dynamics depend critically on situation, indicating that quite often in daily life, retrieval may be a self-propagating, rather than a self-limiting process. "} 
}
@article{StJacques2017103,
title = {"Shifting visual perspective during retrieval shapes autobiographical memories "},
journal = {"NeuroImage "},
volume = {"148"},
number = {""},
pages = {"103 - 114"},
year = {"2017"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.12.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916307509"},
author = {"Peggy L. St. Jacques and Karl K. Szpunar and Daniel L. Schacter"},
keywords = {"Egocentric perspective", "Memory", "fMRI", "Precuneus", "Repetition suppression "},
abstract = {"Abstract The dynamic and flexible nature of memories is evident in our ability to adopt multiple visual perspectives. Although autobiographical memories are typically encoded from the visual perspective of our own eyes they can be retrieved from the perspective of an observer looking at our self. Here, we examined the neural mechanisms of shifting visual perspective during long-term memory retrieval and its influence on online and subsequent memories using functional magnetic resonance imaging (fMRI). Participants generated specific autobiographical memories from the last five years and rated their visual perspective. In a separate fMRI session, they were asked to retrieve the memories across three repetitions while maintaining the same visual perspective as their initial rating or by shifting to an alternative perspective. Visual perspective shifting during autobiographical memory retrieval was supported by a linear decrease in neural recruitment across repetitions in the posterior parietal cortices. Additional analyses revealed that the precuneus, in particular, contributed to both online and subsequent changes in the phenomenology of memories. Our findings show that flexibly shifting egocentric perspective during autobiographical memory retrieval is supported by the precuneus, and suggest that this manipulation of mental imagery during retrieval has consequences for how memories are retrieved and later remembered. "} 
}
@article{Bialuk2014931,
title = {"CP55,940 attenuates spatial memory retrieval in mice "},
journal = {"Pharmacological Reports "},
volume = {"66"},
number = {"6"},
pages = {"931 - 936"},
year = {"2014"},
note = {""},
issn = {"1734-1140"},
doi = {"https://doi.org/10.1016/j.pharep.2014.06.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1734114014002138"},
author = {"Izabela Bialuk and Katarzyna Dobosz and Bartosz Potrzebowski and Maria Małgorzata Winnicka"},
keywords = {"CP55,940", "Spatial memory retrieval", "Morris water maze", "Hole-board test", "Mice "},
abstract = {"AbstractBackground Cannabinoids constitute a varied group of lipophilic substances able to infiltrate the blood–brain barrier and influence neuronal processes. Clinical observations supported by experimental data have revealed that these compounds exert a deleterious effect on cognitive processes. The present study was carried out to determine the influence of a single systemic administration of CP55,940, a potent synthetic agonist of cannabinoid receptors, on spatial memory retrieval assessed in a Morris water maze. Methods C57BL/6J male mice were submitted to three consecutive days of training to find a hidden platform in the water maze. CP55,940 was given intraperitoneally once, at doses of 0.025, 0.125 or 0.25 mg/kg on the fourth day, 30 min before testing memory retrieval, and in separate groups before testing psychomotor activity and anxiety level in a hole-board test. Results CP55,940 only at the highest dose of 0.25 mg/kg significantly altered all parameters used to assess spatial memory. It increased the latency in the first crossing of the former platform location (target area), decreased the number of target area crossings and shortened the time spent in the target quadrant. Moreover, CP55,940 at doses of 0.25 and 0.125 mg/kg attenuated motor and exploratory activity in hole-board test. Conclusion Since the attenuated psychomotor activity after a dose of 0.125 mg/kg did not interfere with memory retrieval, we assume that the impairment of spatial memory observed after the highest dose of CP55,940 (0.25 mg/kg) was exerted by its influence on cognitive processes, however, the impact on locomotion could not be excluded. "} 
}
@article{Yan20141726,
title = {"Fusing multi-cues description for partial-duplicate image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"7"},
pages = {"1726 - 1731"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.06.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314001047"},
author = {"Chenggang Clarence Yan and Liang Li and Zhan Wang and Jian Yin and Hailong Shi and Shuqiang Jiang and Qingming Huang"},
keywords = {"Multi-cues", "Local Self-Similarity Descriptor", "Spatial pyramid", "Partial-duplicate image retrieval "},
abstract = {"Abstract In traditional image retrieval, images are commonly represented using Bag-of-visual-Words (BoW) built from image local features. However, the lack of spatial and structural information suppresses its performance in applications. In this paper, we introduce a multi-cues description by fusing structural, content and spatial information for partial-duplicate image retrieval. Firstly, we propose a rotation-invariant Local Self-Similarity Descriptor (LSSD), which captures the internal structural layouts in the local textural self-similar regions around interest points. Then, based on the spatial pyramid model, we make use of both \{LSSD\} and \{SIFT\} to construct an image representation with multi-cues. Finally, we formulate the Semi-Relative Entropy as the distance metric. Comparison experiments with state-of-the-art methods on four popular databases show the efficiency and effectiveness of our approach. "} 
}
@article{Tokola20151973,
title = {"Avoiding Fragmentation in Miniload Automated Storage and Retrieval Systems "},
journal = {"IFAC-PapersOnLine "},
volume = {"48"},
number = {"3"},
pages = {"1973 - 1977"},
year = {"2015"},
note = {"15th \{IFAC\} Symposium onInformation Control Problems inManufacturingINCOM 2015 "},
issn = {"2405-8963"},
doi = {"https://doi.org/10.1016/j.ifacol.2015.06.377"},
url = {"http://www.sciencedirect.com/science/article/pii/S2405896315006163"},
author = {"Henri Tokola and Esko Niemi"},
keywords = {"warehouse automation", "automated storage and retrieval system", "fragmentation avoidance", "simulation "},
abstract = {"Abstract This paper studies detailed slotting in miniload automated storage and retrieval systems (miniload AS/RSs). The systems that are studied have a number of identical shelves and they handle cartons with different widths. The purpose is to find out a detailed slotting rule that makes utilisation high by reducing the fragmentation of the available storage space into small and unusable gaps. For this purpose, the paper constructs and analyses a detailed slotting rule which is based on a best fit rule, but which aligns the cartons being handled to both ends of the shelf and next to a longer carton. The rule is compared to the first fit rule and to different aligning options in order to validate its performance. The simulation results show that the rule thus constructed can give as much as a 10% saving in the utilisation when compared to the first fit rule without aligning. Aligning next to a longer carton instead of next to a shorter carton gives a 1% benefit. "} 
}
@article{ElHaj201754,
title = {"Eye movement during retrieval of emotional autobiographical memories "},
journal = {"Acta Psychologica "},
volume = {"174"},
number = {""},
pages = {"54 - 58"},
year = {"2017"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2017.02.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691817300689"},
author = {"Mohamad El Haj and Jean-Louis Nandrino and Pascal Antoine and Muriel Boucart and Quentin Lenoble"},
keywords = {"Autobiographical memory", "Emotion", "Eye movement", "Fixations", "Saccades "},
abstract = {"Abstract This study assessed whether specific eye movement patterns are observed during emotional autobiographical retrieval. Participants were asked to retrieve positive, negative and neutral memories while their scan path was recorded by an eye-tracker. Results showed that positive and negative emotional memories triggered more fixations and saccades but shorter fixation duration than neutral memories. No significant differences were observed between emotional and neutral memories for duration and amplitude of saccades. Positive and negative retrieval triggered similar eye movement (i.e., similar number of fixations and saccades, fixation duration, duration of saccades, and amplitude of saccades). Interestingly, the participants reported higher visual imagery for emotional memories than for neutral memories. The findings demonstrate similarities and differences in eye movement during retrieval of neutral and emotional memories. Eye movement during autobiographical retrieval seems to be triggered by the creation of visual mental images as the latter are indexed by autobiographical reconstruction. "} 
}
@article{MedinaLlamas2014167,
title = {"Use of magnetic polyaniline/maghemite nanocomposite for \{DNA\} retrieval from aqueous solutions "},
journal = {"Journal of Colloid and Interface Science "},
volume = {"434"},
number = {""},
pages = {"167 - 174"},
year = {"2014"},
note = {""},
issn = {"0021-9797"},
doi = {"https://doi.org/10.1016/j.jcis.2014.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0021979714005554"},
author = {"Juan Carlos Medina-Llamas and Alicia Elizabeth Chávez-Guajardo and Cesar Augusto Souza Andrade and Kleber Gonçalves Bezerra Alves and Celso Pinto de Melo"},
keywords = {"Pani/γ-Fe2O3 magnetic nanocomposite", "DNA retrieval", "UV–Vis spectroscopy "},
abstract = {"Abstract We demonstrated that the magnetic polyaniline/maghemite nanocomposite (Pani/γ-Fe2O3 MNC) is an efficient agent for retrieval of pure double stranded deoxyribonucleic acid (dsDNA) chains from aqueous solutions. The dsDNA chains used in the retrieval experiments were of sodium salt of Salmon Sperm DNA. Based on λ = 260 nm absorption measurements, we have employed UV–Vis spectroscopy to estimate the concentration of \{DNA\} present in solutions, before and after the interaction with the MNC. The best results corresponded to a maximum amount of 75.2 mg of \{DNA\} absorbed per gram of \{MNC\} reached within only 10 min of joint exposure into the aqueous solution. After magnetic separation of the fully DNA-loaded Pani/γ-Fe2O3 MNC, we achieved essentially complete \{DNA\} desorption by appropriate changes in the pH of the solution. We have shown that it is possible to recycle the use of these \{MNC\} in several adsorption–desorption cycles. By comparing the present results to those of other \{DNA\} retrieval systems reported in the literature, we argued that the Pani/γ-Fe2O3 \{MNC\} here described represent a promising low-cost material for use as a fast, simple and efficient method of \{DNA\} separation and concentration. "} 
}
@article{Kang2014183,
title = {"Is the benefit of retrieval practice modulated by motivation? "},
journal = {"Journal of Applied Research in Memory and Cognition "},
volume = {"3"},
number = {"3"},
pages = {"183 - 188"},
year = {"2014"},
note = {"Cognition and Education "},
issn = {"2211-3681"},
doi = {"https://doi.org/10.1016/j.jarmac.2014.05.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211368114000503"},
author = {"Sean H.K. Kang and Harold Pashler"},
keywords = {"Retrieval practice", "Testing effects", "Motivation "},
abstract = {"Abstract Retrieval practice tends to produce better long-term learning than rereading, but laboratory studies have typically used arbitrary material that subjects may not care to learn. The observed advantage of retrieval practice may be exaggerated because low motivation may result in deficient processing during (usually passive) rereading. Thus, when subjects are motivated to learn the material, the type of study strategy (whether retrieval practice or rereading) might be less important. To test this hypothesis, we conducted 3 experiments in which we manipulated the incentives (using monetary bonuses or time savings) for learning Swahili–English word pairs. Items that had undergone retrieval practice were better recalled than reread items on a final test 2 days later, but this effect did not interact with incentive level. These results provide some reassurance that lab findings from the testing effects literature likely generalize to real-world situations in which motivation to learn may be greater. "} 
}
@article{Yi2014540,
title = {"Considering polarization in MODIS-based cloud property retrievals by using a vector radiative transfer code "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"146"},
number = {""},
pages = {"540 - 548"},
year = {"2014"},
note = {"Electromagnetic and Light Scattering by Nonspherical Particles \{XIV\} "},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2014.05.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407314002295"},
author = {"Bingqi Yi and Xin Huang and Ping Yang and Bryan A. Baum and George W. Kattawar"},
keywords = {"Polarization", "Cloud property retrieval", "MODIS", "Satellite observation", "Vector radiative transfer model "},
abstract = {"Abstract In this study, a full-vector, adding–doubling radiative transfer model is used to investigate the influence of the polarization state on cloud property retrievals from Moderate Resolution Imaging Spectroradiometer (MODIS) satellite observations. Two sets of lookup tables (LUTs) are developed for the retrieval purposes, both of which provide water cloud and ice cloud reflectivity functions at two wavelengths in various sun-satellite viewing geometries. However, only one of the \{LUTs\} considers polarization. The \{MODIS\} reflectivity observations at 0.65 μm (band 1) and 2.13 μm (band 7) are used to infer the cloud optical thickness and particle effective diameter, respectively. Results indicate that the retrievals for both water cloud and ice cloud show considerable sensitivity to polarization. The retrieved water and ice cloud effective diameter and optical thickness differences can vary by as much as ±15% due to polarization state considerations. In particular, the polarization state has more influence on completely smooth ice particles than on severely roughened ice particles. "} 
}
@article{Nouri2014699,
title = {"Severe haematoperitoneum caused by ovarian bleeding after transvaginal oocyte retrieval: A retrospective analysis and systematic literature review "},
journal = {"Reproductive BioMedicine Online "},
volume = {"29"},
number = {"6"},
pages = {"699 - 707"},
year = {"2014"},
note = {""},
issn = {"1472-6483"},
doi = {"https://doi.org/10.1016/j.rbmo.2014.08.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1472648314004842"},
author = {"Kazem Nouri and Katharina Walch and Regina Promberger and Christine Kurz and Clemens B Tempfer and Johannes Ott"},
keywords = {"bleeding", "hematoperitoneum", "in-vitro fertilization", "oocyte retrieval", "topical hemostatic agents "},
abstract = {"Abstract A case series of haematoperitoneum caused by ovarian bleeding after transvaginal oocyte retrieval (TVOR) is presented and all published cases summarized. In a retrospective case series, four patients with ovarian bleeding after \{TVOR\} were included. In addition, a pooled analysis of all published cases (n = 32) who underwent surgical intervention for severe haematoperitoneum caused by ovarian bleeding after \{TVOR\} was carried out. Main outcome measures were incidence, risk factors, course and intraoperative findings. In the pooled analysis, the incidence was 0.08%. The first sign of haematoperitoneum was evident in 33.3% within the first postoperative hour, and, cumulatively, in 93.3% within 24 h. The median time between \{TVOR\} and surgical intervention was 10 h. In four patients, the ovary could not be preserved, which was associated with a longer time interval between \{TVOR\} and the onset of symptoms (median 18 h versus 2.5 h; P = 0.004) as well as between \{TVOR\} and surgical intervention (median 21.5 h versus 8.5 h; 0.004). In conclusion, severe haematoperitoneum occurs in 0.08% after TVOR. Late-onset bleeding is common. A longer time interval between \{TVOR\} and surgical intervention might put a patient at risk of ovariectomy. "} 
}
@article{Miernecki201489,
title = {"Comparison of \{SMOS\} and \{SMAP\} soil moisture retrieval approaches using tower-based radiometer data over a vineyard field "},
journal = {"Remote Sensing of Environment "},
volume = {"154"},
number = {""},
pages = {"89 - 101"},
year = {"2014"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2014.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425714002983"},
author = {"Maciej Miernecki and Jean-Pierre Wigneron and Ernesto Lopez-Baeza and Yann Kerr and Richard De Jeu and Gabrielle J.M. De Lannoy and Thomas J. Jackson and Peggy E. O'Neill and Mike Schwank and Roberto Fernandez Moran and Simone Bircher and Heather Lawrence and Arnaud Mialon and Ahmad Al Bitar and Philippe Richaume"},
keywords = {"SMOS", "SMAP", "Soil moisture retrieval", "ELBARA", "Valencia Anchor Station "},
abstract = {"Abstract The objective of this study was to compare several approaches to soil moisture (SM) retrieval using l-band microwave radiometry. The comparison was based on a brightness temperature (TB) data set acquired since 2010 by the L-band radiometer ELBARA-II over a vineyard field at the Valencia Anchor Station (VAS) site. ELBARA-II, provided by the European Space Agency (ESA) within the scientific program of the \{SMOS\} (Soil Moisture and Ocean Salinity) mission, measures multiangular \{TB\} data at horizontal and vertical polarization for a range of incidence angles (30°–60°). Based on a three year data set (2010–2012), several \{SM\} retrieval approaches developed for spaceborne missions including AMSR-E (Advanced Microwave Scanning Radiometer for EOS), \{SMAP\} (Soil Moisture Active Passive) and \{SMOS\} were compared. The approaches include: the Single Channel Algorithm (SCA) for horizontal (SCA-H) and vertical (SCA-V) polarizations, the Dual Channel Algorithm (DCA), the Land Parameter Retrieval Model (LPRM) and two simplified approaches based on statistical regressions (referred to as ‘Mattar’ and ‘Saleh’). Time series of vegetation indices required for three of the algorithms (SCA-H, SCA-V and ‘Mattar’) were obtained from \{MODIS\} observations. The \{SM\} retrievals were evaluated against reference \{SM\} values estimated from a multiangular 2-Parameter inversion approach. As no in situ \{SM\} data was used, the evaluation made here is relative to the use of this specific reference data set. The results obtained with the current base line algorithms developed for \{SMAP\} (SCA-H and -V) are in very good agreement with the ‘reference’ \{SM\} data set derived from the multi-angular observations (R2 ≈ 0.90, \{RMSE\} varying between 0.035 and 0.056 m3/m3 for several retrieval configurations). This result showed that, provided the relationship between vegetation optical depth and a remotely-sensed vegetation index can be calibrated, the \{SCA\} algorithms can provide results very close to those obtained from multi-angular observations in this study area. The approaches based on statistical regressions provided similar results and the best accuracy was obtained with the ‘Saleh’ methods based on either bi-angular or bipolarization observations (R2 ≈ 0.93, \{RMSE\} ≈ 0.035 m3/m3). The \{LPRM\} and \{DCA\} algorithms were found to be slightly less successful in retrieving the ‘reference’ \{SM\} time series (R2 ≈ 0.75, \{RMSE\} ≈ 0.055 m3/m3). However, the two above approaches have the great advantage of not requiring any model calibrations previous to the \{SM\} retrievals. "} 
}
@article{Wang2014531,
title = {"Phase retrieval for sparse signals "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"37"},
number = {"3"},
pages = {"531 - 544"},
year = {"2014"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2014.04.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520314000517"},
author = {"Yang Wang and Zhiqiang Xu"},
keywords = {"Signal recovery", "Phase retrieval", "Compressed sensing", "Null space property "},
abstract = {"Abstract The aim of this paper is to build up the theoretical framework for the recovery of sparse signals from the magnitude of the measurements. We first investigate the minimal number of measurements for the success of the recovery of sparse signals from the magnitude of samples. We completely settle the minimality question for the real case and give a bound for the complex case. We then study the recovery performance of the ℓ 1 minimization for the sparse phase retrieval problem. In particular, we present the null space property which, to our knowledge, is the first sufficient and necessary condition for the success of ℓ 1 minimization for k-sparse phase retrieval. "} 
}
@article{Shangguan201410,
title = {"Content-based image retrieval approaches to interpret ground penetrating radar data "},
journal = {"Construction and Building Materials "},
volume = {"69"},
number = {""},
pages = {"10 - 17"},
year = {"2014"},
note = {""},
issn = {"0950-0618"},
doi = {"https://doi.org/10.1016/j.conbuildmat.2014.06.060"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950061814006795"},
author = {"Pengcheng Shangguan and Imad L. Al-Qadi"},
keywords = {"Ground penetrating radar", "GPR", "Railroad ballast", "Ballast fouling", "Texture retrieval "},
abstract = {"Abstract This paper presents a new data processing algorithm to interpret ground penetrating radar (GPR) data for quantification of railroad ballast fouling conditions. The algorithm is based on the observation that different fouling levels generate different textures in the \{GPR\} images. The algorithm was designed following the content-based image retrieval procedure, which includes two steps: feature extraction and similarity measurement. First, texture feature was extracted using discrete wavelet transform. Second, similarity measurement was performed. Laboratory \{GPR\} data were used to evaluate the accuracy of the algorithm. The accuracy was 93%, which demonstrated the effectiveness of the algorithm. "} 
}
@article{Wang201467,
title = {"Optical image encryption via reverse engineering of a modified amplitude-phase retrieval-based attack "},
journal = {"Optics Communications "},
volume = {"328"},
number = {""},
pages = {"67 - 72"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.04.059"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814004027"},
author = {"Xiaogang Wang and Chaoqing Dai and Junlang Chen"},
keywords = {"Optical encryption", "Amplitude-phase retrieval", "Phase truncation", "Attack "},
abstract = {"Abstract By reverse-engineering the modified amplitude-phase retrieval-based attack that has deciphered the phase-truncated double random phase encoding scheme, we proposed a new cryptosystem to encode a target image into a preselected fake image using a modified phase retrieval algorithm under the framework of phase-truncated double random phase encoding. With two private keys that are generated during the encryption, the decryption can be optically realized using a classical linear double random phase encoding method. The proposed cryptosystem has immunity against the recently proposed specific attack and the new attack based on a modified amplitude-phase retrieval algorithm. Numerical results are presented to demonstrate the validity and good performance of our proposed algorithm. "} 
}
@article{Liu2014895,
title = {"An Unconditioned Stimulus Retrieval Extinction Procedure to Prevent the Return of Fear Memory "},
journal = {"Biological Psychiatry "},
volume = {"76"},
number = {"11"},
pages = {"895 - 901"},
year = {"2014"},
note = {"Anxiety Disorders "},
issn = {"0006-3223"},
doi = {"https://doi.org/10.1016/j.biopsych.2014.03.027"},
url = {"http://www.sciencedirect.com/science/article/pii/S000632231400239X"},
author = {"Jianfeng Liu and Liyan Zhao and Yanxue Xue and Jie Shi and Lin Suo and Yixiao Luo and Baisheng Chai and Chang Yang and Qin Fang and Yan Zhang and Yanping Bao and Charles L. Pickens and Lin Lu"},
keywords = {"Extinction", "fear memory", "hippocampus", "reconsolidation", "retrieval", "unconditioned stimulus "},
abstract = {"Background Conditioned fear memories can be updated by extinction during reconsolidation, and this effect is specific to the reactivated conditioned stimulus (CS). However, a traumatic event can be associated with several cues, and each cue can potentially trigger recollection of the event. We introduced a technique to target all diverse cues associated with an aversive event that causes fear. Methods In human experiments, 161 subjects underwent modified fear conditioning, in which they were exposed to an unconditioned stimulus (US) or unreinforced \{CS\} to reactivate the memory and then underwent extinction, spontaneous recovery, and reinstatement. In animal experiments, 343 rats underwent contextual fear conditioning under a similar protocol as that used in the human experiments. We also explored the molecular alterations after \{US\} reactivation in rats. Results Presentation of a lower intensity \{US\} before extinction disrupted the associations between the different \{CS\} and reactivated \{US\} in both humans and rats. This effect persisted for at least 6 months in humans and was selective to the reactivated US. This procedure was also effective for remote memories in both humans and rats. Compared with the CS, the \{US\} induced stronger endocytosis of alpha-amino-3-hydroxy-5-methyl-4-isoxazole propionic acid glutamate receptors 1 and 2 and stronger activation of protein kinase A, p70S6 kinase, and cyclic adenosine monophosphate response element binding protein in the dorsal hippocampus in rats. Conclusions These findings demonstrate that a modified \{US\} retrieval extinction strategy may have a potential impact on therapeutic approaches to prevent the return of fear. "} 
}
@article{Blanco2015148,
title = {"IntoNews: Online news retrieval using closed captions "},
journal = {"Information Processing & Management "},
volume = {"51"},
number = {"1"},
pages = {"148 - 162"},
year = {"2015"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2014.07.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457314000703"},
author = {"Roi Blanco and Gianmarco De Francisci Morales and Fabrizio Silvestri"},
keywords = {"Second screen", "News retrieval", "Continuous retrieval", "IntoNow", "IntoNews "},
abstract = {"Abstract We present IntoNews, a system to match online news articles with spoken news from a television newscasts represented by closed captions. We formalize the news matching problem as two independent tasks: closed captions segmentation and news retrieval. The system segments closed captions by using a windowing scheme: sliding or tumbling window. Next, it uses each segment to build a query by extracting representative terms. The query is used to retrieve previously indexed news articles from a search engine. To detect when a new article should be surfaced, the system compares the set of retrieved articles with the previously retrieved one. The intuition is that if the difference between these sets is large enough, it is likely that the topic of the newscast currently on air has changed and a new article should be displayed to the user. In order to evaluate IntoNews, we build a test collection using data coming from a second screen application and a major online news aggregator. The dataset is manually segmented and annotated by expert assessors, and used as our ground truth. It is freely available for download through the Webscope program.1 http://webscope.sandbox.yahoo.com. 1 Our evaluation is based on a set of novel time-relevance metrics that take into account three different aspects of the problem at hand: precision, timeliness and coverage. We compare our algorithms against the best method previously proposed in literature for this problem. Experiments show the trade-offs involved among precision, timeliness and coverage of the airing news. Our best method is four times more accurate than the baseline. "} 
}
@article{Demeter2014153,
title = {"Obsessed not to forget: Lack of retrieval-induced suppression effect in obsessive-compulsive disorder "},
journal = {"Psychiatry Research "},
volume = {"218"},
number = {"1–2"},
pages = {"153 - 160"},
year = {"2014"},
note = {""},
issn = {"0165-1781"},
doi = {"https://doi.org/10.1016/j.psychres.2014.04.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S016517811400300X"},
author = {"Gyula Demeter and Attila Keresztes and András Harsányi and Katalin Csigó and Mihály Racsmány"},
keywords = {"Memory", "Retrieval-induced forgetting", "Executive function", "Cognitive control", "Inhibition", "Interference", "OCD "},
abstract = {"Abstract The aim of the present study was to investigate the role of executive functions in resolving memory interference in a clinical sample of patients with obsessive-compulsive disorder (OCD). Retrieval of memories has been shown to involve some form of executive act that diminishes the accessibility of rival memory traces, leading to retrieval-induced forgetting (RIF). These executive control processes might suppress unwanted thoughts and irrelevant memories during competitive retrieval. We assessed \{RIF\} with the retrieval practice paradigm among 25 \{OCD\} patients and 25 healthy controls matched for age and education. Retrieval of target memories led to enhancement of target memory recall in both groups, but suppression of related memories (RIF) occurred only among controls. Our results suggest that suppression of irrelevant, interfering memories during competitive recall is impaired in OCD. "} 
}
@article{Walia20141335,
title = {"Fusion framework for effective color image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"6"},
pages = {"1335 - 1348"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314000844"},
author = {"Ekta Walia and Aman Pal"},
keywords = {"Content based image retrieval", "Lab color space", "Color Difference Histogram", "Angular Radial Transform", "Borda Count", "Min–max normalization", "Z-score normalization", "Fusion "},
abstract = {"Abstract This paper presents a novel framework for color image retrieval through combination of all the low level features, which gives higher retrieval accuracy. The Color Difference Histogram (CDH) and Angular Radial Transform (ART) features are exploited to capture color, texture and shape information of an image. The \{CDH\} algorithm is modified in order to make the proposed system more effective. The proposed fusion framework combines the ranking results of the aforementioned descriptors through various post-classification methods i.e. Borda Count method, Min–max and Z-score normalization. The maximum retrieval accuracy attained in terms of average precision using Min–max normalization on Wang’s database is 78.3% when \{ART\} is applied on non-overlapping regions of the images. The proposed fusion framework is recommended because it improves the average retrieval accuracy by approximately 16% and 14% over \{CDH\} and \{ART\} respectively. Extensive experiments are carried out on different databases to establish the efficacy of the proposed scheme. "} 
}
@article{Kurtz20141082,
title = {"On combining image-based and ontological semantic dissimilarities for medical image retrieval applications "},
journal = {"Medical Image Analysis "},
volume = {"18"},
number = {"7"},
pages = {"1082 - 1100"},
year = {"2014"},
note = {""},
issn = {"1361-8415"},
doi = {"https://doi.org/10.1016/j.media.2014.06.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S1361841514001030"},
author = {"Camille Kurtz and Adrien Depeursinge and Sandy Napel and Christopher F. Beaulieu and Daniel L. Rubin"},
keywords = {"Image retrieval", "Riesz wavelets", "Image annotation", "Semantic dissimilarities", "Computed tomographic (CT) images "},
abstract = {"Abstract Computer-assisted image retrieval applications can assist radiologists by identifying similar images in archives as a means to providing decision support. In the classical case, images are described using low-level features extracted from their contents, and an appropriate distance is used to find the best matches in the feature space. However, using low-level image features to fully capture the visual appearance of diseases is challenging and the semantic gap between these features and the high-level visual concepts in radiology may impair the system performance. To deal with this issue, the use of semantic terms to provide high-level descriptions of radiological image contents has recently been advocated. Nevertheless, most of the existing semantic image retrieval strategies are limited by two factors: they require manual annotation of the images using semantic terms and they ignore the intrinsic visual and semantic relationships between these annotations during the comparison of the images. Based on these considerations, we propose an image retrieval framework based on semantic features that relies on two main strategies: (1) automatic “soft” prediction of ontological terms that describe the image contents from multi-scale Riesz wavelets and (2) retrieval of similar images by evaluating the similarity between their annotations using a new term dissimilarity measure, which takes into account both image-based and ontological term relations. The combination of these strategies provides a means of accurately retrieving similar images in databases based on image annotations and can be considered as a potential solution to the semantic gap problem. We validated this approach in the context of the retrieval of liver lesions from computed tomographic (CT) images and annotated with semantic terms of the RadLex ontology. The relevance of the retrieval results was assessed using two protocols: evaluation relative to a dissimilarity reference standard defined for pairs of images on a 25-images dataset, and evaluation relative to the diagnoses of the retrieved images on a 72-images dataset. A normalized discounted cumulative gain (NDCG) score of more than 0.92 was obtained with the first protocol, while \{AUC\} scores of more than 0.77 were obtained with the second protocol. This automatical approach could provide real-time decision support to radiologists by showing them similar images with associated diagnoses and, where available, responses to therapies. "} 
}
@article{Guo20172,
title = {"A review of iterative phase retrieval for measurement and encryption "},
journal = {"Optics and Lasers in Engineering "},
volume = {"89"},
number = {""},
pages = {"2 - 12"},
year = {"2017"},
note = {"3DIM-DS 2015: Optical Image Processing in the context of 3D Imaging, Metrology, and Data Security "},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.03.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616300197"},
author = {"Cheng Guo and Ce Wei and Jiubin Tan and Kana Chen and Shutian Liu and Qun Wu and Zhengjun Liu"},
keywords = {"Inverse problem", "Phase measurement", "Security "},
abstract = {"Abstract Phase retrieval technique is regarded as one of the most significant tools to solve optical inverse problems. Several phase retrieval algorithms are discussed in this review. The occurrence of ill-posed conditions often makes the calculation difficult. As a synthesis, the multiple-image phase retrieval technology is invented to obtain more accurate convergence result in iterative computation. The multiple-input retrieval scheme can attach new constraints on convergence as a new limitation. As an indirect measuring method, it will make it possible to reconstruct the distribution of intensity and phase in an imaging or measurement system, where data processing is executed by computer. Moreover, the retrieval method has been applied for image encryption successfully. Finally, the development and application of the iterative phase retrieval are overviewed. "} 
}
@article{Chou201632,
title = {"Integrating \{XBRL\} data with textual information in Chinese: A semantic web approach "},
journal = {"International Journal of Accounting Information Systems "},
volume = {"21"},
number = {""},
pages = {"32 - 46"},
year = {"2016"},
note = {""},
issn = {"1467-0895"},
doi = {"https://doi.org/10.1016/j.accinf.2016.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S146708951630032X"},
author = {"Chi-Chun Chou and C. Janie Chang and Jacob Peng"},
keywords = {"Text analytics", "Business information retrieval", "Integration of financial and non-financial information", "XBRL "},
abstract = {"Abstract Due to formatting differences, the difficulties of processing the textual disclosures and integrating them with quantitative financial data are well documented in the literature. Using a design science methodology, this paper describes a method that automatically extracts relevant textual data from annual reports published in Chinese. These extracted words are then mapped to a knowledge framework we proposed. This paper shows that it is technologically feasible to reorganize the MD&amp;A contents into any given knowledge structure to improve the search capability, readability, and cohesiveness of the MD&amp;A contents. Finally, we demonstrate a prototype system that uses semantic web technology to achieve information integration that presents \{XBRL\} formatted accounting data with relevant textual disclosures together to assist user decision making. "} 
}
@article{Shamsi2017,
title = {"Columnar-Organized Memory (COM): Brain-inspired associative memory with large capacity and robust retrieval "},
journal = {"Biologically Inspired Cognitive Architectures "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2212-683X"},
doi = {"https://doi.org/10.1016/j.bica.2017.02.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212683X16301037"},
author = {"Jafar Shamsi and Karim Mohammadi and Shahriar B. Shokouhi"},
keywords = {"Mini-columns", "Macro-columns", "Winner take all", "Associative memory", "Columnar organized memory "},
abstract = {"Abstract Brain-inspired computing is an interdisciplinary field, which aims to use the capabilities of the human brain. The brain is remarkable for large memory capacity and robust memory retrieval. These characteristics are due to the specific structure of the brain. In this paper, an associative memory with large capacity and robust retrieval is introduced that is inspired by the cortical structure. The proposed model is called Columnar-Organized Memory (COM). Its architecture is based on the spiking winner-take-all (WTA): There are lateral excitatory connections between the \{WTAs\} and lateral inhibitory connections between the neurons of a WTA. Training of \{COM\} involves a two-phase algorithm: pattern storage phase and pattern association phase. The pattern storage phase is based on a spike timing dependent plasticity (STDP) rule and the pattern association phase is compatible with the classic Hebbian rule. The key characteristics of the proposed model are storing a large number of messages and retrieving them accurately. These properties are related to its structure notably; robust retrieval is a consequence of the lateral excitatory connections. Also, the overall effect of the lateral inhibitory connections is large storage capacity. "} 
}
@article{Sudhakar2014492,
title = {"An effective biomedical image retrieval framework in a fuzzy feature space employing Phase Congruency and GeoSOM "},
journal = {"Applied Soft Computing "},
volume = {"22"},
number = {""},
pages = {"492 - 503"},
year = {"2014"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2014.04.029"},
url = {"http://www.sciencedirect.com/science/article/pii/S156849461400194X"},
author = {"M.S. Sudhakar and K. Bhoopathy Bagan"},
keywords = {"L*a*b* color space", "Phase Congruency", "SIFT transform", "GeoSOM", "Fuzzy logic", "Image retrieval "},
abstract = {"Abstract This paper presents a detailed study about a biomedical image retrieval framework by extracting Phase Congruency (PC) features from L*a*b* triplets of images (query, target) and representing them in fuzzy feature space. These features correspond to an edge-corner map of the given image. The resulting map is then processed by Scale Invariant Feature Transform (SIFT) to derive keypoints, that are invariant to affine transformations. The ensuing features were vector quantized to build a codebook of keypoints. The codebook was produced using a Spherical Self-Organizing Map (SOM) built with a geodesic data structure termed as GeoSOM. Then keypoints of the query image are mapped with the codebook and their occurrences are counted to formulate a histogram termed as Phase Congruency-based Bag of Keypoints (PC-BoK). This histogram is generated offline for target images and a similarity measure was performed with the query image to yield the nearest match based on a global fuzzy membership function. Exhaustive experiments of the proposed framework named as \{BIRS\} (Biomedical Image Retrieval System) were performed on a diverse medical image collection (NBIA, MESSIDOR, DRIVE). Finally, performance of \{BIRS\} demonstrates the advantage of the proposed image representation approach in terms of Precision (P)–Recall (R) parameters. Furthermore relative comparison of the proposed scheme with existing feature descriptors depicts improved P–R values. The proposed feature extraction and representation scheme was also robust against quantization errors. "} 
}
@article{Ciaramelli2017,
title = {"Subjective recollection independent from multifeatural context retrieval following damage to the posterior parietal cortex "},
journal = {"Cortex "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2017.03.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945217300953"},
author = {"Elisa Ciaramelli and Giorgia Faggi and Cristina Scarpazza and Flavia Mattioli and Julia Spaniol and Simona Ghetti and Morris Moscovitch"},
keywords = {"Source memory", "Remember/know judgments", "Feature integration", "Metamemory "},
abstract = {"Abstract This study investigated whether damage to the posterior parietal cortex (PPC) impairs the capacity to retrieve multiple aspects of the encoding context in which items were studied, or whether it impairs the subjective awareness of recollection. Patients with lesions to the \{PPC\} (PPC patients) and healthy controls memorized words along with the position in which the words were presented on the screen and the ink color in which they were printed. We studied \{PPC\} patients' recognition and source memory performance, as well as subjective recollection as indexed by Remember/Know judgments. \{PPC\} patients had preserved recognition memory, and gave a similar number of R responses as did controls. Moreover, \{PPC\} patients' source memory performance, including memory for multiple contextual features, was similar to the controls'. However, whereas healthy controls were more likely to select R responses with correct multifeatural source judgments compared to K responses, \{PPC\} patients were not. These findings indicate that the \{PPC\} plays a role in the subjective experience and metamnemonic evaluation of memory contents. "} 
}
@article{Zand2015305,
title = {"Texture classification and discrimination for region-based image retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"26"},
number = {""},
pages = {"305 - 316"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.10.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314001643"},
author = {"Mohsen Zand and Shyamala Doraisamy and Alfian Abdul Halin and Mas Rina Mustaffa"},
keywords = {"Region-based image retrieval", "Texture feature extraction", "Texture classification", "Gabor wavelet", "Curvelet filters", "Polynomials", "ImageCLEF", "Outex "},
abstract = {"Abstract In RBIR, texture features are crucial in determining the class a region belongs to since they can overcome the limitations of color and shape features. Two robust approaches to model texture features are Gabor and curvelet features. Although both features are close to human visual perception, sufficient information needs to be extracted from their sub-bands for effective texture classification. Moreover, shape irregularity can be a problem since Gabor and curvelet transforms can only be applied on the regular shapes. In this paper, we propose an approach that uses both the Gabor wavelet and the curvelet transforms on the transferred regular shapes of the image regions. We also apply a fitting method to encode the sub-bands’ information in the polynomial coefficients to create a texture feature vector with the maximum power of discrimination. Experiments on texture classification task with ImageCLEF and Outex databases demonstrate the effectiveness of the proposed approach. "} 
}
@article{Giannouli2016S412,
title = {"Depressive symptomatology and learning: Does intermediate testing or restudying the information determine long-term memory retrieval of novel symbols? "},
journal = {"European Psychiatry "},
volume = {"33, Supplement"},
number = {""},
pages = {"S412 - "},
year = {"2016"},
note = {"Abstracts of the 24rd European Congress of Psychiatry "},
issn = {"0924-9338"},
doi = {"https://doi.org/10.1016/j.eurpsy.2016.01.1486"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924933816014905"},
author = {"V. Giannouli"},

abstract = {"Introduction There is a hypothesis in cognitive psychology that long-term memory retrieval is improved by intermediate testing than by restudying the information. The effect of testing has been investigated with the use of a variety of stimuli. However, almost all testing effect studies to date have used purely verbal materials such as word pairs, facts and prose passages. Objective Here byzantine music symbol–word pairs were used as to-be-learned materials to demonstrate the generalisability of the testing effect to symbol learning in participants with and without depressive symptoms. Method Fifty healthy (24 women, M age = 26.20, \{SD\} = 5.64) and forty volunteers with high depressive symptomatology (20 women, M age = 27.00, \{SD\} = 1.04) were examined. The participants did not have a music education. The examination material was completely new for them: 16 byzantine music notation stimuli, paired with a verbal label (the ancient Greek name of the symbol). Half of the participants underwent intermediate testing and the others restudied the information in a balanced design. Results Results indicated that there were no statistically significant differences in final memory test performance after a retention interval of 5 minutes for both groups of participants with low and high level depressive symptomatology (P &gt; 0.005). After a retention interval of a week, tested pairs were retained better than repeatedly studied pairs for high and low depressive symptomatology groups (P &lt; 0.005). Conclusions This research suggests that the effect of testing time on later memory retrieval can also be obtained in byzantine symbol learning. "} 
}
@article{Yang20141308,
title = {"Content-based image retrieval using local visual attention feature "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"6"},
pages = {"1308 - 1323"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.05.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314000820"},
author = {"Hong-Ying Yang and Yong-Wei Li and Wei-Yi Li and Xiang-Yang Wang and Fang-Yu Yang"},
keywords = {"Image retrieval", "Salient point", "SURF", "Visually significant image point", "Weighted color histogram", "Spatial distribution entropy", "Color complexity measure", "Similarity "},
abstract = {"Abstract Content-based image retrieval (CBIR) has been an active research topic in the last decade. As one of the promising approaches, salient point based image retrieval has attracted many researchers. However, the related work is usually very time consuming, and some salient points always may not represent the most interesting subset of points for image indexing. Based on fast and performant salient point detector, and the salient point expansion, a novel content-based image retrieval using local visual attention feature is proposed in this paper. Firstly, the salient image points are extracted by using the fast and performant \{SURF\} (Speeded-Up Robust Features) detector. Then, the visually significant image points around salient points can be obtained according to the salient point expansion. Finally, the local visual attention feature of visually significant image points, including the weighted color histogram and spatial distribution entropy, are extracted, and the similarity between color images is computed by using the local visual attention feature. Experimental results, including comparisons with the state-of-the-art retrieval systems, demonstrate the effectiveness of our proposal. "} 
}
@article{Seifert201469,
title = {"Spectrographic phase-retrieval algorithm for femtosecond and attosecond pulses with frequency gaps "},
journal = {"Optics Communications "},
volume = {"329"},
number = {""},
pages = {"69 - 75"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.05.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814004362"},
author = {"B. Seifert and S. Wallentowitz and U. Volkmann and A. Hause and K. Sperlich and H. Stolz"},
keywords = {"Ultrafast processes", "Phase retrieval", "Numerical optimization "},
abstract = {"Abstract We present a phase-reconstruction algorithm for a self-referenced spectrographic pulse characterization technique called “very advanced method for phase and intensity retrieval of e-fields” (VAMPIRE). This technique permits a spectral phase reconstruction of pulses with separated frequency components. The algorithm uses the particular characteristics of \{VAMPIRE\} spectrograms. It is a locally structured algorithm which is fast, robust, and it allows us to master stagnation problems. The algorithm is tested by use of both simulated and measured data. "} 
}
@article{Kocsis201446,
title = {"Case-Based Reasoning system for mathematical modelling options and resolution methods for production scheduling problems: Case representation, acquisition and retrieval "},
journal = {"Computers & Industrial Engineering "},
volume = {"77"},
number = {""},
pages = {"46 - 64"},
year = {"2014"},
note = {""},
issn = {"0360-8352"},
doi = {"https://doi.org/10.1016/j.cie.2014.09.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360835214002794"},
author = {"Tibor Kocsis and Stéphane Negny and Pascal Floquet and Xuân Meyer and Endre Rév"},
keywords = {"Decision-support system", "Process scheduling", "Case Based Reasoning", "Classification and notation system", "Case retrieval "},
abstract = {"Abstract Thanks to a wide and dynamic research community on short term production scheduling, a large number of modelling options and solving methods have been developed in the recent years both in chemical production and manufacturing domains. This trend is expected to grow in the future as the number of publications is constantly increasing because of industrial interest in the current economic context. The frame of this work is the development of a decision-support system to work out an assignment strategy between scheduling problems, mathematical modelling options and appropriate solving methods. The system must answer the question about which model and which solution method should be applied to solve a new scheduling problem in the most convenient way. The decision-support system is to be built on the foundations of Case Based Reasoning (CBR). \{CBR\} is based on a data base which encompasses previously successful experiences. The three major contributions of this paper are: (i) the proposition of an extended and a more exhaustive classification and notation scheme in order to obtain an efficient scheduling case representation (based on previous ones), (ii) a method for bibliographic analysis used to perform a deep study to fill the case base on the one hand, and to examine the topics the more or the less examined in the scheduling domain and their evolution over time on the other hand, and (iii) the proposition of criteria to extract relevant past experiences during the retrieval step of the CBR. The capabilities of our decision support system are illustrated through a case study with typical constraints related to process engineering production in beer industry. "} 
}
@article{Chiang2014106,
title = {"Age-related changes in feature-based object memory retrieval as measured by event-related potentials "},
journal = {"Biological Psychology "},
volume = {"100"},
number = {""},
pages = {"106 - 114"},
year = {"2014"},
note = {""},
issn = {"0301-0511"},
doi = {"https://doi.org/10.1016/j.biopsycho.2014.05.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0301051114001094"},
author = {"Hsueh-Sheng Chiang and Raksha A. Mudar and Jeffrey S. Spence and Athula Pudhiyidath and Justin Eroh and Bambi DeLaRosa and Michael A. Kraut and John Hart Jr."},
keywords = {"Semantic", "Object memory", "Memory retrieval", "Feature", "ERP", "Aging "},
abstract = {"Abstract To investigate neural mechanisms that support semantic functions in aging, we recorded scalp \{EEG\} during an object retrieval task in 22 younger and 22 older adults. The task required determining if a particular object could be retrieved when two visual words representing object features were presented. Both age groups had comparable accuracy although response times were longer in older adults. In both groups a left fronto-temporal negative potential occurred at around 750 ms during object retrieval, consistent with previous findings (Brier, Maguire, Tillman, Hart, &amp; Kraut, 2008). In only older adults, a later positive frontal potential was found peaking between 800 and 1000 ms during no retrieval. These findings suggest younger and older adults employ comparable neural mechanisms when features clearly facilitate retrieval of an object memory, but when features yield no retrieval, older adults use additional neural resources to engage in a more effortful and exhaustive search prior to making a decision. "} 
}
@article{Tillman201766,
title = {"Electrophysiological correlates of semantic memory retrieval in Gulf War Syndrome 2 patients "},
journal = {"Journal of the Neurological Sciences "},
volume = {"373"},
number = {""},
pages = {"66 - 72"},
year = {"2017"},
note = {""},
issn = {"0022-510X"},
doi = {"https://doi.org/10.1016/j.jns.2016.12.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022510X16308164"},
author = {"Gail D. Tillman and Clifford S. Calley and Virginia I. Buhl and Hsueh-Sheng Chiang and Robert W. Haley and John Hart Jr and Michael A. Kraut"},
keywords = {"Word-finding", "Gulf War illness", "Semantic memory", "EEG", "ERP", "Cholinergic "},
abstract = {"Abstract Gulf War veterans meeting criteria for Haley Syndrome 2 of Gulf War illness endorse a particular constellation of symptoms that include difficulty with processing information, word-finding, and confusion. To explore the neural basis of their word-finding difficulty, we assessed event-related potentials (ERPs) associated with semantic memory retrieval in 22 veterans classified as Syndrome 2 and 28 veterans who served as controls. We recorded \{EEGs\} while subjects judged whether pairs of words that represented object features combined to elicit a retrieval of an object memory or no retrieval. Syndrome 2 subjects' responses were significantly slower, and those participants were less accurate than controls on the retrieval trials, but they performed similarly on the nonretrieval trials. Analysis of the \{ERPs\} revealed a difference between retrievals and nonretrievals that has previously been detected around 750 ms at the left temporal region was present in both the Syndrome 2 patients and controls. However, the Syndrome 2 patients also showed an \{ERP\} difference between retrievals and nonretrievals at the midline parietal region that had a scalp voltage polarity opposite from that recorded at the left temporal area. We hypothesize that the similarities between task performance and \{ERP\} patterns in Syndrome 2 veterans and in patients with amnestic mild cognitive impairment reflect disordered thalamic cholinergic neural activity, possibly in the dorsomedial nucleus. "} 
}
@article{Jaming2014413,
title = {"Uniqueness results in an extension of Pauli's phase retrieval problem "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"37"},
number = {"3"},
pages = {"413 - 441"},
year = {"2014"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2014.01.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520314000189"},
author = {"Philippe Jaming"},
keywords = {"Phase retrieval", "Pauli problem", "Fractional Fourier transform", "Entire function of finite order "},
abstract = {"Abstract In this paper, we investigate an extension of Pauli's phase retrieval problem. The original problem asks whether a function u is uniquely determined by its modulus | u | and the modulus of its Fourier transform | F u | up to a constant phase factor. Here we extend this problem by considering the uniqueness of the phase retrieval problem for the fractional Fourier transform (FrFT) of variable order. This problem occurs naturally in optics and quantum physics. More precisely, we show that if u and v are such that fractional Fourier transforms of order α have same modulus | F α u | = | F α v | for some set τ of α's, then v is equal to u up to a constant phase factor. The set τ depends on some extra assumptions either on u or on both u and v. Cases considered here are u, v of compact support, pulse trains, Hermite functions or linear combinations of translates and dilates of Gaussians. In this last case, the set τ may even be reduced to a single point (i.e. one fractional Fourier transform may suffice for uniqueness in the problem). "} 
}
@article{VanderAuwera2014177,
title = {"Self-broadening coefficients and improved line intensities for the ν7 band of ethylene near , and impact on ethylene retrievals from Jungfraujoch solar spectra "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"148"},
number = {""},
pages = {"177 - 185"},
year = {"2014"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2014.07.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407314002878"},
author = {"J. Vander Auwera and A. Fayt and M. Tudorie and M. Rotger and V. Boudon and B. Franco and E. Mahieu"},
keywords = {"Ethylene", "High-resolution infrared absorption spectroscopy", "Line intensities", "Self-broadening coefficients", "Atmospheric retrievals "},
abstract = {"Abstract Relying on high-resolution Fourier transform infrared (FTIR) spectra, the present work involved extensive measurements of individual line intensities and self-broadening coefficients for the ν7 band of 12C2H4. The measured self-broadening coefficients exhibit a dependence on both J and Ka. Compared to the corresponding information available in the latest edition of the \{HITRAN\} spectroscopic database, the measured line intensities were found to be higher by about 10% for high J lines in the P branch and lower by about 5% for high J lines of the R branch, varying between these two limits roughly linearly with the line positions. The impact of the presently measured line intensities on retrievals of atmospheric ethylene in the 949.0–952.0 cm−1 microwindow was evaluated using a subset of ground-based high-resolution \{FTIR\} solar spectra recorded at the Jungfraujoch station. The use of \{HITRAN\} 2012 with line intensities modified to match the present measurements led to a systematic reduction of the measured total columns of ethylene by − 4.1 ± 0.1 % . "} 
}
@article{Wang2014963,
title = {"Content-based image retrieval using H.264 intra coding features "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"5"},
pages = {"963 - 969"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.02.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314000546"},
author = {"Ren-Jie Wang and Ya-Ting Yang and Pao-Chi Chang"},
keywords = {"Content-based image/video retrieval", "H.264", "Intra prediction", "Video coding", "Compression domain", "Geometrical verification", "Image search", "Texture features "},
abstract = {"Abstract Efficient multimedia retrieval has become a vital issue because more audio and video data are now available. This paper focuses on content-based image retrieval (CBIR) in the compression domain (CPD). The retrieval features are extracted based on I-frame coding information in H.264. This paper proposes using a local mode histogram as the texture feature to match images and applying the residual coefficients to filter non-confident modes. The geometrical correspondence between two images is also considered. The experimental results show that the proposed method can substantially reduce computational and memory resource consumption, and provides similar performance compared with methods that extract features from decompressed images. "} 
}
@article{Wang201491,
title = {"Nonlinear multiple-image encryption based on mixture retrieval algorithm in Fresnel domain "},
journal = {"Optics Communications "},
volume = {"330"},
number = {""},
pages = {"91 - 98"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.05.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814004878"},
author = {"Y. Wang and C. Quan and C.J. Tay"},
keywords = {"Multiple-image encryption", "Mixture retrieval algorithm", "Fresnel transform (FrT) "},
abstract = {"Abstract We propose a novel nonlinear multiple-image encryption based on mixture retrieval algorithm and phase mask multiplexing in Fresnel domain. The encryption process is realized by applying the Yang–Gu algorithm cascaded with a modified Gerchberg–Saxton algorithm (MGSA), which generate a private key and an intermediate phase to ensure high security. In the proposed method, all images are encoded separately into a phase only function (POF). Obtained \{POFs\} are integrated into a final \{POF\} based on phase mask multiplexing. As a result, cross-talk noise is removed resulting in a large improvement of the encryption capacity. A spatial light modulator (SLM) based optical setup has been suggested for decryption. Numerical simulations are presented to demonstrate the feasibility and effectiveness of the proposed system. Results also indicate the high robustness of the system against occlusion and noise attacks. "} 
}
@article{Hans201410,
title = {"Posthumous gamete retrieval and reproduction: Would the deceased spouse consent? "},
journal = {"Social Science & Medicine "},
volume = {"119"},
number = {""},
pages = {"10 - 17"},
year = {"2014"},
note = {""},
issn = {"0277-9536"},
doi = {"https://doi.org/10.1016/j.socscimed.2014.08.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0277953614005279"},
author = {"Jason D. Hans"},
keywords = {"Oocyte retrieval", "Posthumous reproduction", "Presumed consent", "Sperm preservation", "Sudden death "},
abstract = {"Abstract Policy and medical decision-making has been hindered by the absence of reliable data on attitudes toward having one's own gametes retrieved posthumously and used to produce a child in the event of an untimely death. The purpose of this study is to directly and empirically examine whether the presumption against consent is justified in the case of posthumous gamete retrieval following sudden death. Respondents (N = 2064) were contacted using a random-digit dialing method that gave every household telephone in the continental United States an equal probability of being contacted, and were asked: “Suppose you were to experience an early death and your spouse wanted to have a biological child with you. Would you or would you not want your spouse to be able to use your sperm/eggs following your death to have a child with you?” Among reproductive age respondents (18–44 years), 70% of males and 58% of females wanted their spouse to be able to use their gametes and, for the most part, attitudes were fairly consistent across demographic characteristics. Religiosity was the best predictor of attitudes—those who described themselves as more religious were less likely to desire posthumous gamete retrieval—but the majority (58%) of respondents who were very religious approved of retrieval. Overall, these data indicate that abandoning the prevailing presumption against consent in favor of a presumption of consent on the part of the deceased will result in the deceased's wishes being honored two and three times more often for females and males, respectively. Three main arguments against a presumption of consent in this context are discussed: autonomy of the deceased, conflict of interest, and the decision-making capacity of a grieving spouse. "} 
}
@article{Jiang2017232,
title = {"Pixel-by-pixel absolute phase retrieval using three phase-shifted fringe patterns without markers "},
journal = {"Optics and Lasers in Engineering "},
volume = {"91"},
number = {""},
pages = {"232 - 241"},
year = {"2017"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616305280"},
author = {"Chufan Jiang and Beiwen Li and Song Zhang"},
keywords = {"Absolute phase", "Real-time", "Structured light", "Geometric constraints", "Depth range extension "},
abstract = {"Abstract This paper presents a method that can recover absolute phase pixel by pixel without embedding markers on three phase-shifted fringe patterns, acquiring additional images, or introducing additional hardware component(s). The proposed three-dimensional (3D) absolute shape measurement technique includes the following major steps: (1) segment the measured object into different regions using rough priori knowledge of surface geometry; (2) artificially create phase maps at different z planes using geometric constraints of structured light system; (3) unwrap the phase pixel by pixel for each region by properly referring to the artificially created phase map; and (4) merge unwrapped phases from all regions into a complete absolute phase map for 3D reconstruction. We demonstrate that conventional three-step phase-shifted fringe patterns can be used to create absolute phase map pixel by pixel even for large depth range objects. We have successfully implemented our proposed computational framework to achieve absolute 3D shape measurement at 40 Hz. "} 
}
@article{Nigam2014173,
title = {"Retrieval of wheat leaf area index from \{AWiFS\} multispectral data using canopy radiative transfer simulation "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"32"},
number = {""},
pages = {"173 - 185"},
year = {"2014"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2014.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243414000877"},
author = {"Rahul Nigam and Bimal K. Bhattacharya and Swapnil Vyas and Markand P. Oza"},
keywords = {"\{LAI\} retrieval", "Canopy radiative transfer", "Satellite", "Crop "},
abstract = {"Abstract Accurate representation of leaf area index (LAI) from high resolution satellite observations is obligatory for various modelling exercises and predicting the precise farm productivity. Present study compared the two retrieval approach based on canopy radiative transfer (CRT) method and empirical method using four vegetation indices (VI) (e.g. NDVI, NDWI, \{RVI\} and GNDVI) to estimate the wheat LAI. Reflectance observations available at very high (56 m) spatial resolution from Advanced Wide-Field Sensor (AWiFS) sensor onboard Indian Remote Sensing (IRS) P6, Resourcesat-1 satellite was used in this study. This study was performed over two different wheat growing regions, situated in different agro-climatic settings/environments: Trans-Gangetic Plain Region (TGPR) and Central Plateau and Hill Region (CPHR). Forward simulation of canopy reflectances in four \{AWiFS\} bands viz. green (0.52–0.59 μm), red (0.62–0.68 μm), \{NIR\} (0.77–0.86 μm) and \{SWIR\} (1.55–1.70 μm) were carried out to generate the look up table (LUT) using \{CRT\} model \{PROSAIL\} from all combinations of canopy intrinsic variables. An inversion technique based on minimization of cost function was used to retrieve \{LAI\} from \{LUT\} and observed \{AWiFS\} surface reflectances. Two consecutive wheat growing seasons (November 2005–March 2006 and November 2006–March 2007) datasets were used in this study. The empirical models were developed from first season data and second growing season data used for validation. Among all the models, LAI-NDVI empirical model showed the least \{RMSE\} (root mean square error) of 0.54 and 0.51 in both agro-climatic regions respectively. The comparison of \{PROSAIL\} retrieved \{LAI\} with in situ measurements of 2006–2007 over the two agro-climatic regions produced substantially less \{RMSE\} of 0.34 and 0.41 having more \{R2\} of 0.91 and 0.95 for \{TGPR\} and \{CPHR\} respectively in comparison to empirical models. Moreover, \{CRT\} retrieved \{LAI\} had less value of errors in all the \{LAI\} classes contrary to empirical estimates. The \{PROSAIL\} based retrieval has potential for operational implementation to determine the regional crop \{LAI\} and can be extendible to other regions after rigorous validation exercise. "} 
}
@article{deVes20142925,
title = {"A statistical model for magnitudes and angles of wavelet frame coefficients and its application to texture retrieval "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"9"},
pages = {"2925 - 2939"},
year = {"2014"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2014.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320314000740"},
author = {"Esther de Ves and Daniel Acevedo and Ana Ruedin and Xaro Benavent"},
keywords = {"Image retrieval", "Rotation invariant", "Statistical models", "Texture descriptor", "Wavelet frames "},
abstract = {"Abstract This paper presents a texture descriptor based on wavelet frame transforms. At each position in the image, and for each resolution level, we consider both vertical and horizontal wavelet detail coefficients as the components of a bivariate random vector. The magnitudes and angles of these vectors are computed. At each level the empirical histogram of magnitudes is modeled by a Generalized Gamma distribution, and the empirical histogram of angles is modeled by a different version of the von Mises distribution that accounts for histograms with 2 modes. Each texture is characterized by few parameters. A new distance is presented (based on the Kullback–Leibler divergence) that allows giving relative importance to each model and to each resolution level. This distance is later conveniently adapted to provide for rotation invariance, by establishing equivalence classes over distributions of angles. Through a broad set of experiments on three different image databases, we demonstrate that our new descriptor and distance measure can be successfully applied in the context of texture retrieval. We compare our system to several relevant methods in this field in terms of retrieval performance and number of parameters used by each method. We also include some classification tests. In all the tests, we obtain superior retrieval rates for a set of fewer parameters involved. "} 
}
@article{Faria2015367,
title = {"Content-based image retrieval for brain MRI: An image-searching engine and population-based analysis to utilize past clinical data for future diagnosis "},
journal = {"NeuroImage: Clinical "},
volume = {"7"},
number = {""},
pages = {"367 - 376"},
year = {"2015"},
note = {""},
issn = {"2213-1582"},
doi = {"https://doi.org/10.1016/j.nicl.2015.01.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213158215000091"},
author = {"Andreia V. Faria and Kenichi Oishi and Shoko Yoshida and Argye Hillis and Michael I. Miller and Susumu Mori"},
keywords = {"Automated parcellation", "Brain", "MRI", "Content-based image retrieval", "Atlas-based analysis "},
abstract = {"Abstract Radiological diagnosis is based on subjective judgment by radiologists. The reasoning behind this process is difficult to document and share, which is a major obstacle in adopting evidence-based medicine in radiology. We report our attempt to use a comprehensive brain parcellation tool to systematically capture image features and use them to record, search, and evaluate anatomical phenotypes. Anatomical images (T1-weighted MRI) were converted to a standardized index by using a high-dimensional image transformation method followed by atlas-based parcellation of the entire brain. We investigated how the indexed anatomical data captured the anatomical features of healthy controls and a population with Primary Progressive Aphasia (PPA). \{PPA\} was chosen because patients have apparent atrophy at different degrees and locations, thus the automated quantitative results can be compared with trained clinicians' qualitative evaluations. We explored and tested the power of individual classifications and of performing a search for images with similar anatomical features in a database using partial least squares-discriminant analysis (PLS-DA) and principal component analysis (PCA). The agreement between the automated z-score and the averaged visual scores for atrophy (r = 0.8) was virtually the same as the inter-evaluator agreement. The \{PCA\} plot distribution correlated with the anatomical phenotypes and the PLS-DA resulted in a model with an accuracy of 88% for distinguishing \{PPA\} variants. The quantitative indices captured the main anatomical features. The indexing of image data has a potential to be an effective, comprehensive, and easily translatable tool for clinical practice, providing new opportunities to mine clinical databases for medical decision support. "} 
}
@article{Lee20141045,
title = {"Improved open-vocabulary spoken content retrieval with word and subword lattices using acoustic feature similarity "},
journal = {"Computer Speech & Language "},
volume = {"28"},
number = {"5"},
pages = {"1045 - 1065"},
year = {"2014"},
note = {""},
issn = {"0885-2308"},
doi = {"https://doi.org/10.1016/j.csl.2013.12.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0885230813001162"},
author = {"Hung-yi Lee and Po-wei Chou and Lin-shan Lee"},
keywords = {"Spoken content retrieval", "Spoken term detection", "Pseudo-relevance feedback", "Random walk "},
abstract = {"Abstract Spoken content retrieval will be very important for retrieving and browsing multimedia content over the Internet, and spoken term detection (STD) is one of the key technologies for spoken content retrieval. In this paper, we show acoustic feature similarity between spoken segments used with pseudo-relevance feedback and graph-based re-ranking can improve the performance of STD. This is based on the concept that spoken segments similar in acoustic feature vector sequences to those with higher/lower relevance scores should have higher/lower scores, while graph-based re-ranking further uses a graph to consider the similarity structure among all the segments retrieved in the first pass. These approaches are formulated on both word and subword lattices, and a complete framework of using them in open vocabulary retrieval of spoken content is presented. Significant improvements for these approaches with both in-vocabulary and out-of-vocabulary queries were observed in preliminary experiments. "} 
}
@article{Raio2014212,
title = {"Acute stress impairs the retrieval of extinction memory in humans "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"112"},
number = {""},
pages = {"212 - 221"},
year = {"2014"},
note = {"Stress and the regulation of memory: From basic mechanisms to clinical implications "},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.01.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714000239"},
author = {"Candace M. Raio and Edith Brignoni-Perez and Rachel Goldman and Elizabeth A. Phelps"},
keywords = {"Extinction retrieval", "Fear conditioning", "Stress", "Cortisol "},
abstract = {"Abstract Extinction training is a form of inhibitory learning that allows an organism to associate a previously aversive cue with a new, safe outcome. Extinction does not erase a fear association, but instead creates a competing association that may or may not be retrieved when a cue is subsequently encountered. Characterizing the conditions under which extinction learning is expressed is important to enhancing the treatment of anxiety disorders that rely on extinction-based exposure therapy as a primary treatment technique. The ventromedial prefrontal cortex, which plays a critical role in the expression of extinction memory, has been shown to be functionally impaired after stress exposure. Further, recent work in rodents has demonstrated that exposure to stress leads to deficits in extinction retrieval, although this has yet to be tested in humans. To explore how stress might influence extinction retrieval in humans, participants underwent a differential aversive learning paradigm, in which one image was probabilistically paired with an aversive shock while the other image denoted safety. Extinction training directly followed, at which point reinforcement was omitted. A day later, participants returned to the lab and either completed an acute stress manipulation (i.e., cold pressor), or a control task, before undergoing an extinction retrieval test. Skin conductance responses and salivary cortisol concentrations were measured throughout each session as indices of fear arousal and neuroendocrine stress response, respectively. The efficacy of our stress induction was established by observing significant increases in cortisol for the stress condition only. We examined extinction retrieval by comparing conditioned responses during the last trial of extinction (day 1) with that of the first trial of re-extinction (day 2). Groups did not differ on initial fear acquisition or extinction, however, a day later participants in the stress group (n = 27) demonstrated significantly lower extinction retrieval (i.e., greater fear recovery) than those in the control group (n = 25). Our results suggest that acute stress impairs the retrieval of extinction learning and offers insight into why treatment strategies used in the clinic may be challenging to recruit in daily life where stress is pervasive. "} 
}
@article{LakshmiPriya2014107,
title = {"Shot based keyframe extraction for ecological video indexing and retrieval "},
journal = {"Ecological Informatics "},
volume = {"23"},
number = {""},
pages = {"107 - 117"},
year = {"2014"},
note = {"Special Issue on Multimedia in Ecology and Environment "},
issn = {"1574-9541"},
doi = {"https://doi.org/10.1016/j.ecoinf.2013.09.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1574954113000873"},
author = {"G.G. Lakshmi Priya and S. Domnic"},
keywords = {"Video shot boundary detection", "Keyframe extraction", "ICSA", "Ecological video summarization", "Indexing and retrieval", "Evaluation criteria "},
abstract = {"Abstract Among possible research area in multimedia, keyframe extraction is an important topic that provides video summarization, faster browsing and accessing of wide video collections. In this paper, we propose a new automatic shot based keyframe extraction for video indexing and retrieval applications. Initially, the frames are sequentially clustered into shots by using feature extraction, continuity value construction steps of shot boundary detection process and the shot frame clustering technique. The cluster having a larger dispersion rate is selected for inter cluster similarity analysis (ICSA) and the sub-shot based keyframes are extracted using ICSA. The proposed shot boundary detection algorithm and video keyframe extraction technique are implemented and evaluated on publicly available ecological video datasets. Compared with existing related algorithms, our method yields better F1-score of 94.2% for shot boundary detection and better results for keyframe extraction. The keyframes extracted by the proposed method are used for video indexing and retrieval. "} 
}
@article{Metwally2016S433,
title = {"Sa2026 A Novel Voice-Activated Web Application for Rapid Knowledge Generation and Information Retrieval Through Semantic Parsing of Verbal Communication "},
journal = {"Gastroenterology "},
volume = {"150"},
number = {"4, Supplement 1"},
pages = {"S433 - "},
year = {"2016"},
note = {""},
issn = {"0016-5085"},
doi = {"https://doi.org/10.1016/S0016-5085(16)31503-7"},
url = {"http://www.sciencedirect.com/science/article/pii/S0016508516315037"},
author = {"Omar N. Metwally and Sidhartha R. Sinha"} 

}
@article{Flores2015298,
title = {"Color deflectometry for phase retrieval using phase-shifting methods "},
journal = {"Optics Communications "},
volume = {"334"},
number = {""},
pages = {"298 - 302"},
year = {"2015"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2014.08.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401814007779"},
author = {"Jorge L. Flores and Ricardo Legarda-Saenz and G. Garcia-Torales"},
keywords = {"Fringe analysis", "Image reconstruction techniques", "Phase retrieval "},
abstract = {"Abstract In this paper, we propose a technique based on a color fringe pattern used on deflectometry experiment. The advantages of using color fringe patterns together with phase shifting techniques on deflectometry experiment are presented. An experimental wavefront reconstruction of a progressive lens shows the accuracy and simplicity of these techniques used to process the deflection measurements. "} 
}
@article{Köster201457,
title = {"Theta–gamma coupling during episodic retrieval in the human \{EEG\} "},
journal = {"Brain Research "},
volume = {"1577"},
number = {""},
pages = {"57 - 68"},
year = {"2014"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2014.06.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899314008440"},
author = {"Moritz Köster and Uwe Friese and Benjamin Schöne and Nelson Trujillo-Barreto and Thomas Gruber"},
keywords = {"Neuronal oscillations", "Memory retrieval", "Theta–gamma phase-amplitude coupling", "Cross frequency coupling "},
abstract = {"Abstract Recent findings indicate that phase-amplitude coupling between neuronal oscillations in the theta- (3–6 Hz) and the gamma-band (30–100 Hz) plays a functional role in memory processes. Here, using electroencephalography, we provide further evidence for coupling between prefrontal theta and parietal gamma during successful memory retrieval in the human brain. In a pictorial recognition task, the coupling between prefrontal theta phase and parietal gamma amplitude was quantified using the modulation index, 100–1500 ms after stimulus onset. Results show an increased coupling for remembered, as opposed to forgotten and new stimuli (i.e. a “recognition effect” and an “old/new effect”). Phase-amplitude coupling between the prefrontal theta phase and posterior gamma amplitudes is hypothesized to reflect long range communication between prefrontal control processes and the activation of posterior object representations accompanying mnemonic processing. "} 
}
@article{Wang20143293,
title = {"The method for image retrieval based on multi-factors correlation utilizing block truncation coding "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"10"},
pages = {"3293 - 3303"},
year = {"2014"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2014.04.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320314001666"},
author = {"Xingyuan Wang and Zongyu Wang"},
keywords = {"Content based image retrieval", "Block truncation coding", "Multi-factors correlation", "Structure element correlation", "Gradient value correlation", "Gradient direction correlation "},
abstract = {"Abstract In this paper, we proposed multi-factors correlation (MFC) to describe the image, structure element correlation (SEC), gradient value correlation (GVC) and gradient direction correlation (GDC). At first, the \{RGB\} color space image is converted to a bitmap image and a mean color component image utilizing the block truncation coding (BTC). Then, three correlations will be used to extract the image feature. The structure elements can effectively represent the bitmap which is generated by BTC, and \{SEC\} can effectively denote the bitmap׳s structure and the correlation of the block in the bitmap. \{GVC\} and \{GDC\} can effectively denote the gradient relation, which is computed by a mean color component image. Formed by SEC, \{GVC\} and GDC, the image feature vectors can effectively represent the image. In the end, the results demonstrate that the method has better performance than other image retrieval methods in the experiment. "} 
}
@article{Limbachia2017,
title = {"Laparoscopic retrieval of a foreign body (broken surgical knife) from retroperitoneal space: An interesting case "},
journal = {"Gynecology and Minimally Invasive Therapy "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2213-3070"},
doi = {"https://doi.org/10.1016/j.gmit.2016.10.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213307017300448"},
author = {"Dipak Limbachia and Preeti Gandhi"},
keywords = {"broken knife", "foreign body", "laparoscopy", "retroperitoneal "},
abstract = {"Abstract We present a rare and interesting case, of a retrieval of a broken surgical knife blade, from the retroperitoneal space, through laparoscopic approach by a gynecology endoscopist. A 40-year-old man underwent open lumbar discectomy surgery, when the surgical knife blade inadvertently broke, and was retained in the disc space. The broken blade could not be removed during the initial surgery. A second attempt was made to retrieve it; however, it migrated further anteriorly into the retroperitoneal space. Subsequently, a gynecology endoscopist was called in, who successfully retrieved the broken blade from the retroperitoneal space through laparoscopic approach. A four-port laparoscopic transperitoneal approach was performed. The broken fragment of the knife was found just medial to the left common iliac artery in the retroperitoneal space, which was removed. Operation time was 40 minutes and the postoperative course was uneventful. "} 
}
@article{Jo201420,
title = {"Memory retrieval in response to partial cues requires \{NMDA\} receptor-dependent neurotransmission in the medial prefrontal cortex "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"109"},
number = {""},
pages = {"20 - 26"},
year = {"2014"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2013.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742713002219"},
author = {"Yong Sang Jo and June-Seek Choi"},
keywords = {"Prefrontal cortex", "Memory retrieval", "NMDA receptors", "Spatial memory", "Rat "},
abstract = {"Abstract The medial prefrontal cortex (mPFC) has been suggested to play a crucial role in retrieving detailed contextual information about a previous learning episode in response to a single retrieval cue. However, few studies investigated the neurochemical mechanisms that mediate the prefrontal retrieval process. In the current study, we examined whether N-methyl-D-aspartate receptors (NMDARs) in the mPFC were necessary for retrieval of a well-learned spatial location on the basis of partial or degraded spatial cues. Rats were initially trained to find a hidden platform in the Morris water maze using four extramaze cues in the surrounding environment. Their retrieval performance was subsequently tested under different cue conditions. Infusions of DL-2-amino-5-phosphonovaleric acid (APV), a \{NMDAR\} antagonist, significantly disrupted memory retrieval when three of the original cues were removed. By contrast, \{APV\} injections into the mPFC did not affect animals’ retrieval performance when the original cues were presented or when three novels landmarks were added alongside the original cues. These results indicate that prefrontal \{NMDARs\} are required for memory retrieval when allocentric spatial information is degraded. NMDAR-dependent neurotransmission in the mPFC may facilitate an active retrieval process to reactivate complete contextual representations associated with partial retrieval cues. "} 
}
@article{Vashisth20145309,
title = {"Image encryption using fractional Mellin transform, structured phase filters, and phase retrieval "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"125"},
number = {"18"},
pages = {"5309 - 5315"},
year = {"2014"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2014.06.068"},
url = {"http://www.sciencedirect.com/science/article/pii/S003040261400713X"},
author = {"Sunanda Vashisth and Hukum Singh and A.K. Yadav and Kehar Singh"},
keywords = {"Fractional Mellin transform", "Structured phase masks", "Toroidal zone plate", "Radial Hilbert mask", "Phase retrieval algorithm "},
abstract = {"Abstract An image encryption scheme has been presented by using two structured phase masks in the fractional Mellin transform (FrMT) plane of a system, employing a phase retrieval technique. Since FrMT is a non-linear integral transform, its use enhances the system security. We also add further security features by carrying out spatial filtering in the frequency domain by using a combination of two phase masks: a toroidal zone plate (TZP) and a radial Hilbert mask (RHM). These masks together increase the key space making the system more secure. The phase key used in decryption has been obtained by applying an iterative phase retrieval algorithm based on the fractional Fourier transform. The algorithm uses amplitude constraints of secret target image and the ciphertext (encrypted image) obtained from multiplication of fractional Mellin transformed arbitrary input image and the two phase masks (TZP and RHM). The proposed encryption scheme has been validated for a few grayscale images, by numerical simulations. The efficacy of the scheme has been evaluated by computing mean-squared-error (MSE) between the secret target image and the decrypted image. The sensitivity analysis of the decryption process to variations in various encryption parameters has also been carried out. "} 
}
@article{VijayaBhaskarReddy2014637,
title = {"Content based image indexing and retrieval using directional local extrema and magnitude patterns "},
journal = {"\{AEU\} - International Journal of Electronics and Communications "},
volume = {"68"},
number = {"7"},
pages = {"637 - 643"},
year = {"2014"},
note = {""},
issn = {"1434-8411"},
doi = {"https://doi.org/10.1016/j.aeue.2014.01.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1434841114000284"},
author = {"P. Vijaya Bhaskar Reddy and A. Rama Mohan Reddy"},
keywords = {"Ditectional local extrema patterns (DLEPs)", "Local binary patterns (LBPs)", "Image retrieval", "Pattern recognition", "Databases "},
abstract = {"Abstract In this paper, we integrate the concept of directional local extremas and their magnitude based patterns for content based image indexing and retrieval. The standard ditectional local extrama pattern (DLEP) extracts the directional edge information based on local extrema in 0°, 45°, 90°, and 135° directions in an image. However, they are not considering the magnitudes of local extremas. The proposed method integrates these two concepts for better retrieval performance. The sign \{DLEP\} (SDLEP) operator is a generalized \{DLEP\} operator and magnitude \{DLEP\} (MDLEP) operator is calculated using magnitudes of local extremas. The performance of the proposed method is compared with DLEP, local binary patterns (LBPs), block-based \{LBP\} (BLK_LBP), center-symmetric local binary pattern (CS-LBP), local edge patterns for segmentation (LEPSEG) and local edge patterns for image retrieval (LEPINV) methods by conducting two experiments on benchmark databases, viz. Corel-5K and Corel-10K databases. The results after being investigated show a significant improvement in terms of their evaluation measures as compared to other existing methods on respective databases. "} 
}
@article{Tong2014423,
title = {"Evaluation of satellite precipitation retrievals and their potential utilities in hydrologic modeling over the Tibetan Plateau "},
journal = {"Journal of Hydrology "},
volume = {"519, Part A"},
number = {""},
pages = {"423 - 437"},
year = {"2014"},
note = {""},
issn = {"0022-1694"},
doi = {"https://doi.org/10.1016/j.jhydrol.2014.07.044"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022169414005617"},
author = {"Kai Tong and Fengge Su and Daqing Yang and Zhenchun Hao"},
keywords = {"Satellite precipitation retrievals", "VIC hydrological model", "Streamflow simulation", "Tibetan Plateau "},
abstract = {"Summary In this study, we evaluate four widely used global high-resolution satellite precipitation products against gauge observations over the Tibetan Plateau (TP). We also investigate the capability of the satellite products in streamflow simulations using the \{VIC\} hydrological model. Results show that the 3B42 and \{CMORPH\} perform better than the 3B42RT and \{PERSIANN\} at both plateau and basin scales. The 3B42RT and \{PERSIANN\} considerably overestimate the gauge precipitation estimates almost over the entire plateau, and the \{PERSIANN\} fail to capture the spatial and temporal pattern of the gauge precipitation estimates. For different satellite estimates, the error sources are systematically different for various seasons. For the 3B42, the miss bias is the main problem. The \{CMORPH\} exhibits obvious negative hit bias and miss bias in the rainy season and false-rain bias in the non-rainy season. The total bias in the 3B42RT and \{PERSIANN\} mainly attribute to positive hit bias in the rainy season and false-rain bias in the non-rainy season. The 3B42RT and \{PERSIANN\} show little capability for streamflow simulations over the TP, while the \{CMORPH\} exhibits an encouraging potential for hydrological applications in this regions in spite of the general underestimates. The 3B42 shows comparable performance to the \{CMA\} (China Meteorological Administration) data in both monthly and daily streamflow simulations mostly due to the monthly gauge adjustment involved in it. "} 
}
@article{Jian20149,
title = {"Face-image retrieval based on singular values and potential-field representation "},
journal = {"Signal Processing "},
volume = {"100"},
number = {""},
pages = {"9 - 15"},
year = {"2014"},
note = {""},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2014.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168414000073"},
author = {"Muwei Jian and Kin-Man Lam"},
keywords = {"Face-image retrieval", "Potential-field representation", "Singular values", "Rotation-shift-scale-invariant feature "},
abstract = {"Abstract In this paper, an efficient method based on singular values and potential-field representation is proposed for face-image retrieval. Firstly, we theoretically prove that the leading singular values of an image can be used as a rotation-shift-scale-invariant global feature. Then, for the feature-extraction stage, we exploit these special properties of the singular values to devise a compact, global feature for face-image representation. We also use the singular values of the potential field derived from edge gradients to enhance the retrieval performance. Experimental results based on the \{GTAV\} database show that the use of singular values as rotation-shift-scale-invariant global features is able to produce plausible retrieval results. "} 
}
@article{Wei201471,
title = {"Meta-heuristic Bayesian networks retrieval combined polarization corrected temperature and scattering index for precipitations "},
journal = {"Neurocomputing "},
volume = {"136"},
number = {""},
pages = {"71 - 81"},
year = {"2014"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2014.01.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214002240"},
author = {"Chih-Chiang Wei"},
keywords = {"Bayesian network", "Heuristic technique", "Precipitation", "Retrieval "},
abstract = {"Abstract This paper proposes Bayesian networks (BNs) that combine polarization corrected temperature (PCT) and scattering index (SI) methods to identify rainfall intensity. To learn \{BN\} network structures, meta-heuristic techniques including tabu search (TS), simulated annealing (SA) and genetic algorithm (GA) were empirically evaluated and compared for efficiency. The proposed models were applied to the Tanshui river basin in Taiwan. The meteorological data from the Special Sensor Microwave/Imager (SSM/I) of the National Oceanic and Atmospheric Administration (NOAA) comprises seven passive microwave brightness temperatures, and was used to detect rain rates. The data consisted of 71 typhoons affecting the watershed during 2000–2012. A preliminary analysis using simple meta-heuristic \{BNs\} identified the main attributes, namely the brightness temperatures of 19, 22, 37 and 85 \{GHz\} for rainfall retrieval. Based on the preliminary analysis of a simple \{BN\} run, the advanced \{BNs\} combined with \{SI\} and \{PCT\} successfully demonstrated improved rain rate retrieval accuracy. To compare the proposed meta-heuristic BNs, the traditional \{SI\} method, the SI-based support vector regression model (SI-SVR), and artificial neural network (ANN) were used as benchmarks. The results showed that (1) meta-heuristic \{BN\} techniques can be used to identify the vital attributes of the rainfall retrieval problem and their causal relationships and (2) according to a comparison of \{BNs\} combined with \{PCT\} and \{SI\} and artificial intelligence (AI)-based models (SI-SVR and ANN), in heavy, torrential, and pouring rainfall, models of \{BNs\} combined with \{PCT\} and \{SI\} provide a superior retrieval performance than that of AI-based models. Therefore, this study confirms that meta-heuristic \{BNs\} combined with \{PCT\} and \{SI\} is an efficient tool for addressing rainfall retrieval problems. "} 
}
@article{Zhu201425,
title = {"Phase retrieval from single frame projection fringe pattern with variational image decomposition "},
journal = {"Optics and Lasers in Engineering "},
volume = {"59"},
number = {""},
pages = {"25 - 33"},
year = {"2014"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2014.03.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816614000621"},
author = {"Xinjun Zhu and Chen Tang and Biyuan Li and Chen Sun and Linlin Wang"},
keywords = {"Projection fringe pattern", "Phase retrieval", "Fourier transform", "Shearlet transform", "Variational image decomposition "},
abstract = {"Abstract Phase retrieval from single frame projection fringe pattern is of fundamental importance, and is also a challenging problem in fringe projection measurement. In this paper, we present a new method for phase retrieval from a single frame projection fringe pattern based on variational image decomposition (VID) methods. We propose a new image decomposition model TV-G-Shearlet in order to effectively split a projection fringe pattern into background part, fringe part and noise part. The performance of the proposed approach is verified by simulated and real projection fringes as well as the comparison with the widely used and well-known Fourier transform method and wavelet transform method. "} 
}
@article{Wang2014226,
title = {"FRR: Fair remote retrieval of outsourced private medical records in electronic health networks "},
journal = {"Journal of Biomedical Informatics "},
volume = {"50"},
number = {""},
pages = {"226 - 233"},
year = {"2014"},
note = {"Special Issue on Informatics Methods in Medical Privacy "},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2014.02.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046414000458"},
author = {"Huaqun Wang and Qianhong Wu and Bo Qin and Josep Domingo-Ferrer"},
keywords = {"Cloud computing", "Medical records", "Fair remote data retrieval "},
abstract = {"Abstract Cloud computing is emerging as the next-generation \{IT\} architecture. However, cloud computing also raises security and privacy concerns since the users have no physical control over the outsourced data. This paper focuses on fairly retrieving encrypted private medical records outsourced to remote untrusted cloud servers in the case of medical accidents and disputes. Our goal is to enable an independent committee to fairly recover the original private medical records so that medical investigation can be carried out in a convincing way. We achieve this goal with a fair remote retrieval (FRR) model in which either t investigation committee members cooperatively retrieve the original medical data or none of them can get any information on the medical records. We realize the first \{FRR\} scheme by exploiting fair multi-member key exchange and homomorphic privately verifiable tags. Based on the standard computational Diffie–Hellman (CDH) assumption, our scheme is provably secure in the random oracle model (ROM). A detailed performance analysis and experimental results show that our scheme is efficient in terms of communication and computation. "} 
}
@article{Konijnenberg201770,
title = {"Non-iterative phase retrieval by phase modulation through a single parameter "},
journal = {"Ultramicroscopy "},
volume = {"174"},
number = {""},
pages = {"70 - 78"},
year = {"2017"},
note = {""},
issn = {"0304-3991"},
doi = {"https://doi.org/10.1016/j.ultramic.2016.12.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S030439911630239X"},
author = {"A.P. Konijnenberg and W.M.J. Coene and H.P. Urbach"},

abstract = {"Abstract We report on a novel non-iterative phase retrieval method with which the complex-valued transmission function of an object can be retrieved with a non-iterative computation, with a limited number of intensity measurements. The measurements are taken in either real space or Fourier space, and for each measurement the phase in its dual space is modulated according to a single optical parameter. The requirement found for the phase modulation function is a general one, which therefore allows for plenty of customization in this method. It is shown that quantitative Zernike phase contrast imaging is one special case of this general method. With simulations we investigate the sampling requirements for a microscopy setup and for a Coherent Diffraction Imaging (CDI) setup. "} 
}
@article{Patarroyo201758,
title = {"Vibrissal paralysis produces increased corticosterone levels and impairment of spatial memory retrieval "},
journal = {"Behavioural Brain Research "},
volume = {"320"},
number = {""},
pages = {"58 - 66"},
year = {"2017"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2016.11.045"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432816311561"},
author = {"William E. Patarroyo and Milady García-Perez and Marisol Lamprea and Alejandro Múnera and Julieta Troncoso"},
keywords = {"Vibrissae", "Rat", "Spatial memory", "Corticosterone", "Stress", "Barnes circular maze "},
abstract = {"Abstract This research was aimed at establishing how the absence of active whisking in rats affects acquisition and recovery of spatial memory. The mystacial vibrissae were irreversibly paralyzed by cutting the facial nerve’s mandibular and buccal branches bilaterally in the facial nerve lesion group (N = 14); control animals were submitted to sham-surgery (N = 15). Sham-operated (N = 11) and facial nerve-lesioned (N = 10) animals were trained (one session, eight acquisition trials) and tested 24 h later in a circular Barnes maze. It was found that facial nerve lesioned-animals adequately acquired the spatial task, but had impaired recovery of it when tested 24 h after training as compared to control ones. Plasma corticosterone levels were measured after memory testing in four randomly chosen animals of each trained group and after a single training trial in the maze in additional facial nerve-lesioned (N = 4) and sham-operated animals (N = 4). Significant differences respecting the elevation of corticosterone concentration after either a single training trial or memory testing indicated that stress response was enhanced in facial nerve-lesioned animals as compared to control ones. Increased corticosterone levels during training and testing might have elicited the observed whisker paralysis-induced spatial memory retrieval impairment. "} 
}
@incollection{Karpicke2014237,
title = {"Chapter Seven - Retrieval-Based Learning: An Episodic Context Account "},
editor = {"Brian H. Ross"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2014"},
volume = {"61"},
pages = {"237 - 284"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/B978-0-12-800283-4.00007-1"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128002834000071"},
author = {"Jeffrey D. Karpicke and Melissa Lehman and William R. Aue"},
keywords = {"Retrieval practice", "Testing effect", "Learning", "Context", "Episodic memory "},
abstract = {"Abstract Practicing retrieval is a powerful way to promote learning and long-term retention. This chapter addresses the theoretical underpinnings of retrieval-based learning. We review methodological issues in retrieval practice research, identify key findings to be accounted for, and evaluate current candidate theories. We propose an episodic context account of retrieval-based learning, which explains retrieval practice in terms of context reinstatement, context updating, and restriction of the search set. Retrieval practice involves attempting to reinstate a prior learning context, and when retrieval is successful, the representation of context is updated to include features of retrieved contexts and the current context. Future retrieval is enhanced because updated context representations can be used to restrict the search set and hone in on a desired target. The context account accommodates a wide variety of phenomena in the retrieval practice literature and provides a comprehensive and cohesive account of retrieval-based learning. "} 
}
@article{Kumar2014119,
title = {"Structural similarity for document image classification and retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"43"},
number = {""},
pages = {"119 - 126"},
year = {"2014"},
note = {"\{ICPR2012\} Awarded Papers "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2013.10.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865513004224"},
author = {"Jayant Kumar and Peng Ye and David Doermann"},
keywords = {"Structural similarity", "Retrieval", "Classification", "Random forest "},
abstract = {"Abstract This paper presents a novel approach to defining document image structural similarity for the applications of classification and retrieval. We first build a codebook of \{SURF\} descriptors extracted from a set of representative training images. We then encode each document and model the spatial relationships between them by recursively partitioning the image and computing histograms of codewords in each partition. A random forest classifier is trained with the resulting features, and used for classification and retrieval. We demonstrate the effectiveness of our approach on table and tax form retrieval, and show that the proposed method outperforms previous approaches even when the training data is limited. "} 
}
@article{Rondinella2017631,
title = {"In toto microscopic scanning of \{ZTA\} femoral head retrievals using CAD-assisted confocal Raman spectroscopy "},
journal = {"Materials & Design "},
volume = {"116"},
number = {""},
pages = {"631 - 637"},
year = {"2017"},
note = {""},
issn = {"0264-1275"},
doi = {"https://doi.org/10.1016/j.matdes.2016.12.064"},
url = {"http://www.sciencedirect.com/science/article/pii/S0264127516315908"},
author = {"Alfredo Rondinella and Saverio Affatato and Elia Marin and Wenliang Zhu and Bryan J. McEntire and B. Sonny Bal and Toshiyuki Tateiwa and Kengo Yamamoto and Giovanni Valdré and Giuseppe Pezzotti"},
keywords = {"Zirconia-toughened alumina", "Confocal Raman spectroscopy", "Phase transformation", "Metal contamination", "3D-Cad "},
abstract = {"Abstract The purpose of this work is to establish a protocol, which combines \{CAD\} modeling to non-destructive microscopic techniques of confocal Raman micro-spectroscopy and laser microscopy, to assess the in-vivo hydrothermal stability of \{ZTA\} femoral head retrievals. The combined effects of wear, biological environment, and in vivo occurring peculiar events as metal staining were evaluated on five retrieved \{ZTA\} femoral heads with implantation time ranging from 9 to 106 months. The protocol relies on the application of a polar grid on the entire surface of the head, which divides it into small sectors; each sector is then automatically screened with micrometer resolution. Maps are finally linked to each other and an in-toto view of the retrieved head becomes available in three dimensions. Upon combining analytical techniques with a solid modeling computer-aided design (CAD) software, it becomes possible to develop a 3D model of the femoral head, which comprehensively describes topographic, crystallographic, and micromechanical characteristics of the entire surface and immediate sub-surface. The combination of CAD, polarized Raman spectroscopy, and laser microscopy has led to in-toto screening of femoral head with micrometer-scale resolution, thus providing a new and comprehensive protocol for both quality assessments on new components and failure analysis on retrievals. "} 
}
@article{Murala20141324,
title = {"Expert content-based image retrieval system using robust local patterns "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"25"},
number = {"6"},
pages = {"1324 - 1334"},
year = {"2014"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2014.05.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320314000935"},
author = {"Subrahmanyam Murala and Q.M. Jonathan Wu"},
keywords = {"Local binary pattern (LBP)", "Content based image retrieval (CBIR)", "Texture", "Gabor transform (GT)", "Feature extraction", "Multi-scale features", "Local difference operator (LDO)", "Database "},
abstract = {"Abstract A new image indexing and retrieval algorithm for content based image retrieval is proposed in this paper. The local region of the image is represented by making the use of local difference operator (LDO), separating it into two components i.e. sign and magnitude. The sign \{LBP\} operator (S_LBP) is a generalized \{LBP\} operator. The magnitude \{LBP\} (M_LBP) operator is calculated using the magnitude of LDO. A robust \{LBP\} (RLBP) operator is presented employing robust S_LBP and robust M_LBP. Further, the combination of Gabor transform and \{RLBP\} operator has also been presented. The robustness is established by conducting four experiments on different image database i.e. Corel 1000 (DB1), Brodatz texture database (DB2) and \{MIT\} VisTex database (DB3) under different lighting (illumination) and noise conditions. Investigations reveal a promising achievement of the technique presented when compared to S_LBP and other existing transform domain techniques in terms of their evaluation measures. "} 
}
@article{Bekinschtein2014252,
title = {"Role of \{PFC\} during retrieval of recognition memory in rodents "},
journal = {"Journal of Physiology-Paris "},
volume = {"108"},
number = {"4–6"},
pages = {"252 - 255"},
year = {"2014"},
note = {"Neurobiology of Learning and Memory: A Tribute to Hector Maldonado "},
issn = {"0928-4257"},
doi = {"https://doi.org/10.1016/j.jphysparis.2014.03.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0928425714000114"},
author = {"Pedro Bekinschtein and Noelia Weisstaub"},
keywords = {"Retrieval", "mPFC", "Recognition memory", "Rodents", "Behavior "},
abstract = {"Abstract One of the challenges for memory researches is the study of the neurobiology of episodic memory which is defined by the integration of all the different components of experiences that support the conscious recollection of events. The features of episodic memory includes a particular object or person (“what”), the context in which the experience took place (“where”) and the particular time at which the event occurred (“when”). Although episodic memory has been mainly studied in humans, there are many studies that demonstrate these features in non-human animals. Here, we summarize a set of studies that employ different versions of recognition memory tasks in animals to study the role of the medial prefrontal cortex in episodic memory. "} 
}
@article{GarciadelaTorre201435,
title = {"Role of glutamate receptors of central and basolateral amygdala nuclei on retrieval and reconsolidation of taste aversive memory "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"111"},
number = {""},
pages = {"35 - 40"},
year = {"2014"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.03.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714000495"},
author = {"Paola Garcia-delaTorre and Consuelo Pérez-Sánchez and Kioko Guzmán-Ramos and Federico Bermúdez-Rattoni"},
keywords = {"Glutamate", "Amygdala", "Taste recognition", "Retrieval", "Reconsolidation "},
abstract = {"Abstract There are a number of experiments showing an important involvement of amygdala N-methyl-d-aspartate (NMDA) glutamate receptors on consolidation of conditioned taste aversion (CTA) memory. Interestingly, recent evidence has shown that α-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA) glutamate receptors are particularly involved in \{CTA\} retrieval. Memory reconsolidation has been proposed as a destabilization and re-stabilization process induced by memory reactivation. We have recently suggested that reconsolidation could be enabled in the absence of retrieval. Hence, we decided to analyze the participation of \{AMPA\} and \{NMDA\} receptors of the central (CeA) and basolateral amygdala (BLA) in \{CTA\} memory retrieval and reconsolidation. To do so, we tested whether administrations of an \{AMPA\} receptor blocker (NBQX) or an \{NMDA\} receptor blocker (APV) 15 min before a second acquisition trial could have effects on taste aversion. We found that administration of \{NBQX\} in the \{BLA\} blocked retrieval, whereas \{APV\} blocked reconsolidation in the BLA, and consolidation in the CeA. When we administered both \{NBQX\} and \{APV\} into the \{BLA\} before the second acquisition trial, results showed impairment of both retrieval and reconsolidation. These results further support the idea that reconsolidation is independent of retrieval, since retrieval blockade in the \{BLA\} did not impair memory reconsolidation. These results suggest that glutamate receptors have different participation on retrieval and reconsolidation of \{CTA\} and further support the hypothesis that these two processes could be independent. "} 
}
@article{Dreifus201435,
title = {"Retrieval-induced forgetting under psychosocial stress: No reduction by delayed stress and beta-adrenergic blockade "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"110"},
number = {""},
pages = {"35 - 46"},
year = {"2014"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2014.01.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742714000112"},
author = {"Laura Dreifus and Harald Engler and Johanna Kissler"},
keywords = {"Memory", "Retrieval-induced forgetting", "Psychosocial stress", "HPA-axis", "Adrenergic system", "Trier Social Stress Test", "Beta-blockade "},
abstract = {"Abstract Retrieval-induced forgetting (RIF) is the phenomenon that ‘retrieval-practice’, the repeated retrieval of a subset of initially learned material, can impair the recall of episodically related memories. Previous studies showed that \{RIF\} is eliminated when retrieval-practice is carried out under psycho-social stress, anxiety, or in negative mood. However, pharmacological manipulation by hydrocortisone did not eliminate the effect. This study investigated the effect of beta-adrenergic blockade on stress-induced modulations of RIF, addressing possible interactive effects of the glucocorticoid and sympatho–adrenomedullary systems. Participants learned categorized word lists and then received either 60 mg propranolol or a placebo. After 90 min they were exposed to the TSST. A third group did not receive any medication and performed a non-stressful control task with the same timing as the other two groups. Finally, all participants underwent retrieval-practice and final recall. Both \{TSST\} groups exhibited a stress-induced increase in cortisol-levels, and the placebo group also exhibited large increases in markers of sympathetic nervous system activity and more psychological distress at the time of retrieval-practice. Although, overall recall was poorer under stress, an overall \{RIF\} effect emerged irrespective of group and showed no clear modulation by stress with or without beta-adrenergic blockade. In previous demonstrations of \{RIF\} elimination by negative emotion, state induction and retrieval-practice followed very briefly after initial learning. Given that both the previous study of hydrocortisone effects on \{RIF\} and the present study used longer delays between learning and retrieval-practice, the possibility that stress effects on retrieval-practice eliminate \{RIF\} only relatively briefly after learning is discussed. "} 
}
@article{Wang2014128,
title = {"A new sketch-based 3D model retrieval approach by using global and local features "},
journal = {"Graphical Models "},
volume = {"76"},
number = {"3"},
pages = {"128 - 139"},
year = {"2014"},
note = {"Computational Visual Media Conference 2013Second Computational Visual Media Conference (CVM) "},
issn = {"1524-0703"},
doi = {"https://doi.org/10.1016/j.gmod.2013.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1524070313000593"},
author = {"Feng Wang and Lanfen Lin and Min Tang"},
keywords = {"Sketch-based 3D model retrieval", "Global features", "Local features", "Semantic relations "},
abstract = {"Abstract With the rapid growth of available 3D models, fast retrieval of suitable 3D models has become a crucial task for industrial applications. This paper proposes a novel sketch-based 3D model retrieval approach which utilizes both global feature-based and local feature-based techniques. Unlike current approaches which use either global or local features, as well as do not take into account semantic relations between local features, we extract these two kinds of feature information from the representative 2D views of 3D models that can facilitate semantic description and retrieval for 3D models. Global features represent the gross exterior boundary shape information, and local features describe the interior details by compact visual words. Specifically, an improved bag-of-features method is provided to extract local features and their latent semantic relations. In addition, an efficient two-stage matching strategy is used to measure the distance between the query sketch and 3D models for selection and refinement. Experiment results demonstrate that our approach which combines these two kinds of complementary features significantly outperforms several state-of-the-art approaches. "} 
}
@article{Fickus2014475,
title = {"Phase retrieval from very few measurements "},
journal = {"Linear Algebra and its Applications "},
volume = {"449"},
number = {""},
pages = {"475 - 499"},
year = {"2014"},
note = {""},
issn = {"0024-3795"},
doi = {"https://doi.org/10.1016/j.laa.2014.02.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0024379514000780"},
author = {"Matthew Fickus and Dustin G. Mixon and Aaron A. Nelson and Yang Wang"},
keywords = {"Phase retrieval", "Informationally complete", "Unit norm tight frames", "Computational complexity "},
abstract = {"Abstract In many applications, signals are measured according to a linear process, but the phases of these measurements are often unreliable or not available. To reconstruct the signal, one must perform a process known as phase retrieval. This paper focuses on completely determining signals with as few intensity measurements as possible, and on efficient phase retrieval algorithms from such measurements. For the case of complex M-dimensional signals, we construct a measurement ensemble of size 4 M − 4 which yields injective intensity measurements; this is conjectured to be the smallest such ensemble. For the case of real signals, we devise a theory of “almost” injective intensity measurements, and we characterize such ensembles. Later, we show that phase retrieval from M + 1 almost injective intensity measurements is \{NP\} -hard, indicating that computationally efficient phase retrieval must come at the price of measurement redundancy. "} 
}
@article{Vidya20161240,
title = {"Web Page Ranking Using Multilingual Information Search Algorithm - A Novel Approach "},
journal = {"Procedia Technology "},
volume = {"24"},
number = {""},
pages = {"1240 - 1247"},
year = {"2016"},
note = {"International Conference on Emerging Trends in Engineering, Science and Technology (ICETEST - 2015) "},
issn = {"2212-0173"},
doi = {"https://doi.org/10.1016/j.protcy.2016.05.102"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212017316301918"},
author = {"P.V. Vidya and P.C. Reghu Raj and V. Jayan"},
keywords = {"Multilingual Information Retrieval", "Google Translate API", "Google Search", "Inverted Index", "Word Frequency "},
abstract = {"Abstract The goal of an information retrieval system is to provide the information that is relevant to the user's query. In some cases the information relevant to the user request may not exist in the user's native language. Situations may also arise where the user is able to read documents in languages different from the native one, but might have difficulty in formulating queries in them. The main intention behind Multilingual Information Retrieval is to find the relevant information available irrespective of the language used in the query. "} 
}
@article{Wang201431,
title = {"From one graph to many: Ensemble transduction for content-based database retrieval "},
journal = {"Knowledge-Based Systems "},
volume = {"65"},
number = {""},
pages = {"31 - 37"},
year = {"2014"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2014.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705114001178"},
author = {"Jim Jing-Yan Wang and Yijun Sun"},
keywords = {"Content-based database retrieval", "Contextual similarity", "Graph transduction", "Multi-Kernel Learning", "Ensembel learning "},
abstract = {"Abstract Similarity learning plays a fundamental role in the problem of database retrieval and nearest classification problem. Traditional pairwise similarity measure ignores the contextual information, and the Graph Transduction (GT) has been proposed as a contextual similarity learning algorithm to utilize the contextual information, which is embedded in a nearest neighbor graph. On main shortage of this method is that it is difficult to choose the optimal graph since different graphs may focus on different aspects of the objects. Co-Transduction (CT) is lately proposed by fusing two different graphs. In this paper, we generalize this problem by using the ensemble of many candidate graphs with different models and parameters for transduction, by assuming that the optimal graph could be obtained by the weighted linear ensemble of these candidate graphs. The similarities and graph weights are modeled within one unified objective function, and optimized alternately in an iterative algorithm. The new proposed algorithm, named as Ensemble Transduction (ET), is tested on two challenging tasks and the experimental results show that it can outperform both the \{GT\} and CT. "} 
}
@article{Warford201428,
title = {"Antigen retrieval, blocking, detection and visualisation systems in immunohistochemistry: A review and practical evaluation of tyramide and rolling circle amplification systems "},
journal = {"Methods "},
volume = {"70"},
number = {"1"},
pages = {"28 - 33"},
year = {"2014"},
note = {"Advancing the boundaries of molecular cellular pathology "},
issn = {"1046-2023"},
doi = {"https://doi.org/10.1016/j.ymeth.2014.03.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1046202314000942"},
author = {"Anthony Warford and Hameed Akbar and Deise Riberio"},
keywords = {"Immunohistochemistry", "Antigen retrieval", "Detection systems", "Tyramide signal amplification", "Rolling circle amplification "},
abstract = {"Abstract To achieve specificity and sensitivity using immunohistochemistry it is necessary to combine the application of validated primary antibodies with optimised pre-treatment, detection and visualisation steps. The influence of these surrounding procedures is reviewed. A practical evaluation of tyramide signal amplification and rolling circle amplification detection methods is provided in which formalin fixed paraffin embedded sections of adenocarcinomas of breast, colon and lung together with squamous metaplasia of lung were immunostained with \{CD20\} and \{CK19\} primary antibodies. The results indicate that the detection systems are of comparable sensitivity and specificity. "} 
}
@article{BenMimoun2014375,
title = {"Determinants of e-consumer productivity in product retrieval on a commercial website: An experimental approach "},
journal = {"Information & Management "},
volume = {"51"},
number = {"4"},
pages = {"375 - 390"},
year = {"2014"},
note = {""},
issn = {"0378-7206"},
doi = {"https://doi.org/10.1016/j.im.2014.02.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0378720614000111"},
author = {"Mohamed Slim Ben Mimoun and Marion Garnier and Richard Ladwein and Christophe Benavent"},
keywords = {"E-consumer productivity", "Product retrieval", "Site design", "Online experiment", "Cognitive absorption", "Site complexity "},
abstract = {"Abstract This article investigates what determines e-consumer productivity, in the specific case of product retrieval, on a commercial website. With a 2 × 2 × 2 factorial design on 292 participants, an online experiment reveals that productivity in product retrieval (measured in terms of effectiveness, efficiency, and time) relates to website design (e.g., abstraction level of labels, animation), user characteristics (e.g., Internet experience, product category familiarity, cognitive absorption), and situational characteristics (e.g., task nature). The results also confirm interactive effects among the type of strategy used, the nature of the task, and the website design. These findings have notable implications for both research and practice. "} 
}
@article{JeenaJacob201472,
title = {"Local Oppugnant Color Texture Pattern for image retrieval system "},
journal = {"Pattern Recognition Letters "},
volume = {"42"},
number = {""},
pages = {"72 - 78"},
year = {"2014"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2014.01.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865514000312"},
author = {"I. Jeena Jacob and K.G. Srinivasagan and K. Jayapriya"},
keywords = {"Content based image retrieval", "Local Oppugnant Colored Texture Pattern", "Colored Pattern Appearance Model "},
abstract = {"Abstract The current scenario of image retrieval pays attention to local texture patterns. The recently proposed Local Tetra Pattern (LTrP) represents the image by the directional information and gives promising results. This paper proposes Local Oppugnant Color Texture Pattern (LOCTP), an enhancement of LTrP, which is able to discriminate the information derived from spatial inter-chromatic texture patterns of different spectral channels within a region. It determines the relationship in terms of the intensity and directional information between the referenced pixels and their oppugnant neighbors. The \{LOCTP\} strives to use the harmonized link between color and texture, which helps the system to incorporate the human perception. The experimental analysis of the proposed method is done with state-of-art techniques by using standard image databases Brodatz texture database (DB1) and Corel database (DB2). Also, the evaluation has been done in various color models like YCbCr, HSV, Lab, and RGB. In addition, a feature-level fusion framework is used to combine the Colored Pattern Appearance Model (CPAM) and the \{LOCTP\} for getting better result in natural images. The experimental results show considerable improvement in terms of average precision, average recall and average retrieval rate when compared with the previous works. "} 
}
@article{Roberts2014124,
title = {"Strategic retrieval processing and the impact of knowing when a memory was first created "},
journal = {"Brain and Cognition "},
volume = {"86"},
number = {""},
pages = {"124 - 130"},
year = {"2014"},
note = {""},
issn = {"0278-2626"},
doi = {"https://doi.org/10.1016/j.bandc.2014.02.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0278262614000311"},
author = {"J.S. Roberts and D. Tsivilis and A.R. Mayes"},
keywords = {"Recognition memory", "Retention interval", "Event related potentials (ERPs)", "Retrieval orientation "},
abstract = {"Abstract Retrieval orientation refers to a process where participants strategically alter how a memory cue is processed in response to different task demands. In the present study we explored whether retrieval orientation is influenced by knowing when an old stimulus was first encoded. Participants completed separate remember/know test blocks for old items from a recent delay (40 min) and old items from a remote delay (48 h). Manipulations at encoding ensured that performance levels were matched between these two blocks, thus avoiding confounds with differences in retrieval effort. Importantly, a third test block comprised old items from both delays randomly intermixed. As the nature of the old items varies unpredictably in the mixed block, it should not be possibly to adopt a specific retrieval orientation and the mixed block therefore acts as a control condition. Participants saw the words “mixed,” “recent” or “remote” prior to each test block. Comparing \{ERPs\} from the recent and remote blocks permitted an investigation of whether participants alter their retrieval orientation in response to the specific length of the retention interval. Comparing \{ERPs\} from the pure (recent and remote) test blocks to \{ERPs\} from the mixed block permitted an investigation of whether delay information per se led to differences in retrieval strategy. Analysis of the \{ERP\} data found no differences between the recent and remote blocks. However, \{ERPs\} from these pure blocks were significantly less positive than \{ERPs\} from the mixed block from 200 ms towards the end of the epoch. The findings suggest that the delay information was useful in a general sense and encouraged retrieval strategies distinct from those engaged in the mixed block. We speculate that such strategies might relate to whether or not the retrieval search is specific and constrained and/or whether processes that serve to reinstate the original encoding context are engaged. "} 
}
@article{Ding2017,
title = {"Large-scale image retrieval with Sparse Embedded Hashing "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2017.01.055"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217301601"},
author = {"Guiguang Ding and Jile Zhou and Yuchen Guo and Zijia Lin and Sicheng Zhao and Jungong Han"},
keywords = {"Hashing", "Sparse coding", "Matrix factorization "},
abstract = {"Abstract In this paper, we present a novel sparsity-based hashing framework termed Sparse Embedded Hashing (SEH), exploring the technique of sparse coding. Unlike most of the existing systems that focus on finding either a better sparse representation in hash space or an optimal solution to preserve the pairwise similarity of the original data, we intend to solve these two problems in one goal. More specifically, \{SEH\} firstly generates sparse representations in a data-driven way, and then learns a projection matrix, taking sparse representing, affinity preserving and linear embedding into account. In order to make the learned compact features locality sensitive, \{SEH\} employs the matrix factorization technique to approximate the Euclidean structures of the original data. The usage of the matrix factorization enables the decomposed matrix to be constructed from either visual or textual features depending on which kind of Euclidean structure is preserved. Due to this flexibility, our \{SEH\} framework could handle both single-modal retrieval and cross-modal retrieval simultaneously. Experimental evidence shows this method achieves much better performance in both single- and cross-modal retrieval tasks as compared to state-of-the-art approaches. "} 
}
@article{Yang2014192,
title = {"Multi-Query Parallel Field Ranking for image retrieval "},
journal = {"Neurocomputing "},
volume = {"135"},
number = {""},
pages = {"192 - 202"},
year = {"2014"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2013.12.033"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231214000514"},
author = {"Ji Yang and Bin Xu and Binbin Lin and Xiaofei He"},
keywords = {"Image retrieval", "Parallel vector field", "Multi-query "},
abstract = {"Abstract Relevance feedback image retrieval is an effective scheme bridging the gap between low-level features and high-level concepts. It is essentially a multi-query ranking problem where the user submitted image and provided positive examples are considered as queries. Most of the existing approaches either merge the multiple queries into a single query or consider them independently, and then the geodesic distances on the image manifold are used to measure the similarities between the query image and the other images in database. In this paper, we propose a novel approach called Multi-Query Parallel Field Ranking (MQPFR) which finds an optimal ranking function whose gradient field is as parallel as possible. In this way, the obtained ranking function varies linearly along the geodesics of the data manifold, and achieves the highest value at the multiple queries simultaneously. Extensive experiments are carried out on a large image database and demonstrate the effectiveness of the proposed approach. "} 
}
@article{Tsai2014127,
title = {"Rotation-invariant texture image retrieval using particle swarm optimization and support vector regression "},
journal = {"Applied Soft Computing "},
volume = {"17"},
number = {""},
pages = {"127 - 139"},
year = {"2014"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2013.12.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494613004225"},
author = {"Hung-Hsu Tsai and Bae-Muu Chang and Shin-Hung Liou"},
keywords = {"Content-based image retrieval", "Log-polar mapping", "Fast Fourier transform", "Zernike moment", "Particle swarm optimization", "Support vector regression "},
abstract = {"Abstract This paper presents a novel rotation-invariant texture image retrieval using particle swarm optimization (PSO) and support vector regression (SVR), which is called the \{RTIRPS\} method. It respectively employs log-polar mapping (LPM) combined with fast Fourier transformation (FFT), Gabor filter, and Zernike moment to extract three kinds of rotation-invariant features from gray-level images. Subsequently, the \{PSO\} algorithm is utilized to optimize the \{RTIRPS\} method. Experimental results demonstrate that the \{RTIRPS\} method can achieve satisfying results and outperform the existing well-known rotation-invariant image retrieval methods under considerations here. Also, in order to reduce calculation complexity for image feature matching, the \{RTIRPS\} method employs the \{SVR\} to construct an efficient scheme for the image retrieval. "} 
}
@article{Toepper2014157,
title = {"The impact of age on prefrontal cortex integrity during spatial working memory retrieval "},
journal = {"Neuropsychologia "},
volume = {"59"},
number = {""},
pages = {"157 - 168"},
year = {"2014"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2014.04.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393214001481"},
author = {"Max Toepper and Hans J. Markowitsch and Helge Gebhardt and Thomas Beblo and Eva Bauer and Friedrich G. Woermann and Martin Driessen and Gebhard Sammer"},
keywords = {"Aging", "Working memory", "Retrieval", "Dorsolateral prefrontal cortex", "Functional connectivity", "Cognitive control "},
abstract = {"Abstract Healthy aging is accompanied by a decline in spatial working memory that is related to functional cerebral changes within the spatial working memory network. In the last decade, important findings were presented concerning the location (e.g., prefrontal), kind (e.g., ‘underactivation,’ ‘overactivation’), and meaning (e.g., functional deficits, compensation) of these changes. Less is known about how functional connections between specific brain regions are affected by age and how these changes are related to behavioral performance. To address these issues, we used functional magnetic resonance imaging to examine retrieval-related brain activation and functional connectivity in 18 younger individuals and 18 older individuals. We assessed working memory with a modified version of the Corsi Block-Tapping test, which requires the storage and reproduction of spatial target sequences. Analyses of group differences in brain activation and functional connectivity included comparisons between younger individuals, older individuals, older high-performers, and older low-performers. In addition, we conducted a functional connectivity analysis by using a seed region approach. In comparison to younger individuals, older individuals showed lower right-hemispheric dorsolateral prefrontal activation and lower functional connectivity between the right dorsolateral prefrontal cortex and the bilateral orbitofrontal cortex. Older high-performers showed higher right dorsolateral and anterior prefrontal cortex activation than older low-performers, as well as higher functional connectivity between these brain regions. The present results suggest age-related reductions of prefrontal activation during spatial working memory retrieval. Moreover, task-related functional connectivity appears to be lower in older adults. Performance accuracy in older adults is associated with right dorsolateral and anterior prefrontal cortex activation, and with the functional connection between these regions. "} 
}
@article{CostaPereira2014123,
title = {"Cross-modal domain adaptation for text-based regularization of image semantics in image retrieval systems "},
journal = {"Computer Vision and Image Understanding "},
volume = {"124"},
number = {""},
pages = {"123 - 135"},
year = {"2014"},
note = {"Large Scale Multimedia Semantic Indexing "},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2014.03.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S107731421400054X"},
author = {"Jose Costa Pereira and Nuno Vasconcelos"},
keywords = {"Content-based image retrieval", "Query-by-example", "Domain adaptation", "Semantic representation", "Cross-modal regularization", "Class-specific regularization "},
abstract = {"Abstract In query-by-semantic-example image retrieval, images are ranked by similarity of semantic descriptors. These descriptors are obtained by classifying each image with respect to a pre-defined vocabulary of semantic concepts. In this work, we consider the problem of improving the accuracy of semantic descriptors through cross-modal regularization, based on auxiliary text. A cross-modal regularizer, composed of three steps, is proposed. Training images and text are first mapped to a common semantic space. A regularization operator is then learned for each concept in the semantic vocabulary. This is an operator which maps the semantic descriptors of images labeled with that concept to the descriptors of the associated texts. A convex formulation of the learning problem is introduced, enabling the efficient computation of concept-specific regularization operators. The third step is the selection of the most suitable operator for the image to regularize. This is implemented through a quantization of the semantic space, where a regularization operator is associated with each quantization cell. Overall, the proposed regularizer is a non-linear mapping, implemented as a piecewise linear transformation of the semantic image descriptors to regularize. This transformation is a form of cross-modal domain adaptation. It is shown to achieve better performance than recent proposals in the domain adaptation literature, while requiring much simpler optimization. "} 
}
@article{Li2017,
title = {"SPA: Spatially Pooled Attributes for image retrieval "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.10.074"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217301479"},
author = {"Jun Li and Chang Xu and Wankou Yang and Changyin Sun"},
keywords = {"Semantic gap", "Attribute embedding", "Local spatial cues", "Classemes attribute vector", "Spatially Pooled Attributes (SPA) "},
abstract = {"Abstract Semantic gap, which refers to the limitation that low-level hand-crafted visual features insufficiently encode high-level semantic concepts contained in the images, has been a challenging issue in image retrieval and significantly impairs the performance of real-world retrieval systems. Despite massive efforts that have been devoted to developing effective image signatures, e.g., Bag-of-Visual-Words (BOVW), the Fisher Vector (FV) and the Vector of Locally Aggregated Descriptors (VLAD), these mid-level image features still fail to handle the problem of semantic gap and thus lead to suboptimal results. Towards this end, a large body of work focuses on introducing attribute learning into a variety of vision applications. As inherent nature that describes the intrinsic properties of objects, such as color, shape and rigidity, learned attributes serve as intermediate representations that bridge the semantic gap. However, conventional attribute embedding methods are generally developed for image global representation while ignoring local spatial cues, which prevents them from achieving desirable performance. In this paper, we attempt to encode weak spatial information into attribute embedding for effective image retrieval. Specifically, we partition the image into regular grids and extract Classemes attribute vector from each patch, which results in a large pool of Classemes descriptors followed by \{VLAD\} aggregation for generating holistic representation. In order to produce a compact and discriminative code, we employ a piecewise Fisher Discriminant Analysis (FDA) for dimension reduction and concatenate all the compressed Classemes into a single vector coined Spatially Pooled Attributes (SPA). Thorough experimental evaluation and comparative study on three public benchmarks demonstrate the superiority of the proposed approach. "} 
}
@article{Wang2017132,
title = {"Dust aerosol impact on the retrieval of cloud top height from satellite observations of CALIPSO, CloudSat and \{MODIS\} "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"188"},
number = {""},
pages = {"132 - 141"},
year = {"2017"},
note = {"Advances in Atmospheric Light Scattering: Theory and Remote Sensing Techniques "},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.03.034"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316300097"},
author = {"Wencai Wang and Lifang Sheng and Xu Dong and Wenjun Qu and Jilin Sun and Hongchun Jin and Timothy Logan"},
keywords = {"Dust", "Cloud top height", "Satellite "},
abstract = {"Abstract Dust aerosol effect on the retrievals of dusty cloud top height (DCTH) are analyzed over Northwest China using cloud products from \{MODerate\} Resolution Imaging Spectroradiometer (MODIS) on Aqua, Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observations (CALIPSO), and CloudSat for the Spring season of March–May over the years 2007–2011. An excellent agreement is found between CloudSat and \{CALIPSO\} derived \{DCTHs\} for all cloud types, suggesting that the effect of dust aerosols plays a small role in \{DCTHs\} determination for lidar and radar measurements. However, the presence of dust aerosols greatly affects the retrievals of \{DCTHs\} for \{MODIS\} compared with pure clouds and the active sensors derived results. The differences of \{DCTHs\} retrieving from CloudSat and \{MODIS\} range from −2.30 to 6.8 km. Likewise, the differences of \{DCTHs\} retrieving from \{CALIPSO\} and \{MODIS\} range from −2.66 to 6.78 km. In addition, the results show that the differences in \{DCTHs\} for active and passive sensors are dependent on cloud type. On the whole, dust aerosols have the largest effect on cloud top heights (CTH) retrieved of nimbostratus (Ns), followed by altocumulus (Ac) and altostratus (As), the last is cirrus (Ci) over Northwest China. Our results also indicate that the accuracy of MODIS-derived retrievals reduces accompanied with a decrease of height. "} 
}
@article{FernándezAltuna201675,
title = {"Encontrar sin perderse: ¿se ha frustrado al buscar la información médica que necesita? "},
journal = {"Investigación en Educación Médica "},
volume = {"5"},
number = {"18"},
pages = {"75 - 87"},
year = {"2016"},
note = {""},
issn = {"2007-5057"},
doi = {"https://doi.org/10.1016/j.riem.2015.10.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S2007505715000770"},
author = {"María de los Ángeles Fernández-Altuna and Alejandra Martínez del Prado and Diego Gutiérrez Rayón and Elizabeth Arriarán Rodríguez and Héctor Armando Toriz Castillo and Miguel Betancourt Cravioto and Alberto Lifshitz Guinzberg"},
keywords = {"Estrategias de búsqueda", "Recuperación de información", "Fuentes de información electrónicas, keywords =nformación médica", "Biblioteca Médica Digital Universidad Nacional Autónoma de México", "Search strategies", "Information retrieval", "Electronic information resources", "Medical information", "Universidad Nacional Autónoma de México Medical Digital Library "},
abstract = {"AbstractIntroduction Access to information is no longer a problem as medical students search for information online. However, it is becoming harder to find relevant information due to the wide range of available electronic information resources (EIR). The Universidad Nacional Autónoma de México (UNAM) School of Medicine academic community has valuable electronic information resources in its Digital Medical Library (DML), but daily experience suggests it is not used in its full potential. Objectives To identify the most relevant \{EIR\} in UNAM's libraries and their access routes, especially the DML, to apply information search strategies through an example for efficient retrieval of information, and to help educate the academic community of the School of Medicine on the usefulness of resources available in their DML. Method A general overview of the UNAM's \{EIR\} was written. Some proposals for information search strategies were reviewed and implemented using the available \{EIR\} of the DML. Results were analysed to determine which strategies were better, according to their usefulness and relevance. Results Through a successful search strategy, it was possible to obtain reduced (and therefore more manageable) units of specific material. Through the DML, between 85 and 100% of the material was obtained in full text. In some cases all the material was relevant to the topic (PubMed), and in others the majority was not (Scopus and Dynamed). The same search strategy in some of the resources of the \{DML\} threw up a large number of results. “Advanced searches” were used to refine the results. Not all filtered results were relevant to the research topic. Some resources of the \{DML\} handle material that was useful for some researchers. Some resources translated the keywords automatically from Spanish to English. Conclusions Knowing and using search strategies can lead to an effective retrieval of information to be performed, thereby avoided getting lost in the sea of information available, contributing to develop information skills and allowing better decisions to be made. The information in the \{DML\} is very valuable. Effective strategies for search and recovery are recommended, to be used by the community of the \{UNAM\} School of Medicine. "} 
}
@article{GuimarãesPedronette201491,
title = {"A scalable re-ranking method for content-based image retrieval "},
journal = {"Information Sciences "},
volume = {"265"},
number = {""},
pages = {"91 - 104"},
year = {"2014"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2013.12.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025513008864"},
author = {"Daniel Carlos Guimarães Pedronette and Jurandy Almeida and Ricardo da S. Torres"},
keywords = {"Content-based image retrieval", "Re-ranking methods", "Indexing structures "},
abstract = {"Abstract Content-based Image Retrieval (CBIR) systems consider only a pairwise analysis, i.e., they measure the similarity between pairs of images, ignoring the rich information encoded in the relations among several images. However, the user perception usually considers the query specification and responses in a given context. In this scenario, re-ranking methods have been proposed to exploit the contextual information and, hence, improve the effectiveness of \{CBIR\} systems. Besides the effectiveness, the usefulness of those systems in real-world applications also depends on the efficiency and scalability of the retrieval process, imposing a great challenge to the re-ranking approaches, once they usually require the computation of distances among all the images of a given collection. In this paper, we present a novel approach for the re-ranking problem. It relies on the similarity of top-k lists produced by efficient indexing structures, instead of using distance information from the entire collection. Extensive experiments were conducted on a large image collection, using several indexing structures. Results from a rigorous experimental protocol show that the proposed method can obtain significant effectiveness gains (up to 12.19% better) and, at the same time, improve considerably the efficiency (up to 73.11% faster). In addition, our technique scales up very well, which makes it suitable for large collections. "} 
}
@article{Tian2014530,
title = {"Feature integration of \{EODH\} and Color-SIFT: Application to image retrieval based on codebook "},
journal = {"Signal Processing: Image Communication "},
volume = {"29"},
number = {"4"},
pages = {"530 - 545"},
year = {"2014"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2014.01.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596514000320"},
author = {"Xiaolin Tian and Licheng Jiao and Xianlong Liu and Xiaohua Zhang"},
keywords = {"Image retrieval", "Edge orientation difference histogram (EODH) descriptor", "Color-SIFT", "Codebook", "Weighted codeword distribution "},
abstract = {"Abstract This paper proposes a new feature descriptor, edge orientation difference histogram (EODH) descriptor, which is a rotation-invariant and scale-invariant feature representation. The main orientation of each edge pixel is obtained through steerable filter and vector sum. Based on the main orientation, we construct the \{EODH\} descriptor for each edge pixel. Finally, we integrate the \{EODH\} and Color-SIFT descriptor, and build an effective image retrieval system based on weighted codeword distribution using the integrated feature descriptor. Experiments show that the codebook-based image retrieval method achieves the best performance on the given benchmark problems comparing to the state-of-the-art methods. "} 
}
@article{Li201457,
title = {"A comparison of methods for sketch-based 3D shape retrieval "},
journal = {"Computer Vision and Image Understanding "},
volume = {"119"},
number = {""},
pages = {"57 - 80"},
year = {"2014"},
note = {""},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2013.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314213002282"},
author = {"Bo Li and Yijuan Lu and Afzal Godil and Tobias Schreck and Benjamin Bustos and Alfredo Ferreira and Takahiko Furuya and Manuel J. Fonseca and Henry Johan and Takahiro Matsuda and Ryutarou Ohbuchi and Pedro B. Pascoal and Jose M. Saavedra"},
keywords = {"Sketch-based 3D model retrieval", "Evaluation", "SHREC contest", "Large-scale", "Benchmark "},
abstract = {"Abstract Sketch-based 3D shape retrieval has become an important research topic in content-based 3D object retrieval. To foster this research area, two Shape Retrieval Contest (SHREC) tracks on this topic have been organized by us in 2012 and 2013 based on a small-scale and large-scale benchmarks, respectively. Six and five (nine in total) distinct sketch-based 3D shape retrieval methods have competed each other in these two contests, respectively. To measure and compare the performance of the top participating and other existing promising sketch-based 3D shape retrieval methods and solicit the state-of-the-art approaches, we perform a more comprehensive comparison of fifteen best (four top participating algorithms and eleven additional state-of-the-art methods) retrieval methods by completing the evaluation of each method on both benchmarks. The benchmarks, results, and evaluation tools for the two tracks are publicly available on our websites [1,2]. "} 
}
@article{Gupta2017996,
title = {"Soil moisture retrieval using ground based bistatic scatterometer data at X-band "},
journal = {"Advances in Space Research "},
volume = {"59"},
number = {"4"},
pages = {"996 - 1007"},
year = {"2017"},
note = {""},
issn = {"0273-1177"},
doi = {"https://doi.org/10.1016/j.asr.2016.11.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S0273117716306755"},
author = {"Dileep Kumar Gupta and Rajendra Prasad and Pradeep Kumar and Ajeet Kumar Vishwakarma"},
keywords = {"Soil moisture", "Microwave remote sensing", "BPANN", "RBFANN", "GRANN", "Regression analysis "},
abstract = {"Abstract Several hydrological phenomenon and applications need high quality soil moisture information of the top Earth surface. The advent of technologies like bistatic scatterometer can retrieve soil moisture information with high accuracy and hence used in present study. The radar data is acquired by specially designed ground based bistatic scatterometer system in the specular direction of 20–70° incidence angles at steps of 5° for \{HH\} and \{VV\} polarizations. This study provides first time comprehensive evaluation of different machine learning algorithms for the retrieval of soil moisture using the X-band bistatic scatterometer measurements. The comparison of different artificial neural network (ANN) models such as back propagation artificial neural network (BPANN), radial basis function artificial neural network (RBFANN), generalized regression artificial neural network (GRANN) along with linear regression model (LRM) are used to estimate the soil moisture. The performance indices such as %Bias, Root Mean Squared Error (RMSE) and Nash-Sutcliffe Efficiency (NSE) are used to evaluate the performances of the machine learning techniques. Among different models employed in this study, the \{BPANN\} is found to have marginally higher performance in case of \{HH\} polarization while \{RBFANN\} is found suitable with \{VV\} polarization followed by \{GRANN\} and LRM. The results obtained are of considerable scientific and practical value to the wider scientific community for the number of practical applications and research studies in which radar datasets are used. "} 
}
@article{Bandeira2014106,
title = {"Saving phase: Injectivity and stability for phase retrieval "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"37"},
number = {"1"},
pages = {"106 - 125"},
year = {"2014"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2013.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520313000936"},
author = {"Afonso S. Bandeira and Jameson Cahill and Dustin G. Mixon and Aaron A. Nelson"},
keywords = {"Phase retrieval", "Quantum mechanics", "Bilipschitz function", "Cramer–Rao lower bound "},
abstract = {"Abstract Recent advances in convex optimization have led to new strides in the phase retrieval problem over finite-dimensional vector spaces. However, certain fundamental questions remain: What sorts of measurement vectors uniquely determine every signal up to a global phase factor, and how many are needed to do so? Furthermore, which measurement ensembles yield stability? This paper presents several results that address each of these questions. We begin by characterizing injectivity, and we identify that the complement property is indeed a necessary condition in the complex case. We then pose a conjecture that 4 M − 4 generic measurement vectors are both necessary and sufficient for injectivity in M dimensions, and we prove this conjecture in the special cases where M = 2 , 3 . Next, we shift our attention to stability, both in the worst and average cases. Here, we characterize worst-case stability in the real case by introducing a numerical version of the complement property. This new property bears some resemblance to the restricted isometry property of compressed sensing and can be used to derive a sharp lower Lipschitz bound on the intensity measurement mapping. Localized frames are shown to lack this property (suggesting instability), whereas Gaussian random measurements are shown to satisfy this property with high probability. We conclude by presenting results that use a stochastic noise model in both the real and complex cases, and we leverage Cramer–Rao lower bounds to identify stability with stronger versions of the injectivity characterizations. "} 
}
@article{Schönfeld2014249,
title = {"Remembering under stress: Different roles of autonomic arousal and glucocorticoids in memory retrieval "},
journal = {"Psychoneuroendocrinology "},
volume = {"39"},
number = {""},
pages = {"249 - 256"},
year = {"2014"},
note = {""},
issn = {"0306-4530"},
doi = {"https://doi.org/10.1016/j.psyneuen.2013.09.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306453013003399"},
author = {"Pia Schönfeld and Karina Ackermann and Lars Schwabe"},
keywords = {"Stress", "Cortisol", "Noradrenaline", "Autonomic arousal", "Memory", "Memory retrieval "},
abstract = {"Abstract It is commonly assumed that stress impairs memory retrieval. Glucocorticoids, released with a delay of several minutes in response to stressful experiences, are thought to play a key role in the stress-induced retrieval impairment. Accordingly, most studies on the impact of stress on retrieval tested memory a considerable time after stressor exposure, when glucocorticoid levels were elevated. Here, we asked how stress affects memory when retrieval takes place under stress, that is, when stress is part of the retrieval situation and glucocorticoids are not yet increased at the time of testing. To contrast stress effects on ongoing and delayed memory retrieval, 72 participants learned first neutral and emotional material. Twenty-four hours later, half of the learned material was tested either in a stressful, oral examination-like testing situation or in a standard, non-stressful free recall test. Memory for the other half of the learned material was assessed 25 min after the first, stressful or non-stressful retention test. Significant increases in blood pressure and salivary cortisol confirmed the stress induction by the first, examination-like testing situation. Retrieval performance under stress was positively correlated with the blood pressure response to the stressor but unaffected by cortisol. Conversely, retrieval performance 25 min post stress was negatively correlated with the cortisol response to the stressor, particularly for emotional items. These results suggest that the same stressor may have opposite effects on ongoing and delayed memory retrieval, depending on the presence of autonomic arousal and glucocorticoids. "} 
}
@article{Wu2017,
title = {"Deep binary codes for large scale image retrieval "},
journal = {"Neurocomputing "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.12.070"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231217301455"},
author = {"Song Wu and Ard Oerlemans and Erwin M. Bakker and Michael S. Lew"},
keywords = {"Convolutional neural network", "Deep binary codes", "Late fusion", "Large scale image search "},
abstract = {"Abstract Recent studies have shown that image representations built upon deep convolutional layers in Convolutional Neural Networks (CNNs) have strong discriminative characteristics. In this paper, we present a novel and effective method to create compact binary codes (deep binary codes) based on deep convolutional features for image retrieval. Deep binary codes are generated by comparing the response from each feature map and the average response across all the feature maps on the deep convolutional layers. Additionally, a spatial cross-summing strategy is proposed to directly generate bit-scalable binary codes. As the deep binary codes on different deep layers can be obtained by passing the image through the \{CNN\} and each of them makes a different contribution to the search accuracy, we then present a dynamic, on-the-fly late fusion approach where the top N high quality search scores from deep binary codes are automatically determined online and fused to further enhance the retrieval precision. Two strengths of the proposed methods are that the generation of deep binary codes is based on a generic model, which does not require additional training for new image domains, and that the dynamic late fusion scheme is query adaptive. Extensive experimental results on well known benchmarks show that the performance of deep binary codes are competitive with state-of-the-art approaches for large scale image retrieval. Moreover, it is shown that the dynamic late fusion scheme significantly enhances the search accuracy. "} 
}
@article{Chen20141349,
title = {"Ranking consistency for image matching and object retrieval "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"3"},
pages = {"1349 - 1360"},
year = {"2014"},
note = {"Handwriting Recognition and other \{PR\} Applications "},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2013.09.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S003132031300383X"},
author = {"Yanzhi Chen and Xi Li and Anthony Dick and Rhys Hill"},
keywords = {"Ranking consistency", "Image matching", "Object retrieval", "List-wise min-Hash "},
abstract = {"Abstract The goal of object retrieval is to rank a set of images by the similarity of their contents to those of a query image. However, it is difficult to measure image content similarity due to visual changes caused by varying viewpoint and environment. In this paper, we propose a simple, efficient method to more effectively measure content similarity from image measurements. Our method is based on the ranking information available from existing retrieval systems. We observe that images within the set which, when used as queries, yield similar ranking lists are likely to be relevant to each other and vice versa. In our method, ranking consistency is used as a verification method to efficiently refine an existing ranking list, in much the same fashion that spatial verification is employed. The efficiency of our method is achieved by a list-wise min-Hash scheme, which allows rapid calculation of an approximate similarity ranking. Experimental results demonstrate the effectiveness of the proposed framework and its applications. "} 
}
@article{Hu20141138,
title = {"Latent topic model for audio retrieval "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"3"},
pages = {"1138 - 1143"},
year = {"2014"},
note = {"Handwriting Recognition and other \{PR\} Applications "},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2013.06.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320313002628"},
author = {"Pengfei Hu and Wenju Liu and Wei Jiang and Zhanlei Yang"},
keywords = {"Topic model", "LDA", "Gaussian distribution", "Audio retrieval "},
abstract = {"Abstract Latent topic model such as Latent Dirichlet Allocation (LDA) has been designed for text processing and has also demonstrated success in the task of audio related processing. The main idea behind \{LDA\} assumes that the words of each document arise from a mixture of topics, each of which is a multinomial distribution over the vocabulary. When applying the original \{LDA\} to process continuous data, the word-like unit need be first generated by vector quantization (VQ). This data discretization usually results in information loss. To overcome this shortage, this paper introduces a new topic model named Gaussian-LDA for audio retrieval. In the proposed model, we consider continuous emission probability, Gaussian instead of multinomial distribution. This new topic model skips the vector quantization and directly models each topic as a Gaussian distribution over audio features. It avoids discretization by this way and integrates the procedure of clustering. The experiments of audio retrieval demonstrate that Gaussian-LDA achieves better performance than other compared methods. "} 
}
@article{VanWittenberghe201437,
title = {"Gaussian processes retrieval of leaf parameters from a multi-species reflectance, absorbance and fluorescence dataset "},
journal = {"Journal of Photochemistry and Photobiology B: Biology "},
volume = {"134"},
number = {""},
pages = {"37 - 48"},
year = {"2014"},
note = {""},
issn = {"1011-1344"},
doi = {"https://doi.org/10.1016/j.jphotobiol.2014.03.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1011134414000840"},
author = {"Shari Van Wittenberghe and Jochem Verrelst and Juan Pablo Rivera and Luis Alonso and José Moreno and Roeland Samson"},
keywords = {"Machine learning algorithm", "Spectral features", "Hyperspectral", "Parameter retrieval", "Chlorophyll", "Leaf structure", "Specific leaf area", "Leaf water content "},
abstract = {"Abstract Biochemical and structural leaf properties such as chlorophyll content (Chl), nitrogen content (N), leaf water content (LWC), and specific leaf area (SLA) have the benefit to be estimated through nondestructive spectral measurements. Current practices, however, mainly focus on a limited amount of wavelength bands while more information could be extracted from other wavelengths in the full range (400–2500 nm) spectrum. In this research, leaf characteristics were estimated from a field-based multi-species dataset, covering a wide range in leaf structures and Chl concentrations. The dataset contains leaves with extremely high Chl concentrations (&gt;100 μg cm−2), which are seldom estimated. Parameter retrieval was conducted with the machine learning regression algorithm Gaussian Processes (GP), which is able to perform adaptive, nonlinear data fitting for complex datasets. Moreover, insight in relevant bands is provided during the development of a regression model. Consequently, the physical meaning of the model can be explored. Best estimates of SLA, \{LWC\} and Chl yielded a best obtained normalized root mean square error of 6.0%, 7.7%, 9.1%, respectively. Several distinct wavebands were chosen across the whole spectrum. A band in the red edge (710 nm) appeared to be most important for the estimation of Chl. Interestingly, spectral features related to biochemicals with a structural or carbon storage function (e.g. 1090, 1550, 1670, 1730 nm) were found important not only for estimation of SLA, but also for LWC, Chl or N estimation. Similar, Chl estimation was also helped by some wavebands related to water content (950, 1430 nm) due to correlation between the parameters. It is shown that leaf parameter retrieval by \{GP\} regression is successful, and able to cope with large structural differences between leaves. "} 
}
@article{He20141337,
title = {"Synergetic retrieval of terrestrial \{AOD\} from \{MODIS\} images of twin satellites Terra and Aqua "},
journal = {"Advances in Space Research "},
volume = {"53"},
number = {"9"},
pages = {"1337 - 1346"},
year = {"2014"},
note = {""},
issn = {"0273-1177"},
doi = {"https://doi.org/10.1016/j.asr.2014.02.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0273117714001343"},
author = {"Junliang He and Yong Zha and Jiahua Zhang and Jay Gao and Qiang Wang"},
keywords = {"AOD", "Synergetic retrieval", "MODIS", "AERONET", "Taihu Lake "},
abstract = {"Abstract Aerosol optical depth (AOD) is one of the most important indicators of atmospheric pollution. It can be retrieved from satellite imagery using several established methods, such as the dark dense vegetation method and the deep blue algorithm. All of these methods require estimation of surface reflectance prior to retrieval, and are applicable to a certain pre-designated type of surface cover. Such limitations can be overcome by using a synergetic method of retrieval proposed in this study. This innovative method is based on the fact that the ratio K of surface reflectance at different angles/geometries is independent of wavelength as reported by Flowerdew and Haigh (1995). An atmospheric radiative transfer model was then established and resolved with the assistance of the ratio K obtained from two Moderate Resolution Imaging Spectroradiometer (MODIS) spectral bands acquired from the twin satellites of Terra and Aqua whose overpass is separated by three hours. This synergetic method of retrieval was tested with 20 pairs of \{MODIS\} images. The retrieved \{AOD\} was validated against the ground observed \{AOD\} at the Taihu station of the \{AErosol\} \{RObotic\} \{NETwork\} (AERONET). It is found that they are correlated with the observations at a coefficient of 0.828 at 0.47 μm and 0.921 at 0.66 μm wavelengths. The retrieved \{AOD\} has a mean relative error of 25.47% at 0.47 μm and 24.3% at 0.66 μm. Of the 20 samples, 15 and 17 fall within two standard error of the line based observed \{AOD\} data on the ground at the 0.47 μm and 0.66 μm, respectively. These results indicate that this synergetic method can be used to reliably retrieve \{AOD\} from the twin satellites \{MODIS\} images, namely Terra and Aqua. It is not necessary to determine surface reflectance first. "} 
}
@article{Xu201762,
title = {"Age invariant face recognition and retrieval by coupled auto-encoder networks "},
journal = {"Neurocomputing "},
volume = {"222"},
number = {""},
pages = {"62 - 71"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.10.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216311729"},
author = {"Chenfei Xu and Qihe Liu and Mao Ye"},
keywords = {"Face recognition", "Age invariant", "Auto-encoder "},
abstract = {"Abstract Recently many promising results have been shown on face recognition related problems. However, age-invariant face recognition and retrieval remains a challenge. Inspired by the observation that age variation is a nonlinear but smooth transform and the ability of auto-encoder network to learn latent representations from inputs, in this paper, we propose a new neural network model called coupled auto-encoder networks (CAN) to handle age-invariant face recognition and retrieval problem. \{CAN\} is a couple of two auto-encoders which bridged by two shallow neural networks used to fit complex nonlinear aging and de-aging process. We further propose a nonlinear factor analysis method to nonlinearly decompose one given face image into three components which are identity feature, age feature and noise, where identity feature is age-invariant and can be used for face recognition and retrieval. Experiments on three public available face aging datasets: FGNET, \{CACD\} and CACD-VS show the effectiveness of the proposed approach. "} 
}
@article{Simon201742,
title = {"A quality improvement project to improve inferior vena cava filter retrieval "},
journal = {"Journal of Vascular Surgery: Venous and Lymphatic Disorders "},
volume = {"5"},
number = {"1"},
pages = {"42 - 46"},
year = {"2017"},
note = {""},
issn = {"2213-333X"},
doi = {"https://doi.org/10.1016/j.jvsv.2016.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213333X16301780"},
author = {"Todd E. Simon and Patrick F. Walker and Leo J. Daab and Joseph M. White and Paul W. White"},

abstract = {"AbstractObjective Poor retrieval rates for retrievable inferior vena cava filters (R-IVCFs) have been reported throughout the literature, with poor follow-up a common cause. In 2009, we reported a retrieval rate of 18% despite an initial follow-up rate of 85%. Use of a registry has been shown to improve retrieval rates. As a quality improvement project, in May 2012, the vascular surgery fellowship implemented a reiterative registry to track R-IVCFs placed at Walter Reed National Military Medical Center to improve retrieval rates. We report the results in 125 patients after 38 months. Methods Patients receiving an R-IVCF were entered into a registry. All patients were reviewed monthly using an electronic health record. When there was no longer an indication for the R-IVCF, the patient was scheduled for an outpatient appointment with a vascular surgeon followed by retrieval. Rates of retrieval, technical success, dwell time, indication, complications, and demographics were collected. Results There were 125 R-IVCFs placed between May 2012 and June 2015; 52 filters were placed for therapeutic and 73 for prophylactic indications. Our follow-up rate improved to 94%. A total of 79 filters were retrieved (63% absolute retrieval rate). Excluding patients who died before retrieval and patients with a permanent indication, 77% of filters were retrieved. The average dwell time was 101.5 days (7-460 days), and 63% of successful R-IVCF retrievals were within 3 months of placement. Technical success for retrieval was 92%. There were two major complications from retrievals (1.5% of retrievals). Conclusions The creation of an R-IVCF registry promoted ongoing follow-up with patients. In our earlier experience, retrieval rates were poor despite a high follow-up rate. The use of a reiterative registry improved our retrieval rate by 45% and increased our follow-up rate to 94%. These results emphasize the importance of repetitive follow-up for R-IVCFs. Despite a follow-up rate &gt;90%, around a third of R-IVCFs were not retrieved. "} 
}
@article{Tolstaya2016385,
title = {"Review of Information Databases Providing Data on Current Scientific and Technical Achievements "},
journal = {"Procedia Computer Science "},
volume = {"88"},
number = {""},
pages = {"385 - 390"},
year = {"2016"},
note = {"7th Annual International Conference on Biologically Inspired Cognitive Architectures, \{BICA\} 2016, held July 16 to July 19, 2016 in New York City, NY, \{USA\} "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.07.453"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916317094"},
author = {"Anastasia Tolstaya and Irina Suslina and Polina Tolstaya"},
keywords = {"Patent database", "patent research", "patent search", "information retrieval system "},
abstract = {"Abstract This study deals with the information databases providing information on scientific and technical developments that can be used for patent researches. The paper provides the analysis of several patent databases, reveals their main features and assess the completeness of the information provided by various information retrieval resource. Recommendations on the choice of the search databases are given. The results of this research can be useful to carry out a patent research in order to increase the efficiency of commercialization process of the intellectual activity results in bringing the goods into the home and the international market. "} 
}
@article{Lin20143276,
title = {"Fast K-means algorithm based on a level histogram for image retrieval "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"7"},
pages = {"3276 - 3283"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2013.11.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417413009299"},
author = {"Chuen-Horng Lin and Chun-Chieh Chen and Hsin-Lun Lee and Jan-Ray Liao"},
keywords = {"K-means", "Histogram", "Image retrieval", "Color feature "},
abstract = {"Abstract In image retrieval, the image feature is the main factor determining accuracy; the color feature is the most important feature and is most commonly used with a K-means algorithm. To create a fast K-means algorithm for this study, first a level histogram of statistics for the image database is made. The level histogram is used with the K-means algorithm for clustering data. A fast K-means algorithm not only shortens the length of time spent on training the image database cluster centers, but it also overcomes the cluster center re-training problem since large numbers of images are continuously added into the database. For the experiment, we use gray and color image database sets for performance comparisons and analyzes, respectively. The results show that the fast K-means algorithm is more effective, faster, and more convenient than the traditional K-means algorithm. Moreover, it overcomes the problem of spending excessive amounts of time on re-training caused by the continuous addition of images to the image database. Selection of initial cluster centers also affects the performance of cluster center training. "} 
}
@article{Nayak2014676,
title = {"Progesterone level at oocyte retrieval predicts in vitro fertilization success in a short-antagonist protocol: a prospective cohort study "},
journal = {"Fertility and Sterility "},
volume = {"101"},
number = {"3"},
pages = {"676 - 682.e1"},
year = {"2014"},
note = {""},
issn = {"0015-0282"},
doi = {"https://doi.org/10.1016/j.fertnstert.2013.11.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0015028213032822"},
author = {"Shweta Nayak and Melanie E. Ochalski and Bo Fu and Kathryn-Mary Wakim and Tian Jao Chu and Xinxin Dong and Anthony N. Wakim"},
keywords = {"Progesterone level", "oocyte retrieval", "antagonist cycle "},
abstract = {"Objective To evaluate the distribution of P levels on the day of oocyte retrieval as it relates to pregnancy outcome in an antagonist protocol, which may be at higher risk for elevated P levels. Design Prospective cohort study. Setting Academic \{IVF\} center. Patient(s) One hundred eighty-six women undergoing controlled ovarian hyperstimulation with an antagonist protocol. Intervention(s) None. Main Outcome Measure(s) Implantation, pregnancy, and spontaneous abortion rates were collected. Result(s) Implantation rate (positive hCG 14 days after ET) and pregnancy rate were significantly higher when the P level was &lt;12 ng/mL on the day of oocyte retrieval. Miscarriage rates were higher when the P level was ≥12 ng/mL, although this did not reach statistical significance. Conclusion(s) Elevated P on the day of oocyte retrieval is associated with significantly lower implantation and ongoing pregnancy rates. This is the first study to date to both uncover the distribution of P on the day of oocyte retrieval in an antagonist cycle and determine the impact an elevation may have on pregnancy outcome. "} 
}
@article{Montani2014128,
title = {"Retrieval and clustering for supporting business process adjustment and analysis "},
journal = {"Information Systems "},
volume = {"40"},
number = {""},
pages = {"128 - 141"},
year = {"2014"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2012.11.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437912001482"},
author = {"Stefania Montani and Giorgio Leonardi"},
keywords = {"Business process adjustment and analysis", "Case-based retrieval", "Hierarchical clustering", "Temporal constraints "},
abstract = {"In this paper, we describe a framework able to support run-time adjustment and a posteriori analysis of business processes, which exploits the retrieval step of the Case-based Reasoning (CBR) methodology. In particular, our framework allows to retrieve traces of process execution similar to the current one. Moreover, it supports an automatic organization of the trace database content through the application of hierarchical clustering techniques. Results can provide help both to end users, in the process execution phase, and to process engineers, in (formal) process conformance evaluation and long term process schema redesign. Retrieval and clustering rely on a distance definition able to take into account temporal information in traces. This metric has outperformed simpler distance definitions in our experiments, which were conducted in a real-world application domain. "} 
}
@article{Murala2014400,
title = {"\{MRI\} and \{CT\} image indexing and retrieval using local mesh peak valley edge patterns "},
journal = {"Signal Processing: Image Communication "},
volume = {"29"},
number = {"3"},
pages = {"400 - 409"},
year = {"2014"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2013.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596513001872"},
author = {"Subrahmanyam Murala and Q.M. Jonathan Wu"},
keywords = {"Medical imaging", "Image retrieval", "Patterns", "Texture", "Local binary patterns (LBP) "},
abstract = {"Abstract In this paper, a new pattern based feature, local mesh peak valley edge pattern (LMePVEP) is proposed for biomedical image indexing and retrieval. The standard \{LBP\} extracts the gray scale relationship between the center pixel and its surrounding neighbors in an image. Whereas the proposed method extracts the gray scale relationship among the neighbors for a given center pixel in an image. The relations among the neighbors are peak/valley edges which are obtained by performing the first-order derivative. The performance of the proposed method (LMePVEP) is tested by conducting two experiments on two benchmark biomedical databases. Further, it is mentioned that the databases used for experiments are OASIS−MRI database which is the magnetic resonance imaging (MRI) database and VIA/I–ELCAP-CT database which includes region of interest computer tomography (CT) images. The results after being investigated show a significant improvement in terms average retrieval precision (ARP) and average retrieval rate (ARR) as compared to \{LBP\} and \{LBP\} variant features. "} 
}
@article{PamiesJuarez20141,
title = {"On the interplay between data redundancy and retrieval times in \{P2P\} storage systems "},
journal = {"Computer Networks "},
volume = {"59"},
number = {""},
pages = {"1 - 16"},
year = {"2014"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.bjp.2013.12.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128613004088"},
author = {"Lluis Pamies-Juarez and Marc Sanchez-Artigas and Pedro García-López and Rubén Mondéjar and Rahma Chaabouni"},
keywords = {"\{P2P\} storage", "Retrieval times", "Storage codes", "Distributed systems "},
abstract = {"Abstract Peer-to-peer (P2P) storage systems aggregate spare storage resources from end users to build a large collaborative online storage solution. In these systems, however, the high levels of user churn—peers failing or leaving temporarily or permanently—affect the quality of the storage service and might put data reliability on risk. Indeed, one of the main challenge of \{P2P\} storage systems has traditionally been how to guarantee that stored data can always be retrieved within some time frame. To meet this challenge, existing systems store objects with high amounts of data redundancy, rendering data availability values close to 100%, which in turn ensure optimal retrieval times (only constrained by network limits). Unfortunately, this redundancy reduces the overall net capacity of the system and increases data maintenance costs. To alleviate these problems data redundancy can be reduced at the expense of lengthening retrieval times. The problem is that both the rewards and disadvantages of doing so are not well understood. In this paper we present a novel analytical framework that allows us to model retrieval times in \{P2P\} storage systems and describe the interplay between data redundancy and retrieval times for different churn patterns. Using availability traces from real \{P2P\} applications, we show that our framework provides accurate estimation of retrieval times in realistic environments. "} 
}
@article{Cooper2017127,
title = {"Eye movements reveal a dissociation between memory encoding and retrieval in adults with autism "},
journal = {"Cognition "},
volume = {"159"},
number = {""},
pages = {"127 - 138"},
year = {"2017"},
note = {""},
issn = {"0010-0277"},
doi = {"https://doi.org/10.1016/j.cognition.2016.11.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010027716302852"},
author = {"Rose A. Cooper and Kate C. Plaisted-Grant and Simon Baron-Cohen and Jon S. Simons"},
keywords = {"Autism", "Eye-tracking", "Attention", "Recollection", "Encoding "},
abstract = {"Abstract People with Autism Spectrum Disorder (ASD) exhibit subtle deficits in recollection, which have been proposed to arise from encoding impairments, though a direct link has yet to be demonstrated. In the current study, we used eye-tracking to obtain trial-specific measures of encoding (eye movement patterns) during incidental (natural viewing) and intentional (strategic) encoding conditions in adults with \{ASD\} and typical controls. Using this approach, we tested the degree to which differences in encoding might contribute to recollection impairments, or whether group differences in memory primarily emerge at retrieval. Following encoding of scenes, participants were asked to distinguish between old and similar lure scenes and provide ‘remember’/‘familiar’ responses. Intentional encoding increased eye movements and subsequent recollection in both groups to a similar degree, but the \{ASD\} group were impaired overall at the memory task and used recollection less frequently. In controls, eye movements at encoding predicted subsequent correct responses and subsequent recollection on a trial-by-trial basis, as expected. In contrast, despite a similar pattern of eye movements during encoding in the two groups, eye movements did not predict trial-by-trial subsequent memory in ASD. Furthermore, recollection was associated with lower similarity between encoding- and retrieval-related eye movements in the \{ASD\} group compared to the control group. The eye-tracking results therefore provide novel evidence for a dissociation between encoding and recollection-based retrieval in ASD. "} 
}
@article{MichelLombera201456,
title = {"Peer-to-peer publication, search and retrieval using the Android mobile platform "},
journal = {"Computer Networks "},
volume = {"65"},
number = {""},
pages = {"56 - 72"},
year = {"2014"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2014.03.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128614000954"},
author = {"Isaí Michel Lombera and Louise E. Moser and P. Michael Melliar-Smith and Yung-Ting Chuang"},
keywords = {"Peer-to-peer network", "Mobile ad hoc network", "Wi-Fi Direct", "Android mobile platform", "Decentralized publication", "Search and retrieval "},
abstract = {"Abstract In this paper, we present the iTrust over Wi-Fi Direct system, which is a peer-to-peer publication, search and retrieval system for mobile ad hoc networks. We describe the iTrust over Wi-Fi Direct architecture and components, as implemented on the Android platform for mobile devices, and show how user applications can easily interface with iTrust over Wi-Fi Direct. We also describe the iTrust over Wi-Fi Direct networking model, and the interactions with the Android and Linux stacks. In addition, we describe the peer management protocol for iTrust over Wi-Fi Direct on the Android platform, which enables peers to construct a mobile ad hoc network by automatically discovering and connecting peers. We discuss deficiencies of the Android platform for Wi-Fi Direct, and present our solution to address those limitations. Finally, we present a performance evaluation of iTrust over Wi-Fi Direct in terms of the match probabilities without and with message forwarding, the peer management overhead, and the resource transfer latency. "} 
}
@article{Penatti2014705,
title = {"Visual word spatial arrangement for image retrieval and classification "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"2"},
pages = {"705 - 720"},
year = {"2014"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2013.08.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320313003336"},
author = {"Otávio A.B. Penatti and Fernanda B. Silva and Eduardo Valle and Valerie Gouet-Brunet and Ricardo da S. Torres"},
keywords = {"Visual words", "Spatial arrangement", "Image retrieval", "Image classification "},
abstract = {"Abstract We present word spatial arrangement (WSA), an approach to represent the spatial arrangement of visual words under the bag-of-visual-words model. It lies in a simple idea which encodes the relative position of visual words by splitting the image space into quadrants using each detected point as origin. \{WSA\} generates compact feature vectors and is flexible for being used for image retrieval and classification, for working with hard or soft assignment, requiring no pre/post processing for spatial verification. Experiments in the retrieval scenario show the superiority of \{WSA\} in relation to Spatial Pyramids. Experiments in the classification scenario show a reasonable compromise between those methods, with Spatial Pyramids generating larger feature vectors, while \{WSA\} provides adequate performance with much more compact features. As \{WSA\} encodes only the spatial information of visual words and not their frequency of occurrence, the results indicate the importance of such information for visual categorization. "} 
}
@article{AlAwami2017,
title = {"Robust decentralized data storage and retrieval for wireless networks "},
journal = {"Computer Networks "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2017.02.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128617300427"},
author = {"Louai Al-Awami and Hossam S. Hassanein"},
keywords = {"Wireless sensor networks", "Decentralized storage", "Data survivability", "Energy efficiency", "Fountain codes "},
abstract = {"Abstract In this paper we study the problem of distributed data storage using Rateless codes for large-scale resource-constrained wireless networks. We focus on building a robust storage system using Fountain codes from physically decentralized sources. Fountain codes, e.g. LT-codes, can achieve reduced complexity of both encoding and decoding, which caters well to the nature of such networks. We propose an energy-efficient distributed dissemination and coding scheme to build a decentralized LT-codes based storage over a network of resource-limited nodes to provide data survivability against possible failures. In the proposed scheme, each sensor node is assigned a selection probability derived from a Robust Soliton Distribution (RSD) in a distributed fashion. Source nodes then disseminate their data over the storage network randomly, in accordance with the selection probabilities. The proposed scheme is compared to similar schemes in the literature by means of simulations. We evaluate the energy required for building the storage as well as the energy needed for data retrieval from the storage system. Results show that energy consumption can be substantially reduced while achieving the required storage requirements. "} 
}
@incollection{Zhou2014383,
title = {"Chapter 12 - Multimedia Content-Based Visual Retrieval "},
editor = {"Sergios Theodoridis and Rama Chellappa"},
booktitle = {"Academic Press Library in signal ProcessingImage and Video Compression and Multimedia"},
publisher = {"Elsevier"},
year = {"2014"},
volume = {"5"},
pages = {"383 - 416"},
series = {"Academic Press Library in Signal Processing "},
issn = {"2351-9819"},
doi = {"https://doi.org/10.1016/B978-0-12-420149-1.00012-0"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780124201491000120"},
author = {"Wengang Zhou and Houqiang Li and Qi Tian"},
keywords = {"Content-based retrieval", "Feature representation", "Feature matching", "Quantization", "Image index", "Geometric verification", "Hashing "},
abstract = {"Abstract With the ever explosive growth of multimedia visual data on the Web, content-based visual retrieval has been attracting sufficient attention in both the academia and the industry. Based on the pioneering work of invariant local \{SIFT\} feature and the classic Bag-of-Visual-Words model, the last decade has witnessed the fast advance in content-based visual retrieval in the computer vision and multimedia community. The notable characteristic that distinguishes multimedia content-based retrieval from other visual processing problems lies in emphasizing on the scalability to million- or billion-scale database and the query response in real time. Due to the well-known semantic gap problem, most content-based visual retrieval methods target at specific object/scene image retrieval or partial-duplicate Web image retrieval, and great success has been achieved. This chapter investigates the general framework of the multimedia content-based visual retrieval. It overviews the general visual search pipeline and discusses five key modules of the pipeline separately in detail. A series of methods addressing the key issues in each module are introduced. In this chapter, we are focused on discussing the key problems, defining the algorithms, and illustrating the main idea with the goal of scalable retrieval in large-scale image database. "} 
}
@article{Bandara201427,
title = {"Towards soil property retrieval from space: Proof of concept using in situ observations "},
journal = {"Journal of Hydrology "},
volume = {"512"},
number = {""},
pages = {"27 - 38"},
year = {"2014"},
note = {""},
issn = {"0022-1694"},
doi = {"https://doi.org/10.1016/j.jhydrol.2014.02.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022169414001395"},
author = {"Ranmalee Bandara and Jeffrey P. Walker and Christoph Rüdiger"},
keywords = {"Surface soil moisture", "Soil hydraulic parameter retrieval", "JULES", "Land surface modeling "},
abstract = {"Summary Soil moisture is a key variable that controls the exchange of water and energy fluxes between the land surface and the atmosphere. However, the temporal evolution of soil moisture is neither easy to measure nor monitor at large scales because of its high spatial variability. This is mainly a result of the local variation in soil properties and vegetation cover. Thus, land surface models are normally used to predict the evolution of soil moisture and yet, despite their importance, these models are based on low-resolution soil property information or typical values. Therefore, the availability of more accurate and detailed soil parameter data than are currently available is vital, if regional or global soil moisture predictions are to be made with the accuracy required for environmental applications. The proposed solution is to estimate the soil hydraulic properties via model calibration to remotely sensed soil moisture observation, with in situ observations used as a proxy in this proof of concept study. Consequently, the feasibility is assessed, and the level of accuracy that can be expected determined, for soil hydraulic property estimation of duplex soil profiles in a semi-arid environment using near-surface soil moisture observations under naturally occurring conditions. The retrieved soil hydraulic parameters were then assessed by their reliability to predict the root zone soil moisture using the Joint \{UK\} Land Environment Simulator model. When using parameters that were retrieved using soil moisture observations, the root zone soil moisture was predicted to within an accuracy of 0.04 m3/m3, which is an improvement of ∼0.025 m3/m3 on predictions that used published values or pedo-transfer functions. "} 
}
@article{Fan20142526,
title = {"Hybrid similarity measure for case retrieval in \{CBR\} and its application to emergency response towards gas explosion "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"5"},
pages = {"2526 - 2534"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2013.09.051"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417413008051"},
author = {"Zhi-Ping Fan and Yong-Hai Li and Xiaohuan Wang and Yang Liu"},
keywords = {"Case-based reasoning (CBR)", "Case retrieval", "Hybrid similarity", "Attribute value", "Gas explosion", "Emergency response "},
abstract = {"Abstract Case retrieval is a primary step in case-based reasoning (CBR). It is important to measure the similarity between each historical case and the target case during the case retrieval process. In recent years, some methods for similarity measure with multiple formats of attribute values can be found in the practical \{CBR\} applications, but the in-depth study is still lacking. The objective of this paper is to develop a new method for hybrid similarity measure with five formats of attribute values: crisp symbols, crisp numbers, interval numbers, fuzzy linguistic variables and random variables. First, for each format of the attribute values, the calculation formula to measure the attribute similarity is presented. Then, the method for measuring hybrid similarity between each historical case and the target case is given by aggregating attribute similarities using the simple additive weighting method, and the proper historical case(s) can be retrieved according to the obtained hybrid similarities afterwards. Finally, a case study in the field of emergency response towards gas explosion is introduced to illustrate the use of the proposed method. "} 
}
@article{Li2014126,
title = {"The differential hippocampal phosphoproteome of Apodemus sylvaticus paralleling spatial memory retrieval in the Barnes maze "},
journal = {"Behavioural Brain Research "},
volume = {"264"},
number = {""},
pages = {"126 - 134"},
year = {"2014"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2014.01.047"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432814000618"},
author = {"Lin Li and Edina Csaszar and Edit Szodorai and Sudarshan Patil and Arnold Pollak and Gert Lubec"},
keywords = {"Apodemus sylvaticus", "Barnes maze", "Phosphoproteome", "Mass spectrometry", "Memory", "Retrieval "},
abstract = {"Abstract Protein phosphorylation is a well-known and well-documented mechanism in memory processes. Although a large series of protein kinases involved in memory processes have been reported, information on phosphoproteins is limited. It was therefore the aim of the study to determine a partial and differential phosphoproteome along with the corresponding network in hippocampus of a wild caught mouse strain with excellent performance in several paradigms of spatial memory. Apodemus sylvaticus mice were trained in the Barnes maze, a non-invasive test system for spatial memory and untrained mice served as controls. Animals were sacrificed 6 h following memory retrieval, hippocampi were taken, proteins extracted and in-solution digestion was carried out with subsequent iTRAQ double labelling. Phosphopeptides were enriched by a TiO2-based method and semi-quantified using two fragmentation principles on the LTQ-orbitrap Velos. In hippocampi of trained animals phosphopeptide levels representing signalling, neuronal, synaptosomal, cytoskeletal and metabolism proteins were at least twofold reduced or increased. Furthermore, a network revealing a link to pathways of ubiquitination, the androgen receptor, small \{GTPase\} Rab5 and \{MAPK\} signaling as well as synucleins was constructed. This work is relevant for interpretation of previous work and the design of future studies on protein phosphorylation in spatial memory. "} 
}
@article{vanOosten20141031,
title = {"Separability versus prototypicality in handwritten word-image retrieval "},
journal = {"Pattern Recognition "},
volume = {"47"},
number = {"3"},
pages = {"1031 - 1038"},
year = {"2014"},
note = {"Handwriting Recognition and other \{PR\} Applications "},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2013.09.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320313003786"},
author = {"Jean-Paul van Oosten and Lambert Schomaker"},
keywords = {"Image retrieval", "Handwriting recognition", "Nearest centroid", "Support-vector machines", "Separability", "Prototypicality", "Historical manuscripts", "Big data", "Continuous machine learning "},
abstract = {"Abstract Hit lists are at the core of retrieval systems. The top ranks are important, especially if user feedback is used to train the system. Analysis of hit lists revealed counter-intuitive instances in the top ranks for good classifiers. In this study, we propose that two functions need to be optimised: (a) in order to reduce a massive set of instances to a likely subset among ten thousand or more classes, separability is required. However, the results need to be intuitive after ranking, reflecting (b) the prototypicality of instances. By optimising these requirements sequentially, the number of distracting images is strongly reduced, followed by nearest-centroid based instance ranking that retains an intuitive (low-edit distance) ranking. We show that in handwritten word-image retrieval, precision improvements of up to 35 percentage points can be achieved, yielding up to 100% top hit precision and 99% top-7 precision in data sets with 84 000 instances, while maintaining high recall performances. The method is conveniently implemented in a massive scale, continuously trainable retrieval engine, Monk. "} 
}
@article{Shi2017,
title = {"Remote sensing retrieval of urban land surface temperature in hot-humid region "},
journal = {"Urban Climate "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2212-0955"},
doi = {"https://doi.org/10.1016/j.uclim.2017.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212095517300019"},
author = {"Yurong Shi and Yufeng Zhang"},
keywords = {"Land surface temperature", "Urban climate", "Remote sensing", "Mono-window algorithm", "Field observation "},
abstract = {"Abstract With the rapid urbanization and the global climate change, the urban climate problems become increasingly serious in the hot-humid region of China. This study established the satellite-based remote sensing retrieval methods for urban land surface temperature (LST) based on the mono-window algorithm and the estimation methods of ground emissivity and atmospheric transmittance. Through retrieving \{LST\} of Haizhu district in Guangzhou in a sunny summer day, it was found that the retrieval methods were able to distinguish the surface temperature variations for different underlying urban surfaces. By comparison with the field observations, it was found that the error of the retrieval methods was about 1.0 °C and the methods were applicable for \{LST\} retrieval in the cities in the hot-humid region. By applying the retrieval methods, it showed that the cooling effects of water and vegetation on surrounding urban lands were effective within distances of 250 m and 350 m, respectively. The water cooling effect correlated with its area and width positively, and the vegetation \{LST\} correlated with its canopy density negatively. The present study provides reliable techniques for observing and evaluating urban \{LST\} and useful guidance for planning and design of urban climate in the hot-humid region. "} 
}
@article{Shrivastava2014212,
title = {"Content based image retrieval based on relative locations of multiple regions of interest using selective regions matching "},
journal = {"Information Sciences "},
volume = {"259"},
number = {""},
pages = {"212 - 224"},
year = {"2014"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2013.08.043"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025513006105"},
author = {"Nishant Shrivastava and Vipin Tyagi"},
keywords = {"Region of Interest (ROI)", "Region code", "Content Based Image Retrieval (CBIR)", "Local Binary Pattern (LBP)", "Relative location "},
abstract = {"Abstract In this study, a novel technique for image retrieval based on selective regions matching using region codes is presented. All images in the database are uniformly divided into multiple regions and each region is assigned a 4-bit region code based upon its location relative to the central region. Dominant color and Local Binary Pattern (LBP) based texture features are extracted from these regions. Feature vectors together with their region codes are stored and indexed in the database. During retrieval, feature vectors of regions having region codes similar to the query image region are used for comparison. To reflect the user’s intent in query formulation in a better way, an effective technique for Region of Interest (ROI) overlapping block selection is also proposed. Region codes are further used to find relative locations of multiple \{ROIs\} in query and target images. The performance of the proposed approach is tested on the MPEG-7 \{CCD\} database and Corel image database. Experimental results show that the proposed approach increases the accuracy and reduces image retrieval time. "} 
}
@article{Kleinböhl2017511,
title = {"Two-dimensional radiative transfer for the retrieval of limb emission measurements in the martian atmosphere "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"187"},
number = {""},
pages = {"511 - 522"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.07.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316302667"},
author = {"Armin Kleinböhl and A. James Friedson and John T. Schofield"},
keywords = {"2D", "Radiative transfer", "Limb geometry", "Mars", "MCS "},
abstract = {"Abstract The remote sounding of infrared emission from planetary atmospheres using limb-viewing geometry is a powerful technique for deriving vertical profiles of structure and composition on a global scale. Compared with nadir viewing, limb geometry provides enhanced vertical resolution and greater sensitivity to atmospheric constituents. However, standard limb profile retrieval techniques assume spherical symmetry and are vulnerable to biases produced by horizontal gradients in atmospheric parameters. We present a scheme for the correction of horizontal gradients in profile retrievals from limb observations of the martian atmosphere. It characterizes horizontal gradients in temperature, pressure, and aerosol extinction along the line-of-sight of a limb view through neighboring measurements, and represents these gradients by means of two-dimensional radiative transfer in the forward model of the retrieval. The scheme is applied to limb emission measurements from the Mars Climate Sounder instrument on Mars Reconnaissance Orbiter. Retrieval simulations using data from numerical models indicate that biases of up to 10 K in the winter polar region, obtained with standard retrievals using spherical symmetry, are reduced to about 2 K in most locations by the retrieval with two-dimensional radiative transfer. Retrievals from Mars atmospheric measurements suggest that the two-dimensional radiative transfer greatly reduces biases in temperature and aerosol opacity caused by observational geometry, predominantly in the polar winter regions. "} 
}
@article{Yasmin201487,
title = {"Intelligent Image Retrieval Techniques: A Survey "},
journal = {"Journal of Applied Research and Technology "},
volume = {"12"},
number = {"1"},
pages = {"87 - 103"},
year = {"2014"},
note = {""},
issn = {"1665-6423"},
doi = {"https://doi.org/10.1016/S1665-6423(14)71609-8"},
url = {"http://www.sciencedirect.com/science/article/pii/S1665642314716098"},
author = {"Mussarat Yasmin and Sajjad Mohsin and Muhammad Sharif"},
keywords = {"Image retrieval", "intelligent image indexing", "image data store", "online image retrieval", "search by visual contents "},
abstract = {"Abstract In the current era of digital communication, the use of digital images has increased for expressing, sharing and interpreting information. While working with digital images, quite often it is necessary to search for a specific image for a particular situation based on the visual contents of the image. This task looks easy if you are dealing with tens of images but it gets more difficult when the number of images goes from tens to hundreds and thousands, and the same content-based searching task becomes extremely complex when the number of images is in the millions. To deal with the situation, some intelligent way of content-based searching is required to fulfill the searching request with right visual contents in a reasonable amount of time. There are some really smart techniques proposed by researchers for efficient and robust content-based image retrieval. In this research, the aim is to highlight the efforts of researchers who conducted some brilliant work and to provide a proof of concept for intelligent content-based image retrieval techniques. "} 
}
@article{Kumar2014330,
title = {"A graph-based approach for the retrieval of multi-modality medical images "},
journal = {"Medical Image Analysis "},
volume = {"18"},
number = {"2"},
pages = {"330 - 342"},
year = {"2014"},
note = {""},
issn = {"1361-8415"},
doi = {"https://doi.org/10.1016/j.media.2013.11.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1361841513001710"},
author = {"Ashnil Kumar and Jinman Kim and Lingfeng Wen and Michael Fulham and Dagan Feng"},
keywords = {"Content-based image retrieval", "Graph similarity", "Multi-modality", "PET-CT "},
abstract = {"Abstract In this paper, we address the retrieval of multi-modality medical volumes, which consist of two different imaging modalities, acquired sequentially, from the same scanner. One such example, positron emission tomography and computed tomography (PET-CT), provides physicians with complementary functional and anatomical features as well as spatial relationships and has led to improved cancer diagnosis, localisation, and staging. The challenge of multi-modality volume retrieval for cancer patients lies in representing the complementary geometric and topologic attributes between tumours and organs. These attributes and relationships, which are used for tumour staging and classification, can be formulated as a graph. It has been demonstrated that graph-based methods have high accuracy for retrieval by spatial similarity. However, naïvely representing all relationships on a complete graph obscures the structure of the tumour-anatomy relationships. We propose a new graph structure derived from complete graphs that structurally constrains the edges connected to tumour vertices based upon the spatial proximity of tumours and organs. This enables retrieval on the basis of tumour localisation. We also present a similarity matching algorithm that accounts for different feature sets for graph elements from different imaging modalities. Our method emphasises the relationships between a tumour and related organs, while still modelling patient-specific anatomical variations. Constraining tumours to related anatomical structures improves the discrimination potential of graphs, making it easier to retrieve similar images based on tumour location. We evaluated our retrieval methodology on a dataset of clinical PET-CT volumes. Our results showed that our method enabled the retrieval of multi-modality images using spatial features. Our graph-based retrieval algorithm achieved a higher precision than several other retrieval techniques: gray-level histograms as well as state-of-the-art methods such as visual words using the scale- invariant feature transform (SIFT) and relational matrices representing the spatial arrangements of objects. "} 
}
@article{Joshi2014535,
title = {"Image Retrieval System Using Intuitive Descriptors "},
journal = {"Procedia Technology "},
volume = {"14"},
number = {""},
pages = {"535 - 542"},
year = {"2014"},
note = {"2nd International Conference on Innovations in Automation and Mechatronics Engineering, \{ICIAME\} 2014 "},
issn = {"2212-0173"},
doi = {"https://doi.org/10.1016/j.protcy.2014.08.068"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212017314001042"},
author = {"Keyur D. Joshi and Sanket N. Bhavsar and Rajesh C. Sanghvi"},
keywords = {"Content Based Image Retrieval", "Object Recognition", "color image", "grayscale image "},
abstract = {"Abstract With the increase in the popularity of using huge image databases in various image retrieval applications, a need arises to develop an efficient, robust and automatic system which provides output in the form of similar images with respect to the input or query image. In this paper, three Image Retrieval Systems using very basic but novel descriptors, which can retrieve black and white (binary) image, grayscale image and color image from the binary, grayscale and color image databases, respectively, were implemented. It should be noted that the features used for the binary image and grayscale image may not be efficiently applicable to the color images. Obtained results indicate the same and it additionally shows that irrespective of numbers of images in database, developed Image Retrieval Systems retrieve images in very short period of time with high accuracy. Accuracy in color image retrieval is less compared to binary and grayscale image retrieval. So, it creates a need to design highly effective features for the color image retrieval. "} 
}
@article{Li2014212,
title = {"Multidimensional color image storage, retrieval, and compression based on quantum amplitudes and phases "},
journal = {"Information Sciences "},
volume = {"273"},
number = {""},
pages = {"212 - 232"},
year = {"2014"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2014.03.035"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025514003193"},
author = {"Hai-Sheng Li and Qingxin Zhu and Ri-Gui zhou and Ming-Cui Li and lan Song and Hou Ian"},
keywords = {"Image storage", "Image retrieval", "Image compression", "Image processing", "Quantum computing "},
abstract = {"Abstract In this study, we propose a new representation method for multidimensional color images, called an n-qubit normal arbitrary superposition state (NASS), where n qubits represent the colors and coordinates of 2 n pixels (e.g., a three-dimensional color image of 1024 × 1024 × 1024 using only 30 qubits). Based on NASS, we present an ( n + 1 )-qubit normal arbitrary superposition state with relative phases (NASSRP) and an ( n + 2 )-qubit normal arbitrary superposition state with three components (NASSTC) for lossless and lossy quantum compression, respectively. We also design three general quantum circuits to generate NASS, NASSRP, and \{NASSTC\} states, where we retrieve an image from a quantum system using different projection measurement operators. Finally, we define the quantum compression ratio and analyze lossless and lossy quantum compression algorithms of multidimensional quantum images. For the first time, we implemented the compression of multidimensional color images on a quantum computer. Thus, we address the theoretical and practical aspects of image processing on a quantum computer. "} 
}
@article{Bergmann2014115,
title = {"Similarity assessment and efficient retrieval of semantic workflows "},
journal = {"Information Systems "},
volume = {"40"},
number = {""},
pages = {"115 - 127"},
year = {"2014"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2012.07.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437912001020"},
author = {"Ralph Bergmann and Yolanda Gil"},
keywords = {"Business workflows", "Scientific workflows", "Workflow similarity", "Retrieval", "Case-based reasoning "},
abstract = {"In the recent years, the use of workflows has significantly expanded from its original domain of business processes towards new areas. The increasing demand for individual and more flexible workflows asks for new methods that support domain experts to create, monitor, and adapt workflows. The emergent field of process-oriented case-based reasoning addresses this problem by proposing methods for reasoning with workflows based on experience. New workflows can be constructed by reuse of already available similar workflows from a repository. Hence, methods for the similarity assessment of workflows and for the efficient retrieval of similar workflows from a repository are of core importance. To this end, we describe a new generic model for representing workflows as semantically labeled graphs, together with a related model for knowledge intensive similarity measures. Further, new algorithms for workflow similarity computation, based on A⁎ search are described. A new retrieval algorithm is introduced that goes beyond traditional sequential retrieval for graphs, interweaving similarity computation with case selection. We describe the application of this model and several experimental evaluations of the algorithms in the domain of scientific workflows and in the domain of business workflows, thereby showing its broad applicability. "} 
}
@article{Wang2014255,
title = {"An Eigen-based motion retrieval method for real-time animation "},
journal = {"Computers & Graphics "},
volume = {"38"},
number = {""},
pages = {"255 - 267"},
year = {"2014"},
note = {""},
issn = {"0097-8493"},
doi = {"https://doi.org/10.1016/j.cag.2013.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0097849313001878"},
author = {"Pengjie Wang and Rynson W.H. Lau and Zhigeng Pan and Jiang Wang and Haiyu Song"},
keywords = {"Eigenspace retrieval", "Motion retrieval", "Real-time animation", "Real-time motion retrieval "},
abstract = {"Abstract Research on real-time 3D animation is attracting a lot of attention in recent years due to the popularity of emerging applications such as distributed virtual environments and computer games. One of the important issues in real-time animation is that the existing motion retrieval techniques generally have a high matching time because they are typically based on matching time-series, making them less suitable for use with large motion databases. In this paper, we propose a different approach to motion retrieval, called Eigen-based Motion Retrieval (or EigenMR), to address this limitation of the existing methods by performing motion retrieval in the transform domain instead of the time domain. To differentiate the motion of different body parts, we propose to perform the matching on individual body parts as well as on the whole body. Our approach has the important advantage that each body part can be represented by an index of fixed size, consisting of a number of eigenvectors and the corresponding eigenvalues. As a result, our approach has constant time complexity based on the number of motion files in the database instead of the size of the database. The experimental results show that our approach is both efficient and accurate compared with some of the latest methods. When applied to a motion database of 4 \{GB\} in size, our method requires approximately 20% of the standard time, making it more suitable for real-time animation. "} 
}
@article{Su2017,
title = {"Retrieval Analysis of Neck-Stem Coupling in Modular Hip Prostheses "},
journal = {"The Journal of Arthroplasty "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2017.02.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540317301158"},
author = {"Sherwin L. Su and Chelsea N. Koch and Thu M. Nguyen and Jayme C. Burket and Timothy M. Wright and Geoffrey H. Westrich"},
keywords = {"total hip arthroplasty", "modular neck", "fretting", "corrosion", "adverse local tissue reaction "},
abstract = {"AbstractBackground Dual-taper modular stems have suffered from high revision rates caused by adverse local tissue reactions secondary to fretting and corrosion. We compared the fretting and corrosion behavior of a group of modular neck designs to that of a design that had been recalled for risks associated with fretting and corrosion at the modular neck junction. Methods We previously analyzed fretting and corrosion on 60 retrieved Rejuvenate modular neck-stem implants. Here we compare those results to results from 26 retrieved implants from 7 other modular neck designs. For the 26 additional cases, histology slides of tissue collected at revision were reviewed and graded for aseptic lymphocyte-dominated vasculitis-associated lesion (ALVAL). Multivariate analyses were performed to assess differences in fretting and corrosion, adjusting for confounding factors (eg, length of implantation). Results The Rejuvenate design had higher damage and corrosion scores than the other 7 designs (P &lt; .01). Histologic samples from the recalled design were 20 times more likely to show \{ALVAL\} than samples from the other designs (P &lt; .01). Mixed metal couples had higher fretting (P &lt; .01) and corrosion (P = .02) scores than non-mixed metal couples. Conclusion Fretting and corrosion occurred on all modular neck-stem retrievals regardless of design. However, mixed metal couples suffered more corrosion than homogenous couples. This may be due to the lower modulus of the titanium alloy used for the stem, allowing for increased metal transfer and surface damage when loaded against a cobalt alloy modular neck, which in turn could account for the higher \{ALVAL\} and corrosion scores. Due to increased corrosion risk with mixed metals and increased neck fracture risk with non-mixed metal stem and necks, we suggest that clinicians avoid implantation of modular neck-stem systems. "} 
}
@article{Singh201734,
title = {"Uncertainty characterization in the retrieval of an atmospheric point release "},
journal = {"Atmospheric Environment "},
volume = {"152"},
number = {""},
pages = {"34 - 50"},
year = {"2017"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2016.12.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S135223101630975X"},
author = {"Sarvesh Kumar Singh and Pramod Kumar and Grégory Turbelin and Raj Rani"},
keywords = {"Confidence bounds", "FFT07 field experiment", "MUST field experiment", "Renormalization", "Source reconstruction", "Uncertainty "},
abstract = {"Abstract The study proposes a methodology in a recent inversion technique, called as Renormalization, to characterize the uncertainties in the reconstruction of a point source. The estimates are derived for measuring the inversion error, the degree of model fit towards measurements (model determination coefficient) and the confidence intervals for the retrieved point source parameters (mainly, location and strength). The inversion error is reflected through an angular estimate which measures the deviation between the measured and predicted concentrations. The uncertainty estimation methodology is evaluated for point source reconstruction studies, using real measurements from two field experiments, known as Fusion Field Trials 2007 (FFT07) in flat terrain and Mock Urban Setting Test (MUST) in urban like terrain. In \{FFT07\} and \{MUST\} experiments, the point source location is retrieved with an average Euclidean distance of 22 m and 15 m respectively. The source strength is retrieved, on average, within a factor of 1.5 in both the datasets. The inversion error is observed as 24 o and 21 o in \{FFT07\} and \{MUST\} experiment, respectively. The 95% confidence interval estimates show that the uncertainty in the retrieved parameters is relatively large in approximately 50% \{FFT07\} and 30% \{MUST\} trials in spite of their closeness towards true source parameters. For a comparative analysis, the interval estimates are also compared with a more general method of uncertainty estimation, Residual Bootstrap Sampling. In most of the trials, we observed that the intervals estimates with the present method are comparable (within 10–20% variations) to bootstrap estimates. The proposed methodology provides near accurate and computationally efficient uncertainty estimates in comparison to the methods based on Hessian and sampling procedures. "} 
}
@article{Mistry2017,
title = {"Content based image retrieval using hybrid features and various distance metric "},
journal = {"Journal of Electrical Systems and Information Technology "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"2314-7172"},
doi = {"https://doi.org/10.1016/j.jesit.2016.12.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S2314717216301155"},
author = {"Yogita Mistry and D.T. Ingole and M.D. Ingole"},
keywords = {"CBIR", "DTCWT", "SWT moments", "Minkowski distance", "Mahalanobis distance "},
abstract = {"Abstract In last decade, large database of images have grown rapidly and will continue in future. Retrieval and querying of these image in efficient way is needed in order to access the visual content from large database. Content based image retrieval (CBIR) provides the solution for efficient retrieval of image from these huge image database. In this article a hybrid feature based efficient \{CBIR\} system is proposed using various distance measure. Spatial domain features including color auto-correlogram, color moments, \{HSV\} histogram features, and frequency domain features like moments using SWT, features using Gabor wavelet transform are used. Further, to enhance precision binarized statistical image features, color and edge directivity descriptor features are employed for developing efficient \{CBIR\} system. Various distance metrics are used for retrieval. The experiments are performed using \{WANG\} database which consists of 1000 images from 10 different classes. Experimental result shows that the proposed approach performs better in terms of precision compared to other existing systems. "} 
}
@article{Eldar2014473,
title = {"Phase retrieval: Stability and recovery guarantees "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"36"},
number = {"3"},
pages = {"473 - 494"},
year = {"2014"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2013.08.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520313000717"},
author = {"Yonina C. Eldar and Shahar Mendelson"},
keywords = {"Phase retrieval", "Compressed sensing "},
abstract = {"Abstract We consider stability and uniqueness in real phase retrieval problems over general input sets, when the data consists of random and noisy quadratic measurements of an unknown input x 0 ∈ R n that lies in a general set T. We study conditions under which x 0 can be stably recovered from the measurements. In the noise-free setting we show that the number of measurements needed to ensure a unique and stable solution depends on the set T through its Gaussian mean-width, which can be computed explicitly for many sets of interest. In particular, for k-sparse inputs, O ( k log ( n / k ) ) measurements suffice, while if x 0 is an arbitrary vector in R n , O ( n ) measurements are sufficient. In the noisy case, we show that if the empirical risk is bounded by a given, computable constant that depends only on statistical properties of the noise, the error with respect to the true input is bounded by the same Gaussian parameter (up to logarithmic factors). Therefore, the number of measurements required for stable recovery is the same as in the noise-free setting up to log factors. It turns out that the complexity parameter for the quadratic problem is the same as the one used for analyzing stability in linear measurements under very general conditions. Thus, no substantial price has to be paid in terms of stability when there is no knowledge of the phase of the measurements. "} 
}
@article{DiMartino2014114,
title = {"Differential 3D shape retrieval "},
journal = {"Optics and Lasers in Engineering "},
volume = {"58"},
number = {""},
pages = {"114 - 118"},
year = {"2014"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2014.02.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816614000530"},
author = {"J. Matías Di Martino and Alicia Fernández and Gastón A. Ayubi and José A. Ferrari"},
keywords = {"Depth retrieval", "Fringe projection", "3D face recognition "},
abstract = {"Abstract We are presenting a differential three-dimensional (3-D) shape profiling method that is based on the combination of orthogonal fringe projection. It allows us to compute depth gradient maps in a fast and efficient manner. What we are demonstrating is that depth gradients can be computed in a simple way by measuring fringe deformation throughout a novel single-shot approach. We show the usefulness and potential applications of the proposed approach. Validation experiments are presented as well. "} 
}
@article{Afanas'ev2017146,
title = {"Differential inverse inelastic mean free path and differential surface excitation probability retrieval from electron energy loss spectra "},
journal = {"Vacuum "},
volume = {"136"},
number = {""},
pages = {"146 - 155"},
year = {"2017"},
note = {""},
issn = {"0042-207X"},
doi = {"https://doi.org/10.1016/j.vacuum.2016.10.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0042207X16304390"},
author = {"Viktor P. Afanas'ev and Alexander S. Gryazev and Dmitry S. Efremenko and Pavel S. Kaplya"},
keywords = {"\{DIIMFP\} extraction", "REELS deconvolution", "PES", "Invariant imbedding", "XPS", "Electron cross-section "},
abstract = {"Abstract Quantitative interpretation of the electron spectroscopy data requires the information on differential inverse inelastic mean free paths (DIIMFP) and differential surface excitation probabilities (DSEP). In this paper, we test an algorithm of extracting \{DIIMFP\} and \{DSEP\} from reflected electron energy loss spectra (REELS) and photo-electron spectra (PES) in which the desired functions are parametrized on the base of a classical Lorentz oscillator. Unknown parameters are found by using the fitting procedure. To account for surface excitations, the investigated samples are considered as multi-layer systems. Simulations of \{REELS\} and \{PES\} are performed by making use of the partial intensity approach. The partial intensities for the reflection function and the photo-electron density flux are computed on the base of the invariant imbedding method. Extracted \{DIIMFPs\} and \{DSEPs\} are compared with those obtained by other authors. Finally, \{REELS\} and \{PES\} spectra for Be, Mg, Al, Si, Nb and W are computed using the retrieved \{DIIMFPs\} and DSEPs, and compared with the experimental spectra. All comparisons show good agreement. "} 
}
@article{Ma20141377,
title = {"A graph distance based metric for data oriented workflow retrieval with variable time constraints "},
journal = {"Expert Systems with Applications "},
volume = {"41"},
number = {"4, Part 1"},
pages = {"1377 - 1388"},
year = {"2014"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2013.08.035"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417413006477"},
author = {"Yinglong Ma and Xiaolan Zhang and Ke Lu"},
keywords = {"Business process management", "Data oriented workflow", "Similarity computation", "Process mining", "Process retrieval "},
abstract = {"Abstract There are many applications in business process management that require measuring the similarity between business processes, such as workflow retrieval and process mining, etc. However, most existing approaches and models cannot represent variable constraints and achieve data oriented workflow retrieval of considering different QoS requirements, and also fail to allow users to express arbitrary constraints based on graph structures of workflows. These problems will impede the customization and reuse of workflows, especially for data oriented workflows. In this paper, we will be towards workflow retrieval with variable time constraints. We propose a graph distance based approach for measuring the similarity between data oriented workflows with variable time constraints. First, a formal structure called Time Dependency Graph (TDG) is proposed and further used as representation model of workflows. Similarity comparison between two workflows can be reduced to computing the similarity between their TDGs. Second, we detect whether two \{TDGs\} of workflows for similarity comparison are compatible. A distance based measure is proposed for computing their similarity by their normalization matrices established based on their TDGs. We theoretically proof that the proposed measure satisfies the all the properties of distance. In addition, some exemplar processes are studied to illustrate the effectiveness of our approach of similarity comparison for workflows. "} 
}
@article{García201766,
title = {"Retrieval of the optical properties of a semiinfinite compartment in a layered scattering medium by single-distance, time-resolved diffuse reflectance measurements "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"189"},
number = {""},
pages = {"66 - 74"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.11.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316306070"},
author = {"H.A. García and D.I. Iriarte and J.A. Pomarico and D. Grosenick and R. Macdonald"},
keywords = {"NIRS", "Reflectance", "Time-resolved", "Brain", "Layered media "},
abstract = {"Abstract Functional analysis of the human brain requires methods that take the layered structure of the head into account. In this work we introduce an improved theoretical model that describes light propagation in multilayered, turbid cylinders with a infinitely thick bottom layer, which simplifies calculations and reduces computation times. Our approach was validated with Monte Carlo simulations and single distance, time-resolved experiments on a three-layered phantom, where the absorption of the deepest layer was gradually modified. We were able to retrieve both, the scattering and absorption coefficient of this layer within reasonable errors. Hereby, changes in scattering were found to have less effect on the experimental data than absorption changes, making the reliable estimation of the reduced scattering coefficient more difficult in comparison to absorption. Stability of the implemented fitting routine was thoroughly analyzed, revealing that special care is needed to obtain accurate values for the reduced scattering coefficient. "} 
}
@article{Navarro201483,
title = {"New space/time tradeoffs for top-k document retrieval on sequences "},
journal = {"Theoretical Computer Science "},
volume = {"542"},
number = {""},
pages = {"83 - 97"},
year = {"2014"},
note = {""},
issn = {"0304-3975"},
doi = {"https://doi.org/10.1016/j.tcs.2014.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304397514003545"},
author = {"Gonzalo Navarro and Sharma V. Thankachan"},
keywords = {"Document retrieval", "Top-k queries", "String databases", "Compressed data structures "},
abstract = {"Abstract We address the problem of indexing a collection D = { T 1 , T 2 , … , T D } of D string documents of total length n, so that we can efficiently answer top-k queries: retrieve k documents most relevant to a pattern P of length p given at query time. There exist linear-space data structures, that is, using O ( n ) words, that answer such queries in optimal O ( p + k ) time for an ample set of notions of relevance. However, using linear space is not sufficiently good for large text collections. In this paper we explore how far the space/time tradeoff for this problem can be pushed. We obtain three results: (1) When relevance is measured as term frequency (number of times P appears in a document T i ), an index occupying | \{CSA\} | + o ( n ) bits answers the query in time O ( t search ( p ) + k lg 2 k lg ε n ) , where \{CSA\} is a compressed suffix array indexing D , t search ( p ) is its time to find the suffix array interval of P, and ε &gt; 0 is any constant. (2) With the same measure of relevance, an index occupying | \{CSA\} | + n lg D + o ( n lg σ + n lg D ) bits answers the query in time O ( t search ( p ) + k lg ⁎ k ) , where lg ⁎ k is the iterated logarithm of k. (3) When the relevance depends only on the documents, an index occupying | \{CSA\} | + O ( n lg lg n ) bits answers the query in O ( t search ( p ) + k t \{SA\} ) time, where t \{SA\} is the time the \{CSA\} needs to retrieve a suffix array cell. On our way, we obtain some other results of independent interest. "} 
}
@article{Jones201489,
title = {"Active learning for human action retrieval using query pool selection "},
journal = {"Neurocomputing "},
volume = {"124"},
number = {""},
pages = {"89 - 96"},
year = {"2014"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2013.07.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231213007844"},
author = {"Simon Jones and Ling Shao and Kairan Du"},
keywords = {"Content-Based Video Retrieval", "Active learning", "Human action recognition", "Relevance feedback "},
abstract = {"Abstract Content-Based Video Retrieval (CBVR) is gaining considerable research interest, inspired by the need to manage the large amounts of video media accumulating on the Internet. In this paper, we verify that the current state-of-the-art retrieval algorithms for \{CBVR\} can be improved with active learning. Active learning algorithms query a user for relevance feedback on specific items within the search database, using the additional labeled datapoints to improve the accuracy of the user's original query. We propose a simple \{CBVR\} system with \{SVM\} relevance feedback, and integrate it with active learning using a simple query pool selection algorithm, based on two co-testing learners. Our experiments demonstrate that such a system performs significantly better with active learning than without, surpassing the state-of-the-art. "} 
}
@article{Almeida2014243,
title = {"Phase contrast X-ray microtomography of the Rhodnius prolixus head: Comparison of direct reconstruction and phase retrieval approach "},
journal = {"Radiation Physics and Chemistry "},
volume = {"95"},
number = {""},
pages = {"243 - 246"},
year = {"2014"},
note = {"Proceedings of the 12th International Symposium on Radiation Physics (ISRP 2012) "},
issn = {"0969-806X"},
doi = {"https://doi.org/10.1016/j.radphyschem.2013.02.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0969806X13000741"},
author = {"A.P. Almeida and D. Braz and L.P. Nogueira and M.V. Colaço and J. Soares and S.C. Cardoso and E.S. Garcia and P. Azambuja and M.S. Gonzalez and S. Mohammadi and G. Tromba and R.C. Barroso"},
keywords = {"Phase retrieval", "Phase contrast", "Synchrotron radiation", "Micro-computed tomography", "Rhodnius prolixus", "Trypanosoma cruzi "},
abstract = {"We have used phase-contrast X-ray microtomography (PPC-μCT) to study the head of the blood-feeding bug, Rhodnius prolixus, which is one of the most important insect vector of Trypanosoma cruzi, ethiologic agent of Chagas disease in Latin America. Images reconstructed from phase-retrieved projections processed by \{ANKA\} phase are compared to those obtained through direct tomographic reconstruction of the flat-field-corrected transmission radiographs. It should be noted that the relative locations of the important morphological internal structures are observable with a precision that is difficult to obtain without the phase retrieval approach. "} 
}
@article{Zhu2017152,
title = {"Retrievals of all-weather daytime air temperature from \{MODIS\} products "},
journal = {"Remote Sensing of Environment "},
volume = {"189"},
number = {""},
pages = {"152 - 163"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.11.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716304503"},
author = {"Wenbin Zhu and Aifeng Lű and Shaofeng Jia and Jiabao Yan and Rashid Mahmood"},
keywords = {"Air temperature", "Land surface temperature", "Atmospheric temperature profile", "Adiabatic lapse rate", "MODIS", "Remote sensing "},
abstract = {"Abstract It is well known that remote sensing techniques hold the potential to explore the spatial estimation of air temperature (Ta) with fine spatial and temporal resolution across the world. However, because of the complex interaction of land-atmosphere system and the contamination of cloud cover, the retrieval of daytime Ta exclusively from remote sensing data is still far from straight forward, especially under cloudy sky conditions. In this paper, we presented a simple parameterization scheme of daytime Ta under all-weather conditions entirely based on Moderate Resolution Imaging Spectroradiometer (MODIS) products. To evaluate its applicability, the scheme was demonstrated in two regions with totally different geomorphological and climatic conditions, the east part of the Qaidam Basin (EQB) in China and the Southern Great Plains (SGP) in the United States of America. The instantaneous Ta under clear sky conditions (Ta , clear) was determined as the average of near surface air temperature (TaS) retrieved from MOD07_L2 product and land surface temperature (Ts) retrieved from MOD06_L2 product. Then a regression model between Ta , clear and Ts was established, and the instantaneous Ta under cloudy sky conditions (Ta , cloudy) was estimated by applying the regression model to Ts retrieved under cloudy sky conditions. The results showed that the averaging parameterization scheme has significantly improved the accuracy of Ta , clear retrievals with \{MAE\} = 1.95 °C, \{RMSE\} = 2.50 °C, and B = 0.02 in the EQB, and \{MAE\} = 2.02 °C, \{RMSE\} = 2.56 °C, and B = 0.01 in the SGP. The Ta , cloudy estimates also showed good agreement with Ta observations in both regions with a correlation coefficient (r) higher than 0.91. The values of \{RMSE\} calculated for the \{EQB\} and \{SGP\} were 3.42 °C and 2.91 °C, respectively. The accuracy of both Ta , clear and Ta , cloudy estimates has reached a level comparable with other traditional statistical approaches that adopt ancillary Ta measurements as training dataset. Therefore, it is feasible to estimate daytime Ta under all-weather conditions entirely based on \{MODIS\} products. "} 
}
@article{Laiche2014556,
title = {"Curve normalization for shape retrieval "},
journal = {"Signal Processing: Image Communication "},
volume = {"29"},
number = {"4"},
pages = {"556 - 571"},
year = {"2014"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2014.01.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596514000319"},
author = {"Nacéra Laiche and Slimane Larabi and Farouk Ladraa and Abdelnour Khadraoui"},
keywords = {"Curvature points", "Polygon approximation", "Least squares model", "Shape matching", "Shape retrieval "},
abstract = {"Abstract In this paper, we propose a novel part-based approach for two dimensional (2-D) shape description and recognition. According to this method, first the polygonal approximation is employed to represent the outline shape by an ordered sequence of parts. Then using the Least squares model, each part is associated with a cubic polynomial curve. The obtained curves are normalized that are invariant to scaling, rotation and translation. Finally, based on shape similarity of resulting curves, a shape similarity between an input shape and its reference model is defined. A two-step matching algorithm is proposed. Experiments using several benchmark databases are performed and the obtained retrieval results demonstrate that the proposed approach is effective as compared to other matching techniques. "} 
}
@article{Becchi2014100,
title = {"A Distributed System for Multimedia Monitoring, Publishing and Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"38"},
number = {""},
pages = {"100 - 107"},
year = {"2014"},
note = {"10th Italian Research Conference on Digital Libraries, \{IRCDL\} 2014 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2014.10.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050914013775"},
author = {"Giuseppe Becchi and Marco Bertini and Alberto Del Bimbo and Andrea Ferracani and Daniele Pezzatini"},
keywords = {"semantic multimedia annotation", "SOA", "multimedia retrieval "},
abstract = {"Abstract In this paper we present a distributed and interactive multi-user system which provides a flexible approach to collect, manage, annotate and publish collections of images, videos and textual documents. The system is based on a Service Oriented Architecture that allows to combine and orchestrate a large set of web services for automatic and manual annotation, retrieval, browsing, ingestion and authoring of different multimedia sources. These tools can been used to create several publicly available vertical applications, addressing different use cases. Positive results of usability test evaluations have shown that the system can be effectively used to create video retrieval systems. "} 
}
@article{Slama2014131,
title = {"3D human motion analysis framework for shape similarity and retrieval "},
journal = {"Image and Vision Computing "},
volume = {"32"},
number = {"2"},
pages = {"131 - 154"},
year = {"2014"},
note = {""},
issn = {"0262-8856"},
doi = {"https://doi.org/10.1016/j.imavis.2013.12.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S026288561400002X"},
author = {"Rim Slama and Hazem Wannous and Mohamed Daoudi"},
keywords = {"Motion analysis", "Shape similarity", "3D video retrieval", "3D human action "},
abstract = {"Abstract 3D shape similarity from video is a challenging problem lying at the heart of many primary research areas in computer graphics and computer vision applications. In this paper, we address within a new framework the problem of 3D shape representation and shape similarity in human video sequences. Our shape representation is formulated using extremal human curve (EHC) descriptor extracted from the body surface. It allows taking benefits from Riemannian geometry in the open curve shape space and therefore computing statistics on it. It also allows subject pose comparison regardless of geometrical transformations and elastic surface change. Shape similarity is performed by an efficient method which takes advantage of a compact \{EHC\} representation in open curve shape space and an elastic distance measure. Thanks to these main assets, several important exploitations of the human action analysis are performed: shape similarity computation, video sequence comparison, video segmentation, video clustering, summarization and motion retrieval. Experiments on both synthetic and real 3D human video sequences show that our approach provides an accurate static and temporal shape similarity for pose retrieval in video, compared with the state-of-the-art approaches. Moreover, local 3D video retrieval is performed using motion segmentation and dynamic time warping (DTW) algorithm in the feature vector space. The obtained results are promising and show the potential of this approach. "} 
}
@article{Wang2014214,
title = {"An image retrieval scheme with relevance feedback using feature reconstruction and \{SVM\} reclassification "},
journal = {"Neurocomputing "},
volume = {"127"},
number = {""},
pages = {"214 - 230"},
year = {"2014"},
note = {"Advances in Intelligent SystemsSelected papers from the 2012 Brazilian Symposium on Neural Networks (SBRN 2012) "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2013.08.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231213008783"},
author = {"Xiang-Yang Wang and Yong-Wei Li and Hong-Ying Yang and Jing-Wei Chen"},
keywords = {"Content-based image retrieval", "Relevance feedback", "Support vector machine", "Orthogonal complement component analysis", "Feature reconstruction "},
abstract = {"Abstract In content-based image retrieval (CBIR), the gap between low-level visual features and high-level semantic meanings usually leads to poor performance, and relevance feedback (RF) is an effective method to bridge this gap and to scale up the performance in \{CBIR\} systems. In recent years, the support vector machine (SVM) based relevance feedbacks have been popular because they can outperform many other classifiers when the size of the training set is small, but they are often very complex and some unsatisfactory relevance of results occur frequently. To overcome the above limitations, we propose a \{SVM\} relevance feedback \{CBIR\} algorithm based on feature reconstruction, in which the covariance matrix based kernel empirical orthogonal complement component analysis is utilized. Firstly, the original input image space is projected nonlinearly onto a high-dimensional feature space by using nonlinear analysis approaches. Secondly, the covariance matrix of the positive feedback images are calculated, and the kernel empirical orthogonal complement components of the covariance matrix are also calculated. Thirdly, the new features of positive feedback images, negative feedback images, and all the remaining images are reconstructed by utilizing the kernel empirical orthogonal complement components of positive feedback images. Finally, a \{SVM\} classifier is constructed and all the images are resorted based on the new reconstructed image feature. Experiments on large databases show that the proposed algorithms are significantly more effective than the state-of-the-art approaches. "} 
}
@article{Miguez201443,
title = {"Failure to observe renewal following retrieval-induced forgetting "},
journal = {"Behavioural Processes "},
volume = {"103"},
number = {""},
pages = {"43 - 51"},
year = {"2014"},
note = {""},
issn = {"0376-6357"},
doi = {"https://doi.org/10.1016/j.beproc.2013.11.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0376635713002428"},
author = {"Gonzalo Miguez and Lisa E. Mash and Cody W. Polack and Ralph R. Miller"},
keywords = {"Renewal", "Spontaneous recovery", "Retrieval induced forgetting", "Inhibition "},
abstract = {"Abstract Recent studies have pursued the nature of inhibition observed in retrieval-induced forgetting (RIF) tasks. In a \{RIF\} paradigm, participants are trained on category–exemplar pairs in Phase 1. Then, some exemplars from select categories (Rp+ items) receive further practice in Phase 2. At test, impaired recall for non-practiced exemplars of the practiced categories (Rp− items) is observed relative to exemplars from non-practiced categories (Nrp items). This difference constitutes RIF. Prior reports of spontaneous recovery from \{RIF\} indicate that \{RIF\} represents a lapse rather than a loss of memory. Empirical analogs and theoretical considerations suggest that \{RIF\} should also be reversible through a change of context between Phase 2 and testing (i.e., renewal). We conducted two experiments using human participants to evaluate the context dependency of RIF. In both experiments, Phases 1 and 2 occurred in distinctly different contexts with subsequent testing occurring in either the Phase 1 context or the Phase 2 context. \{RIF\} was observed in both experiments. Experiment 1 additionally found that the magnitude of \{RIF\} was not reduced by testing in the Phase 1 context relative to testing in the Phase 2 context. Experiment 2 further tested context dependency of \{RIF\} by (1) increasing the dissimilarity between the two contexts and (2) inserting a retention interval between Phase 2 and test for half of the participants in each test context condition. The data again indicated no effect of the context manipulation. Thus, no renewal from \{RIF\} was observed in either experiment; moreover, these null findings were supported by Bayesian analyses. These results are compared with analogous inhibitory processes in the animal memory literature that typically show both physical and temporal context dependency. "} 
}
@article{Chudnovsky2014189,
title = {"Fine particulate matter predictions using high resolution Aerosol Optical Depth (AOD) retrievals "},
journal = {"Atmospheric Environment "},
volume = {"89"},
number = {""},
pages = {"189 - 198"},
year = {"2014"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2014.02.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S1352231014001150"},
author = {"Alexandra A. Chudnovsky and Petros Koutrakis and Itai Kloog and Steven Melly and Francesco Nordio and Alexei Lyapustin and Yujie Wang and Joel Schwartz"},
keywords = {"Particulate matter", "PM2.5", "Aerosol Optical Depth (AOD)", "High resolution aerosol retrieval", "MAIAC", "Intra-urban pollution", "Variability in PM2.5 levels", "Scales of pollution "},
abstract = {"Abstract To date, spatial-temporal patterns of particulate matter (PM) within urban areas have primarily been examined using models. On the other hand, satellites extend spatial coverage but their spatial resolution is too coarse. In order to address this issue, here we report on spatial variability in \{PM\} levels derived from high 1 km resolution \{AOD\} product of Multi-Angle Implementation of Atmospheric Correction (MAIAC) algorithm developed for \{MODIS\} satellite. We apply day-specific calibrations of \{AOD\} data to predict PM2.5 concentrations within the New England area of the United States. To improve the accuracy of our model, land use and meteorological variables were incorporated. We used inverse probability weighting (IPW) to account for nonrandom missingness of \{AOD\} and nested regions within days to capture spatial variation. With this approach we can control for the inherent day-to-day variability in the AOD-PM2.5 relationship, which depends on time-varying parameters such as particle optical properties, vertical and diurnal concentration profiles and ground surface reflectance among others. Out-of-sample “ten-fold” cross-validation was used to quantify the accuracy of model predictions. Our results show that the model-predicted PM2.5 mass concentrations are highly correlated with the actual observations, with out-of-sample \{R2\} of 0.89. Furthermore, our study shows that the model captures the pollution levels along highways and many urban locations thereby extending our ability to investigate the spatial patterns of urban air quality, such as examining exposures in areas with high traffic. Our results also show high accuracy within the cities of Boston and New Haven thereby indicating that \{MAIAC\} data can be used to examine intra-urban exposure contrasts in PM2.5 levels. "} 
}
@article{Yamin2017267,
title = {"Research on Matching Method for Case Retrieval Process in \{CBR\} Based on \{FCM\} "},
journal = {"Procedia Engineering "},
volume = {"174"},
number = {""},
pages = {"267 - 274"},
year = {"2017"},
note = {"13th Global Congress on Manufacturing and Management Zhengzhou, China 28-30 November, 2016 "},
issn = {"1877-7058"},
doi = {"https://doi.org/10.1016/j.proeng.2017.01.134"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877705817301340"},
author = {"Zhao Yamin and Zhang Mengmeng and Guo Xiaomin and Zhou Zhiwei and Zhang Jianhua"},
keywords = {"CBR", "case matching", "similarity algorithm", "FCM "},
abstract = {"Abstract Era of knowledge economy, how to effectively mining, the use of knowledge is the enterprise growing concern. \{CBR\} system from the field of artificial intelligence is a self-learning system to manage tacit knowledge (case). Case retrieval link is the core link, the advantages and disadvantages of search methods directly affect the efficiency of case retrieval and case matching accuracy. Therefore, this paper proposes a new case matching process: when the size of the case database is small, it searches based on the case similarity algorithm; when the case database is large, it searches based on the \{FCM\} secondary retrieval model. And illustrates the fastness and efficiency of \{FCM\} in matching large-scale case database. "} 
}
@article{O'Neill2017,
title = {"The neurocognitive basis of borrowed context information "},
journal = {"Cortex "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2017.01.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945217300205"},
author = {"Meagan O'Neill and Rachel A. Diana"},
keywords = {"Source memory", "Context retrieval", "False memory", "Recollection", "Medial temporal lobe "},
abstract = {"Abstract Falsely remembered items can be accompanied by episodic context retrieval. This finding is difficult to explain because there is no episode that binds the remembered item to the experimenter-controlled context features. The current study examines the neural correlates of false context retrieval when the context features can be traced to encoding episodes of semantically-similar items. Our neuroimaging results support a “dissociated source” mechanism for context borrowing in false memory. We found that parahippocampal cortex (PHc) activation, thought to indicate context retrieval, was greater during trials that involved context borrowing (an incorrect, but plausible source decision) than during baseline correct context retrieval. In contrast, hippocampal activation, thought to indicate retrieval of an episodic binding, was stronger during correct source retrieval than during context borrowing. Vivid context retrieval during false recollection experiences was also indicated by increased activation in visual perceptual regions for context borrowing as compared to other incorrect source judgments. The pattern of findings suggests that context borrowing can arise when unusually strong activation of a semantically-related item's contextual features drives relatively weak retrieval of the associated episodic binding with failure to confirm the item information within that binding. This dissociated source retrieval mechanism suggests that context-driven episodic retrieval does not necessarily lead to retrieval of specific item details. That is, source information can be retrieved in the absence of item memory. "} 
}
@article{Mintz20161857,
title = {"Is a Venacavogram Necessary after Inferior Vena Cava Filter Retrieval? "},
journal = {"Journal of Vascular and Interventional Radiology "},
volume = {"27"},
number = {"12"},
pages = {"1857 - 1864"},
year = {"2016"},
note = {""},
issn = {"1051-0443"},
doi = {"https://doi.org/10.1016/j.jvir.2015.08.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051044315007952"},
author = {"Joseph D. Mintz and S. William Stavropoulos and Scott O. Trerotola"},

abstract = {"AbstractPurpose To evaluate the utility of venacavography after optional inferior vena cava (IVC) filter retrieval using routine and complex techniques. Materials and Methods Patients (N = 224; 228 patient encounters) in whom venacavography was performed before and after \{IVC\} filter retrieval were reviewed from a 12-year period ending March 2014. Retrieval was considered complex if it required forceps or other adjuncts. Venacavograms were assessed for abnormalities including stenosis, filling defects, dissection, and extravasation of contrast material. Results Filling defects (n = 53; 23%) and stenosis (n = 137; 60%) were significantly more frequent after retrieval (P &lt; .05), but they did not change patient management. The only major abnormality after retrieval was extravasation (n = 3), which occurred only in the complex group and was treated with balloon tamponade and observation. No dissection was observed. Dwell time was not correlated with the presence of abnormalities after retrieval (r = 0.002, P = .977). Conclusions The lack of abnormalities requiring treatment on venacavography after routine \{IVC\} filter retrieval may justify omitting venacavography after retrieval regardless of dwell time. Although uncommon, extravasation requiring treatment may be seen after complex retrieval; venacavography remains warranted in this setting. "} 
}
@article{Sumowski2014397,
title = {"Retrieval Practice Improves Memory in Survivors of Severe Traumatic Brain Injury "},
journal = {"Archives of Physical Medicine and Rehabilitation "},
volume = {"95"},
number = {"2"},
pages = {"397 - 400"},
year = {"2014"},
note = {""},
issn = {"0003-9993"},
doi = {"https://doi.org/10.1016/j.apmr.2013.10.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0003999313011180"},
author = {"James F. Sumowski and Julia Coyne and Amanda Cohen and John DeLuca"},
keywords = {"Brain trauma", "Memory", "Rehabilitation", "Traumatic brain injuries "},
abstract = {"AbstractObjective To investigate whether retrieval practice (RP) improves delayed recall after short and long delays in survivors of severe traumatic brain injury (TBI) relative to massed restudy (MR) and spaced restudy (SR). Design 3(learning condition: MR, SR, RP)×2(delayed recall: 30min, 1wk) within-subject experiment. Setting Nonprofit medical rehabilitation research center. Participants Memory-impaired (&lt;5th percentile) survivors of severe \{TBI\} (N=10). Intervention During RP, patients are quizzed on to-be-learned information shortly after it is presented, such that patients practice retrieval. \{MR\} consists of repeated restudy (ie, cramming). \{SR\} consists of restudy trials separated in time (ie, distributed learning). Main Outcome Measures Forty-eight verbal paired associates (VPAs) were equally divided across 3 learning conditions (16 per condition). Delayed recall for one half of the \{VPAs\} was assessed after 30 minutes (8 per condition) and for the other half after 1 week (8 per condition). Results There was a large effect of learning condition after the short delay (P&lt;.001, η2=.72), with much better recall of \{VPAs\} studied through \{RP\} (46.3%) relative to \{MR\} (12.5%) and \{SR\} (15.0%). This large effect of learning condition remained after the long delay (P=.001, η2=.56), as patients recalled 11.3% of the \{VPAs\} studied through RP, but nothing through \{MR\} (0.0%) and only 1.3% through SR. That is, \{RP\} was essentially the only learning condition to result in successful recall after 1 week, with most patients recalling at least 1 VPA. Conclusions The robust effect of \{RP\} among \{TBI\} survivors with severe memory impairment engenders confidence that this strategy would work outside the laboratory to improve memory in real-life settings. Future randomized controlled trials of \{RP\} training are needed. "} 
}
@incollection{Cleary201477,
title = {"Chapter Three - The Sense of Recognition during Retrieval Failure: Implications for the Nature of Memory Traces "},
editor = {"Brian H. Ross"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2014"},
volume = {"60"},
pages = {"77 - 112"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/B978-0-12-800090-8.00003-2"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128000908000032"},
author = {"Anne M. Cleary"},
keywords = {"Recognition without cued recall", "Recognition without identification", "Features", "Feature keywords =atching", "Familiarity-based recognition", "Retrieval failure", "Familiarity signal", "Semantic features", "Memory trace", "Engram "},
abstract = {"Abstract What produces a sense of recognition with a situation when no prior experience with it comes to mind? Research suggests that resemblance of a new situation to one or more in memory can lead to the sense of recognition when retrieval fails. The process responsible for this sense during retrieval failure is likely feature matching, whereby features in a current situation are matched to features stored in memory to produce a sense of familiarity. This supports the long-held idea that memory traces are basically sets of features or elements from earlier experiences. However, the work presented here goes beyond merely suggesting the existence of features within memory traces; the focus of the work presented here is on the following questions: What is a feature? What exactly are the features or elements of experiences that are somehow tied together within memory traces? This chapter describes how research on the sense of recognition during retrieval failure has been used to systematically identify features of experiences that can lead to recognition. "} 
}
@article{Efremenko2014128,
title = {"Optical property dimensionality reduction techniques for accelerated radiative transfer performance: Application to remote sensing total ozone retrievals "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"133"},
number = {""},
pages = {"128 - 135"},
year = {"2014"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2013.07.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407313003166"},
author = {"Dmitry Efremenko and Adrian Doicu and Diego Loyola and Thomas Trautmann"},
keywords = {"Dimensionality reduction techniques", "Accelerated radiative transfer", "Trace gas retrievals "},
abstract = {"Abstract In this paper, we introduce several dimensionality reduction techniques for optical parameters. We consider the principal component analysis, the local linear embedding methods (locality pursuit embedding, locality preserving projection, locally embedded analysis), and discrete orthogonal transforms (cosine, Legendre, wavelet). The principle component analysis has already been shown to be an effective and accurate method of enhancing radiative transfer performance for simulations in an absorbing and a scattering atmosphere. By linearizing the corresponding radiative transfer model, we analyze the applicability of the proposed methods to a practical problem of total ozone column retrieval from UV-backscatter measurements. "} 
}
@article{Zheng2014302,
title = {"Absolute phase retrieval for defocused fringe projection three-dimensional measurement "},
journal = {"Optics Communications "},
volume = {"312"},
number = {""},
pages = {"302 - 311"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2013.09.056"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401813008778"},
author = {"Dongliang Zheng and Feipeng Da"},
keywords = {"Three-dimensional measurement", "Fringe projection", "Absolute phase retrieval", "Pulse-width modulation "},
abstract = {"Abstract Defocused fringe projection three-dimensional technique based on pulse-width modulation (PWM) can generate high-quality sinusoidal fringe patterns. It only uses slightly defocused binary structured patterns which can eliminate the gamma problem (i.e. nonlinear response), and the phase error can be significantly reduced. However, when the projector is defocused, it is difficult to retrieve the absolute phase from the wrapped phase. A recently proposed phase coding method is efficient for absolute phase retrieval, but the gamma problem leads this method not so reliable. In this paper, we use the \{PWM\} technique to generate fringe patterns for the phase coding method. The gamma problem of the projector can be eliminated, and correct absolute phase can be retrieved. The proposed method only uses two grayscale values (0's and 255's), which can be used for real-time 3D shape measurement. Both simulation and experiment demonstrate the performance of the proposed method. "} 
}
@article{Iwen2017135,
title = {"Robust sparse phase retrieval made easy "},
journal = {"Applied and Computational Harmonic Analysis "},
volume = {"42"},
number = {"1"},
pages = {"135 - 142"},
year = {"2017"},
note = {""},
issn = {"1063-5203"},
doi = {"https://doi.org/10.1016/j.acha.2015.06.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S1063520315000937"},
author = {"Mark Iwen and Aditya Viswanathan and Yang Wang"},

abstract = {"Abstract In this short note we propose a simple two-stage sparse phase retrieval strategy that uses a near-optimal number of measurements, and is both computationally efficient and robust to measurement noise. In addition, the proposed strategy is fairly general, allowing for a large number of new measurement constructions and recovery algorithms to be designed with minimal effort. "} 
}
@article{Yan2014601,
title = {"Correction of wave-front retrieval errors caused by the imperfect collimation of reference beam in phase-shifting interferometry "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"125"},
number = {"2"},
pages = {"601 - 605"},
year = {"2014"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2012.05.054"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402613010565"},
author = {"R.S. Yan and L.Z. Cai and X.F. Meng"},
keywords = {"Holographic interferometry", "Image reconstruction", "Image forming and processing", "Phase retrieval "},
abstract = {"Abstract In phase-shifting interferometry (PSI) the standard wave retrieval formulae are usually derived based on the condition of a plane reference beam normal to the recording plane. In practice, however, the reference wave may be a spherical wave of large radius or even have a slight inclination at the same time due to the imperfect collimation and coaxality of the optical system, and this fact will introduce phase distortion for the reconstructed object wave-front. A simple digital processing algorithm without any additional measurements is proposed to determine the unknown parameters of the spherical reference wave and then correct the object wave errors reconstructed with standard wave retrieval formulae. The effectiveness of this method is verified by a series of computer simulations, and its limitation is also discussed. "} 
}
@article{Wang2017251,
title = {"Effects of thalamic hemorrhagic lesions on explicit and implicit learning during the acquisition and retrieval phases in an animal model of central post-stroke pain "},
journal = {"Behavioural Brain Research "},
volume = {"317"},
number = {""},
pages = {"251 - 262"},
year = {"2017"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2016.09.053"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432816307094"},
author = {"Cheng Chung Wang and Hsi-Chien Shih and Bai Chuang Shyu and Andrew Chih Wei Huang"},
keywords = {"Central post-stroke pain", "Conditioned place preference", "Spatial learning", "Morris water maze", "Motor function", "Ventrobasal complex nuclei of the thalamus "},
abstract = {"Abstract Hemorrhagic stroke has many symptoms, including central pain, learning and memory impairments, motor deficits, language problems, emotional disturbances, and social maladjustment. Lesions of the ventral basal complex (VBC) of the thalamus elicit thermal and mechanical hyperalgesia, forming an animal model of central post-stroke pain (CPSP). However, no research has yet examined the involvement of learning and memory in \{CPSP\} using an animal model. The present study examined whether \{VBC\} lesions affect motor function, conditioned place preference (CPP; implicit memory), and spatial learning (explicit memory) in the acquisition and retrieval phases. The results showed that rats with \{VBC\} lesions exhibited thermal hyperalgesia in the acquisition and retrieval phases, indicating that these lesions can induce CPSP. During these phases, the rats with \{VBC\} lesions exhibited enhanced (morphine-induced) \{CPP\} learning. These lesions did not affect the rats’ total distance travelled, time spent, or velocity in the spatial learning tasks. The lesions also did not affect motor function in the rotarod task. Altogether, \{VBC\} lesions resulted in \{CPSP\} and facilitated \{CPP\} (implicit memory). However, the lesions did not affect spatial learning (explicit memory) or motor function. The relationship between \{CPSP\} and learning and memory is important for patients who suffer from such central pain. The implications of the present study may provide insights into helping reduce \{CPSP\} and its associated symptoms. "} 
}
@article{Zhang201416,
title = {"ObjectPatchNet: Towards scalable and semantic image annotation and retrieval "},
journal = {"Computer Vision and Image Understanding "},
volume = {"118"},
number = {""},
pages = {"16 - 29"},
year = {"2014"},
note = {""},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2013.03.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314213001574"},
author = {"Shiliang Zhang and Qi Tian and Gang Hua and Qingming Huang and Wen Gao"},
keywords = {"Visual vocabulary", "Large-scale image retrieval", "Image annotation "},
abstract = {"Abstract The ever increasing Internet image collection densely samples the real world objects, scenes, etc. and is commonly accompanied with multiple metadata such as textual descriptions and user comments. Such image data has potential to serve as a knowledge source for large-scale image applications. Facilitated by such publically available and ever-increasing loosely annotated image data on the Internet, we propose a scalable data-driven solution for annotating and retrieving Web-scale image data. We extrapolate from large-scale loosely annotated images a compact and informative representation, namely ObjectPatchNet. Each vertex in ObjectPatchNet, which is called as an ObjectPatchNode, is defined as a collection of discriminative image patches annotated with object category labels. The edge linking two ObjectPatchNodes models the co-occurrence relationship among different objects in the same image. Therefore, ObjectPatchNet models not only probabilistically labeled image patches, but also the contextual relationship between objects. It is well suited to scalable image annotation task. Besides, we further take ObjectPatchNet as a visual vocabulary with semantic labels, and hence are able to easily develop inverted file indexing for efficient semantic image retrieval. ObjectPatchNet is tested on both large-scale image annotation and large-scale image retrieval applications. Experimental results manifest that ObjectPatchNet is both discriminative and efficient in these applications. "} 
}
@article{ElAlami2014407,
title = {"A new matching strategy for content based image retrieval system "},
journal = {"Applied Soft Computing "},
volume = {"14, Part C"},
number = {""},
pages = {"407 - 418"},
year = {"2014"},
note = {""},
issn = {"1568-4946"},
doi = {"https://doi.org/10.1016/j.asoc.2013.10.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1568494613003372"},
author = {"M.E. ElAlami"},
keywords = {"Content-based image retrieval", "Color co-occurrence matrix", "Dimensionality reduction", "Artificial neural networks", "Similarity measure "},
abstract = {"Abstract Adopting effective model to access the desired images is essential nowadays with the presence of a huge amount of digital images. The present paper introduces an accurate and rapid model for content based image retrieval process depending on a new matching strategy. The proposed model is composed of four major phases namely: features extraction, dimensionality reduction, \{ANN\} classifier and matching strategy. As for the feature extraction phase, it extracts a color and texture features, respectively, called color co-occurrence matrix (CCM) and difference between pixels of scan pattern (DBPSP). However, integrating multiple features can overcome the problems of single feature, but the system works slowly mainly because of the high dimensionality of the feature space. Therefore, the dimensionality reduction technique selects the effective features that jointly have the largest dependency on the target class and minimal redundancy among themselves. Consequently, these features reduce the calculation work and the computation time in the retrieval process. The artificial neural network (ANN) in our proposed model serves as a classifier so that the selected features of query image are the input and its output is one of the multi classes that have the largest similarity to the query image. In addition, the proposed model presents an effective feature matching strategy that depends on the idea of the minimum area between two vectors to compute the similarity value between a query image and the images in the determined class. Finally, the results presented in this paper demonstrate that the proposed model provides accurate retrieval results and achieve improvement in performance with significantly less computation time compared with other models. "} 
}
@article{Takamura2014410,
title = {"Wear Analysis of 39 Conserve Plus Metal-on-Metal Hip Resurfacing Retrievals "},
journal = {"The Journal of Arthroplasty "},
volume = {"29"},
number = {"2"},
pages = {"410 - 415"},
year = {"2014"},
note = {""},
issn = {"0883-5403"},
doi = {"https://doi.org/10.1016/j.arth.2013.05.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S0883540313004129"},
author = {"Karren M. Takamura and Harlan C. Amstutz and Zhen Lu and Pat A. Campbell and Edward Ebramzadeh"},
keywords = {"metal-on-metal", "wear", "ALTR", "hip resurfacing", "arthroplasty", "implant retrieval "},
abstract = {"Abstract There have been increasing concerns regarding adverse local tissue reactions (ALTR) following metal-on-metal (MOM) hip arthroplasties. This study examined wear rates in retrievals of one design of \{MOM\} resurfacing arthroplasty, and assessed the differences in wear between those with and without ALTR. Wear measurements were made on 39 \{MOM\} resurfacing components (30 femoral, 9 acetabular) which were at least 2 years in vivo. Seven hips (6 patients; 4 acetabular components, 7 femoral components) were identified to have ALTR. Acetabular component abduction and anteversion angles were determined using EBRA, and the contact-patch-to-rim (CPR) distance was calculated. The \{ALTR\} group had higher linear femoral and acetabular wear rates, acetabular anteversion and abduction angles, lower CPR, and longer time to revision. Given the increased risk for \{ALTR\} associated with acetabular component malpositioning, patients with malpositioned acetabular components may require closer clinical follow-up and monitoring. "} 
}
@article{Efremenko201458,
title = {"Acceleration of radiative transfer model calculations for the retrieval of trace gases under cloudy conditions "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"135"},
number = {""},
pages = {"58 - 65"},
year = {"2014"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2013.11.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S002240731300469X"},
author = {"Dmitry S. Efremenko and Diego G. Loyola and Robert J.D. Spurr and Adrian Doicu"},
keywords = {"Fast radiative transfer model", "Cloud", "Ozone retrieval "},
abstract = {"Abstract In the independent pixel approximation (IPA), radiative transfer computations involving cloudy scenes require two separate calls to the radiative transfer model (RTM), one call for a clear sky scenario, the other for an atmosphere containing clouds. In this paper, clouds are considered as an optically homogeneous layer. We present two novel methods for \{RTM\} performance enhancement with particular application to trace gas retrievals under cloudy conditions. Both methods are based on reusing results from clear-sky \{RTM\} calculations to speed up corresponding calculations for the cloud-filled scenario. The first approach is numerically exact, and has been applied to the discrete-ordinate with matrix exponential (DOME) RTM. Results from the original clear sky computation can be saved in the memory and reused for the non-cloudy layers in the second computation. In addition, for the whole-atmosphere boundary-value approach to the determination of the intensity field, we can exploit a ’telescoping technique’ to reduce the dimensionality (and hence the computational effort for the solution) of the boundary value problem in the absence of Rayleigh scattering contributions for higher azimuthal components of the radiation field. The second approach is (for the cloudy scenario) to generate a spectral correction applied to the radiation field from a fast two-stream RTM. This correction is based on the use of principal-component analysis (PCA) applied to a given window of spectral optical property data, in order to exploit redundancy in the data and confine the number of full-stream multiple scatter computations to the first few \{EOFs\} (Empirical Orthogonal Functions) arising from the PCA. This method has been applied to the \{LIDORT\} RTM; although the method involves some approximation, it provides accuracy better than 0.2%, and a speed-up factor of approximately 2 compared with two calls of RTM. "} 
}
@article{Chikano2014214,
title = {"Recovery and localization of handwritings by a camera-pen based on tracking and document image retrieval "},
journal = {"Pattern Recognition Letters "},
volume = {"35"},
number = {""},
pages = {"214 - 224"},
year = {"2014"},
note = {"Frontiers in Handwriting Processing "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2012.10.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865512003339"},
author = {"Megumi Chikano and Koichi Kise and Masakazu Iwamura and Seiichi Uchida and Shinichiro Omachi"},
keywords = {"Camera-pen", "Document image retrieval", "LLAH", "SURF", "LK tracking", "Handwriting "},
abstract = {"Abstract We propose a camera-based method for digital recovery of handwritings on ordinary paper. Our method is characterized by the following two points: (1) it requires no special device such as special paper other than a camera-pen to recover handwritings, (2) if the handwriting is on a printed document, the method is capable of localizing it onto an electronic equivalent of the printed document. The above points are enabled by the following processing. The handwriting is recovered by the \{LK\} tracking to trace the move of the pen-tip. The recovered shape is localized onto the corresponding part of the electronic document with the help of document image retrieval called \{LLAH\} (locally likely arrangement hashing). A new framework for stably estimating the homography from a camera-captured image to the corresponding electronic document allows us to localize the recovered handwritings accurately. We experimentally evaluate the accuracy, processing time and memory usage of the proposed method using 30 handwritings. From the comparison to other methods that implement alternative ways for realizing the same functionality, we have confirmed that the proposed method is superior to those other methods. "} 
}
@incollection{Sutcliffe2017,
title = {"Object Retrieval-Detour Task☆ "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.00711-2"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245007112"},
author = {"J.S. Sutcliffe and S. Palfi"},
keywords = {"Frontal cortex", "Huntington disease", "Nonhuman primate model", "Striatal degeneration", "Subcortical cognitive deficit "},
abstract = {"Abstract The object retrieval detour task (ORDT) is a task designed to assess the functional and anatomical integrity of the fronto-striatal pathway in humans and nonhuman primates. This entry describes the \{ORDT\} task and its potential to detect a deficit and a restoration of a frontal-type cognitive deficit in primate displaying striatal pathologies. "} 
}
@article{Alton201774,
title = {"Retrieval of seasonal Rubisco-limited photosynthetic capacity at global \{FLUXNET\} sites from hyperspectral satellite remote sensing: Impact on carbon modelling "},
journal = {"Agricultural and Forest Meteorology "},
volume = {"232"},
number = {""},
pages = {"74 - 88"},
year = {"2017"},
note = {""},
issn = {"0168-1923"},
doi = {"https://doi.org/10.1016/j.agrformet.2016.08.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0168192316303483"},
author = {"Paul B. Alton"},
keywords = {"Carbon cycle", "Land-surface modelling", "Photosynthetic capacity", "Moderate Resolution Imaging Spectroradiometer (MODIS)", "FLUXNET", "MEdium Resolution Imaging Spectrometer (MERIS) "},
abstract = {"Abstract Process-based ecophysiological models, which simulate carbon exchange at the land-surface, are powerful and indispensable tools for understanding how vegetation behaves under present and future climate. However, these models are necessarily complex, containing numerous biophysical parameters which are often poorly defined. The current study develops a novel retrieval of Rubisco-limited top-of-canopy photosynthetic capacity (i.e. maximum carboxylation rate, V cmax 25 , toc ), which is one of the most critical parameters in the calculation of Gross Primary Productivity (GPP). The retrieval combines standard remote sensing satellite products of Leaf Area Index (LAI), from the Moderate Resolution Imaging Spectroradiometer (MODIS), with a hyperspectral index of total canopy chlorophyll concentration from the \{MEdium\} Resolution Imaging Spectrometer (MERIS). Monthly values of V cmax 25 , toc are determined over a 9 year period for 296 global \{FLUXNET\} sites (catalogue made available online) and 8 Plant Functional Types (PFTs). \{PFT\} averages agree favourably with compilations of field-based measurements. However, according to a Monte Carlo analysis, our method is still currently subject to large systematic uncertainties (25–30%), much of which arises from the empirical relationship between maximum electron transport and leaf chlorophyll content. For all 8 PFTs, except tropical broadleaf forest, V cmax 25 , toc varies considerably across the season (generally a factor of 1.6). Similarly, variability between sites of the same \{PFT\} is significant (interquartile range is 40% of the median). This suggests an important additional role for satellites in the spatial and temporal parameterisation of carbon models. Inclusion of this temporal and spatial variability in a process-based ecophysiological model produces, respectively, an impact of 11% and 12% on simulated GPP. "} 
}
@article{Sobin2017,
title = {"Early chronic low-level Pb exposure alters global exploratory behaviors but does not impair spatial and object memory retrieval in an object-in-place task in pre-adolescent C57BL/6J mice "},
journal = {"Neurotoxicology and Teratology "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0892-0362"},
doi = {"https://doi.org/10.1016/j.ntt.2017.01.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0892036217300247"},
author = {"Christina Sobin and Mayra Gisel Flores-Montoya and Juan Manuel Alvarez"},
keywords = {"Developmental lead exposure", "Low-level lead exposure", "Visual spatial memory", "Visual object memory", "Mouse behavior "},
abstract = {"Abstract The mechanisms by which early chronic low-level lead (Pb) exposure disrupts the developing brain are not yet understood. Rodent models have provided promising results however behavioral tests sensitive to effects at lowest levels of exposure during development are needed. Preadolescent animals (N = 52) exposed to low and higher levels of Pb via lactation from birth to \{PND\} 28 completed the Object-in-Place Task of visual spatial and visual object memory retrieval (at \{PND\} 28). Generalized linear mixed models were used, controlling for sex and litter as a random effect. As compared with controls, global vertical exploratory behavior (rearing) markedly increased during memory retrieval. The findings suggested that early chronic Pb exposure altered the development of critical exploratory functions needed for learning and survival. Behaviors exhibited in novel spatial and novel object zone perimeters suggested that the Object-in-Place task is a valid measure of visual spatial and visual object memory in pre-adolescent C57BL/6J mice. Additional studies are needed to understand how early chronic low-level lead exposure disrupts the trajectory and possible linkages of critical exploratory and perceptual systems during development. "} 
}
@article{Onykiy2016336,
title = {"Agent Technologies for Polythematic Organizations Information-Analytical Support "},
journal = {"Procedia Computer Science "},
volume = {"88"},
number = {""},
pages = {"336 - 340"},
year = {"2016"},
note = {"7th Annual International Conference on Biologically Inspired Cognitive Architectures, \{BICA\} 2016, held July 16 to July 19, 2016 in New York City, NY, \{USA\} "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.07.445"},
url = {"http://www.sciencedirect.com/science/article/pii/S187705091631701X"},
author = {"Boris Onykiy and Alexey Artamonov and Anastasia Ananieva and Evheniy Tretyakov and Larisa Pronicheva and Kristina Ionkina and Alyona Suslina"},
keywords = {"agent", "multi-agent system", "Big Data", "Data mining", "retrieval system", "information and analytical system "},
abstract = {"Abstract Large scientific organizations, laboratories, departments and scientific groups exercise need in information support due to issues related to the navigation among huge amount of information in the Internet that is growing every day. This paper describes agent-based approach that is used in Multi-agent information and analytical system (MIAS) developed at the National Research Nuclear University “MEPhI” and addressed challenges in the information support that was encountered by our partners: the “Plasma Physics” Department, Department of “Laser physics”, laboratory “Photonics” and others. The \{MIAS\} support of object-oriented approach and international standards of linked data contributes to the development of future information systems that will enable forecasting on specific scientific field. "} 
}
@article{Harrison2017139,
title = {"New and improved infra-red absorption cross sections and ACE-FTS retrievals of carbon tetrachloride (CCl4) "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"186"},
number = {""},
pages = {"139 - 149"},
year = {"2017"},
note = {"Satellite Remote Sensing and Spectroscopy: Joint ACE-Odin Meeting, October 2015 "},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.04.025"},
url = {"http://www.sciencedirect.com/science/article/pii/S002240731630108X"},
author = {"Jeremy J. Harrison and Christopher D. Boone and Peter F. Bernath"},
keywords = {"CCl4", "Carbon tetrachloride", "High-resolution Fourier transform spectroscopy", "Infra-red absorption cross sections", "Remote sensing", "Atmospheric chemistry "},
abstract = {"Abstract Carbon tetrachloride (CCl4) is one of the species regulated by the Montreal Protocol on account of its ability to deplete stratospheric ozone. As such, the inconsistency between observations of its abundance and estimated sources and sinks is an important problem requiring urgent attention (Carpenter et al., 2014) [5]. Satellite remote-sensing has a role to play, particularly limb sounders which can provide vertical profiles into the stratosphere and therefore validate stratospheric loss rates in atmospheric models. This work is in two parts. The first describes new and improved high-resolution infra-red absorption cross sections of carbon tetrachloride/dry synthetic air over the spectral range 700–860 cm−1 for a range of temperatures and pressures (7.5–760 Torr and 208–296 K) appropriate for atmospheric conditions. This new cross-section dataset improves upon the one currently available in the \{HITRAN\} and \{GEISA\} databases. The second describes a new, preliminary ACE-FTS carbon tetrachloride retrieval that improves upon the v3.0/v3.5 data products, which are biased high by up to ~20–30% relative to ground measurements. Making use of the new spectroscopic data, this retrieval also improves the microwindow selection, contains additional interfering species, and utilises a new instrumental lineshape; it will form the basis for the upcoming v4.0 \{CCl4\} data product. "} 
}
@article{Qing201464,
title = {"Remote sensing retrieval of inorganic suspended particle size in the Bohai Sea "},
journal = {"Continental Shelf Research "},
volume = {"73"},
number = {""},
pages = {"64 - 71"},
year = {"2014"},
note = {""},
issn = {"0278-4343"},
doi = {"https://doi.org/10.1016/j.csr.2013.11.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0278434313003919"},
author = {"Song Qing and Jie Zhang and Tingwei Cui and Yuhai Bao"},
keywords = {"Inorganic suspended particle size", "Remote sensing retrieval", "Bohai Sea", "MERIS", "MODIS "},
abstract = {"Abstract In situ data set in the Bohai Sea of China was collected to test a previous model for surface water inorganic suspended particle size developed by Bowers et al. Based on this, a simple empirical model was then established for estimating median particle size in the Bohai Sea. The median inorganic suspended particle size was retrieved from ratio of green (560 nm) to red (665 nm) band. The model produced retrieval of particle sizes which are in good agreement with in situ measurements with the average percent difference of 27.0% (N=40, R2=0.55) and root mean squared deviation of 4.311 μm. This model was quite insensitive to input noises. Then the model was applied to \{MERIS\} Level 2 data and \{MODIS\} Level 3 data (monthly climatology) to analyze the spatio-temporal pattern and seasonal variability of inorganic suspended particle size in the Bohai Sea. The size of inorganic suspended particles was expected to be related to water turbulence. Wind was idendified as an important influencing factor of particle size distribution. There was an onshore to offshore gradient in inorganic suspended particle size in the Bohai Sea. A significant seasonal cycle exits in particle sizes (large in summer and small in winter). More independent dataset was needed for further research. "} 
}
@article{Kokkalis2017255,
title = {"Validation of \{LIRIC\} aerosol concentration retrievals using airborne measurements during a biomass burning episode over Athens "},
journal = {"Atmospheric Research "},
volume = {"183"},
number = {""},
pages = {"255 - 267"},
year = {"2017"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2016.09.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809516303337"},
author = {"Panagiotis Kokkalis and Vassilis Amiridis and James D. Allan and Alexandros Papayannis and Stavros Solomos and Ioannis Binietoglou and Aikaterini Bougiatioti and Alexandra Tsekeri and Athanasios Nenes and Philip D. Rosenberg and Franco Marenco and Eleni Marinou and Jeni Vasilescu and Doina Nicolae and Hugh Coe and Asan Bacak and Anatoli Chaikovsky"},
keywords = {"Lidar", "Inversion", "Airborne measurements "},
abstract = {"Abstract In this paper we validate the Lidar-Radiometer Inversion Code (LIRIC) retrievals of the aerosol concentration in the fine mode, using the airborne aerosol chemical composition dataset obtained over the Greater Athens Area (GAA) in Greece, during the \{ACEMED\} campaign. The study focuses on the 2nd of September 2011, when a long-range transported smoke layer was observed in the free troposphere over Greece, in the height range from 2 to 3 km. \{CIMEL\} sun-photometric measurements revealed high \{AOD\} (~ 0.4 at 532 nm) and Ångström exponent values (~ 1.7 at 440/870 nm), in agreement with coincident ground-based lidar observations. Airborne chemical composition measurements performed over the GAA, revealed increased \{CO\} volume concentration (~ 110 ppbv), with 57% sulphate dominance in the \{PM1\} fraction. For this case, we compare \{LIRIC\} retrievals of the aerosol concentration in the fine mode with the airborne Aerosol Mass Spectrometer (AMS) and Passive Cavity Aerosol Spectrometer Probe (PCASP) measurements. Our analysis shows that the remote sensing retrievals are in a good agreement with the measured airborne in-situ data from 2 to 4 km. The discrepancies observed between \{LIRIC\} and airborne measurements at the lower troposphere (below 2 km), could be explained by the spatial and temporal variability of the aerosol load within the area where the airborne data were averaged along with the different time windows of the retrievals. "} 
}
@article{Qin2014193,
title = {"Compressed sensing phase retrieval with phase diversity "},
journal = {"Optics Communications "},
volume = {"310"},
number = {""},
pages = {"193 - 198"},
year = {"2014"},
note = {""},
issn = {"0030-4018"},
doi = {"https://doi.org/10.1016/j.optcom.2013.08.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030401813007232"},
author = {"Shun Qin and Xinqi Hu and Qiong Qin"},
keywords = {"Compressed sensing", "Phase retrieval", "Phase diversity", "Complex object", "HIO algorithm", "ℓ 0 norm constrain "},
abstract = {"Abstract The compressed sensing (CS) theory shows that sparse signal can be reconstructed accurately with some randomly observed measurements that are much fewer than what traditional method requires. Since it takes structure of signals into consideration, it has many advantages in the structured signals process. With CS, measuring can be speeded up and the cost of hardware can be decreased significantly. However, it faces great challenge in the amplitude-only measurement. In this article, we study the magnitude-only compressed sensing phase retrieval (CSPR) problem, and propose a practical recovery algorithm. In our algorithm, we introduce the powerful Hybrid-Input–Output algorithm with phase diversity to make our algorithm robust and efficient. A relaxed ℓ 0 norm constrain is also introduced to help \{PR\} find a sparse solution with fewer measurements, which is demonstrated to be essential and effective to CSPR. We finally successfully apply it into complex-valued object recovery in \{THz\} imaging. The numerical results show that the proposed algorithm can recover the object pretty well with fewer measurements than what \{PR\} traditionally requires. "} 
}
@article{Meurer2017255,
title = {"Rapid Systematic Review: Intra-Arterial Thrombectomy (“Clot Retrieval”) for Selected Patients with Acute Ischemic Stroke "},
journal = {"The Journal of Emergency Medicine "},
volume = {"52"},
number = {"2"},
pages = {"255 - 261"},
year = {"2017"},
note = {""},
issn = {"0736-4679"},
doi = {"https://doi.org/10.1016/j.jemermed.2016.10.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0736467916308794"},
author = {"William J. Meurer and Bradley E. Barth and Gary Gaddis and Gary M. Vilke and Samuel H.F. Lam"},
keywords = {"acute ischemic stroke", "mechanical intra-arterial thrombectomy", "rapid review "},
abstract = {"AbstractBackground Acute ischemic stroke (AIS) is a leading cause of morbidity and mortality. However, precisely defining the optimal treatment for individual patients early after \{AIS\} onset remains elusive. There has recently been a surge in published studies documenting the effectiveness of mechanical intra-arterial thrombectomy for treatment of a subset of patients with AIS. This therapy has been proposed and studied for the small (&lt;1.2%) subgroup of patients with ischemic strokes who have “large vessel” strokes or strokes that fail to improve after the administration of tissue plasminogen activator (t-PA). The current rapid systematic review provides practicing emergency physicians updated information regarding mechanical thrombectomy as a treatment option for carefully selected \{AIS\} patients. Methods A PubMed literature search was conducted from January 1996 to June 2016 and limited to human clinical trials written in English with relevant keywords. High-quality randomized controlled studies identified then underwent a structured review. Results In total, 179 papers fulfilling the search criteria were screened and 8 appropriate articles were rigorously reviewed in detail and recommendations given on the effectiveness and indication of mechanical intra-arterial thrombectomy for the treatment of AIS. Conclusions Mechanical intra-arterial thrombectomy reduces long-term disability in a properly selected subset of patients who have an \{AIS\} caused by large vessel occlusion. Many of these patients will have failed to improve after intravenous administration of t-PA, and mortality is not increased when combined with t-PA. Careful screening criteria should be in place to identify the limited subset of patients to whom this therapy is delivered to derive optimal treatment benefits. "} 
}
@article{Cho201795,
title = {"Does \{AMSR2\} produce better soil moisture retrievals than AMSR-E over Australia? "},
journal = {"Remote Sensing of Environment "},
volume = {"188"},
number = {""},
pages = {"95 - 105"},
year = {"2017"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.10.050"},
url = {"http://www.sciencedirect.com/science/article/pii/S003442571630428X"},
author = {"Eunsang Cho and Chun-Hsu Su and Dongryeol Ryu and Hyunglok Kim and Minha Choi"},
keywords = {"Remotely sensed soil moisture", "Microwave sensor", "AMSR2", "AMSR-E", "MERRA-L", "Evaluation", "Error estimation "},
abstract = {"Abstract The Advanced Microwave Scanning Radiometer 2 (AMSR2), a follow-up microwave sensor to the \{AMSR\} for Earth Observing System (AMSR-E), was launched on the Global Change Observation Mission 1 – Water (GCOM-W1) satellite in May 2012. It is as yet unclear if instrumental improvements in \{AMSR2\} over AMSR-E have led to better soil moisture (SM) estimates, especially since there is no overlapping period of data between the sensors. This study focuses on comparing the results of \{AMSR2\} and AMSR-E \{SM\} over Australia, distinguishing four Köppen climate zones to determine if \{AMSR2\} is better than AMSR-E. This is achieved by selecting two year-long comparative time periods from the operating periods of AMSR-E and AMSR2, based on their statistical similarities in modeled \{SM\} as a proxy, using Modern Era Retrospective-analysis for Research and Applications-Land (MERRA-L). The \{AMSR2\} and AMSR-E C- and X-band \{SM\} derived from the Land Parameter Retrieval Model (LPRM) was evaluated. Both \{AMSR2\} C- and X-band \{SM\} products were found to show similar temporal patterns and spatial agreement with AMSR-E C- and X-band SM, supported by unbiased root mean square difference (ubRMSD) and R-values with MERRA-L SM, respectively. Using lag-based instrumental variable analysis to estimate the random error component of \{SM\} retrievals, the noise-to-signal ratios in \{AMSR2\} X-band \{SM\} were found to be slightly higher than their AMSR-E counterparts. The improvements in AMSR2, such as the superior radiometric sensitivity and spatial resolution, have therefore not led to statistically significant differences in performance for \{LPRM\} retrievals at 1/2° × 1/2° grid resolution, when compared with AMSR-E. However, similarities in the metrics for \{AMSR2\} and AMSR-E \{SM\} suggest that \{AMSR2\} provides a valuable continuation to AMSR-E. "} 
}
@article{Mustacoglu201620,
title = {"A novel digital information service for federating distributed digital entities "},
journal = {"Information Systems "},
volume = {"55"},
number = {""},
pages = {"20 - 36"},
year = {"2016"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2015.07.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437915001350"},
author = {"Ahmet F. Mustacoglu and Geoffrey C. Fox"},
keywords = {"Web services and Service-Oriented computing", "SOA", "Web 2.0", "Data management", "Information retrieval and management", "Federation and unifications "},
abstract = {"Abstract We investigate the performance and the scalability metrics of a Digital Information Service framework that is used for unifying and federating online digital entities by retrieving and managing information located on the web. The Digital Information Service consists of tools and web services for supporting Cyberinfrastructure based scientific research. This system supports a number of existing online Web 2.0 research tools (social bookmarking, academic search, scientific databases, journal and conference content management systems) and aims to develop added-value community building tools that leverage the management and federation of digital entities and their metadata obtained from multiple services. We introduce a prototype implementation and present its evaluation. As the results indicate, the proposed system achieves federation and unification of digital entities coming from different sources with negligible processing overheads. "} 
}
@article{Joho2015834,
title = {"Temporal information searching behaviour and strategies "},
journal = {"Information Processing & Management "},
volume = {"51"},
number = {"6"},
pages = {"834 - 850"},
year = {"2015"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2015.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457315000448"},
author = {"Hideo Joho and Adam Jatowt and Roi Blanco"},
keywords = {"Temporal information retrieval", "Information searching behaviour", "Search strategies", "User study "},
abstract = {"Abstract Temporal aspects have been receiving a great deal of interest in Information Retrieval and related fields. Although previous studies have proposed, designed and implemented temporal-aware systems and solutions, understanding of people’s temporal information searching behaviour is still limited. This paper reports the findings of a user study that explored temporal information searching behaviour and strategies in a laboratory setting. Information needs were grouped into three temporal classes (Past, Recency, and Future) to systematically study their characteristics. The main findings of our experiment are as follows. (1) It is intuitive for people to augment topical keywords with temporal expressions such as history, recent, or future as a tactic of temporal search. (2) However, such queries produce mixed results and the success of query reformulations appears to depend on topics to a large extent. (3) Search engine interfaces should detect temporal information needs to trigger the display of temporal search options. (4) Finding a relevant Wikipedia page or similar summary page is a popular starting point of past information needs. (5) Current search engines do a good job for information needs related to recent events, but more work is needed for past and future tasks. (6) Participants found it most difficult to find future information. Searching for domain experts was a key tactic in Future search, and file types of relevant documents are different from other temporal classes. Overall, the comparison of search across temporal classes indicated that Future search was the most difficult and the least successful followed by the search for the Past and then for Recency information. This paper discusses the implications of these findings on the design of future temporal \{IR\} systems. "} 
}
@article{Pardini201779,
title = {"Retrieval and intercomparison of volcanic \{SO2\} injection height and eruption time from satellite maps and ground-based observations "},
journal = {"Journal of Volcanology and Geothermal Research "},
volume = {"331"},
number = {""},
pages = {"79 - 91"},
year = {"2017"},
note = {""},
issn = {"0377-0273"},
doi = {"https://doi.org/10.1016/j.jvolgeores.2016.12.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S037702731630244X"},
author = {"Federica Pardini and Mike Burton and Mattia de' Michieli Vitturi and Stefano Corradini and Giuseppe Salerno and Luca Merucci and Giuseppe Di Grazia"},
keywords = {"Volcanic SO2", "Trajectory modelling", "Remote sensing", "Volcanic tremor "},
abstract = {"Abstract Syneruptive gas flux time series can, in principle, be retrieved from satellite maps of \{SO2\} collected during and immediately after volcanic eruptions, and used to gain insights into the volcanic processes which drive the volcanic activity. Determination of the age and height of volcanic plumes are key prerequisites for such calculations. However, these parameters are challenging to constrain using satellite-based techniques. Here, we use imagery from \{OMI\} and GOME-2 satellite sensors and a novel numerical procedure based on back-trajectory analysis to calculate plume height as a function of position at the satellite measurement time together with plume injection height and time at a volcanic vent location. We applied this new procedure to three Etna eruptions (12 August 2011, 18 March 2012 and 12 April 2013) and compared our results with independent satellite and ground-based estimations. We also compare our injection height time-series with measurements of volcanic tremor, which reflects the eruption intensity, showing a good match between these two datasets. Our results are a milestone in progressing towards reliable determination of gas flux data from satellite-derived \{SO2\} maps during volcanic eruptions, which would be of great value for operational management of explosive eruptions. "} 
}
@article{SalmazoSilva201710,
title = {"Lexical-retrieval and semantic memory in Parkinson’s disease: The question of noun and verb dissociation "},
journal = {"Brain and Language "},
volume = {"165"},
number = {""},
pages = {"10 - 20"},
year = {"2017"},
note = {""},
issn = {"0093-934X"},
doi = {"https://doi.org/10.1016/j.bandl.2016.10.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0093934X15301565"},
author = {"Henrique Salmazo-Silva and Maria Alice de Mattos Pimenta Parente and Maria Sheila Rocha and Roberta Roque Baradel and André M. Cravo and João Ricardo Sato and Fabio Godinho and Maria Teresa Carthery-Goulart"},
keywords = {"Verbs", "Actions", "Semantics", "Parkinson disease", "Embodied Cognition "},
abstract = {"Abstract The dissociation between the processing of verbs and nouns has been debated in light of the Embodied Cognition Theory (EC). The objective of this paper is to verify how action and verb processing deficits of \{PD\} patients are modulated by different tasks with different cognitive demands. Action and object lexical-semantic processing was evaluated in patients with Parkinson’s Disease (PD) and cognitively healthy controls through three different tasks (verbal fluency, naming and semantic association). Compared to controls, \{PD\} patients presented worse performance in naming actions and in the two semantic association tasks (action/object). Action verbal fluency performance was significantly associated with \{PD\} severity whereas object semantic association deficits and noun verbal fluency scores were associated to lower scores in measures of global cognitive functioning. Our data suggest that semantic deficits are related to the type of cognitive processing and this is in the line with more flexible \{EC\} accounts. "} 
}
@article{Hattori201722,
title = {"Successful catheter intervention for deep vein thrombosis due to inferior vena cava stenosis after retrieval of a temporary inferior vena cava filter "},
journal = {"Journal of Cardiology Cases "},
volume = {"15"},
number = {"1"},
pages = {"22 - 24"},
year = {"2017"},
note = {""},
issn = {"1878-5409"},
doi = {"https://doi.org/10.1016/j.jccase.2016.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1878540916300640"},
author = {"Yusuke Hattori and Akihiro Tsuji and Takeshi Ogo and Jin Ueda and Shigefumi Fukui and Satoshi Yasuda"},
keywords = {"Inferior vena cava stenosis", "Temporary inferior vena cava filter", "Catheter-directed thrombolysis "},
abstract = {"Abstract Inferior vena cava (IVC) stenosis is a well-known complication of the \{IVC\} filter. However, there are no previous reports of \{IVC\} stenosis caused by a temporary \{IVC\} filter. In this case report, we describe the case of a 35-year-old man who was referred to our center for the treatment of recurrent proximal deep vein thrombosis (DVT) and severe \{IVC\} stenosis that occurred after retrieval of a temporary \{IVC\} filter. We performed a catheter-directed thrombolysis and balloon angioplasty. \{DVT\} resolved effectively, and his leg symptoms resolved. &lt;Learning objective: Although \{IVC\} filter-related stenosis is not common, it should be managed, even when a temporary \{IVC\} filter is used. The combination of catheter-directed thrombolysis and balloon angioplasty may be considered for a proximal deep vein thrombosis complicated with \{IVC\} stenosis.&gt; "} 
}
@article{LópezPlata201770,
title = {"Minimizing the Waiting Times of block retrieval operations in stacking facilities "},
journal = {"Computers & Industrial Engineering "},
volume = {"103"},
number = {""},
pages = {"70 - 84"},
year = {"2017"},
note = {""},
issn = {"0360-8352"},
doi = {"https://doi.org/10.1016/j.cie.2016.11.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360835216304314"},
author = {"Israel López-Plata and Christopher Expósito-Izquierdo and Eduardo Lalla-Ruiz and Belén Melián-Batista and J. Marcos Moreno-Vega"},
keywords = {"Blocks Relocation Problem with Waiting Times", "Stacking crane", "Optimization model", "Heuristic "},
abstract = {"Abstract This paper addresses the Blocks Relocation Problem with Waiting Times. Its objective is to retrieve a set of homogeneous blocks from a two-dimensional storage by minimizing the waiting times during their retrieval. An integer programming model and a heuristic algorithm are developed to solve this optimization problem. The mathematical model is able to solve small-size cases to optimality in reasonable computational times. Unfortunately, it requires large computational times when tackling medium and large-size scenarios. For its part, the heuristic algorithm overcomes the problems associated with the computational burden of the model by bringing forward the availability of blocks to retrieve from the storage. With this goal in mind, several look ahead strategies dedicated to perform the most promising predictive block relocation movements are proposed. The computational results disclose the proposed heuristic algorithm is able to report high-quality solutions through very short computational times, less than one second, in practical cases. "} 
}
@article{Pagnanelli2017706,
title = {"Leaching of electrodic powders from lithium ion batteries: Optimization of operating conditions and effect of physical pretreatment for waste fraction retrieval "},
journal = {"Waste Management "},
volume = {"60"},
number = {""},
pages = {"706 - 715"},
year = {"2017"},
note = {"Special Thematic Issue: Urban Mining and Circular Economy "},
issn = {"0956-053X"},
doi = {"https://doi.org/10.1016/j.wasman.2016.11.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0956053X16307322"},
author = {"Francesca Pagnanelli and Emanuela Moscardini and Pietro Altimari and Thomas Abo Atia and Luigi Toro"},
keywords = {"Li ion batteries", "Mechanical pretreatment", "Leaching", "Glucose "},
abstract = {"Abstract Experimental results of leaching tests using waste fractions obtained by mechanical pretreatment of lithium ion batteries (LIB) were reported. Two physical pretreatments were performed at pilot scale in order to recover electrodic powders: the first including crushing, milling, and sieving and the second granulation, and sieving. Recovery yield of electrodic powder was significantly influenced by the type of pretreatment. About 50% of initial \{LIB\} wastes was recovered by the first treatment (as electrodic powder with size &lt;0.5 mm, Sample 1), while only 37% of powder with size &lt;1 mm (Sample 2) can be recovered by the second treatment. Chemical digestion put in evidence the heterogeneity of recovered powders denoting different amounts of Co, Mn, and Ni. Leaching tests of both powders were performed in order to determine optimized conditions for metal extraction. Solid/liquid ratios and sulfuric acid concentrations were changed according to factorial designs at constant temperature (80 °C). Optimized conditions for quantitative extraction (&gt;99%) of Co and Li from Sample 1 are 1/10 g/mL as solid/liquid ratio and +50% stoichiometric excess of acid (1.1 M). Using the same solid/liquid ratio, +100% acid excess (1.2 M) is necessary to extract 96% of Co and 86% of Li from Sample 2. Best conditions for leaching of Sample 2 using glucose are +200% acid excess (1.7 M) and 0.05 M glucose concentration. Optimized conditions found in this work are among the most effective reported in the literature in term of Co extraction and reagent consumption. "} 
}
@article{Ding2017244,
title = {"Solid pole tide in global \{GPS\} and superconducting gravimeter observations: Signal retrieval and inference for mantle anelasticity "},
journal = {"Earth and Planetary Science Letters "},
volume = {"459"},
number = {""},
pages = {"244 - 251"},
year = {"2017"},
note = {""},
issn = {"0012-821X"},
doi = {"https://doi.org/10.1016/j.epsl.2016.11.039"},
url = {"http://www.sciencedirect.com/science/article/pii/S0012821X16306732"},
author = {"Hao Ding and Benjamin F. Chao"},
keywords = {"pole tide", "Love numbers", "lower-mantle anelasticity", "GPS", "superconducting gravimeter", "optimal sequence estimation "},
abstract = {"Abstract The mantle anelasticity plays an important role in Earth's interior dynamics. Here we seek to determine the lower-mantle anelasticity through the solution of the complex Love numbers at the Chandler wobble period. The Love numbers h 21 , l 21 , δ 21 and k 21 are obtained in the frequency domain by dividing off the observed polar motion, or more specifically the pole tide potential, from the observed \{GPS\} 3-D displacement field and \{SG\} gravity variation. The latter signals are obtained through the array processing method of \{OSE\} (optimal sequence estimation) that results in greatly enhanced signals to be extracted from global array data. The resultant Love number estimates h 21 = 0.6248 ( ± 5 e − 4 ) − 0.013 ( ± 5 e − 3 ) i , l 21 = 0.0904 ( ± 8 e − 4 ) − 0.0008 ( ± 2 e − 3 ) i , δ 21 = 1.156 ( ± 2 e − 3 ) − 0.003 ( ± 1 e − 3 ) i and k 21 = 0.3125 ( ± 2 e − 3 ) − 0.0069 ( ± 3 e − 3 ) i are thus well-constrained in comparison to past estimates that vary considerably. They further lead to estimates of the corresponding mantle anelastic parameters f r and f i , which in turn determines, under the single-absorption band assumption, the dispersion exponent of α = 0.21 ± 0.02 with respect to the reference frequency of 5 mHz. We believe our estimate is robust and hence can better constrain the mantle anelasticity and attenuation models of the Earth interior. "} 
}
@article{Patil2016,
title = {"Analysis of content based image retrieval for plant leaf diseases using color, shape and texture features "},
journal = {"Engineering in Agriculture, Environment and Food "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"1881-8366"},
doi = {"https://doi.org/10.1016/j.eaef.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1881836616301100"},
author = {"Jayamala Kumar Patil and Raj Kumar"},
keywords = {"CBIR", "Features", "LGGP", "SIFT", "Histogram "},
abstract = {"Abstract This research paper is an attempt to present Content Based Image Retrieval (CBIR) system developed for retrieving diseased leaves of soybean. It uses color, shape and texture features of leaf. Color features are extracted using \{HSV\} color histogram. Scale Invariant Feature Transform (SIFT) provides shape features in the form of matching key points. Local Binary Pattern (LBP) and Gabor filter are widely used texture features. Novel texture feature named Local Gray Gabor Pattern (LGGP) is proposed by combining \{LBP\} and Gabor. Performance of all these features with respect to retrieval precision is tested for three soybean leaf diseases. Further color, shape and texture features are combined to increase performance. It is found that when \{LGGP\} is combined with color histogram and \{SIFT\} retrieval precision is improved. Retrieval efficiency of about 96%, 68% and 76% is achieved for soybean leaves affected by mosaic virus, septoria brown spot and pod mottle disease respectively. Average retrieval efficiency of 80% (for the top 5 retrieval) and 72% (for the top 10 retrieval) is obtained by combined features. This retrieval precision is database dependent and varies with size of the database and quality of images. "} 
}
@article{Rekioua201757,
title = {"Snowpack permittivity profile retrieval from tomographic \{SAR\} data "},
journal = {"Comptes Rendus Physique "},
volume = {"18"},
number = {"1"},
pages = {"57 - 65"},
year = {"2017"},
note = {"Prizes of the French Academy of Sciences 2015 / Prix de l'Académie des sciences 2015 "},
issn = {"1631-0705"},
doi = {"https://doi.org/10.1016/j.crhy.2015.12.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1631070515002947"},
author = {"Badreddine Rekioua and Matthieu Davy and Laurent Ferro-Famil and Stefano Tebaldini"},
keywords = {"Snowpack", "Snow permittivity", "SAR", "SAR tomography", "GB-SAR", "Time domain back projection "},
abstract = {"Abstract This work deals with 3D structure characterization and permittivity profile retrieval of snowpacks by tomographic \{SAR\} data processing. The acquisition system is a very high resolution ground based \{SAR\} system, developed and operated by the \{SAPHIR\} team, of IETR, University of Rennes-1 (France). It consists mainly of a vector network analyser and a multi-static antenna system, moving along two orthogonal directions, so as to obtain a two-dimensional synthetic array. Data were acquired during the AlpSAR campaign carried by the European Space Agency and led by ENVEO. In this study, tomographic imaging is performed using Time Domain Back Projection and consists in coherently combining the different recorded backscatter contributions. The assumption of free-space propagation during the focusing process is discussed and illustrated by focusing experimental data. An iterative method for estimating true refractive indices of the snow layers is presented. The antenna pattern is also compensated for. The obtained tomograms after refractive index correction are compared to the stratigraphy of the observed snowpack. "} 
}
@article{Margaris2017,
title = {"Query personalization using social network information and collaborative filtering techniques "},
journal = {"Future Generation Computer Systems "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0167-739X"},
doi = {"https://doi.org/10.1016/j.future.2017.03.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167739X17303692"},
author = {"Dionisis Margaris and Costas Vassilakis and Panagiotis Georgiadis"},
keywords = {"Social networks", "Personalization", "Collaborative search", "Database query transformation", "Presentation of retrieval results "},
abstract = {"Abstract Query personalization has emerged as a means to handle the issue of information volume growth, aiming to tailor query answer results to match the goals and interests of each user. Query personalization dynamically enhances queries, based on information regarding user preferences or other contextual information; typically enhancements relate to incorporation of conditions that filter out results that are deemed of low value to the user and/or ordering results so that data of high value are presented first. In the domain of personalization, social network information can prove valuable; users’ social networks profiles, including their interests, influence from social friends, etc. can be exploited to personalize queries. In this paper, we present a query personalization algorithm, which employs collaborative filtering techniques and takes into account influence factors between social network users, leading to personalized results that are better-targeted to the user. "} 
}
@article{Bowen2016,
title = {"Recapitulation of emotional source context during memory retrieval "},
journal = {"Cortex "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945216303185"},
author = {"Holly J. Bowen and Elizabeth A. Kensinger"},
keywords = {"Recapitulation", "Emotion", "Memory", "Source memory", "Reactivation "},
abstract = {"Abstract Recapitulation involves the reactivation of cognitive and neural encoding processes at retrieval. In the current study, we investigated the effects of emotional valence on recapitulation processes. Participants encoded neutral words presented on a background face or scene that was negative, positive or neutral. During retrieval, studied and novel neutral words were presented alone (i.e., without the scene or face) and participants were asked to make a remember, know or new judgment. Both the encoding and retrieval tasks were completed in the fMRI scanner. Conjunction analyses were used to reveal the overlap between encoding and retrieval processing. These results revealed that, compared to positive or neutral contexts, words that were recollected and previously encoded in a negative context showed greater encoding-to-retrieval overlap, including in the ventral visual stream and amygdala. Interestingly, the visual stream recapitulation was not enhanced within regions that specifically process faces or scenes but rather extended broadly throughout visual cortices. These findings elucidate how memories for negative events can feel more vivid or detailed than positive or neutral memories. "} 
}
@article{Hashemi2017106,
title = {"Spectroscopic line parameters of 12CH4 for atmospheric composition retrievals in the 4300–4500 cm−1 region "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"186"},
number = {""},
pages = {"106 - 117"},
year = {"2017"},
note = {"Satellite Remote Sensing and Spectroscopy: Joint ACE-Odin Meeting, October 2015 "},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.03.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407315303319"},
author = {"R. Hashemi and A. Predoi-Cross and A.V. Nikitin and Vl.G. Tyuterev and K. Sung and M.A.H. Smith and V. Malathy Devi"},
keywords = {"Methane", "CH4–CH4 &amp; CH4-air half-width coefficient", "Relaxation matrix coefficients", "CH4-air &amp; CH4–CH4 shift coefficient "},
abstract = {"Abstract Due to the importance of methane as a trace atmospheric gas and a greenhouse gas, we have carried out a precise line-shape study to obtain the CH4–CH4 and CH4–air half-width coefficients, CH4–CH4 and CH4–air shift coefficients and off-diagonal relaxation matrix element coefficients for methane transitions in the spectral range known as the “methane Octad”. In addition, the associated temperature dependences of these coefficients have been measured in the 4300–4500 cm−1 region of the Octad. The high signal to noise ratio spectra of pure methane and of dilute mixtures of methane in dry air with high resolution have been recorded at temperatures from 148 K to room temperature using the Bruker \{IFS\} 125 \{HR\} Fourier transform spectrometer (FTS) at the Jet Propulsion Laboratory, Pasadena, California. The analysis of spectra was done using a multispectrum non-linear least-squares curve fitting technique. Theoretical calculations have been performed and the results are compared with the previously published line positions, intensities and with the line parameters available in the \{GEISA\} and \{HITRAN2012\} databases. "} 
}
@article{Ibrahim2016548,
title = {"Retrieval of macro- and micro-physical properties of oceanic hydrosols from polarimetric observations "},
journal = {"Remote Sensing of Environment "},
volume = {"186"},
number = {""},
pages = {"548 - 566"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.09.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716303480"},
author = {"Amir Ibrahim and Alexander Gilerson and Jacek Chowdhary and Samir Ahmed"},
keywords = {"Remote sensing", "Polarization", "Hydrosol", "Ocean color", "Case-I waters", "Case \{II\} waters", keywords =Bio-optics", "Chlorophyll a", "CDOM", "Plankton", "Minerals", "Scattering", "Vector radiative transfer", "modeling", "Aerosol", "Cloud", "Ocean ecosystem", "PACE "},
abstract = {"Abstract Remote sensing has mainly relied on measurements of scalar radiance and its spectral and angular features to retrieve micro- and macro-physical properties of aerosols/hydrosols. However, it is recognized that measurements that include the polarimetric characteristics of light provide more intrinsic information about particulate scattering. To take advantage of this, we used vector radiative transfer (VRT) simulations and developed an analytical relationship to retrieve the macro and micro-physical properties of the oceanic hydrosols. Specifically, we investigated the relationship between the observed degree of linear polarization (DoLP) and the ratio of attenuation-to-absorption coefficients (c/a) in water, from which the scattering coefficient can be readily computed (b = c − a), after retrieving a. This relationship was parameterized for various scattering geometries, including sensor zenith/azimuth angles relative to the Sun's principal plane, and for varying Sun zenith angles. An inversion method was also developed for the retrieval of the microphysical properties of hydrosols, such as the bulk refractive index and the particle size distribution. The DoLP vs c/a relationship was tested and validated against in-situ measurements of underwater light polarization obtained by a custom-built polarimeter and measurements of the coefficients a and c, obtained using an in-water \{WET\} Labs ac-s instrument package. These measurements confirmed the validity of the approach, with retrievals of attenuation coefficients showing a high coefficient of determination depending on the wavelength. We also performed a sensitivity analysis of the DoLP at the Top of Atmosphere (TOA) over coastal waters showing the possibility of polarimetric remote sensing application for ocean color. "} 
}
@article{Erten2016130,
title = {"Retrieval of agricultural crop height from space: A comparison of SAR techniques "},
journal = {"Remote Sensing of Environment "},
volume = {"187"},
number = {""},
pages = {"130 - 144"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.10.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716303790"},
author = {"Esra Erten and Juan M. Lopez-Sanchez and Onur Yuzugullu and Irena Hajnsek"},
keywords = {"Height estimation", "TanDEM-X", "Rice", "Synthetic Aperture Radar", "PolSAR", "Interferometry", "PolInSAR", "Metamodel", "Agriculture "},
abstract = {"Abstract This paper deals with the retrieval of agricultural crop height from space by using multipolarization Synthetic Aperture Radar (SAR) images. Coherent and incoherent crop height estimation methods are discussed for the first time with a unique TanDEM-X dataset acquired over rice cultivation areas. Indeed, with its polarimetric and interferometric capabilities, the TanDEM-X mission enables the tracking of crop height through interferometric \{SAR\} (InSAR), polarimetric interferometric \{SAR\} (PolInSAR) and the inversion of radiative transfer-based backscattering model. The paper evaluates the three aforementioned techniques simultaneously with a data set acquired in September 2014 and 2015 over rice fields in Turkey during their reproductive stage. The assessment of the absolute height accuracy and the limitations of the approaches are provided. In-situ measurements conducted in the same cultivation periods are used for validation purposes. The PolInSAR and morphological backscattering model results showed better performance with low \{RMSEs\} (12 and 13 cm) compared to the differential InSAR result having \{RMSE\} of 18 cm. The spatial baseline, i.e. the distance between satellites, is a key parameter for coherent methods such as InSAR and PolInSAR. Its effect on the absolute height accuracy is discussed using TanDEM-X pairs separated by a baseline of 101.7m and 932m. Although the InSAR based approach is demonstrated to provide sufficient crop height accuracy, the availability of a precise vegetation-free digital elevation model and a structurally dense crop are basic requirements for achieving high accuracy. The PolInSAR approach provides reliable crop height estimation if the spatial baseline is large enough for the inversion. The impact of increasing spatial baseline on the absolute accuracy of the crop height estimation is evident for both methods. However, PolInSAR is more cost-efficient, e.g. there is no need for phase unwrapping and any external vegetation free surface elevation data. Instead, the usage of radiative transfer based backscattering models provides not only crop height but also other biophysical properties of the crops with consistent accuracy. The efficient retrieval of crop height with backscattering model is achieved by metamodelling, which makes the computational cost of backscattering inversion comparable to the ones of the coherent methods. However, effectiveness depends on not only the backscattering model, but also the integration of agronomic crop growth rules. Motivated by these results, a combination of backscattering and PolInSAR inversion models would provide a successful method of future precision farming studies. "} 
}
@article{Shao2016618,
title = {"Deep canonical correlation analysis with progressive and hypergraph learning for cross-modal retrieval "},
journal = {"Neurocomputing "},
volume = {"214"},
number = {""},
pages = {"618 - 628"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.06.047"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216306877"},
author = {"Jie Shao and Leiquan Wang and Zhicheng Zhao and Fei su and Anni Cai"},
keywords = {"Progressive", "Semantic", "Hypergraph", "Search-based "},
abstract = {"Abstract This paper deals with the problem of modeling Internet images and associated texts for cross-modal retrieval such as text-to-image retrieval and image-to-text retrieval. We start with deep canonical correlation analysis (DCCA), a deep approach for mapping text and image pairs into a common latent space. We first propose a novel progressive framework and embed \{DCCA\} in it. In our progressive framework, a linear projection loss layer is inserted before the nonlinear hidden layers of a deep network. The training of linear projection and the training of nonlinear layers are combined to ensure that the linear projection is well matched with the nonlinear processing stages and good representations of the input raw data are learned at the output of the network. Then we introduce a hypergraph semantic embedding (HSE) method, which extracts latent semantics from texts, into \{DCCA\} to regularize the latent space learned by image view and text view. In addition, a search-based similarity measure is proposed to score relevance of image-text pairs. Based on the above ideas, we propose a model, called DCCA-PHS, for cross-modal retrieval. Experiments on three publicly available data sets show that DCCA-PHS is effective and efficient, and achieves state-of-the-art performance for unsupervised scenario. "} 
}
@article{Mei2016,
title = {"A Cloud masking algorithm for the \{XBAER\} aerosol retrieval using \{MERIS\} data "},
journal = {"Remote Sensing of Environment "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.11.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716304618"},
author = {"Linlu Mei and Marco Vountas and Luis Gómez-Chova and Vladimir Rozanov and Malte Jäger and Wolfhardt Lotz and John P. Burrows and Rainer Hollmann"},
keywords = {"Cloud mask", "Aerosol", "MERIS", "XBAER "},
abstract = {"Abstract To determine aerosol optical thickness, AOT, and other geophysical parameters describing conditions in the atmosphere and at the earth's surface by inversion of remote sensing measurements from space based instrumentation, it is necessary to separate ground scenes into cloud free and cloudy or cloud contaminated. Identifying the presence of cloud in a ground scene and establishing an accurate and adequate cloud mask is a challenging task. In this study, measurements by the European Space Agency (ESA) \{MEdium\} Resolution Imaging Spectrometer (MERIS) have been used to develop a cloud identification and cloud mask algorithm for preprocessing prior to application of the new algorithm called eXtensible Bremen \{AErosol\} Retrieval (XBAER), which retrieves AOT. The new \{XBAER\} cloud identification and cloud mask algorithm is called XBAER-CM. This uses thresholds of the reflectance and reflectance ratios measured by \{MERIS\} at Top Of Atmosphere (TOA). In this study the parameters used to determine the presence of cloud in ground scenes are i) the brightness of the scenes, ii) the homogeneity or variability of the radiance and iii) cloud height or altitude information. The threshold values used to identify the presence of cloud are selected by using accurate radiative transfer modeling with different surface and atmospheric scenarios. A histogram analysis has been used for different cloud (thin, thick, two-layers, aerosol contaminated cloud), aerosol (dust and biomass burning) and surface scenarios (vegetation, urban, desert and water). Additionally, a snow/ice detection algorithm has been adapted from MerIs Cloud fRation fOr Sciamachy (MICROS) algorithm. A validation for the resulting cloud mask data products has been undertaken. This comprised i) comparison of regions scenes, which have been manually generated by experts and ii) more global comparison with cloud identification data products from surface synoptic observations (SYNOP) and Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP). As a part of verification and validation, the XBAER-CM results have been shown to be in good agreement with the “manually”-created masks, considered to be the true reference for a set of challenging scenarios. The overall accuracy compared with \{SYNOP\} and \{CALIOP\} are 84.4% and 83.2%, respectively. The XBAER-CM data product is a standalone data product but valuable for use with algorithms, which retrieve other cloud, aerosol and surface parameters from the measurements of \{MERIS\} and the follow on instruments such as Sentinel 3 Ocean and Land Color Instrument (OLCI) now in space. "} 
}
@incollection{Singer2017,
title = {"Memory for Text and Discourse: Retrieval and Comprehension "},
editor = {""},
booktitle = {"Reference Module in Neuroscience and Biobehavioral Psychology "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2017"},
pages = {" - "},
isbn = {"978-0-12-809324-5"},
doi = {"https://doi.org/10.1016/B978-0-12-809324-5.21065-1"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128093245210651"},
author = {"Murray Singer"},
keywords = {"Comprehension", "Discourse", "Inference", "Learning", "Memory", "Question answering", "Reading", "Recall", "Recognition", "Representation", "Text "},
abstract = {"Abstract The two major sections of this chapter on memory and text address people's mental processes of (1) remembering what they have read and (2) retrieving the preceding text information and related world knowledge needed to achieve comprehension in the first place. In remembering texts, people can retrieve some of the specific words and idea content of the message but most robust is their memory of the situation to which the message alluded. This enables people to recall and recognize text content long after the original reading. The basic cognitive mechanisms of remembering text and of learning from text are examined. Regarding the memories that enable comprehension, each successive text segment can remind the reader of what preceded and of relevant world knowledge. Access to these memories is regulated by the current segment's similarity to and distance from the prior text, and of the typicality and distinctiveness of that text. Throughout, the mechanisms of text memory are regarded as common to rather than distinct from memory in other cognitive domains. "} 
}
@article{LoríaSalazar2016345,
title = {"Evaluation of \{MODIS\} columnar aerosol retrievals using \{AERONET\} in semi-arid Nevada and California, U.S.A., during the summer of 2012 "},
journal = {"Atmospheric Environment "},
volume = {"144"},
number = {""},
pages = {"345 - 360"},
year = {"2016"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2016.08.070"},
url = {"http://www.sciencedirect.com/science/article/pii/S1352231016306690"},
author = {"S. Marcela Loría-Salazar and Heather A. Holmes and W. Patrick Arnott and James C. Barnard and Hans Moosmüller"},
keywords = {"MODIS", "Algorithms", "Albedo", "Deep-blue", "Dark-target", "Biomass burning "},
abstract = {"Abstract Satellite characterization of local aerosol pollution is desirable because of the potential for broad spatial coverage, enabling transport studies of pollution from major sources, such as biomass burning events. However, retrieval of quantitative measures of air pollution such as Aerosol Optical Depth (AOD) from satellite measurements is challenging over land because the underlying surface albedo may be heterogeneous in space and time. Ground-based sunphotometer measurements of \{AOD\} are unaffected by surface albedo and are crucial in enabling evaluation, testing, and further development of satellite instruments and retrieval algorithms. Columnar aerosol optical properties from ground-based sunphotometers (Cimel CE-318) as part of \{AERONET\} and \{MODIS\} aerosol retrievals from Aqua and Terra satellites were compared over semi-arid California and Nevada during the summer season of 2012. Sunphotometer measurements were used as a ‘ground truth’ to evaluate the current state of satellite retrievals in this spatiotemporal domain. Satellite retrieved (MODIS Collection 6) \{AOD\} showed the presence of wildfires in northern California during August. During the study period, the dark-target (DT) retrieval algorithm appears to overestimate \{AERONET\} \{AOD\} by an average factor of 3.85 in the entire study domain. \{AOD\} from the deep-blue (DB) algorithm overestimates \{AERONET\} \{AOD\} by an average factor of 1.64. Low \{AOD\} correlation was also found between AERONET, DT, and \{DB\} retrievals. Smoke from fires strengthened the aerosol signal, but \{MODIS\} versus \{AERONET\} \{AOD\} correlation hardly increased during fire events (r2∼0.1–0.2 during non-fire periods and r2∼0–0.31 during fire periods). Furthermore, aerosol from fires increased the normalized mean bias (NMB) of \{MODIS\} retrievals of \{AOD\} (NMB∼23%–154% for non-fire periods and NMB∼77%–196% for fire periods). Ångström Extinction Exponent (AEE) from \{DB\} for both Terra and Aqua did not correlate with \{AERONET\} observations. High surface reflectance and incorrect aerosol physical parametrizations may still be affecting the \{DT\} and \{DB\} \{MODIS\} \{AOD\} retrievals in the semi-arid western U.S. "} 
}
@article{Demartini20155,
title = {"Hybrid human–machine information systems: Challenges and opportunities "},
journal = {"Computer Networks "},
volume = {"90"},
number = {""},
pages = {"5 - 13"},
year = {"2015"},
note = {"Crowdsourcing "},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2015.05.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128615002194"},
author = {"Gianluca Demartini"},
keywords = {"Human computation", "Crowdsourcing", "Database", "Semantic web", "Information retrieval "},
abstract = {"Abstract Micro-task Crowdsourcing has been used for different purposes: creating training data for machine learning algorithms, relevance judgments for evaluation of information systems, sentiment analysis, language translation, etc. In this paper we focus on the use of crowdsourcing as core component of data-driven systems. The creation of hybrid human–machine systems is a highly promising direction as it allows leveraging both the scalability of machines over large amounts of data as well as keeping the quality of human intelligence in the loop to finally obtain both efficiency and effectiveness in data processing applications. Such a hybrid approach is a great opportunity to develop systems that are more powerful than purely machine-based ones. For example, it is possible to build systems that can understand sarcasm in text at scale. However, when designing such systems it is critical to take into account a number of dimensions related to human behavior as humans become a component of the overall process. In this paper, we overview existing hybrid human–machine systems presenting commonalities in the approaches taken by different research communities. We summarize the key challenges that one has to face in developing such systems as well the opportunities and the open research directions to make such approaches the best way to process data in the future. "} 
}
@article{Taylor201611,
title = {"The role of verbal labels on flexible memory retrieval at 12-months of age "},
journal = {"Infant Behavior and Development "},
volume = {"45, Part A"},
number = {""},
pages = {"11 - 17"},
year = {"2016"},
note = {""},
issn = {"0163-6383"},
doi = {"https://doi.org/10.1016/j.infbeh.2016.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0163638315301028"},
author = {"Gemma Taylor and Hao Liu and Jane S. Herbert"},
keywords = {"Memory flexibility", "Memory development", "Imitation", "Infant "},
abstract = {"Abstract The provision of verbal labels enhances 12-month-old infants’ memory flexibility across a form change in a puppet imitation task (Herbert, 2011), although the mechanisms for this effect remain unclear. Here we investigate whether verbal labels can scaffold flexible memory retrieval when task difficulty increases and consider the mechanism responsible for the effect of language cues on early memory flexibility. Twelve-month-old infants were provided with English, Chinese, or empty language cues during a difficult imitation task, a combined change in the puppet’s colour and form at the test (Hayne et al., 1997). Imitation performance by infants in the English language condition only exceeded baseline performance after the 10-min delay. Thus, verbal labels facilitated flexible memory retrieval on this task. There were no correlations between infants’ language comprehension and imitation performance. Thus, it is likely that verbal labels facilitate both attention and categorisation during encoding and retrieval. "} 
}
@article{Kilic2016198,
title = {"Sensitivity of evapotranspiration retrievals from the \{METRIC\} processing algorithm to improved radiometric resolution of Landsat 8 thermal data and to calibration bias in Landsat 7 and 8 surface temperature "},
journal = {"Remote Sensing of Environment "},
volume = {"185"},
number = {""},
pages = {"198 - 209"},
year = {"2016"},
note = {"Landsat 8 Science Results "},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.07.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716302681"},
author = {"Ayse Kilic and Richard Allen and Ricardo Trezza and Ian Ratcliffe and Baburao Kamble and Clarence Robison and Doruk Ozturk"},

abstract = {"Abstract We made an assessment on the use of 12-bit resolution of Landsat 8 (L8) on evapotranspiration (ET) retrievals via the \{METRIC\} process as compared to using 8-bit resolution imagery of previous Landsat missions. \{METRIC\} (Mapping Evapotranspiration at high Resolution using Internalized Calibration) is an \{ET\} retrieval system commonly used in water and water rights management where the surface energy balance process is coupled with an extreme-end point calibration process to remove most impacts of systematic bias in remotely sensed inputs. We degraded \{L8\} thermal images by grouping sequential digital numbers to reduce the apparent numerical resolution and then recomputed \{ET\} using \{METRIC\} and compared to nondegraded \{ET\} products. The use of 8-bit thermal data did not substantially impair the accuracy of \{ET\} retrievals derived from METRIC, as compared to the use of 12-bit thermal data. The largest error introduced into \{ET\} was &lt; 1%. We also compared \{ET\} retrieved from images processed during the \{L8\} and Landsat 7 (L7) March 2013 underfly to assess differences in \{ET\} caused by differences in signal to noise ratio (SNR) and scaling of the two systems. We evaluated the impact of bias in land surface temperature (LST) retrievals on \{ET\} determination using the \{CIMEC\} calibration approach (Calibration using Inverse Modeling using Extreme Member Calibration) employed in \{METRIC\} by introducing globally systematic biases into \{LST\} retrievals from \{L7\} and \{L8\} and comparing to \{ET\} from non-biased retrievals. The impacts of the introduction of both additive and multiplicative biases into surface temperature on \{ET\} were small for the three regions of the \{US\} studied, and for both \{L7\} and \{L8\} satellite systems. An independent study showed that METRIC-produced \{ET\} compared to within 3% of measured \{ET\} for the California site. The study assessed the impact of the February 2014 recalibration of \{L8\} thermal data that caused a 3 K downward shift in \{LST\} estimation and changed reflectance values by about 0.7%. We found that the use of the recalibrated \{LST\} and shortwave data sets in \{METRIC\} did not change the accuracy of \{ET\} retrievals due to the automatic compensation for systematic biases employed by METRIC. "} 
}
@article{Dutta Roy201542,
title = {"Camera-based document image matching using multi-feature probabilistic information fusion "},
journal = {"Pattern Recognition Letters "},
volume = {"58"},
number = {""},
pages = {"42 - 50"},
year = {"2015"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2015.02.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865515000628"},
author = {"Sumantra Dutta Roy and Kavita Bhardwaj and Rhishabh Garg and Santanu Chaudhury"},
keywords = {"Camera-based document analysis and retrieval", "Probabilistic information fusion", "Geometric hashing-based matching "},
abstract = {"Abstract A common requirement in camera-based document matching and retrieval systems, is to retrieve a document whose image has been taken under difficult imaging conditions (insufficient and non-uniform illumination, skew, occlusions, all of these possibly coming in together in the same image). We present a system for robust matching and retrieval which works well for such difficult query images, using probabilistic information fusion from multiple independent sources of measurement. Our experiments with two robust and computationally inexpensive features show promising results on a representative database, compared with the state-of-the-art in the area. "} 
}
@article{Giovannini2016391,
title = {"Knowledge representation, retrieval and reuse for product family design: An anti-logicist approach "},
journal = {"Computers & Industrial Engineering "},
volume = {"101"},
number = {""},
pages = {"391 - 402"},
year = {"2016"},
note = {""},
issn = {"0360-8352"},
doi = {"https://doi.org/10.1016/j.cie.2016.10.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360835216303709"},
author = {"A. Giovannini and A. Aubry and H. Panetto and H. El Haouzi and O. Canciglieri Junior and L. Pierrel"},
keywords = {"Product family", "Product platform", "Knowledge representation", "Knowledge reuse", "Anti-logicism "},
abstract = {"Abstract The product family design is a design approach to meet the demand of customisable products. This paper deals with the knowledge representation, retrieval and reuse supporting the design stage of product families. Usually, the methods in the literature do not focus on the retrieve and the reusability of the knowledge. In other words, they do not ensure if a non-expert user can effectively retrieve and reuse the represented knowledge. To cope with this point, here, the aim is to apply an anti-logicist approach for the unambiguous design-knowledge representation to support the unambiguous retrieval and the automatic reuse of the knowledge during a product family design stage. The retrieval is unambiguous because the link between the knowledge models and the requirements is based on a syntax comparison, e.g. intervals of numbers, units of measure. An algorithm for the automatic reuse has been developed: provided an unambiguous definition of the new requirements related to the product family, the algorithm’s outputs are the functional and physical definitions of all the products included in the product families, i.e. performances and \{CAD\} files. The case study is a family of components of the \{HVAC\} (heating, ventilating and air-conditioning) systems sector. Finally the advantages and issues of a potential industrial implementation are discussed. "} 
}
@article{Mahieu201796,
title = {"Retrieval of HCFC-142b (CH3CClF2) from ground-based high-resolution infrared solar spectra: Atmospheric increase since 1989 and comparison with surface and satellite measurements "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"186"},
number = {""},
pages = {"96 - 105"},
year = {"2017"},
note = {"Satellite Remote Sensing and Spectroscopy: Joint ACE-Odin Meeting, October 2015 "},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.03.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316300723"},
author = {"Emmanuel Mahieu and Bernard Lejeune and Benoît Bovy and Christian Servais and Geoffrey C. Toon and Peter F. Bernath and Christopher D. Boone and Kaley A. Walker and Stefan Reimann and Martin K. Vollmer and Simon O’Doherty"},
keywords = {"HCFC-142b", "FTIR spectroscopy", "Jungfraujoch", "NDACC", "ACE-FTS", "AGAGE "},
abstract = {"Abstract We have developed an approach for retrieving HCFC-142b (CH3CClF2) from ground-based high-resolution infrared solar spectra, using its ν7 band Q branch in the 900–906 cm−1 interval. Interferences by HNO3, \{CO2\} and \{H2O\} have to be accounted for. Application of this approach to observations recorded within the framework of long-term monitoring activities carried out at the northern mid-latitude, high-altitude Jungfraujoch station in Switzerland (46.5°N, 8.0°E, 3580 m above sea level) has provided a total column times series spanning the 1989 to mid-2015 time period. A fit to the HCFC-142b daily mean total column time series shows a statistically-significant long-term trend of (1.23±0.08×1013 molec cm−2) per year from 2000 to 2010, at the 2-σ confidence level. This corresponds to a significant atmospheric accumulation of (0.94±0.06) ppt (1 ppt=1/1012) per year for the mean tropospheric mixing ratio, at the 2−σ confidence level. Over the subsequent time period (2010–2014), we note a significant slowing down in the HCFC-142b buildup. Our ground-based \{FTIR\} (Fourier Transform Infrared) results are compared with relevant data sets derived from surface in situ measurements at the Mace Head and Jungfraujoch sites of the \{AGAGE\} (Advanced Global Atmospheric Gases Experiment) network and from occultation measurements by the ACE-FTS (Atmospheric Chemistry Experiment-Fourier Transform Spectrometer) instrument on-board the \{SCISAT\} satellite. "} 
}
@article{Xu2016961,
title = {"Distinct Hippocampal Pathways Mediate Dissociable Roles of Context in Memory Retrieval "},
journal = {"Cell "},
volume = {"167"},
number = {"4"},
pages = {"961 - 972.e16"},
year = {"2016"},
note = {""},
issn = {"0092-8674"},
doi = {"https://doi.org/10.1016/j.cell.2016.09.051"},
url = {"http://www.sciencedirect.com/science/article/pii/S0092867416313368"},
author = {"Chun Xu and Sabine Krabbe and Jan Gründemann and Paolo Botta and Jonathan P. Fadok and Fumitaka Osakada and Dieter Saur and Benjamin F. Grewe and Mark J. Schnitzer and Edward M. Callaway and Andreas Lüthi"},
keywords = {"fear conditioning", "fear renewal", "contextual fear", "central amygdala", "basal amygdala", "basal amygdala", "ventral hippocampus", "rabies-ArchT", "trans-synaptic tracing", "optogenetics "},
abstract = {"Summary Memories about sensory experiences are tightly linked to the context in which they were formed. Memory contextualization is fundamental for the selection of appropriate behavioral reactions needed for survival, yet the underlying neuronal circuits are poorly understood. By combining trans-synaptic viral tracing and optogenetic manipulation, we found that the ventral hippocampus (vHC) and the amygdala, two key brain structures encoding context and emotional experiences, interact via multiple parallel pathways. A projection from the vHC to the basal amygdala mediates fear behavior elicited by a conditioned context, whereas a parallel projection from a distinct subset of vHC neurons onto midbrain-projecting neurons in the central amygdala is necessary for context-dependent retrieval of cued fear memories. Our findings demonstrate that two fundamentally distinct roles of context in fear memory retrieval are processed by distinct vHC output pathways, thereby allowing for the formation of robust contextual fear memories while preserving context-dependent behavioral flexibility. "} 
}
@article{StLaurent201615,
title = {"The retrieval of perceptual memory details depends on right hippocampal integrity and activation "},
journal = {"Cortex "},
volume = {"84"},
number = {""},
pages = {"15 - 33"},
year = {"2016"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2016.08.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945216302313"},
author = {"Marie St-Laurent and Morris Moscovitch and Mary Pat McAndrews"},
keywords = {"Autobiographical memory", "Episodic memory", "fMRI", "Hippocampus", "Temporal lobe epilepsy "},
abstract = {"Abstract We assessed whether perceptual richness, a defining feature of episodic memory, depends on the engagement and integrity of the hippocampus during episodic memory retrieval. We tested participants' memory for complex laboratory events (LEs) that differed in perceptual content: short stories were either presented as perceptually rich film clips or as perceptually impoverished narratives. Participants underwent functional magnetic resonance imaging (fMRI) while retrieving these \{LEs\} (narratives and clips), as well as events from their personal life (autobiographical memories). In a group of healthy adults, a conjunction analysis showed that both real-life and laboratory memories engaged overlapping regions from an autobiographical memory (AM) retrieval network, indicating that laboratory memories mimicked autobiographical events successfully. A direct contrast between the film clip and the narrative laboratory conditions identified regions activated by the retrieval of perceptual memory content, which included the right hippocampus, parahippocampal gyrus, middle occipital gyrus and precuneus. In individuals with medial temporal lobe epilepsy (mTLE) originating from the right hippocampus, the magnitude of this “perceptually rich” signal was reduced significantly, which is consistent with evidence of reduced perceptual memory content in this clinical population. In healthy controls, right hippocampal activation also correlated positively with a behavioral measure of perceptual content in the clip condition. Thus, right hippocampal activity contributed to the retrieval of perceptual episodic memory content in the healthy brain, while right hippocampal damage disrupted activation in regions that process perceptual memory content. Our results suggest that the hippocampus contributes to recollection by retrieving and integrating perceptual details into vivid memory constructs. "} 
}
@incollection{Cooper2017609,
title = {"Appendix \{CA2\} - Retrieval, Preparation and Storage of Skeletal and Other Material "},
editor = {"Cooper, John E.  and Hull, Gordon "},
booktitle = {"Gorilla Pathology and Health "},
publisher = {"Academic Press"},
edition = {""},
address = {"San Diego"},
year = {"2017"},
pages = {"609 - 615"},
isbn = {"978-0-12-802039-5"},
doi = {"https://doi.org/10.1016/B978-0-12-802039-5.00040-8"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128020395000408"},
author = {"John E. Cooper and Gordon Hull"} 

}
@article{Nguyen201511,
title = {"SEMU: A semantic knowledge management system of musical information "},
journal = {"Entertainment Computing "},
volume = {"9–10"},
number = {""},
pages = {"11 - 18"},
year = {"2015"},
note = {""},
issn = {"1875-9521"},
doi = {"https://doi.org/10.1016/j.entcom.2015.06.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1875952115000051"},
author = {"Dinh Hoa Cuong Nguyen and Ngamnij Arch-int and Somjit Arch-int"},
keywords = {"Semantic Web", "Ontology", "Knowledge management", "Musical Information Retrieval "},
abstract = {"Abstract The diverse data types of musical information domain including binary and text-based structures create semantic gaps between the entities of different data formats. This leads to difficulties in analyzing, capturing and managing entities of the domain. In this paper, we present a semantic knowledge management system, called SEMU, to efficiently managing musical information. We propose \{SEMU\} ontology to capture information extracted from various data types and sources. In order to extract information from raw data, we use Musical Information Retrieval techniques for audio files and Natural Language Processing techniques for text-based formats. We develop a rule-based solution to enrich the system knowledge base. Later, we provide a web application with seamless integration between \{SEMU\} knowledge base and user interface to enable users to benefit from the advantages of the \{SEMU\} system. "} 
}
@article{LüscherDias2016260,
title = {"c-Fos expression predicts long-term social memory retrieval in mice "},
journal = {"Behavioural Brain Research "},
volume = {"313"},
number = {""},
pages = {"260 - 271"},
year = {"2016"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2016.07.030"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432816304582"},
author = {"Thomaz Lüscher Dias and Hudson Fernandes Golino and Vinícius Elias Moura de Oliveira and Márcio Flávio Dutra Moraes and Grace Schenatto Pereira"},
keywords = {"Long-term social memory", "c-Fos", "Random Forest", "Contextual integration", "Top-down modulation "},
abstract = {"Abstract The way the rodent brain generally processes socially relevant information is rather well understood. How social information is stored into long-term social memory, however, is still under debate. Here, brain c-Fos expression was measured after adult mice were exposed to familiar or novel juveniles and expression was compared in several memory and socially relevant brain areas. Machine Learning algorithm Random Forest was then used to predict the social interaction category of adult mice based on c-Fos expression in these areas. Interaction with a familiar co-specific altered brain activation in the olfactory bulb, amygdala, hippocampus, lateral septum and medial prefrontal cortex. Remarkably, Random Forest was able to predict interaction with a familiar juvenile with 100% accuracy. Activity in the olfactory bulb, amygdala, hippocampus and the medial prefrontal cortex were crucial to this prediction. From our results, we suggest long-term social memory depends on initial social olfactory processing in the medial amygdala and its output connections synergistically with non-social contextual integration by the hippocampus and medial prefrontal cortex top-down modulation of primary olfactory structures. "} 
}
@article{Ford201678,
title = {"Effects of internal and external vividness on hippocampal connectivity during memory retrieval "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"134, Part A"},
number = {""},
pages = {"78 - 90"},
year = {"2016"},
note = {"Hippocampal Interactions with Brain Networks that Influence Learning &amp; Memory "},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2015.12.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742715002373"},
author = {"Jaclyn H. Ford and Elizabeth A. Kensinger"},
keywords = {"Hippocampal connectivity", "Memory", "Internal vividness", "External vividness "},
abstract = {"Abstract Successful memory for an image can be supported by retrieval of one’s personal reaction to the image (i.e., internal vividness), as well as retrieval of the specific details of the image itself (i.e., external vividness). Prior research suggests that memory vividness relies on regions within the medial temporal lobe, particularly the hippocampus, but it is unclear whether internal and external vividness are supported by the hippocampus in a similar way. To address this open question, the current study examined hippocampal connectivity associated with enhanced internal and external vividness ratings during retrieval. Participants encoded complex visual images paired with verbal titles. During a scanned retrieval session, they were presented with the titles and asked whether each had been seen with an image during encoding. Following retrieval of each image, participants were asked to rate internal and external vividness. Increased hippocampal activity was associated with higher vividness ratings for both scales, supporting prior evidence implicating the hippocampus in retrieval of memory detail. However, different patterns of hippocampal connectivity related to enhanced external and internal vividness. Further, hippocampal connectivity with medial prefrontal regions was associated with increased ratings of internal vividness, but with decreased ratings of external vividness. These findings suggest that the hippocampus may contribute to increased internal and external vividness via distinct mechanisms and that external and internal vividness of memories should be considered as separable measures. "} 
}
@article{Houborg2016105,
title = {"Adapting a regularized canopy reflectance model (REGFLEC) for the retrieval challenges of dryland agricultural systems "},
journal = {"Remote Sensing of Environment "},
volume = {"186"},
number = {""},
pages = {"105 - 120"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.08.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716303200"},
author = {"Rasmus Houborg and Matthew F. McCabe"},
keywords = {"LAI", "Leaf chlorophyll", "REGFLEC", "RapidEye", "Red-edge", "Aerosols", "Foliar dust", "Adjacency effects", "Precision agriculture "},
abstract = {"Abstract A regularized canopy reflectance model (REGFLEC) is applied over a dryland irrigated agricultural system in Saudi Arabia for the purpose of retrieving leaf area index (LAI) and leaf chlorophyll content (Chll). To improve the robustness of the retrieved properties, \{REGFLEC\} was modified to 1) correct for aerosol and adjacency effects, 2) consider foliar dust effects on modeled canopy reflectances, 3) include spectral information in the red-edge wavelength region, and 4) exploit empirical \{LAI\} estimates in the model inversion. Using multi-spectral RapidEye imagery allowed Chll to be retrieved with a Mean Absolute Deviation (MAD) of 7.9 μg cm− 2 (16%), based upon in-situ measurements conducted in fields of alfalfa, Rhodes grass and maize over the course of a growing season. \{LAI\} and Chll compensation effects on canopy reflectance were largely avoided by informing the inversion process with ancillary \{LAI\} inputs established empirically on the basis of a statistical machine learning technique. As a result, \{LAI\} was reproduced with good accuracy, with an overall \{MAD\} of 0.42 m2 m− 2 (12.5%). Results highlighted the considerable challenges associated with the translation of at-sensor radiance observations to surface bidirectional reflectances in dryland environments, where issues such as high aerosol loadings and large spatial gradients in surface reflectance from bright desert soils to dark vegetated fields are often present. Indeed, surface reflectances in the visible bands were reduced by up to 60% after correction for such adjacency effects. In addition, dust deposition on leaves required explicit modification of the reflectance sub-model to account for its influence. By implementing these model refinements, \{REGFLEC\} demonstrated its utility for within-field characterization of vegetation conditions over the challenging landscapes typical of dryland agricultural regions, offering a means through which improvements can be made in the management of these globally important systems. "} 
}
@article{Hou201714,
title = {"An algorithm for hyperspectral remote sensing of aerosols: 2. Information content analysis for aerosol parameters and principal components of surface spectra "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"192"},
number = {""},
pages = {"14 - 29"},
year = {"2017"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2017.01.041"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316306604"},
author = {"Weizhen Hou and Jun Wang and Xiaoguang Xu and Jeffrey S. Reid"},
keywords = {"TEMPO", "Geostationary satellite", "Information content analysis", "Degrees of freedom for signal", "Principal component", "Hyperspectral remote sensing", "Common band selection "},
abstract = {"Abstract This paper describes the second part of a series of investigation to develop algorithms for simultaneous retrieval of aerosol parameters and surface reflectance from the future hyperspectral and geostationary satellite sensors such as Tropospheric Emissions: Monitoring of \{POllution\} (TEMPO). The information content in these hyperspectral measurements is analyzed for 6 principal components (PCs) of surface spectra and a total of 14 aerosol parameters that describe the columnar aerosol volume V total , fine-mode aerosol volume fraction, and the size distribution and wavelength-dependent index of refraction in both coarse and fine mode aerosols. Forward simulations of atmospheric radiative transfer are conducted for 5 surface types (green vegetation, bare soil, rangeland, concrete and mixed surface case) and a wide range of aerosol mixtures. It is shown that the \{PCs\} of surface spectra in the atmospheric window channel could be derived from the top-of-the-atmosphere reflectance in the conditions of low aerosol optical depth (AOD ≤ 0.2 at 550 nm), with a relative error of 1%. With degree freedom for signal analysis and the sequential forward selection method, the common bands for different aerosol mixture types and surface types can be selected for aerosol retrieval. The first 20% of our selected bands accounts for more than 90% of information content for aerosols, and only 4 \{PCs\} are needed to reconstruct surface reflectance. However, the information content in these common bands from each \{TEMPO\} individual observation is insufficient for the simultaneous retrieval of surface’s \{PC\} weight coefficients and multiple aerosol parameters (other than V total ). In contrast, with multiple observations for the same location from \{TEMPO\} in multiple consecutive days, 1–3 additional aerosol parameters could be retrieved. Consequently, a self-adjustable aerosol retrieval algorithm to account for surface types, \{AOD\} conditions, and multiple-consecutive observations is recommended to derive aerosol parameters and surface reflectance simultaneously from TEMPO. "} 
}
@article{Elag2017100,
title = {"Identification and characterization of information-networks in long-tail data collections "},
journal = {"Environmental Modelling & Software "},
volume = {"94"},
number = {""},
pages = {"100 - 111"},
year = {"2017"},
note = {""},
issn = {"1364-8152"},
doi = {"https://doi.org/10.1016/j.envsoft.2017.03.032"},
url = {"http://www.sciencedirect.com/science/article/pii/S1364815216309732"},
author = {"Mostafa M. Elag and Praveen Kumar and Luigi Marini and James D. Myers and Margaret Hedstrom and Beth A. Plale"},
keywords = {"Long-tail data", "Information-networks", "Linked-data", "Cyberinfrastructure", "Environmental data", "Data-intensive science "},
abstract = {"Abstract Scientists' ability to synthesize and reuse long-tail scientific data lags far behind their ability to collect and produce these data. Many Earth Science Cyberinfrastructures enable sharing and publishing their data over the web using metadata standards. While profiling data attributes advances the Linked Data approach, it has become clear that building information-networks among distributed data silos is essential to increase their integration and reusability. In this research, we developed a Long-Tail Information-Network (LTIN) model, which uses a metadata-driven approach to build semantic information-networks among datasets published over the web and aggregate them around environmental events. The model identifies and characterizes the spatial and temporal contextual association links and dependencies among datasets. This paper presents the design and application of the \{LTIN\} model, and an evaluation of its performance. The model capabilities were demonstrated by inferring the information-network of a stream discharge located at the downstream end of the Illinois River. "} 
}
@article{Liuzzi2016128,
title = {"Physical inversion of the full \{IASI\} spectra: Assessment of atmospheric parameters retrievals, consistency of spectroscopy and forward modelling "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"182"},
number = {""},
pages = {"128 - 157"},
year = {"2016"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.05.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316301248"},
author = {"G. Liuzzi and G. Masiello and C. Serio and S. Venafra and C. Camy-Peyret"},
keywords = {"Remote sensing", "Infrared", "Satellite", "Spectroscopy", "Forward modelling "},
abstract = {"Abstract Spectra observed by the Infrared Atmospheric Sounder Interferometer (IASI) have been used to assess both retrievals and the spectral quality and consistency of current forward models and spectroscopic databases for atmospheric gas line and continuum absorption. The analysis has been performed with thousands of observed spectra over sea surface in the Pacific Ocean close to the Mauna Loa (Hawaii) validation station. A simultaneous retrieval for surface temperature, atmospheric temperature, H2O, HDO, \{O3\} profiles and gas average column abundance of CO2, CO, CH4, SO2, N2O, HNO3, NH3, \{OCS\} and \{CF4\} has been performed and compared to in situ observations. The retrieval system considers the full \{IASI\} spectrum (all 8461 spectral channels on the range 645–2760 cm−1). We have found that the average column amount of atmospheric greenhouse gases can be retrieved with a precision better than 1% in most cases. The analysis of spectral residuals shows that, after inversion, they are generally reduced to within the \{IASI\} radiometric noise. However, larger residuals still appear for many of the most abundant gases, namely H2O, \{CH4\} and CO2. The \{H2O\} ν2 spectral region is in general warmer (higher radiance) than observations. The \{CO2\} ν2 and N2O/CO2 ν3 spectral regions now show a consistent behavior for channels, which are probing the troposphere. Updates in \{CH4\} spectroscopy do not seem to improve the residuals. The effect of isotopic fractionation of \{HDO\} is evident in the 2500–2760 cm−1 region and in the atmospheric window around 1200 cm−1. "} 
}
@article{Merz2016392,
title = {"The impact of psychosocial stress on conceptual knowledge retrieval "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"134, Part B"},
number = {""},
pages = {"392 - 399"},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2016.08.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742716301630"},
author = {"Christian J. Merz and Florian Dietsch and Michael Schneider"},
keywords = {"Cortisol", "Glucocorticoids", "SECPT", "Naïve theory", "Scientific theory", "Stress hormones "},
abstract = {"Abstract The acquisition of conceptual knowledge in scientific domains is among the central aims of school instruction because this semantic declarative knowledge helps individuals make interferences and explain complex phenomena. Recent research shows that naïve concepts acquired during childhood persist in long-term memory long after learning the scientifically correct concepts in school. In this study, we investigated the effects of stress on the retrieval of these conceptual representations. To this end, 40 healthy men were randomly assigned to either psychosocial stress or a control condition and evaluated, as quickly and accurately as possible, statements that were compatible with scientific concepts or incompatible with those concepts. Some of these statements were true and some were false. Incompatible statements in this case are statements which are in line with adults’ scientific concepts, but not with children’s naïve theories. In contrast, compatible statements are in line with both. Stress induction was successful as evidenced by increases in blood pressure and cortisol concentrations in the stress group compared to the control group. Responses were delayed and less accurate for incompatible compared to compatible statements. Psychosocial stress had no main effect on retrieval, but abolished reaction time differences on false- vs. true-incompatible statements. This effect was mirrored in correlations between individuals’ cortisol increases and reaction times. These results suggest that stress, as embodied by increases in cortisol concentrations, interferes with the retrieval of conceptual knowledge. They help to better understand conceptual knowledge retrieval in real-life situations such as examinations or problem solving in the workplace. "} 
}
@article{Heidemann2015S1082,
title = {"Tu1007 Use of a Text Search Information Retrieval Tool to Identify Outpatients With Drug Induced Liver Injury "},
journal = {"Gastroenterology "},
volume = {"148"},
number = {"4, Supplement 1"},
pages = {"S-1082 - "},
year = {"2015"},
note = {""},
issn = {"0016-5085"},
doi = {"https://doi.org/10.1016/S0016-5085(15)33696-9"},
url = {"http://www.sciencedirect.com/science/article/pii/S0016508515336969"},
author = {"Lauren Heidemann and James J. Law and Robert J. Fontana"} 

}
@article{Chen2016,
title = {"Improved \{TFIDF\} in big news retrieval: An empirical study "},
journal = {"Pattern Recognition Letters "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.11.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516303178"},
author = {"Chien-Hsing Chen"},
keywords = {"Big news", "Term weighting", "Two-stage learning", "News classification", "News clustering "},
abstract = {"Abstract Thomson Reuters news articles have been considered integral data sources that have given rise to several inspiring applications of text classification and clustering. The most well-known term weighting approach, the term frequency-inverse document frequency (TFIDF) method, is often used to assign term weights that support such applications. Thomson Reuters reports pertinent incoming news (e.g., the refugee crisis in Europe) over a given period of time, and the most prominent terms (e.g., “refugee”) are thus frequently found in a large collection of news stories. When term weights are measured via the \{TFIDF\} method, such weights must be heavily compromised while the collection of news is sufficiently large. As the \{TFIDF\} approach is vulnerable to biases because the most important terms are typically referred to as noise, thus leading lower term weights, news retrieval without the use of the most important terms is difficult and ineffective. We thus present a new distance-based term weighting method for overcoming this bias by considering a basic characteristic whereby each news article must be similar or different from others while processing big news that include large amounts of news. All news must not be considered to contribute equally to the weighting of a particular term. In this study, the weight of a particular term is assessed based on its distance in an article to other instances of the same term, and this weight is highly sensitive to whether similar articles cause a term to occur and to whether different articles cause a term to disappear. The most important terms are thus delivered in large news corpora when studying similarities between news stories. In addition, we create a two-stage learning algorithm to refine the term's weights, and we develop an intelligent model that applies our term weighting method to Reuters news analyses based upon classification and clustering problems. The experimental results show that our methods perform better performance than \{TFIDF\} in terms of news classification and clustering. "} 
}
@article{Yang2017375,
title = {"The effect of spatial information characterization on 3D local feature descriptors: A quantitative evaluation "},
journal = {"Pattern Recognition "},
volume = {"66"},
number = {""},
pages = {"375 - 391"},
year = {"2017"},
note = {""},
issn = {"0031-3203"},
doi = {"https://doi.org/10.1016/j.patcog.2017.01.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031320317300183"},
author = {"Jiaqi Yang and Qian Zhang and Zhiguo Cao"},
keywords = {"Local feature descriptor", "Spatial information", "Local reference axis", "Local reference frame", "Feature matching "},
abstract = {"Abstract Designing local feature descriptors for 3D objects is a fundamental yet challenging task in 3D computer vision. Both geometry and spatial information descriptions are critical for a 3D local descriptor, while most previous studies concentrate on the former one. This paper investigates on how the characterization of spatial information would affect a 3D local descriptor in terms of descriptiveness, robustness, compactness and efficiency. The evaluation process is deployed as follows. First, based on the analysis of representative spatial information characterization methods of existing local shape descriptors, six typical characterization methods with different spatial dimensions and partition principles of spatial information are presented. Second, three geometric attributes, i.e., normal deviation, local depth and shape index, are respectively assigned to each point in the local surface for local geometry description, creating a total of 18 different feature descriptors. Then, a quantitative analysis of performance (i.e., descriptiveness, robustness, compactness and efficiency) for these descriptors is carried out on three benchmark datasets. Grounded on the experimental outcomes, the traits, merits and demerits of each spatial information encoding approach are eventually summarized. This study reveals that different spatial information encoding approaches would bring significant effect on a local shape descriptor with respect to its discriminative power, stability, compactness and efficiency. "} 
}
@article{Liansheng20161,
title = {"Amplitude-phase retrieval attack free image encryption based on two random masks and interference "},
journal = {"Optics and Lasers in Engineering "},
volume = {"86"},
number = {""},
pages = {"1 - 10"},
year = {"2016"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.04.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616300720"},
author = {"Sui Liansheng and Zhou bei and Wang Zhanmin and Sun qindong"},
keywords = {"Specific attack", "Phase-truncated Fourier-transform-based encoding", "Interference "},
abstract = {"Abstract An amplitude-phase retrieval attack free encryption scheme is proposed by using two random masks, where one is considered as the random image and other as the public key. Initially, the random image is encrypted to two phase-only masks based on interference technique with the help of the public key. These two phase-only masks are real-valued functions and used as the encryption keys. Then, the plain image is encrypted to the ciphertext with the white noise distribution by using the phase-truncated Fourier-transform-based encoding scheme with the previous encryption keys. The encryption process is nonlinear in which no iterative calculation is involved, while the decryption process is linear which can be easily implemented with the 4 f optical system. Moreover, less constraints makes the specific attack unusable. Simulation results are given to verify the feasibility and robustness of the proposed encryption scheme. "} 
}
@article{Ali201668,
title = {"Retrieval of forest leaf functional traits from HySpex imagery using radiative transfer models and continuous wavelet analysis "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"122"},
number = {""},
pages = {"68 - 80"},
year = {"2016"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2016.09.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271616304257"},
author = {"Abebe Mohammed Ali and Andrew K. Skidmore and Roshanak Darvishzadeh and Iris van Duren and Stefanie Holzwarth and Joerg Mueller"},
keywords = {"Continuous wavelet analysis", "INFORM", "LDMC", "SLA", "Leaf traits "},
abstract = {"Abstract Quantification of vegetation properties plays an important role in the assessment of ecosystem functions with leaf dry mater content (LDMC) and specific leaf area (SLA) being two key functional traits. For the first time, these two leaf traits have been estimated from the airborne images (HySpex) using the \{INFORM\} radiative transfer model and Continuous Wavelet Analysis (CWA). Ground truth data, were collected for 33 sample plots during a field campaign in July 2013 in the Bavarian Forest National Park, Germany, concurrent with the hyperspectral overflight. The \{INFORM\} model was used to simulate the canopy reflectance of the test site and the simulated spectra were transformed to wavelet features by applying CWA. Next, the top 1% strongly correlated wavelet features with the \{LDMC\} and \{SLA\} were used to develop predictive (regression) models. The two leaf traits were then retrieved using the \{CWA\} transformed HySpex imagery and the predictive models. The results were validated using \{R2\} and the \{RMSE\} of the estimated and measured variables. Our results revealed strong correlations between six wavelet features and LDMC, as well as between four wavelet features and SLA. The wavelet features at 1741 nm (scale 5) and 2281 nm (scale 4) were the two most strongly correlated with \{LDMC\} and \{SLA\} respectively. The combination of all the identified wavelet features for \{LDMC\} yielded the most accurate prediction (R2 = 0.59 and \{RMSE\} = 4.39%). However, for \{SLA\} the most accurate prediction was obtained from the single most correlated feature: 2281 nm, scale 4 (R2 = 0.85 and \{RMSE\} = 4.90). Our results demonstrate the applicability of Continuous Wavelet Analysis (CWA) when inverting radiative transfer models, for accurate mapping of forest leaf functional traits. "} 
}
@article{Chenlo201558,
title = {"Finding a needle in the blogosphere: An information fusion approach for blog distillation search "},
journal = {"Information Fusion "},
volume = {"23"},
number = {""},
pages = {"58 - 68"},
year = {"2015"},
note = {""},
issn = {"1566-2535"},
doi = {"https://doi.org/10.1016/j.inffus.2014.09.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1566253514001018"},
author = {"José M. Chenlo and Javier Parapar and David E. Losada and José Santos"},
keywords = {"Blog distillation", "Particle swarm optimisation", "Differential evolution", "Line search", "Information retrieval "},
abstract = {"Abstract In the blogosphere, different actors express their opinions about multiple topics. Users, companies or editors socially interact by commenting, recommending and linking blogs and posts. These social media contents are increasingly growing. As a matter of fact, the size of the blogosphere is estimated to double every six months. In this context, the problem of finding a topically relevant blog to subscribe to becomes a Big Data challenge. Moreover, combining multiple types of evidence is essential for this search task. In this paper we propose a group of textual and social-based signals, and apply different Information Fusion algorithms for a blog distillation search task. Information fusion through the combination of the different types of evidence requires optimisation for appropriately weighting each source of evidence. To this end, we analyse well-established population-based search methods. Namely, global search (Particle Swarm Optimisation and Differential Evolution) and a local search method (Line Search) that has been effective in various Information Retrieval tasks. Moreover, we propose hybrid combinations between the global search and the local search method and compare all the alternatives following a standard methodology. Efficiency is an imperative here and, therefore, we focus not only on achieving high search effectiveness but also on designing efficient solutions. "} 
}
@article{Lynn201647,
title = {"Impaired retrieval processes evident during visual working memory in schizophrenia "},
journal = {"Schizophrenia Research: Cognition "},
volume = {"5"},
number = {""},
pages = {"47 - 55"},
year = {"2016"},
note = {""},
issn = {"2215-0013"},
doi = {"https://doi.org/10.1016/j.scog.2016.07.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S2215001316300087"},
author = {"Peter A. Lynn and Seung Suk Kang and Scott R. Sponheim"},
keywords = {"Working memory", "Schizophrenia", "Event-related potential", "Endophenotype", "Relatives "},
abstract = {"Abstract Prominent working memory (WM) deficits have been observed in people with schizophrenia (PSZ) across multiple sensory modalities, including the visuospatial realm. Electrophysiological abnormalities noted during early visual processing as well as later cognitive functions in \{PSZ\} may underlie deficiencies in \{WM\} ability, though the mechanisms linking behavior to neural responses are not well understood. \{WM\} dysfunction has also been observed in biological relatives of \{PSZ\} (REL) and therefore may be a manifestation of genetic liability for the disorder. We administered a delayed response visuospatial \{WM\} task to 23 PSZ, 30 of their REL, and 37 healthy controls (CTRL) to better understand the contributions of neural abnormalities to \{WM\} performance deficits associated with schizophrenia. \{PSZ\} performed more poorly on the \{WM\} task and failed to effectively process distractor stimuli as well as \{CTRL\} and REL. \{N1\} electrophysiological responses to probes during retrieval differentiated the type and locations of stimuli presented during encoding in CTRL. Retrieval \{N1\} responses in PSZ, however, failed to do so, while retrieval responses in \{REL\} showed more pronounced differentiation of stimulus features during encoding. Furthermore, neural responses during retrieval predicted behavioral performance in \{PSZ\} and REL, but not CTRL. These results suggest that retrieval processes are particularly important to efficient visuospatial \{WM\} function in \{PSZ\} and REL, and support further investigation of \{WM\} retrieval as a potential target for improving overall \{WM\} function through clinical intervention. "} 
}
@article{Wiese2017220,
title = {"Using contextual information to predict co-changes "},
journal = {"Journal of Systems and Software "},
volume = {"128"},
number = {""},
pages = {"220 - 235"},
year = {"2017"},
note = {""},
issn = {"0164-1212"},
doi = {"https://doi.org/10.1016/j.jss.2016.07.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0164121216301194"},
author = {"Igor Scaliante Wiese and Reginaldo Ré and Igor Steinmacher and Rodrigo Takashi Kuroda and Gustavo Ansaldi Oliva and Christoph Treude and Marco Aurélio Gerosa"},
keywords = {"Contextual information", "Co-change prediction", "Software change context", "Change coupling", "Change propagation", "Change impact analysis "},
abstract = {"Abstract Background: Co-change prediction makes developers aware of which artifacts will change together with the artifact they are working on. In the past, researchers relied on structural analysis to build prediction models. More recently, hybrid approaches relying on historical information and textual analysis have been proposed. Despite the advances in the area, software developers still do not use these approaches widely, presumably because of the number of false recommendations. We conjecture that the contextual information of software changes collected from issues, developers’ communication, and commit metadata captures the change patterns of software artifacts and can improve the prediction models. Objective: Our goal is to develop more accurate co-change prediction models by using contextual information from software changes. Method: We selected pairs of files based on relevant association rules and built a prediction model for each pair relying on their associated contextual information. We evaluated our approach on two open source projects, namely Apache \{CXF\} and Derby. Besides calculating model accuracy metrics, we also performed a feature selection analysis to identify the best predictors when characterizing co-changes and to reduce overfitting. Results: Our models presented low rates of false negatives (∼8% average rate) and false positives (∼11% average rate). We obtained prediction models with \{AUC\} values ranging from 0.89 to 1.00 and our models outperformed association rules, our baseline model, when we compared their precision values. Commit-related metrics were the most frequently selected ones for both projects. On average, 6 out of 23 metrics were necessary to build the classifiers. Conclusions: Prediction models based on contextual information from software changes are accurate and, consequently, they can be used to support software maintenance and evolution, warning developers when they miss relevant artifacts while performing a software change. "} 
}
@article{deCamargoFiorini2017241,
title = {"Information systems and sustainable supply chain management towards a more sustainable society: Where we are and where we are going "},
journal = {"International Journal of Information Management "},
volume = {"37"},
number = {"4"},
pages = {"241 - 249"},
year = {"2017"},
note = {""},
issn = {"0268-4012"},
doi = {"https://doi.org/10.1016/j.ijinfomgt.2016.12.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0268401216301578"},
author = {"Paula de Camargo Fiorini and Charbel José Chiappetta Jabbour"},
keywords = {"Information systems for sustainable development", "Sustainable supply chain management", "Green supply chain management", "Sustainable development", "Green information systems", "Sustainable \{IT\} "},
abstract = {"Abstract The objectives of this study are to identify and systematize scholarly articles on the use of information system to support sustainable supply chain management and to suggest future research opportunities. Therefore, a structured literature review was conducted. The most relevant studies identified were classified and categorized into seven dimensions: research context, research focus, research method, sector analyzed, information system (IS) beneficiaries, relationship between \{IS\} and green supply chain practices, and performance benefits. The main authors and articles on this particular topic were identified. In addition, it was concluded that \{IS\} is an important support tool for sustainable supply chain management practices since it brings benefits to the organization, suppliers, and customers. Furthermore, \{IS\} positively influences the operational, financial, and environmental performance of the organization. However, further advances in the literature are still needed. The major contribution of this research is related to the recommendations that provide opportunities for future research. "} 
}
@article{Mejri201746,
title = {"Crisis information to support spatial planning in post disaster recovery "},
journal = {"International Journal of Disaster Risk Reduction "},
volume = {"22"},
number = {""},
pages = {"46 - 61"},
year = {"2017"},
note = {""},
issn = {"2212-4209"},
doi = {"https://doi.org/10.1016/j.ijdrr.2017.02.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S2212420916303144"},
author = {"Ouejdane Mejri and Scira Menoni and Kyla Matias and Negar Aminoltaheri"},
keywords = {"Crisis information", "Spatial planning", "Resilience", "Knowledge management", "Ontologies", "Crowdsourcing "},
abstract = {"Abstract In this paper we propose to explore the complex node of post disaster reconstruction, knowledge and data necessary to support spatial planning, and new information technologies. The methodology that is illustrated assumes that post-event damage assessments are useful to verify to what extent hazard and risk assessments that were available to planners to make decisions before the disaster were correct and if they were actually used as a basis for locational and zoning choices. Our contribution is aimed at the creation and design of knowledge bases accounting for the dynamic evolution of disasters. New web based technologies provide the opportunity to collect and analyse dynamic territorial crisis data using crowdsourcing and crowdmapping platforms. The proposed methodology permits to sort and classify a very large set of different types of data generated through the web. Semantic conceptualization using ontologies is performed to identify and select the information produced during the emergency that can support spatial planning in the post disaster reconstruction. The city of Tacloban in the Philippines, affected by the Super Typhoon Haiyan in November 2013 constitutes the test case for applying the methodology that has been developed. "} 
}
@article{Wang201530,
title = {"Spatiotemporal and semantic information extraction from Web news reports about natural hazards "},
journal = {"Computers, Environment and Urban Systems "},
volume = {"50"},
number = {""},
pages = {"30 - 40"},
year = {"2015"},
note = {""},
issn = {"0198-9715"},
doi = {"https://doi.org/10.1016/j.compenvurbsys.2014.11.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0198971514001252"},
author = {"Wei Wang and Kathleen Stewart"},
keywords = {"Spatiotemporal semantic information retrieval", "Natural language processing", "Hazard ontology", "GIS", "Gazetteers "},
abstract = {"Abstract In the field of geographic information science, modeling geographic dynamics based on spatiotemporal information extracted from the Web, especially unconstructed data such as online news reports, is a growing area of research. Extracting spatiotemporal and semantic information from a set of Web documents enables us to build a rich representation of geographic knowledge described in text, capturing where, when, or what events have occurred. This work investigates the role ontologies play as a key component in the process of semantic information extraction. We show how ontologies can be used in conjunction with natural language gazetteers in order to process semantic information about hazard events and augment spatiotemporal extraction with semantics. We are interested in capturing the spatiotemporal patterns of hazard-related events from online news reports to track the occurrences and evolution of natural hazards, such as severe storms. A hazard ontology has been created to assist the spatiotemporal information extraction process, especially with the automatic detection of different kinds of events at multiple granularities from unstructured texts revealing relationships between the events over space–time. The extraction and retrieval of semantic information about event dynamics provides information about the progression of events using both natural and human perspectives. "} 
}
@article{StackmanJr2016118,
title = {"Temporary inactivation reveals that the \{CA1\} region of the mouse dorsal hippocampus plays an equivalent role in the retrieval of long-term object memory and spatial memory "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"133"},
number = {""},
pages = {"118 - 128"},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2016.06.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742716300910"},
author = {"Robert W. Stackman Jr. and Sarah J. Cohen and Joan C. Lora and Lisa M. Rios"},
keywords = {"Object recognition", "Morris water maze", "Novel object preference", "Hippocampus", "Muscimol", "Spatial memory "},
abstract = {"Abstract Recognition of a previously experienced item or object depends upon the successful retrieval of memory for the object. The neural mechanisms that support object recognition memory in the mammalian brain are not well understood. The rodent hippocampus plays a well-established role in spatial memory, and we previously demonstrated that temporary inactivation of the mouse hippocampus impairs object memory, as assessed with a novel object preference (NOP) test. The present studies were designed to test some remaining issues regarding the contribution of the \{CA1\} sub-region of the mouse dorsal hippocampus to long-term object memory. Specifically, we examined whether the retrieval of spatial memory (as assessed by the Morris water maze; MWM) and object recognition memory are differentially sensitive to inactivation of the \{CA1\} region. The current study used pre-test local microinfusion of muscimol directly into the \{CA1\} region of dorsal hippocampus to temporarily interrupt its function during the respective retrieval phases of both behavioral tasks, in order to compare the contribution of the \{CA1\} to object memory and spatial memory. Histological analyses revealed that local intra-CA1 injection of muscimol diffused within, and not beyond, the \{CA1\} region of dorsal hippocampus. The degree of memory retrieval impairment induced by muscimol was comparable in the two tasks, supporting the view that object memory and spatial memory depend similarly on the \{CA1\} region of rodent hippocampus. Further, we confirmed that the muscimol-induced impairment of \{CA1\} function is temporary. First, mice that exhibited impaired object memory retrieval immediately after intra-CA1 muscimol, subsequently exhibited unimpaired retrieval of object memory when tested 24 h later. Secondly, a cohort of mice that exhibited impaired object memory retrieval after intra-CA1 muscimol later acquired spatial memory in the \{MWM\} comparable to that of control mice. Together, these results offer further support for the involvement of the \{CA1\} region of mouse hippocampus in object recognition memory, and provide evidence to suggest that the \{NOP\} task is as much a test of hippocampal function as the classic \{MWM\} test. "} 
}
@article{Moradizadeh2016803,
title = {"Vegetation Effects Modeling in Soil Moisture Retrieval Using \{MSVI\} "},
journal = {"Photogrammetric Engineering & Remote Sensing "},
volume = {"82"},
number = {"10"},
pages = {"803 - 810"},
year = {"2016"},
note = {""},
issn = {"0099-1112"},
doi = {"https://doi.org/10.14358/PERS.82.10.803"},
url = {"http://www.sciencedirect.com/science/article/pii/S0099111216301434"},
author = {"Mina Moradizadeh and Mohammad R. Saradjian"},

abstract = {"Abstract Brightness temperature (BT) measured by passive microwave sensors is usually affected by soil moisture, vegetation cover, and soil roughness. Soil moisture estimates have been limited to regions that had either bare soil or low to moderate amounts of vegetation cover. In this study, Simultaneous Land Parameters Retrieval Model (SLPRM) as an iterative least-squares minimization method has been used. This algorithm retrieves surface soil moisture, land surface temperature, and canopy temperature simultaneously using brightness temperature data in bare soil, low to moderate and higher amounts of vegetation cover. Furthermore, a new index called \{MSVI\} (Multi Sensor Vegetation Index) has been introduced to approximate vegetation effects on properly observed brightness temperatures. The algorithm includes model construction, calibration, and validation using observations carried out for the \{SMEX03\} (Soil Moisture Experiment 2003) region in the South and North of Oklahoma. The results indicated about 0.9 percent improvement on soil moisture estimation accuracy using the MSVI. "} 
}
@article{Zamberlam201655,
title = {"Effects of standardized Ginkgo biloba extract on the acquisition, retrieval and extinction of conditioned suppression: Evidence that short-term memory and long-term memory are differentially modulated "},
journal = {"Physiology & Behavior "},
volume = {"165"},
number = {""},
pages = {"55 - 68"},
year = {"2016"},
note = {""},
issn = {"0031-9384"},
doi = {"https://doi.org/10.1016/j.physbeh.2016.06.036"},
url = {"http://www.sciencedirect.com/science/article/pii/S0031938416304772"},
author = {"C.R. Zamberlam and N.C. Vendrasco and D.R. Oliveira and R.B. Gaiardo and S.M. Cerutti"},

abstract = {"Abstract Studies in our laboratory have characterized the putative neuromodulatory effects of a standardized extract of the green leaves of Ginkgo biloba (EGb), which comprises a formulation of 24% ginkgo-flavoglycosides and 6% ginkgo-terpenoid lactones, on conditioned suppression. This model comprises a suitable animal model for investigating the behavioral changes and pharmacological mechanisms that underlie fear memory and anxiety. The characterization of the effects on distinct stages of fear memory or fear extinction will help illustrate both the beneficial and harmful effects. Three hundred adult male Wistar rats were randomly assigned to 30 groups according to the treatment as follows: i–ii) control groups (CS-US and CSno-US); iii) vehicle group (12% Tween®80); and iv–vi) \{EGb\} groups (250, 500 and 1000 mg kg− 1); or experimental procedures designed to assess the effects of \{EGb\} treatment prior to the acquisition (n = 20 per group) and retrieval of conditioned fear (n = 10 per group) or prior to the extinction training (n = 10 per group) and extinction retention test (n = 10 per group). Furthermore, to better understand the effects of acute \{EGb\} treatment on fear memory, we conducted two additional analyses: the acquisition of within- and between-session extinction of fear memory (short- and long-term memory, respectively). No difference was identified between the control and treatment groups during the retention test (P &gt; 0.05), with the exception of the CSno-US group in relation to all groups (P &lt; 0.05). A between-session analysis indicated that \{EGb\} at 250 mg kg− 1 facilitated the acquisition of extinction fear memory, which was verified by the suppression ration in the first trial of extinction training (SR = 0.39) and the extinction retention test session (SR = 0.53, P &lt; 0.05), without impairments in fear memory acquisition, which were evaluated during the retention test (SR = 0.79). Moreover, \{EGb\} administered at 1000 mg kg− 1 prior to conditioning did not enhance the long-term extinction memory, i.e., it did not prevent the return of extinguished fear memory in the extinction retention test, in which the spontaneous recovery of fear was demonstrated (SR = 0.63, P &lt; 0.05); however, it significantly facilitated short-term memory as verified by data from the within-session extinction (1 to 8–10 trials) during the retention test (SR = 0.73 to \{SR\} = 0.59; P &lt; 0.05) and the extinction retention test (SR = 0.63 to \{SR\} = 0.41; P &lt; 0.05). Moreover, spontaneous recovery was identified in response to a higher dose of \{EGb\} when administered prior to extinction training (SR = 0.75, P &lt; 0.05) and the extinction retention test (SR = 0.70; P &lt; 0.05). At dose of 500 mg kg− 1 \{EGb\} reduced the suppression ratio when administered prior to the retention test (SR = 0.57) and extinction training (SR = 0.55; P &lt; 0.05) without preventing the acquisition of fear memory, which suggests that \{EGb\} has anti-anxiety effects. Taken together, the current findings suggest that \{EGb\} differentially modulates short- and long-term memory, as well as anxiety-like behavior. The actions of \{EGb\} may provide information regarding the beneficial effects in the prevention and treatment of neurocognitive impairments and anxiety disorders. Additional analyses are necessary to facilitate an understanding of these effects; however, previous data from our group suggest that GABAergic, serotoninergic and glutamatergic receptors are potential targets of the effects of \{EGb\} on conditioned suppression. "} 
}
@article{Kose2017105,
title = {"An integrated approach based on game theory and geographical information systems to solve decision problems "},
journal = {"Applied Mathematics and Computation "},
volume = {"308"},
number = {""},
pages = {"105 - 114"},
year = {"2017"},
note = {""},
issn = {"0096-3003"},
doi = {"https://doi.org/10.1016/j.amc.2017.03.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0096300317301947"},
author = {"Erkan Kose and Mehmet Erbas and Erkan Ersen"},
keywords = {"Decision making", "Game theory", "Geographic information systems "},
abstract = {"Abstract In this study, a military decision problem is handled by an integrated approach based on game theory and geographical information systems (GIS). The problem can be defined as: finding layout plan for troops who want to maximize probability of identifying enemies using particular routes to penetrate border line. The problem has been transformed to two-person zero-sum game by some assumptions and solved in four interconnected stages. First, suitable spots in the terrain for monitoring the enemies were identified. Then, visibility percentages of each of the spots were calculated by using \{GIS\} for the routes used by enemies to pass the border line. Next, by assuming the calculated visibility ratios as the probability of identifying the enemy, a two-person zero-sum payoff matrix was formed. Finally, linear mathematical model established to obtain optimal strategies with their probabilities. There are many techniques in literature to solve military decision problems but we believe that this study, by holding the peculiarity of the first study in which game theory and \{GIS\} are used together, will make a significant contribution to literature and future studies. "} 
}
@article{Marzouk2017351,
title = {"Building information modeling-based model for calculating direct and indirect emissions in construction projects "},
journal = {"Journal of Cleaner Production "},
volume = {"152"},
number = {""},
pages = {"351 - 363"},
year = {"2017"},
note = {""},
issn = {"0959-6526"},
doi = {"https://doi.org/10.1016/j.jclepro.2017.03.138"},
url = {"http://www.sciencedirect.com/science/article/pii/S0959652617305905"},
author = {"Mohamed Marzouk and Eslam Mohammed Abdelkader and Khalid Al-Gahtani"},
keywords = {"Construction projects", "Construction emissions", "Building information modeling", "Direct emission", "Indirect emissions", "Project life cycle phases "},
abstract = {"Abstract The construction industry is considered as one of the most dynamic sectors that have upstream and downstream economic links and has been growing rapidly in the last few decades. On the other hand, it is considered as one of the main sources of greenhouse gases where construction projects represent a huge portion of sources producing carbon dioxide gases (CO2). Furthermore, greenhouse gases (GHG) are one of construction emissions that should be investigated to calculate the overall emissions. Therefore, estimating construction emissions is very important in order to keep emissions at an acceptable level. This paper presents a building information modeling (BIM)-based model that enables the estimation of six types of emissions including: greenhouse gases, sulfur dioxide, particular matter, eutrophication particles, ozone depleting particles and smog. As such, the total direct and indirect emissions can be calculated where these emissions are produced from construction activities during the overall project life cycle phases which are: manufacturing phase, transportation phase, construction phase, operation phase, maintenance phase, and deconstruction/demolition phase. The methods of calculating direct and indirect emissions are extensively described in the paper. A case study is presented to illustrate the use of the proposed BIM-based model. "} 
}
@article{Ahmed20161724,
title = {"VenaTech \{LP\} Filter Retrieval for Filter-Related Thrombosis or Malpositioning "},
journal = {"Journal of Vascular and Interventional Radiology "},
volume = {"27"},
number = {"11"},
pages = {"1724 - 1726"},
year = {"2016"},
note = {""},
issn = {"1051-0443"},
doi = {"https://doi.org/10.1016/j.jvir.2016.06.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051044316302512"},
author = {"Osman Ahmed and Sreekumar Madassery and Derek Heussner and Patrick Tran and Abdulrahman Masrani and Bulent Arslan and Ulku Cenk Turba"} 

}
@article{Addis201680,
title = {"Characterizing cerebellar activity during autobiographical memory retrieval: \{ALE\} and functional connectivity investigations "},
journal = {"Neuropsychologia "},
volume = {"90"},
number = {""},
pages = {"80 - 93"},
year = {"2016"},
note = {"Memory, Consciousness, and the Brain: A Special Issue in Honour of Morris Moscovitch "},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2016.05.025"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393216301774"},
author = {"Donna Rose Addis and Eleanor E.J. Moloney and Lynette J. Tippett and Reece P. Roberts and Sylvia Hach"},
keywords = {"Autobiographical memory", "Cerebellum", "FMRI", "Connectivity", "Activation-Likelihood Estimation "},
abstract = {"Abstract Previous neuroimaging research has shown that the cerebellum is often activated during autobiographical memory (AM) retrieval. However, the reliability of that activation, its localization within the cerebellum, and its relationship to other areas of the \{AM\} network remains unknown. The current study used Activation Likelihood Estimation meta-analysis (ALE) as well as resting-state and task-related functional connectivity analyses to better characterize cerebellar activation in relation to AM. The \{ALE\} meta-analysis was run on 32 neuroimaging studies of \{AM\} retrieval. The results revealed a cluster of reliable AM-related activity within the Crus I lobule of the right posterior cerebellum. Using the peak \{ALE\} coordinate within Crus I as a seed region, both task-related and resting state functional connectivity analyses were run on fMRI data from 38 healthy participants. To determine the specificity of connectivity patterns to Crus I, we also included a cerebellar seed region in right Lobule \{VI\} previously identified in an \{ALE\} meta-analysis as associated with working memory. Resting-state functional connectivity analyses indicated that Crus I was intrinsically connected with other areas of the \{AM\} network as well as surrounding and contralateral cerebellar regions. In contrast, the Lobule \{VI\} seed was functionally connected with cerebral and cerebellar regions typically associated with working memory. The task-related connectivity analyses revealed a similar pattern, where the Crus I seed exhibited significant connectivity with key nodes of the \{AM\} network while the Lobule \{IV\} seed did not. During a semantic control task, both Crus I and Lobule \{VI\} showed significant correlations with a network of regions that was largely distinct from the \{AM\} network. Together these results indicate that right Crus I lobule is reliably engaged during \{AM\} retrieval and is functionally connected to the \{AM\} network both during rest, and more importantly, during \{AM\} retrieval. "} 
}
@article{Sun2016115,
title = {"Part-based clothing image annotation by visual neighbor retrieval "},
journal = {"Neurocomputing "},
volume = {"213"},
number = {""},
pages = {"115 - 124"},
year = {"2016"},
note = {"Binary Representation Learning in Computer Vision "},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.12.141"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216307159"},
author = {"Guang-Lu Sun and Xiao Wu and Qiang Peng"},
keywords = {"Image annotation", "Clothing search", "Part-based", "Annotation by search "},
abstract = {"Abstract With the advent and popularity of e-commerce and clothing image-sharing websites, clothing image search and annotation become active research topics in recent years. Clothing image annotation is a challenging task due to large variations in clothing appearance, human body pose and background. In this paper, we explore part-based clothing image annotation in a search and mining framework. Similar image search is first conducted to discover visual neighbors for a query image. The impact of large variations of clothing is alleviated by pose detection and part-based feature alignment. Tag relevance and tag saliency are taken into consideration to obtain the candidate tags. The relevance of candidate tags is identified by mining visual neighbors of a query image, while the saliency is determined according to the relationship between query image parts and part clusters on the whole training set. Experiments on a dataset with 1.1 million clothing images demonstrate the effectiveness and efficiency of the proposed approach. "} 
}
@article{Vrij201744,
title = {"Using the model statement to elicit information and cues to deceit in interpreter-based interviews "},
journal = {"Acta Psychologica "},
volume = {"177"},
number = {""},
pages = {"44 - 53"},
year = {"2017"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2017.04.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691816301998"},
author = {"Aldert Vrij and Sharon Leal and Samantha Mann and Gary Dalton and Eunkyung Jo and Alla Shaboltas and Maria Khaleeva and Juliana Granskaya and Kate Houston"},
keywords = {"Interpreter", "Model statement", "Non-native speakers", "Information gathering", "Deception "},
abstract = {"Abstract We examined how the presence of an interpreter during an interview affects eliciting information and cues to deceit, while using a method that encourages interviewees to provide more detail (model statement, MS). A total of 199 Hispanic, Korean and Russian participants were interviewed either in their own native language without an interpreter, or through an interpreter. Interviewees either lied or told the truth about a trip they made during the last twelve months. Half of the participants listened to a \{MS\} at the beginning of the interview. The dependent variables were ‘detail’, ‘complications’, ‘common knowledge details’, ‘self-handicapping strategies’ and ‘ratio of complications’. In the MS-absent condition, the interviews resulted in less detail when an interpreter was present than when an interpreter was absent. In the MS-present condition, the interviews resulted in a similar amount of detail in the interpreter present and absent conditions. Truthful statements included more complications and fewer common knowledge details and self-handicapping strategies than deceptive statements, and the ratio of complications was higher for truth tellers than liars. The \{MS\} strengthened these results, whereas an interpreter had no effect on these results. "} 
}
@article{Yang201759,
title = {"Hypergraph partitioning for social networks based on information entropy modularity "},
journal = {"Journal of Network and Computer Applications "},
volume = {"86"},
number = {""},
pages = {"59 - 71"},
year = {"2017"},
note = {"Special Issue on Pervasive Social Networking "},
issn = {"1084-8045"},
doi = {"https://doi.org/10.1016/j.jnca.2016.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1084804516302326"},
author = {"Wenyin Yang and Guojun Wang and Md Zakirul Alam Bhuiyan and Kim-Kwang Raymond Choo"},
keywords = {"Scale-free network", "Social network partitioning", "Hypergraph partitioning", "Information entropy", "Modularity "},
abstract = {"Abstract A social network is a typical scale-free network with power-law degree distribution characteristics. It demonstrates several natural imbalanced clusters when it is abstracted as a graph, and expands quickly under its generative mechanism. Hypergraph is superior for modeling multi-user operations in social networks, and partitioning the hypergraph modeled social networks could ease the scaling problems. However, today's popular hypergraph partitioning tools are not sufficiently scalable; thus, unable to achieve high partitioning quality for naturally imbalanced datasets. Recently proposed hypergraph partitioner, hyperpart, replaces the balance constraint with an entropy constraint to achieve high-fidelity partitioning solutions, but it is not tailored for scale-free networks, like social networks. In order to achieve scalable and high quality partitioning results for hypergraph modeled social networks, we propose a partitioning method, EQHyperpart, which utilizes information-Entropy-based modularity Q value (EQ) to direct the hypergraph partitioning process. This \{EQ\} considers power-law degree distribution while describing the “natural” structure of scale-free networks. We then apply simulated annealing and introduce a new definition of hyperedge cut, micro cut, to avoid the local minima in convergence of partitioning, developing \{EQHyperpart\} into two specific partitioners, namely: EQHyperpart-SA and EQHyperpart-MC. Finally, we evaluate the utility of our proposed method using classical social network datasets, including Facebook dataset. Findings show that \{EQHyperpart\} partitioners are more scalable than competing approaches, achieving a tradeoff between modularity retaining and cut size minimizing under balance constraints, and an auto-tradeoff without balance constraints for hypergraph modeled social networks. "} 
}
@article{FaroqiShah2016,
title = {"Cognitive control, word retrieval and bilingual aphasia: Is there a relationship? "},
journal = {"Journal of Neurolinguistics "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2016"},
note = {""},
issn = {"0911-6044"},
doi = {"https://doi.org/10.1016/j.jneuroling.2016.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0911604416300707"},
author = {"Yasmeen Faroqi-Shah and Monica Sampson and Mariah Pranger and Susan Baughman"},
keywords = {"Bilingualism", "Aphasia", "Word fluency", "Bilingual advantage", "Cognitive control "},
abstract = {"Abstract It is proposed that successful word retrieval involves lateral inhibition of lexical competitors, and suppression of the non-target language in bilingual speakers. Thus cognitive control is crucial for word production. Given that word retrieval difficulty is a hallmark feature of aphasia, the relationship between word retrieval and cognitive control in aphasia has not been sufficiently explored. This study examined whether persons with aphasia show 1) evidence of a cognitive control deficit, 2) bilingual status interacts with cognitive control deficit in persons with aphasia, and (3) a relationship between measures of word naming and cognitive control. Thirty-eight persons with aphasia were administered a task of cognitive control (Stroop color-word task) and two word production tasks (picture naming and category fluency). We found weakened cognitive control in aphasia relative to age-matched neurologically healthy adults. A bilingual advantage in cognitive control was found in neurologically healthy adults and in one group of bilingual speakers with aphasia, but not the other group. Word retrieval in persons with aphasia was not correlated with Stroop task performance. These findings show that cognitive control performance (as measured by the Stroop task) is compromised in persons with aphasia, irrespective of bilingual status. There was a bilingual advantage in two out of three groups, showing a general support for the bilingual inhibitory control advantage (BICA) hypothesis. "} 
}
@article{Swar2017416,
title = {"Information overload, psychological ill-being, and behavioral intention to continue online healthcare information search "},
journal = {"Computers in Human Behavior "},
volume = {"70"},
number = {""},
pages = {"416 - 425"},
year = {"2017"},
note = {""},
issn = {"0747-5632"},
doi = {"https://doi.org/10.1016/j.chb.2016.12.068"},
url = {"http://www.sciencedirect.com/science/article/pii/S0747563216308974"},
author = {"Bobby Swar and Tahir Hameed and Iris Reychav"},
keywords = {"Online health information", "Information search behaviour", "Information processing theory", "Information overload", "Psychological ill-being", "Behavioral intention "},
abstract = {"Abstract Internet these days have been extensively used to access and search health information supplementing or substituting the traditional sources of online health information (OHI) like health professionals. With the increase in online health information search the production of health information on internet is also rapidly increasing. Due to the enormous volume of health information available on internet, it is hard to locate, process and manage the required valuable information effectively often overloading health information seekers. Information overload phenomenon occurs when more information is presented than the ability of information seekers to process and handle the information. Researchers argue that information overload phenomenon is significantly associated with health-related issues of information seekers. Therefore, the aim of this study is to empirically examine how \{OHI\} related information overload impacts the psychological state of information seekers and their behavioral intention to continue the use of \{OHI\} search. A research model based on Information Processing Theory and Theory of Planned Behavior is developed and tested using the data collected from 380 survey responses. The results show that perceived information overload has a positive impact on information seekers’ psychological ill-being influencing their behavioral intention to discontinue the use of \{OHI\} search. Theoretical and practical implications are discussed at the end of the paper. "} 
}
@article{Verrelst2016554,
title = {"Spectral band selection for vegetation properties retrieval using Gaussian processes regression "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"52"},
number = {""},
pages = {"554 - 567"},
year = {"2016"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2016.07.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243416301234"},
author = {"Jochem Verrelst and Juan Pablo Rivera and Anatoly Gitelson and Jesus Delegido and José Moreno and Gustau Camps-Valls"},
keywords = {"Gaussian processes regression (GPR)", "Machine learning", "Band selection", "ARTMO", "Vegetation properties", "Hyperspectral "},
abstract = {"Abstract With current and upcoming imaging spectrometers, automated band analysis techniques are needed to enable efficient identification of most informative bands to facilitate optimized processing of spectral data into estimates of biophysical variables. This paper introduces an automated spectral band analysis tool (BAT) based on Gaussian processes regression (GPR) for the spectral analysis of vegetation properties. The GPR-BAT procedure sequentially backwards removes the least contributing band in the regression model for a given variable until only one band is kept. GPR-BAT is implemented within the framework of the free ARTMO's \{MLRA\} (machine learning regression algorithms) toolbox, which is dedicated to the transforming of optical remote sensing images into biophysical products. GPR-BAT allows (1) to identify the most informative bands in relating spectral data to a biophysical variable, and (2) to find the least number of bands that preserve optimized accurate predictions. To illustrate its utility, two hyperspectral datasets were analyzed for most informative bands: (1) a field hyperspectral dataset (400–1100 nm at 2 nm resolution: 301 bands) with leaf chlorophyll content (LCC) and green leaf area index (gLAI) collected for maize and soybean (Nebraska, US); and (2) an airborne HyMap dataset (430–2490 nm: 125 bands) with \{LAI\} and canopy water content (CWC) collected for a variety of crops (Barrax, Spain). For each of these biophysical variables, optimized retrieval accuracies can be achieved with just 4 to 9 well-identified bands, and performance was largely improved over using all bands. A \{PROSAIL\} global sensitivity analysis was run to interpret the validity of these bands. Cross-validated R \{CV\} 2 (NRMSECV) accuracies for optimized \{GPR\} models were 0.79 (12.9%) for LCC, 0.94 (7.2%) for gLAI, 0.95 (6.5%) for \{LAI\} and 0.95 (7.2%) for CWC. This study concludes that a wise band selection of hyperspectral data is strictly required for optimal vegetation properties mapping. "} 
}
@article{Kwok201613,
title = {"Testing the ice-water discrimination and freeboard retrieval algorithms for the ICESat-2 mission "},
journal = {"Remote Sensing of Environment "},
volume = {"183"},
number = {""},
pages = {"13 - 25"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.05.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716302127"},
author = {"R. Kwok and G.F. Cunningham and J. Hoffmann and T. Markus"},
keywords = {"ICESat-2", "MABEL", "Sea ice", "Polar oceans", "Freeboard", "Lidars "},
abstract = {"Abstract The ICESat-2 mission will provide routine estimates of sea ice freeboard from profiles of surface heights acquired by its photon-counting lidar: the Advanced Topographic Laser Altimeter System (ATLAS). In this paper, we describe and test procedures devised to separate returns of ice from open water — a crucial step in the estimation of local sea levels for freeboard calculations. The two data sets used in these tests, one each from winter and summer, were acquired by a Multiple Altimeter Beam Experimental Lidar (MABEL) implemented to support pre-launch development of retrieval approaches. Our approach first identifies likely open water returns using surface photon and background count rates as proxy indicators of apparent surface reflectance. Since these measured rates are noisy estimates of expected reflectance, relative surface heights are used to refine the selection of the candidate sea surface samples. Results show that winter freeboard distributions are consistent with expected regional variability, and the nearly identical repeat-track freeboard distributions during summer show retrieval consistency. From coincident lidar coverage, variability of sea level samples identified in the \{MABEL\} and Airborne Topographic Mapper (ATM) lidar profiles are 1.6 cm and 2.6 cm, with the overall difference between the distributions at 0.00 ± 0.15 m. This demonstrates the viability of the algorithms. The parameters used in these procedures will serve as a baseline and as a guide for understanding algorithm reliability. It is expected that they will be adjusted post-launch to reflect the on-orbit performance of ATLAS. "} 
}
@article{Nazeer20161119,
title = {"Improved water quality retrieval by identifying optically unique water classes "},
journal = {"Journal of Hydrology "},
volume = {"541, Part B"},
number = {""},
pages = {"1119 - 1132"},
year = {"2016"},
note = {""},
issn = {"0022-1694"},
doi = {"https://doi.org/10.1016/j.jhydrol.2016.08.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022169416305108"},
author = {"Majid Nazeer and Janet E. Nichol"},
keywords = {"Coastal waters", "Fuzzy clustering", "Landsat", "HJ-1 A/B \{CCD\} "},
abstract = {"Abstract Accurate remote sensing retrieval of water quality parameters in complex coastal environments is challenging due to variability of the coastal environment. For example, in the coastal waters of Hong Kong water quality varies from east to west. The currently existing water zones, defined by the Hong Kong Environmental Protection Department (EPD) are based on ease of access to sampling locations rather than on water quality alone. In this study an archive of fifty-seven Landsat Thematic Mapper (TM), Enhanced Thematic Mapper Plus (ETM+) and HJ-1 A/B Charged Couple Device (CCD) images over a 13-year period (January 2000–December 2012) was used to define optically distinct water classes by Fuzzy c-Means (FCM) clustering. The clustering was applied by combining the Surface Reflectance (SR) derived from the first four bands of Landsat and HJ-1 scenes with 240 insitu samples of Chlorophyll-a (Chl-a) and Suspended Solid (SS) concentrations collected within 2 h of image acquisition. The \{FCM\} clustering suggested the existence of five optically different water classes in the region. The significance of the defined water classes was tested in terms of the water \{SR\} behaviour in each band. The \{SR\} for Classes 1 and 2 in bands 1–3 was lower than in other classes, and band 4 showed the lowest reflectance, indicating that these classes represent a clearer type of water. Class 3 showed intermediate reflectance in all bands, while Classes 4 and 5 showed overall higher reflectance indicating high sediment contribution from the Pearl River Delta. Application of water quality retrievals within individual classes showed much greater confidence with Root Mean Square Error (RMSE) of 1.32 μg/l (1.21 mg/l) for Chl-a (SS) concentrations, compared with 5.97 μg/l (2.98 mg/l) when applied to the whole spectrum of different water types across the region. "} 
}
@article{SamperZapater20153833,
title = {"Semantic web service discovery system for road traffic information services "},
journal = {"Expert Systems with Applications "},
volume = {"42"},
number = {"8"},
pages = {"3833 - 3842"},
year = {"2015"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2015.01.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417415000202"},
author = {"J. Javier Samper Zapater and Dolores M. Llidó Escrivá and Francisco R. Soriano García and Juan José Martínez Durá"},
keywords = {"Semantic web services", "Matchmaking", "Information retrieval", "Road traffic information systems", "Knowledge discovery "},
abstract = {"Abstract We describe a multi-agent platform for a traveller information system, allowing travellers to find the road traffic information web service (WSs) that best fits their requirements. After studying existing proposals for discovery of semantic WS, we implemented a hybrid matching algorithm, which is described in detail here. Semantic \{WS\} profiles are annotated semantically as an OWL-S and also the traveller request is represented as a OWL-S profile. The algorithm assigns different weights and measures to each advertised \{WS\} profile parameter, depending on their relevance, type and nature. To do this we have extended Paolucci’s Algorithm and adapted it to our scenario. We have added new similarity measures, in particular, the use of the ‘sibling’ relationship, to improve the recall, allowing relevant services to be discovered by the users yet not retrieved by other algorithms. Although we have increased the similarity concept relations, we have improved the run-time using a pre-process filter step that reduces the set of potentially useful WS. This improves the scalability of the semantic matching algorithm. "} 
}
@article{Megías2016155,
title = {"The retrieval and selection of arithmetic facts in oral arithmetic "},
journal = {"Acta Psychologica "},
volume = {"170"},
number = {""},
pages = {"155 - 162"},
year = {"2016"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2016.08.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691816301548"},
author = {"Patricia Megías and Pedro Macizo"},
keywords = {"Simple arithmetic", "Oral arithmetic", "Arithmetic facts", "Selection by inhibition", "Auditory format "},
abstract = {"Abstract We examined the co-activation and the selection of arithmetic facts in oral arithmetic. In two experiments, participants had to verify whether simple additions were correct or not. In Experiment 1, additions were presented in the auditory-verbal format; in Experiment 2, additions were presented in the digit format but simulating the temporal sequence of auditory problems of Experiment 1. Results were similar in both experiments. Firstly, participants took the same time to respond when an addition was incorrect but the result was that of multiplying the operands (e.g., 2 + 4 = 8) relative to a control addition with unrelated result. Secondly, participants took more time to respond when the result of multiplying the operands of the first trial was presented again in a correct addition problem (e.g., 2 + 6 = 8) relative to a control addition. This pattern of results is discussed in terms of the temporal resolution to which auditory problems are resolved and the role of an inhibitory mechanism involved in the selection of arithmetic facts. "} 
}
@article{Neinavaz2016390,
title = {"Retrieval of leaf area index in different plant species using thermal hyperspectral data "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"119"},
number = {""},
pages = {"390 - 401"},
year = {"2016"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2016.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S092427161630154X"},
author = {"Elnaz Neinavaz and Andrew K. Skidmore and Roshanak Darvishzadeh and Thomas A. Groen"},
keywords = {"Thermal infrared", "Emissivity spectra", "Leaf area index (LAI)", "Canopy", "Hyperspectral", "Remote sensing "},
abstract = {"Abstract Leaf area index (LAI) is an important variable of terrestrial ecosystems because it is strongly correlated with many ecosystem processes (e.g., water balance and evapotranspiration) and directly related to the plant energy balance and gas exchanges. Although \{LAI\} has been accurately predicted using visible and short-wave infrared hyperspectral data (0.3–2.5 μm), \{LAI\} estimation using thermal infrared (TIR, 8–14 μm) measurements has not yet been addressed. The novel approach of this study is to evaluate the retrieval of \{LAI\} using \{TIR\} hyperspectral data. The leaf area indices were destructively acquired for four plant species: Azalea japonica, Buxussempervirens, Euonymus japonicus, and Ficus benjamina. Canopy emissivity spectral measurements were obtained under controlled laboratory conditions using a \{MIDAC\} (M4401-F) spectrometer. The \{LAI\} retrieval was assessed using a partial least squares regression (PLSR), artificial neural networks (ANNs), and narrow band indices calculated from all possible combinations of waveband pairs for three vegetation indices including simple difference, simple ratio, and normalized difference. \{ANNs\} retrieved \{LAI\} more accurately than \{PLSR\} and vegetation indices (0.67 &lt; \{R2\} &lt; 0.95 versus 11.54% &lt; \{RMSEcv\} &lt; 31.23%). The accuracy of \{LAI\} retrieval did not differ significantly between the vegetation indices. The results revealed that wavebands from the 8–12 μm region contain relevant information for \{LAI\} estimation, irrespective of the chosen vegetation index. Moreover, they demonstrated that \{LAI\} may be successfully predicted from \{TIR\} hyperspectral data, even for higher values of \{LAI\} ( \{LAI\} ⩾ 5.5 ). The study showed the significance of using \{PLSR\} and \{ANNs\} as multivariate methods compared to the univariate technique (e.g., narrow band vegetation indices) when hyperspectral thermal data is utilized. We thus demonstrated for the first time the potential of hyperspectral thermal data to accurately retrieve LAI. "} 
}
@article{Inagaki2016276,
title = {"Improving the retrieval rate of inferior vena cava filters with a multidisciplinary team approach "},
journal = {"Journal of Vascular Surgery: Venous and Lymphatic Disorders "},
volume = {"4"},
number = {"3"},
pages = {"276 - 282"},
year = {"2016"},
note = {""},
issn = {"2213-333X"},
doi = {"https://doi.org/10.1016/j.jvsv.2015.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S2213333X15002838"},
author = {"Elica Inagaki and Alik Farber and Mohammad H. Eslami and Jeffrey J. Siracuse and Denis V. Rybin and Shayna Sarosiek and J. Mark Sloan and Jeffrey Kalish"},

abstract = {"Objective The option to retrieve inferior vena cava (IVC) filters has resulted in an increase in the utilization of these devices as stopgap measures in patients with relative contraindications to anticoagulation. These retrievable \{IVC\} filters, however, are often not retrieved and become permanent. Recent data from our institution confirmed a historically low retrieval rate. Therefore, we hypothesized that the implementation of a new \{IVC\} filter retrieval protocol would increase the retrieval rate of appropriate \{IVC\} filters at our institution. Methods All consecutive patients who underwent an \{IVC\} filter placement at our institution between September 2003 and July 2012 were retrospectively reviewed. In August 2012, a multidisciplinary task force was established, and a new \{IVC\} filter retrieval protocol was implemented. Prospective data were collected using a centralized interdepartmental \{IVC\} filter registry for all consecutive patients who underwent an \{IVC\} filter placement between August 2012 and September 2014. Patients were chronologically categorized into preimplementation (PRE) and postimplementation (POST) groups. Comparisons of outcome measures, including the retrieval rate of \{IVC\} filters along with rates of retrieval attempt and technical failure, were made between the two groups. Results In the \{PRE\} and \{POST\} groups, a total of 720 and 74 retrievable \{IVC\} filters were implanted, respectively. In the \{POST\} group, 40 of 74 filters (54%) were successfully retrieved compared with 82 of 720 filters (11%) in the \{PRE\} group (P &lt; .001). Furthermore, a greater number of \{IVC\} filter retrievals were attempted in the \{POST\} group than in the \{PRE\} group (66% vs 14%; P &lt; .001). No significant difference was observed between the \{PRE\} and \{POST\} groups for technical failure (17% vs 18%; P = .9). Conclusions The retrieval rate of retrievable \{IVC\} filters at our institution was significantly increased with the implementation of a new \{IVC\} filter retrieval protocol with a multidisciplinary team approach. This improved retrieval rate is possible with minimal dedication of resources and can potentially lead to a decrease in \{IVC\} filter-related complications in the future. "} 
}
@article{Che2016743,
title = {"Calibration of the 936 nm water-vapor channel for the China aerosol remote sensing \{NETwork\} (CARSNET) and the effect of the retrieval water-vapor on aerosol optical property over Beijing, China "},
journal = {"Atmospheric Pollution Research "},
volume = {"7"},
number = {"5"},
pages = {"743 - 753"},
year = {"2016"},
note = {""},
issn = {"1309-1042"},
doi = {"https://doi.org/10.1016/j.apr.2016.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1309104215301264"},
author = {"Huizheng Che and Ke Gui and Quanliang Chen and Yu Zheng and Jie Yu and Tianze Sun and Xiaoye Zhang and Guangyu Shi"},
keywords = {"CE-318 sunphotometer", "Calibration", "Modified langley method", "CARSNET", "Columnar water-vapor "},
abstract = {"Abstract Based on measurements of the 936 nm water-vapor channel and the 870 nm, and 1020 nm atmospheric window band for the CE-318 sunphotometer of CARSNET, clear-sky direct solar radiation observational data and relative optical air masses of between 2 and 5, and considering sensitivity parameters such as pressure, altitude, wavelength, and AOD936nm, which may affect the calibration result, a method to calibrate the 936 nm water-vapor channel using a modified Langley method is presented. The daily average columnar water-vapor (CWV) over urban Beijing was retrieved using three methods (Methods A, B and C), and compared with the \{AERONET\} water-vapor product. Finally, the seasonal relationships of \{CWV\} with \{AOD500nm\} and α440–870 were analyzed. The calibration results showed the calibration value to differ from the original value by about 4%. The \{CWV\} retrieval result showed that \{AERONET\} and the three methods of retrieval for \{CWV\} were highly correlated. The monthly average variation trends of \{AOD500nm\} and \{CWV\} were similar, with the maximum occurring in July, and the minimum in December. The seasonal average variation trends of \{AOD500nm\} and \{CWV\} were also similar, but could be placed in the following order: summer &gt; autumn &gt; spring &gt; winter. The seasonal variation of α440–870 versus AOD500nm, α440–870 versus CWV, and \{AOD500nm\} versus CWV, showed increasing \{AOD500nm\} with increasing CWV, which reflected the hygroscopicity of aerosol fine particle growth characteristics. Summer was mainly characterized by fine particles; while spring, autumn and winter were a mix of coarse and fine particles, showing typical urban aerosol properties. "} 
}
@article{Tao2016430,
title = {"Temporary inferior vena cava filter indications, retrieval rates, and follow-up management at a multicenter tertiary care institution "},
journal = {"Journal of Vascular Surgery "},
volume = {"64"},
number = {"2"},
pages = {"430 - 437"},
year = {"2016"},
note = {""},
issn = {"0741-5214"},
doi = {"https://doi.org/10.1016/j.jvs.2016.02.034"},
url = {"http://www.sciencedirect.com/science/article/pii/S0741521416002627"},
author = {"Mary Jiayi Tao and Janice M. Montbriand and Naomi Eisenberg and Kenneth W. Sniderman and Graham Roche-Nagle"},

abstract = {"Objective The aim of this study was to investigate the practice pattern of inferior vena cava (IVC) filters and to determine factors predictive of filter retrievals at a multicenter, tertiary care institution. Methods A retrospective review of all \{IVC\} filter procedures performed between January 2001 and July 2013 was conducted. Data collected included demographics, venous thromboembolism risk factors, medical comorbidities, insertional and retrieval characteristics, referring services, complications, discharge, and follow-up management. Results During the study period, 1123 \{IVC\} filter procedures were performed; 69% (n = 810) were insertions and 31% (n = 313) were retrievals. Of the patients receiving filters, the average age was 61.4 years, and 53.3% were male. Overall, 408 filters (51.5%) were placed with absolute indications, 214 (27.0%) for relative indications, 138 (17.4%) prophylactically, and 32 (4.0%) for reasons outside the established guidelines. Of the 663 retrievable filters, successful removal rate was 41.6% (n = 276); the mean time to first retrieval attempt was 76.4 days (standard deviation = 110.5). Documentation of the filter was present in 342 (43.1%) discharge summaries, and outlined instructions for filter management were seen in 129 (16.3%) cases. Significant predictors of filter removal were thrombosis follow-up (odds ratio [OR], 6.7; P &lt; .01) and the ordering service as filters ordered by medical specialties were less likely to be retrieved than filters ordered by surgical specialties (OR, 0.53; P = .04). Compared with discharge summaries without filter management instructions, those with plans had higher filter retrieval rates (OR, 3.74; P &lt; .00). Filter-related complications was observed in 57 patients. Conclusions Given the established complications relating to long indwelling times and recent Food and Drug Administration guidelines, a multidisciplinary and systematic follow-up protocol needs to be implemented to optimize filter retrieval rates and to ensure exemplary quality of care. "} 
}
@article{Brocas2016198,
title = {"A neuroeconomic theory of memory retrieval "},
journal = {"Journal of Economic Behavior & Organization "},
volume = {"130"},
number = {""},
pages = {"198 - 205"},
year = {"2016"},
note = {""},
issn = {"0167-2681"},
doi = {"https://doi.org/10.1016/j.jebo.2016.07.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S016726811630138X"},
author = {"Isabelle Brocas and Juan D. Carrillo"},
keywords = {"Memory systems", "Memory management", "Declarative", "Procedural", "Neuroeconomic theory "},
abstract = {"Abstract We propose a theory of “optimal memory management” that unveils causal relationships between memory systems and the characteristics of the information retrieved. Our model shows that if the declarative memory is more accurate but also more costly than the procedural memory, then it is optimal to retrieve exceptional experiences with the former and average experiences with the latter. The theory provides other testable predictions: (i) decisions are closer to original experiences when the declarative memory is invoked, and (ii) the declarative memory is more likely to be invoked when the importance of recalling information accurately increases. "} 
}
@article{Vandecasteele2017,
title = {"Fireground location understanding by semantic linking of visual objects and building information models "},
journal = {"Fire Safety Journal "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0379-7112"},
doi = {"https://doi.org/10.1016/j.firesaf.2017.03.083"},
url = {"http://www.sciencedirect.com/science/article/pii/S0379711217301364"},
author = {"Florian Vandecasteele and Bart Merci and Steven Verstockt"},
keywords = {"Building information models", "Fire analysis", "Multi-view sensing", "Location estimation", "Visual object recognition", "Semantic linking "},
abstract = {"Abstract This paper presents an outline for improved localization and situational awareness in fire emergency situations based on semantic technology and computer vision techniques. The novelty of our methodology lies in the semantic linking of video object recognition results from visual and thermal cameras with Building Information Models (BIM). The current limitations and possibilities of certain building information streams in the context of fire safety or fire incident management are addressed in this paper. Furthermore, our data management tools match higher-level semantic metadata descriptors of \{BIM\} and deep-learning based visual object recognition and classification networks. Based on these matches, estimations can be generated of camera, objects and event positions in the \{BIM\} model, transforming it from a static source of information into a rich, dynamic data provider. Previous work has already investigated the possibilities to link \{BIM\} and low-cost point sensors for fireground understanding, but these approaches did not take into account the benefits of video analysis and recent developments in semantics and feature learning research. Finally, the strengths of the proposed approach compared to the state-of-the-art is its (semi-)automatic workflow, generic and modular setup and multi-modal strategy, which allows to automatically create situational awareness, to improve localization and to facilitate the overall fire understanding. "} 
}
@article{Chesnokova2016171,
title = {"Impact of difference in absorption line parameters in spectroscopic databases on \{CO2\} and \{CH4\} atmospheric content retrievals "},
journal = {"Journal of Molecular Spectroscopy "},
volume = {"327"},
number = {""},
pages = {"171 - 179"},
year = {"2016"},
note = {"New Visions of Spectroscopic Databases, Volume \{II\} "},
issn = {"0022-2852"},
doi = {"https://doi.org/10.1016/j.jms.2016.07.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022285216301199"},
author = {"T.Yu. Chesnokova and A.V. Chentsov and N.V. Rokotyan and V.I. Zakharov"},
keywords = {"Atmospheric radiative transfer", "Methane", "Carbon dioxide", "Absorption line "},
abstract = {"Abstract The impact of uncertainties in \{CH4\} and \{CO2\} absorption line parameters in modern spectroscopic databases on the atmospheric transmission simulation in the near-infrared region is investigated. The atmospheric contents of \{CH4\} and \{CO2\} are retrieved from the absorption solar spectra measured by a ground-based Fourier transform spectrometer. Different spectroscopic databases are used in the forward radiative transfer model and a comparison of the retrieved results is made. "} 
}
@article{Gwo2016341,
title = {"Shoeprint retrieval: Core point alignment for pattern comparison "},
journal = {"Science & Justice "},
volume = {"56"},
number = {"5"},
pages = {"341 - 350"},
year = {"2016"},
note = {""},
issn = {"1355-0306"},
doi = {"https://doi.org/10.1016/j.scijus.2016.06.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S1355030616300521"},
author = {"Chih-Ying Gwo and Chia-Hung Wei"},
keywords = {"Shoeprint", "Feature extraction", "Zernike moments", "Curve fitting "},
abstract = {"Abstract Purpose: Shoeprint recognition has been widely used as forensic evidence in criminal cases. The purpose of this study is to propose a shoeprint retrieval method based on core point alignment for pattern analysis. Method: The proposed method firstly detects contour points in a black-and-white shoeprint image. These reliable contour points are selected to simulate the left and right sidelines of the shoeprint by a curve fitting method. Subsequently, the most concave points along the left and right sidelines can determine the core point of the shoeprint, thereby partitioning the shoeprint into circular regions. Next, the Zernike moments of the circular regions are calculated for pattern descriptions of each region. Finally, the Euclidean distance is measured to match the shoeprints with the same pattern. Result: The highest \{APR\} = 0.726 is obtained from the first four Zernike moments with a radius of 90 pixels and three baselines. The experimental results also show that the Zernike method in any order always outperforms the compared moment invariant and \{GLCM\} method. The experimental results also indicate that the core point is more stable than the gravity center in the both sets, because the standard deviation values of the core point are less than that of the gravity center. Conclusions: This study has verified that the proposed method can effectively align shoeprints for pattern comparison. "} 
}
@article{Brewin201682,
title = {"Underway spectrophotometry along the Atlantic Meridional Transect reveals high performance in satellite chlorophyll retrievals "},
journal = {"Remote Sensing of Environment "},
volume = {"183"},
number = {""},
pages = {"82 - 97"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.05.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716301985"},
author = {"Robert J.W. Brewin and Giorgio Dall'Olmo and Silvia Pardo and Virginie van Dongen-Vogels and Emmanuel S. Boss"},
keywords = {"Phytoplankton", "Ocean colour", "Remote sensing", "Chlorophyll", "Validation", "Atlantic Ocean "},
abstract = {"Abstract To evaluate the performance of ocean-colour retrievals of total chlorophyll-a concentration requires direct comparison with concomitant and co-located in situ data. For global comparisons, these in situ match-ups should be ideally representative of the distribution of total chlorophyll-a concentration in the global ocean. The oligotrophic gyres constitute the majority of oceanic water, yet are under-sampled due to their inaccessibility and under-represented in global in situ databases. The Atlantic Meridional Transect (AMT) is one of only a few programmes that consistently sample oligotrophic waters. In this paper, we used a spectrophotometer on two \{AMT\} cruises (AMT19 and AMT22) to continuously measure absorption by particles in the water of the ship's flow-through system. From these optical data continuous total chlorophyll-a concentrations were estimated with high precision and accuracy along each cruise and used to evaluate the performance of ocean-colour algorithms. We conducted the evaluation using level 3 binned ocean-colour products, and used the high spatial and temporal resolution of the underway system to maximise the number of match-ups on each cruise. Statistical comparisons show a significant improvement in the performance of satellite chlorophyll algorithms over previous studies, with root mean square errors on average less than half (~ 0.16 in log10 space) that reported previously using global datasets (~ 0.34 in log10 space). This improved performance is likely due to the use of continuous absorption-based chlorophyll estimates, that are highly accurate, sample spatial scales more comparable with satellite pixels, and minimise human errors. Previous comparisons might have reported higher errors due to regional biases in datasets and methodological inconsistencies between investigators. Furthermore, our comparison showed an underestimate in satellite chlorophyll at low concentrations in 2012 (AMT22), likely due to a small bias in satellite remote-sensing reflectance data. Our results highlight the benefits of using underway spectrophotometric systems for evaluating satellite ocean-colour data and underline the importance of maintaining in situ observatories that sample the oligotrophic gyres. "} 
}
@article{Figueroa201649,
title = {"Improving business process retrieval using categorization and multimodal search "},
journal = {"Knowledge-Based Systems "},
volume = {"110"},
number = {""},
pages = {"49 - 59"},
year = {"2016"},
note = {""},
issn = {"0950-7051"},
doi = {"https://doi.org/10.1016/j.knosys.2016.07.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950705116302283"},
author = {"Cristhian Figueroa and Hugo Ordoñez and Juan-Carlos Corrales and Carlos Cobos and Leandro Krug Wives and Enrique Herrera-Viedma"},
keywords = {"Business process categorization", "Semantic categorization", "Multimodal search "},
abstract = {"Abstract Enterprises use repositories of Business Processes to standardize and adapt their operations in order to reuse them for new functional requirements. However, a disorganized growth of these repositories have hampered the search of Business Processes which is fundamental for reusing them. In this paper an approach for organizing and searching Business Processes is proposed, which is composed of two phases: First, an automatic and semantic categorization phase to classify Business Processes based on their functionality, and second a multimodal search phase in order to rank Business Processes based on structural and textual features. The proposed approach was tested in an evaluation over a closed repository collaboratively built by 20 expert evaluators. Initially, evaluators were asked to rate categories assigned by our approach to each Business Process in order to assess our results against the user perspective. Later, evaluators were asked to compare six queries against the repository in order to obtain a set of relevant Business Processes for each query. With these results, precision, recall and F-measure were calculated to evaluate the relevance and ranking concordance of the proposed approach against state-of-the-art algorithms for Business Process similarity search. Additionally, we applied the Friedman and the Wilcoxon signed rank tests over the results obtained for each query over precision and F-measure in order to evaluate the statistically significance of these results. The results obtained demonstrated the effectiveness of the proposed approach for categorizing and retrieving Business Processes. "} 
}
@article{Windahl201611,
title = {"An intercomparison of Landsat land surface temperature retrieval methods under variable atmospheric conditions using in situ skin temperature "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"51"},
number = {""},
pages = {"11 - 27"},
year = {"2016"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2016.04.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243416300629"},
author = {"Emily Windahl and Kirsten de Beurs"},
keywords = {"Land surface temperature", "Precipitable water vapor", "Landsat", "Thermal remote sensing", "Atmospheric correction", "Radiative transfer equation "},
abstract = {"Abstract Land surface temperature retrieved from Landsat is a valuable resource for understanding land cover change, monitoring the urban heat island effect, and modeling hydrological and carbon cycles, among other applications. However, this dataset is underutilized, in part because it is difficult to accurately correct for atmospheric interference, and in part because it is difficult to validate the resulting \{LST\} dataset. As a result, it is often challenging to verify the accuracy of \{LST\} calculated from historical data. Currently, three correction methods are commonly used to retrieve land surface temperature from single-band Landsat \{TIR\} data—the radiative transfer equation (RTE), the mono-window algorithm (MWA), and the generalized single-channel (GSC) method. Based on current research, it is often unclear which method is best applied in different circumstances and what the actual achieved accuracy is—especially when these methods are employed as they would be for actual applications, rather than under validation conditions. This study retrieves \{LST\} from two years’ worth of clear-sky Landsat 5 \{TM\} data using all three methods, as well as \{LST\} with no atmospheric correction, and validates the results against on-the-ground skin temperature measurements from twenty-five Oklahoma Mesonet stations. Additionally, \{LST\} results using both modeled transmittance values and transmittance values based on precipitable water vapor are assessed, as are results from dates with both high and low precipitable water vapor. Results suggest that the \{MWA\} method using modeled transmittance is the most robust, with results statistically indistinguishable from Mesonet skin temperature for the complete dataset and a cloud-free subset, as well as for subsets above and below 2 g/cm2 precipitable water vapor. The \{RTE\} method using modeled atmospheric parameters is also appropriate in some circumstances. "} 
}
@article{Divine201677,
title = {"Photogrammetric retrieval and analysis of small scale sea ice topography during summer melt "},
journal = {"Cold Regions Science and Technology "},
volume = {"129"},
number = {""},
pages = {"77 - 84"},
year = {"2016"},
note = {""},
issn = {"0165-232X"},
doi = {"https://doi.org/10.1016/j.coldregions.2016.06.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165232X16301148"},
author = {"Dmitry V. Divine and Christina A. Pedersen and Tor Ivan Karlsen and Harald Faste Aas and Mats A. Granskog and Stephen R. Hudson and Sebastian Gerland"},
keywords = {"Photogrammetry", "Sea ice imagery", "Sea ice topography", "Melt ponds "},
abstract = {"Abstract The paper presents a setup for photogrammetric retrievals of small scale sea ice surface topography using low-altitude aerial imagery. The setup features two digital cameras, a combined \{GPS\} receiver/inertial navigation system (INS) unit, and a laser range finder. The components are fit in a single aerodynamic enclosure mounted outside a helicopter cabin. Results from its first deployment during the field campaign on Arctic sea ice north of Svalbard during summer 2012 are shown. Comparison of photogrammetrically derived digital elevation models (DEMs) with in situ measurements of sea ice topography made on melting first year sea ice demonstrated the ability of the method to accurately recover the topography of sea ice including melt ponds with depths down to at least 0.3m. The inter-comparison of the photogrammetrically derived \{DEM\} and in situ measured elevations yielded estimates of a root mean square error (RMS) of about 0.04m and bias of 0.03m, both for sea ice freeboard and melt pond depths. The bimodality of the probability density function of measured melt pond depths was also accurately reproduced in the reconstructed DEM. Discrepancies between the measured and \{DEM\} distributions were within the range of the inferred uncertainty of the photogrammetric and in situ techniques, with some of the bias likely associated with sea ice melt during the time elapsed between in situ and aerial measurements. "} 
}
@article{Lin2016150,
title = {"Retrieval of effective leaf area index (LAIe) and leaf area density (LAD) profile at individual tree level using high density multi-return airborne LiDAR "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"50"},
number = {""},
pages = {"150 - 158"},
year = {"2016"},
note = {""},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2016.03.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243416300459"},
author = {"Yi Lin and Geoff West"},
keywords = {"Leaf area index (LAI)", "Leaf area density (LAD) profile", "Effective \{LAI\} (LAIe)", "Unified cumulative \{LAI\} (ucLAI)", "Light detection and ranging (LiDAR)", "Static terrestrial laser scanning (TLS) "},
abstract = {"Abstract As an important canopy structure indicator, leaf area index (LAI) proved to be of considerable implications for forest ecosystem and ecological studies, and efficient techniques for accurate \{LAI\} acquisitions have long been highlighted. Airborne light detection and ranging (LiDAR), often termed as airborne laser scanning (ALS), once was extensively investigated for this task but showed limited performance due to its low sampling density. Now, \{ALS\} systems exhibit more competing capacities such as high density and multi-return sampling, and hence, people began to ask the questions like—“can \{ALS\} now work better on the task of \{LAI\} prediction?” As a re-examination, this study investigated the feasibility of \{LAI\} retrievals at the individual tree level based on high density and multi-return ALS, by directly considering the vertical distributions of laser points lying within each tree crown instead of by proposing feature variables such as quantiles involving laser point distribution modes at the plot level. The examination was operated in the case of four tree species (i.e. Picea abies, Pinus sylvestris, Populus tremula and Quercus robur) in a mixed forest, with their LAI-related reference data collected by using static terrestrial laser scanning (TLS). In light of the differences between ALS- and TLS-based \{LAI\} characterizations, the methods of voxelization of 3D scattered laser points, effective \{LAI\} (LAIe) that does not distinguish branches from canopies and unified cumulative \{LAI\} (ucLAI) that is often used to characterize the vertical profiles of crown leaf area densities (LADs) was used; then, the relationships between the ALS- and TLS-derived \{LAIes\} were determined, and so did ucLAIs. Tests indicated that the tree-level \{LAIes\} for the four tree species can be estimated based on the used airborne LiDAR (R2 = 0.07, 0.26, 0.43 and 0.21, respectively) and their ucLAIs can also be derived. Overall, this study has validated the usage of the contemporary high density multi-return airborne LiDARs for \{LAIe\} and \{LAD\} profile retrievals at the individual tree level, and the contribution are of high potential for advancing forest ecosystem modeling and ecological understanding. "} 
}
@article{Jimura201624,
title = {"Relatedness-dependent rapid development of brain activity in anterior temporal cortex during pair-association retrieval "},
journal = {"Neuroscience Letters "},
volume = {"627"},
number = {""},
pages = {"24 - 29"},
year = {"2016"},
note = {""},
issn = {"0304-3940"},
doi = {"https://doi.org/10.1016/j.neulet.2016.05.044"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304394016303640"},
author = {"Koji Jimura and Satoshi Hirose and Hiroyuki Wada and Yasunori Yoshizawa and Yoshio Imai and Masaaki Akahane and Toru Machida and Ichiro Shirouzu and Yasuharu Koike and Seiki Konishi"},
keywords = {"Human", "fMRI", "Memory consolidation "},
abstract = {"Abstract Functional \{MRI\} studies have revealed that the brain activity in the anterior temporal cortex during memory retrieval increases over months after memory encoding. Behavioral evidence has demonstrated that long-term memory can sometimes be consolidated more rapidly in one or two days. In the present functional \{MRI\} study, we manipulated the relatedness between paired faces to be retrieved in a pair-association task. The brain activity in the anterior temporal cortex during retrieval of paired associates increased rapidly in one day, as shown in previous studies. We found that the speed of the brain activity development was dependent on the level of semantic relatedness of paired faces. The results suggest that the semantic relatedness enhances the speed of formation of memory representation in the anterior temporal cortex. "} 
}
@article{Beydoun201445,
title = {"Identification of ontologies to support information systems development "},
journal = {"Information Systems "},
volume = {"46"},
number = {""},
pages = {"45 - 60"},
year = {"2014"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2014.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S030643791400074X"},
author = {"Ghassan Beydoun and Graham Low and Francisco García-Sánchez and Rafael Valencia-García and Rodrigo Martínez-Béjar"},
keywords = {"Information systems development", "Ontologies", "Early requirements", "Ontology retrieval", "i* Models "},
abstract = {"Abstract Ontologies can provide many benefits during information systems development. They can provide domain knowledge to requirement engineers, are reusable software components for web applications or intelligent agent developers, and can facilitate semi-automatic model verification and validation. They also assist in software extensibility, interoperability and reuse. All these benefits critically depend on the provision of a suitable ontology (ies). This paper introduces a semantically-based three stage-approach to assist developers in checking the consistency of the requirements models and choose the most suitable and relevant ontology (ies) for their development project from a given repository. The early requirements models, documented using the i⁎ language, are converted to a retrieval ontology. The consistency of this retrieval ontology is then checked before being used to identify a set of reusable ontologies that are relevant for the development project. The paper also provides an initial validation of each of the stages. "} 
}
@article{Xie201681,
title = {"Cross-Modal Self-Taught Hashing for large-scale image retrieval "},
journal = {"Signal Processing "},
volume = {"124"},
number = {""},
pages = {"81 - 92"},
year = {"2016"},
note = {"Big Data Meets Multimedia AnalyticsContaining a selection of papers from the 21st International Conference on Multimedia Modelling (MMM2015) "},
issn = {"0165-1684"},
doi = {"https://doi.org/10.1016/j.sigpro.2015.10.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0165168415003539"},
author = {"Liang Xie and Lei Zhu and Peng Pan and Yansheng Lu"},
keywords = {"Image retreival", "Cross-modal hashing", "Self-taught learning", "Semantic correlation "},
abstract = {"Abstract Cross-modal hashing integrates the advantages of traditional cross-modal retrieval and hashing, it can solve large-scale cross-modal retrieval effectively and efficiently. However, existing cross-modal hashing methods rely on either labeled training data, or lack semantic analysis. In this paper, we propose Cross-Modal Self-Taught Hashing (CMSTH) for large-scale cross-modal and unimodal image retrieval. \{CMSTH\} can effectively capture the semantic correlation from unlabeled training data. Its learning process contains three steps: first we propose Hierarchical Multi-Modal Topic Learning (HMMTL) to detect multi-modal topics with semantic information. Then we use Robust Matrix Factorization (RMF) to transfer the multi-modal topics to hash codes which are more suited to quantization, and these codes form a unified hash space. Finally we learn hash functions to project all modalities into the unified hash space. Experimental results on two web image datasets demonstrate the effectiveness of \{CMSTH\} compared to representative cross-modal and unimodal hashing methods. "} 
}
@article{Fedarenka201672,
title = {"Utilization of \{AERONET\} polarimetric measurements for improving retrieval of aerosol microphysics: GSFC, Beijing and Dakar data analysis "},
journal = {"Journal of Quantitative Spectroscopy and Radiative Transfer "},
volume = {"179"},
number = {""},
pages = {"72 - 97"},
year = {"2016"},
note = {""},
issn = {"0022-4073"},
doi = {"https://doi.org/10.1016/j.jqsrt.2016.03.021"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022407316301534"},
author = {"Anton Fedarenka and Oleg Dubovik and Philippe Goloub and Zhengqiang Li and Tatyana Lapyonok and Pavel Litvinov and Luc Barel and Louis Gonzalez and Thierry Podvin and Didier Crozel"},
keywords = {"Aerosol remote sensing", "Sun-photometer", "Polarimetry", "Sensitivity study", "Data inversion "},
abstract = {"Abstract The study presents the efforts on including the polarimetric data to the routine inversion of the radiometric ground-based measurements for characterization of the atmospheric aerosols and analysis of the obtained advantages in retrieval results. First, to operationally process the large amount of polarimetric data the data preparation tool was developed. The \{AERONET\} inversion code adapted for inversion of both intensity and polarization measurements was used for processing. Second, in order to estimate the effect from utilization of polarimetric information on aerosol retrieval results, both synthetic data and the real measurements were processed using developed routine and analyzed. The sensitivity study has been carried out using simulated data based on three main aerosol models: desert dust, urban industrial and urban clean aerosols. The test investigated the effects of utilization of polarization data in the presence of random noise, bias in measurements of optical thickness and angular pointing shift. The results demonstrate the advantage of polarization data utilization in the cases of aerosols with pronounced concentration of fine particles. Further, the extended set of \{AERONET\} observations was processed. The data for three sites have been used: GSFC, \{USA\} (clean urban aerosol dominated by fine particles), Beijing, China (polluted industrial aerosol characterized by pronounced mixture of both fine and coarse modes) and Dakar, Senegal (desert dust dominated by coarse particles). The results revealed considerable advantage of polarimetric data applying for characterizing fine mode dominated aerosols including industrial pollution (Beijing). The use of polarization corrects particle size distribution by decreasing overestimated fine mode and increasing the coarse mode. It also increases underestimated real part of the refractive index and improves the retrieval of the fraction of spherical particles due to high sensitivity of polarization to particle shape. Overall, the study demonstrates a substantial value of polarimetric data for improving aerosol characterization. "} 
}
@article{Qin201662,
title = {"Encryption of \{QR\} code and grayscale image in interference-based scheme with high quality retrieval and silhouette problem removal "},
journal = {"Optics and Lasers in Engineering "},
volume = {"84"},
number = {""},
pages = {"62 - 73"},
year = {"2016"},
note = {""},
issn = {"0143-8166"},
doi = {"https://doi.org/10.1016/j.optlaseng.2016.03.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0143816616300264"},
author = {"Yi Qin and Hongjuan Wang and Zhipeng Wang and Qiong Gong and Danchen Wang"},
keywords = {"Optical encryption", "QR code", "Silhouette problem "},
abstract = {"Abstract In optical interference-based encryption (IBE) scheme, the currently available methods have to employ the iterative algorithms in order to encrypt two images and retrieve cross-talk free decrypted images. In this paper, we shall show that this goal can be achieved via an analytical process if one of the two images is \{QR\} code. For decryption, the \{QR\} code is decrypted in the conventional architecture and the decryption has a noisy appearance. Nevertheless, the robustness of \{QR\} code against noise enables the accurate acquisition of its content from the noisy retrieval, as a result of which the primary \{QR\} code can be exactly regenerated. Thereafter, a novel optical architecture is proposed to recover the grayscale image by aid of the \{QR\} code. In addition, the proposal has totally eliminated the silhouette problem existing in the previous \{IBE\} schemes, and its effectiveness and feasibility have been demonstrated by numerical simulations. "} 
}
@article{Cameron201439,
title = {"A hybrid approach to finding relevant social media content for complex domain specific information needs "},
journal = {"Web Semantics: Science, Services and Agents on the World Wide Web "},
volume = {"29"},
number = {""},
pages = {"39 - 52"},
year = {"2014"},
note = {"Life Science and e-Science "},
issn = {"1570-8268"},
doi = {"https://doi.org/10.1016/j.websem.2014.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S157082681400105X"},
author = {"Delroy Cameron and Amit P. Sheth and Nishita Jaykumar and Krishnaprasad Thirunarayan and Gaurish Anand and Gary A. Smith"},
keywords = {"Semantic search", "Domain specific information retrieval", "Complex information needs", "Ontology", "Background knowledge", "Context-free grammar", "Knowledge-aware search "},
abstract = {"Abstract While contemporary semantic search systems offer to improve classical keyword-based search, they are not always adequate for complex domain specific information needs. The domain of prescription drug abuse, for example, requires knowledge of both ontological concepts and “intelligible constructs” not typically modeled in ontologies. These intelligible constructs convey essential information that include notions of intensity, frequency, interval, dosage, and sentiments, which could be important to the holistic needs of the information seeker. In this paper, we present a hybrid approach to domain specific information retrieval (or knowledge-aware search) that integrates ontology-driven query interpretation with synonym-based query expansion, and domain specific rules, to facilitate search. Our framework is based on a context-free grammar (CFG) that defines the query language of constructs interpretable by the search system. The grammar provides two levels of semantic interpretation: (1) a top-level \{CFG\} that facilitates retrieval of diverse textual patterns, which belong to broad templates and (2) a low-level \{CFG\} that enables interpretation of specific expressions that belong to such patterns. These low-level expressions occur as concepts from four different categories of data: (1) ontological concepts, (2) concepts in lexicons (such as emotions and sentiments), (3) concepts in lexicons with only partial ontology representation, called lexico-ontology concepts (such as side effects and routes of administration (ROA)), and (4) domain specific expressions (such as date, time, interval, frequency, and dosage) derived solely through rules. Our approach is embodied in a novel Semantic Web platform called PREDOSE, which provides search support for complex domain specific information needs in prescription drug abuse epidemiology. When applied to a corpus of over 1 million drug abuse-related web forum posts, our search framework proved effective in retrieving relevant documents when compared with three existing search systems. "} 
}
@article{Chang2016152,
title = {"Investigating ambient ozone formation regimes in neighboring cities of shale plays in the Northeast United States using photochemical modeling and satellite retrievals "},
journal = {"Atmospheric Environment "},
volume = {"142"},
number = {""},
pages = {"152 - 170"},
year = {"2016"},
note = {""},
issn = {"1352-2310"},
doi = {"https://doi.org/10.1016/j.atmosenv.2016.06.058"},
url = {"http://www.sciencedirect.com/science/article/pii/S1352231016304915"},
author = {"Chih-Yuan Chang and Eric Faust and Xiangting Hou and Pius Lee and Hyun Cheol Kim and Brent C. Hedquist and Kuo-Jen Liao"},
keywords = {"CMAQ", "GOME-2", "OMI", "Ozone formation regimes", "Shale oil and gas "},
abstract = {"Abstract This study investigates long-term (i.e., 2007–2014) fluctuations in ambient ozone formation regimes for cities adjacent to shale plays in the Northeast United States (U.S.). Ozone air quality in many cities of the Northeast U.S. does not meet the U.S. National Ambient Air Quality Standards (NAAQS), and understanding ambient ozone formation regimes is essential to develop effective air pollution mitigation strategies for cities violating the air quality standards. Since 2013, the U.S. has become the world’s largest producer of tight oil and natural gas from shale rock, and previous studies show that emissions of air pollutant precursors from shale oil and gas-related activities would have the potential to affect ambient ozone air quality in adjacent cities of shale plays. This work leveraged (1) satellite-retrieved column densities of formaldehyde (HCHO) and nitrogen dioxide (NO2) from multiple instruments (i.e., Ozone Monitoring Instrument (OMI) and Global Ozone Monitoring Experiment-2 (GOME-2)); (2) photochemical air quality modeling and sensitivity analysis; and (3) ratios of satellite-retrieved air pollutant column densities to investigate ambient ozone formation regimes in neighboring cities of shale plays (i.e., Marcellus Shale) in the Northeast U.S. from 2007 to 2014. Our results show that ambient ozone formation in Boston, Pittsburgh, Philadelphia and Washington, D.C. (which are close to Marcellus Shale) was in the \{NOx\} -limited or transition regime during the period of study. Ambient ozone formation in New York City was in the transition regime during 2010–2013 and \{VOC\} -limited regime during 2007–2009 and in 2014. Based on the result of this study, we conclude that controls \{NOx\} emissions would mitigate ozone air pollution from 2007 to 2014 in most of the cities examined in this study. Controls of local \{VOC\} emissions would ease ozone air pollution in New York City during the study period. With projected increases in oil and gas production from shale plays in the Northeast U.S., air pollutant emissions from oil and gas-related activities are expected to increase in the future. The results of this study imply that controls of ozone precursor emissions from shale oil and gas-related activities could be a potential strategy for reducing ambient ozone formation in cities adjacent to the shale plays in Northeast U.S. in the future. "} 
}
@article{Moradizadeh2016127,
title = {"The effect of roughness in simultaneously retrieval of land surface parameters "},
journal = {"Physics and Chemistry of the Earth, Parts A/B/C "},
volume = {"94"},
number = {""},
pages = {"127 - 135"},
year = {"2016"},
note = {"3rd International Conference on Ecohydrology, Soil and Climate Change, EcoHCC’14 "},
issn = {"1474-7065"},
doi = {"https://doi.org/10.1016/j.pce.2016.03.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1474706516300018"},
author = {"Mina Moradizadeh and Mohammad R. Saradjian"},
keywords = {"Soil moisture", "SLPRM", "AMSR_E", "Roughness", "SAR", "Vegetated areas "},
abstract = {"Abstract Using remotely-sensed data, various soil moisture estimation models have been developed for bare soil areas. Previous studies have shown that the brightness temperature (BT) measured by passive microwave sensors were affected by characteristics of the land surface parameters including soil moisture, vegetation cover and soil roughness. Therefore knowledge of vegetation cover and soil roughness is important for obtaining frequent and global estimations of land surface parameters especially soil moisture. In this study, a model called Simultaneous Land Parameters Retrieval Model (SLPRM) that is an iterative least-squares minimization method is proposed. The algorithm estimates surface soil moisture, land surface temperature and canopy temperature simultaneously in vegetated areas using AMSR-E (Advance Microwave Scanning Radiometer-EOS) brightness temperature data. The simultaneous estimations of the three parameters are based on a multi-parameter inversion algorithm which includes model construction, calibration and validation using observations carried out for the \{SMEX03\} (Soil Moisture Experiment, 2003) region in the South and North of Oklahoma. Roughness parameter has also been included in the algorithm to increase the soil parameters retrieval accuracy. Unlike other methods, the \{SLPRM\} method works efficiently in all land covers types. The study focuses on soil parameters estimation by comparing three different scenarios with the inclusion of roughness data and selects the most appropriate one. The difference between the resulted accuracies of scenarios is due to the roughness calculation approach. The analysis on the retrieval model shows a meaningful and acceptable accuracy on soil moisture estimation according to the three scenarios. The \{SLPRM\} method has shown better performance when the \{SAR\} (Synthetic Aperture RADAR) data are used for roughness calculation. "} 
}
@article{Zhioua2016220,
title = {"A joint active time and flow selection model for cellular content retrieval through \{ITS\} "},
journal = {"Computer Networks "},
volume = {"107, Part 2"},
number = {""},
pages = {"220 - 232"},
year = {"2016"},
note = {"Mobile Wireless Networks "},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2016.03.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S138912861630086X"},
author = {"G.e.m. Zhioua and J. Zhang and H. Labiod and N. Tabbane and S. Tabbane"},
keywords = {"cellular 4G network", "offload", "modeling", "analytic study", "performances", "vehicular network "},
abstract = {"Abstract Operators need to address increased data demands to meet subscribers’ growing requirements by offloading a portion of cellular traffic onto other types of networks. In this paper, we investigate the possibility of using vehicular ad hoc networks (VANETs) for this purpose. We study joint data flow selection and contention resolution in a hybrid VANET-cellular system. We formulate the problem as an optimization problem called FOSAA, which considers vehicle-to-vehicle and vehicle-to-infrastructure link quality, channel access, inter-nodal interference and node active time. The problem is solved through an iterative approach. \{FOSAA\} is compared to other proposed schemes. The performance results show that offloading fraction is significantly affected by the data volume, vehicle density and number of hops from the infrastructure to the downloader vehicles. "} 
}
@article{He20166,
title = {"Retrieval of aerosol size distribution using improved quantum-behaved particle swarm optimization on spectral extinction measurements "},
journal = {"Particuology "},
volume = {"28"},
number = {""},
pages = {"6 - 14"},
year = {"2016"},
note = {""},
issn = {"1674-2001"},
doi = {"https://doi.org/10.1016/j.partic.2014.12.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S1674200115001194"},
author = {"Zhenzong He and Hong Qi and Qin Chen and Liming Ruan"},
keywords = {"Quantum-behaved particle swarm optimization", "Aerosol", "Aerosol size distribution", "Inverse problem "},
abstract = {"Abstract An improved quantum-behaved particle swarm optimization (IQPSO) algorithm is employed to determine aerosol size distribution (ASD). The direct problem is solved using the anomalous diffraction approximation and Lambert–Beer's Law. Compared with the standard particle swarm optimization algorithm, the stochastic particle size optimization algorithm and the original QPSO, our \{IQPSO\} has faster convergence speed and higher accuracy within a smaller number of generations. Optimization parameters for the \{IQPSO\} were also evaluated; we recommend using four measurement wavelengths and 50 particles. Size distributions of various aerosol types were estimated using the \{IQPSO\} under dependent and independent models. Finally, experimental \{ASDs\} at different locations in Harbin were recovered using the IQPSO. All our results confirm that the \{IQPSO\} algorithm is an effective and reliable technique for estimating ASD. "} 
}
@article{Pinet201674,
title = {"Response retrieval and motor planning during typing "},
journal = {"Brain and Language "},
volume = {"159"},
number = {""},
pages = {"74 - 83"},
year = {"2016"},
note = {""},
issn = {"0093-934X"},
doi = {"https://doi.org/10.1016/j.bandl.2016.05.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0093934X15301802"},
author = {"Svetlana Pinet and Anne-Sophie Dubarry and F.-Xavier Alario"},
keywords = {"EEG", "Language production", "Serial order", "Picture-naming", "Sequential motor planning "},
abstract = {"Abstract Recent work in language production research suggests complex relationships between linguistic and motor processes. Typing is an interesting candidate for investigating further this issue. First, typing presumably relies on the same distributed left-lateralized brain network as handwriting and speech production. Second, typing has its own set of highly specific motor constraints, such as internal keystroke representations that hold information about both letter identity and spatial characteristics of the key to strike. The present study aims to further develop research on typed production, by targeting the dynamics between linguistic and motor neural networks. Specifically, we used a typed picture-naming task to examine the interplay between response retrieval and motor planning. To track processes associated with both linguistic processing and keystroke representation, we manipulated, respectively, the semantic context in which the target appeared and the side of the first keystrokes of the word. We recorded high-density electroencephalography (EEG) continuously from the presentation of a picture, to the typing of its name, and computed both event-related potentials (ERP) and beta-band power analyses. Non-parametric data-driven analysis revealed a clear pattern of response preparation over both hemispheres close to response time, in both the \{ERP\} and beta-band power modulations. This was preceded by a left-lateralized power decrease in the beta-band, presumably representing memory retrieval, and an early contrast in ERP, between left and right keystrokes’ preparation. We discuss these results in terms of a dynamic access approach for internal keystroke representations, and argue for an integrative rather than separatist view of linguistic and motor processes. "} 
}
@article{Chen20171,
title = {"Information authentication using sparse representation of double random phase encoding in fractional Fourier transform domain "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"136"},
number = {""},
pages = {"1 - 7"},
year = {"2017"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2017.02.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402617301353"},
author = {"Junxin Chen and Zhi-liang Zhu and Chong Fu and Li-bo Zhang and Yushu Zhang"},
keywords = {"Double random phase encoding", "Sparse representation", "Fractional Fourier transform", "Information authentication "},
abstract = {"Abstract This paper presents an information authentication scheme using sparse representation of double random phase encoding in fractional Fourier transform domain. Different from traditional cryptographic applications, only sparse version of the ciphertext is available at the receiver end. The decrypted image is unrecognizable and of no meaningful information of the plaintext, which can enhance the resistance against various attacks. The decrypted image can be authenticated using nonlinear optical correlation approach. Numerical simulations have been carried out, and the results prove the effectiveness and noise resistance of the proposed scheme. "} 
}
@article{Łapaj2016478,
title = {"Response by Dr. Lapaj to comment on Lapaj et al.: Retrieval analysis of titanium nitride (TiN) coated prosthetic femoral heads articulating with polyethylene "},
journal = {"Journal of the Mechanical Behavior of Biomedical Materials "},
volume = {"63"},
number = {""},
pages = {"478 - 481"},
year = {"2016"},
note = {""},
issn = {"1751-6161"},
doi = {"https://doi.org/10.1016/j.jmbbm.2016.04.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S175161611630090X"},
author = {"Łukasz Łapaj and Justyna Wendland and Jacek Markuszewski and Adrian Mróz and Tomasz Wiśniewski"} 

}
@article{Gugger2016575,
title = {"Retrieval analysis of lingual fixed retainer adhesives "},
journal = {"American Journal of Orthodontics and Dentofacial Orthopedics "},
volume = {"150"},
number = {"4"},
pages = {"575 - 584"},
year = {"2016"},
note = {""},
issn = {"0889-5406"},
doi = {"https://doi.org/10.1016/j.ajodo.2016.06.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S0889540616302906"},
author = {"Jonas Gugger and Nikolaos Pandis and Spiros Zinelis and Raphael Patcas and George Eliades and Theodore Eliades"},

abstract = {"Introduction Our objective was to analyze the surface and bulk properties alterations of clinically aged composites used for fixed retention. Methods Twenty-six lingual retainers bonded for different time periods (2.2-17.4 years) were retrieved from postorthodontic patients. Fifteen lingual retainers had been cemented by a chemically cured adhesive (Maximum Cure, Reliance Orthodontic Products, Itasca, Ill), and 11 were treated with a photo-cured adhesive (Flow-Tain, Reliance Orthodontic Products). The first group was in service for 2.8 to 17.4 years and the second for 2.2 to 5.4 years. Five specimens from each material were prepared and used as the control (or reference) group. The debonded surfaces from enamel were studied by attenuated total reflectance Fourier transform infrared spectroscopy (n = 3 per material per group), low-vacuum scanning electron microscopy, and energy dispersive x-ray microanalysis (n = 3 per material per group). All specimens were used for the assessment of Vickers hardness, indentation modulus, and elastic index with the instrumented indentation testing method. The values of Vickers hardness, indentation modulus, and elastic index were compared between the retrieved and the reference groups with 1-way analysis of variance and the Student-Newman-Keuls multiple comparison test (α = 0.05). Results The attenuated total reflectance Fourier transform infrared spectroscopy analysis showed that both retrieved composites demonstrated reduced unsaturation in comparison with the corresponding reference specimens. Some bonded surfaces showed development of organic integuments. All retrieved specimens showed reduced silicon content. Barium was identified only in the photo-cured group. No significant differences were found between the reference and retrieved groups in Vickers hardness, indentation modulus, and elastic index. Conclusions Despite the changes in composition, the mechanical properties of the materials tested remained unaffected by intraoral aging. "} 
}
@incollection{Baykoucheva201533,
title = {"5 - Finding and managing scientific information "},
editor = {"Baykoucheva, Svetla "},
booktitle = {"Managing Scientific Information and Research Data "},
publisher = {"Chandos Publishing"},
edition = {""},
address = {""},
year = {"2015"},
pages = {"33 - 41"},
isbn = {"978-0-08-100195-0"},
doi = {"https://doi.org/10.1016/B978-0-08-100195-0.00005-6"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780081001950000056"},
author = {"Svetla Baykoucheva"},
keywords = {"information retrieval", "databases", "National Library of Medicine (NLM)", "NCBI", "­PubMed", "PubChem", "SciFinder", "Scopus", "Web of Science", "ChemSpider", "MEDLINE", "Chemical Abstracts Service (CAS). "},
abstract = {"Abstract The new digital technologies and the Internet have changed how researchers gather and use scientific information. The processes of gathering information and managing it are integrated in researchers’ daily routine of working at the lab bench, writing papers, and discussing research findings. This chapter outlines some strategies for searching and filtering scientific information using the “smart” features and tools provided by database publishers. "} 
}
@article{Iansavichus201526,
title = {"High-Performance Information Search Filters for \{CKD\} Content in PubMed, Ovid MEDLINE, and \{EMBASE\} "},
journal = {"American Journal of Kidney Diseases "},
volume = {"65"},
number = {"1"},
pages = {"26 - 32"},
year = {"2015"},
note = {""},
issn = {"0272-6386"},
doi = {"https://doi.org/10.1053/j.ajkd.2014.06.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0272638614009640"},
author = {"Arthur V. Iansavichus and Ainslie M. Hildebrand and R. Brian Haynes and Nancy L. Wilczynski and Adeera Levin and Brenda R. Hemmelgarn and Karen Tu and Gihad E. Nesrallah and Danielle M. Nash and Amit X. Garg"},
keywords = {"Chronic kidney disease (CKD)", "health informatics", "information retrieval", "MEDLINE", "EMBASE", "bibliographic database", "search filter", "renal insufficiency "},
abstract = {"Background Finding relevant articles in large bibliographic databases such as PubMed, Ovid MEDLINE, and \{EMBASE\} to inform care and future research is challenging. Articles relevant to chronic kidney disease (CKD) are particularly difficult to find because they are often published under different terminology and are found across a wide range of journal types. Study Design We used computer automation within a diagnostic test assessment framework to develop and validate information search filters to identify \{CKD\} articles in large bibliographic databases. Setting &amp; Participants 22,992 full-text articles in PubMed, Ovid MEDLINE, or EMBASE. Index Test 1,374,148 unique search filters. Reference Test We established the reference standard of article relevance to \{CKD\} by manual review of all full-text articles using prespecified criteria to determine whether each article contained \{CKD\} content or not. We then assessed filter performance by calculating sensitivity, specificity, and positive predictive value for the retrieval of \{CKD\} articles. Filters with high sensitivity and specificity for the identification of \{CKD\} articles in the development phase (two-thirds of the sample) were then retested in the validation phase (remaining one-third of the sample). Results We developed and validated high-performance \{CKD\} search filters for each bibliographic database. Filters optimized for sensitivity reached at least 99% sensitivity, and filters optimized for specificity reached at least 97% specificity. The filters were complex; for example, one PubMed filter included more than 89 terms used in combination, including “chronic kidney disease,” “renal insufficiency,” and “renal fibrosis.” In proof-of-concept searches, physicians found more articles relevant to the topic of \{CKD\} with the use of these filters. Limitations As knowledge of the pathogenesis of \{CKD\} grows and definitions change, these filters will need to be updated to incorporate new terminology used to index relevant articles. Conclusions PubMed, Ovid MEDLINE, and \{EMBASE\} can be filtered reliably for articles relevant to CKD. These high-performance information filters are now available online and can be used to better identify \{CKD\} content in large bibliographic databases. "} 
}
@article{Yadav20169538,
title = {"A novel technique for automatic retrieval of embedded text from books "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"20"},
pages = {"9538 - 9550"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.05.122"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616305733"},
author = {"Niharika Yadav and Vinay Kumar"},
keywords = {"Scene text", "CC-based method", "Histogram clustering", "Morphological operations", "Text extraction "},
abstract = {"Abstract The current paper propounds a method for extracting text from images of book covers and embedded text. The automation of this process greatly reduces the human interference while converting books (specifically their covers where this task becomes extremely difficult) to readable and editable electronic format specifically for electronic book readers. To achieve this purpose we propose a technique which works on scanned images of documents. The image is first clustered to reduce the number of color variances, a suitable plane is identified and then text region is segmented using connected component based method. The text thus obtained is then enhanced to ameliorate the results. "} 
}
@article{Kim2016482,
title = {"Evaluation of chlorophyll retrievals from Geostationary Ocean Color Imager (GOCI) for the North-East Asian region "},
journal = {"Remote Sensing of Environment "},
volume = {"184"},
number = {""},
pages = {"482 - 495"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.07.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716302887"},
author = {"Wonkook Kim and Jeong-Eon Moon and Young-Je Park and Joji Ishizaka"},
keywords = {"Geostationary Ocean Color Imager", "GOCI", "Chlorophyll-a concentrations", "Ocean color", "Phytoplankton pigments", "Case-2", "Korea", "North-East Asia "},
abstract = {"Abstract Estimation of chlorophyll concentration in the marine biosphere has been the central topic of ocean color remote sensing since its advent. While various algorithms were proposed in the literature so far and tested for oceanic waters of diverse constituent composition, an independent algorithm evaluation is needed for local ocean waters that have dynamic variation in optically active water constituents such as colored dissolved organic matters (CDOM) and suspended particulate matter (SPM). This paper evaluates the performance of chlorophyll algorithms for Geostationary Ocean Color Imager (GOCI) radiometric data, using in situ measurements collected at 491 stations around Korea Peninsula during 2010–2014 from which there were 130 match-ups with \{GOCI\} data. For the evaluation in areas with high variation in SPM, water samples were first classified into three levels of SPM, and then the coefficients of candidate algorithms were newly derived for the turbidity cases using the in situ and \{GOCI\} remote sensing reflectance (Rrs) data. Functional forms of traditional band ratio algorithms (e.g. \{OC\} algorithms (O′Reilly et al., 1998) and Tassan's algorithm (Tassan, 1994)), fluorescence line height algorithm, and near-infrared-to-red band ratio approach were tested. The evaluation results for the coincident in situ pairs of Rrs and chlorophyll measurements showed that the mean uncertainty was &lt; 35% with the correlation around 0.8 by using the \{OC3\} with turbidity consideration (OCT) and Tassan's algorithm with turbidity dependent coefficients (Tassan-TD). For the \{GOCI\} match-ups, the mean uncertainty for all turbidity levels was around 35% with correlation around 0.65, when \{OCT\} and Tassan-TD were used. "} 
}
@article{Wang2016582,
title = {"An improved approach of total freeboard retrieval with IceBridge Airborne Topographic Mapper (ATM) elevation and Digital Mapping System (DMS) images "},
journal = {"Remote Sensing of Environment "},
volume = {"184"},
number = {""},
pages = {"582 - 594"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716303054"},
author = {"Xianwei Wang and Fang Guan and Junyuan Liu and Hongjie Xie and Stephen Ackley"},
keywords = {"Leads", "Sea Surface Height", "Total freeboard", "Sea ice thickness", "IceBridge "},
abstract = {"Abstract The existence and detection of leads are critical to obtain a local Sea Surface Height (SSH) reference for computing total freeboard and sea ice thickness from NASA's IceBridge Airborne Topographic Mapper (ATM) elevations. However, the shaded areas of the Digital Mapping System (DMS) images and the biased \{ATM\} elevations impact the correct determination of leads and SSH. This study develops an automated approach to overcome the above challenges and to correctly determine \{SSHs\} by combining \{DMS\} images, \{ATM\} L1B's apparent reflectivity and statistical discrimination. Dynamic pixel intensity thresholds are established to classify leads under different solar illuminations. This automated approach is then validated by manual selection in detecting SSHs. The high agreement of \{SSHs\} from this automated approach with those from manual selection indicates the reliability and usefulness of this approach. Within a 45-km section of one \{ATM\} \{L1B\} file, \{SSH\} demonstrates a linear gradient, which is applied to derive \{SSHs\} where there are no leads. The resulted \{SSHs\} are then used to compute total freeboard and ice thickness. This automated approach is also tried to retrieve \{SSH\} and then compute the total freeboard on one entire IceBridge sea ice flight each in Arctic and Antarctica. "} 
}
@article{Tajik20161,
title = {"Activation of the dorsal hippocampal nicotinic acetylcholine receptors improves tamoxifen-induced memory retrieval impairment in adult female rats "},
journal = {"Neuroscience "},
volume = {"327"},
number = {""},
pages = {"1 - 9"},
year = {"2016"},
note = {""},
issn = {"0306-4522"},
doi = {"https://doi.org/10.1016/j.neuroscience.2016.04.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645221630063X"},
author = {"Azam Tajik and Ameneh Rezayof and Zahra Ghasemzadeh and Maryam Sardari"},
keywords = {"tamoxifen", "nicotine", "mecamylamine", "dorsal hippocampus", "passive avoidance learning", "female rat(s) "},
abstract = {"Abstract Tamoxifen (TAM), a selective estrogen receptor modulator, has frequently been used in the treatment of breast cancer. In view of the fact that cognitive deficits in women who receive adjuvant chemotherapy for breast cancer is a common health problem, using female animal models for investigating the cognitive effects of \{TAM\} administration may improve our knowledge of \{TAM\} therapy. Therefore, the present study assessed the role of dorsal hippocampal cholinergic nicotinic receptors (nAChRs) in the effect of \{TAM\} administration on memory retrieval in ovariectomized (OVX) and non-OVX female rats using a passive avoidance learning task. Our results showed that pre-test administration of \{TAM\} (2–6 mg/kg) impaired memory retrieval. Pre-test intra-CA1 microinjection of nicotine (0.3–0.5 μg/rat) reversed TAM-induced memory impairment. Pre-test intra-CA1 microinjection of mecamylamine (0.1–0.3 μg/rat) plus 2 mg/kg (an ineffective dose) of \{TAM\} impaired memory retrieval. Pre-test intra-CA1 microinjection of the same doses of nicotine and mecamylamine by themselves had no effect on memory retrieval. In \{OVX\} rats, the administration of \{TAM\} (6 mg/kg) produced memory impairment but pre-test intra-CA1 microinjection of nicotine (0.5 μg/rat) had no effect on \{TAM\} response. Moreover, the administration of an ineffective dose of \{TAM\} (2 mg/kg) had no effect on memory retrieval in \{OVX\} rats, while pre-test intra-CA1 microinjection of mecamylamine (0.3 μg/rat) impaired memory retrieval. Taken together, it can be concluded that the impairing effect of \{TAM\} on memory formation may be modulated by nAChRs of the \{CA1\} regions. It seems that memory impairment may be considered as an important side effect of TAM. "} 
}
@article{Persson201640,
title = {"Disambiguating past events: Accurate source memory for time and context depends on different retrieval processes "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"132"},
number = {""},
pages = {"40 - 48"},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2016.05.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742716300569"},
author = {"Bjorn M. Persson and James A. Ainge and Akira R. O’Connor"},
keywords = {"Episodic memory", "Time", "Context", "Recollection", "Familiarity "},
abstract = {"Abstract Current animal models of episodic memory are usually based on demonstrating integrated memory for what happened, where it happened, and when an event took place. These models aim to capture the testable features of the definition of human episodic memory which stresses the temporal component of the memory as a unique piece of source information that allows us to disambiguate one memory from another. Recently though, it has been suggested that a more accurate model of human episodic memory would include contextual rather than temporal source information, as humans’ memory for time is relatively poor. Here, two experiments were carried out investigating human memory for temporal and contextual source information, along with the underlying dual process retrieval processes, using an immersive virtual environment paired with a ‘Remember-Know’ memory task. Experiment 1 (n = 28) showed that contextual information could only be retrieved accurately using recollection, while temporal information could be retrieved using either recollection or familiarity. Experiment 2 (n = 24), which used a more difficult task, resulting in reduced item recognition rates and therefore less potential for contamination by ceiling effects, replicated the pattern of results from Experiment 1. Dual process theory predicts that it should only be possible to retrieve source context from an event using recollection, and our results are consistent with this prediction. That temporal information can be retrieved using familiarity alone suggests that it may be incorrect to view temporal context as analogous to other typically used source contexts. This latter finding supports the alternative proposal that time since presentation may simply be reflected in the strength of memory trace at retrieval – a measure ideally suited to trace strength interrogation using familiarity, as is typically conceptualised within the dual process framework. "} 
}
@article{Yeari20171,
title = {"The role of working memory in inference generation during reading comprehension: Retention, (re)activation, or suppression of verbal information? "},
journal = {"Learning and Individual Differences "},
volume = {"56"},
number = {""},
pages = {"1 - 12"},
year = {"2017"},
note = {""},
issn = {"1041-6080"},
doi = {"https://doi.org/10.1016/j.lindif.2017.04.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1041608017300808"},
author = {"Menahem Yeari"},
keywords = {"Working memory", "Predictive and bridging inferences", "Information retention", "Information reactivation", "Information suppression", "Domain-general versus domain-specific "},
abstract = {"Abstract The present study explored the role of working memory (WM) in online activation of bridging and predictive inferences during reading comprehension. Using short narratives and a probe-naming procedure, five hypotheses were examined: Text retention, text reactivation, inference retention, inference activation, and text and inference suppression. In addition, three types of \{WM\} span tests—listening-, operation- and symmetry-span tests—were used to examine whether the role of \{WM\} in inference generation is domain-specific for discourse items, domain-specific for verbal items, or domain-general, respectively. Different patterns of results were observed for high- and low-span groups only when participants were divided based on the listening-span test. High-span participants generated predictive inferences faster than low-span participants, and then quickly inhibited them when they became less relevant in the following sentence. Moreover, high-span participants generated more bridging inferences than low-span participants, possibly due to enhanced retention and reactivation of inference-evoking textual information. These findings support the inference activation, inference inhibition, text retention, text reactivation, and discourse-domain-specific hypotheses of WM's role in inference generation. The unique contribution of this study to the field is discussed in relation to existing findings and theories of WM. "} 
}
@article{Abdulnabi2017230,
title = {"A distributed framework for health information exchange using smartphone technologies "},
journal = {"Journal of Biomedical Informatics "},
volume = {"69"},
number = {""},
pages = {"230 - 250"},
year = {"2017"},
note = {""},
issn = {"1532-0464"},
doi = {"https://doi.org/10.1016/j.jbi.2017.04.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S1532046417300837"},
author = {"Mohamed Abdulnabi and Ahmed Al-Haiqi and M.L.M. Kiah and A.A. Zaidan and B.B. Zaidan and Muzammil Hussain"},
keywords = {"Health information exchange HIE", "Bioinformatics", "NFC", "Mobile computing", "mPHR "},
abstract = {"Abstract Nationwide health information exchange (NHIE) continues to be a persistent concern for government agencies, despite the many efforts and the conceived benefits of sharing patient data among healthcare providers. Difficulties in ensuring global connectivity, interoperability, and concerns on security have always hampered the government from successfully deploying NHIE. By looking at \{NHIE\} from a fresh perspective and bearing in mind the pervasiveness and power of modern mobile platforms, this paper proposes a new approach to \{NHIE\} that builds on the notion of consumer-mediated HIE, albeit without the focus on central health record banks. With the growing acceptance of smartphones as reliable, indispensable, and most personal devices, we suggest to leverage the concept of mobile personal health records (PHRs installed on smartphones) to the next level. We envision mPHRs that take the form of distributed storage units for health information, under the full control and direct possession of patients, who can have ready access to their personal data whenever needed. However, for the actual exchange of data with health information systems managed by healthcare providers, the latter have to be interoperable with patient-carried mPHRs. Computer industry has long ago solved a similar problem of interoperability between peripheral devices and operating systems. We borrow from that solution the idea of providing special interfaces between mPHRs and provider systems. This interface enables the two entities to communicate with no change to either end. The design and operation of the proposed approach is explained. Additional pointers on potential implementations are provided, and issues that pertain to any solution to implement \{NHIE\} are discussed. "} 
}
@article{Sağlam2014104,
title = {"Automatic information timeliness assessment of diabetes web sites by evidence based medicine "},
journal = {"Computer Methods and Programs in Biomedicine "},
volume = {"117"},
number = {"2"},
pages = {"104 - 113"},
year = {"2014"},
note = {""},
issn = {"0169-2607"},
doi = {"https://doi.org/10.1016/j.cmpb.2014.07.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169260714003034"},
author = {"Rahime Belen Sağlam and Tuğba Taşkaya Temizel"},
keywords = {"Content-based retrieval", "Diabetes", "Medical information systems", "Timeliness analysis "},
abstract = {"Abstract Studies on health domain have shown that health websites provide imperfect information and give recommendations which are not up to date with the recent literature even when their last modified dates are quite recent. In this paper, we propose a framework which assesses the timeliness of the content of health websites automatically by evidence based medicine. Our aim is to assess the accordance of website contents with the current literature and information timeliness disregarding the update time stated on the websites. The proposed method is based on automatic term recognition, relevance feedback and information retrieval techniques in order to generate time-aware structured queries. We tested the framework on diabetes health web sites which were archived between 2006 and 2013 by Archive-it using American Diabetes Association's (ADA) guidelines. The results showed that the proposed framework achieves 65% and 77% accuracy in detecting the timeliness of the web content according to years and pre-determined time intervals respectively. Information seekers and web site owners may benefit from the proposed framework in finding relevant and up-to-date diabetes web sites. "} 
}
@article{Sakr2016522,
title = {"An efficient fast-response content-based image retrieval framework for big data "},
journal = {"Computers & Electrical Engineering "},
volume = {"54"},
number = {""},
pages = {"522 - 538"},
year = {"2016"},
note = {""},
issn = {"0045-7906"},
doi = {"https://doi.org/10.1016/j.compeleceng.2016.04.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0045790616300957"},
author = {"Noha A. Sakr and Ali.I. ELdesouky and Hesham Arafat"},
keywords = {"CBIR", "Feature Extraction", "BOVW", "Image indexing", "Hadoop", "MapReduce", "Clustering "},
abstract = {"Abstract In this paper, an efficient fast-response content-based image retrieval (CBIR) framework based on Hadoop MapReduce is proposed to operate stably with high performance targeting big data. It provides a novel bag of visual words (BOVW) technique based on a proposed chain-clustering binary search-tree (CC-BST) algorithm to build the visual statements for representing the image. As well, it introduces a proposed methodology for creating representatives for these visual statements as a solution for big-data' high-dimensionality. Further, those representatives are utilized to provide an indexing scheme for building one large file as an input for Hadoop. Moreover, an efficient-MapReduce technique is presented to exploit the created visual-representatives of the images to retrieve the top-relevant images for the input query. Empirical tests for the proposed techniques outperform the state-of-art compared techniques. "} 
}
@article{He2017670,
title = {"Mapping the managerial areas of Building Information Modeling (BIM) using scientometric analysis "},
journal = {"International Journal of Project Management "},
volume = {"35"},
number = {"4"},
pages = {"670 - 685"},
year = {"2017"},
note = {""},
issn = {"0263-7863"},
doi = {"https://doi.org/10.1016/j.ijproman.2016.08.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S026378631630062X"},
author = {"Qinghua He and Ge Wang and Lan Luo and Qian Shi and Jianxun Xie and Xianhai Meng"},
keywords = {"Construction project management", "Building Information Modeling (BIM)", "Scientometrics", "Literature analysis "},
abstract = {"Abstract The successful adoption of Building Information Modeling (BIM) leads to the subsequent need for improving management practices and stakeholders' relationships. Previous studies have attempted to explore solutions for non-technical issues; however, a systematic and quantitative review of the details of non-technical field, namely, the managerial areas of \{BIM\} (MA–BIM), seems to be missing. Hence, a scientometric approach is used to construct knowledge maps in MA–BIM, thereby allowing bibliometric data to provide an objective and accurate perspective in the field as a whole. Through keyword and abstract term analysis of 126 related papers published from 2007 to 2015, an integrated conceptual framework is proposed to summarize current status and structure future directions of MA–BIM based on five principal research areas. This study shows the transformation of MA–BIM from an individual approach to a wide-ranging organizational strategy. It provides new insights into managing \{BIM\} projects by referring to the accurate representation and analysis of previous research efforts. "} 
}
@article{Bulgin2016213,
title = {"Independent uncertainty estimates for coefficient based sea surface temperature retrieval from the Along-Track Scanning Radiometer instruments "},
journal = {"Remote Sensing of Environment "},
volume = {"178"},
number = {""},
pages = {"213 - 222"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.02.022"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716300505"},
author = {"C.E. Bulgin and O. Embury and G. Corlett and C.J. Merchant"},
keywords = {"Sea surface temperature", "Uncertainty budget", "Remote sensing", "Climate change initiative "},
abstract = {"Abstract We establish a methodology for calculating uncertainties in sea surface temperature estimates from coefficient based satellite retrievals. The uncertainty estimates are derived independently of in-situ data. This enables validation of both the retrieved \{SSTs\} and their uncertainty estimate using in-situ data records. The total uncertainty budget is comprised of a number of components, arising from uncorrelated (e.g. noise), locally systematic (e.g. atmospheric), large scale systematic and sampling effects (for gridded products). The importance of distinguishing these components arises in propagating uncertainty across spatio-temporal scales. We apply the method to \{SST\} data retrieved from the Advanced Along Track Scanning Radiometer (AATSR) and validate the results for two different \{SST\} retrieval algorithms, both at a per pixel level and for gridded data. We find good agreement between our estimated uncertainties and validation data. This approach to calculating uncertainties in \{SST\} retrievals has a wider application to data from other instruments and retrieval of other geophysical variables. "} 
}
@article{Ali20173,
title = {"Rule-guided human classification of Volunteered Geographic Information "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"127"},
number = {""},
pages = {"3 - 15"},
year = {"2017"},
note = {"Geospatial Week 2015 "},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2016.06.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271616301137"},
author = {"Ahmed Loai Ali and Zoe Falomir and Falko Schmid and Christian Freksa"},
keywords = {"Volunteered Geographic Information (VGI)", "Spatial data quality", "Spatial data mining", "Classification", "Topology", "Qualitative spatial reasoning "},
abstract = {"Abstract During the last decade, web technologies and location sensing devices have evolved generating a form of crowdsourcing known as Volunteered Geographic Information (VGI). \{VGI\} acted as a platform of spatial data collection, in particular, when a group of public participants are involved in collaborative mapping activities: they work together to collect, share, and use information about geographic features. \{VGI\} exploits participants’ local knowledge to produce rich data sources. However, the resulting data inherits problematic data classification. In \{VGI\} projects, the challenges of data classification are due to the following: (i) data is likely prone to subjective classification, (ii) remote contributions and flexible contribution mechanisms in most projects, and (iii) the uncertainty of spatial data and non-strict definitions of geographic features. These factors lead to various forms of problematic classification: inconsistent, incomplete, and imprecise data classification. This research addresses classification appropriateness. Whether the classification of an entity is appropriate or inappropriate is related to quantitative and/or qualitative observations. Small differences between observations may be not recognizable particularly for non-expert participants. Hence, in this paper, the problem is tackled by developing a rule-guided classification approach. This approach exploits data mining techniques of Association Classification (AC) to extract descriptive (qualitative) rules of specific geographic features. The rules are extracted based on the investigation of qualitative topological relations between target features and their context. Afterwards, the extracted rules are used to develop a recommendation system able to guide participants to the most appropriate classification. The approach proposes two scenarios to guide participants towards enhancing the quality of data classification. An empirical study is conducted to investigate the classification of grass-related features like forest, garden, park, and meadow. The findings of this study indicate the feasibility of the proposed approach. "} 
}
@article{Vittucci2016115,
title = {"\{SMOS\} retrieval over forests: Exploitation of optical depth and tests of soil moisture estimates "},
journal = {"Remote Sensing of Environment "},
volume = {"180"},
number = {""},
pages = {"115 - 127"},
year = {"2016"},
note = {"Special Issue: ESA's Soil Moisture and Ocean Salinity Mission - Achievements and Applications "},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716300979"},
author = {"C. Vittucci and P. Ferrazzoli and Y. Kerr and P. Richaume and L. Guerriero and R. Rahmoune and G. Vaglio Laurin"},

abstract = {"Abstract This research aims to test data obtained by level 2 retrieval algorithm of \{SMOS\} over land, in order to provide information regarding vegetation and soil moisture over forested areas. Results presented in this paper were obtained using the last 620 version of the algorithm. The correlation between the new vegetation optical depth (VOD) product and the height of the forest estimated by \{ICES\} at \{GLAS\} lidar on a global scale is investigated. Over South American and African forests a good correspondence between the two variables is observed, with saturation occurring above about 30 m height. Moreover, the comparison between the \{VOD\} and the height of the forest shows good spatial and temporal stability, and the r2 correlation coefficient is within a 0.59–0.69 range. Conversely, discrepancies are observed in some Indonesian islands, particularly New Guinea. Over specific areas, the trends vs. forest height obtained with \{SMOS\} \{VOD\} are compared with the corresponding trends of AMSR-E VOD. Results are also validated at country-level scale. To this aim, accurate estimates of forest biomass derived from airborne lidar over selected forests of Peru, Columbia and Panama are used. Finally, the soil moisture retrieved over forests is investigated, reporting continental maps for Tropical areas and comparisons with ground measurements in selected forests of the US. Continental maps obtained with the new level 2 \{V620\} algorithm cover almost all forest areas, and show seasonal variations which are dependent on climatic zones. Comparisons between soil moisture retrievals in forests and ground measurements of the \{US\} \{SCAN\} network produce worse \{RMSE\} values with respect to low vegetation areas. Significant improvements however are achieved after averaging among close nodes of the ground network. "} 
}
@article{Pajić2014145,
title = {"Browse to search, visualize to explore: Who needs an alternative information retrieving model? "},
journal = {"Computers in Human Behavior "},
volume = {"39"},
number = {""},
pages = {"145 - 153"},
year = {"2014"},
note = {""},
issn = {"0747-5632"},
doi = {"https://doi.org/10.1016/j.chb.2014.07.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0747563214003768"},
author = {"Dejan Pajić"},
keywords = {"Information retrieval", "Information visualization", "Visual search", "Bibliographic databases", "Usability", "User satisfaction "},
abstract = {"Abstract This article presents the results of the evaluation of \{SCIViS\} – a visualization-based scientific information retrieval (IR) system. \{SCIViS\} is based on the logic of concept maps and enables the visualization of relationships among descriptors and authors of scientific papers. It creates an interactive interface between the user’s cognitive space and document information space. The system was evaluated by the group of 138 psychology students which have performed a variety of search tasks, using both the classic text-based and the visualization based \{IR\} systems. The \{SCIViS\} model has proved to be effective and intuitive. Participants were more efficient using the visual \{IR\} system, particularly when performing tasks requiring modifications of the initial query and finding alternative keywords. User responses indicated that system’s speed and ease of use are the most important attributes of the overall assessment. They also revealed the impact of users’ previous experience with \{IR\} systems on users’ satisfaction and perception of usefulness. Previous experience may be regarded both as the rate of success in performing search tasks, as well as the familiarity with popular search engines. The later one seems to be an important factor in modeling users’ information seeking behavior and their attitudes toward alternative \{IR\} models. "} 
}
@article{Rizvi20161,
title = {"A comparative observational study of inpatient clinical note-entry and reading/retrieval styles adopted by physicians "},
journal = {"International Journal of Medical Informatics "},
volume = {"90"},
number = {""},
pages = {"1 - 11"},
year = {"2016"},
note = {""},
issn = {"1386-5056"},
doi = {"https://doi.org/10.1016/j.ijmedinf.2016.02.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S1386505616300314"},
author = {"Rubina F. Rizvi and Kathleen A. Harder and Gretchen M. Hultman and Terrence J. Adam and Michael Kim and Serguei V.S. Pakhomov and Genevieve B. Melton"},
keywords = {"Electronic health records systems (EHR)", "Clinical documentation", "Qualitative analysis", "Human-Computer Interaction (HCI)", "Graphical User Interface (GUI)", "Usability "},
abstract = {"AbstractObjective The objective of this study is to understand physicians’ usage of inpatient notes by (i) ascertaining different clinical note-entry and reading/retrieval styles in two different and widely used Electronic Health Record (EHR) systems, (ii) extrapolating potential factors leading to adoption of various note-entry and reading/retrieval styles and (iii) determining the amount of time to task associated with documenting different types of clinical notes. Methods In order to answer “what” and “why” questions on physicians’ adoption of certain-note-entry and reading/retrieval styles, an ethnographic study entailing Internal Medicine residents, with a mixed data analysis approach was performed. Participants were observed interacting with two different \{EHR\} systems in inpatient settings. Data was collected around the use and creation of History and Physical (H&amp;P) notes, progress notes and discharge summaries. Results The highest variability in template styles was observed with progress notes and the least variability was within discharge summaries, while note-writing styles were most consistent for H&amp;P notes. The first sections to be read in a H&amp;P and progress note were the Chief Complaint and Assessment &amp; Plan sections, respectively. The greatest note retrieval variability, with respect to the order of how note sections were reviewed, was observed with H&amp;P and progress notes. Physician preference for adopting a certain reading/retrieval order appeared to be a function of what best fits their workflow while fulfilling the stimulus demands. The time spent entering H&amp;P, discharge summaries and progress notes were similar in both EHRs. Conclusion This research study unveils existing variability in clinical documentation processes and provides us with important information that could help in designing a next generation \{EHR\} Graphical User Interface (GUI) that is more congruent with physicians’ mental models, task performance needs, and workflow requirements. "} 
}
@article{Sani20161909,
title = {"Seventy-two-hour antibiotic retrieval from the ED: reporting the strength of association "},
journal = {"The American Journal of Emergency Medicine "},
volume = {"34"},
number = {"9"},
pages = {"1909 - 1910"},
year = {"2016"},
note = {""},
issn = {"0735-6757"},
doi = {"https://doi.org/10.1016/j.ajem.2016.07.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0735675716304120"},
author = {"Mohadeseh Sani and Erfan Ayubi and Kamyar Mansori and Salman Khazaei"} 

}
@article{Olives2016999,
title = {"Seventy-two-hour antibiotic retrieval from the ED: a randomized controlled trial of discharge instructional modality "},
journal = {"The American Journal of Emergency Medicine "},
volume = {"34"},
number = {"6"},
pages = {"999 - 1005"},
year = {"2016"},
note = {""},
issn = {"0735-6757"},
doi = {"https://doi.org/10.1016/j.ajem.2016.02.046"},
url = {"http://www.sciencedirect.com/science/article/pii/S0735675716001261"},
author = {"Travis D. Olives and Roma G. Patel and Hannah M. Thompson and Scott Joing and James R. Miner"},

abstract = {"AbstractBackground Limited health literacy is a risk factor for poor outcomes in numerous health care settings. Little is known about the impact of instructional modality and health literacy on adherence to emergency department (ED) discharge instructions. Purpose To examine the impact of instructional modality on 72-hour antibiotic retrieval among \{ED\} patients prescribed outpatient antibiotics for infections. Methods English-speaking \{ED\} patients diagnosed as having acute infections and prescribed outpatient antibiotics were randomized to standard discharge instructions, standard instructions plus text-messaged instructions, or standard instructions plus voicemailed instructions targeting \{ED\} prescriptions. Health literacy was determined by validated instrument. Seventy-two-hour antibiotic retrieval, 30-day report of prescription completion, and discharge instructional modality preference were assessed. Results Nearly one-quarter of the 2521 participants demonstrated low health literacy. Low health literacy predicted decreased 72-hour antibiotic retrieval (χ2 = 9.56, P = .008). No significant association with antibiotic retrieval was noted across the 3 treatment groups (χ2 = 5.112, P = .078). However, patients randomized to the text message group retrieved antibiotic prescriptions within 72 hours more frequently than did those randomized to the voicemail treatment group (χ2 = 4.345, P = .037), and patients with low health literacy randomized to voicemailed instructions retrieved their antibiotic prescriptions less frequently than did those randomized to standard of care instructions (χ2 = 5.526, P = .019). Reported instructional modality preferences were inconsistent with the primary findings of the study. Conclusions Discharge instructional modality impacts antibiotic retrieval in patients with low health literacy. Preference for discharge instructional modality varies by degree of health literacy, but does not predict which modality will optimize 72-hour antibiotic retrieval. "} 
}
@article{van Dongen20161722,
title = {"Physical Exercise Performed Four Hours after Learning Improves Memory Retention and Increases Hippocampal Pattern Similarity during Retrieval "},
journal = {"Current Biology "},
volume = {"26"},
number = {"13"},
pages = {"1722 - 1727"},
year = {"2016"},
note = {""},
issn = {"0960-9822"},
doi = {"https://doi.org/10.1016/j.cub.2016.04.071"},
url = {"http://www.sciencedirect.com/science/article/pii/S0960982216304651"},
author = {"Eelco V. van Dongen and Ingrid H.P. Kersten and Isabella C. Wagner and Richard G.M. Morris and Guillén Fernández"},

abstract = {"Summary Persistent long-term memory depends on successful stabilization and integration of new memories after initial encoding [1, 2]. This consolidation process is thought to require neuromodulatory factors such as dopamine, noradrenaline, and brain-derived neurotrophic factor [3–7]. Without the release of such factors around the time of encoding, memories will decay rapidly [3, 5, 6, 8]. Recent studies have shown that physical exercise acutely stimulates the release of several consolidation-promoting factors in humans [9–14], raising the question of whether physical exercise can be used to improve memory retention [15–17]. Here, we used a single session of physical exercise after learning to exogenously boost memory consolidation and thus long-term memory. Three groups of randomly assigned participants first encoded a set of picture-location associations. Afterward, one group performed exercise immediately, one 4 hr later, and the third did not perform any exercise. Participants otherwise underwent exactly the same procedures to control for potential experimental confounds. Forty-eight hours later, participants returned for a cued-recall test in a magnetic resonance scanner. With this design, we could investigate the impact of acute exercise on memory consolidation and retrieval-related neural processing. We found that performing exercise 4 hr, but not immediately, after encoding improved the retention of picture-location associations compared to the no-exercise control group. Moreover, performing exercise after a delay was associated with increased hippocampal pattern similarity for correct responses during delayed retrieval. Our results suggest that appropriately timed physical exercise can improve long-term memory and highlight the potential of exercise as an intervention in educational and clinical settings. "} 
}
@article{Chang201629,
title = {"Integrating a semantic-based retrieval agent into case-based reasoning systems: A case study of an online bookstore "},
journal = {"Computers in Industry "},
volume = {"78"},
number = {""},
pages = {"29 - 42"},
year = {"2016"},
note = {"Natural Language Processing and Text Analytics in Industry "},
issn = {"0166-3615"},
doi = {"https://doi.org/10.1016/j.compind.2015.10.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166361515300531"},
author = {"Jia Wei Chang and Ming Che Lee and Tzone I Wang"},
keywords = {"Short-text semantic similarity", "Case-based reasoning", "Case-based machine learning "},
abstract = {"Abstract Natural language search engines should be developed to provide a friendly environment for business-to-consumer e-commerce that reduce the fatigue customers experience and help them decide what to buy. To support product information retrieval and reuse, this paper presents a novel framework for a case-based reasoning system that includes a collaborative filtering mechanism and a semantic-based case retrieval agent. Furthermore, the case retrieval agent integrates short-text semantic similarity (STSS) and recognizing textual entailment (RTE). The proposed approach was evaluated using competitive methods in the performance of \{STSS\} and RTE, and according to the results, the proposed approach outperforms most previously described approaches. Finally, the effectiveness of the proposed approach was investigated using a case study of an online bookstore, and according to the results of case study, the proposed approach outperforms a compared system using string similarity and an existing e-commerce system, Amazon. "} 
}
@article{Stiers201611,
title = {"Reverse inference of memory retrieval processes underlying metacognitive monitoring of learning using multivariate pattern analysis "},
journal = {"NeuroImage "},
volume = {"132"},
number = {""},
pages = {"11 - 23"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.02.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916001154"},
author = {"Peter Stiers and Luciana Falbo and Alexandros Goulas and Tamara van Gog and Anique de Bruin"},
keywords = {"Working memory", "Judgement of learning", "Metacognition", "Functional MRI", "Educational psychology "},
abstract = {"Abstract Monitoring of learning is only accurate at some time after learning. It is thought that immediate monitoring is based on working memory, whereas later monitoring requires re-activation of stored items, yielding accurate judgements. Such interpretations are difficult to test because they require reverse inference, which presupposes specificity of brain activity for the hidden cognitive processes. We investigated whether multivariate pattern classification can provide this specificity. We used a word recall task to create single trial examples of immediate and long term retrieval and trained a learning algorithm to discriminate them. Next, participants performed a similar task involving monitoring instead of recall. The recall-trained classifier recognized the retrieval patterns underlying immediate and long term monitoring and classified delayed monitoring examples as long-term retrieval. This result demonstrates the feasibility of decoding cognitive processes, instead of their content. "} 
}
@article{SastreIII201642,
title = {"Age- and performance-related differences in hippocampal contributions to episodic retrieval "},
journal = {"Developmental Cognitive Neuroscience "},
volume = {"19"},
number = {""},
pages = {"42 - 50"},
year = {"2016"},
note = {""},
issn = {"1878-9293"},
doi = {"https://doi.org/10.1016/j.dcn.2016.01.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1878929316000128"},
author = {"Marcos Sastre III and Carter Wendelken and Joshua K. Lee and Silvia A. Bunge and Simona Ghetti"},
keywords = {"Episodic memory", "Childhood", "Development", "Hippocampus", "Head", "Individual-differences "},
abstract = {"Abstract The goal of the present study was to investigate whether hippocampal contribution to episodic memory retrieval varies as a function of age (8–9 versus 10–11 versus adults), performance levels (high versus low) and hippocampal sub-region (head, body, tail). We examined fMRI data collected during episodic retrieval from a large sample (N = 126). Participants judged whether a stimulus had been encoded previously, and, if so, which of three scenes it had been paired with (i.e., source judgment). For 8- to 9-years-olds as well as low-performing 10- to 11-year-olds, hippocampal activations did not reliably differentiate between trials on which item-scene associations were correctly recalled (correct source), incorrectly recalled (incorrect source), or trials on which the item was forgotten (miss trials). For high-performing 10–11-year olds and low-performing adults, selective hippocampal activation was observed for correct source relative to incorrect source and miss trials; this effect was observed across the entire hippocampus. For high-performing adults, hippocampal activation also distinguished between correct and incorrect source trialsl, but only in the hippocampal head, suggesting that good performance in adults is associated with more focal hippocampal recruitment. Thus, both age and performance are important factors for understanding the development of memory and hippocampal function. "} 
}
@article{Piles2016403,
title = {"Towards improved spatio-temporal resolution soil moisture retrievals from the synergy of \{SMOS\} and \{MSG\} \{SEVIRI\} spaceborne observations "},
journal = {"Remote Sensing of Environment "},
volume = {"180"},
number = {""},
pages = {"403 - 417"},
year = {"2016"},
note = {"Special Issue: ESA's Soil Moisture and Ocean Salinity Mission - Achievements and Applications "},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.02.048"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716300761"},
author = {"María Piles and George P. Petropoulos and Nilda Sánchez and Ángel González-Zamora and Gareth Ireland"},
keywords = {"Soil moisture", "SMOS", "MSG SEVIRI", "Synergy", "Downscaling", "Temporal resolution", "Spatial resolution "},
abstract = {"Abstract Earth Observation (EO) technology is today at a maturity level that allows deriving operational estimates of Surface Soil Moisture (SSM) from a variety of sensors; yet, such products are provided at present at a coarse spatial and/or temporal resolution, which restricts their use in local or regional scale studies and practical applications. Herein, a methodology to derive \{SSM\} estimates from space at previously unattained spatio-temporal resolutions is proposed. The method is based on a variant of the “triangle” inversion technique leveraging on the strengths and synergies of \{SMOS\} (Soil Moisture and Ocean Salinity mission) microwave observations and geostationary optical/infrared data. The \{SSM\} retrieval technique allows for: i) enhancing the spatial resolution of \{SMOS\} \{SSM\} product estimates to 3 km spatial resolution, and, ii) providing a temporal average daytime \{SM\} product from the instantaneous fine-scale \{SSM\} estimates acquired every 15 min; the latter is allowing higher coverage in presence of clouds and representativeness (up to 96 estimates per day) in comparison to the instantaneous estimate at the time of satellite overpass. The proposed technique has been implemented to \{SMOS\} and \{MSG\} (Meteosat Second Generation) \{SEVIRI\} (Spinning Enhanced Visible and Infrared Imager) observations acquired over the Iberian Peninsula and Southern France during year 2011. \{SSM\} instantaneous estimates at the time of \{SMOS\} overpass and daytime-averaged \{SSM\} estimates have been obtained and evaluated separately against collocated in-situ measurements acquired from a total of 40 stations belonging to the REMEDHUS, \{VAS\} and \{SMOSMANIA\} permanent soil moisture measurement networks. Statistical agreement between compared datasets has been evaluated both at individual stations and considering the network average on the basis of several statistical terms computed including correlation, bias, root-mean-squared errors, slope and intercept of linear regression. Results showed that the proposed method not only preserves the quality of \{SMOS\} \{SSM\} at finer spatial scales, but also allows achieving higher temporal coverage and representativeness in daytime averages. The synergy of \{SMOS\} and \{SEVIRI\} provides a pathway to enhance water cycle \{EO\} capabilities taking full advantage of the new observational records of \{SSM\} and operational geostationary information. "} 
}
@article{Serafim2016127,
title = {"Intra-amygdala microinjections of chlorpheniramine impair memory formation or memory retrieval in anxiety- and fear-mediated models "},
journal = {"Brain Research Bulletin "},
volume = {"125"},
number = {""},
pages = {"127 - 133"},
year = {"2016"},
note = {""},
issn = {"0361-9230"},
doi = {"https://doi.org/10.1016/j.brainresbull.2016.06.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0361923016301307"},
author = {"K.R. Serafim and P.S.T. Russo and C.E.M. Fernandes and A.C.L. Gianlorenço and R. Mattioli"},
keywords = {"Emotional memory", "Amygdala", "Elevated plus maze", "Inhibitory avoidance task "},
abstract = {"Abstract \{H1\} receptor histaminergic antagonist, chlorpheniramine (CPA) participates in cognitive performance in various animal models. However, little is known regarding the effects of \{CPA\} microinjection into the amygdala on emotional behavior. The purpose of this study was to investigate whether \{CPA\} microinjection into the amygdala has the same effect on two models, one anxiety- and the other fear-mediated, in various memory stages using the elevated plus maze (EPM) and the inhibitory avoidance task (IAT) tests. Two experiments were performed with seventy-two adult male Swiss mice. Behavioral testing was performed on two consecutive days, and in both experiments, before each trial, the animals received bilateral microinjections of saline (SAL) or \{CPA\} (0.16 nmol). The animals were re-exposed to the \{EPM\} or \{IAT\} 24 h after the first trial. Four experimental groups were tested: SAL-SAL, SAL-CPA, CPA-SAL and CPA-CPA. In experiment 1, a decreased open arm exploration (% open arm entries, %OAE and% open arms time, %OAT) for SAL-SAL and SAL-CPA was showed, while these measures did not decrease for the CPA-SAL and CPA-CPA groups in Trial 2. In experiment 2, an increase of retention latency in relation to training 2 for the groups SAL-SAL and CPA-SAL and a significant decrease in latency for the group SAL-CPA was revealed. These results indicate that chlorpheniramine microinjection into the amygdala impairs emotional memory acquisition and/or consolidation in the \{EPM\} and retrieval of IAT. "} 
}
@article{Wang2016740,
title = {"Impact of Physician Education and a Dedicated Inferior Vena Cava Filter Tracking System on Inferior Vena Cava Filter Use and Retrieval Rates Across a Large \{US\} Health Care Region "},
journal = {"Journal of Vascular and Interventional Radiology "},
volume = {"27"},
number = {"5"},
pages = {"740 - 748"},
year = {"2016"},
note = {""},
issn = {"1051-0443"},
doi = {"https://doi.org/10.1016/j.jvir.2016.01.130"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051044316001366"},
author = {"Stephen L. Wang and Hsien-Hwa A. Cha and James R. Lin and Bolanos and Francis and Wakley and Elizabeth and Porras and Martin and Sudhir Rajan"},

abstract = {"AbstractPurpose To evaluate the effects of physician familiarity with current evidence and guidelines on inferior vena cava (IVC) filter use and the availability of \{IVC\} filter tracking infrastructure on retrieval rates. Materials and Methods Fourteen continuing medical education–approved in-hospital grand rounds covering evidence-based review of the literature on \{IVC\} filter efficacy, patient-centered outcomes, guidelines for \{IVC\} filter indications, and complications were performed across a large United States (US) health care region serving more than 3.5 million members. A computer-based \{IVC\} filter tracking system was deployed simultaneously. \{IVC\} filter use, rates of attempted retrieval, and fulfillment of guidelines for \{IVC\} filter indications were retrospectively evaluated at each facility for 12 months before intervention (n = 427) and for 12 months after intervention (n = 347). Results After education, \{IVC\} filter use decreased 18.7%, with a member enrollment–adjusted decrease of 22.2%, despite an increasing \{IVC\} filter use trend for 4 years. Reduction in \{IVC\} filter use at each facility strongly correlated with physician attendance at grand rounds (r = −0.69; P = .007). Rates of attempted retrieval increased from 38.9% to 54.0% (P = .0006), with similar rates of successful retrieval (82.3% before education and 85.8% after education on first attempt). Improvement in \{IVC\} filter retrieval attempts correlated with physician attendance at grand rounds (r = 0.51; P = .051). \{IVC\} filter dwell times at first retrieval attempt were similar (10.2 wk before and 10.8 wk after). Conclusions Physician education dramatically reduced \{IVC\} filter use across a large \{US\} health care region, and represents a learning opportunity for physicians who request and place them. Education and a novel tracking system improved rates of retrieval for \{IVC\} filter devices. "} 
}
@article{Niskanen20165562,
title = {"Refractive index retrieval from transmittance measurements "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"14"},
pages = {"5562 - 5567"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2016.03.073"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402616302534"},
author = {"Ilpo Niskanen and Matti Härkönen and Kenichi Hibino and Terhi Suoranta and Alexey Popov"},
keywords = {"Calcium fluoride", "Refractive index", "Concentration", "Wavelength-matching method "},
abstract = {"Abstract This study focuses on the development of an analytical method for simultaneous retrieval of the refractive index and the concentration of particles by measuring suspensions in industrial applications. The proposed method is based on the wavelength-matching method, where the idea is to find the maximum value of light transmittance of the suspension by scanning the irradiation wavelength. The samples were calcium fluoride (CaF2) powders manufactured by different global producers. The wavelength-matching method is suggested to be a relatively easy, economic and fast modality to retrieve the refractive index of particles. The wavelength-matching method is also considered to be independent on particle size and morphology. The refractive index is of high importance, for instance, if the opacity of products, such as paper or sunscreens, is sought to be increased for product quality improvement. "} 
}
@article{Borlund2014493,
title = {"An investigation of the search behaviour associated with Ingwersen’s three types of information needs "},
journal = {"Information Processing & Management "},
volume = {"50"},
number = {"4"},
pages = {"493 - 507"},
year = {"2014"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2014.03.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S030645731400017X"},
author = {"Pia Borlund and Sabine Dreier"},
keywords = {"Information needs", "User study", "Interactive information retrieval", "Internet searching", "Ordinary users", "Everyday-life information seeking "},
abstract = {"Abstract We report a naturalistic interactive information retrieval (IIR) study of 18 ordinary users in the age of 20–25 who carry out everyday-life information seeking (ELIS) on the Internet with respect to the three types of information needs identified by Ingwersen (1986): the verificative information need (VIN), the conscious topical information need (CIN), and the muddled topical information need (MIN). The searches took place in the private homes of the users in order to ensure as realistic searching as possible. Ingwersen (1996) associates a given search behaviour to each of the three types of information needs, which are analytically deduced, but not yet empirically tested. Thus the objective of the study is to investigate whether empirical data does, or does not, conform to the predictions derived from the three types of information needs. The main conclusion is that the analytically deduced information search behaviour characteristics by Ingwersen are positively corroborated for this group of test participants who search the Internet as part of ELIS. "} 
}
@article{Santi201661,
title = {"Application of artificial neural networks for the soil moisture retrieval from active and passive microwave spaceborne sensors "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"48"},
number = {""},
pages = {"61 - 73"},
year = {"2016"},
note = {"Advances in the Validation and Application of Remotely Sensed Soil Moisture - Part 2 "},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2015.08.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243415300143"},
author = {"Emanuele Santi and Simonetta Paloscia and Simone Pettinato and Giacomo Fontanelli"},
keywords = {"Artificial neural networks", "Soil moisture content", "Synthetic Aperture Radar (SAR)", "Scatterometer", "Microwave radiometers "},
abstract = {"Abstract Among the algorithms used for the retrieval of \{SMC\} from microwave sensors (both active, such as Synthetic Aperture Radar-SAR, and passive, radiometers), the artificial neural networks (ANN) represent the best compromise between accuracy and computation speed. \{ANN\} based algorithms have been developed at IFAC, and adapted to several radar and radiometric satellite sensors, in order to generate \{SMC\} products at a resolution varying from hundreds of meters to tens of kilometers according to the spatial scale of each sensor. These algorithms, which are based on the \{ANN\} techniques for inverting theoretical and semi-empirical models, have been adapted to the C- to Ka- band acquisitions from spaceborne radiometers (AMSR-E/AMSR2), \{SAR\} (Envisat/ASAR, Cosmo-SkyMed) and real aperture radar (MetOP ASCAT). Large datasets of co-located satellite acquisitions and direct \{SMC\} measurements on several test sites worldwide have been used along with simulations derived from forward electromagnetic models for setting up, training and validating these algorithms. An overall quality assessment of the obtained results in terms of accuracy and computational cost was carried out, and the main advantages and limitations for an operational use of these algorithms were evaluated. This technique allowed the retrieval of \{SMC\} from both active and passive satellite systems, with accuracy values of about 0.05 m3/m3 of \{SMC\} or better, thus making these applications compliant with the usual accuracy requirements for \{SMC\} products from space. "} 
}
@article{Myers2017,
title = {"Prioritizing Information during Working Memory: Beyond Sustained Internal Attention "},
journal = {"Trends in Cognitive Sciences "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1364-6613"},
doi = {"https://doi.org/10.1016/j.tics.2017.03.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S1364661317300530"},
author = {"Nicholas E. Myers and Mark G. Stokes and Anna C. Nobre"},
keywords = {"working memory", "attention", "focus of attention", "retrocue", "task set", "latent information storage "},
abstract = {"Working memory (WM) has limited capacity. This leaves attention with the important role of allowing into storage only the most relevant information. It is increasingly evident that attention is equally crucial for prioritizing representations within \{WM\} as the importance of individual items changes. Retrospective prioritization has been proposed to result from a focus of internal attention highlighting one of several representations. Here, we suggest an updated model, in which prioritization acts in multiple steps: first orienting towards and selecting a memory, and then reconfiguring its representational state in the service of upcoming task demands. Reconfiguration sets up an optimized perception–action mapping, obviating the need for sustained attention. This view is consistent with recent literature, makes testable predictions, and links \{WM\} with task switching and action preparation. "} 
}
@article{Guo2016121,
title = {"Early assessment of Integrated Multi-satellite Retrievals for Global Precipitation Measurement over China "},
journal = {"Atmospheric Research "},
volume = {"176–177"},
number = {""},
pages = {"121 - 133"},
year = {"2016"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2016.02.020"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809516300370"},
author = {"Hao Guo and Sheng Chen and Anming Bao and Ali Behrangi and Yang Hong and Felix Ndayisaba and Junjun Hu and Phillip M. Stepanian"},
keywords = {"Global Precipitation Measurement", "Remote sensing", "Satellite", "Precipitation "},
abstract = {"Abstract Two post-real time precipitation products from the Integrated Multi-satellite Retrievals for Global Precipitation Measurement Mission (IMERG) are systematically evaluated over China with China daily Precipitation Analysis Product (CPAP) as reference. The \{IMERG\} products include the gauge-corrected \{IMERG\} product (IMERG_Cal) and the version of \{IMERG\} without direct gauge correction (IMERG_Uncal). The post-research \{TRMM\} Multisatellite Precipitation Analysis version 7 (TMPA-3B42V7) is also evaluated concurrently with \{IMERG\} for better perspective. In order to be consistent with CPAP, the evaluation and comparison of selected products are performed at 0.25° and daily resolutions from 12 March 2014 through 28 February 2015. The results show that: Both \{IMERG\} and 3B42V7 show similar performances. Compared to IMERG_Uncal, IMERG_Cal shows significant improvement in overall and conditional bias and in the correlation coefficient. Both IMERG_Cal and IMERG_Uncal perform relatively poor in winter and over-detect slight precipitation events in northwestern China. As an early validation of the GPM-era \{IMERG\} products that inherit the TRMM-era global satellite precipitation products, these findings will provide useful feedbacks and insights for algorithm developers and data users over China and beyond. "} 
}
@article{Sehgal2016107,
title = {"Inversion of radiative transfer model for retrieval of wheat biophysical parameters from broadband reflectance measurements "},
journal = {"Information Processing in Agriculture "},
volume = {"3"},
number = {"2"},
pages = {"107 - 118"},
year = {"2016"},
note = {""},
issn = {"2214-3173"},
doi = {"https://doi.org/10.1016/j.inpa.2016.04.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S2214317316300075"},
author = {"Vinay Kumar Sehgal and Debasish Chakraborty and Rabi Narayan Sahoo"},
keywords = {"PROSAIL", "Look up table", "Neural network", "Leaf area index", "Chlorophyll content", "Target diagram", "IRS LISS-3 "},
abstract = {"Abstract This study describes the retrieval of wheat biophysical variables of leaf chlorophyll (Cab), leaf area index (LAI), canopy chlorophyll (CCC), and leaf wetness (Cw) from broadband reflectance data corresponding to \{IRS\} LISS-3 (Linear Imaging Self Scanner) sensor by inversion of \{PROSAIL5B\} canopy radiative transfer model. Reflectance data of wheat crop, grown under different treatments, were measured by hand-held spectroradiometer and later integrated to LISS-3 reflectance using its band-wise relative spectral response function. Three inversion techniques were used and their performance was compared using different statistical parameters and target diagram. The inversion techniques tried were: a look up table with best solution (LUT-I), a look up table with mean of best 10% solutions (LUT-II) and an artificial neural network (ANN). All the techniques could estimate the biophysical variables by capturing variability in their observed values, though accuracy of estimation varied among the three techniques. Target diagram clearly depicted the superiority of LUT-II over the other two approaches indicating that a mean of best 10% solutions is a better strategy while \{ANN\} was worst performer showing highest bias for all the parameters. In all the three inversion techniques, the general order of retrieval accuracy was \{LAI\} &gt; Cab &gt; \{CCC\} &gt; Cw. The range of Cw was very narrow and none of the techniques could estimate variations in it. In most of the cases, the parameters were underestimated by model inversion. The best identified LUT-II technique was then applied to retrieve wheat \{LAI\} from \{IRS\} LISS-3 satellite image of 5-Feb-2012 in Sheopur district. The comparison with ground observations showed that the \{RMSE\} of \{LAI\} retrieval was about 0.56, similar to that observed in ground experimentation. The findings of this study may help in refining the protocol for generating operational crop biophysical products from \{IRS\} LISS-3 or similar sensors. "} 
}
@article{Waiyahong201426,
title = {"Technical Standards for Accessing Information in the 21st Century: Z39.50 to Web Gateways "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"147"},
number = {""},
pages = {"26 - 31"},
year = {"2014"},
note = {"3rd International Conference on Integrated Information (IC-ININFO) "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2014.07.095"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877042814039998"},
author = {"Natita Waiyahong and Enukondar Rama Reddy"},
keywords = {"Technical standards", "Z39.50", "Web gateways", "Information Retrieval "},
abstract = {"Abstract Libraries have large stake in search protocols because library systems are diverse yet library users need to access multiple sites without learning the search syntax of each site. The purpose of this project is to combine the power of Z39.50 protocol for search and retrieval from heterogeneous systems with the ease of use provided by the Web. The web gateways usually have to make compromise when interfacing Z39.50 protocol. This project reviews and compares the relative advantages of Z39.50 to Web Gateways and several of the newest search protocols and query languages: Search via \{URL\} (SRU), OpenSearch, Contextual Query Language (CQL), and XQuery. The models for \{SRU\} and OpenSearch operations are described in order to explain differences in functionality − keyword search and simple data record return for OpenSearch and richer search with multiple format data return for SRU. The advantages of \{CQL\} are described along with possible complementary uses of the highly detailed and complex \{XQuery\} being developed for XML. "} 
}
@article{He20161,
title = {"A parameterization scheme of aerosol vertical distribution for surface-level visibility retrieval from satellite remote sensing "},
journal = {"Remote Sensing of Environment "},
volume = {"181"},
number = {""},
pages = {"1 - 13"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.03.016"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716301092"},
author = {"Qianshan He and Chengcai Li and Fuhai Geng and Guangqiang Zhou and Wei Gao and Wei Yu and Zhenkun Li and Mingbin Du"},
keywords = {"Visibility", "Satellite", "Parameterization", "Aerosol "},
abstract = {"Abstract In this study, a vertical correction method based on a two-layer aerosol model is proposed to estimate the surface-level visibility from satellite measurements of aerosol optical depth (AOD). The meteorological parameters from the re-analysis data of the National Centers for Environmental Prediction (NCEP) are applied to estimate the aerosol layer height (ALH) of the two-layer aerosol model via an automatic workflow. The estimated extinction coefficients near the surface by AOD/ALH over the single point of a lidar site in Shanghai agree well with those of the ground measurements from a visibility sensor, with a correlation coefficient of 0.86 and root mean squared error (RMS) of 0.19 km− 1 for the data set from April 18, 2008 to April 30, 2014. The season-long spatial comparison demonstrates that most of the correlation coefficients (90%) are &gt; 0.6, and more than half of the samples (68%) have coefficients higher than 0.7 for the data set from January 1 to April 30, 2014. Dust transportation and higher relative humidity (RH) have been confirmed to be important factors in reducing the accuracy of estimated visibility, as these situations fail to meet the assumptions of the two-layer model. Additionally, the less-rigorous cloud mask algorithm of the Moderate Resolution Imaging Spectroradiometer (MODIS)/AOD might lead to overestimates of AOD, and further underestimating of the surface-level visibility. The spatial variation of temporal correlation coefficients shows that most comparison sites (&gt; 74%) of satellite estimations agree well with the surface-level visibility measurements, with correlation coefficients up to 0.6 during the study period. The northern area of Eastern China presented better agreement than the southern area. This may be related to the complex underlying surface characteristics and higher \{RH\} in the southern part. This work will significantly improve the quality of climate simulations and air quality forecasts in Eastern China. "} 
}
@article{Abramov201791,
title = {"Visuospatial information processing load and the ratio between parietal cue and target \{P3\} amplitudes in the Attentional Network Test "},
journal = {"Neuroscience Letters "},
volume = {"647"},
number = {""},
pages = {"91 - 96"},
year = {"2017"},
note = {""},
issn = {"0304-3940"},
doi = {"https://doi.org/10.1016/j.neulet.2017.03.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304394017302513"},
author = {"Dimitri M. Abramov and Monique Pontes and Adailton T. Pontes and Carlos A. Mourao-Junior and Juliana Vieira and Carla Quero Cunha and Tiago Tamborino and Paulo R. Galhanone and Leonardo C. deAzevedo and Vladimir V. Lazarev"},
keywords = {"Visuospatial information processing", "Event related potentials", "P3", "Cueing of target", "Parietal cortex", "Attentional Network Test "},
abstract = {"Abstract In \{ERP\} studies of cognitive processes during attentional tasks, the cue signals containing information about the target can increase the amplitude of the parietal cue \{P3\} in relation to the ‘neutral’ temporal cue, and reduce the subsequent target \{P3\} when this information is valid, i.e. corresponds to the target's attributes. The present study compared the cue-to-target \{P3\} ratios in neutral and visuospatial cueing, in order to estimate the contribution of valid visuospatial information from the cue to target stages of the task performance, in terms of cognitive load. The \{P3\} characteristics were also correlated with the results of individuals’ performance of the visuospatial tasks, in order to estimate the relationship of the observed \{ERP\} with spatial reasoning. In 20 typically developing boys, aged 10–13 years (11.3 ± 0.86), the intelligence quotient (I.Q.) was estimated by the Block Design and Vocabulary subtests from the WISC-III. The subjects performed the Attentional Network Test (ANT) accompanied by \{EEG\} recording. The cued two-choice task had three equiprobable cue conditions: No cue, with no information about the target; Neutral (temporal) cue, with an asterisk in the center of the visual field, predicting the target onset; and Spatial cues, with an asterisk in the upper or lower hemifield, predicting the onset and corresponding location of the target. The \{ERPs\} were estimated for the mid-frontal (Fz) and mid-parietal (Pz) scalp derivations. In the Pz, the Neutral cue \{P3\} had a lower amplitude than the Spatial cue P3; whereas for the target ERPs, the \{P3\} of the Neutral cue condition was larger than that of the Spatial cue condition. However, the sums of the magnitudes of the cue and target \{P3\} were equal in the spatial and neutral cueing, probably indicating that in both cases the equivalent information processing load is included in either the cue or the target reaction, respectively. Meantime, in the Fz, the analog \{ERP\} components for both the cue and target stimuli did not depend on the cue condition. The results show that, in the parietal site, the spatial cue \{P3\} reflects the processing of visuospatial information regarding the target position. This contributes to the subsequent “decision-making”, thus reducing the information processing load on the target response, which is probably reflected in the lower P3. This finding is consistent with the positive correlation of parietal cue \{P3\} with the individual's ability to perform spatial tasks as scored by the Block Design subtest. "} 
}
@article{Byeon2017S303,
title = {"\{TCTAP\} C-216 Percutaneous Retrieval of a Migrated Stent in Right Ventricle in Patient with Infective Endocarditis "},
journal = {"Journal of the American College of Cardiology "},
volume = {"69"},
number = {"16, Supplement"},
pages = {"S303 - S304"},
year = {"2017"},
note = {"22nd Cardiovascular Summit \{TCTAP\} 201722nd Cardiovascular Summit Transcatheter Cardiovascular Therapeutics Asia Pacific (TCTAP) "},
issn = {"0735-1097"},
doi = {"https://doi.org/10.1016/j.jacc.2017.03.453"},
url = {"http://www.sciencedirect.com/science/article/pii/S0735109717365658"},
author = {"Jaeho Byeon and Jang Jaehyuk and Ha Wook Park and Yoon Seok Koh"} 

}
@article{Denolf201628,
title = {"Bohr complementarity in memory retrieval "},
journal = {"Journal of Mathematical Psychology "},
volume = {"73"},
number = {""},
pages = {"28 - 36"},
year = {"2016"},
note = {""},
issn = {"0022-2496"},
doi = {"https://doi.org/10.1016/j.jmp.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S002224961600033X"},
author = {"Jacob Denolf and Ariane Lambert-Mogiliansky"},
keywords = {"Episodic overdistribution", "Memory", "Word recognition", "Quantum probability", "Complementarity "},
abstract = {"Abstract We comment on the use of the mathematical formalism of Quantum Mechanics in the analysis of the documented subadditivity phenomenon in human episodic memory. This approach was first proposed by Brainerd et al. in Brainerd et al. (2013). The subadditivity of probability in focus arises as a violation of the disjunction rule of Boolean algebra. This phenomenon is viewed as a consequence of the co-existence of two types of memory traces: verbatim and gist. Instead of assuming that verbatim and gist trace can combine into a coherent memory state of superposition as is done in the \{QEM\} model, we propose to model gist and verbatim traces as Bohr complementary properties of memory. In mathematical terms, we represent the two types of memory as alternative bases of one and the same Hilbert Space. We argue that, in contrast with the \{QEM\} model, our model appeals to the one essential distinction between classical and quantum models of reality namely the existence of incompatible but complementary properties of a system. This feature is also at the heart of the quantum cognition approach to mental phenomena. We sketch an experiment that could separate the two models. We next test our model with data from the same word list experiment as the one used by Brainerd et al. While our model entails significantly less degrees of freedom it yields a good fit to the experimental data. "} 
}
@article{Fouladvand2017S218,
title = {"\{TCTAP\} C-130 Retrieval of Stent Loss During \{LAD\} \{PTCA\} - Complication Consequences "},
journal = {"Journal of the American College of Cardiology "},
volume = {"69"},
number = {"16, Supplement"},
pages = {"S218 - S219"},
year = {"2017"},
note = {"22nd Cardiovascular Summit \{TCTAP\} 201722nd Cardiovascular Summit Transcatheter Cardiovascular Therapeutics Asia Pacific (TCTAP) "},
issn = {"0735-1097"},
doi = {"https://doi.org/10.1016/j.jacc.2017.03.359"},
url = {"http://www.sciencedirect.com/science/article/pii/S0735109717364719"},
author = {"Farhat Fouladvand and Sashko Zhezhovski and Dimitar Mizov"} 

}
@article{Jarome2016103,
title = {"CaMKII regulates proteasome phosphorylation and activity and promotes memory destabilization following retrieval "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"128"},
number = {""},
pages = {"103 - 109"},
year = {"2016"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2016.01.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742716000137"},
author = {"Timothy J. Jarome and Nicole C. Ferrara and Janine L. Kwapis and Fred J. Helmstetter"},
keywords = {"Reconsolidation", "Amygdala", "CaMKII", "Proteasome", "Ubiquitin "},
abstract = {"Abstract Numerous studies have suggested that memories “destabilize” and require de novo protein synthesis in order to reconsolidate following retrieval, but very little is known about how this destabilization process is regulated. Recently, ubiquitin–proteasome mediated protein degradation has been identified as a critical regulator of memory trace destabilization following retrieval, though the specific mechanisms controlling retrieval-induced changes in ubiquitin–proteasome activity remain equivocal. Here, we found that proteasome activity is increased in the amygdala in a CaMKII-dependent manner following the retrieval of a contextual fear memory. We show that in vitro inhibition of CaMKII reversed retrieval-induced increases in proteasome activity. Additionally, in vivo pharmacological blockade of CaMKII abolished increases in proteolytic activity and activity related regulatory phosphorylation in the amygdala following retrieval, suggesting that CaMKII was “upstream” of protein degradation during the memory reconsolidation process. Consistent with this, while inhibiting CaMKII in the amygdala did not impair memory following retrieval, it completely attenuated the memory impairments that resulted from post-retrieval protein synthesis blockade. Collectively, these results suggest that CaMKII controls the initiation of the memory reconsolidation process through regulation of the proteasome. "} 
}
@article{Verma201662,
title = {"Local tri-directional patterns: A new texture feature descriptor for image retrieval "},
journal = {"Digital Signal Processing "},
volume = {"51"},
number = {""},
pages = {"62 - 72"},
year = {"2016"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2016.02.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200416000208"},
author = {"Manisha Verma and Balasubramanian Raman"},
keywords = {"Local tri-directional pattern", "Local binary pattern", "Feature extraction", "Texture feature "},
abstract = {"Abstract Texture is a prominent feature of image and very useful in feature extraction for image retrieval application. Statistical and structural patterns have been proposed for image retrieval and browsing. In the proposed work, a new texture feature descriptor is developed. The proposed method uses local intensity of pixels based on three directions in the neighborhood and named as the local tri-directional pattern (LTriDP). Also, one magnitude pattern is merged for better feature extraction. The proposed method is tested on three databases, in which first two, Brodatz texture image database and \{MIT\} VisTex database are texture image databases and third one is the AT&amp;T face database. Further, the effectiveness of the proposed method is proven by comparing it with existing algorithms for image retrieval application. "} 
}
@article{Tache2016657,
title = {"Multiphase whole-body \{CT\} angiography before multiorgan retrieval in clinically brain dead patients: Role and influence on clinical practice "},
journal = {"Diagnostic and Interventional Imaging "},
volume = {"97"},
number = {"6"},
pages = {"657 - 665"},
year = {"2016"},
note = {""},
issn = {"2211-5684"},
doi = {"https://doi.org/10.1016/j.diii.2015.06.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S2211568415003083"},
author = {"A. Tache and N. Badet and A. Azizi and J. Behr and S. Verdy and E. Delabrousse"},
keywords = {"Multiorgan harvesting", "Brain death", "Multiphase whole-body \{CT\} angiography "},
abstract = {"AbstractGoals To evaluate the contribution of multiphase whole-body \{CT\} angiography (CTA) for identifying the contra-indications to multiorgan retrieval (MOR) and improving the preoperative organ harvesting strategy. Patients and methods One hundred and eleven consecutive patients who were clinically brain dead underwent multiphase whole-body \{CTA\} to confirm the diagnosis of brain death and for assessment of MOR. The \{CTA\} protocol included volumetric acquisitions of the brain and abdominopelvic cavity without \{IV\} administration of iodinated contrast material, then images of the thorax-abdomen-pelvis 25 s after \{IV\} contrast administration, of the brain at 60 s and finally an abdominopelvic \{CT\} acquisition at 90 s. The diagnosis of brain death was based on well-established criteria. The assessment of thorax, abdomen and pelvis was based on a systematic checklist. Post-processing imaging techniques were used in all patients. Results No organs were retrieved from 21 patients due to patient refusal (19%). Twenty-two potential \{MOR\} were denied because of general contra-indications including 12/22 (54%) based on \{CTA\} criteria alone. Finally, 68 patients were eligible for \{MOR\} and 160 organs were harvested. The exclusion of specific organs was based on \{CTA\} alone for 2/16 livers, 4/70 kidneys and 5/55 lungs. Fifty hearts and 58 pancreases were not harvested, none based on \{CTA\} results alone. Hepatic abnormalities and vascular anatomical variants were identified in 10% of patients. At least one renal artery variant was found in 28% of patients, 13% presented with a double renal vein and 8% with a hepato-mesenteric artery. Conclusion Multiphase whole-body \{CTA\} for \{MOR\} is based on the simultaneous association of cerebral \{CTA\} to determine brain death with \{CTA\} of the thorax, abdomen and pelvis. This rapid, standardized and easily accessible procedure has no harmful effects on harvested kidneys. It makes it possible to select the donors and the organs to be harvested and allows the retrieving surgeon to identify and anticipate technical difficulties. "} 
}
@article{D'Souza2014S308,
title = {"Poster #T56 \{LEARN\} \{BEFORE\} \{YOU\} BURN: \{THC\} \{IMPAIRS\} \{ENCODING\} \{BUT\} \{NOT\} \{RETRIEVAL\} \{OF\} \{VERBAL\} \{INFORMATION\} "},
journal = {"Schizophrenia Research "},
volume = {"153, Supplement 1"},
number = {""},
pages = {"S308 - S309"},
year = {"2014"},
note = {"Abstracts of the 4th Biennial Schizophrenia International Research Conference "},
issn = {"0920-9964"},
doi = {"https://doi.org/10.1016/S0920-9964(14)70873-4"},
url = {"http://www.sciencedirect.com/science/article/pii/S0920996414708734"},
author = {"Deepak Cyril D'Souza and Mohini Ranganathan and Peter Addy and Halle Thurnauer and Ashley Schnakenberg and Brian Pittman and Rajiv Radhakrishnan and Patrick Skosnik and Richard Andrew Sewell"} 

}
@article{Hannan201610,
title = {"Content-based image retrieval system for solid waste bin level detection and performance evaluation "},
journal = {"Waste Management "},
volume = {"50"},
number = {""},
pages = {"10 - 19"},
year = {"2016"},
note = {""},
issn = {"0956-053X"},
doi = {"https://doi.org/10.1016/j.wasman.2016.01.046"},
url = {"http://www.sciencedirect.com/science/article/pii/S0956053X16300459"},
author = {"M.A. Hannan and M. Arebey and R.A. Begum and Hassan Basri and Md. Abdulla Al Mamun"},
keywords = {"CBIR", "Feature extraction", "Solid waste bin level", "Gabor", "GLCM", "GLAM "},
abstract = {"Abstract This paper presents a \{CBIR\} system to investigate the use of image retrieval with an extracted texture from the image of a bin to detect the bin level. Various similarity distances like Euclidean, Bhattacharyya, Chi-squared, Cosine, and \{EMD\} are used with the \{CBIR\} system for calculating and comparing the distance between a query image and the images in a database to obtain the highest performance. In this study, the performance metrics is based on two quantitative evaluation criteria. The first one is the average retrieval rate based on the precision-recall graph and the second is the use of \{F1\} measure which is the weighted harmonic mean of precision and recall. In case of feature extraction, texture is used as an image feature for bin level detection system. Various experiments are conducted with different features extraction techniques like Gabor wavelet filter, gray level co-occurrence matrix (GLCM), and gray level aura matrix (GLAM) to identify the level of the bin and its surrounding area. Intensive tests are conducted among 250 bin images to assess the accuracy of the proposed feature extraction techniques. The average retrieval rate is used to evaluate the performance of the retrieval system. The result shows that, the \{EMD\} distance achieved high accuracy and provides better performance than the other distances. "} 
}
@article{Dulas2016116,
title = {"Age-related changes in overcoming proactive interference in associative memory: The role of PFC-mediated executive control processes at retrieval "},
journal = {"NeuroImage "},
volume = {"132"},
number = {""},
pages = {"116 - 128"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2016.02.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811916001245"},
author = {"Michael R. Dulas and Audrey Duarte"},
keywords = {"Aging", "Associative memory", "Executive control", "fMRI", "Prefrontal cortex "},
abstract = {"Abstract Behavioral evidence has shown age-related impairments in overcoming proactive interference in memory, but it is unclear what underlies this deficit. Imaging studies in the young suggest overcoming interference may require several executive control processes supported by the ventrolateral prefrontal cortex (VLPFC) and dorsolateral \{PFC\} (DLPFC). The present functional magnetic resonance imaging (fMRI) study investigated whether age-related changes in dissociable executive control processes underlie deficits in overcoming proactive interference in associative memory during retrieval. Participants were tasked with remembering which associate (face or scene) objects were paired with most recently during study, under conditions of high or low proactive interference. Behavioral results demonstrated that, as interference increased, memory performance decreased similarly across groups, with slight associative memory deficits in older adults. Imaging results demonstrated that, across groups, left mid-VLPFC showed increasing activity with increasing interference, though activity did not distinguish correct from incorrect associative memory responses, suggesting this region may not directly serve in successful resolution of proactive interference, per se. Under conditions of high interference, older adults showed reduced associative memory accuracy effects in the \{DLPFC\} and anterior PFC. These results suggest that age-related \{PFC\} dysfunction may not be ubiquitous. Executive processes supported by ventral regions that detect mnemonic interference may be less affected than processes supported by dorsal and anterior regions that directly resolve interference. "} 
}
@article{Yang201643,
title = {"Invariant multi-scale descriptor for shape representation, matching and retrieval "},
journal = {"Computer Vision and Image Understanding "},
volume = {"145"},
number = {""},
pages = {"43 - 58"},
year = {"2016"},
note = {"Light Field for Computer Vision "},
issn = {"1077-3142"},
doi = {"https://doi.org/10.1016/j.cviu.2016.01.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1077314216000187"},
author = {"Jianyu Yang and Hongxing Wang and Junsong Yuan and Youfu Li and Jianyang Liu"},
keywords = {"Invariant descriptor", "Shape representation", "Shape matching", "Contour "},
abstract = {"Abstract Shape matching and retrieval have been some of the fundamental topics in computer vision. Object shape is a meaningful and informative cue in object recognition, where an effective shape descriptor plays an important role. To capture the invariant features of both local shape details and visual parts, we propose a novel invariant multi-scale descriptor for shape matching and retrieval. In this work, we define three types of invariants to capture the shape features from different aspects. Each type of the invariants is used in multiple scales from a local range to a semi-global part. An adaptive discrete contour evolution method is also proposed to extract the salient feature points of a shape contour for compact representation. Shape matching is performed using the dynamic programming algorithm. The proposed method is invariant to rotation, scale variation, intra-class variation, articulated deformation and partial occlusion. Our method is robust to noise as well. To validate the invariance and robustness of our proposed method, we perform experiments on multiple benchmark datasets, including MPEG-7, Kimia and articulated shape datasets. The competitive results indicate the effectiveness of our proposed method for shape matching and retrieval. "} 
}
@article{Rami201645,
title = {"Texture retrieval using mixtures of generalized Gaussian distribution and Cauchy–Schwarz divergence in wavelet domain "},
journal = {"Signal Processing: Image Communication "},
volume = {"42"},
number = {""},
pages = {"45 - 58"},
year = {"2016"},
note = {""},
issn = {"0923-5965"},
doi = {"https://doi.org/10.1016/j.image.2016.01.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0923596516000084"},
author = {"Hassan Rami and Leila Belmerhnia and Ahmed Drissi El Maliani and Mohammed El Hassouni"},
keywords = {"Wavelet decomposition", "Mixture of generalized Gaussian model", "Similarity measurement", "Cauchy–Schwarz divergence "},
abstract = {"Abstract This paper presents a novel similarity measure in a texture retrieval framework based on statistical modeling in wavelet domain. In this context, we use the recently proposed finite mixture of generalized Gaussian distribution (MoGG) thanks to its ability to model accurately a wide range of wavelet sub-bands histograms. This model has already been relied on the approximation of Kullback–Leibler divergence (KLD) which hinders significantly the retrieval process. To overcome this drawback, we introduce the Cauchy–Schwarz divergence (CSD) between two MoGG distributions as a similarity measure. Hence, an analytic closed-form expression of this measure is developed in the case of fixed shape parameter. Otherwise, when the shape parameter is variable, two approximations are derived using the well-known stochastic integration with Monte-Carlo simulations and numerical integration with Simpson׳s rule. Experiments conducted on a well known dataset show good performance of the \{CSD\} in terms of retrieval rates and the computational time improvement compared to the KLD. "} 
}
@article{Hughes2017,
title = {"Enabling interoperability in planetary sciences and heliophysics: The case for an information model "},
journal = {"Planetary and Space Science "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"0032-0633"},
doi = {"https://doi.org/10.1016/j.pss.2017.04.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0032063316304652"},
author = {"J. Steven Hughes and Daniel J. Crichton and Anne C. Raugh and Baptiste Cecconi and Edward A. Guinness and Christopher E. Isbell and Joseph N. Mafi and Mitchell K. Gordon and Sean H. Hardman and Ronald S. Joyner"},
keywords = {"Interoperability", "Information architecture", "Information model", "Planetary science", "Heliophysics", "Semantic", "Digital repository", "Ontology "},
abstract = {"Abstract The Planetary Data System has developed the \{PDS4\} Information Model to enable interoperability across diverse science disciplines. The Information Model is based on an integration of International Organization for Standardization (ISO) level standards for trusted digital archives, information model development, and metadata registries. Where controlled vocabularies provides a basic level of interoperability by providing a common set of terms for communication between both machines and humans the Information Model improves interoperability by means of an ontology that provides semantic information or additional related context for the terms. The information model was defined by team of computer scientists and science experts from each of the diverse disciplines in the Planetary Science community, including Atmospheres, Geosciences, Cartography and Imaging Sciences, Navigational and Ancillary Information, Planetary Plasma Interactions, Ring-Moon Systems, and Small Bodies. The model was designed to be extensible beyond the Planetary Science community, for example there are overlaps between certain \{PDS\} disciplines and the Heliophysics and Astrophysics disciplines. "Interoperability" can apply to many aspects of both the developer and the end-user experience, for example agency-to-agency, semantic level, and application level interoperability. We define these types of interoperability and focus on semantic level interoperability, the type of interoperability most directly enabled by an information model. "} 
}
@article{Mendonca201615,
title = {"Improving atmospheric \{CO2\} retrievals using line mixing and speed-dependence when fitting high-resolution ground-based solar spectra "},
journal = {"Journal of Molecular Spectroscopy "},
volume = {"323"},
number = {""},
pages = {"15 - 27"},
year = {"2016"},
note = {"Atmospheric Spectroscopy "},
issn = {"0022-2852"},
doi = {"https://doi.org/10.1016/j.jms.2016.01.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S002228521630008X"},
author = {"J. Mendonca and K. Strong and G.C. Toon and D. Wunch and K. Sung and N.M. Deutscher and D.W.T. Griffith and J.E. Franklin"},
keywords = {"CO2", "Absorption coefficient", "Line mixing", "Speed-dependence", "High-resolution solar spectra "},
abstract = {"Abstract A quadratic speed-dependent Voigt spectral line shape with line mixing (qSDV + LM) has been included in atmospheric trace-gas retrievals to improve the accuracy of the calculated \{CO2\} absorption coefficients. \{CO2\} laboratory spectra were used to validate absorption coefficient calculations for three bands: the strong 20013 ← 00001 band centered at 4850 cm−1, and the weak 30013 ← 00001 and 30012 ← 00001 bands centered at 6220 cm−1 and 6340 cm−1 respectively, and referred to below as bands 1 and 2. Several different line lists were tested. Laboratory spectra were best reproduced for the strong \{CO2\} band when using \{HITRAN\} 2008 spectroscopic data with air-broadened widths divided by 0.985, self-broadened widths divided by 0.978, line mixing coefficients calculated using the exponential power gap (EPG) law, and a speed-dependent parameter of 0.11 used for all lines. For the weak \{CO2\} bands, laboratory spectra were best reproduced using spectroscopic parameters from the studies by Devi et al. in 2007 coupled with line mixing coefficients calculated using the \{EPG\} law. A total of 132,598 high-resolution ground-based solar absorption spectra were fitted using qSDV + \{LM\} to calculate \{CO2\} absorption coefficients and compared to fits that used the Voigt line shape. For the strong \{CO2\} band, the average root mean square (RMS) residual is 0.49 ± 0.22% when using qSDV + \{LM\} to calculate the absorption coefficients. This is an improvement over the results with the Voigt line shape, which had an average \{RMS\} residual of 0.60 ± 0.21%. When using the qSDV + \{LM\} to fit the two weak \{CO2\} bands, the average \{RMS\} residual is 0.47 ± 0.19% and 0.51 ± 0.20% for bands 1 and 2, respectively. These values are identical to those obtained with the Voigt line shape. Finally, we find that using the qSDV + \{LM\} decreases the airmass dependence of the column averaged dry air mole fraction of \{CO2\} retrieved from the strong and both weak \{CO2\} bands when compared to the retrievals obtained using the Voigt line shape. "} 
}
@article{Nahata2016260,
title = {"Sperm Retrieval in Adolescents and Young Adults with Klinefelter Syndrome: A Prospective, Pilot Study "},
journal = {"The Journal of Pediatrics "},
volume = {"170"},
number = {""},
pages = {"260 - 265.e2"},
year = {"2016"},
note = {""},
issn = {"0022-3476"},
doi = {"https://doi.org/10.1016/j.jpeds.2015.12.028"},
url = {"http://www.sciencedirect.com/science/article/pii/S0022347615015401"},
author = {"Leena Nahata and Richard N. Yu and Harriet J. Paltiel and Jeanne S. Chow and Tanya Logvinenko and Ilina Rosoklija and Laurie E. Cohen"},

abstract = {"Objective To assess sperm retrieval rates in adolescents and young adults with Klinefelter syndrome, with the ultimate goal of improving fertility in this population. Secondary aims were to evaluate other clinical characteristics of the cohort and identify predictors of sperm retrieval. Study design Patients 12-25 years of age with Klinefelter syndrome (47,XXY) were recruited at the Boston Children's Hospital. Physical examination, biochemical evaluation, scrotal ultrasonography, and semen analysis were performed. Neurocognitive data were collected. Microdissection sperm extraction (unilateral micro-testicular sperm extraction) was offered to individuals with no sperm in their ejaculates. Given the small sample size, analysis was primarily descriptive. Results Fifteen patients were enrolled. None had sperm in their ejaculates. Ten patients underwent unilateral micro-testicular sperm extraction. Sperm retrieval rate was 50%. From a neurocognitive standpoint, subjects reported problems with peers, conduct, and overall difficulties. Incidentally, one-third of the patients were found to have testicular microlithiasis and 17% of subjects with renal ultrasound imaging had bilateral renal medullary nephrocalcinosis. Conclusions This pilot study suggests that sperm retrieval rates in adolescents and young adults with Klinefelter syndrome are comparable with those reported in older men. However, larger studies are needed to confirm our findings. The clinical significance of the scrotal and renal ultrasound findings merits further investigation. Trial registration ClinicalTrials.gov: NCT01817296. "} 
}
@article{Chen201653,
title = {"Effect of emissivity uncertainty on surface temperature retrieval over urban areas: Investigations based on spectral libraries "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"114"},
number = {""},
pages = {"53 - 65"},
year = {"2016"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2016.01.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271616000228"},
author = {"Feng Chen and Song Yang and Z. Su and Kai Wang"},
keywords = {"Thermal imagery", "Land surface temperature", "Landsat", "HJ1B", "Spectral library "},
abstract = {"Abstract Land surface emissivity (LSE) is a prerequisite for retrieving land surface temperature (LST) through single channel methods. According to error model, a 0.01 (1%) uncertainty of \{LSE\} may result in a 0.5 K error in \{LST\} under a moderate condition, while an obvious error (approximately 1 K) is possible under a warmer and less humid situation. Significant emissivity variations are presented among the anthropogenic materials in three spectral libraries, which raise a critical question that whether urban \{LSE\} can be estimated accurately to meet the needs for \{LST\} retrieval. Methods widely used for urban \{LSE\} estimation are investigated, including the classification-based method, the spectral-index based method, and the linear spectral mixture model (LSMM). Results indicate that the classification-based method may not be effectively applicable for urban \{LSE\} estimation, due mainly to the insignificant relation between the short-wave multispectral reflectance and the long-wave thermal emissivity shown by the spectra. Compared with the classification-based method, the \{LSMM\} shows relatively more accurate predictions, whereas, the performance of the \{LSMM\} largely depends on the determination of endmembers. Obvious uncertainties in \{LSE\} estimation likely appear if endmembers are determined improperly. Increasing the spectra for endmembers is a practical and beneficial means for \{LSMM\} when there is not a priori knowledge, which emphasizes the necessity of building a comprehensive spectral library of urban materials. Furthermore, the \{LST\} retrieval from a single channel of Landsat 8 is more challenging as compared with the retrieval from the channels of its predecessors—Landsat 4/5/7. "} 
}
@article{Papenmeier201690,
title = {"If you watch it move, you'll recognize it in 3D: Transfer of depth cues between encoding and retrieval "},
journal = {"Acta Psychologica "},
volume = {"164"},
number = {""},
pages = {"90 - 95"},
year = {"2016"},
note = {""},
issn = {"0001-6918"},
doi = {"https://doi.org/10.1016/j.actpsy.2015.12.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0001691815301049"},
author = {"Frank Papenmeier and Stephan Schwan"},
keywords = {"Object recognition", "Stereoscopic displays", "Memory", "Depth perception", "Depth from motion", "Binocular disparity "},
abstract = {"Abstract Viewing objects with stereoscopic displays provides additional depth cues through binocular disparity supporting object recognition. So far, it was unknown whether this results from the representation of specific stereoscopic information in memory or a more general representation of an object's depth structure. Therefore, we investigated whether continuous object rotation acting as depth cue during encoding results in a memory representation that can subsequently be accessed by stereoscopic information during retrieval. In Experiment 1, we found such transfer effects from continuous object rotation during encoding to stereoscopic presentations during retrieval. In Experiments 2a and 2b, we found that the continuity of object rotation is important because only continuous rotation and/or stereoscopic depth but not multiple static snapshots presented without stereoscopic information caused the extraction of an object's depth structure into memory. We conclude that an object's depth structure and not specific depth cues are represented in memory. "} 
}
@article{Delorenzo2017,
title = {"Characteristics of Fixed Wing Air Ambulance Transports in Victoria, Australia "},
journal = {"Air Medical Journal "},
volume = {""},
number = {""},
pages = {" - "},
year = {"2017"},
note = {""},
issn = {"1067-991X"},
doi = {"https://doi.org/10.1016/j.amj.2017.02.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1067991X16303029"},
author = {"Ashleigh J. Delorenzo and Jeremy W. Abetz and Emily Andrew and Anthony de Wit and Brett Williams and Karen Smith"},

abstract = {"AbstractObjective Air medical transport is important for the transfer of patients in the prehospital and interhospital environment. Few studies have described the services provided by fixed wing ambulances or the broader clinical profiles of patients they transport. Such information may be useful for the planning and allocation of resources, assistance with training, and refining clinical protocols. We sought to describe the characteristics of patients transported by fixed wing aircraft at Air Ambulance Victoria (AAV) and the service \{AAV\} provides in Victoria, Australia. Methods A retrospective data review of patients transported by \{AAV\} fixed wing aircraft between January 1, 2011, and June 30, 2015, was performed. Data were sourced from the Ambulance Victoria data warehouse. Retrievals involving physicians were excluded. Results A total of 16,579 patients were transported during the study period, with a median age of 66 years. Most patients were male (58.7%), and cardiovascular/hematologic conditions (27.2%) were most common. Overall, 51.7% of cases were prebooked routine transfers, 47.4% were interhospital routine transfers, and 0.9% were primary responses. Caseloads were largest in the regions furthest from the capital city. Conclusion The \{AAV\} fixed wing service in Victoria enables regional and remote patients to be transported to definitive care without major disruption to ground ambulances. "} 
}
@article{Hanum2014214,
title = {"Using Topic Analysis for Querying Halal Information on Malay Documents "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"121"},
number = {""},
pages = {"214 - 222"},
year = {"2014"},
note = {"International Halal Conference InHAC 2012 "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2014.01.1122"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877042814011392"},
author = {"Haslizatul Mohamed Hanum and Zainab Abu Bakar and Nurazzah Abdul Rahman and Marshima Mohd Rosli and Norzilah Musa"},
keywords = {"topic analysis", "latent semantic indexing", "information retrieval "},
abstract = {"Abstract Many documents with descriptions of halal products are available through resources from the Internet web pages. User may enquire for halal-related information through query words and as a result of the query user will be present- ed list of documents relevant to the query. We investigate on topic analysis techniques such as Latent Semantic Anal- ysis (LSA). For retrieval purposes, frequency-based inverted indexing and latent semantic indexing (LSI) techniques are used to discover the important association of the relationship between terms and terms, terms and documents and documents and documents. Cosine similarity measurement is used to measure the similarity between the query word and terms as well as the documents. We develop a prototype and evaluate the techniques on Malay test collection which contain documents extracted from translated Al-Quran collection, translated hadiths collection and web pages written in Malay language. Results and analysis show that, \{LSI\} technique outperformed the exact frequency-based technique despite the longer processing time it took during the indexing. We compare and discuss the result we get from using latent semantic with the result from using conventional frequency analysis. "} 
}
@article{Lin2015423,
title = {"A statistical model for predicting the retrieval rate of separated instruments and clinical decision-making "},
journal = {"Journal of Dental Sciences "},
volume = {"10"},
number = {"4"},
pages = {"423 - 430"},
year = {"2015"},
note = {""},
issn = {"1991-7902"},
doi = {"https://doi.org/10.1016/j.jds.2015.05.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1991790215000641"},
author = {"Chen Lin and Li Xu and Yang-xi Chen and Yuan Liang and Xiao-lin Chen and Yao Lin and Xiao-qing Huang and Ya Fang and Zhi Chen"},
keywords = {"instrument fracture", "logistic regression analysis", "root canal treatment", "separated instruments", "statistical model "},
abstract = {"AbstractBackground/purpose There are controversial opinions about the prognosis of the retrieval of a separated instrument from the root canal. The aim of the study was to establish a statistical model to predict the success rate of the retrieval of separated instruments and to aid clinicians with decision-making. Materials and methods In retrospective studies, information on the tooth position, the root canal curvature, and the depth and length of separated instruments were collected in 210 clinical cases with separated instruments in the lower segments of curved root canals. The correlations of these factors and the retrieval rate of separated instruments were analyzed. Two factors with significant correlations were chosen and a regression equation was established using stepwise multivariate logistic regression analysis. In the verification study, the efficiency of the statistical model was verified by 63 new cases. Results The root canal curvature and depth of the separated instruments are major factors affecting the retrieval rate of broken instruments. The retrieval rate of separated instruments decreased gradually with the increase of root canal curvature or the depth of the instrument. A regression equation was established correlating these two factors. The predicted accuracy rate of the regression equation was 94.3% for successful retrieval, and 80.0% for failed retrieval. Conclusion A statistical model relating to root canal curvature and depth of separated instruments was established to evaluate the retrieval rate of separated instruments, and the result of this formulation may provide clues for clinical decision-making. "} 
}
@article{Cummings201671,
title = {"Phonological code retrieval during picture naming: Influence of consonant class "},
journal = {"Brain Research "},
volume = {"1635"},
number = {""},
pages = {"71 - 85"},
year = {"2016"},
note = {""},
issn = {"0006-8993"},
doi = {"https://doi.org/10.1016/j.brainres.2016.01.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0006899316000275"},
author = {"Alycia Cummings and Amebu Seddoh and Brianna Jallo"},
keywords = {"Event-related potentials (ERP)", "Lexical processing", "Picture naming", "Segmental phonology", "Distinctive features", "Adult psycholinguistics "},
abstract = {"Abstract Investigations of the time course of various stages of lexical processing have indicated either early or late onset of brain activation for phonological code retrieval. The basis of the differential findings is unclear, but factors related to segmental phonology appear to be part of it. The purpose of the present study was to determine whether phonological encoding is influenced by consonant type. Undergraduate students were presented pictures of common and familiar objects to name. Each picture label had an initial liquid (/l/, /ɹ/) or a stop (/b/, /d/) consonant. Accuracy of picture naming was high and comparable for the two stimulus sets. However, words beginning with liquids elicited larger \{N2\} \{ERP\} responses than did those with initial stops. Cluster permutation analysis indicated that the \{ERP\} responses elicited by words in the two stimulus sets differed between 293 ms and 371 ms post picture onset. These findings point to a late onset of phonological code retrieval. They have implications for segmental phonology and/or motor planning and execution of speech. "} 
}
@article{Hollins201687,
title = {"Giving and stealing ideas in memory: Source errors in recall are influenced by both early-selection and late-correction retrieval processes "},
journal = {"Journal of Memory and Language "},
volume = {"88"},
number = {""},
pages = {"87 - 103"},
year = {"2016"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2016.01.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X1600005X"},
author = {"Timothy J. Hollins and Nicholas Lange and Christopher J. Berry and Ian Dennis"},
keywords = {"Unconscious plagiarism", "Source memory", "Generation", "Monitoring", "Recall "},
abstract = {"Abstract Previous studies of unconscious plagiarism have asked participants to recall their own ideas from a previous group-problem solving session, and have typically reported that people mistakenly include a partner’s responses when trying to recall their own. To date, there has been little research looking at the propensity to include one’s own responses when trying to recall a partner’s previous contribution to the group. Experiment 1 demonstrated that people make both kinds of source-error during recall, but source errors are more common in the recall-partner task. This pattern was replicated in Experiments 2a and 2b with source-errors and intrusions increasing over a delay. Experiment 3 used an extended version of each recall task, in which participants reported all items that came to mind, whilst indicating which responses were goal-relevant. The tendency for source-errors to occur more for the recall-partner task was shown to be a function of both idea availability and output monitoring, whereas the tendency for source-errors to increase over a delay was shown to be due solely to output monitoring. Thus, unconscious plagiarism errors are one instantiation of the more general problem of source-specified recall, which is influenced jointly by processes at generation and output monitoring. "} 
}
@article{Koner2016266,
title = {"Hybrid cloud and error masking to improve the quality of deterministic satellite sea surface temperature retrieval and data coverage "},
journal = {"Remote Sensing of Environment "},
volume = {"174"},
number = {""},
pages = {"266 - 278"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.12.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715302364"},
author = {"Prabhat K. Koner and Andrew Harris and Eileen Maturi"},
keywords = {"Cloud detection", "Spectral differences method", "Radiative transfer model", "Bayesian cloud detection", "Modified total least squares", "Sea surface temperature", "GOES-13 imager "},
abstract = {"Abstract In the infrared region, the quality of sea surface temperature (SST) retrievals critically depends on the cloud detection scheme. More than 5 million matchups, where the surface and top of atmosphere measurements are available, have been carefully analyzed to understand clouds related errors and to develop the advanced cloud detection scheme for improvement of satellite \{SST\} quality. The effectiveness of a Bayesian cloud detection (BCD) scheme, operationally implemented at the \{NOAA\} Office of Satellite Product Operations (OSPO) for the GOES-Imager, has been examined using an experimental filter and it is found that this scheme is not optimal. Thus, a new algorithm for cloud and error masking (CEM) scheme is proposed for physical \{SST\} retrievals. This is based on a quasi-deterministic approach combined with an approximated radiative transfer model and the functional spectral differences at pixel level. Although, traditionally the validation of cloud detection algorithms have often been reported qualitatively using visual inspection of imagery, we have made a quantitative validation of the cloud algorithm for its intended purpose by determining the quality of satellite \{SST\} retrievals against in situ data. Results show that \{CEM\} can reduce the root mean square error in \{SST\} by an average of 22% while increasing the data coverage by an average of 38% compared to the operationally implemented \{BCD\} at OSPO, as assessed over a period of fifty months. "} 
}
@article{Jin2016632,
title = {"Distinct Circuits for the Formation and Retrieval of an Imprinted Olfactory Memory "},
journal = {"Cell "},
volume = {"164"},
number = {"4"},
pages = {"632 - 643"},
year = {"2016"},
note = {""},
issn = {"0092-8674"},
doi = {"https://doi.org/10.1016/j.cell.2016.01.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0092867416000088"},
author = {"Xin Jin and Navin Pokala and Cornelia I. Bargmann"},

abstract = {"Summary Memories formed early in life are particularly stable and influential, representing privileged experiences that shape enduring behaviors. We show that exposing newly hatched C. elegans to pathogenic bacteria results in persistent aversion to those bacterial odors, whereas adult exposure generates only transient aversive memory. Long-lasting imprinted aversion has a critical period in the first larval stage and is specific to the experienced pathogen. Distinct groups of neurons are required during formation (AIB, RIM) and retrieval (AIY, RIA) of the imprinted memory. \{RIM\} synthesizes the neuromodulator tyramine, which is required in the \{L1\} stage for learning. \{AIY\} memory retrieval neurons sense tyramine via the SER-2 receptor, which is essential for imprinted, but not for adult-learned, aversion. Odor responses in several neurons, most notably RIA, are altered in imprinted animals. These findings provide insight into neuronal substrates of different forms of memory, and lay a foundation for further understanding of early learning. "} 
}
@article{Bavota2014163,
title = {"Enhancing software artefact traceability recovery processes with link count information "},
journal = {"Information and Software Technology "},
volume = {"56"},
number = {"2"},
pages = {"163 - 182"},
year = {"2014"},
note = {""},
issn = {"0950-5849"},
doi = {"https://doi.org/10.1016/j.infsof.2013.08.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S0950584913001754"},
author = {"Gabriele Bavota and Andrea De Lucia and Rocco Oliveto and Genoveffa Tortora"},
keywords = {"Traceability recovery", "Information retrieval", "Link count information", "Controlled experiments "},
abstract = {"AbstractContext The intensive human effort needed to manually manage traceability information has increased the interest in using semi-automated traceability recovery techniques. In particular, Information Retrieval (IR) techniques have been largely employed in the last ten years to partially automate the traceability recovery process. Aim Previous studies mainly focused on the analysis of the performances of IR-based traceability recovery methods and several enhancing strategies have been proposed to improve their accuracy. Very few papers investigate how developers (i) use IR-based traceability recovery tools and (ii) analyse the list of suggested links to validate correct links or discard false positives. We focus on this issue and suggest exploiting link count information in IR-based traceability recovery tools to improve the performances of the developers during a traceability recovery process. Method Two empirical studies have been conducted to evaluate the usefulness of link count information. The two studies involved 135 University students that had to perform (with and without link count information) traceability recovery tasks on two software project repositories. Then, we evaluated the quality of the recovered traceability links in terms of links correctly and erroneously traced by the students. Results The results achieved indicate that the use of link count information significantly increases the number of correct links identified by the participants. Conclusions The results can be used to derive guidelines on how to effectively use traceability recovery approaches and tools proposed in the literature. "} 
}
@article{HoTongMinh2016138,
title = {"\{SAR\} tomography for the retrieval of forest biomass and height: Cross-validation at two tropical forest sites in French Guiana "},
journal = {"Remote Sensing of Environment "},
volume = {"175"},
number = {""},
pages = {"138 - 147"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.12.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715302595"},
author = {"Dinh Ho Tong Minh and Thuy Le Toan and Fabio Rocca and Stefano Tebaldini and Ludovic Villard and Maxime Réjou-Méchain and Oliver L. Phillips and Ted R. Feldpausch and Pascale Dubois-Fernandez and Klaus Scipal and Jérôme Chave"},
keywords = {"Aboveground biomass", "BIOMASS mission", "French Guiana", "Paracou", "Nouragues", "TropiSAR", "P-band \{SAR\} tomography", "Tomography phase", "Vertical forest structure "},
abstract = {"Abstract Developing and improving methods to monitor forest carbon in space and time is a timely challenge, especially for tropical forests. The next European Space Agency Earth Explorer Core Mission \{BIOMASS\} will collect synthetic aperture radar (SAR) data globally from employing a multiple baseline orbit during the initial phase of its lifetime. These data will be used for tomographic \{SAR\} (TomoSAR) processing, with a vertical resolution of about 20 m, a resolution sufficient to decompose the backscatter signal into two to three layers for most closed-canopy tropical forests. A recent study, conducted in the Paracou site, French Guiana, has already shown that TomoSAR significantly improves the retrieval of forest aboveground biomass (AGB) in a high biomass forest, with an error of only 10% at 1.5-ha resolution. However, the degree to which this TomoSAR approach can be transferred from one site to another has not been assessed. We test this approach at the Nouragues site in central French Guiana (ca 100 km away from Paracou), and develop a method to retrieve the top-of-canopy height from TomoSAR. We found a high correlation between the backscatter signal and \{AGB\} in the upper canopy layer (i.e. 20–40 m), while lower layers only showed poor correlations. The relationship between \{AGB\} and TomoSAR data was found to be highly similar for forests at Nouragues and Paracou. Cross validation using training plots from Nouragues and validation plots from Paracou, and vice versa, gave an error of 16–18% of \{AGB\} using 1-ha plots. Finally, using a high-resolution LiDAR canopy model as a reference, we showed that TomoSAR has the potential to retrieve the top-of-canopy height with an error to within 2.5 m. Our analyses show that the TomoSAR-AGB retrieval method is accurate even in hilly and high-biomass forest areas and suggest that our approach may be generalizable to other study sites, having a canopy taller than 30 m. These results have strong implications for the tomographic phase of the \{BIOMASS\} spaceborne mission. "} 
}
@article{Law2014S37,
title = {"REGNET: Regulatory information management, compliance and analysis "},
journal = {"Government Information Quarterly "},
volume = {"31, Supplement 1"},
number = {""},
pages = {"S37 - S48"},
year = {"2014"},
note = {"\{ICEGOV\} 2012 SupplementTOWARDS \{SMARTER\} GOVERNMENTS: \{NEW\} \{TECHNOLOGIES\} \{AND\} \{INNOVATION\} \{IN\} \{THE\} \{PUBLIC\} \{SECTOR\} "},
issn = {"0740-624X"},
doi = {"https://doi.org/10.1016/j.giq.2014.01.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0740624X14000549"},
author = {"Kincho H. Law and Gloria Lau and Shawn Kerrigan and Julia A. Ekstrom"},
keywords = {"Regulations", "Compliance assistance", "Relatedness analysis", "Information retrieval", "e-Government", "Eco-system models "},
abstract = {"Abstract This paper provides an overview of a research effort that aims to investigate methodologies and tools to facilitate access, compliance and analysis of government regulations. The complexity, diversity, and volume of government regulations are detrimental to business and hinder public understanding of government. The burden of complying with regulations can fall disproportionately on small businesses since these businesses may not have the expertise or resources to keep track of the regulations and the requirements. Regulations emanating from different agencies, each has its own objectives and scopes of concerns, may overlap on similar and related issues and may have inconsistency. The situation can potentially be improved by developing appropriate methodologies and tools that can help facilitate the development and analysis of regulatory documents as well as compliance process. To illustrate, this paper discusses the applications of information technology for selected services related to regulations, such as compliance assistance and comparison of regulations. "} 
}
@incollection{Kalet2014397,
title = {"Chapter 4 - Biomedical Information Access "},
editor = {"Kalet, Ira J. "},
booktitle = {"Principles of Biomedical Informatics (Second Edition) "},
publisher = {"Academic Press"},
edition = {"Second Edition"},
address = {"San Diego"},
year = {"2014"},
pages = {"397 - 478"},
isbn = {"978-0-12-416019-4"},
doi = {"https://doi.org/10.1016/B978-0-12-416019-4.00004-4"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780124160194000044"},
author = {"Ira J. Kalet"},
keywords = {"Biomedical information access", "Information retrieval systems", "Document repositories", "Search engines", "Networks", "Biomedical data communication "},
abstract = {"Abstract Biomedical information access is concerned with organizing text documents and other kinds of records and documents, to support searching such repositories to identify relevant and important documents as needed. Systems that address this task are called Information Retrieval (IR) systems, or more commonly, Search Engines. The key concepts we will address here are: how the structure and organization of information affect the efficiency of search, the construction and use of indexing systems, how a query is matched to items, how to rank order the results, and alternatives to rank ordering. This chapter will introduce how such document repositories are constructed, and how search engines work. We will also examine how to access web-based information repositories from programs (as opposed to using web browser front ends). "} 
}
@article{ElHajj2016202,
title = {"Soil moisture retrieval over irrigated grassland using X-band \{SAR\} data "},
journal = {"Remote Sensing of Environment "},
volume = {"176"},
number = {""},
pages = {"202 - 218"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.01.027"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716300281"},
author = {"Mohammad El Hajj and Nicolas Baghdadi and Mehrez Zribi and Gilles Belaud and Bruno Cheviron and Dominique Courault and François Charron"},
keywords = {"grassland", "TerraSAR-X", "COSMO-SkyMED", "neural networks", "inversion", "soil moisture", "vegetation indices "},
abstract = {"Abstract The aim of this study was to develop an inversion approach to estimate surface soil moisture from X-band \{SAR\} data over irrigated grassland areas. This approach simulates a coupling scenario between Synthetic Aperture Radar (SAR) and optical images through the Water Cloud Model (WCM). A time series of \{SAR\} (TerraSAR-X and COSMO-SkyMed) and optical (SPOT 4/5 and \{LANDSAT\} 7/8) images were acquired over an irrigated grassland region in southeastern France. An inversion technique based on multi-layer perceptron neural networks (NNs) was used to invert the Water Cloud Model (WCM) for soil moisture estimation. Three inversion configurations based on \{SAR\} and optical images were defined: (1) \{HH\} polarization, (2) \{HV\} polarization, and (3) both \{HH\} and \{HV\} polarizations, all with one vegetation descriptor derived from optical data. The investigated vegetation descriptors were the Normalized Difference Vegetation Index “NDVI”, Leaf Area Index “LAI”, Fraction of Absorbed Photosynthetically Active Radiation “FAPAR”, and the Fractional vegetation \{COVER\} “FCOVER”. These vegetation descriptors were derived from optical images. For the three inversion configurations, the \{NNs\} were trained and validated using a noisy synthetic dataset generated by the \{WCM\} for a wide range of soil moisture and vegetation descriptor values. The trained \{NNs\} were then validated from a real dataset composed of X-band \{SAR\} backscattering coefficients and vegetation descriptor derived from optical images. The use of X-band \{SAR\} measurements in \{HH\} polarization (in addition to one vegetation descriptor derived from optical images) yields more precise results on soil moisture (Mv) estimates. In the case of \{NDVI\} derived from optical images as the vegetation descriptor, the Root Mean Square Error on Mv estimates was 3.6 Vol.% for \{NDVI\} values between 0.45 and 0.75, and 6.1 Vol.% for \{NDVI\} between 0.75 and 0.90. Similar results were obtained regardless of the other vegetation descriptor used. "} 
}
@article{Renu2016101,
title = {"Computing similarity of text-based assembly processes for knowledge retrieval and reuse "},
journal = {"Journal of Manufacturing Systems "},
volume = {"39"},
number = {""},
pages = {"101 - 110"},
year = {"2016"},
note = {""},
issn = {"0278-6125"},
doi = {"https://doi.org/10.1016/j.jmsy.2016.03.004"},
url = {"http://www.sciencedirect.com/science/article/pii/S027861251630005X"},
author = {"Rahul Sharan Renu and Gregory Mocko"},
keywords = {"Assembly process planning", "Assembly work instructions", "Text similarity "},
abstract = {"Abstract The objective of this research is to use text similarity algorithms to enable retrieval and knowledge sharing of text-based assembly process plans. In distributed design-manufacturing enterprises, there exists a need to: (1) establish and use “best practice” assembly process descriptions to ensure process design consistency across manufacturing locations and (2) leverage and adapt existing process design knowledge across product lines. In this research, the need for better communication is addressed by design knowledge reuse. Specifically, previously-authored assembly processes are retrieved from a centralized repository with a text-based similarity and retrieval algorithm. The similarity of forty-five text-based assembly work instruction pairs (obtained from ten work instruction sets) is computed using four text mining algorithms: (1) Word Overlap, (2) Jaccard Score, (3) TF–IDF and (4) Latent Semantic Analysis. The similarity scores are used to compare and retrieve similar work instructions from a repository of existing assembly processes descriptions. A survey is conducted to develop a baseline quantification of assembly work instruction similarity. The scores from each text comparison method are compared to the scores from the survey. A statistical hypothesis test shows the Jaccard method mimics human interpretation of assembly work instruction similarity better than the three other text comparison methods. However, the Jaccard method is insensitive to synonymy and polysemy of words. The Latent Semantic Analysis method is relatively insensitive to synonymy and polysemy of words; and was found to have a difference of 0.1 with respect to survey data. This indicates that Latent Semantic Analysis can be used to retrieve assembly work instructions authored in free text. By doing so, engineers will be presented with similar variants of assembly work instructions have been authored. This will allow engineers to compare and assess the efficiency of their assembly process and gain insight into how other facilities are performing similar assembly operations. "} 
}
@article{Lunny2016107,
title = {"Retrieval of overviews of systematic reviews in \{MEDLINE\} was improved by the development of an objectively derived and validated search strategy "},
journal = {"Journal of Clinical Epidemiology "},
volume = {"74"},
number = {""},
pages = {"107 - 118"},
year = {"2016"},
note = {""},
issn = {"0895-4356"},
doi = {"https://doi.org/10.1016/j.jclinepi.2015.12.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0895435615005788"},
author = {"Carole Lunny and Joanne E. McKenzie and Steve McDonald"},
keywords = {"Overviews of systematic reviews", "Search strategy design", "Search filter", "Text mining", "Sensitivity", "MEDLINE "},
abstract = {"AbstractObjectives Locating overviews of systematic reviews is difficult because of an absence of appropriate indexing terms and inconsistent terminology used to describe overviews. Our objective was to develop a validated search strategy to retrieve overviews in MEDLINE. Study Design and Setting We derived a test set of overviews from the references of two method articles on overviews. Two population sets were used to identify discriminating terms, that is, terms that appear frequently in the test set but infrequently in two population sets of references found in MEDLINE. We used text mining to conduct a frequency analysis of terms appearing in the titles and abstracts. Candidate terms were combined and tested in \{MEDLINE\} in various permutations, and the performance of strategies measured using sensitivity and precision. Results Two search strategies were developed: a sensitivity-maximizing strategy, achieving 93% sensitivity (95% confidence interval [CI]: 87, 96) and 7% precision (95% CI: 6, 8), and a sensitivity-and-precision–maximizing strategy, achieving 66% sensitivity (95% CI: 58, 74) and 21% precision (95% CI: 17, 25). Conclusion The developed search strategies enable users to more efficiently identify overviews of reviews compared to current strategies. Consistent language in describing overviews would aid in their identification, as would a specific \{MEDLINE\} Publication Type. "} 
}
@article{Grilli2016180,
title = {"Experience-near but not experience-far autobiographical facts depend on the medial temporal lobe for retrieval: Evidence from amnesia "},
journal = {"Neuropsychologia "},
volume = {"81"},
number = {""},
pages = {"180 - 185"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.12.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215302645"},
author = {"Matthew D. Grilli and Mieke Verfaellie"},
keywords = {"Personal semantics", "Autobiographical memory", "Self", "Semantic memory", "Episodic memory "},
abstract = {"Abstract This paper addresses the idea that there may be two types of autobiographical facts with distinct cognitive and neural mechanisms: “Experience-near” autobiographical facts, which contain spatiotemporal content derived from personal experience and thus depend on the medial temporal lobe (MTL) for retrieval, and “experience-far” autobiographical facts, which are abstract memories and thus rely on neocortical brain regions involved in retrieval of general semantic memory. To investigate this conceptual model of autobiographical fact knowledge, we analyzed the nature of autobiographical facts that were generated by 8 individuals with \{MTL\} amnesia and 12 control participants in a recent study of identity and memory [Grilli, M.D., &amp; Verfaellie, M. (2015). Supporting the self-concept with memory: insight from amnesia. Social Cognitive and Affective Neuroscience, 10, 1684–1692]. Results revealed that \{MTL\} amnesic participants generated fewer experience-near autobiographical facts than controls. Experience-far autobiographical fact generation was not impaired in amnesic participants with damage restricted to the MTL, but there was preliminary evidence to suggest that it may be impaired in amnesic participants with damage to the \{MTL\} and anterior lateral temporal lobe. These results support a cognitive and neural distinction between experience-near and experience-far autobiographical facts and have implications for understanding the contribution of autobiographical fact knowledge to self-related cognition. "} 
}
@article{Olson201653,
title = {"Altered source memory retrieval is associated with pathological doubt in obsessive–compulsive disorder "},
journal = {"Behavioural Brain Research "},
volume = {"296"},
number = {""},
pages = {"53 - 60"},
year = {"2016"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2015.08.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432815301649"},
author = {"Christy A. Olson and Lisa R. Hale and Nancy Hamilton and Joshua N. Powell and Laura E. Martin and Cary R. Savage"},
keywords = {"Obsessive–compulsive disorder", "Anxiety", "Memory", "Source", "fMRI", "Neuroimaging "},
abstract = {"Abstract Individuals with obsessive–compulsive disorder (OCD) often complain of doubt related to memory. As neuropsychological research has demonstrated that individuals with \{OCD\} tend to focus on details and miss the larger context, the construct of source (contextual) memory may be particularly relevant to memory complaints in OCD. Memory for object versus contextual information relies on partially distinct regions within the prefrontal cortex, parietal and medial temporal lobe, and may be differentially impacted by OCD. In the present study, we sought to test the hypothesis that individuals with \{OCD\} exhibit impaired source memory retrieval using a novel memory paradigm – The Memory for Rooms Test (MFRT) – a four-room memory task in which participants walk through four rooms and attempt to encode and remember objects. Demographically matched individuals with \{OCD\} and healthy controls studied objects in the context of four rooms, and then completed a memory retrieval test while undergoing functional magnetic resonance imaging (fMRI). While no differences were observed in source memory accuracy, individuals with \{OCD\} exhibited greater task related activation in the posterior cingulate cortex (PCC) relative to healthy controls during correct source memory retrieval. During correct object recognition, individuals with \{OCD\} failed to recruit the dorsolateral prefrontal(DLPFC)/premotor, left mPFC, and right parietal regions to the same extent as healthy controls. Our results suggest abnormal recruitment of frontal-parietal and \{PCC\} regions during source verses object memory retrieval in OCD. Within the \{OCD\} group, activation in the \{PCC\} and the premotor/DLPFC was associated with greater pathological doubt. This finding is consistent with the observation that \{OCD\} patients often experience extreme doubt, even when memory performance is intact. "} 
}
@article{Thürer2016172,
title = {"Increased gamma band power during movement planning coincides with motor memory retrieval "},
journal = {"NeuroImage "},
volume = {"125"},
number = {""},
pages = {"172 - 181"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2015.10.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811915009027"},
author = {"Benjamin Thürer and Christian Stockinger and Anne Focke and Felix Putze and Tanja Schultz and Thorsten Stein"},
keywords = {"Electroencephalography (EEG)", "Consolidation", "Explicit memory", "Force field", "Sensorimotor learning", "Reaching movement "},
abstract = {"Abstract The retrieval of motor memory requires a previous memory encoding and subsequent consolidation of the specific motor memory. Previous work showed that motor memory seems to rely on different memory components (e.g., implicit, explicit). However, it is still unknown if explicit components contribute to the retrieval of motor memories formed by dynamic adaptation tasks and which neural correlates are linked to memory retrieval. We investigated the lower and higher gamma bands of subjects' electroencephalography during encoding and retrieval of a dynamic adaptation task. A total of 24 subjects were randomly assigned to a treatment and control group. Both groups adapted to a force field A on day 1 and were re-exposed to the same force field A on day 3 of the experiment. On day 2, treatment group learned an interfering force field B whereas control group had a day rest. Kinematic analyses showed that control group improved their initial motor performance from day 1 to day 3 but treatment group did not. This behavioral result coincided with an increased higher gamma band power in the electrodes over prefrontal areas on the initial trials of day 3 for control but not treatment group. Intriguingly, this effect vanished with the subsequent re-adaptation on day 3. We suggest that improved re-test performance in a dynamic motor adaptation task is contributed by explicit memory and that gamma bands in the electrodes over the prefrontal cortex are linked to these explicit components. Furthermore, we suggest that the contribution of explicit memory vanishes with the subsequent re-adaptation while task automaticity increases. "} 
}
@article{McLean201673,
title = {"Nicotinic α7 and α4β2 agonists enhance the formation and retrieval of recognition memory: Potential mechanisms for cognitive performance enhancement in neurological and psychiatric disorders "},
journal = {"Behavioural Brain Research "},
volume = {"302"},
number = {""},
pages = {"73 - 80"},
year = {"2016"},
note = {""},
issn = {"0166-4328"},
doi = {"https://doi.org/10.1016/j.bbr.2015.08.037"},
url = {"http://www.sciencedirect.com/science/article/pii/S0166432815301674"},
author = {"Samantha L. McLean and Ben Grayson and Samuel Marsh and Samah H.O. Zarroug and Michael K. Harte and Jo C. Neill"},
keywords = {"Object recognition memory", "Female rat", "Delay-dependent deficits", "α7 Nicotinic receptors", "α4β2 Nicotinic receptors "},
abstract = {"Abstract Cholinergic dysfunction has been shown to be central to the pathophysiology of Alzheimer’s disease and has also been postulated to contribute to cognitive dysfunction observed in various psychiatric disorders, including schizophrenia. Deficits are found across a number of cognitive domains and in spite of several attempts to develop new therapies, these remain an unmet clinical need. In the current study we investigated the efficacy of donepezil, risperidone and selective nicotinic α7 and α4β2 receptor agonists to reverse a delay-induced deficit in recognition memory. Adult female Hooded Lister rats received drug treatments and were tested in the novel object recognition (NOR) task following a 6 h inter-trial interval (ITI). In all treatment groups, there was no preference for the left or right identical objects in the acquisition trial. Risperidone failed to enhance recognition memory in this paradigm whereas donepezil was effective such that rats discriminated between the novel and familiar object in the retention trial following a 6 h ITI. Although a narrow dose range of PNU-282987 and RJR-2403 was tested, only one dose of each increased recognition memory, the highest dose of PNU-282987 (10 mg/kg) and the lowest dose of RJR-2403 (0.1 mg/kg), indicative of enhanced cognitive performance. Interestingly, these compounds were also efficacious when administered either before the acquisition or the retention trial of the task, suggesting an important role for nicotinic receptor subtypes in the formation and retrieval of recognition memory. "} 
}
@article{McColl201631,
title = {"Triple collocation for binary and categorical variables: Application to validating landscape freeze/thaw retrievals "},
journal = {"Remote Sensing of Environment "},
volume = {"176"},
number = {""},
pages = {"31 - 42"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2016.01.010"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425716300104"},
author = {"Kaighin A. McColl and Alexandre Roy and Chris Derksen and Alexandra G. Konings and Seyed Hamed Alemohammed and Dara Entekhabi"},
keywords = {"Triple collocation", "Freeze/thaw classification", "SMAP", "Aquarius "},
abstract = {"Abstract Triple collocation (TC) can be used to validate observations of a continuous geophysical target variable when the error-free true value is not known. However, as we show in this study, naïve application of \{TC\} to categorical target variables results in biased error estimates. The bias occurs because the categorical variable is usually bounded, introducing correlations between the errors and the truth, violating TC's assumptions. We introduce Categorical Triple Collocation (CTC), a variant of \{TC\} that relaxes these assumptions and may be applied to categorical target variables. The method estimates the rankings of the three measurement systems for each category with respect to their balanced accuracies (a binary-variable performance metric). As an example application, we estimate performance rankings of landscape freeze/thaw (FT) observations derived from model soil temperatures, in-situ station air temperatures and satellite-observed microwave brightness temperatures in Alberta and Saskatchewan, Canada. While rankings vary spatially, in most locations the model-based \{FT\} product is ranked the highest, followed by the satellite product and the in-situ air temperature product. These rankings are likely due to a combination of differences in measurement errors between \{FT\} products, and differences in scale. They illustrate the value in using a suite of different measurements as part of satellite \{FT\} validation, rather than simply treating in-situ measurements as an error-free ‘truth’. "} 
}
@article{Dubois2016228,
title = {"Building detection and building parameter retrieval in InSAR phase images "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"114"},
number = {""},
pages = {"228 - 241"},
year = {"2016"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2016.02.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271616000526"},
author = {"Clémence Dubois and Antje Thiele and Stefan Hinz"},
keywords = {"High-resolution spaceborne interferometry", "InSAR phase images", "Layover areas", "Phase detector", "Building detection", "Building parameters "},
abstract = {"Abstract The high resolution provided by the current satellite \{SAR\} missions makes them an attractive solution for the detailed analysis of urban areas. Especially due to their weather and daylight independency, they can be employed when optical sensors come to their limits. Due to the specific oblique side-looking configuration of such \{SAR\} sensors, phenomena such as layover, double bounce and shadow appear at building location, which can be better understood with very high resolution (VHR) \{SAR\} data. The detection of those areas, as well as the retrieval of building parameters through a detailed analysis of the extracted structures, is a challenging task. Indeed, depending on the acquisition configuration, on building material and surroundings, those patterns are not always consistent in amplitude \{SAR\} images. They can be difficult to recognize and distinguish automatically. Considering InSAR phase images instead of amplitude images is very helpful for this task, as InSAR is more depending on the geometry. Therefore, in this paper, we focus on the detection and extraction of building layover in InSAR phase images. Two complementing detectors are proposed, and their results are combined, in order to provide reliable building hypotheses. Based on the extracted segments, further analysis is conducted. Especially, the number of connected facades is analyzed. Characteristically geometrical shapes are finally fitted for each facade to permit the determination of the final building parameters as length, width, and height. Results of this approach are shown for three different datasets, first in terms of correctness and completeness of the extraction, and second in terms of accuracy of the extracted building parameters. For the considered datasets, the completeness and correctness are of about 70% and 90%, respectively. Eliminating clear outliers, the determined parameters present an accuracy up to 4 m (length), 2 m (height) and 3 ° (orientation). In this article isolated, middle to high rise buildings with flat roof and rectangular shape are considered. "} 
}
@article{He2016161,
title = {"Spatial distribution of aerosol hygroscopicity and its effect on PM2.5 retrieval in East China "},
journal = {"Atmospheric Research "},
volume = {"170"},
number = {""},
pages = {"161 - 167"},
year = {"2016"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2015.11.011"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809515003828"},
author = {"Qianshan He and Guangqiang Zhou and Fuhai Geng and Wei Gao and Wei Yu"},
keywords = {"Hygroscopicity", "Aerosol", "Spatial distribution", "PM2.5", "East China "},
abstract = {"Abstract The hygroscopic properties of aerosol particles have strong impact on climate as well as visibility in polluted areas. Understanding of the scattering enhancement due to water uptake is of great importance in linking dry aerosol measurements with relevant ambient measurements, especially for satellite retrievals. In this study, an observation-based algorithm combining meteorological data with the particulate matter (PM) measurement was introduced to estimate spatial distribution of indicators describing the integrated humidity effect in East China and the main factors impacting the hygroscopicity were explored. Investigation of 1 year data indicates that the larger mass extinction efficiency αext values (&gt; 9.0 m2/g) located in middle and northern Jiangsu Province, which might be caused by particulate organic material (POM) and sulfate aerosol from industries and human activities. The high level of \{POM\} in Jiangsu Province might also be responsible for the lower growth coefficient γ value in this region. For the inland junction provinces of Jiangsu and Anhui, a considerable higher hygroscopic growth region in East China might be attributed to more hygroscopic particles mainly comprised of inorganic salts (e.g., sulfates and nitrates) from several large-scale industrial districts distributed in this region. Validation shows good agreement of calculated PM2.5 mass concentrations with in situ measurements in most stations with correlative coefficients of over 0.85, even if several defective stations induced by station location or seasonal variation of aerosol properties in this region. This algorithm can be used for more accurate surface level PM2.5 retrieval from satellite-based aerosol optical depth (AOD) with combination of the vertical correction for aerosol profile. "} 
}
@article{MoncadaHernández2014106,
title = {"Cómo realizar una búsqueda de información eficiente. Foco en estudiantes, profesores e investigadores en el área educativa "},
journal = {"Investigación en Educación Médica "},
volume = {"3"},
number = {"10"},
pages = {"106 - 115"},
year = {"2014"},
note = {""},
issn = {"2007-5057"},
doi = {"https://doi.org/10.1016/S2007-5057(14)72734-6"},
url = {"http://www.sciencedirect.com/science/article/pii/S2007505714727346"},
author = {"Sandra Guillermina Moncada-Hernández"},
keywords = {"Estrategias de búsqueda", "búsqueda de información", "habilidades en la búsqueda de información", keywords =recuperación de información", "investigación educativa", "México", "Search strategies", "retrieval information", "information seeking", "information skills", "educational research", "Mexico "},
abstract = {"Abstract A large percentage of students and professors from the Biomedical field use Google as their first option of information source whenever an academic question emerges. On the other hand, only 40% of searches performed by physicians to solve clinical issues result in a correct information. The aim of this document was to provide the basis for Information Search (IS) and the acquisition of abilities to obtain selective, significant, and pertinent information in an efficient and critical way. Also, to identify information sources relative to the Biomedical field. To achieve this, three groups of \{IS\} users were proposed: 1) Students and Professors, 2) Clinical Professionals, and 3) Researchers. The purpose being to build a search methodology and identify information sources according to each group needs. A six-phase process was proposed for an efficient information search: closing on the subject, question presentation, strategy elaboration, choice of information sources, option to limit the search, and the organization, administration and use of the information. These involves the development of the most important abilities for IS. \{IS\} entails a dynamic process. As necessary abilities are developed to guarantee a successful process, the skill to “proceed from information to knowledge” will be achieved. The ability to formulate questions and elaborate search strategies to obtain the best evidence as well as a critical evaluation is an essential skill to support decision-making, elaboration of reference frames, and update the teaching-learning process. The academic community should get to know and use library services, especially nowadays since controlled teaching trends imply students be more self-regulated and independent. "} 
}
@article{Biaz20143598,
title = {"Informational Strategies and the use of Information Systems by Doctoral Students: A Case Study at the University of Hassan \{II\} Mohammedia, Casablanca "},
journal = {"Procedia - Social and Behavioral Sciences "},
volume = {"116"},
number = {""},
pages = {"3598 - 3604"},
year = {"2014"},
note = {"5th World Conference on Educational Sciences "},
issn = {"1877-0428"},
doi = {"https://doi.org/10.1016/j.sbspro.2014.01.809"},
url = {"http://www.sciencedirect.com/science/article/pii/S187704281400826X"},
author = {"Abdelouahed Biaz and Ahmed Bennamara and Abderrahim Khyati and Mohammed Talbi"},
keywords = {"Informational Strategies", "Information system", "information retrieval", "information literacy "},
abstract = {"Abstract Technological revolutions, centred on information, transform the traditional models of our society at an ever increasing pace generating a proliferation of information resources, and the emergence of new systems of communication founded on convergence with other technologies. As these technologies produce benefits for users, new ways to transmit knowledge have also created problems.In the research field, the scientific community has become aware that access to information is an integral part of research activity. Therefore, it is important to study the forms, processes and strategies in accessing information during research conducted by PhD students at the University of Hassan \{II\} Mohammedia - Casablanca, together with any difficulties encountered by these students. "} 
}
@article{Cheng201674,
title = {"Development of a mobile app for generating creative ideas based on exploring designers' on-line resource searching and retrieval behavior "},
journal = {"Design Studies "},
volume = {"44"},
number = {""},
pages = {"74 - 99"},
year = {"2016"},
note = {""},
issn = {"0142-694X"},
doi = {"https://doi.org/10.1016/j.destud.2016.02.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0142694X16000132"},
author = {"Pei-Jung Cheng"},
keywords = {"design cognition", "design behavior", "ideation", "software design "},
abstract = {"This study explored the keyword thinking and searching habits of 24 design students and, on the basis of the research outcomes, developed an app for generating creative ideas (AGCI). Thirty practicing designers tested the app, and the retrospective interview results and feedback were used as criteria for modifying the app. This study assigned seven codes to behaviors observed in video recordings of each designer's ideation, and investigated the connections between the seven types of behaviors and the modes of associating words and images to be used as design concepts in developing the \{AGCI\} interface prototype. In addition, lateral thinking mode was found related to the designers' idea writing behavior, which could assist them in developing idea sketches further. "} 
}
@article{LakshmiTulasi2016148,
title = {"Ontology- Based Annotation for Semantic Multimedia Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"92"},
number = {""},
pages = {"148 - 154"},
year = {"2016"},
note = {"2nd International Conference on Intelligent Computing, Communication &amp; Convergence, \{ICCC\} 2016, 24-25 January 2016, Bhubaneswar, Odisha, India "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.07.339"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916315861"},
author = {"R. Lakshmi Tulasi and M. Srinivasa Rao and K. Usha and R.H. Goudar"},
keywords = {"Video Annotation", "Ontology", "Multimedia", "Feature Extraction ; "},
abstract = {"Abstract Numerous educational video lectures, \{CCTV\} surveillance, transport and other types have upgraded the impact of multimedia video content. In order to make large video databases realistic, video data has to be automatically indexed in order to search and retrieve relevant material. An annotation is a markup reference made to data in video in order to improve the video accessibility. Video annotation is used to examine the massive quantity of multimedia data in the repositories. Video annotation refers to the taking out of significant data present in video and placing this data to the video can benefit in “retrieval, browsing, analysis, searching comparison and categorization”. Video annotation implies taking out of data and to attach such metadata to the video which will “accelerate the retrieval speed, ease of access, analysis and categorization”. It permits fast and better understanding of video content and improves the performance of retrieval and decreases human time &amp; efforts for better study of videos. Video annotation is imperative technique that assists in video access. Proposed system provides effortless access to the data of the video and decrease the time necessary to access and evaluate the video. Ontology-based video annotation helps the user to get the semantic information from video, which is essential to search the needful data from a video. "} 
}
@article{Kappel201642,
title = {"Multi-spectrum retrieval of Venus \{IR\} surface emissivity maps from VIRTIS/VEX nightside measurements at Themis Regio "},
journal = {"Icarus "},
volume = {"265"},
number = {""},
pages = {"42 - 62"},
year = {"2016"},
note = {""},
issn = {"0019-1035"},
doi = {"https://doi.org/10.1016/j.icarus.2015.10.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0019103515004807"},
author = {"David Kappel and Gabriele Arnold and Rainer Haus"},
keywords = {"Venus, surface", "Infrared observations", "Radiative transfer "},
abstract = {"Abstract Surface emissivity maps in the infrared can contribute to explore Venus’ geology. Nightside radiance spectra at Themis Regio acquired by the \{IR\} mapping channel of the Visible and InfraRed Thermal Imaging Spectrometer (VIRTIS-M-IR) aboard Venus \{EXpress\} (VEX) are used to derive emissivity data from the three accessible spectral surface windows at 1.02, 1.10, and 1.18 μm. The measured spectra are simulated by applying a full radiative transfer model. Neglecting geologic activity, a multi-spectrum retrieval algorithm is utilized to determine the emissivity maps of the surface target as parameter vectors that are common to many spectrally resolved images that cover this target. Absolute emissivity values are difficult to obtain due to strong interferences from other parameters. The true emissivity mean of the target cannot be retrieved, nor can the emissivity mean of a retrieved map be strictly preset. The retrieved map can exhibit trends with latitude and topography that are probably artificial. Once the trends have been removed in a post-processing step, it can be observed that the magnitude of the resulting spatial emissivity fluctuations around their mean value increases with increasing mean value. A linear transformation is applied that converts the de-trended map to exhibit a defined emissivity mean value called reference emissivity, here 0.5, yielding the ‘renormalized emissivity map’ with accordingly transformed fluctuations. It is verified that renormalized emissivity maps are largely independent of the emissivity mean before renormalization, of modifications to interfering atmospheric, surface, and instrumental parameters, and of selected details of the retrieval pipeline and data calibration and preprocessing. Extremely large emissivity retrieval errors due to imperfect or unconsidered forward model parameters are effectively avoided. If the absolute emissivity at a given bin of the target were known, the absolute emissivity map of the entire target could be computed according to the mentioned transformation, assuming absent true trends with latitude and topography. Until then, the renormalized emissivities are interpreted as spatial variations relative to the reference emissivity. They represent an important step toward the retrieval of absolute emissivities. Renormalized emissivity maps of Themis Regio at the three surface windows are determined from 64 measurement repetitions. Retrieval errors are estimated by a statistical evaluation of maps derived from various disjoint selections of spectra and using different assumptions on the interfering parameters. Double standard deviation errors for the three surface windows amount to 3%, 8%, and 4%, respectively, allowing geologic interpretation. A comparison to results from an earlier error analysis based on synthetic spectra shows that unconsidered time variations of interfering atmospheric parameters are a major error source. Spatial variations of the 1.02 μm surface emissivity of 20% that correspond to the difference between unweathered granitic and basaltic rocks would be easily detectable, but such variations are ruled out for the studied target area. Emissivity anomalies of up to 8% are detected at both 1.02 and 1.18 μm. At present sensitivity, no anomalies are identified at 1.10 μm, but anomalies exceeding the determined error level can be excluded. With single standard deviation significance, all three maps show interesting spatial emissivity variations. "} 
}
@article{Meng2016141,
title = {"Similar image retrieval only using one image "},
journal = {"Optik - International Journal for Light and Electron Optics "},
volume = {"127"},
number = {"1"},
pages = {"141 - 144"},
year = {"2016"},
note = {""},
issn = {"0030-4026"},
doi = {"https://doi.org/10.1016/j.ijleo.2015.10.041"},
url = {"http://www.sciencedirect.com/science/article/pii/S0030402615013960"},
author = {"Xin Meng and Yu An and Jinghan He and Zengqing Zhuo and Hao Wu and Xing Gao"},
keywords = {"Deep learning", "WLS filter", "Image optimization", "Image decomposition "},
abstract = {"Abstract In this paper, we present one method that can retrieve the similar images only using one image. In recent years, we have used different ways to achieve image retrieval. However, if we use the unsupervised method to achieve image retrieval, the accuracy of image retrieval is reduced obviously. Even if we use the supervised method, the computing time is too long because we need to learn quite a few learning instances. We use best feature descriptor selected, image optimization, deep learning technique to retrieve the target images that is similar to original image. On the one hand, we can see that the method makes full use of image information and select the most effective feature descriptors. On the other hand, we increase the accuracy through optimizing the target images and deep learning technique, so that it is convenient for us to extract more effective information directly. At last, we set up one big database that contains images from different categories. The images are as more complicated as possible. The experimental results show that our method not only can save the computing resource but also can keep the accuracy. "} 
}
@incollection{Blummer201411,
title = {"2 - Information research and the search process "},
editor = {"Blummer, Barbara  and Kenton, Jeffrey M. "},
booktitle = {"Improving Student Information Search "},
publisher = {"Chandos Publishing"},
edition = {""},
address = {""},
year = {"2014"},
pages = {"11 - 21"},
isbn = {"978-1-84334-781-1"},
doi = {"https://doi.org/10.1533/9781780634623.11"},
url = {"http://www.sciencedirect.com/science/article/pii/B9781843347811500025"},
author = {"Barbara Blummer and Jeffrey M. Kenton"},
keywords = {"information models", "information search process", "information search difficulties", "problem solving", "users’ uncertainties", "behavior", "retrieval systems "},
abstract = {"Abstract: Information professionals may question the effectiveness of a metacognitive scaffold for enhancing users’ search capabilities. Information research is utilized to document the difficulties users encounter during the search process as well as the cognitive and metacognitive aspect of information search. The literature contained references to individuals’ use of metacognitive strategies in information search for planning strategies, differentiating among sources, monitoring the process, and evaluating results. Still, studies underscored deficiencies in the user as well as the process that impeded their information-seeking activities. Theorists also described efforts to support users’ information search including librarians’ awareness of user strategies as well as improvements in search interfaces and database design. Authors failed to consider the role of metacognition in enhancing individuals’ information search. "} 
}
@article{Iqbal2016413,
title = {"An efficient image retrieval scheme for colour enhancement of embedded and distributed surveillance images "},
journal = {"Neurocomputing "},
volume = {"174, Part A"},
number = {""},
pages = {"413 - 430"},
year = {"2016"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.03.120"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215012539"},
author = {"Kashif Iqbal and Michael Odetayo and Anne James and Rahat Iqbal and Neeraj Kumar and Shovan Barma"},
keywords = {"Surveillance images", "Image enhancement", "Colour", "Texture and shape features "},
abstract = {"Abstract From the past few years, the size of the data grows exponentially with respect to volume, velocity, and dimensionality due to wide spread use of embedded and distributed surveillance cameras for security reasons. In this paper, we have proposed an integrated approach for biometric-based image retrieval and processing which addresses the two issues. The first issue is related to the poor visibility of the images produced by the embedded and distributed surveillance cameras, and the second issue is concerned with the effective image retrieval based on the user query. This paper addresses the first issue by proposing an integrated image enhancement approach based on contrast enhancement and colour balancing methods. The contrast enhancement method is used to improve the contrast, while the colour balancing method helps to achieve a balanced colour. Importantly, in the colour balancing method, a new process for colour cast adjustment is introduced which relies on statistical calculation. It adjusts the colour cast and maintains the luminance of the image. The integrated image enhancement approach is applied to the enhancement of low quality images produced by surveillance cameras. The paper addresses the second issue relating to image retrieval by proposing a content-based image retrieval approach. The approach is based on the three features extraction methods namely colour, texture and shape. Colour histogram is used to extract the colour features of an image. Gabor filter is used to extract the texture features and the moment invariant is used to extract the shape features of an image. The use of these three algorithms ensures that the proposed image retrieval approach produces results which are highly relevant to the content of an image query, by taking into account the three distinct features of the image and the similarity metrics based on Euclidean measure. In order to retrieve the most relevant images, the proposed approach also employs a set of fuzzy heuristics to improve the quality of the results further. The results show the proposed approaches perform better than the well-known existing approaches. "} 
}
@article{Hsieh201578,
title = {"Cortical and subcortical contributions to sequence retrieval: Schematic coding of temporal context in the neocortical recollection network "},
journal = {"NeuroImage "},
volume = {"121"},
number = {""},
pages = {"78 - 90"},
year = {"2015"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2015.07.040"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811915006515"},
author = {"Liang-Tien Hsieh and Charan Ranganath"},
keywords = {"fMRI", "Recollection network", "Default network", "Temporal context", "Sequence "},
abstract = {"Abstract Episodic memory entails the ability to remember what happened when. Although the available evidence indicates that the hippocampus plays a role in structuring serial order information during retrieval of event sequences, information processed in the hippocampus must be conveyed to other cortical and subcortical areas in order to guide behavior. However, the extent to which other brain regions contribute to the temporal organization of episodic memory remains unclear. Here, we examined multivoxel activity pattern changes during retrieval of learned and random object sequences, focusing on a neocortical “core recollection network” that includes the medial prefrontal cortex, retrosplenial cortex, and angular gyrus, as well as on striatal areas including the caudate nucleus and putamen that have been implicated in processing of sequence information. The results demonstrate that regions of the core recollection network carry information about temporal positions within object sequences, irrespective of object information. This schematic coding of temporal information is in contrast to the putamen, which carried information specific to objects in learned sequences, and the caudate, which carried information about objects, irrespective of sequence context. Our results suggest a role for the cortical recollection network in the representation of temporal structure of events during episodic retrieval, and highlight the possible mechanisms by which the striatal areas may contribute to this process. More broadly, the results indicate that temporal sequence retrieval is a useful paradigm for dissecting the contributions of specific brain regions to episodic memory. "} 
}
@article{Hampstead2016997,
title = {"Patterns of effective connectivity during memory encoding and retrieval differ between patients with mild cognitive impairment and healthy older adults "},
journal = {"NeuroImage "},
volume = {"124, Part A"},
number = {""},
pages = {"997 - 1008"},
year = {"2016"},
note = {""},
issn = {"1053-8119"},
doi = {"https://doi.org/10.1016/j.neuroimage.2015.10.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S1053811915008964"},
author = {"B.M. Hampstead and M. Khoshnoodi and W. Yan and G. Deshpande and K. Sathian"},

abstract = {"Abstract Previous research has shown that there is considerable overlap in the neural networks mediating successful memory encoding and retrieval. However, little is known about how the relevant human brain regions interact during these distinct phases of memory or how such interactions are affected by memory deficits that characterize mild cognitive impairment (MCI), a condition that often precedes dementia due to Alzheimer's disease. Here we employed multivariate Granger causality analysis using autoregressive modeling of inferred neuronal time series obtained by deconvolving the hemodynamic response function from measured blood oxygenation level-dependent (BOLD) time series data, in order to examine the effective connectivity between brain regions during successful encoding and/or retrieval of object location associations in \{MCI\} patients and comparable healthy older adults. During encoding, healthy older adults demonstrated a left hemisphere dominant pattern where the inferior frontal junction, anterior intraparietal sulcus (likely involving the parietal eye fields), and posterior cingulate cortex drove activation in most left hemisphere regions and virtually every right hemisphere region tested. These regions are part of a frontoparietal network that mediates top-down cognitive control and is implicated in successful memory formation. In contrast, in the \{MCI\} patients, the right frontal eye field drove activation in every left hemisphere region examined, suggesting reliance on more basic visual search processes. Retrieval in the healthy older adults was primarily driven by the right hippocampus with lesser contributions of the right anterior thalamic nuclei and right inferior frontal sulcus, consistent with theoretical models holding the hippocampus as critical for the successful retrieval of memories. The pattern differed in \{MCI\} patients, in whom the right inferior frontal junction and right anterior thalamus drove successful memory retrieval, reflecting the characteristic hippocampal dysfunction of these patients. These findings demonstrate that neural network interactions differ markedly between \{MCI\} patients and healthy older adults. Future efforts will investigate the impact of cognitive rehabilitation of memory on these connectivity patterns. "} 
}
@article{Konings2016178,
title = {"Vegetation optical depth and scattering albedo retrieval using time series of dual-polarized L-band radiometer observations "},
journal = {"Remote Sensing of Environment "},
volume = {"172"},
number = {""},
pages = {"178 - 189"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.11.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S003442571530198X"},
author = {"Alexandra G. Konings and María Piles and Kathrina Rötzer and Kaighin A. McColl and Steven K. Chan and Dara Entekhabi"},
keywords = {"Vegetation optical depth", "Single-scattering albedo", "Soil dielectric constant", "Soil moisture", "Vegetation water content", "L-band radiometry", "Aquarius/SAC-D", "SMAP "},
abstract = {"Abstract Passive microwave measurements have the potential to estimate vegetation optical depth (VOD), an indicator of aboveground vegetation water content. They are also sensitive to the vegetation scattering albedo and soil moisture. In this work, we propose a novel algorithm to retrieve \{VOD\} and soil moisture from time series of dual-polarized L-band radiometric observations along with time-invariant scattering albedo. The method takes advantage of the relatively slow temporal dynamics of early morning vegetation water content and combines a number of consecutive observations to estimate a single VOD. It is termed the multi-temporal dual channel algorithm (MT-DCA). The soil dielectric constant (directly related to soil moisture) of each observation is also retrieved simultaneously. Additionally, the method retrieves a constant albedo, thereby providing for the first time information on global single-scattering albedo variations. The algorithm is tested using three years of L-band passive observations from the \{NASA\} Aquarius sensor. The global \{VOD\} distribution follows expected gradients of climate and canopy biomass conditions. Its seasonal dynamics follow expected behavior based on precipitation and land cover. The retrieved \{VOD\} is closely related to coincident cross-polarized backscatter coefficients. The \{VOD\} and dielectric retrievals from MT-DCA are compared to those obtained from implementing the commonly used Land Parameter Retrieval Model (LPRM) algorithm and shown to have less high-frequency noise. There is almost as much variation in MT-DCA retrieved albedo between pixels of a given land cover class than between land cover classes, suggesting the common approach of assigning albedo based on land cover class may not capture its spatial variability. Globally, albedo appears to be primarily sensitive to woody biomass. The proposed algorithm allows for a more accurate accounting of the effects of vegetation on radiometric soil moisture retrievals, and generates new observations of L-band \{VOD\} and effective single-scattering albedo. These new datasets are complementary to existing remotely sensed vegetation measurements such as fluorescence and optical-infrared indices. "} 
}
@article{Kalyvas201736,
title = {"A survey of official online sources of high-quality free-of-charge geospatial data for maritime geographic information systems applications "},
journal = {"Information Systems "},
volume = {"65"},
number = {""},
pages = {"36 - 51"},
year = {"2017"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2016.11.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437916304185"},
author = {"Christos Kalyvas and Athanasios Kokkos and Theodoros Tzouramanis"},
keywords = {"Maritime geographic information science and systems (GIS)", "Research and development", "GIS education", "Maritime data technology and applications", "Worldwide seas coverage of real-world high-precision maritime data "},
abstract = {"Abstract Maritime information systems are innovative geographic information systems for study, monitoring and action-taking in maritime areas. They respond to needs in the development of intelligent systems for applications such as scientific research and safety (monitoring the global ecosystem, the atmosphere, the oceans, the biosphere, ice fields, fish populations etc.) or the support of the maritime industry and its related organizations (tracking the position of vessels in motion, providing them with safe routing etc.). For these systems to efficiently handle the complex demands made on such specialized applications, up-to-date real-world data purchased or downloaded from official, trustworthy online data sources is needed. This article examines geospatial free-of-charge data sources and discusses the various classes of available data. Several hundred resources and their available datasets were empirically tested and their quality and usefulness verified, producing a selective thesaurus. An accompanying website summarizing useful available information about the data sources and datasets also includes information which could not be mentioned in the article. The survey, covering a wide spectrum of online information regarding up-to-date sources for genuine valuable real-world high-precision maritime data worldwide, is, to the best of the authors’ knowledge, the only one of its kind at the time of writing. "} 
}
@article{Seetharaman2016110,
title = {"A unified learning framework for content based medical image retrieval using a statistical model "},
journal = {"Journal of King Saud University - Computer and Information Sciences "},
volume = {"28"},
number = {"1"},
pages = {"110 - 124"},
year = {"2016"},
note = {""},
issn = {"1319-1578"},
doi = {"https://doi.org/10.1016/j.jksuci.2014.10.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S1319157815000889"},
author = {"K. Seetharaman and S. Sathiamoorthy"},
keywords = {"Full Range Autoregressive Model", "Bayesian approach", "Color autocorrelogram", "Edge orientation autocorrelogram", "Micro-textures", "Relevance feedback "},
abstract = {"Abstract This paper presents a unified learning framework for heterogeneous medical image retrieval based on a Full Range Autoregressive Model (FRAR) with the Bayesian approach (BA). Using the unified framework, the color autocorrelogram, edge orientation autocorrelogram (EOAC) and micro-texture information of medical images are extracted. The \{EOAC\} is constructed in \{HSV\} color space, to circumvent the loss of edges due to spectral and chromatic variations. The proposed system employed adaptive binary tree based support vector machine (ABTSVM) for efficient and fast classification of medical images in feature vector space. The Manhattan distance measure of order one is used in the proposed system to perform a similarity measure in the classified and indexed feature vector space. The precision and recall (PR) method is used as a measure of performance in the proposed system. Short-term based relevance feedback (RF) mechanism is also adopted to reduce the semantic gap. The Experimental results reveal that the retrieval performance of the proposed system for heterogeneous medical image database is better than the existing systems at low computational and storage cost. "} 
}
@article{Fascetti2016135,
title = {"A comparison of \{ASCAT\} and \{SMOS\} soil moisture retrievals over Europe and Northern Africa from 2010 to 2013 "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"45, Part B"},
number = {""},
pages = {"135 - 142"},
year = {"2016"},
note = {"Advances in the Validation and Application of Remotely Sensed Soil Moisture - Part 1 "},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2015.09.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243415300313"},
author = {"Fabio Fascetti and Nazzareno Pierdicca and Luca Pulvirenti and Raffaele Crapolicchio and J. Muñoz-Sabater"},
keywords = {"Remote sensing", "SMOS", "ASCAT", "Soil moisture "},
abstract = {"Abstract A comparison between ASCAT/H-SAF and \{SMOS\} soil moisture products was performed in the frame of the \{EUMETSAT\} H-SAF project. The analysis was extended to the whole H-SAF region of interest, including Europe and North Africa, and the period between January 2010 and November 2013 was considered. Since \{SMOS\} and \{ASCAT\} soil moisture data are expressed in terms of absolute and relative values, respectively, different approaches were adopted to scale \{ASCAT\} data to use the same volumetric soil moisture unit. Effects of land cover, quality index filtering, season and geographical area on the matching between the two products were also analyzed. The two satellite retrievals were also compared with other independent datasets, namely the NCEP/NCAR volumetric soil moisture content reanalysis developed by \{NOAA\} and the ERA-Interim/Land soil moisture produced by ECMWF. In situ data, available through the International Soil Moisture Network, were also considered as benchmark. The results turned out to be influenced by the way \{ASCAT\} data was scaled. Correlation between the two products exceeded 0.6, while the root mean square difference did not decrease below 8%. \{ASCAT\} generally showed a fairly good degree of correlation with ERA, while, as expected considering the different kinds of measurement, the discrepancies with respect to local in situ data were large for both satellite products. "} 
}
@article{FernandezMoran2015269,
title = {"Roughness and vegetation parameterizations at L-band for soil moisture retrievals over a vineyard field "},
journal = {"Remote Sensing of Environment "},
volume = {"170"},
number = {""},
pages = {"269 - 279"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.09.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715301292"},
author = {"R. Fernandez-Moran and J.-P. Wigneron and E. Lopez-Baeza and A. Al-Yaari and A. Coll-Pajaron and A. Mialon and M. Miernecki and M. Parrens and P.M. Salgado-Hernanz and M. Schwank and S. Wang and Y.H. Kerr"},
keywords = {"Microwave radiometry", "L-band", "Soil moisture", "Soil roughness", "Vegetation", "L-MEB", "SMOS "},
}
@article{Lin201676,
title = {"Abundance retrieval of hydrous minerals around the Mars Science Laboratory landing site in Gale crater, Mars "},
journal = {"Planetary and Space Science "},
volume = {"121"},
number = {""},
pages = {"76 - 82"},
year = {"2016"},
note = {""},
issn = {"0032-0633"},
doi = {"https://doi.org/10.1016/j.pss.2015.12.007"},
url = {"http://www.sciencedirect.com/science/article/pii/S0032063315003682"},
author = {"Honglei Lin and Xia Zhang and Tong Shuai and Lifu Zhang and Yanli Sun"},
keywords = {"Mars surface", "Hydrous mineral", "Spectroscopy", "Spectral unmixing", "Hyperspectral remote sensing "},
abstract = {"Abstract The detection of hydrous minerals on Mars is of great importance for revealing the early water environment as well as possible biotic activity. However, few studies focus on abundance retrieval of hydrous minerals for some difficulties. In this paper, we studied the area around the Mars Science Laboratory (MSL) landing site, to identify hydrous minerals and retrieve their abundance. Firstly, the distribution of hydrous minerals was extracted using their hydration features. Then, a sparse unmixing algorithm was applied along with the \{CRISM\} spectral library to retrieve the abundance of hydrous minerals in this area. As a result, seven hydrous minerals were retrieved, i.e. actinolite, montmorillonite, saponite, jarosite, halloysite, szomolnokite and magnesite and, the total concentration of all hydrous minerals was as high as 40 vol% near the lower reaches of Mount Sharp. Our results were consistent with results from related research and the in-situ analysis of the \{MSL\} rover Curiosity. "} 
}
@article{Rossato2015146,
title = {"Inactivation of the dorsal hippocampus or the medial prefrontal cortex impairs retrieval but has differential effect on spatial memory reconsolidation "},
journal = {"Neurobiology of Learning and Memory "},
volume = {"125"},
number = {""},
pages = {"146 - 151"},
year = {"2015"},
note = {""},
issn = {"1074-7427"},
doi = {"https://doi.org/10.1016/j.nlm.2015.09.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1074742715001707"},
author = {"Janine I. Rossato and Cristiano A. Köhler and Andressa Radiske and Lia R.M. Bevilaqua and Martín Cammarota"},
keywords = {"Anisomycin", "Muscimol", "Recall", "Reactivation", "Memory", "Water maze "},
abstract = {"Abstract Active memories can incorporate new information through reconsolidation. However, the notion that memory retrieval is necessary for reconsolidation has been recently challenged. Non-reinforced retrieval induces hippocampus and medial prefrontal cortex (mPFC)-dependent reconsolidation of spatial memory in the Morris water maze (MWM). We found that the effect of protein synthesis inhibition on this process is abolished when retrieval of the learned spatial preference is hindered through mPFC inactivation but not when it is blocked by deactivation of dorsal CA1. Our results do not fully agree with the hypothesis that retrieval is unneeded for reconsolidation. Instead, they support the idea that a hierarchic interaction between the hippocampus and the mPFC controls spatial memory in the MWM, and indicate that this cortex is sufficient to retrieve the information essential to reconsolidate the spatial memory trace, even when the hippocampus is inactivated. "} 
}
@incollection{Harrington2016323,
title = {"Chapter 16 - Simple \{SQL\} Retrieval "},
editor = {"Harrington, Jan L. "},
booktitle = {"Relational Database Design and Implementation (Fourth edition) "},
publisher = {"Morgan Kaufmann"},
edition = {"Fourth edition"},
address = {"Boston"},
year = {"2016"},
pages = {"323 - 354"},
isbn = {"978-0-12-804399-8"},
doi = {"https://doi.org/10.1016/B978-0-12-804399-8.00016-8"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128043998000168"},
author = {"Jan L. Harrington"},
keywords = {"SQL", "SQL SELECT", "SQL WHERE", "SQL predicates", "SQL operators "},
abstract = {"Abstract This chapter begins a sequence of chapters that focus on \{SQL\} retrieval statements. This chapter covers specifying columns for display, and choosing rows from one table at a time. It introduces the construction of \{SQL\} predicates using relationship operators, logical operators, and SQL’s special operators. "} 
}
@article{Liu2017255,
title = {"Information-centric mobile ad hoc networks and content routing: A survey "},
journal = {"Ad Hoc Networks "},
volume = {"58"},
number = {""},
pages = {"255 - 268"},
year = {"2017"},
note = {"Hybrid Wireless Ad Hoc Networks "},
issn = {"1570-8705"},
doi = {"https://doi.org/10.1016/j.adhoc.2016.04.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S1570870516301019"},
author = {"Xuan Liu and Zhuo Li and Peng Yang and Yongqiang Dong"},
keywords = {"Content routing", "Mobile ad hoc networks", "Named data networking", "Information centric networking "},
abstract = {"Abstract As the future Internet architecture, information centric networking(ICN) can also offer superior architectural support for mobile ad hoc networking. Therefore, information-centric mobile ad hoc networks (ICMANET), a new cross-cutting research area, is gradually forming. In the paper, we firstly introduce the current advances in \{ICN\} and analyze its development trends, and then interpret the formation of \{ICMANET\} and sketch an overview of it. Subsequently, we define a concept model for content routing and categorize the content routing into proactive, reactive and opportunistic types, and then detail the representative schemes. Finally, the existing issues are summarized. The goal of the work is to provide the references and guidelines for readers approaching study on the new area. "} 
}
@article{Chen2016146,
title = {"Orthogonal Polar V Transforms and application to shape retrieval "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"34"},
number = {""},
pages = {"146 - 152"},
year = {"2016"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.11.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315002199"},
author = {"Wei Chen and Zhanchuan Cai"},
keywords = {"V-system", "Moments", "Orthogonal piecewise polynomial", "Rotation-invariant", "Multi-scale features", "Low computational complexity", "Shape", "Perspective distortion "},
abstract = {"Abstract The traditional orthogonal moments (e.g., Zernike moments) are formulated with polynomials as their basis that often face the problem of computation difficulty especially with the high-order moments. In this paper, we present a novel set of transforms namely the Polar V Transforms (PVTs). We can use the \{PVTs\} not only to generate the rotation-invariant features but also to capture global and local information of images. Since the \{PVTs\} basis functions can keep a low order of polynomials, we can significantly speed-up the runtime for computing the kernels. The experimental results have demonstrated that our proposed method outperforms the previous methods in runtimes and achieves very good results in shape retrieval compared to the previous methods especially when the images with high degree of perspective distortions. "} 
}
@article{Nagano2016256,
title = {"Retrieval of deeply buried culturable fungi in marine subsurface sediments, Suruga-Bay, Japan "},
journal = {"Fungal Ecology "},
volume = {"20"},
number = {""},
pages = {"256 - 259"},
year = {"2016"},
note = {""},
issn = {"1754-5048"},
doi = {"https://doi.org/10.1016/j.funeco.2015.12.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1754504816000076"},
author = {"Yuriko Nagano and Masaaki Konishi and Takahiko Nagahama and Takaaki Kubota and Fumiyoshi Abe and Yuji Hatada"},
keywords = {"Aspergillus spp.", "Deep biosphere", "Deep-sea sediments", "Extreme environments", "Fungi", "Subsurface "},
abstract = {"Abstract Culturable fungal communities were investigated in marine subsurface sediment cores obtained at three different sites in Suruga Bay. Sediment core samples were examined at five different depths, namely 3 m, 12 m, 21 m, 31 m and 40 m below the seafloor (mbsf) at each site. Although the occurrence and diversity of culturable fungi in subsurface sediments appeared extremely low, fungi were successfully cultured from 5 out of 15 samples, including a sample taken from 40 m below the seafloor. The most frequently detected fungal species were Aspergillus spp. followed by Pichia and Cadophora. Two possible novel spp. belonging to the phylum Ascomycota were also isolated. Although the presence of fungi in deep subsurface environments has been suggested in some recent reports, there has been only limited information available describing the identification and diversity of culturable fungi from deep subsurface sediments. Our results provide further evidence to support that fungi persist in deep marine subsurface biospheres. Also, it was suggested that marine subsurface biospheres can be a new fungal resource. Further investigation on cultured deep subsurface fungi will provide a better understanding of the ecology and physiology of extremotolerant fungi and their potential for biotechnological application. "} 
}
@article{GarciaPiquer201512,
title = {"Toward high performance solution retrieval in multiobjective clustering "},
journal = {"Information Sciences "},
volume = {"320"},
number = {""},
pages = {"12 - 25"},
year = {"2015"},
note = {""},
issn = {"0020-0255"},
doi = {"https://doi.org/10.1016/j.ins.2015.04.041"},
url = {"http://www.sciencedirect.com/science/article/pii/S0020025515003230"},
author = {"Alvaro Garcia-Piquer and Andreu Sancho-Asensio and Albert Fornells and Elisabet Golobardes and Guiomar Corral and Francesc Teixidó-Navarro"},
keywords = {"Soft-computing", "Genetic algorithms", "Multiobjective optimization", "Clustering", "Pareto set filtering "},
abstract = {"Abstract The massive generation of unlabeled data of current industrial applications has attracted the interest of data mining practitioners. Thus, retrieving novel and useful information from these volumes of data while decreasing the costs of manipulating such amounts of information is a major issue. Multiobjective clustering algorithms are able to recognize patterns considering several objective function which is crucial in real-world situations. However, they dearth from a retrieval system for obtaining the most suitable solution, and due to the fact that the size of Pareto set can be unpractical for human experts, autonomous retrieval methods are fostered. This paper presents an automatic retrieval system for handling Pareto-based multiobjective clustering problems based on the shape of the Pareto set and the quality of the clusters. The proposed method is integrated in CAOS, a scalable and flexible framework, to test its performance. Our approach is compared to classic retrieval methods that only consider individual strategies by using a wide set of artificial and real-world datasets. This filtering approach is evaluated under large data volumes demonstrating its competence in clustering problems. Experiments support that the proposal overcomes the accuracy and significantly reduces the computational time of the solution retrieval achieved by the individual strategies. "} 
}
@article{Li2017123,
title = {"Unsupervised detection of acoustic events using information bottleneck principle "},
journal = {"Digital Signal Processing "},
volume = {"63"},
number = {""},
pages = {"123 - 134"},
year = {"2017"},
note = {""},
issn = {"1051-2004"},
doi = {"https://doi.org/10.1016/j.dsp.2016.12.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1051200417300015"},
author = {"Yanxiong Li and Qin Wang and Xianku Li and Xue Zhang and Yuhan Zhang and Aiwu Chen and Qianhua He and Qian Huang"},
keywords = {"Acoustic event detection", "Information bottleneck principle", "Audio signal processing "},
abstract = {"Abstract An unsupervised approach based on Information Bottleneck (IB) principle is proposed for detecting acoustic events from audio streams. In this paper, the \{IB\} principle is first concisely presented, and then the practical issues related to the application of \{IB\} principle to acoustic event detection are described in detail, including definitions of various variables, criterion for determining the number of acoustic events, tradeoff between amount of information preserved and compression of the initial representation, and detection steps. Further, we compare the proposed approach with both unsupervised and supervised approaches on four different types of audio files. Experimental results show that the proposed approach obtains lower detection errors and higher running speed compared to two state-of-the-art unsupervised approaches, and is little inferior to the state-of-the-art supervised approach in terms of both detection errors and runtime. The advantage of the proposed unsupervised approach over the supervised approach is that it does not need to pre-train classifiers and pre-know any prior information about audio streams. "} 
}
@article{Kim201635,
title = {"Default network activation during episodic and semantic memory retrieval: A selective meta-analytic comparison "},
journal = {"Neuropsychologia "},
volume = {"80"},
number = {""},
pages = {"35 - 46"},
year = {"2016"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.11.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215302220"},
author = {"Hongkeun Kim"},
keywords = {"Fmri", "Default mode network", "Episodic memory", "Semantic memory", "Meta-analysis "},
abstract = {"Abstract It remains unclear whether and to what extent the default network subregions involved in episodic memory (EM) and semantic memory (SM) processes overlap or are separated from one another. This study addresses this issue through a controlled meta-analysis of functional neuroimaging studies involving healthy participants. Various \{EM\} and \{SM\} task paradigms differ widely in the extent of default network involvement. Therefore, the issue at hand cannot be properly addressed without some control for this factor. In this regard, this study employs a two-stage analysis: a preliminary meta-analysis to select \{EM\} and \{SM\} task paradigms that recruit relatively extensive default network regions and a main analysis to compare the selected task paradigms. Based on a within-EM comparison, the default network contributed more to recollection/familiarity effects than to old/new effects, and based on a within-SM comparison, it contributed more to word/pseudoword effects than to semantic/phonological effects. According to a direct comparison of recollection/familiarity and word/pseudoword effects, each involving a range of default network regions, there were more overlaps than separations in default network subregions involved in these two effects. More specifically, overlaps included the bilateral posterior cingulate/retrosplenial cortex, left inferior parietal lobule, and left anteromedial prefrontal regions, whereas separations included only the hippocampal formation and the parahippocampal cortex region, which was unique to recollection/familiarity effects. These results indicate that \{EM\} and \{SM\} retrieval processes involving strong memory signals recruit extensive and largely overlapping default network regions and differ mainly in distinct contributions of hippocampus and parahippocampal regions to \{EM\} retrieval. "} 
}
@article{Doyle2016459,
title = {"Successful elective and medically indicated oocyte vitrification and warming for autologous in vitro fertilization, with predicted birth probabilities for fertility preservation according to number of cryopreserved oocytes and age at retrieval "},
journal = {"Fertility and Sterility "},
volume = {"105"},
number = {"2"},
pages = {"459 - 466.e2"},
year = {"2016"},
note = {""},
issn = {"0015-0282"},
doi = {"https://doi.org/10.1016/j.fertnstert.2015.10.026"},
url = {"http://www.sciencedirect.com/science/article/pii/S0015028215020373"},
author = {"Joseph O. Doyle and Kevin S. Richter and Joshua Lim and Robert J. Stillman and James R. Graham and Michael J. Tucker"},
keywords = {"Autologous oocyte vitrification", "fertility preservation", "live birth", "warming "},
abstract = {"Objective To evaluate a single treatment center's experience with autologous \{IVF\} using vitrified and warmed oocytes, including fertilization, embryonic development, pregnancy, and birth outcomes, and to estimate the likelihood of live birth of at least one, two, or three children according to the number of mature oocytes cryopreserved by elective fertility preservation patients. Design Retrospective cohort study. Setting Private practice clinic. Patient(s) Women undergoing autologous \{IVF\} treatment using vitrified and warmed oocytes. Indications for oocyte vitrification included elective fertility preservation, desire to limit the number of oocytes inseminated and embryos created, and lack of available sperm on the day of oocyte retrieval. Intervention(s) Oocyte vitrification, warming, and subsequent \{IVF\} treatment. Main Outcome Measure(s) Post-warming survival, fertilization, implantation, clinical pregnancy, and live birth rates. Result(s) A total of 1,283 vitrified oocytes were warmed for 128 autologous \{IVF\} treatment cycles. Postthaw survival, fertilization, implantation, and birth rates were all comparable for the different oocyte cryopreservation indications; fertilization rates were also comparable to fresh autologous intracytoplasmic sperm injection cycles (70% vs. 72%). Implantation rates per embryo transferred (43% vs. 35%) and clinical pregnancy rates per transfer (57% vs. 44%) were significantly higher with vitrified–warmed compared with fresh oocytes. However, there was no statistically significant difference in live birth/ongoing pregnancy (39% vs. 35%). The overall vitrified–warmed oocyte to live born child efficiency was 6.4%. Conclusion(s) Treatment outcomes using autologous oocyte vitrification and warming are as good as cycles using fresh oocytes. These results are especially reassuring for infertile patients who must cryopreserve oocytes owing to unavailability of sperm or who wish to limit the number of oocytes inseminated. Age-associated estimates of oocyte to live-born child efficiencies are particularly useful in providing more explicit expectations regarding potential births for elective oocyte cryopreservation. "} 
}
@article{Wirgin2016353,
title = {"Retrieval of the equivalent acoustic constitutive parameters of an inhomogeneous fluid-like object by nonlinear full waveform inversion "},
journal = {"Ultrasonics "},
volume = {"65"},
number = {""},
pages = {"353 - 369"},
year = {"2016"},
note = {""},
issn = {"0041-624X"},
doi = {"https://doi.org/10.1016/j.ultras.2015.09.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S0041624X15002280"},
author = {"Armand Wirgin"},
keywords = {"Inverse problem", "Equivalent parameters", "Biomedical imaging", "Inhomogeneous object", "Mixing formulae "},
abstract = {"Abstract This study addresses the problem of the acoustic characterization of an inhomogeneous object such as a soft-tissue organ containing a cyst or tumor whose size and/or composition evolve either negatively due to increased disease or positively due to increased response to treatment. The so-called ‘corrupted’ binary object, probed by a transient, acoustic plane wave, is a tube composed of a homogenous fluid-like (or assumed as such) mantle (medium 1: three acoustic constitutive parameters, one geometric parameter) surrounding a homogeneous fluid-like (or assumed as such) core (medium 2: three acoustic constitutive parameters, one geometric parameter), immersed in a spatially-infinite, homogeneous fluid (host medium 0: two acoustic parameters). The complete inversion of the diffracted acoustic field response of this object involves the retrieval of seven (six acoustic and one geometric) parameters, assuming we know beforehand the outer radius of the tube and acoustic parameters of the host. An alternative to this time-consuming, hazardous (due to the ill-posed nature of the) procedure, is to minimize the discrepancy, between the full waveform response of the binary object to a transient plane wave and the response of a homogeneous cylinder (medium characterized by three acoustic parameters, one geometric parameter) to the same transient plane wave, so as to retrieve the (three so-called equivalent) acoustic parameters of the homogeneous object. Thus, the first inverse problem is replaced by a second one (same assumptions concerning the outer radius of the objects, the host medium, the probe radiation and the sensing configuration as the first one) involving the retrieval of only three (instead of six) acoustic parameters. This procedure is potentially useful if the variation of at least one of the three equivalent parameters is sensitive to the variation of a key parameter of the inhomogeneous body (usually the characteristic dimension or the wavespeed of the core) and this variation can be expressed in a simple algebraic form (such as by a mixing formula). It is shown that this situation can arise if the average frequency of the acoustic probe radiation is sufficiently low. A sidelight of this investigation is the discovery that the equivalent constitutive parameters of the homogeneous cylinder are dispersive even when the component materials of the tube are not dispersive. "} 
}
@article{Kark2015221,
title = {"Effect of emotional valence on retrieval-related recapitulation of encoding activity in the ventral visual stream "},
journal = {"Neuropsychologia "},
volume = {"78"},
number = {""},
pages = {"221 - 230"},
year = {"2015"},
note = {""},
issn = {"0028-3932"},
doi = {"https://doi.org/10.1016/j.neuropsychologia.2015.10.014"},
url = {"http://www.sciencedirect.com/science/article/pii/S0028393215301925"},
author = {"Sarah M. Kark and Elizabeth A. Kensinger"},
keywords = {"Emotion", "Memory", "Recapitulation", "Ventral visual stream", "Amygdala", "FMRI "},
abstract = {"Abstract While prior work has shown greater retrieval-related reactivation in the ventral visual stream for emotional stimuli compared to neutral stimuli, the effects of valence on retrieval-related recapitulation of successful encoding processes (Dm effects) have yet to be investigated. Here, seventeen participants (aged 19–35) studied line drawings of negative, positive, or neutral images followed immediately by the complete photo. After a 20-min delay, participants performed a challenging recognition memory test, distinguishing the studied line drawing outlines from novel ones. First, results replicated earlier work by demonstrating that negative and positive hits elicited greater ventral occipito-temporal cortex (VOTC) activity than neutral hits during both encoding and retrieval. Moreover, the amount of activation in portions of the \{VOTC\} correlated with the magnitude of participants’ emotional memory enhancement. Second, results revealed significant retrieval-related recapitulation of Dm effects (Hits&gt;Misses) in \{VOTC\} (anterior inferior temporal gyri) only for negative stimuli. Third, connectivity between the amygdala and fusiform gyrus during the encoding of negative stimuli increased the likelihood of fusiform activation during successful retrieval. Together, these results suggest that recapitulation in posterior \{VOTC\} reflects memory for the affective dimension of the stimuli (Emotional Hits&gt;Neutral Hits) and the magnitude of activation in some of these regions is related to superior emotional memory. Moreover, for negative stimuli, recapitulation in more anterior portions of the \{VOTC\} is greater for remembered than forgotten items. The current study offers new evidence for effects of emotion on recapitulation of activity and functional connectivity in support of memory. "} 
}
@article{Sai2016579,
title = {"Truncated \{DCT\} and Decomposed \{DWT\} \{SVD\} Features for Image Retrieval "},
journal = {"Procedia Computer Science "},
volume = {"79"},
number = {""},
pages = {"579 - 588"},
year = {"2016"},
note = {"Proceedings of International Conference on Communication, Computing and Virtualization (ICCCV) 2016 "},
issn = {"1877-0509"},
doi = {"https://doi.org/10.1016/j.procs.2016.03.073"},
url = {"http://www.sciencedirect.com/science/article/pii/S1877050916002040"},
author = {"N.S.T. Sai and Ravindra Patil and Shailesh Sangle and Bhushan Nemade"},
keywords = {"CBIR", "DCT", "DWT", "SVD", "DCT-SVD", "DWT-SVD", "Overall Average Precision and Recall crossover point "},
abstract = {"Abstract This paper describes the comparative study of Truncated DCT-SVD and DWT-SVD. In this paper we propose two different approaches to compute the feature vector for content based image retrieval (CBIR) system. \{SVD\} feature of successively truncated \{DCT\} image and \{DWT\} decomposed image computed for grayscale image, \{RGB\} and \{YCbCrcolor\} image. Truncated \{DCT\} and \{DWT\} decomposition \{SVD\} features of the image computed up to fifth level to compare the performance. Proposed methods incorporate with the multidimensional features vector computed by using \{SVD\} of low frequency coefficients of \{DCT\} and \{DWT\} of image. Similarity between the query image and database image measured here by using simple Euclidean distance and Bray Curtis Distance. The overall average precision and average recall crossover point of each image category. Proposed methods are tested on the augmented image database. "} 
}
@article{Meyer2015205,
title = {"Frontal–posterior theta oscillations reflect memory retrieval during sentence comprehension "},
journal = {"Cortex "},
volume = {"71"},
number = {""},
pages = {"205 - 218"},
year = {"2015"},
note = {""},
issn = {"0010-9452"},
doi = {"https://doi.org/10.1016/j.cortex.2015.06.027"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010945215002397"},
author = {"Lars Meyer and Maren Grigutsch and Noura Schmuck and Phoebe Gaston and Angela D. Friederici"},
keywords = {"Sentence comprehension", "Time–frequency analysis", "Source localization", "Theta oscillations", "Verbal working memory "},
abstract = {"Abstract Successful working-memory retrieval requires that items be retained as distinct units. At the neural level, it has been shown that theta-band oscillatory power increases with the number of to-be-distinguished items during working-memory retrieval. Here we hypothesized that during sentence comprehension, verbal-working-memory retrieval demands lead to increased theta power over frontal cortex, supposedly supporting the distinction amongst stored items during verbal-working-memory retrieval. Also, synchronicity may increase between the frontal cortex and the posterior cortex, with the latter supposedly supporting item retention. We operationalized retrieval by using pronouns, which refer to and trigger the retrieval of antecedent nouns from a preceding sentence part. Retrieval demand was systematically varied by changing the pronoun antecedent: Either, it was non-embedded in the preceding main clause, and thus easy-to-retrieve across a single clause boundary, or embedded in the preceding subordinate clause, and thus hard-to-retrieve across a double clause boundary. We combined electroencephalography (EEG), scalp-level time–frequency analysis, source localization, and source-level coherence analysis, observing a frontal-midline and broad left-hemispheric theta-power increase for embedded-antecedent compared to non-embedded-antecedent retrieval. Sources were localized to left-frontal, left-parietal, and bilateral-inferior-temporal cortices. Coherence analyses suggested synchronicity between left-frontal and left-parietal and between left-frontal and right-inferior-temporal cortices. Activity of an array of left-frontal, left-parietal, and bilateral-inferior-temporal cortices may thus assist retrieval during sentence comprehension, potentially indexing the orchestration of item distinction, verbal working memory, and long-term memory. Our results extend prior findings by mapping prior knowledge on the functional role of theta oscillations onto processes genuine to human sentence comprehension. "} 
}
@article{Nativ20161335,
title = {"Model Predictive Control of an Automated Storage/Retrieval System "},
journal = {"IFAC-PapersOnLine "},
volume = {"49"},
number = {"12"},
pages = {"1335 - 1340"},
year = {"2016"},
note = {"8th \{IFAC\} Conference on Manufacturing Modelling, Management and Control \{MIM\} 2016Troyes, France, 28—30 June 2016 "},
issn = {"2405-8963"},
doi = {"https://doi.org/10.1016/j.ifacol.2016.07.745"},
url = {"http://www.sciencedirect.com/science/article/pii/S2405896316310266"},
author = {"Danielle J. Nativ and Andrea Cataldo and Riccardo Scattolini and Bart De Schutter"},
keywords = {"Control applications", "Manufacturing systems", "Production processes", "Warehouse automation", "Self-organising storage", "Model-based control", "Predictive control", "Discrete-event systems", "Integer programming "},
abstract = {"Abstract Discrete-event systems occur often in the manufacturing field, but due to the characteristics of these systems Model Predictive Control (MPC) is not frequently used for them. This paper approaches \{MPC\} of an Automated Storage/Retrieval System (AS/RS) by using Mixed Logical Dynamical (MLD) modelling. Propositional calculus is used to transform the non-linear dynamic model equations and constraints of the AS/RS into the \{MLD\} form. We consider a performance index that makes sure that customer demand is satisfied as soon and as efficiently as possible. The \{MLD\} model and performance index are reformulated as an integer linear programming problem. A case study is performed on a laboratory stacker crane, and the simulations results illustrate the good performance of the control algorithm. "} 
}
@article{Yan20158006,
title = {"Trustworthiness evaluation and retrieval-based revision method for case-based reasoning classifiers "},
journal = {"Expert Systems with Applications "},
volume = {"42"},
number = {"21"},
pages = {"8006 - 8013"},
year = {"2015"},
note = {""},
issn = {"0957-4174"},
doi = {"https://doi.org/10.1016/j.eswa.2015.06.027"},
url = {"http://www.sciencedirect.com/science/article/pii/S0957417415004297"},
author = {"Aijun Yan and Dianhui Wang"},
keywords = {"Case-based reasoning classifiers", "Classification accuracy", "Case evaluation", "Case revision "},
abstract = {"Abstract To achieve better classification performance using case-based reasoning classifiers, we propose a retrieval-based revision method with trustworthiness evaluation for problem solving. An improved case evaluation method is employed to evaluate the trustworthiness of the suggested solution after the reuse step, which will divide the target cases and its suggested solutions into a trustworthy set and an untrustworthy set in accordance with a threshold value of trustworthiness. The attribute weights are adjusted by running a genetic algorithm and are used in the second round of retrieval of the untrustworthy set to obtain the classification results. Experimental results demonstrate that our proposed method performs favorably compared with other methods. Also, the proposed method has less computation complexity for the trustworthiness evaluation, and enhances understanding on thinking and inference for case-based reasoning classifiers. "} 
}
@article{Yu2016109,
title = {"Retrieval of the diffuse attenuation coefficient from \{GOCI\} images using the 2SeaColor model: A case study in the Yangtze Estuary "},
journal = {"Remote Sensing of Environment "},
volume = {"175"},
number = {""},
pages = {"109 - 119"},
year = {"2016"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.12.053"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715302704"},
author = {"Xiaolong Yu and Mhd. Suhyb Salama and Fang Shen and Wouter Verhoef"},
keywords = {"Diffuse attenuation coefficient", "2SeaColor", "GOCI", "Yangtze Estuary "},
abstract = {"Abstract The 2SeaColor model (Salama &amp; Verhoef, 2015) was proposed to analytically retrieve the diffuse attenuation coefficient (Kd) from remote sensing reflectance (Rrs), but its parameterization was based on approximations and subjected to large uncertainties. In this study, we present an improvement on the parameterization equations in the inverse scheme of the 2Seacolor model. The improved model is then validated with three in-situ datasets and compared with the Zhang model (Zhang &amp; Fell, 2007) and the Lee model (Lee, Darecki et al., 2005). Validation with radiometric data shows that the 2SeaColor model provides the best estimates of Kd for the full range of observations, with the largest determination coefficient (R2 = 0.935) and the smallest root mean squared error (RMSE = 0.078 m− 1). For clear waters, where Kd(490) &lt; 0.2, the Zhang model provides the most accurate Kd estimations, but results from the Lee model and the 2SeaColor are rather comparable. For turbid waters, where Kd(490) &gt; 0.2 m− 1, the 2SeaColor model is found to be more accurate, with an \{RMSE\} of 0.186 m− 1, compared to \{RMSEs\} of 0.279 m− 1 and 0.388 m− 1 for the Zhang model and the Lee model, respectively. The 2SeaColor model is finally applied to the \{GOCI\} (Geostationary Ocean Color Imager) level 2 product (L2P) to produce Kd maps over the Yangtze Estuary, resulting in a reasonable distribution and expected range of Kd, as for example Kd(490) was varying from 0.04 to 9.82 m− 1 for the image acquired at 02:16 UTC, on March 8th 2013. The analytical 2SeaColor model is able to provide consistently stable and fairly accurate Kd estimates in both clear and turbid waters without the need of tuning empirical coefficients from field measurements, and thus has great potential for estimating Kd over optically complex waters. "} 
}
@article{Barrio2017309,
title = {"Sampling strategies for information extraction over the deep web "},
journal = {"Information Processing & Management "},
volume = {"53"},
number = {"2"},
pages = {"309 - 331"},
year = {"2017"},
note = {""},
issn = {"0306-4573"},
doi = {"https://doi.org/10.1016/j.ipm.2016.11.006"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306457316306318"},
author = {"Pablo Barrio and Luis Gravano"},
keywords = {"Information extraction", "Sampling", "Deep web", "Text mining", "Scalability "},
abstract = {"Abstract Information extraction systems discover structured information in natural language text. Having information in structured form enables much richer querying and data mining than possible over the natural language text. However, information extraction is a computationally expensive task, and hence improving the efficiency of the extraction process over large text collections is of critical interest. In this paper, we focus on an especially valuable family of text collections, namely, the so-called deep-web text collections, whose contents are not crawlable and are only available via querying. Important steps for efficient information extraction over deep-web text collections (e.g., selecting the collections on which to focus the extraction effort, based on their contents; or learning which documents within these collections—and in which order—to process, based on their words and phrases) require having a representative document sample from each collection. These document samples have to be collected by querying the deep-web text collections, an expensive process that renders impractical the existing sampling approaches developed for other data scenarios. In this paper, we systematically study the space of query-based document sampling techniques for information extraction over the deep web. Specifically, we consider (i) alternative query execution schedules, which vary on how they account for the query effectiveness, and (ii) alternative document retrieval and processing schedules, which vary on how they distribute the extraction effort over documents. We report the results of the first large-scale experimental evaluation of sampling techniques for information extraction over the deep web. Our results show the merits and limitations of the alternative query execution and document retrieval and processing strategies, and provide a roadmap for addressing this critically important building block for efficient, scalable information extraction. "} 
}
@article{Sitarek201653,
title = {"Software for retrieval of aerosol particle size distribution from multiwavelength lidar signals "},
journal = {"Computer Physics Communications "},
volume = {"199"},
number = {""},
pages = {"53 - 60"},
year = {"2016"},
note = {""},
issn = {"0010-4655"},
doi = {"https://doi.org/10.1016/j.cpc.2015.08.024"},
url = {"http://www.sciencedirect.com/science/article/pii/S0010465515003215"},
author = {"S. Sitarek and T. Stacewicz and M. Posyniak"},
keywords = {"Lidar", "Remote sensing", "Atmospheric aerosol", "Particle size distribution "},
abstract = {"Abstract Software to retrieve profiles of aerosol particle size distribution (APSD) from multiwavelength lidar signals is presented. The approach consists in direct fit of artificial signal generated using predefined distribution to the experimental signals. Combination of two lognormal functions with a few free parameters is applied for the predefined APSD. The minimization technique allows finding lognormal function parameters which provide the best fit. The approach was tested on the experimental signals registered at 1064, 532 and 355 nm. The software is designated for processing on PCs. The computation time was about several minutes. Program summary Program title: APSD_Software Catalogue identifier: AEXV_v1_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AEXV_v1_0.html Program obtainable from: \{CPC\} Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: Open Licence No. of lines in distributed program, including test data, etc.: 12813 No. of bytes in distributed program, including test data, etc.: 878099 Distribution format: tar.gz Programming language: Delphi 2010. Computer: PC. Operating system: Windows XP, Vista, 7, 8, 8.1. RAM: 37MB Classification: 13. Nature of problem: Aerosol Particle Size Distribution (APSD) is a very significant function for evaluation of atmospheric optical properties. Remote determination of \{APSD\} might be performed with multiwavelength lidar. Retrieval of profiles of \{APSD\} from multiwavelength lidar signals is an example of ill-posed problem in the atmospheric physics (in the sense of Jacques Hadamard). Solution method: The approach consists in direct fit of artificial signals to the experimental signals. The artificial signals are generated using predefined aerosol particle distribution, Combination of two lognormal functions with a few free parameters is applied for the predefined APSD. The minimization technique used in the software allows finding lognormal function parameters which provide the best fit. Additional comments: The input signal should be located into the \{SIGNALS\} directory which is automatically created by the software. The results are presented in the main form of the software. They are also saved into the same directory from which it was loaded input file. They are saved as a BitMap as well as the \{ASCII\} files. The software returns two main sets of files: first one “APSD.bmp” and “APSD_Iet.txt”, and the second one “EffectiveRadius.bmp” and “EffectiveRadius.txt”. Running time: 195 s for an input file consisting 12 measurement points (altitudes). "} 
}
@article{Pham201577,
title = {"A neural network based error correction method for radio occultation electron density retrieval "},
journal = {"Journal of Atmospheric and Solar-Terrestrial Physics "},
volume = {"135"},
number = {""},
pages = {"77 - 84"},
year = {"2015"},
note = {""},
issn = {"1364-6826"},
doi = {"https://doi.org/10.1016/j.jastp.2015.10.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S1364682615300730"},
author = {"Viet-Cuong Pham and Jyh-Ching Juang"},
keywords = {"Radio occultation", "Electron density profile", "Abel inversion", "Asymmetry index", "Artificial neural network "},
abstract = {"Abstract Abel inversion techniques have been widely employed to retrieve electron density profiles (EDPs) from radio occultation (RO) measurements, which are available by observing Global Navigation Satellite System (GNSS) satellites from low-earth-orbit (LEO) satellites. It is well known that the ordinary Abel inversion might introduce errors in the retrieval of \{EDPs\} when the spherical symmetry assumption is violated. The error, however, is case-dependent; therefore it is desirable to associate an error index or correction coefficient with respect to each retrieved EDP. Several error indices have been proposed but they only deal with electron density at the \{F2\} peak and suffer from some drawbacks. In this paper we propose an artificial neural network (ANN) based error correction method for \{EDPs\} obtained by the ordinary Abel inversion. The \{ANN\} is first trained to learn the relationship between vertical total electron content (TEC) measurements and retrieval errors at the \{F2\} peak, 220 km and 110 km altitudes; correction coefficients are then estimated to correct the retrieved \{EDPs\} at these three altitudes. Experiments using the NeQuick2 model and real FORMOSAT-3/COSMIC \{RO\} geometry show that the proposed method outperforms existing ones. Real incoherent scatter radar (ISR) measurements at the Jicamarca Radio Observatory and the global \{TEC\} map provided by the International \{GNSS\} Service (IGS) are also used to valid the proposed method. "} 
}
@incollection{RahimzadehBajgiran201647,
title = {"Chapter 3 - Soil Moisture Retrievals Using Optical/TIR Methods "},
editor = {"Srivastava, Prashant K. and Petropoulos, George P.  and Kerr, Yann H. "},
booktitle = {"Satellite Soil Moisture Retrieval "},
publisher = {"Elsevier"},
edition = {""},
address = {""},
year = {"2016"},
pages = {"47 - 72"},
isbn = {"978-0-12-803388-3"},
doi = {"https://doi.org/10.1016/B978-0-12-803388-3.00003-6"},
url = {"http://www.sciencedirect.com/science/article/pii/B9780128033883000036"},
author = {"P. Rahimzadeh-Bajgiran and A. Berg"},
keywords = {"Thermal infrared", "Triangle/trapezoid models", "Soil moisture", "Vegetation indices", "Evaporative fraction "},
abstract = {"Abstract Soil moisture estimation using optical and thermal infrared (TIR) bands known as the surface temperature (Ts)/vegetation index (VI) method is a widely used promising approach for soil water content estimation. Given the importance and increasing applications of optical/TIR satellite remote sensing approaches alone or in combination with data obtained from other sensors for soil moisture estimation retrieval, this chapter attempts to provide a comprehensive and informative description of the Ts/VI concept and methods in five sections. Section 1 provides an introduction; in Section 2 the Ts/VI concept and history are presented; in Section 3 suggested methodologies are discussed; in section 4 a case study is presented and finally advantages and limitations of the Ts/VI approaches for future application are discussed in Section 5. "} 
}
@article{Tonegawa2015101,
title = {"Memory engram storage and retrieval "},
journal = {"Current Opinion in Neurobiology "},
volume = {"35"},
number = {""},
pages = {"101 - 109"},
year = {"2015"},
note = {"Circuit plasticity and memory "},
issn = {"0959-4388"},
doi = {"https://doi.org/10.1016/j.conb.2015.07.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0959438815001270"},
author = {"Susumu Tonegawa and Michele Pignatelli and Dheeraj S Roy and Tomás J Ryan"},

abstract = {"A great deal of experimental investment is directed towards questions regarding the mechanisms of memory storage. Such studies have traditionally been restricted to investigation of the anatomical structures, physiological processes, and molecular pathways necessary for the capacity of memory storage, and have avoided the question of how individual memories are stored in the brain. Memory engram technology allows the labeling and subsequent manipulation of components of specific memory engrams in particular brain regions, and it has been established that cell ensembles labeled by this method are both sufficient and necessary for memory recall. Recent research has employed this technology to probe fundamental questions of memory consolidation, differentiating between mechanisms of memory retrieval and the true neurobiology of memory storage. "} 
}
@article{Perez2017279,
title = {"Video pornography detection through deep learning techniques and motion information "},
journal = {"Neurocomputing "},
volume = {"230"},
number = {""},
pages = {"279 - 293"},
year = {"2017"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2016.12.017"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231216314928"},
author = {"Mauricio Perez and Sandra Avila and Daniel Moreira and Daniel Moraes and Vanessa Testoni and Eduardo Valle and Siome Goldenstein and Anderson Rocha"},
keywords = {"Pornography classification", "Deep learning and motion information", "Optical flow", "MPEG motion vectors", "Sensitive video classification "},
abstract = {"Abstract Recent literature has explored automated pornographic detection – a bold move to replace humans in the tedious task of moderating online content. Unfortunately, on scenes with high skin exposure, such as people sunbathing and wrestling, the state of the art can have many false alarms. This paper is based on the premise that incorporating motion information in the models can alleviate the problem of mapping skin exposure to pornographic content, and advances the bar on automated pornography detection with the use of motion information and deep learning architectures. Deep Learning, especially in the form of Convolutional Neural Networks, have striking results on computer vision, but their potential for pornography detection is yet to be fully explored through the use of motion information. We propose novel ways for combining static (picture) and dynamic (motion) information using optical flow and \{MPEG\} motion vectors. We show that both methods provide equivalent accuracies, but that \{MPEG\} motion vectors allow a more efficient implementation. The best proposed method yields a classification accuracy of 97.9% – an error reduction of 64.4% when compared to the state of the art – on a dataset of 800 challenging test cases. Finally, we present and discuss results on a larger, and more challenging, dataset. "} 
}
@article{Martin201664,
title = {"Towards a full retrieval of the deformation tensor F using convergent beam electron diffraction "},
journal = {"Ultramicroscopy "},
volume = {"160"},
number = {""},
pages = {"64 - 73"},
year = {"2016"},
note = {""},
issn = {"0304-3991"},
doi = {"https://doi.org/10.1016/j.ultramic.2014.12.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0304399114002605"},
author = {"Y. Martin and J.L. Rouviere and J.M. Zuo and V. Favre-Nicolin"},
keywords = {"CBED", "Ambiguity", "Strain", "Lattice parameter determination", "Deformation gradient tensor "},
abstract = {"Abstract A new method to retrieve the local lattice parameters and rotations in a crystal from off-axis convergent beam electron diffraction (CBED) patterns is presented and validated using Bloch wave dynamical simulations. The originality of the method is to use both the diffracted and transmitted beams and to use kinematical approximations in the fitting algorithm. The study is based on the deformation gradient tensor F which includes rotation and strain. Working on simulated images it is shown that (i) from a single direction of observation, seven parameters out of the nine parameters of F can be determined with an accuracy of 3×10−4 for the normal strain parameters εxx, εyy, and εzz, (ii) the unit cell volume can only be retrieved if the diffracted and transmitted beams are both included in the fitting and (iii) all the nine parameters of F can be determined by combining two directions of observation separated by about 20°. "} 
}
@article{Liu2015861,
title = {"An Effective Antarctic Ice Surface Temperature Retrieval Method for \{MODIS\} "},
journal = {"Photogrammetric Engineering & Remote Sensing "},
volume = {"81"},
number = {"11"},
pages = {"861 - 872"},
year = {"2015"},
note = {""},
issn = {"0099-1112"},
doi = {"https://doi.org/10.14358/PERS.81.11.861"},
url = {"http://www.sciencedirect.com/science/article/pii/S0099111215300240"},
author = {"Tingting Liu and Muye NIU and Zemin Wang and Xin Huang and Liqin Cao and Zhongxiang Tian"},

abstract = {"Abstract Given the close relationship between surface melt in polar areas and ice surface temperature (IST), it is important to develop an effective \{IST\} retrieval method. However, the studies concerning this topic are relatively limited. In this context, this paper proposes an effective approach to retrieve \{IST\} in the Antarctic area by presenting a modified split-window algorithm (SWA) and introducing a polynomial fitting for atmospheric transmittance simulation. The effectiveness was quantitatively validated by a comparative study with a Moderate Resolution Imaging Spectroradiometer (MODIS) \{IST\} product (MOD29) and automatic weather station (AWS) data. The comparisons indicated that the proposed method shows a robust performance in Antarctic \{IST\} retrieval for \{MODIS\} data: the bias was − 0.61 K and the root-mean-square error (RMSE) was 1.32 K for the Zhongshan Station data set; the bias was − 1.62 K and the \{RMSE\} was 2.34 K for the Ross Ice Shelf data set. "} 
}
@incollection{Nosofsky201647,
title = {"Chapter Two - An Exemplar-Retrieval Model of Short-term Memory Search: Linking Categorization and Probe Recognition "},
editor = {"Brian H. Ross"},
booktitle = {""},
publisher = {"Academic Press"},
year = {"2016"},
volume = {"65"},
pages = {"47 - 84"},
series = {"Psychology of Learning and Motivation "},
issn = {"0079-7421"},
doi = {"https://doi.org/10.1016/bs.plm.2016.03.002"},
url = {"http://www.sciencedirect.com/science/article/pii/S0079742116000153"},
author = {"Robert M. Nosofsky"},
keywords = {"Exemplar model", "Probe recognition", "Response times", "Short-term memory "},
abstract = {"Abstract Exemplar-retrieval models such as the exemplar-based random walk (EBRW) model have provided good accounts of response time (RT) and choice-probability data in a wide variety of categorization paradigms. In this chapter, I review recent work showing that the model also accounts accurately for \{RT\} and choice-probability data in a wide variety of probe-recognition, short-term, memory-search paradigms. According to the model, observers store items from study lists as individual exemplars in memory. When a test probe is presented, it causes the exemplars to be retrieved. The exemplars that are most readily retrieved are those that are highly similar to the test probe and that have the greatest memory strengths. The retrieved exemplars drive a familiarity-based evidence-accumulation process that determines the speed and accuracy of old–new recognition decisions. The model accounts for effects of memory-set size, old-new status of test probe, and study-test lag; effects of the detailed similarity structure of the memory set; and the role of the history of previously experienced memory sets on performance. Applications of the model reveal a quantitative law of how memory strength varies with the retention interval. In addition, the model provides a unified account of how probe recognition operates in cases involving short and long study lists. Furthermore it provides an account of the classic distinction between controlled versus automatic processing depending on the types of memory-search practice in which observers engage. In short the model brings together and extends prior research and theory on categorization, attention and automaticity, short- and long-term memory, and evidence-accumulation models of choice \{RT\} to move the field closer to a unified account of diverse forms of memory search. "} 
}
@article{Sütterlin2015163,
title = {"Albedo and reflectance anisotropy retrieval from \{AVHRR\} operated onboard \{NOAA\} and MetOp satellites: Algorithm performance and accuracy assessment for Europe "},
journal = {"Remote Sensing of Environment "},
volume = {"168"},
number = {""},
pages = {"163 - 176"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.06.023"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715300535"},
author = {"M. Sütterlin and C.B. Schaaf and R. Stöckli and Q. Sun and F. Hüsler and C. Neuhaus and S. Wunderle"},
keywords = {"BRDF", "Albedo", "AVHRR", "Surface albedo", "bidirectional reflectance", "anisotropy", "Europe "},
abstract = {"Abstract In this study, the land surface albedo together with its Bidirectional Reflectance Distribution Function (BRDF) are retrieved for the years 2000 to 2012 from Local Area Coverage (LAC) surface reflectance data gathered by the Advanced Very High Resolution Radiometer (AVHRR) over Europe. For the retrieval the \{MODerate\} resolution Imaging Spectroradiometer (MODIS) BRDF/albedo processing scheme is employed. The comparatively high revisit frequency and high variability in angular sampling of the \{AVHRR\} sensors operated simultaneously onboard the different National Oceanic and Atmospheric Administration (NOAA) and Meteorological Operational (MetOp) satellites contribute substantially to the success and quality of \{BRDF\} retrieval. The performance of the \{BRDF\} model for \{AVHRR\} data is assessed by comparison to \{MODIS\} \{BRDF\} retrievals, and the \{AVHRR\} \{BRDF\} reflectance data is validated against \{BRDF\} reflectance data from \{MODIS\} and in situ data gathered at three field sites in Switzerland. The comparison shows that the \{AVHRR\} \{BRDF\} retrievals are of high quality across most of Europe. The higher angular sampling of \{AVHRR\} allows for more full model retrievals of best quality and generates less fill values compared to MODIS. For most of the years investigated, the absolute accuracy of the \{AVHRR\} albedos is found to be within 0.05 throughout the complete seasonal cycle with a minimum bias at the peak of the growing season. However, they systematically underestimate the field-measured albedos, predominantly in winter due to spatial scale mismatch in combination with site heterogeneity and because the expression for the calculation of satellite-based blue-sky albedo does not account for multiple scattering. A slightly increased underestimation also occurs during vegetation senescence, presumably because of the narrow to broadband conversion employing only two bands. Overall, the results confirm the potential of \{AVHRR\} to produce multi-decadal data sets of reflectance anisotropy and albedo for use in climate monitoring and modeling studies. This offers a promising and unique opportunity to produce a BRDF/albedo climate data record from \{AVHRR\} dating back to 1985. "} 
}
@article{Ye2015232,
title = {"Standing water effect on soil moisture retrieval from L-band passive microwave observations "},
journal = {"Remote Sensing of Environment "},
volume = {"169"},
number = {""},
pages = {"232 - 242"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.08.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0034425715301012"},
author = {"N. Ye and J.P. Walker and J. Guerschman and D. Ryu and R.J. Gurney"},
keywords = {"Passive microwave remote sensing", "Soil moisture", "Water fraction "},
abstract = {"Abstract Passive microwave remote sensing at L-band has been widely acknowledged as the most promising technique to observe the spatial distribution of near surface (top ~ 5 cm) soil moisture at regional to global scales. The launch of the ESA's Soil Moisture and Ocean Salinity (SMOS) mission in 2009 now means that global space-borne brightness temperature observations are available at L-band (1.41 GHz) to estimate soil moisture every 2 to 3 days with a target accuracy of 0.04 m3/m3. Moreover, NASA's Soil Moisture Active Passive (SMAP) satellite has been launched on 31st January 2015, also carrying an L-band radiometer, together with an L-band radar for downscaling the brightness temperature observations to better than 10 km resolution. At the SMOS/SMAP radiometer scale of ~ 40 km, the presence of water bodies potentially induces an overestimation of retrieved soil moisture, if not carefully accounted for in retrieval models. Such water fraction effects on brightness temperature and soil moisture retrieval accuracy were investigated in this study, using airborne L-band brightness temperature data collected during three Australian field experiments. The water induced brightness temperature effect and water fraction were compared under different resolutions, sampling days, and land surface conditions, showing that the water fraction impact on retrieved soil moisture is independent of scale, but heavily dependent on the soil water content status. Subsequently, the highest water fraction threshold that can be tolerated in order to achieve the 0.04 m3/m3 target accuracy without correction has been determined as 0.08 (actual range is from 0.02 for dry bare soil to 0.08 for wet vegetated soil). Using a \{MODIS\} derived water fraction dataset, the water fraction dynamics were also studied over Australia during the ten years from 2001 to 2010. The results show that if the mean water fraction map was used as a static water map to flag or correct water effects, the water body induced soil moisture retrieval error would have exceeded the 0.04 m3/m3 target more than once for 13.5% of the Australian land 40 km sized radiometer pixels; only 0.6% Australian land pixels would have exceeded this target with a frequency of 10 times or more per year. "} 
}
@article{Kornelsen2015109,
title = {"Reducing multiplicative bias of satellite soil moisture retrievals "},
journal = {"Remote Sensing of Environment "},
volume = {"165"},
number = {""},
pages = {"109 - 122"},
year = {"2015"},
note = {""},
issn = {"0034-4257"},
doi = {"https://doi.org/10.1016/j.rse.2015.04.031"},
url = {"http://www.sciencedirect.com/science/article/pii/S003442571500173X"},
author = {"Kurt C. Kornelsen and Paulin Coulibaly"},
keywords = {"SMOS", "Cumulative distribution function", "Renormalization", "Validation", "Bias correction "},
abstract = {"Abstract Soil moisture is a principal component of the Earth's climate and hydrological systems that is difficult to monitor and model due to high variability, uncertainty in land surface characterization and uncertainty in soil moisture forcing. Satellite soil moisture retrievals and brightness temperature observations, such as those available from the Soil Moisture and Ocean Salinity (SMOS) mission, can be a valuable source of information for data assimilation and merging with other satellite retrieval datasets. To correct for biases in these data sets, bias correction methods such as cumulative distribution function (CDF) matching, linear rescaling and copulas are used to map satellite soil moisture climatology to that of in situ or model values. This study compared \{SMOS\} retrievals to soil moisture observations from the \{SCAN\} network for a calibration period of 2010–2011 and validation period of 2012–2013 before and after bias correction. The focus of the study was on the presence and removal of multiplicative bias when comparing \{SMOS\} retrievals to \{SCAN\} data. Additive bias between \{SMOS\} retrievals and \{SCAN\} observations was removed by standard bias correction techniques and a new resampling approach was found to reduce multiplicative biases. In addition, the new bias correction technique was found very competitive with the benchmark methods for both the calibration and validation periods. "} 
}
@article{Riba2017203,
title = {"Large-scale graph indexing using binary embeddings of node contexts for information spotting in document image databases "},
journal = {"Pattern Recognition Letters "},
volume = {"87"},
number = {""},
pages = {"203 - 211"},
year = {"2017"},
note = {"Advances in Graph-based Pattern Recognition "},
issn = {"0167-8655"},
doi = {"https://doi.org/10.1016/j.patrec.2016.06.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0167865516301398"},
author = {"Pau Riba and Josep Lladós and Alicia Fornés and Anjan Dutta"},
keywords = {"Graph based representation", "Graph indexation", "Information spotting in Document recognition "},
abstract = {"Abstract Graph-based representations are experiencing a growing usage in visual recognition and retrieval due to their representational power in front of classical appearance-based representations. However, retrieving a query graph from a large dataset of graphs implies a high computational complexity. The most important property for a large-scale retrieval is the search time complexity to be sub-linear in the number of database examples. With this aim, in this paper we propose a graph indexation formalism applied to visual retrieval. A binary embedding is defined as hashing keys for graph nodes. Given a database of labeled graphs, graph nodes are complemented with vectors of attributes representing their local context. Then, each attribute vector is converted to a binary code applying a binary-valued hash function. Therefore, graph retrieval is formulated in terms of finding target graphs in the database whose nodes have a small Hamming distance from the query nodes, easily computed with bitwise logical operators. As an application example, we validate the performance of the proposed methods in different real scenarios such as handwritten word spotting in images of historical documents or symbol spotting in architectural floor plans. "} 
}
@article{Verma2015255,
title = {"Local extrema co-occurrence pattern for color and texture image retrieval "},
journal = {"Neurocomputing "},
volume = {"165"},
number = {""},
pages = {"255 - 269"},
year = {"2015"},
note = {""},
issn = {"0925-2312"},
doi = {"https://doi.org/10.1016/j.neucom.2015.03.015"},
url = {"http://www.sciencedirect.com/science/article/pii/S0925231215002878"},
author = {"Manisha Verma and Balasubramanian Raman and Subrahmanyam Murala"},
keywords = {"Local extrema co-occurrence pattern", "Local extrema patterns", "Gray level co-occurrence matrix", "Corel database", "MIT VisTex database", "STex database "},
abstract = {"Abstract A real world problem of image retrieval and searching is considered in this paper. In modern generation, managing images from a large storage medium is not a straightforward job. Many researchers have worked on texture features, and produced diverse feature descriptors based on uniform, rotation invariant, edges and directional properties. However, most of them convert the relationship of the center pixel and the boundary pixel into a local pattern, and use histogram to represent the local pattern as a feature vector. In this work, we propose a new image retrieval technique; local extrema co-occurrence patterns (LECoP) using the \{HSV\} color space. \{HSV\} color space is used in this method to utilize the color, intensity and brightness of images. Local extrema patterns are applied to define the local information of image, and gray level co-occurrence matrix is used to obtain the co-occurrence of \{LEP\} map pixels. The local extrema co-occurrence pattern extracts the local directional information from local extrema pattern, and convert it into a well-mannered feature vector with use of gray level co-occurrence matrix. The presented method is tested on five standard databases called Corel, \{MIT\} VisTex and STex, in which Corel database includes Corel-1k, Corer-5k and Corel-10k databases. Also, this algorithm is compared with previous proposed methods, and results in terms of precision and recall are shown in this work. "} 
}
@article{Lombera2016127,
title = {"Corrigendum to “Peer-to-Peer Publication, Search and Retrieval Using the Android Mobile Platform” [Computer Networks 65(2014) 56-72] "},
journal = {"Computer Networks "},
volume = {"95"},
number = {""},
pages = {"127 - "},
year = {"2016"},
note = {""},
issn = {"1389-1286"},
doi = {"https://doi.org/10.1016/j.comnet.2015.11.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S1389128615004041"},
author = {"I. Michel Lombera and L.E. Moser and P.M. Melliar-Smith and Y.T. Chuang"} 

}
@article{Sánchez201712,
title = {"Information system for image classification based on frequency curve proximity "},
journal = {"Information Systems "},
volume = {"64"},
number = {""},
pages = {"12 - 21"},
year = {"2017"},
note = {""},
issn = {"0306-4379"},
doi = {"https://doi.org/10.1016/j.is.2016.08.001"},
url = {"http://www.sciencedirect.com/science/article/pii/S0306437916303982"},
author = {"L. Sánchez and Javier Alfonso-Cendón and Tiago Oliveira and Joaquín B. Ordieres-Meré and Manuel Castejón Limas and Paulo Novais"},
keywords = {"Information system", "Similarity search", "Frequent itemset mining", "Metadata", "Image classification "},
abstract = {"Abstract With the size digital collections are currently reaching, retrieving the best match of a document from large collections by comparing hundreds of tags is a task that involves considerable algorithm complexity, even more so if the number of tags in the collection is not fixed. For these cases, similarity search appears to be the best retrieval method, but there is a lack of techniques suited for these conditions. This work presents a combination of machine learning algorithms put together to find the most similar object of a given one in a set of pre-processed objects based only on their metadata tags. The algorithm represents objects as character frequency curves and is capable of finding relationships between objects without an apparent association. It can also be parallelized using MapReduce strategies to perform the search. This method can be applied to a wide variety of documents with metadata tags. The case-study used in this work to demonstrate the similarity search technique is that of a collection of image objects in JavaScript Object Notation (JSON) containing metadata tags. "} 
}
@article{Kong201622,
title = {"Retrieval of three-dimensional tree canopy and shade using terrestrial laser scanning (TLS) data to analyze the cooling effect of vegetation "},
journal = {"Agricultural and Forest Meteorology "},
volume = {"217"},
number = {""},
pages = {"22 - 34"},
year = {"2016"},
note = {""},
issn = {"0168-1923"},
doi = {"https://doi.org/10.1016/j.agrformet.2015.11.005"},
url = {"http://www.sciencedirect.com/science/article/pii/S016819231500756X"},
author = {"Fanhua Kong and Weijiao Yan and Guang Zheng and Haiwei Yin and Gina Cavan and Wenfeng Zhan and Ning Zhang and Liang Cheng"},
keywords = {"Cooling effect", "Terrestrial laser scanner", "Vegetation canopy", "Three-dimensional point cloud (3DPC)", "Tree shade "},
abstract = {"Abstract Urban warming has become a serious problem due to global warming and rapid urbanization. One important phenomenon is the increasing urban heat island (UHI) effect, which has a serious negative impact on energy consumption, environmental pollution, and human well-being. Trees lower land surface and air temperatures by providing shade and through the process of evapotranspiration and therefore are useful in effectively mitigating the \{UHI\} effect. The cooling effects of trees vary depending on the tree crown size and density and the optical properties of their leaves. Selection of the best species to plant is important in achieving effective mitigation of the \{UHI\} effect. In this research, we examined four woodlands. Three of these woodlands are dominated by species (Cinnamomum camphora, Metasequoia glyptostroboides, Magnolia grandiflora) that are frequently planted in Nanjing, China and one is a mixed woodland. Terrestrial laser scanning (TLS) was employed to detail the vegetation canopy structure and capture the volume of three-dimensional point clouds of the leaves (L_V3DPC), as well as the shade at each case study site. Meteorological parameters were measured at each site. Statistical analysis was used to assess the cooling effects of the different woodlands and their impacts. This research revealed that trees can influence the microclimate beneath their canopies and that the degree of the impact is different for different tree species. Statistical analyses showed that the woodlands studied exhibit obvious temperature reductions during the daytime (05:00–19:30) and weaker temperature reductions during the nighttime (19:30–05:00). The temperature reduction was greatest for M. glyptostroboides, followed by C. camphora, M. grandiflora, and the trees in the mixed broad-leaved woodland. These results indicate that small-leaved species tend to be more effective at cooling than large-leaved species. Comparisons of the Leaf Area Index (LAI) and Sky View Factor (SVF) with L_V3DPC and shade, respectively, show that L_V3DPC and shade better reflect the impact of the vegetation canopy on the cooling effect. Multiple linear regression analyses showed that shading by trees is of prime importance in cooling the thermal environment. The high significance of L_V3DPC and shade indicate that the tree canopy is a major component of the contribution of trees to microclimatic environments, particularly the cooling effect under the tree canopy. This paper presents an innovative technique for determining tree canopy shade using \{TLS\} data for the purpose of analyzing the cooling effect of trees. The findings can be used as a guide to aid in the selection of the best species for urban greenspace planning and design to cool the thermal environment and enhance energy savings in urban environments. "} 
}
@article{Atzberger201519,
title = {"Comparative analysis of different retrieval methods for mapping grassland leaf area index using airborne imaging spectroscopy "},
journal = {"International Journal of Applied Earth Observation and Geoinformation "},
volume = {"43"},
number = {""},
pages = {"19 - 31"},
year = {"2015"},
note = {"Special Issue on "Advances in remote sensing of vegetation function and traits" "},
issn = {"0303-2434"},
doi = {"https://doi.org/10.1016/j.jag.2015.01.009"},
url = {"http://www.sciencedirect.com/science/article/pii/S0303243415000100"},
author = {"Clement Atzberger and Roshanak Darvishzadeh and Markus Immitzer and Martin Schlerf and Andrew Skidmore and Guerric le Maire"},
keywords = {"Leaf area index", "Radiative transfer model", "Look-up table", "Narrow band vegetation index", "Predictive equation", "Sample size "},
abstract = {"Abstract Fine scale maps of vegetation biophysical variables are useful status indicators for monitoring and managing national parks and endangered habitats. Here, we assess in a comparative way four different retrieval methods for estimating leaf area index (LAI) in grassland: two radiative transfer model (RTM) inversion methods (one based on look-up-tables (LUT) and one based on predictive equations) and two statistical modelling methods (one partly, the other entirely based on in situ data). For prediction, spectral data were used that had been acquired over Majella National Park in Italy by the airborne hyperspectral HyMap instrument. To assess the performance of the four investigated models, the normalized root mean squared error (nRMSE) and coefficient of determination (R2) between estimates and in situ \{LAI\} measurements are reported (n = 41). Using a jackknife approach, we also quantified the accuracy and robustness of empirical models as a function of the size of the available calibration data set. The results of the study demonstrate that the LUT-based \{RTM\} inversion yields higher accuracies for \{LAI\} estimation (R2 = 0.91, nRMSE = 0.18) as compared to \{RTM\} inversions based on predictive equations (R2 = 0.79, nRMSE = 0.38). The two statistical methods yield accuracies similar to the \{LUT\} method. However, as expected, the accuracy and robustness of the statistical models decrease when the size of the calibration database is reduced to fewer samples. The results of this study are of interest for the remote sensing community developing improved inversion schemes for spaceborne hyperspectral sensors applicable to different vegetation types. The examples provided in this paper may also serve as illustrations for the drawbacks and advantages of physical and empirical models. "} 
}
@article{Verrelst2015260,
title = {"Experimental Sentinel-2 \{LAI\} estimation using parametric, non-parametric and physical retrieval methods – A comparison "},
journal = {"\{ISPRS\} Journal of Photogrammetry and Remote Sensing "},
volume = {"108"},
number = {""},
pages = {"260 - 272"},
year = {"2015"},
note = {""},
issn = {"0924-2716"},
doi = {"https://doi.org/10.1016/j.isprsjprs.2015.04.013"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924271615001239"},
author = {"Jochem Verrelst and Juan Pablo Rivera and Frank Veroustraete and Jordi Muñoz-Marí and Jan G.P.W. Clevers and Gustau Camps-Valls and José Moreno"},
keywords = {"Biophysical variables", "Sentinel-2", "Parametric", "Non-parametric", "Machine learning", "Physically-based \{RTM\} inversion "},
abstract = {"Abstract Given the forthcoming availability of Sentinel-2 (S2) images, this paper provides a systematic comparison of retrieval accuracy and processing speed of a multitude of parametric, non-parametric and physically-based retrieval methods using simulated \{S2\} data. An experimental field dataset (SPARC), collected at the agricultural site of Barrax (Spain), was used to evaluate different retrieval methods on their ability to estimate leaf area index (LAI). With regard to parametric methods, all possible band combinations for several two-band and three-band index formulations and a linear regression fitting function have been evaluated. From a set of over ten thousand indices evaluated, the best performing one was an optimized three-band combination according to ( ρ 560 - ρ 1610 - ρ 2190 ) / ( ρ 560 + ρ 1610 + ρ 2190 ) with a 10-fold cross-validation R \{CV\} 2 of 0.82 ( \{RMSE\} \{CV\} : 0.62). This family of methods excel for their fast processing speed, e.g., 0.05 s to calibrate and validate the regression function, and 3.8 s to map a simulated \{S2\} image. With regard to non-parametric methods, 11 machine learning regression algorithms (MLRAs) have been evaluated. This methodological family has the advantage of making use of the full optical spectrum as well as flexible, nonlinear fitting. Particularly kernel-based \{MLRAs\} lead to excellent results, with variational heteroscedastic (VH) Gaussian Processes regression (GPR) as the best performing method, with a R \{CV\} 2 of 0.90 ( \{RMSE\} \{CV\} : 0.44). Additionally, the model is trained and validated relatively fast (1.70 s) and the processed image (taking 73.88 s) includes associated uncertainty estimates. More challenging is the inversion of a \{PROSAIL\} based radiative transfer model (RTM). After the generation of a look-up table (LUT), a multitude of cost functions and regularization options were evaluated. The best performing cost function is Pearson’s χ -square. It led to a R 2 of 0.74 (RMSE: 0.80) against the validation dataset. While its validation went fast (0.33 s), due to a per-pixel \{LUT\} solving using a cost function, image processing took considerably more time (01:01:47). Summarizing, when it comes to accurate and sufficiently fast processing of imagery to generate vegetation attributes, this paper concludes that the family of kernel-based \{MLRAs\} (e.g. GPR) is the most promising processing approach. "} 
}
@article{Samaras2015156,
title = {"Using Raman-lidar-based regularized microphysical retrievals and Aerosol Mass Spectrometer measurements for the characterization of biomass burning aerosols "},
journal = {"Journal of Computational Physics "},
volume = {"299"},
number = {""},
pages = {"156 - 174"},
year = {"2015"},
note = {""},
issn = {"0021-9991"},
doi = {"https://doi.org/10.1016/j.jcp.2015.06.045"},
url = {"http://www.sciencedirect.com/science/article/pii/S0021999115004441"},
author = {"Stefanos Samaras and Doina Nicolae and Christine Böckmann and Jeni Vasilescu and Ioannis Binietoglou and Lev Labzovskii and Florica Toanca and Alexandros Papayannis"},
keywords = {"Aerosols", "Microphysical properties", "Lidar", "AMS", "AERONET "},
abstract = {"Abstract In this work we extract the microphysical properties of aerosols for a collection of measurement cases with low volume depolarization ratio originating from fire sources captured by the Raman lidar located at the National Institute of Optoelectronics (INOE) in Bucharest. Our algorithm was tested not only for pure smoke but also for mixed smoke and urban aerosols of variable age and growth. Applying a sensitivity analysis on initial parameter settings of our retrieval code was proved vital for producing semi-automatized retrievals with a hybrid regularization method developed at the Institute of Mathematics of Potsdam University. A direct quantitative comparison of the retrieved microphysical properties with measurements from a Compact Time of Flight Aerosol Mass Spectrometer (CToF-AMS) is used to validate our algorithm. Microphysical retrievals performed with sun photometer data are also used to explore our results. Focusing on the fine mode we observed remarkable similarities between the retrieved size distribution and the one measured by the AMS. More complicated atmospheric structures and the factor of absorption appear to depend more on particle radius being subject to variation. A good correlation was found between the aerosol effective radius and particle age, using the ratio of lidar ratios (LR: aerosol extinction to backscatter ratios) as an indicator for the latter. Finally, the dependence on relative humidity of aerosol effective radii measured on the ground and within the layers aloft show similar patterns. "} 
}
@article{Pezze20152145,
title = {"Dopamine \{D1\} receptor stimulation modulates the formation and retrieval of novel object recognition memory: Role of the prelimbic cortex "},
journal = {"European Neuropsychopharmacology "},
volume = {"25"},
number = {"11"},
pages = {"2145 - 2156"},
year = {"2015"},
note = {""},
issn = {"0924-977X"},
doi = {"https://doi.org/10.1016/j.euroneuro.2015.07.018"},
url = {"http://www.sciencedirect.com/science/article/pii/S0924977X15002369"},
author = {"Marie A. Pezze and Hayley J. Marshall and Kevin C.F. Fone and Helen J. Cassaday"},
keywords = {"\{D1\} receptors", "SKF81297", "Novel object recognition", "Medial prefrontal cortex", "Rat "},
abstract = {"Abstract Previous studies have shown that dopamine \{D1\} receptor antagonists impair novel object recognition memory but the effects of dopamine \{D1\} receptor stimulation remain to be determined. This study investigated the effects of the selective dopamine \{D1\} receptor agonist \{SKF81297\} on acquisition and retrieval in the novel object recognition task in male Wistar rats. \{SKF81297\} (0.4 and 0.8 mg/kg s.c.) given 15 min before the sampling phase impaired novel object recognition evaluated 10 min or 24 h later. The same treatments also reduced novel object recognition memory tested 24 h after the sampling phase and when given 15 min before the choice session. These data indicate that \{D1\} receptor stimulation modulates both the encoding and retrieval of object recognition memory. Microinfusion of \{SKF81297\} (0.025 or 0.05 μg/side) into the prelimbic sub-region of the medial prefrontal cortex (mPFC) in this case 10 min before the sampling phase also impaired novel object recognition memory, suggesting that the mPFC is one important site mediating the effects of \{D1\} receptor stimulation on visual recognition memory. "} 
}
@article{You2016169,
title = {"A nonlinear model for estimating ground-level \{PM10\} concentration in Xi'an using \{MODIS\} aerosol optical depth retrieval "},
journal = {"Atmospheric Research "},
volume = {"168"},
number = {""},
pages = {"169 - 179"},
year = {"2016"},
note = {""},
issn = {"0169-8095"},
doi = {"https://doi.org/10.1016/j.atmosres.2015.09.008"},
url = {"http://www.sciencedirect.com/science/article/pii/S0169809515002860"},
author = {"Wei You and Zengliang Zang and Lifeng Zhang and Mei Zhang and Xiaobin Pan and Yi Li"},
keywords = {"Aerosol optical depth", "PM10", "MODIS", "Nonlinear model "},
abstract = {"Abstract Satellite measurements have been widely used to estimate particulate matters (PMs) on the ground and their effects on human health. However, such estimation is susceptible to meteorological conditions and may result in large errors. In this study, we developed a nonlinear empirical model for seasonal ground-level \{PM10\} prediction in Xi'an, Shaanxi province of northwestern China. The nonlinear model is based on 3 years (2011–2013) of daily \{PM10\} concentration data from 13 \{PM10\} monitoring stations in Xi'an, aerosol optical depth (AOD) data derived from the Moderate Resolution Imaging Spectroradiometer (MODIS), surface meteorological measurements, and NCEP/NCAR reanalysis data. The nonlinear model corrects the \{AOD\} data using the height of plenary boundary layer and surface relative humidity, and further adjusts the corrected \{AOD\} according to visibility, surface temperature and surface wind speed. Our results show that there is almost a threefold improvement from 0.28 to 0.78 in the correlation coefficient when using the nonlinear model compared to using a linear regression model of \{AOD\} and PM10. The root-mean-square error (RMSE) is reduced from 34.42 to 21.33 μg/m3 using the nonlinear model over the linear model. Further analysis about meteorological variables shows that relative humidity and visibility are important factors to improve the relationship between \{AOD\} and PM10. The relationship between the predicted \{PM10\} concentration from the nonlinear model and observed \{PM10\} concentration is the best in winter, moderate in autumn and spring, and poor in summer. Further validation has shown that the nonlinear model is able to explain approximately 79% (R2 = 0.79, n = 270, p &lt; 0.01) of the variability in the monthly-mean \{PM10\} concentration with an \{RMSE\} of 11.7 μg/m3 and mean absolute percentage error of 14.2% based on monthly-mean data set. These results are useful for accessing surface \{PM10\} concentration and monitoring regional air pollution. "} 
}
@article{Wissman201575,
title = {"Why does collaborative retrieval improve memory? Enhanced relational and item-specific processing "},
journal = {"Journal of Memory and Language "},
volume = {"84"},
number = {""},
pages = {"75 - 87"},
year = {"2015"},
note = {""},
issn = {"0749-596X"},
doi = {"https://doi.org/10.1016/j.jml.2015.05.003"},
url = {"http://www.sciencedirect.com/science/article/pii/S0749596X15000716"},
author = {"Kathryn T. Wissman and Katherine A. Rawson"},
keywords = {"Collaborative memory", "Learning", "Distinctiveness theory "},
abstract = {"Abstract Engaging in collaborative retrieval practice increases performance on subsequent memory tests taken individually (Blumen &amp; Stern, 2011). However, the basis of these post-collaborative benefits is largely unexplained. Thus, the primary goal of the current research was to investigate the cognitive mechanisms underlying post-collaborative benefits vis-à-vis the theoretical framework of distinctiveness theory, which postulates that two processes influence memory. Relational processing refers to the encoding of similarity among a set of items, whereas item-specific processing refers to the encoding of information that differentiates items from one another. The central claim of distinctiveness theory is that memory is enhanced when differences among individual items are processed in the context of the similarity among those items (referred to as distinctive processing). The basic design of all three experiments was similar (i.e., close replications with intent to provide multiple estimates of effect sizes on which to base conclusions): Learners were asked to study lists of exemplars from taxonomic categories, followed by recall practice that occurred either collaboratively or individually. All learners completed individual final tests, immediately after practice and/or after a delay. Of greatest theoretical interest for diagnosing the extent to which post-collaborative benefits reflect distinctive processing, we examined indicators of relational processing (clustering and category access) and item-specific processing (items recalled per category and recognition performance). Results across the three experiments established that distinctive processing (i.e., enhancements in both relational and item-specific processing) contributes to post-collaborative benefits across both short and long retention intervals. "} 
}
@article{Alzu’bi201520,
title = {"Semantic content-based image retrieval: A comprehensive study "},
journal = {"Journal of Visual Communication and Image Representation "},
volume = {"32"},
number = {""},
pages = {"20 - 54"},
year = {"2015"},
note = {""},
issn = {"1047-3203"},
doi = {"https://doi.org/10.1016/j.jvcir.2015.07.012"},
url = {"http://www.sciencedirect.com/science/article/pii/S1047320315001327"},
author = {"Ahmad Alzu’bi and Abbes Amira and Naeem Ramzan"},
keywords = {"CBIR", "Image features", "Dimensionality reduction", "Deep learning", "Relevance feedback", "Image annotation", "Visualization", "Semantic gap "},
abstract = {"Abstract The complexity of multimedia contents is significantly increasing in the current digital world. This yields an exigent demand for developing highly effective retrieval systems to satisfy human needs. Recently, extensive research efforts have been presented and conducted in the field of content-based image retrieval (CBIR). The majority of these efforts have been concentrated on reducing the semantic gap that exists between low-level image features represented by digital machines and the profusion of high-level human perception used to perceive images. Based on the growing research in the recent years, this paper provides a comprehensive review on the state-of-the-art in the field of CBIR. Additionally, this study presents a detailed overview of the \{CBIR\} framework and improvements achieved; including image preprocessing, feature extraction and indexing, system learning, benchmarking datasets, similarity matching, relevance feedback, performance evaluation, and visualization. Finally, promising research trends, challenges, and our insights are provided to inspire further research efforts. "} 
}
@article{Cheng2015349,
title = {"A non-linear case-based reasoning approach for retrieval of similar cases and selection of target credits in \{LEED\} projects "},
journal = {"Building and Environment "},
volume = {"93, Part 2"},
number = {""},
pages = {"349 - 361"},
year = {"2015"},
note = {""},
issn = {"0360-1323"},
doi = {"https://doi.org/10.1016/j.buildenv.2015.07.019"},
url = {"http://www.sciencedirect.com/science/article/pii/S0360132315300676"},
author = {"Jack C.P. Cheng and Lucky J. Ma"},
keywords = {"Artificial neural network", "Case-based reasoning", "Decision support tool", "LEED-NC v2009", "Non-linear", "Target credit selection "},
abstract = {"Abstract Leadership in Energy and Environmental Design (LEED) is a widely used international green building certification program developed by the U.S. Green Building Council (USGBC). Although the need for \{LEED\} certification has grown significantly, \{LEED\} managers still face challenges in target credit selection and green building technology design. They frequently meet new types of projects with different project characteristics and requirements. Therefore, it would be helpful if \{LEED\} managers could refer to other similar certified green building cases when planning and designing \{LEED\} projects. However, this is not supported in current studies and research. This paper proposes a case-based reasoning (CBR) approach to provide case studies of similar certified green building projects and suggestions on target \{LEED\} credits. Currently, linear formation of Local-Global method is commonly used in the retrieval step of CBR. This paper presents a non-linear formation of Local-Global retrieval based on Artificial Neural Network (ANN), which can provide a higher accuracy. \{LEED\} for New Construction (LEED-NC) is the focus of this paper, and 1000 LEED-NC v2009 certified cases were collected for the case base. Pairwise comparison was conducted to generate the local distance (attribute similarity) and the target for training the \{ANN\} model. The proposed non-linear \{CBR\} approach was tested and evaluated using 20 recently certified projects, and the results showed a prediction accuracy of 80.75% on the \{LEED\} credit selection. The results were also compared with those calculated by commonly used linear \{CBR\} approaches: Multiple Regression Analysis, Correlation Analysis, and the k-NN approach. The accuracy achieved by these methods was between 71.23% and 77.54%, which was lower than the proposed approach. }"
}

