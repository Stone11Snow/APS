[
    {
        "abstract": "Abstract Deep learning with a convolutional neural network (CNN) has been proved to be very effective in feature extraction and representation of images. For image classification problems, this work aims at exploring the capability of extreme learning machine on high-level deep features of images. Additionally, motivated by the biological learning mechanism of ELM, in this paper, an adaptive extreme learning machine (AELM) method is proposed for handling cross-task (domain) learning problems, without loss of its nature of randomization and high efficiency. The proposed \\{AELM\\} is an extension of \\{ELM\\} from single task to cross task learning, by introducing a new error term and Laplacian graph based manifold regularization term in objective function. We have discussed the nearest neighbor, support vector machines and extreme learning machines for image classification under deep convolutional activation feature representation. Specifically, we adopt 4 benchmark object recognition datasets from multiple sources with domain bias for evaluating different classifiers. The deep features of the object dataset are obtained by a well-trained \\{CNN\\} with five convolutional layers and three fully-connected layers on ImageNet. Experiments demonstrate that the proposed \\{AELM\\} is comparable and effective in single and multiple domains based recognition tasks.", 
        "author": "Lei Zhang and Zhenwei He and Yan Liu", 
        "keyword": "Deep learning\", \"Image classification\", \"Support vector machine\", \"Extreme learning machine\", \"Object recognition", 
        "title": "Deep object recognition across domains based on adaptive extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) is a popular machine learning method which can flexibly simulate the relationships of real-world classification applications. When facing problems (i.e., data sets) with a smaller number of samples (i.e., instances), \\{ELM\\} may often result in the overfitting trouble. In this paper, we propose a new Instance Cloned Extreme Learning Machine (IC-ELM for short) which can handle numerous different classification problems. IC-ELM uses an instance cloning method to balance the input data\u2019s distribution and extend the training data set, which alleviates the overfitting issue and enhances the testing classification accuracy. Experiments and comparisons on 20 \\{UCI\\} data sets, and validations on image and text classification applications, demonstrate that IC-ELM is able to achieve superior results compared to the original \\{ELM\\} algorithm and its variants, as well as several other classical machine learning algorithms.", 
        "author": "Yongshan Zhang and Jia Wu and Chuan Zhou and Zhihua Cai", 
        "keyword": "Extreme Learning Machine\", \"Instance cloning\", \"Local learning\", \"Classification", 
        "title": "Instance cloned extreme learning machine"
    }, 
    {
        "abstract": "Abstract Multi-class sentiment classification has extensive application backgrounds, whereas studies on this issue are still relatively scarce. In this paper, a framework for multi-class sentiment classification is proposed, which includes two parts: 1) selecting important features of texts using the feature selection algorithm, and 2) training multi-class sentiment classifier using the machine learning algorithm. Then, experiments are conducted for comparing the performances of four popular feature selection algorithms (document frequency, \\{CHI\\} statistics, information gain and gain ratio) and five popular machine learning algorithms (decision tree, na\u00efve Bayes, support vector machine, radial basis function neural network and K-nearest neighbor) in multi-class sentiment classification. The experiments are conducted on three public datasets which include twelve data subsets, and 10-fold cross validation is used to obtain the classification accuracy concerning each combination of feature selection algorithm, machine learning algorithm, feature set size and data subset. Based on the obtained 3600 classification accuracies (4 feature selection algorithms \u00d7\u20095 machine learning algorithms \u00d7\u200915 feature set sizes \u00d7\u200912 data subsets), the average classification accuracy of each algorithm is calculated, and the Wilcoxon test is used to verify the existence of significant difference between different algorithms in multi-class sentiment classification. The results show that, in terms of classification accuracy, gain ratio performs best among the four feature selection algorithms and support vector machine performs best among the five machine learning algorithms. In terms of execution time, the similar comparisons are also conducted. The obtained results would be valuable for further improving the existing multi-class sentiment classifiers and developing new multi-class sentiment classifiers.", 
        "author": "Yang Liu and Jian-Wu Bi and Zhi-Ping Fan", 
        "keyword": "Multi-class sentiment classification\", \"Experimental comparison\", \"Feature selection algorithms\", \"Machine learning algorithms", 
        "title": "Multi-class sentiment classification: The experimental comparisons of feature selection and machine learning algorithms"
    }, 
    {
        "abstract": "Abstract To compact the architecture of extreme learning machine (ELM), two incremental learning algorithms are proposed in this paper. The previous incremental learning algorithms for \\{ELM\\} recruit hidden nodes randomly, which is equivalent to implementing a random selection from a candidate set of infinite size. Hence, it is impossible to recruit good hidden nodes, and thus it usually requires more hidden nodes than traditional neural networks to achieve matched performance. To improve the quality of the hidden nodes recruited, an incremental learning algorithm for \\{ELM\\} is presented based on Gram--Schmidt process (GSI-ELM), which recruits the best hidden node from a random subset of fixed size via defining an evaluating criterion at each learning step. However, the \u201cnesting effect\u201d exists in the GSI-ELM, that is to say, the hidden nodes once recruited by GSI-ELM can not be later discarded. To treat this \u201cnesting problem\u201d, the improved GSI-ELM (IGSI-ELM) is generated with an elimination mechanism. At each learning step IGSI-ELM eliminates the worst hidden node from the already-recruited group if it is not the newly-recruited one. Finally, to verify the efficacy and feasibility of the proposed algorithms, i.e. GSI-ELM and IGSI-ELM, in this paper, experiments on regression and classification benchmark data sets are investigated.", 
        "author": "Yong-Ping Zhao and Zhi-Qiang Li and Peng-Peng Xi and Dong Liang and Liguo Sun and Ting-Hao Chen", 
        "keyword": "Extreme learning machine\", \"Incremental learning\", \"QR decomposition\", \"Gram\u2013Schmidt process", 
        "title": "Gram\u2013Schmidt process based incremental extreme learning machine"
    }, 
    {
        "abstract": "Abstract A commonly used technique for improving search engine performance is result caching. In result caching, precomputed results (e.g., \\{URLs\\} and snippets of best matching pages) of certain queries are stored in a fast-access storage. The future occurrences of a query whose results are already stored in the cache can be directly served by the result cache, eliminating the need to process the query using costly computing resources. Although other performance metrics are possible, the main performance metric for evaluating the success of a result cache is hit rate. In this work, we present a machine learning approach to improve the hit rate of a result cache by facilitating a large number of features extracted from search engine query logs. We then apply the proposed machine learning approach to static, dynamic, and static-dynamic caching. Compared to the previous methods in the literature, the proposed approach improves the hit rate of the result cache up to 0.66%, which corresponds to 9.60% of the potential room for improvement.", 
        "author": "Tayfun Kucukyilmaz and B. Barla Cambazoglu and Cevdet Aykanat and Ricardo Baeza-Yates", 
        "keyword": "Query result caching\", \"Machine learning\", \"Feature-based caching\", \"Static caching\", \"Static-dynamic caching", 
        "title": "A machine learning approach for result caching in web search engines"
    }, 
    {
        "abstract": "Abstract Among the machine learning models used for landslide susceptibility indexes calculation, the support vector machine (SVM) is commonly used; however, \\{SVM\\} is time-consuming. In addition, the non-landslide grid cells are selected randomly and/or subjectively, which may result in unreasonable training and validating data for the machine learning models. This study proposes the self-organizing-map (SOM) network-based extreme learning machine (ELM) model to calculate the landslide susceptibility indexes. Wanzhou district in Three Gorges Reservoir Area is selected as the study area. Nine environmental factors are chosen as input variables and 639 investigated landslides are used as recorded landslides. First, an initial landslide susceptibility map is produced using the \\{SOM\\} network, and the reasonable non-landslide grid cells are subsequently selected from the very low susceptible area. Next, the final landslide susceptibility map is produced using the \\{ELM\\} model based on the recorded landslides and reasonable non-landslide grid cells. The single \\{ELM\\} model which selects the non-landslide grid cells randomly, and the \\{SOM\\} network-based \\{SVM\\} model are used for comparisons. It is concluded that the SOM-ELM model possesses higher success and prediction rates than the single \\{ELM\\} and SOM-SVM models, and the \\{ELM\\} has a considerably higher prediction efficiency than the SVM.", 
        "author": "Faming Huang and Kunlong Yin and Jinsong Huang and Lei Gui and Peng Wang", 
        "keyword": "Landslide susceptibility map\", \"Self-organizing-map network\", \"Extreme learning machine\", \"Support keywords =ector machine\", \"Three-Gorges Reservoir", 
        "title": "Landslide susceptibility mapping based on self-organizing-map network and extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, a hybrid learning approach, which combines the extreme learning machine (ELM) with a new switching delayed \\{PSO\\} (SDPSO) algorithm, is proposed for the problem of the short-term load forecasting (STLF). In particular, the input weights and biases of \\{ELM\\} are optimized by a new developed \\{SDPSO\\} algorithm, where the delayed information of locally best particle and globally best particle are exploited to update the velocity of particle. By testing the proposed SDPSO-ELM in a comprehensive manner on a tanh function, this approach obtain better generalization performance and can also avoid adding unnecessary hidden nodes and overtraining problems. Moreover, it has shown outstanding performance than other state-of-the-art ELMs. Finally, the proposed SDPSO-ELM algorithm is successfully applied to the \\{STLF\\} of power system. Experiment results demonstrate that the proposed learning algorithm can get better forecasting results in comparison with the radial basis function neural network (RBFNN) algorithm.", 
        "author": "Nianyin Zeng and Hong Zhang and Weibo Liu and Jinling Liang and Fuad E. Alsaadi", 
        "keyword": "Short-term load forecasting\", \"Extreme learning machine\", \"Switching delayed particle swarm keywords =ptimization (SDPSO)\", \"Neural network\", \"Time-delay", 
        "title": "A switching delayed \\{PSO\\} optimized extreme learning machine for short-term load forecasting"
    }, 
    {
        "abstract": "Abstract We evaluate the performance of four machine learning methods for modeling and predicting \\{FCC\\} solute diffusion barriers. More than 200 \\{FCC\\} solute diffusion barriers from previous density functional theory (DFT) calculations served as our dataset to train four machine learning methods: linear regression (LR), decision tree (DT), Gaussian kernel ridge regression (GKRR), and artificial neural network (ANN). We separately optimize key physical descriptors favored by each method to model diffusion barriers. We also assess the ability of each method to extrapolate when faced with new hosts with limited known data. \\{GKRR\\} and \\{ANN\\} were found to perform the best, showing 0.15 eV cross-validation errors and predicting impurity diffusion in new hosts to within 0.2 eV when given only 5 data points from the host. We demonstrate the success of a combined \\{DFT\\} + data mining approach towards solving materials science challenges and predict the diffusion barrier of all available impurities across all \\{FCC\\} hosts.", 
        "author": "Henry Wu and Aren Lorenson and Ben Anderson and Liam Witteman and Haotian Wu and Bryce Meredig and Dane Morgan", 
        "keyword": "Diffusion\", \"Data-mining\", \"Machine learning\", \"DFT\", \"Neural network", 
        "title": "Robust \\{FCC\\} solute diffusion predictions from ab-initio machine learning methods"
    }, 
    {
        "abstract": "Abstract Dark slope streaks (DSSs) on the Martian surface are one of the active geologic features that can be observed on Mars nowadays. The detection of \\{DSS\\} is a prerequisite for studying its appearance, morphology, and distribution to reveal its underlying geological mechanisms. In addition, increasingly massive amounts of Mars high resolution data are now available. Hence, an automatic detection method for locating \\{DSSs\\} is highly desirable. In this research, we present an automatic \\{DSS\\} detection method by combining interest region extraction and machine learning techniques. The interest region extraction combines gradient and regional grayscale information. Moreover, a novel recognition strategy is proposed that takes the normalized minimum bounding rectangles (MBRs) of the extracted regions to calculate the Local Binary Pattern (LBP) feature and train a \\{DSS\\} classifier using the Adaboost machine learning algorithm. Comparative experiments using five different feature descriptors and three different machine learning algorithms show the superiority of the proposed method. Experimental results utilizing 888 extracted region samples from 28 HiRISE images show that the overall detection accuracy of our proposed method is 92.4%, with a true positive rate of 79.1% and false positive rate of 3.7%, which in particular indicates great performance of the method at eliminating non-DSS regions.", 
        "author": "Yexin Wang and Kaichang Di and Xin Xin and Wenhui Wan", 
        "keyword": "Dark slope streak\", \"Martian surface\", \"Machine learning\", \"HiRISE image\", \"Region detection", 
        "title": "Automatic detection of Martian dark slope streaks by machine learning using HiRISE images"
    }, 
    {
        "abstract": "Abstract This paper presents and evaluates a prototype smartphone/server software service entitled the Occupant Mobile Gateway (OMG), developed to collect and analyze real-time occupant subjective feedback and objective thermal data from embedded sensors. The objective of the \\{OMG\\} is to enable mobile sensing as a scalable approach to realize the comfort and energy savings potential of data-driven thermal management using personalized comfort models. In contrast to the universal application of static comfort criteria, data-driven models have the potential to enable flexible and continuous interpretation of thermal comfort, allowing for more personalized control of the thermal environment and minimization of the energy wasted by overheating and overcooling. Novel machine-learning algorithms are applied to synthesize subjective and physical thermal measurements into personalized comfort models which can be interpreted to determine optimal temperature setpoints based on energy and comfort goals. The feasibility of machine learning algorithms to generate useful personalized occupant comfort profiles is examined using field data from four test sites (N\u00a0=\u00a045 occupants total). The findings demonstrate that it is possible to model the thermal preferences of occupants at both the individual and zone level with data collected over a relatively small time period (2-weeks). Application of occupant-driven comfort models in annual energy simulations shows that thermal management informed by occupant feedback has the potential for significant energy savings.", 
        "author": "K. Konis and M. Annavaram", 
        "keyword": "Energy efficiency\", \"Indoor environmental quality\", \"Thermal comfort\", \"Machine learning\", \"Mobile keywords =ensing\", \"Indoor location", 
        "title": "The Occupant Mobile Gateway: A participatory sensing and machine-learning approach for occupant-aware energy management"
    }, 
    {
        "abstract": "Abstract The control of product quality of complex chemical processes strictly depends on the measure of the key process variables. However, the online measure device is extremely expensive, and these devices are hard to protect. Meanwhile, there is a delay for these online measure devices. Therefore, the soft sensor technology plays a vital role in measuring the key process variables. Extreme Learning Machine (ELM) is an efficient and simple single layer feed-forward neural networks (SLFNs) to building an exact soft sensor model. However, unsuitable selected hidden nodes and random parameters will greatly affect the performance of the ELM. Therefore, this paper proposes a novel Self-Organizing Extreme Learning Machine (SOELM) algorithm constructed by the biological neuron-glia interaction principle to solve the issue of the ELM. Firstly, the weights between input layer nodes and the \\{CNS\\} are tuned iteratively by the Hebbian learning rule. Then the network structure is adjusted self-organizing by Mutual Information (MI) among different structures of networks. Secondly, the weights between the \\{CNS\\} and output layer nodes are obtained by the ELM. The experimental results based on different \\{UCI\\} data sets prove that the \\{SOELM\\} has a better generalization capability and stability than that of the ELM. Moreover, our proposed method is developed as a soft sensor model for accurately predicting the key variables of the Purified Terephthalic Acid (PTA) process.", 
        "author": "Zhiqiang Geng and Jungen Dong and Jie Chen and Yongming Han", 
        "keyword": "Self-Organizing\", \"Extreme Learning Machine\", \"Mutual Information\", \"Hebbian learning rule\", \"Soft keywords =ensor\", \"Complicated chemical processes", 
        "title": "A new Self-Organizing Extreme Learning Machine soft sensor model and its applications in complicated chemical processes"
    }, 
    {
        "abstract": "Abstract Accurate and timely predicting values of performance parameters are currently strongly needed for important complex equipment in engineering. In time series prediction, two problems are urgent to be solved. One problem is how to achieve the accuracy, stability and efficiency together, and the other is how to handle time series with multiple regimes. To solve these two problems, random forests-based extreme learning machine ensemble model and a novel multi-regime approach are proposed respectively, and these two approaches can be integrated to achieve better performance. First, the extreme learning machine (ELM) is used in the proposed model because of its efficiency. Then the regularized \\{ELM\\} and ensemble learning strategy are used to improve generalization performance and prediction accuracy. The bootstrap sampling technique is used to generate training sample sets for multiple base-level \\{ELM\\} models, and then the random forests (RF) model is used as the combiner to aggregate these \\{ELM\\} models to achieve more accurate and stable performance. Next, based on the specific properties of turbofan engine time series, a multi-regime approach is proposed to handle it. Regimes are first separated, then the proposed RF-based \\{ELM\\} ensemble model is used to learn models of all regimes, individually, and last, all the learned regime models are aggregated to predict performance parameter at the future timestamp. The proposed RF-based \\{ELM\\} ensemble model and multi-regime approaches are evaluated by using \\{NN3\\} time series and \\{NASA\\} turbofan engine time series, and then the proposed model is applied to the exhaust gas temperature prediction of \\{CFM\\} engine. The results demonstrate that the proposed RF-based \\{ELM\\} ensemble model and multi-regime approach can be accurate, stable and efficient in predicting multi-regime time series, and it can be robust against overfitting.", 
        "author": "Lin Lin and Fang Wang and Xiaolong Xie and Shisheng Zhong", 
        "keyword": "Extreme learning machine\", \"Random forests\", \"Ensemble learning\", \"Multi-regime time series\", \"Time series prediction", 
        "title": "Random forests-based extreme learning machine ensemble for multi-regime time series prediction"
    }, 
    {
        "abstract": "Abstract Machine learning (ML) is continuously unleashing its power in a wide range of applications. It has been pushed to the forefront in recent years partly owing to the advent of big data. \\{ML\\} algorithms have never been better promised while challenged by big data. Big data enables \\{ML\\} algorithms to uncover more fine-grained patterns and make more timely and accurate predictions than ever before; on the other hand, it presents major challenges to \\{ML\\} such as model scalability and distributed computing. In this paper, we introduce a framework of \\{ML\\} on big data (MLBiD) to guide the discussion of its opportunities and challenges. The framework is centered on \\{ML\\} which follows the phases of preprocessing, learning, and evaluation. In addition, the framework is also comprised of four other components, namely big data, user, domain, and system. The phases of \\{ML\\} and the components of \\{MLBiD\\} provide directions for identification of associated opportunities and challenges and open up future work in many unexplored or under explored research areas.", 
        "author": "Lina Zhou and Shimei Pan and Jianwu Wang and Athanasios V. Vasilakos", 
        "keyword": "Machine learning\", \"Big data\", \"Data preprocessing\", \"Evaluation\", \"Parallelization", 
        "title": "Machine learning on big data: Opportunities and challenges"
    }, 
    {
        "abstract": "Abstract Fixed placements of inertial sensors have been utilized by previous human activity recognition algorithms to train the classifier. However, the distribution of sensor data is seriously affected by the sensor placement. The performance will be degraded when the model trained on one placement is used in others. In order to tackle this problem, a fast and robust human activity recognition model called TransM-RKELM (Transfer learning mixed and reduced kernel Extreme Learning Machine) is proposed in this paper; It uses a kernel fusion method to reduce the influence by the choice of kernel function and the reduced kernel is utilized to reduce the computational cost. After realizing initial activity recognition model by mixed and reduced kernel extreme learning model (M-RKELM), in the online phase M-RKELM is utilized to classify the activity and adapt the model to new locations based on high confident recognition results in real time. Experimental results show that the proposed model can adapt the classifier to new sensor locations quickly and obtain good recognition performance.", 
        "author": "Zhelong Wang and Donghui Wu and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang", 
        "keyword": "Human activity recognition\", \"Extreme learning machine\", \"Inertial sensors\", \"Mixed kernel\", \"Machine learning", 
        "title": "Kernel fusion based extreme learning machine for cross-location activity recognition"
    }, 
    {
        "abstract": "AbstractBackground Identification of underlying mechanisms behind drugs side effects is of extreme interest and importance in drugs discovery today. Therefore machine learning methodology, linking such different multi features aspects and able to make predictions, are crucial for understanding side effects. Methods In this paper we present DrugClust, a machine learning algorithm for drugs side effects prediction. DrugClust pipeline works as follows: first drugs are clustered with respect to their features and then side effects predictions are made, according to Bayesian scores. Biological validation of resulting clusters can be done via enrichment analysis, another functionality implemented in the methodology. This last tool is of extreme interest for drug discovery, given that it can be used as a validation of the clusters obtained, as well as for the study of new possible interactions between certain side effects and nontargeted pathways. Results Results were evaluated on a 5-folds cross validations procedure, and extensive comparisons were made with available datasets in the field: Zhang et al. (2015), Liu et al. (2012) and Mizutani et al. (2012). Results are promising and show better performances in most of the cases with respect to the available literature. Availability DrugClust is an R package freely available at: https://cran.r-project.org/web/packages/DrugClust/index.html.", 
        "author": "Giovanna Maria Dimitri and Pietro Li\u00f3", 
        "keyword": "Drugs side effects\", \"Machine learning\", \"R package DrugClust", 
        "title": "DrugClust: A machine learning approach for drugs side effects prediction"
    }, 
    {
        "abstract": "AbstractObjective Suicide is a major concern for those afflicted by schizophrenia. Identifying patients at the highest risk for future suicide attempts remains a complex problem for psychiatric interventions. Machine learning models allow for the integration of many risk factors in order to build an algorithm that predicts which patients are likely to attempt suicide. Currently it is unclear how to integrate previously identified risk factors into a clinically relevant predictive tool to estimate the probability of a patient with schizophrenia for attempting suicide. Methods We conducted a cross-sectional assessment on a sample of 345 participants diagnosed with schizophrenia spectrum disorders. Suicide attempters and non-attempters were clearly identified using the Columbia Suicide Severity Rating Scale (C-SSRS) and the Beck Suicide Ideation Scale (BSS). We developed four classification algorithms using a regularized regression, random forest, elastic net and support vector machine models with sociocultural and clinical variables as features to train the models. Results All classification models performed similarly in identifying suicide attempters and non-attempters. Our regularized logistic regression model demonstrated an accuracy of 67% and an area under the curve (AUC) of 0.71, while the random forest model demonstrated 66% accuracy and an \\{AUC\\} of 0.67. Support vector classifier (SVC) model demonstrated an accuracy of 67% and an \\{AUC\\} of 0.70, and the elastic net model demonstrated and accuracy of 65% and an \\{AUC\\} of 0.71. Conclusion Machine learning algorithms offer a relatively successful method for incorporating many clinical features to predict individuals at risk for future suicide attempts. Increased performance of these models using clinically relevant variables offers the potential to facilitate early treatment and intervention to prevent future suicide attempts.", 
        "author": "Nuwan C. Hettige and Thai Binh Nguyen and Chen Yuan and Thanara Rajakulendran and Jermeen Baddour and Nikhil Bhagwat and Ali Bani-Fatemi and Aristotle N. Voineskos and M. Mallar Chakravarty and Vincenzo De Luca", 
        "keyword": "Suicide\", \"Schizophrenia\", \"Childhood trauma\", \"Migration\", \"Machine learning", 
        "title": "Classification of suicide attempters in schizophrenia using sociocultural and clinical features: A machine learning approach"
    }, 
    {
        "abstract": "Abstract In our society, many fields have produced a large number of data streams. How to mining the interesting knowledge and patterns from continuous data stream becomes a problem which we have to solve. Different from conventional classification algorithms, data stream classification algorithms have to adjust their classification models with the change of data stream because of concept drift. However, conventional classification models will keep stable once models are trained. To solve the problem, a dynamic extreme learning machine for data stream classification (DELM) is proposed. \\{DELM\\} utilizes online learning mechanism to train \\{ELM\\} as basic classifier and trains a double hidden layer structure to improve the performance of ELM. When an alert about concept drift is set, more hidden layer nodes are added into \\{ELM\\} to improve the generalization ability of classifier. If the value measuring concept drift reaches the upper limit or the accuracy of \\{ELM\\} is in a low level, the current classifier will be deleted, and the algorithm will use new data to train a new classifier so as to learn new concept. The experimental results showed \\{DELM\\} could improve the accuracy of classification result, and can adapt to new concept in a short time.", 
        "author": "Shuliang Xu and Junhong Wang", 
        "keyword": "Data stream\", \"Classification\", \"Concept drift\", \"Extreme learning machine\", \"Online learning", 
        "title": "Dynamic extreme learning machine for data stream classification"
    }, 
    {
        "abstract": "Abstract The analysis of travel mode choice is an important task in transportation planning and policy making in order to understand and predict travel demands. While advances in machine learning have led to numerous powerful classifiers, their usefulness for modeling travel mode choice remains largely unexplored. Using extensive Dutch travel diary data from the years 2010 to 2012, enriched with variables on the built and natural environment as well as on weather conditions, this study compares the predictive performance of seven selected machine learning classifiers for travel mode choice analysis and makes recommendations for model selection. In addition, it addresses the importance of different variables and how they relate to different travel modes. The results show that random forest performs significantly better than any other of the investigated classifiers, including the commonly used multinomial logit model. While trip distance is found to be the most important variable, the importance of the other variables varies with classifiers and travel modes. The importance of the meteorological variables is highest for support vector machine, while temperature is particularly important for predicting bicycle and public transport trips. The results suggest that the analysis of variable importance with respect to the different classifiers and travel modes is essential for a better understanding and effective modeling of people\u2019s travel behavior.", 
        "author": "Julian Hagenauer and Marco Helbich", 
        "keyword": "Travel mode choice\", \"Classification\", \"Machine learning\", \"The Netherlands", 
        "title": "A comparative study of machine learning classifiers for modeling travel mode choice"
    }, 
    {
        "abstract": "Abstract This study investigates the success of a multiobjective genetic algorithm (GA) combined with state-of-the-art machine learning (ML) techniques for the feature subset selection (FSS) in binary classification problem (BCP). Recent studies have focused on improving the accuracy of \\{BCP\\} by including all of the features, neglecting to determine the best performing subset of features. However, for some problems, the number of features may reach thousands, which will cause too much computation power to be consumed during the feature evaluation and classification phases, also possibly reducing the accuracy of the results. Therefore, selecting the minimum number of features while preserving and/or increasing the accuracy of the results at a high level becomes an important issue for achieving fast and accurate binary classification. Our multiobjective evolutionary algorithm includes two phases, \\{FSS\\} using a \\{GA\\} and applying \\{ML\\} techniques for the BCP. Since exhaustively investigating all of the feature subsets is intractable, a \\{GA\\} is preferred for the first phase of the algorithm for intelligently detecting the most appropriate feature subset. The \\{GA\\} uses multiobjective crossover and mutation operators to improve a population of individuals (each representing a selected feature subset) and obtain (near-) optimal solutions through generations. In the second phase of the algorithms, the fitness of the selected subset is decided by using state-of-the-art \\{ML\\} techniques; Logistic Regression, Support Vector Machines, Extreme Learning Machine, K-means, and Affinity Propagation. The performance of the multiobjective evolutionary algorithm (and the \\{ML\\} techniques) is evaluated with comprehensive experiments and compared with state-of-the-art algorithms, Greedy Search, Particle Swarm Optimization, Tabu Search, and Scatter Search. The proposed algorithm was observed to be robust and it performed better than the existing methods on most of the datasets.", 
        "author": "Ay\u00e7a Deniz and Hakan Ezgi Kiziloz and Tansel Dokeroglu and Ahmet Cosar", 
        "keyword": "Multiobjective feature selection\", \"Evolutionary algorithm\", \"Binary classification\", \"Supervised/unsupervised machine learning", 
        "title": "Robust multiobjective evolutionary feature subset selection algorithm for binary classification using machine learning techniques"
    }, 
    {
        "abstract": "AbstractObjective Major depressive disorder (MDD) is a systemic and multifactorial disorder that involves abnormalities in multiple biochemical pathways and the autonomic nervous system. This study applied a machine-learning method to classify \\{MDD\\} and control groups by incorporating data from serum proteomic analysis and heart rate variability (HRV) analysis for the identification of novel peripheral biomarkers. Methods The study subjects consisted of 25 drug-free female \\{MDD\\} patients and 25 age- and sex-matched healthy controls. First, quantitative serum proteome profiles were analyzed by liquid chromatography-tandem mass spectrometry using pooled serum samples from 10 patients and 10 controls. Next, candidate proteins were quantified with multiple reaction monitoring (MRM) in 50 subjects. We also analyzed 22 linear and nonlinear \\{HRV\\} parameters in 50 subjects. Finally, we identified a combined biomarker panel consisting of proteins and \\{HRV\\} indexes using a support vector machine with recursive feature elimination. Results A separation between \\{MDD\\} and control groups was achieved using five parameters (apolipoprotein B, group-specific component, ceruloplasmin, RMSSD, and SampEn) at 80.1% classification accuracy. A combination of \\{HRV\\} and proteomic data achieved better classification accuracy. Conclusions A high classification accuracy can be achieved by combining multimodal information from heart rate dynamics and serum proteomics in MDD. Our approach can be helpful for accurate clinical diagnosis of MDD. Further studies using larger, independent cohorts are needed to verify the role of these candidate biomarkers for \\{MDD\\} diagnosis.", 
        "author": "Eun Young Kim and Min Young Lee and Se Hyun Kim and Kyooseob Ha and Kwang Pyo Kim and Yong Min Ahn", 
        "keyword": "Major depressive disorder\", \"Biomarker\", \"Proteomics\", \"Heart rate variability\", \"Machine-learning", 
        "title": "Diagnosis of major depressive disorder by combining multimodal information from heart rate dynamics and serum proteomics using machine-learning algorithm"
    }, 
    {
        "abstract": "Abstract Electricity load forecasting is an important tool which can be utilized to enable effective control of commercial building electricity loads. Accurate forecasts of commercial building electricity loads can bring significant environmental and economic benefits by reducing electricity use and peak demand and the corresponding \\{GHG\\} emissions. This paper presents a review of different electricity load forecasting models with a particular focus on regression models, discussing different applications, most commonly used regression variables and methods to improve the performance and accuracy of the models. A comparison between the models is then presented for forecasting day ahead hourly electricity loads using real building and Campus data obtained from the Kensington Campus and Tyree Energy Technologies Building (TETB) at the University of New South Wales (UNSW). The results reveal that Artificial Neural Networks with Bayesian Regulation Backpropagation have the best overall root mean squared and mean absolute percentage error performance and almost all the models performed better predicting the overall Campus load than the single building load. The models were also tested on forecasting daily peak electricity demand. For each model, the obtained error for daily peak demand forecasts was higher than the average day ahead hourly forecasts. The regression models which were the main focus of the study performed fairly well in comparison to other more advanced machine learning models.", 
        "author": "B. Yildiz and J.I. Bilbao and A.B. Sproul", 
        "keyword": "Short term load forecasting for commercial buildings\", \"Review of regression models\", \"Machine keywords =earning\", \"Neural Networks\", \"Support Vector Regression\", \"Regression Trees", 
        "title": "A review and analysis of regression and machine learning models on commercial building electricity load forecasting"
    }, 
    {
        "abstract": "Abstract Protein fold recognition is an important problem in bioinformatics to predict three-dimensional structure of a protein. One of the most challenging tasks in protein fold recognition problem is the extraction of efficient features from the amino-acid sequences to obtain better classifiers. In this paper, we have proposed six descriptors to extract features from protein sequences. These descriptors are applied in the first stage of a three-stage framework PCA-DELM-LDA to extract feature vectors from the amino-acid sequences. Principal Component Analysis \\{PCA\\} has been implemented to reduce the number of extracted features. The extracted feature vectors have been used with original features to improve the performance of the Deep Extreme Learning Machine \\{DELM\\} in the second stage. Four new features have been extracted from the second stage and used in the third stage by Linear Discriminant Analysis \\{LDA\\} to classify the instances into 27 folds. The proposed framework is implemented on the independent and combined feature sets in \\{SCOP\\} datasets. The experimental results show that extracted feature vectors in the first stage could improve the performance of \\{DELM\\} in extracting new useful features in second stage.", 
        "author": "Wisam Ibrahim and Mohammad Saniee Abadeh", 
        "keyword": "Protein fold recognition\", \"Extreme learning machine\", \"Protein descriptor\", \"Feature extraction", 
        "title": "Extracting features from protein sequences to improve deep extreme learning machine for protein fold recognition"
    }, 
    {
        "abstract": "Abstract One of the biggest problems in automated diagnosis of psychiatric disorders from medical images is the lack of sufficiently large samples for training. Sample size is especially important in the case of highly heterogeneous disorders such as schizophrenia, where machine learning models built on relatively low numbers of subjects may suffer from poor generalizability. Via multicenter studies and consortium initiatives researchers have tried to solve this problem by combining data sets from multiple sites. The necessary sharing of (raw) data is, however, often hindered by legal and ethical issues. Moreover, in the case of very large samples, the computational complexity might become too large. The solution to this problem could be distributed learning. In this paper we investigated the possibility to create a meta-model by combining support vector machines (SVM) classifiers trained on the local datasets, without the need for sharing medical images or any other personal data. Validation was done in a 4-center setup comprising of 480 first-episode schizophrenia patients and healthy controls in total. We built \\{SVM\\} models to separate patients from controls based on three different kinds of imaging features derived from structural \\{MRI\\} scans, and compared models built on the joint multicenter data to the meta-models. The results showed that the combined meta-model had high similarity to the model built on all data pooled together and comparable classification performance on all three imaging features. Both similarity and performance was superior to that of the local models. We conclude that combining models is thus a viable alternative that facilitates data sharing and creating bigger and more informative models.", 
        "author": "Petr Dluho\u0161 and Daniel Schwarz and Wiepke Cahn and Neeltje van Haren and Ren\u00e9 Kahn and Filip \u0160paniel and Ji\u0159\u00ed Hor\u00e1\u010dek and Tom\u00e1\u0161 Ka\u0161p\u00e1rek and Hugo Schnack", 
        "keyword": "Machine learning\", \"multi-center\", \"meta-model\", \"combining models\", \"support vector machines (keywords =VM)\", \"first-episode schizophrenia\", \"classification\", \"prediction", 
        "title": "Multi-center machine learning in imaging psychiatry: A meta-model approach"
    }, 
    {
        "abstract": "AbstractBackground and Objectives The main pathologic feature of asthma is episodic airway obstruction. This is usually detected by spirometry and body plethysmography. These tests, however, require a high degree of collaboration and maximal effort on the part of the patient. There is agreement in the literature that there is a demand of research into new technologies to improve non-invasive testing of lung function. The purpose of this study was to develop automatic classifiers to simplify the clinical use and to increase the accuracy of the forced oscillation technique (FOT) in the diagnosis of airway obstruction in patients with asthma. Methods The data consisted of \\{FOT\\} parameters obtained from 75 volunteers (39 with obstruction and 36 without). Different supervised machine learning (ML) techniques were investigated, including k-nearest neighbors (KNN), random forest (RF), AdaBoost with decision trees (ADAB) and feature-based dissimilarity space classifier (FDSC). Results The first part of this study showed that the best \\{FOT\\} parameter was the resonance frequency (AUC\u2009=\u20090.81), which indicates moderate accuracy (0.70\u20130.90). In the second part of this study, the use of the cited \\{ML\\} techniques was investigated. All the classifiers improved the diagnostic accuracy. Notably, \\{ADAB\\} and \\{KNN\\} were very close to achieving high accuracy (AUC\u2009=\u20090.88 and 0.89, respectively). Experiments including the cross products of the \\{FOT\\} parameters showed that all the classifiers improved the diagnosis accuracy and \\{KNN\\} was able to reach a higher accuracy range (AUC\u2009=\u20090.91). Conclusions Machine learning classifiers can help in the diagnosis of airway obstruction in asthma patients, and they can assist clinicians in airway obstruction identification.", 
        "author": "Jorge L.M. Amaral and Agnaldo J. Lopes and Juliana Veiga and Alvaro C.D. Faria and Pedro L. Melo", 
        "keyword": "Clinical decision support\", \"Classification\", \"Machine learning\", \"Airway obstruction severity\", keywords =Forced oscillation technique\", \"Asthma", 
        "title": "High-accuracy detection of airway obstruction in asthma using machine learning algorithms and forced oscillation measurements"
    }, 
    {
        "abstract": "Abstract Since the actual food safety monitoring data have characteristics of high-dimension, complexity, discreteness and nonlinear properties, it is difficult to accurately predict the risk of actual food inspection process. Therefore, this paper proposes a predictive modeling approach based on analytic hierarchy process (AHP) integrated extreme learning machine (ELM) (AHP-ELM). The proposed approach utilizes the \\{AHP\\} model to obtain the effective process characteristic information (PCIs). Compared with the analytic hierarchy process (AHP) integrated traditional artificial neural network (ANN) approach, the AHP-ELM prediction model is effectively verified by executing a linear comparison between all \\{PCIs\\} and the effective \\{PCIs\\} through daily inspection data source from the supervision and inspection department repository of China quality supervision system. Finally, the \\{PCIs\\} and the prediction value are obtained to provide more reliable food information and identification of potentially emerging food safety issues. The proposed method is applied to the food safety early warning and monitoring system in China. The result shows that the proposed model is effective and feasible in processing the complex food inspection data. Meanwhile, it can help to improve the quality of food products, ensure food safety and reduce the risk of food safety.", 
        "author": "ZhiQiang Geng and ShanShan Zhao and GuangCan Tao and YongMing Han", 
        "keyword": "Food safety\", \"Extreme learning machine\", \"Analytic hierarchy process\", \"Artificial neural keywords =etwork\", \"Early warning modeling", 
        "title": "Early warning modeling and analysis based on analytic hierarchy process integrated extreme learning machine (AHP-ELM): Application to food safety"
    }, 
    {
        "abstract": "Abstract Conventional methods of monitoring salt accumulation in irrigation schemes require regular field visits to collect soil samples for laboratory analysis. Identifying areas prone to salt accumulation by means of geomorphometry (i.e. terrain analyses using digital elevation models (DEMs)) can potentially save time and costs. This study evaluated the extent to which \\{DEM\\} derivatives and machine learning (ML) algorithms (k-nearest neighbour, support vector machine, decision tree (DT) and random forest) can be used for predicting the location and extent of salt-affected areas within the Vaalharts and Breede River irrigation schemes of South Africa. In accordance with local management policies, salt-affected areas were defined as regions with soil electrical conductivity (EC) values &gt; 4 dS/m. Two DEMs, namely the one-arch second Shuttle Radar Topography Mission (SRTM) \\{DEM\\} and a photogrammetrically-extracted digital surface model (DSM), were used for deriving the derivatives. Wetness indices as well as hydrological and morphometric terrain analysis techniques were used to generate predictive variables. For comparative purposes, the predictive variables were also used as input to regression modelling and kriging with external drift (KED). Thresholds were applied to the regression models and \\{KED\\} results to obtain a binary classification. \\{EC\\} values based on in situ soil samples were used for model development, classifier training and accuracy assessment. The results show that \\{KED\\} achieved the highest overall accuracy (OA) in Vaalharts (79.6%), whereas \\{KED\\} and \\{ML\\} (DT) showed the most promise in the Breede River (75%). The findings suggest that the use of elevation data and its derivatives as input to geostatistics and \\{ML\\} holds much potential for monitoring salt accumulation in irrigated areas, particularly for simulating sub-surface conditions. More work is needed to investigate the potential of using \\{ML\\} and DEM-derivatives, along with other geospatial datasets such as satellite imagery (that have been shown to be effective for monitoring surface conditions), for the operational modelling of salt accumulation in large irrigation schemes.", 
        "author": "Divan Vermeulen and Adriaan Van Niekerk", 
        "keyword": "Salinity\", \"Hydrology\", \"Digital terrain analysis\", \"Geomorphometry\", \"Machine learning\", \"Geostatistics", 
        "title": "Machine learning performance for predicting soil salinity using different combinations of geomorphometric covariates"
    }, 
    {
        "abstract": "Abstract Accurate service-life prediction of structures is vital for taking appropriate measures in a time- and cost-effective manner. However, the conventional prediction models rely on simplified assumptions, leading to inaccurate estimations. The paper reviews the capability of machine learning in addressing the limitations of classical prediction models. This is due to its ability to capture the complex physical and chemical process of the deterioration mechanism. The paper also presents previous researches that proposed the applicability of machine learning in assisting durability assessment of reinforced concrete structures. The advantages of employing machine learning for durability and service-life assessment of reinforced concrete structures are also discussed in detail. The growing trend of collecting more and more in-service data using wireless sensors facilitates the use of machine learning for durability and service-life assessment. The paper concludes by recommending the future directions based on examination of recent advances and current practices in this specific area.", 
        "author": "Woubishet Zewdu Taffese and Esko Sistonen", 
        "keyword": "Reinforced concrete\", \"Corrosion\", \"Durability\", \"Service life\", \"Machine learning\", \"Modelling\", keywords =Carbonation\", \"Chloride", 
        "title": "Machine learning for durability and service-life assessment of reinforced concrete structures: Recent advances and future directions"
    }, 
    {
        "abstract": "Abstract This paper introduces a data science method to determine a set of features for training a vector support machine (SVM). The \\{SVM\\} is used to model the relationship between the distribution of one particular invasive mosquito species and climate data. Two biologists selected training data on the basis of their domain expertise. This was compared with the result of the data science simulation. The paper then explores the possible uses of data science to generate new knowledge as well as to identify the weaknesses of this technique.", 
        "author": "Ralf Wieland and Antje Kerkow and Linus Fr\u00fch and Helge Kampen and Doreen Walther", 
        "keyword": "Data science\", \"Machine learning\", \"Genetic optimization\", \"Cluster computing\", \"Mosquito dispersion modeling", 
        "title": "Automated feature selection for a machine learning approach toward modeling a mosquito distribution"
    }, 
    {
        "abstract": "Abstract Scholars of New Urbanism have suggested that mixing along various dimensions in neighborhoods (e.g., income, race/ethnicity, land use) may have positive consequences for neighborhoods, particularly for economic dynamism. A challenge for empirically assessing this hypothesis is that the impact of mixing may depend on various socio-demographic characteristics of the neighborhood and takes place in a complex fashion that cannot be appropriately handled by traditional statistical analytical approaches. We utilize a rarely used, innovative estimation technique\u2014kernel regularized least squares\u2014that allows for nonparametric estimation of the relationship between various neighborhood characteristics in 2000 and the change in average household income in the neighborhood from 2000 to 2010. The results demonstrate that the relationships between average income growth and both income mixing and racial/ethnic mixing are contingent upon several neighborhood socio-demographic \u201cingredients\u201d. For example, racial mixing is positively associated with average income over time when it occurs in neighborhoods with a high percentage of Latinos or immigrants, high population density, or high housing age mixing. Income mixing is associated with worsening average household income in neighborhoods with more poverty, unemployment, immigrants, or population density. It appears that considering the broader characteristics of the neighborhood is important for understanding economic dynamism.", 
        "author": "John R. Hipp and Kevin Kane and Jae Hong Kim", 
        "keyword": "Neighborhoods\", \"Household incomes\", \"Machine learning\", \"Social mix", 
        "title": "Recipes for neighborhood development: A machine learning approach toward understanding the impact of mixing in neighborhoods"
    }, 
    {
        "abstract": "Abstract This paper compares six land use change (LUC) models, including artificial neural networks (ANNs), support vector regression (SVR), random forest (RF), classification and regression trees (CART), logistic regression (LR), and multivariate adaptive regression splines (MARS). These models were used to simulate urban growth in the megacity of Tehran Metropolitan Area (TMA). These \\{LUC\\} models were integrated with cellular automata (CA) and validated using a variety of goodness-of-fit metrics. The results showed that the percent correct metrics (PCMs) varied between 54.6% for \\{LR\\} and 59.6% for MARS, while the area under curve (AUC) ranged from 67.6% for \\{LR\\} to 74.7% for ANNs. The results also showed a considerable difference between the spatial patterns within the error maps. The results of this comparative study will enable decision makers and scholars to better understand the performance of the models when reducing the number of misses and false alarms is a priority.", 
        "author": "Hossein Shafizadeh-Moghadam and Ali Asghari and Amin Tayyebi and Mohammad Taleai", 
        "keyword": "Machine learning models\", \"Tree-based models\", \"Statistical models\", \"Cellular automata\", \"Error keywords =ap\", \"Accuracy assessment", 
        "title": "Coupling machine learning, tree-based and statistical models with cellular automata to simulate urban growth"
    }, 
    {
        "abstract": "Abstract Electroencephalographic (EEG) arousals are related to sleep fragmentation and the consequent daytime sleepiness, and are usually detected by visual inspection of sleep polysomnographic (PSG) recordings. As this is a time-consuming task, automatic processes are required. A method using signal processing and machine learning models is presented. Using signal processing techniques, after a first step of signal conditioning, abrupt frequency changes in two \\{EEG\\} derivations and amplitude events in one submental electromyogram are identified. These events are grouped if they occur at the same time, using the epoch segmentation for that purpose. A set of features (that includes Hjorth\u2019s Parameters and the Sleep Stage), is extracted from each group and used as input for several machine learning models. With a first dataset of 20 \\{PSG\\} recordings, six models are configured and compared: Fisher\u2019s Linear Discriminant, Support Vector Machines, Artificial Neural Networks, Classification Trees, k-Nearest Neighbors, and Naive Bayes. The best models, in terms of the classification error and the capabilities to detect \\{EEG\\} arousals, were used to build two different combined approaches. The first approach follows the Shortliffe and Buchanan\u2019s certainty factors model and the second follows a linear combination. Conducting experiments on 26 \\{PSG\\} recordings, a sensitivity of 0.78 and a specificity of 0.89 with an error of 0.12 was achieved using the first approach, and a sensitivity of 0.81 and a specificity of 0.88 with an error of 0.13 was achieved using the second approach. Both approaches improved the performance over the individual models. These results were also compared to two well-known ensemble methods: Random Forest and k-Nearest Neighbor Ensemble. Again, the combined approaches showed the best performance.", 
        "author": "Isaac Fern\u00e1ndez-Varela and Elena Hern\u00e1ndez-Pereira and Diego \u00c1lvarez-Est\u00e9vez and Vicente Moret-Bonillo", 
        "keyword": "\\{EEG\\} arousals\", \"Signal processing\", \"Machine learning", 
        "title": "Combining Machine Learning Models for the Automatic Detection of \\{EEG\\} Arousals"
    }, 
    {
        "abstract": null, 
        "author": "Cyril Voyant and Gilles Notton and Soteris Kalogirou and Marie-Laure Nivet and Christophe Paoli and Fabrice Motte and Alexis Fouilloy", 
        "keyword": "Solar radiation forecasting\", \"Machine learning\", \"Artificial neural networks\", \"Support vector keywords =achines\", \"Regression", 
        "title": "Machine learning methods for solar radiation forecasting: A review"
    }, 
    {
        "abstract": "Abstract Online product reviews have been shown to be a viable source of information for helping customers make informed purchasing decisions. In many cases, users of online shopping platforms have the ability to rate products on a numerical scale, and also provide textual feedback pertaining to a purchased product. Beyond using online product review platforms as customer decision support systems, this information rich data source could also aid designers seeking to increase the chances of their products being successful in the market through a deeper understanding of market needs. However, the increasing size and complexity of products on the market makes manual analysis of such data challenging. Information obtained from such sources, if not mined correctly, risks misrepresenting a product's true success/failure (e.g., a customer leaves a one star rating because of the slow shipping service of a product, not necessarily that he/she dislikes the product). The objective of this paper is three fold: i) to propose a machine learning approach that disambiguates online customer review feedback by classifying them into one of three direct product characteristics (i.e., form, function or behavior) and two indirect product characteristics (i.e., service and other), ii) to discover the machine learning algorithm that yields the highest and most generalizable results in achieving objective i) and iii) to quantify the correlation between product ratings and direct and indirect product characteristics. A case study involving review data for products mined from e-commerce websites is presented to demonstrate the validity of the proposed method. A multilayered (i.e., k-fold and leave one out) validation approach is presented to explore the generalizability of the proposed method. The resulting machine learning model achieved classification accuracies of 82.44% for within product classification, 80.84% for across product classification, 79.03% for across product type classification and 80.64% for across product domain classification. Furthermore, it was determined that the form of a product had the highest Pearson Correlation Coefficient relating to a product's star rating, with a value of 0.934. The scientific contributions of this work have the potential to transform the manner in which both product designers and customers incorporate product reviews into their decision making processes by quantifying the relationship between product reviews and product characteristics.", 
        "author": "Abhinav Singh and Conrad S. Tucker", 
        "keyword": "Machine learning\", \"Product attribute extraction\", \"Text mining\", \"Product reviews\", \"Product design", 
        "title": "A machine learning approach to product review disambiguation based on function, form and behavior classification"
    }, 
    {
        "abstract": "Abstract A high-resolution drought forecast model for ungauged areas was developed in this study. The Standardized Precipitation Index (SPI) and Standardized Precipitation Evapotranspiration Index (SPEI) with 3-, 6-, 9-, and 12-month time scales were forecasted with 1\u20136-month lead times at 0.05 \u00d7 0.05\u00b0 resolution. The use of long-range climate forecast data was compared to the use of climatological data for periods with no observation data. Machine learning models utilizing drought-related variables based on remote sensing data were compared to the spatial interpolation of Kriging. Two performance measures were used; one is producer\u2019s drought accuracy, defined as the number of correctly classified samples in extreme, severe, and moderate drought classes over the total number of samples in those classes, and the other is user\u2019s drought accuracy, defined as the number of correctly classified samples in drought classes over the total number of samples classified to those classes. One of the machine learning models, extremely randomized trees, performed the best in most cases in terms of producer\u2019s accuracy reaching up to 64%, while spatial interpolation performed better in terms of user\u2019s accuracy up to 44%. The contribution of long-range climate forecast data was not significant under the conditions used in this study, but further improvement is expected if forecast skill is improved or a more sophisticated downscaling method is used. Simulated decreases of forecast error in precipitation and mean temperature were tested: the simulated decrease of forecast error in precipitation improves drought forecast while the decrease of forecast error in mean temperature does not contribute much. Although there is still some room for improvement, the developed model can be used for drought-related decision making in ungauged areas.", 
        "author": "Jinyoung Rhee and Jungho Im", 
        "keyword": "Drought forecasting\", \"Machine learning\", \"Climate forecast data\", \"Remote sensing\", \"Spatial interpolation", 
        "title": "Meteorological drought forecasting for ungauged areas based on machine learning: Using long-range climate forecast and remote sensing data"
    }, 
    {
        "abstract": "Abstract Programmable biomolecules, such as \\{DNA\\} strands, deoxyribozymes, and restriction enzymes, have been used to solve computational problems, construct large-scale logic circuits, and program simple molecular games. Although studies have shown the potential of molecular computing, the capability of computational learning with \\{DNA\\} molecules, i.e., molecular machine learning, has yet to be experimentally verified. Here, we present a novel molecular learning in vitro model in which symmetric internal loops of double-stranded \\{DNA\\} are exploited to measure the differences between training instances, thus enabling the molecules to learn from small errors. The model was evaluated on a data set of twenty dialogue sentences obtained from the television shows Friends and Prison Break. The wet DNA-computing experiments confirmed that the molecular learning machine was able to generalize the dialogue patterns of each show and successfully identify the show from which the sentences originated. The molecular machine learning model described here opens the way for solving machine learning problems in computer science and biology using in vitro molecular computing with the data encoded in \\{DNA\\} molecules.", 
        "author": "Ji-Hoon Lee and Seung Hwan Lee and Christina Baek and Hyo-Sun Chun and Je-hwan Ryu and Jin-Woo Kim and Russell Deaton and Byoung-Tak Zhang", 
        "keyword": "Biomolecular computation\", \"Hypernetwork\", \"Machine learning\", \"Classification", 
        "title": "In Vitro Molecular Machine Learning Algorithm via Symmetric Internal Loops of \\{DNA\\}"
    }, 
    {
        "abstract": "Abstract Accurate cell grading of cancerous tissue pathological image is of great importance in medical diagnosis and treatment. This paper proposes a joint multiple fully connected convolutional neural network with extreme learning machine (MFC-CNN-ELM) architecture for hepatocellular carcinoma (HCC) nuclei grading. First, in preprocessing stage, each grayscale image patch with the fixed size is obtained using center-proliferation segmentation (CPS) method and the corresponding labels are marked under the guidance of three pathologists. Next, a multiple fully connected convolutional neural network (MFC-CNN) is designed to extract the multi-form feature vectors of each input image automatically, which considers multi-scale contextual information of deep layer maps sufficiently. After that, a convolutional neural network extreme learning machine (CNN-ELM) model is proposed to grade \\{HCC\\} nuclei. Finally, a back propagation (BP) algorithm, which contains a new up-sample method, is utilized to train MFC-CNN-ELM architecture. The experiment comparison results demonstrate that our proposed MFC-CNN-ELM has superior performance compared with related works for \\{HCC\\} nuclei grading. Meanwhile, external validation using \\{ICPR\\} 2014 HEp-2 cell dataset shows the good generalization of our MFC-CNN-ELM architecture.", 
        "author": "Siqi Li and Huiyan Jiang and Wenbo Pang", 
        "keyword": "Multiple fully connected layers\", \"Convolutional neural network\", \"Extreme learning machine\", \"Back keywords =ropagation\", \"Hepatocellular carcinoma nuclei grading", 
        "title": "Joint multiple fully connected convolutional neural network with extreme learning machine for hepatocellular carcinoma nuclei grading"
    }, 
    {
        "abstract": "Abstract Knowledge discovery is an important aspect of human cognition. The advantage of the visual approach is in opportunity to substitute some complex cognitive tasks by easier perceptual tasks. However for cognitive tasks such as financial investment decision making this opportunity faces the challenge that financial data are abstract multidimensional and multivariate, i.e., outside of traditional visual perception in 2D or 3D world. This paper presents an approach to find an investment strategy based on pattern discovery in multidimensional space of specifically prepared time series. Visualization based on the lossless Collocated Paired Coordinates (CPC) plays an important role in this approach for building the criteria in the multidimensional space for finding an efficient investment strategy. Criteria generated with the \\{CPC\\} approach allow reducing/compressing space using simple directed graphs with beginnings and the ends located in different time points. The dedicated subspaces constructed for time series include characteristics such as Bollinger Band, difference between moving averages, changes in volume etc. Extensive simulation studies have been performed in learning/testing context. Effective relations were found for one-hour \\{EURUSD\\} pair for recent and historical data. Also the method has been explored for one-day \\{EURUSD\\} time series n 2D and 3D visualization spaces. The main positive result is finding the effective split of a normalized 3D space on 4x4x4 cubes in the visualization space that leads to a profitable investment decision (long, short position or nothing). The strategy is ready for implementation in algotrading mode.", 
        "author": "Antoni Wilinski and Boris Kovalerchuk", 
        "keyword": "Visual knowledge discovery\", \"cognitive algorithm\", \"machine learning\", \"multidimensional keywords =isualization\", \"investment strategies\", \"collocated paired coordinates\", \"algorithmic trading\", \"time keywords =eries prediction\", \"artificial intelligence\", \"big data\", \"classification\", \"forex", 
        "title": "Visual Knowledge Discovery and Machine Learning for Investment Strategy"
    }, 
    {
        "abstract": "Abstract In this paper, we model the trajectory of sea vessels and provide a service that predicts in near-real time the position of any given vessel in 4\u2032, 10\u2032, 20\u2032 and 40\u2032 time intervals. We explore the necessary tradeoffs between accuracy, performance and resource utilization is explored given the large volume and update rates of input data. We start with building models based on well-established machine learning algorithms using static datasets and multi-scan training approaches and identify the best candidate to be used in implementing a single-pass predictive approach, under real-time constraints. The results are measured in terms of accuracy and performance and are compared against the baseline kinematic equations. Results show that it is possible to efficiently model the trajectory of multiple vessels using a single model, which is trained and evaluated using an adequately large, static dataset, thus achieving a significant gain in terms of resource usage while not compromising accuracy.", 
        "author": "Angelos Valsamis and Konstantinos Tserpes and Dimitrios Zissis and Dimosthenis Anagnostopoulos and Theodora Varvarigou", 
        "keyword": "Trajectory prediction\", \"Real-time query response\", \"Data streams\", \"Machine learning", 
        "title": "Employing traditional machine learning algorithms for big data streams analysis: The case of object trajectory prediction"
    }, 
    {
        "abstract": "Abstract Exposure to erythemally-effective solar ultraviolet radiation (UVR) that contributes to malignant keratinocyte cancers and associated health-risk is best mitigated through innovative decision-support systems, with global solar \\{UV\\} index (UVI) forecast necessary to inform real-time sun-protection behaviour recommendations. It follows that the \\{UVI\\} forecasting models are useful tools for such decision-making. In this study, a model for computationally-efficient data-driven forecasting of diffuse and global very short-term reactive (VSTR) (10-min lead-time) UVI, enhanced by drawing on the solar zenith angle ( \u03b8 s ) data, was developed using an extreme learning machine (ELM) algorithm. An \\{ELM\\} algorithm typically serves to address complex and ill-defined forecasting problems. \\{UV\\} spectroradiometer situated in Toowoomba, Australia measured daily cycles (0500\u20131700 h) of \\{UVI\\} over the austral summer period. After trialling activations functions based on sine, hard limit, logarithmic and tangent sigmoid and triangular and radial basis networks for best results, an optimal \\{ELM\\} architecture utilising logarithmic sigmoid equation in hidden layer, with lagged combinations of \u03b8 s as the predictor data was developed. ELM\u2019s performance was evaluated using statistical metrics: correlation coefficient (r), Willmott\u2019s Index (WI), Nash-Sutcliffe efficiency coefficient ( E \\{NS\\} ), root mean square error (RMSE), and mean absolute error (MAE) between observed and forecasted UVI. Using these metrics, the \\{ELM\\} model\u2019s performance was compared to that of existing methods: multivariate adaptive regression spline (MARS), \\{M5\\} Model Tree, and a semi-empirical (Pro6UV) clear sky model. Based on \\{RMSE\\} and \\{MAE\\} values, the \\{ELM\\} model (0.255, 0.346, respectively) outperformed the \\{MARS\\} (0.310, 0.438) and \\{M5\\} Model Tree (0.346, 0.466) models. Concurring with these metrics, the Willmott\u2019s Index for the ELM, \\{MARS\\} and \\{M5\\} Model Tree models were 0.966, 0.942 and 0.934, respectively. About 57% of the \\{ELM\\} model\u2019s absolute errors were small in magnitude (\u00b10.25), whereas the \\{MARS\\} and \\{M5\\} Model Tree models generated 53% and 48% of such errors, respectively, indicating the latter models\u2019 errors to be distributed in larger magnitude error range. In terms of peak global \\{UVI\\} forecasting, with half the level of error, the \\{ELM\\} model outperformed \\{MARS\\} and \\{M5\\} Model Tree. A comparison of the magnitude of hourly-cumulated errors of 10-min lead time forecasts for diffuse and global \\{UVI\\} highlighted \\{ELM\\} model\u2019s greater accuracy compared to MARS, \\{M5\\} Model Tree or Pro6UV models. This confirmed the versatility of an \\{ELM\\} model drawing on \u03b8 s data for \\{VSTR\\} forecasting of \\{UVI\\} at near real-time horizon. When applied to the goal of enhancing expert systems, ELM-based accurate forecasts capable of reacting quickly to measured conditions can enhance real-time exposure advice for the public, mitigating the potential for solar UV-exposure-related disease.", 
        "author": "Ravinesh C. Deo and Nathan Downs and Alfio V. Parisi and Jan F. Adamowski and John M. Quilty", 
        "keyword": "Extreme learning machine\", \"Solar ultraviolet index (UVI)\", \"Multivariate adaptive regression keywords =plines\", \"M5 Model Tree\", \"Real-time solar forecasting", 
        "title": "Very short-term reactive forecasting of the solar ultraviolet index using an extreme learning machine integrated with the solar zenith angle"
    }, 
    {
        "abstract": "Abstract In recent years, the number and variety of malicious mobile apps have increased drastically, especially on Android platform, which brings insurmountable challenges for malicious app detection. Researchers endeavor to discover the traces of malicious apps using network traffic analysis. In this study, we combine network traffic analysis with machine learning methods to identify malicious network behavior, and eventually to detect malicious apps. However, most network traffic generated by malicious apps is benign, while only a small portion of traffic is malicious, leading to an imbalanced data problem when the traffic model skews towards modeling the benign traffic. To address this problem, we introduce imbalanced classification methods, including the synthetic minority oversampling technique (SMOTE) + support vector machine (SVM), \\{SVM\\} cost-sensitive (SVMCS), and C4.5 cost-sensitive (C4.5CS) methods. However, when the imbalance rate reaches a certain threshold, the performance of common imbalanced classification algorithms degrades significantly. To avoid performance degradation, we propose to use the imbalanced data gravitation-based classification (IDGC) algorithm to classify imbalanced data. Moreover, we develop a simplex imbalanced data gravitation classification (S-IDGC) model to further reduce the time costs of \\{IDGC\\} without sacrificing the classification performance. In addition, we propose a machine learning based comparative benchmark prototype system, which provides users with substantial autonomy, such as multiple choices of the desired classifiers or traffic features. Using this prototype system, users can compare the detection performance of different classification algorithms on the same data set, as well as the performance of a specific classification algorithm on multiple data sets.", 
        "author": "Zhenxiang Chen and Qiben Yan and Hongbo Han and Shanshan Wang and Lizhi Peng and Lin Wang and Bo Yang", 
        "keyword": "Network traffic\", \"Malicious apps\", \"Imbalanced data\", \"Malware detection\", \"Machine learning", 
        "title": "Machine Learning Based Mobile Malware Detection Using Highly Imbalanced Network Traffic"
    }, 
    {
        "abstract": "Abstract Visual analytics (VA) systems help data analysts solve complex problems interactively, by integrating automated data analysis and mining, such as machine learning (ML) based methods, with interactive visualizations. We propose a conceptual framework that models human interactions with \\{ML\\} components in the \\{VA\\} process, and that puts the central relationship between automated algorithms and interactive visualizations into sharp focus. The framework is illustrated with several examples and we further elaborate on the interactive \\{ML\\} process by identifying key scenarios where \\{ML\\} methods are combined with human feedback through interactive visualization. We derive five open research challenges at the intersection of \\{ML\\} and visualization research, whose solution should lead to more effective data analysis.", 
        "author": "Dominik Sacha and Michael Sedlmair and Leishi Zhang and John A. Lee and Jaakko Peltonen and Daniel Weiskopf and Stephen C. North and Daniel A. Keim", 
        "keyword": "Machine Learning\", \"Information Visualization\", \"Interaction\", \"Visual Analytics", 
        "title": "What You See Is What You Can Change: Human-Centered Machine Learning By Interactive Visualization"
    }, 
    {
        "abstract": "Abstract Harnessing natural variation in photosynthetic capacity is a promising route towards yield increases, but physiological phenotyping is still too laborious for large scale genetic screens. Here, we evaluate the potential of leaf reflectance spectroscopy to predict parameters of photosynthetic capacity in Brassica oleracea and Zea mays, a \\{C3\\} and a \\{C4\\} crop, respectively. To this end we systematically evaluate properties of reflectance spectra and find that they are surprisingly similar over a wide range of species. We assessed the performance of a wide range of machine learning methods and selected recursive feature elimination on un-transformed spectra followed by partial least squares regression as the preferred algorithm that yielded the highest predictive power. Learning curves of this algorithm suggest optimal, species-specific sample sizes. Using the Brassica relative Moricandia, we evaluate model transferability between species and find that cross-species performance cannot be predicted from phylogenetic proximity. The final intra-species models predict crop photosynthetic capacity with high accuracy. Based on the estimated model accuracy, we simulated the models\u2019 use in selective breeding experiments, showing that high-throughput photosynthetic phenotyping using our method has the potential to greatly improve breeding success. In summary, leaf reflectance phenotyping is an efficient method for the improvement of crop photosynthetic capacity.", 
        "author": "David Heckmann and Urte Schl\u00fcter and Andreas P.M. Weber", 
        "keyword": "leaf spectrometry\", \"photosynthesis\", \"machine learning\", \"crops\", \"C3\", \"C4\", \"phenotyping", 
        "title": "Machine learning techniques for predicting crop photosynthetic capacity from leaf reflectance spectra"
    }, 
    {
        "abstract": "Abstract In residential and commercial buildings, thermostat controllers have been typically utilized to maintain room temperature near desired set-point. Recently, advanced computing and statistical technologies, such as Fuzzy Inference System (FIS) and Artificial Neural Network (ANN) algorithms, were introduced to complement the control performance for optimal energy use in building thermal systems. However, most schemes were developed to control fuel use or fan motor speed in a plant or a system, and showed some disadvantages to immediately respond to sensitive changes in thermal demands for a zone scaled level. This paper introduces heating energy models capable of controlling the amount of supply air and its temperature simultaneously, and the \\{FIS\\} and \\{ANN\\} algorithms are developed to control the optimal supply air conditions for a heating season. Both the \\{FIS\\} and \\{ANN\\} models are compared to thermostat controllers with 4-step dead-band setups from normal to sensitive levels. The sum of errors, caused by the difference between desired set-point and controlled room temperatures, and the amount of energy supply are used to define control precision and energy efficiency of the control models. From the simulation results, the machine-learning based \\{ANN\\} controller averagely reduces control errors by 88% and mitigates increases in energy consumption by 2% in comparison with thermostat on/off controllers. The control system can be effective when various sensitive settings are required as a type of buildings and rooms without an excessive increase in energy use.", 
        "author": "Jonghoon Ahn and Soolyeon Cho", 
        "keyword": "Building Control System\", \"Thermostat Sensitivity\", \"Machine Learning\", \"Control Precision\", \"Energy Efficiency", 
        "title": "Dead-band vs. machine-learning control systems: Analysis of control benefits and energy efficiency"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is an efficient and effective learning algorithm for pattern classification. For binary classification problem, traditional \\{ELM\\} learns only one hyperplane to separate different classes in the feature space. In this paper, we propose a novel twin extreme learning machine (TELM) to simultaneously train two \\{ELMs\\} with two nonparallel classification hyperplanes. Specifically, \\{TELM\\} first utilizes the random feature mapping mechanism to construct the feature space, and then two nonparallel separating hyperplanes are learned for the final classification. For each hyperplane, \\{TELM\\} jointly minimizes its distance to one class and requires it to be far away from the other class. \\{TELM\\} incorporates the idea of twin support vector machine (TSVM) into the basic framework of ELM, thus \\{TELM\\} could have the advantages of the both algorithms. Moreover, compared to TSVM, \\{TELM\\} has fewer optimization constraint variables but with better classification performance. We also introduce a successive over-relaxation technique to speed up the training of our algorithm. Comprehensive experimental results on a large number of datasets verify the effectiveness and efficiency of TELM.", 
        "author": "Yihe Wan and Shiji Song and Gao Huang and Shuang Li", 
        "keyword": "Twin extreme learning machine\", \"Pattern classification\", \"Extreme learning machine\", \"Twin support keywords =ector machine\", \"Nonparallel separating hyperplane", 
        "title": "Twin extreme learning machines for pattern classification"
    }, 
    {
        "abstract": "Abstract One of the most relevant research topics in Information Retrieval is Automatic Document Classification (ADC). Several \\{ADC\\} algorithms have been proposed in the literature. However, the majority of these algorithms assume that the underlying data distribution does not change over time. Previous work has demonstrated evidence of the negative impact of three main temporal effects in representative datasets textual datasets, reflected by variations observed over time in the class distribution, in the pairwise class similarities and in the relationships between terms and classes [1]. In order to minimize the impact of temporal effects in \\{ADC\\} algorithms, we have previously introduced the notion of a temporal weighting function (TWF), which reflects the varying nature of textual datasets. We have also proposed a procedure to derive the TWF\u2019s expression and parameters. However, the derivation of the \\{TWF\\} requires the running of explicit and complex statistical tests, which are very cumbersome or can not even be run in several cases. In this article, we propose a machine learning methodology to automatically learn the \\{TWF\\} without the need to perform any statistical tests. We also propose new strategies to incorporate the \\{TWF\\} into \\{ADC\\} algorithms, which we call temporally-aware classifiers. Experiments showed that the fully-automated temporally-aware classifiers achieved significant gains (up to 17%) when compared to their non-temporal counterparts, even outperforming some state-of-the-art algorithms (e.g., SVM) in most cases, with large reductions in execution time.", 
        "author": "Thiago Salles and Leonardo Rocha and Fernando Mour\u00e3o and Marcos Gon\u00e7alves and Felipe Viegas and Wagner Meira Jr.", 
        "keyword": "Automatic Document Classification\", \"Temporal Weighting Function\", \"Fully-Automated Machine Learning Process", 
        "title": "A Two-Stage Machine Learning Approach for Temporally-Robust Text Classification"
    }, 
    {
        "abstract": "Abstract Several code smells detection tools have been developed providing different results, because smells can be subjectively interpreted and hence detected in different ways. Machine learning techniques have been used for different topics in software engineering, e.g., design pattern detection, code smell detection, bug prediction, recommending systems. In this paper, we focus our attention on the classification of code smell severity through the use of machine learning techniques in different experiments. The severity of code smells is an important factor to take into consideration when reporting code smell detection results, since it allows the prioritization of refactoring efforts. In fact, code smells with high severity can be particularly large and complex, and create larger issues to the maintainability of software a system. In our experiments, we apply several machine learning models, spanning from multinomial classification to regression, plus a method to apply binary classifiers for ordinal classification. In fact, we model code smell severity as an ordinal variable. We take the baseline models from previous work, where we applied binary classification models for code smell detection with good results. We report and compare the performance of the models according to their accuracy and four different performance measures used for the evaluation of ordinal classification techniques. From our results, while the accuracy of the classification of severity is not high as in the binary classification of absence or presence of code smells, the ranking correlation of the actual and predicted severity for the best models reaches 0.88\u20130.96, measured through Spearman\u2019s \u03c1.", 
        "author": "Francesca Arcelli Fontana and Marco Zanoni", 
        "keyword": "code smells detection\", \"machine learning\", \"code smell severity\", \"ordinal classification\", \"refactoring prioritization", 
        "title": "Code Smell Severity Classification using Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract There has been intensive research from academics and practitioners regarding models for predicting bankruptcy and default events, for credit risk management. Seminal academic research has evaluated bankruptcy using traditional statistics techniques (e.g. discriminant analysis and logistic regression) and early artificial intelligence models (e.g. artificial neural networks). In this study, we test machine learning models (support vector machines, bagging, boosting, and random forest) to predict bankruptcy one year prior to the event, and compare their performance with results from discriminant analysis, logistic regression, and neural networks. We use data from 1985 to 2013 on North American firms, integrating information from the Salomon Center database and Compustat, analysing more than 10,000 firm-year observations. The key insight of the study is a substantial improvement in prediction accuracy using machine learning techniques especially when, in addition to the original Altman\u2019s Z-score variables, we include six complementary financial indicators. Based on Carton and Hofer (2006), we use new variables, such as the operating margin, change in return-on-equity, change in price-to-book, and growth measures related to assets, sales, and number of employees, as predictive variables. Machine learning models show, on average, approximately 10% more accuracy in relation to traditional models. Comparing the best models, with all predictive variables, the machine learning technique related to random forest led to 87% accuracy, whereas logistic regression and linear discriminant analysis led to 69% and 50% accuracy, respectively, in the testing sample. We find that bagging, boosting, and random forest models outperform the others techniques, and that all prediction accuracy in the testing sample improves when the additional variables are included. Our research adds to the discussion of the continuing debate about superiority of computational methods over statistical techniques such as in Tsai, Hsu, and Yen (2014) and Yeh, Chi, and Lin (2014). In particular, for machine learning mechanisms, we do not find \\{SVM\\} to lead to higher accuracy rates than other models. This result contradicts outcomes from Danenas and Garsva (2015) and Cleofas-S\u00e1nchez, Garc\u00eda, Marqu\u00e9s, and S\u00e9nchez (2016), but corroborates, for instance, Wang, Ma, and Yang (2014), Liang, Lu, Tsai, and Shih (2016), and Cano et\u00a0al. (2017). Our study supports the applicability of the expert systems by practitioners as in Heo and Yang (2014), Kim, Kang, and Kim (2015) and Xiao, Xiao, and Wang (2016).", 
        "author": "Flavio Barboza and Herbert Kimura and Edward Altman", 
        "keyword": "Bankruptcy prediction\", \"Machine learning\", \"Support vector machines\", \"Boosting\", \"Bagging\", \"Random forest", 
        "title": "Machine Learning Models and Bankruptcy Prediction"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a simple yet effective method for video based action recognition referred to as dual-layer kernel extreme learning machine (DKELM). Our approach takes advantages of both early and late fusion techniques into a unified framework. In particular, the first layer in \\{DKELM\\} adopts linear kernel extreme learning machine (KELM) on handcrafted feature kernel, deep-learned feature kernel, and the fused kernel to provide various perspectives about the video. The second layer trains a radial basis function based \\{KELM\\} classifier on different fusion scores obtained from the first layer to predict the final action class label. Finally, we empirically show the superior performance of DKELM, both in terms of accuracy and computational time, over some state-of-the-art human action recognition methods on two large-scale datasets.", 
        "author": "Tam V. Nguyen and Bilal Mirza", 
        "keyword": "Action recognition\", \"Extreme learning machine\", \"Dual-layer kernel learning", 
        "title": "Dual-layer kernel extreme learning machine for action recognition"
    }, 
    {
        "abstract": "Abstract As real industrial processes have measurement samples with noises of different statistical characteristics and obtain the sample one by one usually, on-line sequential learning algorithms which can achieve better learning performance for systems with noises of various statistics are necessary. This paper proposes a new online Extreme Learning Machine (ELM, of Huang et al.) algorithm, namely recursive least mean p-power \\{ELM\\} (RLMP-ELM). In RLMP-ELM, a novel error criterion for cost function, namely the least mean p-power (LMP) error criterion, provides a mechanism to update the output weights sequentially. The \\{LMP\\} error criterion aims to minimize the mean p-power of the error that is the generalization of the mean square error criterion used in the ELM. The proposed on-line learning algorithm is able to provide on-line predictions of variables with noises of different statistics and obtains better performance than \\{ELM\\} and online sequential \\{ELM\\} (OS-ELM) while the non-Gaussian noises impact the processes. Simulations are reported to demonstrate the performance and effectiveness of the proposed methods.", 
        "author": "Jing Yang and Feng Ye and Hai-jun Rong and Badong Chen", 
        "keyword": "Recursive least mean p-power\", \"Extreme learning machine\", \"Online sequential learning\", keywords =Non-Gaussian noises\", \"Alpha-stable noises", 
        "title": "Recursive least mean p-power extreme learning machine"
    }, 
    {
        "abstract": "Abstract While visual servoing (VS) provides the ability of motion using vision for robot manipulators, the approaches for a better \\{VS\\} have to deal with three common problems: obtaining the interaction matrix and its pseudoinverse for defined feature points, finding an appropriate gain value for the \\{VS\\} controller and keeping the features in the field of view (FOV) for \\{VS\\} permanency. In this study, a new intelligent image-based visual servoing (IBVS) system for eye-in-hand configured robot manipulators using extreme learning machine (ELM) and fuzzy logic (FL) is proposed to solve these common problems of \\{VS\\} in a single system. As the first stage of the system, the pseudoinverse of the interaction matrix is approximated using trained \\{ELMs\\} which do not need hidden layer tuning. As the second stage, the classical \\{IBVS\\} controller is modified by a differential equation regarding initial velocity continuity and an appropriate gain in each loop is assigned by an \\{FL\\} unit to provide fast convergence within velocity limits. This unit also promotes manipulability of the manipulator to avoid singularities. As the last stage of the proposed system, regions are defined in the image plane to take precautions before feature missing. When a feature comes close to the edge of a restricted region, an \\{FL\\} unit is activated to obtain negative linear velocities in x and y direction which will be added to the instant velocities to drag the features towards the center of the FOV. In addition to these abilities, some \\{VS\\} metrics are redefined analytically to standardize the performance metric definitions of VS. To show the performance of the proposed system, simulation results of the classical and the proposed \\{IBVS\\} system under practical disturbances are presented for visual servoing of a Puma 560 arm. The advantages of singular matrix and joint configuration avoidance, adaptive gain with smooth gain surface, decreased convergence time within velocity limits, initial velocity continuity, \\{FOV\\} keeping with smooth velocity assurance, redefined \\{VS\\} metrics for standardization and robustness against disturbances are proved by variety of simulations. The simulation results also verify that the proposed system utilizing intelligent methods like \\{ELM\\} and \\{FL\\} is capable of dealing with common problems of \\{VS\\} and achieves sufficient results in terms of \\{VS\\} metrics.", 
        "author": "Tolga Y\u00fcksel", 
        "keyword": "Image-based visual servoing\", \"Extreme learning machine\", \"Fuzzy logic", 
        "title": "Intelligent visual servoing with extreme learning machine and fuzzy logic"
    }, 
    {
        "abstract": "Abstract Accurate estimation of reference evapotranspiration (ET0) is essential to agricultural water management. The present study developed two artificial intelligence models for daily \\{ET0\\} estimation only with temperature data, including extreme learning machine (ELM) and generalized regression neural network (GRNN) in 6 meteorological stations of Sichuan basin, southwest China, and compared the proposed \\{ELM\\} and \\{GRNN\\} with the corresponding temperature-based Hargreaves (HG) model and its calibrated version considering FAO-56 Penman-Monteith \\{ET0\\} as benchmark. Two data management scenarios were evaluated for estimation of ET0: (1) the models were trained/calibrated and tested using the local data of each station; and (2) the models were trained/calibrated using the pooled data from all the stations and tested in each station. In the first scenario, the results showed that the temperature-based \\{ELM\\} model provided the better estimation than the GRNN, \\{HG\\} and calibrated \\{HG\\} models, with average relative root mean square error (RRMSE) of 0.198, mean absolute error (MAE) of 0.267 mm/d and Nash-Sutcliffe coefficient (NS) of 0.891, respectively. In the second scenario, \\{GRNN\\} model provided the most accurate results among the considered models, with average \\{RRMSE\\} of 0.194, \\{MAE\\} of 0.263 mm/d and \\{NS\\} of 0.895, respectively. Both of the temperature-based \\{GRNN\\} and \\{ELM\\} performed much better than the \\{HG\\} and calibrated \\{HG\\} models for the two scenarios, and the temperature-based \\{GRNN\\} and \\{ELM\\} models are appropriate alternatives for accurate estimation of \\{ET0\\} for Sichuan basin of southwest China, which is very helpful for farmers or irrigation system operators to improve their irrigation scheduling.", 
        "author": "Yu Feng and Yong Peng and Ningbo Cui and Daozhi Gong and Kuandi Zhang", 
        "keyword": "Reference evapotranspiration\", \"Temperature data\", \"Extreme learning machine\", \"Generalized keywords =egression neural network\", \"Hargreaves model", 
        "title": "Modeling reference evapotranspiration using extreme learning machine and generalized regression neural network only with temperature data"
    }, 
    {
        "abstract": "Abstract Data-driven models can be used as an efficient proxy to model complex concepts in engineering. It is common engineering practice to optimize some controllable input parameters in a model to increase efficiency of operations. Machine Learning can be used to predict the rate of penetration (ROP) during drilling to a great accuracy as shown by Hegde, Wallace, and Gray (2015). This paper illustrates the use of machine learning to predict and increase \\{ROP\\} effectively. The machine learning model is first used to predict \\{ROP\\} \u2013 with input parameters such as weight on bit (WOB), rotations per minute of the drill bit (RPM), and flow rate of the drilling mud. The input parameters are then modified to increase ROP. This process has been applied to field drilling data from a vertical well consisting of different rocks and formations. The procedure can be used to determine the maximum achievable \\{ROP\\} in each formation, and map out operational guidelines for drilling of pad wells. A post drilling analysis can be conducted for pad wells to cut costs and save time while drilling. This model is very innovative because only surface measured parameters are used, without a priori requirements for geological, laboratory, or drilling data.", 
        "author": "Chiranth Hegde and K.E. Gray", 
        "keyword": "Machine learning\", \"Drilling parametrics\", \"ROP\", \"Data analytics\", \"Drilling optimization", 
        "title": "Use of machine learning and data analytics to increase drilling efficiency for nearby wells"
    }, 
    {
        "abstract": "Abstract The uncertainty and nonstationary of wind speed have compelled the power system operators and researchers to search for more accurate and reliable techniques to implement wind speed forecasting (WSF). In allusion to this phenomenon, this paper presents an adaptive ensemble of model for the probabilistic WSF, which is based on combination of the adaptive ensemble of on-line sequential \\{ORELM\\} (OS-ORELM) and the time-varying mixture copula function (TVMCF) to perform multi-step WSF. An OS-ORELM with forgetting mechanism based on Cook\u2019s distance ( \u03bb \\{CDFF\\} OS-ORELM) serves as a basic \\{WSF\\} model and an on-line ensemble using ordered aggregation (OEOA) technique is employed to improve the prediction performance. In the data pre-processing period, the Bernaola Galvan algorithm (BGA) is employed to partition the raw wind speed series into segments and the adaptive variational mode decomposition (AVMD) is used to decompose each segment into sub-series with different sub-band. Each transformed sub-series is well-modeled with the application of \u03bb \\{CDFF\\} OS-ORELM-OEOA, which is optimized by modified crisscross optimization algorithm (CSO). Eventual forecast results are obtained through aggregate calculation. Then the probabilistic prediction intervals (PIs) of wind speed are established in a \\{TVMCF\\} framework by modeling the conditional forecasting error. Case studies using the real wind speed data from the National Renewable Energy Laboratory (NREL) demonstrate that the proposed model can not only improves point forecasts compared with benchmark methods, but also constructs higher quality of probabilistic PIs.", 
        "author": "Xiangang Peng and Weiqin Zheng and Dan Zhang and Yi Liu and Di Lu and Lixiang Lin", 
        "keyword": "Probabilistic wind speed forecasting\", \"Time-varying mixture copula function\", \"On-line sequential keywords =utlier Robust Extreme Learning Machine\", \"On-line ensemble using ordered aggregation\", \"Bernaola Galvan Algorithm", 
        "title": "A novel probabilistic wind speed forecasting based on combination of the adaptive ensemble of on-line sequential \\{ORELM\\} (Outlier Robust Extreme Learning Machine) and \\{TVMCF\\} (time-varying mixture copula function)"
    }, 
    {
        "abstract": "Abstract Side weirs are installed on the side walls of main channels to control and regulate flow. In this study, sensitivity analysis is planned using Extreme Learning Machines (ELM) to recognize the factors affecting the discharge coefficient in trapezoidal channels. A total of 31 models with 1 to 5 parameters are developed. The input parameters are ratio of side weir length to trapezoidal channel bottom width (L/b), Froude number (Fr), ratio of side weir length to flow depth upstream of the side weir (L/y1), ratio of flow depth upstream of the side weir to the main channel bottom width (y1/b) and trapezoid channel side wall slope (m). Among the models with one input parameter, the model including Froude number modeled the discharge coefficient more accurately (MAPE=4.118, R2=0.835). Between models with two input parameters, the model using Fr and L/b produced \\{MAPE\\} and \\{R2\\} values of 2.607 and 0.913 respectively. Moreover, among the models with four input parameters, the model containing Fr, L/b, L/y1 and y1/b was the most accurate (MAPE=2.916, R2=0.925).", 
        "author": "Hamed Azimi and Hossein Bonakdari and Isa Ebtehaj", 
        "keyword": "Side weir\", \"Trapezoidal channel\", \"Discharge capacity\", \"Sensitivity analysis\", \"Extreme learning machine (ELM)", 
        "title": "Sensitivity analysis of the factors affecting the discharge capacity of side weirs in trapezoidal channels using extreme learning machines"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is an efficient learning algorithm of training single layer feed-forward neural networks (SLFNs). With the development of unsupervised learning in recent years, integrating \\{ELM\\} with autoencoder has become a new perspective for extracting feature using unlabeled data. In this paper, we propose a new variant of extreme learning machine autoencoder (ELM-AE) called generalized extreme learning machine autoencoder (GELM-AE) which adds the manifold regularization to the objective of ELM-AE. Some experiments carried out on real-world data sets show that GELM-AE outperforms some state-of-the-art unsupervised learning algorithms, including k-means, laplacian embedding (LE), spectral clustering (SC) and ELM-AE. Furthermore, we also propose a new deep neural network called multilayer generalized extreme learning machine autoencoder (ML-GELM) by stacking several GELM-AE to detect more abstract representations. The experiments results show that ML-GELM outperforms \\{ELM\\} and many other deep models, such as multilayer \\{ELM\\} autoencoder (ML-ELM), deep belief network (DBN) and stacked autoencoder (SAE). Due to the utilization of ELM, ML-GELM is also faster than \\{DBN\\} and SAE.", 
        "author": "Kai Sun and Jiangshe Zhang and Chunxia Zhang and Junying Hu", 
        "keyword": "Extreme learning machine\", \"Generalized extreme learning machine autoencoder\", \"Manifold keywords =egularization\", \"Deep neural network\", \"Multilayer generalized extreme learning machine autoencoder", 
        "title": "Generalized extreme learning machine autoencoder and a new deep neural network"
    }, 
    {
        "abstract": "Abstract This paper considers the two-stage capacitated facility location problem (TSCFLP) in which products manufactured in plants are delivered to customers via storage depots. Customer demands are satisfied subject to limited plant production and limited depot storage capacity. The objective is to determine the locations of plants and depots in order to minimize the total cost including the fixed cost and transportation cost. However, the problem is known to be NP-hard. A practicable exact algorithm is impossible to be developed. In order to solve large-sized problems encountered in the practical decision process, an efficient alternative approximate method becomes more valuable. This paper aims to propose a hybrid evolutionary algorithm framework with machine learning fitness approximation for delivering better solutions in a reasonable amount of computational time. In our study, genetic operators are adopted to perform the search process and a local search strategy is used to refine the best solution found in the population. To avoid the expensive consumption of computational time during the fitness evaluating process, the framework uses extreme machine learning to approximate the fitness of most individuals. Moreover, two heuristics based on the characteristics of the problem is incorporated to generate a good initial population. Computational experiments are performed on two sets of test instances from the recent literature. The performance of the proposed algorithm is evaluated and analyzed. Compared with other algorithms in the literature, the proposed algorithm can find the optimal or near-optimal solutions in a reasonable amount of computational time. By employing the proposed algorithm, facilities can be positioned more efficiently, which means the fixed cost and the transportation cost can be decreased significantly, and organizations can enhance competitiveness by using the optimized facility location scheme.", 
        "author": "Peng Guo and Wenming Cheng and Yi Wang", 
        "keyword": "Facility location\", \"Evolutionary algorithm\", \"Fitness approximation\", \"Local search\", \"Extreme machine learning", 
        "title": "Hybrid evolutionary algorithm with extreme machine learning fitness function evaluation for two-stage capacitated facility location problems"
    }, 
    {
        "abstract": "Abstract A high degree of uncertainty associated with the emission inventory for China tends to degrade the performance of chemical transport models in predicting PM2.5 concentrations especially on a daily basis. In this study a novel machine learning algorithm, Geographically-Weighted Gradient Boosting Machine (GW-GBM), was developed by improving \\{GBM\\} through building spatial smoothing kernels to weigh the loss function. This modification addressed the spatial nonstationarity of the relationships between PM2.5 concentrations and predictor variables such as aerosol optical depth (AOD) and meteorological conditions. GW-GBM also overcame the estimation bias of PM2.5 concentrations due to missing \\{AOD\\} retrievals, and thus potentially improved subsequent exposure analyses. GW-GBM showed good performance in predicting daily PM2.5 concentrations (R2\u00a0=\u00a00.76, RMSE\u00a0=\u00a023.0\u00a0\u03bcg/m3) even with partially missing \\{AOD\\} data, which was better than the original \\{GBM\\} model (R2\u00a0=\u00a00.71, RMSE\u00a0=\u00a025.3\u00a0\u03bcg/m3). On the basis of the continuous spatiotemporal prediction of PM2.5 concentrations, it was predicted that 95% of the population lived in areas where the estimated annual mean PM2.5 concentration was higher than 35\u00a0\u03bcg/m3, and 45% of the population was exposed to PM2.5 &gt;75\u00a0\u03bcg/m3 for over 100 days in 2014. GW-GBM accurately predicted continuous daily PM2.5 concentrations in China for assessing acute human health effects.", 
        "author": "Yu Zhan and Yuzhou Luo and Xunfei Deng and Huajin Chen and Michael L. Grieneisen and Xueyou Shen and Lizhong Zhu and Minghua Zhang", 
        "keyword": "Fine particulate matter\", \"Human exposure\", \"Spatial nonstationarity\", \"Geographically weighted\", \"Machine learning", 
        "title": "Spatiotemporal prediction of continuous daily PM2.5 concentrations across China using a spatially explicit machine learning algorithm"
    }, 
    {
        "abstract": "AbstractBackground and objectives Early-phase virtual screening of candidate drug molecules plays a key role in pharmaceutical industry from data mining and machine learning to prevent adverse effects of the drugs. Computational classification methods can distinguish approved drugs from withdrawn ones. We focused on 6 data sets including maximum 110 approved and 110 withdrawn drugs for all and nervous system diseases to distinguish approved drugs from withdrawn ones. Methods In this study, we used support vector machines (SVMs) and ensemble methods (EMs) such as boosted and bagged trees to classify drugs into approved and withdrawn categories. Also, we used \\{CORINA\\} Symphony program to identify Toxprint chemotypes including over 700 predefined chemotypes for determination of risk and safety assesment of candidate drug molecules. In addition, we studied nervous system withdrawn drugs to determine the key fragments with The ParMol package including gSpan algorithm. Results According to our results, the descriptors named as the number of total chemotypes and bond CN_amine_aliphatic_generic were more significant descriptors. The developed Medium Gaussian \\{SVM\\} model reached 78% prediction accuracy on test set for drug data set including all disease. Here, bagged tree and linear \\{SVM\\} models showed 89% of accuracies for phycholeptics and psychoanaleptics drugs. A set of discriminative fragments in nervous system withdrawn drug (NSWD) data sets was obtained. These fragments responsible for the drugs removed from market were benzene, toluene, N,N-dimethylethylamine, crotylamine, 5-methyl-2,4-heptadiene, octatriene and carbonyl group. Conclusion This paper covers the development of computational classification methods to distinguish approved drugs from withdrawn ones. In addition, the results of this study indicated the identification of discriminative fragments is of significance to design a new nervous system approved drugs with interpretation of the structures of the NSWDs.", 
        "author": "Aytun Onay and Melih Onay and Osman Abul", 
        "keyword": "Machine learning\", \"Support vector machine\", \"Drug discovery\", \"ToxPrint chemotypes\", \"Approved &amp; withdrawn drug", 
        "title": "Classification of nervous system withdrawn and approved drugs with ToxPrint features via machine learning strategies"
    }, 
    {
        "abstract": "Abstract The 38th radiology Intersociety Committee reviewed the current state and future direction of clinical data science and its application to radiology practice. The assembled participants discussed the need to use current technology to better generate and demonstrate radiologists\u2019 value for our patients and referring providers. The attendants grappled with the potentially disruptive applications of machine learning to image analysis. Although the prospect of algorithms\u2019 interpreting images automatically initially shakes the core of the radiology profession, the group emerged with tremendous optimism about the future of radiology. Emerging technologies will provide enormous opportunities for radiologists to augment and improve the quality of care they provide to their patients. Radiologists must maintain an active role in guiding the development of these technologies. The conference ended with a call to action to develop educational strategies for future leaders, communicate optimism for our profession\u2019s future, and engage with industry to ensure the ethics and clinical relevance of developing technologies.", 
        "author": "Jonathan B. Kruskal and Seth Berkowitz and J. Raymond Geis and Woojin Kim and Paul Nagy and Keith Dreyer", 
        "keyword": "Intersociety Committee\", \"ACR\", \"big data\", \"deep learning\", \"machine learning\", \"data science\", keywords =radiology\", \"imaging informatics", 
        "title": "Big Data and Machine Learning\u2014Strategies for Driving This Bus: A Summary of the 2016 Intersociety Summer Conference"
    }, 
    {
        "abstract": "Abstract The thickness of tectonically deformed coal (TDC) has positive correlation associations with gas outbursts. In order to predict the \\{TDC\\} thickness of coal beds, we propose a new quantitative predicting method using an extreme learning machine (ELM) algorithm, a principal component analysis (PCA) algorithm, and seismic attributes. At first, we build an \\{ELM\\} prediction model using the \\{PCA\\} attributes of a synthetic seismic section. The results suggest that the \\{ELM\\} model can produce a reliable and accurate prediction of the \\{TDC\\} thickness for synthetic data, preferring Sigmoid activation function and 20 hidden nodes. Then, we analyze the applicability of the \\{ELM\\} model on the thickness prediction of the \\{TDC\\} with real application data. Through the cross validation of near-well traces, the results suggest that the \\{ELM\\} model can produce a reliable and accurate prediction of the TDC. After that, we use 250 near-well traces from 10 wells to build an \\{ELM\\} predicting model and use the model to forecast the \\{TDC\\} thickness of the No. 15 coal in the study area using the \\{PCA\\} attributes as the inputs. Comparing the predicted results, it is noted that the trained \\{ELM\\} model with two selected \\{PCA\\} attributes yields better predication results than those from the other combinations of the attributes. Finally, the trained \\{ELM\\} model with real seismic data have a different number of hidden nodes (10) than the trained \\{ELM\\} model with synthetic seismic data. In summary, it is feasible to use an \\{ELM\\} model to predict the \\{TDC\\} thickness using the calculated \\{PCA\\} attributes as the inputs. However, the input attributes, the activation function and the number of hidden nodes in the \\{ELM\\} model should be selected and tested carefully based on individual application.", 
        "author": "Xin Wang and Yan Li and Tongjun Chen and Qiuyan Yan and Li Ma", 
        "keyword": "Thickness prediction\", \"Tectonically deformed coal\", \"Extreme learning machine\", \"Seismic keywords =ttribute\", \"Principal component analysis\", \"Cross validation", 
        "title": "Quantitative thickness prediction of tectonically deformed coal using Extreme Learning Machine and Principal Component Analysis: a case study"
    }, 
    {
        "abstract": "Abstract Progress in biomechanical modelling of human soft tissue is the basis for the development of new clinical applications capable of improving the diagnosis and treatment of some diseases (e.g. cancer), as well as the surgical planning and guidance of some interventions. The finite element method (FEM) is one of the most popular techniques used to predict the deformation of the human soft tissue due to its high accuracy. However, \\{FEM\\} has an associated high computational cost, which makes it difficult its integration in real-time computer-aided surgery systems. An alternative for simulating the mechanical behaviour of human organs in real time comes from the use of machine learning (ML) techniques, which are much faster than FEM. This paper assesses the feasibility of \\{ML\\} methods for modelling the biomechanical behaviour of the human liver during the breathing process, which is crucial for guiding surgeons during interventions where it is critical to track this deformation (e.g. some specific kind of biopsies) or for the accurate application of radiotherapy dose to liver tumours. For this purpose, different \\{ML\\} regression models were investigated, including three tree-based methods (decision trees, random forests and extremely randomised trees) and other two simpler regression techniques (dummy model and linear regression). In order to build and validate the \\{ML\\} models, a labelled data set was constructed from modelling the deformation of eight ex-vivo human livers using FEM. The best prediction performance was obtained using extremely randomised trees, with a mean error of 0.07\u00a0mm and all the samples with an error under 1\u00a0mm. The achieved results lay the foundation for the future development of some real-time software capable of simulating the human liver deformation during the breathing process during clinical interventions.", 
        "author": "D. Lorente and F. Mart\u00ednez-Mart\u00ednez and M.J. Rup\u00e9rez and M.A. Lago and M. Mart\u00ednez-Sober and P. Escandell-Montero and J.M. Mart\u00ednez-Mart\u00ednez and S. Mart\u00ednez-Sanchis and A.J. Serrano-L\u00f3pez and C. Monserrat and J.D. Mart\u00edn-Guerrero", 
        "keyword": "Soft tissue deformation\", \"Biomechanical behaviour\", \"Liver\", \"Machine learning\", \"Tree-based regression", 
        "title": "A framework for modelling the biomechanical behaviour of the human liver during breathing in real time using machine learning"
    }, 
    {
        "abstract": "Abstract Machine learning is one of the driving forces of science and commerce, but the proliferation of Big Data demands paradigm shifts from traditional methods in the application of machine learning techniques on this voluminous data having varying velocity. With the availability of large health care datasets and progressions in machine learning techniques, computers are now well equipped in diagnosing many health issues. This work aims at developing a real time remote health status prediction system built around open source Big Data processing engine, the Apache Spark, deployed in the cloud which focus on applying machine learning model on streaming Big Data. In this scalable system, the user tweets his health attributes and the application receives the same in real time, extracts the attributes and applies machine learning model to predict user's health status which is then directly messaged to him/her instantly for taking appropriate action.", 
        "author": "Lekha R. Nair and Sujala D. Shetty and Siddhanth D. Shetty", 
        "keyword": "Big data machine learning\", \"Streaming data processing\", \"Tweet processing\", \"Apache spark\", \"Health informatics", 
        "title": "Applying spark based machine learning model on streaming big data for health status prediction"
    }, 
    {
        "abstract": "AbstractBackground and aim This study aims to examine the distinguishability of age-related cognitive decline (ARCD) from dementias based on some neurocognitive tests using machine learning. Materials and methods 106 subjects were divided into four groups: \\{ARCD\\} (n = 30), probable Alzheimer\u2019s disease (AD) (n = 20), vascular dementia (VD) (n = 21) and amnestic mild cognitive impairment (MCI) (n = 35). The following tests were applied to all subjects: The Wechsler memory scale-revised, a clock-drawing, the dual similarities, interpretation of proverbs, word fluency, the Stroop, the Boston naming (BNT), the Benton face recognition, a copying-drawings and \u00d6ktem verbal memory processes (\u00d6-VMPT) tests. A multilayer perceptron, a support vector machine and a classification via regression with M5-model trees were employed for classification. Results The pairwise classification results show that \\{ARCD\\} is completely separable from \\{AD\\} with a success rate of 100% and highly separable from \\{MCI\\} and \\{VD\\} with success rates of 95.4% and 86.30%, respectively. The neurocognitive tests with the higher merit values were \u00d6-VMPT recognition (ARCD vs. AD), \u00d6-VMPT total learning (ARCD vs. MCI) and semantic fluency, proverbs, Stroop interference and naming \\{BNT\\} (ARCD vs. VD). Conclusion The findings show that machine learning can be successfully utilized for distinguishing \\{ARCD\\} from dementias based on neurocognitive tests.", 
        "author": "F\u00fcsun Er and P\u0131nar Iscen and Sevki Sahin and Nilgun \u00c7inar and Sibel Karsidag and Dionysis Goularas", 
        "keyword": "Age-related cognitive decline\", \"Dementia, machine learning\", \"Mild cognitive impairment", 
        "title": "Distinguishing age-related cognitive decline from dementias: A study based on machine learning algorithms"
    }, 
    {
        "abstract": "Abstract A complexity of business dynamics often forces decision-makers to make decisions based on subjective mental models, reflecting their experience. However, research has shown that companies perform better when they apply data-driven decision-making. This creates an incentive to introduce intelligent, data-based decision models, which are comprehensive and support the interactive evaluation of decision options necessary for the business environment. Recently, a new general explanation methodology has been proposed, which supports the explanation of state-of-the-art black-box prediction models. Uniform explanations are generated on the level of model/individual instance and support what-if analysis. We present a novel use of this methodology inside an intelligent system in a real-world case of business-to-business (B2B) sales forecasting, a complex task frequently done judgmentally. Users can validate their assumptions with the presented explanations and test their hypotheses using the presented what-if parallel graph representation. The results demonstrate effectiveness and usability of the methodology. A significant advantage of the presented method is the possibility to evaluate seller\u2019s actions and to outline general recommendations in sales strategy. This flexibility of the approach and easy-to-follow explanations are suitable for many different applications. Our well-documented real-world case shows how to solve a decision support problem, namely that the best performing black-box models are inaccessible to human interaction and analysis. This could extend the use of the intelligent systems to areas where they were so far neglected due to their insistence on comprehensible models. A separation of the machine learning model selection from model explanation is another significant benefit for expert and intelligent systems. Explanations unconnected to a particular prediction model positively influence acceptance of new and complex models in the business environment through their easy assessment and switching.", 
        "author": "Marko Bohanec and Mirjana Kljaji\u0107 Bor\u0161tnar and Marko Robnik-\u0160ikonja", 
        "keyword": "Machine learning\", \"Prediction explanation\", \"Intelligent system\", \"Black-box models\", \"B2B Sales forecasting", 
        "title": "Explaining machine learning models in sales predictions"
    }, 
    {
        "abstract": "AbstractObjectives In older adults, traditional metrics derived from polysomnography (PSG) are not well correlated with subjective sleep quality. Little is known about whether the association between \\{PSG\\} and subjective sleep quality changes with age, or whether quantitative assessment of \\{EEG\\} (qEEG) is associated with sleep quality. We therefore examined the relationship between subjective sleep quality and objective sleep characteristics (standard polysomnography and qEEG) across middle to older adulthood. Methods Using a cross-sectional analyses of 3,173 community-dwelling men and women ages 39-90 participating in the Sleep Heart Health Study, we examined the relationship between a morning rating of the prior night\u2019s sleep quality (Sleep Depth and Restfulness) and polysomnographic and qEEG descriptors of that single night of sleep, along with clinical and demographic measures. Multivariable models were constructed using two machine learning methods, lasso penalized regressions and random forests. Results Little variance was explained across models. Greater objective sleep efficiency, reduced wake after sleep onset and fewer sleep to wake stage transitions were each associated with higher sleep quality; qEEG variables contributed little explanatory power. The oldest adults reported the highest sleep quality even as objective sleep deteriorated, such that they would rate their sleep better given the same level of sleep efficiency. Despite this, there were no major differences in the predictors of subjective sleep across the age span. Conclusion Standard metrics derived from polysomnography, including qEEG, contribute little to explaining subjective sleep quality in middle-aged to older adults. The objective correlates of subjective sleep quality do not appear to systematically change with age, despite a change in the relationship between subjective sleep quality and objective sleep efficiency.", 
        "author": "Katherine A. Kaplan and Prajesh P. Hardas and Susan Redline and Jamie M. Zeitzer", 
        "keyword": "Sleep quality\", \"machine learning\", \"polysomnography\", \"aging\", \"sex differences", 
        "title": "Correlates of sleep quality in midlife and beyond: a machine learning analysis"
    }, 
    {
        "abstract": "Abstract Predictions regarding the solar greenhouse temperature and humidity are important because they play a critical role in greenhouse cultivation. On account of this, it is important to set up a predictive model of temperature and humidity that would precisely predict the temperature and humidity, reducing potential financial losses. This paper presents a novel temperature and humidity prediction model based on convex bidirectional extreme learning machine (CB-ELM). Simulation results show that the convergence rate of the bidirectional extreme learning machine (B-ELM) can further be improved while retaining the same simplicity, by simply recalculating the output weights of the existing nodes based on a convex optimization method when a new hidden node is randomly added. The performance of the CB-ELM model is compared with other modeling approaches by applying it to predict solar greenhouse temperature and humidity. The experiment results show that the CB-ELM model predictions are more accurate than those of the B-ELM, Back Propagation Neural Network (BPNN), Support Vector Machine (SVM), and Radial Basis Function (RBF). Therefore, it can be considered as a suitable and effective method for predicting the solar greenhouse temperature and humidity.", 
        "author": "Weidong Zou and Fenxi Yao and Baihai Zhang and Chaoxing He and Zixiao Guan", 
        "keyword": "Solar greenhouse\", \"Support vector machine\", \"Radial basis function\", \"Convex bidirectional extreme learning machine", 
        "title": "Verification and predicting temperature and humidity in a solar greenhouse based on convex bidirectional extreme learning machine algorithm"
    }, 
    {
        "abstract": "Abstract Alzheimer\u2019s disease is a complex progressive neurodegenerative brain disorder, being its prevalence expected to rise over the next decades. Unconventional strategies for elucidating the genetic mechanisms are necessary due to its polygenic nature. In this work, the input information sources are five: a public \\{DNA\\} microarray that measures expression levels of control and patient samples, repositories of known genes associated to Alzheimer\u2019s disease, additional data, Gene Ontology and finally, a literature review or expert knowledge to validate the results. As methodology to identify genes highly related to this disease, we present the integration of three machine learning techniques: particularly, we have used decision trees, quantitative association rules and hierarchical cluster to analyze Alzheimer\u2019s disease gene expression profiles to identify genes highly linked to this neurodegenerative disease, through changes in their expression levels between control and patient samples. We propose an ensemble of decision trees and quantitative association rules to find the most suitable configurations of the multi-objective evolutionary algorithm GarNet, in order to overcome the complex parametrization intrinsic to this type of algorithms. To fulfill this goal, GarNet has been executed using multiple configuration settings and the well-known C4.5 has been used to find the minimum accuracy to be satisfied. Then, GarNet is rerun to identify dependencies between genes and their expression levels, so we are able to distinguish between healthy individuals and Alzheimer\u2019s patients using the configurations that overcome the minimum threshold of accuracy defined by C4.5 algorithm. Finally, a hierarchical cluster analysis has been used to validate the obtained gene-Alzheimer\u2019s Disease associations provided by GarNet. The results have shown that the obtained rules were able to successfully characterize the underlying information, grouping relevant genes for Alzheimer Disease. The genes reported by our approach provided two well defined groups that perfectly divided the samples between healthy and Alzheimer\u2019s Disease patients. To prove the relevance of the obtained results, a statistical test and gene expression fold-change were used. Furthermore, this relevance has been summarized in a volcano plot, showing two clearly separated and significant groups of genes that are up or down-regulated in Alzheimer\u2019s Disease patients. A biological knowledge integration phase was performed based on the information fusion of systematic literature review, enrichment Gene Ontology terms for the described genes found in the hippocampus of patients. Finally, a validation phase with additional data and a permutation test is carried out, being the results consistent with previous studies.", 
        "author": "Mar\u00eda Mart\u00ednez-Ballesteros and Jos\u00e9 M. Garc\u00eda-Heredia and Isabel A. Nepomuceno-Chamorro and Jos\u00e9 C. Riquelme-Santos", 
        "keyword": "Association rules\", \"Gene expression profiles\", \"Alzheimer\u2019s disease\", \"Statistical significant keywords =enes\", \"Ensemble learning\", \"Biological knowledge integration", 
        "title": "Machine learning techniques to discover genes with potential prognosis role in Alzheimer\u2019s disease using different biological sources"
    }, 
    {
        "abstract": "Abstract The quantitative simulation of forest fire spreading plays an essential role in designing quick risk management and implementing effective suppression policies. As a preferable modelling approach, the cellular automaton (CA) has been used to simulate the complex mechanisms of fire spreading. However, in traditional \\{CA\\} models, comprehensive studies on the physical principles of forest fires are needed to define the local transition rules. Instead of defining transition rules, the Extreme Learning Machine (ELM) was applied in this study. By integrating the \\{ELM\\} with the traditional forest fire \\{CA\\} framework, a new cellular automaton modelling approach was proposed. After that, its performance was validated using data collected from five fires in the west of United States. Results show that the \\{ELM\\} performed well in predicting each cell\u2019s igniting probability. The impact of wind velocity on fire spreading pattern can be effectively described by the proposed modelling approach. Furthermore, the validation against actual fire behavior observations shows that its simulation performance is acceptable and in most cases is better than that of the previously reported studies.", 
        "author": "Zhong Zheng and Wei Huang and Songnian Li and Yongnian Zeng", 
        "keyword": "Cellular automaton\", \"Machine learning\", \"Forest fire\", \"Simulation", 
        "title": "Forest fire spread simulating model using cellular automaton with extreme learning machine"
    }, 
    {
        "abstract": "Abstract Energy saving and carbon emissions reduction of the petrochemical industry are affected by many factors. Thus, it is difficult to analyze and optimize the energy of complex petrochemical systems accurately. This paper proposes an energy and carbon emissions analysis and prediction approach based on an improved extreme learning machine (ELM) integrated interpretative structural model (ISM) (ISM-ELM). \\{ISM\\} based the partial correlation coefficient is utilized to analyze key parameters that affect the energy and carbon emissions of the complex petrochemical system, and can denoise and reduce dimensions of data to decrease the training time and errors of the \\{ELM\\} prediction model. Meanwhile, in terms of the model accuracy and the training time, the robustness and effectiveness of the ISM-ELM model are better than the \\{ELM\\} through standard data sets from the University of California Irvine (UCI) repository. Moreover, a multi-inputs and single-output (MISO) model of energy and carbon emissions of complex ethylene systems is established based on the ISM-ELM. Finally, detailed analyses and simulations using the real ethylene plant data demonstrate the effectiveness of the ISM-ELM and can guide the improvement direction of energy saving and carbon emissions reduction in complex petrochemical systems.", 
        "author": "Yongming Han and Qunxiong Zhu and Zhiqiang Geng and Yuan Xu", 
        "keyword": "Energy saving\", \"Carbon emissions reduction\", \"Extreme learning machine\", \"Interpretative keywords =tructural model\", \"Complex petrochemical systems", 
        "title": "Energy and carbon emissions analysis and prediction of complex petrochemical systems based on an improved extreme learning machine integrated interpretative structural model"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) for regression has been used in many fields because of its easy-implementation, fast training speed and good generalization performance. However, basic \\{ELM\\} with \u21132-norm loss function is sensitive to outliers. Recently, \u21131-norm loss function and Huber loss function have been used in \\{ELM\\} to enhance the robustness. However, the \u21131-norm loss function and the Huber loss function can also be effected by outliers because of their linear correlation with the errors. Moreover, existing robust \\{ELM\\} methods only use \u21132-norm regularization or have no regularization term. In this study, we propose a unified model for robust regularized \\{ELM\\} regression using iteratively reweighted least squares (IRLS), and call it RELM-IRLS. We perform a comprehensive study on the robust loss function and regularization term for robust \\{ELM\\} regression. Four loss functions (i.e., \u21131-norm, Huber, Bisquare and Welsch) are used to enhance the robustness, and two types of regularization (\u21132-norm and \u21131-norm) are used to avoid overfitting. Experiments show that our proposed RELM-IRLS with \u21132-norm and \u21131-norm regularization is stable and accurate for data with 0 \u223c 40 % outlier levels, and that RELM-IRLS with \u21131-norm regularization can obtain a compact network because of the highly sparse output weights of the network.", 
        "author": "Kai Chen and Qi Lv and Yao Lu and Yong Dou", 
        "keyword": "Extreme learning machine\", \"Iteratively reweighted least squares\", \"Robustness\", \"\u21132-norm keywords =egularization\", \"\u21131-norm regularization", 
        "title": "Robust regularized extreme learning machine for regression using iteratively reweighted least squares"
    }, 
    {
        "abstract": "Abstract A \u201cmiRNA sponge\u201d is an artificial oligonucleotide-based miRNA inhibitor containing multiple binding sites for a specific miRNA. Each miRNA sponge can bind and sequester several miRNA copies, thereby decreasing the cellular levels of the target miRNA. In addition to developing artificial miRNA sponges, scientists have sought endogenous \\{RNA\\} transcripts and found that long non-coding RNAs, competing endogenous RNAs, pseudogenes, circular RNAs, and coding \\{RNAs\\} could act as miRNA sponges under precise conditions. Here we present a computational approach for the prediction of endogenous human miRNA sponge candidates targeting viral miRNAs derived from pathogenic human viruses. Viral miRNA binding sites were predicted using a newly-developed machine learning-based method, and candidate interactions between miRNAs and sponge \\{RNAs\\} were experimentally validated using luciferase reporter assay, western blot analysis, and flow cytometry. We found that BX649188.1 functions as a potential natural miRNA sponge against kshv-miR-K12-7-3p.", 
        "author": "Soowon Kang and Seunghyun Park and Sungroh Yoon and Hyeyoung Min", 
        "keyword": "Machine learning\", \"Hierarchical agglomerative clustering\", \"microRNA sponge\", \"Competing keywords =ndogenous \\{RNA\\} (ceRNA)\", \"Pseudogene", 
        "title": "Machine learning-based identification of endogenous cellular microRNA sponges against viral microRNAs"
    }, 
    {
        "abstract": "Abstract Identification and classification of graph data is a hot research issue in pattern recognition. The conventional methods of graph classification usually convert the graph data to the vector representation and then using \\{SVM\\} to be a classifier. These methods ignore the sparsity of graph data, and with the increase of the input sample, the storage and computation of the kernel matrix will cost a lot of memory and time. In this paper, we propose a new graph classification algorithm called graph classification based on sparse graph feature selection and extreme learning machine. The key of our method is using the lasso to select features because of the sparsity of graph data, and extreme learning machine(ELM) is introduced to the following classification task due to its good performance. Extensive experimental results on a series of benchmark graph data sets validate the effectiveness of the proposed methods.", 
        "author": "Yajun Yu and Zhisong Pan and Guyu Hu and Huifeng Ren", 
        "keyword": "Graph kernel\", \"Graph classification\", \"Extreme learning machine\", \"Lasso", 
        "title": "Graph classfication based on sparse graph feature selection and extreme learning machine"
    }, 
    {
        "abstract": "The immune system has evolved to sense invading pathogens, control infection, and restore tissue integrity. Despite symptomatic variability in patients, unequivocal evidence that an individual's immune system distinguishes between different organisms and mounts an appropriate response is lacking. We here used a systematic approach to characterize responses to microbiologically well-defined infection in a total of 83 peritoneal dialysis patients on the day of presentation with acute peritonitis. A broad range of\u00a0cellular and soluble parameters was determined in peritoneal effluents, covering the majority of local immune cells, inflammatory and regulatory cytokines and chemokines as well as tissue damage\u2013related factors. Our analyses, utilizing machine-learning algorithms, demonstrate that different groups of bacteria induce qualitatively distinct local immune fingerprints, with specific biomarker signatures associated with Gram-negative and Gram-positive organisms, and with culture-negative episodes of unclear etiology. Even more, within the Gram-positive group, unique immune biomarker combinations identified streptococcal and non-streptococcal species including coagulase-negative Staphylococcus spp. These findings have diagnostic and prognostic implications by informing patient management and treatment choice at the point of care. Thus, our data establish the power of non-linear mathematical models to analyze complex biomedical datasets and highlight key pathways involved in pathogen-specific immune responses.", 
        "author": "Jingjing Zhang and Ida M. Friberg and Ann Kift-Morgan and Gita Parekh and Matt P. Morgan and Anna Rita Liuzzi and Chan-Yu Lin and Kieron L. Donovan and Chantal S. Colmont and Peter H. Morgan and Paul Davis and Ian Weeks and Donald J. Fraser and Nicholas Topley and Matthias Eberl", 
        "keyword": "biomarkers\", \"inflammation\", \"machine learning methods\", \"microbial\u00a0infection\", \"peritoneal dialysis", 
        "title": "Machine-learning algorithms define pathogen-specific local immune fingerprints in peritoneal dialysis patients with bacterial infections"
    }, 
    {
        "abstract": "Abstract Deep learning has received significant attention recently as a promising solution to many problems in the area of artificial intelligence. Among several deep learning architectures, convolutional neural networks (CNNs) demonstrate superior performance when compared to other machine learning methods in the applications of object detection and recognition. We use a \\{CNN\\} for image enhancement and the detection of driving lanes on motorways. In general, the process of lane detection consists of edge extraction and line detection. A \\{CNN\\} can be used to enhance the input images before lane detection by excluding noise and obstacles that are irrelevant to the edge detection result. However, training conventional \\{CNNs\\} requires considerable computation and a big dataset. Therefore, we suggest a new learning algorithm for \\{CNNs\\} using an extreme learning machine (ELM). The \\{ELM\\} is a fast learning method used to calculate network weights between output and hidden layers in a single iteration and thus, can dramatically reduce learning time while producing accurate results with minimal training data. A conventional \\{ELM\\} can be applied to networks with a single hidden layer; as such, we propose a stacked \\{ELM\\} architecture in the \\{CNN\\} framework. Further, we modify the backpropagation algorithm to find the targets of hidden layers and effectively learn network weights while maintaining performance. Experimental results confirm that the proposed method is effective in reducing learning time and improving performance.", 
        "author": "Jihun Kim and Jonghong Kim and Gil-Jin Jang and Minho Lee", 
        "keyword": "Convolutional neural network\", \"Extreme learning machine\", \"Advanced driver assistance system\", \"Lane detection", 
        "title": "Fast learning method for convolutional neural networks using extreme learning machine and its application to lane detection"
    }, 
    {
        "abstract": "Abstract To achieve energy efficiency in the Internet-of-Things (IoT), more intelligence is required in the wireless IoT nodes. Otherwise, the energy required by the wireless communication of raw sensor data will prohibit battery lifetime, the backbone of IoT. One option to achive this intelligence is to implement a variety of machine learning algorithms on the IoT sensor instead of the cloud. Shown here is sub-milliwatt machine learning accelerator operating at the Ultra-Low Voltage Minimum-Energy Point. The accelerator is a Transport Triggered Architecture (TTA) Application-Specific Instruction-Set Processor (ASIP) targeted for running various Machine Learning algorithms. The \\{ASIP\\} is implemented in 28 nm \\{FDSOI\\} (Fully Depleted Silicon On Insulator) \\{CMOS\\} process, with an operating voltage of 0.35 V, and is capable of 5.3pJ/cycle and 1.8nJ/iteration when performing conventional machine learning algorithms. The \\{ASIP\\} also includes hardware and compiler support for approximate computing. With the machine learning algorithms, computing approximately brings a maximum of 4.7% energy savings.", 
        "author": "Jukka Teittinen and Markus Hiienkari and Indr\u0117 \u017dliobait\u0117 and Jaakko Hollmen and Heikki Berg and Juha Heiskala and Timo Viitanen and Jesse Simonsson and Lauri Koskinen", 
        "keyword": "Integrated circuit\", \"Processor\", \"Approximate computing\", \"Minimum energy point\", \"Machine keywords =earning\", \"Timing error detection", 
        "title": "A 5.3 pJ/op approximate \\{TTA\\} \\{VLIW\\} tailored for machine learning"
    }, 
    {
        "abstract": "Abstract How to determine the network structure is an open problem in extreme learning machine (ELM). Error minimized extreme learning machine (EM-ELM) is a simple and efficient approach to determine the number of hidden nodes. However, similar to other constructive ELM, EM-ELM lays much emphasis on the convergence accuracy, which may obtain a single-hidden-layer feedforward neural networks (SLFN) with good convergence performance but bad condition. In this paper, an effective approach based on error minimized \\{ELM\\} and particle swarm optimization (PSO) is proposed to adaptively determine the structure of \\{SLFN\\} for regression problem. In the new method, to establish a compact and well-conditioning SLFN, the hidden node optimized by \\{PSO\\} is added to the \\{SLFN\\} one by one. Moreover, not only the regression accuracy but also the condition value of the hidden output matrix of the network is considered in the optimization process. Experiment results on various regression problems verify that the proposed algorithm achieves better generalization performance with fewer hidden nodes than other constructive ELM.", 
        "author": "Fei Han and Min-Ru Zhao and Jian-Ming Zhang and Qing-Hua Ling", 
        "keyword": "Extreme learning machine\", \"Particle swarm optimization\", \"Network structure\", \"Generalization keywords =erformance\", \"Condition value", 
        "title": "An improved incremental constructive single-hidden-layer feedforward networks for extreme learning machine based on particle swarm optimization"
    }, 
    {
        "abstract": "Abstract Extreme learning machine, as a generalized single-hidden-layer feedforward network, has achieved much attention for its extremely fast learning speed and good generalization performance. However, big data often makes a challenge in large scale learning of extreme learning machine due to the memory limitation of single machine as well as the distributed manner of large scale data in many applications. For the purpose of relieving the limitation of memory with big data, in this paper, we exploit a novel distributed model to implement the extreme learning machine algorithm in parallel for large-scale data set, namely distributed extreme learning machine (DELM). A corresponding algorithm is developed on the basis of alternating direction method of multipliers which has shown its effectiveness in distributed convex optimization. Finally, extensive experiments on some benchmark data sets are carried out to illustrate the effectiveness and superiority of the proposed \\{DELM\\} method with an analysis on the performance of speedup, scaleup and sizeup.", 
        "author": "Minnan Luo and Lingling Zhang and Jun Liu and Jun Guo and Qinghua Zheng", 
        "keyword": "Extreme learning machine\", \"Neuron work\", \"Alternating direction method of multiplier", 
        "title": "Distributed extreme learning machine with alternating direction method of multiplier"
    }, 
    {
        "abstract": "Abstract The successful applications of the conventional Computational Intelligence (CI) techniques and Hybrid Intelligent Systems (HIS) in petroleum reservoir characterization have been reported. However, these techniques are limited in their capability to handle a single hypothesis of a problem at a time. The major objective of the reservoir characterization process is to produce models that are robust enough to help improve the accuracy of the predictions of reservoir properties for use in full-field and large-scale simulation models. Research in \\{CI\\} continues to evolve new techniques and paradigms to meet this noble objective. It has been shown that there are uncertainties in the reservoir characterization process as well as the optimal choice of CI/HIS models parameters. The main challenge is to develop models that are capable of handling multiple hypotheses to reduce the uncertainties thereby ensuring optimal solutions. The ensemble machine learning paradigm has been established to tackle this challenge. This new machine learning technology has not been adequately explored in handling some of the petroleum engineering challenges. This paper rigorously reviews the concept of ensemble learning paradigm, presents successful applications outside petroleum engineering and the geosciences, discusses a few successful attempts in petroleum engineering and the geosciences, and concludes with some recommendations for the much-needed future applications.", 
        "author": "Fatai Adesina Anifowose and Jane Labadin and Abdulazeez Abdulraheem", 
        "keyword": "Ensemble machine learning\", \"Reservoir characterization and modeling\", \"Petroleum reservoir keywords =roperties\", \"Computational intelligence", 
        "title": "Ensemble machine learning: An untapped modeling paradigm for petroleum reservoir characterization"
    }, 
    {
        "abstract": "Abstract The growing trend of obesity and overweight worldwide has reached epidemic proportions with one third of the global population now considered obese. This is having a significant medical impact on children and adults who are at risk of developing osteoarthritis, coronary heart disease and stroke, type 2 diabetes, cancers, respiratory problems, and non-alcoholic fatty liver disease. In an attempt to redress the issue, physical activity is being promoted as a fundamental component for maintaining a healthy lifestyle. Recommendations for physical activity levels are issued by most governments as part of their public health measures. However, current techniques and protocols, including those used in laboratory settings, have been criticised. The main concern is that it is not feasible to use multiple pieces of measurement hardware, such as \\{VO2\\} masks and heart rate monitors, to monitor children in free-living environments due to weight and encumbrance constraints. This has prompted research in the use of wearable sensing and machine learning technology to produce classifications for specific physical activity events. This paper builds on this approach and presents a supervised machine learning method that utilises data obtained from accelerometer sensors worn by children in free-living environments. Our results show that when using an artificial neural network algorithm it is possible to obtain an overall accuracy of 96% using four features from the initial dataset, with sensitivity and specificity values equal to 95% and 99% respectively. Expanding the dataset with interpolated cases, it was possible to improve on these results with 98.8% for accuracy, and 99% for sensitivity and specificity when four features were used.", 
        "author": "Paul Fergus and Abir J. Hussain and John Hearty and Stuart Fairclough and Lynne Boddy and Kelly Mackintosh and Gareth Stratton and Nicky Ridgers and Dhiya Al-Jumeily and Ahmed J. Aljaaf and Jenet Lunn", 
        "keyword": "Physical activity\", \"Overweight\", \"Obesity\", \"Machine learning\", \"Classification\", \"Neural keywords =etworks\", \"Sensors", 
        "title": "A machine learning approach to measure and monitor physical activity in children"
    }, 
    {
        "abstract": "Abstract End-to-end learning machines enable a direct mapping from the raw input data to the desired outputs, eliminating the need for hand-crafted features. Despite less engineering effort than the hand-crafted counterparts, these learning machines achieve extremely good results for many computer vision and medical image analysis tasks. Two dominant classes of end-to-end learning machines are massive-training artificial neural networks (MTANNs) and convolutional neural networks (CNNs). Although \\{MTANNs\\} have been actively used for a number of medical image analysis tasks over the past two decades, \\{CNNs\\} have recently gained popularity in the field of medical imaging. In this study, we have compared these two successful learning machines both experimentally and theoretically. For that purpose, we considered two well-studied topics in the field of medical image analysis: detection of lung nodules and distinction between benign and malignant lung nodules in computed tomography (CT). For a thorough analysis, we used 2 optimized \\{MTANN\\} architectures and 4 distinct \\{CNN\\} architectures that have different depths. Our experiments demonstrated that the performance of \\{MTANNs\\} was substantially higher than that of \\{CNN\\} when using only limited training data. With a larger training dataset, the performance gap became less evident even though the margin was still significant. Specifically, for nodule detection, \\{MTANNs\\} generated 2.7 false positives per patient at 100% sensitivity, which was significantly ( p &lt; 0.05 ) lower than the best performing \\{CNN\\} model with 22.7 false positives per patient at the same level of sensitivity. For nodule classification, \\{MTANNs\\} yielded an area under the receiver-operating-characteristic curve (AUC) of 0.8806 (95% CI: 0.8389\u20130.9223), which was significantly ( p &lt; 0.05 ) greater than the best performing \\{CNN\\} model with an \\{AUC\\} of 0.7755 (95% CI: 0.7120\u20130.8270). Thus, with limited training data, \\{MTANNs\\} would be a suitable end-to-end machine-learning model for detection and classification of focal lesions that do not require high-level semantic features.", 
        "author": "Nima Tajbakhsh and Kenji Suzuki", 
        "keyword": "Deep learning\", \"Patch-based machine learning\", \"Image-based machine learning\", \"Massive-training keywords =rtificial neural network\", \"Convolution neural network\", \"Focal lesions\", \"Classification\", keywords =Computer-aided diagnosis\", \"Lung nodules", 
        "title": "Comparing two classes of end-to-end machine-learning models in lung nodule detection and classification: \\{MTANNs\\} vs. \\{CNNs\\}"
    }, 
    {
        "abstract": "Abstract Interactive model analysis, the process of understanding, diagnosing, and refining a machine learning model with the help of interactive visualization, is very important for users to efficiently solve real-world artificial intelligence and data mining problems. Dramatic advances in big data analytics have led to a wide variety of interactive model analysis tasks. In this paper, we present a comprehensive analysis and interpretation of this rapidly developing area. Specifically, we classify the relevant work into three categories: understanding, diagnosis, and refinement. Each category is exemplified by recent influential work. Possible future research opportunities are also explored and discussed.", 
        "author": "Shixia Liu and Xiting Wang and Mengchen Liu and Jun Zhu", 
        "keyword": "Interactive model analysis\", \"Interactive visualization\", \"Machine learning\", \"Understanding\", keywords =Diagnosis\", \"Refinement", 
        "title": "Towards better analysis of machine learning models: A visual analytics perspective"
    }, 
    {
        "abstract": "AbstractBackground Preoperative identification of patients whose trachea will be difficult to intubate would decrease the rate of anesthesia related adverse respiratory events. Each test for airway examination may predict a separate aspect of airway. A computer-based approach is tested in this study to precisely evaluate difficult laryngoscopy. Aim of the work Aim of the work was to evaluate the efficacy and accuracy of a multiparameter computer-based system for prediction of difficult laryngoscopy. Study design 50 Adult patients presenting for non emergency surgery at Alexandria main university hospital from February 2015 to Feruary 2016 with unanticipated difficult laryngoscopy were assessed postoperatively according to selected nine airway parameters. The same was done for their matched 50 controls after full recovery from general anesthesia. All data were entered into an information\u2013based computer system where they were converted into numerical variables. All data have been processed and analyzed using the Microsoft visual studio 2008 (C#.net) and \\{WEKA\\} (Waikato Environment for Knowledge Analysis) machine learning algorithms. Classification was done using \\{J48\\} algorithm based on a decision tree and a \u201cWeighter\u201d filter was used to allow one to specify a numeric attribute to be used as an instance weight. Results Processed data have been designed as a software termed \u201cAlex Difficult Laryngoscopy Software\u201d (ADLS). Positive predictive value was 76%, Negative predictive value was 76%, Matthews correlation coefficient was 0.52 and area under the \\{ROC\\} curve was 0.79. Conclusion \u201cAlex Difficult Laryngoscopy Software\u201d (ADLS) is a machine learning program for prediction of difficult laryngoscopy. New cases can be entered to the training set thus improving the accuracy of the software.", 
        "author": "Moustafa Abdelaziz Moustafa and Shahira El-Metainy and Khaled Mahar and Essam Mahmoud Abdel-magied", 
        "keyword": "Difficult\", \"Laryngoscopy\", \"Machine learning", 
        "title": "Defining difficult laryngoscopy findings by using multiple parameters: A machine learning approach"
    }, 
    {
        "abstract": "Abstract The deconvolution of \\{DNA\\} mixtures remains one of the most critical challenges in the field of forensic \\{DNA\\} analysis. In addition, of all the data features required to perform such deconvolution, the number of contributors in the sample is widely considered the most important, and, if incorrectly chosen, the most likely to negatively influence the mixture interpretation of a \\{DNA\\} profile. Unfortunately, most current approaches to mixture deconvolution require the assumption that the number of contributors is known by the analyst, an assumption that can prove to be especially faulty when faced with increasingly complex mixtures of 3 or more contributors. In this study, we propose a probabilistic approach for estimating the number of contributors in a \\{DNA\\} mixture that leverages the strengths of machine learning. To assess this approach, we compare classification performances of six machine learning algorithms and evaluate the model from the top-performing algorithm against the current state of the art in the field of contributor number classification. Overall results show over 98% accuracy in identifying the number of contributors in a \\{DNA\\} mixture of up to 4 contributors. Comparative results showed 3-person mixtures had a classification accuracy improvement of over 6% compared to the current best-in-field methodology, and that 4-person mixtures had a classification accuracy improvement of over 20%. The Probabilistic Assessment for Contributor Estimation (PACE) also accomplishes classification of mixtures of up to 4 contributors in less than 1 s using a standard laptop or desktop computer. Considering the high classification accuracy rates, as well as the significant time commitment required by the current state of the art model versus seconds required by a machine learning-derived model, the approach described herein provides a promising means of estimating the number of contributors and, subsequently, will lead to improved \\{DNA\\} mixture interpretation.", 
        "author": "Michael A. Marciano and Jonathan D. Adelman", 
        "keyword": "\\{DNA\\} mixtures\", \"Number of contributors\", \"Probabilistic\", \"Machine learning", 
        "title": "PACE: Probabilistic Assessment for Contributor Estimation\u2014 A machine learning-based assessment of the number of contributors in \\{DNA\\} mixtures"
    }, 
    {
        "abstract": "Abstract Surface phenomena are increasingly becoming important in exploring nanoscale materials growth and characterization. Consequently, the need for atomistic based simulations is increasing. Recently, we proposed a machine learning approach, known as AGNI, that allows fast and quantum mechanical accurate atomic force predictions given an atom\u2019s neighborhood environment. Here, we make use of such force fields to study and characterize the nanoscale diffusion and growth processes occurring on an Al (1 1 1) surface. In particular we focus on the adatom ripening phenomena, confirming past experimental findings, wherein a low and high temperature growth regime were observed using entirely molecular dynamics simulations.", 
        "author": "V. Botu and J. Chapman and R. Ramprasad", 
        "keyword": "Molecular dynamics\", \"Machine learning\", \"Force field\", \"Island ripening\", \"Surface growth", 
        "title": "A study of adatom ripening on an Al (1 1 1) surface with machine learning force fields"
    }, 
    {
        "abstract": "Abstract The widespread adoption of Android devices and their capability to access significant private and confidential information have resulted in these devices being targeted by malware developers. Existing Android malware analysis techniques can be broadly categorized into static and dynamic analysis. In this paper, we present two machine learning aided approaches for static analysis of Android malware. The first approach is based on permissions and the other is based on source code analysis utilizing a bag-of-words representation model. Our permission-based model is computationally inexpensive, and is implemented as the feature of \\{OWASP\\} Seraphimdroid Android app that can be obtained from Google Play Store. Our evaluations of both approaches indicate an F-score of 95.1% and F-measure of 89% for the source code-based classification and permission-based classification models, respectively.", 
        "author": "Nikola Milosevic and Ali Dehghantanha and Kim-Kwang Raymond Choo", 
        "keyword": "Static malware analysis\", \"OWASP\", \"Seraphimdroid Android app\", \"OWASP Seraphimdroid Android app\", \"Machine learning", 
        "title": "Machine learning aided Android malware classification"
    }, 
    {
        "abstract": "Abstract Real-Time Strategy games are very popular test beds for Artificial Intelligence (AI) researchers because they provide complex and controlled environments on which to test different \\{AI\\} techniques. In this paper we play the role of an external observer that tries to predict who is going to win from the events occurring during the game. In order to predict the outcome of the game, we model the game states using influence maps. Influence maps are numerical matrices representing the influence of each player\u2019s army in the map, and they are useful for different types of spatial reasoning. We test different machine learning techniques on two different datasets of StarCraft games. The first dataset contains 4-player games in which the players are controlled by the internal game AI. The second dataset contains 2-player human games from specialized websites. We analyze the similarities and differences between both datasets and the performance of each algorithm. Finally, we perform a small experiment with expert players and conclude that our system reaches a level of precision similar to the human judges, although human judges base their predictions on a much more complex and abstract set of game features.", 
        "author": "Antonio A. S\u00e1nchez-Ruiz and Maximiliano Miranda", 
        "keyword": "Real-Time Strategy Games\", \"Influence maps\", \"Machine learning\", \"Prediction\", \"StarCraft", 
        "title": "A machine learning approach to predict the winner in StarCraft based on influence maps"
    }, 
    {
        "abstract": "Abstract The paper addresses the role of randomization in the training process of a learning machine, and analyses the affinities between two well-known schemes, namely, Extreme Learning Machines (ELMs) and the learning framework using similarity functions. These paradigms share a common approach to inductive learning, which combines an explicit remapping of data with a linear separator; however, they seem to exploit different strategies in the design of the mapping layer. The paper shows that, in fact, the theory of learning with similarity functions can stimulate a novel interpretation of the \\{ELM\\} paradigm, thus leading to a common framework. New insights into the \\{ELM\\} model are obtained, and the \\{ELM\\} strategy for the setup of the neurons\u2019 parameters can be significantly improved. Experimental results confirm that the novel method improves over conventional approaches, especially in the trade-off between classification accuracy and machine complexity (i.e., the dimensionality of the remapped space). This, in turn, supports the reliability of the unified framework envisioned in this paper.", 
        "author": "P. Gastaldo and F. Bisio and C. Gianoglio and E. Ragusa and R. Zunino", 
        "keyword": "Extreme learning machine\", \"Similarity functions\", \"Single-layer feedforward neural networks", 
        "title": "Learning with similarity functions: A novel design for the extreme learning machine"
    }, 
    {
        "abstract": "Abstract This study presents a novel method to detect an islanding condition in a distribution system with distributed generations (DGs). The proposed approach is based on Hilbert\u2013Huang transform (HHT) and Extreme learning machine (ELM). The system taken for testing of the proposed method consists of different types of \\{DGs\\} like hydro turbine generator with synchronous machine and wind turbine generator with asynchronous machine. The analysis starts with extracting the non-stationary three phase voltage signals at the target \\{DG\\} end and decomposed into mono component signals, called intrinsic mode function (IMF), by the empirical mode decomposition (EMD) method. In the next step, the amplitude, phase angle and frequency of the components are computed by applying the \\{HHT\\} to each IMF. Then, the different distinguish features are calculated such as, energy, standard deviation of phase and amplitude to track the islanding condition from different non-islanding conditions like single line to ground fault, line to line fault, three phase fault, voltage sag, voltage swell, sudden load change, capacitor switching and other \\{DG\\} tripping etc. To test the accuracy of proposed method, a modified \\{ELM\\} classifier is developed based on the feature index. It has been found that the proposed HHT\u2013ELM technique is highly successful to discriminate islanding events under a wide range of operating conditions from the other type of disturbances in the power distribution network. The proposed scheme is simulated by the MATLAB/SIMULINK environment.", 
        "author": "M. Mishra and M. Sahani and P.K. Rout", 
        "keyword": "Distributed generation\", \"Hilbert transform\", \"Empirical mode decomposition\", \"Extreme learning keywords =achine\", \"Intrinsic mode function", 
        "title": "An islanding detection algorithm for distributed generation based on Hilbert\u2013Huang transform and extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is a machine learning technique based on competitive single-hidden layer feedforward neural network (SLFN). However, traditional \\{ELM\\} and its variants are only based on random assignment of hidden weights using a uniform distribution, and then the calculation of the weights output using the least-squares method. This paper proposes a new architecture based on a non-linear layer in parallel by another non-linear layer and with entries of independent weights. We explore the use of a deterministic assignment of the hidden weight values using low-discrepancy sequences (LDSs). The simulations are performed with Halton and Sobol sequences. The results for regression and classification problems confirm the advantages of using the proposed method called PL-ELM algorithm with the deterministic assignment of hidden weights. Moreover, the PL-ELM algorithm with the deterministic generation using \\{LDSs\\} can be extended to other modified \\{ELM\\} algorithms.", 
        "author": "Pablo A. Henr\u00edquez and Gonzalo A. Ruz", 
        "keyword": "Extreme learning machine\", \"Low-discrepancy points\", \"Parallel layers\", \"Regression\", \"Classification", 
        "title": "Extreme learning machine with a deterministic assignment of hidden weights in two parallel layers"
    }, 
    {
        "abstract": "Abstract Over the last years, researchers have addressed the automatic classification of calling bird species. This is important for achieving more exhaustive environmental monitoring and for managing natural resources. Vocalisations help to identify new species, their natural history and macro-systematic relations, while computer systems allow the bird recognition process to be sped up and improved. In this study, an approach that uses state-of-the-art features designed for speech and speaker state recognition is presented. A method for voice activity detection was employed previous to feature extraction. Our analysis includes several classification techniques (multilayer perceptrons, support vector machines and random forest) and compares their performance using different configurations to define the best classification method. The experimental results were validated in a cross-validation scheme, using 25 species of the family Furnariidae that inhabit the Paranaense Littoral region of Argentina (South America). The results show that a high classification rate, close to 90%, is obtained for this family in this Furnariidae group using the proposed features and classifiers.", 
        "author": "Enrique M. Albornoz and Leandro D. Vignolo and Juan A. Sarquis and Evelina Leon", 
        "keyword": "Bird sound classification\", \"Computational bioacoustics\", \"Machine learning\", \"Speech-related keywords =eatures\", \"Furnariidae", 
        "title": "Automatic classification of Furnariidae species from the Paranaense Littoral region using speech-related features and machine learning"
    }, 
    {
        "abstract": "AbstractBackground and objective Collagen proportional area (CPA) extraction in liver biopsy images provides the degree of fibrosis expansion in liver tissue, which is the most characteristic histological alteration in hepatitis C virus (HCV). Assessment of the fibrotic tissue is currently based on semiquantitative staging scores such as Ishak and Metavir. Since its introduction as a fibrotic tissue assessment technique, \\{CPA\\} calculation based on image analysis techniques has proven to be more accurate than semiquantitative scores. However, \\{CPA\\} has yet to reach everyday clinical practice, since the lack of standardized and robust methods for computerized image analysis for \\{CPA\\} assessment have proven to be a major limitation. Methods The current work introduces a three-stage fully automated methodology for \\{CPA\\} extraction based on machine learning techniques. Specifically, clustering algorithms have been employed for background-tissue separation, as well as for fibrosis detection in liver tissue regions, in the first and the third stage of the methodology, respectively. Due to the existence of several types of tissue regions in the image (such as blood clots, muscle tissue, structural collagen, etc.), classification algorithms have been employed to identify liver tissue regions and exclude all other non-liver tissue regions from \\{CPA\\} computation. Results For the evaluation of the methodology, 79 liver biopsy images have been employed, obtaining 1.31% mean absolute \\{CPA\\} error, with 0.923 concordance correlation coefficient. Conclusions The proposed methodology is designed to (i) avoid manual threshold-based and region selection processes, widely used in similar approaches presented in the literature, and (ii) minimize \\{CPA\\} calculation time.", 
        "author": "Markos G. Tsipouras and Nikolaos Giannakeas and Alexandros T. Tzallas and Zoe E. Tsianou and Pinelopi Manousou and Andrew Hall and Ioannis Tsoulos and Epameinondas Tsianos", 
        "keyword": "Collagen proportional area\", \"Liver biopsy image analysis\", \"Machine learning techniques\", keywords =Clustering\", \"Classification", 
        "title": "A methodology for automated \\{CPA\\} extraction using liver biopsy image analysis and machine learning techniques"
    }, 
    {
        "abstract": "Abstract This paper proposes a multivariate chaotic Extreme Learning Machine (ELM) model for the prediction of the displacement of reservoir landslides. The displacement time series of the Baishuihe and Bazimen landslides in the Three Gorges Reservoir Area in China are used as examples. The results show that there are evidences of chaos in the displacement time series. The univariate chaotic \\{ELM\\} model and the multivariate chaotic model based on Particle Swarm Optimization and Support Vector Machine (PSO-SVM) model are also applied for the purpose of comparison. The comparisons show that the multivariate chaotic \\{ELM\\} model achieves higher prediction accuracy than the univariate chaotic \\{ELM\\} model and the multivariate chaotic PSO-SVM model.", 
        "author": "Faming Huang and Jinsong Huang and Shuihua Jiang and Chuangbing Zhou", 
        "keyword": "Reservoir landslides\", \"Displacement prediction\", \"Multivariate phase space reconstruction\", keywords =Extreme learning machine\", \"Double exponential smoothing", 
        "title": "Landslide displacement prediction based on multivariate chaotic model and extreme learning machine"
    }, 
    {
        "abstract": "Abstract In order to seek non-propagation method to train generalized single-hidden layer feed forward neural networks, extreme learning machine was proposed, which has been proven to be an effective and efficient model for both multi-class classification and regression. Different from most of existing studies which consider extreme learning machine as a classifier, we make improvements on it to let it become a feature extraction model in this paper. Specifically, a discriminative extreme learning machine with supervised sparsity preserving (SPELM) model is proposed. From the hidden layer to output layer, \\{SPELM\\} performs as a subspace learning method by considering the discriminative as well as sparsity information of data. The sparsity information of data is identified by solving a supervised sparse representation objective. Experiments are conducted on four widely used image benchmark data sets and the classification results demonstrate the effectiveness of the proposed \\{SPELM\\} model.", 
        "author": "Yong Peng and Bao-Liang Lu", 
        "keyword": "Extreme learning machine\", \"Sparse representation\", \"Group sparsity\", \"Sparsity preserving\", \"Image classification", 
        "title": "Discriminative extreme learning machine with supervised sparsity preserving for image classification"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) is a learning algorithm based on generalized single-hidden-layer feed-forward neural network. Since \\{ELM\\} has an excellent performance on regression and classification problems, it has been paid more and more attention recently. The determination of structure of \\{ELM\\} plays a vital role in \\{ELM\\} applications. Essentially, determination of the structure of \\{ELM\\} is equivalent to the determination of the hidden layer structure. Utilizing a smaller scale of the hidden layer structure can promote faster running speed. In this paper, we propose algorithm PCI-ELM (Pruned-Convex Incremental Extreme Learning Machine) based on CI-ELM (Convex Incremental Extreme Learning Machine). Furthermore, we also present an improved PCI-ELM algorithm, EPCI-ELM (Enhanced Pruned-Convex Incremental Extreme Learning Machine), which introduces a filtering strategy for PCI-ELM during the neurons adding process. In order to adjust the single-hidden-layer feed-forward neural network more flexibly and achieve the most compact form of the hidden layer structure, in this paper, we propose an algorithm which can dynamically determine hidden layer structure, DCI-ELM (Dynamic Convex Incremental Extreme Learning Machine). At the end of this paper, we verify the performance of PCI-ELM, EPCI-ELM and DCI-ELM. The results show that PCI-ELM, EPCI-ELM and DCI-ELM control hidden layer structure very well and construct the more compact single-hidden-layer feed-forward neural network.", 
        "author": "Yongjiao Sun and Yuangen Chen and Ye Yuan and Guoren Wang", 
        "keyword": "Extreme learning machine\", \"Dynamic adjustment\", \"Feed-forward neural network\", \"Convex optimal increment", 
        "title": "Dynamic adjustment of hidden layer structure for convex incremental extreme learning machine"
    }, 
    {
        "abstract": "Abstract Conformance improvement by polymer gels continues to gain momentum in the field of water management in mature oilfields. A key component for a successful treatment is the identification of the most appropriate gel technology for a targeted reservoir. Advanced approaches provide efficient screening and ranking tools; however, to the best of our knowledge, no such approaches have been developed for polymer gels so far. In this study, we utilized a machine-learning technique to develop an advanced selection methodology for the application of polymer gels in injection wells. Historical data of four in-situ gel systems including bulk gels, high temperature bulk gels, colloidal dispersion gels, and weak gels were used to train logistic regression models. Data sets of 19 property or parameter were tested for potential outliers, missing values were imputed, and some variables were categorized in order to treat data gaps. To identify the most discriminating variables, the univariate entropy R2, stepwise regression, and area under \\{ROC\\} curve (AUC) heuristic technique were employed. The candidate variables were then modified according to some considerations like the match of univariate logistic probability to conformance engineering considerations. To consider the regional tendencies in application of polymer gels, we developed three probabilistic models that include different number of treating technologies. Furthermore, to meet the new developments in the application of some gel systems, we constructed a variant model without the treatment timing indicator (water cut) for each main logistic classifier. Results show that logistic classification models and their variants correctly predict the proper gel technology in more than 85% of projects in the training and validation samples with a minimum \\{AUC\\} of 0.9375. We also used a prediction profiler to visually monitor performances of the classifiers and certain tendencies were identified by the investigation of the mispredicted projects. The novelty of the new methodology is its capability to predict the most applicable gel technology for undiagnosed injection wells.", 
        "author": "Munqith Aldhaheri and Mingzhen Wei and Baojun Bai and Mortadha Alsaba", 
        "keyword": "Enhanced oil recovery\", \"Polymer gels\", \"Conformance improvement treatments\", \"Machine learning keywords =echniques\", \"Advanced screening models", 
        "title": "Development of machine learning methodology for polymer gels screening for injection wells"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is extended from the generalized single hidden layer feedforward networks where the input weights of the hidden layer nodes can be assigned randomly. It has been widely used for its much faster learning speed and less manual works. Considering the field of multi-label text classification, in this paper, we propose an \\{ELM\\} based algorithm combined with L21-norm minimization of the output weights matrix called L21-norm Minimization ELM, which not only fully inherits the merits of \\{ELM\\} but also facilitates group sparsity and reduces complexity of the learning model. Extensive experiments on several benchmark data sets show that our proposed algorithm can obtain superior performances compared with other common multi-label classification algorithms.", 
        "author": "Mingchu Jiang and Zhisong Pan and Na Li", 
        "keyword": "text categorization\", \"Multi-label learning\", \"Extreme learning machine\", \"L21-norm minimization", 
        "title": "Multi-label Text Categorization Using L21-norm Minimization Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract Due to its much faster speed and better generalization performance, extreme learning machine (ELM) has attracted much attention as an effective learning approach. However, \\{ELM\\} rarely involves strategies for imbalanced data distributions which may exist in many fields. Existing approaches for imbalance learning only consider the effect of the number of the class samples ignoring the dispersion degree of the data, and may lead to the suboptimal learning results. In this paper, we will propose a novel ELM, class-specific cost regulation extreme learning machine (CCR-ELM), together with its kernel based extension, for binary and multiclass classification problems with imbalanced data distributions. CCR-ELM introduces class-specific regulation cost for misclassification of each class in the performance index as the tradeoff of structural risk and empirical risk. The performance of CCR-ELM is verified using a number of benchmark datasets and the real blast furnace status diagnosis problem. Experimental results show that CCR-ELM can achieve better performance for classification problems with imbalanced data distributions than the original \\{ELM\\} and existing \\{ELM\\} imbalance learning approach, and the kernel based CCR-ELM can improve the performance further.", 
        "author": "Wendong Xiao and Jie Zhang and Yanjiao Li and Sen Zhang and Weidong Yang", 
        "keyword": "Extreme learning machine\", \"Imbalanced data distribution\", \"Class-specific cost regulation extreme keywords =earning machine\", \"Blast furnace status diagnosis", 
        "title": "Class-specific cost regulation extreme learning machine for imbalanced classification"
    }, 
    {
        "abstract": "Abstract one of the most important tasks of Mars rover, a robot which explores the Mars surface, is the process of automatic segmentation of images taken by front-line Panoramic Camera (Pancam). This procedure is highly significant since the transformation cost of images from Mars to earth is extremely high. Also, image analysis may help Mars rover for its navigation and localization. In this paper, a new feature vector including wavelet and color features for Mars images is proposed. Then, this feature vector is presented for extreme learning machine (ELM) classifier which leads to a high accuracy pixel classifier. It is shown that this system statistically outperforms support vector machine (SVM) and k-nearest neighbours (KNNs) classifiers with respect to both accuracy and run time. After that, dimension reduction in feature space is done by two proposed feature section algorithms based on ant colony optimization (ACO) to decrease the time complexity which is very important in Mars on-board applications. In the first proposed feature selection algorithm, the same feature subset is selected among the feature vector for all pixel classes, while in the second proposed algorithm, the most significant features are selected for each pixel class, separately. Proposed pixel classifier with complete feature set outperforms prior methods by 6.44% and 5.84% with respect to average Fmeasure and accuracy, respectively. Finally, proposed feature selection methods decrease the feature vector size up to 76% and achieves Fmeasure and accuracy of 91.72% and 91.05%, respectively, which outperforms prior methods with 87.22% and 86.64%.", 
        "author": "Abdolreza Rashno and Behzad Nazari and Saeed Sadri and Mohamad Saraee", 
        "keyword": "Pixel classification\", \"Feature selection\", \"Ant colony optimization\", \"Extreme learning machine\", keywords =Wavelet features\", \"Color features", 
        "title": "Effective pixel classification of Mars images based on ant colony optimization feature selection and extreme learning machine"
    }, 
    {
        "abstract": "Abstract Monotonic classification problems mean that both feature values and class labels are ordered and monotonicity relationships exist between some features and the decision label. Extreme Learning Machine (ELM) is a single-hidden layer feedforward neural network with fast training rate and good generalization capability, but due to the existence of training error, \\{ELM\\} cannot be directly used to handle monotonic classification problems. This work proposes a generalization of \\{ELM\\} for processing the monotonic classification, named as Monotonic Classification Extreme Learning Machine (MCELM) in which the monotonicity constraints are imposed to the original \\{ELM\\} model. Mathematically, \\{MCELM\\} is a quadratic programming problem in which the monotonicity relationships are considered as constraints and the training error is the objective to be minimized. The mathematical model of \\{MCELM\\} not only can make the generated classifier monotonic but also can minimize the classification error. \\{MCELM\\} does not need to tune parameters iteratively, and therefore, keeps the advantage of extremely fast training which is the essential characteristic of ELM. \\{MCELM\\} does not require that the monotonic relationships existing between features and the output are consistent, which essentially relaxes the assumption of consistent monotonicity used in most existing approaches to handling monotonic classification problems. In comparison with exiting approaches to handling monotonic classification, \\{MCELM\\} can indeed generate a monotonicity-reserving classifier which experimentally shows a much better generalization capability on both artificial and real world datasets.", 
        "author": "Hong Zhu and Eric C.C. Tsang and Xi-Zhao Wang and Rana Aamir Raza Ashfaq", 
        "keyword": "Monotonic classification\", \"Extreme learning machine\", \"Constrained extreme learning machine\", keywords =Monotonicity\", \"Quadratic programming", 
        "title": "Monotonic classification extreme learning machine"
    }, 
    {
        "abstract": "Abstract Region-based active contour models are effective in segmenting images with poorly defined boundaries but often fail when applied to images containing intensity inhomogeneity. The traditional models utilize pixel intensity and are very sensitive to parameter tuning. On the other hand, machine learning algorithms are highly effective in handling inhomogeneities but often result in noise from misclassified pixels. In addition, there is no objective function. We propose a framework which integrates machine learning with a region-based active contour model. Classification probability scores from machine learning algorithm, which are regularized using a non-linear function, are used to replace the pixel intensity values during energy minimization. In our experiments, we integrate the k-nearest neighbours and the support vector machine with the Chan-Vese method and compare the results obtained with the traditional methods of Chan-Vese and Li et al. The proposed framework gives better accuracy and less sensitive to parameter tuning.", 
        "author": "Agus Pratondo and Chee-Kong Chui and Sim-Heng Ong", 
        "keyword": "Machine learning\", \"Active contour\", \"Medical images\", \"Segmentation", 
        "title": "Integrating machine learning with region-based active contour models in medical image segmentation"
    }, 
    {
        "abstract": "Abstract One-class classification (OCC) has been prime concern for researchers and effectively employed in various disciplines. But, traditional methods based one-class classifiers are very time consuming due to its iterative process and various parameters tuning. In this paper, we present six \\{OCC\\} methods and their thirteen variants based on extreme learning machine (ELM) and online sequential \\{ELM\\} (OSELM). Our proposed classifiers mainly lie in two categories: reconstruction based and boundary based, where three proposed classifiers belong to reconstruction based and three belong to boundary based. We are presenting both types of learning viz., online and offline learning for OCC. Out of six methods, four are offline and remaining two are online methods. Out of four offline methods, two methods perform random feature mapping and two methods perform kernel feature mapping. We present a comprehensive discussion on these methods and their comparison to each other. Kernel feature mapping based approaches have been tested with \\{RBF\\} kernel and online version of one-class classifiers is tested with both types of nodes viz., additive and RBF. It is well known fact that threshold decision is a crucial factor in case of OCC, so, three different threshold deciding criteria have been employed so far and analyze the effectiveness of one threshold deciding criteria over another. Further, these methods are tested on two artificial datasets to check their boundary construction capability and on eight benchmark datasets from different discipline to evaluate the performance of the classifiers. Our proposed classifiers exhibit better performance compared to ten traditional one-class classifiers and \\{ELM\\} based two one-class classifiers. Through proposed one-class classifiers, we intend to expand the functionality of the most used toolbox for \\{OCC\\} i.e. \\{DD\\} toolbox. All of our methods are totally compatible with all the present features of the toolbox.", 
        "author": "Chandan Gautam and Aruna Tiwari and Qian Leng", 
        "keyword": "One-class classification (OCC)\", \"Extreme learning machine (ELM)\", \"Online sequential \\{ELM\\} (keywords =SELM)\", \"One-class \\{ELM\\} (OCELM)\", \"Autoassociative \\{ELM\\} (AAELM)", 
        "title": "On the construction of extreme learning machine for online and offline one-class classification\u2014An expanded toolbox"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has been attracted increasing attentions for its fast learning speed and excellent generalization performance. However, the prediction result of a single \\{ELM\\} regression model is usually unstable due to the randomly generating of the input weights and hidden layer bias. To overcome this drawback, an ensemble form of ELM, termed as subagging ELM, was proposed and used for spectral quantitative analysis of complex samples. In the approach, a series of \\{ELM\\} sub-models was built by randomly selecting a certain number of samples from the original training set without replacement, and then the predictions of these sub-models were combined by a simple averaging way to give the final ensemble prediction. The performance of the method was tested with fuel oil and blood samples. Compared to a single \\{ELM\\} model, the results confirm that subagging \\{ELM\\} can achieve much better stability and higher accuracy than ELM.", 
        "author": "Caixia Zhang and Xihui Bian and Peng Liu and Xiaoyao Tan and Qingjie Fan and Wei Liu and Ligang Lin", 
        "keyword": "Extreme learning machine\", \"Ensemble modeling\", \"Multivariate calibration\", \"Complex samples\", \"Spectral analysis", 
        "title": "Subagging for the improvement of predictive stability of extreme learning machine for spectral quantitative analysis of complex samples"
    }, 
    {
        "abstract": "Abstract We integrate machine-learning algorithms into the descriptor-based design approach for rapid screening of transition-metal catalysts. By engineering numerical representation of surface metal atoms using easily accessible features such as the local electronegativity and the effective coordination number that are dependent on the surroundings of an adsorption site, together with the intrinsic properties of active metal atoms including the electronegativity, ionic potential, and electron affinity, the machine-learning model optimized with \u223c250 ab initio adsorption energies on bimetallic alloys can capture complex, non-linear adsorbate/substrate interactions with the root mean squared errors (RMSE) \u223c0.12 eV. We applied the model to search for {100}-terminated multimetallic copper (Cu) catalysts for electrochemical \\{CO2\\} reduction where the *CO adsorption energy represents an important efficiency metric. Compared with the traditional high-throughput computational and experimental trial-and-error approach, the machine-learning chemisorption models have great potential in accelerating the discovery of interesting catalytic materials. As the complexity of catalyst structures increases, new features will be needed to learn underlying correlations and avoid introducing significant errors on top of the average \\{DFT\\} prediction errors expected with standard semi-local generalized gradient approximation (GGA) functionals.", 
        "author": "Zheng Li and Xianfeng Ma and Hongliang Xin", 
        "keyword": "Machine learning\", \"Artificial neural network\", \"Feature engineering\", \"Density functional theory\", \"Electrochemical \\{CO2\\} reduction", 
        "title": "Feature engineering of machine-learning chemisorption models for catalyst design"
    }, 
    {
        "abstract": "Abstract Endocrine-disrupting chemicals (EDCs), which can threaten ecological safety and be harmful to human beings, have been cause for wide concern. There is a high demand for efficient methodologies for evaluating potential \\{EDCs\\} in the environment. Herein an evaluation platform was developed using novel and statistically robust ternary models via different machine learning models (i.e., linear discriminant analysis, classification and regression tree, and support vector machines). The platform is aimed at effectively classifying chemicals with agonistic, antagonistic, or no estrogen receptor (ER) activities. A total of 440 chemicals from the literature were selected to derive and optimize the three-class model. One hundred and nine new chemicals appeared on the 2014 \\{EPA\\} list for \\{EDC\\} screening, which were used to assess the predictive performances by comparing the E-screen results with the predicted results of the classification models. The best model was obtained using support vector machines (SVM) which recognized agonists and antagonists with accuracies of 76.6% and 75.0%, respectively, on the test set (with an overall predictive accuracy of 75.2%), and achieved a 10-fold cross-validation (CV) of 73.4%. The external predicted accuracy validated by the E-screen assay was 87.5%, which demonstrated the application value for a virtual alert for \\{EDCs\\} with \\{ER\\} agonistic or antagonistic activities. It was demonstrated that the ternary computational model could be used as a faster and less expensive method to identify \\{EDCs\\} that act through nuclear receptors, and to classify these chemicals into different mechanism groups.", 
        "author": "Quan Zhang and Lu Yan and Yan Wu and Li Ji and Yuanchen Chen and Meirong Zhao and Xiaowu Dong", 
        "keyword": "Ternary classification\", \"Machine learning methods\", \"Estrogen receptor activities", 
        "title": "A ternary classification using machine learning methods of distinct estrogen receptor activities within a large collection of environmental chemicals"
    }, 
    {
        "abstract": "Abstract The random assignment strategy for input weights has brought extreme learning machine (ELM) many advantages such as fast learning speed, minimal manual intervention and so on. However, the Monte Carlo (MC) based random sampling method that is typically used to generate input weights of \\{ELM\\} has poor capability of sample structure preserving (SSP), which will degenerate the learning and generalization performance. For this reason, the Quasi-Monte Carlo (QMC) method is revisited and it is shown that the distortion error of \\{QMC\\} projection can obtain faster convergence rate than that of \\{MC\\} for relatively low-dimensional problems. Further, a unified random orthogonal (RO) projection method is proposed, and it is shown that such \\{RO\\} method can always provide the optimal transformation in terms of minimizing the loss of all the distances between samples. Experimental results on real-world benchmark data sets verify the rationality of theoretical analysis and indicate that by enhancing the \\{SSP\\} capability of input weights, \\{QMC\\} and \\{RO\\} projection methods tend to bring \\{ELM\\} algorithms better generalization performance.", 
        "author": "Wenhui Wang and Xueyi Liu", 
        "keyword": "Monte Carlo sampling\", \"Quasi-Monte Carlo sequence\", \"Extreme learning machine\", \"Distance keywords =reserving\", \"Generalization performance\", \"Orthogonal projection", 
        "title": "The selection of input weights of extreme learning machine: A sample structure preserving point of view"
    }, 
    {
        "abstract": "Abstract Signals collected from the magnetic scans of metal-loss defects have distinct patterns. Experienced pipeline engineers are able to recognize those patterns in magnetic flux leakage (MFL) scans of pipelines, and use them to characterize defect types (e.g., corrosion, cracks, dents, etc.) and estimate their lengths and depths. This task, however, can be highly cumbersome to a human operator, because of the large amount of data to be analyzed. This paper proposes a solution to automate the analysis of \\{MFL\\} signals. The proposed solution uses pattern-adapted wavelets to detect and estimate the length of metal-loss defects. Once the parts of \\{MFL\\} signals corresponding to metal-loss defects are isolated, artificial neural networks are used to predict their depth. The proposed technique is computationally efficient, achieves high levels of accuracy, and works for a wide range of defect shapes.", 
        "author": "Mohamed Layouni and Mohamed Salah Hamdi and Sofi\u00e8ne Tahar", 
        "keyword": "Oil and gas pipelines\", \"Safety assessment\", \"Pattern-adapted wavelets\", \"Pattern recognition\", keywords =Neural networks\", \"Machine learning\", \"Defect location\", \"Defect sizing\", \"Magnetic flux leakage", 
        "title": "Detection and sizing of metal-loss defects in oil and gas pipelines using pattern-adapted wavelets and machine learning"
    }, 
    {
        "abstract": "Abstract A multi-graph is represented by a bag of graphs and modeled as a generalization of a multi-instance. Multi-graph classification is a supervised learning problem, which has a wide range of applications, such as scientific publication categorization, bio-pharmaceutical activity tests and online product recommendation. However, existing algorithms are limited to process small datasets due to high computation complexity of multi-graph classification. Specially, the precision is not high enough for a large dataset. In this paper, we propose a scalable and high-precision parallel algorithm to handle the multi-graph classification problem on massive datasets using MapReduce and extreme learning machine. Extensive experiments on real-world and synthetic graph datasets show that the proposed algorithm is effective and efficient.", 
        "author": "Jun Pang and Yu Gu and Jia Xu and Xiaowang Kong and Ge Yu", 
        "keyword": "Multi-graph\", \"Classification\", \"Extreme learning machine\", \"MapReduce", 
        "title": "Parallel multi-graph classification using extreme learning machine and MapReduce"
    }, 
    {
        "abstract": "Abstract The paper introduces a fuzzy training approach based on nonlinear regularization in an effort to avoid over training. The main idea is to restrict training so that the basic expert knowledge used to build the model is still visible. This is implemented by a new nonlinear regularization approach which can be applied to any kind of training data set. The approach is demonstrated using a large crop yield data set (&gt;4500 field records) for sugar beet collected in agricultural farms over a 14-year period (1976\u20131989) in East Germany. The software is implemented in SAMT2, free and open source software, using the Python programming language.", 
        "author": "Ralf Wieland and Wilfried Mirschel", 
        "keyword": "Fuzzy modeling\", \"Expert knowledge\", \"Machine learning\", \"Nonlinear regularization\", keywords =Optimization\", \"Yield modeling", 
        "title": "Combining expert knowledge with machine learning on the basis of fuzzy training"
    }, 
    {
        "abstract": "Abstract As one of supervised learning algorithms, extreme learning machine (ELM) has been proposed for training single-hidden-layer feedforward neural networks and shown great generalization performance. \\{ELM\\} randomly assigns the weights and biases between input and hidden layers and only learns the weights between hidden and output layers. Physiological research has shown that neurons at the same layer are laterally inhibited to each other such that outputs of each layer are sparse. However, it is difficult for \\{ELM\\} to accommodate the lateral inhibition by directly using random feature mapping. Therefore, this paper proposes a sparse coding \\{ELM\\} (ScELM) algorithm, which can map the input feature vector into a sparse representation. In this proposed ScELM algorithm, an unsupervised way is used for sparse coding and dictionary is randomly assigned rather than learned. Gradient projection based method is used for the sparse coding. The output weights are trained through the same supervised way as ELM. Experimental results on the benchmark datasets have shown that this proposed ScELM algorithm can outperform other state-of-the-art methods in terms of classification accuracy.", 
        "author": "Yuanlong Yu and Zhenzhen Sun", 
        "keyword": "Sparse coding\", \"Extreme learning machine\", \"Gradient projection", 
        "title": "Sparse coding extreme learning machine for classification"
    }, 
    {
        "abstract": "Abstract The problem of choosing error penalty parameter C for optimization extreme learning machine (OELM) is that it can take any positive value for different applications and it is therefore hard to choose correctly. In this paper, we reformulated \\{OELM\\} to take a new regularization parameter \u03bd (\u03bd-OELM) which is inspired by Sch\u00f6lkopf et al. The regularization in terms of \u03bd is bounded between 0 and 1, and is easier to interpret as compared to C. This paper shows that: (1) \u03bd-OELM and \u03bd-SVM have similar dual optimization formulation, but \u03bd-OELM has less optimization constraints due to its special capability of class separation and (2) experiment results on both artificial and real binary classification problems show that \u03bd-OELM tends to achieve better generalization performance than \u03bd-SVM, \\{OELM\\} and other popular machine learning approaches, and it is computationally efficient on high dimension data sets. Additionally, the optimal parameter \u03bd in \u03bd-OELM can be easily selected from few candidates.", 
        "author": "Ding Xiao-jian and Lan Yuan and Zhang Zhi-feng and Xu xin", 
        "keyword": "\u03bd-optimization extreme learning machine\", \"Classification\", \"Parameter selection", 
        "title": "Optimization extreme learning machine with \u03bd regularization"
    }, 
    {
        "abstract": "Abstract In many practical engineering applications, data tend to be collected in online sequential way with imbalanced class. Many traditional machine learning methods such as support vector machine and so on generally get biased classifier which leads to lower classification precision for minor class than major class. To get fast and efficient classification, a new online sequential extreme learning machine method with two-stage hybrid strategy is proposed. In offline stage, data-based strategy is employed, and the principal curve is introduced to model the distribution of minority class data. In online stage, algorithm-based strategy is employed, and a new leave-one-out cross-validation method using Sherman\u2013Morrison matrix inversion lemma is proposed to tackle online imbalance data, meanwhile, with add-delete mechanism for updating network weights. And the rationality of this strategy is proved theoretically. The proposed method is evaluated on four \\{UCI\\} datasets and the real-world Macau air pollutant forecasting dataset. The experimental results show that, the proposed method outperforms the classical ELM, OS-ELM and meta-cognitive OS-ELM in terms of generalization performance and numerical stability.", 
        "author": "Wentao Mao and Jinwan Wang and Ling He and Yangyang Tian", 
        "keyword": "Extreme learning machine\", \"Imbalance problem\", \"Principal curve\", \"Leave-one-out keywords =ross-validation\", \"Online sequential learning", 
        "title": "Online sequential prediction of imbalance data with two-stage hybrid strategy by extreme learning machine"
    }, 
    {
        "abstract": "Abstract The randomness, non-stationarity and irregularity of air quality index (AQI) series bring the difficulty of \\{AQI\\} forecasting. To enhance forecast accuracy, a novel hybrid forecasting model combining two-phase decomposition technique and extreme learning machine (ELM) optimized by differential evolution (DE) algorithm is developed for \\{AQI\\} forecasting in this paper. In phase I, the complementary ensemble empirical mode decomposition (CEEMD) is utilized to decompose the \\{AQI\\} series into a set of intrinsic mode functions (IMFs) with different frequencies; in phase II, in order to further handle the high frequency \\{IMFs\\} which will increase the forecast difficulty, variational mode decomposition (VMD) is employed to decompose the high frequency \\{IMFs\\} into a number of variational modes (VMs). Then, the \\{ELM\\} model optimized by \\{DE\\} algorithm is applied to forecast all the \\{IMFs\\} and VMs. Finally, the forecast value of each high frequency \\{IMF\\} is obtained through adding up the forecast results of all corresponding VMs, and the forecast series of \\{AQI\\} is obtained by aggregating the forecast results of all IMFs. To verify and validate the proposed model, two daily \\{AQI\\} series from July 1, 2014 to June 30, 2016 collected from Beijing and Shanghai located in China are taken as the test cases to conduct the empirical study. The experimental results show that the proposed hybrid model based on two-phase decomposition technique is remarkably superior to all other considered models for its higher forecast accuracy.", 
        "author": "Deyun Wang and Shuai Wei and Hongyuan Luo and Chenqiang Yue and Olivier Grunder", 
        "keyword": "Air quality index (AQI)\", \"Complementary ensemble empirical mode decomposition (CEEMD)\", keywords =Variational mode decomposition (VMD)\", \"Differential evolution (DE)\", \"Extreme learning machine (ELM)", 
        "title": "A novel hybrid model for air quality index forecasting based on two-phase decomposition technique and modified extreme learning machine"
    }, 
    {
        "abstract": "AbstractObjective The current study proposes an automated machine learning approach for the quantification of cells in cell death pathways according to \\{DNA\\} fragmentation. Methods A total of 17 images of kidney histological slide samples from male Wistar rats were used. The slides were photographed using an Axio Zeiss Vert.A1 microscope with a 40x objective lens coupled with an Axio Cam \\{MRC\\} Zeiss camera and Zen 2012 software. The images were analyzed using CellProfiler (version 2.1.1) and CellProfiler Analyst open-source software. Results Out of the 10,378 objects, 4970 (47,9%) were identified as \\{TUNEL\\} positive, and 5408 (52,1%) were identified as \\{TUNEL\\} negative. On average, the sensitivity and specificity values of the machine learning approach were 0.80 and 0.77, respectively. Conclusion Image cytometry provides a quantitative analytical alternative to the more traditional qualitative methods more commonly used in studies.", 
        "author": "Nayana Damiani Macedo and Aline Rodrigues Buzin and Isabela Bastos Binotti Abreu de Araujo and Breno Valentim Nogueira and Tadeu Uggere de Andrade and Denise Coutinho Endringer and Dominik Lenz", 
        "keyword": "Tissue cytometry\", \"Automated detection\", \"Image analysis\", \"Machine learning\", \"Tissue analysis", 
        "title": "Objective detection of apoptosis in rat renal tissue sections using light microscopy and free image analysis software with subsequent machine learning: Detection of apoptosis in renal tissue"
    }, 
    {
        "abstract": "Abstract Discriminative subgraph mining from a large collection of graph objects is a crucial problem for graph classification. Several main memory-based approaches have been proposed to mine discriminative subgraphs, but they always lack scalability and are not suitable for large-scale graph databases. Extreme Learning Machine (ELM) is a simple and efficient Single-hidden Layer Feedforward neural Networks (SLFNs) algorithm with extremely fast learning capacity. In this paper, we propose a discriminative subgraph mining approach based on ELM-Filter strategy within the scalable MapReduce computing model. We randomly partition the collection of graphs among worker nodes, and each worker applies a fast pattern evolutionary method to mine a set of discriminative subgraphs with the help of ELM-Filter strategy in its partition. And, the set of discriminative subgraphs must produce higher \\{ELM\\} training accuracy. The union of all such discriminative subgraphs is the mining result for the input large-scale graphs. Also, based on the proposed Support Graph Vector Model (SGVM) and \\{ELM\\} algorithm, we construct the graph classification model using the mined discriminative subgraphs. Extensive experimental results on both real and synthetic datasets show that our method obviously outperforms the other approaches in terms of both classification accuracy and runtime efficiency.", 
        "author": "Zhanghui Wang and Yuhai Zhao and Ye Yuan and Guoren Wang and Lei Chen", 
        "keyword": "Discriminative subgraph pattern\", \"MapReduce\", \"Extreme Learning Machine\", \"Graph classification", 
        "title": "Extreme Learning Machine for large-scale graph classification based on MapReduce"
    }, 
    {
        "abstract": "Abstract In this paper, we propose an efficient parameter tuning-free squared-loss mutual information (SMI) estimator in a form of a radial basis function (RBF) network. The input layer of the proposed network propagates a sample pair of two random variables to the hidden layer. The propagated samples are then transformed by a set of Gaussian \\{RBF\\} kernels with randomly determined kernel centers and widths similar to that in an extreme learning machine. The output layer adopts a linear weighting scheme which can be analytically estimated. Our empirical results show that the proposed estimator outperforms the competing state-of-the-art \\{SMI\\} estimators in terms of computational efficiency while showing the comparable estimation accuracy performance. Moreover, the proposed model achieves promising results in an application study of time-series change-points detection and driving stress.", 
        "author": "Beom-Seok Oh and Lei Sun and Chung Soo Ahn and Yong Kiang Yeo and Yan Yang and Nan Liu and Zhiping Lin", 
        "keyword": "Density ratio approximation\", \"Squared-loss mutual information estimation\", \"Extreme learning keywords =achine\", \"Change-points detection\", \"Electrocardiogram\", \"Driving stress", 
        "title": "Extreme learning machine based mutual information estimation with application to time-series change-points detection"
    }, 
    {
        "abstract": "Abstract Energy optimization and analysis of complex chemical processes play a significant role in the sustainable development procedure. In order to deal with the high-dimensional and noise data in complex chemical processes, we present an energy optimization and analysis method based on extreme learning machine integrating the index decomposition analysis. First, index decomposition analysis has been used to decompose the high-dimensional data to three energy performance indexes of the activity effect, the structure effect and the intensity. And then, those indexes and the production/conductivity of the chemical process are defined as inputs and outputs of the extreme learning machine respectively to build energy optimization and analysis model. Finally, the proposed method has been applied to optimizing and analyzing energy status of the ethylene system and the purified terephthalic acid solvent system in complex chemical processes. The experiment results show that the proposed method has the characteristics of fast learning, stable network outputs and high model accuracy in handling with the high-dimensional data. Moreover, it can optimize energy of chemical processes and guide the production operation. In our experiment, the production of ethylene plants can be increased by 5.33%, and the conductivity of purified terephthalic acid plants can be reduced by 0.046%.", 
        "author": "Zhiqiang Geng and Xiao Yang and Yongming Han and Qunxiong Zhu", 
        "keyword": "Index decomposition analysis\", \"Extreme learning machine\", \"Energy optimization and analysis\", keywords =Ethylene plants\", \"Purified terephthalic acid (PTA) solvent plants", 
        "title": "Energy optimization and analysis modeling based on extreme learning machine integrated index decomposition analysis: Application to complex chemical processes"
    }, 
    {
        "abstract": "Abstract This paper presents a novel approach for iris dissimilarity computation based on Computer Vision and Machine Learning. First, iris images are processed using well-known image processing algorithms. Pixels of the output image are considered the input of the previously trained classifiers, obtaining the a posteriori probability for each of the considered class values. The main novelty of the presented work remains in the computation of the dissimilarity value of two iris images as the distance between the aforementioned a posteriori probabilities. Experimental results, based on the testing dataset given by the \\{MICHE\\} \\{II\\} Challenge organizers, indicate the appropriateness of the deployed method for the iris recognition task. Best results show a precision score above 90% even for iris images of new individuals.", 
        "author": "Naiara Aginako and Goretti Echegaray and J.M. Mart\u00ednez-Otzeta and Igor Rodr\u00edguez and Elena Lazkano and Basilio Sierra", 
        "keyword": "Image Processing\", \"Machine Learning\", \"Biometrics\", \"Iris recognition\", \"Dissimilarity computation", 
        "title": "Iris matching by means of Machine Learning paradigms: A new approach to dissimilarity computation"
    }, 
    {
        "abstract": "In many areas of animal behaviour research, improvements in our ability to collect large and detailed data sets are outstripping our ability to analyse them. These diverse, complex and often high-dimensional data sets exhibit nonlinear dependencies and unknown interactions across multiple variables, and may fail to conform to the assumptions of many classical statistical methods. The field of machine learning provides methodologies that are ideally suited to the task of extracting knowledge from these data. In this review, we aim to introduce animal behaviourists unfamiliar with machine learning (ML) to the promise of these techniques for the analysis of complex behavioural data. We start by describing the rationale behind \\{ML\\} and review a number of animal behaviour studies where \\{ML\\} has been successfully deployed. The \\{ML\\} framework is then introduced by presenting several unsupervised and supervised learning methods. Following this overview, we illustrate key \\{ML\\} approaches by developing data analytical pipelines for three different case studies that exemplify the types of behavioural and ecological questions \\{ML\\} can address. The first uses a large number of spectral and morphological characteristics that describe the appearance of pheasant, Phasianus colchicus, eggs to assign them to putative clutches. The second takes a continuous data stream of feeder visits from \\{PIT\\} (passive integrated transponder)-tagged jackdaws, Corvus monedula, and extracts foraging events from it, which permits the construction of social networks. Our final example uses aerial images to train a classifier that detects the presence of wildebeest, Connochaetes taurinus, to count individuals in a population. With the advent of cheaper sensing and tracking technologies an unprecedented amount of data on animal behaviour is becoming available. We believe that \\{ML\\} will play a central role in translating these data into scientific knowledge and become a useful addition to the animal behaviourist's analytical toolkit.", 
        "author": "John Joseph Valletta and Colin Torney and Michael Kings and Alex Thornton and Joah Madden", 
        "keyword": "animal behaviour data\", \"classification\", \"clustering\", \"dimensionality reduction\", \"machine keywords =earning\", \"predictive modelling\", \"random forests\", \"social networks\", \"supervised learning\", \"unsupervised learning", 
        "title": "Applications of machine learning in animal behaviour studies"
    }, 
    {
        "abstract": "Abstract A variable-structure online sequential extreme learning machine (OS-ELM) is proposed by incorporating a hidden units pruning strategy. As conventional OS-ELM increases network dimensionality by adding newly-received samples as hidden units, the hidden layer dimension would expand and result in \u201cdimensionality curse\u201d finally. Furthermore, the vast number of hidden units cannot represent time-varying dynamics adaptively and would deteriorate the network generalization capability. Therefore, there is a practical need to adjust the dimension of OS-ELM not only by adding hidden units but also by simultaneously pruning superfluous units which contribute less to the output. To evaluate the individual contribution of existing hidden units, an index is proposed referred to as normalized error reduction ratio. The variable structure OS-ELM adds newly received samples in hidden units, and prunes those units contribute less to current dynamics from network simultaneously, thus the resulted network possesses parsimonious structure which can represent current system dynamics more efficiently. The online network structure adjustment approach can handle samples which are presented one-by-one or chuck-by-chuck. The variable-structure OS-ELM (VS-OSELM) can be implemented for online identification and prediction of time-varying systems. In this study, to evaluate the efficiency of VS-OSELM, it was implemented for real-time prediction of tidal level change which is a complex time-varying process. Online tidal prediction simulations is conducted based on the real measured tidal and meteorological data of Old Port Tampa in Florida, United States. Simulation results demonstrate that the proposed variable-structure OS-ELM is suitable for identification and prediction of complex time-varying systems with high prediction accuracy and fast computation speed.", 
        "author": "Jian-Chuan Yin", 
        "keyword": "Online sequential extreme learning machine\", \"Time-varying system\", \"Pruning strategy\", \"Tidal keywords =rediction\", \"Real-time prediction", 
        "title": "A variable-structure online sequential extreme learning machine for time-varying system prediction"
    }, 
    {
        "abstract": "Abstract This chapter aims to introduce machine learning\u2014a field of study that uses computational algorithms to turn empirical data into usable models. Cyber security machine learning based models need to be able to represent a real-world system, infer system properties, and learn and adapt based on knowledge and observations. The chapter starts with an introduction of the concepts and techniques of machine learning, outlining the categories of machine learning\u2014classification, clustering, regression, and anomaly detection. The chapter then explores the use of probabilistic models, such as Bayesian networks and hidden Markov models, as data driven classification/modeling strategies, with examples given.", 
        "author": "Thomas W. Edgar and David O. Manz", 
        "keyword": "Anomaly detection\", \"Bayesian networks\", \"cluster analysis\", \"hidden Markov model\", \"machine keywords =earning\", \"regression", 
        "title": "Chapter 6 - Machine Learning"
    }, 
    {
        "abstract": "Abstract The primary goal of this chapter is to provide a basic understanding of the machine learning methods for transportation-related applications. This chapter discusses how the machine learning methods can be utilized to improve performance of transportation data analytics tools. The chapter focuses on selected machine learning methods and importance of quality and quantity of available data. An example is provided along with the \\{MATLAB\\} code to present how the machine learning method can improve performance of data-driven transportation system by predicting a speed of the roadway section.", 
        "author": "Parth Bhavsar and Ilya Safro and Nidhal Bouaynaya and Robi Polikar and Dimah Dera", 
        "keyword": "Machine learning methods\", \"data fusion\", \"regression methods\", \"support vector machines\", keywords =decision tree\", \"neural networks", 
        "title": "Chapter 12 - Machine Learning in Transportation Data Analytics"
    }, 
    {
        "abstract": "Abstract The paper presents the application of Extreme Leaning Machines (ELMs) for inverse reactor kinetic applications. \\{ELMs\\} were proposed by Huang and co-workers (2004, 2006a,b, 2015), which showed their enhances capabilities in terms of training speed and generalization with respect to classical Artificial Neural Networks (ANNs). \\{ELMs\\} are here implemented for reactivity determination as an alternative to \\{ANNs\\} (e.g. Picca et al. (2008)) and Gaussian Processes (Picca and Furfaro, 2012). After a review of the main features of ELMs, their application to inverse kinetic problems is proposed. The \\{ELMs\\} performance is tested on a typical accelerator drive system configuration (Yalina reactor) and the inversion is carried out on an accurate kinetic model (multi-group transport).", 
        "author": "Paolo Picca and Roberto Furfaro", 
        "keyword": "Inverse neutron kinetics\", \"Accelerator-driven system\", \"Artificial Neural Network\", \"Extreme Learning Machines", 
        "title": "Application of Extreme Learning Machines to inverse neutron kinetics"
    }, 
    {
        "abstract": null, 
        "author": "Sunghoon Lim and Conrad S. Tucker and Soundar Kumara", 
        "keyword": "Latent infectious diseases\", \"Information retrieval\", \"Unsupervised machine learning\", \"Sentiment keywords =nalysis\", \"Social media", 
        "title": "An unsupervised machine learning model for discovering latent infectious diseases using social media data"
    }, 
    {
        "abstract": "Abstract Bike-sharing systems (BSS) are a means of smart transportation with the benefit of a positive impact on urban mobility. To improve the satisfaction of a user of a BSS, it is useful to inform her/him on the status of the stations at run time, and indeed most of the current systems provide the information in terms of number of bicycles parked in each docking stations by means of services available via web. However, when the departure station is empty, the user could also be happy to know how the situation will evolve and, in particular, if a bike is going to arrive (and vice versa when the arrival station is full). To fulfill this expectation, we envisage services able to make a prediction and infer if there is in use a bike that could be, with high probability, returned at the station where she/he is waiting. The goal of this paper is hence to analyze the feasibility of these services. To this end, we put forward the idea of using Machine Learning methodologies, proposing and comparing different solutions.", 
        "author": "Davide Bacciu and Antonio Carta and Stefania Gnesi and Laura Semini", 
        "keyword": "Machine learning techniques\", \"Prediction\", \"Bike-sharing systems", 
        "title": "An experience in using machine learning for short-term predictions in smart transportation systems"
    }, 
    {
        "abstract": "Abstract Manual field surveys for nature conservation management are expensive and time-consuming and could be supplemented and streamlined by using Remote Sensing (RS). \\{RS\\} is critical to meet requirements of existing laws such as the \\{EU\\} Habitats Directive (HabDir) and more importantly to meet future challenges. The full potential of \\{RS\\} has yet to be harnessed as different nomenclatures and procedures hinder interoperability, comparison and provenance. Therefore, automated tools are needed to use \\{RS\\} data to produce comparable, empirical data outputs that lend themselves to data discovery and provenance. These issues are addressed by a novel, semi-automatic ontology-based classification method that uses machine learning algorithms and Web Ontology Language (OWL) ontologies that yields traceable, interoperable and observation-based classification outputs. The method was tested on European Union Nature Information System (EUNIS) grasslands in Rheinland-Palatinate, Germany. The developed methodology is a first step in developing observation-based ontologies in the field of nature conservation. The tests show promising results for the determination of the grassland indicators wetness and alkalinity with an overall accuracy of 85% for alkalinity and 76% for wetness.", 
        "author": "Niklas Moran and Simon Nieland and Gregor Tintrup gen. Suntrup and Birgit Kleinschmit", 
        "keyword": "Remote sensing\", \"Ontology\", \"Biotope classification\", \"Machine learning\", \"Nature conservation\", keywords =OWL\", \"EUNIS\", \"GEOBIA\", \"Grasslands", 
        "title": "Combining machine learning and ontological data handling for multi-source classification of nature conservation areas"
    }, 
    {
        "abstract": "Abstract In the context of drug discovery, a key problem is the identification of candidate molecules that affect proteins associated with diseases. Inside Janssen Pharmaceutica, the Chemogenomics project aims to derive new candidates from existing experiments through a set of machine learning predictor programs, written in single-node C++. These programs take a long time to run and are inherently parallel, but do not use multiple nodes. We show how we reimplemented the pipeline using Apache Spark, which enabled us to lift the existing programs to a multi-node cluster without making changes to the predictors. We have benchmarked our Spark pipeline against the original, which shows almost linear speedup up to 8 nodes. In addition, our pipeline generates fewer intermediate files while allowing easier checkpointing and monitoring.", 
        "author": "Dries Harnie and Mathijs Saey and Alexander E. Vapirev and J\u00f6rg Kurt Wegner and Andrey Gedich and Marvin Steijaert and Hugo Ceulemans and Roel Wuyts and Wolfgang De Meuter", 
        "keyword": "Drug discovery\", \"Apache Spark\", \"Machine learning\", \"Target prediction", 
        "title": "Scaling machine learning for target prediction in drug discovery using Apache Spark"
    }, 
    {
        "abstract": "Abstract Although linear modal analysis has proved itself to be the method of choice for the analysis of linear dynamic structures, its extension to nonlinear structures has proved to be a problem. A number of competing viewpoints on nonlinear modal analysis have emerged, each of which preserves a subset of the properties of the original linear theory. From the geometrical point of view, one can argue that the invariant manifold approach of Shaw and Pierre is the most natural generalisation. However, the Shaw\u2013Pierre approach is rather demanding technically, depending as it does on the analytical construction of a mapping between spaces, which maps physical coordinates into invariant manifolds spanned by independent subsets of variables. The objective of the current paper is to demonstrate a data-based approach motivated by Shaw\u2013Pierre method which exploits the idea of statistical independence to optimise a parametric form of the mapping. The approach can also be regarded as a generalisation of the Principal Orthogonal Decomposition (POD). A machine learning approach to inversion of the modal transformation is presented, based on the use of Gaussian processes, and this is equivalent to a nonlinear form of modal superposition. However, it is shown that issues can arise if the forward transformation is a polynomial and can thus have a multi-valued inverse. The overall approach is demonstrated using a number of case studies based on both simulated and experimental data.", 
        "author": "K. Worden and P.L. Green", 
        "keyword": "Nonlinear modal analysis\", \"Machine learning\", \"Data-based analysis\", \"Self-Adaptive Differential Evolution", 
        "title": "A machine learning approach to nonlinear modal analysis"
    }, 
    {
        "abstract": "Abstract The extreme learning machine (ELM) is widely used in batch learning, sequential learning, and incremental learning because of its fast and efficient learning speed, fast convergence, good generalization ability, and ease of implementation. With the development of the traditional ELM, lots of improved \\{ELM\\} algorithms have been proposed; meanwhile the scope of implementing the \\{ELM\\} has been further expanded from supervised learning, to semisupervised learning and unsupervised learning. However, due to its memory-residency, and high space and time complexity, the traditional \\{ELM\\} is not able to train big data fast and efficiently. Optimization strategies have been employed for the traditional \\{ELM\\} to solve this problem. In this chapter, we will first review \\{ELM\\} theories and some important variants, and then describe parallel \\{ELM\\} algorithms based on MapReduce and Spark in detail. Lastly, we show some practical applications of the \\{ELM\\} for big data.", 
        "author": "Cen Chen and Kenli Li and Mingxing Duan and Keqin Li", 
        "keyword": "Big data\", \"Cloud computing\", \"Distributed computing\", \"Extreme learning machine\", \"MapReduce\", \"Spark", 
        "title": "Chapter 6 - Extreme Learning Machine and Its Applications in Big Data Processing"
    }, 
    {
        "abstract": "Abstract Characterization, correlation and provenance determination of tephra samples in sedimentary sections (tephrochronological studies) are powerful tools for establishing ages of depositional events, volcanic eruptions, and tephra dispersion. Despite the large literature and the advancements in this research field, the univocal attribution of tephra deposits to specific volcanic sources remains too often elusive. In this contribution, we test the application of a machine learning technique named Support Vector Machine to attempt shedding new light upon tephra deposits related to one of the most complex and debated volcanic regions on Earth: the Pliocene-Pleistocene magmatism in Italy. The machine learning algorithm was trained using one of the most comprehensive global petrological databases (GEOROC); 17 chemical elements including major (SiO2, TiO2, Al2O3, Fe2O3T, CaO, MgO, MnO, Na2O, K2O, P2O5) and selected trace (Sr, Ba, Rb, Zr, Nb, La, Ce) elements were chosen as input parameters. We first show the ability of support vector machines in discriminating among different Pliocene-Pleistocene volcanic provinces in Italy and then apply the same methodology to determine the volcanic source of tephra samples occurring in the Caio outcrop, an Early Pleistocene sedimentary section located in Central Italy. Our results show that: 1) support vector machines can successfully resolve high-dimensional tephrochronological problems overcoming the intrinsic limitation of two- and three-dimensional discrimination diagrams; 2) support vector machines can discriminate among different volcanic provinces in complex magmatic regions; 3) in the specific case study, support vector machines indicate that the most probable source for the investigated tephra samples is the so-called Roman Magmatic Province. These results have strong geochronological and geodynamical implications suggesting new age constraints (1.4 Ma instead of 0.8 Ma) for the starting of the volcanic activity in the Roman Magmatic Province.", 
        "author": "Maurizio Petrelli and Roberto Bizzarri and Daniele Morgavi and Angela Baldanza and Diego Perugini", 
        "keyword": "Machine learning\", \"Tephrochronology\", \"Melt inclusions\", \"Pliocene-Pleistocene Italian magmatism\", \"Continental deposits", 
        "title": "Combining machine learning techniques, microanalyses and large geochemical datasets for tephrochronological studies in complex volcanic areas: New age constraints for the Pleistocene magmatism of central Italy"
    }, 
    {
        "abstract": "Abstract The purpose of this research is to develop and apply the artificial neural network (ANN) with extreme learning machine (ELM) to forecast gross domestic product (GDP) growth rate. The economic growth forecasting was analyzed based on agriculture, manufacturing, industry and services value added in GDP. The results were compared with \\{ANN\\} with back propagation (BP) learning approach since \\{BP\\} could be considered as conventional learning methodology. The reliability of the computational models was accessed based on simulation results and using several statistical indicators. Based on results, it was shown that \\{ANN\\} with \\{ELM\\} learning methodology can be applied effectively in applications of \\{GDP\\} forecasting.", 
        "author": "Ljubi\u0161a Mila\u010di\u0107 and Sr\u0111an Jovi\u0107 and Tanja Vujovi\u0107 and Jovica Miljkovi\u0107", 
        "keyword": "GDP\", \"Forecasting\", \"Extreme learning machine\", \"Economic", 
        "title": "Application of artificial neural network with extreme learning machine for economic growth estimation"
    }, 
    {
        "abstract": "Abstract The proliferation of data along with the ability to quickly compute has in recent years led to a variety of techniques for estimating probabilities that depends less on assuming a particular model for the data and more on utilizing large amounts of data. Such techniques are often referred to as being \u201cmachine learning\u201d. This chapter will give an introduction to certain popular machine learning techniques.", 
        "author": "Sheldon M. Ross", 
        "keyword": "Machine Learning\", \"Naive Bayes\", \"Nearest Neighbor rules\", \"Distance based rules\", \"Bandit problems", 
        "title": "Chapter 16 - Machine Learning and Big Data"
    }, 
    {
        "abstract": "Abstract Diagnosis, clinical management and research of psychiatric disorders remain subjective \u2014 largely guided by historically developed categories which may not effectively capture underlying pathophysiological mechanisms of dysfunction. Here, we report a novel approach of identifying and validating distinct and biologically meaningful clinical phenotypes of bipolar disorders using both unsupervised and supervised machine learning techniques. First, neurocognitive data were analyzed using an unsupervised machine learning approach and two distinct clinical phenotypes identified namely; phenotype I and phenotype II. Second, diffusion weighted imaging scans were pre-processed using the tract-based spatial statistics (TBSS) method and \u2018skeletonized\u2019 white matter fractional anisotropy (FA) and mean diffusivity (MD) maps extracted. The \u2018skeletonized\u2019 white matter \\{FA\\} and \\{MD\\} maps were entered into the Elastic Net machine learning algorithm to distinguish individual subjects' phenotypic labels (e.g. phenotype I vs. phenotype II). This calculation was performed to ascertain whether the identified clinical phenotypes were biologically distinct. Original neurocognitive measurements distinguished individual subjects' phenotypic labels with 94% accuracy (sensitivity = 92%, specificity = 97%). \\{TBSS\\} derived \\{FA\\} and \\{MD\\} measurements predicted individual subjects' phenotypic labels with 76% and 65% accuracy respectively. In addition, individual subjects belonging to phenotypes I and \\{II\\} were distinguished from healthy controls with 57% and 92% accuracy respectively. Neurocognitive task variables identified as most relevant in distinguishing phenotypic labels included; Affective Go/No-Go (AGN), Cambridge Gambling Task (CGT) coupled with inferior fronto-occipital fasciculus and callosal white matter pathways. These results suggest that there may exist two biologically distinct clinical phenotypes in bipolar disorders which can be identified from healthy controls with high accuracy and at an individual subject level. We suggest a strong clinical utility of the proposed approach in defining and validating biologically meaningful and less heterogeneous clinical sub-phenotypes of major psychiatric disorders.", 
        "author": "Mon-Ju Wu and Benson Mwangi and Isabelle E. Bauer and Ives C. Passos and Marsal Sanches and Giovana B. Zunta-Soares and Thomas D. Meyer and Khader M. Hasan and Jair C. Soares", 
        "keyword": "Bipolar disorder\", \"Neuroimaging\", \"Neuropsychology\", \"Machine learning\", \"Heterogeneity\", keywords =Research Domain Criteria (RDoC)\", \"Big data", 
        "title": "Identification and individualized prediction of clinical phenotypes in bipolar disorders using neurocognitive data, neuroimaging scans and machine learning"
    }, 
    {
        "abstract": "Abstract Pixel-based optical proximity correction (PBOPC) is currently a key resolution enhancement technique to push the resolution limit of optical lithography. However, the increasing scale, density and complexity of modern integrated circuits pose new challenges to both of the \\{OPC\\} computational intensity and mask manufacturability. This paper aims at developing a practical \\{OPC\\} algorithm based on a machine learning technique to effectively reduce the \\{PBOPC\\} runtime and mask complexity. We first divide the target layout into small regions around corners and edge fragments. Using a nonparametric kernel regression technique, these small regions are then filled in by the weighted linear combination of a subset of training \\{OPC\\} examples selected from the pre-calculated libraries. To keep balance between the image fidelity and mask complexity, we use an edge-based \\{OPC\\} (EBOPC) library to synthesize the \\{OPC\\} patterns in non-critical areas, while use another \\{PBOPC\\} library for hotspots. In addition, a post-processing method is developed to refine the regressed \\{OPC\\} pattern so as to guarantee the final image fidelity and mask manufacturability. Experimental results show that, compared to a currently professional \\{PBOPC\\} software, the proposed algorithm can achieve approximately two-fold speedup and more manufacture-friendly \\{OPC\\} patterns.", 
        "author": "Xu Ma and Shangliang Jiang and Jie Wang and Bingliang Wu and Zhiyang Song and Yanqiu Li", 
        "keyword": "Optical lithography\", \"Optical proximity correction\", \"Machine learning\", \"Nonparametric kernel keywords =egression\", \"Manufacturability", 
        "title": "A fast and manufacture-friendly optical proximity correction based on machine learning"
    }, 
    {
        "abstract": "Abstract The two-terminal reliability problem in system reliability analysis is known to be computationally intractable for large infrastructure graphs. Monte Carlo techniques can estimate the probability of a disconnection between two points in a network by selecting a representative sample of network component failure realizations and determining the source-terminal connectivity of each realization. To reduce the runtime required for the Monte Carlo approximation, this article proposes an approximate framework in which the connectivity check of each sample is estimated using a machine-learning-based classifier. The framework is implemented using both a support vector machine (SVM) and a logistic regression based surrogate model. Numerical experiments are performed on the California gas distribution network using the epicenter and magnitude of the 1989 Loma Prieta earthquake as well as randomly-generated earthquakes. It is shown that the \\{SVM\\} and logistic regression surrogate models are able to predict network connectivity with accuracies of 99% for both methods, and are 1\u20132 orders of magnitude faster than using a Monte Carlo method with an exact connectivity check.", 
        "author": "R.E. Stern and J. Song and D.B. Work", 
        "keyword": "Lifeline networks\", \"System reliability analysis\", \"Monte Carlo simulations\", \"Support vector keywords =achine\", \"Logistic regression\", \"Surrogate models\", \"Seismic reliability analysis", 
        "title": "Accelerated Monte Carlo system reliability analysis through machine-learning-based surrogate models of network connectivity"
    }, 
    {
        "abstract": "Abstract Clinical narrative text includes information related to a patient\u2019s medical history such as chronological progression of medical problems and clinical treatments. A chronological view of a patient\u2019s history makes clinical audits easier and improves quality of care. In this paper, we propose a clinical Problem-Action relation extraction method, based on clinical semantic units and event causality patterns, to present a chronological view of a patient\u2019s problem and a doctor\u2019s action. Based on our observation that a clinical text describes a patient's medical problems and a doctor's treatments in chronological order, a clinical semantic unit is defined as a problem and/or an action relation. Since a clinical event is a basic unit of the problem and action relation, events are extracted from narrative texts, based on the external knowledge resources context features of the conditional random fields. A clinical semantic unit is extracted from each sentence based on time expressions and context structures of events. Then, a clinical semantic unit is classified into a problem and/or action relation based on the event causality patterns of the support vector machines. Experimental results on Korean discharge summaries show 78.8% performance in the F1-measure. This result shows that the proposed method is effectively classifies clinical Problem-Action relations.", 
        "author": "Jae-Wook Seol and Wangjin Yi and Jinwook Choi and Kyung Soon Lee", 
        "keyword": "Relation extraction\", \"Clinical semantic unit\", \"Problem-Action relation\", \"Causality pattern\", \"Machine learning", 
        "title": "Causality patterns and machine learning for the extraction of problem-action relations in discharge summaries"
    }, 
    {
        "abstract": "Abstract This chapter provides an application study of how \\{CUDA\\} and \\{GPU\\} computing helped to enable deep learning and revolutionize the field of machine learning. It starts by introducing the basic concepts of convolutional neural networks (CNN). It then shows the \\{CNN\\} code examples that have been accelerated with CUDA. The chapter concludes with an explanation of how the cuDNN library uses a matrix multiplication formulation of the convolution layer computation to improve the speed and utilization of the GPU.", 
        "author": "Boris Ginsburg", 
        "keyword": "Convolutional neural network\", \"machine learning\", \"deep learning\", \"matrix\u2013matrix multiplication\", keywords =forward propagation\", \"gradient backpropagation\", \"training\", \"cuDNN", 
        "title": "Chapter 16 - Application case study\u2014machine learning"
    }, 
    {
        "abstract": "Abstract The remarkable advances in biotechnology and health sciences have led to a significant production of data, such as high throughput genetic data and clinical information, generated from large Electronic Health Records (EHRs). To this end, application of machine learning and data mining methods in biosciences is presently, more than ever before, vital and indispensable in efforts to transform intelligently all available information into valuable knowledge. Diabetes mellitus (DM) is defined as a group of metabolic disorders exerting significant pressure on human health worldwide. Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data. The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research with respect to a) Prediction and Diagnosis, b) Diabetic Complications, c) Genetic Background and Environment, and e) Health Care and Management with the first category appearing to be the most popular. A wide range of machine learning algorithms were employed. In general, 85% of those used were characterized by supervised learning approaches and 15% by unsupervised ones, and more specifically, association rules. Support vector machines (SVM) arise as the most successful and widely used algorithm. Concerning the type of data, clinical datasets were mainly used. The title applications in the selected articles project the usefulness of extracting valuable knowledge leading to new hypotheses targeting deeper understanding and further investigation in DM.", 
        "author": "Ioannis Kavakiotis and Olga Tsave and Athanasios Salifoglou and Nicos Maglaveras and Ioannis Vlahavas and Ioanna Chouvarda", 
        "keyword": "Machine learning\", \"Data mining\", \"Diabetes mellitus\", \"Diabetic complications\", \"Disease keywords =rediction models\", \"Biomarker(s) identification", 
        "title": "Machine Learning and Data Mining Methods in Diabetes Research"
    }, 
    {
        "abstract": "Abstract Diagnosis of bearings generally plays an important role in fault diagnosis of mechanical system, and machine learning has been a promising tool in this field. In many real applications of bearings fault diagnosis, the data tend to be online imbalanced, which means, the number of fault data is much less than the normal data while they are all collected in online sequential way. Suffering from this problem, many traditional diagnosis methods will get low accuracy of fault data which acts as the minority class in the collected bearing data. To address this problem, an online sequential prediction method for imbalanced fault diagnosis problem is proposed based on extreme learning machine. This method introduces the principal curve and granulation division to simulate the flow distribution and overall distribution characteristics of fault data, respectively. Then a confident over-sampling and under-sampling process is proposed to establish the initial offline diagnosis model. In online stage, the obtained granules and principal curves are rebuilt on the bearing data which are arrived in sequence, and after the over-sampling and under-sampling process, the balanced sample set is formed to update the diagnosis model dynamically. A theoretical analysis is provided and proves that, even existing information loss, the proposed method has lower bound of the model reliability. Simulation experiments are conducted on \\{IMS\\} bearing data and \\{CWRU\\} bearing data. The comparative results demonstrate that the proposed method can improve the fault diagnosis accuracy with better effectiveness and robustness than other algorithms.", 
        "author": "Wentao Mao and Ling He and Yunju Yan and Jinwan Wang", 
        "keyword": "Fault diagnosis\", \"Extreme learning machine\", \"Imbalance problem\", \"Incipient fault\", \"Online sequential Learning", 
        "title": "Online sequential prediction of bearings imbalanced fault diagnosis by extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, we propose an approximation scheme of the Kernel Extreme Learning Machine algorithm for Single-hidden Layer Feedforward Neural network training that can be used for large scale classification problems. The Approximate Kernel Extreme Learning Machine is able to scale well in both computational cost and memory, while achieving good generalization performance. Regularized versions and extensions in order to exploit the total and within-class variance of the training data in the feature space are also proposed. Extensive experimental evaluation in medium-scale and large-scale classification problems denotes that the proposed approach is able to operate extremely fast in both the training and test phases and to provide satisfactory performance, outperforming relating classification schemes.", 
        "author": "Alexandros Iosifidis and Anastasios Tefas and Ioannis Pitas", 
        "keyword": "Extreme Learning Machine\", \"Large Scale Learning\", \"Facial Image Classification", 
        "title": "Approximate kernel extreme learning machine for large scale data classification"
    }, 
    {
        "abstract": "Abstract Injury narratives are now available real time and include useful information for injury surveillance and prevention. However, manual classification of the cause or events leading to injury found in large batches of narratives, such as workers compensation claims databases, can be prohibitive. In this study we compare the utility of four machine learning algorithms (Na\u00efve Bayes, Single word and Bi-gram models, Support Vector Machine and Logistic Regression) for classifying narratives into Bureau of Labor Statistics Occupational Injury and Illness event leading to injury classifications for a large workers compensation database. These algorithms are known to do well classifying narrative text and are fairly easy to implement with off-the-shelf software packages such as Python. We propose human-machine learning ensemble approaches which maximize the power and accuracy of the algorithms for machine-assigned codes and allow for strategic filtering of rare, emerging or ambiguous narratives for manual review. We compare human-machine approaches based on filtering on the prediction strength of the classifier vs. agreement between algorithms. Regularized Logistic Regression (LR) was the best performing algorithm alone. Using this algorithm and filtering out the bottom 30% of predictions for manual review resulted in high accuracy (overall sensitivity/positive predictive value of 0.89) of the final machine-human coded dataset. The best pairings of algorithms included Na\u00efve Bayes with Support Vector Machine whereby the triple ensemble \\{NBSW\\} = NBBI-GRAM = \\{SVM\\} had very high performance (0.93 overall sensitivity/positive predictive value and high accuracy (i.e. high sensitivity and positive predictive values)) across both large and small categories leaving 41% of the narratives for manual review. Integrating \\{LR\\} into this ensemble mix improved performance only slightly. For large administrative datasets we propose incorporation of methods based on human-machine pairings such as we have done here, utilizing readily-available off-the-shelf machine learning techniques and resulting in only a fraction of narratives that require manual review. Human-machine ensemble methods are likely to improve performance over total manual coding.", 
        "author": "Helen R. Marucci-Wellman and Helen L. Corns and Mark R. Lehto", 
        "keyword": "Injury\", \"Narrative text\", \"Injury surveillance\", \"Cause of injury\", \"Machine learning", 
        "title": "Classifying injury narratives of large administrative databases for surveillance\u2014A practical approach combining machine learning ensembles and human review"
    }, 
    {
        "abstract": "Abstract This study explored the potential of computer vision system (CVS) and hyperspectral imaging (HSI) technique covering spectral range of 900\u20131700\u2009nm for identifying freezer burnt salmon fillets after frozen storage. Local binary pattern (LBP) descriptor was applied for the \\{RGB\\} image classification. Reflectance spectra were obtained from various positions surface and pretreated using the standard normal variate (SNV) transformation. TreeBagger classifier was used to build classification models for recognition and authentication of the freezer burnt flesh. The results suggested that hyperspectral discrimination performed much better than \\{CVS\\} with the correct classification rate (CCR) of 0.905 in validation and \\{CCR\\} of 0.945 in cross-validation. The effective wavelengths were selected based upon the feature importance in the TreeBagger model and the corresponding optimized model yielded \\{CCR\\} of 0.914 in validation and 0.978 in cross-validation. Overall, the outcome suggested the capability of \\{HSI\\} for rapid categorization of damaged regions on frozen salmon.", 
        "author": "Jun-Li Xu and Da-Wen Sun", 
        "keyword": "Atlantic salmon\", \"Hyperspectral imaging\", \"Computer vision\", \"TreeBagger classifier\", \"Machine keywords =earning\u00e9s\", \"Saumon atlantique\", \"Imagerie hyperspectrale\", \"Vision par ordinateur\", \"Classificateur keywords =reeBagger\", \"Apprentissage automatique", 
        "title": "Identification of freezer burn on frozen salmon surface using hyperspectral imaging and computer vision combined with machine learning algorithm"
    }, 
    {
        "abstract": "AbstractObjective To discover diverse genotype-phenotype associations affiliated with Type 2 Diabetes Mellitus (T2DM) via genome-wide association study (GWAS) and phenome-wide association study (PheWAS), more cases (T2DM subjects) and controls (subjects without T2DM) are required to be identified (e.g., via Electronic Health Records (EHR)). However, existing expert based identification algorithms often suffer in a low recall rate and could miss a large number of valuable samples under conservative filtering standards. The goal of this work is to develop a semi-automated framework based on machine learning as a pilot study to liberalize filtering criteria to improve recall rate with a keeping of low false positive rate. Materials and methods We propose a data informed framework for identifying subjects with and without \\{T2DM\\} from \\{EHR\\} via feature engineering and machine learning. We evaluate and contrast the identification performance of widely-used machine learning models within our framework, including k-Nearest-Neighbors, Na\u00efve Bayes, Decision Tree, Random Forest, Support Vector Machine and Logistic Regression. Our framework was conducted on 300 patient samples (161 cases, 60 controls and 79 unconfirmed subjects), randomly selected from 23,281 diabetes related cohort retrieved from a regional distributed \\{EHR\\} repository ranging from 2012 to 2014. Results We apply top-performing machine learning algorithms on the engineered features. We benchmark and contrast the accuracy, precision, AUC, sensitivity and specificity of classification models against the state-of-the-art expert algorithm for identification of \\{T2DM\\} subjects. Our results indicate that the framework achieved high identification performances (\u223c0.98 in average AUC), which are much higher than the state-of-the-art algorithm (0.71 in AUC). Discussion Expert algorithm-based identification of \\{T2DM\\} subjects from \\{EHR\\} is often hampered by the high missing rates due to their conservative selection criteria. Our framework leverages machine learning and feature engineering to loosen such selection criteria to achieve a high identification rate of cases and controls. Conclusions Our proposed framework demonstrates a more accurate and efficient approach for identifying subjects with and without \\{T2DM\\} from EHR.", 
        "author": "Tao Zheng and Wei Xie and Liling Xu and Xiaoying He and Ya Zhang and Mingrong You and Gong Yang and You Chen", 
        "keyword": "Electronic health records\", \"Type 2 diabetes\", \"Data mining\", \"Feature engineering\", \"Machine learning", 
        "title": "A machine learning-based framework to identify type 2 diabetes through electronic health records"
    }, 
    {
        "abstract": "Abstract The dam displacement can effectively reflect the dam security status. To improve the accuracy of dam displacement prediction, a combination prediction model is presented based on extreme learning machine (ELM). In this combination model, the predictive values of the grey GM(1,1) and regression analysis, combined with the average values of predictive results of the two methods, are used as the input vectors of ELM, and the actual values of dam displacement are selected as the output vectors, and then the nonlinear combination prediction model is built. The simulation results show that the mean relative error, the average absolute error are 3.04% and 4.14% of the combination method based on extreme learning machine, respectively, which less than those of the GM(1,1), regression analysis and equal weight combination method, and is suitable for the prediction of dam displacement.", 
        "author": "Jiatang Cheng and Yan Xiong", 
        "keyword": "dam\", \"displacement\", \"combination prediction\", \"extreme learning machine", 
        "title": "Application of Extreme Learning Machine Combination Model for Dam Displacement Prediction"
    }, 
    {
        "abstract": "Abstract Heat affected zone (HAZ) of the laser cutting process may be developed based on combination of different factors. In this investigation the \\{HAZ\\} forecasting, based on the different laser cutting parameters, was analyzed. The main goal was to predict the \\{HAZ\\} according to three inputs. The purpose of this research was to develop and apply the Extreme Learning Machine (ELM) to predict the HAZ. The \\{ELM\\} results were compared with genetic programming (GP) and artificial neural network (ANN). The reliability of the computational models were accessed based on simulation results and by using several statistical indicators. Based upon simulation results, it was demonstrated that \\{ELM\\} can be utilized effectively in applications of \\{HAZ\\} forecasting.", 
        "author": "Obrad Anicic and Sr\u0111an Jovi\u0107 and Hivzo Skrijelj and Bogdan Nedi\u0107", 
        "keyword": "Extreme Learning Machine\", \"Forecasting\", \"HAZ\", \"Laser cutting", 
        "title": "Prediction of laser cutting heat affected zone by extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this study, the potential of different machine-learning algorithms in modeling global horizontal solar irradiation is examined. Multi-layer perceptron (MLP), adaptive neuro-fuzzy inference system (ANFIS) and Support Vector Machines (SVM) algorithms are adopted, beside a newly suggested algorithm: decision trees. All models are grouped in four categories: sunshine-, temperature-, meteorological parameters- and day number-based models. All models have been trained, optimized, validated and compared with each other and with old and newly suggested regression models, using high-resolution, highly accurate measured data recorded over Cairo, Egypt, throughout five years, as a case study. Models with best statistical measures of accuracy and best generalization abilities have been recommended after being tested using an independent dataset. The results show that \\{MLP\\} models excel in estimating global irradiation with root mean square error lower than that of best corresponding regression models by 4.75\u201331.69%, depending on the model category. Followed by \\{ANFIS\\} models (if carefully validated) and \\{SVM\\} models. In addition, the study assesses the ability of decision trees in modeling solar radiation. Despite of their simplicity, the merits of temperature- and day number-based models are demonstrated, with coefficients of determination greater than 85%, to be used in case of unavailability of sunshine records.", 
        "author": "Muhammed A. Hassan and A. Khalil and S. Kaseb and M.A. Kassem", 
        "keyword": "Global solar radiation\", \"Neural network\", \"ANFIS\", \"Decision trees\", \"Regression analysis\", \"Support Vector Machines", 
        "title": "Potential of four different machine-learning algorithms in modeling daily global solar radiation"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is an interesting algorithm for learning the hidden layer of single layer feed forward neural networks. However, one of the main shortcomings restricting further improvement of \\{ELM\\} is the complexity of singular value decomposition (SVD) for computing the Moore-Penrose generalized inverse of the hidden layer matrix. This paper presents a new algorithm named fast adaptive shrinkage/thresholding algorithm \\{ELM\\} (FASTA-ELM) which uses an extension of forward-backward splitting (FBS) to compute the smallest norm of the output weights in ELM. The proposed FASTA-ELM algorithm is evaluated on face gender recognition problem using 5 benchmarked datasets. The results indicate that FASTA-ELM provides efficient performance and outperforms the standard \\{ELM\\} and two other variants of \\{ELM\\} in terms of generalization ability and computational time. Furthermore, the recognition performance of FASTA-ELM is comparable to other state-of-the-art face gender recognition methods.", 
        "author": "Saif F. Mahmood and Mohammad Hamiruce Marhaban and Fakhrul Zaman Rokhani and Khairulmizam Samsudin and Olasimbo Ayodeji Arigbabu", 
        "keyword": "Fast adaptive shrinkage/thresholding\", \"Extreme learning machine\", \"Hidden node selection\", keywords =Feature representation\", \"Face gender recognition", 
        "title": "FASTA-ELM: A fast adaptive shrinkage/thresholding algorithm for extreme learning machine and its application to gender recognition"
    }, 
    {
        "abstract": "Abstract As the usability of Cloud-based solutions has increased for various types of users with different needs, from scientists that want to process big data sets collected from sensors or business analysts that want to take decisions based on the huge amount of gathered data to simple users that store or share documents via a Cloud platform, the generated data is increasing more and more. For example, the \\{ATLAS\\} and other detectors at \\{CERN\\} generate petabytes of data and Facebook stores data with a rate of around 600\u00a0 \\{TB\\} daily. In the current context, efficient scheduling for Big Data applications is a challenge and an appropriate scheduling technique is required for different types of incoming requests. In this paper we propose a scheduling algorithm for different types of computation requests: independent tasks, like bag of tasks (BoT) model or tasks with dependencies modeled as directed acyclic graphs (DAG), and they will be scheduled for execution in a Cloud datacenter. The tasks in the requests are scheduled on the available resources using the suitable scheduling algorithm for each request. We rely on a machine learning toolbox, named as MLBox, to find what algorithm should be used for a certain request. We implemented four heuristics for scheduling BoTs and four heuristics for \\{DAGs\\} scheduling and generated the training data for the machine learning algorithm by running multiple traditional scheduling algorithms and selecting the \u2018best\u2019 one for a given request. We evaluate the performance by comparing the scheduling of different tasks requests using some of the traditional algorithms and our machine learning based scheduling algorithm.", 
        "author": "Mihaela-Andreea VASILE and Florin POP and Mihaela-C\u0103t\u0103lina NI\u0162\u0102 and Valentin CRISTEA", 
        "keyword": "Asymptotic scheduling\", \"BoT scheduling\", \"DAG scheduling\", \"Scheduling heuristics\", \"Machine keywords =earning\", \"Datacenters", 
        "title": "MLBox: Machine learning box for asymptotic scheduling"
    }, 
    {
        "abstract": "Abstract Stroke risk stratification based on grayscale morphology of the ultrasound carotid wall has recently been shown to have a promise in classification of high risk versus low risk plaque or symptomatic versus asymptomatic plaques. In previous studies, this stratification has been mainly based on analysis of the far wall of the carotid artery. Due to the multifocal nature of atherosclerotic disease, the plaque growth is not restricted to the far wall alone. This paper presents a new approach for stroke risk assessment by integrating assessment of both the near and far walls of the carotid artery using grayscale morphology of the plaque. Further, this paper presents a scientific validation system for stroke risk assessment. Both these innovations have never been presented before. The methodology consists of an automated segmentation system of the near wall and far wall regions in grayscale carotid B-mode ultrasound scans. Sixteen grayscale texture features are computed, and fed into the machine learning system. The training system utilizes the lumen diameter to create ground truth labels for the stratification of stroke risk. The cross-validation procedure is adapted in order to obtain the machine learning testing classification accuracy through the use of three sets of partition protocols: (5, 10, and Jack Knife). The mean classification accuracy over all the sets of partition protocols for the automated system in the far and near walls is 95.08% and 93.47%, respectively. The corresponding accuracies for the manual system are 94.06% and 92.02%, respectively. The precision of merit of the automated machine learning system when compared against manual risk assessment system are 98.05% and 97.53% for the far and near walls, respectively. The \\{ROC\\} of the risk assessment system for the far and near walls is close to 1.0 demonstrating high accuracy.", 
        "author": "Tadashi Araki and Pankaj K. Jain and Harman S. Suri and Narendra D. Londhe and Nobutaka Ikeda and Ayman El-Baz and Vimal K. Shrivastava and Luca Saba and Andrew Nicolaides and Shoaib Shafique and John R. Laird and Ajay Gupta and Jasjit S. Suri", 
        "keyword": "Stroke\", \"Carotid wall\", \"Ultrasound\", \"Near\", \"Far\", \"Segmentation\", \"Machine learning\", keywords =Precision of merit\", \"ROC", 
        "title": "Stroke Risk Stratification and its Validation using Ultrasonic Echolucent Carotid Wall Plaque Morphology: A Machine Learning Paradigm"
    }, 
    {
        "abstract": "Abstract Social networks represent an emerging challenging sector where the natural language expressions of people can be easily reported through short but meaningful text messages. Key information that can be grasped from social environments relates to the polarity of text messages (ie, positive, negative, or neutral). In this chapter we present a literature review regarding polarity classification in social networks, by distinguishing between supervised, unsupervised, and semisupervised machine learning models. In particular, the most recent advancements of the state of the art are presented, focusing on the real nature of the messages that are actually provided in an informal and networked environment.", 
        "author": "E. Fersini", 
        "keyword": "Sentiment analysis\", \"Microblogs\", \"Machine learning\", \"Social network\", \"Language\", \"Relationships", 
        "title": "Chapter 6 - Sentiment Analysis in Social Networks: A Machine Learning Perspective"
    }, 
    {
        "abstract": "Abstract Imaging flow cytometry (IFC) enables the high throughput collection of morphological and spatial information from hundreds of thousands of single cells. This high content, information rich image data can in theory resolve important biological differences among complex, often heterogeneous biological samples. However, data analysis is often performed in a highly manual and subjective manner using very limited image analysis techniques in combination with conventional flow cytometry gating strategies. This approach is not scalable to the hundreds of available image-based features per cell and thus makes use of only a fraction of the spatial and morphometric information. As a result, the quality, reproducibility and rigour of results are limited by the skill, experience and ingenuity of the data analyst. Here, we describe a pipeline using open-source software that leverages the rich information in digital imagery using machine learning algorithms. Compensated and corrected raw image files (.rif) data files from an imaging flow cytometer (the proprietary .cif file format) are imported into the open-source software CellProfiler, where an image processing pipeline identifies cells and subcellular compartments allowing hundreds of morphological features to be measured. This high-dimensional data can then be analysed using cutting-edge machine learning and clustering approaches using \u201cuser-friendly\u201d platforms such as CellProfiler Analyst. Researchers can train an automated cell classifier to recognize different cell types, cell cycle phases, drug treatment/control conditions, etc., using supervised machine learning. This workflow should enable the scientific community to leverage the full analytical power of IFC-derived data sets. It will help to reveal otherwise unappreciated populations of cells based on features that may be hidden to the human eye that include subtle measured differences in label free detection channels such as bright-field and dark-field imagery.", 
        "author": "Holger Hennig and Paul Rees and Thomas Blasi and Lee Kamentsky and Jane Hung and David Dao and Anne E. Carpenter and Andrew Filby", 
        "keyword": "Imaging flow cytometry\", \"Machine learning\", \"Open-source software\", \"High-throughput\", \"Feature keywords =election\", \"Profiling", 
        "title": "An open-source solution for advanced imaging flow cytometry data analysis using machine learning"
    }, 
    {
        "abstract": "Abstract Mangrove forests are well-known for their provision of ecosystem services and capacity to reduce carbon dioxide concentrations in the atmosphere. Mapping and quantifying mangrove biomass is useful for the effective management of these forests and maximizing their ecosystem service performance. The objectives of this research were to model, map, and analyse the biomass change between 2000 and 2011 of mangrove forests in the Cangio region in Vietnam. \\{SPOT\\} 4 and 5 images were used in conjunction with object-based image analysis and machine learning algorithms. The study area included natural and planted mangroves of diverse species. After image preparation, three different mangrove associations were identified using two levels of image segmentation followed by a Support Vector Machine classifier and a range of spectral, texture and \\{GIS\\} information for classification. The overall classification accuracy for the 2000 and 2011 images were 77.1% and 82.9%, respectively. Random Forest regression algorithms were then used for modelling and mapping biomass. The model that integrated spectral, vegetation association type, texture, and vegetation indices obtained the highest accuracy (R2adj\u00a0=\u00a00.73). Among the different variables, vegetation association type was the most important variable identified by the Random Forest model. Based on the biomass maps generated from the Random Forest, total biomass in the Cangio mangrove forest increased by 820,136 tons over this period, although this change varied between the three different mangrove associations.", 
        "author": "Lien T.H. Pham and Lars Brabyn", 
        "keyword": "Mangrove\", \"Biomass change\", \"Object-based\", \"Random forest\", \"Support vector machine", 
        "title": "Monitoring mangrove biomass change in Vietnam using \\{SPOT\\} images and an object-based approach combined with machine learning algorithms"
    }, 
    {
        "abstract": "Abstract Implicit modeling has experienced a rise in popularity over the last decade due to its advantages in terms of speed and reproducibility in comparison with manual digitization of geological structures. The potential-field method consists in interpolating a scalar function that indicates to which side of a geological boundary a given point belongs to, based on cokriging of point data and structural orientations. This work proposes a vector potential-field solution from a machine learning perspective, recasting the problem as multi-class classification, which alleviates some of the original method's assumptions. The potentials related to each geological class are interpreted in a compositional data framework. Variogram modeling is avoided through the use of maximum likelihood to train the model, and an uncertainty measure is introduced. The methodology was applied to the modeling of a sample dataset provided with the software Move\u2122. The calculations were implemented in the R language and 3D visualizations were prepared with the rgl package.", 
        "author": "\u00cdtalo Gomes Gon\u00e7alves and Sissa Kumaira and Felipe Guadagnin", 
        "keyword": "Implicit modeling\", \"Machine learning\", \"Potential field\", \"Kriging\", \"3D geological modeling\", \"Compositional data analysis", 
        "title": "A machine learning approach to the potential-field method for implicit modeling of geological structures"
    }, 
    {
        "abstract": "Abstract This paper presents meaning-based machine learning, the use of semantically meaningful input data into machine learning systems in order to produce output that is meaningful to a human user where the semantic input comes from the Ontological Semantics Technology theory of natural language processing. How to bridge from knowledge-based natural language processing architectures to traditional machine learning systems is described to include high-level descriptions of the steps taken. These meaning-based machine learning systems are then applied to problems in information assurance and security that remain unsolved and feature large amounts of natural language text.", 
        "author": "Courtney Falk and Lauren Stuart", 
        "keyword": "Natural language processing\", \"Machine learning\", \"Information security", 
        "title": "Meaning-based machine learning for information assurance"
    }, 
    {
        "abstract": "Abstract The range and quality of freely available geo-referenced datasets is increasing. We evaluate the usefulness of free datasets for deforestation prediction by comparing generalised linear models and generalised linear mixed models (GLMMs) with a variety of machine learning models (Bayesian networks, artificial neural networks and Gaussian processes) across two study regions. Freely available datasets were able to generate plausible risk maps of deforestation using all techniques for study zones in both Mexico and Madagascar. Artificial neural networks outperformed \\{GLMMs\\} in the Madagascan (average \\{AUC\\} 0.83 vs 0.80), but not the Mexican study zone (average \\{AUC\\} 0.81 vs 0.89). In Mexico and Madagascar, Gaussian processes (average \\{AUC\\} 0.89, 0.85) and structured Bayesian networks (average \\{AUC\\} 0.88, 0.82) performed at least as well as \\{GLMMs\\} (average \\{AUC\\} 0.89, 0.80). Bayesian networks produced more stable results across different sampling methods. Gaussian processes performed well (average \\{AUC\\} 0.85) with fewer predictor variables.", 
        "author": "Helen Mayfield and Carl Smith and Marcus Gallagher and Marc Hockings", 
        "keyword": "Artificial neural network\", \"Bayesian network\", \"Deforestation\", \"Freely available data\", \"Gaussian keywords =rocess\", \"Logistic regression", 
        "title": "Use of freely available datasets and machine learning methods in predicting deforestation"
    }, 
    {
        "abstract": "Abstract Landslides are one of the most important natural hazards, causing serious financial damages and loss of life in many regions, including Iran. Landslide spatial modeling (LSM) in the current research consists of four phases including: (1) determining the relationship between each conditioning factor and landslide occurrences, using the evidential belief function (EBF) model; (2) utilizing \\{LSM\\} using three geographic information systems (GIS)-based machine-learning models, including the support vector machine (SVM), random forest (RF), and Na\u00efve Bayes (NB); (3) evaluating considered models and selecting the best model using receiver operating characteristics and calculation of the area under the curve (AUC); and (4) feature selection and the rank of importance of conditioning factors using the learning vector quantization (LVQ) algorithm. In order to achieve this aim, first, a landslide inventory map with 146 disaster locations was prepared using national reports and field monitoring, and landslide locations were divided into a training (70% = 102) and validating (30% = 44) data set. Then, 12 landslide conditioning factors, such as aspect, altitude, drainage density, distance from faults, lithology, slope, land use, plan curvature, profile curvature, distance from rivers, distance from roads, and the topographic wetness index, were selected as input layers for the \\{LSM\\} in the Chahardangeh Watershed. In the next step, the \\{EBF\\} model was used to consider the relationship between landslide locations and the aforementioned conditioning factors. Subsequently, three GIS-based machine learning algorithms were applied for landslide susceptibility mapping, and their results were validated using \\{AUC\\} values. Finally, the \\{LVQ\\} algorithm was applied for feature selection and importance determination of different conditioning factors. The results showed that the \\{RF\\} model had the highest \\{AUC\\} value (83.3%), followed by the SVM, and the \\{NB\\} with \\{AUC\\} values of 75.7% and 72.5%, respectively. Also, the results of the \\{LVQ\\} model revealed that altitude, the distance from the road, lithology, and land use have the most effects on landslide occurrence, respectively. So, the landslide susceptibility maps can be used for land use planning, and the management of landslide hazards in this study area.", 
        "author": "Alireza Motevalli and Hamid Reza Pourghasemi and Mohsen Zabihi", 
        "keyword": "Evidential belief function\", \"GIS\", \"Iran\", \"Landslide spatial modeling\", \"Learning vector keywords =uantization\", \"Na\u00efve Bayes\", \"Random forest\", \"Support vector machine", 
        "title": "Assessment of GIS-Based Machine Learning Algorithms for Spatial Modeling of Landslide Susceptibility: Case Study in Iran"
    }, 
    {
        "abstract": "Abstract Intrusion detection has become essential to network security because of the increasing connectivity between computers. Several intrusion detection systems have been developed to protect networks using different statistical methods and machine learning techniques. This study aims to design a model that deals with real intrusion detection problems in data analysis and classify network data into normal and abnormal behaviors. This study proposes a multi-level hybrid intrusion detection model that uses support vector machine and extreme learning machine to improve the efficiency of detecting known and unknown attacks. A modified K-means algorithm is also proposed to build a high-quality training dataset that contributes significantly to improving the performance of classifiers. The modified K-means is used to build new small training datasets representing the entire original training dataset, significantly reduce the training time of classifiers, and improve the performance of intrusion detection system. The popular \\{KDD\\} Cup 1999 dataset is used to evaluate the proposed model. Compared with other methods based on the same dataset, the proposed model shows high efficiency in attack detection, and its accuracy (95.75%) is the best performance thus far.", 
        "author": "Wathiq Laftah Al-Yaseen and Zulaiha Ali Othman and Mohd Zakree Ahmad Nazri", 
        "keyword": "Intrusion detection system\", \"Support vector machine\", \"Extreme learning machine\", \"K-means\", keywords =Multi-level\", \"KDD Cup 1999", 
        "title": "Multi-level hybrid support vector machine and extreme learning machine based on modified K-means for intrusion detection system"
    }, 
    {
        "abstract": "AbstractBackground Key lifestyle-environ risk factors are operative for depression, but it is unclear how risk factors cluster. Machine-learning (ML) algorithms exist that learn, extract, identify and map underlying patterns to identify groupings of depressed individuals without constraints. The aim of this research was to use a large epidemiological study to identify and characterise depression clusters through \u201cGraphing lifestyle-environs using machine-learning methods\u201d (GLUMM). Methods Two \\{ML\\} algorithms were implemented: unsupervised Self-organised mapping (SOM) to create \\{GLUMM\\} clusters and a supervised boosted regression algorithm to describe clusters. Ninety-six \u201clifestyle-environ\u201d variables were used from the National health and nutrition examination study (2009\u20132010). Multivariate logistic regression validated clusters and controlled for possible sociodemographic confounders. Results The \\{SOM\\} identified two \\{GLUMM\\} cluster solutions. These solutions contained one dominant depressed cluster (GLUMM5-1, GLUMM7-1). Equal proportions of members in each cluster rated as highly depressed (17%). Alcohol consumption and demographics validated clusters. Boosted regression identified GLUMM5-1 as more informative than GLUMM7-1. Members were more likely to: have problems sleeping; unhealthy eating; \u2264 2\u00a0years in their home; an old home; perceive themselves underweight; exposed to work fumes; experienced sex at \u2264 14\u00a0years; not perform moderate recreational activities. A positive relationship between GLUMM5-1 (OR: 7.50, P &lt; 0.001) and GLUMM7-1 (OR: 7.88, P &lt; 0.001) with depression was found, with significant interactions with those married/living with partner (P = 0.001). Conclusion Using \\{ML\\} based \\{GLUMM\\} to form ordered depressive clusters from multitudinous lifestyle-environ variables enabled a deeper exploration of the heterogeneous data to uncover better understandings into relationships between the complex mental health factors.", 
        "author": "J.F. Dipnall and J.A. Pasco and M. Berk and L.J. Williams and S. Dodd and F.N. Jacka and D. Meyer", 
        "keyword": "Depression\", \"Psychiatry\", \"Machine learning\", \"Boosted regression\", \"Cluster\", \"Lifestyle", 
        "title": "Why so GLUMM? Detecting depression clusters through graphing lifestyle-environs using machine-learning methods (GLUMM)"
    }, 
    {
        "abstract": "Abstract This work explores the use of a pen-and-tablet device to study differences in hand movement and muscle coordination between healthy subjects and Parkinson\u2019s disease patients. We let volunteers draw simple horizontal lines and recorded the trajectory of the pen\u2019s tip on the pad\u2019s surface. The signals thus obtained were then processed to compute various features which correspond to the variability of the pen tip\u2019s velocity, the deviation from the horizontal plane, and the trajectory\u2019s entropy. Our goal was to establish simple and objective metrics which can be used to differentiate between normal and pathological movement. In a small-scale clinical trial, 44 age-matched subjects were divided in two groups, namely 20 healthy subjects (H), and 24 Parkinson\u2019s disease (PD) patients. We applied a comprehensive machine learning approach to build a model that could classify unknown subjects based on their line-drawing performance. We were able to achieve an average prediction accuracy of 91% (88% sensitivity [\u03a4P], 95% specificity [\u03a4N]). Our results show that the proposed method is a good candidate for differentiating between healthy and Parkinson\u2019s disease individuals, and shows promise in the context of telemedicine applications and tracking of the disease\u2019s symptoms via inexpensive, widely available hardware.", 
        "author": "C. Kotsavasiloglou and N. Kostikis and D. Hristu-Varsakelis and M. Arnaoutoglou", 
        "keyword": "Movement disorders\", \"Parkinson\u2019s disease\", \"Handwriting\", \"Machine learning\", \"Normalized velocity", 
        "title": "Machine learning-based classification of simple drawing movements in Parkinson's disease"
    }, 
    {
        "abstract": "Abstract The success of myoelectric pattern recognition (M-PR) mostly relies on the features extracted and classifier employed. This paper proposes and evaluates a fast classifier, extreme learning machine (ELM), to classify individual and combined finger movements on amputees and non-amputees. \\{ELM\\} is a single hidden layer feed-forward network (SLFN) that avoids iterative learning by determining input weights randomly and output weights analytically. Therefore, it can accelerate the training time of SLFNs. In addition to the classifier evaluation, this paper evaluates various feature combinations to improve the performance of M-PR and investigate some feature projections to improve the class separability of the features. Different from other studies on the implementation of \\{ELM\\} in the myoelectric controller, this paper presents a complete and thorough investigation of various types of \\{ELMs\\} including the node-based and kernel-based ELM. Furthermore, this paper provides comparisons of \\{ELMs\\} and other well-known classifiers such as linear discriminant analysis (LDA), k-nearest neighbour (kNN), support vector machine (SVM) and least-square \\{SVM\\} (LS-SVM). The experimental results show the most accurate \\{ELM\\} classifier is radial basis function \\{ELM\\} (RBF-ELM). The comparison of RBF-ELM and other well-known classifiers shows that RBF-ELM is as accurate as \\{SVM\\} and LS-SVM but faster than the \\{SVM\\} family; it is superior to \\{LDA\\} and kNN. The experimental results also indicate that the accuracy gap of the M-PR on the amputees and non-amputees is not too much with the accuracy of 98.55% on amputees and 99.5% on the non-amputees using six electromyography (EMG) channels.", 
        "author": "Khairul Anam and Adel Al-Jumaily", 
        "keyword": "Classification\", \"Myoelectric pattern recognition\", \"Electromyography (EMG)\", \"Extreme learning keywords =achine (ELM)\", \"Amputee", 
        "title": "Evaluation of extreme learning machine for classification of individual and combined finger movements using electromyography on amputees and non-amputees"
    }, 
    {
        "abstract": "Abstract This study is to develop a detector that automatically detects cracks from the photographs of concrete structures, using convolution neural network which is a kind of deep learning. Firstly, photographs of concrete were collected for the learning data. Secondly, pictures of cracked part, chalk letter part, joint part, surface part and others part were produced from these photographs for the dataset. Thirdly, classifier to classify into these 5 class from pictures was created using the dataset and convolution neural network. Finally, the automatic detector was produced using this classifier.", 
        "author": "Suguru Yokoyama and Takashi Matsumoto", 
        "keyword": "machine learning\", \"deep learning\", \"cracked concrete\", \"automatic detection", 
        "title": "Development of an Automatic Detector of Cracks in Concrete Using Machine Learning"
    }, 
    {
        "abstract": "Abstract How can behavioral science incorporate tools from machine learning (ML)? We propose that \\{ML\\} models can be used as upper bounds for the \u201cexplainable\u201d variance in a given data set and thus serve as upper bounds for the potential power of a theory. We demonstrate this method in the domain of uncertainty. We ask over 600 individuals to make a total of 6000 choices with randomized parameters and compare standard economic models to \\{ML\\} models. In the domain of risk, a version of expected utility that allows for non-linear probability weighting (as in cumulative prospect theory) and individual-level parameters performs as well out-of-sample as \\{ML\\} techniques. By contrast, in the domain of ambiguity, two of the most widely studied models (a linear version of maximin preferences and second order expected utility) fail to compete with the \\{ML\\} methods. We open the \u201cblack boxes\u201d of the \\{ML\\} methods and show that under risk we \u201crediscover\u201d expected utility with probability weighting. However, in the case of ambiguity the form of ambiguity aversion implied by our \\{ML\\} models suggests that there is gain from theoretical work on a portable model of ambiguity aversion. Our results highlight ways in which behavioral scientists can incorporate \\{ML\\} techniques in their daily practice to gain genuinely new insights.", 
        "author": "Alexander Peysakhovich and Jeffrey Naecker", 
        "keyword": "Behavioral economics\", \"Machine learning\", \"Risk\", \"Ambiguity\", \"Decision-making", 
        "title": "Using methods from machine learning to evaluate behavioral models of choice under risk and ambiguity"
    }, 
    {
        "abstract": "Abstract In this research, we conduct a case study of mapping polymetallic prospectivity using an extreme learning machine (ELM) regression. A Quad-Core \\{CPU\\} 1.8 \\{GHz\\} laptop computer served as hardware platform. Almeida's Python program was used to construct the \\{ELM\\} regression model to map polymetallic prospectivity of the Lalingzaohuo district in Qinghai Province in China. Based on geologic, metallogenic, and statistical analyses of the study area, one target and eight predictor map patterns and two training sets were then used to train the \\{ELM\\} regression and logistic regression models. \\{ELM\\} regression modeling using the two training sets spends 61.4 s and 65.9 s; whereas the logistic regression modeling using the two training sets spends 1704.0 s and 1628.0 s. The four trained regression models were used to map polymetallic prospectivity. Based on the polymetallic prospectivity predicted by each model, the receiver operating characteristic (ROC) curve was plotted and the area under the curve (AUC) was estimated. The \\{ROC\\} curves show that the two ELM-regression-based models somewhat dominate the two logistic-regression-based models over the \\{ROC\\} performance space; and the \\{AUC\\} values indicate that the overall performances of the two ELM-regression-based models are somewhat better than those of the two logistic-regression-based models. Hence, the ELM-regression-based models slightly outperform the logistic-regression-based models in mapping polymetallic prospectivity. Polymetallic targets were optimally delineated by using the Youden index to maximize spatial association between the delineated polymetallic targets and the discovered polymetallic deposits. The polymetallic targets predicted by the two ELM-regression-based models occupy lower percentage of the study area (2.66\u20132.68%) compared to those predicted by the two logistic-regression-based models (4.96%) but contain the same percentage of the discovered polymetallic deposits (82%). Therefore, the \\{ELM\\} regression is a useful fast-learning data-driven model that slightly outperforms the widely used logistic regression model in mapping mineral prospectivity. The case study reveals that the magmatic complexes, which intruded into the Baishahe Formation of the Paleoproterozoic Jinshuikou Group or the Carboniferous Dagangou and Shiguaizi Formations, and which were controlled by northwest-western/east-western trending deep faults, are critical for polymetallic mineralization and need to be paid much attention to in future mineral exploration in the study area.", 
        "author": "Yongliang Chen and Wei Wu", 
        "keyword": "Extreme learning machine (ELM) regression\", \"Logistic regression\", \"Mineral prospectivity mapping\", keywords =Receiver operating characteristic (ROC) curve\", \"Area under the curve or AUC\", \"Youden index", 
        "title": "Mapping mineral prospectivity using an extreme learning machine regression"
    }, 
    {
        "abstract": "Abstract Prediction of new proteins/enzymes is a main goal in drug development. In this chapter we introduce a new methodology to predict enzyme subclasses based on a new 2D approach. In this contest, Randic, Liao, Nandy, Basak, and many others developed some special types of graph-based representations for pseudofolding process of sequences guided by simple heuristics. These include geometrical constraints to node positioning (sequence pseudofolding rules) in 2D space, leading to final geometrical shapes that resemble latticelike patterns. Lattice networks have been used in the past to visually depict \\{DNA\\} and protein sequences, but they are very flexible. In fact, we can use this technique to create string pseudofolding lattice representations for any kind of string data. In this work, we carried out a statistical analysis of 50,000+ cases to seek and validate a new quantitative structure\u2013activity relationship\u2013like predictor for enzyme subclasses using a machine learning approach. The model uses spectral moments, entropy, and mean potential of pseudofolding lattice graphs as inputs. In this work we report the five best models that we found.", 
        "author": "R. Concu and H. Gonz\u00e1lez-D\u00edaz and M.N.D.S. Cordeiro", 
        "keyword": "Complex networks\", \"Enzyme subclasses\", \"Graph theory\", \"Machine learning\", \"Protein folding\", \"Proteomics", 
        "title": "Chapter 2 - Machine Learning Approach to Predict Enzyme Subclasses"
    }, 
    {
        "abstract": "Abstract Early fault detection of engineering systems allows early warnings of anomalies and provides time to initiate proactive mitigation actions before the anomaly has developed to a problem that either requires extensive maintenance or affects the productivity of the system. In this paper, a new fault detection method using signal reconstruction based on Auto-Associative Extreme Learning Machines (AAELM) is proposed. \\{AAELM\\} are applied for fault detection on an artificially generated dataset to test the performance of the algorithm under controlled conditions and a real case study based on condition monitoring data from a combined-cycle power plant compressor. The performance of \\{AAELM\\} is compared to that of two other commonly used signal reconstruction methods: Auto-Associative Kernel Regression (AAKR) and Principal Component Analysis (PCA). The results from the two case studies demonstrate that \\{AAELM\\} achieve a smaller reconstruction error, shorter detection delay, lower spillover and a higher distinguishability compared to \\{AAKR\\} and \\{PCA\\} on the evaluated datasets. The obtained results are generalized to elaborate guidelines for industrial users for selecting suitable signal reconstruction algorithms based on their specific requirements and boundary conditions.", 
        "author": "Yang Hu and Thomas Palm\u00e9 and Olga Fink", 
        "keyword": "Fault detection\", \"Auto-Associative Extreme Learning Machines\", \"Performance comparison\", keywords =Auto-Associative Kernel Regression\", \"Principal Component Analysis\", \"Combined-cycle power plant compressor", 
        "title": "Fault detection based on signal reconstruction with Auto-Associative Extreme Learning Machines"
    }, 
    {
        "abstract": "Abstract In this paper, we propose an effective algorithm based on Extreme Learning Machine (ELM) for salient object detection. First, saliency maps generated by existing methods are taken as prior maps, from which training samples are collected for an \\{ELM\\} classifier. Second, the \\{ELM\\} classifier is learned to detect the salient regions, and the final results are generated by fusing multi-scale saliency maps. This ELM-based model can improve the performance of different state-of-the-art methods to a large degree. Furthermore, we present an integration mechanism to take advantages of superiorities of multiple saliency maps. Extensive experiments on five datasets demonstrate that our method performs well and the significant improvement can be achieved when applying our model to existing saliency approaches.", 
        "author": "Lu Zhang and Jianhua Li and Huchuan Lu", 
        "keyword": "Saliency detection\", \"Extreme learning machine\", \"Multi-scale superpixels", 
        "title": "Saliency detection via extreme learning machine"
    }, 
    {
        "abstract": "Abstract A model that accurately predicts, at the time of admission, the Length of Stay (LOS) for hospitalized patients could be an effective tool for healthcare providers. It could enable early interventions to prevent complications, enabling more efficient utilization of manpower and facilities in hospitals. In this study, we apply a regression tree (Cubist) model for predicting the LOS, based on static inputs, that is, values that are known at the time of admission and that do not change during patient's hospital stay. The model was trained and validated on de-identified administrative data from the Veterans Health Administration (VHA) hospitals in Pittsburgh, PA. We chose to use a Cubist model because it produced more accurate predictions than did alternative techniques. In addition, tree models enable us to examine the classification rules learned from the data, in order to better understand the factors that are most correlated with hospital LOS. Cubist recursively partitions the data set as it estimates linear regressions for each partition, and the error level differs for different partitions, so that it is possible to deduce what are the characteristics of patients whose \\{LOS\\} can be accurately predicted at admission, and what are the characteristics of patients for whom the \\{LOS\\} estimate at that point in time is more highly uncertain. For example, our model indicates that the prediction error is greater for patients who had more admissions in the recent past, and for those who had longer previous hospital stays. Our approach suggests that mapping the cases into a higher dimensional space, using a Radial Basis Function (RBF) kernel, helps to separate them by their level of Cubist error, using a Support Vector Machine (SVM).", 
        "author": "Lior Turgeman and Jerrold H. May and Roberta Sciulli", 
        "keyword": "Cubist decision tree\", \"Continuous association rule mining algorithm (CARMA)\", \"Support vector keywords =achine (SVM)\", \"Decision function\", \"Error distribution\", \"Length of Stay (LOS)", 
        "title": "Insights from a machine learning model for predicting the hospital Length of Stay (LOS) at the time of admission"
    }, 
    {
        "abstract": "Abstract Data streams classification is an important approach to get useful knowledge from massive and dynamic data. Because of concept drift, traditional data mining techniques cannot be directly applied in data streams environment. Extreme learning machine (ELM) is a single hidden layer feedforward neural network (SLFN), comparing with the traditional neural network (e.g. \\{BP\\} network), \\{ELM\\} has a faster speed, so it is very suitable for real-time data processing. In order to deal with the challenge in data streams classification, a new approach based on extreme learning machine is proposed in this paper. The approach utilizes \\{ELMs\\} as base classifiers and adaptively decides the number of the neurons in hidden layer, in addition, activation functions are also randomly selected from a series of functions to improve the performance of the approach. Finally, the algorithm trains a series of classifiers and the decision results for unlabeled data are made by weighted voting strategy. When the concept in data streams keeps stable, every classifier is incrementally updated by using new data; if concept drift is detected, the classifiers with weak performance will be cleared away. In the experiment, we used 7 artificial data sets and 9 real data sets from \\{UCI\\} repository to evaluate the performance of the proposed approach. The testing results showed, comparing with the conventional classification methods for data streams such as ELM, BP, \\{AUE2\\} and Learn++.MF, on most data sets, the new approach could not only be simplest in the structure, but also get a higher and more stable accuracy with lower time consuming.", 
        "author": "Shuliang Xu and Junhong Wang", 
        "keyword": "Data mining\", \"Extreme learning machine\", \"Data streams\", \"Classification\", \"Concept drift", 
        "title": "A fast incremental extreme learning machine algorithm for data streams classification"
    }, 
    {
        "abstract": "Abstract The need for reduction in \\{CO2\\} emissions to mitigate global warming has resulted in increasing use of renewable energy sources. In urban areas, solar photovoltaic (PV) deployment on existing rooftops is one of the most viable sustainable energy resources. The present study uses a combination of support vector machines (SVMs) and geographic information systems (GIS) to estimate the rooftop solar \\{PV\\} potential for the urban areas at the commune level (the smallest administrative division) in Switzerland. The rooftop solar \\{PV\\} potential for a total 1901 out of 2477 communes in Switzerland is estimated. Following a 6-fold cross validation, the root-mean-square error (also normalized) is used to estimate the accuracy of the different \\{SVM\\} models. The results show that, on average, 81% of the total ground floor area of each building corresponds to the available roof area for the \\{PV\\} installation. Also considering the total available roof area for \\{PV\\} installation, that is, 328 km2 and roof orientations within \u00b190\u00b0 of due south, the annual potential \\{PV\\} electricity production for the urban areas in Switzerland is estimated at 17.86 \\{TW\\} h (assumed 17% efficiency and 80% performance ratio). This amount corresponds to 28% of Switzerland\u2019s electricity consumption in 2015.", 
        "author": "Dan Assouline and Nahid Mohajeri and Jean-Louis Scartezzini", 
        "keyword": "Machine learning\", \"Support vector regression\", \"Solar photovoltaics\", \"Large-scale solar keywords =otential\", \"Geographic information systems", 
        "title": "Quantifying rooftop photovoltaic solar energy potential: A machine learning approach"
    }, 
    {
        "abstract": "Abstract Office documents are used extensively by individuals and organizations. Most users consider these documents safe for use. Unfortunately, Office documents can contain malicious components and perform harmful operations. Attackers increasingly take advantage of naive users and leverage Office documents in order to launch sophisticated advanced persistent threat (APT) and ransomware attacks. Recently, targeted cyber-attacks against organizations have been initiated with emails containing malicious attachments. Since most email servers do not allow the attachment of executable files to emails, attackers prefer to use of non-executable files (e.g., documents) for malicious purposes. Existing anti-virus engines primarily use signature-based detection methods, and therefore fail to detect new unknown malicious code which has been embedded in an Office document. Machine learning methods have been shown to be effective at detecting known and unknown malware in various domains, however, to the best of our knowledge, machine learning methods have not been used for the detection of malicious XML-based Office documents (*.docx, *.xlsx, *.pptx, *.odt, *.ods, etc.). In this paper we present a novel structural feature extraction methodology (SFEM) for XML-based Office documents. \\{SFEM\\} extracts discriminative features from documents, based on their structure. We leveraged SFEM\u2019s features with machine learning algorithms for effective detection of malicious *.docx documents. We extensively evaluated \\{SFEM\\} with machine learning classifiers using a representative collection (16,938 *.docx documents collected \"from the wild\") which contains \u223c4.9% malicious and \u223c95.1% benign documents. We examined 1,600 unique configurations based on different combinations of feature extraction, feature selection, feature representation, top-feature selection methods, and machine learning classifiers. The results show that machine learning algorithms trained on features provided by \\{SFEM\\} successfully detect new unknown malicious *.docx documents. The Random Forest classifier achieves the highest detection rates, with an \\{AUC\\} of 99.12% and true positive rate (TPR) of 97% that is accompanied by a false positive rate (FPR) of 4.9%. In comparison, the best anti-virus engine achieves a \\{TPR\\} which is \u223c25% lower.", 
        "author": "Aviad Cohen and Nir Nissim and Lior Rokach and Yuval Elovici", 
        "keyword": "Machine learning\", \"Malware detection\", \"Static analysis\", \"Structural features\", \"Microsoft office keywords =pen xml\", \"Document", 
        "title": "SFEM: Structural feature extraction methodology for the detection of malicious office documents using machine learning methods"
    }, 
    {
        "abstract": "AbstractBackground and objective Smoking is the largest preventable cause of death and diseases in the developed world, and advances in modern electronics and machine learning can help us deliver real-time intervention to smokers in novel ways. In this paper, we examine different machine learning approaches to use situational features associated with having or not having urges to smoke during a quit attempt in order to accurately classify high-urge states. Methods To test our machine learning approaches, specifically, Bayes, discriminant analysis and decision tree learning methods, we used a dataset collected from over 300 participants who had initiated a quit attempt. The three classification approaches are evaluated observing sensitivity, specificity, accuracy and precision. Results The outcome of the analysis showed that algorithms based on feature selection make it possible to obtain high classification rates with only a few features selected from the entire dataset. The classification tree method outperformed the naive Bayes and discriminant analysis methods, with an accuracy of the classifications up to 86%. These numbers suggest that machine learning may be a suitable approach to deal with smoking cessation matters, and to predict smoking urges, outlining a potential use for mobile health applications. Conclusions In conclusion, machine learning classifiers can help identify smoking situations, and the search for the best features and classifier parameters significantly improves the algorithms' performance. In addition, this study also supports the usefulness of new technologies in improving the effect of smoking cessation interventions, the management of time and patients by therapists, and thus the optimization of available health care resources. Future studies should focus on providing more adaptive and personalized support to people who really need it, in a minimum amount of time by developing novel expert systems capable of delivering real-time interventions.", 
        "author": "Antoine Dumortier and Ellen Beckjord and Saul Shiffman and Ervin Sejdi\u0107", 
        "keyword": "Smoking urges\", \"Smoking cessation\", \"Machine learning\", \"Supervised learning\", \"Feature selection", 
        "title": "Classifying smoking urges via machine learning"
    }, 
    {
        "abstract": "Abstract Forecasting energy consumption in buildings is a key step towards the realization of optimized energy production, distribution and consumption. This paper presents a data driven approach for analysis and forecast of aggregate space and water thermal load in buildings. The analysis and the forecast models are built using district heating data unobtrusively collected from 10 residential and commercial buildings located in Skellefte\u00e5, Sweden. The load forecast models are generated using supervised machine learning techniques, namely, support vector machine, regression tree, feed forward neural network, and multiple linear regression. The model takes the outdoor temperature, historical values of heat load, time factor variables and physical parameters of district heating substations as its input. A performance comparison among the machine learning methods and identification of the importance of models input variables is carried out. The models are evaluated with varying forecast horizons of every hour from 1 up to 48 h. Our results show that support vector machine, feed forward neural network and multiple linear regression are more suitable machine learning methods with lower performance errors than the regression tree. Support vector machine has the least normalized root mean square error of 0.07 for a forecast horizon of 24 h.", 
        "author": "Samuel Idowu and Saguna Saguna and Christer \u00c5hlund and Olov Schel\u00e9n", 
        "keyword": "Data driven modeling\", \"District heating\", \"Energy efficiency\", \"Machine learning\", \"Smart cities", 
        "title": "Applied machine learning: Forecasting heat load in district heating system"
    }, 
    {
        "abstract": "Abstract Fatigue stress concentration factor (FSCF) plays a vital role in studying the limitation of material fatigue resistance. Theoretically, \\{FSCF\\} not only reflects the level of fatigue stress concentration but also indicates the notch sensitive degree. In this work, a novel and efficient numerical model is presented for predicting FSCF, which exploits an emergent learning technique, i.e., Extreme Learning Machine (ELM). Specifically, we adopt seven parameters (i.e., tensile strength, yield strength, fatigue strength, theoretical stress concentration factor, notch root radius, samples size and notch fatigue limit) as the inputs, and the corresponding \\{FSCF\\} value is used as the output. With the randomly generated hidden neuron parameters, the ELM-based predictor can be fast trained. Besides, a pairwise metric constraint is introduced in the presented model, which can elevate the forecasting accuracy. A series of cross validation experiments demonstrate that the proposed \\{FSCF\\} predictor performs favorably against the existing empirical formulas and other learning based methods.", 
        "author": "Baoxian Wang and Weigang Zhao and Yanliang Du and Guangyuan Zhang and Yong Yang", 
        "keyword": "Fatigue stress concentration factor\", \"Material fatigue resistance\", \"Extreme learning machine\", \"Prediction", 
        "title": "Prediction of fatigue stress concentration factor using extreme learning machine"
    }, 
    {
        "abstract": "Abstract Lexicographic preferences on a set of attributes provide a cognitively plausible structure for modeling the behavior of human decision makers. Therefore, the induction of corresponding models from revealed preferences or observed decisions constitutes an interesting problem from a machine learning point of view. In this paper, we introduce a learning algorithm for inducing generalized lexicographic preference models from a given set of training data, which consists of pairwise comparisons between objects. Our approach generalizes simple lexicographic orders in the sense of allowing the model to consider several attributes simultaneously (instead of looking at them one by one), thereby significantly increasing the expressiveness of the model class. In order to evaluate our method, we present a case study of a highly complex real-world problem, namely the choice of the recognition method for actuarial gains and losses from occupational pension schemes. Using a unique sample of European companies, this problem is well suited for demonstrating the effectiveness of our lexicographic ranker. Furthermore, we conduct a series of experiments on benchmark data from the machine learning domain.", 
        "author": "Michael Br\u00e4uning and Eyke H\u00fcllermeier and Tobias Keller and Martin Glaum", 
        "keyword": "Lexicographic orders\", \"Preference learning\", \"Artificial intelligence\", \"Decision analysis\", \"Accounting", 
        "title": "Lexicographic preferences for predictive modeling of human decision making: A new machine learning method with an application in accounting"
    }, 
    {
        "abstract": "AbstractPurpose To predict patients who would benefit from adaptive radiotherapy (ART) and re-planning intervention based on machine learning from anatomical and dosimetric variations in a retrospective dataset. Materials and methods 90 patients (pts) treated for head-neck cancer (H&amp;N) formed a multicenter data-set. 41 H&amp;N pts (45.6%) were considered for learning; 49 pts (54.4%) were used to test the tool. A homemade machine-learning classifier was developed to analyze volume and dose variations of parotid glands (PG). Using deformable image registration (DIR) and GPU, patients\u2019 conditions were analyzed automatically. Support Vector Machines (SVM) was used for time-series evaluation. \u201cInadequate\u201d class identified patients that might benefit from replanning. Double-blind evaluation by two radiation oncologists (ROs) was carried out to validate day/week selected for re-planning by the classifier. Results The cohort was affected by \\{PG\\} mean reduction of 23.7 \u00b1 8.8%. During the first 3 weeks, 86.7% cases show \\{PG\\} deformation aligned with predefined tolerance, thus not requiring re-planning. From 4th week, an increased number of pts would potentially benefit from re-planning: a mean of 58% of cases, with an inter-center variability of 8.3%, showed \u201cinadequate\u201d conditions. 11% of cases showed \u201cbias\u201d due to \\{DIR\\} and script failure; 6% showed \u201cwarning\u201d output due to potential positioning issues. Comparing re-planning suggested by tool with recommended by ROs, the 4th week seems the most favorable time in 70% cases. Conclusions \\{SVM\\} and decision-making tool was applied to overcome \\{ART\\} challenges. Pts would benefit from \\{ART\\} and ideal time for re-planning intervention was identified in this retrospective analysis.", 
        "author": "G. Guidi and N. Maffei and B. Meduri and E. D\u2019Angelo and G.M. Mistretta and P. Ceroni and A. Ciarmatori and A. Bernabei and S. Maggi and M. Cardinali and V.E. Morabito and F. Rosica and S. Malara and A. Savini and G. Orlandi and C. D\u2019Ugo and F. Bunkheila and M. Bono and S. Lappi and C. Blasi and F. Lohr and T. Costi", 
        "keyword": "Machine learning\", \"Re-planning\", \"Adaptive RT\", \"Deformable registration", 
        "title": "A machine learning tool for re-planning and adaptive RT: A multicenter cohort investigation"
    }, 
    {
        "abstract": "Abstract Economic growth may be developed based on trade, imports and exports parameters. The main goal in this study was to predict the economic growth based on trade in services, exports of goods and services, imports of goods and services, trade and merchandise trade on the economic growth. Gross domestic product (GDP) was used as economic growth indicator. The main purpose of this research is to develop and apply the artificial neural network (ANN) with back propagation learning (BP) algorithm and with extreme learning machine (ELM) in order predict \\{GDP\\} growth rate. The aim was to compare the results of \\{BP\\} and \\{ELM\\} prediction accuracy for the \\{GDP\\} growth rate prediction based on the trade data. Based on results, it was demonstrated that \\{ELM\\} can be utilized effectively in applications of \\{GDP\\} growth rate forecasting.", 
        "author": "Svetlana Sokolov-Mladenovi\u0107 and Milos Milovan\u010devi\u0107 and Igor Mladenovi\u0107 and Meysam Alizamir", 
        "keyword": "Artificial neural network\", \"Extreme learning machine\", \"Forecasting\", \"Gross domestic product", 
        "title": "Economic growth forecasting by artificial neural network with extreme learning machine based on trade, import and export parameters"
    }, 
    {
        "abstract": "Abstract Ocean acidification (OA), or the reduction in the pH of the ocean, is driven by increasing carbon dioxide concentration in the atmosphere and local pollution. There is already evidence of the detrimental impact of \\{OA\\} on marine organisms. As further increases in atmospheric \\{CO2\\} and changes in water quality are expected, it is crucial to develop and implement advanced technologies that enable better monitoring, allow for understanding of adaptation potential of the organisms, and facilitate the use of mitigation strategies toward predicted environmental changes. Collaboration of marine and computer scientists, engineers, and citizens is needed to develop innovative sustainable technologies to mitigate and reduce future increase of CO2.", 
        "author": "Daniela Turk and Nina Bednar\u0161ek and Wiley Evans and Maribel I. Garc\u00eda-Ib\u00e1\u00f1ez and Burke Hales and Jessica Cross", 
        "keyword": "Autonomous sensors and platforms\", \"Carbon capture and storage\", \"Citizen science\", \"CO2 mitigating keywords =echnologies\", \"Indicator species\", \"Machine learning\", \"Ocean acidification\", \"Ocean monitoring\", keywords =Statistical modeling\", \"Sustainable technology\", \"Water-quality impairment", 
        "title": "Role of Technology in Ocean Acidification: Monitoring, Water-Quality Impairments, \\{CO2\\} Mitigation, and Machine Learning"
    }, 
    {
        "abstract": "Rationale and Objectives This study aimed to assess the performance of a text classification machine-learning model in predicting highly cited articles within the recent radiological literature and to identify the model's most influential article features. Materials and Methods We downloaded from PubMed the title, abstract, and medical subject heading terms for 10,065 articles published in 25 general radiology journals in 2012 and 2013. Three machine-learning models were applied to predict the top 10% of included articles in terms of the number of citations to the article in 2014 (reflecting the 2-year time window in conventional impact factor calculations). The model having the highest area under the curve was selected to derive a list of article features (words) predicting high citation volume, which was iteratively reduced to identify the smallest possible core feature list maintaining predictive power. Overall themes were qualitatively assigned to the core features. Results The regularized logistic regression (Bayesian binary regression) model had highest performance, achieving an area under the curve of 0.814 in predicting articles in the top 10% of citation volume. We reduced the initial 14,083 features to 210 features that maintain predictivity. These features corresponded with topics relating to various imaging techniques (eg, diffusion-weighted magnetic resonance imaging, hyperpolarized magnetic resonance imaging, dual-energy computed tomography, computed tomography reconstruction algorithms, tomosynthesis, elastography, and computer-aided diagnosis), particular pathologies (prostate cancer; thyroid nodules; hepatic adenoma, hepatocellular carcinoma, non-alcoholic fatty liver disease), and other topics (radiation dose, electroporation, education, general oncology, gadolinium, statistics). Conclusions Machine learning can be successfully applied to create specific feature-based models for predicting articles likely to achieve high influence within the radiological literature.", 
        "author": "Andrew B. Rosenkrantz and Ankur M. Doshi and Luke A. Ginocchio and Yindalon Aphinyanaphongs", 
        "keyword": "Radiology\", \"bibliometrics\", \"biomedical journals\", \"machine learning", 
        "title": "Use of a Machine-learning Method for Predicting Highly Cited Articles Within General Radiology Journals"
    }, 
    {
        "abstract": "AbstractIntroduction The evaluation of tongue colour has been an important approach to examine human health in Kampo medicine (traditional Japanese medicine) because the change in tongue colour may suggest physical or mental disorders. Several tongue colour quantification methods have been published to objectify clinical information among East Asian countries. However, reliable tongue colour analysis results among Japanese test persons are limited because of a lack of quantitative evaluation of tongue colour. We aimed to use advances in digital imaging processing to quantify and verify clinical data tongue colour diagnosis by characterising differences intongue features. Methods The DS01-B tongue colour information acquisition system was used to extract tongue images of 1080 Japanese test subjects. Evaluation of tongue colour, body and coating was performed by 10 experienced Kampo medicine physicians. The acquired images were classified into five tongue body colour categories and six tongue coating colour categories based on evaluations from 10 physicians with extensive Kampo medicine experience. K-means clustering algorithm was applied as a machine learning (the study of pattern recognition by computational learning) method to the acquired images to quantify tongue body and coating colour information. Results Tongue body (n = 550) and tongue coating (n = 516) colour samples were classified and analysed. Clusters consisting of five tongue body colour categories and six tongue coating colour categories were experimentally described in the \\{CIELAB\\} colour space. Statistical differences were evident among the clinically primary tongue colours. Conclusions Clinically important tongue colour differences in Kampo medicine can be visualised by applying machine learning to tongue images taken under stable conditions. This has implications for developing globally unified, reliable tongue colour diagnostic criteria which could be used to explore the relevance between clinical status and tongue colour.", 
        "author": "Tadaaki Kawanabe and Nur Diyana Kamarudin and Chia Yee Ooi and Fuminori Kobayashi and Xiaoyu Mi and Mariko Sekine and Akino Wakasugi and Hiroshi Odaguchi and Toshihiko Hanawa", 
        "keyword": "Tongue colour diagnosis\", \"Machine learning\", \"K-means clustering\", \"Kampo medicine\", \"Traditional Japanese medicine", 
        "title": "Quantification of tongue colour using machine learning in Kampo medicine"
    }, 
    {
        "abstract": "Abstract Problematic internet use is common, functionally impairing, and in need of further study. Its relationship with obsessive-compulsive and impulsive disorders is unclear. Our objective was to evaluate whether problematic internet use can be predicted from recognised forms of impulsive and compulsive traits and symptomatology. We recruited volunteers aged 18 and older using media advertisements at two sites (Chicago USA, and Stellenbosch, South Africa) to complete an extensive online survey. State-of-the-art out-of-sample evaluation of machine learning predictive models was used, which included Logistic Regression, Random Forests and Na\u00efve Bayes. Problematic internet use was identified using the Internet Addiction Test (IAT). 2006 complete cases were analysed, of whom 181 (9.0%) had moderate/severe problematic internet use. Using Logistic Regression and Na\u00efve Bayes we produced a classification prediction with a receiver operating characteristic area under the curve (ROC-AUC) of 0.83 (SD 0.03) whereas using a Random Forests algorithm the prediction ROC-AUC was 0.84 (SD 0.03) [all three models superior to baseline models p\u00a0&lt;\u00a00.0001]. The models showed robust transfer between the study sites in all validation sets [p\u00a0&lt;\u00a00.0001]. Prediction of problematic internet use was possible using specific measures of impulsivity and compulsivity in a population of volunteers. Moreover, this study offers proof-of-concept in support of using machine learning in psychiatry to demonstrate replicability of results across geographically and culturally distinct settings.", 
        "author": "Konstantinos Ioannidis and Samuel R. Chamberlain and Matthias S. Treder and Franz Kiraly and Eric W. Leppink and Sarah A. Redden and Dan J. Stein and Christine Lochner and Jon E. Grant", 
        "keyword": "ADHD\", \"Compulsivity\", \"Impulsivity\", \"Internet use\", \"OCD\", \"Machine learning", 
        "title": "Problematic internet use (PIU): Associations with the impulsive-compulsive spectrum. An application of machine learning in psychiatry"
    }, 
    {
        "abstract": "AbstractContext Software defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. Objective The main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. Method In this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, MMS, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. Results The results show that the area under the curve measure for Na\u00efve Bayes, LogitBoost and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the \\{ML\\} techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. Conclusion The results confirm the predictive capability of various \\{ML\\} techniques for developing defect prediction models. The results also confirm the superiority of one \\{ML\\} technique over the other \\{ML\\} techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.", 
        "author": "Ruchika Malhotra", 
        "keyword": "Object-oriented metrics\", \"Machine-learning\", \"Software defect proneness\", \"Statistical tests\", \"Inter-release validation", 
        "title": "An empirical framework for defect prediction using machine learning techniques with Android software"
    }, 
    {
        "abstract": "Abstract Soil water content (SWC) is a key factor in optimizing the usage of water resources in agriculture since it provides information to make an accurate estimation of crop water demand. Methods for predicting \\{SWC\\} that have simple data requirements are needed to achieve an optimal irrigation schedule, especially for various water-saving irrigation strategies that are required to resolve both food and water security issues under conditions of water shortages. Thus, a two-year field investigation was carried out to provide a dataset to compare the effectiveness of HYDRUS-2D, a physically-based numerical model, with various machine-learning models, including Multiple Linear Regressions (MLR), Adaptive Neuro-Fuzzy Inference Systems (ANFIS), and Support Vector Machines (SVM), for simulating time series of \\{SWC\\} data under water stress conditions. \\{SWC\\} was monitored using \\{TDRs\\} during the maize growing seasons of 2010 and 2011. Eight combinations of six, simple, independent parameters, including pan evaporation and average air temperature as atmospheric parameters, cumulative growth degree days (cGDD) and crop coefficient (Kc) as crop factors, and water deficit (WD) and irrigation depth (In) as crop stress factors, were adopted for the estimation of \\{SWCs\\} in the machine-learning models. Having Root Mean Square Errors (RMSE) in the range of 0.54\u20132.07 mm, HYDRUS-2D ranked first for the \\{SWC\\} estimation, while the \\{ANFIS\\} and \\{SVM\\} models with input datasets of cGDD, Kc, \\{WD\\} and In ranked next with \\{RMSEs\\} ranging from 1.27 to 1.9 mm and mean bias errors of \u22120.07 to 0.27 mm, respectively. However, the \\{MLR\\} models did not perform well for \\{SWC\\} forecasting, mainly due to non-linear changes of \\{SWCs\\} under the irrigation process. The results demonstrated that despite requiring only simple input data, the \\{ANFIS\\} and \\{SVM\\} models could be favorably used for \\{SWC\\} predictions under water stress conditions, especially when there is a lack of data. However, process-based numerical models are undoubtedly a better choice for predicting \\{SWCs\\} with lower uncertainties when required data are available, and thus for designing water saving strategies for agriculture and for other environmental applications requiring estimates of SWCs.", 
        "author": "Fatemeh Karandish and Ji\u0159\u00ed \u0160im\u016fnek", 
        "keyword": "Machine-learning models\", \"ANFIS\", \"HYDRUS-2D\", \"MLR\", \"SVM\", \"Soil water content\", \"Water saving irrigation", 
        "title": "A comparison of numerical and machine-learning modeling of soil water content with limited input data"
    }, 
    {
        "abstract": "Abstract In forest harvesting, terrain trafficability is the key parameter needed for route planning. Advance knowledge of the soil bearing capacity is crucial for heavy machinery operations. Especially peatland areas can cause severe problems for harvesting operations and can result in increased costs. In addition to avoiding potential damage to the soil, route planning must also take into consideration the root damage to the remaining trees. In this paper we study the predictability of boreal soil load bearing capacity by using remote sensing data and field measurement data. We conduct our research by using both linear and nonlinear methods of machine learning. With the best prediction method, ridge regression, the results are promising with a C-index value higher than 0.68 up to 200 m prediction range from the closest point with known bearing capacity, the baseline value being 0.5. The load bearing classification of the soil resulted in 76% accuracy up to 60 m by using a multilayer perceptron method. The results indicate that there is a potential for production applications and that there is a great need for automatic real-time sensoring in order to produce applicable predictions.", 
        "author": "J. Pohjankukka and H. Riihim\u00e4ki and P. Nevalainen and T. Pahikkala and J. Ala-Ilom\u00e4ki and E. Hyv\u00f6nen and J. Varjo and J. Heikkonen", 
        "keyword": "Terrain trafficability\", \"Soil bearing capacity prediction\", \"Forest harvesting\", \"Machine keywords =earning\", \"Open data", 
        "title": "Predictability of boreal forest soil bearing capacity by machine learning"
    }, 
    {
        "abstract": "AbstractObject Our purpose was to develop a new machine-learning approach (a virtual health check-up) toward identification of those at high risk of hyperuricemia. Applying the system to general health check-ups is expected to reduce medical costs compared with administering an additional test. Methods Data were collected during annual health check-ups performed in Japan between 2011 and 2013 (inclusive). We prepared training and test datasets from the health check-up data to build prediction models; these were composed of 43,524 and 17,789 persons, respectively. Gradient-boosting decision tree (GBDT), random forest (RF), and logistic regression (LR) approaches were trained using the training dataset and were then used to predict hyperuricemia in the test dataset. Undersampling was applied to build the prediction models to deal with the imbalanced class dataset. Results The results showed that the \\{RF\\} and \\{GBDT\\} approaches afforded the best performances in terms of sensitivity and specificity, respectively. The area under the curve (AUC) values of the models, which reflected the total discriminative ability of the classification, were 0.796 [95% confidence interval (CI): 0.766\u20130.825] for the GBDT, 0.784 [95% CI: 0.752\u20130.815] for the RF, and 0.785 [95% CI: 0.752\u20130.819] for the \\{LR\\} approaches. No significant differences were observed between pairs of each approach. Small changes occurred in the \\{AUCs\\} after applying undersampling to build the models. Conclusions We developed a virtual health check-up that predicted the development of hyperuricemia using machine-learning methods. The GBDT, RF, and \\{LR\\} methods had similar predictive capability. Undersampling did not remarkably improve predictive power.", 
        "author": "Daisuke Ichikawa and Toki Saito and Waka Ujita and Hiroshi Oyama", 
        "keyword": "Hyperuricemia\", \"Machine-learning\", \"Prediction", 
        "title": "How can machine-learning methods assist in virtual screening for hyperuricemia? A healthcare machine-learning approach"
    }, 
    {
        "abstract": "Abstract We present a novel approach for measuring democracy based on Support Vector Machines, a mathematical algorithm for pattern recognition. The Support Vector Machines Democracy Index (SVMDI) is continuous on the [0,1] interval and enables very detailed and sensitive measurement of democracy for 185 countries in the period between 1981 and 2011. Application of the \\{SVMDI\\} yields results which highlight a robust positive relationship between democracy and economic growth. We argue that the ambiguity in recent studies mainly originates from the lack of sensitivity of traditional democracy indicators. Analyzing transmission channels through which democracy exerts its influence on growth, we conclude that democratic countries feature better educated populations, higher investment shares, and lower fertility rates, but not necessarily higher levels of redistribution.", 
        "author": "Klaus Gr\u00fcndler and Tommy Krieger", 
        "keyword": "Democracy\", \"Economic growth\", \"Panel data\", \"Machine learning\", \"Support Vector Machines", 
        "title": "Democracy and growth: Evidence from a machine learning\u00a0indicator"
    }, 
    {
        "abstract": "Abstract This paper considers single machine scheduling problems which determine the optimal job schedule, due window location and resource allocation simultaneously. The optimized criteria consist of makespan, earliness, tardiness, due window starting time and size, and the allocated resource cost, to conform with just-in-time (JIT) manufacturing. The job's actual processing time is a general function of its position, starting time, and the resource quantity allocated for the job. Specifically, both the linear and convex resource consumption scenarios are considered. In the context of the linear and convex resource consumption, we present four research problems and prove that all of them are polynomially solvable under \\{CON\\} due window (all jobs share a common due window), \\{SLK\\} due window (each job is assigned an individual due window based on a common flow allowance) and \\{DIF\\} due window (each job has a different due window with no restrictions) assignment assumptions, respectively.", 
        "author": "Lu Liu and Jian-Jun Wang and Feng Liu and Ming Liu", 
        "keyword": "Scheduling\", \"Due window assignment\", \"Resource allocation\", \"Learning effects", 
        "title": "Single machine due window assignment and resource allocation scheduling problems with learning and general positional effects"
    }, 
    {
        "abstract": "Abstract Multimodal biometrics provides rich information in biometric recognition systems, thus a valid multimodal feature fusion framework and an efficient recognition algorithm are desirable for multimodal biometrics systems. In this paper, we design a multimodal fusion framework for face and fingerprint images using block based feature-image matrix, and extract a type of middle-layer semantic feature from local features\u2014a local fusion visual feature, which has better characterization capabilities with lower dimension for multimodal biometrics. Furthermore, we create recognition utilizing the Variational Bayesian Extreme Learning Machine (VBELM), which has an obvious speed advantage by random input weights, and also has superior stability and generalization by adding a non-informative full Gaussian prior. This research enables multimodal biometrics recognition system to have a concentrated fusion feature description and great recognition performance. Experimental results show that the proposed multimodal biometrics recognition system has a higher testing accuracy in comparison to the traditional methods with higher efficiency and better stability.", 
        "author": "Yarui Chen and Jucheng Yang and Chao Wang and Na Liu", 
        "keyword": "Multimodal biometrics recognition\", \"Local fusion visual feature\", \"Extreme learning machine\", \"Variational Bayesian", 
        "title": "Multimodal biometrics recognition based on local fusion visual features and variational Bayesian extreme learning machine"
    }, 
    {
        "abstract": "Abstract This study presents a framework that recognizes and imitates human upper-body motions in real time. The framework consists of two parts. In the first part, a transformation algorithm is applied to 3D human motion data captured by a Kinect. The data are then converted into the robot\u2019s joint angles by the algorithm. The human upper-body motions are successfully imitated by the \\{NAO\\} humanoid robot in real time. In the second part, the human action recognition algorithm is implemented for upper-body gestures. A human action dataset is also created for the upper-body movements. Each action is performed 10 times by twenty-four users. The collected joint angles are divided into six action classes. Extreme Learning Machines (ELMs) are used to classify the human actions. Additionally, the Feed-Forward Neural Networks (FNNs) and K-Nearest Neighbor (K-NN) classifiers are used for comparison. According to the comparative results, \\{ELMs\\} produce a good human action recognition performance.", 
        "author": "Emrehan Yav\u015fan and Ay\u015feg\u00fcl U\u00e7ar", 
        "keyword": "Human action recognition\", \"NAO humanoid robot\", \"Xbox 360 Kinect\", \"Extreme learning machines", 
        "title": "Gesture imitation and recognition using Kinect sensor and extreme learning machines"
    }, 
    {
        "abstract": "Abstract This paper presents a machine learning algorithm for processing of massive data collected from the mechanical components of movable bridges. The proposed approach consists of training and monitoring phases. The training phase was focused on the extracting statistical features and conducting cross correlation analysis (CCA) and robust regression analysis (RRA). The monitoring phase included tracking of errors associated with the derived models. The main goal was to analyze the efficiency of the developed system for health monitoring of the bridge mechanical components such as gearbox, motor and rack and pinion. To this aim, Sunrise Movable Bridge in Ft. Lauderdale, Florida was selected and instrumented. A comprehensive database was collected from the sensors installed on the mechanical and structural components of the Sunrise Bridge for about 4 years. The collected data were utilized to assess the performance of the algorithm under baseline and different common damage scenarios. Based on the results, the proposed health monitoring system has a satisfactory performance for the detection of the damage scenarios caused by leakage and lack of sufficient oil in gearbox, as well as bolt removal from rack and pinion. The introduced algorithm can be regarded as a valuable tool for the management and interpretation of the massive (big) data collected for structural health monitoring (SHM) of movable bridges.", 
        "author": "F. Necati Catbas and Masoud Malekzadeh", 
        "keyword": "Maintenance monitoring\", \"Machine-learning\", \"Massive \\{SHM\\} data\", \"Robust regression analysis\", keywords =Movable bridge\", \"Damage detection", 
        "title": "A machine learning-based algorithm for processing massive data collected from the mechanical components of movable bridges"
    }, 
    {
        "abstract": "Abstract Epilepsy, one of the most common neurological disorders of the human brain, is unpredictable and irregular. There is much difficulty involved in its detection. Here, a sequential processing feature extraction method and a novel multiplicative extreme learning machine are proposed for using in the electroencephalogram (EEG) classification process towards epileptic seizure detection. Firstly, a discrete wavelet transform (DWT) algorithm based on the frequency decomposition is used to obtain the sub-band wavelet coefficients. Secondly, two-dimensional (2D) and three-dimensional (3D) phase space reconstruction (PSR) of the sub-band are calculated to reveal the nonlinear chaos characteristics of signals in the high dimension. Thirdly, and differing from other statistical methods, the singular values are calculated based on the covariance matrix of 2D or 3D phase space as features that reduce the correlation of each dimension and which demonstrate the crucial variance in the original \\{EEG\\} signals. A combination of the proposed sequential methods can extract the significant features of epileptic seizure signals for classification. Finally, a novel multiplicative extreme learning machine (M-ELM) is proposed for using in the classification process. As compared with the normal ELM, support vector machine (SVM) with different kernels and backpropagation (BP) neural networks, the use of M-ELM can further improve the classification accuracy rate of the seizure signals, seizure free signals and healthy signals from the public dataset. Tests of the proposed epilepsy detection approach can achieve the highest 100% detection accuracy with rapid calculation speed.", 
        "author": "Dazi Li and Qianwen Xie and Qibing Jin and Kotaro Hirasawa", 
        "keyword": "Discrete Wavelet Transforms (DWT)\", \"Phase Space Reconstruction (PSR)\", \"Singular values of keywords =ovariance matrix\", \"Multiplicative extreme learning machine\", \"Epileptic seizure detection", 
        "title": "A sequential method using multiplicative extreme learning machine for epileptic seizure detection"
    }, 
    {
        "abstract": "Abstract Kernel based extreme learning machine (K-ELM) has better generalization performance than basic \\{ELM\\} with less tuned parameters in most applications. However the original K-ELM is lack of sparseness, which makes the model scale grows linearly with sample size. This paper focuses on sparsity of K-ELM and proposes recursive reduced kernel based extreme learning machine (RR-KELM). The proposed algorithm chooses samples making more contribution to target function to constitute kernel dictionary meanwhile considering all the constraints generated by the whole training set. As a result it can simplify model structure and realize sparseness of K-ELM. Experimental results on benchmark datasets show that no matter for regression or classification problems, RR-KELM produces more compact model structure and higher real-time in comparison with other methods. The application of RR-KELM for aero-engine fault pattern recognition is also given in this paper. The simulation results demonstrate that RR-KELM has a high recognition rate on aero-engine fault pattern based on measurable parameters of aero-engine.", 
        "author": "Cheng-Xin You and Jin-Quan Huang and Feng Lu", 
        "keyword": "Extreme learning machine\", \"Kernel method\", \"Sparseness\", \"Reduced technique\", \"Aero-engine\", \"Fault pattern recognition", 
        "title": "Recursive reduced kernel based extreme learning machine for aero-engine fault pattern recognition"
    }, 
    {
        "abstract": "Abstract The research presented in this paper shows an adaptive approach for long-term thermal error compensation of 5-axis machine tools (MT). A system of differential equations is used to compute the model based compensation values. The model can predict thermal displacements of the tool center point (TCP) based on changes in the environmental temperature, load-dependent changes and boundary condition changes and states, like machining with or without cutting fluid. The model based compensation of the rotary axis of a 5-axis \\{MT\\} is then extended by on-machine measurements. The information gained by the process-intermittent probing is used to adaptively update the model parameters, so that the model learns how to predict thermal position and orientation errors and to maintain a small residual error of the thermally induced errors of the rotary axis over a long time. This approach not only increases the \\{MT\\} accuracy but also reduces the amount of time spent on preproduction model parameter identification. Additionally an algorithm has been developed to dynamically adjust the length of the on-machine measurement intervals to maintain a high productivity and a constant deviation of the machined parts. Experimental results confirm that the adaptive learning control (ALC) for thermal errors shows a desirable long-term prediction accuracy.", 
        "author": "Philip Blaser and Florentina Pavli\u010dek and Kotaro Mori and Josef Mayr and Sascha Weikert and Konrad Wegener", 
        "keyword": "Machine tool\", \"Thermal error\", \"Compensation\", \"Adaptive control\", \"On-machine measurement", 
        "title": "Adaptive learning control for thermal error compensation of 5-axis machine tools"
    }, 
    {
        "abstract": "Abstract To explore the driving forces behind deformation twinning in Mg AZ31, a machine learning framework is utilized to mine data obtained from electron backscatter diffraction (EBSD) scans in order to extract correlations in physical characteristics that cause twinning. The results are intended to inform physics-based models of twin nucleation and growth. A decision tree learning environment is selected to capture the relationships between microstructure and twin formation; this type of model effectively highlights the more influential characteristics of the local microstructure. Trees are assembled to analyze both twin nucleation in a given grain, and twin propagation across grain boundaries. Each model reveals a unique combination of crystallographic attributes that affect twinning in the Mg. Twin nucleation is found to be mostly controlled by a combination of grain size, basal Schmid factor, and bulk dislocation density while twin propagation is affected most by grain boundary length, basal Schmid factor, angle from grain boundary plane to the \\{RD\\} plane, and grain boundary misorientation. The machine learning framework can be readily adapted to investigate other relationships between microstructure and material response.", 
        "author": "Andrew D. Orme and Isaac Chelladurai and Travis M. Rampton and David T. Fullwood and Ali Khosravani and Michael P. Miles and Raja K. Mishra", 
        "keyword": "Magnesium AZ31\", \"Twin formation\", \"Machine learning\", \"Decision tree\", \"EBSD", 
        "title": "Insights into twinning in Mg AZ31: A combined \\{EBSD\\} and machine learning study"
    }, 
    {
        "abstract": "Abstract Numerical weather forecasts, such as meteorological forecasts of precipitation, are inherently uncertain. These uncertainties depend on model physics as well as initial and boundary conditions. Since precipitation forecasts form the input into hydrological models, the uncertainties of the precipitation forecasts result in uncertainties of flood forecasts. In order to consider these uncertainties, ensemble prediction systems are applied. These systems consist of several members simulated by different models or using a single model under varying initial and boundary conditions. However, a too wide uncertainty range obtained as a result of taking into account members with poor prediction skills may lead to underestimation or exaggeration of the risk of hazardous events. Therefore, the uncertainty range of model-based flood forecasts derived from the meteorological ensembles has to be restricted. In this paper, a methodology towards improving flood forecasts by weighting ensemble members according to their skills is presented. The skill of each ensemble member is evaluated by comparing the results of forecasts corresponding to this member with observed values in the past. Since numerous forecasts are required in order to reliably evaluate the skill, the evaluation procedure is time-consuming and tedious. Moreover, the evaluation is highly subjective, because an expert who performs it makes his decision based on his implicit knowledge. Therefore, approaches for the automated evaluation of such forecasts are required. Here, we present a semi-automated approach for the assessment of precipitation forecast ensemble members. The approach is based on supervised machine learning and was tested on ensemble precipitation forecasts for the area of the Mulde river basin in Germany. Based on the evaluation results of the specific ensemble members, weights corresponding to their forecast skill were calculated. These weights were then successfully used to reduce the uncertainties within rainfall-runoff simulations and flood risk predictions.", 
        "author": "Kristina Doycheva and Gordon Horn and Christian Koch and Andreas Schumann and Markus K\u00f6nig", 
        "keyword": "Precipitation forecast\", \"Supervised machine learning\", \"Pattern recognition\", \"Uncertainty", 
        "title": "Assessment and weighting of meteorological ensemble forecast members based on supervised machine learning with application to runoff simulations and flood warning"
    }, 
    {
        "abstract": "Abstract Precision medicine relies on an increasing amount of heterogeneous data. Advances in radiation oncology, through the use of \\{CT\\} Scan, dosimetry and imaging performed before each fraction, have generated a considerable flow of data that needs to be integrated. In the same time, Electronic Health Records now provide phenotypic profiles of large cohorts of patients that could be correlated to this information. In this review, we describe methods that could be used to create integrative predictive models in radiation oncology. Potential uses of machine learning methods such as support vector machine, artificial neural networks, and deep learning are also discussed.", 
        "author": "Jean-Emmanuel Bibault and Philippe Giraud and Anita Burgun", 
        "keyword": "Radiation oncology\", \"Big Data\", \"Predictive model\", \"Machine learning", 
        "title": "Big Data and machine learning in radiation oncology: State of the art and future prospects"
    }, 
    {
        "abstract": "Abstract Machine learning approaches are increasingly successful in image-based diagnosis, disease prognosis, and risk assessment. This paper highlights new research directions and discusses three main challenges related to machine learning in medical imaging: coping with variation in imaging protocols, learning from weak labels, and interpretation and evaluation of results.", 
        "author": "Marleen de Bruijne", 
        "keyword": "Machine learning\", \"Classification\", \"Computer aided diagnosis\", \"Transfer learning", 
        "title": "Machine learning approaches in medical image analysis: From detection to diagnosis"
    }, 
    {
        "abstract": "Abstract Inadequacy of spatial soil information is one of the limiting factors to making evidence-based decisions to improve food security and land management in the developing countries. Various digital soil mapping (DSM) techniques have been applied in many parts of the world to improve availability and usability of soil data, but less has been done in Africa, particularly in Tanzania and at the scale necessary to make farm management decisions. The Kilombero Valley has been identified for intensified rice production. However the valley lacks detailed and up-to-date soil information for decision-making. The overall objective of this study was to develop a predictive soil map of a portion of Kilombero Valley using \\{DSM\\} techniques. Two widely used decision tree algorithms and three sources of Digital Elevation Models (DEMs) were evaluated for their predictive ability. Firstly, a numerical classification was performed on the collected soil profile data to arrive at soil taxa. Secondly, the derived taxa were spatially predicted and mapped following \\{SCORPAN\\} framework using Random Forest (RF) and \\{J48\\} machine learning algorithms. Datasets to train the model were derived from legacy soil map, RapidEye satellite image and three DEMs: 1 arc SRTM, 30 m ASTER, and 12 m WorldDEM. Separate predictive models were built using each \\{DEM\\} source. Mapping showed that \\{RF\\} was less sensitive to the training set sampling intensity. Results also showed that predictions of soil taxa using 1 arc \\{SRTM\\} and 12 m WordDEM were identical. We suggest the use of \\{RF\\} algorithm and the freely available \\{SRTM\\} \\{DEM\\} combination for mapping the soils for the whole Kilombero Valley. This combination can be tested and applied in other areas which have relatively flat terrain like the Kilombero Valley.", 
        "author": "Boniface H.J. Massawe and Sakthi K. Subburayalu and Abel K. Kaaya and Leigh Winowiecki and Brian K. Slater", 
        "keyword": "Kilombero Valley\", \"Numerical classification\", \"Machine learning\", \"Soil mapping\", \"Decision tree keywords =nalysis\", \"DEM", 
        "title": "Mapping numerically classified soil taxa in Kilombero Valley, Tanzania using machine learning"
    }, 
    {
        "abstract": "Abstract Nowadays, data always have multiple representations, and a good feature representation usually leads to a good clustering performance. Existing multi-view clustering works generally integrate multiple complementary information to gain better clustering performance rather than relying on a single view. However, these works usually focus on the combination of information rather than improving the feature representation capability of each view. As a new method, extreme learning machine (ELM) has excellent feature representation capability, easy parameter selection, and promising performance in various clustering tasks. This paper proposes a novel multi-view clustering framework with \\{ELM\\} to further improve clustering performance, and implements three algorithms based on this framework. In this framework, the normalized features of each individual view are mapped onto a higher dimensional feature space by the \\{ELM\\} random mapping. Afterwards, the unsupervised multi-view clustering is performed in this feature space. Thus far, this is the first work on multi-view clustering with ELM. Numerous baseline methods on five real-world datasets are empirically compared to show the effectiveness of the proposed algorithms. As indicated, the proposed algorithms yield superior clustering performance when compared with several state-of-art multi-view clustering methods in recent literatures.", 
        "author": "Qiang Wang and Yong Dou and Xinwang Liu and Qi Lv and Shijie Li", 
        "keyword": "Multi-view clustering\", \"Unsupervised clustering\", \"Extreme learning machine", 
        "title": "Multi-view clustering with extreme learning machine"
    }, 
    {
        "abstract": null, 
        "author": "Sotirios A. Tsaftaris and Massimo Minervini and Hanno Scharr", 
        "keyword": "image processing\", \"machine learning\", \"plant phenotyping\", \"stress.", 
        "title": "Machine Learning for Plant Phenotyping Needs Image Processing"
    }, 
    {
        "abstract": "Abstract Iris recognition is one of the most promising fields in biometrics. Notwithstanding this, there are not so many research works addressing it by machine learning techniques. In this survey, we especially focus on recognition, and leave the detection and feature extraction problems in the background. However, the kind of features used to code the iris pattern may significantly influence the complexity of the methods and their performance. In other words, complexity affects learning, and iris patterns require relatively complex feature vectors, even if their size can be optimized. A cross-comparison of these two parameters, feature complexity vs. learning effectiveness, in the context of different learning algorithms, would require an unbiased common benchmark. Moreover, at present it is still very difficult to reproduce techniques and experiments due to the lack of either sufficient implementation details or reliable shared code.", 
        "author": "Maria De Marsico and Alfredo Petrosino and Stefano Ricciardi", 
        "keyword": "Biometrics\", \"Iris recognition\", \"Periocular recognition\", \"Machine learning", 
        "title": "Iris recognition through machine learning techniques: A survey"
    }, 
    {
        "abstract": "Abstract The grasslands of Western Jilin Province in China have experienced severe degradation during the last 50 years. Radial basis function neural networks (RBFNN) and support vector machines (SVM) were used to predict the carbon, nitrogen, and phosphorus contents of Leymus chinensis (L.\u00a0chinensis) and explore the degree of grassland degradation using the matter-element extension model. Both \\{RBFNN\\} and \\{SVM\\} demonstrated good prediction accuracy. The results indicated that there was severe degradation, as samples were mainly concentrated in the 3rd and 4th levels. The growth of L.\u00a0chinensis was shown to be limited by either nitrogen, phosphorus, or both during different stages of degradation. The soil chemistry changed noticeably as degradation aggravated, which represents a destabilization of L.\u00a0chinensis community homeostasis. Soil salinization aggravates soil nutrient loss and decreases the bioavailability of soil nutrients. This, along with the destabilization of C/N, C/P and N/P ratios, weakens the photosynthetic ability and productivity of L.\u00a0chinensis. This conclusion was supported by observations that L.\u00a0chinensis is gradually being replaced by a Chloris virgata, Puccinellia tenuiflora and Suaeda acuminate mixed community.", 
        "author": "Yuefen Li and Shuo Liang and Yiying Zhao and Wenbo Li and Yuejiao Wang", 
        "keyword": "Radial basis function neural networks\", \"Support vector machines\", \"Matter-element extension keywords =odel\", \"Ecological stoichiometry\", \"Degradation mechanism\", \"Western Jilin Province", 
        "title": "Machine learning for the prediction of L.\u00a0chinensis carbon, nitrogen and phosphorus contents and understanding of mechanisms underlying grassland degradation"
    }, 
    {
        "abstract": "Abstract This article discusses the application of machine learning for the analysis of medical images. Specifically: (i) We show how a special type of learning models can be thought of as automatically optimized, hierarchically-structured, rule-based algorithms, and (ii) We discuss how the issue of collecting large labelled datasets applies to both conventional algorithms as well as machine learning techniques. The size of the training database is a function of model complexity rather than a characteristic of machine learning methods.", 
        "author": "A. Criminisi", 
        "keyword": "Machine learning\", \"Decision forests\", \"Training data", 
        "title": "Machine learning for medical images analysis"
    }, 
    {
        "abstract": "Abstract Most transit agencies are trying to increase their ridership. To achieve this goal, they are looking to maintain or even improve their level of service. This is very hard, since traffic congestion is normally increasing. As a result, bus travel times are higher and less reliable, which makes harder to predict travel times and avoid bunching. Being able to accurately predict bus travel speeds and update this prediction with real-time information could improve the quality and reliability of the information given to users, and increase the effectiveness of control schemes. In this work we implement and compare different machine learning methods (Artificial Neural Networks, Support Vector Machines and Bayes Networks) to predict bus travel speeds using real-time information about traffic conditions. The proposed algorithms are compared against two common approaches used to predict travel speeds. In order to feed our models, we apply traffic shockwaves theory to select our predictors. The input data used in each model was the speed obtained and processed from \\{GPS\\} devices installed in each of the buses from Transantiago, the public transportation system from Santiago, Chile. Two types of speed were available: historical speed and a real-time speed, each for a given route segment and day period. Our results show that machine learning algorithms can outperform na\u00efve predictions that use either only historical data or only real-time data with a 10-min delay. In particular, the Artificial Neural Network (ANN) algorithm achieved the best results, obtaining improvements of up to 23% in the root mean square error (RMSE) compared with the best benchmark model, and up to 3.3% in the \\{RMSE\\} versus the second best machine learning algorithm studied. Moreover, we validated our hypothesis that real-time data helps improve the accuracy of predictions up to 35% in the RMSE.", 
        "author": "Nikolas Julio and Ricardo Giesen and Pedro Lizana", 
        "keyword": "Transit\", \"Public transport\", \"Transantiago\", \"Speed prediction\", \"Machine learning\", \"Statistical keywords =earning\", \"Real-time information\", \"Artificial neural networks\", \"Support vector machines\", \"Support vector regression", 
        "title": "Real-time prediction of bus travel speeds using traffic shockwaves and machine learning algorithms"
    }, 
    {
        "abstract": "Abstract One major limitation currently with studying street level urban design qualities for walkability is the often inconsistent and unreliable measures of streetscape features across different field surveyors even with costly training due to lack of more objective processes, which also make large scale study difficult. The recent advances in sensor technologies and digitization have produced a wealth of data to help research activities by facilitating improved measurements and conducting large scale analysis. This paper explores the potential of big data and big data analytics in the light of current approaches to measuring streetscape features. By applying machine learning algorithms on Google Street View imagery, we generated objectively three measures on visual enclosure. The results showed that sky areas were identified fairly well for the calculation of proportion of sky. The three visual enclosure measures were found to be correlated with pedestrian volume and Walk Score. This method allows large scale and consistent objective measures of visual enclosure that can be done reproducibly and universally applicable with readily available Google Street View imagery in many countries around the world to help test their association with walking behaviors.", 
        "author": "Li Yin and Zhenxin Wang", 
        "keyword": "Street design features\", \"Enclosure\", \"Walkability\", \"Machine learning", 
        "title": "Measuring visual enclosure for street walkability: Using machine learning algorithms and Google Street View imagery"
    }, 
    {
        "abstract": "Abstract Two different machine-learning techniques have been assessed and applied to define rule-based control strategies for a parallel hybrid midsize sport utility vehicle equipped with a diesel engine. Both methods include two phases: a clustering algorithm and a rule definition. In the first method, a homemade clustering algorithm is preliminarily run to generate the set of clusters, while the rules are identified by minimizing an objective function. In the second method, a genetic algorithm provides the optimal size of the clusters, while the associated rules are extracted from the results obtained with a benchmark optimizer. The controllers were tested over NEDC, 1015, \\{AMDC\\} and WLTP.", 
        "author": "Mattia Venditti", 
        "keyword": "Machine learning\", \"rule-based controller\", \"genetic algorithm\", \"dynamic programming", 
        "title": "Analysis of the Performance of Different Machine Learning Techniques for the Definition of Rule-based Control Strategies in a Parallel \\{HEV\\}"
    }, 
    {
        "abstract": "Abstract Sources of fecal indicator bacteria are difficult to identify in watersheds that are impacted by a variety of non-point sources. We developed a molecular source tracking test using the PhyloChip microarray that detects and distinguishes fecal bacteria from humans, birds, ruminants, horses, pigs and dogs with a single test. The multiplexed assay targets 9001 different 25-mer fragments of 16S rRNA genes that are common to the bacterial community of each source type. Both random forests and SourceTracker were tested as discrimination tools, with SourceTracker classification producing superior specificity and sensitivity for all source types. Validation with 12 different mammalian sources in mixtures found 100% correct identification of the dominant source and 84\u2013100% specificity. The test was applied to identify sources of fecal indicator bacteria in the Russian River watershed in California. We found widespread contamination by human sources during the wet season proximal to settlements with antiquated septic infrastructure and during the dry season at beaches during intense recreational activity. The test was more sensitive than common fecal indicator tests that failed to identify potential risks at these sites. Conversely, upstream beaches and numerous creeks with less reliance on onsite wastewater treatment contained no fecal signal from humans or other animals; however these waters did contain high counts of fecal indicator bacteria after rain. Microbial community analysis revealed that increased E.\u00a0coli and enterococci at these locations did not co-occur with common fecal bacteria, but rather co-varied with copiotrophic bacteria that are common in freshwaters with high nutrient and carbon loading, suggesting runoff likely promoted the growth of environmental strains of E.\u00a0coli and enterococci. These results indicate that machine-learning classification of PhyloChip microarray data can outperform conventional single marker tests that are used to assess health risks, and is an effective tool for distinguishing numerous fecal and environmental sources of pathogen indicators.", 
        "author": "Eric A. Dubinsky and Steven R. Butkus and Gary L. Andersen", 
        "keyword": "Microbial source tracking\", \"PhyloChip microarray\", \"Machine learning\", \"Fecal indicator bacteria\", keywords =Pathogen TMDL\", \"Microbial community analysis", 
        "title": "Microbial source tracking in impaired watersheds using PhyloChip and machine-learning classification"
    }, 
    {
        "abstract": "Abstract In order to model the drift of fiber optic gyroscope (FOG) efficiently, a novel multi-scale prediction method is proposed by utilizing signal decomposition. Analytical expression of thermally induced drift of \\{FOG\\} is given first, which forms our theoretical basis of multi-scale prediction. Newly proposed bounded \\{EEMD\\} is used to decompose drift signal into a series of stationary modes, and then an adaptive feature selection criterion is proposed to construct distinct sub-series. Extreme learning machine is used to train these sub-series respectively, and a hybrid model is then obtained by adding up all the sub-models. Experiments have shown that, compared with the state-of-the-art methods, the proposed method improves prediction accuracy by two orders and achieves much faster speed in training process.", 
        "author": "Xiyuan Chen and Bingbo Cui", 
        "keyword": "Fiber optics sensors\", \"Ensemble empirical mode decomposition\", \"Thermal effects\", \"Extreme learning machine", 
        "title": "Efficient modeling of fiber optic gyroscope drift using improved \\{EEMD\\} and extreme learning machine"
    }, 
    {
        "abstract": "Abstract This study represents one of the series applying computer-oriented processes and tools in digging for information, analysing data and finally extracting correlations and meaningful outcomes. In this context, binding energies could be used to model and predict the mass of loaded drugs in solid lipid nanoparticles after molecular docking of literature-gathered drugs using MOE\u00ae software package on molecularly simulated tripalmitin matrices using GROMACS\u00ae. Consequently, Gaussian processes as a supervised machine learning artificial intelligence technique were used to correlate the drugs\u2019 descriptors (e.g. M.W., x Log P, \\{TPSA\\} and fragment complexity) with their molecular docking binding energies. Lower percentage bias was obtained compared to previous studies which allows the accurate estimation of the loaded mass of any drug in the investigated solid lipid nanoparticles by just projecting its chemical structure to its main features (descriptors).", 
        "author": "Rania M. Hathout and Abdelkader A. Metwally", 
        "keyword": "Gaussian\", \"Lipid nanoparticles\", \"Machine learning\", \"Descriptors\", \"Docking\", \"Molecular keywords =ynamics\", \"Computational pharmaceutics", 
        "title": "Towards better modelling of drug-loading in solid lipid nanoparticles: Molecular dynamics, docking experiments and Gaussian Processes machine learning"
    }, 
    {
        "abstract": "Abstract This paper presents a novel design of interval type-2 fuzzy logic systems (IT2FLS) by utilizing the theory of extreme learning machine (ELM) for electricity load demand forecasting. \\{ELM\\} has become a popular learning algorithm for single hidden layer feed-forward neural networks (SLFN). From the functional equivalence between the \\{SLFN\\} and fuzzy inference system, a hybrid of fuzzy-ELM has gained attention of the researchers. This paper extends the concept of fuzzy-ELM to an \\{IT2FLS\\} based on \\{ELM\\} (IT2FELM). In the proposed design the antecedent membership function parameters of the \\{IT2FLS\\} are generated randomly, whereas the consequent part parameters are determined analytically by the Moore\u2013Penrose pseudo inverse. The \\{ELM\\} strategy ensures fast learning of the \\{IT2FLS\\} as well as optimality of the parameters. Effectiveness of the proposed design of \\{IT2FLS\\} is demonstrated with the application of forecasting nonlinear and chaotic data sets. Nonlinear data of electricity load from the Australian National Electricity Market for the Victoria region and from the Ontario Electricity Market are considered here. The proposed model is also applied to forecast Mackey-glass chaotic time series data. Comparative analysis of the proposed model is conducted with some traditional models such as neural networks (NN) and adaptive neuro fuzzy inference system (ANFIS). In order to verify the structure of the proposed design of \\{IT2FLS\\} an alternate design of \\{IT2FLS\\} based on Kalman filter (KF) is also utilized for the comparison purposes.", 
        "author": "Saima Hassan and Abbas Khosravi and Jafreezal Jaafar and Mojtaba Ahmadieh Khanesar", 
        "keyword": "Extreme learning machine\", \"Interval type-2 fuzzy logic systems\", \"Electricity load forecasting\", keywords =Learning algorithm\", \"Smart grid", 
        "title": "A systematic design of interval type-2 fuzzy logic system using extreme learning machine for electricity load demand forecasting"
    }, 
    {
        "abstract": "Abstract Without a doubt, the current commercial circumstance exists in a strong competition and is full of uncertainty. Managers focus on continuous effort for increasing profits and reducing cost in their organization. In the past two decades, the price of raw materials has fluctuated severely and steel plants found it hard to earn profits and keep the capacity normal. Whereas some steel plants reduced the overcapacity of production by revamping the blast furnace or cutting down the throughput, others tried to limit and eliminate unnecessary cost. However, these strategies have failed to keep pace with the frequent changes in the raw material prices and could not support the profit targets greatly. This study aims at addressing such concerns by proposing an extreme learning machine (ELM) to predict the major raw material price in steel plants. Typically, this paper focuses on integration of Grey Relation Analysis (GRA) with a hybrid forecasting model to forecast the cost of iron ore and coking coal that are majorly used in steel plants. Here we attempt to establish a dynamic cost system to forecast the manufacturing cost of end products and adjust the purchasing and production strategy. This forecasting model can offer an accurate and rapidly predicting result of raw material price. Managers can use this forecasting results to reconsider the purchasing of raw materials and adjust the pricing strategy to pursuit their company\u2019s profit targets.", 
        "author": "Tsung-Yin Ou and Chen-Yang Cheng and Po-Jung Chen and Chayun Perng", 
        "keyword": "Dynamic cost forecasting model\", \"Grey Relation Analysis\", \"Extreme learning machine\", \"Cold keywords =olling products\", \"Steel plant", 
        "title": "Dynamic cost forecasting model based on extreme learning machine - A case study in steel plant"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel hybrid approach for feature selection in two different relevant problems for marine energy applications: significant wave height ( H m 0 ) and wave energy flux (P) prediction. Specifically, a hybrid Grouping Genetic Algorithm \u2013 Extreme Learning Machine approach (GGA-ELM) is proposed, in such a way that the \\{GGA\\} searches for several subsets of features, and the \\{ELM\\} provides the fitness of the algorithm, by means of its accuracy on H m 0 or P prediction. Since the \\{GGA\\} was specifically created for problems involving a number of groups, the proposed algorithm may be used to evolve different groups of features in parallel, which may improve the performance of the predictions obtained. After the feature selection process with the GGA-ELM, the final results are given by an \\{ELM\\} and also by a Support Vector Machine, both working on the best \\{GGA\\} groups obtained. The performance of the proposed system has been tested in a real problem of H m 0 and P prediction at the Western coast of the USA, obtaining good results.", 
        "author": "L. Cornejo-Bueno and J.C. Nieto-Borge and P. Garc\u00eda-D\u00edaz and G. Rodr\u00edguez and S. Salcedo-Sanz", 
        "keyword": "Wave energy flux\", \"Marine energy\", \"Significant wave height\", \"Grouping genetic algorithm (GGA)\", keywords =Extreme Learning Machines\", \"Support vector machines", 
        "title": "Significant wave height and energy flux prediction for marine energy applications: A grouping genetic algorithm \u2013 Extreme Learning Machine approach"
    }, 
    {
        "abstract": "Abstract Shrinking size of transistors has enabled us to integrate more and more logic elements into \\{FPGA\\} chips leading to higher computing power. However, it also brings a serious concern to the leakage power dissipation of the \\{FPGA\\} devices. One of the major reasons for leakage power dissipation in \\{FPGA\\} is the utilization of prefetching technique to minimize the reconfiguration overhead (delay) in Partially Reconfigurable (PR) FPGAs. This technique creates delays between the reconfiguration and execution parts of a task, which may lead up to 38% leakage power of \\{FPGA\\} since the SRAM-cells containing reconfiguration information cannot be powered down. In this work, a resource management approach (RMA) containing scheduling, placement and post-placement stages has been proposed to address the aforementioned issue. In scheduling stage, a leakage-aware priority function is derived to cope with the leakage power. The placement stage uses a cost function that allows designers to determine the desired trade-off between performance and leakage-saving. The post-placement stage employs a heuristic approach to close the gaps between reconfiguration and execution of tasks, hence further reduce leakage waste. To further examine the trade-off between performance (schedule length) and leakage waste, we propose a framework to utilize the Genetic Algorithm (GA) for exploring the design space and obtaining Pareto optimal design points. Addressing the time-consuming limitation of GA, we apply Regression technique and Clustering algorithm to build predictive models for the Pareto fronts using a training task graph dataset. Experiments show that our approach can achieve large leakage savings for both synthetic and real-life applications with acceptable extended deadline. Furthermore, different variants of the proposed approach can reduce leakage power by 40\u201365% when compared to a performance-driven approach and by 15\u201343% when compared to state-of-the-art works. It\u2019s also proven that our Machine Learning Optimization framework can estimate the Pareto front for new coming task graphs 10x faster than well-established \\{GA\\} approach with only 10% degradation in quality.", 
        "author": "Nam Khanh Pham and Akash Kumar and Amit Kumar Singh and Mi Mi Aung Khin", 
        "keyword": "Scheduling\", \"Mapping\", \"Resource management\", \"Design space exploration\", \"Machine learning", 
        "title": "Leakage aware resource management approach with machine learning optimization framework for partially reconfigurable architectures"
    }, 
    {
        "abstract": "AbstractObjective After swallowing, the upper esophageal sphincter (UES) needs a certain amount of time to return from maximum pressure to the resting condition. Disturbances of sphincter function not only during the swallowing process but also in this phase of pressure restitution may lead to globus sensation or dysphagia. Since \\{UES\\} pressures do not decrease in a linear or asymptotic manner, it is difficult to determine the exact time when the resting pressure is reached, even when using high resolution manometry (HRM). To overcome this problem a Machine Learning model was established to objectively determine the \\{UES\\} restitution time (RT) and moreover to collect physiological data on sphincter function after swallowing. Methods and material HRM-data of 15 healthy participants performing 10 swallows each were included. After manual annotation of the \\{RT\\} interval by two swallowing experts, data were transferred to the Machine Learning model, which applied a sequence labeling modeling approach based on logistic regression to learn and objectivize the characteristics of all swallows. Individually computed \\{RT\\} values were then compared with the annotated values. Results Estimates of the \\{RT\\} were generated by the Machine Learning model for all 150 swallows. When annotated by swallowing experts mean \\{RT\\} of 11.16 s \u00b1 5.7 (SD) and 10.04 s \u00b1 5.74 were determined respectively, compared to model-generated values from 8.91 s \u00b1 3.71 to 10.87 s \u00b1 4.68 depending on model selection. The correlation score for the annotated \\{RT\\} of both examiners was 0.76 and 0.63 to 0.68 for comparison of model predicted values. Conclusions Restitution time represents an important physiologic swallowing parameter not previously considered in HRM-studies of the UES, especially since disturbances of \\{UES\\} restitution may increase the risk of aspiration. The data presented here show that it takes approximately 9 to 11 s for the \\{UES\\} to come to rest after swallowing. Based on maximal \\{RT\\} values, we demonstrate that an interval of 25\u201330 s in between swallows is necessary until the next swallow is initiated. This should be considered in any further HRM-studies designed to evaluate the characteristics of individual swallows. The calculation model enables a quick and reproducible determination of the time it takes for the \\{UES\\} to come to rest after swallowing (RT). The results of the calculation are partially independent of the input of the investigator. Adding more swallows and integrating additional parameters will improve the Machine Leaning model in the future. By applying similar models to other swallowing parameters of the pharynx and UES, such as the relaxation time of the \\{UES\\} or the activity time during swallowing, a complete automatic evaluation of HRM-data of a swallow should be possible.", 
        "author": "Michael Jungheim and Andre Busche and Simone Miller and Nicolas Schilling and Lars Schmidt-Thieme and Martin Ptok", 
        "keyword": "High resolution manometry\", \"Upper esophageal sphincter\", \"Deglutition\", \"Dysphagia\", \"Restitution keywords =ime\", \"Machine learning model", 
        "title": "Calculation of upper esophageal sphincter restitution time from high resolution manometry data using machine learning"
    }, 
    {
        "abstract": "Abstract Feature subset selection (FSS) has been an active area of research in machine learning. A number of techniques have been developed for selecting an optimal or sub-optimal subset of features, because it is a major factor to determine the performance of a machine-learning technique. In this paper, we propose and develop a novel optimization technique, namely, a binary coordinate ascent (BCA) algorithm that is an iterative deterministic local optimization that can be coupled with wrapper or filter FSS. The algorithm searches throughout the space of binary coded input variables by iteratively optimizing the objective function in each dimension at a time. We investigated our \\{BCA\\} approach in wrapper-based \\{FSS\\} under area under the receiver-operating-characteristic (ROC) curve (AUC) criterion for the best subset of features in classification. We evaluated our BCA-based \\{FSS\\} in optimization of features for support vector machine, multilayer perceptron, and Na\u00efve Bayes classifiers with 12 datasets. Our experimental datasets are distinct in terms of the number of attributes (ranging from 18 to 11,340), and the number of classes (binary or multi-class classification). The efficiency in terms of the number of subset evaluations was improved substantially (by factors of 5\u201337) compared with two popular \\{FSS\\} meta-heuristics, i.e., sequential forward selection (SFS) and sequential floating forward selection (SFFS), while the classification performance for unseen data was maintained.", 
        "author": "Amin Zarshenas and Kenji Suzuki", 
        "keyword": "Machine learning\", \"Classification\", \"Feature selection\", \"Wrapper\", \"Optimization\", \"Heuristic", 
        "title": "Binary coordinate ascent: An efficient optimization technique for feature subset selection for machine learning"
    }, 
    {
        "abstract": "Abstract Monthly stream-flow forecasting can yield important information for hydrological applications including sustainable design of rural and urban water management systems, optimization of water resource allocations, water use, pricing and water quality assessment, and agriculture and irrigation operations. The motivation for exploring and developing expert predictive models is an ongoing endeavor for hydrological applications. In this study, the potential of a relatively new data-driven method, namely the extreme learning machine (ELM) method, was explored for forecasting monthly stream-flow discharge rates in the Tigris River, Iraq. The \\{ELM\\} algorithm is a single-layer feedforward neural network (SLFNs) which randomly selects the input weights, hidden layer biases and analytically determines the output weights of the SLFNs. Based on the partial autocorrelation functions of historical stream-flow data, a set of five input combinations with lagged stream-flow values are employed to establish the best forecasting model. A comparative investigation is conducted to evaluate the performance of the \\{ELM\\} compared to other data-driven models: support vector regression (SVR) and generalized regression neural network (GRNN). The forecasting metrics defined as the correlation coefficient (r), Nash-Sutcliffe efficiency (ENS), Willmott\u2019s Index (WI), root-mean-square error (RMSE) and mean absolute error (MAE) computed between the observed and forecasted stream-flow data are employed to assess the \\{ELM\\} model\u2019s effectiveness. The results revealed that the \\{ELM\\} model outperformed the \\{SVR\\} and the \\{GRNN\\} models across a number of statistical measures. In quantitative terms, superiority of \\{ELM\\} over \\{SVR\\} and \\{GRNN\\} models was exhibited by \\{ENS\\} = 0.578, 0.378 and 0.144, r = 0.799, 0.761 and 0.468 and \\{WI\\} = 0.853, 0.802 and 0.689, respectively and the \\{ELM\\} model attained lower \\{RMSE\\} value by approximately 21.3% (relative to SVR) and by approximately 44.7% (relative to GRNN). Based on the findings of this study, several recommendations were suggested for further exploration of the \\{ELM\\} model in hydrological forecasting problems.", 
        "author": "Zaher Mundher Yaseen and Othman Jaafar and Ravinesh C. Deo and Ozgur Kisi and Jan Adamowski and John Quilty and Ahmed El-Shafie", 
        "keyword": "Extreme learning machine\", \"Stream-flow forecasting\", \"Support vector regression\", \"Generalized keywords =egression neural network\", \"Semi-arid\", \"Iraq", 
        "title": "Stream-flow forecasting using extreme learning machines: A case study in a semi-arid region in Iraq"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has emerged as an efficient and effective learning algorithm for classification and regression tasks. Most of the existing research on the \\{ELMs\\} mainly focus on supervised learning. Recently, researchers have extended \\{ELMs\\} for semi-supervised learning, in which they exploit both the labeled and unlabeled data in order to enhance the learning performances. They have incorporated Laplacian regularization to determine the geometry of the underlying manifold. However, Laplacian regularization lacks extrapolating power and biases the solution towards a constant function. In this paper, we present a novel algorithm called Hessian semi-supervised \\{ELM\\} (HSS-ELM) to enhance the semi-supervised learning of ELM. Unlike the Laplacian regularization, the Hessian regularization that favors functions whose values vary linearly along the geodesic distance and preserves the local manifold structure well. This leads to good extrapolating power. Furthermore, HSS-ELM maintains almost all the advantages of the traditional \\{ELM\\} such as the significant training efficiency and straight forward implementation for multiclass classification problems. The proposed algorithm is tested on publicly available data sets. The experimental results demonstrate that our proposed algorithm is competitive with the state-of-the-art semi-supervised learning algorithms in term of accuracy. Additionally, HSS-ELM requires remarkably less training time compared to semi-supervised SVMs/regularized least-squares methods.", 
        "author": "Ganesh Krishnasamy and Raveendran Paramesran", 
        "keyword": "Extreme learning machine\", \"Semi-supervised learning\", \"Manifold learning\", \"Hessian regularization", 
        "title": "Hessian semi-supervised extreme learning machine"
    }, 
    {
        "abstract": "Abstract Computer vision and machine learning methods were applied to the challenge of automatic microstructure recognition. Here, a case study on dendritic morphologies was performed. Two classification tasks were completed, and involved distinguishing between micrographs that depict dendritic morphologies from those that do not contain this particular microstructural feature (Task 1), and from those micrographs identified as depicting dendrites, different cross-sectional views (longitudinal or transverse) were identified (Task 2). Data sets were comprised of images taken over a range of magnifications, from materials with different compositions and varying orientations of microstructural features. Feature extraction and dimensionality reduction were performed prior to training machine learning algorithms to classify microstructural image data. Visual bag of words, texture and shape statistics, and pre-trained convolutional neural networks (deep learning algorithms) were used for feature extraction. Classification was then performed using support vector machine, voting, nearest neighbors, and random forest models. For each model, classification was completed using full (original size) and reduced feature vectors for each feature extraction method tested. Performance comparisons were done to evaluate all possible combinations of feature extraction, selection, and classifiers for the task of micrograph classification. Results demonstrate that pre-trained neural networks represent microstructure image data well, and when used for feature extraction yield the highest classification accuracies for the majority of classifier and feature selection methods tested. Thus, deep learning algorithms can successfully be applied to micrograph recognition tasks. Maximum classification accuracies of 91.85 \u00b1 4.25% and 97.37 \u00b1 3.33% for Tasks 1 and 2 respectively, were achieved. This work is a broad investigation of computer vision and machine learning methods that acts as a step towards applying these established methods to more sophisticated materials recognition or characterization tasks. The approach presented here could offer improvements over established stereological measurements by removing the requirement of expert knowledge (bias) for interpretation of image data prior to characterization.", 
        "author": "Aritra Chowdhury and Elizabeth Kautz and B\u00fclent Yener and Daniel Lewis", 
        "keyword": "Microstructure\", \"Computer vision\", \"Machine learning\", \"Classification\", \"Convolutional neural keywords =etworks\", \"Micrograph", 
        "title": "Image driven machine learning methods for microstructure recognition"
    }, 
    {
        "abstract": "Abstract Machine learning methods have been widely used in recent years for detection of neuroimaging biomarkers in regions of interest (ROIs) and assisted diagnosis of neurodegenerative diseases. The innovation of this study is to use multilevel-ROI-features-based machine learning method to detect sensitive morphometric biomarkers in Parkinson\u2019s disease (PD). Specifically, the low-level \\{ROI\\} features (gray matter volume, cortical thickness, etc.) and high-level correlative features (connectivity between ROIs) are integrated to make the multilevel \\{ROI\\} features. Filter- and wrapper- based feature selection methods and multi-kernel support vector machine (SVM) are used in the classification algorithm. T1-weighted brain magnetic resonance (MR) images of 69 \\{PD\\} patients and 103 normal controls from the Parkinson\u2019s Progression Markers Initiative (PPMI) dataset are included in the study. The machine learning method performs well in classification between \\{PD\\} patients and normal controls with an accuracy of 85.78%, a specificity of 87.79%, and a sensitivity of 87.64%. The most sensitive biomarkers between \\{PD\\} patients and normal controls are mainly ROI-based features in frontal lobe, parental lobe, limbic lobe, temporal lobe, and central region. The classification performance of our method with multilevel \\{ROI\\} features is significantly improved compared with other classification methods: using single-level features. The proposed method shows promising identification ability for detecting morphometric biomarkers in PD, thus confirming the potentiality of this method in assisted diagnosis of the disease.", 
        "author": "Bo Peng and Suhong Wang and Zhiyong Zhou and Yan Liu and Baotong Tong and Tao Zhang and Yakang Dai", 
        "keyword": "multilevel \\{ROI\\} features\", \"support vector machine (SVM)\", \"magnetic resonance imaging (MRI)\", \"Parkinson's disease", 
        "title": "A multilevel-ROI-features-based machine learning method for detection of morphometric biomarkers in Parkinson\u2019s disease"
    }, 
    {
        "abstract": "Abstract Changes in illumination will result in serious color difference evaluation error in the process of textile printing. In order to solve the problem, a novel illuminant estimation method based on kernel extreme learning machine (KELM) is proposed. Furthermore, a new efficient and low dimensional color feature extraction method based on Grey-Edge framework is adopted to replace the traditional high dimensional binary chromaticity histogram, which is used to represent the input data of KELM. The experiments show that the proposed color constancy method performs better than the traditional support vector regression (SVR) and basic extreme learning machine (ELM) based color constancy methods. Compared with \\{SVR\\} and ELM, the proposed method reduces the median and root mean square errors with approximately 6%, 11%, 43% and 48%, respectively.", 
        "author": "Zhiyu Zhou and Rui Xu and Dichong Wu and Zefei Zhu and Haiyan Wang", 
        "keyword": "Illumination correction\", \"Kernel extreme learning machine (KELM)\", \"Grey-Edge", 
        "title": "Illumination correction of dyeing products based on Grey-Edge and kernel extreme learning machine"
    }, 
    {
        "abstract": "Abstract Despite the online availability of data, analysis of this information in academic research is arduous. This article explores the application of supervised machine learning (SML) to overcome challenges associated with online data analysis. In \\{SML\\} classifiers are used to categorize and code binary data. Based on a case study of Dutch employees\u2019 work-related tweets, this paper compares the coding performance of three classifiers, Linear Support Vector Machine, Na\u00efve Bayes, and logistic regression. The performance of these classifiers is assessed by examining accuracy, precision, recall, the area under the precision-recall curve, and Krippendorf\u2019s Alpha. These indices are obtained by comparing the coding decisions of the classifier to manual coding decisions. The findings indicate that the Linear Support Vector Machine and Na\u00efve Bayes classifiers outperform the logistic regression classifier. This study also compared the performance of these classifiers based on stratified random samples and random samples of training data. The findings indicate that in smaller training sets stratified random training samples perform better than random training samples, in large training sets (n\u00a0=\u00a04000) random samples yield better results. Finally, the Linear Support Vector Machine classifier was trained with 4000 tweets and subsequently used to categorize 578,581 tweets obtained from 430 employees.", 
        "author": "Ward van Zoonen and Toni and G.L.A. van der Meer", 
        "keyword": "Twitter\", \"Supervised machine learning\", \"Communication research\", \"Content analysis", 
        "title": "Social media research: The application of supervised machine learning in organizational communication research."
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) is a promising model for training single-hidden layer feedforward networks (SLFNs) and has been widely used for classification. However, \\{ELM\\} faces the challenge of arbitrarily selected parameters, e.g., the network weights and hidden biases. Therefore, many efforts have been made to enhance the performance of ELM, such as using evolutionary algorithms to explore promising areas of the solution space. Although evolutionary algorithms can explore promising areas of the solution space, they are not able to locate global optimum efficiently. In this paper, we present a new Memetic Algorithm (MA)-based Extreme Learning Machine (M-ELM for short). M-ELM embeds the local search strategy into the global optimization framework to obtain optimal network parameters. Experiments and comparisons on 46 \\{UCI\\} data sets validate the performance of M-ELM. The corresponding results demonstrate that M-ELM significantly outperforms state-of-the-art \\{ELM\\} algorithms.", 
        "author": "Yongshan Zhang and Jia Wu and Zhihua Cai and Peng Zhang and Ling Chen", 
        "keyword": "Extreme Learning Machine\", \"Self-adaptive\", \"Memetic Algorithm\", \"Evolutionary Machine Learning\", \"Classification", 
        "title": "Memetic Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract Landslide susceptibility assessment of Uttarakhand area of India has been done by applying five machine learning methods namely Support Vector Machines (SVM), Logistic Regression (LR), Fisher's Linear Discriminant Analysis (FLDA), Bayesian Network (BN), and Na\u00efve Bayes (NB). Performance of these methods has been evaluated using the \\{ROC\\} curve and statistical index based methods. Analysis and comparison of the results show that all five landslide models performed well for landslide susceptibility assessment (AUC\u00a0=\u00a00.910\u20130.950). However, it has been observed that the \\{SVM\\} model (AUC\u00a0=\u00a00.950) has the best performance in comparison to other landslide models, followed by the \\{LR\\} model (AUC\u00a0=\u00a00.922), the \\{FLDA\\} model (AUC\u00a0=\u00a00.921), the \\{BN\\} model (AUC\u00a0=\u00a00.915), and the \\{NB\\} model (AUC\u00a0=\u00a00.910), respectively.", 
        "author": "Binh Thai Pham and Biswajeet Pradhan and Dieu Tien Bui and Indra Prakash and M.B. Dholakia", 
        "keyword": "Landslides susceptibility assessment\", \"Machine learning\", \"Uttarakhand\", \"India", 
        "title": "A comparative study of different machine learning methods for landslide susceptibility assessment: A case study of Uttarakhand area (India)"
    }, 
    {
        "abstract": null, 
        "author": "Fl\u00e1vio H.D. Ara\u00fajo and Andr\u00e9 M. Santana and Pedro de A. Santos Neto", 
        "keyword": "Classification\", \"Data mining\", \"Ensemble\", \"Prepaid health plans\", \"Machine learning", 
        "title": "Using machine learning to support healthcare professionals in making preauthorisation decisions"
    }, 
    {
        "abstract": "Abstract Recently, an increasing number of researchers have endeavored to develop practical tools for diagnosing patients with schizophrenia using machine learning techniques applied to \\{EEG\\} biomarkers. Although a number of studies showed that source-level \\{EEG\\} features can potentially be applied to the differential diagnosis of schizophrenia, most studies have used only sensor-level \\{EEG\\} features such as \\{ERP\\} peak amplitude and power spectrum for machine learning-based diagnosis of schizophrenia. In this study, we used both sensor-level and source-level features extracted from \\{EEG\\} signals recorded during an auditory oddball task for the classification of patients with schizophrenia and healthy controls. \\{EEG\\} signals were recorded from 34 patients with schizophrenia and 34 healthy controls while each subject was asked to attend to oddball tones. Our results demonstrated higher classification accuracy when source-level features were used together with sensor-level features, compared to when only sensor-level features were used. In addition, the selected sensor-level features were mostly found in the frontal area, and the selected source-level features were mostly extracted from the temporal area, which coincide well with the well-known pathological region of cognitive processing in patients with schizophrenia. Our results suggest that our approach would be a promising tool for the computer-aided diagnosis of schizophrenia.", 
        "author": "Miseon Shim and Han-Jeong Hwang and Do-Won Kim and Seung-Hwan Lee and Chang-Hwan Im", 
        "keyword": "Schizophrenia\", \"Event-related potential (ERP)\", \"Machine learning\", \"Source-level features\", \"Computer-aided diagnosis", 
        "title": "Machine-learning-based diagnosis of schizophrenia using combined sensor-level and source-level \\{EEG\\} features"
    }, 
    {
        "abstract": "AbstractIntroduction The performance limitation of \\{MRI\\} equipment and higher resolution demand of \\{NMR\\} images from radiologists have formed a strong contrast. Therefore, it is important to study the super resolution algorithm suitable for \\{NMR\\} images, using low costs software to replace the expensive equipment-updating. Methods and materials Firstly, a series of \\{NMR\\} images are obtained from original \\{NMR\\} images with original noise to the lowest resolution images with the highest noise. Then, based on extreme learning machine, the mapping relation model is constructed from lower resolution \\{NMR\\} images with higher noise to higher resolution \\{NMR\\} images with lower noise in each pair of adjacent images in the obtained image sequence. Finally, the optimal mapping model is established by the ensemble way to reconstruct the higher resolution \\{NMR\\} images with lower noise on the basis of original resolution \\{NMR\\} images with original noise. Experiments are carried out by 990111 \\{NMR\\} brain images in datasets NITRC, REMBRANDT, \\{RIDER\\} \\{NEURO\\} MRI, TCGA-GBM and TCGA-LGG. Results The performance of proposed method is compared with three approaches through 7 indexes, and the experimental results show that our proposed method has a significant improvement. Discussion Since our method considers the influence of the noise, it has 20 % higher in Peak-Signal-to-Noise-Ratio comparison. As our method is sensitive to details, and has a better characteristic retention, it has higher image quality upgrade of 15% in the additional evaluation. Finally, since extreme learning machine has a celerity learning speed, our method is 46.1% faster.", 
        "author": "Zhiqiong Wang and Junchang Xin and Zhongyang Wang and Shuo Tian and Xuejun Qiu", 
        "keyword": "Super-resolution\", \"Single image\", \"NMR\", \"Extreme learning machine", 
        "title": "Single \\{NMR\\} image super-resolution based on extreme learning machine"
    }, 
    {
        "abstract": "Abstract The past 20 years have seen a mushrooming growth of the field of computational neuroanatomy. Much of this work has been enabled by the development and refinement of powerful, high-dimensional image warping methods, which have enabled detailed brain parcellation, voxel-based morphometric analyses, and multivariate pattern analyses using machine learning approaches. The evolution of these 3 types of analyses over the years has overcome many challenges. We present the evolution of our work in these 3 directions, which largely follows the evolution of this field. We discuss the progression from single-atlas, single-registration brain parcellation work to current ensemble-based parcellation; from relatively basic mass-univariate t-tests to optimized regional pattern analyses combining deformations and residuals; and from basic application of support vector machines to generative-discriminative formulations of multivariate pattern analyses, and to methods dealing with heterogeneity of neuroanatomical patterns. We conclude with discussion of some of the future directions and challenges.", 
        "author": "Christos Davatzikos", 
        "keyword": "Computational neuroanatomy\", \"Pattern analysis\", \"Machine learning\", \"Brain image analysis", 
        "title": "Computational neuroanatomy using brain deformations: From brain parcellation to multivariate pattern analysis and machine learning"
    }, 
    {
        "abstract": "Abstract Sales forecasting has long been crucial for companies since it is important for financial planning, inventory management, marketing, and customer service. In this study, a novel clustering-based sales forecasting scheme that uses an extreme learning machine (ELM) and assembles the results of linkage methods is proposed. The proposed scheme first uses the K-means algorithm to divide the training sales data into multiple disjointed clusters. Then, for each cluster, the \\{ELM\\} is applied to construct a forecasting model. Finally, a test datum is assigned to the most suitable cluster identified according to the result of combining five linkage methods. The constructed \\{ELM\\} model corresponding to the identified cluster is utilized to perform the final prediction. Two real sales datasets of computer servers collected from two multinational electronics companies are used to illustrate the proposed model. Empirical results showed that the proposed clustering-based sales forecasting scheme statistically outperforms eight benchmark models, and hence demonstrates that the proposed approach is an effective alternative for sales forecasting.", 
        "author": "Chi-Jie Lu and Ling-Jing Kao", 
        "keyword": "Sales forecasting\", \"Clustering\", \"Ensemble learning\", \"Linkage method\", \"Extreme learning keywords =achine\", \"Computer server", 
        "title": "A clustering-based sales forecasting scheme by using extreme learning machine and ensembling linkage methods with applications to computer server"
    }, 
    {
        "abstract": "Abstract Flood forecasting in natural rivers is a complicated procedure because of uncertainties involved in the behaviour of the flood wave movement. This leads to complex problems in hydrological modelling which have been widely solved by soft computing techniques. In real time flood forecasting, data generation is continuous and hence there is a need to update the developed mapping equation frequently which increases the computational burden. In short term flood forecasting where the accuracy of flood peak value and time to peak are critical, frequent model updating is unavoidable. In this paper, we studied a new technique: Online Sequential Extreme Learning Machine (OS-ELM) which is capable of updating the model equation based on new data entry without much increase in computational cost. The OS-ELM was explored for use in flood forecasting on the Neckar River, Germany. The reach was characterized by significant lateral flow that affected the flood wave formation. Hourly data from 1999\u20132000 at the upstream section of Rottweil were used to forecast flooding at the Oberndorf downstream site with a lead time of 1\u20136 h. Model performance was assessed by using three evaluation measures: the coefficient of determination (R2), the Nash-Sutcliffe efficiency coefficient (NS) and the root mean squared error (RMSE). The performance of the OS-ELM was comparable to those of other widely used Artificial Intelligence (AI) techniques like support vector machines (SVM), Artificial Neural Networks (ANN) and Genetic Programming (GP). The frequent updating of the model in OS-ELM gave a closer reproduction of flood events and peak values with minimum error compared to SVM, \\{ANN\\} and GP.", 
        "author": "Basant Yadav and Sudheer Ch and Shashi Mathur and Jan Adamowski", 
        "keyword": "Flood forecasting\", \"Extreme Learning Machine\", \"Artificial intelligence techniques", 
        "title": "Discharge forecasting using an Online Sequential Extreme Learning Machine (OS-ELM) model: A case study in Neckar River, Germany"
    }, 
    {
        "abstract": "Abstract Monitoring of the interface temperature at skin level in lower-limb prosthesis is notoriously complicated. This is due to the flexible nature of the interface liners used impeding the required consistent positioning of the temperature sensors during donning and doffing. Predicting the in-socket residual limb temperature by monitoring the temperature between socket and liner rather than skin and liner could be an important step in alleviating complaints on increased temperature and perspiration in prosthetic sockets. In this work, we propose to implement an adaptive neuro fuzzy inference strategy (ANFIS) to predict the in-socket residual limb temperature. \\{ANFIS\\} belongs to the family of fused neuro fuzzy system in which the fuzzy system is incorporated in a framework which is adaptive in nature. The proposed method is compared to our earlier work using Gaussian processes for machine learning. By comparing the predicted and actual data, results indicate that both the modeling techniques have comparable performance metrics and can be efficiently used for non-invasive temperature monitoring.", 
        "author": "Neha Mathur and Ivan Glesk and Arjan Buis", 
        "keyword": "ANFIS\", \"Fuzzy logic\", \"Gaussian process for machine learning\", \"Lower limb prosthetics\", keywords =Modeling\", \"Temperature", 
        "title": "Comparison of adaptive neuro-fuzzy inference system (ANFIS) and Gaussian processes for machine learning (GPML) algorithms for the prediction of skin temperature in lower limb prostheses"
    }, 
    {
        "abstract": "Abstract Analysis of the seabed composition over a large spatial scale is an interesting yet very challenging task. Apart from the field work involved, hours of video footage captured by cameras mounted on Remote Operated Vehicles (ROVs) have to be reviewed by an expert in order to classify the seabed topology and to identify potential anthropogenic impacts on sensitive benthic assemblages. Apart from being time consuming, such work is highly subjective and through visual inspection alone, a quantitative analysis is highly unlikely to be made. This study investigates the applicability of various Machine Learning techniques for the automatic classification of the seabed into maerl and sand regions from recorded \\{ROV\\} footage. \\{ROV\\} data collected from depths ranging between 50 m and 140 m and at 9.5 km from the northeast coastline of the Maltese Islands, is processed. Through the application of the presented technique, 5.23 \\{GB\\} of data corresponding to 2 h and 24 min of footage which was collected during June 2013, was initially cleaned and classified. An estimate for the percentage cover of the two benthic habitats (sandy seabed and maerl) was also computed by using artifacts encountered during the \\{ROV\\} survey and of known dimensions as a reference. Unlike other automatic seabed mapping techniques, the presented prototype processes video footage captured by a down-facing camera and not through acoustic backscatter. Image data is easier and much cheaper to capture. Promising results that indicate a very good degree of agreement between the true and predicted habitat type distribution values, were obtained.", 
        "author": "Adam Gauci and Alan Deidun and John Abela and Kristian Zarb Adami", 
        "keyword": "Machine Learning\", \"Image processing\", \"Seabed classification\", \"Decision trees\", \"Maerl keywords =etection\", \"Sand detection", 
        "title": "Machine Learning for benthic sand and maerl classification and coverage estimation in coastal areas around the Maltese Islands"
    }, 
    {
        "abstract": "Abstract Learning a classifier from groups of unlabeled data, only knowing, for each group, the proportions of data with particular labels, is an important branch of classification tasks that are conceivable in many practical applications. In this paper, we proposed a novel solution for the problem of learning with label proportions (LLP) based on nonparallel support vector machines, termed as proportion-NPSVM, which can improve the classifiers to be a pair of nonparallel classification hyperplanes. The unique property of our method is that it only needs to solve a pair of smaller quadratic programming problems. Moreover, it can efficiently incorporate the known group label proportions with the latent unknown observation labels into one optimization model under a large-margin framework. Compared to the existing approaches, there are several advantages shown as follows: 1) it does not need to make restrictive assumptions on the training data; 2) nonparallel classifiers can be achieved without computing the large inverse matrices; 3) the optimization model can be effectively solved by using the alternative strategy with \\{SMO\\} technique or \\{SOR\\} method; 4) proportion-NPSVM has better generalization ability. Sufficient experimental results on both binary-classes and multi-classes data sets show the efficiency of our proposed method in classification accuracy, which prove the state-of-the-art method for \\{LLP\\} problems compared with competing algorithms.", 
        "author": "Zhensong Chen and Zhiquan Qi and Bo Wang and Limeng Cui and Fan Meng and Yong Shi", 
        "keyword": "Learning with label proportion\", \"Nonparallel SVM\", \"Proportion-NPSVM\", \"Large-margin", 
        "title": "Learning with label proportions based on nonparallel support vector machines"
    }, 
    {
        "abstract": "Abstract Sleep staging is a significant step in the diagnosis and treatment of sleep disorders. Sleep scoring is a time-consuming and difficult process. Given that sleep scoring requires expert knowledge, it is generally undertaken by sleep experts. In this study, a new hybrid machine learning method consisting of complex-valued nonlinear features (CVNF) and a complex-valued neural network (CVANN) has been presented for automatic sleep scoring using single channel electroencephalography (EEG) signals. First of all, we should note that in this context, nine nonlinear features have been obtained as those are often preferred for the classification of \\{EEG\\} signals. These obtained features were then converted into a complex-valued number format using a phase encoding method. In this way, a new complex-valued feature set was obtained for sleep scoring. The obtained attributes have been presented as input to the \\{CVANN\\} algorithm. We have used a number of different statistical parameters during the evaluation process. The results that have been obtained are based on two sleep standards: Rechtschaffen &amp; Kales (R&amp;K) and American Academy of Sleep Medicine (AASM). Finally, a 91.57% accuracy rate was obtained according to R&amp;K standard; a 93.84% accuracy rate was obtained according to the \\{AASM\\} standard using the proposed method. We therefore observed that the proposed method is promising in terms of the sleep scoring.", 
        "author": "Musa Peker", 
        "keyword": "Machine learning\", \"EEG\", \"Complex-valued nonlinear features\", \"Complex-valued neural network\", \"Sleep scoring", 
        "title": "An efficient sleep scoring system based on \\{EEG\\} signal using complex-valued machine learning algorithms"
    }, 
    {
        "abstract": "Abstract Energy demand prediction is an important problem whose solution is evaluated by policy makers in order to take key decisions affecting the economy of a country. A number of previous approaches to improve the quality of this estimation have been proposed in the last decade, the majority of them applying different machine learning techniques. In this paper, the performance of a robust hybrid approach, composed of a Variable Neighborhood Search algorithm and a new class of neural network called Extreme Learning Machine, is discussed. The Variable Neighborhood Search algorithm is focused on obtaining the most relevant features among the set of initial ones, by including an exponential prediction model. While previous approaches consider that the number of macroeconomic variables used for prediction is a parameter of the algorithm (i.e., it is fixed a priori), the proposed Variable Neighborhood Search method optimizes both: the number of variables and the best ones. After this first step of feature selection, an Extreme Learning Machine network is applied to obtain the final energy demand prediction. Experiments in a real case of energy demand estimation in Spain show the excellent performance of the proposed approach. In particular, the whole method obtains an estimation of the energy demand with an error lower than 2%, even when considering the crisis years, which are a real challenge.", 
        "author": "J. S\u00e1nchez-Oro and A. Duarte and S. Salcedo-Sanz", 
        "keyword": "Energy demand estimation\", \"Variable Neighborhood Search\", \"Extreme Learning Machines\", \"Socio-economic predictive variables", 
        "title": "Robust total energy demand estimation with a hybrid Variable Neighborhood Search \u2013 Extreme Learning Machine algorithm"
    }, 
    {
        "abstract": "Abstract Cell morphology has been identified as a potential indicator of stem cell response to biomaterials. However, determination of cell shape phenotype in biomaterials is complicated by heterogeneous cell populations, microenvironment heterogeneity, and multi-parametric definitions of cell morphology. To associate cell morphology with cell-material interactions, we developed a shape phenotyping framework based on support vector machines. A feature selection procedure was implemented to select the most significant combination of cell shape metrics to build classifiers with both accuracy and stability to identify and predict microenvironment-driven morphological differences in heterogeneous cell populations. The analysis was conducted at a multi-cell level, where a \u201csupercell\u201d method used average shape measurements of small groups of single cells to account for heterogeneous populations and microenvironment. A subsampling validation algorithm revealed the range of supercell sizes and sample sizes needed for classifier stability and generalization capability. As an example, the responses of human bone marrow stromal cells (hBMSCs) to fibrous vs flat microenvironments were compared on day 1. Our analysis showed that 57\u00a0cells (grouped into supercells of size 4) are the minimum needed for phenotyping. The analysis identified that a combination of minor axis length, solidity, and mean negative curvature were the strongest early shape-based indicator of hBMSCs response to fibrous microenvironment.", 
        "author": "Desu Chen and Sumona Sarkar and Juli\u00e1n Candia and Stephen J. Florczyk and Subhadip Bodhak and Meghan K. Driscoll and Carl G. Simon Jr. and Joy P. Dunkers and Wolfgang Losert", 
        "keyword": "Cell morphology\", \"Machine learning\", \"Supercell\", \"Fibrous substrates\", \"Stem cell", 
        "title": "Machine learning based methodology to identify cell shape phenotypes associated with microenvironmental cues"
    }, 
    {
        "abstract": "Abstract Hypoglycemia is a very common in type 1 diabetic persons and can occur at any age. It is always threatening to the well-being of patients with Type 1 diabetes mellitus (T1DM) since hypoglycemia leads to seizures or loss of consciousness and the possible development of permanent brain dysfunction under certain circumstances. Because of that, an accurate continuing hypoglycemia monitoring system is a very important medical device for diabetic patients. In this paper, we proposed a non-invasive hypoglycemia monitoring system using the physiological parameters of electrocardiography (ECG) signal. To enhance the detection accuracy, extreme learning machine (ELM) is developed to recognize the presence of hypoglycemia. A clinical study of 16 children with \\{T1DM\\} is given to illustrate the good performance of ELM.", 
        "author": "Sai Ho Ling and Phyo Phyo San and Hung T. Nguyen", 
        "keyword": "Extreme learning machine\", \"Hypoglycemia\", \"Diabetes", 
        "title": "Non-invasive hypoglycemia monitoring system using extreme learning machine for Type 1 diabetes"
    }, 
    {
        "abstract": "Abstract This paper presents a fast algorithm and an accelerated toolbox11 https://github.com/akusok/elmvis for data visualization. The visualization is stated as an assignment problem between data samples and the same number of given visualization points. The mapping function is approximated by an Extreme Learning Machine, which provides an error for a current assignment. This work presents a new mathematical formulation of the error function based on cosine similarity. It provides a closed form equation for a change of error for exchanging assignments between two random samples (called a swap), and an extreme speed-up over the original method even for a very large corpus like the \\{MNIST\\} Handwritten Digits dataset. The method starts from random assignment, and continues in a greedy optimization algorithm by randomly swapping pairs of samples, keeping the swaps that reduce the error. The toolbox speed reaches a million of swaps per second, and thousands of model updates per second for successful swaps in \\{GPU\\} implementation, even for very large dataset like \\{MNIST\\} Handwritten Digits.", 
        "author": "Anton Akusok and Stephen Baek and Yoan Miche and Kaj-Mikael Bj\u00f6rk and Rui Nian and Paula Lauren and Amaury Lendasse", 
        "keyword": "Visualization\", \"Nonlinear Dimensionality Reduction\", \"Cosine Distance\", \"Extreme Learning keywords =achines\", \"Big Data\", \"Projection", 
        "title": "ELMVIS+: Fast nonlinear visualization technique based on cosine distance and extreme learning machines"
    }, 
    {
        "abstract": "Abstract In this paper, a meta-cognitive online sequential extreme learning machine (MOS-ELM) is proposed for class imbalance and concept drift learning. In MOS-ELM, meta-cognition is used to self-regulate the learning by selecting suitable learning strategies for class imbalance and concept drift problems. MOS-ELM is the first sequential learning method to alleviate the imbalance problem for both binary class and multi-class data streams with concept drift. In MOS-ELM, a new adaptive window approach is proposed for concept drift learning. A single output update equation is also proposed which unifies various application specific OS-ELM methods. The performance of MOS-ELM is evaluated under different conditions and compared with methods each specific to some of the conditions. On most of the datasets in comparison, MOS-ELM outperforms the competing methods.", 
        "author": "Bilal Mirza and Zhiping Lin", 
        "keyword": "Multi-class imbalance\", \"Concept drift\", \"Extreme learning machine\", \"Meta-cognition\", \"Sequential learning", 
        "title": "Meta-cognitive online sequential extreme learning machine for imbalanced and concept-drifting data classification"
    }, 
    {
        "abstract": "Abstract Smart grids are a promising solution to the rapidly growing power demand because they can considerably increase building energy efficiency. This study developed a novel time-series sliding window metaheuristic optimization-based machine learning system for predicting real-time building energy consumption data collected by a smart grid. The proposed system integrates a seasonal autoregressive integrated moving average (SARIMA) model and metaheuristic firefly algorithm-based least squares support vector regression (MetaFA-LSSVR) model. Specifically, the proposed system fits the \\{SARIMA\\} model to linear data components in the first stage, and the MetaFA-LSSVR model captures nonlinear data components in the second stage. Real-time data retrieved from an experimental smart grid installed in a building were used to evaluate the efficacy and effectiveness of the proposed system. A k-week sliding window approach is proposed for employing historical data as input for the novel time-series forecasting system. The prediction system yielded high and reliable accuracy rates in 1-day-ahead predictions of building energy consumption, with a total error rate of 1.181% and mean absolute error of 0.026 kW h. Notably, the system demonstrates an improved accuracy rate in the range of 36.8\u2013113.2% relative to those of the linear forecasting model (i.e., SARIMA) and nonlinear forecasting models (i.e., \\{LSSVR\\} and MetaFA-LSSVR). Therefore, end users can further apply the forecasted information to enhance efficiency of energy usage in their buildings, especially during peak times. In particular, the system can potentially be scaled up for using big data framework to predict building energy consumption.", 
        "author": "Jui-Sheng Chou and Ngoc-Tri Ngo", 
        "keyword": "Smart grid data\", \"Building energy management\", \"Energy consumption\", \"Pattern prediction\", keywords =Time-series technique\", \"Metaheuristic optimization\", \"Machine learning", 
        "title": "Time series analytics using sliding window metaheuristic optimization-based machine learning system for identifying building energy consumption patterns"
    }, 
    {
        "abstract": "Abstract The needs to ground construction safety-related decisions under uncertainty on knowledge extracted from objective, empirical data are pressing. Although construction research has considered machine learning (ML) for more than two decades, it had yet to be applied to safety concerns. We applied two state-of-the-art \\{ML\\} models, Random Forest (RF) and Stochastic Gradient Tree Boosting (SGTB), to a data set of carefully featured attributes and categorical safety outcomes, extracted from a large pool of textual construction injury reports via a highly accurate Natural Language Processing (NLP) tool developed by past research. The models can predict injury type, energy type, and body part with high skill (0.236 &lt; \\{RPSS\\} &lt; 0.436), outperforming the parametric models found in the literature. The high predictive skill reached suggests that injuries do not occur at random, and that therefore construction safety should be studied empirically and quantitatively rather than strictly being approached through the analysis of subjective data, expert opinion, and with a regulatory and managerial perspective. This opens the gate to a new research field, where construction safety is considered an empirically grounded quantitative science. Finally, the absence of predictive skill for the output variable injury severity suggests that unlike other safety outcomes, injury severity is mainly random, or that extra layers of predictive information should be used in making predictions, like the energy level in the environment. In the context of construction safety analysis, this study makes important strides in that the results provide reliable probabilistic forecasts of likely outcomes should an accident occur, and show great potential for integration with building information modeling and work packaging due to the binary and physical nature of the input variables. Such data-driven predictions had been absent from the field since its inception.", 
        "author": "Antoine J.-P. Tixier and Matthew R. Hallowell and Balaji Rajagopalan and Dean Bowman", 
        "keyword": "Machine learning\", \"Construction safety\", \"Predictive modeling\", \"Injury prevention\", \"Random keywords =orest\", \"Boosting\", \"Attribute", 
        "title": "Application of machine learning to construction injury prediction"
    }, 
    {
        "abstract": "Abstract Building energy conservation measures (ECMs) can significantly lower greenhouse gas (GHG) emissions from urban areas; however, uncertainties regarding not only \\{ECM\\} eligibility, but also associated costs and energy savings have slowed adoption of ECMs. To encourage \\{ECM\\} implementation, local governments have implemented a range of policies designed to increase the available information on building energy use. Energy audit mandates, such as New York City (NYC)\u2019s Local Law 87 (LL87), require energy consultants to analyze installed building systems and provide building stakeholders with cost effective \\{ECM\\} recommendations on a multi-year cycle. However, complete audits are costly and time consuming. To accelerate \\{ECM\\} implementation, policymakers are exploring ways to utilize available data to target \\{ECMs\\} across a city\u2019s entire building stock. In this study, energy audit data for over 1100 buildings in NYC, submitted in compliance with LL87, are analyzed to identify opportunities for \\{ECMs\\} across building system categories (e.g. distribution system, domestic hot water, etc.). A machine learning classifier, specifically a user-facing falling rule list (FRL) classifier based on binary features derived from \\{LL87\\} data, is developed here to predict \\{ECM\\} eligibility given a specific set of building characteristics. Overall, the trained \\{FRL\\} classifier performs well (ROC \\{AUC\\} 0.72\u20130.86) for predicting cooling system, distribution system, domestic hot water, fuel switching, lighting, and motors \\{ECM\\} opportunities, which represent a majority of the auditor-recommended \\{ECMs\\} in the sample. Additionally, linear decision lists developed by the model allow building stakeholders to easily conduct streamlined audits of building systems and identify possible \\{ECM\\} opportunities by limiting input to the most relevant factors and prioritizing likely retrofit candidates. The implications of this work are significant in accelerating the adoption of building \\{ECMs\\} and catalyzing energy use and \\{GHG\\} emissions reductions from buildings.", 
        "author": "Daniel E. Marasco and Constantine E. Kontokosta", 
        "keyword": "Building energy\", \"Energy retrofit\", \"Predictive modeling\", \"Machine learning\", \"Urban sustainability", 
        "title": "Applications of machine learning methods to identifying and predicting building retrofit opportunities"
    }, 
    {
        "abstract": "Abstract Herbal medicines are vigorously marketed, but poorly regulated. Analysis methodology for this field is still forming. One particular analytical task is confirmation of plant species identity for medicinal plants used as ingredients. In this work, machine learning approach has been implemented for LC\u2013MS plant species identification. Samples for 36 plant species have been analyzed. Peak data (m/z, abundance) from respective samples have been used for development of classification algorithms. Namely, logistic regression (LR), support vector machine (SVM) and random forest (RF) techniques were used. For most of used machine learning algorithms, classification accuracy of 95% higher were obtained on cross-validation dataset. Now, massive training datasets are needed for full-scale application of this approach.", 
        "author": "D.V. Nazarenko and P.V. Kharyuk and I.V. Oseledets and I.A. Rodin and O.A. Shpigun", 
        "keyword": "Plant species identification\", \"Liquid chromatography\u2013mass spectrometry\", \"Machine learning\", \"Multiclass classification", 
        "title": "Machine learning for LC\u2013MS medicinal plants identification"
    }, 
    {
        "abstract": "Abstract Light-intensity modulated (LIM) force sensors are seeing increasing interest in the field of surgical robotics and flexible systems in particular. However, such sensing modalities are notoriously susceptible to ambient effects such as temperature and environmental irradiance which can register as false force readings. We explore machine learning techniques to dynamically compensate for environmental biases that plague multi-axis optoelectronic force sensors. In this work, we fabricate a multisensor: three-axis \\{LIM\\} force sensor with integrated temperature and ambient irradiance sensing manufactured via a monolithic, origami-inspired fabrication process called printed-circuit MEMS. We explore machine learning regression techniques to compensate for temperature and ambient light sensitivity using on-board environmental sensor data. We compare batch-based ridge regression, kernelized regression and support vector techniques to baseline ordinary least-squares estimates to show that on-board environmental monitoring can substantially improve sensor force tracking performance and output stability under variable lighting and large (&gt;100 \u00b0C) thermal gradients. By augmenting the least-squares estimate with nonlinear functions describing both environmental disturbances and cross-axis coupling effects, we can reduce the error in Fx, Fy and Fz by 10%, 33%, and 73%, respectively. We assess viability of each algorithm tested in terms of both prediction accuracy and computational overhead, and analyze kernel-based regression for prediction in the context of online force feedback and haptics applications in surgical robotics. Finally, we suggest future work for fast approximation and prediction using stochastic, sparse kernel techniques.", 
        "author": "J. Gafford and F. Doshi-Velez and R. Wood and C. Walsh", 
        "keyword": "Light-intensity-modulation\", \"Force sensors\", \"Surgical robotics\", \"Machine learning\", \"Nonlinear regression", 
        "title": "Machine learning approaches to environmental disturbance rejection in multi-axis optoelectronic force sensors"
    }, 
    {
        "abstract": "Abstract Recent research has shown the speed advantage of extreme learning machine (ELM) and the accuracy advantage of sparse representation classification (SRC) in the area of image classification. Those two methods, however, have their respective drawbacks, e.g., in general, \\{ELM\\} is known to be less robust to noise while \\{SRC\\} is known to be time-consuming. Consequently, \\{ELM\\} and \\{SRC\\} complement each other in computational complexity and classification accuracy. In order to unify such mutual complementarity and thus further enhance the classification performance, we propose an efficient hybrid classifier to exploit the advantages of \\{ELM\\} and \\{SRC\\} in this paper. More precisely, the proposed classifier consists of two stages: first, an \\{ELM\\} network is trained by supervised learning. Second, a discriminative criterion about the reliability of the obtained \\{ELM\\} output is adopted to decide whether the query image can be correctly classified or not. If the output is reliable, the classification will be performed by ELM; otherwise the query image will be fed to SRC. Meanwhile, in the stage of SRC, a sub-dictionary that is adaptive to the query image instead of the entire dictionary is extracted via the \\{ELM\\} output. The computational burden of \\{SRC\\} thus can be reduced. Extensive experiments on handwritten digit classification, landmark recognition and face recognition demonstrate that the proposed hybrid classifier outperforms \\{ELM\\} and \\{SRC\\} in classification accuracy with outstanding computational efficiency.", 
        "author": "Jiuwen Cao and Kai Zhang and Minxia Luo and Chun Yin and Xiaoping Lai", 
        "keyword": "Extreme learning machine\", \"Sparse representation\", \"Image classification\", \"Leave-one-out cross validation", 
        "title": "Extreme learning machine and adaptive sparse representation for image classification"
    }, 
    {
        "abstract": "Abstract This paper introduces suitable features and methods to define hazard rate function by acoustic emission (AE) parametric analysis to develop robust damage statement index and reliability analysis. \\{AE\\} signal energy was first examined to find out the relation between damage progress and \\{AE\\} signal energy so that a damage index based on \\{AE\\} signal energy could be proposed to quantify progressive damage imposed to ferrocement composite slabs. Moreover, by using \\{AE\\} signal strength, historic index could be computed and utilized to develop a modified hazard rate function through integration of bathtub curve and Weibull function. Furthermore, to provide a practical scheme for real condition monitoring, support vector regression was utilized to produce a robust tools for failure prediction considering uncertainties exist in real structures.", 
        "author": "Arash Behnia and Navid Ranjbar and Hwa Kian Chai and Mahyar Masaeli", 
        "keyword": "Acoustic emission\", \"Bathtub curve\", \"Damage detection\", \"Reliability analysis\", \"Ferrocement keywords =labs\", \"Machine learning", 
        "title": "Failure prediction and reliability analysis of ferrocement composite structures by incorporating machine learning into acoustic emission monitoring technique"
    }, 
    {
        "abstract": "Abstract This article presents a comprehensive review of applications of data mining and machine learning for the prediction of biomedical properties of nanoparticles of medical interest. The papers reviewed here present the results of research using these techniques to predict the biological fate and properties of a variety of nanoparticles relevant to their biomedical applications. These include the influence of particle physicochemical properties on cellular uptake, cytotoxicity, molecular loading, and molecular release in addition to manufacturing properties like nanoparticle size, and polydispersity. Overall, the results are encouraging and suggest that as more systematic data from nanoparticles becomes available, machine learning and data mining would become a powerful aid in the design of nanoparticles for biomedical applications. There is however the challenge of great heterogeneity in nanoparticles, which will make these discoveries more challenging than for traditional small molecule drug design.", 
        "author": "David E. Jones and Hamidreza Ghandehari and Julio C. Facelli", 
        "keyword": "Nanomedicine\", \"Nanoinformatics\", \"Data mining\", \"Machine learning", 
        "title": "A review of the applications of data mining and machine learning for the prediction of biomedical properties of nanoparticles"
    }, 
    {
        "abstract": "Abstract The clustering problem has been considered one of the most relevant problems in the research area of unsupervised learning. However, the comprehension and definition of such clusters is not a trivial task, making necessary their identification, i.e., assign a label to each cluster. To address the problem of labelling clusters, this paper presents a methodology based on techniques for supervised learning, unsupervised learning and a discretization model. Thus, a method with unsupervised learning is applied to the clustering problem, and the supervised learning algorithm is responsible for detecting the meaningful attributes to define each formed cluster. Some strategies are used to form a methodology that presents a label (based on attributes and values) for each provided cluster. Such methodology is applied to three different databases, in which acceptable results were achieved with an average that exceeds 92.89% of correctly labelled elements.", 
        "author": "Lucas A. Lopes and Vinicius P. Machado and Ricardo A.L. Rab\u00ealo and Ricardo A.S. Fernandes and Bruno V.A. Lima", 
        "keyword": "Machine learning\", \"clustering\", \"labelling\", \"artificial neural networks", 
        "title": "Automatic labelling of clusters of discrete and continuous data with supervised machine learning"
    }, 
    {
        "abstract": "Abstract This study presents an extreme learning machine (ELM) approach, for estimating monthly reference evapotranspiration (ET0) in two weather stations in Serbia (Nis and Belgrade stations), for a 31-year period (1980\u20132010). The data set including minimum and maximum air temperatures, actual vapour pressure, wind speed and sunshine hours was employed for modelling \\{ET0\\} using the adjusted Hargreaves (ET0,AHARG), Priestley\u2013Taylor (ET0,PT) and Turc (ET0,T) equations. The reliability of the computational model was accessed based on simulation results and using five statistical tests including mean absolute percentage error (MAPE), mean absolute deviation (MAD), root-mean-square error (RMSE), Pearson correlation coefficient (r) and coefficient of determination (R2). The validity of \\{ELM\\} modelled \\{ET0\\} are compared with the FAO-56 Penman\u2013Monteith equation (ET0,PM) which is used as the reference model. For the Belgrade and Nis stations, the ET0,AHARG \\{ELM\\} model with \\{MAPE\\} = 9.353 and 10.299%, \\{MAD\\} = 0.142 and 0.151 mm/day, \\{RMSE\\} = 0.180 and 0.192 mm/day, r = 0.994 and 0.992, \\{R2\\} = 0.988 and 0.984 in testing period, was found to be superior in modelling monthly \\{ET0\\} than the other models, respectively.", 
        "author": "Milan Gocic and Dalibor Petkovi\u0107 and Shahaboddin Shamshirband and Amirrudin Kamsin", 
        "keyword": "Reference evapotranspiration\", \"Estimating\", \"Limited weather data\", \"Extreme learning machine\", \"Serbia", 
        "title": "Comparative analysis of reference evapotranspiration equations modelling by extreme learning machine"
    }, 
    {
        "abstract": "Abstract In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using data-driven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.", 
        "author": "Julia Ling and Reese Jones and Jeremy Templeton", 
        "keyword": "Machine learning\", \"Turbulence models\", \"Constitutive models\", \"Tensor invariants", 
        "title": "Machine learning strategies for systems with invariance properties"
    }, 
    {
        "abstract": "Abstract The fact that the linear estimators using the rank-based Wilcoxon approach in linear regression problems are usually insensitive to outliers is known in statistics. Outliers are the data points that differ greatly from the pattern set by the bulk of the data. Inspired by this fact, Hsieh et al. introduced the Wilcoxon approach into the area of machine learning. They investigated four new learning machines, such as Wilcoxon neural network (WNN), and developed four gradient descent based backpropagation algorithms to train these learning machines. The performances of these machines are better than ordinary nonrobust neural networks in outliers exist tasks. However, it is hard to balance the learning speed and the stability of these algorithms which is inherently the drawback of gradient descent based algorithms. In this paper, a new algorithm is used to train the output weights of single-layer feedforward neural networks (SLFN) with input weights and biases being randomly chosen. This algorithm is called Wilcoxon-norm based robust extreme learning machine or \\{WRELM\\} for short.", 
        "author": "Xiao-Liang Xie and Gui-Bin Bian and Zeng-Guang Hou and Zhen-Qiu Feng and Jian-Long Hao", 
        "keyword": "Extreme learning machine\", \"Wilcoxon neural network\", \"Wilcoxon-norm based robust extreme learning machine", 
        "title": "Preliminary study on Wilcoxon-norm-based robust extreme learning machine"
    }, 
    {
        "abstract": "Abstract Deep learning is recently regarded as the closest artificial intelligence model to human brain. It is about learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text. One deep model often consists of a hierarchical architecture that has the capability to model super non-linear and stochastic problems. Restricted Boltzmann Machine (RBM) is the main constructing block of current deep networks, as most of deep architectures are built with it. Based on MapReduce framework and Hadoop distributed file system, this paper proposes a distributed algorithm for training the \\{RBM\\} model. Its implementation and performance are evaluated on Big Data platform-Hadoop. The main contribution of the new learning algorithm is that it solves the scalability problem that limits the development of deep learning. The intelligence growing process of human brain requires learning from Big Data. The distributed learning mechanism for \\{RBM\\} makes it possible to abstract sophisticated and informative features from Big Data to achieve high-level intelligence. The evaluations of the proposed learning algorithm are carried out on image inpainting and classification problems based on the \\{BAS\\} dataset and \\{MNIST\\} hand-written digits dataset.", 
        "author": "Chun-Yang Zhang and C.L. Philip Chen and Dewang Chen and Kin Tek NG", 
        "keyword": "Deep learning\", \"Restricted Boltzmann Machine\", \"Big data\", \"MapReduce", 
        "title": "MapReduce based distributed learning algorithm for Restricted Boltzmann Machine"
    }, 
    {
        "abstract": "Abstract This study examines the effectiveness of state-of-the-art supervised machine learning methods in conjunction with different feature types for the task of automatic annotation of fragments of clinical text based on codebooks with a large number of categories. We used a collection of motivational interview transcripts consisting of 11,353 utterances, which were manually annotated by two human coders as the gold standard, and experimented with state-of-art classifiers, including Na\u00efve Bayes, \\{J48\\} Decision Tree, Support Vector Machine (SVM), Random Forest (RF), AdaBoost, DiscLDA, Conditional Random Fields (CRF) and Convolutional Neural Network (CNN) in conjunction with lexical, contextual (label of the previous utterance) and semantic (distribution of words in the utterance across the Linguistic Inquiry and Word Count dictionaries) features. We found out that, when the number of classes is large, the performance of \\{CNN\\} and \\{CRF\\} is inferior to SVM. When only lexical features were used, interview transcripts were automatically annotated by \\{SVM\\} with the highest classification accuracy among all classifiers of 70.8%, 61% and 53.7% based on the codebooks consisting of 17, 20 and 41 codes, respectively. Using contextual and semantic features, as well as their combination, in addition to lexical ones, improved the accuracy of \\{SVM\\} for annotation of utterances in motivational interview transcripts with a codebook consisting of 17 classes to 71.5%, 74.2%, and 75.1%, respectively. Our results demonstrate the potential of using machine learning methods in conjunction with lexical, semantic and contextual features for automatic annotation of clinical interview transcripts with near-human accuracy.", 
        "author": "Mehedi Hasan and Alexander Kotov and April Idalski Carcone and Ming Dong and Sylvie Naar and Kathryn Brogan Hartlieb", 
        "keyword": "Machine learning\", \"Deep learning\", \"Text classification\", \"Annotation of clinical text\", \"Motivational interviewing", 
        "title": "A study of the effectiveness of machine learning methods for classification of clinical interview fragments into a large number of categories"
    }, 
    {
        "abstract": "Abstract The restricted Boltzmann machine (RBM) is an essential constituent of deep learning, but it is hard to train by using maximum likelihood (ML) learning, which minimizes the Kullback\u2013Leibler (KL) divergence. Instead, contrastive divergence (CD) learning has been developed as an approximation of \\{ML\\} learning and widely used in practice. To clarify the performance of \\{CD\\} learning, in this paper, we analytically derive the fixed points where \\{ML\\} and \\{CD\\} n learning rules converge in two types of RBMs: one with Gaussian visible and Gaussian hidden units and the other with Gaussian visible and Bernoulli hidden units. In addition, we analyze the stability of the fixed points. As a result, we find that the stable points of \\{CD\\} n learning rule coincide with those of \\{ML\\} learning rule in a Gaussian\u2013Gaussian RBM. We also reveal that larger principal components of the input data are extracted at the stable points. Moreover, in a Gaussian\u2013Bernoulli RBM, we find that both \\{ML\\} and \\{CD\\} n learning can extract independent components at one of stable points. Our analysis demonstrates that the same feature components as those extracted by \\{ML\\} learning are extracted simply by performing \\{CD\\} 1 learning. Expanding this study should elucidate the specific solutions obtained by \\{CD\\} learning in other types of \\{RBMs\\} or in deep networks.", 
        "author": "Ryo Karakida and Masato Okada and Shun-ichi Amari", 
        "keyword": "Deep learning\", \"Restricted Boltzmann machine\", \"Contrastive divergence\", \"Component analysis\", \"Stability of learning algorithms", 
        "title": "Dynamical analysis of contrastive divergence learning: Restricted Boltzmann machines with Gaussian visible units"
    }, 
    {
        "abstract": null, 
        "author": "Ana Monsalve-Torra and Daniel Ruiz-Fernandez and Oscar Marin-Alonso and Antonio Soriano-Pay\u00e1 and Jaime Camacho-Mackenzie and Marisol Carre\u00f1o-Jaimes", 
        "keyword": "Machine learning\", \"Mortality prediction\", \"Abdominal aortic aneurysm\", \"Clinical decision support keywords =ystem\", \"Data analysis", 
        "title": "Using machine learning methods for predicting inhospital mortality in patients undergoing open repair of abdominal aortic aneurysm"
    }, 
    {
        "abstract": "Abstract As the significant branch of intelligent vehicle networking technology, the intelligent fatigue driving detection technology has been introduced into the paper in order to recognize the fatigue state of the vehicle driver and avoid the traffic accident. The disadvantages of the traditional fatigue driving detection method have been pointed out when we study on the traditional eye tracking technology and traditional artificial neural networks. On the basis of the image topological analysis technology, Haar like features and extreme learning machine algorithm, a new detection method of the intelligent fatigue driving has been proposed in the paper. Besides, the detailed algorithm and realization scheme of the intelligent fatigue driving detection have been put forward as well. Finally, by comparing the results of the simulation experiments, the new method has been verified to have a better robustness, efficiency and accuracy in monitoring and tracking the drivers' fatigue driving by using the human eye tracking technology.", 
        "author": "Chang Zheng and Ban Xiaojuan and Wang Yu", 
        "keyword": "Haar feature\", \"extreme learning machine\", \"fatigue driving detection", 
        "title": "Fatigue driving detection based on Haar feature and extreme learning machine"
    }, 
    {
        "abstract": "Abstract Recently, extreme learning machine (ELM) has become a popular topic in machine learning community. By replacing the so-called \\{ELM\\} feature mappings with the nonlinear mappings induced by kernel functions, two kernel ELMs, i.e., P-KELM and D-KELM, are obtained from primal and dual perspectives, respectively. Unfortunately, both P-KELM and D-KELM possess the dense solutions in direct proportion to the number of training data. To this end, a constructive algorithm for P-KELM (CCP-KELM) is first proposed by virtue of Cholesky factorization, in which the training data incurring the largest reductions on the objective function are recruited as significant vectors. To reduce its training cost further, PCCP-KELM is then obtained with the application of a probabilistic speedup scheme into CCP-KELM. Corresponding to CCP-KELM, a destructive P-KELM (CDP-KELM) is presented using a partial Cholesky factorization strategy, where the training data incurring the smallest reductions on the objective function after their removals are pruned from the current set of significant vectors. Finally, to verify the efficacy and feasibility of the proposed algorithms in this paper, experiments on both small and large benchmark data sets are investigated.", 
        "author": "Yong-Ping Zhao", 
        "keyword": "Extreme learning machine\", \"Kernel method\", \"Parsimoniousness\", \"Constructive algorithm\", \"Destructive algorithm", 
        "title": "Parsimonious kernel extreme learning machine in primal via Cholesky factorization"
    }, 
    {
        "abstract": "Abstract For remote sensing images, whose spectral signatures are intricate, the traditional edge detection methods cannot obtain satisfactory results. This paper takes the space computing capacity of Cellular Automata (CA) and the data pattern search ability of Extreme Learning Machine (ELM) into account and puts forward an Extreme Learning Machine based on Cellular Automata (ELM-CA) of edge detection for remote sensing images. This model can extract evolution rules of Cellular Automata. On the basis of the rules, false edges are removed and purer edge map is obtained. The result of the simulation experiment shows that the performance of the method suggested by this paper is much better compared to other edge detection arithmetic operators. It can prove that ELM-CA is an ideal method of remote sensing image edge detection.", 
        "author": "Min Han and Xue Yang and Enda Jiang", 
        "keyword": "Remote sensing image\", \"Edge detection\", \"Extreme Learning Machine\", \"Cellular Automata", 
        "title": "An Extreme Learning Machine based on Cellular Automata of edge detection for remote sensing images"
    }, 
    {
        "abstract": "Abstract This study proposes a novel classification system integrating swarm and metaheuristic intelligence, i.e., a smart firefly algorithm (SFA), with a least squares support vector machine (LSSVM). Benchmark functions were used to validate the optimization performance of the SFA. The experimental results showed that the \\{SFA\\} obtained 100% success rate in searching the optimum for most benchmark functions. The \\{SFA\\} was then integrated with the \\{LSSVM\\} to create a metaheuristic optimized classification model. A graphical user interface was developed for the proposed classification system to assist engineers and researchers in executing advanced machine learning tasks. The system was applied to several geotechnical engineering problems that involved measuring the groutability of sandy silt soil, monitoring seismic hazards in coal mines, predicting postearthquake soil liquefaction, and determining the propensity of slope collapse. The prediction problems in these studies were complex because they were dependent on various physical factors, and such factors exhibited highly nonlinear relations. The analytical results revealed that the metaheuristic optimization within machine learning-based classification system exhibited a groutability prediction accuracy of 95.42%, seismic prediction accuracy of 93.96%, soil liquefaction prediction accuracy of 95.18%, and soil collapse prediction accuracy of 95.45%. Hence, the proposed system is a promising tool to provide decision-makers with timely warnings of geotechnical hazards.", 
        "author": "Jui-Sheng Chou and Julian Pratama Putra Thedja", 
        "keyword": "Expert system\", \"Early warning\", \"Metaheuristic optimization\", \"Swarm intelligence\", \"Machine keywords =earning\", \"Classification\", \"Human\u2013machine interface\", \"Gehazards\", \"Geotechnical engineering", 
        "title": "Metaheuristic optimization within machine learning-based classification system for early warnings related to geotechnical problems"
    }, 
    {
        "abstract": "Abstract Recent advances in wireless and mobile computing have paved the way for an unprecedented demand growth for mobile services and applications. These services and applications communicate and exchange information using wireless local area networks (WLANs) and mobile ad hoc networks (MANETs). However, new design challenges emerge due to the error-proneness, self-organization and mobility nature of these networks. This paper proposes a neural learning-based solution to the problems associated with the mobility of \\{MANET\\} nodes where future changes in the network topology are efficiently predicted. Using synthetic and real-world mobility traces, the proposed predictor does not only outperform existing mobility prediction algorithms but achieves accuracy scores higher by an order of magnitude. The attained accuracy enables the proposed mobility predictor to improve the overall quality of service in MANETs.", 
        "author": "Lahouari Ghouti", 
        "keyword": "Mobility prediction\", \"Neural learning machines\", \"Mobility models\", \"Mobile ad hoc networks (MANETs)", 
        "title": "Mobility prediction in mobile ad hoc networks using neural learning machines"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has demonstrated great potential in machine learning owing to its simplicity, rapidity and good generalization performance. In this investigation, based on least-squares estimate (LSE) and least absolute deviation (LAD), we propose four sparse \\{ELM\\} formulations with zero-norm regularization to automatically choose the optimal hidden nodes. Furthermore, we develop two continuous optimization methods to solve the proposed problems respectively. The first is \\{DC\\} (difference of convex functions) approximation approach that approximates the zero-norm by a \\{DC\\} function, and the resulting optimizations are posed as \\{DC\\} programs. The second is an exact penalty technique for zero-norm, and the resulting problems are reformulated as \\{DC\\} programs, and the corresponding \\{DCAs\\} converge finitely. Moreover, the proposed framework is applied directly to recognize the hardness of licorice seeds using near-infrared spectral data. Experiments in different spectral regions illustrate that the proposed approaches can reduce the number of hidden nodes (or output features), while either improve or show no significant difference in generalization compared with the traditional \\{ELM\\} methods and support vector machine (SVM). Experiments on several benchmark data sets demonstrate that the proposed framework is competitive with the traditional approaches in generalization, but selects fewer output features.", 
        "author": "Liming Yang and Siyun Zhang", 
        "keyword": "Extreme learning machine\", \"Zero-norm\", \"DC programming\", \"Exact penalty technique\", \"Least keywords =bsolute deviation\", \"Hardness of licorice seeds", 
        "title": "A sparse extreme learning machine framework by continuous optimization algorithms and its application in pattern recognition"
    }, 
    {
        "abstract": "Abstract Genotype imputation is an important tool for prediction of unknown genotypes for both unrelated individuals and parent-offspring trios. Several imputation methods are available and can either employ universal machine learning methods, or deploy algorithms dedicated to infer missing genotypes. In this research the performance of eight machine learning methods: Support Vector Machine, K-Nearest Neighbors, Extreme Learning Machine, Radial Basis Function, Random Forest, AdaBoost, LogitBoost, and TotalBoost compared in terms of the imputation accuracy, computation time and the factors affecting imputation accuracy. The methods employed using real and simulated datasets to impute the un-typed \\{SNPs\\} in parent-offspring trios. The tested methods show that imputation of parent-offspring trios can be accurate. The Random Forest and Support Vector Machine were more accurate than the other machine learning methods. The TotalBoost performed slightly worse than the other methods.The running times were different between methods. The \\{ELM\\} was always most fast algorithm. In case of increasing the sample size, the \\{RBF\\} requires long imputation time.The tested methods in this research can be an alternative for imputation of un-typed \\{SNPs\\} in low missing rate of data. However, it is recommended that other machine learning methods to be used for imputation.", 
        "author": "Abbas Mikhchi and Mahmood Honarvar and Nasser Emam Jomeh Kashan and Mehdi Aminafshar", 
        "keyword": "Computation time\", \"Genotype imputation\", \"Imputation accuracy\", \"Machine learning methods", 
        "title": "Assessing and comparison of different machine learning methods in parent-offspring trios for genotype imputation"
    }, 
    {
        "abstract": "Abstract In propylene polymerization (PP) process, the melt index (MI) is one of the most important quality variables for determining different brands of products and different grades of product quality. Accurate prediction of \\{MI\\} is essential for efficient and professional monitoring and control of practical \\{PP\\} processes. This paper presents a novel soft sensor based on extreme learning machine (ELM) and modified gravitational search algorithm (MGSA) to estimate \\{MI\\} from real \\{PP\\} process variables, where the \\{MGSA\\} algorithm is developed to find the best parameters of input weights and hidden biases for ELM. As the comparative basis, the models of ELM, APSO-ELM and GSA-ELM are also developed respectively. Based on the data from a real \\{PP\\} production plant, a detailed comparison of the models is carried out. The research results show the accuracy and universality of the proposed model and it can be a powerful tool for online \\{MI\\} prediction.", 
        "author": "Miao Zhang and Xinggao Liu and Zeyin Zhang", 
        "keyword": "Propylene polymerization\", \"Melt index prediction\", \"Extreme learning machine\", \"Gravitational search algorithm", 
        "title": "A soft sensor for industrial melt index prediction based on evolutionary extreme learning machine"
    }, 
    {
        "abstract": "Abstract As the world\u2019s energy problem becomes more severe day by day, photovoltaic power generation has opened a new door for us with no doubt. It will provide an effective solution for this severe energy problem and meet human\u2019s needs for energy if we can apply photovoltaic power generation in real life, Similar to wind power generation, photovoltaic power generation is uncertain. Therefore, the forecast of photovoltaic power generation is very crucial. In this paper, entropy method and extreme learning machine (ELM) method were combined to forecast a short-term photovoltaic power generation. First, entropy method is used to process initial data, train the network through the data after unification, and then forecast electricity generation. Finally, the data results obtained through the entropy method with \\{ELM\\} were compared with that generated through generalized regression neural network (GRNN) and radial basis function neural network (RBF) method. We found that entropy method combining with \\{ELM\\} method possesses higher accuracy and the calculation is faster.", 
        "author": "Pingzhou Tang and Di Chen and Yushuo Hou", 
        "keyword": "Entropy method\", \"Extreme learning machine\", \"Photovoltaic power generation forecasting", 
        "title": "Entropy method combined with extreme learning machine method for the short-term photovoltaic power generation forecasting"
    }, 
    {
        "abstract": "Abstract Machine learning techniques represent the third-generation of clinical neuroimaging studies where the principal interest is not related to describe anatomical changes of a neurological disorder, but to evaluate if a multivariate approach may use these abnormalities to predict the correct classification of previously unseen clinical cohort. In the next few years, Machine learning will revolutionize clinical practice of Parkinson's disease, but enthusiasm should be turned down before removing some important barriers.", 
        "author": "Antonio Cerasa", 
        "keyword": "Parkinson's disease\", \"Machine learning\", \"Computer-based diagnosis\", \"Neuroimaging\", \"Clinical practice", 
        "title": "Machine learning on Parkinson's disease? Let's translate into clinical practice"
    }, 
    {
        "abstract": "Abstract Technical and quantitative analysis in financial trading use mathematical and statistical tools to help investors decide on the optimum moment to initiate and close orders. While these traditional approaches have served their purpose to some extent, new techniques arising from the field of computational intelligence such as machine learning and data mining have emerged to analyse financial information. While the main financial engineering research has focused on complex computational models such as Neural Networks and Support Vector Machines, there are also simpler models that have demonstrated their usefulness in applications other than financial trading, and are worth considering to determine their advantages and inherent limitations when used as trading analysis tools. This paper analyses the role of simple machine learning models to achieve profitable trading through a series of trading simulations in the \\{FOREX\\} market. It assesses the performance of the models and how particular setups of the models produce systematic and consistent predictions for profitable trading. Due to the inherent complexities of financial time series the role of attribute selection, periodic retraining and training set size are discussed in order to obtain a combination of those parameters not only capable of generating positive cumulative returns for each one of the machine learning models but also to demonstrate how simple algorithms traditionally precluded from financial forecasting for trading applications presents similar performances as their more complex counterparts. The paper discusses how a combination of attributes in addition to technical indicators that has been used as inputs of the machine learning-based predictors such as price related features, seasonality features and lagged values used in classical time series analysis are used to enhance the classification capabilities that impacts directly into the final profitability.", 
        "author": "Eduardo A. Gerlein and Martin McGinnity and Ammar Belatreche and Sonya Coleman", 
        "keyword": "Trading\", \"Financial forecasting\", \"Computer intelligence\", \"Data mining\", \"Machine learning\", \"FOREX markets", 
        "title": "Evaluating machine learning classification for financial trading: An empirical approach"
    }, 
    {
        "abstract": "Abstract Interbank Offered rate is the only direct market rate in China\u2019s currency market. Volatility forecasting of China Interbank Offered Rate (IBOR) has a very important theoretical and practical significance for financial asset pricing and financial risk measure or management. However, \\{IBOR\\} is a dynamics and non-steady time series whose developmental changes have stronger random fluctuation, so it is difficult to forecast the volatility of IBOR. This paper offers a hybrid algorithm using grey model and extreme learning machine (ELM) to forecast volatility of IBOR. The proposed algorithm is composed of three phases. In the first, grey model is used to deal with the original \\{IBOR\\} time series by accumulated generating operation (AGO) and weaken the stochastic volatility in original series. And then, a forecasting model is founded by using \\{ELM\\} to analyze the new \\{IBOR\\} series. Lastly, the predictive value of the original \\{IBOR\\} series can be obtained by inverse accumulated generating operation (IAGO). The new model is applied to forecasting Interbank Offered Rate of China. Compared with the forecasting results of \\{BP\\} and classical ELM, the new model is more efficient to forecasting short- and middle-term volatility of IBOR.", 
        "author": "Xiaoyong Liu and Hui Fu", 
        "keyword": "Nonlinear dynamics system\", \"Extreme learning machine\", \"Grey model\", \"Artificial neural network\", \"Volatility forecasting", 
        "title": "Volatility forecasting for interbank offered rate using grey extreme learning machine: The case of China"
    }, 
    {
        "abstract": "Abstract This paper compares the performance of five statistical models on the estimation of manufacturing cost of jet engine components, during the early design phase and using real industrial data. The analysis shows that recent techniques such as Gradient Boosted Trees and Support Vector Regression are up to two times more efficient than the ones typically encountered in the literature (Multiple Linear Regression and Artificial Neural Networks). If goodness-of-fit and predictive accuracy remain crucial to assess the performance of a model, other criteria such as computational cost, easiness to train or interpretability should be considered when selecting a statistical method for estimating the manufacturing cost of mechanical parts. Ideally, cost estimators should rely on several statistical models concurrently, as their distinct characteristics yield complementary views on the drivers of manufacturing cost. Finally, some engineering insights revealed by the statistical analysis are presented. They include the ranking and quantification of the most important cost drivers, the approximation of the economic production function of component cost according to accumulated production volume and a different view on the traditional breakdown of manufacturing cost of some jet engine components. As a conclusion, Machine Learning appears to be an effective, affordable, accurate and scalable technique to cost mechanical parts in the early stage of the design process.", 
        "author": "Jean-Loup Loyer and Elsa Henriques and Mihail Fontul and Steve Wiseall", 
        "keyword": "Machine Learning cost model\", \"Manufacturing cost\", \"Economic production function\", keywords =Design-to-cost\", \"Gradient boosted trees\", \"Support vector regression", 
        "title": "Comparison of Machine Learning methods applied to the estimation of manufacturing cost of jet engine components"
    }, 
    {
        "abstract": "Abstract Among many factors that influence the success of a software project, the software process model employed is an essential one. An improper process model will be time consuming, error-prone and cost expensive, and further lower the quality of software. Therefore, how to choose an appropriate software process model is a very important problem for software development. Current works focus on the selection criteria and often lead to subjective results. In this paper, we propose a software process model recommendation method, to help project managers choose the most appropriate software process model for a new project at an early stage of development process according to historical software engineering data. The proposed method casts the process model recommendation into a classification problem. It first evaluates the different combinations of the alternative classification and attribute selection algorithms, and the best one is used to build the recommendation model with historical software engineering data; then, the constructed recommendation model is used to predict process models for a new software project with only a few data. We also analyze the mutual impacts between process models and different types of project factors, to further help managers locate the most suitable process model. We found process models are also responsible for defect count, defect severity and software change. Experiments on the data sets from 37 different development teams of different countries show that the average recommendation accuracy of our method reaches up to 82.5%, which makes it potentially useful in practice.", 
        "author": "Qinbao Song and Xiaoyan Zhu and Guangtao Wang and Heli Sun and He Jiang and Chenhao Xue and Baowen Xu and Wei Song", 
        "keyword": "Software project management\", \"Software process model\", \"Model recommendation\", \"Impact analysis\", \"Machine learning", 
        "title": "A machine learning based software process model recommendation method"
    }, 
    {
        "abstract": "Abstract This paper compares the vapour ejector and electric vacuum pump power consumptions with machine learning algorithms by using real process data and presents some novelty guideline for the selection of an appropriate condenser vacuum pump system of a steam turbine power plant. The machine learning algorithms are made by using the supervised machine learning methods such as artificial neural network model and local linear neuro-fuzzy models. The proposed non-linear models are designed by using a wide range of real process operation data sets from the \\{CHP\\} system in the thermal power plant. The novelty guideline for the selection of an appropriate condenser vacuum pumps system is expressed in the comparative analysis of the energy consumption and use of specific energy capable of work. Furthermore, the novelty is expressed in the economic efficiency analysis of the investment taking into consideration the operating costs of the vacuum pump systems and may serve as basic guidelines for the selection of an appropriate condenser vacuum pump system of a steam turbine.", 
        "author": "Du\u0161an Stru\u0161nik and Milan Mar\u010di\u010d and Marjan Golob and Ale\u0161 Hribernik and Marija \u017divi\u0107 and Jurij Avsec", 
        "keyword": "Ejector\", \"Machine learning\", \"Mixing section\", \"Operating principle\", \"Thermodynamic analysis\", \"Vacuum pump", 
        "title": "Energy efficiency analysis of steam ejector and electric vacuum pump for a turbine condenser air extraction system based on supervised machine learning modelling"
    }, 
    {
        "abstract": "Abstract Learning Analytics (LA) has a major interest in exploring and understanding the learning process of humans and, for this purpose, benefits from both Cognitive Science, which studies how humans learn, and Machine Learning, which studies how algorithms learn from data. Usually, Machine Learning is exploited as a tool for analyzing data coming from experimental studies, but it has been recently applied to humans as if they were algorithms that learn from data. One example is the application of Rademacher Complexity, which measures the capacity of a learning machine, to human learning, which led to the formulation of Human Rademacher Complexity (HRC). In this line of research, we propose here a more powerful measure of complexity, the Human Algorithmic Stability (HAS), as a tool to better understand the learning process of humans. The experimental results from three different empirical studies, on more than 600 engineering students from the University of Genoa, showed that \\{HAS\\} (i) can be measured without the assumptions required by HRC, (ii) depends not only on the knowledge domain, as HRC, but also on the complexity of the problem, and (iii) can be exploited for better understanding of the human learning process.", 
        "author": "Mehrnoosh Vahdat and Luca Oneto and Davide Anguita and Mathias Funk and Matthias Rauterberg", 
        "keyword": "Machine learning\", \"Human learning\", \"Rademacher Complexity\", \"Algorithmic stability\", \"Exploratory experiments on students", 
        "title": "Can machine learning explain human learning?"
    }, 
    {
        "abstract": "Abstract This paper examines parallel machine scheduling with the objective of minimizing total completion time considering job splitting and learning. This study is motivated by real situations in labor-intensive industry, where learning effects take place and managers need to make decisions to split and assign orders to parallel production teams. Firstly, some analytical properties which are efficient at reducing complexity of the problem are presented. Utilizing the analytical property of the problem, a branch-and-bound algorithm which is efficient at solving small-sized problems is proposed. For the large-sized problems, several constructive heuristics and meta-heuristics are presented. Among them, the greedy search, which can take both the current profit and future cost after splitting a job into consideration, obtains a near-optimal solution for the small sized problems and performs best in all proposed heuristics for the large sized problems. Finally, extensive numerical experiments are conducted to test the performance of the proposed methods.", 
        "author": "Chenjie Wang and Changchun Liu and Zhi-hai Zhang and Li Zheng", 
        "keyword": "Parallel machine scheduling\", \"Job splitting\", \"Learning effect\", \"Branch-and-bound\", \"Greedy search", 
        "title": "Minimizing the total completion time for parallel machine scheduling with job splitting and learning"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is a recently proposed learning algorithm for single hidden layer feedfoward neural networks (SLFN) that achieved remarkable performances in various applications. In ELM, the hidden neurons are randomly assigned and the output layer weights are learned in a single step using the Moore-Penrose generalized inverse. This approach results in a fast learning neural network algorithm with a single hyperparameter (the number of hidden neurons). Despite the aforementioned advantages, using \\{ELM\\} can result in models with a large number of hidden neurons and this can lead to poor generalization. To overcome this drawback, we propose a novel method to prune hidden layer neurons based on genetic algorithms (GA). The proposed approach, referred as GAP-ELM, selects subset of the hidden neurons to optimize a multiobjective fitness function that defines a compromise between accuracy and the number of pruned neurons. The performance of GAP-ELM is assessed on several real world datasets and compared to other \\{SLFN\\} and a well known pruning method called Optimally Pruned \\{ELM\\} (OP-ELM). On the basis of our experiments, we can state that GAP-ELM is a valid alternative for classification tasks.", 
        "author": "Alisson S.C. Alencar and Ajalmar R. Rocha Neto and Jo\u00e3o Paulo P. Gomes", 
        "keyword": "Extreme learning machines\", \"Pruning methods\", \"Genetic algorithms", 
        "title": "A new pruning method for extreme learning machines via genetic algorithms"
    }, 
    {
        "abstract": "Abstract Video transcoding is to convert one compressed video stream to another. In this paper, a fast H.264/AVC to High Efficiency Video Coding (HEVC) transcoding method based on machine learning is proposed by considering the similarity between compressed streams, especially the block partition correlations, to reduce the computational complexity. This becomes possible by constructing three-level binary classifiers to predict quad-tree Coding Unit (CU) partition in HEVC. Then, we propose a feature selection algorithm to get representative features to improve predication accuracy of the classification. In addition, we propose an adaptive probability threshold determination scheme to achieve a good trade-off between low coding complexity and high compression efficiency during the \\{CU\\} depth prediction in HEVC. Extensive experimental results demonstrate the proposed transcoder achieves complexity reduction of 50.2% and 49.2% on average under lowdelay P main and random access configurations while the rate-distortion degradation is negligible. The proposed scheme is proved more effective as comparing with the state-of-the-art benchmarks.", 
        "author": "Linwei Zhu and Yun Zhang and Na Li and Gangyi Jiang and Sam Kwong", 
        "keyword": null, 
        "title": "Machine learning based fast H.264/AVC to \\{HEVC\\} transcoding exploiting block partition similarity"
    }, 
    {
        "abstract": "Abstract To reduce the large integration errors brought by traditional methods in gas flow measurement under complex flow field, artificial neural network, support vector machine and other intelligent algorithms have been put into use. But these intelligent methods consume much time for training and need intensive user intervention for network design. This paper proposes to apply extreme learning machine to multipath ultrasonic flowmeters, which can analytically determine the output weights of networks instead of error backpropagation algorithm and iterative tuning of the parameters, and therefore provide high metering accuracy at extremely fast learning speed as well as require least human intervention. To test its effectiveness under different flow field and sensitivity to complex flow profiles, extreme learning machine is applied to determine the flow rate under two piping configurations, which can produce mild and severe flow disturbances. The determination errors are compared with a traditional integration method on the position of 5D and 10D as well as with the path orientation of 0\u00b0 and 90\u00b0. Then 7 installation angles and 9 installation positions are respectively configured to study the performance and sensitivity of \\{UFMs\\} to installation effects. Finally, a comparison between extreme learning machine and other two intelligent algorithms is made in training and test time, the mean squared error and the maximal metering error under severe flow disturbance. It is found that extreme learning machine has rather high determination accuracy for flow rate at extremely fast learning speed and it is insensitive to the installation effects of ultrasonic gas flowmeter.", 
        "author": "Longhui Qin and Liang Hu and Kai Mao and Wenyu Chen and Xin Fu", 
        "keyword": "Ultrasonic gas flowmeter\", \"Extreme learning machine\", \"Numerical verification\", \"Installation keywords =ffects\", \"Artificial neural network\", \"Support vector machine", 
        "title": "Application of extreme learning machine to gas flow measurement with multipath acoustic transducers"
    }, 
    {
        "abstract": "AbstractObjectives This study assesses the ability of a novel, \u201cautomatic classification\u201d approach to facilitate identification of infants at highest familial risk for language-learning disorders (LLD) and to provide converging assessments to enable earlier detection of developmental disorders that disrupt language acquisition. Methods Network connectivity measures derived from 62-channel electroencephalogram (EEG) recording were used to identify selected features within two infant groups who differed on \\{LLD\\} risk: infants with a family history of \\{LLD\\} (FH+) and typically-developing infants without such a history (FH\u2212). A support vector machine was deployed; global efficiency and global and local clustering coefficients were computed. A novel minimum spanning tree (MST) approach was also applied. Cross-validation was employed to assess the resultant classification. Results Infants were classified with about 80% accuracy into FH+ and FH\u2212 groups with 89% specificity and precision of 92%. Clustering patterns differed by risk group and \\{MST\\} network analysis suggests that FH+ infants\u2019 \\{EEG\\} complexity patterns were significantly different from FH\u2212 infants. Conclusions The automatic classification techniques used here were shown to be both robust and reliable and should provide valuable information when applied to early identification of risk or clinical groups. Significance The ability to identify infants at highest risk for \\{LLD\\} using \u201cautomatic classification\u201d strategies is a novel convergent approach that may facilitate earlier diagnosis and remediation.", 
        "author": "Marzieh Zare and Zahra Rezvani and April A. Benasich", 
        "keyword": "Infant\", \"Machine learning\", \"Support vector machine (SVM)\", \"EEG\", \"Developmental language keywords =isorder\", \"Network analysis", 
        "title": "Automatic classification of 6-month-old infants at familial risk for language-based learning disorder using a support vector machine"
    }, 
    {
        "abstract": "Abstract Total organic carbon (TOC) is a critical parameter for source rock characterization in shale gas reservoirs. In this work, the use of extreme learning machines (ELM) for predicting \\{TOC\\} from well logs data have been investigated. We use log data from two wells located in an unconventional shale gas reservoir in the Sichuan Basin, China. Seven wireline logs from this well and a total of 185 \\{TOC\\} observations from core measurements were incorporated. Prediction accuracy of the model has been evaluated and compared with commonly used artificial neural network which is based on Levenberg-Marquardt logarithm (ANN-LM). An Extreme Learning Machine (ELM) network is a single hidden-layer feed-forward network with many advantages over multi-layer networks, such as fast computing speed and better generalization performance. The results demonstrated that \\{TOC\\} prediction by the \\{ELM\\} model and the \\{ANN\\} model, but the \\{ELM\\} method can achieve high accuracy while maintains high running speed. This study shows that \\{ELM\\} technology is a promising tool for \\{TOC\\} prediction, and this work can be incorporated into a software system that can be used in quick \u2018sweet spot\u2019 determination and well completion guidance.", 
        "author": "Xian Shi and Jian Wang and Gang Liu and Liu Yang and Xinmin Ge and Shu Jiang", 
        "keyword": "Organic shale\", \"Total organic carbon\", \"Extreme learning machine\", \"Well logs\", \"Artificial intelligence", 
        "title": "Application of extreme learning machine and neural networks in total organic carbon content prediction in organic shale with wire line logs"
    }, 
    {
        "abstract": "Abstract Parallel factor (PARAFAC) analysis of dissolved organic matter (DOM) fluorescence has facilitated a surge of investigation into its biogeochemical cycling. However, rigorous, PARAFAC-based methods for holistically distinguishing \\{DOM\\} sources are lacking. This study classified 1029 PARAFAC-analyzed excitation-emission matrices (EEMs) measured using \\{DOM\\} isolated from 24 different leaf leachates, rivers, and organic matter standards using four machine learning methods (MLM). \\{EEMs\\} were also divided into subsets to assess the impact of experimental treatments (i.e. whole EEMs, size fractionation, mixtures, quenching) and dataset properties (i.e. different numbers of \\{EEMs\\} from each leachate/river) on classification. A split-half validated, 10-component \\{PARAFAC\\} model was extended to 12 components to remove consistent peaks evident in model residuals. The 12-component model performed better than the 10-component model, correctly classifying up to 80 additional EEMs, when the dataset included size-fractionated \\{DOM\\} or several different sources (i.e. many leaf species and rivers); however, the 10-component model performed better for whole-sample \\{EEMs\\} when comparing leaf leachates to rivers. The \\{MLM\\} correctly classified whole \\{EEMs\\} of riverine \\{DOM\\} by source with up to 87.0% accuracy, leachates with up to 92.5% accuracy, and distinguished leachates from rivers with 97.2% accuracy. A difference of up to 17.3% in classification accuracy was observed depending on the \\{MLM\\} method used with the following order: multilayer perceptron\u00a0=\u00a0support vector machine\u00a0&gt;\u00a0k-nearest neighbours\u00a0\u226b\u00a0decision tree; however, performances differed widely depending on the data subset. Classification accuracy for whole and size-fractionated rivers compared to whole and size-fractionated leachates using N-way partial least-squares discriminant analysis (NPLS-DA; 97.7%) was similar to that achieved using MLM. Combining \\{MLM\\} with \\{PARAFAC\\} is an effective method for classifying \\{DOM\\} based on its fluorescence signature because \\{PARAFAC\\} can isolate meaningful fluorescent species and unlike PLSDA, \\{MLM\\} constructs a single model which simultaneously classifies \\{EEMs\\} as belonging to one of several categories. A complete accounting of carbon flows through ecosystems should include the processes and sources that contribute to the disparate fluorescence signatures of riverine and leached DOM.", 
        "author": "C.W. Cuss and S.M. McConnell and C. Gu\u00e9guen", 
        "keyword": "Parallel factor analysis (PARAFAC)\", \"Excitation-emission matrix (EEM)\", \"Data mining/machine keywords =earning\", \"Leaf leachate\", \"K-nearest neighbours (kNN)\", \"Dissolved organic matter (DOM)", 
        "title": "Combining parallel factor analysis and machine learning for the classification of dissolved organic matter according to source using fluorescence signatures"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) was proposed as a new efficient learning algorithm for single-hidden layer feedforward neural networks (SLFN) in recent years. It is featured by its much faster training speed and better generalization performance over traditional \\{SLFN\\} learning techniques. However, \\{ELM\\} cannot deal directly with incomplete data which widely exists in real-world applications. In this paper, we propose a new algorithm to handle incomplete data with voting based extreme learning machine (V-ELMI). V-ELMI did not rely on any assumptions about missing values. It first obtains a group of data subsets according to the missing values of the training set. Then, it applies mutual information to measure the importance degree of each data subsets. After that, it trains a group of subclassifiers on these data subsets by applying \\{ELM\\} as base learning algorithm. Finally, for a given test sample with missing values, V-ELMI selects the subclassifiers whose input did not require the missing values to predict it. And final prediction is determined by weighted majority voting according to the mean value of the norms of the output weights and the importance degree of each available subclassifier. Experimental results on 15 \\{UCI\\} incomplete datasets and 5 \\{UCI\\} complete datasets have shown that, V-ELMI generally has better performance than the algorithms compared. Moreover, compared with the classification algorithms based on neural network ensemble (NNE), V-ELMI can greatly improve algorithm computational efficiency.", 
        "author": "Yuan-Ting Yan and Yan-Ping Zhang and Jie Chen and Yi-Wen Zhang", 
        "keyword": "Incomplete data\", \"Extreme learning machine\", \"Mutual information\", \"Data subset\", \"Weighted majority voting", 
        "title": "Incomplete data classification with voting based extreme learning machine"
    }, 
    {
        "abstract": "Abstract Entity resolution (ER), an important and common data cleaning problem, is about detecting data duplicate representations for the same external entities, and merging them into single representations. Relatively recently, declarative rules called matching dependencies (MDs) have been proposed for specifying similarity conditions under which attribute values in database records are merged. In this work we show the process and the benefits of integrating four components of ER: (a) Building a classifier for duplicate/non-duplicate record pairs built using machine learning (ML) techniques; (b) Use of \\{MDs\\} for supporting the blocking phase of ML; (c) Record merging on the basis of the classifier results; and (d) The use of the declarative language LogiQL\u2014an extended form of Datalog supported by the LogicBlox platform\u2014for all activities related to data processing, and the specification and enforcement of MDs.", 
        "author": "Zeinab Bahmani and Leopoldo Bertossi and Nikolaos Vasiloglou", 
        "keyword": "Entity resolution\", \"Matching dependencies\", \"Support-vector machines\", \"Classification\", \"Datalog", 
        "title": "ERBlox: Combining matching dependencies with machine learning for entity resolution"
    }, 
    {
        "abstract": "Abstract Most common objectives in single-machine scheduling problems are minimize makespan, total completion time and total weighted completion time, respectively. In this paper, we consider single machine scheduling problems under position-dependent fuzzy learning effect with fuzzy processing times. Furthermore, we show that these three problems are polynomially solvable under position dependent fuzzy learning effect with fuzzy processing times. In order to model the uncertainty of fuzzy model parameters such as processing time and learning effect, we use an approach called as likelihood profile that dependent on the possibility and necessity measures of fuzzy parameters. For three objective functions, we build Fuzzy Mixed Integer Nonlinear Programming (FMINP) models those are dependent chance constrained programming technique for the same predetermined confidence levels. Furthermore, we present polynomially solvable algorithms for different confidence levels for these problems.", 
        "author": "Hamed Asadi", 
        "keyword": "Scheduling\", \"Fuzzy learning effect\", \"Fuzzy processing time\", \"Fuzzy mixed\", \"Integer nonlinear keywords =rogramming\", \"Likelihood profile\", \"Chance constrained programming", 
        "title": "Apply Fuzzy Learning Effect with Fuzzy Processing Times for Single Machine Scheduling Problems"
    }, 
    {
        "abstract": "Abstract Electronic spam is the most troublesome Internet phenomenon challenging large global companies, including AOL, Google, Yahoo and Microsoft. Spam causes various problems that may, in turn, cause economic losses. Spam causes traffic problems and bottlenecks that limit memory space, computing power and speed. Spam causes users to spend time removing it. Various methods have been developed to filter spam, including black list/white list, Bayesian classification algorithms, keyword matching, header information processing, investigation of spam-sending factors and investigation of received mails. This study describes three machine-learning algorithms to filter spam from valid emails with low error rates and high efficiency using a multilayer perceptron model. Several widely used techniques include C4.5 decision tree classifier, multilayer perceptron and Na\u00efve Bayes classifier, all of which are used for training data whether in the form of spam or valid emails. Finally, the results are discussed, and outputs of considered techniques are examined in relation to the proposed model.", 
        "author": "Ali Shafigh Aski and Navid Khalilzadeh Sourati", 
        "keyword": "Spam\", \"Header\", \"Machine learning\", \"Classifier", 
        "title": "Proposed efficient algorithm to filter spam using machine learning techniques"
    }, 
    {
        "abstract": "Abstract It is well known that the Leave-One-Out Cross-Validation (LOO-CV) is a highly reliable procedure in terms of model selection. Unfortunately, it is an extremely tedious method and has rarely been deployed in practical applications. In this paper, a highly efficient Leave-One-Out Cross-Validation (LOO-CV) formula has been developed and integrated with the popular Regularized Extreme Learning Machine (RELM). The main contribution of this paper is the proposed algorithm, termed as Efficient LOO-CV-based \\{RELM\\} (ELOO-RELM), that can effectively and efficiently update the LOO-CV error with every regularization parameter and automatically select the optimal model with limited user intervention. Rigorous analysis of computational complexity shows that the ELOO-RELM, including the tuning process, can achieve similar efficiency as the original \\{RELM\\} with pre-defined parameter, in which both scale linearly with the size of the training data. An early termination criterion is also introduced to further speed up the learning process. Experimentation studies on benchmark datasets show that the ELOO-RELM can achieve comparable generalization performance as the Support Vector Machines (SVM) with significantly higher learning efficiency. More importantly, comparing to the trial and error tuning procedure employed by the original RELM, the ELOO-RELM can provide more reliable results by the virtue of incorporating the LOO-CV procedure.", 
        "author": "Zhifei Shao and Meng Joo Er", 
        "keyword": "Extreme Learning Machine (ELM)\", \"Regularized \\{ELM\\} (RELM)\", \"Ridge regression\", \"LOO-CV\", \"Leave-One-Out Cross-Validation", 
        "title": "Efficient Leave-One-Out Cross-Validation-based Regularized Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract Door-to-door transportation service for elderly and persons with disabilities is often called dial-a-ride (DAR), and is usually provided by transit agencies through private contractors. Growth in \\{DAR\\} ridership is reported across the United States and this tendency will likely continue due to aging population. Such trends encourage development of models that can provide decision support in planning new \\{DAR\\} systems or expanding existing ones. Several statistical models were previously developed to predict the required \\{DAR\\} system capacity, given various characteristics of the service region, level-of-service requirements and operator constraints. Our work contributes to this line of research by proposing statistical and machine learning approaches that provide more accurate predictions over a wider range of scenarios. This is accomplished through transformation of variables and application of generalized linear model and support vector regression. Proposed models are built into an online tool that can help transit planners and policy makers: (a) estimate the capacity and operating cost of a \\{DAR\\} system needed to provide the desired level of service, (b) explore tradeoffs between system costs and levels of service, and (c) compare the cost of providing \\{DAR\\} service with other transportation alternatives (e.g., taxi, conventional transit).", 
        "author": "Nikola Markovi\u0107 and Myungseob (Edward) Kim and Paul Schonfeld", 
        "keyword": "Dial-a-ride\", \"Paratransit\", \"Planning\", \"Decision support system\", \"Statistics\", \"Machine learning", 
        "title": "Statistical and machine learning approach for planning dial-a-ride systems"
    }, 
    {
        "abstract": "Abstract Patients with thyroid disease (TD) boast continuously increasing because of excessive growth of thyroid gland and its hormones. Automatic classification tools may reduce the burden on doctors. This paper evaluates the selected algorithms for predicting thyroid disease diagnoses (TDD). The algorithms considered here are regularization methods (RM) of machine learning algorithms (MLA). The analysis report generated by the proposed work suggests the best algorithm for predicting the exact levels of TDD. This work is a comparative study of \\{MLA\\} on \\{UCI\\} thyroid datasets (UCITD). The developed system deals with \\{RM\\} i.e., ridge regression algorithm (RRA) &amp; least absolute shrinkage and selection operator algorithm (LASSO). The above algorithms personage produce at most 79% accuracy by \\{RRA\\} and 98.99% accuracy by LASSO. Thus, this paper shows the importance of LASSO, along with an example for parameter generation. The decisive factors (DF) also suggest the accuracy rate of \\{LASSO\\} is much better when compared with RRA.", 
        "author": "Vadamodula Prasad and T. Srinivasa Rao and P.V.G.D. Prasad Reddy", 
        "keyword": "Thyroid\", \"Ridge regression\", \"Machine learning\", \"Regularization method", 
        "title": "Improvised prophecy using regularization method of machine learning algorithms on medical data"
    }, 
    {
        "abstract": "Abstract Growth in electricity demand also gives a rise to the necessity of cheaper and safer electric supply and forecasting electricity load plays a key role in this goal. In this study recurrent extreme learning machine (RELM) was proposed as a novel approach to forecast electricity load more accurately. In RELM, extreme learning machine (ELM), which is a training method for single hidden layer feed forward neural network, was adapted to train a single hidden layer Jordan recurrent neural network. Electricity Load Diagrams 2011\u20132014 dataset was employed to evaluate and validate the proposed approach. Obtained results were compared with traditional ELM, linear regression, generalized regression neural network and some other popular machine learning methods. Achieved root mean square errors (RMSE) by \\{RELM\\} were nearly twice less than obtained results by other employed machine learning methods. The results showed that the recurrent type \\{ANNs\\} had extraordinary success in forecasting dynamic systems and also time-ordered datasets with comparison to feed forward ANNs. Also, used time in the training stage is similar to \\{ELM\\} and they are extremely fast than the others. This study showed that the proposed approach can be applied to forecast electricity load and \\{RELM\\} has high potential to be utilized in modeling dynamic systems effectively.", 
        "author": "\u00d6mer Faruk Ertugrul", 
        "keyword": "Recurrent extreme learning machine\", \"Electricity load forecasting\", \"Recurrent neural network\", \"Context neuron", 
        "title": "Forecasting electricity load by a novel recurrent extreme learning machines approach"
    }, 
    {
        "abstract": "Abstract The stage and grade of psoriasis severity is clinically relevant and important for dermatologists as it aids them lead to a reliable and an accurate decision making process for better therapy. This paper proposes a novel psoriasis risk assessment system (pRAS) for stratification of psoriasis severity from colored psoriasis skin images having Asian Indian ethnicity. Machine learning paradigm is adapted for risk stratification of psoriasis disease grades utilizing offline training and online testing images. We design four kinds of pRAS systems. It uses two kinds of classifiers (support vector machines (SVM) and decision tree (DT)) during training and testing phases and two kinds of feature selection criteria (Principal Component Analysis (PCA) and Fisher Discriminant Ratio (FDR)), thus, leading to an exhaustive comparison between these four systems. Our database consisted of 848 psoriasis images with five severity grades: healthy, mild, moderate, severe and very severe, consisting of 383, 47, 245, 145, and 28 images respectively. The pRAS system computes 859 colored and grayscale image features. Using cross-validation protocol with K-fold procedure, the pRAS system utilizing the \\{SVM\\} with \\{FDR\\} combination with combined color and grayscale feature set gives an accuracy of 99.92%. Several performance evaluation parameters such as: feature retaining power, aggregated feature effect and system reliability is computed meeting our assumptions and hypothesis. Our results demonstrate promising results and pRAS system is able to stratify the psoriasis disease.", 
        "author": "Vimal K. Shrivastava and Narendra D. Londhe and Rajendra S. Sonawane and Jasjit S. Suri", 
        "keyword": "Dermatology\", \"Psoriasis skin disease\", \"Color features\", \"Texture features\", \"Machine learning\", \"Multiclass", 
        "title": "A novel approach to multiclass psoriasis disease risk stratification: Machine learning paradigm"
    }, 
    {
        "abstract": "AbstractObjective To develop and validate a method for automatically quantifying the scientific quality and sensationalism of individual news records. Study design After retrieving 163,433 news records mentioning the Severe Acute Respiratory Syndrome (SARS) and \\{H1N1\\} pandemics, a maximum entropy model for inductive machine learning was used to identify relationships among 500 randomly sampled news records that correlated with systematic human assessments of their scientific quality and sensationalism. These relationships were then computationally applied to automatically classify 10,000 additional randomly sampled news records. The model was validated by randomly sampling 200 records and comparing human assessments of them to the computer assessments. Results The computer model correctly assessed the relevance of 86% of news records, the quality of 65% of records, and the sensationalism of 73% of records, as compared to human assessments. Overall, the scientific quality of \\{SARS\\} and \\{H1N1\\} news media coverage had potentially important shortcomings, but coverage was not too sensationalizing. Coverage slightly improved between the two pandemics. Conclusion Automated methods can evaluate news records faster, cheaper, and possibly better than humans. The specific procedure implemented in this study can at the very least identify subsets of news records that are far more likely to have particular scientific and discursive qualities.", 
        "author": "Steven J. Hoffman and Victoria Justicz", 
        "keyword": "Health communication\", \"Mass media\", \"News\", \"Pandemics\", \"Machine learning\", \"Validation studies", 
        "title": "Automatically quantifying the scientific quality and sensationalism of news records mentioning pandemics: validating a maximum entropy machine-learning model"
    }, 
    {
        "abstract": "Abstract In this paper, a comprehensive review on methods for voltage sag source location is presented and also nine generalized methods using positive sequence phasors, instantaneous positive sequence components, Clarke\u2019s components and integration are introduced. Most discussed methods use single criteria, and as results will show, their accuracy is limited. Therefore, this paper proposes another novel method using a robust support vector machine (SVM) in which many features are extracted, based on previously described methods. Then, the source location by machine learning technique is discussed with two steps in detail and the \\{SVM\\} with the linear, polynomial, and radial basis function (RBF) kernels are applied along with optimal genetic search. Also, the k-fold cross validation is used to prevent over fitting. The effect of principal component analysis (PCA) is investigated, too. A comparative analysis is performed between the existing methods, the nine generalized methods and the novel method, by applying extensive numerical simulations in a Brazilian regional utility, by using PSCAD/EMTDC and MATLAB. Finally, effectiveness of all methods was obtained, reactive power based on generalized methods using instantaneous positive sequence components and Clarke\u2019s components gave the right location in 88% of total simulated cases, whereas the robust \\{SVM\\} based method with \\{RBF\\} kernel without \\{PCA\\} had the highest accuracy (95%).", 
        "author": "Younes Mohammadi and Mohammad H. Moradi and Roberto Chouhy Leborgne", 
        "keyword": "Voltage sag source location\", \"Support vector machine (SVM)\", \"Positive sequence\", \"k-Fold\", \"Radial basis function (RBF)", 
        "title": "A novel method for voltage-sag source location using a robust machine learning approach"
    }, 
    {
        "abstract": "Abstract Most machine learning systems for binary classification are trained using algorithms that maximize the accuracy and assume that false positives and false negatives are equally bad. However, in many applications, these two types of errors may have very different costs. In this paper, we consider the problem of controlling the false positive rate on SVMs, since its traditional formulation does not offer such assurance. To solve this problem, we define a feature space sensitive area, where the probability of having false positives is higher, and use a second classifier (unanimity k-NN) in this area to better filter errors and improve the decision-making process. We call this method Risk Area \\{SVM\\} (RA-SVM). We compare the RA-SVM to other state-of-the-art methods for low false positive classification using 33 standard datasets in the literature. The solution we propose shows better performance in the vast majority of the cases using the standard Neyman\u2013Pearson measure.", 
        "author": "Daniel Moraes and Jacques Wainer and Anderson Rocha", 
        "keyword": "Support vector machines\", \"k-nearest neighbors\", \"Low false positive learning", 
        "title": "Low false positive learning with support vector machines"
    }, 
    {
        "abstract": "AbstractBackground and purpose Severe acute mucositis commonly results from head and neck (chemo)radiotherapy. A predictive model of mucositis could guide clinical decision-making and inform treatment planning. We aimed to generate such a model using spatial dose metrics and machine learning. Materials and methods Predictive models of severe acute mucositis were generated using radiotherapy dose (dose\u2013volume and spatial dose metrics) and clinical data. Penalised logistic regression, support vector classification and random forest classification (RFC) models were generated and compared. Internal validation was performed (with 100-iteration cross-validation), using multiple metrics, including area under the receiver operating characteristic curve (AUC) and calibration slope, to assess performance. Associations between covariates and severe mucositis were explored using the models. Results The dose\u2013volume-based models (standard) performed equally to those incorporating spatial information. Discrimination was similar between models, but the \\{RFCstandard\\} had the best calibration. The mean \\{AUC\\} and calibration slope for this model were 0.71 (s.d. = 0.09) and 3.9 (s.d. = 2.2), respectively. The volumes of oral cavity receiving intermediate and high doses were associated with severe mucositis. Conclusions The \\{RFCstandard\\} model performance is modest-to-good, but should be improved, and requires external validation. Reducing the volumes of oral cavity receiving intermediate and high doses may reduce mucositis incidence.", 
        "author": "Jamie A. Dean and Kee H. Wong and Liam C. Welsh and Ann-Britt Jones and Ulrike Schick and Kate L. Newbold and Shreerang A. Bhide and Kevin J. Harrington and Christopher M. Nutting and Sarah L. Gulliford", 
        "keyword": "Oral mucositis\", \"NTCP modelling\", \"Dose\u2013response modelling\", \"Machine learning\", \"Spatial dose keywords =etrics\", \"Head and neck radiotherapy", 
        "title": "Normal tissue complication probability (NTCP) modelling using spatial dose metrics and machine learning methods for severe acute oral mucositis resulting from head and neck radiotherapy"
    }, 
    {
        "abstract": "Summary While nonlinear machine methods have been widely used in environmental forecasting, in situations where new data arrive continually, the need to make frequent model updates can become cumbersome and computationally costly. To alleviate this problem, an online sequential learning algorithm for single hidden layer feedforward neural networks \u2013 the online sequential extreme learning machine (OSELM) \u2013 is automatically updated inexpensively as new data arrive (and the new data can then be discarded). \\{OSELM\\} was applied to forecast daily streamflow at two small watersheds in British Columbia, Canada, at lead times of 1\u20133 days. Predictors used were weather forecast data generated by the \\{NOAA\\} Global Ensemble Forecasting System (GEFS), and local hydro-meteorological observations. \\{OSELM\\} forecasts were tested with daily, monthly or yearly model updates. More frequent updating gave smaller forecast errors, including errors for data above the 90th percentile. Larger datasets used in the initial training of \\{OSELM\\} helped to find better parameters (number of hidden nodes) for the model, yielding better predictions. With the online sequential multiple linear regression (OSMLR) as benchmark, we concluded that \\{OSELM\\} is an attractive approach as it easily outperformed \\{OSMLR\\} in forecast accuracy.", 
        "author": "Aranildo R. Lima and Alex J. Cannon and William W. Hsieh", 
        "keyword": "Streamflow\", \"Forecast\", \"Extreme learning machine (ELM)\", \"Online sequential \\{ELM\\} (OSELM)\", \"Machine learning", 
        "title": "Forecasting daily streamflow using online sequential extreme learning machines"
    }, 
    {
        "abstract": "Abstract This paper presents a novel scheme for global solar radiation prediction, based on a hybrid neural-genetic algorithm. Specifically a grouping genetic algorithm (GGA) and an Extreme Learning Machine algorithm (ELM) have been merged in a single algorithm, in such a way that the \\{GGA\\} solves the optimal selection of features, and the \\{ELM\\} carries out the prediction. The proposed scheme is also novel because it uses as input of the system the output of a numerical weather meso-scale model (WRF), i.e., atmospherical variables predicted by the \\{WRF\\} at different nodes. We consider then different problems associated with this general algorithmic framework: first, we evaluate the capacity of the GGA\u2013ELM for carrying out a statistical downscaling of the \\{WRF\\} to a given point of interest (where a measure of solar radiation is available), i.e., we only take into account predictive variables from the \\{WRF\\} and the objective variable at the same time tag. In a second evaluation approach, we try to predict the solar radiation at the point of interest at different time tags t + x , using predictive variables from the WRF. Finally, we tackle the complete prediction problem by including previous values of measured solar radiation in the prediction. The proposed algorithm and its efficiency for selecting the best set of features from the \\{WRF\\} are analyzed in this paper, and we also describe different operators and dynamics for the GGA. Finally, we evaluate the performance of the system with these different characteristics in a real problem of solar radiation prediction at Toledo\u2019s radiometric observatory (Spain), where the proposed system has shown an excellent performance in all the subproblems considered, in terms of different error metrics.", 
        "author": "A. Aybar-Ruiz and S. Jim\u00e9nez-Fern\u00e1ndez and L. Cornejo-Bueno and C. Casanova-Mateo and J. Sanz-Justo and P. Salvador-Gonz\u00e1lez and S. Salcedo-Sanz", 
        "keyword": "Grouping genetic algorithm (GGA)\", \"Global solar radiation prediction\", \"Solar energy\", \"Extreme Learning Machines", 
        "title": "A novel Grouping Genetic Algorithm\u2013Extreme Learning Machine approach for global solar radiation prediction from numerical weather models inputs"
    }, 
    {
        "abstract": "Abstract District heating systems are important utility systems. If these systems are properly managed, they can ensure economic and environmental friendly provision of heat to connected customers. Potentials for further improvement of district heating systems\u2019 operation lie in improvement of present control strategies. One of the options is introduction of model predictive control. Multistep ahead predictive models of consumers\u2019 heat load are starting point for creating successful model predictive strategy. In this article, short-term, multistep ahead predictive models of heat load of consumer attached to district heating system were created. Models were developed using the novel method based on Extreme Learning Machine (ELM). Nine different \\{ELM\\} predictive models, for time horizon from 1 to 24 h ahead, were developed. Estimation and prediction results of \\{ELM\\} models were compared with genetic programming (GP) and artificial neural networks (ANNs) models. The experimental results show that an improvement in predictive accuracy and capability of generalization can be achieved by the \\{ELM\\} approach in comparison with \\{GP\\} and ANN. Moreover, achieved results indicate that developed \\{ELM\\} models can be used with confidence for further work on formulating novel model predictive strategy in district heating systems. The experimental results show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms.", 
        "author": "Shahin Sajjadi and Shahaboddin Shamshirband and Meysam Alizamir and Por Lip Yee and Zulkefli Mansor and Azizah Abdul Manaf and Torki A. Altameem and Ali Mostafaeipour", 
        "keyword": "District heating systems\", \"Heat load\", \"Estimation\", \"Prediction\", \"Extreme Learning Machine (ELM)", 
        "title": "Extreme learning machine for prediction of heat load in district heating systems"
    }, 
    {
        "abstract": "Abstract An effective machine learning algorithm, the support vector machine (SVM), is presented in the context of a coherent optical transmission system. As a classifier, the \\{SVM\\} can create nonlinear decision boundaries to mitigate the distortions caused by nonlinear phase noise (NLPN). Without any prior information or heuristic assumptions, the \\{SVM\\} can learn and capture the link properties from only a few training data. Compared with the maximum likelihood estimation (MLE) algorithm, a lower bit-error rate (BER) is achieved by the \\{SVM\\} for a given launch power; moreover, the launch power dynamic range (LPDR) is increased by 3.3 dBm for 8 phase-shift keying (8 PSK), 1.2 dBm for QPSK, and 0.3 dBm for BPSK. The maximum transmission distance corresponding to a \\{BER\\} of 1 \u00d7 10 \u2212 3 is increased by 480 km for the case of 8 PSK. The larger launch power range and longer transmission distance improve the tolerance to amplitude and phase noise, which demonstrates the feasibility of the \\{SVM\\} in digital signal processing for M-PSK formats. Meanwhile, in order to apply the \\{SVM\\} method to 16 quadratic amplitude modulation (16 QAM) detection, we propose a parameter optimization scheme. By utilizing a cross-validation and grid-search techniques, the optimal parameters of \\{SVM\\} can be selected, thus leading to the \\{LPDR\\} improvement by 2.8 dBm. Additionally, we demonstrate that the \\{SVM\\} is also effective in combating the laser phase noise combined with the inphase and quadrature (I/Q) modulator imperfections, but the improvement is insignificant for the linear noise and separate I/Q imbalance. The computational complexity of \\{SVM\\} is also discussed. The relatively low complexity makes it possible for \\{SVM\\} to implement the real-time processing.", 
        "author": "Danshi Wang and Min Zhang and Zhongle Cai and Yue Cui and Ze Li and Huanhuan Han and Meixia Fu and Bin Luo", 
        "keyword": "Digital signal processing\", \"Machine learning\", \"Fiber nonlinearity\", \"Coherent detection", 
        "title": "Combatting nonlinear phase noise in coherent optical systems with an optimized decision processor based on machine learning"
    }, 
    {
        "abstract": "Abstract While multiple model adaptive control (MMAC) scheme provides a solution to systems with unknown and rapidly time-varying parameters, many offline samples must be obtained beforehand, and the number of models is difficult to be found if no prior knowledge is given. This paper proposes a new adaptive control strategy to handle such systems. The principle is to use a change detection mechanism to check if there is an abrupt change, and immediately train a new model if a change is detected. A novel online identification algorithm, namely initial-training-free online extreme learning machine (ITF-OELM), is also proposed to allow the model to be trained anytime without concerns on prior data. With this strategy, only one model is necessary as compared to MMAC, resulting in reduction on computational complexity and memory usage. Simulation results show that the proposed strategy is effective. Besides, although the use of forgetting factor in ITF-OELM can accelerate the convergence speed for system identification, sometimes it may lead to ill-conditioned covariance matrix in the recursively updating process. This paper shows that such issue can be solved by the change detection mechanism.", 
        "author": "Xiang Hui Gao and Ka In Wong and Pak Kin Wong and Chi Man Vong", 
        "keyword": "Adaptive control\", \"System identification\", \"Time-varying discrete systems\", \"Machine learning", 
        "title": "Adaptive control of rapidly time-varying discrete-time system using initial-training-free online extreme learning machine"
    }, 
    {
        "abstract": "Abstract Type 1 Gaucher disease (GD) is an autosomal recessive lysosomal storage disease, affecting bone metabolism, structure and strength. Current bone assessment methods are not ideal. Semi-quantitative \\{MRI\\} scoring is unreliable, not standardized, and only evaluates bone marrow. \\{DXA\\} \\{BMD\\} is also used but is a limited predictor of bone fragility/fracture risk. Our purpose was to measure trabecular bone microarchitecture, as a biomarker of bone disease severity, in type 1 \\{GD\\} individuals with different \\{GD\\} genotypes and to apply machine learning based analytics to discriminate between \\{GD\\} patients and healthy individuals. Micro-MR imaging of the distal radius was performed on 20 type 1 \\{GD\\} patients and 10 healthy controls (HC). Fifteen stereological and textural measures (STM) were calculated from the \\{MR\\} images. General linear models demonstrated significant differences between \\{GD\\} and HC, and \\{GD\\} genotypes. Stereological measures, main contributors to the first two principal components (PCs), explained ~50% of data variation and were significantly different between males and females. Subsequent \\{PCs\\} textural measures were significantly different between \\{GD\\} patients and \\{HC\\} individuals. Textural measures also significantly differed between \\{GD\\} genotypes, and distinguished between \\{GD\\} patients with normal and pathologic \\{DXA\\} scores. \\{PCA\\} and \\{SVM\\} predictive analyses discriminated between \\{GD\\} and \\{HC\\} with maximum accuracy of 73% and area under \\{ROC\\} curve of 0.79. Trabecular \\{STM\\} differences can be quantified between \\{GD\\} patients and HC, and \\{GD\\} sub-types using micro-MRI and machine learning based analytics. Work is underway to expand this approach to evaluate \\{GD\\} disease burden and treatment efficacy.", 
        "author": "Gulshan B. Sharma and Douglas D. Robertson and Dawn A. Laney and Michael J. Gambello and Michael Terk", 
        "keyword": "Bone\", \"Trabeculae bone\", \"Microarchitecture\", \"Stereology\", \"Texture\", \"Principal component keywords =nalysis\", \"Machine learning\", \"Support vector machine\", \"Magnetic resonance imaging\", \"Gaucher disease", 
        "title": "Machine learning based analytics of micro-MRI trabecular bone microarchitecture and texture in type 1 Gaucher disease"
    }, 
    {
        "abstract": "Abstract Multiple Empirical Kernel Learning (MEKL) explicitly maps samples into different empirical feature spaces in which the kernel features of the mapped samples can be directly provided. Thus, \\{MEKL\\} is much easier than the conventional Multiple Kernel Learning (MKL) in terms of processing and analyzing the structure of mapped feature spaces. However, the computational complexity of \\{MEKL\\} with M empirical feature spaces is O ( \\{MN\\} 3 ) where N is the number of training samples. The dimensions of the generated empirical feature spaces are approximate to N. When dealing with large-scale problems, \\{MEKL\\} cannot handle them properly due to the severe computation and memory burden. Moreover, most existing \\{MEKL\\} utilizes the gradient decent optimization to learn classifiers, but it is time consuming for training. Therefore, this paper proposes a Multiple Random Empirical Kernel Learning Machine (MREKLM) to overcome these problems. The proposed \\{MREKLM\\} adopts the random projection idea to map samples into multiple low-dimensional empirical feature spaces with lower computational complexity O ( \\{MP\\} 3 ) , where P ( \u226a N ) is the number of the randomly selected samples. After that, \\{MREKLM\\} adopts an analytical optimization approach to directly deal with multi-class problems. The computational complexity of \\{MREKLM\\} is O ( M 3 P 3 ) . Experimental results also validate both efficiency and effectiveness of the proposed MREKLM. The contributions of this work are: (1) proposing a fast \\{MEKL\\} algorithm named MREKLM, (2) introducing an efficient random empirical kernel mapping approach, and (3) extending the capability of \\{MEKL\\} to handle large-scale problems.", 
        "author": "Qi Fan and Zhe Wang and Hongyuan Zha and Daqi Gao", 
        "keyword": "Multiple Kernel Learning\", \"Empirical Kernel Mapping\", \"Random projection\", \"Analytical keywords =ptimization\", \"Classifier design\", \"Pattern recognition", 
        "title": "MREKLM: A fast multiple empirical kernel learning machine"
    }, 
    {
        "abstract": "Abstract Performance of small molecule automated docking programs has conceptually been divided into docking -, scoring -, ranking - and screening power, which focuses on the crystal pose prediction, affinity prediction, ligand ranking and database screening capabilities of the docking program, respectively. Benchmarks show that different docking programs can excel in individual benchmarks which suggests that the scoring function employed by the programs can be optimized for a particular task. Here the scoring function of Smina is re-optimized towards enhancing the docking power using a supervised machine learning approach and a manually curated database of ligands and cross docking receptor pairs. The optimization method does not need associated binding data for the receptor-ligand examples used in the data set and works with small train sets. The re-optimization of the weights for the scoring function results in a similar docking performance with regard to docking power towards a cross docking test set. A ligand decoy based benchmark indicates a better discrimination between poses with high and low RMSD. The reported parameters for Smina are compatible with Autodock Vina and represent ready-to-use alternative parameters for researchers who aim at pose prediction rather than affinity prediction.", 
        "author": "Esben J. Bjerrum", 
        "keyword": "Molecular docking\", \"Docking power\", \"Scoring function\", \"Machine learning optimization\", \"Smina\", keywords =Autodock Vina\", \"Drug discovery\", \"Cross docking", 
        "title": "Machine learning optimization of cross docking accuracy"
    }, 
    {
        "abstract": "Abstract Differently from Vector-pattern-oriented Classifier Design (VecCD), Matrix-pattern-oriented Classifier Design (MatCD) is expected to manipulate matrix-oriented patterns directly rather than turning them into a vector, and further demonstrated its effectiveness. However, some prior information, such as the local sensitive discriminant information among matrix-oriented patterns, might be neglected by MatCD. To overcome such flaw, a new regularization term named \\{RLSD\\} is adopted into MatCD by taking advantage of Locality Sensitive Discriminant Analysis (LSDA) in this paper. In detail, the objective function of \\{LSDA\\} is modified and transformed into the regularization term \\{RLSD\\} to explore the local sensitive discriminant information among matrix-oriented patterns. In the implementation, \\{RLSD\\} is collaborated with one typical MatCD, whose name is Matrix-pattern-oriented Ho-Kashyap Classifier (MatMHKS), so as to create a new classifier based on local sensitive discriminant information named \\{LSDMatMHKS\\} for short. Finally, comprehensive experiments are designed to validate the effectiveness of LSDMatMHKS. The major contributions of this paper can be concluded as (1) improving the classification performance and the learning ability of MatCD, (2) introducing local sensitive discriminant information into MatCD and extending the application scenario of LSDA, and (3) validating and analyzing the feasibility and effectiveness of RLSD.", 
        "author": "Zhe Wang and Guowei Zhang and Dongdong Li and Yujin Zhu and Chenjie Cao", 
        "keyword": "Locality sensitive discriminant\", \"Regularization term learning\", \"Matrix-pattern-oriented keywords =lassifier\", \"Ho-Kashyap algorithm\", \"Pattern recognition", 
        "title": "Locality sensitive discriminant matrixized learning machine"
    }, 
    {
        "abstract": "Abstract Models for predicting the probability of experiencing various health outcomes or adverse events over a certain time frame (e.g., having a heart attack in the next 5 years) based on individual patient characteristics are important tools for managing patient care. Electronic health data (EHD) are appealing sources of training data because they provide access to large amounts of rich individual-level data from present-day patient populations. However, because \\{EHD\\} are derived by extracting information from administrative and clinical databases, some fraction of subjects will not be under observation for the entire time frame over which one wants to make predictions; this loss to follow-up is often due to disenrollment from the health system. For subjects without complete follow-up, whether or not they experienced the adverse event is unknown, and in statistical terms the event time is said to be right-censored. Most machine learning approaches to the problem have been relatively ad hoc; for example, common approaches for handling observations in which the event status is unknown include (1) discarding those observations, (2) treating them as non-events, (3) splitting those observations into two observations: one where the event occurs and one where the event does not. In this paper, we present a general-purpose approach to account for right-censored outcomes using inverse probability of censoring weighting (IPCW). We illustrate how \\{IPCW\\} can easily be incorporated into a number of existing machine learning algorithms used to mine big health care data including Bayesian networks, k-nearest neighbors, decision trees, and generalized additive models. We then show that our approach leads to better calibrated predictions than the three ad hoc approaches when applied to predicting the 5-year risk of experiencing a cardiovascular adverse event, using \\{EHD\\} from a large U.S. Midwestern healthcare system.", 
        "author": "David M. Vock and Julian Wolfson and Sunayan Bandyopadhyay and Gediminas Adomavicius and Paul E. Johnson and Gabriela Vazquez-Benitez and Patrick J. O\u2019Connor", 
        "keyword": "Censored data\", \"Electronic health data\", \"Inverse probability weighting\", \"Machine learning\", keywords =Risk prediction\", \"Survival analysis", 
        "title": "Adapting machine learning techniques to censored time-to-event health record data: A general-purpose approach using inverse probability of censoring weighting"
    }, 
    {
        "abstract": "\\{ABSTRACT\\} The rise of big data has led to new demands for machine learning (ML) systems to learn complex models, with millions to billions of parameters, that promise adequate capacity to digest massive datasets and offer powerful predictive analytics (such as high-dimensional latent features, intermediate representations, and decision functions) thereupon. In order to run \\{ML\\} algorithms at such scales, on a distributed cluster with tens to thousands of machines, it is often the case that significant engineering efforts are required\u2014and one might fairly ask whether such engineering truly falls within the domain of \\{ML\\} research. Taking the view that \u201cbig\u201d \\{ML\\} systems can benefit greatly from ML-rooted statistical and algorithmic insights\u2014and that \\{ML\\} researchers should therefore not shy away from such systems design\u2014we discuss a series of principles and strategies distilled from our recent efforts on industrial-scale \\{ML\\} solutions. These principles and strategies span a continuum from application, to engineering, and to theoretical research and development of big \\{ML\\} systems and architectures, with the goal of understanding how to make them efficient, generally applicable, and supported with convergence and scaling guarantees. They concern four key questions that traditionally receive little attention in \\{ML\\} research: How can an \\{ML\\} program be distributed over a cluster? How can \\{ML\\} computation be bridged with inter-machine communication? How can such communication be performed? What should be communicated between machines? By exposing underlying statistical and algorithmic characteristics unique to \\{ML\\} programs but not typically seen in traditional computer programs, and by dissecting successful cases to reveal how we have harnessed these principles to design and develop both high-performance distributed \\{ML\\} software as well as general-purpose \\{ML\\} frameworks, we present opportunities for \\{ML\\} researchers and practitioners to further shape and enlarge the area that lies between \\{ML\\} and systems.", 
        "author": "Eric P. Xing and Qirong Ho and Pengtao Xie and Dai Wei", 
        "keyword": "Machine learning\", \"Artificial intelligence big data\", \"Big model\", \"Distributed systems\", keywords =Principles\", \"Theory\", \"Data-parallelism\", \"Model-parallelism", 
        "title": "Strategies and Principles of Distributed Machine Learning on Big Data"
    }, 
    {
        "abstract": "Abstract Reinforcement learning (RL) is a learning paradigm that can be useful in a wide variety of real-world applications. However, its applicability to complex problems remains problematic due to different causes. Particularly important among these are the high quantity of data required by the agent to learn useful policies and the poor scalability to high-dimensional problems due to the use of local approximators. This paper presents a novel \\{RL\\} algorithm, called online fitted policy iteration (OFPI), that steps forward in both directions. \\{OFPI\\} is based on a semi-batch scheme that increases the convergence speed by reusing data and enables the use of global approximators by reformulating the value function approximation as a standard supervised problem. The proposed method has been empirically evaluated in three benchmark problems. During the experiments, \\{OFPI\\} has employed a neural network trained with the extreme learning machine algorithm to approximate the value functions. Results have demonstrated the stability of \\{OFPI\\} using a global function approximator and also performance improvements over two baseline algorithms (SARSA and Q-learning) combined with eligibility traces and a radial basis function network.", 
        "author": "Pablo Escandell-Montero and Delia Lorente and Jos\u00e9 M. Mart\u00ednez-Mart\u00ednez and Emilio Soria-Olivas and Joan Vila-Franc\u00e9s and Jos\u00e9 D. Mart\u00edn-Guerrero", 
        "keyword": "Reinforcement learning\", \"Sequential decision-making\", \"Fitted policy iteration\", \"Extreme learning machine", 
        "title": "Online fitted policy iteration based on extreme learning machines"
    }, 
    {
        "abstract": "AbstractBackground and aims Machine learning techniques for the text mining of cancer-related clinical documents have not been sufficiently explored. Here some techniques are presented for the pre-processing of free-text breast cancer pathology reports, with the aim of facilitating the extraction of information relevant to cancer staging. Materials and methods The first technique was implemented using the freely available software RapidMiner to classify the reports according to their general layout: \u2018semi-structured\u2019 and \u2018unstructured\u2019. The second technique was developed using the open source language engineering framework \\{GATE\\} and aimed at the prediction of chunks of the report text containing information pertaining to the cancer morphology, the tumour size, its hormone receptor status and the number of positive nodes. The classifiers were trained and tested respectively on sets of 635 and 163 manually classified or annotated reports, from the Northern Ireland Cancer Registry. Results The best result of 99.4% accuracy \u2013 which included only one semi-structured report predicted as unstructured \u2013 was produced by the layout classifier with the k nearest algorithm, using the binary term occurrence word vector type with stopword filter and pruning. For chunk recognition, the best results were found using the \\{PAUM\\} algorithm with the same parameters for all cases, except for the prediction of chunks containing cancer morphology. For semi-structured reports the performance ranged from 0.97 to 0.94 and from 0.92 to 0.83 in precision and recall, while for unstructured reports performance ranged from 0.91 to 0.64 and from 0.68 to 0.41 in precision and recall. Poor results were found when the classifier was trained on semi-structured reports but tested on unstructured. Conclusions These results show that it is possible and beneficial to predict the layout of reports and that the accuracy of prediction of which segments of a report may contain certain information is sensitive to the report layout and the type of information sought.", 
        "author": "Giulio Napolitano and Adele Marshall and Peter Hamilton and Anna T. Gavin", 
        "keyword": "Natural language processing\", \"Information extraction\", \"Supervised machine learning\", \"Surgical keywords =athology report\", \"Cancer staging", 
        "title": "Machine learning classification of surgical pathology reports and chunk recognition for information extraction noise reduction"
    }, 
    {
        "abstract": "Abstract This paper approaches, from a computational perspective, the problem of predicting the stature of human skeletal remains from bone measurements. There are traditional methods for constructing models that give good results for stature estimation. In this paper, we aim to investigate the usefulness of using machine learning-based models to approximate stature. Assuming that the stature of an individual is indirectly related to bone measurement values, we can derive methods that learn from archaeological data and construct models that give good estimates of the stature. Two novel machine learning-based regression models for stature estimation are proposed in this paper. Experiments using artificial neural networks and genetic algorithms were performed on samples from the Terry Collection Postcranial Osteometric Database, and the obtained results are discussed and compared with the results from other similar studies. The experimental evaluations indicate that the machine learning-based regression models are efficient for the stature estimation of archaeological remains and highlight the potential of our proposal.", 
        "author": "Gabriela Czibula and Vlad-Sebastian Ionescu and Diana-Lucia Miholca and Ioan-Gabriel Mircea", 
        "keyword": "Machine learning\", \"Supervised learning\", \"Bioarchaeology\", \"Stature prediction", 
        "title": "Machine learning-based approaches for predicting stature from archaeological skeletal remains using long bone lengths"
    }, 
    {
        "abstract": "Abstract Quantum computing represents a promising paradigm for solving complex problems, such as large-number factorization, exhaustive search, optimization, and mean and median computation. On the other hand, supervised learning deals with the classical induction problem where an unknown input-output relation is inferred from a set of data that consists of examples of this relation. Lately, because of the rapid growth of the size of datasets, the dimensionality of the input and output space, and the variety and structure of the data, conventional learning techniques have started to show their limits. Considering these problems, the purpose of this chapter is to illustrate how quantum computing can be useful for addressing the computational issues of building, tuning, and estimating the performance of a model learned from data.", 
        "author": "L. Oneto and S. Ridella and D. Anguita", 
        "keyword": "Supervised learning\", \"Quantum computing\", \"Classical computing\", \"Quantum mean computation\", keywords =Quantum minimum search\", \"Statistical learning theory\", \"Training\", \"Model selection\", \"Error keywords =stimation\", \"Out-of-sample\", \"In-sample\", \"Hold-out\", \"Cross validation\", \"Bootstrap\", keywords =Vapnik-Chervonenkis theory\", \"Rademacher complexity theory\", \"PAC-Bayes theory\", \"Algorithmic keywords =tability\", \"Compression bound", 
        "title": "Chapter 2 - Quantum computing and supervised machine learning: Training, model selection, and error estimation"
    }, 
    {
        "abstract": "Abstract Soft sensors have been widely used as online instrument measurements for the key process variables of industrial processes. In this paper, a novel robust soft sensor model for predicting the key process variables is proposed. The proposed soft sensor model integrates an enhanced hidden layer based dynamic extreme learning machine (EHLDELM) with the partial least-square regression (PLSR). The traditional extreme learning machine with a static structure cannot well deal with the dynamic feature of the process data, so a dynamic strategy is adopted. Additionally, a special linear hidden layer node is added in the dynamic extreme learning machine to further enhance the performance. Then, the partial least-square method is utilized to deal with the collinearity problem. Finally, an optimal model between the hidden layer and the output layer is obtained. Thus, a novel robust nonlinear soft sensor model integrated \\{EHLDELM\\} with \\{PLSR\\} (PLSR-EHLDELM) is proposed. As a case study, the proposed PLSR-EHLDELM model is demonstrated through an application to the Tennessee Eastman process (TEP) for estimation of the key process variable. Compared with the other four models of ELM, PLSR, Kernel-based PLS, and PLS-ELM, the proposed PLSR-EHLDELM model achieves higher accuracy.", 
        "author": "Yan-Lin He and Yuan Xu and Qun-Xiong Zhu", 
        "keyword": "Extreme learning machine\", \"Single hidden layer feed-forward neural network\", \"Partial least keywords =quare\", \"Tennessee Eastman process", 
        "title": "Soft-sensing model development using PLSR-based dynamic extreme learning machine with an enhanced hidden layer"
    }, 
    {
        "abstract": "Abstract In this work a Support Vector Machine Regression (SVMR) algorithm is used to calculate local magnitude (ML) using only five seconds of signal after the P wave onset of one three component seismic station. This algorithm was trained with 863 records of historical earthquakes, where the input regression parameters were an exponential function of the waveform envelope estimated by least squares and the maximum value of the observed waveform for each component in a single station. Ten-fold cross validation was applied for a normalized polynomial kernel obtaining the mean absolute error for different exponents and complexity parameters. The local magnitude (ML) could be estimated with 0.19 units of mean absolute error. The proposed algorithm is easy to implement in hardware and may be used directly after the field seismological sensor to generate fast decisions at seismological control centers, increasing the possibility of having an effective reaction.", 
        "author": "Luis H. Ochoa and Luis F. Ni\u00f1o and Carlos A. Vargas", 
        "keyword": "Earthquake early warning\", \"Support Vector Machine Regression\", \"Earthquake\", \"Rapid response\", keywords =Local magnitude\", \"Seismic event\", \"Seismology\", \"Bogota\", \"Colombia", 
        "title": "Fast magnitude determination using a single seismological station record implementing machine learning techniques"
    }, 
    {
        "abstract": "Abstract Distance and similarity measures usually are complementary to pattern classification. With pairwise constraints, several approaches have been proposed to combine distance and similarity measures. However, it remains less investigated to use triplets of samples for joint learning of distance and similarity measures. Moreover, the kernel extension of triplet-based model is also nontrivial and computationally expensive. In this paper, we propose a novel method to learn a combined distance and similarity measure (CDSM). By incorporating with the max-margin model, we suggest a triplet-based \\{CDSM\\} learning model with a unified regularizer of the Frobenius norm. A support vector machine (SVM)-based algorithm is then adopted to solve the optimization problem. Furthermore, we extend \\{CDSM\\} for learning nonlinear measures via the kernel trick. Two effective strategies are adopted to speed up training and testing of kernelized CDSM. Experiments on the UCI, handwritten digits and person re-identification datasets demonstrate that \\{CDSM\\} and kernelized \\{CDSM\\} outperform several state-of-the-art metric learning methods.", 
        "author": "Mu Li and Qilong Wang and David Zhang and Peihua Li and Wangmeng Zuo", 
        "keyword": "Metric learning\", \"Support vector machine\", \"Kernel function\", \"Max-margin model", 
        "title": "Joint distance and similarity measure learning based on triplet-based constraints"
    }, 
    {
        "abstract": "Abstract Feature selection is an important research topic in machine learning and computer vision in that it can reduce the dimensionality of input data and improve the performance of learning algorithms. Low-rank approximation techniques can well exploit the low-rank property of input data, which coincides with the internal consistency of dimensionality reduction. In this paper, we propose an efficient unsupervised feature selection algorithm, which incorporates low-rank approximation as well as structure learning. First, using the self-representation of data matrix, we formalize the feature selection problem as a matrix factorization with low-rank constraints. This matrix factorization formulation also embeds structure learning regularization as well as a sparse regularized term. Second, we present an effective technique to approximate low-rank constraints and propose a convergent algorithm in a batch mode. This technique can serve as an algorithmic framework for general low-rank recovery problems as well. Finally, the proposed algorithm is validated in twelve publicly available datasets from machine learning repository. Extensive experimental results demonstrate that the proposed method is capable to achieve competitive performance compared to existing state-of-the-art feature selection methods in terms of clustering performance.", 
        "author": "Shiping Wang and Han Wang", 
        "keyword": "Machine learning\", \"Feature selection\", \"Unsupervised learning\", \"Low-rank approximation\", \"Structure learning", 
        "title": "Unsupervised feature selection via low-rank approximation and structure learning"
    }, 
    {
        "abstract": "Abstract Recently novel constructive and destructive parsimonious extreme learning machines (CP-ELM and DP-ELM) arose to cope with regression problems. With these foundations, several improvements on CP-ELM and DP-ELM are suggested. CP-ELM can be improved by replacing the Givens rotation with the Householder transformation, yielding the improved CP-ELM (ICP-ELM) which results in the acceleration of the training speed without hampering the generalization performance. Subsequently, a hybrid constructive\u2013destructive \\{ELM\\} (CDP-ELM) is generated integrating elements from CP-ELM and DP-ELM. The goal is to combine the advantages of training speed and parsimony from CP-ELM and DP-ELM. Finally, experiments on regression data sets and a real-world system identification of robot arm example are done to test the feasibility and efficacy of these variants including ICP-ELM and CDP-ELM.", 
        "author": "Yong-Ping Zhao and Ram\u00f3n Huerta", 
        "keyword": "Single-hidden-layer feedforward network\", \"Extreme learning machine\", \"Givens rotation\", \"Householder transformation", 
        "title": "Improvements on parsimonious extreme learning machine using recursive orthogonal least squares"
    }, 
    {
        "abstract": "Abstract Balanced dataset has been utilized by the previous human activity recognition algorithms to train the classifier. However, imbalanced dataset are ubiquitous in human activity recognition, especially in the case of abnormal activity detection. Though the class imbalance problem exists as a universal phenomenon in human activity recognition, few researches mentioned this problem and solved it. In order to reduce the influence of the imbalance datasets problem, the mixed-kernel based weighted extreme learning machine (MK-WELM) has been proposed in this paper. Considering that the performance of extreme learning machine (ELM) is greatly influenced by the choice of kernel, the mixed kernel method is proposed for ELM. In order to deal with the imbalanced problem, the cost sensitive method is utilized. The main idea of the cost sensitive method is that the cost of minority class increases with the misclassification rate. Considering the cost sensitive function and the mixed kernel method, the MK-WELM is constructed. Comparing with \\{ELM\\} and weighted \\{ELM\\} methods, experimental results over different human activity datasets demonstrate the effectiveness of the proposed method.", 
        "author": "Donghui Wu and Zhelong Wang and Ye Chen and Hongyu Zhao", 
        "keyword": "Human activity recognition\", \"Imbalanced dataset\", \"Weighted extreme learning machine\", \"Inertial keywords =ensors\", \"Mixed kernel", 
        "title": "Mixed-kernel based weighted extreme learning machine for inertial sensor based human activity recognition with imbalanced dataset"
    }, 
    {
        "abstract": "AbstractBackground and objective Percutaneous coronary interventional procedures need advance planning prior to stenting or an endarterectomy. Cardiologists use intravascular ultrasound (IVUS) for screening, risk assessment and stratification of coronary artery disease (CAD). We hypothesize that plaque components are vulnerable to rupture due to plaque progression. Currently, there are no standard grayscale \\{IVUS\\} tools for risk assessment of plaque rupture. This paper presents a novel strategy for risk stratification based on plaque morphology embedded with principal component analysis (PCA) for plaque feature dimensionality reduction and dominant feature selection technique. The risk assessment utilizes 56 grayscale coronary features in a machine learning framework while linking information from carotid and coronary plaque burdens due to their common genetic makeup. Method This system consists of a machine learning paradigm which uses a support vector machine (SVM) combined with \\{PCA\\} for optimal and dominant coronary artery morphological feature extraction. Carotid artery proven intima-media thickness (cIMT) biomarker is adapted as a gold standard during the training phase of the machine learning system. For the performance evaluation, K-fold cross validation protocol is adapted with 20 trials per fold. For choosing the dominant features out of the 56 grayscale features, a polling strategy of \\{PCA\\} is adapted where the original value of the features is unaltered. Different protocols are designed for establishing the stability and reliability criteria of the coronary risk assessment system (cRAS). Results Using the PCA-based machine learning paradigm and cross-validation protocol, a classification accuracy of 98.43% (AUC 0.98) with K = 10 folds using an \\{SVM\\} radial basis function (RBF) kernel was achieved. A reliability index of 97.32% and machine learning stability criteria of 5% were met for the cRAS. Conclusions This is the first Computer aided design (CADx) system of its kind that is able to demonstrate the ability of coronary risk assessment and stratification while demonstrating a successful design of the machine learning system based on our assumptions.", 
        "author": "Tadashi Araki and Nobutaka Ikeda and Devarshi Shukla and Pankaj K. Jain and Narendra D. Londhe and Vimal K. Shrivastava and Sumit K. Banchhor and Luca Saba and Andrew Nicolaides and Shoaib Shafique and John R. Laird and Jasjit S. Suri", 
        "keyword": "Coronary artery\", \"IVUS\", \"Carotid IMT\", \"Machine learning\", \"PCA\", \"Risk assessment", 
        "title": "PCA-based polling strategy in machine learning framework for coronary artery disease risk assessment in intravascular ultrasound: A link between carotid and coronary grayscale plaque morphology"
    }, 
    {
        "abstract": "Abstract Attributes of the retinal vessel play important role in systemic conditions and ophthalmic diagnosis. In this paper, a supervised method based on Extreme Learning Machine (ELM) is proposed to segment retinal vessel. Firstly, a set of 39-D discriminative feature vectors, consisting of local features, morphological features, phase congruency, Hessian and divergence of vector fields, is extracted for each pixel of the fundus image. Then a matrix is constructed for pixel of the training set based on the feature vector and the manual labels, and acts as the input of the \\{ELM\\} classifier. The output of classifier is the binary retinal vascular segmentation. Finally, an optimization processing is implemented to remove the region less than 30 pixels which is isolated from the retinal vascilar. The experimental results testing on the public Digital Retinal Images for Vessel Extraction (DRIVE) database demonstrate that the proposed method is much faster than the other methods in segmenting the retinal vessels. Meanwhile the average accuracy, sensitivity, and specificity are 0.9607, 0.7140 and 0.9868, respectively. Moreover the proposed method exhibits high speed and robustness on a new Retinal Images for Screening (RIS) database. Therefore it has potential applications for real-time computer-aided diagnosis and disease screening.", 
        "author": "Chengzhang Zhu and Beiji Zou and Rongchang Zhao and Jinkai Cui and Xuanchu Duan and Zailiang Chen and Yixiong Liang", 
        "keyword": "Colour fundus image\", \"Retinal vessel segmentation\", \"Feature extraction\", \"Supervised learning\", \"Computer-aided diagnosis", 
        "title": "Retinal vessel segmentation in colour fundus images using Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract The aim of this study was to validate a novel classification for the diagnosis of PNESs. Fifty-five \\{PNES\\} video-EEG recordings were retrospectively analyzed by four epileptologists and one psychiatrist in a blind manner and classified into four distinct groups: Hypermotor (H), Akinetic (A), Focal Motor (FM), and with Subjective Symptoms (SS). Eleven signs and symptoms, which are frequently found in PNESs, were chosen for statistical validation of our classification. An artificial neural network (ANN) analyzed \\{PNES\\} video recordings based on the signs and symptoms mentioned above. By comparing results produced by the \\{ANN\\} with classifications given by examiners, we were able to understand whether such classification was objective and generalizable. Through accordance metrics based on signs and symptoms (range: 0\u2013100%), we found that most of the seizures belonging to class A showed a high degree of accordance (mean \u00b1 \\{SD\\} = 73% \u00b1 5%); a similar pattern was found for class \\{SS\\} (80% slightly lower accordance was reported for class H (58% \u00b1 18%)), with a minimum of 30% in some cases. Low agreement arose from the \\{FM\\} group. Seizures were univocally assigned to a given class in 83.6% of seizures. The \\{ANN\\} classified \\{PNESs\\} in the same way as visual examination in 86.7%. Agreement between \\{ANN\\} classification and visual classification reached 83.3% (SD = 17.8%) accordance for class H, 100% (SD = 22%) for class A, 83.3% (SD = 21.2%) for class SS, and 50% (SD = 19.52%) for class FM. This is the first study in which the validity of a new \\{PNES\\} classification was established and reached in two different ways. Video-EEG evaluation needs to be performed by an experienced clinician, but later on, it may be fed into \\{ANN\\} analysis, whose feedback will provide guidance for differential diagnosis. Our analysis, supported by the \\{ML\\} approach, showed that this model of classification could be objectively performed by video-EEG examination.", 
        "author": "Adriana Magaudda and Angela Lagan\u00e0 and Alessandro Calamuneri and Teresa Brizzi and Cinzia Scalera and Massimiliano Beghi and Cesare Maria Cornaggia and Gabriella Di Rosa", 
        "keyword": "Psychogenic seizures\", \"Video-EEG\", \"Machine learning\", \"Classification of \\{PNESs\\}", 
        "title": "Validation of a novel classification model of psychogenic nonepileptic seizures by video-EEG analysis and a machine learning approach"
    }, 
    {
        "abstract": "Abstract Cancer prediction is of great importance and significance and it is crucial to provide researchers and scientists with novel, accurate and robust computational tools for this issue. Recent technologies such as microarray and next-generation sequencing have paved the way for computational methods and techniques to play critical roles in this regard. Many important problems in cell biology require the dense nonlinear interactions between functional modules to be considered. The importance of computer simulation in understanding cellular processes is now widely accepted, and a variety of simulation algorithms useful for studying certain subsystems have been designed. In this article, a sparse compact incremental learning machine (SCILM) is proposed for cancer classification problem on microarray gene expression data, which take advantage of correntropy cost that makes it robust against diverse noises and outliers. Moreover, since \\{SCILM\\} uses l1-norm of the weights, it has sparseness, which can be applied for gene selection purposes as well. Finally, due to compact structure, the proposed method is capable of performing classification tasks in all of the cases with only one neuron in its hidden layer. The experimental analysis is performed on 26 well-known microarray data sets regarding diverse kinds of cancers and the results show that the proposed method not only achieved significantly high accuracy but also because of its sparseness, final connectivity weights determined the value and effectivity of each gene regarding the corresponding cancer.", 
        "author": "Mojtaba Nayyeri and Hossein Sharifi Noghabi", 
        "keyword": "Microarray\", \"Cancer classification\", \"Machine Learning\", \"Incremental Learning Machines\", \"Correntropy", 
        "title": "Cancer classification by correntropy-based sparse compact incremental learning machine"
    }, 
    {
        "abstract": "Abstract In this study, the self-adaptive evolutionary (SaE) agent is employed to structure the contributing elements to process the management of extreme learning machine (ELM) architecture based on a logical procedure. In fact, the SaE algorithm is utilized for possibility of enhancing the performance of the \\{ELM\\} to estimate daily soil temperature (ST) at 6 different depths of 5, 10, 20, 30, 50 and 100 cm. In the developed SaE-ELM model, the network hidden node parameters of the \\{ELM\\} are optimized using SaE algorithm. The precision of the SaE-ELM is then compared with the \\{ELM\\} model. Daily weather data sets including minimum, maximum and average air temperatures (Tmin, Tmax and Tavg), atmospheric pressure (P) and global solar radiation (RS) collected for two Iranian stations of Bandar Abbas and Kerman with different climate conditions have been utilized. After primary evaluation, Tmin, Tmax and Tavg are considered as final inputs for the \\{ELM\\} and SaE-ELM models due to their high correlations with \\{ST\\} at all depths. The achieved results for both stations reveal that both \\{ELM\\} and SaE-ELM models offer desirable performance to estimate daily \\{ST\\} at all depths; nevertheless, a slightly more precision can be obtained by the SaE-ELM model. The performance of the \\{ELM\\} and SaE-ELM models are verified against genetic programming (GP) and artificial neural network (ANN) models developed in this study. For Bandar Abbass station, the obtained mean absolute bias error (MABE) and correlation coefficient (R) for the \\{ELM\\} model at different depths are in the range of 0.9116\u20131.5988 \u00b0C and 0.9023\u20130.9840, respectively while for the SaE-ELM model they are in the range of 0.8660\u20131.5338 \u00b0C and 0.9084\u20130.9893, respectively. In addition, for Kerman Station the attained \\{MABE\\} and \\{RMSE\\} for the \\{ELM\\} model vary from 1.6567 to 2.4233 \u00b0C and 0.8661 to 0.9789, respectively while for the SaE-ELM model they vary from 1.5818 to 2.3422 \u00b0C and 0.8736 to 0.9831, respectively.", 
        "author": "Behnaz Nahvi and Jafar Habibi and Kasra Mohammadi and Shahaboddin Shamshirband and Othman Saleh Al Razgan", 
        "keyword": "Soil temperature\", \"Extreme Learning Machine (ELM)\", \"Self-Adaptive Evolutionary Extreme Learning keywords =achine (SaE-ELM)\", \"Estimation\", \"Agent", 
        "title": "Using self-adaptive evolutionary algorithm to improve the performance of an extreme learning machine for estimating soil temperature"
    }, 
    {
        "abstract": "Abstract Deep learning techniques for Sentiment Analysis have become very popular. They provide automatic feature extraction and both richer representation capabilities and better performance than traditional feature based techniques (i.e., surface methods). Traditional surface approaches are based on complex manually extracted features, and this extraction process is a fundamental question in feature driven methods. These long-established approaches can yield strong baselines, and their predictive capabilities can be used in conjunction with the arising deep learning methods. In this paper we seek to improve the performance of deep learning techniques integrating them with traditional surface approaches based on manually extracted features. The contributions of this paper are sixfold. First, we develop a deep learning based sentiment classifier using a word embeddings model and a linear machine learning algorithm. This classifier serves as a baseline to compare to subsequent results. Second, we propose two ensemble techniques which aggregate our baseline classifier with other surface classifiers widely used in Sentiment Analysis. Third, we also propose two models for combining both surface and deep features to merge information from several sources. Fourth, we introduce a taxonomy for classifying the different models found in the literature, as well as the ones we propose. Fifth, we conduct several experiments to compare the performance of these models with the deep learning baseline. For this, we use seven public datasets that were extracted from the microblogging and movie reviews domain. Finally, as a result, a statistical study confirms that the performance of these proposed models surpasses that of our original baseline on F1-Score.", 
        "author": "Oscar Araque and Ignacio Corcuera-Platas and J. Fernando S\u00e1nchez-Rada and Carlos A. Iglesias", 
        "keyword": "Ensemble\", \"Deep learning\", \"Sentiment analysis\", \"Machine learning\", \"Natural language processing", 
        "title": "Enhancing deep learning sentiment analysis with ensemble techniques in social applications"
    }, 
    {
        "abstract": "Abstract Using \\{MRI\\} to diagnose mental disorders has been a long-term goal. Despite this, the vast majority of prior neuroimaging work has been descriptive rather than predictive. The current study applies support vector machine (SVM) learning to \\{MRI\\} measures of brain white matter to classify adults with Major Depressive Disorder (MDD) and healthy controls. In a precisely matched group of individuals with \\{MDD\\} (n =25) and healthy controls (n =25), \\{SVM\\} learning accurately (74%) classified patients and controls across a brain map of white matter fractional anisotropy values (FA). The study revealed three main findings: 1) \\{SVM\\} applied to \\{DTI\\} derived \\{FA\\} maps can accurately classify \\{MDD\\} vs. healthy controls; 2) prediction is strongest when only right hemisphere white matter is examined; and 3) removing \\{FA\\} values from a region identified by univariate contrast as significantly different between \\{MDD\\} and healthy controls does not change the \\{SVM\\} accuracy. These results indicate that \\{SVM\\} learning applied to neuroimaging data can classify the presence versus absence of \\{MDD\\} and that predictive information is distributed across brain networks rather than being highly localized. Finally, \\{MDD\\} group differences revealed through typical univariate contrasts do not necessarily reveal patterns that provide accurate predictive information.", 
        "author": "David M. Schnyer and Peter C. Clasen and Christopher Gonzalez and Christopher G. Beevers", 
        "keyword": null, 
        "title": "Evaluating the diagnostic utility of applying a machine learning algorithm to diffusion tensor \\{MRI\\} measures in individuals with major depressive disorder"
    }, 
    {
        "abstract": "Abstract Manifold learning techniques have shown a great potential for computer vision problems; however, they do not extend easily to points different from the ones on which they were trained (out-of-sample). On the other hand, extreme learning machine (ELM) is a powerful method that allows to perform nonlinear, multivariate regression. This paper discusses the effectiveness of \\{ELM\\} for the out-of-sample problem and compares it to the state-of-the-art solution : the Nystr\u00f6m extension. Both methods are evaluated through the reconstruction of the manifold learnt using Laplacian eigenmaps, via experiments on a wide range of publicly available image datasets. We show that when reducing the data dimension to its intrinsic dimension, the \\{ELM\\} offers a better approximation of the embedded coordinates, also with reduced computational costs during testing.", 
        "author": "Arturo Mendoza Quispe and Caroline Petitjean and Laurent Heutte", 
        "keyword": "Dimensionality reduction\", \"Manifold learning\", \"Laplacian eigenmaps\", \"Out-of-sample extension\", \"Extreme learning machine", 
        "title": "Extreme learning machine for out-of-sample extension in Laplacian eigenmaps"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel ensemble method for short-term load forecasting based on wavelet transform, extreme learning machine (ELM) and partial least squares regression. In order to improve forecasting performance, a wavelet-based ensemble strategy is introduced into the forecasting model. The individual forecasters are derived from different combinations of mother wavelet and number of decomposition levels. For each sub-component from the wavelet decomposition, a parallel model consisting of 24 \\{ELMs\\} is invoked to predict the hourly load of the next day. The individual forecasts are then combined to form the ensemble forecast using the partial least squares regression method. Numerical results show that the proposed method can significantly improve forecasting performance.", 
        "author": "Song Li and Lalit Goel and Peng Wang", 
        "keyword": "Ensemble method\", \"Extreme learning machine\", \"Partial least squares regression\", \"Short-term load keywords =orecasting\", \"Wavelet transform", 
        "title": "An ensemble approach for short-term load forecasting by extreme learning machine"
    }, 
    {
        "abstract": "Abstract The Critical Clearing Time (CCT) is a key issue for Transient Stability Assessment (TSA) in electrical power system operation, security, and maintenance. However, there are some difficulties in obtaining the CCT, which include the accuracy, fast computation, and robustness for \\{TSA\\} online. Therefore, obtaining the \\{CCT\\} is still an interesting topic for investigation. This paper proposes a new technique for obtaining \\{CCT\\} based on numerical calculations and artificial intelligence techniques. First, the \\{CCT\\} is calculated by the critical trajectory method based on critical generation. Second, the \\{CCT\\} is learned by Extreme Learning Machine (ELM). This proposed method has the ability to obtain the \\{CCT\\} with load changes, different fault occurrences, accuracy, and fast computation, and considering the controller. This proposed method is tested by the \\{IEEE\\} 3-machine 9-bus system and Java-Bali 500 kV 54-machine 25-bus system. The proposed method can provide accurate \\{CCTs\\} with an average error of 0.33% for the Neural Network (NN) method and an average error of 0.06% for the \\{ELM\\} method. The simulation result also shows that this method is a robust algorithm that can address several load changes and different locations of faults occurring. There are 29 load changes used to obtain the CCT, with 20 load changes included for the training process and 9 load changes not included.", 
        "author": "Irrine Budi Sulistiawati and Ardyono Priyadi and Ony Asrarul Qudsi and Adi Soeprijanto and Naoto Yorino", 
        "keyword": "Critical Clearing Time (CCT)\", \"Transient Stability Assessment (TSA)\", \"ELM (Extreme Learning keywords =achine)\", \"Critical trajectory\", \"Load changing", 
        "title": "Critical Clearing Time prediction within various loads for transient stability assessment by means of the Extreme Learning Machine method"
    }, 
    {
        "abstract": "Abstract Big dimensional data is a growing trend that is emerging in many real world contexts, extending from web mining, gene expression analysis, protein\u2013protein interaction to high-frequency financial data. Nowadays, there is a growing consensus that the increasing dimensionality poses impeding effects on the performances of classifiers, which is termed as the \u201cpeaking phenomenon\u201d in the field of machine intelligence. To address the issue, dimensionality reduction is commonly employed as a preprocessing step on the Big dimensional data before building the classifiers. In this paper, we propose an Extreme Learning Machine (ELM) approach for large-scale data analytic. In contrast to existing approaches, we embed hidden nodes that are designed using singular value decomposition (SVD) into the classical ELM. These \\{SVD\\} nodes in the hidden layer are shown to capture the underlying characteristics of the Big dimensional data well, exhibiting excellent generalization performances. The drawback of using \\{SVD\\} on the entire dataset, however, is the high computational complexity involved. To address this, a fast divide and conquer approximation scheme is introduced to maintain computational tractability on high volume data. The resultant algorithm proposed is labeled here as Fast Singular Value Decomposition-Hidden-nodes based Extreme Learning Machine or FSVD-H-ELM in short. In FSVD-H-ELM, instead of identifying the \\{SVD\\} hidden nodes directly from the entire dataset, \\{SVD\\} hidden nodes are derived from multiple random subsets of data sampled from the original dataset. Comprehensive experiments and comparisons are conducted to assess the FSVD-H-ELM against other state-of-the-art algorithms. The results obtained demonstrated the superior generalization performance and efficiency of the FSVD-H-ELM.", 
        "author": "Wan-Yu Deng and Zuo Bai and Guang-Bin Huang and Qing-Hua Zheng", 
        "keyword": "Extreme Learning Machine\", \"Singular value decomposition\", \"Big data\", \"Big dimensional data\", \"Fast approximation method", 
        "title": "A Fast SVD-Hidden-nodes based Extreme Learning Machine for Large-Scale Data Analytics"
    }, 
    {
        "abstract": "Abstract In the past twenty years, skeletal part profiles, which are prone to equifinality, have not occupied a prominent role in the interpretation of early Pleistocene sites on Africa. Alternatively, taphonomic studies on bone surface modifications and bone breakage patterns, have provided heuristic interpretations of some of the best preserved archaeological record of this period; namely, the Olduvai Bed I sites. The most recent and comprehensive taphonomic study of these sites (Dom\u00ednguez-Rodrigo et\u00a0al., 2007a) showed that \\{FLK\\} Zinj was an anthropogenic assemblage in which hominins acquired carcasses via primary access. That study also showed that the other sites were palimpsests with minimal or no intervention by hominins. The \\{FLK\\} N, \\{FLK\\} \\{NN\\} and \\{DK\\} sequence seemed to be dominated by single-agent (mostly, felid) or multiple-agent (mostly, felid-hyenid) processes. The present study re-analyzes the Bed I sites focusing on skeletal part profiles. Machine learning methods, which incorporate complex algorithms, are powerful predictive and classification methods and have the potential to better extract information from skeletal part representation than past approaches. Here, multiple algorithms (via decision trees, neural networks, random forests and support vector machines) are combined to produce a solid interpretation of bone accumulation agency at the Olduvai Bed I sites. This new approach virtually coincides with previous taphonomic interpretations on a site by site basis and shows that felids were dominant accumulating agents over hyenas during Bed I times. The recent discovery of possibly a modern lion-accumulated assemblage at Olduvai Gorge (Arriaza et\u00a0al., submitted) provides a very timely analog for this interpretation.", 
        "author": "Mari Carmen Arriaza and Manuel Dom\u00ednguez-Rodrigo", 
        "keyword": "Skelelal element\", \"MAU\", \"Machine learning\", \"Hominin\", \"Felid\", \"Hyenid\", \"Taphonomy", 
        "title": "When felids and hominins ruled at Olduvai Gorge: A machine learning analysis of the skeletal profiles of the non-anthropogenic Bed I sites"
    }, 
    {
        "abstract": "Abstract Many agitation and mixing processes utilize various sensors for real-time monitoring and control, which can involve complex and costly equipment. For many mixing and agitation processes, such as in dough making, as mixing energy is placed, the resistance to extension increases and then after some point it decreases again. High-quality bread is obtained by stopping mixing at or close to the maximum resistance. The change in resistance causes a change in motor torque. The torque change affects the motor\u2019s current draw for agitation and mixing machines driven by electrical motors. The rheological characteristics of the mixed material are related to motor torque of the mixing machine. Therefore, it is related to the motor electric current where the load variation can be estimated by a low-cost current sensor. This paper outlines a novel design for an intelligent agitator/mixer process controller. The design is based on current sensing and on-line learning through reinforcement learning using operator input. The system provides a low-cost approach to automate various kinds of production equipment currently operated manually, which are common in the developing world. Additionally, the approach requires minimal modification to the equipment: it requires only a current sensor, an on/off control relay, a set of buttons for operation, and an embedded system.", 
        "author": "Ahmad Aljaafreh", 
        "keyword": "Agitation\", \"Mixing\", \"Machine learning\", \"Reinforcement learning", 
        "title": "Agitation and mixing processes automation using current sensing and reinforcement learning"
    }, 
    {
        "abstract": "Abstract Comprehensive models of biomass pyrolysis are needed to develop renewable fuels and chemicals from biomass. Unfortunately, the detailed kinetic schemes required to optimize industrial biomass pyrolysis processes are too computationally expensive to include in models that account for both kinetics and transport within reacting particles. Here we present a machine learning approach using artificial neural networks and decision trees to reduce the computational expense of detailed kinetic models by four orders of magnitude, enabling their use in comprehensive models. The trained neural networks generalize very well, predicting the outputs of the detailed kinetic model with over 99.9% accuracy on new data. The machine learning approach we outline is not specific to kinetic modeling and can be applied to any set of input and output data, even if the underlying relationship between inputs and outputs is unknown.", 
        "author": "Blake R. Hough and David A.C. Beck and Daniel T. Schwartz and Jim Pfaendtner", 
        "keyword": "Neural network\", \"Kinetic modeling\", \"Pyrolysis\", \"Biomass", 
        "title": "Application of machine learning to pyrolysis reaction networks: Reducing model solution time to enable process optimization"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a novel life-long learning framework, which constantly evolves with changing data distribution, learning new knowledge while retaining some old knowledge. In many practical systems, data in the past is still useful but no longer available. Therefore, a question arises on how to update the model based on both new data and current model. To address this issue, our framework lays its basis on ensemble method with multiple sub-classifiers, independent of base type. When new data is processed, new sub-classifiers are generated accordingly. The classifiers are then dynamically combined using decision tree, together with a novelly proposed pruning method to prevent overfitting and eliminate out-dated models. Guarantees are provided to the combination method. Experiments indicate that the framework achieves good performance when the data changes with time, and has better accuracy compared to existing transfer and incremental learning, and methods in stream data mining.", 
        "author": "Boya Ren and Hongzhi Wang and Jianzhong Li and Hong Gao", 
        "keyword": "Machine learning\", \"Life-long learning\", \"Dynamic combination model\", \"Data streams\", \"Decision trees", 
        "title": "Life-long learning based on dynamic combination model"
    }, 
    {
        "abstract": "Abstract Thermal quality of open public spaces in every city influences its residents\u2019 outdoor life. Higher level of thermal comfort attracts more visitors to such places; hence, brings benefits to the community. Previous research works have used the body energy balance or adaptation model for predicting the thermal comfort in outdoor spaces. However, limited research works have applied computational methods in this field. For the first of its\u2019 type, this study applied a systematic approach using a class of soft-computing methodology known as the extreme learning machine (ELM) to forecast the thermal comfort of the subject visitors at an open area in Iran. For data collection, this study used common thermal indices for assessing the thermal perceptions of the subjects. The fieldworks comprised of measuring the microclimatic conditions and interviewing the visitors. This study compared the results of \\{ELM\\} with other conventional soft-computing methods (i.e., artificial neural network (ANN) and genetic programming (GP)). The findings indicate that the \\{ELM\\} results match with the field data. This implies that a model constructed by \\{ELM\\} can accurately predict visitors\u2019 thermal sensations. We conclude that the proposed model\u2019s predictability performance is reliable and superior compared to other approaches (i.e., \\{GP\\} and ANN). Besides, the \\{ELM\\} methodology significantly reduces training time for a Neural Network as compared to the conventional methods.", 
        "author": "Shahab Kariminia and Shahaboddin Shamshirband and Shervin Motamedi and Roslan Hashim and Chandrabhushan Roy", 
        "keyword": "Outdoor thermal comfort\", \"Open urban area\", \"Extreme learning machine\", \"Regression\", \"Moderate keywords =limate\", \"Dry climate", 
        "title": "A systematic extreme learning machine approach to analyze visitors\u05f3 thermal comfort at a public urban space"
    }, 
    {
        "abstract": "Abstract The system of crystal structure has a major effect on the physical and chemical properties of Li-ion silicate cathodes. Hence, the prediction of crystal system has a vital importance to estimate many other properties of cathodes for applications in batteries. Three major crystal systems (monoclinic, orthorhombic and triclinic) of silicate-based cathodes with Li\u2013Si\u2013(Mn, Fe, Co)\u2013O compositions were predicted using wide range of classification algorithms in machine learning. The calculations are based on the results of density functional theory calculations from Materials Project. The strong correlation between the crystal system and other physical properties of the cathodes was confirmed based on the feature evaluation in the statistical models. In addition, the parameters of various classification methods were optimized to obtain the best accuracy of prediction. Ensemble methods including random forests and extremely randomized trees provided the highest accuracy of prediction among other classification methods in the Monte Carlo cross validation tests.", 
        "author": "M. Attarian Shandiz and R. Gauvin", 
        "keyword": "Li-ion batteries\", \"Crystal system\", \"Machine learning\", \"Classification methods\", \"Monte Carlo\", keywords =Ensemble methods\", \"Optimization", 
        "title": "Application of machine learning methods for the prediction of crystal system of cathode materials in lithium-ion batteries"
    }, 
    {
        "abstract": "Abstract This work identifies effective computable features from the Breast Imaging Reporting and Data System (BI-RADS), to develop a computer-aided diagnosis (CAD) system for breast ultrasound. Computerized features corresponding to ultrasound BI-RADs categories were designed and tested using a database of 283 pathology-proven benign and malignant lesions. Features were selected based on classification performance using a\u00a0\u201cbottom-up\u201d approach for different machine learning methods, including decision tree, artificial neural network, random forest and support vector machine. Using 10-fold cross-validation on the database of 283 cases, the highest area under the receiver operating characteristic (ROC) curve (AUC) was 0.84 from a support vector machine with 77.7% overall accuracy; the highest overall accuracy, 78.5%, was from a random forest with the \\{AUC\\} 0.83. Lesion margin and orientation were optimum features common to all of the different machine learning methods. These features can be used in \\{CAD\\} systems to help distinguish benign from worrisome lesions.", 
        "author": "Juan Shan and S. Kaisar Alam and Brian Garra and Yingtao Zhang and Tahira Ahmed", 
        "keyword": "Breast cancer\", \"Computer-aided diagnosis\", \"Computerized features\", \"Breast Imaging Reporting and keywords =ata\u00a0System\", \"BI-RADS\", \"Machine learning\", \"Receiver operating characteristic\", \"Tissue keywords =haracterization\", \"Tumor classification\", \"Ultrasonic imaging", 
        "title": "Computer-Aided Diagnosis for Breast Ultrasound Using Computerized BI-RADS Features and Machine Learning Methods"
    }, 
    {
        "abstract": "AbstractBackground Recent animal and human studies reveal distinct cognitive and neurobiological differences between opiate and stimulant addictions; however, our understanding of the common and specific effects of these two classes of drugs remains limited due to the high rates of polysubstance-dependence among drug users. Methods The goal of the current study was to identify multivariate substance-specific markers classifying heroin dependence (HD) and amphetamine dependence (AD), by using machine-learning approaches. Participants included 39 amphetamine mono-dependent, 44 heroin mono-dependent, 58 polysubstance dependent, and 81 non-substance dependent individuals. The majority of substance dependent participants were in protracted abstinence. We used demographic, personality (trait impulsivity, trait psychopathy, aggression, sensation seeking), psychiatric (attention deficit hyperactivity disorder, conduct disorder, antisocial personality disorder, psychopathy, anxiety, depression), and neurocognitive impulsivity measures (Delay Discounting, Go/No-Go, Stop Signal, Immediate Memory, Balloon Analogue Risk, Cambridge Gambling, and Iowa Gambling tasks) as predictors in a machine-learning algorithm. Results The machine-learning approach revealed substance-specific multivariate profiles that classified \\{HD\\} and \\{AD\\} in new samples with high degree of accuracy. Out of 54 predictors, psychopathy was the only classifier common to both types of addiction. Important dissociations emerged between factors classifying \\{HD\\} and AD, which often showed opposite patterns among individuals with \\{HD\\} and AD. Conclusions These results suggest that different mechanisms may underlie \\{HD\\} and AD, challenging the unitary account of drug addiction. This line of work may shed light on the development of standardized and cost-efficient clinical diagnostic tests and facilitate the development of individualized prevention and intervention programs for \\{HD\\} and AD.", 
        "author": "Woo-Young Ahn and Jasmin Vassileva", 
        "keyword": "Heroin\", \"Amphetamines\", \"Addiction\", \"Protracted abstinence\", \"Impulsivity\", \"Machine-learning", 
        "title": "Machine-learning identifies substance-specific behavioral markers for opiate and stimulant dependence"
    }, 
    {
        "abstract": "Abstract Lamb muscle discrimination is important for the meat industry due to the different pricing of each type of muscle. In this paper, we combine hyperspectral imaging, operating in the wavelength range 380\u20131028\u00a0nm, with several machine learning algorithms to deal automatically with the classification of lamb muscles. More specifically, we study the discrimination of four different lamb muscles, namely, Longissimus dorsi, Psoas major, Semimembranosus and Semitendinosus from thirty lambs of Churra Galega Mirandesa breed. The objective of the paper is to determine the best method for muscle classification. In the experimental study we report an analysis of the performance of seven classifiers. We study their behavior when they are applied over the original data as well as over the data pre-processed using Principal Component Analysis (PCA) to reduce the dimensionality of the problem. The seven classifiers used to differentiate the muscle types are two Artificial Neural Networks, namely the linear Least Mean Squares (LMS) classifier and the Multilayer Perceptron with Scaled Conjugate Gradient (MLP-SCG), two Support Vector Machines (SVM), namely the \u03bd \\{SVM\\} and the \\{SVM\\} trained with Sequential Minimal Optimization (SMO), the Logistic Regression (LR), the Center Based Nearest Neighbor classifier and the Linear Discriminant Analysis. The best result, determined using a leave-one-animal-out scheme, is provided by the linear \\{LMS\\} classifier using the original data, since it correctly classifies 96.67% of the samples. The LR, the MLP-SCG using original data and the \\{SVM\\} trained with \\{SMO\\} on data preprocessed with \\{PCA\\} are also suitable techniques to tackle the lamb muscle classification problem.", 
        "author": "Jose Antonio Sanz and Armando M. Fernandes and Edurne Barrenechea and Severiano Silva and Virginia Santos and Norberto Gon\u00e7alves and Daniel Paternain and Aranzazu Jurio and Pedro Melo-Pinto", 
        "keyword": "Lamb muscle\", \"Hyperspectral imaging\", \"Classification\", \"Machine learning", 
        "title": "Lamb muscle discrimination using hyperspectral imaging: Comparison of various machine learning algorithms"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) proposes a non-iterative training method for Single Layer Feedforward Neural Networks that provides an effective solution for classification and prediction problems. Its hardware implementation is an important step towards fast, accurate and reconfigurable embedded systems based on neural networks, allowing to extend the range of applications where neural networks can be used, especially where frequent and fast training, or even real-time training, is required. This work proposes three hardware architectures for on-chip \\{ELM\\} training computation and implementation, a sequential and two parallel. All three are implemented parameterizably on \\{FPGA\\} as an \\{IP\\} (Intellectual Property) core. Results describe performance, accuracy, resources and power consumption. The analysis is conducted parametrically varying the number of hidden neurons, number of training patterns and internal bit-length, providing a guideline on required resources and level of performance that an \\{FPGA\\} based \\{ELM\\} training can provide.", 
        "author": "Jose V. Frances-Villora and A. Rosado-Mu\u00f1oz and Jos\u00e9 M. Mart\u00ednez-Villena and Manuel Bataller-Mompean and Juan Fco. Guerrero and Marek Wegrzyn", 
        "keyword": "FPGA\", \"Extreme Learning Machine - ELM\", \"Neural network training\", \"Neural network hardware\", keywords =On-chip machine learning\", \"Embedded systems", 
        "title": "Hardware implementation of real-time Extreme Learning Machine in FPGA: Analysis of precision, resource occupation and performance"
    }, 
    {
        "abstract": "Abstract Selection of relevant and appropriate features to characterize breast patterns is of paramount importance in breast tissue representation and classification in machine learning paradigm. Feature selection based on single evaluation criterion has shown limited capability in breast tumor detection and classification due to their biases towards single criterion. In this paper, a new hybrid feature selection scheme is used to determine most relevant features for classification of benign and malignant tumors in breast ultrasound images. The proposed approach uses ten different evaluation criteria to decide the relevance of a particular feature. The existing feature selection techniques are also reviewed. A new database of 178 breast ultrasound images consisting of 88 benign and 90 malignant cases are used in experiments. The performance of the proposed approach is compared with that of existing feature selection techniques using back-propagation artificial neural network (BPANN) and support vector machine (SVM) based classifiers. The results demonstrate that proposed feature selection approach outperformed traditional methods achieving significantly higher classification accuracy of 96.6% and 94.4% with \\{BPANN\\} and \\{SVM\\} classifiers respectively.", 
        "author": "Bikesh Kumar Singh and Kesari Verma and A.S. Thoke and Jasjit S. Suri", 
        "keyword": "Ultrasound images\", \"Breast cancer\", \"Feature selection\", \"Relevant features\", \"Classification accuracy", 
        "title": "Risk stratification of 2D ultrasound-based breast lesions using hybrid feature selection in machine learning paradigm"
    }, 
    {
        "abstract": "Abstract In this paper, we present a fast and accurate kernel-based supervised algorithm referred to as the Reduced Kernel Extreme Learning Machine (RKELM). In contrast to the work on Support Vector Machine (SVM) or Least Square \\{SVM\\} (LS-SVM), which identifies the support vectors or weight vectors iteratively, the proposed \\{RKELM\\} randomly selects a subset of the available data samples as support vectors (or mapping samples). By avoiding the iterative steps of SVM, significant cost savings in the training process can be readily attained, especially on Big datasets. \\{RKELM\\} is established based on the rigorous proof of universal learning involving reduced kernel-based SLFN. In particular, we prove that \\{RKELM\\} can approximate any nonlinear functions accurately under the condition of support vectors sufficiency. Experimental results on a wide variety of real world small instance size and large instance size applications in the context of binary classification, multi-class problem and regression are then reported to show that \\{RKELM\\} can perform at competitive level of generalized performance as the SVM/LS-SVM at only a fraction of the computational effort incurred.", 
        "author": "Wan-Yu Deng and Yew-Soon Ong and Qing-Hua Zheng", 
        "keyword": "Extreme learning machine\", \"Kernel method\", \"Support vector machine\", \"RBF network", 
        "title": "A Fast Reduced Kernel Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract For a sustainable integration of wind power into the electricity grid, a precise prediction method is required. In this work, we investigate the use of machine learning ensembles for wind power prediction. We first analyze homogeneous ensemble regressors that make use of a single base algorithm and compare decision trees to k-nearest neighbors and support vector regression. As next step, we construct heterogeneous ensembles that make use of multiple base algorithms and benefit from a gain of diversity among the weak predictors. In the experimental evaluation, we show that a combination of decision trees and support vector regression outperforms state-of-the-art predictors (improvements of up to 37% compared to support vector regression) as well as homogeneous ensembles while requiring a shorter runtime (speed-ups from 1.60\u00d7 to 8.78\u00d7). Furthermore, we show the heterogeneous ensemble prediction can be improved when using high-dimensional patterns by increasing the number of past steps considered and hereby the spatio-temporal information available by the measurements of the nearby turbines. The experiments are based on a large wind time series data set from simulations and real measurements.", 
        "author": "Justin Heinermann and Oliver Kramer", 
        "keyword": "Wind power prediction\", \"Machine learning ensembles\", \"Multi-inducer\", \"Heterogeneous ensembles\", keywords =Decision trees\", \"Support vector regression", 
        "title": "Machine learning ensembles for wind power prediction"
    }, 
    {
        "abstract": "Abstract In this work, the problems of knowledge acquisition and information processing are explored in relation to the definitions of concepts and conceptual processing, and their implications for artificial agents. The discussion focuses on views of cognition as a dynamic property in which the world is actively represented in grounded mental states which only have meaning in the action context. Reasoning is understood as an emerging property consequence of actions-environment couplings achieved through experience, and concepts as situated and dynamic phenomena enabling behaviours. Re-framing the characteristics of concepts is considered crucial to overcoming settled beliefs and reinterpreting new understandings in artificial systems. The first part presents a review of concepts from cognitive sciences. Support is found for views on grounded and embodied cognition, describing concepts as dynamic, flexible, context-dependent, and distributedly coded. That is argued to contrast with many technical implementations assuming concepts as categories, whilst explains limitations when grounding amodal symbols, or in unifying learning, perception and reasoning. The characteristics of concepts are linked to methods of active inference, self-organization, and deep learning to address challenges posed and to reinterpret emerging techniques. In a second part, an architecture based on deep generative models is presented to illustrate arguments elaborated. It is evaluated in a navigation task, showing that sufficient representations are created regarding situated behaviours with no semantics imposed on data. Moreover, adequate behaviours are achieved through a dynamic integration of perception and action in a single representational domain and process.", 
        "author": "Juan Sebastian Olier and Emilia Barakova and Carlo Regazzoni and Matthias Rauterberg", 
        "keyword": "Concepts\", \"Conceptual representations\", \"Cognition\", \"Artificial intelligence\", \"Robotics\", \"Machine Learning", 
        "title": "Re-framing the characteristics of concepts and their relation to learning and cognition in artificial agents"
    }, 
    {
        "abstract": "Abstract Energy efficiency is a critical element of building energy conservation. Energy Information Administration (EIA) and International Electrotechnical Commission (IEC) estimated that over 6% of electrical energy was lost during transmission and distribution. Sensing and tracking technologies, and data-mining offer new windows to better understanding these losses in real-time. Recent developments in energy optimization computational methods also allow engineers to better characterize energy consumption load profiles. The paper focuses on developing new and robust data-mining techniques to explore large and complex data generated by sensing and tracking technologies. These techniques would potentially offer new avenues to understand and prevent energy losses during transmission. The paper presents two new concepts: First, a set of clustering algorithms that model the supply-demand characterization of four different substations clusters, and second, a semi-supervised machine learning and clustering technique are developed to optimize the losses and automate the process of identifying loss factors contributing to the total loss. This three-step process uses real-time data from buildings and the substations that supply electricity to the buildings to develop the proposed technique. The preliminary findings of this paper help the utility service providers to understand the energy supply-demand requirements.", 
        "author": "Hariharan Naganathan and Wai Oswald Chong and Xuewen Chen", 
        "keyword": "Building clustering\", \"Electricity losses\", \"Data mining\", \"Semi-supervised learning\", \"Deep-learning framework", 
        "title": "Building energy modeling (BEM) using clustering algorithms and semi-supervised machine learning approaches"
    }, 
    {
        "abstract": "Abstract The shape features of wear particles generated from wear track usually contain plenty of information about the wear states of a machinery operational condition. Techniques to quickly identify types of wear particles quickly to respond to the machine operation and prolong the machine\u05f3s life appear to be lacking and are yet to be established. To bridge rapid off-line feature recognition with on-line wear mode identification, this paper presents a new radial concave deviation (RCD) method that mainly involves the use of the particle boundary signal to analyze wear particle features. Signal output from the \\{RCDs\\} subsequently facilitates the determination of several other feature parameters, typically relevant to the shape and size of the wear particle. Debris feature and type are identified through the use of various classification methods, such as linear discriminant analysis, quadratic discriminant analysis, na\u00efve Bayesian method, and classification and regression tree method (CART). The average errors of the training and test via ten-fold cross validation suggest \\{CART\\} is a highly suitable approach for classifying and analyzing particle features. Furthermore, the results of the wear debris analysis enable the maintenance team to diagnose faults appropriately.", 
        "author": "Wei Yuan and K.S. Chin and Meng Hua and Guangneng Dong and Chunhui Wang", 
        "keyword": "Wear particles\", \"Image processing\", \"Radial concave deviation\", \"Particle classification\", \"Machine learning", 
        "title": "Shape classification of wear particles by image boundary analysis using machine learning algorithms"
    }, 
    {
        "abstract": "Abstract This paper proposes a fast and effective sequential active learning method using meta-cognitive extreme learning machine (SEAL-ELM). The proposed algorithm consists of two components, namely the cognitive component and the meta-cognitive component. The cognitive component is an online sequential extreme learning machine while the meta-cognitive component controls the learning process of the cognitive component using a self-regulating mechanism to decide what to learn, when to learn and how to learn the arriving samples. Active learning is employed to select different strategies, namely sample deletion, sample reserve and sample learning strategy to determine whether the data will be deleted directly, reserved for later use or used immediately. This is the first time the similarity of meta-cognitive machine learning and active learning is exploited. The meta-cognition mechanism and active learning principle are utilized to reduce the labeling efforts and costs. The use of \\{ELM\\} greatly reduces the computation complexity of the learning process. The new algorithm is evaluated on a set of real-world benchmark classification problems. Simulation results demonstrate the usefulness and effectiveness of sequential active learning and show that the SEAL-ELM can achieve similar or better learning accuracy with a much faster learning speed compared with the state-of-the-arts algorithms.", 
        "author": "Yong Zhang and Meng Joo Er", 
        "keyword": "Active learning\", \"Extreme learning machine\", \"Meta-cognition\", \"Sequential learning", 
        "title": "Sequential active learning using meta-cognitive extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, we explore the potential of extreme learning machine (ELM) and kernel \\{ELM\\} (KELM) for early diagnosis of Parkinson\u2019s disease (PD). In the proposed method, the key parameters including the number of hidden neuron and type of activation function in ELM, and the constant parameter C and kernel parameter \u03b3 in \\{KELM\\} are investigated in detail. With the obtained optimal parameters, \\{ELM\\} and \\{KELM\\} manage to train the optimal predictive models for \\{PD\\} diagnosis. In order to further improve the performance of \\{ELM\\} and \\{KELM\\} models, feature selection techniques are implemented prior to the construction of the classification models. The effectiveness of the proposed method has been rigorously evaluated against the \\{PD\\} data set in terms of classification accuracy, sensitivity, specificity and the area under the \\{ROC\\} (receiver operating characteristic) curve (AUC). Compared to the existing methods in previous studies, the proposed method has achieved very promising classification accuracy via 10-fold cross-validation (CV) analysis, with the highest accuracy of 96.47% and average accuracy of 95.97% over 10 runs of 10-fold CV.", 
        "author": "Hui-Ling Chen and Gang Wang and Chao Ma and Zhen-Nao Cai and Wen-Bin Liu and Su-Jing Wang", 
        "keyword": "Kernel extreme learning machine\", \"Feature selection\", \"Medical diagnosis\", \"Parkinson\u05f3s disease", 
        "title": "An efficient hybrid kernel extreme learning machine approach for early diagnosis of Parkinson\u05f3s disease"
    }, 
    {
        "abstract": "Abstract Identifying diffuse axonal injury (DAI) in patients with traumatic brain injury (TBI) presenting with normal appearing radiological \\{MRI\\} presents a significant challenge. Neuroimaging methods such as diffusion \\{MRI\\} and probabilistic tractography, which probe the connectivity of neural networks, show significant promise. We present a machine learning approach to classify \\{TBI\\} participants primarily with mild traumatic brain injury (mTBI) based on altered structural connectivity patterns derived through the network based statistical analysis of structural connectomes generated from \\{TBI\\} and age-matched control groups. In this approach, higher order diffusion models were used to map white matter connections between 116 cortical and subcortical regions. Tracts between these regions were generated using probabilistic tracking and mean fractional anisotropy (FA) measures along these connections were encoded in the connectivity matrices. Network-based statistical analysis of the connectivity matrices was performed to identify the network differences between a representative subset of the two groups. The affected network connections provided the feature vectors for principal component analysis and subsequent classification by random forest. The validity of the approach was tested using data acquired from a total of 179 \\{TBI\\} patients and 146 controls participants. The analysis revealed altered connectivity within a number of intra- and inter-hemispheric white matter pathways associated with DAI, in consensus with existing literature. A mean classification accuracy of 68.16% \u00b1 1.81% and mean sensitivity of 80.0% \u00b1 2.36% were achieved in correctly classifying the \\{TBI\\} patients evaluated on the subset of the participants that was not used for the statistical analysis, in a 10-fold cross-validation framework. These results highlight the potential for statistical machine learning approaches applied to structural connectomes to identify patients with diffusive axonal injury.", 
        "author": "Jhimli Mitra and Kai-kai Shen and Soumya Ghose and Pierrick Bourgeat and Jurgen Fripp and Olivier Salvado and Kerstin Pannek and D. Jamie Taylor and Jane L. Mathias and Stephen Rose", 
        "keyword": "Diffusion tractography\", \"Structural network connections\", \"Traumatic brain injury\", \"Network-based keywords =tatistics\", \"Machine learning", 
        "title": "Statistical machine learning to identify traumatic brain injury (TBI) from structural disconnections of white matter networks"
    }, 
    {
        "abstract": "Abstract Slope stability assessment is a critical research area in civil engineering. Disastrous consequences of slope collapse necessitate better tools for predicting their occurrences. This research proposes a hybrid Artificial Intelligence (AI) for slope stability assessment based on metaheuristic and machine learning. The contribution of this study to the body of knowledge is multifold. First, advantages of the Firefly Algorithm (FA) and the Least Squares Support Vector Classification (LS-SVC) are combined to establish an integrated slope prediction model. Second, an inner cross-validation with the operating characteristic curve computation is embedded in the training process to reliably construct the machine learning model. Third, the FA, an effective and easily implemented metaheuristic, is employed to optimize the model construction process by appropriately selecting the LS-SVM's hyper-parameters. Finally, a dataset that contains 168 real cases of slope evaluation, recorded in various countries, is used to establish and confirm the proposed hybrid approach. Experimental results demonstrate that the new hybrid \\{AI\\} model has achieved roughly 4% improvement in classification accuracy compared with other benchmark methods.", 
        "author": "Nhat-Duc Hoang and Anh-Duc Pham", 
        "keyword": "Slope assessment\", \"Metaheuristic\", \"Machine learning\", \"Least squares support vector keywords =lassification\", \"Firefly algorithm", 
        "title": "Hybrid artificial intelligence approach based on metaheuristic and machine learning for slope stability assessment: A multinational data analysis"
    }, 
    {
        "abstract": "AbstractObjective A growing body of evidence has put forward clinical risk factors associated with patients with mood disorders that attempt suicide. However, what is not known is how to integrate clinical variables into a clinically useful tool in order to estimate the probability of an individual patient attempting suicide. Method A total of 144 patients with mood disorders were included. Clinical variables associated with suicide attempts among patients with mood disorders and demographic variables were used to \u2018train\u2019 a machine learning algorithm. The resulting algorithm was utilized in identifying novel or \u2018unseen\u2019 individual subjects as either suicide attempters or non-attempters. Three machine learning algorithms were implemented and evaluated. Results All algorithms distinguished individual suicide attempters from non-attempters with prediction accuracy ranging between 65% and 72% (p&lt;0.05). In particular, the relevance vector machine (RVM) algorithm correctly predicted 103 out of 144 subjects translating into 72% accuracy (72.1% sensitivity and 71.3% specificity) and an area under the curve of 0.77 (p&lt;0.0001). The most relevant predictor variables in distinguishing attempters from non-attempters included previous hospitalizations for depression, a history of psychosis, cocaine dependence and post-traumatic stress disorder (PTSD) comorbidity. Conclusion Risk for suicide attempt among patients with mood disorders can be estimated at an individual subject level by incorporating both demographic and clinical variables. Future studies should examine the performance of this model in other populations and its subsequent utility in facilitating selection of interventions to prevent suicide.", 
        "author": "Ives Cavalcante Passos and Benson Mwangi and Bo Cao and Jane E. Hamilton and Mon-Ju Wu and Xiang Yang Zhang and Giovana B. Zunta-Soares and Joao Quevedo and Marcia Kauer-Sant\u2019Anna and Fl\u00e1vio Kapczinski and Jair C. Soares", 
        "keyword": "Suicide\", \"Bipolar disorder\", \"Depression\", \"Machine learning\", \"Big data\", \"Personalized medicine", 
        "title": "Identifying a clinical signature of suicidality among patients with mood disorders: A pilot study using a machine learning approach"
    }, 
    {
        "abstract": "Abstract In today's large-scaled distributed learning, it often involves a large number of machines. Coordination between them can be very complicated. In order to emphasize the importance of the organic relationships between machines, we introduce the organization theories of human society, such as cooperation and competition, to machine learning. We design two type of multi-agents along with their interaction rules, and then perform the simulation on Swarm platform. The dynamic processes of the simulated team machine learning are examined and the results show that, by elaborately designed interaction rules, the overall performance of team learning can be promoted dramatically and coordination structure of the machines can be optimized.", 
        "author": "Tie Li and Yi Peng and Yong Shi and Gang Kou", 
        "keyword": "Team machine learning\", \"Distributed computing\", \"Co-competition\", \"Multi-agent-based simulation", 
        "title": "Study on Multi-agent Based Simulation of Team Machine Learning"
    }, 
    {
        "abstract": "Abstract We propose and develop SG-ELM, a stable online learning algorithm based on stochastic gradients and Extreme Learning Machines (ELM). We propose SG-ELM particularly for systems that are required to be stable during learning; i.e., the estimated model parameters remain bounded during learning. We use a Lyapunov approach to prove both asymptotic stability of estimation error and boundedness in the model parameters suitable for identification of nonlinear dynamic systems. Using the Lyapunov approach, we determine an upper bound for the learning rate of SG-ELM. The SG-ELM algorithm not only guarantees a stable learning but also reduces the computational demand compared to the recursive least squares based OS-ELM algorithm (Liang et al., 2006). In order to demonstrate the working of SG-ELM on a real-world problem, an advanced combustion engine identification is considered. The algorithm is applied to two case studies: An online regression learning for system identification of a Homogeneous Charge Compression Ignition (HCCI) Engine and an online classification learning (with class imbalance) for identifying the dynamic operating envelope. The case studies demonstrate that the accuracy of the proposed SG-ELM is comparable to that of the OS-ELM approach but adds stability and a reduction in computational effort.", 
        "author": "Vijay Manikandan Janakiraman and XuanLong Nguyen and Dennis Assanis", 
        "keyword": "Online learning\", \"Extreme learning machine\", \"System identification\", \"Lyapunov stability\", keywords =Engine control\", \"Operating envelope", 
        "title": "Stochastic gradient based extreme learning machines for stable online learning of advanced combustion engines"
    }, 
    {
        "abstract": "Abstract Machine-learning is the automated process of uncovering patterns in large datasets using computer-based statistical models, where a fitted model may then be used for prediction purposes on new data. Despite the growing number of machine-learning algorithms that have been developed, relatively few studies have provided a comparison of an array of different learners \u2014 typically, model comparison studies have been restricted to a comparison of only a few models. This study evaluates and compares a suite of 10 machine-learners as classification algorithms for the prediction of soil taxonomic units in the Lower Fraser Valley, British Columbia, Canada. A variety of machine-learners (CART, \\{CART\\} with bagging, Random Forest, k-nearest neighbor, nearest shrunken centroid, artificial neural network, multinomial logistic regression, logistic model trees, and support vector machine) were tested in the extraction of the complex relationships between soil taxonomic units (great groups and orders) from a conventional soil survey and a suite of 20 environmental covariates representing the topography, climate, and vegetation of the study area. Methods used to extract training data from a soil survey included by-polygon, equal-class, area-weighted, and area-weighted with random over sampling (ROS) approaches. The fitted models, which consist of the soil-environmental relationships, were then used to predict soil great groups and orders for the entire study area at a 100 m spatial resolution. The resulting maps were validated using 262 points from legacy soil data. On average, the area-weighted sampling approach for developing training data from a soil survey was most effective. Using a validation of R = 1 cell, the k-nearest neighbor and support vector machine with radial basis function resulted in the highest accuracy of 72% for great groups using ROS; however, models such as \\{CART\\} with bagging, logistic model trees, and Random Forest were preferred due to the speed of parameterization and the interpretability of the results while resulting in similar accuracies ranging from 65\u201370% using the area-weighted sampling approach. Model choice and sample design greatly influenced outputs. This study provides a comprehensive comparison of machine-learning techniques for classification purposes in soil science and may assist in model selection for digital soil mapping and geomorphic modeling studies in the future.", 
        "author": "Brandon Heung and Hung Chak Ho and Jin Zhang and Anders Knudby and Chuck E. Bulmer and Margaret G. Schmidt", 
        "keyword": "Digital soil mapping\", \"Machine-learning\", \"Soil classification\", \"Data-mining\", \"Model comparison", 
        "title": "An overview and comparison of machine-learning techniques for classification purposes in digital soil mapping"
    }, 
    {
        "abstract": "Abstract Graphics Processing Units (GPUs) are effective tools for improving the efficiency of many computationally demanding algorithms. \\{GPUs\\} have been particularly effective at speeding up the evaluation stage of evolutionary machine learning systems. The speedups obtained in these tasks, depend on many factors: dataset characteristics, the parallel strategy of the \\{GPU\\} code and the fit of the \\{GPU\\} code within the rest of the learning system. A solid understanding of all these factors is required to choose and adjust the most suitable \\{GPU\\} strategy in different scenarios. In this paper we present a large-scale performance evaluation of two \\{GPU\\} strategies for speeding up the evaluation of evolutionary machine learning systems. We use highly-tuneable synthetic problems to exhaustively explore the space of problem characteristics and determine the type of problems where each strategy performs best. The lessons learnt from this extensive evaluation are further confirmed by running experiments on a broad range of real-world datasets. Through this thorough evaluation we obtain a solid understanding of the capabilities and limitations of the evaluated \\{GPU\\} strategies for boosting the efficiency of evolutionary machine learning systems.", 
        "author": "Mar\u00eda A. Franco and Jaume Bacardit", 
        "keyword": "Evolutionary machine learning\", \"Large-scale data mining\", \"Graphics Processing Units", 
        "title": "Large-scale experimental evaluation of \\{GPU\\} strategies for evolutionary machine learning"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel algorithm, termed random Fourier extreme learning machine with \u2113 2 , 1 -norm regularization, to improve the robustness and compactness of the widely used extreme learning machine. In specific, we firstly introduce the random Fourier mappings as activation functions to approximate the Gaussian kernel, with the aim to improve the extendibility of the powerful kernel \\{ELM\\} algorithms. We then adopt the \u2113 2 , 1 -norm to eliminate the potential irrelevant neurons, resulting in a more compact and discriminative hidden layer. After that, we propose an efficient algorithm with proved convergence to solve the resultant optimization problem. Extensive experiments have been conducted on 30 benchmark data sets to compare the proposed algorithm with six popular extreme learning algorithms. As observed, our algorithm outperforms the enumerated hidden layer reinforcement algorithms. In addition, it significantly improves the computational efficiency of Gaussian kernel extreme learning machine with comparable classification and regression performance in large scale learning scenarios.", 
        "author": "Sihang Zhou and Xinwang Liu and Qiang Liu and Siqi Wang and Chengzhang Zhu and Jianping Yin", 
        "keyword": "Extreme learning machine\", \"\u2113 2 , 1 -norm regularization\", \"Random Fourier mapping\", \"Kernel learning", 
        "title": "Random Fourier extreme learning machine with -norm regularization"
    }, 
    {
        "abstract": "Abstract Crop yield forecast models for barley, canola and spring wheat grown on the Canadian Prairies were developed using vegetation indices derived from satellite data and machine learning methods. Hierarchical clustering was used to group the crop yield data from 40 Census Agricultural Regions (CARs) into several larger regions for building the forecast models. The Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI) derived from the Moderate-resolution Imaging Spectroradiometer (MODIS), and \\{NDVI\\} derived from the Advanced Very High Resolution Radiometer (AVHRR) were considered as predictors for crop yields. Multiple linear regression (MLR) and two nonlinear machine learning models \u2013 Bayesian neural networks (BNN) and model-based recursive partitioning (MOB) \u2013 were used to forecast crop yields, with various combinations of MODIS-NDVI, MODIS-EVI and NOAA-NDVI as predictors. Crop yield forecasts made using predictors from July and earlier were evaluated by the cross-validated mean absolute error skill score (in reference to climatological forecasts) during 2000\u20132011. While MODIS-NDVI was found to be the most effective predictor for all three crops, having MODIS-EVI as an additional predictor enhanced the forecast skills. While MLR, \\{BNN\\} and \\{MOB\\} all showed significantly higher skills than climatological forecasts for all three crops, barley was the only case where the nonlinear \\{BNN\\} and \\{MOB\\} models showed slightly higher skills than MLR. The lack of skill improvement by nonlinear models over \\{MLR\\} is likely due to the short (12 years) record available for \\{MODIS\\} data, which limits our study to 2000\u20132011, with very low yields coming from a single severe drought year (2002).", 
        "author": "Michael D. Johnson and William W. Hsieh and Alex J. Cannon and Andrew Davidson and Fr\u00e9d\u00e9ric B\u00e9dard", 
        "keyword": "Canadian Prairies\", \"Crop yield forecasting\", \"Remote sensing\", \"MODIS\", \"NDVI\", \"EVI\", \"Machine keywords =earning\", \"Artificial neural networks", 
        "title": "Crop yield forecasting on the Canadian Prairies by remotely sensed vegetation indices and machine learning methods"
    }, 
    {
        "abstract": "Abstract High-dimensional shape descriptors (HDSD) are useful for modeling subcortical brain surface morphometry. Though \\{HDSD\\} is a useful basis for disease biomarkers, its high dimensionality requires careful treatment in its application to machine learning to mitigate the curse of dimensionality. We explored the use of \\{HDSD\\} feature sets by comparing the performance of two feature selection approaches, Regularized Random Forest (RRF) and LASSO, to no feature selection (NFS). Each feature set was applied to three classifiers: Random Forest (RF), Support Vector Machines (SVM) and Na\u00efve Bayes (NB). Paired feature-selection-classifier approaches were 10-fold cross-validated on two diagnostic contrasts: Alzheimer's disease and mild cognitive impairment, both relative to controls across varying sample sizes to evaluate their robustness. \\{LASSO\\} aided classification efficiency, however, \\{RRF\\} and \\{NFS\\} afforded more robust performances. Performance varied considerably by classifier with \\{RF\\} being most stable. We advise careful consideration of performance-efficiency tradeoffs in choosing feature selection strategies for HDSD.", 
        "author": "Benjamin S.C. Wade and Shantanu H. Joshi and Boris A. Gutman and Paul M. Thompson", 
        "keyword": "Feature selection\", \"Shape analysis\", \"Biomarker\", \"Brain\", \"Subcortical", 
        "title": "Machine learning on high dimensional shape data from subcortical brain surfaces: A comparison of feature selection and classification methods"
    }, 
    {
        "abstract": "Abstract Inefficient controlling strategies in heating and cooling systems have given rise to a large amount of energy waste and to widespread complaints about the thermal environment in buildings. An intelligent control method based on a support vector machine (SVM) classifier is proposed in this paper. Skin temperatures are the only inputs to the model and have shown attractive prediction power in recognizing steady state thermal demands. Data were accumulated from two studies to consider potential use for either individuals or a group of occupants. Using a single skin temperature correctly predicts 80% of thermal demands. Using combined skin temperatures from different body segments can improve the model to over 90% accuracy. Results show that three skin locations contained enough information for classification and more would cause the curse of dimensionality. Models using different skin temperatures were compared. Optimal parameters for each model were provided using grid search technique. Considering the overfitting possibility and the cases without learning processes, \\{SVM\\} classifiers with a linear kernel are preferred over Gaussian kernel ones.", 
        "author": "Changzhi Dai and Hui Zhang and Edward Arens and Zhiwei Lian", 
        "keyword": "Thermal environment\", \"Skin temperature\", \"Support vector machine\", \"Intelligent control", 
        "title": "Machine learning approaches to predict thermal demands using skin temperatures: Steady-state conditions"
    }, 
    {
        "abstract": "Abstract A novel approach to extreme learning machine (ELM) ensembles is proposed. It incorporates majority voting into the recently proposed q-generalized random neural network (QRNN) to make the final decision for classification problems. Individual \\{ELMs\\} are trained with q-Gaussian activation functions using different values of the parameter q (called the entropic index). As a result, these classifiers are generally more accurate than traditional ELMs. Simulations on 45 machine learning data sets show that this method, termed voting based q-generalized extreme learning machine (V-QELM), outperforms other extreme learning machine ensembles. Statistical tests (Wilcoxon, Friedman, and Nemenyi) are used to validate statistical differences between our results. Kappa-error diagrams reveal that V-QELM constructs more accurate classifiers than those found in other ensemble methods. This implies that incorporating \\{QRNNs\\} can lead to higher performing ensembles of extreme learning machines.", 
        "author": "Dusan Stosic and Darko Stosic and Teresa Ludermir", 
        "keyword": "Neural networks\", \"Extreme learning machines\", \"Tsallis statistics\", \"Ensemble methods\", \"Majority voting", 
        "title": "Voting based q-generalized extreme learning machine"
    }, 
    {
        "abstract": "Abstract This research shows that inductive bias provides a valuable method to effectively tackle semi-supervised classification problems. In the learning theory framework, inductive bias provides a powerful tool, and allows one to shape the generalization properties of a learning machine. The paper formalizes semi-supervised learning as a supervised learning problem biased by an unsupervised reference solution. The resulting semi-supervised classification framework can apply any clustering algorithm to derive the reference function, thus ensuring maximum flexibility. In this context, the paper derives the biased version of Extreme Learning Machine (br-ELM). The experimental session involves several real world problems and proves the reliability of the semi-supervised classification scheme.", 
        "author": "Federica Bisio and Sergio Decherchi and Paolo Gastaldo and Rodolfo Zunino", 
        "keyword": "Extreme Learning Machine\", \"Semi-supervised learning\", \"Inductive bias", 
        "title": "Inductive bias for semi-supervised extreme learning machine"
    }, 
    {
        "abstract": "Abstract Machine learning has attracted increasing interest in medical image computing and computer-assisted intervention, and plays an important role in image-based computer-aided diagnosis in digital pathology. In particular, machine learning is able to effectively and efficiently handle the complexity and diversity of microscopic images. This chapter presents several popular machine learning techniques and their applications in microscopic image analysis. It starts by introducing the background of automated microscopic image analysis and explaining the reasons why machine learning is in urgent need of data analysis in biology and medicine. Next, it specifically discusses two supervised learning methods for automated nucleus and cell detection on various microscopy images, and then explains another two popular machine learning techniques and describes their applications in nucleus and cell segmentation on different staining pathology images. Finally, it presents one major challenge of nucleus/cell detection and segmentation and provides a potential trend of algorithm design.", 
        "author": "F. Xing and L. Yang", 
        "keyword": "Machine learning\", \"Microscopic image analysis\", \"Nucleus\", \"Cell\", \"Detection\", \"Segmentation", 
        "title": "Chapter 4 - Machine learning and its application in microscopic image analysis"
    }, 
    {
        "abstract": "AbstractBackground Previous studies have reported that patients with bipolar disorder (BD) present with cognitive impairments during mood episodes as well as euthymic phase. However, it is still unknown whether reported neurocognitive abnormalities can objectively identify individual \\{BD\\} patients from healthy controls (HC). Methods A total of 21 euthymic \\{BD\\} patients and 21 demographically matched \\{HC\\} were included in the current study. Participants performed the computerized Cambridge Neurocognitive Test Automated Battery (CANTAB) to assess cognitive performance. The least absolute shrinkage selection operator (LASSO) machine learning algorithm was implemented to identify neurocognitive signatures to distinguish individual \\{BD\\} patients from HC. Results The \\{LASSO\\} machine learning algorithm identified individual \\{BD\\} patients from \\{HC\\} with an accuracy of 71%, area under receiver operating characteristic curve of 0.7143 and significant at p=0.0053. The \\{LASSO\\} algorithm assigned individual subjects with a probability score (0\u2013healthy, 1\u2013patient). Patients with rapid cycling (RC) were assigned increased probability scores as compared to patients without RC. A multivariate pattern of neurocognitive abnormalities comprising of affective Go/No-go and the Cambridge gambling task was relevant in distinguishing individual patients from HC. Limitations Our study sample was small as we only considered euthymic \\{BD\\} patients and demographically matched HC. Conclusion Neurocognitive abnormalities can distinguish individual euthymic \\{BD\\} patients from \\{HC\\} with relatively high accuracy. In addition, patients with \\{RC\\} had more cognitive impairments compared to patients without RC. The predictive neurocognitive signature identified in the current study can potentially be used to provide individualized clinical inferences on \\{BD\\} patients.", 
        "author": "Mon-Ju Wu and Ives Cavalcante Passos and Isabelle E. Bauer and Luca Lavagnino and Bo Cao and Giovana B. Zunta-Soares and Fl\u00e1vio Kapczinski and Benson Mwangi and Jair C. Soares", 
        "keyword": "Bipolar disorder\", \"Neurocognition\", \"Rapid cycling\", \"CANTAB\", \"Machine learning", 
        "title": "Individualized identification of euthymic bipolar disorder using the Cambridge Neuropsychological Test Automated Battery (CANTAB) and machine learning"
    }, 
    {
        "abstract": "Abstract The extreme learning machine (ELM) is a new method for using Single-hidden Layer Feed-forward Networks (SLFNs) with a much simpler training method. While conventional extreme learning machine are based on the training and test data which should be under the same distribution, in reality it is often desirable to learn an accurate model using only a tiny amount of new data and a large amount of old data. Transfer learning (TL) aims to solve related but different target domain problems by using plenty of labeled source domain data. When the task from one new domain comes, new domain samples are relabeled costly, and it would be a waste to discard all the old domain data. Therefore, an algorithm called TL-ELM based on the \\{ELM\\} algorithm is proposed, which uses a small amount of target domain tag data and a large number of source domain old data to build a high-quality classification model. The method inherits the advantages of \\{ELM\\} and makes up for the defects that traditional \\{ELM\\} cannot transfer knowledge. Experimental results indicate that the performance of the proposed methods is superior to or at least comparable with existing benchmarking methods. In addition, a novel domain adaptation kernel extreme learning machine (TL-DAKELM) based on the kernel extreme learning machine was proposed with respect to the TL-ELM. Experimental results show the effectiveness of the proposed algorithm.", 
        "author": "Xiaodong Li and Weijie Mao and Wei Jiang", 
        "keyword": "Extreme learning machine\", \"Transfer learning (TL)\", \"Classification", 
        "title": "Extreme learning machine based transfer learning for data classification"
    }, 
    {
        "abstract": "Abstract We present a method to integrate multiple implementations of a machine learning algorithm in Kepler actors. This feature enables the user to compare accuracy and scalability of various implementations of a machine learning technique without having to change the workflow. These actors are based on the Execution Choice actor. They can be incorporated into any workflow to provide machine learning functionality. We describe a use case where actors that provide several implementations of k-means clustering can be used in a workflow to process sensor data from weather stations for predicting wildfire risks.", 
        "author": "Mai H. Nguyen and Daniel Crawl and Tahereh Masoumi and Ilkay Altintas", 
        "keyword": "scientific workflow\", \"Kepler\", \"machine learning\", \"execution choice\", \"k-means clustering", 
        "title": "Integrated Machine Learning in the Kepler Scientific Workflow System"
    }, 
    {
        "abstract": null, 
        "author": "Eyke H\u00fcllermeier", 
        "keyword": "Fuzzy sets\", \"Fuzzy logic\", \"Machine learning", 
        "title": "Does machine learning need fuzzy logic?"
    }, 
    {
        "abstract": "Abstract Content-aware image resizing (or image retargeting) enables images to be fit to different display devices having different aspect ratios while preserving salient image content. There are many approaches to retargeting, although no \u201cbest\u201d method has been agreed upon. Therefore, finding ways to assess the quality of image retargeting has become a prominent challenge. Traditional image quality assessment methods are not directly applicable to image retargeting because the retargeted image size is not same as the original one. In this paper, we propose an open framework for image retargeting quality assessment, where the quality prediction engine is a trained Radial Basis Function (RBF) neural network. Broadly, our approach is motivated by the observation that no single method can be expected to perform well on all types of content. We train the network on ten perceptually relevant features, including a saliency-weighted, SIFT-directed complex wavelet structural similarity (CW-SSIM) index, and a new image aesthetics evaluation method. These two features and eight other features are used by the neural network to learn to assess the quality of retargeted images. The accuracy of the new model is extensively verified by simulations.", 
        "author": "Bo Yan and Bahetiyaer Bare and Ke Li and Jun Li and Alan C. Bovik", 
        "keyword": "Image retargeting\", \"Machine learning\", \"RBF neural network\", \"CW-SSIM\", \"SIFT\", \"Image aesthetics", 
        "title": "Learning quality assessment of retargeted images"
    }, 
    {
        "abstract": null, 
        "author": "Vlastimir Nikoli\u0107 and Shervin Motamedi and Shahaboddin Shamshirband and Dalibor Petkovi\u0107 and Sudheer Ch and Mohammad Arif", 
        "keyword": "Wind speed\", \"Soft computing\", \"Extreme learning machine\", \"Estimation\", \"Sensorless", 
        "title": "Extreme learning machine approach for sensorless wind speed estimation"
    }, 
    {
        "abstract": "Abstract Driven by the emerging network data exchange and storage, \\{XML\\} documents classification has become increasingly important. Most existing representation model and conventional learning algorithm are defined on certain \\{XML\\} documents. However, in many real-world applications, \\{XML\\} datasets contain inherent uncertainty, which brings greater challenges to classification problem. In this paper, we propose a novel solution to classify uncertain \\{XML\\} documents, including uncertain \\{XML\\} documents representation and two uncertain learning algorithms based on Extreme Learning Machine. Experimental results show that our approaches exhibit prominent performance for uncertain \\{XML\\} documents classification problem.", 
        "author": "Xiangguo Zhao and Xin Bi and Guoren Wang and Zhen Zhang and Hongbo Yang", 
        "keyword": "Extreme Learning Machine\", \"Classification\", \"XML\", \"Uncertain Data", 
        "title": "Uncertain \\{XML\\} documents classification using Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract Machine learning (ML) algorithms have successfully been demonstrated to be valuable tools in satellite-based rainfall retrievals which show the practicability of using \\{ML\\} algorithms when faced with high dimensional and complex data. Moreover, recent developments in parallel computing with \\{ML\\} present new possibilities for training and prediction speed and therefore make their usage in real-time systems feasible. This study compares four \\{ML\\} algorithms \u2014 random forests (RF), neural networks (NNET), averaged neural networks (AVNNET) and support vector machines (SVM) \u2014 for rainfall area detection and rainfall rate assignment using \\{MSG\\} \\{SEVIRI\\} data over Germany. Satellite-based proxies for cloud top height, cloud top temperature, cloud phase and cloud water path serve as predictor variables. The results indicate an overestimation of rainfall area delineation regardless of the \\{ML\\} algorithm (averaged bias = 1.8) but a high probability of detection ranging from 81% (SVM) to 85% (NNET). On a 24-hour basis, the performance of the rainfall rate assignment yielded \\{R2\\} values between 0.39 (SVM) and 0.44 (AVNNET). Though the differences in the algorithms' performance were rather small, \\{NNET\\} and \\{AVNNET\\} were identified as the most suitable algorithms. On average, they demonstrated the best performance in rainfall area delineation as well as in rainfall rate assignment. NNET's computational speed is an additional advantage in work with large datasets such as in remote sensing based rainfall retrievals. However, since no single algorithm performed considerably better than the others we conclude that further research in providing suitable predictors for rainfall is of greater necessity than an optimization through the choice of the \\{ML\\} algorithm.", 
        "author": "Hanna Meyer and Meike K\u00fchnlein and Tim Appelhans and Thomas Nauss", 
        "keyword": "Machine learning\", \"Rainfall retrieval\", \"Rainfall rate\", \"Rainfall area\", \"MSG \\{SEVIRI\\}", 
        "title": "Comparison of four machine learning algorithms for their applicability in satellite-based optical rainfall retrievals"
    }, 
    {
        "abstract": "Abstract The increasing number of demanding consumer digital multimedia applications has boosted interest in no-reference (NR) image quality assessment (IQA). In this paper, we propose a perceptual \\{NR\\} blur evaluation method using a new machine learning technique, i.e., extreme learning machine (ELM). The proposed metric, Blind Image Blur quality Evaluator (BIBE), exploits scene statistics of gradient magnitudes to model the properties of blurred images, and then the underlying blur features are derived by fitting gradient magnitudes distribution. The resultant feature is finally mapped into an associated quality score using ELM. As subjective evaluation scores by human beings are integrated into training, machine learning techniques can predict image quality more accurately than those traditional methods. Compared with other learning techniques such as support vector machine (SVM), \\{ELM\\} has better learning performance and faster learning speed. Experimental results on public databases show that the proposed \\{BIBE\\} correlates well with human perceived blurriness, and outperforms the state-of-the-art specific \\{NR\\} blur evaluation metrics as well as generic \\{NR\\} \\{IQA\\} methods. Moreover, the application of automatic focusing system for digital cameras further confirms the capability of BIBE.", 
        "author": "Shuigen Wang and Chenwei Deng and Baojun Zhao and Guang-Bin Huang and Baoxian Wang", 
        "keyword": "No-reference blur metric\", \"Extreme learning machine\", \"Gradient magnitude\", \"Generalized Gaussian distribution", 
        "title": "Gradient-based no-reference image blur assessment using extreme learning machine"
    }, 
    {
        "abstract": "Abstract Machine learning can be used for several different software data analytics tasks, providing useful insights into software processes and products. For example, it can reveal what software modules are most likely to contain bugs, what amount of effort is likely to be required to develop new software projects, what commits are most likely to induce crashes, how the productivity of a company changes over time, how to improve productivity, etc. The right machine learning algorithm depends on the data and the environment being modeled. Therefore, in order to create good data models, it is important to investigate the data analytics problem in hand before choosing the type of machine learning algorithm to be used. This chapter discusses questions that software engineers can ask about their data analytics problem in order to choose an appropriate machine learning algorithm.", 
        "author": "L.L. Minku", 
        "keyword": "Machine learning\", \"Machine learning styles\", \"Software effort estimation\", \"Software bug keywords =rediction\", \"Crash-inducing commits", 
        "title": "Which machine learning method do you need?"
    }, 
    {
        "abstract": "Abstract Depression is a complex clinical entity that can pose challenges for clinicians regarding both accurate diagnosis and effective timely treatment. These challenges have prompted the development of multiple machine learning methods to help improve the management of this disease. These methods utilize anatomical and physiological data acquired from neuroimaging to create models that can identify depressed patients vs. non-depressed patients and predict treatment outcomes. This article (1) presents a background on depression, imaging, and machine learning methodologies; (2) reviews methodologies of past studies that have used imaging and machine learning to study depression; and (3) suggests directions for future depression-related studies.", 
        "author": "Meenal J. Patel and Alexander Khalaf and Howard J. Aizenstein", 
        "keyword": "Depression\", \"Machine learning\", \"Treatment\", \"Prediction\", \"Review", 
        "title": "Studying depression using imaging and machine learning methods"
    }, 
    {
        "abstract": "Abstract In the paper, we examine the general regression problem under the missing data scenario. In order to provide reliable estimates for the regression function (approximation), a novel methodology based on Gaussian Mixture Model and Extreme Learning Machine is developed. Gaussian Mixture Model is used to model the data distribution which is adapted to handle missing values, while Extreme Learning Machine enables to devise a multiple imputation strategy for final estimation. With multiple imputation and ensemble approach over many Extreme Learning Machines, final estimation is improved over the mean imputation performed only once to complete the data. The proposed methodology has longer running times compared to simple methods, but the overall increase in accuracy justifies this trade-off.", 
        "author": "Du\u0161an Sovilj and Emil Eirola and Yoan Miche and Kaj-Mikael Bj\u00f6rk and Rui Nian and Anton Akusok and Amaury Lendasse", 
        "keyword": "Extreme Learning Machine\", \"Missing data\", \"Multiple imputation\", \"Gaussian mixture model\", keywords =Mixture of Gaussians\", \"Conditional distribution", 
        "title": "Extreme learning machine for missing data using multiple imputations"
    }, 
    {
        "abstract": "Abstract In this paper, a generalized model with past-sequence-dependent learning and forgetting effects is proposed. Both effects are assumed to be dependent on the sum of processing time as well as the scheduling position. Based on this model, we investigate and prove that some single-machine problems remain polynomially solvable with certain agreeable conditions. We further show that many models known in the literature are special cases of our proposed model. Several helpful lemmas are presented to analyze single-machine scheduling problems with various objective functions: makespan, total completion time, weighted completion time, and maximum lateness.", 
        "author": "Chia-Huang Wu and Wen-Chiung Lee and Peng-Jen Lai and Jen-Ya Wang", 
        "keyword": "Job scheduling\", \"Learning effect\", \"Forgetting effect\", \"Single-machine problems", 
        "title": "Some single-machine scheduling problems with elapsed-time-based and position-based learning and forgetting effects"
    }, 
    {
        "abstract": "Abstract Centerline segregation in steel cast products is an internal defect that can be very harmful when slabs are rolled in heavy plate mills. Consequently, anticipate its presence is a matter of importance to prevent future risks. The aim of this study was to obtain a predictive model able to perform an early detection of central segregation severity in continuous cast steel slabs. This study presents a novel hybrid algorithm, based on support vector machines (SVMs) in combination with the particle swarm optimization (PSO) technique, for predicting the centerline segregation from operation input parameters determined experimentally in continuous cast steel slabs. This optimization technique involves kernel parameter setting in the \\{SVM\\} training procedure, which significantly influences the regression accuracy. Additionally, a multilayer perceptron network (MLP) and a multivariate adaptive regression splines (MARS) approach, this last method also in combination with the particle swarm optimization (PSO) technique, were fitted to the experimental data with comparison purposes. To this end, the most important physical\u2013chemical parameters of this industrial process are monitored and analyzed. The results of the present study are two-fold. In the first place, the significance of each physical\u2013chemical variables on the segregation is presented through the model. Secondly, some models for predicting segregation are obtained with success. Indeed, regression with optimal hyperparameters was performed and coefficients of determination equal to 0.98 for continuity factor estimation and 0.97 for average width were obtained when this hybrid PSO\u2013SVM-based model with \\{RBF\\} kernel function was applied to the experimental dataset, respectively. Furthermore, the results obtained with the \\{MLP\\} and PSO\u2013MARS-based models are clearly worse than those obtained with the PSO\u2013RBF\u2013SVM-based model. The agreement between experimental data and the model confirmed the good performance of the latter. Finally, conclusions of this innovative research work are exposed.", 
        "author": "P.J. Garc\u00eda Nieto and E. Garc\u00eda-Gonzalo and J.C. \u00c1lvarez Ant\u00f3n and V.M. Gonz\u00e1lez Su\u00e1rez and R. Mayo Bay\u00f3n and F. Mateos Mart\u00edn", 
        "keyword": "Support vector machines (SVMs)\", \"Multivariate adaptive regression splines (MARS)\", \"Particle swarm keywords =ptimization (PSO)\", \"Artificial neural networks (ANNs)\", \"Continuous cast steel slabs\", \"Centerline segregation prediction", 
        "title": "A comparison of several machine learning techniques for the centerline segregation prediction in continuous cast steel slabs and evaluation of its performance"
    }, 
    {
        "abstract": "Abstract Rare events, especially those that could potentially negatively impact society, often require humans\u2019 decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.", 
        "author": "Guo Haixiang and Li Yijing and Jennifer Shang and Gu Mingyun and Huang Yuanyue and Gong Bing", 
        "keyword": "Rare events\", \"Imbalanced data\", \"Machine learning\", \"Data mining", 
        "title": "Learning from class-imbalanced data: Review of methods and applications"
    }, 
    {
        "abstract": "Abstract In this paper, we present an Online Sequential Reduced Kernel Extreme Learning Machine (OS-RKELM). In OS-RKELM, only a small part of the instances in the original training samples is employed for training the kernel neurons, while the output weights are attained analytically. Similar to the Online Sequential Extreme Learning Machine (OS-ELM), OS-RKELM learns data samples in a chunk-by-chunk or one-by-one mode and does not require an archival of the data sample once it has been learned. OS-RKELM also contains few control parameters, thus avoiding the need for cumbersome fine-tuning of the algorithm. OS-RKELM supports a widespread types of kernels as hidden neurons and is capable of addressing the singular problem that arises when the initial training samples are smaller than the neuron size. A comprehensive performance evaluation of the OS-RKELM against other state-of-the-art sequential learning algorithms, including OS-ELM, Large-scale Active Support Vector Machine (LASVM) and Budgeted Stochastic Gradient Descent Support Vector Machine (BSGD) using popular time series, regression and classification benchmarks have been conducted. Experimental results obtained indicate that the proposed OS-RKELM showcases improved prediction accuracy and efficiency over the OS-ELM, \\{LASVM\\} and \\{BSGD\\} in many cases.", 
        "author": "Wan-Yu Deng and Yew-Soon Ong and Puay Siew Tan and Qing-Hua Zheng", 
        "keyword": "Extreme learning machine\", \"Support vector machine\", \"Online sequential learning\", \"Big data", 
        "title": "Online sequential reduced kernel extreme learning machine"
    }, 
    {
        "abstract": "Abstract 3D shape features play a crucial role in graphics applications, such as 3D shape matching, recognition, and retrieval. Various 3D shape descriptors have been developed over the last two decades; however, existing descriptors are handcrafted features that are labor-intensively designed and cannot extract discriminative information for a large set of data. In this paper, we propose a rapid 3D feature learning method, namely, a convolutional auto-encoder extreme learning machine (CAE-ELM) that combines the advantages of the convolutional neuron network, auto-encoder, and extreme learning machine (ELM). This method performs better and faster than other methods. In addition, we define a novel architecture based on CAE-ELM. The architecture accepts two types of 3D shape representation, namely, voxel data and signed distance field data (SDF), as inputs to extract the global and local features of 3D shapes. Voxel data describe structural information, whereas \\{SDF\\} data contain details on 3D shapes. Moreover, the proposed CAE-ELM can be used in practical graphics applications, such as 3D shape completion. Experiments show that the features extracted by CAE-ELM are superior to existing hand-crafted features and other deep learning methods or \\{ELM\\} models. Moreover, the classification accuracy of the proposed architecture is superior to that of other methods on ModelNet10 (91.4%) and ModelNet40 (84.35%). The training process also runs faster than existing deep learning methods by approximately two orders of magnitude.", 
        "author": "Yueqing Wang and Zhige Xie and Kai Xu and Yong Dou and Yuanwu Lei", 
        "keyword": "Convolutional\", \"Extreme learning machine\", \"Auto-encoder\", \"Feature learning", 
        "title": "An efficient and effective convolutional auto-encoder extreme learning machine network for 3d feature learning"
    }, 
    {
        "abstract": "Abstract In this era of big data, analyzing large scale data efficiently and accurately has become a challenging problem. As one of the \\{ELM\\} variants, online sequential extreme learning machine (OS-ELM) provides a method to analyze incremental data. Ensemble methods provide a way to learn from data more accurately. MapReduce, which provides a simple, scalable and fault-tolerant framework, can be utilized for large scale learning. In this paper, we first propose an ensemble OS-ELM framework which supports any combination of bagging, subspace partitioning and cross validation. Then we design a parallel ensemble of online sequential extreme learning machine (PEOS-ELM) algorithm based on MapReduce for large scale learning. PEOS-ELM algorithm is evaluated with real and synthetic data with the maximum number of training data 5120K and the maximum number of attributes 512. The speedup of this algorithm reaches as high as 40 on a cluster with maximum 80 cores. The accuracy of PEOS-ELM algorithm is at the same level as that of ensemble OS-ELM executing on a single machine, which is higher than that of the original OS-ELM.", 
        "author": "Shan Huang and Botao Wang and Junhao Qiu and Jitao Yao and Guoren Wang and Ge Yu", 
        "keyword": "Parallel learning\", \"Ensemble\", \"Extreme learning machine\", \"MapReduce\", \"Sequential learning", 
        "title": "Parallel ensemble of online sequential extreme learning machine based on MapReduce"
    }, 
    {
        "abstract": "Abstract Desired material synthesis and design can be directly predicted on the basis of first principle calculations and machine learning. Material big data is constructed based on density functional theory where every possible element combinations are considered and then used as training sets for support vector machines. The predicted material properties for common materials are successfully matched with experimental data. In addition, material combinations based on desired material properties are also able to be predicted. Thus, the proposed work flow becomes the bridge between the material database and designing materials. The approach enables efficient material mining from material big data and could potentially reveal undiscovered desired materials. This approach could also potentially enable targeted material mining from material big data, the unveiling of undiscovered desired materials, and the execution of targeted material synthesis in experiment.", 
        "author": "Keisuke Takahashi and Yuzuru Tanaka", 
        "keyword": "Material informatics\", \"Density functional theory\", \"Machine learning\", \"Material big data", 
        "title": "Material synthesis and design from first principle calculations and machine learning"
    }, 
    {
        "abstract": "Abstract The current energy requirements of buildings comprise a large percentage of the total energy consumed around the world. The demand of energy, as well as the construction materials used in buildings, are becoming increasingly problematic for the earth's sustainable future, and thus have led to alarming concern. The energy efficiency of buildings can be improved, and in order to do so, their operational energy usage should be estimated early in the design phase, so that buildings are as sustainable as possible. An early energy estimate can greatly help architects and engineers create sustainable structures. This study proposes a novel method to estimate building energy consumption based on the \\{ELM\\} (Extreme Learning Machine) method. This method is applied to building material thicknesses and their thermal insulation capability (K-value). For this purpose up to 180 simulations are carried out for different material thicknesses and insulation properties, using the EnergyPlus software application. The estimation and prediction obtained by the \\{ELM\\} model are compared with \\{GP\\} (genetic programming) and \\{ANNs\\} (artificial neural network) models for accuracy. The simulation results indicate that an improvement in predictive accuracy is achievable with the \\{ELM\\} approach in comparison with \\{GP\\} and ANN.", 
        "author": "Sareh Naji and Afram Keivani and Shahaboddin Shamshirband and U. Johnson Alengaram and Mohd Zamin Jumaat and Zulkefli Mansor and Malrey Lee", 
        "keyword": "Energy consumption\", \"Residential buildings\", \"Estimation\", \"Energy efficiency\", \"ELM (extreme learning machine)", 
        "title": "Estimating building energy consumption using extreme learning machine method"
    }, 
    {
        "abstract": "Abstract Most of semi-supervised learning algorithms based on manifold regularization framework are surface learning algorithms, such as semi-supervised \\{ELM\\} (SS-ELM) and Laplacian smooth twin support vector machine (Lap-STSVM). Multi-layer extreme learning machine (ML-ELM) stacks extreme learning machine based auto encoder (ELM-AE) to create a multi-layer neural network. ML-ELM not only approximates the complicated function but also achieves fast training time. The outputs of ELM-AE are the same as inputs, which cannot guarantee the effectiveness of the learning feature representations. We put forward extreme learning machine based denoising auto encoder (ELM-DAE) which introduces local denoising criterion into ELM-AE and is used as the basic component for Denoising ML-ELM. Resembling ML-ELM, Denoising ML-ELM stacks ELM-DAE to create a deep network. And then we introduce manifold regularization into the model of Denoising ML-ELM and propose denoising Laplacian ML-ELM (Denoising Lap-ML-ELM). Denoising Lap-ML-ELM is more efficient than SS-ELM in classification and does not need to spend too much time. Experimental results show that Denoising ML-ELM and Denoising Lap-ML-ELM are effective learning algorithms.", 
        "author": "Nan Zhang and Shifei Ding and Zhongzhi Shi", 
        "keyword": "Extreme learning machine\", \"Semi-supervised learning\", \"Deep learning\", \"Denoising\", \"Manifold regularization", 
        "title": "Denoising Laplacian multi-layer extreme learning machine"
    }, 
    {
        "abstract": "Abstract Radium (226Ra) contamination derived from military, industrial, and pharmaceutical products can be found at a number of historical sites across the world posing a risk to human health. The analysis of spectral data derived using gamma-ray spectrometry can offer a powerful tool to rapidly estimate and map the activity, depth, and lateral distribution of 226Ra contamination covering an extensive area. Subsequently, reliable risk assessments can be developed for individual sites in a fraction of the timeframe compared to traditional labour-intensive sampling techniques: for example soil coring. However, local heterogeneity of the natural background, statistical counting uncertainty, and non-linear source response are confounding problems associated with gamma-ray spectral analysis. This is particularly challenging, when attempting to deal with enhanced concentrations of a naturally occurring radionuclide such as 226Ra. As a result, conventional surveys tend to attribute the highest activities to the largest total signal received by a detector (Gross counts): an assumption that tends to neglect higher activities at depth. To overcome these limitations, a methodology was developed making use of Monte Carlo simulations, Principal Component Analysis and Machine Learning based algorithms to derive depth and activity estimates for 226Ra contamination. The approach was applied on spectra taken using two gamma-ray detectors (Lanthanum Bromide and Sodium Iodide), with the aim of identifying an optimised combination of detector and spectral processing routine. It was confirmed that, through a combination of Neural Networks and Lanthanum Bromide, the most accurate depth and activity estimates could be found. The advantage of the method was demonstrated by mapping depth and activity estimates at a case study site in Scotland. There the method identified significantly higher activity (&lt; 3 Bq g\u2212 1) occurring at depth (&gt; 0.4 m), that conventional gross counting algorithms failed to identify. It was concluded that the method could easily be employed to identify areas of high activity potentially occurring at depth, prior to intrusive investigation using conventional sampling techniques.", 
        "author": "Adam Varley and Andrew Tyler and Leslie Smith and Paul Dale and Mike Davies", 
        "keyword": "Radium contaminated land\", \"Gamma-ray spectrometry\", \"Machine Learning\", \"Contamination mapping", 
        "title": "Mapping the spatial distribution and activity of 226Ra at legacy sites through Machine Learning interpretation of gamma-ray spectrometry data"
    }, 
    {
        "abstract": "Abstract Intrusion detection system plays an important role in network security. Intrusion detection model is a predictive model used to predict the network data traffic as normal or intrusion. Machine Learning algorithms are used to build accurate models for clustering, classification and prediction. In this paper classification and predictive models for intrusion detection are built by using machine learning classification algorithms namely Logistic Regression, Gaussian Naive Bayes, Support Vector Machine and Random Forest. These algorithms are tested with NSL-KDD data set. Experimental results shows that Random Forest Classifier out performs the other methods in identifying whether the data traffic is normal or an attack.", 
        "author": "Manjula C. Belavagi and Balachandra Muniyal", 
        "keyword": "Classification Algorithms\", \"Intrusion Detection\", \"Machine Learning\", \"Network Security\", \"Supervised Learning.", 
        "title": "Performance Evaluation of Supervised Machine Learning Algorithms for Intrusion Detection"
    }, 
    {
        "abstract": "Abstract Due to the outstanding advantage, such as generalization performance and fast convergence, Extreme Learning Machine (ELM) and its variants have been widely used for many applications. The distributed \\{ELM\\} with MapReduce could handle large-scale training dataset efficiently, but how to cope with its updated hidden nodes number which aims to get the higher accuracy is still a challenging task. In this paper, we propose a novel Adaptive Distributed Extreme Learning Machine with MapReduce (A-ELM\u204e). It could overcome the weakness of ELM\u204e in learning massive training dataset for updating hidden nodes number. Firstly, we found that through partial adjustment of incremental hidden nodes and decremental hidden nodes, matrix multiplication (the most computation-expensive part in A-ELM\u204e) can be calculated. Next, A-ELM\u204e based on MapReduce framework is proposed. A-ELM\u204e first calculates the intermediate matrix multiplications of the updated hidden nodes subset, and then update the matrix multiplications by modifying the old matrix multiplications with the intermediate ones. Then, based on the updated matrix multiplications, there could obtain the corresponding new output weight vector with centralized computing. Therefore, it is effective for learning large scale training dataset, in which the hidden nodes update rapidly. Finally, we verify the effectiveness and efficiency of our proposed A-ELM\u204e, using synthetic data with extensive experiments, in learning updated hidden nodes.", 
        "author": "Junchang Xin and Zhiqiong Wang and Luxuan Qu and Ge Yu and Yan Kang", 
        "keyword": "Extreme Learning Machine\", \"MapReduce\", \"Incremental hidden nodes\", \"Decremental hidden nodes", 
        "title": "A-ELM\u204e: Adaptive Distributed Extreme Learning Machine with MapReduce"
    }, 
    {
        "abstract": "Abstract Some key variables in the complex chemical processes are very difficult to measure due to the nonlinearity, the disturbances, and the technological limitations. In order to accurately predict the difficult-to-measure variables, soft sensor based on a novel robust bagging nonlinear model integrating improved extreme learning machine with partial least square (RB-PLSIELM) is developed. Motivated by the ensemble ideas, the proposed RB-PLSIELM model is based on the bagging ensemble scheme to combine some individual nonlinear models integrating improved extreme learning machine with partial least square (PLSIELM). The sub-data for building the individual \\{PLSIELM\\} model are re-sampled from the original training data using the bagging tool. The problem of over-training in the \\{PLSELM\\} model can be avoided by using the bagging re-sampling technology. The proposed RB-PLSIELM model was demonstrated by applying it to predicting the key variables of the Tennessee Eastman Process (TEP) and the Purified Terephthalic Acid Process (PTAP). The simulation results obtained by RB-PLSIELM are compared with those obtained by the individual \\{PLSELM\\} model, the \\{ELM\\} model, and the partial least square regression (PLSR) model. Compared with the other models, the RB-PLSIELM can achieve higher prediction accuracy and stability.", 
        "author": "YanLin He and ZhiQiang Geng and QunXiong Zhu", 
        "keyword": "Partial least square\", \"Extreme learning machine\", \"Bagging\", \"Soft sensor\", \"Tennessee Eastman keywords =rocess\", \"Purified Terephthalic Acid Process", 
        "title": "Soft sensor development for the key variables of complex chemical processes using a novel robust bagging nonlinear model integrating improved extreme learning machine with partial least square"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a fast manifold learning strategy to estimate the underlying geometrical distribution and develop the relevant mathematical criterion on the basis of the extreme learning machine (ELM) in the high-dimensional space. The local tangent space alignment (LTSA) method has been used to perform the manifold production and the single hidden layer feedforward network (SLFN) is established via \\{ELM\\} to simulate the low-dimensional representation process. The scheme of the \\{ELM\\} ensemble then combines the individual \\{SLFN\\} for the model selection, where the manifold regularization mechanism has been brought into \\{ELM\\} to preserve the local geometrical structure of LTSA. Some developments have been done to evaluate the inherent representation embedding in the \\{ELM\\} learning. The simulation results have shown the excellent performance in the accuracy and efficiency of the developed approach.", 
        "author": "Qian Wang and Weiguo Wang and Rui Nian and Bo He and Yue Shen and Kaj-Mikael Bj\u00f6rk and Amaury Lendasse", 
        "keyword": "Extreme learning machine\", \"Manifold learning\", \"Local tangent space alignment\", \"High-dimensional space", 
        "title": "Manifold learning in local tangent space via extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM), which was initially proposed for training single-layer feed-forward networks (SLFNs), provides us a unified efficient and effective framework for regression and multiclass classification. Though various \\{ELM\\} variants were proposed in recent years, most of them focused on the supervised learning scenario while little effort was made to extend it into unsupervised learning paradigm. Therefore, it is of great significance to put \\{ELM\\} into learning tasks with only unlabeled data. One popular approach for mining knowledge from unlabeled data is based on the manifold assumption, which exploits the geometrical structure of data by assuming that nearby points will also be close to each other in transformation space. However, considering the manifold information only is insufficient for discriminative tasks. In this paper, we propose an improved unsupervised discriminative \\{ELM\\} (UDELM) model, whose main advantage is to combine the local manifold learning with global discriminative learning together. \\{UDELM\\} can be efficiently optimized by solving a generalized eigen-value decomposition problem. Extensive comparisons over several state-of-the-art models on clustering image and emotional \\{EEG\\} data demonstrate the efficacy of UDELM.", 
        "author": "Yong Peng and Wei-Long Zheng and Bao-Liang Lu", 
        "keyword": "Extreme learning machine (ELM)\", \"Unsupervised learning\", \"Manifold information\", \"Discriminative keywords =nformation\", \"Image clustering\", \"EEG", 
        "title": "An unsupervised discriminative extreme learning machine and its applications to data clustering"
    }, 
    {
        "abstract": "Abstract This chapter defines analytics and traces its evolution from its origin in 1988 to its current stage\u2014cognitive analytics. We discuss types of learning and describe classes of machine learning algorithms. Given this backdrop, we propose a reference architecture for cognitive analytics and indicate ways to implement the architecture. A few cognitive analytics applications are briefly described. The chapter concludes by indicating current trends and future research direction.", 
        "author": "V.N. Gudivada and M.T. Irfan and E. Fathi and D.L. Rao", 
        "keyword": "Cognitive analytics\", \"Text analytics\", \"Learning analytics\", \"Educational data mining\", \"Cognitive keywords =ystems\", \"Cognitive computing\", \"Personalized learning\", \"Data science\", \"Machine learning\", \"Big keywords =ata analytics\", \"Business analytics", 
        "title": "Chapter 5 - Cognitive Analytics: Going Beyond Big Data Analytics and Machine Learning"
    }, 
    {
        "abstract": "Abstract Diagnosis of people with mild Parkinson's symptoms is difficult. Nevertheless, variations in gait pattern can be utilised to this purpose, when measured via Inertial Measurement Units (IMUs). Human gait, however, possesses a high degree of variability across individuals, and is subject to numerous nuisance factors. Therefore, off-the-shelf Machine Learning techniques may fail to classify it with the accuracy required in clinical trials. In this paper we propose a novel framework in which \\{IMU\\} gait measurement sequences sampled during a 10 m walk are first encoded as hidden Markov models (HMMs) to extract their dynamics and provide a fixed-length representation. Given sufficient training samples, the distance between \\{HMMs\\} which optimises classification performance is learned and employed in a classical Nearest Neighbour classifier. Our tests demonstrate how this technique achieves accuracy of 85.51% over a 156 people with Parkinson's with a representative range of severity and 424 typically developed adults, which is the top performance achieved so far over a cohort of such size, based on single measurement outcomes. The method displays the potential for further improvement and a wider application to distinguish other conditions.", 
        "author": "Fabio Cuzzolin and Michael Sapienza and Patrick Esser and Suman Saha and Miss Marloes Franssen and Johnny Collett and Helen Dawes", 
        "keyword": "Machine Learning algorithms\", \"Hidden Markov models\", \"Metric learning\", \"Inertial Measurement keywords =nit\", \"Gait\", \"Parkinson's", 
        "title": "Metric learning for Parkinsonian identification from \\{IMU\\} gait measurements"
    }, 
    {
        "abstract": "Abstract For adaptively learning the parameters of extreme learning machine (ELM), a novel learning algorithm is proposed on the basis of a multiobjective membrane algorithm. More specifically, first, a multiobjective mathematical model is established to learn the parameters of ELM, which is constructed by three objective functions. These objective functions include the root mean squared error, L_1 norm of output weights and the number of hidden nodes. Second, a series of the trade-off solutions with respect to the above-mentioned objective functions are found by the multiobjective membrane algorithm. Finally, a trade-off solution with the best generalization performance of ELM, which is chosen from the Pareto front obtained by the multiobjective algorithm, will become the final parameters for initializing the \\{ELM\\} network. The simulation experiments are run on the approximation of \u2018SinC\u2019 function, real-world regression problems and real-world classification problems. Experimental results indicate that the proposed framework is able to achieve good generalization performance in the most cases with many compact networks.", 
        "author": "Chuang Liu and Dongling Chen and Fucai Wan", 
        "keyword": "Membrane system\", \"Multiobjective membrane algorithm\", \"Membrane computing\", \"Extreme learning machine", 
        "title": "Multiobjective learning algorithm based on membrane systems for optimizing the parameters of extreme learning machine"
    }, 
    {
        "abstract": "Abstract Biosimilarity assessments are performed to decide whether 2 preparations of complex biomolecules can be considered \u201chighly similar.\u201d In this work, a machine learning approach is demonstrated as a mathematical tool for such assessments using a variety of analytical data sets. As proof-of-principle, physical stability data sets from 8 samples, 4 well-defined immunoglobulin G1-Fragment crystallizable glycoforms in 2 different formulations, were examined (see More et\u00a0al., companion article in this issue). The data sets included triplicate measurements from 3 analytical methods across different pH and temperature conditions (2066 data features). Established machine learning techniques were used to determine whether the data sets contain sufficient discriminative power in this application. The support vector machine classifier identified the 8 distinct samples with high accuracy. For these data sets, there exists a minimum threshold in terms of information quality and volume to grant enough discriminative power. Generally, data from multiple analytical techniques, multiple pH conditions, and at least 200 representative features were required to achieve the highest discriminative accuracy. In addition to classification accuracy tests, various methods such as sample space visualization, similarity analysis based on Euclidean distance, and feature ranking by mutual information scores are demonstrated to display their effectiveness as modeling tools for biosimilarity assessments.", 
        "author": "Jae Hyun Kim and Sangeeta B. Joshi and Thomas J. Tolbert and C. Russell Middaugh and David B. Volkin and Aaron Smalter Hall", 
        "keyword": "biosimilarity\", \"comparability\", \"machine learning\", \"stability\", \"formulation\", \"protein\", \"mAbs\", keywords =glycoforms\", \"Fc", 
        "title": "Biosimilarity Assessments of Model IgG1-Fc Glycoforms Using a Machine Learning Approach"
    }, 
    {
        "abstract": "Abstract Making accurate predictions is a difficult task that is encountered throughout many research domains. In certain cases, the number of available samples is so scarce that providing reliable estimates is a challenging problem. In this paper, we are interested in giving as accurate predictions as possible based on the Extreme Learning Machine type of a neural network in small sample data scenarios. Most of the Extreme Learning Machine literature is focused on choosing a particular model from a pool of candidates, but such approach usually ignores model selection uncertainty and has inferior performance compared to combining methods. We empirically examine several model selection criteria coupled with new model combining approaches that were recently proposed. The results obtained indicate that a careful choice among the combinations must be performed in order to have the most accurate and stable predictions.", 
        "author": "Du\u0161an Sovilj and Kaj-Mikael Bj\u00f6rk and Amaury Lendasse", 
        "keyword": "Extreme Learning Machine\", \"Small sample data\", \"Model selection\", \"Model combining\", \"Mallow\u05f3s keywords =odel Averaging\", \"Jackknife Model Averaging", 
        "title": "Comparison of combining methods using Extreme Learning Machines under small sample scenario"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) proposed by Huang et al. [2] is a novel algorithm for single hidden layer feedforward neural networks (SLFNs) with extremely fast learning speed and good generalization performance. When new hidden nodes are added to the existing network, retraining the network would be time consuming, and EM-ELM [13] was proposed to calculate the output weights incrementally. However there are still two issues in EM-ELM: first, the initial hidden layer output matrix may be rank deficient thus the computation will loss accuracy; second, EM-ELM cannot always get good generalization performance due to overfitting. So we propose the improved version of EM-ELM based on regularization method called Incremental Regularized Extreme Learning Machine (IR-ELM). When new hidden node is added one by one, IR-ELM can update output weights recursively in a fast way. Enhancement of IR-ELM (EIR-ELM) that has a selection of hidden nodes to be added to the network is also introduced in this paper. Empirical studies on benchmark data sets for regression and classification problems have shown that IR-ELM (EIR-ELM) always gets better generalization performance than EM-ELM with the similar training time.", 
        "author": "Zhixin Xu and Min Yao and Zhaohui Wu and Weihui Dai", 
        "keyword": "Extreme Learning Machine\", \"Regularization\", \"Incremental learning\", \"Neural networks", 
        "title": "Incremental regularized extreme learning machine and it\u05f3s enhancement"
    }, 
    {
        "abstract": "Abstract Recognition of complex dynamic texture is a difficult task and captures the attention of the computer vision community for several decades. Essentially the dynamic texture recognition is a multi-class classification problem that has become a real challenge for computer vision and machine learning techniques. Due to the reason that the dynamic textures lie in non-Euclidean manifold, existing classifier such as extreme learning machine cannot effectively deal with this problem. In this paper, we propose a new approach to tackle the dynamic texture recognition problem. First, we utilize the affinity propagation clustering technology to design a codebook, and then construct a soft coding feature to represent the whole dynamic texture sequence. This new coding strategy preserves spatial and temporal characteristics of dynamic texture. Finally, by evaluating the proposed approach on the DynTex dataset, we show the effectiveness of the proposed strategy.", 
        "author": "Liuyang Wang and Huaping Liu and Fuchun Sun", 
        "keyword": "Extreme learning machine\", \"Dynamic texture classification\", \"Linear dynamical systems\", \"Bag-of-systems", 
        "title": "Dynamic texture video classification using extreme learning machine"
    }, 
    {
        "abstract": "Abstract The lack of regulations and disclosures regarding intangible capital has made it rather difficult for investors and creditors to evaluate a firm\u05f3s intangible value before making the associated investment and loan decisions. This study represents an initial attempt to compare/contrast different types of machine learning techniques and identify the optimal prediction model for intangible assets. In addition, this paper shows that machine learning can be used effectively for the problem of intangible assets evaluation. To be specific, five classification algorithms are considered: decision trees (DT), artificial neural networks (ANN), na\u00efve Bayes, support vector machines (SVM) and k-Nearest Neighbors (k-NN). Consequently, thirty prediction models are constructed for comparison, including five single classifiers, boosting and bagging based classifier ensembles, and the combination of k-means clustering, single classifiers and classifier ensembles. The experimental results show that prediction models combining k-means with boosting/bagging based classifier ensembles perform much better than the other methods in terms of prediction accuracy, \\{ROC\\} Curve, as well as Type I and \\{II\\} errors. In particular, while the best single classifier, k-NN provides 78.24% prediction accuracy, k-means+bagging based \\{DT\\} ensembles provide the best performance to predict intangible assets with a prediction accuracy of 91.60%, 96.40% of \\{ROC\\} Curve and 18.65% of Type I and 6.34% of \\{II\\} errors, respectively.", 
        "author": "Chih-Fong Tsai and Yu-Hsin Lu and Yu-Chung Hung and David C. Yen", 
        "keyword": "Intangible assets value\", \"Machine learning\", \"Classifier technology\", \"Classifier ensembles\", \"Hybrid classifiers", 
        "title": "Intangible assets evaluation: The machine learning perspective"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM), a competitive machine learning technique for single-hidden-layer feedforward neural networks (SLFNNs), has proven to be efficient and effective algorithm for regression and classification problems. However, traditional \\{ELM\\} involves a large number of hidden nodes for complex real world regression and classification problems which increasing the computation burden. In this paper, a decomposition based fast \\{ELM\\} (DFELM) algorithm is proposed to effectively reduce the computational burden for large number of hidden nodes condition. Compared with \\{ELM\\} algorithm, \\{DFELM\\} algorithm has faster training time with a large number of hidden nodes maintaining the same accuracy performance. Experiment on three regression problems, six classification problems and a complex blast furnace modeling problem are carried out to verify the performance of \\{DFELM\\} algorithm. Moreover, the decomposition method can be extended to other modified \\{ELM\\} algorithms to further reduce the training time.", 
        "author": "Junpeng Li and Changchun Hua and Yinggan Tang and Xinping Guan", 
        "keyword": "Extreme learning machine\", \"Decomposition\", \"Machine learning\", \"Regression\", \"Classification", 
        "title": "A fast training algorithm for extreme learning machine based on matrix decomposition"
    }, 
    {
        "abstract": "Abstract Transformations are underway in our ability to collect and interrogate remotely sensed data. Here we explore the utility of three machine-learning methods for identifying the controls on coastal cliff landsliding using a dataset from Auckland, New Zealand. Models were built using all available data with a resampling approach used to evaluate uncertainties. All methods identify two dominant landslide predictors (unfailed cliff slope angle and fault proximity). This information could support a range of management approaches, from the development of \u2018rules-of-thumb\u2019 to detailed models that incorporate all predictor information. In our study all statistical approaches correctly predict a high proportion (&gt;85%) of cases. Similar \u2018success\u2019 has been shown in other studies, but important questions should be asked about possible error sources, particularly in regard to absence data. In coastal landslide studies sign decay is a vexing issue, because sites prone to landsliding may also be sites of rapid evidence removal.", 
        "author": "Mark E. Dickson and George L.W. Perry", 
        "keyword": "Landsliding\", \"Machine learning\", \"Erosion\", \"Maxent\", \"Regression trees\", \"Cliffs", 
        "title": "Identifying the controls on coastal cliff landslides using machine-learning approaches"
    }, 
    {
        "abstract": "Abstract Precise estimation of evapotranspiration is crucial for accurate crop-water estimation. Recently machine learning (ML) techniques like artificial neural network (ANN) are being widely used for modeling the process of evapotranspiration. However, \\{ANN\\} faces issues like trapping in local minima, slow learning and tuning of meta-parameters. In this study an improved extreme learning machine (ELM) algorithm was used to estimate weekly reference crop evapotranspiration (ETo). The study was carried out for Jodhpur and Pali meteorological weather stations located in the Thar Desert, India. The study evaluated the performance of three different input combinations. The first input combination used locally available maximum and minimum air temperature data while the second and third combination used \\{ETo\\} values from another station (extrinsic inputs) along with the locally available temperature data as inputs. The performance of \\{ELM\\} models was compared with the empirical Hargreaves equation, \\{ANN\\} and least-square support vector machine (LS-SVM) models. Root mean squared error (RMSE), Nash\u2013Sutcliffe model efficiency coefficient (NSE) and threshold statistics (TS) were used for comparing the performance of the models. The performance of \\{ELM\\} model was found to be better than the Hargreaves and \\{ANN\\} model. The LS-SVM and \\{ELM\\} displayed similar performance. \\{ELM3\\} models, with 36 and 33 neurons in hidden layer were found to be the best models (RMSE of 0.43 for Jodhpur and 0.33 for Pali station) for estimating weekly \\{ETo\\} at Jodhpur and Pali stations respectively. The results showed that \\{ELM\\} is a simple yet efficient algorithm which exhibited good performance; hence, can be recommended for estimating weekly ETo. Furthermore, it was also found that use of \\{ETo\\} values from another station can help in improving the efficiency of \\{ML\\} models in limited data scenario.", 
        "author": "Amit Prakash Patil and Paresh Chandra Deka", 
        "keyword": "Evapotranspiration\", \"Limited data\", \"Extreme learning machine\", \"Arid region\", \"Least square support vector machine", 
        "title": "An extreme learning machine approach for modeling evapotranspiration using extrinsic inputs"
    }, 
    {
        "abstract": "Abstract In this paper we introduce a simple and efficient extension of the Extreme Learning Machine (ELM) network (Huang et al., 2006 [19]), which is very robust to label noise, a type of outlier occurring in classification tasks. Such outliers usually result from mistakes during labeling of the data points (e.g. misjudgment of a specialist) or from typing errors during creation of data files (e.g. by striking an incorrect key on a keyboard). The proposed variant of the ELM, henceforth named Robust \\{ELM\\} (RELM), is designed using M-estimators to compute the output weights instead of the standard ordinary least squares (OLS) method. We evaluate the performance of the \\{RELM\\} using batch and recursive learning rules, and also introduce a model selection strategy based on Particle Swarm Optimization (PSO) to find an optimal architecture for datasets contaminated with non-Gaussian noise and outliers. By means of comprehensive computer simulations using synthetic and real-world datasets, we show that the proposed Robust \\{ELM\\} classifiers consistently outperforms the original version.", 
        "author": "Guilherme A. Barreto and Ana Luiza B.P. Barros", 
        "keyword": "Extreme Learning Machine\", \"Ordinary least squares\", \"Least mean squares\", \"Robust pattern keywords =lassification\", \"Outliers\", \"M-estimation", 
        "title": "A Robust Extreme Learning Machine for pattern classification with outliers"
    }, 
    {
        "abstract": "Abstract In typical data mining applications, labeling the large amounts of data is difficult, expensive, and time consuming, if annotated manually. To avoid manual labeling, semi-supervised learning uses unlabeled data along with the labeled data in the training process. Transductive support vector machine (TSVM) is one such semi-supervised, which has been found effective in enhancing the classification performance. However there are some deficiencies in TSVM, such as presetting number of the positive class samples, frequently exchange of class label, and its requirement for larger amount of unlabeled data. To tackle these deficiencies, in this paper, we propose a new semi-supervised learning algorithm based on active learning combined with TSVM. The algorithm applies active learning to select the most informative instances based on the version space minimum\u2013maximum division principle with human annotation for improve the classification performance. Simultaneously, in order to make full use of the distribution characteristics of unlabeled data, we added a manifold regularization term to the objective function. Experiments performed on several \\{UCI\\} datasets and a real world book review case study demonstrate that our proposed method achieves significant improvement over other benchmark methods yet consuming less amount of human effort, which is very important while labeling data manually.", 
        "author": "Xibin Wang and Junhao Wen and Shafiq Alam and Zhuo Jiang and Yingbo Wu", 
        "keyword": "Transductive support vector machine\", \"Active learning\", \"Version space minimum\u2013maximum division keywords =rinciple\", \"Graph-based method", 
        "title": "Semi-supervised learning combining transductive support vector machine with active learning"
    }, 
    {
        "abstract": "Abstract Liver transplantation is a promising and widely-accepted treatment for patients with terminal liver disease. However, transplantation is restricted by the lack of suitable donors, resulting in significant waiting list deaths. This paper proposes a novel donor-recipient allocation system that uses machine learning to predict graft survival after transplantation using a dataset comprised of donor-recipient pairs from the King\u2019s College Hospital (United Kingdom). The main novelty of the system is that it tackles the imbalanced nature of the dataset by considering semi-supervised learning, analysing its potential for obtaining more robust and equitable models in liver transplantation. We propose two different sources of unsupervised data for this specific problem (recent transplants and virtual donor-recipient pairs) and two methods for using these data during model construction (a semi-supervised algorithm and a label propagation scheme). The virtual pairs and the label propagation method are shown to alleviate the imbalanced distribution. The results of our experiments show that the use of synthetic and real unsupervised information helps to improve and stabilise the performance of the model and leads to fairer decisions with respect to the use of only supervised data. Moreover, the best model is combined with the Model for End-stage Liver Disease score (MELD), which is at the moment the most popular assignation methodology worldwide. By doing this, our decision-support system considers both the compatibility of the donor and the recipient (by our prediction system) and the recipient severity (via the \\{MELD\\} score), supporting then the principles of fairness and benefit.", 
        "author": "M. P\u00e9rez-Ortiz and P.A. Guti\u00e9rrez and M.D. Ayll\u00f3n-Ter\u00e1n and N. Heaton and R. Ciria and J. Brice\u00f1o and C. Herv\u00e1s-Mart\u00ednez", 
        "keyword": "Liver transplantation\", \"Transplant recipient\", \"Survival analysis\", \"Machine learning\", \"Support keywords =ector machines\", \"Semi-supervised learning\", \"Imbalanced classification", 
        "title": "Synthetic semi-supervised learning in imbalanced domains: Constructing a model for donor-recipient matching in liver transplantation"
    }, 
    {
        "abstract": "Abstract The Extreme Learning Machine (ELM) is a novel learning scheme for single hidden layer feedforward neural networks, and it has attracted a great deal of research attention since the last decade because of its extremely fast learning speed. One popular variant of \\{ELM\\} is the Online Sequential \\{ELM\\} (OS-ELM), which can deal with sequential learning tasks. However, limitations exist in the OS-ELM such as requiring the initialization phase, pre-defined important parameters, running into singularity problem, inconsistent and potentially unreliable performance. In this paper, an Online Sequential Regularized \\{ELM\\} (OS-RELM) is proposed to address the aforementioned issues. The main idea is to incorporate the regularization method to further improve its generalization performance, and a new update formula is used to eliminate the initialization phase. To enable the OS-RELM to adapt to new data in an effective and reliable manner, an efficient Leave-One-Out Cross-Validation method is implemented. Finally, a matrix reconstruction method is employed to address the unstable update issue. Unlike some \\{ELM\\} variants that greatly jeopardize the speed advantage of the ELM, we strive to limit the computational load from the proposed scheme. Simulation results on benchmark problems show that the OS-RELM is a reliable and efficient algorithm with superior generalization performance than the OS-ELM.", 
        "author": "Zhifei Shao and Meng Joo Er", 
        "keyword": "Extreme Learning Machine (ELM)\", \"Regularized \\{ELM\\} (RELM)\", \"Ridge regression\", \"Online Sequential \\{RELM\\} (OS-RELM)", 
        "title": "An online sequential learning algorithm for regularized Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract Multi-instance learning (MIL) is one of promising paradigms in the supervised learning aiming to handle real world classification problems where a classification target contains several featured sections, e.g., an image typically contains several salient regions. In this paper, we propose a highly efficient learning method for \\{MI\\} classification based on hierarchical extreme learning machine (ELM), called MI-ELM. Specifically, a double-hidden layers feedforward network (DLFN) is designed to serve as the \\{MI\\} classifier. Then, the \\{MI\\} classification is formulated as an optimization problem. Moreover, the output weights of \\{DLFN\\} can be analytically determined by solving the aforementioned optimization problem. The merits of MI-ELM are as follows: (i) MI-ELM extends the single-layer \\{ELM\\} to be a hierarchical one that well fits for training \\{DLFNs\\} in \\{MI\\} classification. (ii) The input and hidden-layer parameters of \\{DLFNs\\} are assigned randomly rather than tuned iteratively, and the output weights of \\{DLFNs\\} can be determined analytically in one step. Therefore, MI-ELM significantly enhances the efficiency of the \\{DLFN\\} without notable loss of the classification accuracy. Experimental results over several real-world data sets demonstrate that the proposed MI-ELM method significantly outperforms existing kernel methods for \\{MI\\} classification in terms of the classification accuracy and the classification time.", 
        "author": "Qiang Liu and Sihang Zhou and Chengzhang Zhu and Xinwang Liu and Jianping Yin", 
        "keyword": "Multi-instance learning\", \"Hierarchical extreme learning machine\", \"Optimization\", \"Double-hidden layers feedforward network", 
        "title": "MI-ELM: Highly efficient multi-instance learning based on hierarchical extreme learning machine"
    }, 
    {
        "abstract": "Abstract Data mining techniques play a major role in developing computer aided diagnosis systems and expert systems that will aid a physician in clinical decision making. In this work, a classifier that combines the relative merits of fuzzy sets and extreme learning machine (FELM) for clinical datasets is proposed. The three major subsystems in the \\{FELM\\} framework are preprocessing subsystem, fuzzification subsystem and classification subsystem. Missing value imputation and outlier elimination are handled by the preprocessing subsystem. The fuzzification subsystem maps each feature to a fuzzy set and the classification subsystem uses extreme learning machine for classification. Cleveland heart disease (CHD), Statlog heart disease (SHD) and Pima Indian diabetes (PID) datasets from the University of California Irvine (UCI) machine learning repository have been used for experimentation. The \\{CHD\\} and \\{SHD\\} datasets have been experimented with two class labels one indicating the absence and the other indicating the presence of heart disease. The \\{CHD\\} dataset has also been experimented with five class labels, one class label indicating the absence of heart disease and the other four class labels indicating the severity of heart disease namely low risk, medium risk, high risk and serious. The \\{PID\\} data set has been experimented with two class labels one indicating the absence and the other indicating the presence of gestational diabetes. The classifier has achieved an accuracy of 93.55% for \\{CHD\\} data set with two class labels; 73.77% for \\{CHD\\} data set with five class labels; 94.44% for \\{SHD\\} data set and 92.54% for \\{PID\\} dataset.", 
        "author": "Kindie Biredagn Nahato and Khanna H. Nehemiah and A. Kannan", 
        "keyword": "Extreme learning machine\", \"Fuzzification\", \"Fuzzy set\", \"Classification\", \"Euclidean distance\", \"Membership function", 
        "title": "Hybrid approach using fuzzy sets and extreme learning machine for classifying clinical datasets"
    }, 
    {
        "abstract": "Abstract The random-hidden-node extreme learning machine (ELM) is a much more generalized cluster of single-hidden-layer feed-forward neural networks (SLFNs) which has three parts: random projection, non-linear transformation, and ridge regression (RR) model. Networks with deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with computer vision tasks. Deep learning algorithms such as stacked autoencoder (SAE) and deep belief network (DBN) are built on learning several levels of representation of the input. Beyond simply learning features by stacking autoencoders (AE), there is a need for increasing its robustness to noise and reinforcing the sparsity of weights to make it easier to discover interesting and prominent features. The sparse \\{AE\\} and denoising \\{AE\\} was hence developed for this purpose. This paper proposes an approach: SSDAE-RR (stacked sparse denoising autoencoder \u2013 ridge regression) that effectively integrates the advantages in SAE, sparse AE, denoising AE, and the \\{RR\\} implementation in \\{ELM\\} algorithm. We conducted experimental study on real-world classification (binary and multiclass) and regression problems with different scales among several relevant approaches: SSDAE-RR, ELM, DBN, neural network (NN), and SAE. The performance analysis shows that the SSDAE-RR tends to achieve a better generalization ability on relatively large datasets (large sample size and high dimension) that were not pre-processed for feature abstraction. For 16 out of 18 tested datasets, the performance of SSDAE-RR is more stable than other tested approaches. We also note that the sparsity regularization and denoising mechanism seem to be mandatory for constructing interpretable feature representations. The fact that a SSDAE-RR approach often has a comparable training time to \\{ELM\\} makes it useful in some real applications.", 
        "author": "Le-le Cao and Wen-bing Huang and Fu-chun Sun", 
        "keyword": "Extreme learning machine (ELM)\", \"Ridge regression\", \"Feature space\", \"Stacked autoencoder (SAE)\", keywords =Classification\", \"Regression", 
        "title": "Building feature space of extreme learning machine with sparse denoising stacked-autoencoder"
    }, 
    {
        "abstract": "Abstract Learning incorporates a broad range of complex procedures. Machine learning (ML) is a subdivision of artificial intelligence based on the biological learning process. The \\{ML\\} approach deals with the design of algorithms to learn from machine readable data. \\{ML\\} covers main domains such as data mining, difficult-to-program applications, and software applications. It is a collection of a variety of algorithms (e.g. neural networks, support vector machines, self-organizing map, decision trees, random forests, case-based reasoning, genetic programming, etc.) that can provide multivariate, nonlinear, nonparametric regression or classification. The modeling capabilities of the ML-based methods have resulted in their extensive applications in science and engineering. Herein, the role of \\{ML\\} as an effective approach for solving problems in geosciences and remote sensing will be highlighted. The unique features of some of the \\{ML\\} techniques will be outlined with a specific attention to genetic programming paradigm. Furthermore, nonparametric regression and classification illustrative examples are presented to demonstrate the efficiency of \\{ML\\} for tackling the geosciences and remote sensing problems.", 
        "author": "David J. Lary and Amir H. Alavi and Amir H. Gandomi and Annette L. Walker", 
        "keyword": "Machine learning\", \"Geosciences\", \"Remote sensing\", \"Regression\", \"Classification", 
        "title": "Machine learning in geosciences and remote sensing"
    }, 
    {
        "abstract": "Abstract This paper presents a novel computer-aided diagnosis (CAD) system for the diagnosis of breast cancer based on extreme learning machine (ELM). In view of a mammographic image, it is first eliminated interference in the preprocessing stages. Then, the preprocessed images are segmented by the level set model we proposed. Subsequently, a model of multidimensional feature vectors is built. Since not every feature vector contributes to the improvement of performance, feature selection is done by the combination of support vector machine (SVM) and extreme learning machine (ELM). Finally, an optimal subset of feature vectors is inputted into the classifiers for distinguishing malignant masses from benign ones. We also compare our breast mass classification approach based on \\{ELM\\} with several state-of-the-art classification models, and the results show that the proposed \\{CAD\\} system not only has good performance in terms of specificity, sensitivity and accuracy, but also achieves a significant reduction in training time compared with \\{SVM\\} and particle swarm optimization-support vector machine (PSO-SVM). Ultimately, our system achieves the better performance with average accuracy of 96.02% which indicates that the proposed segmentation model, the utilization of selected feature vectors and the effective classifier \\{ELM\\} provide satisfactory system.", 
        "author": "Weiying Xie and Yunsong Li and Yide Ma", 
        "keyword": "Mammography CAD\", \"Level set method\", \"Feature selection\", \"Extreme learning machine\", \"Support vector machine", 
        "title": "Breast mass classification in digital mammography based on extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this study, the novel method based on extreme learning machine (ELM) is adapted to estimate roughness of surface machined with abrasive water jet. Roughness of surface is one of the main attributes of quality of products derived from water jet processing, and directly depends on the cutting parameters, such as thickness of the workpiece, abrasive flow rate, cutting speed and others. In this study, in order to provide data on influence of parameters on surface roughness, extensive experiments were carried out for different cutting regimes. Measured data were used to model the process by using \\{ELM\\} model. Estimation and prediction results of \\{ELM\\} model were compared with genetic programming (GP) and artificial neural networks (ANNs) models. The experimental results show that an improvement in predictive accuracy and capability of generalization can be achieved by the \\{ELM\\} approach in comparison with \\{GP\\} and ANN. Moreover, achieved results indicate that developed \\{ELM\\} models can be used with confidence for further work on formulating novel model predictive strategy for roughness of the surface machined with abrasive water jet. In conclusion, it is conclusively found that application of \\{ELM\\} is particularly promising as an alternative method to estimate the roughness of the surface machined with abrasive water jet.", 
        "author": "\u017darko \u0106ojba\u0161i\u0107 and Dalibor Petkovi\u0107 and Shahaboddin Shamshirband and Chong Wen Tong and Sudheer Ch and Predrag Jankovi\u0107 and Nedeljko Du\u010di\u0107 and Jelena Barali\u0107", 
        "keyword": "Abrasive water jet\", \"Cutting\", \"Surface roughness\", \"Estimation\", \"Extreme learning machine (ELM)", 
        "title": "Surface roughness prediction by extreme learning machine constructed with abrasive water jet"
    }, 
    {
        "abstract": "Abstract Evaluation and prediction of displacement by specific models help in forecasting geo-hazards. Among the various available predictive tools, Least Square Support Vector Machines (LSSVM) model optimized with Genetic Algorithm, namely GA-LSSVM, is commonly used to empirically forecast landslide displacement due to its capability of processing non-linear complex systems. Another improved hybrid model composed of Double Exponential Smoothing (DES) and \\{LSSVM\\} considers measured displacement and precipitation time series to estimate the one-step ahead displacement evolution of rain-induced landslide. Here, the modelling process and accuracy of these two models are presented, and their predictive performances are evaluated by the root mean squared error (RMSE), mean absolute percentage error (MAPE), accuracy factor (AF), and correlation coefficient (R). A slowly-moving landslide on gently dipping rocky slope located in Sichuan Province of China was chosen as the case study for its deformation triggered by intense seasonal rainfall. The application results indicated that both GA-LSSVM and DES-LSSVM models were suitable for accurately predicting the landslide displacement on the basis of precipitation and displacement observations. Furthermore, comparison results show that DES-LSSVM model can provide the better predictive accuracy, with \\{RMSE\\} and \\{MAPE\\} values of 0.059 mm and 0.004%, respectively.", 
        "author": "Xing Zhu and Qiang Xu and Minggao Tang and Wen Nie and Shuqi Ma and Zhipeng Xu", 
        "keyword": "Genetic Algorithm\", \"Least Squares Support Vector Machines\", \"Double Exponential Smoothing\", keywords =Landslide\", \"High-accuracy prediction", 
        "title": "Comparison of two optimized machine learning models for predicting displacement of rainfall-induced landslide: A case study in Sichuan Province, China"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is a very simple machine learning algorithm and it can achieve a good generalization performance with extremely fast speed. Therefore it has practical significance for data analysis in real-world applications. However, it is implemented normally under the empirical risk minimization scheme and it may tend to generate a large-scale and over-fitting model. In this paper, an \\{ELM\\} model based on L1-norm and L2-norm regularizations is proposed to handle regression and multiple-class classification problems in a unified framework. The proposed model called L1\u2013L2-ELM combines the grouping effect benefits of \\{L2\\} penalty and the tendency towards sparse solution of \\{L1\\} penalty, thus it can control the complexity of the network and prevent over-fitting. To solve the mixed penalty problem, the separate elastic net algorithm and Bayesian information criterion (BIC) are adopted to find the optimal model for each response variable. We test the L1\u2013L2-ELM algorithm on one artificial case and nine benchmark data sets to evaluate its performance. Simulation results have shown that the proposed algorithms outperform the original \\{ELM\\} as well as other advanced \\{ELM\\} algorithms in terms of prediction accuracy, and it is more robust in both regression and classification applications.", 
        "author": "Xiong Luo and Xiaohui Chang and Xiaojuan Ban", 
        "keyword": "Extreme learning machine\", \"Ridge regression\", \"Elastic net\", \"Model selection\", \"Bayesian information criterion (BIC)", 
        "title": "Regression and classification using extreme learning machine based on L1-norm and L2-norm"
    }, 
    {
        "abstract": "Abstract Multi-view learning is a widely applicable research direction. This paper presents eight PAC-Bayes bounds to analyze the generalization performance of multi-view classifiers. These bounds adopt data dependent Gaussian priors which emphasize classifiers with high view agreements. The center of the prior for the first two bounds is the origin, while the center of the prior for the third and fourth bounds is given by a data dependent vector. An important technique to obtain these bounds is two derived logarithmic determinant inequalities whose difference lies in whether the dimensionality of data is involved. The centers of the fifth and sixth bounds are calculated on a separate subset of the training set. The last two bounds use unlabeled data to represent view agreements and are thus applicable to semi-supervised multi-view learning. We evaluate all the presented multi-view PAC-Bayes bounds on benchmark data and compare them with previous single-view PAC-Bayes bounds. The usefulness and performance of the multi-view bounds are discussed.", 
        "author": "Shiliang Sun and John Shawe-Taylor and Liang Mao", 
        "keyword": "PAC-Bayes bound\", \"Statistical learning theory\", \"Support vector machine\", \"Multi-view learning", 
        "title": "PAC-Bayes analysis of multi-view learning"
    }, 
    {
        "abstract": "Abstract In order to more accurately model time-varying nonlinear systems, we propose a regularized online sequential extreme learning machine with adaptive regulation factor (ROSELM-ARF). The construction of a new objective function allows for the online updating of both the model coefficient as well as the regulation factor, while negating the influence of the cumulate error. This differs from the traditional regularized online sequential extreme learning machine (ReOS-ELM) which only updates the model coefficient. The development and application of a two-step solving method is used to determine the optimal parameters, where the optimal regulation factor is derived using the proposed fast and online leave-one-out cross validation (FOLOO) method. The computational performance could be drastically improved by using the proposed \\{FOLOO\\} method as compared to using the existing leave-one-out cross validation (LOO) method. The application of the proposed method in the modeling of two practical cases is done in order to demonstrate its effectiveness. The experimental results indicate that the proposed method provides a more accurate model than several conventional modeling methods, while also improving the computational performance.", 
        "author": "XinJiang Lu and Chuang Zhou and MingHui Huang and WenBing Lv", 
        "keyword": "Extreme learning machine\", \"Adaptive regulation factor\", \"Leave-one-out cross validation\", \"modeling", 
        "title": "Regularized online sequential extreme learning machine with adaptive regulation factor for time-varying nonlinear system"
    }, 
    {
        "abstract": "Abstract Localization and interpretation of anatomical structures in medical images is a key step in radiological workflow. Radiologists/technicians usually accomplish this task by identifying some anatomical signatures\u2014any image features that can distinguish one anatomy from others. Is it possible for a computer to learn these \u201canatomical signatures\u201d as well? This chapter introduces a framework to learn anatomical signatures from a large quantity of medical image data. It starts from the detection of anatomical landmarks, gradually extending to organ boxes, and eventually reaching precise segmentation of human anatomies. Multiple machine learning technologies are employed and seamlessly integrated to learn \u201canatomical signatures\u201d at different levels. Our learning-based platform is applied to very diverse applications, ranging from orthopedic studies in magnetic resonance to oncology studies in positron emission tomography/computed tomography. It shows robust and accurate performance and can potentially benefit radiological workflow in various ways.", 
        "author": "Y. Zhan and M. Dewan and S. Zhang and Z. Peng and B. Jian and X.S. Zhou", 
        "keyword": "Machine learning\", \"Anatomy detection\", \"Image segmentation\", \"CT\", \"MR\", \"PET", 
        "title": "Chapter 13 - From point to surface: Hierarchical parsing of human anatomy in medical images using machine learning technologies"
    }, 
    {
        "abstract": "Abstract The persistence of polycyclic aromatic hydrocarbons (PAHs) in contaminated soils is largely controlled by their molecular fate in soil pores. The adsorption and diffusion of 16 \\{PAHs\\} mixture in silica nanopore with diameter of 2.0, 2.5, 3.0 and 3.5\u00a0nm, respectively, were characterized by adsorption energy, mean square displacement, free surface area and free volume fraction using molecular dynamic (MD) simulation. Results suggested that \\{PAHs\\} adsorption in silica nanopores was associated with diffusion process while competitive sorption was not the dominant mechanism in context of this study. The partial least squares (PLS) regression and machine learning (ML) methods (i.e. support vector regression, \\{M5\\} decision tree and multilayer perceptrons) were used to correlate the adsorption energy with the pore diameter and \\{PAH\\} properties (number of carbon atoms, aromatic ring number, boiling point, molecular weight, octanol\u2013water partition coefficient, octanol-organic carbon partition coefficient, solvent accessible area, solvent accessible volume and polarization). Results indicated that the \\{PAH\\} adsorption could not be predicted by linear regression as the \\{R2Y\\} and \\{Q2Y\\} coefficients of \\{PLS\\} analysis was 0.375 and 0.199, respectively. The nonlinearity was well recognized by \\{ML\\} with correlation coefficient up to 0.9. Overall, the combination of \\{MD\\} simulation and \\{ML\\} approaches can assist in interpreting the sequestration of organic contaminants in the soil nanopores.", 
        "author": "Hong Sui and Lin Li and Xinzhe Zhu and Daoyi Chen and Guozhong Wu", 
        "keyword": "Molecular dynamic simulation\", \"Adsorption\", \"Polycyclic aromatic hydrocarbons\", \"Nanopore\", \"Machine learning", 
        "title": "Modeling the adsorption of \\{PAH\\} mixture in silica nanopores by molecular dynamic simulation combined with machine learning"
    }, 
    {
        "abstract": "Abstract OBJECTIVE: The objective of this paper is to investigate the goals and variables employed in the machine learning and microsimulation studies for the prognosis of dementia. METHOD: According to preset protocols, the Pubmed, Socups and Web of Science databases were searched to find studies that matched the defined inclusion/exclusion criteria, and then its references were checked for new studies. A quality checklist assessed the selected studies, and removed the low quality ones. The remaining ones (included set) had their data extracted and summarized. RESULTS: The summary of the data of the 37 included studies showed that the most common goal of the selected studies was the prediction of the conversion from mild cognitive impairment to Alzheimer's Disease, for studies that used machine learning, and cost estimation for the microsimulation ones. About the variables, neuroimaging was the most frequent used. CONCLUSIONS: The systematic literature review showed clear trends in prognosis of dementia research in what concerns machine learning techniques and microsimulation.", 
        "author": "Ana Luiza Dallora and Shahryar Eivazzadeh and Emilia Mendes and Johan Berglund and Peter Anderberg", 
        "keyword": "dementia\", \"prognosis\", \"machine learning\", \"microsimulation", 
        "title": "Prognosis of Dementia Employing Machine Learning and Microsimulation Techniques: A Systematic Literature Review"
    }, 
    {
        "abstract": "Abstract Optimization of the layouts of arrays of wave energy converters (WECs) is a challenging problem. The hydrodynamic analysis and performance estimation of such systems are performed using semi-analytical and numerical models such as the boundary element method. However, the analysis of an array of such converters becomes computationally expensive, and the computational time increases rapidly with the number of devices in the system. As such determination of optimal layouts of \\{WECs\\} in arrays becomes extremely difficult. In this paper, a methodology involving multiple optimization strategies is presented to arrive at the solution to the complex problem. The approach includes a statistical emulator to predict the performance of the \\{WECs\\} in arrays, followed by an innovative active learning strategy to simultaneously explore and focus in regions of interest of the problem, and finally a genetic algorithm to obtain the optimal layouts of WECs. The method is extremely fast and easily scalable to arrays of any size. Case studies are performed on a wavefarm comprising of 40 \\{WECs\\} subject to arbitrary bathymetry and space constraints.", 
        "author": "Dripta Sarkar and Emile Contal and Nicolas Vayatis and Frederic Dias", 
        "keyword": "Wave-energy\", \"Oyster\", \"OWSC\", \"Optimization\", \"Active learning\", \"Genetic algorithm\", \"Gaussian process", 
        "title": "Prediction and optimization of wave energy converter arrays using a machine learning approach"
    }, 
    {
        "abstract": "Abstract This paper presents a project that explores the possibility of assessing the readability level of Arabic medicine information leaflets using machine learning techniques. There are a number of popular readability formulas and tools that have been successfully used to assess the readability of health-related information in several languages. However, there is limited work on the readability assessment of health-related information, specifically medicine information leaflets in Arabic. We describe the design of a tool that uses machine learning to assess the readability of medicine information leaflets. We utilize a corpus comprising 1112 medicine information leaflets annotated with three difficulty levels. Based on a study of existing literature, we selected a number of features influencing text difficulty. The tool will help specialized organizations in medicine information leaflets production to produce the leaflets at appropriate level of reading for the majority of leaflets consumers.", 
        "author": "Sihaam Alotaibi and Maha Alyahya and Hend Al-Khalifa and Sinaa Alageel and Nora Abanmy", 
        "keyword": "Text Readability\", \"Medicine Information Leaflets\", \"Machine Learning\", \"Arabic Language\", \"Arabic Natural Language Processing", 
        "title": "Readability of Arabic Medicine Information Leaflets: A Machine Learning Approach"
    }, 
    {
        "abstract": "Abstract Identifying the disease treatment relation enables to find what disease a person suffers from and what appropriate treatment can be given to that person. The semantic relation tags namely Cure, Prevent and Sideeffects helps to find out the relationship between disease and treatment. Many methodologies like co-occurrence analysis, rule based methodologies and statistical methods are used in disease treatment relation. However, machine learning is widely used in many applications like protein-protein interaction, extraction of medical knowledge and in health care field. we propose a machine learning approach termed as \\{SMO\\} classification, which uses several features namely medical papers, medical abstracts. Our approach identifies the features namely disease-treat, cure, prevent and sideeffects. The performance can be measured by Accuracy, Precision, F-measure and Recall.", 
        "author": "M.C. Keerrthega and D. Thenmozhi Ms.", 
        "keyword": "Natural Language Processing\", \"Machine Learning\", \"SMO Classifcation", 
        "title": "Identifying Disease -Treatment Relations Using Machine Learning Approach"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) uses a non-iterative method to train single-hidden-layer feed-forward networks (SLFNs), which has been proven to be an efficient and effective learning model for both classification and regression. The main advantage of \\{ELM\\} lies in that the input weights as well as the hidden layer biases can be randomly generated, which contributes to the analytical solution of output weights. In this paper, we propose a discriminative manifold \\{ELM\\} (DMELM) by simultaneously considering the discriminative information and geometric structure of data; specifically, we exploit the discriminative information in the local neighborhood around each data point. To this end, a graph regularizer based on a newly designed graph Laplacian to characterize both properties is formulated and incorporated into the \\{ELM\\} objective. In DMELM, the output weights can also be obtained in analytical form. Extensive experiments are conducted on image and \\{EEG\\} signal classification to evaluate the effectiveness of DMELM. The results show that \\{DMELM\\} consistently achieves better performance than original \\{ELM\\} and yields promising results in comparison with several state-of-the-art algorithms, which suggests that both the discriminative as well as manifold information are beneficial to classification.", 
        "author": "Yong Peng and Bao-Liang Lu", 
        "keyword": "Extreme learning machine\", \"Discriminative information\", \"Manifold information\", \"Image keywords =lassification\", \"EEG\", \"Emotion recognition", 
        "title": "Discriminative manifold extreme learning machine and applications to image and \\{EEG\\} signal classification"
    }, 
    {
        "abstract": "Abstract A new era of intelligent medical diagnostics is emerging with the development of machine learning-based algorithms to diagnose neurodegenerative diseases (NDDs). In the present work, we discuss an innovative framework that uses principal component analysis (PCA) for feature extraction, Fisher discriminant ratio (FDR) for feature selection and support vector machines (SVM) for classification of Healthy controls, Parkinson\u2019s Disease and \\{SWEDD\\} subjects. We have extended our framework to handle the challenge of multi-class disease diagnosis, wherein, accuracy up to 100% has been achieved. This demonstrates the potential of the present methodology to be developed into a clinical relevant diagnostic and decision support system.", 
        "author": "Gurpreet Singh and Meet Vadera and Lakshminarayanan Samavedham and Erle Chuen-Hian Lim", 
        "keyword": "Classification\", \"Computer-aided diagnosis\", \"Decision Support system\", \"Image-processing\", keywords =Knowledge based systems\", \"Machine learning", 
        "title": "Machine Learning-Based Framework for Multi-Class Diagnosis of Neurodegenerative Diseases: A Study on Parkinson\u2019s Disease"
    }, 
    {
        "abstract": "Abstract In this paper, we propose two alternative schemes of fast online sequential extreme learning machine (ELM) for training the single hidden-layer feedforward neural networks (SLFN), termed as Cholesky factorization based online regularized \\{ELM\\} with forgetting mechanism (CF-FORELM) and Cholesky factorization based online kernelized \\{ELM\\} with forgetting mechanism (CF-FOKELM). First, the solutions of regularized \\{ELM\\} (RELM) and kernelized \\{ELM\\} (KELM) using the matrix Cholesky factorization are introduced; then the recursive method for calculating Cholesky factor of involved matrix in \\{RELM\\} and \\{KELM\\} is designed when \\{RELM\\} and \\{KELM\\} are applied to train \\{SLFN\\} online; consequently, the CF-FORELM and CF-FOKELM are obtained. The numerical simulation results show CF-FORELM demands less computational burden than Dynamic Regression \\{ELM\\} (DR-ELM), and CF-FOKELM also owns higher computational efficiency than both \\{FOKELM\\} and online sequential \\{ELM\\} with kernels (OS-ELMK), and CF-FORELM is less sensitive to model parameters than CF-FOKELM.", 
        "author": "Xin-Ran Zhou and Chun-Sheng Wang", 
        "keyword": "Extreme learning machine\", \"Online sequential learning algorithms\", \"Forgetting mechanism\", \"Cholesky decomposition", 
        "title": "Cholesky factorization based online regularized and kernelized extreme learning machines with forgetting mechanism"
    }, 
    {
        "abstract": "Abstract Functional and structural neuroimaging have made progress in our understanding of schizophrenia. However, there is still uncertainty about how the clinical symptoms of schizophrenia relate to the neurobiology of the human brain. This prompted the current drift toward more data-driven (ie, fewer assumptions) and higher-dimensional (ie, more features per observation) neuroimaging analyses on larger samples of neuroimaging data (ie, more observations). Coordinate-based meta-analysis by activation likelihood estimation (ALE) may be used to perform quantitative large-scale aggregation of neuroimaging findings. However, emerging machine-learning (ML) approaches allow the automatic detection and prediction of diagnosis and treatment-response patterns in massive datasets. Coordinate-based meta-analysis and machine learning are introduced and exemplified regarding their potential in computational psychiatry research on schizophrenia.", 
        "author": "D. Bzdok and S.B. Eickhoff", 
        "keyword": "Computational psychiatry\", \"data-driven\", \"coordinate-based meta-analysis\", \"machine learning\", \"big data", 
        "title": "Chapter 19 - Statistical Learning of the Neurobiology of Schizophrenia: Neuroimaging Meta-Analyses and Machine-Learning in Schizophrenia Research"
    }, 
    {
        "abstract": "Abstract: Modern electricity grids continue to be vulnerable to large-scale blackouts. As all states leading to large-scale blackouts are unique, there is no algorithm to identify pre-emergency states. Moreover, numerical conventional methods are computationally expensive, which makes it difficult to use for the on-line security assessment. Machine learning techniques with their pattern recognition, learning capabilities and high speed of identifying the potential security boundaries can offer an alternative approach. The purpose of this paper is not to suggest that one particular kind of machine learning technique for security assessment would be more appropriate than others. We start from the premise that almost every method may be useful within some restricted context. Based on this idea, we developed an automated multi-model approach for on-line security assessment. The proposed method allows us to automatically test the different state-of-art techniques in order to find both the best algorithm and its top performance tuning for particular analyzed power system. A case study using the \\{IEEE\\} RTC-96 system demonstrates the effectiveness of the proposed approach.", 
        "author": "Nikita V. Tomin and Victor G. Kurbatsky and Denis N. Sidorov and Alexey V. Zhukov", 
        "keyword": "smart grid\", \"power system\", \"security assessment\", \"blackout\", \"machine learning", 
        "title": "Machine Learning Techniques for Power System Security Assessment*"
    }, 
    {
        "abstract": "Abstract As a single-hidden-layer feedforward neural network, an extreme learning machine (ELM) randomizes the weights between the input layer and the hidden layer as well as the bias of hidden neurons, and analytically determines the weights between the hidden layer and the output layer using the least-squares method. This paper proposes a two-hidden-layer \\{ELM\\} (denoted TELM) by introducing a novel method for obtaining the parameters of the second hidden layer (connection weights between the first and second hidden layer and the bias of the second hidden layer), hence bringing the actual hidden layer output closer to the expected hidden layer output in the two-hidden-layer feedforward network. Simultaneously, the \\{TELM\\} method inherits the randomness of the \\{ELM\\} technique for the first hidden layer (connection weights between the input weights and the first hidden layer and the bias of the first hidden layer). Experiments on several regression problems and some popular classification datasets demonstrate that the proposed \\{TELM\\} can consistently outperform the original ELM, as well as some existing multilayer \\{ELM\\} variants, in terms of average accuracy and the number of hidden neurons.", 
        "author": "B.Y. Qu and B.F. Lang and J.J. Liang and A.K. Qin and O.D. Crisalle", 
        "keyword": "Extreme learning machine\", \"Two-hidden-layer\", \"Regression\", \"Classification\", \"Neural network", 
        "title": "Two-hidden-layer extreme learning machine for regression and classification"
    }, 
    {
        "abstract": "Abstract We propose a modeling paradigm, termed field inversion and machine learning (FIML), that seeks to comprehensively harness data from sources such as high-fidelity simulations and experiments to aid the creation of improved closure models for computational physics applications. In contrast to inferring model parameters, this work uses inverse modeling to obtain corrective, spatially distributed functional terms, offering a route to directly address model-form errors. Once the inference has been performed over a number of problems that are representative of the deficient physics in the closure model, machine learning techniques are used to reconstruct the model corrections in terms of variables that appear in the closure model. These reconstructed functional forms are then used to augment the closure model in a predictive computational setting. As a first demonstrative example, a scalar ordinary differential equation is considered, wherein the model equation has missing and deficient terms. Following this, the methodology is extended to the prediction of turbulent channel flow. In both of these applications, the approach is demonstrated to be able to successfully reconstruct functional corrections and yield accurate predictive solutions while providing a measure of model form uncertainties.", 
        "author": "Eric J. Parish and Karthik Duraisamy", 
        "keyword": "Data-driven modeling\", \"Machine learning\", \"Closure modeling", 
        "title": "A paradigm for data-driven predictive modeling using field inversion and machine learning"
    }, 
    {
        "abstract": "Abstract We present a method for synthesising deep neural networks using Extreme Learning Machines (ELMs) as a stack of supervised autoencoders. We test the method using standard benchmark datasets for multi-class image classification (MNIST, CIFAR-10 and Google Streetview House Numbers (SVHN)), and show that the classification error rate can progressively improve with the inclusion of additional autoencoding \\{ELM\\} modules in a stack. Moreover, we found that the method can correctly classify up to 99.19% of \\{MNIST\\} test images, which surpasses the best error rates reported for standard 3-layer \\{ELMs\\} or previous deep \\{ELM\\} approaches when applied to MNIST. The approach simultaneously offers a significantly faster training algorithm to achieve its best performance (in the order of 5 min on a four-core \\{CPU\\} for MNIST) relative to a single \\{ELM\\} with the same total number of hidden units as the deep ELM, hence offering the best of both worlds: lower error rates and fast implementation.", 
        "author": "Migel D. Tissera and Mark D. McDonnell", 
        "keyword": "Extreme learning machine\", \"Supervised learning\", \"Autoencoder\", \"Classifier\", \"MNIST\", \"Deep neural network", 
        "title": "Deep extreme learning machines: supervised autoencoding architecture for classification"
    }, 
    {
        "abstract": "Abstract In this paper, a new framework to effectively classify the time sequence is developed. The whole time sequence is divided into several smaller sub-sequence by means of the sliding time window technique. The sub-sequence is modeled as a linear dynamic model by appropriate dimension reduction and the whole time sequence is represented as a bag-of-systems model. Such a model is very flexible to describe time sequence originated from different sensor source. To construct the bag-of-systems model, we design the codebook by using the K-medoids clustering algorithm and Martin distance between linear dynamic systems. Such a technology avoids the problem that linear dynamic systems lie in non-Euclidean manifold. After obtaining the represented of time sequence, an extreme learning machine is utilized for classification. Finally, the proposed method is verified on some benchmark and shows that it obtains promising results.", 
        "author": "Huaping Liu and Lianzhi Yu and Wen Wang and Fuchun Sun", 
        "keyword": "Extreme learning machine\", \"Time sequence classification\", \"Linear dynamical systems\", \"Bag-of-systems", 
        "title": "Extreme learning machine for time sequence classification"
    }, 
    {
        "abstract": "Abstract A central problem in modern computational science is that of learning an algebraic model from data obtained from simulations or experiments. We present a methodology that is designed to use a small number of data points to learn models that are as accurate and as simple as possible. The approach relies on integer programming techniques to build low-complexity models. The models are then improved systematically through the use of derivative-free optimization solvers to adaptively sample new simulation or experimental points. Physical constraints and insights are enforced to the model through the solution of semi-infinite optimization and global optimization subproblems. The proposed methodology has been implemented in the \\{ALAMO\\} software for automated learning of algebraic models. We present extensive computational results with \\{ALAMO\\} and comparisons between \\{ALAMO\\} and a variety of machine learning techniques, including Latin hypercube sampling, simple least-squares regression, and the lasso.", 
        "author": "Nick Sahinidis", 
        "keyword": "machine learning\", \"integer programming\", \"algebraic models\", \"derivative-free optimization\", \"ALAMO software", 
        "title": "The \\{ALAMO\\} approach to machine learning"
    }, 
    {
        "abstract": "Abstract In this paper an efficient active set algorithm is presented for fast training of Optimization Extreme Learning Machines (OELMs). This algorithm suggests the use of an efficient identification technique of active set and the value reassignment technique for quadratic programming problem. With these strategies, this algorithm is able to drop many constraints from the active set at each iteration, and it can converge to the optimal solution with less iterations. The global convergence properties of the algorithm as well as its theoretical properties are analyzed. The effectiveness of the algorithm is demonstrated via benchmark datasets from many sources. Experiment results indicate that the quadratic programming problem which keeps the number of constraints in the active set as small as possible is computationally most efficient.", 
        "author": "Ming-hua Zhao and Xiao-feng Ding and Zheng-hao Shi and Quan-zhu Yao and Yong-qin Yuan and Rui-yang Mo", 
        "keyword": "Optimization extreme learning machines\", \"Quadratic programming\", \"Active set\", \"Piecewise projected gradient", 
        "title": "An efficient active set method for optimization extreme learning machines"
    }, 
    {
        "abstract": "Abstract In recent years, along with the generation of uncertain data, more and more attention is paid to the mining of uncertain data. In this paper, we study the problem of classifying uncertain data using Extreme Learning Machine (ELM). We first propose the UU-ELM algorithm for classification of uncertain data which is uniformly distributed. Furthermore, the NU-ELM algorithm is proposed for classifying uncertain data which are non-uniformly distributed. By calculating bounds of the probability, the efficiency of the algorithm can be improved. Finally, the performances of our methods are verified through a large number of simulated experiments. The experimental results show that our methods are effective ways to solve the problem of uncertain data classification, reduce the execution time and improve the efficiency.", 
        "author": "Keyan Cao and Guoren Wang and Donghong Han and Mei Bai and Shuoru Li", 
        "keyword": "Extreme learning machine\", \"Classification\", \"Uncertain data\", \"Single hidden layer feedforward neural networks", 
        "title": "An algorithm for classification over uncertain data based on extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has been one widely used learning paradigm to train single hidden layer feedforward network (SLFN). However, like many other classification algorithms, \\{ELM\\} may learn undesirable class boundaries from data with unbalanced classes. This paper first tries to analyze the reason of the damage caused by class imbalance for ELM, and then discusses the influence of several data distribution factors for the damage. Next, we present an optimal decision outputs compensation strategy to deal with the class imbalance problem in the context of ELM. Specifically, the outputs of the minority classes in \\{ELM\\} are properly compensated. For a binary-class problem, the compensation can be regarded as a single variable optimization problem, thus the golden section search algorithm is adopted to find the optimal compensation value. For a multi-class problem, the particle swarm optimization (PSO) algorithm is used to solve the multivariate optimization problem and to provide the optimal combination of compensations. Experimental results on lots of imbalanced data sets demonstrate the superiority of the proposed algorithm. Statistical results indicate that the proposed approach not only outperforms the original ELM, but also yields better or at least competitive results compared with several widely used and state-of-the-art class imbalance learning methods.", 
        "author": "Hualong Yu and Changyin Sun and Xibei Yang and Wankou Yang and Jifeng Shen and Yunsong Qi", 
        "keyword": "Extreme learning machine\", \"Class imbalance learning\", \"Decision outputs compensation\", \"Prior data keywords =istributions\", \"Optimization", 
        "title": "ODOC-ELM: Optimal decision outputs compensation-based extreme learning machine for classifying imbalanced data"
    }, 
    {
        "abstract": "Abstract Automated seizure detection using \\{EEG\\} has gained increasing attraction in recent years and appeared more and more helpful in both diagnosis and treatment. How to design an appropriate feature extraction method and how to select an efficient classifier are recognized to be crucial in the successful realization. This paper first proposes a new Mahalanobis-similarity-based feature extraction method on the basis of the Mahalanobis distance and discrete wavelet transformation (DWT). Then in order to further improve the performance, this paper designs a fusion feature (MS-SE-FF) in the feature-fusion level, where the Mahalanobis-similarity-based feature characterizing the similarity between signals and the sample-entropy-based feature characterizing the complexity of signals are combined together. Finally, an automated seizure detection method FF-ELM-SD has been built, which is integrated between the novel fusion feature MS-SE-FF and extreme learning machine (ELM). Experimental results demonstrate that the proposed method FF-ELM-SD does a good job in the epileptic seizure detection while preserving the efficiency and simplicity.", 
        "author": "Jiang-Ling Song and Wenfeng Hu and Rui Zhang", 
        "keyword": "Epileptic seizure detection\", \"Mahalanobis distance\", \"Discrete wavelet transformation (DWT)\", keywords =Sample entropy\", \"Fusion feature\", \"Extreme learning machine (ELM)", 
        "title": "Automated detection of epileptic \\{EEGs\\} using a novel fusion feature and extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is a competitive machine learning technique, which is much more efficient and usually lead to better generalization performance compared to the traditional classifiers. In order to further improve its performance, we proposed a novel \\{ELM\\} called ELM+ which introduces the privileged information to the traditional \\{ELM\\} method. This privileged information, which is ignored by the classical \\{ELM\\} but often exists in human teaching and learning, will optimize the training stage by constructing a set of correcting functions. We demonstrate the performance of ELM+ on datasets from \\{UCI\\} machine learning repository, Mackey\u2013Glass time series and radar emitter recognition and also present the comparison with SVM, \\{ELM\\} and SVM+. The experimental results indicate the validity and advantage of our method.", 
        "author": "Wenbo Zhang and Hongbing Ji and Guisheng Liao and Yongquan Zhang", 
        "keyword": "Extreme learning machine (ELM)\", \"ELM+\", \"Privileged information\", \"Hidden information\", \"Radar emitter recognition", 
        "title": "A novel extreme learning machine using privileged information"
    }, 
    {
        "abstract": "Abstract The automotive engine is prone to various faults due to its complex structure and running conditions. Development of a fast response and accurate intelligent system for fault diagnosis of automotive engines is therefore greatly urged. The engine fault diagnosis faces challenges because of the existence of simultaneous-faults which are multiple single-faults appear concurrently. Another challenge is the high cost in acquiring the exponentially increased simultaneous-fault signals. Traditional signal-based engine fault diagnostic systems may not give reliable diagnostic results because they usually rely on single classifier and one kind of engine signal. To enhance the reliability of fault diagnosis and the number of detectable faults, this research proposes a new diagnostic framework namely probabilistic committee machine (PCM). The framework combines feature extraction (empirical mode decomposition and sample entropy), a parameter optimization algorithm, and multiple sparse Bayesian extreme learning machines (SBELM) to form an intelligent diagnostic framework. Multiple \\{SBELM\\} networks are built to form different domain committee members. The members are individually trained using air ratio, ignition pattern and engine sound signals. The diagnostic result from each fault detection member is then combined by using a new probabilistic ensemble method, which can improve the overall diagnostic accuracy and increase the number of detectable faults as compared to individual classifier. Experimental results show the proposed framework is superior to the existing single probabilistic classifier. Moreover, the proposed system can diagnose both single and simultaneous-faults for automotive engines while the system is trained by single-fault patterns only.", 
        "author": "Pak Kin Wong and Jianhua Zhong and Zhixin Yang and Chi Man Vong", 
        "keyword": "Automotive engine\", \"Multi-signal fusion\", \"Simultaneous-fault diagnosis\", \"Sparse Bayesian extreme keywords =earning machine\", \"Probabilistic committee machine", 
        "title": "Sparse Bayesian extreme learning committee machine for engine simultaneous fault diagnosis"
    }, 
    {
        "abstract": "Abstract The well-known Extreme Learning Machine (ELM) method is widely used to analyse independent random distributed measurements. However, in some applications, the problem of modeling clustered data which contains several correlated groups is of interest. The research presented in this paper utilizes the concept of random effects in the \\{ELM\\} framework to model inter-cluster heterogeneity, provided the inherent correlation among the samples of a particular cluster is taken into account, as well. The proposed random effect model includes an additional variance component to accommodate correlated data and to allow for differences among clusters. Inference techniques based on Bayesian evidence procedure are derived for the estimation of model weights, random effect and residual variance parameters as well as hyperparameters. The proposed model is applied to both synthesis and real world clustered datasets. Experimental results show that our proposed method can achieve better performance in terms of accuracy and model size, compared with the previous ELM-based models (ELM, BELM, and SBELM) with the assumption of independency, in cases where the data actually have within cluster correlation. The generalization performance and sparsity of the proposed model are also superior to those of the ME-LSSVM method.", 
        "author": "Farkhondeh Kiaee and Hamid Sheikhzadeh and Samaneh Eftekhari Mahabadi", 
        "keyword": "Extreme learning machine\", \"Mixed-effect models\", \"Sparse Bayesian\", \"Clustered data\", \"Random effect", 
        "title": "Sparse Bayesian mixed-effects extreme learning machine, an approach for unobserved clustered heterogeneity"
    }, 
    {
        "abstract": "Abstract As one of the most important energy resources, an accurate prediction for crude oil price can effectively guarantee a rapid new production development with higher production quality and less production cost. Accordingly, a novel decomposition-and-ensemble learning paradigm integrating ensemble empirical mode decomposition (EEMD) and extended extreme learning machine (EELM) is proposed for crude oil price forecasting, based on the principle of \u201cdecomposition and ensemble\u201d. This novel learning model makes contribution to literature by introducing the current powerful artificial intelligent (AI) technique of \\{EELM\\} in the ensemble model formulation. In the proposed method, EEMD, a competitive decomposition method, is first applied to divide the original data of crude oil price time series into a number of relatively regular components, for simplicity. Second, EELM, a currently proposed, powerful, effective and stable forecasting tool, is implemented to predict all components independently. Finally, these predicted results are aggregated into an ensemble result as final prediction, using simple addition ensemble method. For illustration and verification purposes, the proposed learning paradigm is used to predict the crude oil spot price of WTI. Empirical results demonstrate that the proposed novel ensemble learning paradigm statistically outperforms all considered benchmark models (including popular single models and similar ensemble models) in both prediction accuracy (in terms of level and directional measurement) and effectiveness (in terms of time saving and robustness), indicating that it is a promising tool to predict complicated time series with high volatility and irregularity.", 
        "author": "Lean Yu and Wei Dai and Ling Tang", 
        "keyword": "Crude oil price forecasting\", \"New production development\", \"Artificial intelligence\", keywords =Decomposition-and-ensemble learning paradigm\", \"Extended extreme learning machine", 
        "title": "A novel decomposition ensemble model with extended extreme learning machine for crude oil price forecasting"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has been intensively studied during the last decade due to its high efficiency, effectiveness and easy-to-implementation. Recently, many variants, such as parallel \\{ELM\\} (P-ELM) incremental \\{ELM\\} and online sequential ELM(OS-ELM), have been proposed to improve its timing performance and enable its ability of incremental learning. In this paper, we propose two parallel variants, termed as data parallel regularized \\{ELM\\} (DPR-ELM) and model parallel regularized \\{ELM\\} (MPR-ELM), to further improve the computational efficiency of \\{ELM\\} in handling large scale learning tasks. Collectively, these two variants are called as parallel regularized \\{ELM\\} (PR-ELM). Specifically, our proposed algorithms are implemented on cluster with Message Passing Interface (MPI) environment. In summary, the advantages of the proposed PR-ELM algorithms over existing variants are highlighted as follows: (1) They have better parallelism since they train each data block or each sub-model independently. (2) They dramatically reduce the requirement of huge runtime memory since the whole datasets or the whole model are split into small chunks or sub-models. (3) Both DPR-ELM and MPR-ELM have better scalability since they are able to be configured on clusters with many more computing nodes. Extensive experiments have been conducted to validate the effectiveness of the proposed algorithms. As shown, DPR-ELM and MPR-ELM achieve 5.15\u00d7 and 3.5\u00d7 speedup on cluster with six nodes, respectively. Moreover, the speedup of DPR-ELM increases to 5.85\u00d7 with the increase of the size of dataset, and this quantity is increased to 4\u00d7 for MPR-ELM with the increase of the number of hidden nodes.", 
        "author": "Yueqing Wang and Yong Dou and Xinwang Liu and Yuanwu Lei", 
        "keyword": "Parallel\", \"Extreme learning machine\", \"Cluster\", \"Data\", \"Model", 
        "title": "PR-ELM: Parallel regularized extreme learning machine based on cluster"
    }, 
    {
        "abstract": "Advances in automated and high-throughput imaging technologies have resulted in a deluge of high-resolution images and sensor data of plants. However, extracting patterns and features from this large corpus of data requires the use of machine learning (ML) tools to enable data assimilation and feature identification for stress phenotyping. Four stages of the decision cycle in plant stress phenotyping and plant breeding activities where different \\{ML\\} approaches can be deployed are (i) identification, (ii) classification, (iii) quantification, and (iv) prediction (ICQP). We provide here a comprehensive overview and user-friendly taxonomy of \\{ML\\} tools to enable the plant community to correctly and easily apply the appropriate \\{ML\\} tools and best-practice guidelines for various biotic and abiotic stress traits.", 
        "author": "Arti Singh and Baskar Ganapathysubramanian and Asheesh Kumar Singh and Soumik Sarkar", 
        "keyword": "high-throughput phenotyping\", \"machine learning\", \"Imaging\", \"plant breeding\", \"biotic stress\", \"abiotic stress", 
        "title": "Machine Learning for High-Throughput Stress Phenotyping in Plants"
    }, 
    {
        "abstract": "Abstract In this paper, we describe an approximate method for reducing the time and memory complexities of the kernel Extreme Learning Machine variants. We show that, by adopting a Nystr\u00f6m-based kernel \\{ELM\\} matrix approximation, we can define an \\{ELM\\} space exploiting properties of the kernel \\{ELM\\} space that can be subsequently used to apply several optimization schemes proposed in the literature for \\{ELM\\} network training. The resulted \\{ELM\\} network can achieve good performance, which is comparable to that of its standard kernel \\{ELM\\} counterpart, while overcoming the time and memory restrictions on kernel \\{ELM\\} algorithms that render their application in large-scale learning problems prohibitive.", 
        "author": "Alexandros Iosifidis and Moncef Gabbouj", 
        "keyword": "Kernel extreme learning machine\", \"Nystr\u00f6m approximation\", \"Graph-based regularization", 
        "title": "On the kernel Extreme Learning Machine speedup"
    }, 
    {
        "abstract": "Abstract This chapter provides an overview of two different clinical studies that apply machine learning techniques that create computational models capable of identifying abnormal network connections in the structural brain connectomes of patients with temporal lobe epilepsy (TLE). In particular, using only the structural connectome we introduce two new computational approaches aimed at predicting: (1) the surgical treatment outcome of patients with TLE, and (2) the naming impairment performance of patients with TLE. In both studies, prediction frameworks are trained to identify abnormal network connection patterns (ie, biomarkers) by applying supervised learning techniques to brain network features based on edge or node graph measures derived exclusively from the structural connectome. Furthermore, the performance of the proposed prediction frameworks is able to predict treatment outcomes in epilepsy with similar accuracy as compared with \u201cexpert-based\u201d clinical decision, or is able to predict naming impairment outcomes that are very similar to real outcomes as observed on standard language tests.", 
        "author": "B.C. Munsell and G. Wu and S. Keller and J. Fridriksson and B. Weber and M. Styner and D. Shen and L. Bonilha", 
        "keyword": "Structural brain connectome\", \"Diffusion tensor imaging (DTI)\", \"Temporal lobe epilepsy (TLE)\", keywords =Computational modeling\", \"Machine learning\", \"Treatment outcome prediction\", \"Naming impairment prediction", 
        "title": "Chapter 16 - Neuronal network architecture and temporal lobe epilepsy: A connectome-based and machine learning study"
    }, 
    {
        "abstract": "Abstract Mining data streams is one of the most vital fields in the current era of big data. Continuously arriving data may pose various problems, connected to their volume, variety or velocity. In this paper we focus on two important difficulties embedded in the nature of data streams: non- stationary nature and skewed class distributions. Such a scenario requires a classifier that is able to rapidly adapt itself to concept drift and displays robustness to class imbalance problem. We propose to use online version of Extreme Learning Machine that is enhanced by an efficient drift detector and method to alleviate the bias towards the majority class. We investigate three approaches based on undersampling, oversampling and cost-sensitive adaptation. Additionally, to allow for a rapid updating of the proposed classifier we show how to implement online Extreme Learning Machines with the usage of GPU. The proposed approach allows for a highly efficient mining of high-speed, drifting and imbalanced data streams with significant acceleration offered by \\{GPU\\} processing.", 
        "author": "Bartosz Krawczyk", 
        "keyword": "Data streams\", \"Imbalanced data\", \"Concept drift\", \"Big data\", \"Extreme learning machines\", \"GPU.", 
        "title": "GPU-Accelerated Extreme Learning Machines for Imbalanced Data Streams with Concept Drift"
    }, 
    {
        "abstract": "Abstract In this paper, we investigate the effectiveness of two-stage classification strategies in detecting north Atlantic right whale upcalls. Time-frequency measurements of data from passive acoustic monitoring devices are evaluated as images. Vocalization spectrograms are preprocessed for noise reduction and tone removal. First stage of the algorithm eliminates non-upcalls by an energy detection algorithm. In the second stage, two sets of features are extracted from the remaining signals using contour-based and texture based methods. The former is based on extraction of time\u2013frequency features from upcall contours, and the latter employs a Local Binary Pattern operator to extract distinguishing texture features of the upcalls. Subsequently evaluation phase is carried out by using several classifiers to assess the effectiveness of both the contour-based and texture-based features for upcall detection. Comparing \\{ROC\\} curves of machine learning algorithms obtained from Cornell University\u2019s dataset reveals that \\{LBP\\} features improved performance accuracy up to 43% over time\u2013frequency features. Classifiers such as the Linear Discriminant Analysis, Support Vector Machine, and TreeBagger achieve highest upcall detection rates with \\{LBP\\} features.", 
        "author": "Mahdi Esfahanian and Nurgun Erdol and Edmund Gerstein and Hanqi Zhuang", 
        "keyword": "North Atlantic right whale\", \"Acoustic monitoring\", \"Upcall detection\", \"Local binary patterns\", \"Classification", 
        "title": "Two-stage detection of north Atlantic right whale upcalls using local binary patterns and machine learning algorithms"
    }, 
    {
        "abstract": "AbstractBackground Epilepsy is one of the most common neurological disorders approximately one in every 100 people worldwide are suffering from it. Uncontrolled epilepsy poses a significant burden to society due to associated healthcare cost to treat and control the unpredictable and spontaneous occurrence of seizures. The objective of this research is to develop and present a novel classification framework that is utilised to discriminate interictal and preictal brain activities via quantitative analysis of electroencephalogram (EEG) recordings. New method Sample entropy-based features were extracted in parallel from 6 intracranial \\{EEG\\} channels, and then these features were fed to the extreme learning machine model for classification. Performance was evaluated on the basis of sensitivity and specificity and validation was performed using stratified cross-validation approach. Results The proposed method can correctly distinguish interictal and preictal \\{EEGs\\} with a sensitivity of 86.75% and a specificity of 83.80%, on average, across 21 patients and 6 epileptic seizure origins. Comparison with existing method Compared with traditional variance-based feature extraction, the proposed SampEn-based feature extraction method not only shows a significant improvement in the accuracy, but also has higher classification robustness and stability in terms of the much lower standard errors of classification accuracies across different evaluation periods. In addition, the proposed classification framework runs around 20 times faster than the support vector machine model during testing. Conclusions The high accuracy and efficiency of the proposed method makes it feasible to extend it to the development of a real-time EEG-based brain monitoring system for epileptic seizure prediction.", 
        "author": "Yuedong Song and Jiaxiang Zhang", 
        "keyword": "Epileptic seizure prediction\", \"Electroencephalograms (EEG)\", \"Sample entropy\", \"Extreme learning keywords =achine\", \"Feature extraction", 
        "title": "Discriminating preictal and interictal brain states in intracranial \\{EEG\\} by sample entropy and extreme learning machine"
    }, 
    {
        "abstract": "Summary The structure of genetic interaction networks predicts that, analogous to synthetic lethal interactions between non-essential genes, combinations of compounds with latent activities may exhibit potent synergism. To test this hypothesis, we generated a chemical-genetic matrix of 195 diverse yeast deletion strains treated with 4,915 compounds. This approach uncovered 1,221 genotype-specific inhibitors, which we termed cryptagens. Synergism between 8,128 structurally disparate cryptagen pairs was assessed experimentally and used to benchmark predictive algorithms. A model based on the chemical-genetic matrix and the genetic interaction network failed to accurately predict synergism. However, a combined random forest and Naive Bayesian learner that associated chemical structural features with genotype-specific growth inhibition had strong predictive power. This approach identified previously unknown compound combinations that exhibited species-selective toxicity toward human fungal pathogens. This work demonstrates that machine learning methods trained on unbiased chemical-genetic interaction data may be widely applicable for the discovery of synergistic combinations in different species.", 
        "author": "Jan Wildenhain and Michaela Spitzer and Sonam Dolma and Nick Jarvik and Rachel White and Marcia Roy and Emma Griffiths and David\u00a0S. Bellows and Gerard\u00a0D. Wright and Mike Tyers", 
        "keyword": "antifungal\", \"combination\", \"synergism\", \"genetic network\", \"bipartite graph\", \"Bayesian analysis\", keywords =machine learning\", \"random forest\", \"chemical-genetic interaction", 
        "title": "Prediction of Synergism from Chemical-Genetic Interactions by Machine Learning"
    }, 
    {
        "abstract": "Abstract Classification of motor imagery electroencephalogram (EEG) is one of the most important technologies for BCI. To improve the accuracy, this paper introduces a classification system based on Multilayer Extreme Learning Machine (ML-ELM). In the system, the combination of \\{PCA\\} and \\{LDA\\} is chosen as the method of feature extraction and the ML-ELM is used to classify. The ML-ELM has not only the advantage which \\{ELM\\} has but also better performance than ELM. In the experiment, our method is compared with the methods based on ELM, such as kernel-ELM, Constrained-ELM and V-ELM, and some state-of\u2013the-art methods on the same dataset. The experimental results show that ML-ELM is much more suitable for motor imagery \\{EEG\\} data and has better performance than the others.", 
        "author": "Lijuan Duan and Menghu Bao and Jun Miao and Yanhui Xu and Juncheng Chen", 
        "keyword": "Electroencephalogram Classification\", \"Motor Imagery\", \"Extreme Learning Machine\", \"Multilayer Extreme Learning Machine", 
        "title": "Classification Based on Multilayer Extreme Learning Machine for Motor Imagery Task from \\{EEG\\} Signals"
    }, 
    {
        "abstract": "Abstract Reliable carbonation depth prediction of concrete structures is crucial for optimizing their design and maintenance. The challenge of conventional carbonation prediction models is capturing the complex relationship between governing parameters. To improve the accuracy and methodology of the prediction a machine learning based carbonation prediction model which integrates four learning methods is introduced. The model developed considers parameters influencing the carbonation process and enables the user to choose the best alternative of the machine based methods. The applicability of the method is demonstrated by an example where the carbonation depths are estimated using the developed model and verified with unseen data. The evaluation proofs that the model predicts the carbonation depth with a high accuracy.", 
        "author": "Woubishet Zewdu Taffese and Esko Sistonen and Jari Puttonen", 
        "keyword": "Carbonation\", \"Concrete\", \"Machine learning\", \"Neural network\", \"Decision tree\", \"Bagged decision keywords =ree\", \"Boosted decision tree\", \"Model", 
        "title": "CaPrM: Carbonation prediction model for reinforced concrete using machine learning methods"
    }, 
    {
        "abstract": "Abstract A novel sampling pool selection scheme is proposed for the online sequential extreme learning machine (OS-ELM) based on improved Gath\u2013Geva (IGG) fuzzy segmentation algorithm. Tidal change is a time-varying process whose dynamics vary with changes of internal and environmental factors such as celestial bodies movements, coastal topology and environmental disturbances. When OS-ELM is implemented for identifying time-varying system dynamics, it usually sequentially selects samples with fixed number. Under such circumstance, samples representing different system dynamics are mixed together so that the online representation and prediction abilities of OS-ELM may be deteriorated. To consciously select samples with most representing ability and construct appropriate sampling pool for OS-ELM, in this study, a dynamic sampling pool selection scheme is proposed based on \\{IGG\\} fuzzy segmentation approach. Time series of input and output variables are segmented as per their dynamics characteristics. The change points split up the time series into several segments and the change points themselves represent the changes of system dynamics. Samples within the same segment are considered as possessing homogeneous characteristics. To achieve best representing abilities for current system dynamics, the proposed IGG-based sampling scheme is implemented for selecting sampling pool. The OS-ELM selects homogeneous samples from sampling pool thus possesses better representing ability for current dynamics. In the meantime, conventional harmonic analysis is also applied to represent the influences of celestial bodies and coastal topology. The harmonic method and IGG-based OS-ELM are combined together and the resulted modular prediction scheme is applied for online tidal level prediction of ports of King Point, Mokuoloe and Old Port Tampa in the United States. Simulation results demonstrate the feasibility and effectiveness of the proposed sampling scheme and the modular tidal prediction approach.", 
        "author": "Jianchuan Yin and Nini Wang", 
        "keyword": "Online sequential extreme learning machine\", \"Gath\u2013Geva fuzzy segmentation\", \"Tidal prediction\", \"Modular prediction", 
        "title": "An online sequential extreme learning machine for tidal prediction based on improved Gath\u2013Geva fuzzy segmentation"
    }, 
    {
        "abstract": "Abstract In this study, a novel method based on Extreme Learning Machine with wavelet transform algorithm (ELM-WT) was designed and adapted to estimate the exergetic performance of a \\{DI\\} diesel engine. The exergetic information was obtained by calculating mass, energy, and exergy balance equations for the experimental trials conducted at various engine speeds and loads as well as different biodiesel and expanded polystyrene contents. Furthermore, estimation capability of the ELM-WT model was compared with that of the ELM, \\{GP\\} (genetic programming) and \\{ANN\\} (artificial neural network) models. The experimental results showed that an improvement in the exergetic performance modelling of the \\{DI\\} diesel engine could be achieved by the ELM-WT approach in comparison with the ELM, GP, and \\{ANN\\} methods. Furthermore, the results showed that the applied algorithm could learn thousands of times faster than the conventional popular learning algorithms. Obviously, the developed ELM-WT model could be used with a high degree of confidence for further work on formulating novel model predictive strategy for investigating exergetic performance of \\{DI\\} diesel engines running on various renewable and non-renewable fuels.", 
        "author": "Mortaza Aghbashlo and Shahaboddin Shamshirband and Meisam Tabatabaei and Por Lip Yee and Yaser Nabavi Larimi", 
        "keyword": "Biodiesel\", \"DI diesel engine\", \"Exergetic performance parameters\", \"Expanded polystyrene\", \"Cost keywords =ensitivity analysis\", \"Extreme learning machine-wavelet (ELM-WT)", 
        "title": "The use of ELM-WT (extreme learning machine with wavelet transform algorithm) to predict exergetic performance of a \\{DI\\} diesel engine running on diesel/biodiesel blends containing polymer waste"
    }, 
    {
        "abstract": "Abstract Multi-instance learning (MIL) is commonly used to classify a set of instances, also known as a bag, where labels for the training set are only available for each bag. Many \\{MIL\\} methods exist, but they often suffer from high computation complexity and the key information from \\{MIL\\} being ignored, which deteriorates the classification performance. Recently, locality-sensitive hashing (LSH), with its high scalability, has shown the ability in enhancing \\{MIL\\} performance. However, for these LSH-based methods, the fixed number of bits is used to represent each projected dimension, resulting in subtle information loss and the algorithm performance reduction. In this paper, we propose a self-adaptive \\{LSH\\} encoding method for MIL, termed as SALE. \\{SALE\\} uses \\{LSH\\} to generate the primary batches, followed by a self-adaptive process for reconstruction. Reconstructed bags are transformed into random super histograms (RSH) using an incomplete coding method, and then weighted through a scheme that takes advantage of key instances. These weighted \\{RSHs\\} are used to train the learning model. \\{SALE\\} efficiently deals with large \\{MIL\\} problems, due to its low complexity and RSH\u2019s ability to exploit key information of MIL. Experiments demonstrate SALE\u2019s good performance compared to state-of-the-art \\{MIL\\} methods.", 
        "author": "Dongkuan Xu and Jia Wu and Dewei Li and Yingjie Tian and Xingquan Zhu and Xindong Wu", 
        "keyword": "Multi-instance learning\", \"Machine learning\", \"Locality-sensitive hashing\", \"Self-adaptive learning", 
        "title": "SALE: Self-adaptive \\{LSH\\} encoding for multi-instance learning"
    }, 
    {
        "abstract": "Abstract The use of machine learning algorithms has increased in a wide variety of domains (from finance to biocomputing and astronomy), and nowadays has a significant impact on the geoscience community. In most real cases geoscience data modelling problems are multivariate, high dimensional, variable at several spatial scales, and are generated by non-linear processes. For such complex data, the spatial prediction of continuous (or categorical) variables is a challenging task. The aim of this paper is to investigate the potential of the recently developed Extreme Learning Machine (ELM) for environmental data analysis, modelling and spatial prediction purposes. An important contribution of this study deals with an application of a generic self-consistent methodology for environmental data driven modelling based on Extreme Learning Machine. Both real and simulated data are used to demonstrate applicability of \\{ELM\\} at different stages of the study to understand and justify the results.", 
        "author": "Michael Leuenberger and Mikhail Kanevski", 
        "keyword": "Extreme Learning Machine\", \"Spatial environmental data", 
        "title": "Extreme Learning Machines for spatial environmental data"
    }, 
    {
        "abstract": "Abstract This paper focuses on modeling and reducing \\{NOX\\} emissions for a coal-fired boilers with advanced machine learning approaches. The novel \\{ELM\\} (extreme learning machine) model was introduced to model the correlation between operational parameters and \\{NOX\\} emissions of the boiler. Approximately ten days of real data from the \\{SIS\\} (supervisory information system) of a 700\u00a0MW coal-fired power plant were acquired to train and verify the ELM-based \\{NOX\\} model. Based on the \\{NOX\\} model, \\{HS\\} (harmony search) algorithm was then employed to optimize the operational parameters to finally realize \\{NOX\\} emission reduction. The modeling results indicated that the \\{ELM\\} model was more precise and faster in modeling \\{NOX\\} emissions than the popular artificial neural network and support vector regression. The searching process of \\{HS\\} was convergent and consumed only 0.7\u00a0s of \\{CPU\\} (Central Processing Unit) time on a personal computer. 16.5% and 19.3% \\{NOX\\} emission reductions for the two selected cases were achieved according to the simulation result. Additionally, the simulation result was experimentally justified, which demonstrated that the experimental results corresponded well with the computational: the experimental \\{NOX\\} reduction percentages were 14.8% and 15.7%, respectively. The proposed integrated method was capable of providing desired and feasible solutions within 1\u00a0s.", 
        "author": "Peng Tan and Ji Xia and Cheng Zhang and Qingyan Fang and Gang Chen", 
        "keyword": "\\{NOX\\} emissions\", \"Extreme learning machine\", \"Harmony search\", \"Combustion optimization\", \"Coal-fired boiler", 
        "title": "Modeling and reduction of \\{NOX\\} emissions for a 700\u00a0MW coal-fired boiler with the advanced machine learning method"
    }, 
    {
        "abstract": "Abstract A demand for predictive models for on-line estimation of variables is increasing in industry. As industrial processes are time-varying, on-line learning algorithms should be adaptive to capture process changes. On-line ensemble methods have been shown to provide better generalization performance than single models in changing environments. However, most on-line ensembles do not include and exclude models during on-line operation. As a result, the ensembles have limited adaptation capability. Moreover, a higher performance can be obtained by combining a selected set of most relevant models of the ensemble for the current situation, rather than combining all the models. This paper proposes a new on-line learning ensemble of regressor models using an ordered aggregation (OA) technique which is able to provide on-line predictions of variables in changing environments. \\{OA\\} dynamically selects an optimal size and composition of a subset of models based on the minimization of the ensemble error on the newest sample. The proposed strategy overcomes the problem of defining the optimal ensemble size, and in most cases it obtains better performance than aggregating all the models. Models are added or removed for assuring adaptation of the ensemble in changing environments. Furthermore, this paper proposes and integrates a new on-line Extreme Learning Machine (ELM) neural network model with variable forgetting factor (FF) using the directional \\{FF\\} method which shows superior performance in industrial applications when compared to the well-known On-line Sequential \\{ELM\\} (OS-ELM) algorithm. Experiments are reported to demonstrate the performance and effectiveness of the proposed methods.", 
        "author": "Symone G. Soares and Rui Ara\u00fajo", 
        "keyword": "On-line Extreme Learning Machines\", \"On-line ensemble\", \"Ordered aggregation\", \"Variable forgetting factor", 
        "title": "An adaptive ensemble of on-line Extreme Learning Machines with variable forgetting factor for dynamic system prediction"
    }, 
    {
        "abstract": "AbstractBackground and objectives Labeling instances by domain experts for classification is often time consuming and expensive. To reduce such labeling efforts, we had proposed the application of active learning (AL) methods, introduced our CAESAR-ALE framework for classifying the severity of clinical conditions, and shown its significant reduction of labeling efforts. The use of any of three \\{AL\\} methods (one well known [SVM-Margin], and two that we introduced [Exploitation and Combination_XA]) significantly reduced (by 48% to 64%) condition labeling efforts, compared to standard passive (random instance-selection) \\{SVM\\} learning. Furthermore, our new \\{AL\\} methods achieved maximal accuracy using 12% fewer labeled cases than the SVM-Margin \\{AL\\} method. However, because labelers have varying levels of expertise, a major issue associated with learning methods, and \\{AL\\} methods in particular, is how to best to use the labeling provided by a committee of labelers. First, we wanted to know, based on the labelers\u2019 learning curves, whether using \\{AL\\} methods (versus standard passive learning methods) has an effect on the Intra-labeler variability (within the learning curve of each labeler) and inter-labeler variability (among the learning curves of different labelers). Then, we wanted to examine the effect of learning (either passively or actively) from the labels created by the majority consensus of a group of labelers. Methods We used our CAESAR-ALE framework for classifying the severity of clinical conditions, the three \\{AL\\} methods and the passive learning method, as mentioned above, to induce the classifications models. We used a dataset of 516 clinical conditions and their severity labeling, represented by features aggregated from the medical records of 1.9 million patients treated at Columbia University Medical Center. We analyzed the variance of the classification performance within (intra-labeler), and especially among (inter-labeler) the classification models that were induced by using the labels provided by seven labelers. We also compared the performance of the passive and active learning models when using the consensus label. Results The \\{AL\\} methods: produced, for the models induced from each labeler, smoother Intra-labeler learning curves during the training phase, compared to the models produced when using the passive learning method. The mean standard deviation of the learning curves of the three \\{AL\\} methods over all labelers (mean: 0.0379; range: [0.0182 to 0.0496]), was significantly lower (p = 0.049) than the Intra-labeler standard deviation when using the passive learning method (mean: 0.0484; range: [0.0275\u20130.0724). Using the \\{AL\\} methods resulted in a lower mean Inter-labeler \\{AUC\\} standard deviation among the \\{AUC\\} values of the labelers\u2019 different models during the training phase, compared to the variance of the induced models\u2019 \\{AUC\\} values when using passive learning. The Inter-labeler \\{AUC\\} standard deviation, using the passive learning method (0.039), was almost twice as high as the Inter-labeler standard deviation using our two new \\{AL\\} methods (0.02 and 0.019, respectively). The SVM-Margin \\{AL\\} method resulted in an Inter-labeler standard deviation (0.029) that was higher by almost 50% than that of our two \\{AL\\} methods The difference in the inter-labeler standard deviation between the passive learning method and the SVM-Margin learning method was significant (p = 0.042). The difference between the SVM-Margin and Exploitation method was insignificant (p = 0.29), as was the difference between the Combination_XA and Exploitation methods (p = 0.67). Finally, using the consensus label led to a learning curve that had a higher mean intra-labeler variance, but resulted eventually in an \\{AUC\\} that was at least as high as the \\{AUC\\} achieved using the gold standard label and that was always higher than the expected mean \\{AUC\\} of a randomly selected labeler, regardless of the choice of learning method (including a passive learning method). Using a paired t-test, the difference between the intra-labeler \\{AUC\\} standard deviation when using the consensus label, versus that value when using the other two labeling strategies, was significant only when using the passive learning method (p = 0.014), but not when using any of the three \\{AL\\} methods. Conclusions The use of \\{AL\\} methods, (a) reduces intra-labeler variability in the performance of the induced models during the training phase, and thus reduces the risk of halting the process at a local minimum that is significantly different in performance from the rest of the learned models; and (b) reduces Inter-labeler performance variance, and thus reduces the dependence on the use of a particular labeler. In addition, the use of a consensus label, agreed upon by a rather uneven group of labelers, might be at least as good as using the gold standard labeler, who might not be available, and certainly better than randomly selecting one of the group\u2019s individual labelers. Finally, using the \\{AL\\} methods: when provided by the consensus label reduced the intra-labeler \\{AUC\\} variance during the learning phase, compared to using passive learning.", 
        "author": "Nir Nissim and Yuval Shahar and Yuval Elovici and George Hripcsak and Robert Moskovitch", 
        "keyword": "Active learning\", \"Electronic health records\", \"Phenotyping\", \"Condition\", \"Severity\", \"Variance\", \"Labeling", 
        "title": "Inter-labeler and intra-labeler variability of condition severity classification models using active and passive learning methods"
    }, 
    {
        "abstract": "Abstract This paper concerns the universal consistency of extreme learning machine (ELM) for radial basis function networks (RBFNs). That is, the estimator constructed by \\{ELM\\} for \\{RBFNs\\} learning system can approximate an arbitrary regression function to any accuracy, as long as the number of the training samples is sufficiently large. Furthermore, we also give the conditions for the kernel functions, with which the corresponding ELM-RBFNs estimator is strongly universal consistency. These results not only underlie the feasibility of \\{ELM\\} for \\{RBFNs\\} case, but also provide guidance of practical selection for kernel functions in \\{ELM\\} application.", 
        "author": "Xia Liu and Anhua Wan", 
        "keyword": "Extreme learning machine\", \"Radial basis function networks\", \"Universal consistency", 
        "title": "Universal consistency of extreme learning machine for \\{RBFNs\\} case"
    }, 
    {
        "abstract": "Abstract Multivariate statistical classification methods began in the 1930s with Fisher's linear discriminant function analysis (LDFA). This analysis, despite several important distributional requirements and limitations, has been used extensively in forensic anthropology for classification and in bioarchaeology for biodistance studies. Other statistical classification methods may be more appropriate when \\{LDFA\\} requirements are not met. Since the 1970s, electronic computers have enabled more data-intensive methods, including simulations and machine learning (ML) methods, which continue to revolutionize statistical analysis and classification. \\{ML\\} relies on resampling to create numerous samples that are analyzed using any number of methods. Ensemble methods can use a number of \\{ML\\} methods to come to a consensus classification. \\{ML\\} classifications are often 100% accurate, but most implementations have been used in classifying into only two groups. This chapter is a review and investigation of traditional and \\{ML\\} classification methods using simulation to increase our understanding of them and to improve them.", 
        "author": "S.D. Ousley", 
        "keyword": "Biodistance\", \"Bootstrap\", \"Curse of dimensionality\", \"Daubert\", \"Forensic anthropology\", \"Machine keywords =earning\", \"Simulation\", \"Statistical classification", 
        "title": "Chapter 10 - Forensic Classification and Biodistance in the 21st Century: The\u00a0Rise of Learning Machines"
    }, 
    {
        "abstract": "Abstract This letter to the editor refers to the recently published paper of Wang et al. (2008) [Single-machine scheduling with a time-dependent learning effect. Int. J. Prod. Econ. 111, 802\u2013811]. Wang et al. (2008) showed that an optimal schedule for the number of tardy jobs minimization problem could be obtained by Moores algorithm for some special cases. In this letter, we demonstrate that these results are incorrect by two counterexamples.", 
        "author": "Lin Li and Xiao-Yuan Wang", 
        "keyword": "Scheduling\", \"Single machine\", \"Learning effect\", \"Time-dependent", 
        "title": "Research on single-machine scheduling with a time-dependent learning effect"
    }, 
    {
        "abstract": "Abstract In this paper, the architecture of feedforward kernel neural networks (FKNN) is proposed, which can include a considerably large family of existing feedforward neural networks and hence can meet most practical requirements. Different from the common understanding of learning, it is revealed that when the number of the hidden nodes of every hidden layer and the type of the adopted kernel based activation functions are pre-fixed, a special kernel principal component analysis (KPCA) is always implicitly executed, which can result in the fact that all the hidden layers of such networks need not be tuned and their parameters can be randomly assigned and even may be independent of the training data. Therefore, the least learning machine (LLM) is extended into its generalized version in the sense of adopting much more error functions rather than mean squared error (MSE) function only. As an additional merit, it is also revealed that rigorous Mercer kernel condition is not required in \\{FKNN\\} networks. When the proposed architecture of \\{FKNN\\} networks is constructed in a layer-by-layer way, i.e., the number of the hidden nodes of every hidden layer may be determined only in terms of the extracted principal components after the explicit execution of a KPCA, we can develop FKNN's deep architecture such that its deep learning framework (DLF) has strong theoretical guarantee. Our experimental results about image classification manifest that the proposed FKNN's deep architecture and its \\{DLF\\} based learning indeed enhance the classification performance.", 
        "author": "Shitong Wang and Yizhang Jiang and Fu-Lai Chung and Pengjiang Qian", 
        "keyword": "Feedforward kernel neural networks\", \"Least learning machine\", \"Kernel principal component analysis keywords =KPCA)\", \"Hidden-layer-tuning-free learning\", \"Deep architecture and learning", 
        "title": "Feedforward kernel neural networks, generalized least learning machine, and its deep learning with application to image classification"
    }, 
    {
        "abstract": "Abstract Dissolved inorganic nitrogen (DIN) are typically the main focus of nutrient management strategies; however, some studies have found that dissolved organic nitrogen (DON) can be the dominant form of total nitrogen (TN) in several Australian estuaries and catchments. To better understand nitrogen cycling and explore the relationships between measured groundwater \\{DON\\} and environmental factors, thirteen machine learning (ML) techniques were compared in this study. \\{DON\\} was simulated under two scenarios using a range of input variables: 1) detailed nutrient data with landscape and sampling factors, and 2) limited nutrient data with landscape and sampling factors. Most of the tested \\{ML\\} algorithms more accurately predicted \\{DON\\} than when it was estimated from the difference between \\{TN\\} and DIN. Some models show greater adaptability to different modelling conditions, with only a few approaches able to predict with high accuracy using limited input variables (scenario 2). From the models tested, bagged mars, cubist and random forest were selected as optimal. Sample depth, sampling date and specific surface water area were the important non-nutrient input variables for \\{DON\\} prediction, which reveals the significant effect of surface environmental factors and seasonality on groundwater DON.", 
        "author": "Benya Wang and Carolyn Oldham and Matthew R. Hipsey", 
        "keyword": "DON\", \"Machine learning\", \"Groundwater\", \"Swan-Canning estuary", 
        "title": "Comparison of Machine Learning Techniques and Variables for Groundwater Dissolved Organic Nitrogen Prediction in an Urban Area"
    }, 
    {
        "abstract": null, 
        "author": "Fabio Aiolli and Ga\u00eblle Bonnet-Loosli and Romain H\u00e9rault", 
        "keyword": null, 
        "title": "Advances in artificial neural networks, machine learning and computational intelligence \u2013 Editorial"
    }, 
    {
        "abstract": "Abstract With the growing success of machine learning, both researchers and philosophers have recently regained their interest in the foundational problems of statistical learning. The cooperation between philosophy and machine learning has been recognized to be mutually beneficial that may provide fundamental shift in the paradigms of both camps. In this paper, a unidirectional interaction between philosophy and machine learning is considered. This type of interaction becomes necessary as we reflect upon the practical implications of the model construction. To this extent, I review a specific set of contributions of philosophy to machine learning in determining epistemic standing of object representation and algorithmic design. I discuss three aspects of statistical models, pertaining to semantics of object representation, namely idealization (simplifying properties of an object), abstraction (representing an object with another object that is easier to handle), and use of latent variables. I argue to what extent these aspects necessitate philosophical attention to justify their practical use. To this end, I elucidate different philosophical concepts that are utilized by researchers mostly tacitly when dealing with uncertainties in features and their functional relationships. This is expected to help pave the way for further investigations on semantics of object representation in machine learning.", 
        "author": "Birkan Tun\u00e7", 
        "keyword": "Philosophy of machine learning\", \"Object representation\", \"Idealization\", \"Abstraction\", \"Latent variables", 
        "title": "Semantics of object representation in machine learning"
    }, 
    {
        "abstract": null, 
        "author": "Nehemiah T. Liu and Jose Salinas", 
        "keyword": "Machine learning\", \"Neural networks\", \"Mortality prediction\", \"Burn care\", \"Burn wounds", 
        "title": "Machine learning in burn care and research: A systematic review of the literature"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel regularization approach for Extreme Learning Machines. Regularization is performed using a priori spatial information expressed by an affinity matrix. We show that the use of this type of a priori information is similar to perform Tikhonov regularization. Furthermore, if a parameter free affinity matrix is used, like the cosine similarity matrix, regularization is performed without any need for parameter tuning. Experiments are performed using classification problems to validate the proposed approach.", 
        "author": "Leonardo Jos\u00e9 Silvestre and Andr\u00e9 Paim Lemos and Jo\u00e3o Pedro Braga and Ant\u00f4nio P\u00e1dua Braga", 
        "keyword": "Regularization\", \"Extreme learning machines\", \"Affinity matrices", 
        "title": "Dataset structure as prior information for parameter-free regularization of extreme learning machines"
    }, 
    {
        "abstract": "Abstract Contextual information about users is increasingly shared on mobile social networks. Examples of such information include users\u2019 locations, events, activities, and the co-presence of others in proximity. When disclosing personal information, users take into account several factors to balance privacy, utility and convenience \u2014 they want to share the \u201cright\u201d amount and type of information at each time, thus revealing a selective sharing behavior depending on the context, with a minimum amount of user interaction. In this article, we present SPISM, a novel information-sharing system that decides (semi-)automatically, based on personal and contextual features, whether to share information with others and at what granularity, whenever it is requested. \\{SPISM\\} makes use of (active) machine-learning techniques, including cost-sensitive multi-class classifiers based on support vector machines. \\{SPISM\\} provides both ease of use and privacy features: It adapts to each user\u2019s behavior and predicts the level of detail for each sharing decision. Based on a personalized survey about information sharing, which involves 70 participants, our results provide insight into the most influential features behind a sharing decision, the reasons users share different types of information and their confidence in such decisions. We show that \\{SPISM\\} outperforms other kinds of policies; it achieves a median proportion of correct sharing decisions of 72% (after only 40 manual decisions). We also show that \\{SPISM\\} can be optimized to gracefully balance utility and privacy, but at the cost of a slight decrease in accuracy. Finally, we assess the potential of a one-size-fits-all version of SPISM.", 
        "author": "Igor Bilogrevic and K\u00e9vin Huguenin and Berker Agir and Murtuza Jadliwala and Maria Gazaki and Jean-Pierre Hubaux", 
        "keyword": "Information-sharing\", \"Decision-making\", \"Machine learning\", \"User study\", \"Privacy", 
        "title": "A machine-learning based approach to privacy-aware information-sharing in mobile social networks"
    }, 
    {
        "abstract": "Abstract In the literature there are multiple machine learning techniques that have been used successfully in clinical data analysis. However, there is little information about the parameter configurations, the required data transformations to prepare the data used to train and evaluate the models and the impact of these decisions in the accuracy of the predictive model. This research tackles these issues, using the clinical data of \\{MIMICII\\} to build features from physiological measure patterns to predict the decease of patients inside the hospital in the next 24 hours, building predictive models based on Logistic Regression, Neural Networks, Decision Trees and Nearest Neighbors. In particular, we use data associated to physiological measures of 3220 patients, where 2385 left the hospital alive and 835 passed in the hospital. The results show that the chosen strategy for building features from physiological data gives good results with Neural Networks and Logistic Regression with radial kernel models and the parameter configuration plays a fundamental role in the models performance.", 
        "author": "A. Salcedo-Bernal and M.P. Villamil-Giraldo and A.D. Moreno-Barbosa", 
        "keyword": "Machine Learning\", \"Comparison ;MIMIC\", \"Clinical Data Analysis\", \"Logistic Regression\", \"Neural keywords =etwork\", \"Decision Tree", 
        "title": "Clinical Data Analysis: An Opportunity to Compare Machine Learning Methods"
    }, 
    {
        "abstract": "Abstract In this paper we address the problem of providing an order of relevance, or ranking, among entities\u2019 properties used in \\{RDF\\} datasets, Linked Data and \\{SPARQL\\} endpoints. We first motivate the importance of ranking \\{RDF\\} properties by providing two killer applications for the problem, namely property tagging and entity visualization. Moved by the desiderata of these applications, we propose to apply Machine Learning to Rank (MLR) techniques to the problem of ranking \\{RDF\\} properties. Our devised solution is based on a deep empirical study of all the dimensions involved: feature selection, \\{MLR\\} algorithm and Model training. The major advantages of our approach are the following: (a) flexibility/personalization, as the properties\u2019 relevance can be user-specified by personalizing the training set in a supervised approach, or set by a novel automatic classification approach based on SWiPE; (b) speed, since it can be applied without computing frequencies over the whole dataset, leveraging existing fast \\{MLR\\} algorithms; (c) effectiveness, as it can be applied even when no ontology data is available by using novel dataset-independent features; (d) precision, which is high both in terms of f-measure and Spearman\u2019s rho. Experimental results show that the proposed \\{MLR\\} framework outperform the two existing approaches found in literature which are related to \\{RDF\\} property ranking.", 
        "author": "Andrea Dessi and Maurizio Atzori", 
        "keyword": "Semantic web\", \"Machine learning\", \"Fast property ranking\", \"User experience", 
        "title": "A machine-learning approach to ranking \\{RDF\\} properties"
    }, 
    {
        "abstract": "Abstract \u201cBig Data\u201d can mean different things to different people. The scale and challenges of Big Data are often described using three attributes, namely volume, velocity, and variety (3Vs), which only reflect some of the aspects of data. In this chapter, we review historical aspects of the term \u201cbig data\u201d and the associated analytics. We augment the 3Vs with additional attributes of big data to make it more comprehensive and relevant. We show that Big Data is not just the 3Vs, but actually 32Vs; that is, 9Vs covering the fundamental motivation behind Big Data, which is to incorporate business intelligence based on different hypothesis or statistical models so that Big Data analytics (BDA) can enable decision makers to make useful predictions for making some crucial decisions or researching results. History of Big Data has demonstrated that the most cost-effective way of performing \\{BDA\\} is to employ machine learning (ML) on the cloud computing (CC)-based infrastructure or simply, \\{ML\\} + \\{CC\\} \u2192 BDA. This chapter is devoted to help decision makers by defining \\{BDA\\} as a solution and opportunity to address their business needs.", 
        "author": "C. Wu and R. Buyya and K. Ramamohanarao", 
        "keyword": "Big Data analytics (BDA)\", \"Business intelligence (BI)\", \"Machine learning (ML)\", \"Cloud computing (keywords =C)\", \"Extraction, Transformation, and load (ETL)\", \"Statistics\", \"Hadoop\", \"Spark\", \"Flink\", \"MapReduce", 
        "title": "Chapter 1 - Big Data Analytics = Machine Learning + Cloud Computing"
    }, 
    {
        "abstract": "Abstract Most of the existing Artificial Intelligence (AI) models for data regression commonly assume that the data samples are completely clean without noise or worst yet, only the symmetrical noise is in considerations. However in the real world applications, this is often not the case. This paper addresses a significant note of inefficiency in methods for regression when dealing with outliers, especially for cases with polarity of noise involved (i.e., one sided noise with either only positive noise or negative noise). Using soft margin loss function concept, we propose Constrained Optimization method based Extreme Learning Machine for Regression, hereafter denoted as CO-ELM-R. The proposed method incorporates the two Lagrange multipliers that mimic Support Vector Regression (SVR) into the basis of \\{ELM\\} to cope with infeasible constraints of the regression optimization problem. Thus, CO-ELM-R will complement the recursive iterations of \\{SVR\\} in the training phase due to the fact that \\{ELM\\} is much simpler in structure and faster in implementation. The proposed CO-ELM-R is evaluated empirically on a few benchmark data sets and a real world application of \\{NOx\\} gas emission data set collected from one of the power plant in Malaysia. The obtained results have demonstrated its validity and efficacy in handling noisy data regression problems.", 
        "author": "Shen Yuong Wong and Keem Siah Yap and Hwa Jen Yap", 
        "keyword": "Extreme Learning Machine (ELM)\", \"Noisy data regression\", \"Constrained Optimization\", \"Kernel function", 
        "title": "A Constrained Optimization based Extreme Learning Machine for noisy data regression"
    }, 
    {
        "abstract": "Abstract Generating a low-rank matrix approximation is very important in large-scale machine learning applications. The standard Nystr\u00f6m method is one of the state-of-the-art techniques to generate such an approximation. It has got rapid developments since being applied to Gaussian process regression. Several enhanced Nystr\u00f6m methods such as ensemble Nystr\u00f6m, modified Nystr\u00f6m and SS-Nystr\u00f6m have been proposed. In addition, many sampling methods have been developed. In this paper, we review the Nystr\u00f6m methods for large-scale machine learning. First, we introduce various Nystr\u00f6m methods. Second, we review different sampling methods for the Nystr\u00f6m methods and summarize them from the perspectives of both theoretical analysis and practical performance. Then, we list several typical machine learning applications that utilize the Nystr\u00f6m methods. Finally, we make our conclusions after discussing some open machine learning problems related to Nystr\u00f6m methods.", 
        "author": "Shiliang Sun and Jing Zhao and Jiang Zhu", 
        "keyword": "Low-rank approximation\", \"Nystr\u00f6m method\", \"Sampling method\", \"Machine learning", 
        "title": "A review of Nystr\u00f6m methods for large-scale machine learning"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a novel and efficient system for large-scale action recognition from realistic video clips. Our approach combines several recent advances in this area. We use improved dense trajectory features in combination with Fisher vector encoding, and perform learning and classification with extreme learning machine classifiers. The resulting system is a fast and accurate alternative to more traditional action classification approaches like bag of words and support vector machines. Additionally, we use mid-level features that encode information about presence of humans in the videos, as well as color distributions. We extensively evaluate each step of our pipeline in a comparative manner, and report results on the recently published \\{THUMOS\\} 2014 benchmark, which was introduced as a challenge dataset with temporally untrimmed videos and 101 action classes. We achieve 63.37% mean average precision using the challenge protocol (i.e. sequestered test labels and limited system submissions), and got the third rank among eleven participants. The results show that it is possible to obtain a high accuracy with extreme learning machines in an efficient way, without using the extensively trained and computationally heavy deep neural networks that the top performing systems of the challenge incorporated.", 
        "author": "G\u00fcl Varol and Albert Ali Salah", 
        "keyword": "Action recognition\", \"Extreme learning machine\", \"Fisher vector\", \"Multimedia mining", 
        "title": "Efficient large-scale action recognition in videos using extreme learning machines"
    }, 
    {
        "abstract": "Abstract Machine learning and geostatistics are powerful mathematical frameworks for modeling spatial data. Both approaches, however, suffer from poor scaling of the required computational resources for large data applications. We present the Stochastic Local Interaction (SLI) model, which employs a local representation to improve computational efficiency. \\{SLI\\} combines geostatistics and machine learning with ideas from statistical physics and computational geometry. It is based on a joint probability density function defined by an energy functional which involves local interactions implemented by means of kernel functions with adaptive local kernel bandwidths. \\{SLI\\} is expressed in terms of an explicit, typically sparse, precision (inverse covariance) matrix. This representation leads to a semi-analytical expression for interpolation (prediction), which is valid in any number of dimensions and avoids the computationally costly covariance matrix inversion.", 
        "author": "Dionissios T. Hristopulos", 
        "keyword": "Machine learning\", \"Kernel regression\", \"Geostatistics\", \"Big data\", \"Sparse methods", 
        "title": "Stochastic Local Interaction (SLI) model: Bridging machine learning and geostatistics"
    }, 
    {
        "abstract": "Abstract Epilepsy is a chronic neurological condition that affects approximately 70 million people worldwide. Characterised by sudden bursts of excess electricity in the brain, manifesting as seizures, epilepsy is still not well understood when compared with other neurological disorders. Seizures often happen unexpectedly and attempting to predict them has been a research topic for the last 30 years. Electroencephalograms have been integral to these studies, as the recordings that they produce can capture the brain\u2019s electrical signals. The diagnosis of epilepsy is usually made by a neurologist, but can be difficult to make in the early stages. Supporting para-clinical evidence obtained from magnetic resonance imaging and electroencephalography may enable clinicians to make a diagnosis of epilepsy and instigate treatment earlier. However, electroencephalogram capture and interpretation is time consuming and can be expensive due to the need for trained specialists to perform the interpretation. Automated detection of correlates of seizure activity generalised across different regions of the brain and across multiple subjects may be a solution. This paper explores this idea further and presents a supervised machine learning approach that classifies seizure and non-seizure records using an open dataset containing 342 records (171 seizures and 171 non-seizures). Our approach posits a new method for generalising seizure detection across different subjects without prior knowledge about the focal point of seizures. Our results show an improvement on existing studies with 88% for sensitivity, 88% for specificity and 93% for the area under the curve, with a 12% global error, using the k-NN classifier.", 
        "author": "P. Fergus and A. Hussain and David Hignett and D. Al-Jumeily and Khaled Abdel-Aziz and Hani Hamdan", 
        "keyword": "Seizure\", \"Non-seizure\", \"Machine learning\", \"Classification\", \"Electroencephalogram\", \"Oversampling", 
        "title": "A machine learning system for automated whole-brain seizure detection"
    }, 
    {
        "abstract": "Abstract It is well known that in supervised learning, active learning could effectively decrease the complexity of training instances without obvious loss of the classification performance. Generally, active learning is applied in the scenario that lots of instances are easy to be acquired, but labeling them is expensive and/or time-consuming. In this study, we try to implement active learning by using extreme learning machine (ELM) classifier based on three reasons as follows: (1) \\{ELM\\} has light computational costs, (2) \\{ELM\\} has strong generalization ability which is even comparable with support vector machine (SVM) and (3) \\{ELM\\} could be directly applied on both binary-class and multiclass problems. Specifically, an active learning algorithm based on \\{ELM\\} classifier named AL-ELM is proposed in this paper. During active learning, AL-ELM estimates the uncertainty of each unlabeled instance by creating a mapping relation between the actual outputs of the instance in \\{ELM\\} and the approximated membership probability of the same instance. In other words, \\{ELM\\} is converted as the equivalent Bayes classifier. On each iteration, those most uncertain instances are extracted and labeled to promote the quality of classification model. The learning procedure stops until it satisfies a pre-designed criterion. Experimental results on 20 benchmark data sets show that AL-ELM is better than or at least comparable to several state-of-the-art uncertainty-based active learning algorithms. Also, in contrast with several other algorithms, AL-ELM could effectively decrease the running time of learning procedure.", 
        "author": "Hualong Yu and Changyin Sun and Wankou Yang and Xibei Yang and Xin Zuo", 
        "keyword": "Active learning\", \"Extreme learning machine\", \"Uncertainty measure\", \"Uncertainty sampling\", \"Pool-based active learning", 
        "title": "AL-ELM: One uncertainty-based active learning algorithm using extreme learning machine"
    }, 
    {
        "abstract": "Abstract The main target of oil and gas exploration companies is to identify reservoirs and their location with high accuracy. For this purpose, all efforts are applied to reduce uncertainties and risks of water contamination or drilling of dry wells in order to extract as much as possible from the subsurface in the shortest time and at the lowest cost. This chapter shows an alternative for the combination of machine learning techniques, evolutionary computation, and geological interpretations to decrease uncertainties in identifying the location of favorable reservoirs. For this purpose, seismic and well log data from a sand Brazilian field were analyzed. The identification of sandy facies as conducers was made by means of self-organizing maps and extrapolated into signals of seismic data by probabilistic neural networks, converting the image of original amplitude into rock properties. The genetic algorithm was also tested to evaluate different seismic attributes among a group of 37 possibilities to perform the facies prediction task. The image description by multiattributes allowed the definition of the facies distribution modeling. The same process was applied to predict the probability of porosity distribution in seismic data by multilayer perceptron and generalized regression, once again using the genetic algorithm. Through these properties, models from two favorable areas of reservoir were identified in the southwest part of the field. Core description corroborates with the results found by the suggested methodology, indicating its satisfactory application.", 
        "author": "M.C. Kuroda and A.C. Vidal and J.P. Papa", 
        "keyword": "machine learning\", \"evolutionary computation\", \"bio-inspired computation\", \"rock properties keywords =rediction\", \"seismic image processing", 
        "title": "Chapter 13 - Oil reservoir quality assisted by machine learning and evolutionary computation"
    }, 
    {
        "abstract": "Abstract The study at hand is devoted to schedule jobs on uniform parallel processors which are capable of adapting as well as learning. The problem is formulated into a bi-objective mixed integer mathematical model in which several parameters are supposed to follow triangular possibility distributions. Converting the aforementioned model, an auxiliary equivalent mixed integer crisp one is constructed through an interactive possiblistic programming approach. Due to the NP-hardness of the problem, swarm intelligence is hired by applying a highly modified Particle Swarm Optimization (PSO) method. In the proposed evolutionary method, called L\u00e9vy Flight Embedded Particle Swarm Optimization (LFEPSO), uniformly distributed walks are replaced by L\u00e9vy flights. In order to check the validity of the model and the performance of the proposed LFEPSO, twenty-six data sets are generated on a random basis. As the numerical results indicate, embedding L\u00e9vy flights made a tremendous improvement towards solving the local optima problem of the traditional PSO. Compared to the exact solution method, \\{LFEPSO\\} has shown an outstanding performance in scheduling 8\u2013500 jobs on 3\u201350 parallel processors. In addition, numerical results reveal the significant role of considering the adapting ability in accurately modeling real-world and huge-sized problems.", 
        "author": "S.H. Pakzad-Moghaddam", 
        "keyword": "Parallel-machine scheduling\", \"Learning effect\", \"Adapting ability\", \"Possibilistic programming\", keywords =Particle swarm optimization\", \"L\u00e9vy flight", 
        "title": "A L\u00e9vy flight embedded particle swarm optimization for multi-objective parallel-machine scheduling with learning and adapting considerations"
    }, 
    {
        "abstract": "Abstract Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling.", 
        "author": "Fadi Dornaika and Abdelmalik Moujahid and Youssef El Merabet and Yassine Ruichek", 
        "keyword": "Automatic building detection and delineation\", \"Orthophotos\", \"Image segmentation\", \"Image keywords =escriptors\", \"Supervised learning\", \"Classifier", 
        "title": "Building detection from orthophotos using a machine learning approach: An empirical study on image segmentation and descriptors"
    }, 
    {
        "abstract": "Abstract In the cardiovascular system, blood flow rates, blood velocities and blood pressures can be modeled using the Navier\u2013Stokes equations. Inputs to the system are typically uncertain, such as (a) the geometry of the arterial tree, (b) clinically measured blood pressure and viscosity, (c) boundary resistances, among others. Due to a large number of such parameters, efficient quantification of uncertainty in solution fields in this multi-parameter space is challenging. We use an adaptive stochastic collocation method to quantify the impact of uncertainty in geometry in patient-specific models. We develop a novel subdivision method to define the stochastic space of geometries. To accelerate convergence and make the problem tractable, we use a machine learning approach to approximate the simulation-based solution. Towards this, a reduced order model of the Navier\u2013Stokes equations is developed using a segmental resistance analog boundary conditions (ratio of pressure to flow). Using an offline database of pre-computed solutions, we compute a map (rule) from the features to solution fields. We achieve significant speed-up (of a few orders of magnitude) by approximating the simulation-based solution using a machine learning predictor. A bootstrap aggregated decision tree was found to be the best predictor among many candidate regressors (correlation coefficient of training set was 0.94). We demonstrate stochastic space convergence using the adaptive stochastic collocation method, and also show robustness to the choice of geometry parameterization. The sensitivities to geometry obtained using machine learning had a correlation coefficient of 0.92 with the values obtained using finite element simulations. Segments with significant disease in the larger arteries had the highest sensitivities. Terminal segments are more sensitive to dilation and proximal healthy segments are more sensitive to erosion. Sensitivity to geometry is highest when geometric resistance is comparable to net downstream resistance.", 
        "author": "Sethuraman Sankaran and Leo Grady and Charles A. Taylor", 
        "keyword": "Sensitivity analysis\", \"Hemodynamics\", \"Machine learning\", \"Stochastic collocation\", \"Geometric uncertainty", 
        "title": "Impact of geometric uncertainty on hemodynamic simulations using machine learning"
    }, 
    {
        "abstract": "Abstract This paper introduces a framework of granular neural networks named rough rule granular extreme learning machine (RRGELM), and develops its comprehensive design process. The proposed granular neural networks are formed on the basis of rough decision rules extracted from training samples through rough set theory. Firstly, Sample data are reduced by the algorithms of attributes reduction and attributes values reduction in rough set theory, and then they are compressed to an irredundant data set. In this data set, each sample can represent a rough rule, and is expressed as an If-Then rule which indicates the relationship between the input and output pattern. Moreover, the confidence level and the coverage level of each rule are calculated. Secondly, granular-neurons can be constructed through the If-Then rules, and all the granular-neurons constitute rule matching layer which is regarded as the hidden layer of the RRGELM. The linked weights between the input neurons and granular-neurons can be determined by the confidences of rough decision rules, while the linked weights between the output neurons and granular-neurons can be initialized as the contributions of the rough rules to the classification. Finally, the extreme learning machine (ELM) algorithm is introduced to improve the learning speed of the RRGELM, rather than the \\{BP\\} algorithm used by other traditional \\{GNN\\} models. Good performance of the proposed \\{RRGELM\\} is demonstrated on several well-known benchmark data sets.", 
        "author": "Xinzheng Xu and Guanying Wang and Shifei Ding and Xiangying Jiang and Zuopeng Zhao", 
        "keyword": "Granular neural networks\", \"Single-hidden layer feedforward neural networks\", \"Rough set\", \"Rule keywords =xtraction\", \"Rough rule granular extreme learning machine", 
        "title": "A new method for constructing granular neural networks based on rule extraction and extreme learning machine"
    }, 
    {
        "abstract": "Abstract The popularity and reach of short text messages commonly used in electronic communication have led spammers to use them to propagate undesired content. This is often composed by misleading information, advertisements, viruses, and malwares that can be harmful and annoying to users. The dynamic nature of spam messages demands for knowledge-based systems with online learning and, therefore, the most traditional text categorization techniques can not be used. In this study, we introduce the MDLText, a text classifier based on the minimum description length principle, to the context of filtering undesired short text messages. The proposed approach supports incremental learning and, therefore, its predictive model is scalable and can adapt to continuously evolving spamming techniques. It is also fast, with computational cost increasing linearly with the number of samples and features, which is very desirable for expert systems applied to real-time electronic communication. In addition to the dynamic nature of these messages, they are also short and usually poorly written, rife with slangs, symbols, and abbreviations that difficult text representation, learning, and filtering. In this scenario, we also investigated the benefits of using text normalization and semantic indexing techniques. We showed these techniques can improve the text content quality and, consequently, enhance the performance of the expert systems for spamming detection. Based on these findings, we propose a new hybrid ensemble approach that combines the predictions obtained by the classifiers using the original text samples along with their variations created by applying text normalization and semantic indexing techniques. It has the advantages of being independent of the classification method and the results indicated it is efficient to filter undesired short text messages.", 
        "author": "Renato M. Silva and Tulio C. Alberto and Tiago A. Almeida and Akebo Yamakami", 
        "keyword": "Minimum description length\", \"Short text messages\", \"Semantic indexing\", \"Text categorization\", \"Machine learning", 
        "title": "Towards filtering undesired short text messages using an online learning approach with semantic indexing"
    }, 
    {
        "abstract": "Abstract The majority of the human genome consists of non-coding regions that have been called junk DNA. However, recent studies have unveiled that these regions contain cis-regulatory elements, such as promoters, enhancers, silencers, insulators, etc. These regulatory elements can play crucial roles in controlling gene expressions in specific cell types, conditions, and developmental stages. Disruption to these regions could contribute to phenotype changes. Precisely identifying regulatory elements is key to deciphering the mechanisms underlying transcriptional regulation. Cis-regulatory events are complex processes that involve chromatin accessibility, transcription factor binding, \\{DNA\\} methylation, histone modifications, and the interactions between them. The development of next-generation sequencing techniques has allowed us to capture these genomic features in depth. Applied analysis of genome sequences for clinical genetics has increased the urgency for detecting these regions. However, the complexity of cis-regulatory events and the deluge of sequencing data require accurate and efficient computational approaches, in particular, machine learning techniques. In this review, we describe machine learning approaches for predicting transcription factor binding sites, enhancers, and promoters, primarily driven by next-generation sequencing data. Data sources are provided in order to facilitate testing of novel methods. The purpose of this review is to attract computational experts and data scientists to advance this field.", 
        "author": "Yifeng Li and Chih-yu Chen and Alice M. Kaye and Wyeth W. Wasserman", 
        "keyword": "Cis-regulatory elements\", \"Gene regulation\", \"Enhancers\", \"Promoters\", \"Machine learning\", \"Deep keywords =earning\", \"Ensemble learning\", \"Data integration", 
        "title": "The identification of cis-regulatory elements: A review from a machine learning perspective"
    }, 
    {
        "abstract": "AbstractBackground Rapid eye movements (REMs) are a defining feature of \\{REM\\} sleep. The number of discrete \\{REMs\\} over time, or \\{REM\\} density, has been investigated as a marker of clinical psychopathology and memory consolidation. However, human detection of \\{REMs\\} is a time-consuming and subjective process. Therefore, reliable, automated \\{REM\\} detection software is a valuable research tool. New method We developed an automatic \\{REM\\} detection algorithm combining a novel set of extracted features and the \u2018AdaBoost\u2019 classification algorithm to detect the presence of \\{REMs\\} in Electrooculogram data collected from the right and left outer canthi (ROC/LOC). Algorithm performance measures of Recall (percentage of \\{REMs\\} detected) and Precision (percentage of \\{REMs\\} detected that are true REMs) were calculated and compared to the gold standard of human detection by three expert sleep scorers. \\{REM\\} detection by four non-experts were also investigated and compared to expert raters and the algorithm. Results The algorithm performance (78.1% Recall, 82.6% Precision) surpassed that of the average (expert &amp; non-expert) single human detection performance (76% Recall, 83% Precision). Agreement between non-experts (Cronbach Alpha = 0.65) is markedly lower than experts (Cronbach Alpha = 0.80). Comparison with existing method(s) By following reported methods, we implemented all previously published \\{LOC\\} and \\{ROC\\} based detection algorithms on our dataset. Our algorithm performance exceeded all others. Conclusions The automatic detection algorithm presented is a viable and efficient method of \\{REM\\} detection as it reliably matches the performance of human scorers and outperforms all other known LOC- and ROC-based detection algorithms.", 
        "author": "Benjamin D. Yetton and Mohammad Niknazar and Katherine A. Duggan and Elizabeth A. McDevitt and Lauren N. Whitehurst and Negin Sattari and Sara C. Mednick", 
        "keyword": "\\{REM\\} detection\", \"REM density\", \"Polysomnography\", \"EEG\", \"Adaptive boosting\", \"LOC\", \"ROC\", keywords =Machine learning\", \"Sleep scoring", 
        "title": "Automatic detection of rapid eye movements (REMs): A machine learning approach"
    }, 
    {
        "abstract": "Abstract In this paper, the capabilities of functional data feature extraction technique are combined with the advantages of kernel extreme learning machine (KELM), to develop an effective hyperspectral image (HSI) classification method. In the proposed method, the hyperspectral pixels are firstly represented by functions. Each pixel in the \\{HSI\\} is processed from the perspective of function rather than high-dimensional vector. These functional representations are transformed to a lower dimensionality feature space using functional principal components analysis (FPCA). And then the obtained lower dimensional representations are processed by a multiclass \\{KELM\\} classifier. Experimental results on two \\{HSI\\} datasets show that the proposed method provides a relatively promising performance compared with other methods.", 
        "author": "Yantao Wei and Guangrun Xiao and He Deng and Hong Chen and Mingwen Tong and Gang Zhao and Qingtang Liu", 
        "keyword": "Hyperspectral image classification\", \"Extreme learning machine\", \"Functional principle component analysis", 
        "title": "Hyperspectral image classification using FPCA-based kernel extreme learning machine"
    }, 
    {
        "abstract": "Abstract Light Detection and Ranging (LiDAR) is a remote sensor able to extract three-dimensional information. Environmental models in forest areas have been benefited by the use of LiDAR-derived information in the last years. A multiple linear regression (MLR) with previous stepwise feature selection is the most common method in the literature to develop those models. \\{MLR\\} defines the relation between the set of field measurements and the statistics extracted from a LiDAR flight. Machine learning has emerged as a suitable tool to improve classic stepwise \\{MLR\\} results on LiDAR. Unfortunately, few studies have been proposed to compare the quality of the multiple machine learning approaches. This paper presents a comparison between the classic MLR-based methodology and regression techniques in machine learning (neural networks, support vector machines, nearest neighbour, ensembles such as random forests) with special emphasis on regression trees. The selected techniques are applied to real LiDAR data from two areas in the province of Lugo (Galizia, Spain). The results confirm that classic \\{MLR\\} is outperformed by machine learning techniques and concretely, our experiments suggest that Support Vector Regression with Gaussian kernels statistically outperforms the rest of the techniques.", 
        "author": "J. Garc\u00eda-Guti\u00e9rrez and F. Mart\u00ednez-\u00c1lvarez and A. Troncoso and J.C. Riquelme", 
        "keyword": "LiDAR\", \"Machine learning\", \"Regression\", \"Remote sensing", 
        "title": "A comparison of machine learning regression techniques for LiDAR-derived estimation of forest variables"
    }, 
    {
        "abstract": "Abstract This paper introduces an approach that combines machine learning and adaptive hardware to improve the efficiency of ultra-low-power sensor interfaces. Adaptive feature extraction circuits are assisted by hardware embedded training to dynamically activate only the most relevant features. This selection is done in a context- and power cost-aware manner, through modification of the C4.5 algorithm. As proof-of-principle, a Voice Activity Detector illustrates the context-dependent relevance of features, demonstrating average circuit power savings of 70%, without accuracy loss. The \\{RECAS\\} database developed for experimenting with this context- and dynamic resource-cost-aware training is presented and made open-source for the research community.", 
        "author": "Steven Lauwereins and Komail Badami and Wannes Meert and Marian Verhelst", 
        "keyword": "Resource cost-aware classifier\", \"Context-aware machine learning\", \"Low-power sensor interface\", keywords =Adaptive circuits\", \"Power restricted classifier", 
        "title": "Optimal resource usage in ultra-low-power sensor interfaces through context- and resource-cost-aware machine learning"
    }, 
    {
        "abstract": "Abstract Physiological signals such as electroencephalogram (EEG) and electrooculography (EOG) recordings are very important non-invasive measures of detecting a person\u2019s alertness/drowsiness. Since \\{EEG\\} signals are non-stationary and present evident dynamic characteristics, conventional linear approaches are not highly successful in recognition of drowsy level. Furthermore, previous methods cannot produce satisfying results without considering the basic rhythms underlying the raw signals. To address these drawbacks, we propose a system for drowsiness detection using physiological signals that present four advantages: (1) decomposing \\{EEG\\} signals into wavelet sub-bands to extract more evident information beyond raw signals, (2) extraction and fusion of nonlinear features from \\{EEG\\} sub-bands, (3) fusion the information from \\{EEGs\\} and eyelid movements, (4) employing efficient extremely learning machine for status classification. The experimental results show that the proposed method achieves not only a high detection accuracy but also a very fast computation speed. The proposed algorithm can be further developed into the monitoring and warning systems to prevent the accumulation of mental fatigue and declines of work efficiency in many environments such as vehicular driving, aviation, navigation and medical service.", 
        "author": "Lan-lan Chen and Yu Zhao and Jian Zhang and Jun-zhong Zou", 
        "keyword": "Drowsiness detection\", \"Electroencephalogram (EEG)\", \"Eyelid movements\", \"Wavelet decomposition\", keywords =Nonlinear features\", \"Extreme learning machine (ELM)", 
        "title": "Automatic detection of alertness/drowsiness from physiological signals using wavelet-based nonlinear features and machine learning"
    }, 
    {
        "abstract": "Abstract This paper incorporates the regularization strategy of kernel based extreme learning machines (ELM) to improve the performance of a neuro-fuzzy learning machine. The proposed learning machine, regularized extreme learning adaptive neuro-fuzzy inference system (R-ELANFIS), has the advantages of reduced randomness, reduced computational complexity and better generalization. The parameters of the fuzzy layer of R-ELANFIS are randomly selected by incorporating the explicit knowledge representation using fuzzy membership functions. The parameters of the linear neural layer are determined by solving a constrained optimization problem in a regularized framework. Simulations on regression problems show that R-ELANFIS achieves similar or better generalization performance compared to well known kernel based regression methods and \\{ELM\\} based neuro-fuzzy systems. The proposed method can also be applied to multi-class classification problems.", 
        "author": "Shihabudheen KV and G.N. Pillai", 
        "keyword": "Neuro-fuzzy systems\", \"Extreme learning machines\", \"Kernel based learning\", \"Regularization\", keywords =Regression\", \"Multi-class classification", 
        "title": "Regularized extreme learning adaptive neuro-fuzzy algorithm for regression and classification"
    }, 
    {
        "abstract": "Abstract Falls are the primary cause of accidental injuries (52%) and one of the leading causes of death in individuals aged 65 and above. More than 50% of falls in healthy older adults are due to tripping while walking. Minimum toe clearance (i.e., minimum height of the toe above the ground during the mid-swing phase - MTC) has been investigated as an indicator of tripping risk. There is increasing demand for practicable gait monitoring using wearable sensors such as Inertial Measurement Units (IMU) comprising accelerometers and gyroscopes due to their wearability, compactness and low cost. A major limitation however, is intrinsic noise making acceleration integration unreliable and inaccurate for estimating \\{MTC\\} height from \\{IMU\\} data. A machine learning approach to \\{MTC\\} height estimation was investigated in this paper incorporating features from both raw and integrated inertial signals to train Generalized Regression Neural Networks (GRNN) models using a hill-climbing feature-selection method. The \\{GRNN\\} based \\{MTC\\} height predictions demonstrated root-mean-square-error (RMSE) of 6.6 mm with 9 optimum features for young adults and 7.1 mm \\{RMSE\\} with 5 features for the older adults during treadmill walking. The \\{GRNN\\} based \\{MTC\\} height estimation method devised in this project represents approximately 68% less \\{RMSE\\} than other estimation techniques. The research findings show a strong potential for gait monitoring outside the laboratory to provide real-time \\{MTC\\} height information during everyday locomotion.", 
        "author": "Braveena K. Santhiranayagam and Daniel T.H. Lai and W.A. Sparrow and Rezaul K. Begg", 
        "keyword": "Inertial Measurement Unit (IMU)\", \"Minimum Toe Clearance (MTC)\", \"Generalized Regression Neural keywords =etwork (GRNN)\", \"Gait\", \"Machine learning", 
        "title": "A machine learning approach to estimate Minimum Toe Clearance using Inertial Measurement Units"
    }, 
    {
        "abstract": "Abstract With the increasing importance of wind power as a component of power systems, the problems induced by the stochastic and intermittent nature of wind speed have compelled system operators and researchers to search for more reliable techniques to forecast wind speed. This paper proposes a combination model for probabilistic short-term wind speed forecasting. In this proposed hybrid approach, \\{EWT\\} (Empirical Wavelet Transform) is employed to extract meaningful information from a wind speed series by designing an appropriate wavelet filter bank. The \\{GPR\\} (Gaussian Process Regression) model is utilized to combine independent forecasts generated by various forecasting engines (ARIMA (Autoregressive Integrated Moving Average), \\{ELM\\} (Extreme Learning Machine), \\{SVM\\} (Support Vector Machine) and \\{LSSVM\\} (Least Square SVM)) in a nonlinear way rather than the commonly used linear way. The proposed approach provides more probabilistic information for wind speed predictions besides improving the forecasting accuracy for single-value predictions. The effectiveness of the proposed approach is demonstrated with wind speed data from two wind farms in China. The results indicate that the individual forecasting engines do not consistently forecast short-term wind speed for the two sites, and the proposed combination method can generate a more reliable and accurate forecast.", 
        "author": "Jianzhou Wang and Jianming Hu", 
        "keyword": "Gaussian Process Regression\", \"Wind speed forecasting\", \"Empirical Wavelet Transform\", \"Extreme keywords =earning Machine\", \"Support Vector Machine", 
        "title": "A robust combination approach for short-term wind speed forecasting and analysis \u2013 Combination of the \\{ARIMA\\} (Autoregressive Integrated Moving Average), \\{ELM\\} (Extreme Learning Machine), \\{SVM\\} (Support Vector Machine) and \\{LSSVM\\} (Least Square SVM) forecasts using a \\{GPR\\} (Gaussian Process Regression) model"
    }, 
    {
        "abstract": "Abstract Machine learning algorithms (MLAs) such us artificial neural networks (ANNs), regression trees (RTs), random forest (RF) and support vector machines (SVMs) are powerful data driven methods that are relatively less widely used in the mapping of mineral prospectivity, and thus have not been comparatively evaluated together thoroughly in this field. The performances of a series of MLAs, namely, artificial neural networks (ANNs), regression trees (RTs), random forest (RF) and support vector machines (SVMs) in mineral prospectivity modelling are compared based on the following criteria: i) the accuracy in the delineation of prospective areas; ii) the sensitivity to the estimation of hyper-parameters; iii) the sensitivity to the size of training data; and iv) the interpretability of model parameters. The results of applying the above algorithms to epithermal Au prospectivity mapping of the Rodalquilar district, Spain, indicate that the \\{RF\\} outperformed the other \\{MLA\\} algorithms (ANNs, \\{RTs\\} and SVMs). The \\{RF\\} algorithm showed higher stability and robustness with varying training parameters and better success rates and \\{ROC\\} analysis results. On the other hand, all \\{MLA\\} algorithms can be used when ore deposit evidences are scarce. Moreover the model parameters of \\{RF\\} and \\{RT\\} can be interpreted to gain insights into the geological controls of mineralization.", 
        "author": "V. Rodriguez-Galiano and M. Sanchez-Castillo and M. Chica-Olmo and M. Chica-Rivas", 
        "keyword": "Mineral prospectivity mapping\", \"Mineral potential\", \"Data-driven modelling\", \"Machine learning\", \"Hyperion", 
        "title": "Machine learning predictive models for mineral prospectivity: An evaluation of neural networks, random forest, regression trees and support vector machines"
    }, 
    {
        "abstract": "Abstract In this paper we introduce a framework for learning from \\{RDF\\} data using graph kernels that count substructures in \\{RDF\\} graphs, which systematically covers most of the existing kernels previously defined and provides a number of new variants. Our definitions include fast kernel variants that are computed directly on the \\{RDF\\} graph. To improve the performance of these kernels we detail two strategies. The first strategy involves ignoring the vertex labels that have a low frequency among the instances. Our second strategy is to remove hubs to simplify the \\{RDF\\} graphs. We test our kernels in a number of classification experiments with real-world \\{RDF\\} datasets. Overall the kernels that count subtrees show the best performance. However, they are closely followed by simple bag of labels baseline kernels. The direct kernels substantially decrease computation time, while keeping performance the same. For the walks counting kernel this decrease in computation time is so large that it thereby becomes a computationally viable kernel to use. Ignoring low frequency labels improves the performance for all datasets. The hub removal algorithm increases performance on two out of three of our smaller datasets, but has little impact when used on our larger datasets.", 
        "author": "Gerben Klaas Dirk de Vries and Steven de Rooij", 
        "keyword": "Graph kernels\", \"Machine learning for RDF\", \"Weisfeiler\u2013Lehman\", \"Hub removal", 
        "title": "Substructure counting graph kernels for machine learning from \\{RDF\\} data"
    }, 
    {
        "abstract": "Abstract In this work, a novel supervised learning method, the Minimal Learning Machine (MLM), is proposed. Learning in \\{MLM\\} consists in building a linear mapping between input and output distance matrices. In the generalization phase, the learned distance map is used to provide an estimate of the distance from K output reference points to the unknown target output value. Then, the output estimation is formulated as multilateration problem based on the predicted output distance and the locations of the reference points. Given its general formulation, the Minimal Learning Machine is inherently capable of operating on nonlinear regression problems as well as on multidimensional response spaces. In addition, an intuitive extension of the \\{MLM\\} is proposed to deal with classification problems. A comprehensive set of computer experiments illustrates that the proposed method achieves accuracies that are comparable to more traditional machine learning methods for regression and classification thus offering a computationally valid alternative to such approaches.", 
        "author": "Amauri Holanda de Souza J\u00fanior and Francesco Corona and Guilherme A. Barreto and Yoan Miche and Amaury Lendasse", 
        "keyword": "Learning machines\", \"Supervised learning\", \"Regression\", \"Pattern classification", 
        "title": "Minimal Learning Machine: A novel supervised distance-based approach for regression and classification"
    }, 
    {
        "abstract": "Abstract Pharmacovigilance (PV) is defined by the World Health Organization as the science and activities related to the detection, assessment, understanding and prevention of adverse effects or any other drug-related problem. An essential aspect in \\{PV\\} is to acquire knowledge about Drug\u2013Drug Interactions (DDIs). The shared tasks on DDI-Extraction organized in 2011 and 2013 have pointed out the importance of this issue and provided benchmarks for: Drug Name Recognition, \\{DDI\\} extraction and \\{DDI\\} classification. In this paper, we present our text mining systems for these tasks and evaluate their results on the DDI-Extraction benchmarks. Our systems rely on machine learning techniques using both feature-based and kernel-based methods. The obtained results for drug name recognition are encouraging. For DDI-Extraction, our hybrid system combining a feature-based method and a kernel-based method was ranked second in the DDI-Extraction-2011 challenge, and our two-step system for \\{DDI\\} detection and classification was ranked first in the DDI-Extraction-2013 task at SemEval. We discuss our methods and results and give pointers to future work.", 
        "author": "Asma Ben Abacha and Md. Faisal Mahbub Chowdhury and Aikaterini Karanasiou and Yassine Mrabet and Alberto Lavelli and Pierre Zweigenbaum", 
        "keyword": "Text mining\", \"Machine learning\", \"Drug name recognition\", \"Drug\u2013drug interactions\", \"Pharmacovigilance", 
        "title": "Text mining for pharmacovigilance: Using machine learning for drug name recognition and drug\u2013drug interaction extraction and classification"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has gained increasing attention for its computation feasibility on various applications. However, the previous generalization analysis of \\{ELM\\} relies on the independent and identically distributed (i.i.d) samples. In this paper, we go far beyond this restriction by investigating the generalization bound of the \\{ELM\\} classification associated with the uniform ergodic Markov chains (u.e.M.c) samples. The upper bound of the misclassification error is estimated for the \\{ELM\\} classification showing that the satisfactory learning rate can be achieved even for the dependent samples. Empirical evaluations on real-word datasets are provided to compare the predictive performance of \\{ELM\\} with independent and Markov sampling.", 
        "author": "Peipei Yuan and Hong Chen and Yicong Zhou and Xiaoyan Deng and Bin Zou", 
        "keyword": "Generalization ability\", \"Extreme learning machine\", \"Uniformly ergodic Markov chain", 
        "title": "Generalization ability of extreme learning machine with uniformly ergodic Markov chains"
    }, 
    {
        "abstract": "Abstract Currently, the exponential growth of biomedical data along with the complexities of managing high dimensionality, imbalanced distribution, sparse attributes instigates a difficult challenge of effectively applying functional networks as a new large-scale predictive modeling in healthcare and biomedicine. This article proposes functional networks based on propensity score and Newton Raphson-maximum-likelihood optimizations as a new large-scale machine learning classifier to enhance its performance in addressing these challenges within big biomedical data. Different use-cases scenarios based on integrated phenotypic and genomics big biomedical data were proposed: real-life biomedical data, (i) optimal design of cancer chemotherapy; (ii) identify inpatient-admission of individuals with primary diagnosis of cancer; (iii) identify severe asthma exacerbation children using integrated phenotypic and \\{SNP\\} repository data; and (iv) mixture models simulation studies. Comparative studies were carried to compare the performance of the new paradigm versus the common state-of-the-art of machine learning, data mining, and statistics schemes. The results of performance of the new classifier with the most common classifiers on the four benchmark databases have been recorded in tables and graphs. The obtained results of the new classifier outperform most of existing state-of-the art statistical machine learning schemes with reliable and efficient performance. The new predictive modeling classifier is saving the computational time and having reliable performances along with future avenue for extension to deal with next generation sequencing data on high performance computing platforms.", 
        "author": "Emad Elsebakhi and Frank Lee and Eric Schendel and Anwar Haque and Nagarajan Kathireason and Tushar Pathare and Najeeb Syed and Rashid Al-Ali", 
        "keyword": "Machine learning\", \"Large scale high performance computing\", \"Biomedical data and healthcare\", keywords =Functional networks\", \"Propensity score\", \"Big data\", \"MapReduce\", \"Google Sibyl\", \"Spark", 
        "title": "Large-scale machine learning based on functional networks for biomedical big data with high performance computing platforms"
    }, 
    {
        "abstract": "Abstract Microarray-based gene expression profiling has emerged as an efficient technique for classification, diagnosis, prognosis, and treatment of cancer. The major drawback in microarray data is the \u201ccurse of dimensionality problem,\u201d which hinders the useful information of a data set and leads to computational instability. Therefore, selecting relevant genes is a challenging task in microarray data analysis. Most of the existing schemes employ a two-stage process: feature selection (FS) followed by classification. Various methods such as t-test, F-test, Wilcoxon test, signal-to-noise ratio, \u03c72-test, information gain (IG), Gini index, and Fisher score are used for selecting the significant features. Moreover, different classifiers like logistic regression, naive Bayes, K-nearest neighbor, artificial neural network, radial basis function network, probabilistic neural network, and support vector machine have already been executed for classifying the data set. In this chapter, a permutation of several \\{FS\\} methods and classifiers has been implemented independently, and the finest pair is chosen based on experimental analysis using certain performance parameters for the designed classifiers. The obtained results are compared with existing schemes. The main objective of this study is to survey the already applied intelligent techniques and point out their limitations and advantages.", 
        "author": "M. Kumar and S.K. Rath", 
        "keyword": "Microarray\", \"Feature selection\", \"Classification\", \"Cross validation\", \"Machine learning", 
        "title": "Chapter 15 - Feature Selection and Classification of Microarray Data Using Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract In this paper, a computationally competitive incremental algorithm based on \\{QR\\} factorization is proposed, to automatically determine the number of hidden nodes in generalized single-hidden-layer feedforward networks (SLFNs). This approach, \\{QR\\} factorization based Incremental Extreme Learning Machine (QRI-ELM), is able to add random hidden nodes to \\{SLFNs\\} one by one. The computational complexity of this approach is analyzed in this paper as well. Simulation results show and verify that our new approach is fast and effective with good generalization and accuracy performance.", 
        "author": "Yibin Ye and Yang Qin", 
        "keyword": "Extreme Learning Machine(ELM)\", \"Incremental learning\", \"QR factorization", 
        "title": "\\{QR\\} factorization based Incremental Extreme Learning Machine with growth of hidden nodes"
    }, 
    {
        "abstract": "Abstract The ideal trip characteristics of the distance relay is greatly affected by pre-fault system conditions, ground fault resistance, shunt capacitance and mutual coupling of transmission network. This paper presents an extreme learning machine (ELM) based fast and accurate adaptive relaying scheme for stand-alone distance protection of transmission network. The proposed \\{ELM\\} based fast adaptive distance relaying scheme (FADRS) is extensively validated on the two terminal transmission lines with complex mutual coupling and shunt capacitance and, the performance is compared with the conventional artificial neural networks (ANNs) based adaptive distance relaying scheme (ADRS). The simulation results show significant improvement in the performance indices such as relay speed and selectivity. Further, the performance of proposed \\{FADRS\\} is tested for stressed condition such as power swing and found to be effective and reliable.", 
        "author": "Rahul Dubey and S.R. Samantaray and B.K. Panigrahi", 
        "keyword": "Adaptive distance relaying scheme (ADRS)\", \"Fast adaptive distance relaying scheme (FADRS)\", \"Power keywords =wing\", \"Artificial neural networks (ANNs)\", \"Extreme learning machine (ELM)", 
        "title": "An extreme learning machine based fast and accurate adaptive distance relaying scheme"
    }, 
    {
        "abstract": "Abstract This paper presents an analysis of the recently proposed sparse extreme learning machine (S-ELM) classifier and describes an optimization scheme that can be used to calculate the network output weights. This optimization scheme exploits intrinsic graph structures in order to describe geometric data relationships in the so-called \\{ELM\\} space. Kernel formulations of the approach operating in \\{ELM\\} spaces of arbitrary dimensions are also provided. It is shown that the application of the optimization scheme exploiting geometric data relationships in the original \\{ELM\\} space is equivalent to the application of the original S-ELM to a transformed \\{ELM\\} space. The experimental results show that the incorporation of geometric data relationships in S-ELM can lead to enhanced performance.", 
        "author": "Alexandros Iosifidis and Anastasios Tefas and Ioannis Pitas", 
        "keyword": "Sparse extreme learning machine\", \"Intrinsic graphs\", \"Single-hidden layer neural networks", 
        "title": "Sparse extreme learning machine classifier exploiting intrinsic graphs"
    }, 
    {
        "abstract": "Abstract We present a computational learning method for bio-molecular classification. This method shows how to design biochemical operations both for learning and pattern classification. As opposed to prior work, our molecular algorithm learns generic classes considering the realization in vitro via a sequence of molecular biological operations on sets of \\{DNA\\} examples. Specifically, hybridization between \\{DNA\\} molecules is interpreted as computing the inner product between embedded vectors in a corresponding vector space, and our algorithm performs learning of a binary classifier in this vector space. We analyze the thermodynamic behavior of these learning algorithms, and show simulations on artificial and real datasets as well as demonstrate preliminary wet experimental results using gel electrophoresis.", 
        "author": "Yung-Kyun Noh and Daniel D. Lee and Kyung-Ae Yang and Cheongtag Kim and Byoung-Tak Zhang", 
        "keyword": "\\{DNA\\} computing\", \"Machine learning\", \"Learning in vitro\", \"Kernel methods\", \"Molecular algorithms", 
        "title": "Molecular learning with \\{DNA\\} kernel machines"
    }, 
    {
        "abstract": "Abstract In this paper, the extreme learning machine (ELM) is employed to predict horizontal global solar radiation (HGSR). For this purpose, the capability of developed \\{ELM\\} method is appraised statistically for prediction of monthly mean daily \\{HGSR\\} using three different types of input parameters: (1) sunshine duration-based (SDB), (2) difference temperature-based (TB) and (3) multiple parameters-based (MPB). The long-term measured data sets collected for city of Shiraz situated in the Fars province of Iran have been utilized as a case study. The predicted \\{HGSR\\} via \\{ELM\\} is compared with those of support vector machine (SVM), genetic programming (GP) and artificial neural network (ANN) to ensure the precision of ELM. It is found that higher accuracy can be obtained by multiple parameters-based estimation of \\{HGSR\\} using all techniques. The computational results prove that \\{ELM\\} is highly accurate and reliable and shows higher performance than SVM, \\{GP\\} and ANN. For multiple parameters-based \\{ELM\\} model, the mean absolute percentage error, mean absolute bias error, root mean square error, relative root mean square error and coefficient of determination are obtained as 2.2518%, 0.4343 MJ/m2, 0.5882 MJ/m2, 2.9757% and 0.9865, respectively. By conducting a further verification, it is found that the \\{ELM\\} method also offers high superiority over four empirical models established for this study and an intelligent model from the literature. In the final analysis, a proper sensitivity analysis is performed to identify the influence of considered input elements on \\{HGSR\\} prediction in which the results reveal the significance of appropriate selection of input parameters to boost the accuracy of \\{HGSR\\} prediction by the \\{ELM\\} algorithm. In a nutshell, the comparative results clearly specify that \\{ELM\\} technique can provide reliable predictions with further precision compared to the existing techniques.", 
        "author": "Shahaboddin Shamshirband and Kasra Mohammadi and Por Lip Yee and Dalibor Petkovi\u0107 and Ali Mostafaeipour", 
        "keyword": "Horizontal global solar radiation\", \"Extreme learning machine (ELM)\", \"Prediction\", \"Comparative keywords =ssessment\", \"Sensitivity analysis", 
        "title": "A comparative evaluation for identifying the suitability of extreme learning machine to predict horizontal global solar radiation"
    }, 
    {
        "abstract": "Abstract The extreme learning machine (ELM), a single-hidden layer feedforward neural network algorithm, was tested on nine environmental regression problems. The prediction accuracy and computational speed of the ensemble \\{ELM\\} were evaluated against multiple linear regression (MLR) and three nonlinear machine learning (ML) techniques \u2013 artificial neural network (ANN), support vector regression and random forest (RF). Simple automated algorithms were used to estimate the parameters (e.g. number of hidden neurons) needed for model training. Scaling the range of the random weights in \\{ELM\\} improved its performance. Excluding large datasets (with large number of cases and predictors), \\{ELM\\} tended to be the fastest among the nonlinear models. For large datasets, \\{RF\\} tended to be the fastest. \\{ANN\\} and \\{ELM\\} had similar skills, but \\{ELM\\} was much faster than \\{ANN\\} except for large datasets. Generally, the tested \\{ML\\} techniques outperformed MLR, but no single method was best for all the nine datasets.", 
        "author": "Aranildo R. Lima and Alex J. Cannon and William W. Hsieh", 
        "keyword": "Extreme learning machines\", \"Support vector machine\", \"Artificial neural network\", \"Regression\", keywords =Environmental science\", \"Machine learning", 
        "title": "Nonlinear regression in environmental sciences using extreme learning machines: A comparative evaluation"
    }, 
    {
        "abstract": "Abstract Recent studies showed that machine learning (ML) algorithms (e.g., artificial neural network (ANN) and support vector machine (SVM)) reasonably reproduce passive microwave brightness temperature observations over snow-covered land as measured by the Advanced Microwave Scanning Radiometer (AMSR-E). However, these studies did not explore the sensitivities of the \\{ML\\} algorithms relative to \\{ML\\} inputs in order to determine the behavior and performance of each algorithm. In this current study, normalized sensitivity coefficients are computed to diagnose \\{ML\\} performance as a function of time and space. The results showed that when using the ANN, approximately 20% of locations across North America are relatively sensitive to snow water equivalent (SWE). However, more than 65% of locations in the SVM-based brightness temperature (Tb) estimates are sensitive relative to perturbations in \\{SWE\\} at all frequency and polarization combinations explored in this study. Further, the SVM-based results suggest the algorithm is sensitive in both shallow and deep SWE, \\{SWE\\} with and without overlying forest canopy, and during both the snow accumulation and snow ablation seasons. Therefore, these findings suggest that compared with the ANN, the \\{SVM\\} could potentially serve as a more efficient and effective measurement model operator within a Tb data assimilation framework for the purpose of improving \\{SWE\\} estimates across regional- and continental-scales.", 
        "author": "Yuan Xue and Barton A. Forman", 
        "keyword": "Sensitivity analysis\", \"Machine learning\", \"Brightness temperature\", \"Snow\", \"Data assimilation", 
        "title": "Comparison of passive microwave brightness temperature prediction sensitivities over snow-covered land in North America using machine learning algorithms and the Advanced Microwave Scanning Radiometer"
    }, 
    {
        "abstract": "Abstract Influenza is a yearly recurrent disease that has the potential to become a pandemic. An effective biosurveillance system is required for early detection of the disease. In our previous studies, we have shown that electronic Emergency Department (ED) free-text reports can be of value to improve influenza detection in real time. This paper studies seven machine learning (ML) classifiers for influenza detection, compares their diagnostic capabilities against an expert-built influenza Bayesian classifier, and evaluates different ways of handling missing clinical information from the free-text reports. We identified 31,268 \\{ED\\} reports from 4 hospitals between 2008 and 2011 to form two different datasets: training (468 cases, 29,004 controls), and test (176 cases and 1620 controls). We employed Topaz, a natural language processing (NLP) tool, to extract influenza-related findings and to encode them into one of three values: Acute, Non-acute, and Missing. Results show that all \\{ML\\} classifiers had areas under \\{ROCs\\} (AUC) ranging from 0.88 to 0.93, and performed significantly better than the expert-built Bayesian model. Missing clinical information marked as a value of missing (not missing at random) had a consistently improved performance among 3 (out of 4) \\{ML\\} classifiers when it was compared with the configuration of not assigning a value of missing (missing completely at random). The case/control ratios did not affect the classification performance given the large number of training cases. Our study demonstrates \\{ED\\} reports in conjunction with the use of \\{ML\\} and \\{NLP\\} with the handling of missing value information have a great potential for the detection of infectious diseases.", 
        "author": "Arturo L\u00f3pez Pineda and Ye Ye and Shyam Visweswaran and Gregory F. Cooper and Michael M. Wagner and Fuchiang (Rich) Tsui", 
        "keyword": "Influenza\", \"Emergency department reports\", \"Case detection\", \"Machine learning\", \"Bayesian", 
        "title": "Comparison of machine learning classifiers for influenza detection from emergency department free-text reports"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel method for supervised subspace learning based on Single-hidden Layer Feedforward Neural networks. The proposed method calculates appropriate network target vectors by formulating a Bayesian model exploiting both the labeling information available for the training data and geometric properties of the training data, when represented in the feature space determined by the network\u05f3s hidden layer outputs. After the calculation of the network target vectors, Extreme Learning Machine-based neural network training is applied and classification is performed using a Nearest Neighbor classifier. Experimental results on publicly available data sets show that the proposed approach consistently outperforms the standard \\{ELM\\} approach, as well as other standard methods.", 
        "author": "Alexandros Iosifidis", 
        "keyword": "Extreme Learning Machine\", \"Supervised subspace learning\", \"Network targets calculation", 
        "title": "Extreme learning machine based supervised subspace learning"
    }, 
    {
        "abstract": "Abstract Computerized evaluation of histological preparations of prostate tissues involves identification of tissue components such as stroma (ST), benign/normal epithelium (BN) and prostate cancer (PCa). Image classification approaches have been developed to identify and classify glandular regions in digital images of prostate tissues; however their success has been limited by difficulties in cellular segmentation and tissue heterogeneity. We hypothesized that utilizing image pixels to generate intensity histograms of hematoxylin (H) and eosin (E) stains deconvoluted from H&amp;E images numerically captures the architectural difference between glands and stroma. In addition, we postulated that joint histograms of local binary patterns and local variance (LBPxVAR) can be used as sensitive textural features to differentiate benign/normal tissue from cancer. Here we utilized a machine learning approach comprising of a support vector machine (SVM) followed by a random forest (RF) classifier to digitally stratify prostate tissue into ST, \\{BN\\} and \\{PCa\\} areas. Two pathologists manually annotated 210 images of low- and high-grade tumors from slides that were selected from 20 radical prostatectomies and digitized at high-resolution. The 210 images were split into the training (n = 19) and test (n = 191) sets. Local intensity histograms of H and E were used to train a \\{SVM\\} classifier to separate \\{ST\\} from epithelium (BN + PCa). The performance of \\{SVM\\} prediction was evaluated by measuring the accuracy of delineating epithelial areas. The Jaccard J = 59.5 \u00b1 14.6 and Rand Ri = 62.0 \u00b1 7.5 indices reported a significantly better prediction when compared to a reference method (Chen et al., Clinical Proteomics 2013, 10:18) based on the averaged values from the test set. To distinguish \\{BN\\} from \\{PCa\\} we trained a \\{RF\\} classifier with \\{LBPxVAR\\} and local intensity histograms and obtained separate performance values for \\{BN\\} and PCa: \\{JBN\\} = 35.2 \u00b1 24.9, \\{OBN\\} = 49.6 \u00b1 32, \\{JPCa\\} = 49.5 \u00b1 18.5, \\{OPCa\\} = 72.7 \u00b1 14.8 and Ri = 60.6 \u00b1 7.6 in the test set. Our pixel-based classification does not rely on the detection of lumens, which is prone to errors and has limitations in high-grade cancers and has the potential to aid in clinical studies in which the quantification of tumor content is necessary to prognosticate the course of the disease. The image data set with ground truth annotation is available for public use to stimulate further research in this area.", 
        "author": "Arkadiusz Gertych and Nathan Ing and Zhaoxuan Ma and Thomas J. Fuchs and Sadri Salman and Sambit Mohanty and Sanica Bhele and Adriana Vel\u00e1squez-Vacca and Mahul B. Amin and Beatrice S. Knudsen", 
        "keyword": "Machine learning\", \"Image analysis\", \"Prostate cancer\", \"Tissue classification\", \"Tissue quantification", 
        "title": "Machine learning approaches to analyze histological images of tissues from radical prostatectomies"
    }, 
    {
        "abstract": "Abstract With the rise in whole slide scanner technology, large numbers of tissue slides are being scanned and represented and archived digitally. While digital pathology has substantial implications for telepathology, second opinions, and education there are also huge research opportunities in image computing with this new source of \u201cbig data\u201d. It is well known that there is fundamental prognostic data embedded in pathology images. The ability to mine \u201csub-visual\u201d image features from digital pathology slide images, features that may not be visually discernible by a pathologist, offers the opportunity for better quantitative modeling of disease appearance and hence possibly improved prediction of disease aggressiveness and patient outcome. However the compelling opportunities in precision medicine offered by big digital pathology data come with their own set of computational challenges. Image analysis and computer assisted detection and diagnosis tools previously developed in the context of radiographic images are woefully inadequate to deal with the data density in high resolution digitized whole slide images. Additionally there has been recent substantial interest in combining and fusing radiologic imaging and proteomics and genomics based measurements with features extracted from digital pathology images for better prognostic prediction of disease aggressiveness and patient outcome. Again there is a paucity of powerful tools for combining disease specific features that manifest across multiple different length scales. The purpose of this review is to discuss developments in computational image analysis tools for predictive modeling of digital pathology images from a detection, segmentation, feature extraction, and tissue classification perspective. We discuss the emergence of new handcrafted feature approaches for improved predictive modeling of tissue appearance and also review the emergence of deep learning schemes for both object detection and tissue classification. We also briefly review some of the state of the art in fusion of radiology and pathology images and also combining digital pathology derived image measurements with molecular \u201comics\u201d features for better predictive modeling. The review ends with a brief discussion of some of the technical and computational challenges to be overcome and reflects on future opportunities for the quantitation of histopathology.", 
        "author": "Anant Madabhushi and George Lee", 
        "keyword": "Digital pathology\", \"Deep learning\", \"Radiology\", \"Omics", 
        "title": "Image analysis and machine learning in digital pathology: Challenges and opportunities"
    }, 
    {
        "abstract": "Abstract \\{SOL\\} is an open-source library for scalable online learning with high-dimensional data. The library provides a family of regular and sparse online learning algorithms for large-scale classification tasks with high efficiency, scalability, portability, and extensibility. We provide easy-to-use command-line tools, python wrappers and library calls for users and developers, and comprehensive documents for both beginners and advanced users. \\{SOL\\} is not only a machine learning toolbox, but also a comprehensive experimental platform for online learning research. Experiments demonstrate that \\{SOL\\} is highly efficient and scalable for large-scale learning with high-dimensional data.", 
        "author": "Yue Wu and Steven C.H. Hoi and Chenghao Liu and Jing Lu and Doyen Sahoo and Nenghai Yu", 
        "keyword": "Online learning\", \"Scalable machine learning\", \"High dimensionality\", \"Sparse learning", 
        "title": "SOL: A library for scalable online learning algorithms"
    }, 
    {
        "abstract": "Abstract Anomaly based Intrusion Detection Systems (IDS) learn normal and anomalous behavior by analyzing network traffic in various benchmark datasets. Common challenges for \\{IDSs\\} are large amounts of data to process, low detection rates and high rates of false alarms. In this paper, a technique based on the Online Sequential Extreme Learning Machine (OS-ELM) is presented for intrusion detection. The proposed technique uses alpha profiling to reduce the time complexity while irrelevant features are discarded using an ensemble of Filtered, Correlation and Consistency based feature selection techniques. Instead of sampling, beta profiling is used to reduce the size of the training dataset. For performance evaluation of proposed technique the standard NSL-KDD 2009 (Network Security Laboratory-Knowledge Discovery and Data Mining) dataset is used. In this paper time and space complexity of the proposed technique is also discussed. The experimental results yielded an accuracy of 98.66% with a false positive rate of 1.74% and a detection time of 2.43 s for binary class NSL-KDD dataset. The proposed \\{IDS\\} achieve 97.67% of accuracy with 1.74% of false positive rate in 2.65 s of detection time for multi-class NSL-KDD dataset. The Kyoto University benchmark dataset is also used to test the proposed IDS. Accuracy of 96.37% with false positive rate of 5.76% is yielded by the proposed technique. The proposed technique outperforms other published techniques in terms of accuracy, false positive rate and detection time. Based on the experimental results achieved, we conclude that the proposed technique is an efficient method for network intrusion detection.", 
        "author": "Raman Singh and Harish Kumar and R.K. Singla", 
        "keyword": "Intrusion detection system\", \"Feature selection technique\", \"Network traffic dataset\", \"Network keywords =raffic profiling\", \"Online sequential extreme learning machine (OS-ELM)", 
        "title": "An intrusion detection system using network traffic profiling and online sequential extreme learning machine"
    }, 
    {
        "abstract": "Abstract This paper addresses the prediction of preoperational time for patients with the acute coronary syndrome. Health records contain personal information, life and disease anamnesis, test results. Using this data, we tried to predict time before the coronary stent operation with regression methods. During the preprocessing, we divided health records into three clusters with k-means method and compared the results of cluster's prediction for five different classification methods. The results show that it is possible to classify initial data with the accuracy of 68.31% on average. Pre-classification of health records has helped to improve the results of regression almost twice on average, although the accuracy of prediction is needed to be further increased.", 
        "author": "Anastasia Funkner and Sergey Kovalchuk and Klavdiya Bochenina", 
        "keyword": "machine learning\", \"classification\", \"preoperational time\", \"cardiac ischemia", 
        "title": "Preoperational Time Prediction for Percutaneous Coronary Intervention Using Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract Intravascular optical coherence tomography (IV-OCT) is an in-vivo imaging modality based on the intravascular introduction of a catheter which provides a view of the inner wall of blood vessels with a spatial resolution of 10\u201320 \u03bcm. Recent studies in IV-OCT have demonstrated the importance of the bifurcation regions. Therefore, the development of an automated tool to classify hundreds of coronary \\{OCT\\} frames as bifurcation or nonbifurcation can be an important step to improve automated methods for atherosclerotic plaques quantification, stent analysis and co-registration between different modalities. This paper describes a fully automated method to identify IV-OCT frames in bifurcation regions. The method is divided into lumen detection; feature extraction; and classification, providing a lumen area quantification, geometrical features of the cross-sectional lumen and labeled slices. This classification method is a combination of supervised machine learning algorithms and feature selection using orthogonal least squares methods. Training and tests were performed in sets with a maximum of 1460 human coronary \\{OCT\\} frames. The lumen segmentation achieved a mean difference of lumen area of 0.11 mm2 compared with manual segmentation, and the AdaBoost classifier presented the best result reaching a F-measure score of 97.5% using 104 features.", 
        "author": "Maysa M.G. Macedo and Welingson V.N. Guimar\u00e3es and Micheli Z. Galon and Celso K. Takimura and Pedro A. Lemos and Marco Antonio Gutierrez", 
        "keyword": "Optical coherence tomography\", \"Segmentation\", \"Intravascular\", \"Classification\", \"Orthogonal least keywords =quares\", \"Bifurcation\", \"Machine learning", 
        "title": "A bifurcation identifier for IV-OCT using orthogonal least squares and supervised machine learning"
    }, 
    {
        "abstract": "Abstract Along with the proliferation of mobile devices and wireless signal coverage, indoor localization based on Wi-Fi gets great popularity. Fingerprint based method is the mainstream approach for Wi-Fi indoor localization, for it can achieve high localization performance as long as labeled data are sufficient. However, the number of labeled data is always limited due to the high cost of data acquisition. Nowadays, crowd sourcing becomes an effective approach to gather large number of data; meanwhile, most of them are unlabeled. Therefore, it is worth studying the use of unlabeled data to improve localization performance. To achieve this goal, a novel algorithm Semi-supervised Deep Extreme Learning Machine (SDELM) is proposed, which takes the advantages of semi-supervised learning, Deep Leaning (DL), and Extreme Learning Machine (ELM), so that the localization performance can be improved both in the feature extraction procedure and in the classifier. The experimental results in real indoor environments show that the proposed \\{SDELM\\} not only outperforms other compared methods but also reduces the calibration effort with the help of unlabeled data.", 
        "author": "Yang Gu and Yiqiang Chen and Junfa Liu and Xinlong Jiang", 
        "keyword": "Wi-Fi indoor localization\", \"Semi-supervised learning\", \"Deep learning\", \"Extreme Learning Machine (ELM)", 
        "title": "Semi-supervised deep extreme learning machine for Wi-Fi based localization"
    }, 
    {
        "abstract": "Abstract We present a method for real-time scene classification which achieves high accuracy without a time consuming descriptor learning step and kernelized classifiers. Robustness of the classification is achieved by combining the powerful multi-channel Gabor-based descriptors and an ensemble of Extreme Learning Machines (ELM). We first extend the recently introduced Binary Gabor Patterns (BGP) to multi-channel images. This is done by extracting \\{BGP\\} over several color channels and embedding an additional compact color layout descriptor. Then we propose an effective method for the aggregation of multiple \\{ELMs\\} into a single classification system, which leads to significant classification accuracy improvements. The experimental evaluation demonstrates that multi-channel color information constantly improves classification results. The integration of multiple \\{ELMs\\} into an ensemble using the proposed aggregation strategy significantly outperforms linear \\{SVM\\} in terms of accuracy, and reaches results similar to the non-linear \\{SVM\\} while operating in real time. Therefore, an ensemble of \\{ELMs\\} with the proposed aggregation strategy could be used as an efficient alternative to the non-linear \\{SVM\\} for remote sensing image classification tasks.", 
        "author": "Stevica Cvetkovi\u0107 and Milo\u0161 B. Stojanovi\u0107 and Sa\u0161a V. Nikoli\u0107", 
        "keyword": "Scene classification\", \"Multi-channel descriptor\", \"Extreme learning machine\", \"Ensemble of classifiers", 
        "title": "Multi-channel descriptors and ensemble of Extreme Learning Machines for classification of remote sensing images"
    }, 
    {
        "abstract": "Abstract This paper presents a study of modelling post-combustion \\{CO2\\} capture process using bootstrap aggregated ELMs. The dynamic \\{ELM\\} models predict \\{CO2\\} capture rate and \\{CO2\\} capture level using the following variables as model inputs: inlet flue gas flow rate, \\{CO2\\} concentration in inlet flue gas, pressure of flue gas, temperature of flue gas, lean solvent flow rate, \\{MEA\\} concentration and temperature of lean solvent. In order to enhance model accuracy and reliability, multiple \\{ELM\\} models are developed from bootstrap re-sampling replications of the original training data and combined. Bootstrap aggregated \\{ELM\\} model can offer more accurate and reliable predictions than a single \\{ELM\\} model, as well as provide model prediction confidence bounds. The developed models can be used in the optimisation of \\{CO2\\} capture processes.", 
        "author": "Zhongjing Bai and Fei Li and Jie Zhang and Eni Oko and Meihong Wang and Z. Xiong and D. Huang", 
        "keyword": "Carbon capture\", \"data driven modelling\", \"extreme learning machine\", \"bootstrap re-sampling", 
        "title": "Modelling of a Post-combustion \\{CO2\\} Capture Process Using Bootstrap Aggregated Extreme Learning Machines"
    }, 
    {
        "abstract": "Abstract Uterine contractions produced during labor have the potential to damage a fetus by diminishing the maternal blood flow to the placenta, which can result in fetus hypoxia. In order to observe this phenomenon in practice, labor and delivery are routinely monitored using cardiotocography monitors. The cardiotocography recordings are used by obstetricians to help diagnosis fetus hypoxia. However, cardiotocography capture and interpretation is time consuming and subjective, often leading to misclassification that result in damage to the fetus and unnecessary cesarean sections. Therefore, correct classification is dependent on qualified and experienced obstetric and midwifery staff and their understanding of classification methods. As such, other, more objective measures may help to reduce misclassification among medical practitioners. For example, automatic detection of correlates between uterine contractions and fetal heart rate can be used to reduce unnecessary medical interventions, such as hypoxia and cesarean section, during the first stage of labor and can be instrumental in vaginal delivery in the second. The challenge is to develop predictive algorithms capable of detecting, with high accuracy, when a child is genuinely compromised before medical intervention is considered. This chapter aims to provide a discussion of the requirements for such an approach and discuss a methodology for objectively identifying intrapartum hypoxia.", 
        "author": "Paul Fergus and De-Shuang Huang and Hani Hamdan", 
        "keyword": "Machine Learning\", \"Data Processing\", \"Cardiotocography\", \"Hypoxia\", \"Ambulatory Monitoring\", keywords =Prediction\", \"Signal Processing\", \"Feature Extraction", 
        "title": "Chapter 6 - Prediction of Intrapartum Hypoxia from Cardiotocography Data Using Machine Learning"
    }, 
    {
        "abstract": "Abstract Spatially high resolution climate information is required for a variety of applications in but not limited to functional biodiversity research. In order to scale the generally plot-based research findings to a landscape level, spatial interpolation methods of meteorological variables are required. Based on a network of temperature observation plots across the southern slopes of Mt. Kilimanjaro, the skill of 14 machine learning algorithms in predicting spatial temperature patterns is tested and evaluated against the heavily utilized kriging approach. Based on a 10-fold cross-validation testing design, regression trees generally perform better than linear and non-linear regression models. The best individual performance has been observed by the stochastic gradient boosting model followed by Cubist, random forest and model averaged neural networks which except for the latter are all regression tree-based algorithms. While these machine learning algorithms perform better than kriging in a quantitative evaluation, the overall visual interpretation of the resulting air temperature maps is ambiguous. Here, a combined Cubist and residual kriging approach can be considered the best solution.", 
        "author": "Tim Appelhans and Ephraim Mwangomo and Douglas R. Hardy and Andreas Hemp and Thomas Nauss", 
        "keyword": "Spatial interpolation\", \"Machine learning\", \"Air temperature\", \"Kriging\", \"Cubist\", \"Cross-validation", 
        "title": "Evaluating machine learning approaches for the interpolation of monthly air temperature at Mt. Kilimanjaro, Tanzania"
    }, 
    {
        "abstract": "AbstractContext One of the most important factors in the development of a software project is the quality of their requirements. Erroneous requirements, if not detected early, may cause many serious problems, such as substantial additional costs, failure to meet the expected objectives and delays in delivery dates. For these reasons, great effort must be devoted in requirements engineering to ensure that the project\u2019s requirements results are of high quality. One of the aims of this discipline is the automatic processing of requirements for assessing their quality; this aim, however, results in a complex task because the quality of requirements depends mostly on the interpretation of experts and the necessities and demands of the project at hand. Objective The objective of this paper is to assess the quality of requirements automatically, emulating the assessment that a quality expert of a project would assess. Method The proposed methodology is based on the idea of learning based on standard metrics that represent the characteristics that an expert takes into consideration when deciding on the good or bad quality of requirements. Using machine learning techniques, a classifier is trained with requirements earlier classified by the expert, which then is used for classifying newly provided requirements. Results We present two approaches to represent the methodology with two situations of the problem in function of the requirement corpus learning balancing, obtaining different results in the accuracy and the efficiency in order to evaluate both representations. The paper demonstrates the reliability of the methodology by presenting a case study with requirements provided by the Requirements Working Group of the \\{INCOSE\\} organization. Conclusions A methodology that evaluates the quality of requirements written in natural language is presented in order to emulate the quality that the expert would provide for new requirements, with 86.1 of average in the accuracy.", 
        "author": "Eugenio Parra and Christos Dimou and Juan Llorens and Valent\u00edn Moreno and Anabel Fraga", 
        "keyword": "Software engineering\", \"Requirements engineering\", \"Requirements quality\", \"Machine learning", 
        "title": "A methodology for the classification of quality of requirements using machine learning techniques"
    }, 
    {
        "abstract": "AbstractBackground and purpose Novel approaches applying machine-learning methods to neuroimaging data seek to develop individualized measures that will aid in the diagnosis and treatment of brain-based disorders such as temporal lobe epilepsy (TLE). Using a large cohort of epilepsy patients with and without mesial temporal sclerosis (MTS), we sought to automatically classify \\{MTS\\} using measures of cortical morphology, and to further relate classification probabilities to measures of disease burden. Materials and methods Our sample consisted of high-resolution \\{T1\\} structural scans of 169 adults with epilepsy collected across five different 1.5 T and four different 3 T scanners at UCLA. We applied a multiple support vector machine recursive feature elimination algorithm to morphological measures generated from FreeSurfer's automated segmentation and parcellation in order to classify Epilepsy patients with \\{MTS\\} (n = 85) from those without \\{MTS\\} (N = 84). Results In addition to hippocampal volume, we found that alterations in cortical thickness, surface area, volume and curvature in inferior frontal and anterior and inferior temporal regions contributed to a classification accuracy of up to 81% (p = 1.3 \u00d7 10\u221217) in identifying MTS. We also found that \\{MTS\\} classification probabilities were associated with a longer duration of disease for epilepsy patients both with and without MTS. Conclusions In addition to implicating extra-hippocampal involvement of MTS, these findings shed further light on the pathogenesis of \\{TLE\\} and may ultimately assist in the development of automated tools that incorporate multiple neuroimaging measures to assist clinicians in detecting more subtle cases of \\{TLE\\} and MTS.", 
        "author": "Jeffrey D. Rudie and John B. Colby and Noriko Salamon", 
        "keyword": "Machine learning\", \"Mesial temporal sclerosis\", \"Cortical thickness\", \"Hippocampus\", \"Cortical keywords =olding\", \"Temporal lobe epilepsy", 
        "title": "Machine learning classification of mesial temporal sclerosis in epilepsy patients"
    }, 
    {
        "abstract": "Abstract Machine learning techniques are being increasingly used for detection and diagnosis of diseases for its accuracy and efficiency in pattern classification. In this paper, improved cuckoo search based extreme learning machine (ICSELM) is proposed to classify binary medical datasets. Extreme learning machine (ELM) is widely used as a learning algorithm for training single layer feed forward neural networks (SLFN) in the field of classification. However, to make the model more stable, an evolutionary algorithm improved cuckoo search (ICS) is used to pre-train \\{ELM\\} by selecting the input weights and hidden biases. Like ELM, Moore\u2013Penrose (MP) generalized inverse is used in \\{ICSELM\\} to analytically determines the output weights. To evaluate the effectiveness of the proposed model, four benchmark datasets, i.e. Breast Cancer, Diabetes, Bupa and Hepatitis from the \\{UCI\\} Repository of Machine Learning are used. A number of useful performance evaluation measures including accuracy, sensitivity, specificity, confusion matrix, Gmean, F-score and norm of the output weights as well as the area under the receiver operating characteristic (ROC) curve are computed. The results are analyzed and compared with both \\{ELM\\} based models like ELM, on-line sequential extreme learning algorithm (OSELM), \\{CSELM\\} and other artificial neural networks i.e. multi-layered perceptron (MLP), MLPCS, \\{MLPICS\\} and radial basis function neural network (RBFNN), RBFNNCS, RBFNNICS. The experimental results demonstrate that the \\{ICSELM\\} model outperforms other models.", 
        "author": "P. Mohapatra and S. Chakravarty and P.K. Dash", 
        "keyword": "Extreme learning machine (ELM)\", \"Online sequential extreme learning machine (OSELM)\", \"Cuckoo keywords =earch (CS)\", \"Cuckoo search based extreme learning machine (CSELM)\", \"Improved cuckoo search based extreme learning machine (ICSELM)", 
        "title": "An improved cuckoo search based extreme learning machine for medical data classification"
    }, 
    {
        "abstract": "Abstract Recombinant protein overexpression, an important biotechnological process, is ruled by complex biological rules which are mostly unknown, is in need of an intelligent algorithm so as to avoid resource-intensive lab-based trial and error experiments in order to determine the expression level of the recombinant protein. The purpose of this study is to propose a predictive model to estimate the level of recombinant protein overexpression for the first time in the literature using a machine learning approach based on the sequence, expression vector, and expression host. The expression host was confined to Escherichia coli which is the most popular bacterial host to overexpress recombinant proteins. To provide a handle to the problem, the overexpression level was categorized as low, medium and high. A set of features which were likely to affect the overexpression level was generated based on the known facts (e.g. gene length) and knowledge gathered from related literature. Then, a representative sub-set of features generated in the previous objective was determined using feature selection techniques. Finally a predictive model was developed using random forest classifier which was able to adequately classify the multi-class imbalanced small dataset constructed. The result showed that the predictive model provided a promising accuracy of 80% on average, in estimating the overexpression level of a recombinant protein.", 
        "author": "Narjeskhatoon Habibi and Alireza Norouzi and Siti Z Mohd Hashim and Mohd Shahir Shamsir and Razip Samian", 
        "keyword": "Protein overexpression level\", \"E. coli\", \"Prediction\", \"Feature selection\", \"Machine learning\", \"Recombinant protein", 
        "title": "Prediction of recombinant protein overexpression in Escherichia coli using a machine learning based model (RPOLP)"
    }, 
    {
        "abstract": "Abstract Lately, the kernel extreme learning machine (KELM) has gained considerable importance in the scientific area due to its great efficiency, easy implementation and fast training speed. In this paper, for the first time the potential of \\{KELM\\} to predict the daily horizontal global solar radiation from the maximum and minimum air temperatures (Tmax and Tmin) is appraised. The effectiveness of the proposed \\{KELM\\} method is evaluated against the grid search based support vector regression (SVR), as a robust methodology. Three \\{KELM\\} and \\{SVR\\} models are developed using different input attributes including: (1) Tmin and Tmax, (2) Tmin and Tmax\u2212Tmin, and (3) Tmax and Tmax\u2212Tmin. The achieved results reveal that the best predictions precision is achieved by models (3). The achieved results demonstrate that \\{KELM\\} offers favorable predictions and outperforms the SVR. For the \\{KELM\\} (3) model, the obtained statistical parameters of mean absolute bias error, root mean square error, relative root mean square error and correlation coefficient are 1.3445 MJ/m2, 2.0164 MJ/m2, 11.2464% and 0.9057%, respectively for the testing data. As further examination, a month-by-month evaluation is conducted and found that in six months from May to October the \\{KELM\\} (3) model provides further accuracy than overall accuracy. Based upon the relative root mean square error, the \\{KELM\\} (3) model shows excellent capability in the period of April to October while in the remaining months represents good performance.", 
        "author": "Shahaboddin Shamshirband and Kasra Mohammadi and Hui-Ling Chen and Ganthan Narayana Samy and Dalibor Petkovi\u0107 and Chao Ma", 
        "keyword": "Daily global solar radiation\", \"Kernel Extreme Learning Machine\", \"Support vector regression\", \"Prediction", 
        "title": "Daily global solar radiation prediction from air temperatures using kernel extreme learning machine: A case study for Iran"
    }, 
    {
        "abstract": "AbstractPurpose Tools for survival prediction for non-small cell lung cancer (NSCLC) patients treated with (chemo)radiotherapy are of limited quality. In this work, we develop a predictive model of survival at two years. The model is based on a large volume of historical patient data and serves as a proof of concept to demonstrate the distributed learning approach. Patients and methods Clinical data from 698 lung cancer patients, treated with curative intent with chemoradiation (CRT) or radiotherapy (RT) alone were collected and stored in 2 different cancer institutes (559 patients at Institute 1 (Country 1)), 139 at University of Institute 2 (Country 2). The model was further validated on 196 patients originating from the Institute 3 (Institute 3, Country 3). A Bayesian network model was adapted for distributed learning (watch the animation: link censored). Two-year post-treatment survival was chosen as endpoint. The Institute 1 cohort data is publicly available at (link censored) and the developed models can be found at (link censored). Results Variables included in the final model were T and N stage, age, performance status, and total tumor dose. The model has an \\{AUC\\} of 0.66 on the external validation set and an \\{AUC\\} of 0.62 on a 5-fold cross-validation. A model based on T and N stage performed with an \\{AUC\\} of 0.47 on the validation set, significantly worse than our model (P&lt;0.001). Learning the model in a centralized or distributed fashion yields a minor difference on the probabilities of the conditional probability tables (0.6%), discriminative performance of the models on the validation set is similar (P=0.26). Conclusion Distributed learning from federated databases allows learning of predictive models on data originating from multiple institutions while avoiding many of the data sharing barriers. We believe that Distributed learning is the future of sharing data in health care.", 
        "author": "Arthur Jochems and Timo M. Deist and Issam El Naqa and Marc Kessler and Chuck Mayo and Jackson Reeves and Shruti Jolly and Martha Matuszak and Randall Ten Haken and Johan van Soest and Cary Oberije and Corinne Faivre-Finn and Gareth Price and Dirk de Ruysscher and Philippe Lambin and Andre Dekker", 
        "keyword": "Bayesian networks, distributed learning\", \"privacy preserving data-mining, survival, machine learning", 
        "title": "Developing and validating a survival prediction model for \\{NSCLC\\} patients through distributed learning across three countries"
    }, 
    {
        "abstract": "Abstract Discriminative clustering is an unsupervised learning framework which introduces the discriminative learning rule of supervised classification into clustering. The underlying assumption is that a good partition (clustering) of the data should yield high discrimination, namely, the partitioned data can be easily classified by some classification algorithms. In this paper, we propose three discriminative clustering approaches based on Extreme Learning Machine (ELM). The first algorithm iteratively trains weighted \\{ELM\\} (W-ELM) classifier to gradually maximize the data discrimination. The second and third methods are both built on Fisher\u2019s Linear Discriminant Analysis (LDA); but one approach adopts alternative optimization, while the other leverages kernel k -means. We show that the proposed algorithms can be easily implemented, and yield competitive clustering accuracy on real world data sets compared to state-of-the-art clustering methods.", 
        "author": "Gao Huang and Tianchi Liu and Yan Yang and Zhiping Lin and Shiji Song and Cheng Wu", 
        "keyword": "Discriminative clustering\", \"Extreme learning machine\", \"k -means\", \"Linear discriminant analysis", 
        "title": "Discriminative clustering via extreme learning machine"
    }, 
    {
        "abstract": "Abstract In insulin and leptin signaling pathway, Protein-Tyrosine Phosphatase 1B (PTP1B) plays a crucial controlling role as a negative regulator, which makes it an attractive therapeutic target for both Type-2 Diabetes (T2D) and obesity. In this work, we have generated classification models by using the inhibition data set of known \\{PTP1B\\} inhibitors to identify new inhibitors of \\{PTP1B\\} utilizing multiple machine learning techniques like na\u00efve Bayesian, random forest, support vector machine and k-nearest neighbors, along with structural fingerprints and selected molecular descriptors. Several models from each algorithm have been constructed and optimized, with the different combination of molecular descriptors and structural fingerprints. For the training and test sets, most of the predictive models showed more than 90% of overall prediction accuracies. The best model was obtained with support vector machine approach and has Matthews Correlation Coefficient of 0.82 for the external test set, which was further employed for the virtual screening of Maybridge small compound database. Five compounds were subsequently selected for experimental assay. Out of these two compounds were found to inhibit \\{PTP1B\\} with significant inhibitory activity in in-vitro inhibition assay. The structural fragments which are important for \\{PTP1B\\} inhibition were identified by na\u00efve Bayesian method and can be further exploited to design new molecules around the identified scaffolds. The descriptive and predictive modeling strategy applied in this study is capable of identifying \\{PTP1B\\} inhibitors from the large compound libraries.", 
        "author": "Sharat Chandra and Jyotsana Pandey and Akhilesh Kumar Tamrakar and Mohammad Imran Siddiqi", 
        "keyword": "Protein-tyrosine phosphatase 1B\", \"Type-2 diabetes\", \"Support vector machine\", \"Virtual screening\", \"Structure fragments", 
        "title": "Multiple machine learning based descriptive and predictive workflow for the identification of potential \\{PTP1B\\} inhibitors"
    }, 
    {
        "abstract": "Abstract In this paper, a new sequential learning algorithm is constructed by combining the Online Sequential Extreme Learning Machine (OS-ELM) and Kalman filter regression. The Kalman Online Sequential Extreme Learning Machine (KOSELM) handles the problem of multicollinearity of the OS-ELM, which can generate poor predictions and unstable models. The \\{KOSELM\\} learns the training data one-by-one or chunk-by-chunk by adjusting the variance of the output weights through the Kalman filter. The performance of the proposed algorithm has been validated on benchmark regression datasets, and the results show that \\{KOSELM\\} can achieve a higher learning accuracy than OS-ELM and its related extensions. A statistical validation for the differences of the accuracy for all algorithms is performed, and the results confirm that \\{KOSELM\\} has better stability than ReOS-ELM, \\{TOSELM\\} and LS-IELM.", 
        "author": "Jarley Palmeira Nobrega and Adriano L.I. Oliveira", 
        "keyword": "Online sequential learning\", \"Extreme learning machine\", \"Online Sequential Extreme Learning keywords =achine\", \"Kalman filter regression\", \"Multicollinearity", 
        "title": "Kalman filter-based method for Online Sequential Extreme Learning Machine for regression problems"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) is an effective learning algorithm for single-hidden-layer feed-forward neural networks (SLFNNs). Due to its easiness in theory and implementation, \\{ELM\\} has been widely used in many fields. In order to further enhance the generalization performance of ELM, a positive and negative correlation input attributes oriented subnets based double parallel extreme learning machine (PCNCIAOS-DPELM) is proposed in this paper. A salient feature in the PNIAOS-DPELM is that there are two special subnets. In one of the two subnets, the input attributes have a positive correlation to the outputs. In another subnet, the input attributes have a negative correlation to the outputs. The two kinds of input attributes can be obtained by separating the input attributes into two categories using the correlation coefficient analysis. Then according to the categories, the two subnets can be established. The two subnets are based on well-trained auto-associative neural networks (AANNs), which can extract the nonlinear information of the input attributes and remove the redundant information. An advantage in PNIAOS-DPELM is that the proper number of the nodes in the hidden layer can be determined. To test the validity of PNIAOS-DPELM, it is applied to monitoring three chemical processes in steady state. Meanwhile, ELM, double parallel \\{ELM\\} (DP-ELM), and \\{ELM\\} with kernel (ELMK) were developed for comparisons. Experimental results demonstrated that PNIAOS-DPELM could achieve better regression precision and have better stable ability than ELM, DP-ELM, and \\{ELMK\\} did during the generalization phase.", 
        "author": "Yanlin He and ZhiQiang Geng and QunXiong Zhu", 
        "keyword": "Extreme learning machine\", \"Single-hidden-layer feed-forward neural networks\", \"Auto-associative keywords =eural network\", \"Correlation coefficient analysis\", \"Steady state regression", 
        "title": "Positive and negative correlation input attributes oriented subnets based double parallel extreme learning machine (PNIAOS-DPELM) and its application to monitoring chemical processes in steady state"
    }, 
    {
        "abstract": "Abstract Constructive and destructive parsimonious extreme learning machines (CP-ELM and DP-ELM) were recently proposed to sparsify ELM. In comparison with CP-ELM, DP-ELM owns the advantage in the number of hidden nodes, but it loses the edge with respect to the training time. Hence, in this paper an equivalent measure is proposed to accelerate DP-ELM (ADP-ELM). As a result, ADP-ELM not only keeps the same hidden nodes as DP-ELM but also needs less training time than CP-ELM, which is especially important for the training time sensitive scenarios. The similar idea is extended to regularized \\{ELM\\} (RELM), yielding ADP-RELM. ADP-RELM accelerates the training process of DP-RELM further, and it works better than CP-RELM in terms of the number of hidden nodes and the training time. In addition, the computational complexity of the proposed accelerating scheme is analyzed in theory. From reported results on ten benchmark data sets, the effectiveness and usefulness of the proposed accelerating scheme in this paper is confirmed experimentally.", 
        "author": "Yong-Ping Zhao and Bing Li and Ye-Bo Li", 
        "keyword": "Single-hidden layer feedforward network\", \"Extreme learning machine\", \"Destructive algorithm\", keywords =Constructive algorithms\", \"Sparseness", 
        "title": "An accelerating scheme for destructive parsimonious extreme learning machine"
    }, 
    {
        "abstract": "Abstract This paper proposes using the Parallel Layer Perceptron (PLP) network, instead of the Single Layer Feedforward neural network (SLFN) in the Extreme Learning Machine (ELM) framework. Differently from the \\{SLFNs\\} which consider cascade layers, the \\{PLP\\} is designed to accomplish also parallel layers, being the \\{SLFN\\} its particular case. This paper explores a particular \\{PLP\\} configuration which considers a nonlinear layer in parallel with a linear layer. For n inputs and m nonlinear neurons, it provides ( n + 1 ) m linear parameters, while the \\{SLFN\\} would have only m linear parameters (one for each hidden neuron). Since the \\{ELM\\} is based on adjusting only the linear parameters using the least squares estimate (LSE), the \\{PLP\\} network provides more freedom for the proper adjustment. Results from 12 regression and 6 classification problems are presented considering the training and test errors, the linear vector norm and the system condition number. They point out that the PLP-ELM framework is more efficient than the SLFN-ELM approach.", 
        "author": "L.D. Tavares and R.R. Saldanha and D.A.G. Vieira", 
        "keyword": "Parallel layer perceptrons\", \"Extreme learning machine\", \"Structural risk minimization\", \"Least square estimate", 
        "title": "Extreme learning machine with parallel layer perceptrons"
    }, 
    {
        "abstract": "Abstract Detecting fraudulent and abusive cases in healthcare is one of the most challenging problems for data mining studies. However, most of the existing studies have a shortage of real data for analysis and focus on a very limited version of the problem by covering only a specific actor, healthcare service, or disease. The purpose of this study is to implement and evaluate a novel framework to detect fraudulent and abusive cases independently from the actors and commodities involved in the claims and an extensible structure to introduce new fraud and abuse types. Interactive machine learning that allows incorporating expert knowledge in an unsupervised setting is utilized to detect fraud and abusive cases in healthcare. In order to increase the accuracy of the framework, several well-known methods are utilized, such as the pairwise comparison method of analytic hierarchical processing (AHP) for weighting the actors and attributes, expectation maximization (EM) for clustering similar actors, two-stage data warehousing for proactive risk calculations, visualization tools for effective analyzing, and z-score and standardization in order to calculate the risks. The experts are involved in all phases of the study and produce six different abnormal behavior types using storyboards. The proposed framework is evaluated with real-life data for six different abnormal behavior types for prescriptions by covering all relevant actors and commodities. The Area Under the Curve (AUC) values are presented for each experiment. Moreover, a cost-saving model is also presented. The developed framework, i.e., the eFAD suite, is actor- and commodity-independent, configurable (i.e., easily adaptable in the dynamic environment of fraud and abusive behaviors), and effectively handles the fragmented nature of abnormal behaviors. The proposed framework combines both proactive and retrospective analysis with an enhanced visualization tool that significantly reduces the time requirements for the fact-finding process after the eFAD detects risky claims. This system is utilized by a company to produce monthly reports that include abnormal behaviors to be evaluated by the insurance company.", 
        "author": "Ilker Kose and Mehmet Gokturk and Kemal Kilic", 
        "keyword": "Decision support systems\", \"Fraud detection\", \"Health insurance\", \"Interactive machine learning\", \"Machine intelligence", 
        "title": "An interactive machine-learning-based electronic fraud and abuse detection system in healthcare insurance"
    }, 
    {
        "abstract": "Abstract A practical and easy control of the authenticity of organic sugarcane samples based on the use of machine-learning algorithms and trace elements determination by inductively coupled plasma mass spectrometry is proposed. Reference ranges for 32 chemical elements in 22 samples of sugarcane (13 organic and 9 non organic) were established and then two algorithms, Naive Bayes (NB) and Random Forest (RF), were evaluated to classify the samples. Accurate results (&gt;90%) were obtained when using all variables (i.e., 32 elements). However, accuracy was improved (95.4% for NB) when only eight minerals (Rb, U, Al, Sr, Dy, Nb, Ta, Mo), chosen by a feature selection algorithm, were employed. Thus, the use of a fingerprint based on trace element levels associated with classification machine learning algorithms may be used as a simple alternative for authenticity evaluation of organic sugarcane samples.", 
        "author": "Rommel M. Barbosa and Bruno L. Batista and Camila V. Bari\u00e3o and Renan M. Varrique and Vinicius A. Coelho and Andres D. Campiglia and Fernando Barbosa Jr.", 
        "keyword": "Machine learning\", \"Chemometric\", \"Food samples\", \"ICP-MS\", \"Sugarcane\", \"Trace elements", 
        "title": "A simple and practical control of the authenticity of organic sugarcane samples based on the use of machine-learning algorithms and trace elements determination by inductively coupled plasma mass spectrometry"
    }, 
    {
        "abstract": "Abstract With the emerging technologies and all associated devices, it is predicted that massive amount of data will be created in the next few years \u2013 in fact, as much as 90% of current data were created in the last couple of years \u2013 a trend that will continue for the foreseeable future. Sustainable computing studies the process by which computer engineer/scientist designs computers and associated subsystems efficiently and effectively with minimal impact on the environment. However, current intelligent machine-learning systems are performance driven \u2013 the focus is on the predictive/classification accuracy, based on known properties learned from the training samples. For instance, most machine-learning-based nonparametric models are known to require high computational cost in order to find the global optima. With the learning task in a large dataset, the number of hidden nodes within the network will therefore increase significantly, which eventually leads to an exponential rise in computational complexity. This paper thus reviews the theoretical and experimental data-modeling literature, in large-scale data-intensive fields, relating to: (1) model efficiency, including computational requirements in learning, and data-intensive areas' structure and design, and introduces (2) new algorithmic approaches with the least memory requirements and processing to minimize computational cost, while maintaining/improving its predictive/classification accuracy and stability.", 
        "author": "Omar Y. Al-Jarrah and Paul D. Yoo and Sami Muhaidat and George K. Karagiannidis and Kamal Taha", 
        "keyword": "Big data\", \"Green computing\", \"Efficient machine learning\", \"Computational modeling", 
        "title": "Efficient Machine Learning for Big Data: A Review"
    }, 
    {
        "abstract": "Abstract Predictive models are essential in dam safety assessment. Both deterministic and statistical models applied in the day-to-day practice have demonstrated to be useful, although they show relevant limitations at the same time. On another note, powerful learning algorithms have been developed in the field of machine learning (ML), which have been applied to solve practical problems. The work aims at testing the prediction capability of some state-of-the-art algorithms to model dam behaviour, in terms of displacements and leakage. Models based on random forests (RF), boosted regression trees (BRT), neural networks (NN), support vector machines (SVM) and multivariate adaptive regression splines (MARS) are fitted to predict 14 target variables. Prediction accuracy is compared with the conventional statistical model, which shows poorer performance on average. \\{BRT\\} models stand out as the most accurate overall, followed by \\{NN\\} and RF. It was also verified that the model fit can be improved by removing the records of the first years of dam functioning from the training set.", 
        "author": "F. Salazar and M.A. Toledo and E. O\u00f1ate and R. Mor\u00e1n", 
        "keyword": "Dam monitoring\", \"Dam safety\", \"Machine learning\", \"Boosted regression trees\", \"Neural networks\", keywords =Random forests\", \"MARS\", \"Support vector machines\", \"Leakage flow", 
        "title": "An empirical comparison of machine learning techniques for dam behaviour modelling"
    }, 
    {
        "abstract": "Abstract In this paper, a novel double parallel extreme learning machine with Pearson correlation coefficient based independent subnets (PCCIS-DPELM) was proposed for accurately modeling complex chemical processes. Compared with traditional ELM, PCCIS-DPELM has two salient features. One feature is that there are two independent subnets based on the Pearson correlation coefficient (PCC) between the input attributes and output attributes. Another feature is that PCCIS-DPELM has a double parallel structure. The PCCIS-DPELM model can well deal with the highly nonlinear data generating from complex chemical processes. In order to test the performance of PCCIS-DPELM, two complex processes of the Tennessee Eastman (TE) and the purified terephthalic acid (PTA) were selected. Then PCCIS-DPELM based soft sensors were developed for modeling the two complex processes. Compared with double parallel \\{ELM\\} (DPELM) and ELM, the experimental results of the two applications demonstrate that the PCCIS-DPELM model with less number of parameters can achieve smaller predicted relative errors. And the PCCIS-DPELM model can respond faster than the other two models. It is proved that the proposed PCCIS-DPELM is a promising method for accurately modeling complex chemical processes.", 
        "author": "Yan-Lin He and Zhi-Qiang Geng and Qun-Xiong Zhu", 
        "keyword": "Extreme learning machine\", \"Pearson Correlation Coefficient\", \"Soft sensor\", \"Tennessee Eastman keywords =rocess\", \"Purified terephthalic acid process", 
        "title": "Data driven soft sensor development for complex chemical processes using extreme learning machine"
    }, 
    {
        "abstract": "Abstract The image reconstruction of the electrical capacitance tomography (ECT) is an ill-posed and sparse problem. In order to increase the accuracy and speed of the image reconstruction, this paper proposes a new reconstruction algorithm which is based on the extreme learning machine (ELM) with the Landweber iteration method. Firstly, a nonlinear mapping model is established between the pixel gray-scale values and the interelectrode capacitances by using the \\{ELM\\} which has a good learning ability and high speed. Secondly, the Landweber iteration method, which has a good performance in convergence and stability, is applied to calculate the output weight matrix of ELM. Finally, a convergence and stable mapping model of \\{ELM\\} with the Landweber iteration algorithm (L-ELM) for \\{ECT\\} image reconstruction is trained on Matlab platform. Both simulation and measurement tests are carried out to evaluate and analyze the proposed method. Experimental results indicate that the proposed algorithm has good generalization ability and high image reconstruction quality which are better than those of conventional \\{ELM\\} algorithm.", 
        "author": "Xiao Liu and Xiaoxin Wang and Hongli Hu and Lin Li and Xingyue Yang", 
        "keyword": "Electrical capacitance tomography (ECT)\", \"Ill-posed\", \"Extreme learning machine (ELM)\", \"Landweber iteration", 
        "title": "An extreme learning machine combined with Landweber iteration algorithm for the inverse problem of electrical capacitance tomography"
    }, 
    {
        "abstract": "Abstract The objective of this study is to evaluate machine learning algorithms aimed at predicting surgical treatment outcomes in groups of patients with temporal lobe epilepsy (TLE) using only the structural brain connectome. Specifically, the brain connectome is reconstructed using white matter fiber tracts from presurgical diffusion tensor imaging. To achieve our objective, a two-stage connectome-based prediction framework is developed that gradually selects a small number of abnormal network connections that contribute to the surgical treatment outcome, and in each stage a linear kernel operation is used to further improve the accuracy of the learned classifier. Using a 10-fold cross validation strategy, the first stage in the connectome-based framework is able to separate patients with \\{TLE\\} from normal controls with 80% accuracy, and second stage in the connectome-based framework is able to correctly predict the surgical treatment outcome of patients with \\{TLE\\} with 70% accuracy. Compared to existing state-of-the-art methods that use \\{VBM\\} data, the proposed two-stage connectome-based prediction framework is a suitable alternative with comparable prediction performance. Our results additionally show that machine learning algorithms that exclusively use structural connectome data can predict treatment outcomes in epilepsy with similar accuracy compared with \u201cexpert-based\u201d clinical decision. In summary, using the unprecedented information provided in the brain connectome, machine learning algorithms may uncover pathological changes in brain network organization and improve outcome forecasting in the context of epilepsy.", 
        "author": "Brent C. Munsell and Chong-Yaw Wee and Simon S. Keller and Bernd Weber and Christian Elger and Laura Angelica Tomaz da Silva and Travis Nesland and Martin Styner and Dinggang Shen and Leonardo Bonilha", 
        "keyword": "Brain connectome\", \"Sparse machine learning\", \"Support vector machine (SVM)\", \"Temporal lobe keywords =pilepsy (TLE)\", \"Brain network analysis\", \"White matter fiber tractography\", \"Diffusion tensor imaging (DTI)", 
        "title": "Evaluation of machine learning algorithms for treatment outcome prediction in patients with epilepsy based on structural connectome data"
    }, 
    {
        "abstract": "Abstract Approaches using machine learning methods were investigated systematically to determine the internal quality parameters of Newhall navel oranges based on near infrared (NIR) spectroscopy. Each stage of the approach was investigated extensively and with full comparison. To ensure credibility and robustness, a much larger sample set than previous studies was obtained. Furthermore, the prediction performance of three kinds of \\{NIR\\} spectra (equatorial surface spectra, distal end surface spectra and juice spectra) were evaluated and compared. By using an optimal machine learning approach, all three kinds of spectra yielded promising results for quality measurements. The obtained results were better than that in most previous studies. The equatorial surface spectra performed slightly but consistently better than the distal end spectra. The juice spectra performed best in predicting most internal quality parameters. But in predicting the vitamin C content, the juice spectra performed worse than the surface spectra, which indicated that the prediction with \\{NIRS\\} might result from indirect factors.", 
        "author": "Cong Liu and Simon X. Yang and Lie Deng", 
        "keyword": "Near infrared spectroscopy\", \"Food quality\", \"Machine learning", 
        "title": "Determination of internal qualities of Newhall navel oranges based on \\{NIR\\} spectroscopy using machine learning"
    }, 
    {
        "abstract": "Abstract Bladder cancer is a common cancer in genitourinary malignancy. For muscle invasive bladder cancer, surgical removal of the bladder, i.e. radical cystectomy, is in general the definitive treatment which, unfortunately, carries significant morbidities and mortalities. Accurate prediction of the mortality of radical cystectomy is therefore needed. Statistical methods have conventionally been used for this purpose, despite the complex interactions of high-dimensional medical data. Machine learning has emerged as a promising technique for handling high-dimensional data, with increasing application in clinical decision support, e.g. cancer prediction and prognosis. Its ability to reveal the hidden nonlinear interactions and interpretable rules between dependent and independent variables is favorable for constructing models of effective generalization performance. In this paper, seven machine learning methods are utilized to predict the 5-year mortality of radical cystectomy, including back-propagation neural network (BPN), radial basis function (RBFN), extreme learning machine (ELM), regularized \\{ELM\\} (RELM), support vector machine (SVM), naive Bayes (NB) classifier and k-nearest neighbour (KNN), on a clinicopathological dataset of 117 patients of the urology unit of a hospital in Hong Kong. The experimental results indicate that \\{RELM\\} achieved the highest average prediction accuracy of 0.8 at a fast learning speed. The research findings demonstrate the potential of applying machine learning techniques to support clinical decision making.", 
        "author": "Guanjin Wang and Kin-Man Lam and Zhaohong Deng and Kup-Sze Choi", 
        "keyword": "Bladder cancer\", \"Radical cystectomy\", \"Mortality\", \"Prediction\", \"Prognosis\", \"Machine learning", 
        "title": "Prediction of mortality after radical cystectomy for bladder cancer by machine learning techniques"
    }, 
    {
        "abstract": "Abstract Online communities have become important places for users to exchange information and build knowledge. In these communities, people ask and answer questions, learn with each other, but some problems may occur such as not getting an answer or getting contradictory ones. In order to increase the responsiveness of the communities, it would be important to identify people who are willing to help and who provide good answers in such communities, whom we call reliable users. We investigated various components of online communities and users\u2019 attributes looking for a correlation between these characteristics and the users\u2019 reputation in these communities. After that, we proposed the usage of two machine learning techniques, artificial neural network and clustering algorithm, with the users\u2019 attributes for finding reliable sources. The results show that the usage of an artificial neural network is a good approach as around 90% of the users were correctly identified while the clustering algorithm makes to find groups of reliable users more easily.", 
        "author": "Thiago Baesso Procaci and Sean Wolfgand Matsui Siqueira and Maria Helena Lima Baptista Braz and Leila Cristina Vasconcelos de Andrade", 
        "keyword": "Collaborative learning\", \"Online communities\", \"Experts\", \"Reputation\", \"Bow Tie structure\", \"Machine learning", 
        "title": "How to find people who can help to answer a question? \u2013 Analyses of metrics and machine learning in online communities"
    }, 
    {
        "abstract": "Abstract Fuel efficient Homogeneous Charge Compression Ignition (HCCI) engine combustion timing predictions must contend with non-linear chemistry, non-linear physics, period doubling bifurcation(s), turbulent mixing, model parameters that can drift day-to-day, and air\u2013fuel mixture state information that cannot typically be resolved on a cycle-to-cycle basis, especially during transients. In previous work, an abstract cycle-to-cycle mapping function coupled with \u03f5 -Support Vector Regression was shown to predict experimentally observed cycle-to-cycle combustion timing over a wide range of engine conditions, despite some of the aforementioned difficulties. The main limitation of the previous approach was that a partially acasual randomly sampled training dataset was used to train proof of concept offline predictions. The objective of this paper is to address this limitation by proposing a new online adaptive Extreme Learning Machine (ELM) extension named Weighted Ring-ELM. This extension enables fully causal combustion timing predictions at randomly chosen engine set points, and is shown to achieve results that are as good as or better than the previous offline method. The broader objective of this approach is to enable a new class of real-time model predictive control strategies for high variability \\{HCCI\\} and, ultimately, to bring HCCI\u2019s low engine-out \\{NO\\} x and reduced \\{CO2\\} emissions to production engines.", 
        "author": "Adam Vaughan and Stanislav V. Bohac", 
        "keyword": "Non-linear\", \"Non-stationary\", \"Time series\", \"Chaos theory\", \"Dynamical system\", \"Adaptive extreme learning machine", 
        "title": "Real-time, adaptive machine learning for non-stationary, near chaotic gasoline engine combustion time series"
    }, 
    {
        "abstract": "AbstractIntroduction Predicting mortality from burn injury has traditionally employed logistic regression models. Alternative machine learning methods have been introduced in some areas of clinical prediction as the necessary software and computational facilities have become accessible. Here we compare logistic regression and machine learning predictions of mortality from burn. Methods An established logistic mortality model was compared to machine learning methods (artificial neural network, support vector machine, random forests and na\u00efve Bayes) using a population-based (England &amp; Wales) case-cohort registry. Predictive evaluation used: area under the receiver operating characteristic curve; sensitivity; specificity; positive predictive value and Youden's index. Results All methods had comparable discriminatory abilities, similar sensitivities, specificities and positive predictive values. Although some machine learning methods performed marginally better than logistic regression the differences were seldom statistically significant and clinically insubstantial. Random forests were marginally better for high positive predictive value and reasonable sensitivity. Neural networks yielded slightly better prediction overall. Logistic regression gives an optimal mix of performance and interpretability. Discussion The established logistic regression model of burn mortality performs well against more complex alternatives. Clinical prediction with a small set of strong, stable, independent predictors is unlikely to gain much from machine learning outside specialist research contexts.", 
        "author": "Neophytos Stylianou and Artur Akbarov and Evangelos Kontopantelis and Iain Buchan and Ken W. Dunn", 
        "keyword": "Machine learning\", \"Burn\", \"Mortality\", \"Clinical prediction", 
        "title": "Mortality risk prediction in burn injury: Comparison of logistic regression with machine learning approaches"
    }, 
    {
        "abstract": "Summary Selecting an adequate set of inputs is a critical step for successful data-driven streamflow prediction. In this study, we present a novel approach for Input Variable Selection (IVS) that employs Binary-coded discrete Fully Informed Particle Swarm optimization (BFIPS) and Extreme Learning Machines (ELM) to develop fast and accurate \\{IVS\\} algorithms. A scheme is employed to encode the subset of selected inputs and \\{ELM\\} specifications into the binary particles, which are evolved using single objective and multi-objective \\{BFIPS\\} optimization (MBFIPS). The performances of these ELM-based methods are assessed using the evaluation criteria and the datasets included in the comprehensive \\{IVS\\} evaluation framework proposed by Galelli et al. (2014). From a comparison with 4 major \\{IVS\\} techniques used in their original study it emerges that the proposed methods compare very well in terms of selection accuracy. The best performers were found to be (1) a MBFIPS\u2013ELM algorithm based on the concurrent minimization of an error function and the number of selected inputs, and (2) a BFIPS\u2013ELM algorithm based on the minimization of a variant of the Akaike Information Criterion (AIC). The first technique is arguably the most accurate overall, and is able to reach an almost perfect specification of the optimal input subset for a partially synthetic rainfall\u2013runoff experiment devised for the Kentucky River basin. In addition, MBFIPS\u2013ELM allows for the determination of the relative importance of the selected inputs. On the other hand, the BFIPS\u2013ELM is found to consistently reach high accuracy scores while being considerably faster. By extrapolating the results obtained on the \\{IVS\\} test-bed, it can be concluded that the proposed techniques are particularly suited for rainfall\u2013runoff modeling applications characterized by high nonlinearity in the catchment dynamics.", 
        "author": "Riccardo Taormina and Kwok-Wing Chau", 
        "keyword": "Input variable selection\", \"Streamflow prediction\", \"Rainfall\u2013runoff\", \"Particle swarm keywords =ptimization\", \"Multi-objective optimization\", \"Extreme Learning Machines", 
        "title": "Data-driven input variable selection for rainfall\u2013runoff modeling using binary-coded particle swarm optimization and Extreme Learning Machines"
    }, 
    {
        "abstract": "Abstract We study a two-agent scheduling problem in a two-machine permutation flowshop with learning effects. The objective is to minimize the total completion time of the jobs from one agent, given that the maximum tardiness of the jobs from the other agent cannot exceed a bound. We provide a branch-and-bound algorithm for the problem. In addition, we present several genetic algorithms to obtain near-optimal solutions. Computational results indicate that the algorithms perform well in either solving the problem or efficiently generating near-optimal solutions.", 
        "author": "Yau-Ren Shiau and Ming-Shua Tsai and Wen-Chiung Lee and T.C.E. Cheng", 
        "keyword": "Scheduling\", \"Total completion time\", \"Two agent\", \"Two-machine flowshop\", \"Learning effects", 
        "title": "Two-agent two-machine flowshop scheduling with learning effects to minimize the total completion time"
    }, 
    {
        "abstract": "Abstract This paper proposes an effective Multiple Matrix Learning Machine with Five Aspects of Pattern Information (MMFI). First aspect lies in the class label of each training or validation pattern. Second aspect is the values of components for each pattern. Third aspect is the relationship between patterns in the local regions of input space. Fourth aspect is the representation information and discriminant roles of different matrix representations for patterns. Fifth aspect is the information of patterns in each matrix representation learning. The innovations of the proposed \\{MMFI\\} are: (1) establishing a pattern-dependent function in the matrix learning so as to realize different roles of patterns for the first time; (2) adopting five aspects of pattern information so that a more feasible learning machine can be trained. The advantages of \\{MMFI\\} are: (1) proposing a new nonlinear learning machine which is different from the state-of-the-art kernelization one; (2) achieving a statistically superior classification performance than those learning machines without the introduction of five aspects of pattern information; (3) possessing a lower or comparable computational-complexity than other compared multiple matrix learning machines.", 
        "author": "Changming Zhu and Daqi Gao", 
        "keyword": "Cluster structure\", \"Gating model\", \"Multiple matrix learning machine\", \"Pattern information\", \"Matrix representation", 
        "title": "Multiple Matrix Learning Machine with Five Aspects of Pattern Information"
    }, 
    {
        "abstract": "Abstract The surface piercing and floating coastal defense structures can be applied as an alternative to conventional rubble mound structures in some specific circumstances. A partially submerged steeply inclined thin plate (ITP) is also one of the candidate alternative structures. Knowledge about the wave attenuation mechanism of \\{ITP\\} improves the engineer's ability to make more cost-effective design. From this motivation, the mechanism of \\{ITP\\} was modeled by artificial neural networks based on experimental data. It is particularly aimed to reveal some fundamental facts about the attenuation mechanism of ITP, which could not be previously attained solely by the conventional analysis of the relevant experimental data. Surface plots, which depict the relationships between the governing design variables were generated from the developed model. In this way, the influence of each individual parameter on the performance was decomposed in a more precise way. Based on the data-driven model outputs, it was inferred that the most dominant design variable is the wavelength. The \\{ITP\\} performance is enhanced with increasing submergence degree, an effect that becomes even more pronounced in severe wave climate conditions. In such wave conditions, decreasing inclination angles also improve the functionality of the structure. However, the generated data-driven model indicated that the combination of the examined variables can have a more complicated effect on the \\{ITP\\} performance, especially for the longer wave lengths.", 
        "author": "Oral Yagci and Vasileios Kitsikoudis", 
        "keyword": "Artificial neural networks\", \"Breakwater\", \"Inclined thin plate\", \"Machine learning\", \"Regular keywords =ave\", \"Wave attenuation", 
        "title": "Machine learning based mapping of the wave attenuation mechanism of an inclined thin plate"
    }, 
    {
        "abstract": "AbstractBackground Pre-deployment identification of soldiers at risk for long-term posttraumatic stress psychopathology after home coming is important to guide decisions about deployment. Early post-deployment identification can direct early interventions to those in need and thereby prevents the development of chronic psychopathology. Both hold significant public health benefits given large numbers of deployed soldiers, but has so far not been achieved. Here, we aim to assess the potential for pre- and early post-deployment prediction of resilience or posttraumatic stress development in soldiers by application of machine learning (ML) methods. Methods \\{ML\\} feature selection and prediction algorithms were applied to a prospective cohort of 561 Danish soldiers deployed to Afghanistan in 2009 to identify unique risk indicators and forecast long-term posttraumatic stress responses. Results Robust pre- and early postdeployment risk indicators were identified, and included individual \\{PTSD\\} symptoms as well as total level of \\{PTSD\\} symptoms, previous trauma and treatment, negative emotions, and thought suppression. The predictive performance of these risk indicators combined was assessed by cross-validation. Together, these indicators forecasted long term posttraumatic stress responses with high accuracy (pre-deployment: AUC=0.84 (95% CI=0.81\u20130.87), post-deployment: AUC=0.88 (95% CI=0.85\u20130.91)). Limitations This study utilized a previously collected data set and was therefore not designed to exhaust the potential of \\{ML\\} methods. Further, the study relied solely on self-reported measures. Conclusions Pre-deployment and early post-deployment identification of risk for long-term posttraumatic psychopathology are feasible and could greatly reduce the public health costs of war.", 
        "author": "Karen-Inge Karstoft and Alexander Statnikov and S\u00f8ren B. Andersen and Trine Madsen and Isaac R. Galatzer-Levy", 
        "keyword": "Posttraumatic stress\", \"Military\", \"Prediction\", \"Prevention\", \"Machine learning\", \"Support vector machines", 
        "title": "Early identification of posttraumatic stress following military deployment: Application of machine learning methods to a prospective study of Danish soldiers"
    }, 
    {
        "abstract": "Abstract Several magnetic resonance techniques have been proposed as non-invasive imaging biomarkers for the evaluation of disease progression and early diagnosis of Alzheimer\u2019s Disease (AD). This work is the first application of the Proton Magnetic Resonance Spectroscopy 1H-MRS data and machine-learning techniques to the classification of AD. A gender-matched cohort of 260 subjects aged between 57 and 99 years from the Alzheimer\u2019s Disease Research Unit, of the Fundaci\u00f3n CIEN-Fundaci\u00f3n Reina Sof\u00eda has been used. A single-layer perceptron was found for \\{AD\\} prediction with only two spectroscopic voxel volumes (Tvol and CSFvol) in the left hippocampus, with an \\{AUROC\\} value of 0.866 (with \\{TPR\\} 0.812 and \\{FPR\\} 0.204) in a filter feature selection approach. These results suggest that knowing the composition of white and grey matter and cerebrospinal fluid of the spectroscopic voxel is essential in a 1H-MRS study to improve the accuracy of the quantifications and classifications, particularly in those studies involving elder patients and neurodegenerative diseases.", 
        "author": "Cristian R. Munteanu and Carlos Fernandez-Lozano and Virginia Mato Abad and Salvador Pita Fern\u00e1ndez and Juan \u00c1lvarez-Linera and Juan Antonio Hern\u00e1ndez-Tamames and Alejandro Pazos", 
        "keyword": "Magnetic Resonance Spectroscopy\", \"Metabolite\", \"Alzheimer\u2019s Disease\", \"Machine learning\", \"Single-layer perceptron", 
        "title": "Classification of mild cognitive impairment and Alzheimer\u2019s Disease with machine-learning techniques using 1H Magnetic Resonance Spectroscopy data"
    }, 
    {
        "abstract": "Abstract Although activity recognition is an emerging general area of research in computer science, its potential in construction engineering and management (CEM) domain has not yet been fully investigated. Due to the complex and dynamic nature of many construction and infrastructure projects, the ability to detect and classify key activities performed in the field by various equipment and human crew can improve the quality and reliability of project decision-making and control. In particular to simulation modeling, process-level knowledge obtained as a result of activity recognition can help verify and update the input parameters of simulation models. Such input parameters include but are not limited to activity durations and precedence, resource flows, and site layout. The goal of this research is to investigate the prospect of using built-in smartphone sensors as ubiquitous multi-modal data collection and transmission nodes in order to detect detailed construction equipment activities which can ultimately contribute to the process of simulation input modeling. A case study of front-end loader activity recognition is presented to describe the methodology for action recognition and evaluate the performance of the developed system. In the designed methodology, certain key features are extracted from the collected data using accelerometer and gyroscope sensors, and a subset of the extracted features is used to train supervised machine learning classifiers. In doing so, several important technical details such as selection of discriminating features to extract, sensitivity analysis of data segmentation window size, and choice of the classifier to be trained are investigated. It is shown that the choice of the level of detail (LoD) in describing equipment actions (classes) is an important factor with major impact on the classification performance. Results also indicate that although decreasing the number of classes generally improves the classification output, considering other factors such as actions to be combined as a single activity, methodologies to extract knowledge from classified activities, computational efficiency, and end use of the classification process may as well influence one\u2019s decision in selecting an optimal LoD in describing equipment activities (classes).", 
        "author": "Reza Akhavian and Amir H. Behzadan", 
        "keyword": "Construction equipment action recognition\", \"Smartphone sensors\", \"Accelerometer\", \"Data-driven keywords =imulation\", \"Supervised machine learning\", \"Big data analytics", 
        "title": "Construction equipment activity recognition for simulation input modeling using mobile sensors and machine learning classifiers"
    }, 
    {
        "abstract": "AbstractBackground and objective Understanding the causes of disagreement among experts in clinical decision making has been a challenge for decades. In particular, a high amount of variability exists in diagnosis of retinopathy of prematurity (ROP), which is a disease affecting low birth weight infants and a major cause of childhood blindness. A possible cause of variability, that has been mostly neglected in the literature, is related to discrepancies in the sets of important features considered by different experts. In this paper we propose a methodology which makes use of machine learning techniques to understand the underlying causes of inter-expert variability. Methods The experiments are carried out on a dataset consisting of 34 retinal images, each with diagnoses provided by 22 independent experts. Feature selection techniques are applied to discover the most important features considered by a given expert. Those features selected by each expert are then compared to the features selected by other experts by applying similarity measures. Finally, an automated diagnosis system is built in order to check if this approach can be helpful in solving the problem of understanding high inter-rater variability. Results The experimental results reveal that some features are mostly selected by the feature selection methods regardless the considered expert. Moreover, for pairs of experts with high percentage agreement among them, the feature selection algorithms also select similar features. By using the relevant selected features, the classification performance of the automatic system was improved or maintained. Conclusions The proposed methodology provides a handy framework to identify important features for experts and check whether the selected features reflect the pairwise agreements/disagreements. These findings may lead to improved diagnostic accuracy and standardization among clinicians, and pave the way for the application of this methodology to other problems which present inter-expert variability.", 
        "author": "V. Bol\u00f3n-Canedo and E. Ataer-Cansizoglu and D. Erdogmus and J. Kalpathy-Cramer and O. Fontenla-Romero and A. Alonso-Betanzos and M.F. Chiang", 
        "keyword": "Inter-expert variability\", \"Clinical decision-making\", \"Feature selection\", \"Machine learning\", keywords =Classification\", \"Retinopathy of prematurity", 
        "title": "Dealing with inter-expert variability in retinopathy of prematurity: A machine learning approach"
    }, 
    {
        "abstract": "Abstract In this paper, a robust hybrid model integrating an enhanced inputs based extreme learning machine with the partial least square regression (PLSR-EIELM) was proposed. The proposed PLSR-EIELM model can overcome two main flaws in the extreme learning machine (ELM), i.e. the intractable problem in determining the optimal number of the hidden layer neurons and the over-fitting phenomenon. First, a traditional extreme learning machine (ELM) is selected. Second, a method of randomly assigning is applied to the weights between the input layer and the hidden layer, and then the nonlinear transformation for independent variables can be obtained from the output of the hidden layer neurons. Especially, the original input variables are regarded as enhanced inputs; then the enhanced inputs and the nonlinear transformed variables are tied together as the whole independent variables. In this way, the \\{PLSR\\} can be carried out to identify the \\{PLS\\} components not only from the nonlinear transformed variables but also from the original input variables, which can remove the correlation among the whole independent variables and the expected outputs. Finally, the optimal relationship model of the whole independent variables with the expected outputs can be achieved by using PLSR. Thus, the PLSR-EIELM model is developed. Then the PLSR-EIELM model served as an intelligent measurement tool for the key variables of the Purified Terephthalic Acid (PTA) process and the High Density Polyethylene (HDPE) process. The experimental results show that the predictive accuracy of PLSR-EIELM is stable, which indicate that PLSR-EIELM has good robust character. Moreover, compared with ELM, PLSR, hierarchical \\{ELM\\} (HELM), and PLSR-ELM, PLSR-EIELM can achieve much smaller predicted relative errors in these two applications.", 
        "author": "Yan-Lin He and Zhi-Qiang Geng and Yuan Xu and Qun-Xiong Zhu", 
        "keyword": "Extreme learning machine\", \"Partial least square regression\", \"Intelligent measurement\", \"Enhanced inputs", 
        "title": "A robust hybrid model integrating enhanced inputs based extreme learning machine with \\{PLSR\\} (PLSR-EIELM) and its application to intelligent measurement"
    }, 
    {
        "abstract": "Abstract The deluge of multi-dimensional data acquired from advanced data acquisition tools requires sophisticated algorithms to extract useful knowledge from such data. Traditionally, petroleum and natural gas engineers rely on \u201crules-of-thumb\u201d in the selection of optimal features with much disregard to the hidden patterns in operational data. The traditional multivariate method of feature selection has become grossly inadequate as it is incapable of handling the non-linearity embedded in such natural phenomena. With the application of computational intelligence and its hybrid techniques in the petroleum industry, much improvement has been made. However, they are still incapable of handling more than one hypothesis at a time. Ensemble learning offers robust methodologies to handle the uncertainties in most complex industrial problems. This learning paradigm has not been well embraced in petroleum reservoir characterization despite the persistent quest for increased prediction accuracy. This paper proposes a novel ensemble model of Extreme Learning Machine (ELM) in the prediction of reservoir properties while utilizing the non-linear approximation capability of Functional Networks to select the optimal input features. Different instances of \\{ELM\\} were fed with features selected from different bootstrap samplings of the real-life field datasets. When benchmarked against existing techniques, our proposed ensemble model outperformed the multivariate regression-based feature selection, the conventional bagging and the Random Forest methods with higher correlation coefficient and lower prediction errors. This work confirms the huge potential in the capability of the new ensemble modeling paradigm to improve the prediction of reservoir properties.", 
        "author": "Fatai Adesina Anifowose and Jane Labadin and Abdulazeez Abdulraheem", 
        "keyword": "Reservoir characterization\", \"Porosity and permeability\", \"Feature selection\", \"Ensemble machine keywords =earning\", \"Extreme Learning Machine", 
        "title": "Ensemble model of non-linear feature selection-based Extreme Learning Machine for improved natural gas reservoir characterization"
    }, 
    {
        "abstract": null, 
        "author": "Conrad S. Tucker and Ishan Behoora and Harriet Black Nembhard and Mechelle Lewis and Nicholas W. Sterling and Xuemei Huang", 
        "keyword": "Parkinson's disease (PD) diagnosis\", \"Smart healthcare system\", \"Machine learning\", \"Healthcare keywords =ata\", \"Multimodal sensor\", \"Healthcare delivery\", \"Decision support system\", \"Medication adherence", 
        "title": "Machine learning classification of medication adherence in patients with movement disorders using non-wearable sensors"
    }, 
    {
        "abstract": "Abstract Wave parameters computed from time series measured by buoys (significant wave height Hs, mean wave period, etc.) play a key role in coastal engineering and in the design and operation of wave energy converters. Storms or navigation accidents can make measuring buoys break down, leading to missing data gaps. In this paper we tackle the problem of locally reconstructing Hs at out-of-operation buoys by using wave parameters from nearby buoys, based on the spatial correlation among values at neighboring buoy locations. The novelty of our approach for its potential application to problems in coastal engineering is twofold. On one hand, we propose a genetic algorithm hybridized with an extreme learning machine that selects, among the available wave parameters from the nearby buoys, a subset F n S P with nSP parameters that minimizes the Hs reconstruction error. On the other hand, we evaluate to what extent the selected parameters in subset F n S P are good enough in assisting other machine learning (ML) regressors (extreme learning machines, support vector machines and gaussian process regression) to reconstruct Hs. The results show that all the \\{ML\\} method explored achieve a good Hs reconstruction in the two different locations studied (Caribbean Sea and West Atlantic).", 
        "author": "E. Alexandre and L. Cuadra and J.C. Nieto-Borge and G. Candil-Garc\u00eda and M. del Pino and S. Salcedo-Sanz", 
        "keyword": "Significant wave height local reconstruction\", \"Extreme learning machines\", \"Support vector keywords =egression\", \"Gaussian process regression\", \"Genetic algorithm", 
        "title": "A hybrid genetic algorithm\u2014extreme learning machine approach for accurate significant wave height reconstruction"
    }, 
    {
        "abstract": "Abstract Realization of accurate wind speed forecasting is important to guarantee the safety of wind power utilization. In this paper, a new hybrid forecasting architecture is proposed to realize the wind speed accurate forecasting. In this architecture, four different hybrid models are presented by combining four signal decomposing algorithms (e.g., Wavelet Decomposition/Wavelet Packet Decomposition/Empirical Mode Decomposition/Fast Ensemble Empirical Mode Decomposition) and Extreme Learning Machines. The originality of the study is to investigate the promoted percentages of the Extreme Learning Machines by those mainstream signal decomposing algorithms in the multiple step wind speed forecasting. The results of two forecasting experiments indicate that: (1) the method of Extreme Learning Machines is suitable for the wind speed forecasting; (2) by utilizing the decomposing algorithms, all the proposed hybrid algorithms have better performance than the single Extreme Learning Machines; (3) in the comparisons of the decomposing algorithms in the proposed hybrid architecture, the Fast Ensemble Empirical Mode Decomposition has the best performance in the three-step forecasting results while the Wavelet Packet Decomposition has the best performance in the one and two step forecasting results. At the same time, the Wavelet Packet Decomposition and the Fast Ensemble Empirical Mode Decomposition are better than the Wavelet Decomposition and the Empirical Mode Decomposition in all the step predictions, respectively; and (4) the proposed algorithms are effective in the wind speed accurate predictions.", 
        "author": "Hui Liu and Hong-qi Tian and Yan-fei Li", 
        "keyword": "Wind energy\", \"Wind speed forecasting\", \"Wind speed decomposition\", \"Wavelet\", \"Extreme learning keywords =achines\", \"Empirical mode decomposition", 
        "title": "Four wind speed multi-step forecasting models using extreme learning machines and signal decomposing algorithms"
    }, 
    {
        "abstract": "Abstract As global solar radiation forecasting is a very important challenge, several methods are devoted to this goal with different levels of accuracy and confidence. In this study we propose to better understand how the uncertainty is propagated in the context of global radiation time series forecasting using machine learning. Indeed we propose to decompose the error considering four kinds of uncertainties: the error due to the measurement, the variability of time series, the machine learning uncertainty and the error related to the horizon. All these components of the error allow to determinate a global uncertainty generating prediction bands related to the prediction efficiency. We also have defined a reliability index which could be very interesting for the grid manager in order to estimate the validity of predictions. We have experimented this method on a multilayer perceptron which is a popular machine learning technique. We have shown that the global error and its components are essential to quantify in order to estimate the reliability of the model outputs. The described method has been successfully applied to four meteorological stations in Mediterranean area.", 
        "author": "Cyril Voyant and Gilles Notton and Christophe Darras and Alexis Fouilloy and Fabrice Motte", 
        "keyword": "Time series forecasting\", \"Processing\", \"Artificial neural networks\", \"Interval\", \"Energy keywords =rediction\", \"Stationarity", 
        "title": "Uncertainties in global radiation time series forecasting using machine learning: The multilayer perceptron case"
    }, 
    {
        "abstract": "Abstract With the recent advancement in microfluidics based lab-on-a-chip technology, lensless imaging system integrating microfluidic channel with \\{CMOS\\} image sensor has become a promising solution for the system minimization of flow cytometer. The design challenge for such an imaging-based micro-flow cytometer under poor resolution is how to recover cell recognition error under various flow rates. A microfluidic lensless imaging system is developed in this paper using extreme-learning-machine enhanced single-frame super-resolution processing, which can effectively recover the recognition error when increasing flow rate for throughput. As shown in the experiments, with mixed flowing HepG2 and Huh7 cells as inputs, the developed scheme shows that 23% better recognition accuracy can be achieved compared to the one without error recovery. Meanwhile, it also achieves an average of 98.5% resource saving compared to the previous multi-frame super-resolution processing.", 
        "author": "Xiwei Huang and Xiaolong Wang and Mei Yan and Hao Yu", 
        "keyword": "Microfluidic lensless imaging\", \"Recognition error control\", \"Single-frame super-resolution keywords =rocessing\", \"Extreme learning machine", 
        "title": "A robust recognition error recovery for micro-flow cytometer by machine-learning enhanced single-frame super-resolution processing"
    }, 
    {
        "abstract": "AbstractBackground Depression is frequent in panic disorder (PD); yet, little is known about its influence on the neural substrates of PD. Difficulties in fear inhibition during safety signal processing have been reported as a pathophysiological feature of \\{PD\\} that is attenuated by depression. We investigated the impact of comorbid depression in \\{PD\\} with agoraphobia (AG) on the neural correlates of fear conditioning and the potential of machine learning to predict comorbidity status on the individual patient level based on neural characteristics. Methods Fifty-nine PD/AG patients including 26 (44%) with a comorbid depressive disorder (PD/AG+DEP) underwent functional magnetic resonance imaging (fMRI). Comorbidity status was predicted using a random undersampling tree ensemble in a leave-one-out cross-validation framework. Results PD/AG\u2212DEP patients showed altered neural activation during safety signal processing, while +DEP patients exhibited generally decreased dorsolateral prefrontal and insular activation. Comorbidity status was correctly predicted in 79% of patients (sensitivity: 73%; specificity: 85%) based on brain activation during fear conditioning (corrected for potential confounders: accuracy: 73%; sensitivity: 77%; specificity: 70%). Limitations No primary depressed patients were available; only medication-free patients were included. Major depression and dysthymia were collapsed (power considerations). Conclusions Neurofunctional activation during safety signal processing differed between patients with or without comorbid depression, a finding which may explain heterogeneous results across previous studies. These findings demonstrate the relevance of comorbidity when investigating neurofunctional substrates of anxiety disorders. Predicting individual comorbidity status may translate neurofunctional data into clinically relevant information which might aid in planning individualized treatment. The study was registered with the ISRCTN: ISRCTN80046034.", 
        "author": "Ulrike Lueken and Benjamin Straube and Yunbo Yang and Tim Hahn and Katja Beesdo-Baum and Hans-Ulrich Wittchen and Carsten Konrad and Andreas Str\u00f6hle and Andr\u00e9 Wittmann and Alexander L. Gerlach and Bettina Pfleiderer and Volker Arolt and Tilo Kircher", 
        "keyword": "Panic disorder\", \"Depression\", \"fMRI\", \"Machine learning\", \"Fear conditioning\", \"Amygdala", 
        "title": "Separating depressive comorbidity from panic disorder: A combined functional magnetic resonance imaging and machine learning approach"
    }, 
    {
        "abstract": "Abstract This paper presents an identifying function (IF) approach for determining parameter structure of statistical learning machines (SLMs). This involves studying three related aspects: structural identifiability (SI), parameter redundancy (PR) and reparameterization. Firstly, by employing the Rank Theorem in Riemann geometry, we derive an efficient identifiability criterion by calculating the rank of the derivative matrix (DM) of IF. Secondly, we extend the previous concept of \\{IF\\} to local \\{IF\\} (LIF) for examining local parameter structure of SLMs, and prove that the Kullback\u2013Leibler divergence (KLD) is such a proper LIF, thus relating the \\{LIF\\} approach to several existing criteria. Lastly, an analytical approach for solving minimal reparameterization in parameter-redundant models is established. The dimensionality of the minimal reparameterization can be used to characterize the intrinsic parameter dimensionality of model. We compare the \\{IF\\} approach with existing criteria and discuss its pros/cons from theoretical and application viewpoints. Several model examples from the literature are presented to study their parameter structure.", 
        "author": "Zhi-Yong Ran and Bao-Gang Hu", 
        "keyword": "Identifying function\", \"Structural identifiability\", \"Statistical learning machine\", keywords =Kullback\u2013Leibler divergence\", \"Parameter redundancy\", \"Reparameterization", 
        "title": "An identifying function approach for determining parameter structure of statistical learning machines"
    }, 
    {
        "abstract": "Abstract There has been significant recent interest in sensing systems and \u2018smart environments\u2019, with a number of longitudinal studies in this area. Typically the goal of these studies is to develop methods to predict, at any one moment of time, the activity or activities that the resident(s) of the home are engaged in, which may in turn be used for determining normal or abnormal patterns of behaviour (e.g. in a health-care setting). Classification algorithms, such as Conditional Random Field (CRFs), typically consider sensor activations as features but these are often treated as if they were independent, which in general they are not. Our hypothesis is that learning patterns based on combinations of sensors will be more powerful than single sensors alone. The exhaustive approach \u2013 to take all possible combinations of sensors and learn classifier weights for each combination \u2013 is clearly computationally prohibitive. We show that through the application of signal processing and information-theoretic techniques we can learn about the sensor topology in the home (i.e. learn an adjacency matrix) which enables us to determine the combinations of sensors that will be useful for classification ahead of time. As a result we can achieve classification performance better than that of the exhaustive approach, whilst only incurring a small cost in terms of computational resources. We demonstrate our results on several datasets, showing that our method is robust in terms of variations in the layout and the number of residents in the house. Furthermore, we have incorporated the adjacency matrix into the \\{CRF\\} learning framework and have shown that it can improve performance over multiple baselines.", 
        "author": "Niall Twomey and Tom Diethe and Ian Craddock and Peter Flach", 
        "keyword": "Machine learning\", \"Digital signal processing\", \"Smart homes\", \"Activity recognition\", \"Activities keywords =f daily life\", \"Unsupervised learning\", \"Meta learning", 
        "title": "Unsupervised learning of sensor topologies for improving activity recognition in smart environments"
    }, 
    {
        "abstract": "Abstract The dew point temperature is a significant element particularly required in various hydrological, climatological and agronomical related researches. This study proposes an extreme learning machine (ELM)-based model for prediction of daily dew point temperature. As case studies, daily averaged measured weather data collected for two Iranian stations of Bandar Abass and Tabass, which enjoy different climate conditions, were used. The merit of the \\{ELM\\} model is evaluated against support vector machine (SVM) and artificial neural network (ANN) techniques. The findings from this research work demonstrate that the proposed \\{ELM\\} model enjoys much greater prediction capability than the \\{SVM\\} and \\{ANN\\} models so that it is capable of predicting daily dew point temperature with very favorable accuracy. For Tabass station, the mean absolute bias error (MABE), root mean square error (RMSE) and correlation coefficient (R) achieved for the \\{ELM\\} model are 0.3240 \u00b0C, 0.5662 \u00b0C and 0.9933, respectively, while for the \\{SVM\\} model the values are 0.7561 \u00b0C, 1.0086 \u00b0C and 0.9784, respectively and for the \\{ANN\\} model are 1.0324 \u00b0C, 1.2589 \u00b0C and 0.9663, respectively. For Bandar Abass station, the MABE, \\{RMSE\\} and R for the \\{ELM\\} model are 0.5203 \u00b0C, 0.6709 \u00b0C and 0.9877, respectively whereas for the \\{SVM\\} model the values are 1.0413 \u00b0C, 1.2105 \u00b0C and 0.9733, and for the \\{ANN\\} model are 1.3205 \u00b0C, 1.5530 \u00b0C and 0.9617, respectively. The study results convincingly advocate that \\{ELM\\} can be employed as an efficient method to predict daily dew point temperature with much higher precision than the \\{SVM\\} and \\{ANN\\} techniques.", 
        "author": "Kasra Mohammadi and Shahaboddin Shamshirband and Shervin Motamedi and Dalibor Petkovi\u0107 and Roslan Hashim and Milan Gocic", 
        "keyword": "Dew point temperature\", \"Extreme learning machine (ELM)\", \"Prediction", 
        "title": "Extreme learning machine based prediction of daily dew point temperature"
    }, 
    {
        "abstract": "Abstract Advances in automatic text classification have been necessitated by the rapid increase in the availability of digital documents. Machine learning (ML) algorithms can \u2018learn\u2019 from data: for instance a \\{ML\\} system can be trained on a set of features derived from written texts belonging to known categories, and learn to distinguish between them. Such a trained system can then be used to classify unseen texts. In this paper, we explore the potential of the technique to classify transcribed speech samples along clinical dimensions, using vocabulary data alone. We report the accuracy with which two related \\{ML\\} algorithms [naive Bayes Gaussian (NBG) and naive Bayes multinomial (NBM)] categorized picture descriptions produced by: 32 semantic dementia (SD) patients versus 10 healthy, age-matched controls; and \\{SD\\} patients with left- (n\u00a0=\u00a021) versus right-predominant (n\u00a0=\u00a011) patterns of temporal lobe atrophy. We used information gain (IG) to identify the vocabulary features that were most informative to each of these two distinctions. In the \\{SD\\} versus control classification task, both algorithms achieved accuracies of greater than 90%. In the right- versus left-temporal lobe predominant classification, \\{NBM\\} achieved a high level of accuracy (88%), but this was achieved by both \\{NBM\\} and \\{NBG\\} when the features used in the training set were restricted to those with high values of IG. The most informative features for the patient versus control task were low frequency content words, generic terms and components of metanarrative statements. For the right versus left task the number of informative lexical features was too small to support any specific inferences. An enriched feature set, including values derived from Quantitative Production Analysis (QPA) may shed further light on this little understood distinction.", 
        "author": "Peter Garrard and Vassiliki Rentoumi and Benno Gesierich and Bruce Miller and Maria Luisa Gorno-Tempini", 
        "keyword": "Semantic dementia\", \"Discourse\", \"Laterality\", \"Machine learning\", \"Information gain", 
        "title": "Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse"
    }, 
    {
        "abstract": "Abstract A classification scheme based on extreme learning machine and k nearest neighbor is proposed for cloud classification. In this work, 21 characteristic parameters of texture features, color features and shape features are selected from four different sky conditions (cumulus, stratus, cirrus and clear sky) for classification. The results show that the new scheme using texture features, color features and shape features together can get better performance than using these features alone or any two of them together. When all 21 features are used for classification, the accurate identification rates of cumulus, stratus, cirrus and clear sky are 84.56%, 78.06%, 76.67% and 100.00% respectively, with an average of 84.82%. The proposed model can benefit from the merits of the k-nearest neighbor and the extreme learning machine through its novel structure with high robustness particularly for cloud classification. The simulation results demonstrate that the proposed model in this work is practical for cloud classification and outperforms extreme learning machine (ELM) models, artificial neural network (ANN), k-nearest neighbor (KNN), hybrid method based on \\{KNN\\} and \\{ANN\\} ( \\{KNN\\} \u2013 \\{ANN\\} ), and support vector machine (SVM).", 
        "author": "Min Xia and Weitao Lu and Jun Yang and Ying Ma and Wen Yao and Zichen Zheng", 
        "keyword": "Cloud classification\", \"Extreme learning machine\", \"Sky cloud image\", \"Cloud detection\", \"k Nearest neighbor", 
        "title": "A hybrid method based on extreme learning machine and k-nearest neighbor for cloud classification of ground-based visible cloud image"
    }, 
    {
        "abstract": "Abstract Statistical and now machine learning prediction methods have been gaining popularity in the field of landslide susceptibility modeling. Particularly, these data driven approaches show promise when tackling the challenge of mapping landslide prone areas for large regions, which may not have sufficient geotechnical data to conduct physically-based methods. Currently, there is no best method for empirical susceptibility modeling. Therefore, this study presents a comparison of traditional statistical and novel machine learning models applied for regional scale landslide susceptibility modeling. These methods were evaluated by spatial k-fold cross-validation estimation of the predictive performance, assessment of variable importance for gaining insights into model behavior and by the appearance of the prediction (i.e. susceptibility) map. The modeling techniques applied were logistic regression (GLM), generalized additive models (GAM), weights of evidence (WOE), the support vector machine (SVM), random forest classification (RF), and bootstrap aggregated classification trees (bundling) with penalized discriminant analysis (BPLDA). These modeling methods were tested for three areas in the province of Lower Austria, Austria. The areas are characterized by different geological and morphological settings. Random forest and bundling classification techniques had the overall best predictive performances. However, the performances of all modeling techniques were for the majority not significantly different from each other; depending on the areas of interest, the overall median estimated area under the receiver operating characteristic curve (AUROC) differences ranged from 2.9 to 8.9 percentage points. The overall median estimated true positive rate (TPR) measured at a 10% false positive rate (FPR) differences ranged from 11 to 15pp. The relative importance of each predictor was generally different between the modeling methods. However, slope angle, surface roughness and plan curvature were consistently highly ranked variables. The prediction methods that create splits in the predictors (RF, \\{BPLDA\\} and WOE) resulted in heterogeneous prediction maps full of spatial artifacts. In contrast, the GAM, \\{GLM\\} and \\{SVM\\} produced smooth prediction surfaces. Overall, it is suggested that the framework of this model evaluation approach can be applied to assist in selection of a suitable landslide susceptibility modeling technique.", 
        "author": "J.N. Goetz and A. Brenning and H. Petschko and P. Leopold", 
        "keyword": "Statistical and machine learning techniques\", \"Landslide susceptibility modeling\", \"Spatial keywords =ross-validation\", \"Variable importance", 
        "title": "Evaluating machine learning and statistical prediction techniques for landslide susceptibility modeling"
    }, 
    {
        "abstract": "Abstract Aiming at reducing the total cost in cost-sensitive learning, this paper introduces a semi-supervised learning model based on uncertainty of sample outputs. Its central idea is (1) to categorize the samples which are not in training set into several groups based on the uncertainty-magnitude of their outputs, (2) to add the group of samples which have the least uncertainty together with their predicted labels in the original training set, and (3) to retain a new classifier for total cost reduction. The ratio of costs between classes and its impact on learning system improvement is discussed. Theoretical analysis and experimental demonstration show that the model can effectively improve the performance of a cost-sensitive learning algorithm for a certain type of classifiers.", 
        "author": "Hongyu Zhu and Xizhao Wang", 
        "keyword": "Uncertainty\", \"Cost-sensitive\", \"Semi-supervised learning\", \"Sample selection\", \"Extreme learning machine", 
        "title": "A cost-sensitive semi-supervised learning model based on uncertainty"
    }, 
    {
        "abstract": "Abstract In-silico methods have been explored as potential tools for assessing \\{ADME\\} and \\{ADME\\} regulatory properties particularly in early drug discovery stages. Machine learning methods, with their ability in classifying diverse structures and complex mechanisms, are well suited for predicting \\{ADME\\} and \\{ADME\\} regulatory properties. Recent efforts have been directed at the broadening of application scopes and the improvement of predictive performance with particular focuses on the coverage of \\{ADME\\} properties, and exploration of more diversified training data, appropriate molecular features, and consensus modeling. Moreover, several online machine learning \\{ADME\\} prediction servers have emerged. Here we review these progresses and discuss the performances, application prospects and challenges of exploring machine learning methods as useful tools in predicting \\{ADME\\} and \\{ADME\\} regulatory properties.", 
        "author": "L. Tao and P. Zhang and C. Qin and S.Y. Chen and C. Zhang and Z. Chen and F. Zhu and S.Y. Yang and Y.Q. Wei and Y.Z. Chen", 
        "keyword": "ADME\", \"Absorption\", \"Distribution\", \"Metabolism\", \"Excretion\", \"Drug discovery\", \"Machine keywords =earning\", \"Molecular descriptors\", \"QSAR", 
        "title": "Recent progresses in the exploration of machine learning methods as in-silico \\{ADME\\} prediction tools"
    }, 
    {
        "abstract": "Abstract Recent research has repeatedly shown that machine learning techniques can be applied to either whole files or file fragments to classify them for analysis. We build upon these techniques to show that for samples of un-labeled compiled computer object code, one can apply the same type of analysis to classify important aspects of the code, such as its target architecture and endianess. We show that using simple byte-value histograms we retain enough information about the opcodes within a sample to classify the target architecture with high accuracy, and then discuss heuristic-based features that exploit information within the operands to determine endianess. We introduce a dataset with over 16000 code samples from 20 architectures and experimentally show that by using our features, classifiers can achieve very high accuracy with relatively small sample sizes.", 
        "author": "John Clemens", 
        "keyword": "Machine learning\", \"Classification\", \"Computer architecture\", \"Malware analysis\", \"Object code", 
        "title": "Automatic classification of object code using machine learning"
    }, 
    {
        "abstract": "Abstract This paper reports on the validation of a simplified discharge prediction model that is suitable for implementation on a resourced constrained system such as a wireless sensor network, which will allow their operation to become more proactive rather than reactive. The data-driven model, utilising an \\{M5\\} decision tree modelling technique, is validated using a 12-month training data set derived from published measured data. Daily runoff and drainage is predicted, and the results are compared with existing data-driven models developed in this domain. Results for the model give an \\{R2\\} of 0.82 and Root Relative Mean Square Error (RRMSE) of 35.9%. 80% of the residuals for the predicted test values fall within a \u00b12 mm discharge depth/day error range. The main significance is that the proposed model gives comparable results with fewer samples and simpler parameters when compared to previous published research, which offers the potential for implementation in resource constrained monitoring and control systems.", 
        "author": "Huma Zia and Nick Harris and Geoff Merrett and Mark Rivers", 
        "keyword": "Wireless sensor networks\", \"Discharge prediction\", \"Environmental modelling\", \"Machine learning\", \"M5 trees", 
        "title": "Predicting discharge using a low complexity machine learning model"
    }, 
    {
        "abstract": "Abstract Toxicity characterization of chemical emissions in Life Cycle Assessment (LCA) is a complex task which usually proceeds via multimedia (fate, exposure and effect) models attached to models of dose\u2013response relationships to assess the effects on target. Different models and approaches do exist, but all require a vast amount of data on the properties of the chemical compounds being assessed, which are hard to collect or hardly publicly available (especially for thousands of less common or newly developed chemicals), therefore hampering in practice the assessment in LCA. An example is USEtox, a consensual model for the characterization of human toxicity and freshwater ecotoxicity. This paper places itself in a line of research aiming at providing a methodology to reduce the number of input parameters necessary to run multimedia fate models, focusing in particular to the application of the \\{USEtox\\} toxicity model. By focusing on USEtox, in this paper two main goals are pursued: 1) performing an extensive exploratory analysis (using dimensionality reduction techniques) of the input space constituted by the substance-specific properties at the aim of detecting particular patterns in the data manifold and estimating the dimension of the subspace in which the data manifold actually lies; and 2) exploring the application of a set of linear models, based on partial least squares (PLS) regression, as well as a nonlinear model (general regression neural network \u2014 GRNN) in the seek for an automatic selection strategy of the most informative variables according to the modelled output (USEtox factor). After extensive analysis, the intrinsic dimension of the input manifold has been identified between three and four. The variables selected as most informative may vary according to the output modelled and the model used, but for the toxicity factors modelled in this paper the input variables selected as most informative are coherent with prior expectations based on scientific knowledge of toxicity factors modelling. Thus the outcomes of the analysis are promising for the future application of the approach to other portions of the model, affected by important data gaps, e.g., to the calculation of human health effect factors.", 
        "author": "Antonino Marvuglia and Mikhail Kanevski and Enrico Benetto", 
        "keyword": "Machine learning\", \"Life Cycle Assessment\", \"Chemical risk assessment\", \"USEtox\", \"Dimensionality keywords =eduction\", \"Nonlinear modelling", 
        "title": "Machine learning for toxicity characterization of organic chemical emissions using \\{USEtox\\} database: Learning the structure of the input space"
    }, 
    {
        "abstract": "Abstract In this work, data fusion of multi-element \\{XRF\\} results from archaeological feature soils and regional background soils was applied to assess the complementary value of geochemistry and machine-learning on predictive modelling in archaeology. Our principal aim was to integrate multiple data sources, train learning models for classification of archaeological soils and background soils, and compare model predictions for three validation areas with current archaeological interpretation and established predictive models. This was done using three supervised machine-learning algorithms (k-nearest neighbors, support vector machines and artificial neural networks) which were trained, cross-validated and tested. The validation areas included a high archaeological potential area (n\u00a0=\u00a0247 samples), the Dutch province of Zeeland (n\u00a0=\u00a0261 samples) and an excavated imprint of an ancient farmhouse (n\u00a0=\u00a038 samples). The predictive models showed good overall performance and correctly classified about 95% of all test instances. According to the learning models, the first validation site has a top soil horizon that shows limited parallels with archaeological horizons used in model training, whereas features of high archaeological probability become more apparent below this horizon. This is in good correspondence with geochemical depth profiles and current archaeological interpretation. As for the second validation site, the models highlighted several archaeological hotspots that to some extend spatially coincide with areas of high archaeological potential as indicated by established predictive modelling. Reversely, the classifiers attributed high archaeological potential status to the most southern region of Zeeland, thereby complementing established modelling results. For the third validation site none of the instances were correctly classified and these results clearly show the limitations of geochemical predictive modelling of significantly different soil types (fine-to-coarse sands) compared to the training set (clayey sands). Present proof-of-concept study shows that modelling of multiple-source geochemical soil data using machine-learning algorithms can be successfully accomplished and that model predictions nicely complement current interpretation and/or established archeological predictive modelling of areas of archaeological interest. Limitations of our approach were found to reside in lithological differences between sites used for model training and prediction sites.", 
        "author": "Stijn Oonk and Job Spijker", 
        "keyword": "Geochemistry\", \"Archaeology\", \"Predictive modelling\", \"Machine-learning\", \"Soil", 
        "title": "A supervised machine-learning approach towards geochemical predictive modelling in archaeology"
    }, 
    {
        "abstract": "Abstract Application of machine learning methods shows a popular attempt to identify the purpose of a trip and mode of travel on Global Positioning System (GPS) trajectory data. Data selection for the training and test sets is important in these methods. However, the feasibility and effects of choosing these data from different periods of the year are still unknown. This detail is particularly important since collecting data via \\{GPS\\} decreases the burden on participants to such an extent that it can last for seasons which may own distinct features. In order to bridge this gap, this paper employs Aslan &amp; Zech\u2019s test (AZ-test) and Random Forests (RF) successively to investigate the influence of data selection from different seasons for training and test sets. The dataset obtained in a city with distinct seasons, Hakodate, Japan, is used for our empirical analysis. The results of AZ-test suggest that explanatory variables of the two data sets from distinct seasons follow different distributions. Furthermore, it concludes that data set from two-seasons and data set from single season also follow different distributions. However, this test achieves some contradictory results in some cases. Due to this, \\{RF\\} is used to check how the accuracy varies in a further detail. \\{RF\\} confirms the findings by AZ-test in most cases. In addition, \\{RF\\} results show that including \\{GIS\\} features as explanatory variables has positive effect on the identification accuracy while including weather features has negative effect on the identification accuracy.", 
        "author": "Lei Gong and Ryo Kanamori and Toshiyuki Yamamoto", 
        "keyword": "Identification of trip purpose\", \"Identification of travel mode\", \"GPS trajectory\", \"Aslan &amp; keywords =ech\u2019 test\", \"Random Forests", 
        "title": "Data selection in machine learning for identifying trip purposes and travel modes from longitudinal \\{GPS\\} data collection lasting for seasons"
    }, 
    {
        "abstract": "Abstract In this paper, we consider the permutation flow shop scheduling problem with a general exponential learning effect. The objective is to minimize the maximum lateness. A special case that can be solved to optimality by \\{EDD\\} algorithm is provided. To form a hybrid solution framework, several heuristics, a branch-and-bound algorithm and a new Nested-Partition-based solution approach are proposed. Composite bounds and dominance rules are developed to reduce the searching region and to provide guidance on the lower bound. Finally, computational experiments are conducted to evaluate the performance of the algorithms.", 
        "author": "Hongyu He", 
        "keyword": "Scheduling\", \"Flow shop\", \"Learning effect\", \"Branch and bound\", \"Heuristic algorithm\", \"Nested Partition (NP)", 
        "title": "Minimization of maximum lateness in an m-machine permutation flow shop with a general exponential learning effect"
    }, 
    {
        "abstract": "Abstract Protein inference from the identified peptides is of primary importance in the shotgun proteomics. The target of protein inference is to identify whether each candidate protein is truly present in the sample. To date, many computational methods have been proposed to solve this problem. However, there is still no method that can fully utilize the information hidden in the input data. In this article, we propose a learning-based method named BagReg for protein inference. The method firstly artificially extracts five features from the input data, and then chooses each feature as the class feature to separately build models to predict the presence probabilities of proteins. Finally, the weak results from five prediction models are aggregated to obtain the final result. We test our method on six public available data sets. The experimental results show that our method is superior to the state-of-the-art protein inference algorithms.", 
        "author": "Can Zhao and Dao Liu and Ben Teng and Zengyou He", 
        "keyword": "Protein inference\", \"Machine learning\", \"Shotgun proteomics\", \"Protein identification", 
        "title": "BagReg: Protein inference through machine learning"
    }, 
    {
        "abstract": "Abstract The extensive use of radium during the 20th century for industrial, military and pharmaceutical purposes has led to a large number of contaminated legacy sites across Europe and North America. Sites that pose a high risk to the general public can present expensive and long-term remediation projects. Often the most pragmatic remediation approach is through routine monitoring operating gamma-ray detectors to identify, in real-time, the signal from the most hazardous heterogeneous contamination (hot particles); thus facilitating their removal and safe disposal. However, current detection systems do not fully utilise all spectral information resulting in low detection rates and ultimately an increased risk to the human health. The aim of this study was to establish an optimised detector-algorithm combination. To achieve this, field data was collected using two handheld detectors (sodium iodide and lanthanum bromide) and a number of Monte Carlo simulated hot particles were randomly injected into the field data. This allowed for the detection rate of conventional deterministic (gross counts) and machine learning (neural networks and support vector machines) algorithms to be assessed. The results demonstrated that a Neural Network operated on a sodium iodide detector provided the best detection capability. Compared to deterministic approaches, this optimised detection system could detect a hot particle on average 10 cm deeper into the soil column or with half of the activity at the same depth. It was also found that noise presented by internal contamination restricted lanthanum bromide for this application.", 
        "author": "Adam Varley and Andrew Tyler and Leslie Smith and Paul Dale and Mike Davies", 
        "keyword": "Radium remediation\", \"Gamma spectroscopy\", \"\u201cHot\u201d particles\", \"Machine learning\", \"Monte Carlo\", keywords =Sodium iodide\", \"Lanthanum bromide", 
        "title": "Remediating radium contaminated legacy sites: Advances made through machine learning in routine monitoring of \u201chot\u201d particles"
    }, 
    {
        "abstract": "Abstract Fault diagnosis for rolling bearings under variable conditions is a hot and relatively difficult topic, thus an intelligent fault diagnosis method based on local mean decomposition (LMD)\u2013singular value decomposition (SVD) and extreme learning machine (ELM) is proposed in this paper. LMD, a new self-adaptive time\u2013frequency analysis method, was applied to decompose the nonlinear and non-stationary vibration signals into a series of product functions (PFs), from which instantaneous frequencies with physical significance can be obtained. Then, the singular value vectors, as the fault feature vectors, were acquired by applying \\{SVD\\} to the PFs. Last, for the purpose of lessening human intervention and shortening the fault-diagnosis time, \\{ELM\\} was introduced for identification and classification of bearing faults. From the experimental results it was concluded that the proposed method can accurately diagnose and identify different fault types of rolling bearings under variable conditions in a relatively shorter time.", 
        "author": "Ye Tian and Jian Ma and Chen Lu and Zili Wang", 
        "keyword": "Local mean decomposition\", \"Singular value decomposition\", \"Extreme learning machine\", \"Variable keywords =onditions\", \"Rolling bearing\", \"Fault diagnosis", 
        "title": "Rolling bearing fault diagnosis under variable conditions using LMD-SVD and extreme learning machine"
    }, 
    {
        "abstract": "Abstract Globalization has dramatically increased the need of translating information from one language to another. Frequently, such translation needs should be satisfied under very tight time constraints. Machine translation (MT) techniques can constitute a solution to this overly complex problem. However, the documents to be translated in real scenarios are often limited to a specific domain, such as a particular type of medical or legal text. This situation seriously hinders the applicability of MT, since it is usually expensive to build a reliable translation system, no matter what technology is used, due to the linguistic resources that are required to build them, such as dictionaries, translation memories or parallel texts. In order to solve this problem, we propose the application of automatic post-editing in an online learning framework. Our proposed technique allows the human expert to translate in a specific domain by using a base translation system designed to work in a general domain whose output is corrected (or adapted to the specific domain) by means of an automatic post-editing module. This automatic post-editing module learns to make its corrections from user feedback in real time by means of online learning techniques. We have validated our system using different translation technologies to implement the base translation system, as well as several texts involving different domains and languages. In most cases, our results show significant improvements in terms of \\{BLEU\\} (up to 16 points) with respect to the baseline systems. The proposed technique works effectively when the n-grams of the document to be translated presents a certain rate of repetition, situation which is common according to the document-internal repetition property.", 
        "author": "Antonio L. Lagarda and Daniel Ortiz-Mart\u00ednez and Vicent Alabau and Francisco Casacuberta", 
        "keyword": "Machine translation\", \"Statistical machine translation\", \"Interactive machine translation\", keywords =Automatic post-editing\", \"Online learning", 
        "title": "Translating without in-domain corpus: Machine translation post-editing with online learning techniques"
    }, 
    {
        "abstract": "Abstract Cancer is the second leading cause of death, next only to heart disease, in both developed as well as developing countries. A major source of difficulty in addressing cancer as a disease is its bewildering variety, in that no two manifestations of cancer are alike, even when they occur in the same site. This makes cancer an ideal candidate for \u201cpersonalized medicine\u201d (also known as \u201cprecision medicine\u201d). At present there are some high-quality public databases consisting of both molecular measurements of tumors, as well as clinical data on the patients. By applying machine learning methods to these databases, it is possible even for non-experimenters to generate plausible hypotheses that are supported by the data, which can then be validated on one or more independent data sets. A characteristic of cancer databases is that the number of measured features is many orders of magnitude larger than the number of samples. Therefore any machine learning algorithms must also perform feature selection, that is, elicit the most relevant or most predictive features from the large number of measured features. In this paper, some algorithms for sparse regression and sparse classification are reviewed, and their applications to endometrial and ovarian cancer are discussed.", 
        "author": "Mathukumalli Vidyasagar", 
        "keyword": null, 
        "title": "Machine learning methods in computational cancer biology"
    }, 
    {
        "abstract": "Abstract The detection of design patterns is a useful activity giving support to the comprehension and maintenance of software systems. Many approaches and tools have been proposed in the literature providing different results. In this paper, we extend a previous work regarding the application of machine learning techniques for design pattern detection, by adding a more extensive experimentation and enhancements in the analysis method. Here we exploit a combination of graph matching and machine learning techniques, implemented in a tool we developed, called MARPLE-DPD. Our approach allows the application of machine learning techniques, leveraging a modeling of design patterns that is able to represent pattern instances composed of a variable number of classes. We describe the experimentations for the detection of five design patterns on 10 open source software systems, compare the performances obtained by different learning models with respect to a baseline, and discuss the encountered issues.", 
        "author": "Marco Zanoni and Francesca Arcelli Fontana and Fabio Stella", 
        "keyword": "Design pattern detection\", \"Machine learning techniques", 
        "title": "On applying machine learning techniques for design pattern detection"
    }, 
    {
        "abstract": "Abstract Some microstructure parameters, such as permeability, remain elusive because mathematical models that express their relationship to the \\{MR\\} signal accurately are intractable. Here, we propose to use computational models learned from simulations to estimate these parameters. We demonstrate the approach in an example which estimates water residence time in brain white matter. The residence time \u03c4i of water inside axons is a potentially important biomarker for white matter pathologies of the human central nervous system, as myelin damage is hypothesised to affect axonal permeability, and thus \u03c4i. We construct a computational model using Monte Carlo simulations and machine learning (specifically here a random forest regressor) in order to learn a mapping between features derived from diffusion weighted \\{MR\\} signals and ground truth microstructure parameters, including \u03c4i. We test our numerical model using simulated and in vivo human brain data. Simulation results show that estimated parameters have strong correlations with the ground truth parameters ( R 2 = { 0.88 , 0.95 , 0.82 , 0.99 } ) for volume fraction, residence time, axon radius and diffusivity respectively), and provide a marked improvement over the most widely used K\u00e4rger model ( R 2 = { 0.75 , 0.60 , 0.11 , 0.99 } ). The trained model also estimates sensible microstructure parameters from in vivo human brain data acquired from healthy controls, matching values found in literature, and provides better reproducibility than the K\u00e4rger model on both the voxel and \\{ROI\\} level. Finally, we acquire data from two Multiple Sclerosis (MS) patients and compare to the values in healthy subjects. We find that in the splenium of corpus callosum (CC-S) the estimate of the residence time is 0.57\u00b10.05 s for the healthy subjects, while in the \\{MS\\} patient with a lesion in CC-S it is 0.33\u00b10.12 s in the normal appearing white matter (NAWM) and 0.19\u00b10.11 s in the lesion. In the corticospinal tracts (CST) the estimate of the residence time is 0.52\u00b10.09 s for the healthy subjects, while in the \\{MS\\} patient with a lesion in \\{CST\\} it is 0.56\u00b10.05 s in the \\{NAWM\\} and 0.13\u00b10.09 s in the lesion. These results agree with our expectations that the residence time in lesions would be lower than in \\{NAWM\\} because the loss of myelin should increase permeability. Overall, we find parameter estimates in the two \\{MS\\} patients consistent with expectations from the pathology of \\{MS\\} lesions demonstrating the clinical potential of this new technique.", 
        "author": "Gemma L. Nedjati-Gilani and Torben Schneider and Matt G. Hall and Niamh Cawley and Ioana Hill and Olga Ciccarelli and Ivana Drobnjak and Claudia A.M. Gandini Wheeler-Kingshott and Daniel C. Alexander", 
        "keyword": null, 
        "title": "Machine learning based compartment models with permeability for white matter microstructure imaging"
    }, 
    {
        "abstract": "Abstract The physicochemical changes that occur in poultry egg during storage, make a reduction in its quality. The present research investigates the possibility of the nondestructive classification and quality inspection of eggs using dielectric detection technique in the range of radio frequency. Several machine learning (ML) techniques were developed for freshness detection including artificial neural networks (ANN), Bayesian networks (BNs), decision trees (DTs) and support vector machines (SVMs). Among ANNs, the \\{ANN\\} with topology of 62-18-6 gave a perfect capability to predict the class of freshness for all samples with accuracy of 100%. Also all types of \\{BNs\\} represented excellent results with Kappa statistic of 1 and overall accuracy of 100%. From developed SVMs, the \\{SVM\\} with polynomial kernel function gave the best results with Kappa value of 1 and accuracy of 100%. Among DTs, \\{LMT\\} tree had the highest Kappa value (0.846) and the highest accuracy (87.5%) compared to other \\{DT\\} approaches. Different \\{ML\\} methods were used to predict air cell height. Among \\{ANNs\\} the 24-12-1 structure with R value of 0.817, among \\{DTs\\} the \\{MSP\\} tree with R value of 0.906 and among \\{SVMs\\} the \\{RBF\\} form with R value of 0.920 had the highest value of correlation coefficient and the lowest standard error of 0.452.", 
        "author": "Mahmoud Soltani and Mahmoud Omid", 
        "keyword": "Egg\", \"Freshness detection\", \"Quality prediction\", \"Dielectric spectroscopy\", \"Machine learning", 
        "title": "Detection of poultry egg freshness by dielectric spectroscopy and machine learning techniques"
    }, 
    {
        "abstract": "Summary Recognizing the importance of precise determination of reference evapotranspiration (ET0) is a principal step in the attempts to reserve huge quantities of squandered water. This paper investigates the efficiency of Extreme Learning Machines (ELM) algorithm at predicting Penman\u2013Monteith (P\u2013M) \\{ET0\\} for Mosul, Baghdad, and Basrah meteorological stations, located at the north, mid, and southern part of Iraq. Data of weather parameters containing maximum air temperature (Tmax), minimum air temperature (Tmin), sunshine hours (Rn), relative humidity (Rh), and wind speed (U2) for the period (2000\u20132013) are used as inputs to the \\{ELM\\} model by using four different input cases including complete and incomplete sets of meteorological data. The performance of \\{ELM\\} model is compared with the empirical P\u2013M equation and with feedforward backpropagation (FFBP) model. The evaluation criteria used for comparison are the root of mean squared error (RMSE), mean absolute error (MAE), and coefficient of determination (R2). The statistical results of both models are found to be encouraging; particularly results of running the \\{ELM\\} model with incomplete sets of data, noticing that the sensitivity of the proposed model to missing data changes from one location to another, as well as along the year for certain study location. The Rn is found to be the most effective parameter in Mosul Station, while \\{U2\\} and Rh are found to act almost in parallel with Rn in Baghdad Station, and for conditions of Basrah Station; \\{U2\\} and Rh prove to be the dominant parameters. The minimum and maximum time intervals required for running \\{ELM\\} model for all stations, and in all applied conditions, are (4.64\u20136.19) seconds respectively, while the same order of timing required for running the \\{FFBP\\} model is (6.30\u201327.80) seconds. The maximum \\{R2\\} recorded for the \\{ELM\\} model is 0.991, while for the \\{FFBP\\} it is 0.985. The \\{ELM\\} proved to be efficient, simple in application, of high speed, and has very good generalization performance; therefore, this algorithm is highly recommended for locations similar to the geographical and meteorological conditions of Iraq that consists of both arid and semiarid regions.", 
        "author": "Shafika Sultan Abdullah and M.A. Malek and Namiq Sultan Abdullah and Ozgur Kisi and Keem Siah Yap", 
        "keyword": "Reference evapotranspiration\", \"Penman\u2013Monteith equation\", \"Extreme Learning Machines\", \"Artificial Neural Networks", 
        "title": "Extreme Learning Machines: A new approach for prediction of reference evapotranspiration"
    }, 
    {
        "abstract": "AbstractObjective To synthesise recent research on the use of machine learning approaches to mining textual injury surveillance data. Design Systematic review. Data sources The electronic databases which were searched included PubMed, Cinahl, Medline, Google Scholar, and Proquest. The bibliography of all relevant articles was examined and associated articles were identified using a snowballing technique. Selection criteria For inclusion, articles were required to meet the following criteria: (a) used a health-related database, (b) focused on injury-related cases, \\{AND\\} used machine learning approaches to analyse textual data. Methods The papers identified through the search were screened resulting in 16 papers selected for review. Articles were reviewed to describe the databases and methodology used, the strength and limitations of different techniques, and quality assurance approaches used. Due to heterogeneity between studies meta-analysis was not performed. Results Occupational injuries were the focus of half of the machine learning studies and the most common methods described were Bayesian probability or Bayesian network based methods to either predict injury categories or extract common injury scenarios. Models were evaluated through either comparison with gold standard data or content expert evaluation or statistical measures of quality. Machine learning was found to provide high precision and accuracy when predicting a small number of categories, was valuable for visualisation of injury patterns and prediction of future outcomes. However, difficulties related to generalizability, source data quality, complexity of models and integration of content and technical knowledge were discussed. Conclusions The use of narrative text for injury surveillance has grown in popularity, complexity and quality over recent years. With advances in data mining techniques, increased capacity for analysis of large databases, and involvement of computer scientists in the injury prevention field, along with more comprehensive use and description of quality assurance methods in text mining approaches, it is likely that we will see a continued growth and advancement in knowledge of text mining in the injury field.", 
        "author": "Kirsten Vallmuur", 
        "keyword": "Text data\", \"Injury surveillance\", \"Injury epidemiology\", \"Text mining\", \"Machine learning", 
        "title": "Machine learning approaches to analysing textual injury surveillance data: A systematic review"
    }, 
    {
        "abstract": "Abstract Evaluation of voltage stability status considering its dynamic boundaries is a key issue for saving global stability of power systems. However, this evaluation is a computationally demanding task and its implementation is very hard (if not impossible) for on-line environments such as dispatching centers of power systems. In this paper, a new viewpoint for the problem based on modeling it as a forecast process is proposed, which can be implemented with a low computation burden for practical power systems. For this purpose, a voltage stability classification model considering Hopf and limit induced bifurcations is proposed and a new forecast strategy to predict voltage stability class label based on the proposed classification is suggested. The suggested forecast strategy is composed of an information theoretic feature selection technique, extreme learning machine (ELM) as the forecast engine and a line search procedure to fine-tune the settings. The effectiveness of the proposed classification model and forecast strategy is extensively illustrated on the New England 39-bus and \\{IEEE\\} 145-bus test systems.", 
        "author": "Mohammad Hossein Velayati and Nima Amjady and Issa Khajevandi", 
        "keyword": "Hopf Bifurcation (HB)\", \"Limit Induced Bifurcation (LIB)\", \"Forecast process\", \"Extreme learning machine", 
        "title": "Prediction of dynamic voltage stability status based on Hopf and limit induced bifurcations using extreme learning machine"
    }, 
    {
        "abstract": "Abstract Focal cortical dysplasia (FCD) is the most common cause of pediatric epilepsy and the third most common lesion in adults with treatment-resistant epilepsy. Advances in \\{MRI\\} have revolutionized the diagnosis of FCD, resulting in higher success rates for resective epilepsy surgery. However, many patients with histologically confirmed \\{FCD\\} have normal presurgical \\{MRI\\} studies (\u2018MRI-negative\u2019), making presurgical diagnosis difficult. The purpose of this study was to test whether a novel \\{MRI\\} postprocessing method successfully detects histopathologically verified \\{FCD\\} in a sample of patients without visually appreciable lesions. We applied an automated quantitative morphometry approach which computed five surface-based \\{MRI\\} features and combined them in a machine learning model to classify lesional and nonlesional vertices. Accuracy was defined by classifying contiguous vertices as \u201clesional\u201d when they fell within the surgical resection region. Our multivariate method correctly detected the lesion in 6 of 7 MRI-positive patients, which is comparable with the detection rates that have been reported in univariate vertex-based morphometry studies. More significantly, in patients that were MRI-negative, machine learning correctly identified 14 out of 24 \\{FCD\\} lesions (58%). This was achieved after separating abnormal thickness and thinness into distinct classifiers, as well as separating sulcal and gyral regions. Results demonstrate that MRI-negative images contain sufficient information to aid in the in vivo detection of visually elusive \\{FCD\\} lesions.", 
        "author": "Bilal Ahmed and Carla E. Brodley and Karen E. Blackmon and Ruben Kuzniecky and Gilad Barash and Chad Carlson and Brian T. Quinn and Werner Doyle and Jacqueline French and Orrin Devinsky and Thomas Thesen", 
        "keyword": "Epilepsy\", \"Focal cortical dysplasia\", \"Machine learning\", \"Structural \\{MRI\\}", 
        "title": "Cortical feature analysis and machine learning improves detection of \u201cMRI-negative\u201d focal cortical dysplasia"
    }, 
    {
        "abstract": "Abstract Precise predictions of wind power density play a substantial role in determining the viability of wind energy harnessing. In fact, reliable prediction is particularly useful for operators and investors to offer a secure situation with minimal economic risks. In this paper, a new model based upon \\{ELM\\} (extreme learning machine) is presented to estimate the wind power density. Generally, the two-parameter Weibull function has been normally used and recognized as a reliable method in wind energy estimations for most windy regions. Thus, the required data for training and testing were extracted from two accurate Weibull methods of standard deviation and power density. The validity of the \\{ELM\\} model is verified by comparing its predictions with \\{SVM\\} (Support Vector Machine), \\{ANN\\} (Artificial Neural Network) and \\{GP\\} (Genetic Programming) techniques. The wind powers predicted by all approaches are compared with those calculated using measured data. Based upon simulation results, it is demonstrated that \\{ELM\\} can be utilized effectively in applications of wind power predictions. In a nutshell, the survey results show that the proposed \\{ELM\\} model is suitable and precise to predict wind power density and has much higher performance than the other approaches examined in this study.", 
        "author": "Kasra Mohammadi and Shahaboddin Shamshirband and Por Lip Yee and Dalibor Petkovi\u0107 and Mazdak Zamani and Sudheer Ch", 
        "keyword": "Wind power density\", \"ELM (extreme learning machine)\", \"Weibull method\", \"Prediction", 
        "title": "Predicting the wind power density based upon extreme learning\u00a0machine"
    }, 
    {
        "abstract": "Abstract The classification of imbalanced data is a major challenge for machine learning. In this paper, we presented a fuzzy total margin based support vector machine (FTM-SVM) method to handle the class imbalance learning (CIL) problem in the presence of outliers and noise. The proposed method incorporates total margin algorithm, different cost functions and the proper approach of fuzzification of the penalty into FTM-SVM and formulates them in nonlinear case. We considered an excellent type of fuzzy membership functions to assign fuzzy membership values and got six FTM-SVM settings. We evaluated the proposed FTM-SVM method on two artificial data sets and 16 real-world imbalanced data sets. Experimental results show that the proposed FTM-SVM method has higher G_Mean and F_Measure values than some existing \\{CIL\\} methods. Based on the overall results, we can conclude that the proposed FTM-SVM method is effective for \\{CIL\\} problem, especially in the presence of outliers and noise in data sets.", 
        "author": "Hong-Liang Dai", 
        "keyword": "Support vector machine (SVM)\", \"Fuzzy support vector machine (FSVM)\", \"Class imbalance learning (CIL)", 
        "title": "Class imbalance learning via a fuzzy total margin based support vector machine"
    }, 
    {
        "abstract": "Abstract The current paper investigates a non-identical parallel machine multi-objective scheduling problem in which both the deterioration and learning effects have been considered. Due to uncertainty of the parameters in real-world systems, processing times and due dates of jobs are represented here with triangular fuzzy numbers. Using the credibility measure, a nonlinear mathematical model is provided based on fuzzy chance-constrained programming (FCCP) with the aim to minimize two objective functions, namely total earliness/tardiness (ET) and maximum completion time of jobs (makespan). Since it is a mixed integer nonlinear mathematical model, there is no guarantee that the solution will obtain a global optimum. Therefore, a multi-objective branch and bound algorithm is provided by introducing an effective lower bound in order to obtain a Pareto optimal front. Computational results show that the algorithm proposed is especially useful to solve large-scale problems.", 
        "author": "Mohammad Rostami and Amir Ebrahimzadeh Pilerood and Mohammad Mahdavi Mazdeh", 
        "keyword": "Parallel machine scheduling\", \"Fuzzy environment\", \"Job deterioration\", \"Learning effect\", \"Multi-objective branch and bound", 
        "title": "Multi-objective parallel machine scheduling problem with job deterioration and learning effect under fuzzy environment"
    }, 
    {
        "abstract": "Abstract Concept-based image search is an emerging search paradigm that utilizes a set of concepts as intermediate semantic descriptors of images to bridge the semantic gap. Typically, a user query is rather complex and cannot be well described using a single concept. However, it is less effective to tackle such complex queries by simply aggregating the individual search results for the constituent concepts. In this paper, we propose to introduce the learning to rank techniques to concept-based image search for complex queries. With freely available social tagged images, we first build concept detectors by jointly leveraging the heterogeneous visual features. Then, to formulate the image relevance, we explicitly model the individual weight of each constituent concept in a complex query. The dependence among constituent concepts, as well as the relatedness between query and non-query concepts, are also considered through modeling the pairwise concept correlations in a factorization way. Finally, we train our model to directly optimize the image ranking performance for complex queries under a pairwise learning to rank framework. Extensive experiments on two benchmark datasets well verified the promise of our approach.", 
        "author": "Chaoran Cui and Jialie Shen and Zhumin Chen and Shuaiqiang Wang and Jun Ma", 
        "keyword": "Concept-based image search\", \"Complex query\", \"Learning to rank\", \"Factorization machine", 
        "title": "Learning to rank images for complex queries in concept-based search"
    }, 
    {
        "abstract": "Abstract A sequential extreme learning machine incorporating a noise compensation scheme via an information measure is developed. In this design, the computationally simple extreme learning machine architecture is maintained while survival error information potential function provides a mechanism for noise compensation. The error compensation is updated online via an error codebook design where an error tolerant and stable solution is obtained. The developed method is tested on chaotic time sequence as well as benchmark data sets. Experimental results show potential applications for the developed method.", 
        "author": "Lei Sun and Badong Chen and Kar-Ann Toh and Zhiping Lin", 
        "keyword": "Sequential learning machine\", \"Extreme learning machine\", \"Information measure", 
        "title": "Sequential extreme learning machine incorporating survival error potential"
    }, 
    {
        "abstract": "Abstract Reservoir simulation is the most robust tool for simulating gas production from the desorption controlled and hydraulically fractured shale reservoir. Incorporation of the created massive hydraulic fractures explicitly into the simulation model is the major challenge during the model development and computation phases. A pattern recognition-based proxy model is our proposed technique to overcome the aforementioned problem by modeling time successive shale gas production at the hydraulic fracture cluster level at different time resolutions (Short-, medium- and long term). Ensemble of multiple, interconnected adaptive neuro-fuzzy systems create the core for the development of the shale proxy models. In this approach, unlike reduced order models, the physics and the space-time resolution are not reduced. Instead of using pre-defined functional forms that are more frequently used to develop response surfaces, a series of machine learning algorithms that conform to the system theory are used. A history-matched Marcellus shale gas pad with six horizontal laterals and 169 clusters of hydraulic fracture is used as a base case for shale proxy model development. Additionally, several realizations are defined in order to capture the uncertainties inherent in the shale simulation model. The proxy model is validated using a blind simulation run that is not used during the model development process. The developed shale proxy model re-generates the simulation results for methane production for 169 clusters hydraulic fracture in a second with high accuracy (&lt;15% error), thus making a comprehensive analysis of production from shale a practical and feasible option. Moreover, it can be used as an assisted history-matching tool, since it has the capability to scrutinize the solution space and produce the model response to the uncertainty changes very fast.", 
        "author": "Amirmasoud Kalantari-Dahaghi and Shahab Mohaghegh and Soodabeh Esmaili", 
        "keyword": "Shale gas\", \"Numerical simulation\", \"Multilateral pad\", \"History matching\", \"Pattern recognition\", \"Machine learning", 
        "title": "Coupling numerical simulation and machine learning to model shale gas production at different time resolutions"
    }, 
    {
        "abstract": "AbstractBackground Sleep staging is a critical step in a range of electrophysiological signal processing pipelines used in clinical routine as well as in sleep research. Although the results currently achievable with automatic sleep staging methods are promising, there is need for improvement, especially given the time-consuming and tedious nature of visual sleep scoring. New method Here we propose a sleep staging framework that consists of a multi-class support vector machine (SVM) classification based on a decision tree approach. The performance of the method was evaluated using polysomnographic data from 15 subjects (electroencephalogram (EEG), electrooculogram (EOG) and electromyogram (EMG) recordings). The decision tree, or dendrogram, was obtained using a hierarchical clustering technique and a wide range of time and frequency-domain features were extracted. Feature selection was carried out using forward sequential selection and classification was evaluated using k-fold cross-validation. Results The dendrogram-based \\{SVM\\} (DSVM) achieved mean specificity, sensitivity and overall accuracy of 0.92, 0.74 and 0.88 respectively, compared to expert visual scoring. Restricting \\{DSVM\\} classification to data where both experts\u2019 scoring was consistent (76.73% of the data) led to a mean specificity, sensitivity and overall accuracy of 0.94, 0.82 and 0.92 respectively. Comparison with existing methods The \\{DSVM\\} framework outperforms classification with more standard multi-class \u201cone-against-all\u201d \\{SVM\\} and linear-discriminant analysis. Conclusion The promising results of the proposed methodology suggest that it may be a valuable alternative to existing automatic methods and that it could accelerate visual scoring by providing a robust starting hypnogram that can be further fine-tuned by expert inspection.", 
        "author": "Tarek Lajnef and Sahbi Chaibi and Perrine Ruby and Pierre-Emmanuel Aguera and Jean-Baptiste Eichenlaub and Mounir Samet and Abdennaceur Kachouri and Karim Jerbi", 
        "keyword": "Electroencephalography (EEG)\", \"Sleep scoring\", \"Oscillations\", \"Polysomnography\", \"Decision-tree\", keywords =Support vector machine (SVM)\", \"Linear Discriminant Analysis (LDA)\", \"Hierarchical clustering\", keywords =Machine learning\", \"Dendrogram", 
        "title": "Learning machines and sleeping brains: Automatic sleep stage classification using decision-tree multi-class support vector machines"
    }, 
    {
        "abstract": "Abstract We present a comparative study on the most popular machine learning methods applied to the challenging problem of customer churning prediction in the telecommunications industry. In the first phase of our experiments, all models were applied and evaluated using cross-validation on a popular, public domain dataset. In the second phase, the performance improvement offered by boosting was studied. In order to determine the most efficient parameter combinations we performed a series of Monte Carlo simulations for each method and for a wide range of parameters. Our results demonstrate clear superiority of the boosted versions of the models against the plain (non-boosted) versions. The best overall classifier was the SVM-POLY using AdaBoost with accuracy of almost 97% and F-measure over 84%.", 
        "author": "T. Vafeiadis and K.I. Diamantaras and G. Sarigiannidis and K.Ch. Chatzisavvas", 
        "keyword": "Churn prediction\", \"Machine learning techniques\", \"Boosting algorithm", 
        "title": "A comparison of machine learning techniques for customer churn prediction"
    }, 
    {
        "abstract": "Summary Infrastructure for the automatic collection of single-point measurements of snow water equivalent (SWE) is well-established. However, because \\{SWE\\} varies significantly over space, the estimation of \\{SWE\\} at the catchment scale based on a single-point measurement is error-prone. We propose low-cost, lightweight methods for near-real-time estimation of mean catchment-wide \\{SWE\\} using existing infrastructure, wireless sensor networks, and machine learning algorithms. Because snowpack distribution is highly nonlinear, we focus on Genetic Programming (GP), a nonlinear, white-box, inductive machine learning algorithm. Because we did not have access to near-real-time catchment-scale \\{SWE\\} data, we used available data as ground truth for machine learning in a set of experiments that are successive approximations of our goal of catchment-wide \\{SWE\\} estimation. First, we used a history of maritime snowpack data collected by manual snow courses. Second, we used distributed snow depth (HS) data collected automatically by wireless sensor networks. We compared the performance of \\{GP\\} against linear regression (LR), binary regression trees (BT), and a widely used basic method (BM) that naively assumes non-variable snowpack. In the first experiment set, \\{GP\\} and \\{LR\\} models predicted \\{SWE\\} with lower error than BM. In the second experiment set, \\{GP\\} had lower error than LR, but outperformed \\{BT\\} only when we applied a technique that specifically mitigated the possibility of over-fitting.", 
        "author": "David Buckingham and Christian Skalka and Josh Bongard", 
        "keyword": "Snow water equivalent\", \"Machine learning\", \"Wireless sensor network\", \"Snowpack modeling\", \"Genetic programming", 
        "title": "Inductive machine learning for improved estimation of catchment-scale snow water equivalent"
    }, 
    {
        "abstract": "Abstract Detailed information about seismic building structural types (SBSTs) is crucial for accurate earthquake vulnerability and risk modeling as it reflects the main load-bearing structures of buildings and, thus, the behavior under seismic load. However, for numerous urban areas in earthquake prone regions this information is mostly outdated, unavailable, or simply not existent. To this purpose, we present an effective approach to estimate \\{SBSTs\\} by combining scarce in situ observations, multi-sensor remote sensing data and machine learning techniques. In particular, an approach is introduced, which deploys a sequential procedure comprising five main steps, namely calculation of features from remote sensing data, feature selection, outlier detection, generation of synthetic samples, and supervised classification under consideration of both Support Vector Machines and Random Forests. Experimental results obtained for a representative study area, including large parts of the city of Padang (Indonesia), assess the capabilities of the presented approach and confirm its great potential for a reliable area-wide estimation of \\{SBSTs\\} and an effective earthquake loss modeling based on remote sensing, which should be further explored in future research activities.", 
        "author": "Christian Gei\u00df and Patrick Aravena Pelizari and Mattia Marconcini and Wayan Sengara and Mark Edwards and Tobia Lakes and Hannes Taubenb\u00f6ck", 
        "keyword": "Seismic building structural types\", \"Very high and medium resolution imagery\", \"Machine learning\", keywords =SVM\", \"Random Forests\", \"Earthquake loss estimation", 
        "title": "Estimation of seismic building structural types using multi-sensor remote sensing and machine learning techniques"
    }, 
    {
        "abstract": "Abstract Multivariate time series has attracted increasing attention due to its rich dynamic information of the underlying systems. This paper presents an improved extreme learning machine for online sequential prediction of multivariate time series. The multivariate time series is first phase-space reconstructed to form the input and output samples. Extreme learning machine, which has simple structure and good performance, is used as prediction model. On the basis of the specific network function of extreme learning machine, an improved Levenberg\u2013Marquardt algorithm, in which Hessian matrix and gradient vector are calculated iteratively, is developed to implement online sequential prediction. Finally, simulation results of artificial and real-world multivariate time series are provided to substantiate the effectiveness of the proposed method.", 
        "author": "Xinying Wang and Min Han", 
        "keyword": "Online prediction\", \"Multivariate time series\", \"Extreme Learning Machine\", \"LM algorithm", 
        "title": "Improved extreme learning machine for multivariate time series online sequential prediction"
    }, 
    {
        "abstract": "Abstract In this paper, two real-world medical classification problems using electrocardiogram (ECG) and auscultatory blood pressure (Korotkoff) signals are examined. A total of nine machine learning models are applied to perform classification of the medical data sets. A number of useful performance metrics which include accuracy, sensitivity, specificity, as well as the area under the receiver operating characteristic curve are computed. In addition to the original data sets, noisy data sets are generated to evaluate the robustness of the classifiers against noise. The 10-fold cross validation method is used to compute the performance statistics, in order to ensure statistically reliable results pertaining to classification of the \\{ECG\\} and Korotkoff signals are produced. The outcomes indicate that while logistic regression models perform the best with the original data set, ensemble machine learning models achieve good accuracy rates with noisy data sets.", 
        "author": "Manjeevan Seera and Chee Peng Lim and Wei Shiung Liew and Einly Lim and Chu Kiong Loo", 
        "keyword": "Machine learning\", \"Data classification\", \"Medical signals\", \"Electrocardiogram\", \"Auscultatory blood pressure", 
        "title": "Classification of electrocardiogram and auscultatory blood pressure signals using machine learning models"
    }, 
    {
        "abstract": "Abstract Deep learning methods endeavor to learn features automatically at multiple levels and allow systems to learn complex functions mapping from the input space to the output space for the given data. The ability to learn powerful features automatically is increasingly important as the volume of data and range of applications of machine learning methods continues to grow. This paper proposes a new deep architecture that uses support vector machines (SVMs) with class probability output networks (CPONs) to provide better generalization power for pattern classification problems. As a result, deep features are extracted without additional feature engineering steps, using multiple layers of the \\{SVM\\} classifiers with CPONs. The proposed structure closely approaches the ideal Bayes classifier as the number of layers increases. Using a simulation of classification problems, the effectiveness of the proposed method is demonstrated.", 
        "author": "Sangwook Kim and Zhibin Yu and Rhee Man Kil and Minho Lee", 
        "keyword": "Deep learning\", \"Support vector machine\", \"Class probability output network\", \"Uncertainty measure", 
        "title": "Deep learning of support vector machines with class probability output networks"
    }, 
    {
        "abstract": "Abstract The need for a reliable, unbiased, and objective assessment of hotel location has always been important. This study presents a new approach to evaluate potential sites for proposed hotel properties by designing an automated web \\{GIS\\} application: Hotel Location Selection and Analyzing Toolset (HoLSAT). The application uses a set of machine learning algorithms to predict various business success indicators associated with location sites. Using an example of hotel location assessment in Beijing, HoLSAT calculates and visualizes various desirable sites contingent on the specified characteristics of the proposed hotel. The approach shows considerable potential usefulness in the field of hotel location evaluation.", 
        "author": "Yang Yang and Jingyin Tang and Hao Luo and Rob Law", 
        "keyword": "Web GIS\", \"Hotel location\", \"Spatial decision making\", \"Machine learning", 
        "title": "Hotel location evaluation: A combination of machine learning tools and web \\{GIS\\}"
    }, 
    {
        "abstract": "Abstract Tackling pattern recognition problems in areas such as computer vision, bioinformatics, speech or text recognition is often done best by taking into account task-specific statistical relations between output variables. In structured prediction, this internal structure is used to predict multiple outputs simultaneously, leading to more accurate and coherent predictions. Structural support vector machines (SSVMs) are nonprobabilistic models that optimize a joint input\u2013output function through margin-based learning. Because \\{SSVMs\\} generally disregard the interplay between unary and interaction factors during the training phase, final parameters are suboptimal. Moreover, its factors are often restricted to linear combinations of input features, limiting its generalization power. To improve prediction accuracy, this paper proposes: (i) joint inference and learning by integration of back-propagation and loss-augmented inference in \\{SSVM\\} subgradient descent; (ii) extending \\{SSVM\\} factors to neural networks that form highly nonlinear functions of input features. Image segmentation benchmark results demonstrate improvements over conventional \\{SSVM\\} training methods in terms of accuracy, highlighting the feasibility of end-to-end \\{SSVM\\} training with neural factors.", 
        "author": "Rein Houthooft and Filip De Turck", 
        "keyword": "Structural support vector machine\", \"Neural factors\", \"Structured prediction\", \"Neural networks\", \"Image segmentation", 
        "title": "Integrated inference and learning of neural factors in structural support vector machines"
    }, 
    {
        "abstract": "Background Parathyroidectomy offers the only cure for primary hyperparathyroidism, but today only 50% of primary hyperparathyroidism patients are referred for operation, in large part, because the condition is widely under-recognized. The diagnosis of primary hyperparathyroidism can be especially challenging with mild biochemical indices. Machine learning is a collection of methods in which computers\u00a0build predictive algorithms based on labeled examples. With the aim of facilitating diagnosis, we tested the ability of machine learning to distinguish primary hyperparathyroidism from normal physiology using clinical and laboratory data. Methods This retrospective cohort study used a labeled training set and 10-fold cross-validation to evaluate accuracy of the algorithm. Measures of accuracy included area under the receiver operating characteristic curve, precision (sensitivity), and positive and negative predictive value. Several different algorithms and ensembles of algorithms were tested using the Weka platform. Among 11,830 patients managed operatively at 3 high-volume endocrine surgery programs from March 2001 to August 2013, 6,777 underwent parathyroidectomy for confirmed primary hyperparathyroidism, and 5,053 control patients without primary hyperparathyroidism underwent thyroidectomy. Test-set accuracies for machine learning models were determined using 10-fold cross-validation. Age, sex, and serum levels of preoperative calcium, phosphate, parathyroid hormone, vitamin D, and creatinine were defined as potential predictors of primary hyperparathyroidism. Mild primary hyperparathyroidism was defined as primary hyperparathyroidism with normal preoperative calcium or parathyroid hormone levels. Results After testing a variety of machine learning algorithms, Bayesian network models proved most accurate, classifying correctly 95.2% of all primary hyperparathyroidism patients (area under receiver operating characteristic\u00a0=\u00a00.989). Omitting parathyroid hormone from the model did not decrease the accuracy significantly (area under receiver operating characteristic\u00a0=\u00a00.985). In mild disease cases, however, the Bayesian network model classified correctly 71.1% of patients with normal calcium and 92.1% with normal parathyroid hormone levels preoperatively. Bayesian networking and AdaBoost improved the accuracy of all parathyroid hormone patients to 97.2% cases (area under receiver operating characteristic\u00a0=\u00a00.994), and 91.9% of primary hyperparathyroidism patients with mild disease. This was significantly improved relative to Bayesian networking alone (P\u00a0&lt;\u00a0.0001). Conclusion Machine learning can diagnose accurately primary hyperparathyroidism without human input even in mild disease. Incorporation of this tool into electronic medical record systems may aid in recognition of this under-diagnosed disorder.", 
        "author": "Yash R. Somnay and Mark Craven and Kelly L. McCoy and Sally E. Carty and Tracy S. Wang and Caprice C. Greenberg and David F. Schneider", 
        "keyword": null, 
        "title": "Improving diagnostic recognition of primary hyperparathyroidism with machine learning"
    }, 
    {
        "abstract": "Abstract The passive autofocus mechanism is an essential feature of modern digital cameras and needs to be highly accurate to obtain quality images. In this paper, we address the problem of finding a lens position where the image is in focus. We show that supervised machine learning techniques can be used to construct heuristics for a hill-climbing approach for finding such positions that out-performs previously proposed approaches in accuracy and robustly handles scenes with multiple objects at different focus distances and low-light situations. We gather a suite of 32 benchmarks representative of common photography situations and label them in an automated manner. A decision tree learning algorithm is used to induce heuristics from the data and the heuristics are then integrated into a control algorithm. Our experimental evaluation shows improved accuracy over previous work from 91.5% to 98.5% in regular settings and from 70.3% to 94.0% in low-light.", 
        "author": "Rudi Chen and Peter van Beek", 
        "keyword": "Autofocusing\", \"Digital cameras\", \"Supervised machine learning\", \"Decision trees", 
        "title": "Improving the accuracy and low-light performance of contrast-based autofocus using supervised machine learning"
    }, 
    {
        "abstract": "Abstract Chronic Kidney Disease (CKD) anemia is one of the main common comorbidities in patients undergoing End Stage Renal Disease (ESRD). Iron supplement and especially Erythropoiesis Stimulating Agents (ESA) have become the treatment of choice for that anemia. However, it is very complicated to find an adequate treatment for every patient in each particular situation since dosage guidelines are based on average behaviors, and thus, they do not take into account the particular response to those drugs by different patients, although that response may vary enormously from one patient to another and even for the same patient in different stages of the anemia. This work proposes an advance with respect to previous works that have faced this problem using different methodologies (Machine Learning (ML), among others), since the diversity of the \\{CKD\\} population has been explicitly taken into account in order to produce a general and reliable model for the prediction of ESA/Iron therapy response. Furthermore, the \\{ML\\} model makes use of both human physiology and drug pharmacology to produce a model that outperforms previous approaches, yielding Mean Absolute Errors (MAE) of the Hemoglobin (Hb) prediction around or lower than 0.6 g/dl in the three countries analyzed in the study, namely, Spain, Italy and Portugal.", 
        "author": "Carlo Barbieri and Flavio Mari and Andrea Stopper and Emanuele Gatti and Pablo Escandell-Montero and Jos\u00e9 M. Mart\u00ednez-Mart\u00ednez and Jos\u00e9 D. Mart\u00edn-Guerrero", 
        "keyword": "Prediction\", \"Hemoglobin\", \"Chronic Kidney Disease\", \"Anemia\", \"Machine learning", 
        "title": "A new machine learning approach for predicting the response to anemia treatment in a large cohort of End Stage Renal Disease patients undergoing dialysis"
    }, 
    {
        "abstract": "Abstract Recently, two parsimonious algorithms were proposed to sparsify extreme learning machine (ELM), i.e., constructive parsimonious \\{ELM\\} (CP-ELM) and destructive parsimonious \\{ELM\\} (DP-ELM). In this paper, the ideas behind CP-ELM and DP-ELM are extended to the regularized \\{ELM\\} (RELM), thus obtaining CP-RELM and DP-RELM. For CP-RELM(DP-RELM), there are two schemes to realize it, viz. CP-RELM-I and CP-RELM-II(DP-RELM-I and DP-RELM-II). Generally speaking, CP-RELM-II(DP-RELM-II) outperforms CP-RELM-I(DP-RELM-I) in terms of parsimoniousness. Under nearly the same generalization, compared with CP-ELM(DP-ELM), CP-RELM-II(DP-RELM-II) usually needs fewer hidden nodes. In addition, different from CP-ELM and DP-ELM, for CP-RELM and DP-RELM the number of candidate hidden nodes may be larger than the number of training samples, which assists the selection of much better hidden nodes for constructing more compact networks. Finally, eleven benchmark data sets divided into two groups are utilized to do experiments and the usefulness of the proposed algorithms is reported.", 
        "author": "Yong-Ping Zhao and Kang-Kang Wang and Ye-Bo Li", 
        "keyword": "Extreme learning machine\", \"Sparseness\", \"Tikhonov regularization\", \"Orthogonal transformation\", \"Condition number", 
        "title": "Parsimonious regularized extreme learning machine based on orthogonal transformation"
    }, 
    {
        "abstract": "Abstract In scheduling problems, the learning phenomenon is often seen in some practical applications such as in the processing of certain chemicals in oil refineries and in the steel plates or bars produced by a foundry. A review of the literature reveals that most researchers paid more attention to the scheduling with both the single-machine settings and the learning without a bound. This is at odds with reality and thereby highlights the importance of addressing the issue by different approaches. This paper tackles the issue by considering a two-machine flowshop problem with a truncated learning consideration where the objective function is to minimize the makespan. In order to solve the proposed model, a branch-and-bound algorithm is first developed for the optimal solution. Then four genetic heuristic-based algorithms are proposed for the near-optimal solution. In addition, the experimental results of all proposed algorithms are also provided.", 
        "author": "Wen-Hsiang Wu and Wen-Hung Wu and Juei-Chao Chen and Win-Chin Lin and Jungpin Wu and Chin-Chia Wu", 
        "keyword": "Scheduling\", \"Two-machine\", \"Makespan\", \"Truncated learning effect", 
        "title": "A heuristic-based genetic algorithm for the two-machine flowshop scheduling with learning consideration"
    }, 
    {
        "abstract": "Abstract Currently traffic noise has become an important factor that affects human health, and thus, an application able to classify vehicles on the basis of the sound they produce becomes important in the effort of fulfilling recommendations that aim at reducing traffic noise and improving intelligent transportation systems. This paper focuses on the problem of selecting those sound-describing features that make the vehicle classifier work properly. In particular, the goal of this paper is to evaluate the feasibility of a novel feature selection method based on a special class of Genetic Algorithm (with restricted search) hybridized with a Extreme Learning Machine. Because of its great generalization performance at a very fast learning speed, the Extreme Learning Machine plays the key role of providing the fitness of candidate solutions in each generation of the Genetic Algorithm. After a number of experiments comparing its performance to that of other fast learning algorithms, our approach has been found to be the most feasible for the application at hand. The proposed method helps the Extreme Learning Machine-based classifier to increase its performance from a mean probability of correct classification of 74.83% (with no feature selection) up to 93.74% (when using the optimum subset of selected features).", 
        "author": "E. Alexandre and L. Cuadra and S. Salcedo-Sanz and A. Pastor-S\u00e1nchez and C. Casanova-Mateo", 
        "keyword": "Vehicle classification\", \"Feature selection\", \"Genetic Algorithm\", \"Extreme learning machine", 
        "title": "Hybridizing Extreme Learning Machines and Genetic Algorithms to select acoustic features in vehicle classification applications"
    }, 
    {
        "abstract": "Abstract Iron ore sintering process is the second-most energy-consuming procedure in the iron making industry. The main energy for it is the combustion of coke, which consists primary of carbon. In order to improve the carbon efficiency, it is necessary to predict it. A comprehensive carbon ratio (CCR) was used to be the metric for estimating the carbon efficiency. An iron ore sintering process has the characteristics of autocorrelation of time series of CCR, multiple variables, linearity and nonlinearity, and time delay. In this study, a hybrid time series prediction model was built to predict the \\{CCR\\} based on these characteristics. It consists of two parts: time series prediction based on Elman recurrent neural network (RNN) and Elman-residuals prediction based on double joint linear-nonlinear extreme learning network (JLNELN). The Elman \\{RNN\\} with a context layer has the ability to model the dynamical and nonlinear components in the time series, and the double \\{JLNELN\\} with the input neurons not only connected to the hidden neurons but also to the output neurons has the ability to model both the nonlinear and linear components in the prediction residuals. Actual run data was collected to verify the validity of the devised hybrid model. Experiment results have shown that the hybrid model achieved much higher regression precision than a single Elman RNN, which shows the necessity and validity of the double \\{JLNELN\\} model in the prediction of the Elman residuals. The experiment results of the double \\{JLNELN\\} method also show higher regression precision than both a double extreme learning machine method and a single \\{JLNELN\\} method, which verified the validity of the \\{JLNELN\\} method and the double structure of the prediction model.", 
        "author": "Xiaoxia Chen and Xin Chen and Jinhua She and Min Wu", 
        "keyword": "Elman recurrent neural network\", \"Extreme learning machine\", \"Residual prediction\", \"Time series keywords =rediction\", \"Carbon efficiency\", \"Iron ore sintering process", 
        "title": "A hybrid time series prediction model based on recurrent neural network and double joint linear\u2013nonlinear extreme learning network for prediction of carbon efficiency in iron ore sintering process"
    }, 
    {
        "abstract": "Abstract A smart camera is a vision system capable of extracting application-specific information from the captured images. The paper proposes a decentralized and efficient solution for visual parking lot occupancy detection based on a deep Convolutional Neural Network (CNN) specifically designed for smart cameras. This solution is compared with state-of-the-art approaches using two visual datasets: PKLot, already existing in literature, and CNRPark-EXT. The former is an existing dataset, that allowed us to exhaustively compare with previous works. The latter dataset has been created in the context of this research, accumulating data across various seasons of the year, to test our approach in particularly challenging situations, exhibiting occlusions, and diverse and difficult viewpoints. This dataset is public available to the scientific community and is another contribution of our research. Our experiments show that our solution outperforms and generalizes the best performing approaches on both datasets. The performance of our proposed \\{CNN\\} architecture on the parking lot occupancy detection task, is comparable to the well-known AlexNet, which is three orders of magnitude larger.", 
        "author": "Giuseppe Amato and Fabio Carrara and Fabrizio Falchi and Claudio Gennaro and Carlo Meghini and Claudio Vairo", 
        "keyword": "Machine learning\", \"Classification\", \"Deep learning\", \"Convolutional neural networks\", \"Parking space dataset", 
        "title": "Deep learning for decentralized parking lot occupancy detection"
    }, 
    {
        "abstract": "Abstract This paper proposes an efficient optimization algorithm named chaotic teaching\u2013learning algorithm (CTLA), to solve multimachine power system stabilizers design problem. The original teaching learning algorithm as competitive to other optimization algorithms, used two phases to proceed to the global optimal solution: \u2018teacher phase\u2019 and \u2018learner phase\u2019. However, during the second phase an adequate interaction between the teacher and the learners in entire search space are not guaranteed and the algorithm may be trapped in local optima. Thus, in the proposed \\{CTLA\\} a new phase named \u201cchaotic phase\u201d is added in order to overcome this drawback. The performance of the \\{CTLA\\} is investigated by using a set of benchmark functions. To demonstrate the effectiveness of the proposed algorithm in power systems, the conventional lead-lag power system stabilizers (PSSs) are tuned for: three machines nine bus system (WSCC) and the ten machine thirty-nine bus New England power systems. The performance of the proposed CTLA-based \\{PSS\\} (CTLAPSSs) under different loading conditions and disturbances is investigated through eigen-value analysis, non-linear time domain-simulations and some performance indices.", 
        "author": "Anouar Farah and Tawfik Guesmi and Hsan Hadj Abdallah and Abderrazak Ouali", 
        "keyword": "Chaotic teaching learning\", \"Dynamic stability\", \"Low-frequency oscillation\", \"Power system stabilizer", 
        "title": "A novel chaotic teaching\u2013learning-based optimization algorithm for multi-machine power system stabilizers design problem"
    }, 
    {
        "abstract": "Abstract House sales are determined based on the Standard &amp; Poor\u2019s Case-Shiller home price indices and the housing price index of the Office of Federal Housing Enterprise Oversight (OFHEO). These reflect the trends of the \\{US\\} housing market. In addition to these housing price indices, the development of a housing price prediction model can greatly assist in the prediction of future housing prices and the establishment of real estate policies. This study uses machine learning algorithms as a research methodology to develop a housing price prediction model. To improve the accuracy of housing price prediction, this paper analyzes the housing data of 5359 townhouses in Fairfax County, Virginia, gathered by the Multiple Listing Service (MLS) of the Metropolitan Regional Information Systems (MRIS). We develop a housing price prediction model based on machine learning algorithms such as C4.5, RIPPER, Na\u00efve Bayesian, and AdaBoost and compare their classification accuracy performance. We then propose an improved housing price prediction model to assist a house seller or a real estate agent make better informed decisions based on house price valuation. The experiments demonstrate that the \\{RIPPER\\} algorithm, based on accuracy, consistently outperforms the other models in the performance of housing price prediction.", 
        "author": "Byeonghwa Park and Jae Kwon Bae", 
        "keyword": "Housing price index\", \"Housing price prediction model\", \"Machine learning algorithms\", \"C4.5\", keywords =RIPPER\", \"Na\u00efve Bayesian\", \"AdaBoost", 
        "title": "Using machine learning algorithms for housing price prediction: The case of Fairfax County, Virginia housing data"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel short-term load forecasting (STLF) method based on wavelet transform, extreme learning machine (ELM) and modified artificial bee colony (MABC) algorithm. The wavelet transform is used to decompose the load series for capturing the complicated features at different frequencies. Each component of the load series is then separately forecasted by a hybrid model of \\{ELM\\} and \\{MABC\\} (ELM-MABC). The global search technique \\{MABC\\} is developed to find the best parameters of input weights and hidden biases for ELM. Compared to the conventional neuro-evolution method, ELM-MABC can improve the learning accuracy with fewer iteration steps. The proposed method is tested on two datasets: \\{ISO\\} New England data and North American electric utility data. Numerical testing shows that the proposed method can obtain superior results as compared to other standard and state-of-the-art methods.", 
        "author": "Song Li and Peng Wang and Lalit Goel", 
        "keyword": "Artificial bee colony\", \"Extreme learning machine\", \"Short-term load forecasting\", \"Wavelet transform", 
        "title": "Short-term load forecasting by wavelet transform and evolutionary extreme learning machine"
    }, 
    {
        "abstract": "Abstract We propose a novel approach to the box office forecasting of motion pictures using social network service (SNS) data and machine learning-based algorithms. We begin by providing a comprehensive survey of the forecasting algorithms and explanatory variables used in the motion picture domain. Because of the importance of forecasting in early periods, we develop three sequential forecasting models for predicting the non-cumulative and cumulative box office earnings: (1) prior to, (2) a week after, and (3) two weeks after release. The numbers of \\{SNS\\} mentions and their weekly trends are used as input variables in addition to the screening-related information. A genetic algorithm is adopted for determining significant input variables, whereas three machine learning-based nonlinear regression algorithms and their combinations are employed for building forecasting models. Experimental results show that the utilization of \\{SNS\\} data, machine learning-based algorithms and their combination made noticeable improvements to the forecasting accuracies of all the three models.", 
        "author": "Taegu Kim and Jungsik Hong and Pilsung Kang", 
        "keyword": "Box office earning forecast\", \"Social network service\", \"Machine learning\", \"Genetic algorithm\", \"Forecast combination", 
        "title": "Box office forecasting using machine learning algorithms based on \\{SNS\\} data"
    }, 
    {
        "abstract": "Abstract In this paper, we investigate the problem of classifying an image set of an object, and develop a novel image set representation and classification algorithm. We propose to represent an image set by a joint representation method using both an affine hull of its image samples and a combination of its reference images, and further classify it by a linear classification function from its representation. A unified objective function is formulated to learn both the representation and classifier parameters. Similar to support vector machine, the hinge losses and the squared \u2113 2 norm of the image set classifier are minimized simultaneously in the objective. Moreover, the differences between the two different representations are also minimized. The objective function is optimized with respect to representation and classifier parameters alternately in an iterative algorithm. The proposed algorithm is named as support image set machine (SupISMac) because it takes advantage of support vector machine formulation to learn an image set classifier. The experiments on two different image set classification benchmark databases show that SupISMac not only outperforms the state-of-the-art image set classification methods, but also reduces the running time of test procedures significantly.", 
        "author": "Xin Du and Jim Jing-Yan Wang", 
        "keyword": "Image set classification\", \"Support vector machine\", \"Joint image set representation\", \"Fast keywords =terative shrinkage-thresholding\", \"Supervised learning", 
        "title": "Support image set machine: Jointly learning representation and classifier for image set classification"
    }, 
    {
        "abstract": "Abstract In this study, the application of a transductive support vector machine (TSVM), an innovative semi-supervised learning algorithm, has been proposed for mapping the potential drill targets at a detailed exploration stage. The semi-supervised learning method is a hybrid of supervised and unsupervised learning approach that simultaneously uses both training and non-training data to design a classifier. By using the \\{TSVM\\} algorithm, exploration layers at the Dalli porphyry Cu-Au deposit in the central Iran were integrated to locate the boundary of the Cu-Au mineralization for further drilling. By applying this algorithm on the non-training (unlabeled) and limited training (labeled) Dalli exploration data, the study area was classified in two domains of Cu-Au ore and waste. Then, the results were validated by the earlier block models created, using the available borehole and trench data. In addition to TSVM, the support vector machine (SVM) algorithm was also implemented on the study area for comparison. Thirty percent of the labeled exploration data was used to evaluate the performance of these two algorithms. The results revealed 87 percent correct recognition accuracy for the \\{TSVM\\} algorithm and 82 percent for the \\{SVM\\} algorithm. The deepest inclined borehole, recently drilled in the western part of the Dalli deposit, indicated that the boundary of Cu-Au mineralization, as identified by the \\{TSVM\\} algorithm, was only 15\u00a0m off from the actual boundary intersected by this borehole. According to the results of the \\{TSVM\\} algorithm, six new boreholes were suggested for further drilling at the Dalli deposit. This study showed that the \\{TSVM\\} algorithm could be a useful tool for enhancing the mineralization zones and consequently, ensuring a more accurate drill hole planning.", 
        "author": "Moslem Fatehi and Hooshang H. Asadi", 
        "keyword": "Mineral potential mapping\", \"Drilling\", \"Exploration targeting\", \"Semi-supervised learning\", keywords =Transductive support vector machines (TSVM)\", \"Dalli Cu-Au porphyry deposit", 
        "title": "Data integration modeling applied to drill hole planning through semi-supervised learning: A case study from the Dalli Cu-Au porphyry deposit in the central Iran"
    }, 
    {
        "abstract": "Abstract In this study we use a machine learning software (Ichnaea) to generate predictive models for water samples with different concentrations of fecal contamination (point source, moderate and low). We applied several \\{MST\\} methods (host-specific Bacteroides phages, mitochondrial \\{DNA\\} genetic markers, Bifidobacterium adolescentis and Bifidobacterium dentium markers, and bifidobacterial host-specific qPCR), and general indicators (Escherichia coli, enterococci and somatic coliphages) to evaluate the source of contamination in the samples. The results provided data to the Ichnaea software, that evaluated the performance of each method in the different scenarios and determined the source of the contamination. Almost all \\{MST\\} methods in this study determined correctly the origin of fecal contamination at point source and in moderate concentration samples. When the dilution of the fecal pollution increased (below 3 log10 \\{CFU\\} E.\u00a0coli/100\u00a0ml) some of these indicators (bifidobacterial host-specific qPCR, some mitochondrial markers or B.\u00a0dentium marker) were not suitable because their concentrations decreased below the detection limit. Using the data from source point samples, the software Ichnaea produced models for waters with low levels of fecal pollution. These models included some \\{MST\\} methods, on the basis of their best performance, that were used to determine the source of pollution in this area. Regardless the methods selected, that could vary depending on the scenario, inductive machine learning methods are a promising tool in \\{MST\\} studies and may represent a leap forward in solving \\{MST\\} cases.", 
        "author": "Arnau Casanovas-Massana and Marta G\u00f3mez-Do\u00f1ate and David S\u00e1nchez and Llu\u00eds A. Belanche-Mu\u00f1oz and Maite Muniesa and Anicet R. Blanch", 
        "keyword": "Fecal pollution\", \"Bacteria\", \"Bacteriophages\", \"Bifidobacterium\", \"Bacteroides\", \"Machine keywords =earning\", \"Microbial source tracking", 
        "title": "Predicting fecal sources in waters with diverse pollution loads using general and molecular host-specific indicators and applying machine learning methods"
    }, 
    {
        "abstract": "Abstract Accurate rainfall-runoff modeling during typhoon events is an essential task for natural disaster reduction. In this study, a novel hybrid model which integrates the outputs of physically based hydrologic modeling system into support vector machine is developed to predict hourly runoff discharges in Chishan Creek basin in southern Taiwan. Seven storms (with a total of 1200 data sets) are used for model calibration (training) and validation. Six statistical indices (mean absolute error, root mean square error, correlation coefficient, error of time to peak discharge, error of peak discharge, and coefficient of efficiency) are employed to assess prediction performance. Overall, superiority of the present approach especially for a longer (6-h) lead time prediction is revealed through a systematic comparison among three individual methods (i.e., the physically based hydrologic model, artificial neural network, and support vector machine) as well as their two hybrid combinations. Besides, our analysis and in-depth discussions further clarify the roles of physically based and data-driven components in the proposed framework.", 
        "author": "Chih-Chieh Young and Wen-Cheng Liu and Ming-Chang Wu", 
        "keyword": "Rainfall-runoff\", \"Typhoon events\", \"Hydrologic modeling system (HEC-HMS)\", \"Support vector keywords =egression (SVR)\", \"Artificial neural network (ANN)\", \"Hybrid approach", 
        "title": "A physically based and machine learning hybrid approach for accurate rainfall-runoff modeling during extreme typhoon events"
    }, 
    {
        "abstract": "Abstract In the field of Learning Automata (LA), how to design faster learning algorithms has always been a key issue. Among solutions reported in the literature, the stochastic estimator reward-inaction learning automaton (SERI), which belongs to the Maximum Likelihood estimator based LAs, has been recognized as the fastest \u03f5-optimal LA. In this paper, we first point out the limitations of the traditional Maximum Likelihood Estimator (MLE) based \\{LAs\\} and then introduce Bayesian estimator based approach, which is demonstrated to be equivalent to Laplace smoothing of the traditional method, to overcome these limitations. The key idea is that the Bayesian estimator, which estimates the probability of selecting each action in the LA, aims to reconstruct Bernoulli distribution from sequential data, and is formalized based on exponential conjugate family so that the \\{LA\\} has a relatively simple format for easy implementation. In addition, we also indicate that this Bayesian estimator could be applied to update almost all existing \\{MLE\\} estimator based LAs. Based on the proposed Bayesian estimator, a new LA, known as Generalized Bayesian Stochastic Estimator (GBSE) LA, is presented and proved to be \u03f5-optimal. Finally, extensive experimental results on benchmarks demonstrate that our proposed learning scheme is more efficient than the current best \\{LA\\} SERI.", 
        "author": "Wen Jiang and Bin Li and Shenghong Li and Yuanyan Tang and Chun Lung Philip Chen", 
        "keyword": "Learning Automata\", \"\u03f5-Optimal\", \"Bayesian estimator\", \"Maximum Likelihood Estimator", 
        "title": "A new prospective for Learning Automata: A machine learning approach"
    }, 
    {
        "abstract": "Abstract Supervised classification of quad-polarimetric \\{SAR\\} images is often constrained by the availability of reliable training samples. Active learning (AL) provides a unique capability at selecting samples with high representation quality and low redundancy. The most important part of \\{AL\\} is the criterion for selecting the most informative candidates (pixels) by ranking. In this paper, class supports based on the posterior probability function are approximated by ensemble learning and majority voting. This approximation is statistically meaningful when a large enough classifier ensemble is exploited. In this work, we propose to use extreme learning machines and apply \\{AL\\} to quad-polarimetric \\{SAR\\} image classification. Extreme learning machines are ideal because of their fast operation, straightforward solution and strong generalization. As inputs to the so-called active extreme learning machines, both polarimetric and spatial features (morphological profiles) are considered. In order to validate the proposed method, results and performance are compared with random sampling and state-of-the-art \\{AL\\} methods, such as margin sampling, normalized entropy query-by-bagging and multiclass level uncertainty. Experimental results for four quad-polarimetric \\{SAR\\} images collected by RADARSAT-2, AirSAR and \\{EMISAR\\} indicate that the proposed method achieves promising results in different scenarios. Moreover, the proposed method is faster than existing techniques in both the learning and the classification phases.", 
        "author": "Alim Samat and Paolo Gamba and Peijun Du and Jieqiong Luo", 
        "keyword": "PolSAR\", \"Extreme learning machine\", \"Ensemble learning\", \"Active learning\", \"Active extreme learning machines", 
        "title": "Active extreme learning machines for quad-polarimetric \\{SAR\\} imagery classification"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM), a simple single-hidden-layer feed-forward neural network with fast implementation, has been successfully applied in many fields. This paper proposes an \\{ELM\\} with a constructional structure (CS-ELM) for improving the performance of \\{ELM\\} in dealing with regression problems. In the CS-ELM, there are some partial input subnets (PISs). The first step in designing the \\{PISs\\} is to divide the data-attribute-space into several sub-spaces through using an improved extension clustering algorithm (IECA). The input data attributes in the same sub-space can build a \\{PIS\\} and the similar information of the data attributes is stored in the corresponding PIS. Additionally, a double parallel structure is applied in the CS-ELM, in which there is a special channel that directly connects the input layer neurons to the output layer neurons. In this regard, the proposed procedure can be called \\{ELM\\} with a data-attribute-space-oriented double parallel (DASODP) structure (DASODP\u2013ELM). To test the validity of the proposed method, it is applied to 4 regression applications. The experimental results indicate that, compared with ELM, DASODP\u2013ELM with less number of parameters can achieve higher regression precision in the generalization phase.", 
        "author": "Yan-Lin He and Zhi-Qiang Geng and Qun-Xiong Zhu", 
        "keyword": "Extreme learning machine\", \"Single-hidden-layer feed-forward neural network\", \"Neural networks\", keywords =Regressions\", \"Extension theory", 
        "title": "A data-attribute-space-oriented double parallel (DASODP) structure for enhancing extreme learning machine: Applications to regression datasets"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) is one of the artificial neural network method that introduced by Huang, this method has very fast learning capability. \\{ELM\\} is designed for balance data. Common problems in real-life is imbalanced data problem. So, for imbalanced data problem needs special treatment, because characteristics of the imbalanced data can decrease the accuracy of the data classification. The proposed method in this study is modified \\{ELM\\} to overcome the problems of imbalanced data by integrating the data selection process, which is called by Integrating the data selection and extreme learning machine (IDELM. Performances of learning method are evaluated using 13 imbalanced data from \\{UCI\\} Machine Learning Repository and Benchmark Data Sets for Highly Imbalanced Binary Classification (BDS). The validation includes comparison with some learning algorithms and the result showcases that average perform of our proposed learning method is compete and even outperform of some algorithm in some cases.", 
        "author": "Umi Mahdiyah and M. Isa Irawan and Elly Matul Imah", 
        "keyword": "Data Selection\", \"Extreme Learning Machine\", \"Imbalanced Data", 
        "title": "Integrating Data Selection and Extreme Learning Machine for Imbalanced Data"
    }, 
    {
        "abstract": "Abstract We extend extreme learning machine (ELM) classifiers to complex Reproducing Kernel Hilbert Spaces (RKHS) where the input/output variables as well as the optimization variables are complex-valued. A new family of classifiers, called complex-valued \\{ELM\\} (CELM) suitable for complex-valued multiple-input\u2013multiple-output processing is introduced. In the proposed method, the associated Lagrangian is computed using induced \\{RKHS\\} kernels, adopting a Wirtinger calculus approach formulated as a constrained optimization problem similarly to the conventional \\{ELM\\} classifier formulation. When training the CELM, the Karush\u2013Khun\u2013Tuker (KKT) theorem is used to solve the dual optimization problem that consists of satisfying simultaneously smallest training error as well as smallest norm of output weights criteria. The proposed formulation also addresses aspects of quaternary classification within a Clifford algebra context. For 2D complex-valued inputs, user-defined complex-coupled hyper-planes divide the classifier input space into four partitions. For 3D complex-valued inputs, the formulation generates three pairs of complex-coupled hyper-planes through orthogonal projections. The six hyper-planes then divide the 3D space into eight partitions. It is shown that the \\{CELM\\} problem formulation is equivalent to solving six real-valued \\{ELM\\} tasks, which are induced by projecting the chosen complex kernel across the different user-defined coordinate planes. A classification example of powdered samples on the basis of their terahertz spectral signatures is used to demonstrate the advantages of the \\{CELM\\} classifiers compared to their \\{SVM\\} counterparts. The proposed classifiers retain the advantages of their \\{ELM\\} counterparts, in that they can perform multiclass classification with lower computational complexity than \\{SVM\\} classifiers. Furthermore, because of their ability to perform classification tasks fast, the proposed formulations are of interest to real-time applications.", 
        "author": "X.-X. Yin and S. Hadjiloucas and J. He and Y. Zhang and Y. Wang and D. Zhang", 
        "keyword": "Complex extreme learning machine\", \"Reproducing Kernel Hilbert Space\", \"Quaternary classification\", keywords =Lagrangian\", \"Multiclass classification", 
        "title": "Application of complex extreme learning machine to multiclass classification problems with high dimensionality: A \\{THz\\} spectra classification problem"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM), as one of the most useful techniques in machine learning, has attracted extensive attentions due to its unique ability for extremely fast learning. In particular, it is widely recognized that \\{ELM\\} has speed advantage while performing satisfying results. However, the presence of outliers may give rise to unreliable \\{ELM\\} model. In this paper, our study addresses the outlier robustness of \\{ELM\\} in regression problems. Based on the sparsity characteristic of outliers, this work proposes an outlier-robust \\{ELM\\} where the \u21131-norm loss function is used to enhance the robustness. Specially, the fast and accurate augmented Lagrangian multiplier method is applied to guarantee the effectiveness and efficiency. According to the experiments on function approximation and some real-world applications, the proposed approach not only maintains the advantages from original ELM, but also shows notable and stable accuracy in handling data with outliers.", 
        "author": "Kai Zhang and Minxia Luo", 
        "keyword": "Extreme learning machine\", \"\u21131-norm\", \"Augmented Lagrange multipliers method\", \"Outlier robustness", 
        "title": "Outlier-robust extreme learning machine for regression problems"
    }, 
    {
        "abstract": "Abstract This paper compares machine learning techniques for detecting malicious webpages. The conventional method of detecting malicious webpages is going through the black list and checking whether the webpages are listed. Black list is a list of webpages which are classified as malicious from a user\u2019s point of view. These black lists are created by trusted organizations and volunteers. They are then used by modern web browsers such as Chrome, Firefox, Internet Explorer, etc. However, black list is ineffective because of the frequent-changing nature of webpages, growing numbers of webpages that pose scalability issues and the crawlers\u2019 inability to visit intranet webpages that require computer operators to log in as authenticated users. In this paper therefore alternative and novel approaches are used by applying machine learning algorithms to detect malicious webpages. In this paper three supervised machine learning techniques such as K-Nearest Neighbor, Support Vector Machine and Naive Bayes Classifier, and two unsupervised machine learning techniques such as K-Means and Affinity Propagation are employed. Please note that K-Means and Affinity Propagation have not been applied to detection of malicious webpages by other researchers. All these machine learning techniques have been used to build predictive models to analyze large number of malicious and safe webpages. These webpages were downloaded by a concurrent crawler taking advantage of gevent. The webpages were parsed and various features such as content, \\{URL\\} and screenshot of webpages were extracted to feed into the machine learning models. Computer simulation results have produced an accuracy of up to 98% for the supervised techniques and silhouette coefficient of close to 0.96 for the unsupervised techniques. These predictive models have been applied in a practical context whereby Google Chrome can harness the predictive capabilities of the classifiers that have the advantages of both the lightweight and the heavyweight classifiers.", 
        "author": "H.B. Kazemian and S. Ahmed", 
        "keyword": "K-Nearest Neighbor\", \"Support Vector Machine\", \"Naive Bayes\", \"Affinity Propagation\", \"K-Means\", \"Supervised and unsupervised learning", 
        "title": "Comparisons of machine learning techniques for detecting malicious webpages"
    }, 
    {
        "abstract": "Abstract When a robot is learning it needs to explore its environment and how its environment responds on its actions. When the environment is large and there are a large number of possible actions the robot can take, this exploration phase can take prohibitively long. However, exploration can often be optimised by letting a human expert guide the robot during its learning. Interactive machine learning, in which a human user interactively guides the robot as it learns, has been shown to be an effective way to teach a robot. It requires an intuitive control mechanism to allow the human expert to provide feedback on the robot\u2019s progress. This paper presents a novel method which combines Reinforcement Learning and Supervised Progressively Autonomous Robot Competencies (SPARC). By allowing the user to fully control the robot and by treating rewards as implicit, \\{SPARC\\} aims to learn an action policy while maintaining human supervisory oversight of the robot\u2019s behaviour. This method is evaluated and compared to Interactive Reinforcement Learning in a robot teaching task. Qualitative and quantitative results indicate that \\{SPARC\\} allows for safer and faster learning by the robot, whilst not placing a high workload on the human teacher.", 
        "author": "Emmanuel Senft and Paul Baxter and James Kennedy and S\u00e9verin Lemaignan and Tony Belpaeme", 
        "keyword": "Human-Robot interaction\", \"Reinforcement learning\", \"Interactive machine learning\", \"Robotics\", keywords =Progressive Autonomy\", \"Supervised autonomy", 
        "title": "Supervised autonomy for online learning in human-robot interaction"
    }, 
    {
        "abstract": "Abstract Traditional analytic methods are often ill-suited to the evolving world of health care big data characterized by massive volume, complexity, and velocity. In particular, methods are needed that can estimate models efficiently using very large datasets containing healthcare utilization data, clinical data, data from personal devices, and many other sources. Although very large, such datasets can also be quite sparse (e.g., device data may only be available for a small subset of individuals), which creates problems for traditional regression models. Many machine learning methods address such limitations effectively but are still subject to the usual sources of bias that commonly arise in observational studies. Researchers using machine learning methods such as lasso or ridge regression should assess these models using conventional specification tests.", 
        "author": "William H. Crown", 
        "keyword": "machine learning\", \"outcomes research\", \"treatment effects", 
        "title": "Potential Application of Machine Learning in Health Outcomes Research and Some Statistical Cautions"
    }, 
    {
        "abstract": "AbstractBackground Software fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. Method In this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. Results In this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. Conclusion Based on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.", 
        "author": "Ruchika Malhotra", 
        "keyword": "Machine learning\", \"Software fault proneness\", \"Systematic literature review", 
        "title": "A systematic review of machine learning techniques for software fault prediction"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) has attracted comprehensive attentions as a universal function approximator with its extremely fast learning speed and good generalization performance. Compared to other learning methods for Single Layer Feedforward Networks (SLFNs), the unique feature of the \\{ELM\\} is that the input parameters of hidden neurons are randomly generated rather than being iteratively tuned, and thereby dramatically reducing the computational burden. However, it has been pointed out that the randomness of the \\{ELM\\} parameters would result in fluctuating performance. In this paper, we systematically investigate the performance stabilization effect brought by a regularized variant of the ELM, named Regularized \\{ELM\\} (RELM). Furthermore, by using the \\{PREdiction\\} Sum of Squares (PRESS) statistics formula and a unique property of the RELM, we propose a semi-cross-validation algorithm to effectively realize a robust RELM-based model selection for SLFNs, termed as Automatic Regularized Extreme Learning Machine with Leave-One-Out cross-validation (AR-ELM-LOO). The simulation results show that the AR-ELM-LOO can significantly reduce the randomness performance of the \\{ELM\\} and it can produce nearly identical results as the full cross-validation procedure.", 
        "author": "Zhifei Shao and Meng Joo Er and Ning Wang", 
        "keyword": "Extreme learning machine\", \"Ridge regression\", \"Regularized \\{ELM\\}", 
        "title": "An effective semi-cross-validation model selection method for extreme learning machine with ridge regression"
    }, 
    {
        "abstract": "Abstract Machine learning algorithms are widely used for traffic classification and anomaly detection nowadays, however, how to fast and accurately classify the flows remains extremely challengeable. In this paper, we propose an extreme learning machine (ELM) based algorithm called L1-Norm Minimization ELM, which fully inherits the merits of ELM, and meanwhile, exhibits the sparsity-induced characteristics which could reduce the complexity of learning model. At the evaluation stage, we preprocessed the raw data trace from trans-Pacific backbone link between Japan and the United States, and generated 248 features datasets. The empirical study shows that L1-ELM can achieve good generalization performance on the evaluation datasets, while preserving the fast learning and little human intervened advantages that \\{ELM\\} has.", 
        "author": "Yibing Wang and Dong Li and Yi Du and Zhisong Pan", 
        "keyword": "Traffic classification\", \"Anomaly detection\", \"Extreme learning machine\", \"Support vector machine\", \"L1-norm minimization", 
        "title": "Anomaly detection in traffic using L1-norm minimization extreme learning machine"
    }, 
    {
        "abstract": "Abstract Numerous people die of paraquat (PQ) poisoning because they were not diagnosed and treated promptly at an early stage. Till now, determination of \\{PQ\\} levels in blood or urine is still the only way to confirm the \\{PQ\\} poisoning. In order to develop a new diagnostic method, the potential of machine learning technique was explored in this study. A newly developed classification technique, extreme learning machine (ELM), was taken to discriminate the PQ-poisoned patients from the healthy controls. 15 PQ-poisoned patients recruited from The First Affiliated Hospital of Wenzhou Medical University who had a history of direct contact with \\{PQ\\} and 16 healthy volunteers were involved in the study. The \\{ELM\\} method is examined based on the metabolites of blood samples determined by gas chromatography coupled with mass spectrometry in terms of classification accuracy, sensitivity, specificity and \\{AUC\\} (area under the receiver operating characteristic (ROC) curve) criterion, respectively. Additionally, the feature selection was also investigated to further boost the performance of \\{ELM\\} and the most influential feature was detected. The experimental results demonstrate that the proposed approach can be regarded as a success with the excellent classification accuracy, AUC, sensitivity and specificity of 91.64%, 0.9156%, 91.33% and 91.78%, respectively. Promisingly, the proposed method might serve as a new candidate of powerful tools for diagnosis of PQ-poisoned patients with excellent performance.", 
        "author": "Lufeng Hu and Guangliang Hong and Jianshe Ma and Xianqin Wang and Huiling Chen", 
        "keyword": "Paraquat\", \"Poison\", \"Extreme learning machine\", \"Medical diagnosis", 
        "title": "An efficient machine learning approach for diagnosis of paraquat-poisoned patients"
    }, 
    {
        "abstract": "Abstract Various Web spam features and machine learning structures were constantly proposed to classify Web spam in recent years. The aim of this paper was to provide a comprehensive machine learning algorithms comparison within the Web spam detection community. Several machine learning algorithms and ensemble meta-algorithms as classifiers, area under receiver operating characteristic as performance evaluation and two public available datasets (WEBSPAM-UK2006 and WEBSPAM-UK2007) were experimented in this study. The results have shown that random forest with variations of AdaBoost had achieved 0.937 in WEBSPAM-UK2006 and 0.852 in WEBSPAM-UK2007.", 
        "author": "Kwang Leng Goh and Ashutosh Kumar Singh", 
        "keyword": "Machine Learning\", \"Web Spam Classification\", \"Web Spamming", 
        "title": "Comprehensive Literature Review on Machine Learning Structures for Web Spam Classification"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM), proposed by Huang et al. in 2004 for the first time, performs better than traditional learning machines such as \\{BP\\} networks and \\{SVM\\} in some applications. This paper attempts to give an oscillation bound of the generalization performance of \\{ELM\\} and a reason why \\{ELM\\} is not sensitive to the number of hidden nodes, which are essential open problems proposed by Huang et al. in 2011. The derivation of the bound is in the framework of statistical learning theory and under the assumption that the expectation of the \\{ELM\\} kernel exists. It turns out that our bound is consistent with the experimental results about \\{ELM\\} obtained before and predicts that overfitting can be avoided even when the number of hidden nodes approaches infinity. The prediction is confirmed by our experiments on 15 data sets using one kind of activation function with every parameter independently drawn from the same Guasssian distribution, which satisfies the assumption above. The experiments also showed that when the number of hidden nodes approaches infinity, the \\{ELM\\} kernel with the activation is insensitive to the kernel parameter.", 
        "author": "Di Wang and Ping Wang and Yan Ji", 
        "keyword": "Extreme learning machine\", \"Oscillation bound\", \"Generalization performance\", \"Theoretical keywords =esearch\", \"Infinite hidden nodes", 
        "title": "An oscillation bound of the generalization performance of extreme learning machine and corresponding analysis"
    }, 
    {
        "abstract": "Abstract In this age of big data, analyzing big data is a very challenging problem. MapReduce is a simple, scalable and fault-tolerant data processing framework that enables us to process a massive volume of data. Many machine learning algorithms have been designed based on MapReduce, but there are only a few works related to parallel extreme learning machine (ELM) which is a fast and accurate learning algorithm. Online sequential extreme learning machine (OS-ELM) is one of improved \\{ELM\\} algorithms to support online sequential learning efficiently. In this paper, we first analyze the dependency relationships of matrix calculations of OS-ELM, then propose a parallel online sequential extreme learning machine (POS-ELM) based on MapReduce. POS-ELM is evaluated with real and synthetic data with the maximum number of training data 1280 K and the maximum number of attributes 128. The experimental results show that the training accuracy and testing accuracy of POS-ELM are at the same level as those of OS-ELM and ELM, and it has good scalability with regard to the number of training data and the number of attributes. Compared to original \\{ELM\\} and OS-ELM where the capability to process large scale data is bounded by the limitation of resources within a single processing unit, POS-ELM can deal with much larger scale data. The larger the number of training data is, the higher the speedup of POS-ELM is. It can be concluded that POS-ELM has more powerful capability than both \\{ELM\\} and OS-ELM for large scale learning.", 
        "author": "Botao Wang and Shan Huang and Junhao Qiu and Yu Liu and Guoren Wang", 
        "keyword": "Extreme learning machine\", \"Large scale learning\", \"Online sequential learning\", \"Mapreduce\", \"Parallel classification", 
        "title": "Parallel online sequential extreme learning machine based on MapReduce"
    }, 
    {
        "abstract": "Abstract Multi-agent systems in complex, real time domains require agents to act effectively both autonomously and as part of a team. The complexity of many tasks arising in these domains makes them difficult to solve with pre-programmed agent behaviors. The agents must instead discover a solution on their own, using learning. In this paper, we present \\{MLIMAS\\} a framework for Machine Learning in Interactive Multi-Agent Systems. The \\{MLIMAS\\} is proposed to provide answers to the issues arising from integrating machine learning algorithms in interactive multi-agent systems, focusing on three questions i) what are the learning targets for agents?, (ii) how can the machine learning system be integrated into the agent architecture?, and (iii) how can agents learn interactively?. \\{MLIMAS\\} addresses those three questions plus supporting multi-agent systems consisting of autonomous and adaptive agents acting in real-time and noisy environments. As a result of such required capabilities, \\{MLIMAS\\} allows dynamic and intelligent behavior of the agents to efficiently achieve their local and coalition goals such through modeling other agents actions, and interactively taking benefits of self and others preferences in learning and achieving the agents goals. We studied the proposed framework in the Taxi Domain compared with the traditional Q-Learning algorithm without interactive share of information. Our experiments showed 2 times improvement for the average award received per agents trail rather than the traditional Q-Learning approach. In addition, we have got %80 improvement for the same number of trials of the agents to reach the passengers.", 
        "author": "Khaled M. Khalil and M. Abdel-Aziz and Taymour T. Nazmy and Abdel-Badeeh M. Salem", 
        "keyword": "Multi-Agent Systems\", \"Agent Based Learning Framework\", \"Interactive Multi-Agent Learning\", keywords =Artificial Intelligence\", \"Machine Learning\", \"Knowledge Engineering\", \"Taxi Domain", 
        "title": "MLIMAS: A Framework for Machine Learning in Interactive Multi-agent Systems"
    }, 
    {
        "abstract": "Abstract Rapeseed is widely cultivated throughout the world for the production of animal feed, vegetable fat for human consumption, and biodiesel. Since the seeds are evaluated in many areas for sowing and oilseed processing, they must be identified quickly and accurately for selection of a correct variety. An affordable method based on computer vision and machine learning was proposed to classify the seven rapeseed varieties. Different types of feature sets, feature models, and machine learning classifiers were investigated to obtain the best predictive model for rapeseed classification. The training and test sets were used to tune the model parameters during the training epochs by varying the complexity of the predictive models with grid-search and K-fold cross validation. After obtaining optimized models for each level of complexity, a dedicated validation set was used to validate predictive models. The developed computer vision system provided an overall accuracy rate of 99.24% for the best predictive model in discriminating rapeseed variety.", 
        "author": "F. Kurtulmu\u015f and H. \u00dcnal", 
        "keyword": "Rapeseed\", \"Variety discrimination\", \"Computer vision\", \"Machine learning", 
        "title": "Discriminating rapeseed varieties using computer vision and machine learning"
    }, 
    {
        "abstract": "AbstractObjective Manual evaluation of machine learning algorithms and selection of a suitable classifier from the list of available candidate classifiers, is highly time consuming and challenging task. If the selection is not carefully and accurately done, the resulting classification model will not be able to produce the expected performance results. In this study, we present an accurate multi-criteria decision making methodology (AMD) which empirically evaluates and ranks classifiers\u2019 and allow end users or experts to choose the top ranked classifier for their applications to learn and build classification models for them. Methods and material Existing classifiers performance analysis and recommendation methodologies lack (a) appropriate method for suitable evaluation criteria selection, (b) relative consistent weighting mechanism, (c) fitness assessment of the classifiers\u2019 performances, and (d) satisfaction of various constraints during the analysis process. To assist machine learning practitioners in the selection of suitable classifier(s), \\{AMD\\} methodology is proposed that presents an expert group-based criteria selection method, relative consistent weighting scheme, a new ranking method, called optimum performance ranking criteria, based on multiple evaluation metrics, statistical significance and fitness assessment functions, and implicit and explicit constraints satisfaction at the time of analysis. For ranking the classifiers performance, the proposed ranking method integrates Wgt.Avg.F-score, CPUTimeTesting, CPUTimeTraining, and Consistency measures using the technique for order performance by similarity to ideal solution (TOPSIS). The final relative closeness score produced by TOPSIS, is ranked and the practitioners select the best performance (top-ranked) classifier for their problems in-hand. Findings Based on the extensive experiments performed on 15 publically available \\{UCI\\} and OpenML datasets using 35 classification algorithms from heterogeneous families of classifiers, an average Spearman's rank correlation coefficient of 0.98 is observed. Similarly, the \\{AMD\\} method has showed improved performance of 0.98 average Spearman's rank correlation coefficient as compared to 0.83 and 0.045 correlation coefficient of the state-of-the-art ranking methods, performance of algorithms (PAlg) and adjusted ratio of ratio (ARR). Conclusion and implication The evaluation, empirical analysis of results and comparison with state-of-the-art methods demonstrate the feasibility of \\{AMD\\} methodology, especially the selection and weighting of right evaluation criteria, accurate ranking and selection of optimum performance classifier(s) for the user's application's data in hand. \\{AMD\\} reduces expert's time and efforts and improves system performance by designing suitable classifier recommended by \\{AMD\\} methodology.", 
        "author": "Rahman Ali and Sungyoung Lee and Tae Choong Chung", 
        "keyword": "Multi-criteria decision making\", \"Algorithm recommendation\", \"Algorithm selection\", \"Classification keywords =lgorithms\", \"Classifiers recommendation\", \"TOPSIS\", \"Ranking classifiers", 
        "title": "Accurate multi-criteria decision making methodology for recommending machine learning algorithm"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) has shown its good generalization performance and extremely fast learning speed in many learning applications. Recently, it has been proved that \\{ELM\\} outperforms Support Vector Machine (SVM) with less constraints from the optimization point of view. \\{ELM\\} provides unified learning schemes with a widespread type of feature mappings. Among these unified algorithms, \\{ELM\\} with kernels applies kernels instead of random feature mappings. However, with the exponentially increasing volume of training data in massive learning applications, centralized \\{ELM\\} with kernels suffers from the great memory consumption of large matrix operations. Besides, due to the high communication cost, some of these matrix operations cannot be directly implemented on shared-nothing distributed computing model like MapReduce. This paper proposes a distributed solution named Distributed Kernelized \\{ELM\\} (DK-ELM), which realizes an implementation of \\{ELM\\} with kernels on MapReduce. Distributed kernel matrix calculation and multiplication of matrix with vector are also applied to realize parallel calculation of DK-ELM. Extensive experiments on massive datasets are conducted to verify both the scalability and training performance of DK-ELM. Experimental results show that DK-ELM has good scalability for massive learning applications.", 
        "author": "Xin Bi and Xiangguo Zhao and Guoren Wang and Pan Zhang and Chao Wang", 
        "keyword": "Extreme Learning Machine\", \"Extreme Learning Machine with kernels\", \"Massive data learning\", \"MapReduce", 
        "title": "Distributed Extreme Learning Machine with kernels based on MapReduce"
    }, 
    {
        "abstract": "Abstract A new method for analysis of text-based reports in accident coding is suggested. This approach utilizes latent semantic analysis to infer higher-order structures between documents and provide an unbiased metric to the narrative analysis process. Results from this study on a small sample of aviation safety narratives demonstrates an unsupervised categorization accuracy of 44% for primary-cause within the existing taxonomy. If provided with a large sample set, the indication is that a significant increase in accuracy is possible along with the possibility of recoding between data sets. Demonstrated is the ability of \\{LSA\\} to capture contextual proximity of a narrative.", 
        "author": "S.D. Robinson and W.J. Irwin and T.K. Kelly and X.O. Wu", 
        "keyword": "LSA\", \"Adaptive taxonomy\", \"Safety\", \"Automatic indexing\", \"Machine learning", 
        "title": "Application of machine learning to mapping primary causal factors in self reported safety narratives"
    }, 
    {
        "abstract": "Abstract We investigate the performance of three different machine learning algorithms, namely C5.0, AdaBoost and Genetic programming (GP), to generate robust classifiers for identifying VoIP encrypted traffic. To this end, a novel approach (Alshammari and Zincir-Heywood, 2011) based on machine learning is employed to generate robust signatures for classifying VoIP encrypted traffic. We apply statistical calculation on network flows to extract a feature set without including payload information, and information based on the source and destination of ports number and \\{IP\\} addresses. Our results show that finding and employing the most suitable sampling and machine learning technique can improve the performance of classifying VoIP significantly.", 
        "author": "Riyad Alshammari and A. Nur Zincir-Heywood", 
        "keyword": "Machine learning\", \"Encrypted traffic\", \"Robustness\", \"Network signatures", 
        "title": "Identification of VoIP encrypted traffic using a machine learning approach"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) and its variants have been widely used for many applications due to its fast convergence and good generalization performance. Though the distributed ELM\u204e based on MapReduce framework can handle very large scale training dataset in big data applications, how to cope with its rapidly updating is still a challenging task. Therefore, in this paper, a novel Elastic Extreme Learning Machine based on MapReduce framework, named Elastic \\{ELM\\} (E2LM), is proposed to cover the shortage of ELM\u204e whose learning ability is weak to the updated large-scale training dataset. Firstly, after analyzing the property of ELM\u204e adequately, it can be found out that its most computation-expensive part, matrix multiplication, can be incrementally, decrementally and correctionally calculated. Next, the Elastic \\{ELM\\} based on MapReduce framework is developed, which first calculates the intermediate matrix multiplications of the updated training data subset, and then update the matrix multiplications by modifying the old matrix multiplications with the intermediate ones. Then, the corresponding new output weight vector can be obtained with centralized computing using the update the matrix multiplications. Therefore, the efficient learning of rapidly updated massive training dataset can be realized effectively. Finally, we conduct extensive experiments on synthetic data to verify the effectiveness and efficiency of our proposed \\{E2LM\\} in learning massive rapidly updated training dataset with various experimental settings.", 
        "author": "Junchang Xin and Zhiqiong Wang and Luxuan Qu and Guoren Wang", 
        "keyword": "Extreme learning machine\", \"Big data classification\", \"Incremental learning\", \"Decremental keywords =earning\", \"Correctional learning", 
        "title": "Elastic extreme learning machine for big data classification"
    }, 
    {
        "abstract": "Abstract Traditional kernel-based semi-supervised learning (SSL) algorithms usually have high computational complexity. Moreover, few \\{SSL\\} methods have been proposed to utilize both the manifold of unlabeled data and pairwise constraints effectively. In this paper, we first construct a unified \\{SSL\\} framework to combine the manifold regularization and the terms based on the pairwise constraints for semi-supervised classification tasks. Motivated by the effectiveness of extreme learning machine (ELM), we further utilize \\{ELM\\} to approximate the established kernel-based \\{SSL\\} framework. Finally, we present a fast semi-supervised extreme learning machine with manifold regularization and pairwise constraints. Experimental results on a variety of real-world data sets demonstrate the effectiveness of the proposed fast \\{SSL\\} algorithm.", 
        "author": "Yong Zhou and Beizuo Liu and Shixiong Xia and Bing Liu", 
        "keyword": "Semi-supervised learning\", \"Extreme learning machine (ELM)\", \"Pairwise constraints\", \"Regularization", 
        "title": "Semi-supervised extreme learning machine with manifold and pairwise constraints regularization"
    }, 
    {
        "abstract": "Rapid advances in high-throughput genomic technology have enabled biology to enter the era of \u2018Big Data\u2019 (large datasets). The plant science community not only needs to build its own Big-Data-compatible parallel computing and data management infrastructures, but also to seek novel analytical paradigms to extract information from the overwhelming amounts of data. Machine learning offers promising computational and analytical solutions for the integrative analysis of large, heterogeneous and unstructured datasets on the Big-Data scale, and is gradually gaining popularity in biology. This review introduces the basic concepts and procedures of machine-learning applications and envisages how machine learning could interface with Big Data technology to facilitate basic research and biotechnology in the plant sciences.", 
        "author": "Chuang Ma and Hao Helen Zhang and Xiangfeng Wang", 
        "keyword": "Big Data\", \"machine learning\", \"large-scale datasets\", \"plants", 
        "title": "Machine learning for Big Data analytics in plants"
    }, 
    {
        "abstract": "AbstractObjective To develop a machine learning (ML) methodology based on features extracted from odd-ball auditory evoked potentials to identify neurophysiologic changes induced by Clozapine (CLZ) treatment in responding schizophrenic (SCZ) subjects. This objective is of particular interest because CLZ, though a potentially dangerous drug, can be uniquely effective for otherwise medication-resistant \\{SCZ\\} subjects. We wish to determine whether \\{ML\\} methods can be used to identify a set of EEG-based discriminating features that can simultaneously (1) distinguish all the \\{SCZ\\} subjects before treatment (BT) from healthy volunteer (HV) subjects, (2) distinguish \\{EEGs\\} collected before \\{CLZ\\} treatment (BT) vs. those collected after treatment (AT) for those subjects most responsive to CLZ, (3) discriminate least responsive subjects from \\{HV\\} AT, and (4) no longer discriminate most responsive subjects from \\{HVs\\} AT. If a set of EEG-derived features satisfy these four conditions, then it may be concluded that these features normalize in responsive subjects as a result of \\{CLZ\\} treatment, and therefore potentially provide insight into the functioning of the drug on the \\{SCZ\\} brain. Methods Odd-ball auditory evoked potentials of 66 \\{HVs\\} and 47 \\{SCZ\\} adults both \\{BT\\} and \\{AT\\} with \\{CLZ\\} were derived from \\{EEG\\} recordings. Treatment outcome, after at least one year follow-up, was assessed through clinical rating scores assigned by an experienced clinician, blind to \\{EEG\\} results. Using a criterion of at least 35% improvement after \\{CLZ\\} treatment, subjects were divided into \u201cmost-responsive\u201d (MR) and \u201cleast-responsive\u201d (LR) groups. As a first step, a brain source localization (BSL) procedure was employed on the \\{EEG\\} signals to extract source waveforms from specified brain regions. \\{ML\\} methods were then applied to these source waveform signals to determine whether a set of features satisfying the four conditions outlined above could be discovered. Results A set of cross-power spectral density (CPSD) features meeting these criteria was identified. These \\{CPSD\\} features, consisting of a combination of brain regional source activity and connectivity measures, significantly overlap with the default mode network (DMN). All decrease with \\{CLZ\\} treatment in responding SCZs. Conclusions A set of EEG-derived discriminating features which normalize as a result of \\{CLZ\\} treatment was identified. These discriminating features define a network that shares significant commonality with the DMN. Our findings are consistent with those of previous literature, which suggest that regions of the \\{DMN\\} are hyperactive and hyperconnected in \\{SCZ\\} subjects. Our study shows that these discriminating features decrease after treatment, consistent with portions of the \\{DMN\\} normalizing with \\{CLZ\\} therapy in responsive subjects. Significance Machine learning is proposed as a potentially powerful tool for analysis of the effect of medication on psychiatric illness. If replicated, the proposed approach could be used to gain some improved understanding of the effect of neuroleptic medications in treating psychotic illness. These results may also be useful in the development of new pharmaceuticals, since a new drug which induces changes in brain electrophysiology similar to those seen after \\{CLZ\\} could also have powerful antipsychotic properties.", 
        "author": "Maryam Ravan and Gary Hasey and James P. Reilly and Duncan MacCrimmon and Ahmad Khodayari-Rostamabad", 
        "keyword": "Brain source localization\", \"EEG signals\", \"Odd-ball auditory evoked potentials\", \"Machine keywords =earning\", \"Schizophrenia\", \"Clozapine treatment", 
        "title": "A machine learning approach using auditory odd-ball responses to investigate the effect of Clozapine therapy"
    }, 
    {
        "abstract": "Abstract Automated detection of snow avalanches is crucial to assess the effectiveness of avalanche control by explosions, and to monitor avalanche activity in a given area in view of avalanche forecasting. Several automated or semi-automated detection technologies have been developed in the past among which infrasound-based detection is the most promising for regional-scale avalanche monitoring. However, due to significant ambient noise content in infrasonic signals, e.g. from atmospheric processes or airplanes, fully automated and reliable avalanche detection has been very challenging. Signal processing is highly critical and strongly affects detection accuracy. Here, a robust detection method by using supervised machine learning is introduced. Machine learning algorithms can take into account multiple signal features and statistically optimize the classification task. We analyzed infrasound data with concurrent visual avalanche observations from the test site Lavin (Eastern Swiss Alps) for the winter of 2011\u20132012. A support vector machine was trained by using training data from the first half of the winter season and the accuracy was tested on data from the second half of the season. A significant reduction of false detections, from 65% to 10%, was achieved compared to a threshold-based classifier provided by the sensor manufacturer. The proposed method enables reliable assessment of the avalanche activity in the surroundings of the system and paves the way towards robust and fully automated avalanche detection using infrasonic systems.", 
        "author": "Thomas Th\u00fcring and Marcel Schoch and Alec van Herwijnen and J\u00fcrg Schweizer", 
        "keyword": "Snow avalanches\", \"Infrasound\", \"Array processing\", \"Automated monitoring\", \"Machine learning", 
        "title": "Robust snow avalanche detection using supervised machine learning with infrasonic sensor arrays"
    }, 
    {
        "abstract": "Abstract Recent research revealed that model-assisted parameter tuning can improve the quality of supervised machine learning (ML) models. The tuned models were especially found to generalize better and to be more robust compared to other optimization approaches. However, the advantages of the tuning often came along with high computation times, meaning a real burden for employing tuning algorithms. While the training with a reduced number of patterns can be a solution to this, it is often connected with decreasing model accuracies and increasing instabilities and noise. Hence, we propose a novel approach defined by a two criteria optimization task, where both the runtime and the quality of \\{ML\\} models are optimized. Because the budgets for this optimization task are usually very restricted in ML, the surrogate-assisted Efficient Global Optimization (EGO) algorithm is adapted. In order to cope with noisy experiments, we apply two hypervolume indicator based \\{EGO\\} algorithms with smoothing and re-interpolation of the surrogate models. The techniques do not need replicates. We find that these \\{EGO\\} techniques can outperform traditional approaches such as latin hypercube sampling (LHS), as well as \\{EGO\\} variants with replicates.", 
        "author": "Patrick Koch and Tobias Wagner and Michael T.M. Emmerich and Thomas B\u00e4ck and Wolfgang Konen", 
        "keyword": "Machine learning\", \"Multi-criteria optimization\", \"Efficient Global Optimization\", \"Kriging\", \"Hypervolume indicator", 
        "title": "Efficient multi-criteria optimization on noisy machine learning problems"
    }, 
    {
        "abstract": "Abstract The prediction of future drought is an effective mitigation tool for assessing adverse consequences of drought events on vital water resources, agriculture, ecosystems and hydrology. Data-driven model predictions using machine learning algorithms are promising tenets for these purposes as they require less developmental time, minimal inputs and are relatively less complex than the dynamic or physical model. This paper authenticates a computationally simple, fast and efficient non-linear algorithm known as extreme learning machine (ELM) for the prediction of Effective Drought Index (EDI) in eastern Australia using input data trained from 1957\u20132008 and the monthly \\{EDI\\} predicted over the period 2009\u20132011. The predictive variables for the \\{ELM\\} model were the rainfall and mean, minimum and maximum air temperatures, supplemented by the large-scale climate mode indices of interest as regression covariates, namely the Southern Oscillation Index, Pacific Decadal Oscillation, Southern Annular Mode and the Indian Ocean Dipole moment. To demonstrate the effectiveness of the proposed data-driven model a performance comparison in terms of the prediction capabilities and learning speeds was conducted between the proposed \\{ELM\\} algorithm and the conventional artificial neural network (ANN) algorithm trained with Levenberg\u2013Marquardt back propagation. The prediction metrics certified an excellent performance of the \\{ELM\\} over the \\{ANN\\} model for the overall test sites, thus yielding Mean Absolute Errors, Root-Mean Square Errors, Coefficients of Determination and Willmott's Indices of Agreement of 0.277, 0.008, 0.892 and 0.93 (for ELM) and 0.602, 0.172, 0.578 and 0.92 (for ANN) models. Moreover, the \\{ELM\\} model was executed with learning speed 32 times faster and training speed 6.1 times faster than the \\{ANN\\} model. An improvement in the prediction capability of the drought duration and severity by the \\{ELM\\} model was achieved. Based on these results we aver that out of the two machine learning algorithms tested, the \\{ELM\\} was the more expeditious tool for prediction of drought and its related properties.", 
        "author": "Ravinesh C. Deo and Mehmet \u015eahin", 
        "keyword": "Extreme learning machine\", \"Artificial neural network\", \"Drought prediction\", \"Effective Drought Index", 
        "title": "Application of the extreme learning machine algorithm for the prediction of monthly Effective Drought Index in eastern Australia"
    }, 
    {
        "abstract": "Abstract The current approaches of e-learning face challenges, in isolation of learners from learning process, and shortage of learning process quality. The researchers mentioned that the next generation of e-learning is e-learning ecosystem. E-learning ecosystem has many advantages, in which, learners form groups, collaborate with each other and with educators, and content designed for interaction. E-learning ecosystem faces some issues. It applies teacher-student model, in which, fixed learning pathway is considered suitable for all learners. Consequently, learners are presented with limited personalized materials. E-learning ecosystem needs to merge the personalization's concept. Semantic web ontology based personalization of learning environment plays a leading role to build smart e-learning ecosystem. This paper previews a detailed study which addresses research papers that apply ontology within learning environment. Most of these studies focus on personalizing e-learning by providing learners with suitable learning objects, ignoring the other learning process components. This paper proposes and implements framework for smart e-learning ecosystem using ontology and SWRL. A new direction is proposed. This direction fosters the creation of a separate four ontologies for the personalized full learning package which is composed of learner model and all the learning process components (learning objects, learning activities and teaching methods).", 
        "author": "Shimaa Ouf and Mahmoud Abd Ellatif and S.E. Salama and Yehia Helmy", 
        "keyword": "E-Learning ecosystem\", \"Personalization\", \"Ontology\", \"Software architecture\", \"Semantic Web Rule keywords =anguage\", \"Learner model", 
        "title": "A proposed paradigm for smart learning environment based on semantic web"
    }, 
    {
        "abstract": "Abstract In this investigation, an advanced modeling method, called online sequential extreme learning machine with a hyper-level fault tolerance-based supervisor (OSELM\u2013FTS), is utilized to develop a robust safety-oriented autonomous cruise control based on the model predictive control (MPC) technique. The resulting MPC-based cruise controller is used to improve the driving safety and reduce the energy consumption of an electric vehicle (EV). The structural flexibility of OSELM\u2013FTS allows us to not only improve the operating features of the EV, but also develop an intelligent supervisor which can detect any operating fault and send proper commands for the adaption of the \\{MPC\\} controller. This introduces a degree of robustness to the devised controller, as OSELM\u2013FTS automatically detects and filters any operating faults which may undermine the performance of the \\{MPC\\} controller. To ascertain the veracity of the devised controller, three well-known \\{MPC\\} formulations, i.e. linear \\{MPC\\} (LMPC) and nonlinear \\{MPC\\} (NMPC) and diagonal recurrent neural network \\{MPC\\} (DRNN-MPC), are applied to the baseline \\{EV\\} and their performances are compared with OSELM\u2013FTS-MPC. To further elaborate on the computational advantages of OSELM, a well-known chunk-by-chunk incremental machine learning approach, namely selective negative correlation learning (SNCL), is taken into account. The results of the comparative study indicate that OSELM\u2013FTS-MPC is a very promising control scheme and can be reliably used for safety-oriented autonomous cruise control of the EVs.", 
        "author": "Ahmad Mozaffari and Mahyar Vajedi and Nasser L. Azad", 
        "keyword": "Electric vehicles\", \"Autonomous cruise control\", \"Model predictive control\", \"Online sequential keywords =xtreme learning machine\", \"Hyper-level fault-tolerance based supervisor", 
        "title": "A robust safety-oriented autonomous cruise control scheme for electric vehicles based on model predictive control and online sequential extreme learning machine with a hyper-level fault tolerance-based supervisor"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) has been proposed as a new algorithm for training single hidden layer feed forward neural networks. The main merit of \\{ELM\\} lies in the fact that the input weights as well as hidden layer bias are randomly generated and thus the output weights can be obtained analytically, which can overcome the drawbacks incurred by gradient-based training algorithms such as local optima, improper learning rate and low learning speed. Based on the consistency property of data, which enforces similar samples to share similar properties, we propose a discriminative graph regularized Extreme Learning Machine (GELM) for further enhancing its classification performance in this paper. In the proposed \\{GELM\\} model, the label information of training samples are used to construct an adjacent graph and correspondingly the graph regularization term is formulated to constrain the output weights to learn similar outputs for samples from the same class. The proposed \\{GELM\\} model also has a closed form solution as the standard \\{ELM\\} and thus the output weights can be obtained efficiently. Experiments on several widely used face databases show that our proposed \\{GELM\\} can achieve much performance gain over standard \\{ELM\\} and regularized ELM. Moreover, \\{GELM\\} also performs well when compared with the state-of-the-art classification methods for face recognition.", 
        "author": "Yong Peng and Suhang Wang and Xianzhong Long and Bao-Liang Lu", 
        "keyword": "Extreme learning machine\", \"Graph Laplacian\", \"Manifold regularization\", \"Face recognition", 
        "title": "Discriminative graph regularized extreme learning machine and its application to face recognition"
    }, 
    {
        "abstract": "Abstract In this paper, an online sequential extreme learning machine with kernels (OS-ELMK) has been proposed for nonstationary time series prediction. An online sequential learning algorithm, which can learn samples one-by-one or chunk-by-chunk, is developed for extreme learning machine with kernels. A limited memory prediction strategy based on the proposed OS-ELMK is designed to model the nonstationary time series. Performance comparisons of OS-ELMK with other existing algorithms are presented using artificial and real life nonstationary time series data. The results show that the proposed OS-ELMK produces similar or better accuracies with at least an order-of-magnitude reduction in the learning time.", 
        "author": "Xinying Wang and Min Han", 
        "keyword": "Online\", \"Time series\", \"Extreme learning machine\", \"Support vector machine\", \"Nonstationary", 
        "title": "Online sequential extreme learning machine with kernels for nonstationary time series prediction"
    }, 
    {
        "abstract": "Abstract The emergence of the big data problem has pushed the machine learning research community to develop unsupervised, distributed and computationally efficient learning algorithms to benefit from this data. Extreme learning machines (ELM) have gained popularity as a neuron based architecture with fast training time and good generalization. In this work, we parallelize an \\{ELM\\} algorithm for unsupervised learning on a distributed framework to learn clustering models from big data based on the unsupervised \\{ELM\\} algorithm proposed in the literature. We propose three approaches to do so: 1) Parallel US-ELM which simply distributes the data over computing nodes, 2) Hierarchical US-ELM which hierarchically clusters the data and 3) Ensemble US- \\{ELM\\} which is an ensemble of weak \\{ELM\\} models. The algorithms achieved faster training times compared to their serial counterparts and generalized better than other clustering algorithms in the literature, when tested on multiple datasets from UCI.", 
        "author": "Yara Rizk and Mariette Awad", 
        "keyword": "Big data\", \"Extreme Learning Machines\", \"Unsupervised learning\", \"Distributed computing", 
        "title": "On the Distributed Implementation of Unsupervised Extreme Learning Machines for Big Data"
    }, 
    {
        "abstract": "Abstract With the ever increasing social networking and online marketing sites, the reviews and blogs obtained from those, act as an important source for further analysis and improved decision making. These reviews are mostly unstructured by nature and thus, need processing like classification or clustering to provide a meaningful information for future uses. These reviews and blogs may be classified into different polarity groups such as positive, negative, and neutral in order to extract information from the input dataset. Supervised machine learning methods help to classify these reviews. In this paper, four different machine learning algorithms such as Naive Bayes (NB), Maximum Entropy (ME), Stochastic Gradient Descent (SGD), and Support Vector Machine (SVM) have been considered for classification of human sentiments. The accuracy of different methods are critically examined in order to access their performance on the basis of parameters such as precision, recall, f-measure, and accuracy.", 
        "author": "Abinash Tripathy and Ankit Agrawal and Santanu Kumar Rath", 
        "keyword": "Sentiment analysis\", \"Naive Bayes (NB)\", \"Maximum Entropy (ME)\", \"Stochastic Gradient Descent (keywords =GD)\", \"Support Vector Machine (SVM)\", \"N-gram\", \"IMDb dataset", 
        "title": "Classification of sentiment reviews using n-gram machine learning approach"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) as an emerging technology has achieved exceptional performance in large-scale settings, and is well suited to binary and multi-class classification, as well as regression tasks. However, existing \\{ELM\\} and its variants predominantly employ single hidden layer feedforward networks, leaving the popular and potentially powerful stacked generalization principle unexploited for seeking predictive deep representations of input data. Deep architectures can find higher-level representations, thus can potentially capture relevant higher-level abstractions. But most of current deep learning methods require solving a difficult and non-convex optimization problem. In this paper, we propose a stacked model, DrELM, to learn deep representations via extreme learning machine according to stacked generalization philosophy. The proposed model utilizes \\{ELM\\} as a base building block and incorporates random shift and kernelization as stacking elements. Specifically, in each layer, DrELM integrates a random projection of the predictions obtained by \\{ELM\\} into the original feature, and then applies kernel functions to generate the resultant feature. To verify the classification and regression performance of DrELM, we conduct the experiments on both synthetic and real-world data sets. The experimental results show that DrELM outperforms \\{ELM\\} and kernel ELMs, which appear to demonstrate that DrELM could yield predictive features that are suitable for prediction tasks. The performances of the deep models (i.e. Stacked Auto-encoder) are comparable. However, due to the utilization of ELM, DrELM is easier to learn and faster in testing.", 
        "author": "Wenchao Yu and Fuzhen Zhuang and Qing He and Zhongzhi Shi", 
        "keyword": "Extreme learning machine\", \"Deep learning\", \"Representation learning\", \"Stacked ELMs\", \"Stacked keywords =eneralization\", \"DrELM", 
        "title": "Learning deep representations via extreme learning machines"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a benchmarking of supervised machine learning techniques (neural networks, Gaussian processes and support vector machines) in order to forecast the Global Horizontal solar Irradiance (GHI). We also include in this benchmark a simple linear autoregressive (AR) model as well as two naive models based on persistence of the \\{GHI\\} and persistence of the clear sky index (denoted herein scaled persistence model). The models are calibrated and validated with data from three French islands: Corsica (41.91\u00b0N; 8.73\u00b0E), Guadeloupe (16.26\u00b0N; 61.51\u00b0W) and Reunion (21.34\u00b0S; 55.49\u00b0E). The main findings of this work are, that for hour ahead solar forecasting, the machine learning techniques slightly improve the performances exhibited by the linear \\{AR\\} and the scaled persistence model. However, the improvement appears to be more pronounced in case of unstable sky conditions. These nonlinear techniques start to outperform their simple counterparts for forecasting horizons greater than 1 h.", 
        "author": "Philippe Lauret and Cyril Voyant and Ted Soubdhan and Mathieu David and Philippe Poggi", 
        "keyword": "Intraday solar forecasting\", \"Machine learning techniques\", \"Statistical models", 
        "title": "A benchmarking of machine learning techniques for solar radiation forecasting in an insular context"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a new regularization approach for Extreme Learning Machine-based Single- hidden Layer Feedforward Neural network training. We show that the proposed regularizer is able to weight the dimensions of the \\{ELM\\} space according to the importance of the network's hidden layer weights, without imposing additional computational and memory costs in the network learning process. This enhances the network's performance and makes the proposed approach suitable for learning non- linear decision surfaces in large-scale classification problems. We test our approach in medium- and large-scale face recognition problems, where we observe its superiority when compared to the existing regularized Extreme Learning Machine classifier in both constrained and unconstrained problems, thus making our approach applicable in demanding media analysis applications such as those appearing in digital cinema production.", 
        "author": "Alexandros Iosifidis and Anastasios Tefas and Ioannis Pitas", 
        "keyword": "Extreme Learning Machine\", \"Regularization\", \"Face Recognition\", \"Large-scale learning", 
        "title": "Regularized Extreme Learning Machine for Large-scale Media Content Analysis"
    }, 
    {
        "abstract": "Abstract Deep learning has attracted a lot of attention and has been applied successfully in many areas such as bioinformatics, imaging processing, game playing and computer security etc. On the other hand, deep learning usually requires a lot of training data which may not be provided by a sole owner. As the volume of data gets huge, it is common for users to store their data in a third-party cloud. Due to the confidentiality of the data, data are usually stored in encrypted form. To apply deep learning to these datasets owned by multiple data owners on cloud, we need to tackle two challenges: (i) the data are encrypted with different keys, all operations including intermediate results must be secure; and (ii) the computational cost and the communication cost of the data owner(s) should be kept minimal. In our work, we propose two schemes to solve the above problems. We first present a basic scheme based on multi-key fully homomorphic encryption (MK-FHE), then we propose an advanced scheme based on a hybrid structure by combining the double decryption mechanism and fully homomorphic encryption (FHE). We also prove that these two multi-key privacy-preserving deep learning schemes over encrypted data are secure.", 
        "author": "Ping Li and Jin Li and Zhengan Huang and Tong Li and Chong-Zhi Gao and Siu-Ming Yiu and Kai Chen", 
        "keyword": "Cryptography\", \"Machine learning\", \"Fully homomorphic encryption\", \"Cloud computing", 
        "title": "Multi-key privacy-preserving deep learning in cloud computing"
    }, 
    {
        "abstract": "Abstract With the advancement of technology and communication system, use of internet is giving at a tremendous role. This causes an exponential growth of data and traffic over the internet. So to correctly classify this traffic is a hot research area. Internet traffic classification is a very popular tool against the information detection system. Although so many methods had been develop to efficiently classify internet traffic but among them machine learning techniques are most popular. A brief survey on various supervised and unsupervised machine learning techniques applied by various researchers to solve internet traffic classification has been discussed. This paper also present various issues related to machine learning techniques that may help interested researchers to work future in this direction.", 
        "author": "Neeraj Namdev and Shikha Agrawal and Sanjay Silkari", 
        "keyword": "Internet\", \"Machine learning techniques\", \"Traffic classification", 
        "title": "Recent Advancement in Machine Learning Based Internet Traffic Classification"
    }, 
    {
        "abstract": "Abstract Face recognition (FR) has been at the crux of several novel breakthroughs over the past two decades and has steadily proffered several cross-domain applications that range from mainstream commercial software to critical law enforcement applications. Recent groundbreaking developments in Big Data analysis,Cloud Computing,Social Networks and Machine learning have vastly transformed the conventional view of how several formidable problems in Computer Vision can be tackled. Hence in this paper, we will provide a thorough survey of the concepts of Cloud Computing, Big Data, Social networks and Machine Learning from a contemporary perspective of FR,and proffer a framework for a novel \\{FR\\} approachbased on the Extreme Learning Machines technique to perform the task of Face Tagging for Social Networks operating on Big Data. In the proposed approach, the desirable properties of the aforementioned concepts are amalgamated to form an effective coalition that can augment the performance of FR, in addition to serving immeasurably in a plethora of other disciplines.", 
        "author": "A. Vinay and Vinay S. Shekhar and J. Rituparna and Tushar Aggrawal and K.N. Balasubramanya Murthy and S. Natarajan", 
        "keyword": "Big Data\", \"Cloud Computing\", \"Extreme Learning Machines\", \"Face Recognition\", \"Machine Learning\", \"Social Networks.", 
        "title": "Cloud Based Big Data Analytics Framework for Face Recognition in Social Networks Using Machine Learning"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) as a neural network algorithm has shown its good performance, such as fast speed, simple structure etc, but also, weak robustness is an unavoidable defect in original \\{ELM\\} for blended data. We present a new machine learning framework called \u201cLARSEN-ELM\u201d to overcome this problem. In our paper, we would like to show two key steps in LARSEN-ELM. In the first step, preprocessing, we select the input variables highly related to the output using least angle regression (LARS). In the second step, training, we employ Genetic Algorithm (GA) based selective ensemble and original ELM. In the experiments, we apply a sum of two sines and four datasets from \\{UCI\\} repository to verify the robustness of our approach. The experimental results show that compared with original \\{ELM\\} and other methods such as OP-ELM, GASEN-ELM and LSBoost, LARSEN-ELM significantly improves robustness performance while keeping a relatively high speed.", 
        "author": "Bo Han and Bo He and Rui Nian and Mengmeng Ma and Shujing Zhang and Minghui Li and Amaury Lendasse", 
        "keyword": "Extreme learning machine\", \"LARS algorithm\", \"Selective ensemble\", \"LARSEN-ELM\", \"Robustness", 
        "title": "LARSEN-ELM: Selective ensemble of extreme learning machines using \\{LARS\\} for blended data"
    }, 
    {
        "abstract": "Abstract Lithium-ion battery plays a key role in most industrial systems, which is critical to the system availability. It is important to evaluate the performance degradation and estimate the remaining useful life (RUL) for those batteries. With the capability of uncertainty representation and management, Relevance Vector Machine (RVM) becomes an effective approach for lithium-ion battery \\{RUL\\} estimation. However, small sample size and low precision of multi-step prediction limits its application in battery \\{RUL\\} estimation for sparse \\{RVM\\} algorithm. Due to the continuous on-line update of monitoring data, to improve the prediction performance of battery \\{RUL\\} model, dynamic training and on-line learning capability is desirable. Another challenge in on-line and real-time processing is the operating efficiency and computational complexity. To address these issues, this paper implements a flexible and effective on-line training strategy in \\{RVM\\} algorithm to enhance the prediction ability, and presents an incremental optimized \\{RVM\\} algorithm to the model via efficient on-line training. The proposed on-line training strategy achieves a better prediction precision as well as improves the operating efficiency for battery \\{RUL\\} estimation. Experiments based on \\{NASA\\} battery data set show that the proposed method yields a satisfied performance in \\{RUL\\} estimation of lithium-ion battery.", 
        "author": "Datong Liu and Jianbao Zhou and Dawei Pan and Yu Peng and Xiyuan Peng", 
        "keyword": "Remaining useful life\", \"Relevance Vector Machine\", \"Incremental learning\", \"Lithium-ion battery", 
        "title": "Lithium-ion battery remaining useful life estimation with an optimized Relevance Vector Machine algorithm with incremental learning"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has been an important research topic over the last decade due to its high efficiency, easy-implementation, unification of classification and regression, and unification of binary and multi-class learning tasks. Though integrating these advantages, existing \\{ELM\\} algorithms pay little attention to optimizing the choice of kernels, which is indeed crucial to the performance of \\{ELM\\} in applications. More importantly, there is the lack of a general framework for \\{ELM\\} to integrate multiple heterogeneous data sources for classification. In this paper, we propose a general learning framework, termed multiple kernel extreme learning machines (MK-ELM), to address the above two issues. In the proposed MK-ELM, the optimal kernel combination weights and the structural parameters of \\{ELM\\} are jointly optimized. Following recent research on support vector machine (SVM) based \\{MKL\\} algorithms, we first design a sparse MK-ELM algorithm by imposing an \u21131-norm constraint on the kernel combination weights, and then extend it to a non-sparse scenario by substituting the \u21131-norm constraint with an \u2113p-norm ( p &gt; 1 ) constraint. After that, a radius-incorporated MK-ELM algorithm which incorporates the radius of the minimum enclosing ball (MEB) is introduced. Three efficient optimization algorithms are proposed to solve the corresponding kernel learning problems. Comprehensive experiments have been conducted on Protein, Oxford Flower17, Caltech101 and Alzheimer\u05f3s disease data sets to evaluate the performance of the proposed algorithms in terms of classification accuracy and computational efficiency. As the experimental results indicate, our proposed algorithms can achieve comparable or even better classification performance than state-of-the-art \\{MKL\\} algorithms, while incurring much less computational cost.", 
        "author": "Xinwang Liu and Lei Wang and Guang-Bin Huang and Jian Zhang and Jianping Yin", 
        "keyword": "Extreme learning machine\", \"Multiple kernel learning\", \"Support vector machines", 
        "title": "Multiple kernel extreme learning machine"
    }, 
    {
        "abstract": "Abstract Traditional artificial neural networks (ANN) such as back-propagation neural networks (BPNN) provide good predictions of length-of-day (LOD). However, the determination of network topology is difficult and time consuming. Therefore, we propose a new type of neural network, extreme learning machine (ELM), to improve the efficiency of \\{LOD\\} predictions. Earth orientation parameters (EOP) \\{C04\\} time-series provides daily values from International Earth Rotation and Reference Systems Service (IERS), which serves as our database. First, the known predictable effects that can be described by functional models\u2014such as the effects of solid earth, ocean tides, or seasonal atmospheric variations\u2014are removed a priori from the \\{C04\\} time-series. Only the residuals after the subtraction of a priori model from the observed \\{LOD\\} data (i.e., the irregular and quasi-periodic variations) are employed for training and predictions. The predicted \\{LOD\\} is the sum of a prior extrapolation model and the \\{ELM\\} predictions of the residuals. Different input patterns are discussed and compared to optimize the network solution. The prediction results are analyzed and compared with those obtained by other machine learning-based prediction methods, including BPNN, generalization regression neural networks (GRNN), and adaptive network-based fuzzy inference systems (ANFIS). It is shown that while achieving similar prediction accuracy, the developed method uses much less training time than other methods. Furthermore, to conduct a direct comparison with the existing prediction techniques, the mean-absolute-error (MAE) from the proposed method is compared with that from the \\{EOP\\} prediction comparison campaign (EOP PCC). The results indicate that the accuracy of the proposed method is comparable with that of the former techniques. The implementation of the proposed method is simple.", 
        "author": "Yu Lei and Danning Zhao and Hongbing Cai", 
        "keyword": "Length-of-day (LOD)\", \"Prediction\", \"Extreme learning machine (ELM)\", \"Artificial neural networks (keywords =NN)\", \"Extreme learning machine (ELM)\", \"Earth orientation parameters (EOP)\", \"EOP prediction keywords =omparison campaign (EOP PCC)\", \"Least squares", 
        "title": "Prediction of length-of-day using extreme learning machine"
    }, 
    {
        "abstract": "Abstract There has been an increasing interest in applying machine learning methods in urban energy assessment. This research implemented six statistical learning methods in estimating domestic gas and electricity using both physical and socio-economic explanatory variables in London. The input variables include dwelling types, household tenure, household composition, council tax band, population age groups, etc. Six machine learning methods are two linear approaches (full linear and Lasso) and four non-parametric methods (MARS multivariate adaptive regression spline, \\{SVM\\} support vector machine, bagging MARS, and boosting). The results indicate that all the four non-parametric models outperform two linear models. The \\{SVM\\} models perform the best among these models for both gas and electricity. The bagging \\{MARS\\} performs only a little worse than the \\{SVM\\} for gas use prediction. The Lasso model has similar predictive capability to the full linear model in this case.", 
        "author": "Lai Wei and Wei Tian and Elisabete A. Silva and Ruchi Choudhary and QingXin Meng and Song Yang", 
        "keyword": "Urban buildings\", \"Energy use\", \"Machine learning\", \"Comparative learning\", \"Cross validation", 
        "title": "Comparative Study on Machine Learning for Urban Building Energy Analysis"
    }, 
    {
        "abstract": "Abstract Imbalance problem occurs when negative class contains many more patterns than that of positive class. Since conventional Support Vector Machine (SVM) and Neural Networks (NN) have been proven not to effectively handle imbalanced data, some improved learning machines including Fuzzy \\{SVM\\} (FSVM) have been proposed. \\{FSVM\\} applies a fuzzy membership to each training pattern such that different patterns can give different contributions to the learning machine. However, how to evaluate fuzzy membership becomes the key point to FSVM. Moreover, these learning machines present disadvantages to process matrix patterns. In order to process matrix patterns and to tackle the imbalance problem, this paper proposes an entropy-based matrix learning machine for imbalanced data sets, adopting the Matrix-pattern-oriented Ho\u2013Kashyap learning machine with regularization learning (MatMHKS) as the base classifier. The new leaning machine is named \\{EMatMHKS\\} and its contributions are: (1) proposing a new entropy-based fuzzy membership evaluation approach which enhances the importance of patterns, (2) guaranteeing the importance of positive patterns and get a more flexible decision surface. Experiments on real-world imbalanced data sets validate that \\{EMatMHKS\\} outperforms compared learning machines.", 
        "author": "Changming Zhu and Zhe Wang", 
        "keyword": "Entropy\", \"Fuzzy membership\", \"Imbalanced data set\", \"Pattern recognition", 
        "title": "Entropy-based matrix learning machine for imbalanced data sets"
    }, 
    {
        "abstract": "Abstract In this paper we study both machine learning and statistical approaches for combining fingerprint matchers of the \\{FVC2006\\} competition. We investigate not only which is the best fusion approach, but also the correlation among the state-of-the-art matchers for fingerprint verification and scanner interoperability of the fusion techniques. Several tests are performed on all the four \\{FVC2006\\} datasets, using a leave-one-out dataset testing protocol, i.e., the training phase is conducted on the datasets not used in the testing phase, so it is possible to study the pros and cons of machine learning and statistical approaches when different scanners are used in the training and testing phases. This work confirms that the fusion of different state-of-the-art fingerprint matchers can lead to a significant performance gain with respect to a single matcher.", 
        "author": "Loris Nanni and Alessandra Lumini and Matteo Ferrara and Raffaele Cappelli", 
        "keyword": "Fingerprints\", \"Machine learning\", \"Fusion of matchers\", \"FVC2006", 
        "title": "Combining biometric matchers by means of machine learning and statistical approaches"
    }, 
    {
        "abstract": "Abstract Within a life cycle assessment (LCA), normalization is an essential part for interpretation. In Europe, only the European Union normalization factors (EU NFs), with 2000 as the reference year, are available for \\{LCA\\} practitioners, although they work on a regional level. The hypothesis of this research was based on the assumption that some regional \\{NFs\\} deviate from the \\{EU\\} \\{NFs\\} due to unique regional profiles, or because of previously omitted or generalized human impact. In this particular case study set in Slovenia has been tested. By working on the ReCiPe 1.08 life cycle impact assessment methodology, 18 impact categories were investigated, and an additional 3 were added: electromagnetic radiation, light pollution and electric use. To meet practitioners\u2019 needs, the most up-to-date inventory data was used with the reference years of 2007\u20132012. Out of 440 environmental interventions that were investigated, 139 had no characterization factors (CFs), 97 were estimated using machine learning and 42 had to be omitted. The final result confirmed our hypothesis. Twenty \\{NFs\\} were compared with the \\{EU\\} NFs, and the results have shown that on average, the \\{NFs\\} differ by a factor of 9.76 (median = 1.65). The reasons for the high deviation are due to natural land transformation, and ionising radiation, toxicological and ecotoxicological impact categories; where there are major data gaps in the CFs. The primary concern of the research was data availability for toxicological and ecotoxicological parameters for toxicity-related emissions, and the fact that original \\{CFs\\} covered only 50.25% of plant protection products used in Slovenia. Toxicological and ecotoxicological uncertainties were illustrated by comparing four different results. Future studies should be focused on the use of machine learning to provide the next generation of \\{CFs\\} and to go beyond the CFs\u2019 damage-oriented assessment. Remediation should be the new endpoint category and its units should be Joules.", 
        "author": "Matej Slapnik and Darja Isteni\u010d and Marina Pintar and Andrej Udov\u010d", 
        "keyword": "Upgrading life cycle assessment\", \"Regional normalization factors\", \"Machine learning\", \"Uncertainties", 
        "title": "Extending life cycle assessment normalization factors and use of machine learning \u2013 A Slovenian case study"
    }, 
    {
        "abstract": "Abstract Decades of psychological research have demonstrated that intuitive judgments are often unreliable, thanks to their inflexible reliance on limited information (Kahneman, 2003, 2011). Research on the computational underpinnings of learning, however, indicates that intuitions may be acquired by sophisticated learning mechanisms that are highly sensitive and integrative. With this in mind, Railton (2014) urges a more optimistic view of moral intuition. Is such optimism warranted? Elsewhere (Greene, 2013) I\u2019ve argued that moral intuitions offer reasonably good advice concerning the give-and-take of everyday social life, addressing the basic problem of cooperation within a \u201ctribe\u201d (\u201cMe vs. Us\u201d), but that moral intuitions offer unreliable advice concerning disagreements between tribes with competing interests and values (\u201cUs vs. Them\u201d). Here I argue that a computational perspective on moral learning underscores these conclusions. The acquisition of good moral intuitions requires both good (representative) data and good (value-aligned) training. In the case of inter-tribal disagreement (public moral controversy), the problem of bad training looms large, as training processes may simply reinforce tribal differences. With respect to moral philosophy and the paradoxical problems it addresses, the problem of bad data looms large, as theorists seek principles that minimize counter-intuitive implications, not only in typical real-world cases, but in unusual, often hypothetical, cases such as some trolley dilemmas. In such cases the prevailing real-world relationships between actions and consequences are severed or reversed, yielding intuitions that give the right answers to the wrong questions. Such intuitions\u2014which we may experience as the voice of duty or virtue\u2014may simply reflect the computational limitations inherent in affective learning. I conclude, in optimistic agreement with Railton, that progress in moral philosophy depends on our having a better understanding of the mechanisms behind our moral intuitions.", 
        "author": "Joshua D. Greene", 
        "keyword": "Deontology\", \"Utilitarianism\", \"Consequentialism\", \"Reinforcement learning\", \"Model-free learning\", keywords =Machine learning\", \"Ethics\", \"Normative ethics\", \"Moral judgment", 
        "title": "The rat-a-gorical imperative: Moral intuition and the limits of affective learning"
    }, 
    {
        "abstract": "Abstract Fluid (oil/gas/water) transportation systems present a significant challenge for pipeline health monitoring. With the development of smart devices capable of micro-sensing, on-board processing, and wireless communication capabilities, the wireless sensor networks are able to facilitate online learning and reliable event monitoring and reporting for distribution pipelines. This paper presents the design, development and testing of a smart wireless sensor network (WSN) for leak detection and size estimation in long range pipelines. This system uses wireless communication and machine learning (WML) to learn, make decisions and report the critical events like slow /small leakages in natural gas/oil pipeline autonomously. Machine learning is performed on negative pressure wave (NPW) to identify events based on raw data gathered by individual sensor nodes in network. In machine learning, we use support vector machine (SVM), K-nearest neighbor (KNN) and Gaussian mixture model (GMM) and Naive bayes in multi- dimensional feature space. The proposed technique is investigated for performance and capabilities by a series of trials on a field deployed test bed, with regard to performance of leakage detection and size estimation in pipelines.", 
        "author": "Sidra Rashid and Usman Akram and Shoab A. Khan", 
        "keyword": "Wireless sensor network based machine learning(WML)\", \"leakage detection and size estimation\", \"Negative pressure wave (NPW)", 
        "title": "WML: Wireless Sensor Network based Machine Learning for Leakage Detection and Size Estimation"
    }, 
    {
        "abstract": "Abstract Machine learning (ML) techniques are increasingly used to simulate the behavior of concrete materials and have become an important research area. The compressive strength of high performance concrete (HPC) is a major civil engineering problem. However, the validity of reported relationships between concrete ingredients and mechanical strength is questionable. This paper provides a comprehensive study using advanced \\{ML\\} techniques to predict the compressive strength of HPC. Specifically, individual and ensemble learning classifiers are constructed from four different base learners, including multilayer perceptron (MLP) neural network, support vector machine (SVM), classification and regression tree (CART), and linear regression (LR). For ensemble models that integrate multiple classifiers, the voting, bagging, and stacking combination methods are considered. The behavior simulation capabilities of these techniques are investigated using concrete data from several countries. The comparison results show that ensemble learning techniques are better than learning techniques used individually to predict \\{HPC\\} compressive strength. Although the two single best learning models are \\{SVM\\} and MLP, the stacking-based ensemble model composed of MLP/CART, SVM, and \\{LR\\} in the first level and \\{SVM\\} in the second level often achieves the best performance measures. This study validates the applicability of ML, voting, bagging, and stacking techniques for simple and efficient simulations of concrete compressive strength.", 
        "author": "Jui-Sheng Chou and Chih-Fong Tsai and Anh-Duc Pham and Yu-Hsin Lu", 
        "keyword": "High performance concrete\", \"Compressive strength\", \"Multi-nation data analysis\", \"Machine keywords =earning\", \"Ensemble classifiers\", \"Prediction", 
        "title": "Machine learning in concrete strength simulations: Multi-nation data analytics"
    }, 
    {
        "abstract": "Abstract Many real-world gesture datasets are by nature containing unbalanced number of poses across classes. Such imbalance severely reduces bag-of-poses based classification performance. On the other hand, collecting a dataset of human gestures or actions is an expensive and time-consuming procedure. It is often impractical to reacquire the data or to modify the existing dataset using oversampling or undersampling procedures. The best way to handle such imbalance is by making the used classifier be directly aware and adapt to the real condition inside the data. Balancing class distribution, i.e., the number of pose samples per class, is one of difficult tasks in machine learning. Standard statistical learning models (e.g., SVM, HMM, CRF) are insensitive to unbalanced datasets. This paper proposes a distribution-sensitive prior on a standard statistical learning, i.e., Relevance Vector Machine (RVM), to deal with the imbalanced data problem. This prior analyzes the training dataset before learning a model. Thus, the \\{RVM\\} can put more weight on the samples from under-represented classes, while allows overall samples from the dataset to have a balanced impact to the learning process. Our experiment uses a publicly available gesture datasets, the Microsoft Research Cambridge-12 (MSRC-12). Experimental results show the importance of adapting to the unbalanced data and improving the recognition performance through distribution-sensitive prior.", 
        "author": "Vina Ayumi and Mohamad Ivan Fanany", 
        "keyword": "Distribution-Sensitive Learning\", \"Relevance Vector Machine\", \"human gesture recognition", 
        "title": "Distribution-Sensitive Learning on Relevance Vector Machine for Pose-Based Human Gesture Recognition"
    }, 
    {
        "abstract": "Abstract Mapping the spatial distribution of soil taxonomic classes is important for informing soil use and management decisions. Digital soil mapping (DSM) can quantitatively predict the spatial distribution of soil taxonomic classes. Key components of \\{DSM\\} are the method and the set of environmental covariates used to predict soil classes. Machine learning is a general term for a broad set of statistical modeling techniques. Many different machine learning models have been applied in the literature and there are different approaches for selecting covariates for DSM. However, there is little guidance as to which, if any, machine learning model and covariate set might be optimal for predicting soil classes across different landscapes. Our objective was to compare multiple machine learning models and covariate sets for predicting soil taxonomic classes at three geographically distinct areas in the semi-arid western United States of America (southern New Mexico, southwestern Utah, and northeastern Wyoming). All three areas were the focus of digital soil mapping studies. Sampling sites at each study area were selected using conditioned Latin hypercube sampling (cLHS). We compared models that had been used in other \\{DSM\\} studies, including clustering algorithms, discriminant analysis, multinomial logistic regression, neural networks, tree based methods, and support vector machine classifiers. Tested machine learning models were divided into three groups based on model complexity: simple, moderate, and complex. We also compared environmental covariates derived from digital elevation models and Landsat imagery that were divided into three different sets: 1) covariates selected a priori by soil scientists familiar with each area and used as input into cLHS, 2) the covariates in set 1 plus 113 additional covariates, and 3) covariates selected using recursive feature elimination. Overall, complex models were consistently more accurate than simple or moderately complex models. Random forests (RF) using covariates selected via recursive feature elimination was consistently the most accurate, or was among the most accurate, classifiers between study areas and between covariate sets within each study area. We recommend that for soil taxonomic class prediction, complex models and covariates selected by recursive feature elimination be used. Overall classification accuracy in each study area was largely dependent upon the number of soil taxonomic classes and the frequency distribution of pedon observations between taxonomic classes. Individual subgroup class accuracy was generally dependent upon the number of soil pedon observations in each taxonomic class. The number of soil classes is related to the inherent variability of a given area. The imbalance of soil pedon observations between classes is likely related to cLHS. Imbalanced frequency distributions of soil pedon observations between classes must be addressed to improve model accuracy. Solutions include increasing the number of soil pedon observations in classes with few observations or decreasing the number of classes. Spatial predictions using the most accurate models generally agree with expected soil\u2013landscape relationships. Spatial prediction uncertainty was lowest in areas of relatively low relief for each study area.", 
        "author": "Colby W. Brungard and Janis L. Boettinger and Michael C. Duniway and Skye A. Wills and Thomas C. Edwards Jr.", 
        "keyword": "Digital soil mapping\", \"Machine learning\", \"Recursive feature elimination\", \"Random forests\", \"Brier score", 
        "title": "Machine learning for predicting soil classes in three semi-arid landscapes"
    }, 
    {
        "abstract": "Abstract Face image based age estimation is an approach to classify face images into one of several pre-defined age-groups. It is challenging because facial aging variation is specific to a given individual and is determined by the person's gene and many external factors, such as exposure, weather, gender, and living style. Age estimation is a multiclass problem and the number of classes to predict is quite large. There surely is facial aging trend and faces from closed age range have some similar facial aging features. It is difficult to say there are distinct facial aging features for an age. Facial aging features are found to be overlapped among nearby age groups along the aging life and are continuous in nature. In this paper, we emphasised our work on age range estimation with four pre-defined classes. We applied a fast and efficient machine learning method: extreme learning machines, to solve the age categorization problem. Local Gabor Binary Patterns, Biologically Inspired Feature and Gabor were adopted to represent face image. Age estimation was performed on three different aging datasets and experimental results are reported to demonstrate its effectiveness and robustness.", 
        "author": "Phyo-Kyaw Sai and Jian-Gang Wang and Eam-Khwang Teoh", 
        "keyword": "Facial age range estimation\", \"Extreme learning machines\", \"ECOC\", \"Boosting", 
        "title": "Facial age range estimation with extreme learning machines"
    }, 
    {
        "abstract": "Abstract In this paper, a computationally efficient framework, referred to as ensemble of subset online sequential extreme learning machine (ESOS-ELM), is proposed for class imbalance learning from a concept-drifting data stream. The proposed framework comprises a main ensemble representing short-term memory, an information storage module representing long-term memory and a change detection mechanism to promptly detect concept drifts. In the main ensemble of ESOS-ELM, each OS-ELM network is trained with a balanced subset of the data stream. Using \\{ELM\\} theory, a computationally efficient storage scheme is proposed to leverage the prior knowledge of recurring concepts. A distinctive feature of ESOS-ELM is that it can learn from new samples sequentially in both the chunk-by-chunk and one-by-one modes. ESOS-ELM can also be effectively applied to imbalanced data without concept drift. On most of the datasets used in our experiments, ESOS-ELM performs better than the state-of-the-art methods for both stationary and non-stationary environments.", 
        "author": "Bilal Mirza and Zhiping Lin and Nan Liu", 
        "keyword": "Class imbalance\", \"Concept drift\", \"Extreme learning machine\", \"Online learning\", \"Recurring environments", 
        "title": "Ensemble of subset online sequential extreme learning machine for class imbalance and concept drift"
    }, 
    {
        "abstract": "Abstract Due to the overwhelming complexity of the electrochemical related behaviors and internal structure of lithium ion batteries, it is difficult to obtain an accurate mathematical expression of their thermal dynamics based on the physical principal. In this paper, a data based thermal model which is suitable for online temperature distribution estimation is proposed for lithium-ion batteries. Based on the physics based model, a simple but effective low order model is obtained using the Karhunen\u2013Loeve decomposition method. The corresponding uncertain chemical related heat generation term in the low order model is approximated using extreme learning machine. All uncertain parameters in the low order model can be determined analytically in a linear way. Finally, the temperature distribution of the whole battery can be estimated in real time based on the identified low order model. Simulation results demonstrate the effectiveness of the proposed model. The simple training process of the model makes it superior for onboard application.", 
        "author": "Zhen Liu and Han-Xiong Li", 
        "keyword": "Lithium-ion batteries\", \"Thermal model\", \"Spatiotemporal estimation\", \"Extreme learning machine", 
        "title": "Extreme learning machine based spatiotemporal modeling of lithium-ion battery thermal dynamics"
    }, 
    {
        "abstract": "Abstract As an important branch of neural network, extreme learning machines (ELMs) have attracted wide interests in the fields of pattern classification and regression estimation. However, when facing learning problems with multi-dimensional outputs, named multi-dimensional regression, the conventional \\{ELMs\\} could not generally get satisfactory results because it is incapable of exploiting the relatedness among outputs efficiently. To solve this problem, a new regularized \\{ELM\\} is firstly proposed in this paper by introducing a hyper-spherical loss function as regularizer. As the regularization form with this loss function cannot be solved directly, an solution with iterative procedure is presented. For improving the learning performance, the algorithm proposed above is further reformulated to identify the inner grouping structure hidden in outputs by assuming that the grouping structure is determined by different linear combinations of a small number of latent basis neurons. This is achieved as a mixed integer programming, and finally an alternating minimization method is presented to solve this problem. Experiments on two multi-dimensional data sets, a toy problem and a real-life dynamical cylindrical vibration data set, are conducted, and the results demonstrate the effectiveness of the proposed algorithm.", 
        "author": "Wentao Mao and Shengjie Zhao and Xiaoxia Mu and Haicheng Wang", 
        "keyword": "Extreme learning machine\", \"Multi-dimensional regression\", \"Mixed integer programming\", \"Loss function", 
        "title": "Multi-dimensional extreme learning machine"
    }, 
    {
        "abstract": "AbstractObjective The objective of this paper is to highlight the state-of-the-art machine learning (ML) techniques in computational docking. The use of smart computational methods in the life cycle of drug design is relatively a recent development that has gained much popularity and interest over the last few years. Central to this methodology is the notion of computational docking which is the process of predicting the best pose (orientation + conformation) of a small molecule (drug candidate) when bound to a target larger receptor molecule (protein) in order to form a stable complex molecule. In computational docking, a large number of binding poses are evaluated and ranked using a scoring function. The scoring function is a mathematical predictive model that produces a score that represents the binding free energy, and hence the stability, of the resulting complex molecule. Generally, such a function should produce a set of plausible ligands ranked according to their binding stability along with their binding poses. In more practical terms, an effective scoring function should produce promising drug candidates which can then be synthesized and physically screened using high throughput screening process. Therefore, the key to computer-aided drug design is the design of an efficient highly accurate scoring function (using \\{ML\\} techniques). Methods The methods presented in this paper are specifically based on \\{ML\\} techniques. Despite many traditional techniques have been proposed, the performance was generally poor. Only in the last few years started the application of the \\{ML\\} technology in the design of scoring functions; and the results have been very promising. Material The ML-based techniques are based on various molecular features extracted from the abundance of protein\u2013ligand information in the public molecular databases, e.g., protein data bank bind (PDBbind). Results In this paper, we present this paradigm shift elaborating on the main constituent elements of the \\{ML\\} approach to molecular docking along with the state-of-the-art research in this area. For instance, the best random forest (RF)-based scoring function [35] on \\{PDBbind\\} v2007 achieves a Pearson correlation coefficient between the predicted and experimentally determined binding affinities of 0.803 while the best conventional scoring function achieves 0.644 [34]. The best RF-based ranking power [6] ranks the ligands correctly based on their experimentally determined binding affinities with accuracy 62.5% and identifies the top binding ligand with accuracy 78.1%. Conclusions We conclude with open questions and potential future research directions that can be pursued in smart computational docking; using molecular features of different nature (geometrical, energy terms, pharmacophore), advanced \\{ML\\} techniques (e.g., deep learning), combining more than one \\{ML\\} models.", 
        "author": "Mohamed A. Khamis and Walid Gomaa and Walaa F. Ahmed", 
        "keyword": "Machine learning\", \"Random forest\", \"Support vector machine\", \"Drug discovery\", \"Computational keywords =ocking\", \"Scoring function\", \"Virtual screening\", \"Complex binding affinity\", \"Ligands ranking keywords =ccuracy\", \"Force field interaction\", \"Pharmacophore fingerprint", 
        "title": "Machine learning in computational docking"
    }, 
    {
        "abstract": "Abstract Services in smart environments pursue to increase the quality of people\u2019s lives. The most important issues when developing this kind of environments is testing and validating such services. These tasks usually imply high costs and annoying or unfeasible real-world testing. In such cases, artificial societies may be used to simulate the smart environment (i.e. physical environment, equipment and humans). With this aim, the \\{CHROMUBE\\} methodology guides test engineers when modeling human beings. Such models reproduce behaviors which are highly similar to the real ones. Originally, these models are based on automata whose transitions are governed by random variables. Automaton\u2019s structure and the probability distribution functions of each random variable are determined by a manual test and error process. In this paper, it is presented an alternative extension of this methodology which avoids the said manual process. It is based on learning human behavior patterns automatically from sensor data by using machine learning techniques. The presented approach has been tested on a real scenario, where this extension has given highly accurate human behavior models.", 
        "author": "Francisco Campuzano and Teresa Garcia-Valverde and Juan A. Botia and Emilio Serrano", 
        "keyword": "Smart environments testing\", \"Human behavior modeling\", \"Machine learning\", \"Social simulation", 
        "title": "Generation of human computational models with machine learning"
    }, 
    {
        "abstract": "Abstract In this study we consider unrelated parallel machines scheduling problems with learning effect and deteriorating jobs, in which the actual processing time of a job is a function of joint time-dependent deterioration and position-dependent learning. The objective is to determine the jobs assigned to corresponding each machine and the corresponding optimal schedule to minimize a cost function containing total completion (waiting) time, total absolute differences in completion (waiting) times and total machine load. If the number of machines is a given constant, we show that the problems can be solved in polynomial time under the time-dependent deterioration and position-dependent learning model.", 
        "author": "Xiao-Yuan Wang and Jian-Jun Wang", 
        "keyword": "Scheduling\", \"Unrelated parallel machines\", \"Learning effect\", \"Deteriorating jobs", 
        "title": "Scheduling deteriorating jobs with a learning effect on unrelated parallel machines"
    }, 
    {
        "abstract": null, 
        "author": "A. Mjahad and A. Rosado-Mu\u00f1oz and M. Bataller-Mompe\u00e1n and J.V. Franc\u00e9s-V\u00edllora and J.F. Guerrero-Mart\u00ednez", 
        "keyword": "\\{VF\\} Detection\", \"VT Detection\", \"Time-frequency representation\", \"Pseudo Wigner-Ville\", \"ECG\", \"Classification algorithms", 
        "title": "Ventricular Fibrillation and Tachycardia detection from surface \\{ECG\\} using time-frequency representation images as input dataset for machine learning"
    }, 
    {
        "abstract": "Abstract Ethylene response factor (ERF) constitutes one of the most important gene families which are related to environmental responses and tolerancein plants . \\{ERF\\} genes are defined by the domain AP2/ERF, which comprises approximately 60 amino acids and are involved in \\{DNA\\} binding. Development of computational tools using machine learning tools will definitely enhance rice genome annotation. Machine learning algorithm involves construction and study of systems that can learn from data, rather than follow only explicitly programmed instructions. This study primarily emphasizes on the development of prediction tool, ERFPred, for drought responsive protein \\{ERF\\} in rice using machine learning algorithms. We have used fourteen different feature extraction methods including amino acid features, dipeptide, tripeptide, hybrid methods and exchange group features. Using, Random Forest classifier, we have obtained a precision rate of 100% for the \\{ERFPred\\} tool. To prove that species specific tool is better than an All plant tool, a general tool for plants, two different approaches were used and validated. The results obtained were also further compared with sequence similarity search tool, PSI-BLAST.", 
        "author": "N. Hemalatha and V.F. Brendon and M.M. Shihab and M.K. Rajesh", 
        "keyword": "Random Forest\", \"ERF\", \"Machine learning;", 
        "title": "Machine Learning Algorithm for Predicting Ethylene Responsive Transcription Factor in Rice Using an Ensemble Classifier"
    }, 
    {
        "abstract": "Abstract Modern water distribution networks are equipped with a large amount of sensors to monitor the drinking water quality. To detect anomalies, usually each sensor contains its own threshold, but machine-learning algorithms become an alternative to reduce the parametrization effort. Still, one reason why they are not used in practice is the geographical restricted data access. Data is stored at the plant, but data scientists needed for the data analysis are situated elsewhere. To overcome this challenge, this paper proposes a cloud-based event-detection and reporting platform, which provides a possibility to use machine learning algorithms. The plants measurements are cyclically transferred into a secure cloud service where they are downloaded and analyzed from the data scientist. Results are made available as reports.", 
        "author": "Christian K\u00fchnert and Marc Baruthio and Thomas Bernard and Claude Steinmetz and Jean-Marc Weber", 
        "keyword": "machine-learning\", \"time series analysis\", \"event-detection\", \"cloud-based service ;", 
        "title": "Cloud-based Event Detection Platform for Water Distribution Networks Using Machine-learning Algorithms"
    }, 
    {
        "abstract": "Abstract Graph patterns are widely used to define the feature space for building an efficient graph classification model. Synergy graph patterns refer to those graphs, where the relationships among the nodes are highly inseparable. Compared with the general graph patterns, synergy graph patterns which have much higher discriminative powers are more suitable as the classification features. Extreme Learning Machine (ELM) is a simple and efficient Single-hidden Layer Feedforward neural Networks (SLFNs) algorithm with extremely fast learning capacity. In this paper we propose the problem of extending \\{ELM\\} to non-redundant synergy pattern based graph classification. The graph classification framework being widely used consists of two steps, namely feature generation and classification. The first issue is how to quickly obtain significant graph pattern features from a graph database. The next step is how to effectively build a graph classification model with these graph pattern features. An efficient depth-first algorithm, called GINS, was presented to find all non-redundant synergy graph patterns. Also, based on the proposed Support Graph Vector Model (SGVM) and \\{ELM\\} algorithm, the graph classification model was constructed. Extensive experiments are conducted on a series of real-life datasets. The results show that \\{GINS\\} is more efficient than two representative competitors. Besides, when the generated graph patterns are considered as the classification features, the GINS+ELM classification accuracy can be improved much.", 
        "author": "Zhanghui Wang and Yuhai Zhao and Guoren Wang and Yuan Li and Xue Wang", 
        "keyword": "Synergy graph pattern\", \"Non-redundant\", \"Extreme learning machine\", \"Support graph vector model\", \"Graph classification", 
        "title": "On extending extreme learning machine to non-redundant synergy pattern based graph classification"
    }, 
    {
        "abstract": "Abstract This research work adduces new hybrid machine learning ensembles for improving the performance of a computer aided diagnosis system integrated with multimethod assessment process and statistical process control, used for the spine diagnosis based on noninvasive panoramic radiographs. Novel methods are proposed for enhanced accurate classification. All the computations are performed considering steep error tolerance rate with statistical significance level of 5% as well as 1% and established the results with corrected t-tests. The kernel density estimator has been implemented to distinguish the affected patients against healthy ones. A new ensemble consisting of Bayesian network optimized by Tabu search algorithm as a classifier and Haar wavelets as the projection filter is used for relevant feature selection and attribute\u2019s ranking. The performance analysis of each method along with major findings is discussed using various evaluation metrics and concludes with propitious results. The results are compared to the existing \\{SINPATCO\\} platform that uses MLP, GRNN, and SVM. The optimization of machine learning algorithms is obtained using Design of Experiments scheme to achieve superior prediction accuracy. The highest classification accuracy obtained is 96.55% with sensitivity, specificity of 0.966 and 0.987 respectively. The objective is to enhance the software reliability and quality of spine disorder diagnosis using medical diagnostic system and reinforce the viability of precise treatment.", 
        "author": "Indrajit Mandal", 
        "keyword": "Machine learning ensembles\", \"Multimethod assessment process\", \"Statistical process control\", keywords =Spine diagnosis\", \"Bayesian network\", \"Software reliability", 
        "title": "Developing new machine learning ensembles for quality spine diagnosis"
    }, 
    {
        "abstract": "Abstract This study presents the optimization of biodiesel engine performance that can achieve the goal of fewer emissions, low fuel cost and wide engine operating range. A new biodiesel engine modeling and optimization framework based on extreme learning machine (ELM) is proposed. As an accurate model is required for effective optimization result, kernel-based \\{ELM\\} (K-ELM) is used instead of basic \\{ELM\\} because K-ELM can provide better generalization performance, and the randomness of basic \\{ELM\\} does not occur in K-ELM. By using K-ELM, a biodiesel engine model is first created based on experimental data. Logarithmic transformation of dependent variables is used to alleviate the problems of data scarcity and data exponentiality simultaneously. With the K-ELM engine model, cuckoo search (CS) is then employed to determine the optimal biodiesel ratio. A flexible objective function is designed so that various user-defined constraints can be applied. As an illustrative study, the fuel price in Macau is used to perform the optimization. To verify the modeling and optimization framework, the K-ELM model is compared with a least-squares support vector machine (LS-SVM) model, and the \\{CS\\} optimization result is compared with particle swarm optimization and experimental results. The evaluation result shows that K-ELM can achieve comparable performance to LS-SVM, resulting in a reliable prediction result for optimization. It also shows that the optimization results based on \\{CS\\} is effective.", 
        "author": "Pak Kin Wong and Ka In Wong and Chi Man Vong and Chun Shun Cheung", 
        "keyword": "Biodiesel\", \"Engine optimization\", \"Kernel-based extreme learning machine\", \"Cuckoo search", 
        "title": "Modeling and optimization of biodiesel engine performance using kernel-based extreme learning machine and cuckoo search"
    }, 
    {
        "abstract": "Abstract Complex Event Processing (CEP) is a novel and promising methodology that enables the real-time analysis of stream event data. The main purpose of \\{CEP\\} is detection of the complex event patterns from the atomic and semantically low-level events such as sensor, log, or \\{RFID\\} data. Determination of the rule patterns for matching these simple events based on the temporal, semantic, or spatial correlations is the central task of \\{CEP\\} systems. In the current design of the \\{CEP\\} systems, experts provide event rule patterns. Having reached maturity, the Big Data Systems and Internet of Things (IoT) technology require the implementation of advanced machine learning approaches for automation in the \\{CEP\\} domain. The goal of this research is proposing a machine learning model to replace the manual identification of rule patterns. After a pre-processing stage (dealing with missing values, data outliers, etc.), various rule-based machine learning approaches were applied to detect complex events. Promising results with high preciseness were obtained. A comparative analysis of the performance of classifiers is discussed.", 
        "author": "Nijat Mehdiyev and Julian Krumeich and David Enke and Dirk Werth and Peter Loos", 
        "keyword": "Complex Event Processing\", \"Rule Based Classification\", \"Machine Learning\", \"Event Patterns", 
        "title": "Determination of Rule Patterns in Complex Event Processing Using Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract The dawn of a new era in knowledge management due to information explosion is making old habits of modeling knowledge and decision-making inadequate. In the search for new modeling paradigms, we expect ontologies to play a big role. One of the critical challenges we face is the scarcity of semantically rich, properly populated, ontologies in most application domains in chemical and materials engineering. Developing such ontologies is a very challenging task requiring considerable investment in time, effort, and expert knowledge. One needs automation tools that can assist an ontology engineer to quickly develop and curate domain-specific ontologies. We consider our conceptual framework in this paper, a general approach for populating scientific ontologies, and its implementation as the prototype HOLMES, as an early attempt towards such an automated knowledge management environment. Our approach integrates a variety of machine learning and natural language processing methods to extract information from journal articles and store them semantically in an ontology. In this work, identification of key terms (such as chemicals, drugs, processes, anatomical entities, etc.) from abstracts, and the classification of these terms into 25 classes are presented. Two methods, a multi-class classifier (SVM) and a multi-label classifier (HOMER), were tested on an annotated data set for the pharmaceutical industry. The test was done using two different versions of the same data set, one using the \\{BIO\\} notation and the other not. The \\{F1\\} scores for HOMER, were better in the \\{BIO\\} notation (63.6% vs 48.5%) while \\{SVM\\} performed better in the non-BIO version (54.1% vs 53.2%). However, the standard metrics did not consider the effect of the multiple answers that the multi-label classifier is allowed to obtain. As the results of our computational experiments show, while the performance of multi-label classifier is encouraging, much more remains to be done in order to develop a practically viable automated ontology-based knowledge management system.", 
        "author": "Miguel Francisco M. Remolona and Matthew F. Conway and Sriram Balasubramanian and Linxi Fan and Ziyan Feng and Tianhao Gu and Hyungtae Kim and Prasad M. Nirantar and Sarah Panda and Nithin R. Ranabothu and Neha Rastogi and Venkat Venkatasubramanian", 
        "keyword": "Natural language processing\", \"Entity recognition\", \"Ontology\", \"Machine learning\", \"Concept detection", 
        "title": "Hybrid ontology-learning materials engineering system for pharmaceutical products: Multi-label entity recognition and concept detection"
    }, 
    {
        "abstract": "Abstract Multi-view learning is an emerging direction in machine learning which considers learning with multiple views to improve the generalization performance. Multi-view learning is also known as data fusion or data integration from multiple feature sets. Since the last survey of multi-view machine learning in early 2013, multi-view learning has made great progress and developments in recent years, and is facing new challenges. This overview first reviews theoretical underpinnings to understand the properties and behaviors of multi-view learning. Then multi-view learning methods are described in terms of three classes to offer a neat categorization and organization. For each category, representative algorithms and newly proposed algorithms are presented. The main feature of this survey is that we provide comprehensive introduction for the recent developments of multi-view learning methods on the basis of coherence with early methods. We also attempt to identify promising venues and point out some specific challenges which can hopefully promote further research in this rapidly developing field.", 
        "author": "Jing Zhao and Xijiong Xie and Xin Xu and Shiliang Sun", 
        "keyword": "Multi-view learning\", \"Statistical learning theory\", \"Co-training\", \"Co-regularization\", \"Margin consistency", 
        "title": "Multi-view learning overview: Recent progress and new challenges"
    }, 
    {
        "abstract": "Recent development of computers and the Internet allows us to immediately access a vast amount of information such as texts, sounds, images, and movies. Furthermore, a wide range of personal data such as search logs, purchase records, and diagnosis history are accumulated everyday. Such a huge amount of data is called big databig data, and there is a growing tendency to create new values and business opportunities by extracting useful knowledge from data. This process is often called data miningdata mining, and machine learningmachine learning is the key technology for extracting useful knowledge. In this chapter, an overview of the field of machine learning is provided.", 
        "author": "Masashi Sugiyama", 
        "keyword": "Supervised learning\", \"Unsupervised learning\", \"Reinforcement learning\", \"Regression\", keywords =Classification\", \"Clustering\", \"Outlier detection", 
        "title": "Chapter 1 - Statistical Machine Learning"
    }, 
    {
        "abstract": "Abstract Based on Gaussian margin machine (GMM) and extreme learning machine (ELM), confidence-weighted \\{ELM\\} (CW-ELM) is proposed to provide point forecasts and confidence intervals. CW-ELM maintains a multivariate normal distribution over the output weight vector. It is applied to seek the least informative distribution from those that keep the targets within the forecast confidence intervals. For simplicity, the covariance matrix is assumed to be diagonal. The simplified problem of CW-ELM is approximately solved by using Leave-One-Out-Incremental \\{ELM\\} (LOO-IELM) and the interior point method. Our experimental results on both synthetic and real-world regression datasets demonstrate that CW-ELM has better performance than Bayesian \\{ELM\\} and Gaussian process regression.", 
        "author": "Zhigen Shang and Jianqiang He", 
        "keyword": "Extreme learning machine\", \"Relative entropy\", \"Gaussian margin machine\", \"Regression", 
        "title": "Confidence-weighted extreme learning machine for regression problems"
    }, 
    {
        "abstract": "Abstract There are only a few of labeled training samples in the remote sensing image classification. Therefore, it is a highly challenging problem that finds a good classification method which could achieve high accuracy to deal with these data. In this paper, we propose a new remote sensing image classification method based on extreme learning machine (ELM) ensemble. In order to promote the diversity within the ensemble, we adopt feature segmentation and then feature extraction with nonnegative matrix factorization (NMF) to the original data firstly. Then \\{ELM\\} is chosen as base classifier to improve the classification efficiency. The experimental results show that the proposed algorithm not only has high classification accuracy, but also handles the adverse impact of a few of labeled training samples in the classification of remote sensing image well both on the remote sensing image and \\{UCI\\} data.", 
        "author": "Min Han and Ben Liu", 
        "keyword": "Remote sensing classification\", \"Nonnegative matrix factorization (NMF)\", \"Extreme learning machine keywords =ELM)\", \"Ensemble learning\", \"Feature extraction", 
        "title": "Ensemble of extreme learning machine for remote sensing image classification"
    }, 
    {
        "abstract": "Abstract Smile detection is a specialized task in facial expression analysis with applications such as photo selection, user experience analysis, and patient monitoring. As one of the most important and informative expressions, smile conveys the underlying emotion status such as joy, happiness, and satisfaction. In this paper, an efficient smile detection approach is proposed based on Extreme Learning Machine (ELM). The faces are first detected and a holistic flow-based face registration is applied which does not need any manual labeling or key point detection. Then \\{ELM\\} is used to train the classifier. The proposed smile detector is tested with different feature descriptors on publicly available databases including real-world face images. The comparisons against benchmark classifiers including Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) suggest that the proposed \\{ELM\\} based smile detector in general performs better and is very efficient. Compared to state-of-the-art smile detector, the proposed method achieves competitive results without preprocessing and manual registration.", 
        "author": "Le An and Songfan Yang and Bir Bhanu", 
        "keyword": "Facial expression analysis\", \"Smile detection\", \"Extreme Learning Machine\", \"Classification\", \"Feature extraction", 
        "title": "Efficient smile detection by Extreme Learning Machine"
    }, 
    {
        "abstract": "AbstractBackground High-dimensional biomedical data are frequently clustered to identify subgroup structures pointing at distinct disease subtypes. It is crucial that the used cluster algorithm works correctly. However, by imposing a predefined shape on the clusters, classical algorithms occasionally suggest a cluster structure in homogenously distributed data or assign data points to incorrect clusters. We analyzed whether this can be avoided by using emergent self-organizing feature maps (ESOM). Methods Data sets with different degrees of complexity were submitted to \\{ESOM\\} analysis with large numbers of neurons, using an interactive R-based bioinformatics tool. On top of the trained \\{ESOM\\} the distance structure in the high dimensional feature space was visualized in the form of a so-called U-matrix. Clustering results were compared with those provided by classical common cluster algorithms including single linkage, Ward and k-means. Results Ward clustering imposed cluster structures on cluster-less \u201cgolf ball\u201d, \u201ccuboid\u201d and \u201cS-shaped\u201d data sets that contained no structure at all (random data). Ward clustering also imposed structures on permuted real world data sets. By contrast, the ESOM/U-matrix approach correctly found that these data contain no cluster structure. However, ESOM/U-matrix was correct in identifying clusters in biomedical data truly containing subgroups. It was always correct in cluster structure identification in further canonical artificial data. Using intentionally simple data sets, it is shown that popular clustering algorithms typically used for biomedical data sets may fail to cluster data correctly, suggesting that they are also likely to perform erroneously on high dimensional biomedical data. Conclusions The present analyses emphasized that generally established classical hierarchical clustering algorithms carry a considerable tendency to produce erroneous results. By contrast, unsupervised machine-learned analysis of cluster structures, applied using the ESOM/U-matrix method, is a viable, unbiased method to identify true clusters in the high-dimensional space of complex data.", 
        "author": "Alfred Ultsch and J\u00f6rn L\u00f6tsch", 
        "keyword": "Machine-learning\", \"Clustering", 
        "title": "Machine-learned cluster identification in high-dimensional data"
    }, 
    {
        "abstract": "Abstract This paper discusses the use of machine learning techniques for the classification of medical data, specifically for guiding disease modifying therapies for Sickle Cell. Extensive research has indicated that machine learning approaches generate significant improvements when used for the pre-processing of medical time-series data signals and have assisted in obtaining high accuracy in the classification of medical data. The aim of this paper is to present findings for several classes of learning algorithm for medically related problems. The initial case study addressed in this paper involves classifying the dosage of medication required for the treatment of patients with Sickle Cell Disease. We use different machine learning architectures in order to investigate the accuracy and performance within the case study. The main purpose of applying classification approach is to enable healthcare organisations to provide accurate amount of medication. The results obtained from a range of models during our experiments have shown that of the proposed models, recurrent networks produced inferior results in comparison to conventional feedforward neural networks and the Random Forest model. For our dataset, it was found that the Random Forest Classifier produced the highest levels of performance overall.", 
        "author": "Mohammed Khalaf and Abir Jaafar Hussain and Robert Keight and Dhiya Al-Jumeily and Paul Fergus and Russell Keenan and Posco Tso", 
        "keyword": "Dynamic neural network\", \"Elman\", \"Jordan\", \"Medical data analysis\", \"Sickle cell disease", 
        "title": "Machine learning approaches to the application of disease modifying therapy for sickle cell using classification models"
    }, 
    {
        "abstract": "Abstract Maintaining a desired comfort level while minimizing the total energy consumed is an interesting optimization problem in Heating, ventilating and air conditioning (HVAC) system control. This paper proposes a localized control strategy that uses Computational Fluid Dynamics (CFD) simulation results and K-means clustering algorithm to optimally partition an air-conditioned room into different zones. The temperature and air velocity results from \\{CFD\\} simulation are combined in two ways: 1) based on the relationship indicated in predicted mean vote (PMV) formula; 2) based on the relationship extracted from \\{ASHRAE\\} RP-884 database using extreme learning machine (ELM). Localized control can then be effected in which each of the zones can be treated individually and an optimal control strategy can be developed based on the partitioning result.", 
        "author": "Hongming Zhou and Yeng Chai Soh and Xiaoying Wu", 
        "keyword": "HVAC\", \"Computational Fluid dynamics\", \"K-means\", \"PMV\", \"Extreme learning machine", 
        "title": "Integrated analysis of \\{CFD\\} data with K-means clustering algorithm and extreme learning machine for localized \\{HVAC\\} control"
    }, 
    {
        "abstract": null, 
        "author": "Kelvin K.L. Wong and Liansheng Wang and Defeng Wang", 
        "keyword": null, 
        "title": "Recent developments in machine learning for medical imaging applications"
    }, 
    {
        "abstract": "AbstractObjective Antimicrobial stewardship programs have been shown to limit the inappropriate use of antimicrobials. Hospitals are increasingly relying on clinical decision support systems to assist in the demanding prescription reviewing process. In previous work, we have reported on an emerging clinical decision support system for antimicrobial stewardship that can learn new rules supervised by user feedback. In this paper, we report on the evaluation of this system. Methods The evaluated system uses a knowledge base coupled with a supervised learning module that extracts classification rules for inappropriate antimicrobial prescriptions using past recommendations for dose and dosing frequency adjustments, discontinuation of therapy, early switch from intravenous to oral therapy, and redundant antimicrobial spectrum. Over five weeks, the learning module was deployed alongside the baseline system to prospectively evaluate its ability to discover rules that complement the existing knowledge base for identifying inappropriate prescriptions of piperacillin\u2013tazobactam, a frequently used antimicrobial. Results The antimicrobial stewardship pharmacists reviewed 374 prescriptions, of which 209 (56% of 374) were identified as inappropriate leading to 43 recommendations to optimize prescriptions. The baseline system combined with the learning module triggered alerts in 270 prescriptions with a positive predictive value of identifying inappropriate prescriptions of 74%. Of these, 240 reviewed prescriptions were identified by the alerts of the baseline system with a positive predictive value of 82% and 105 reviewed prescriptions were identified by the alerts of the learning module with a positive predictive value of 62%. The combined system triggered alerts for all 43 recommendations, resulting in a rate of actionable alerts of 16% (43 recommendations of 270 reviewed alerts); the baseline system triggered alerts for 38 interventions, resulting in a rate of actionable alerts of 16% (38 of 240 reviewed alerts); and the learning module triggered alerts for 17 interventions, resulting in a rate of actionable alerts of 16% (17 of 105 reviewed alerts). The learning module triggered alerts for every inappropriate prescription missed by the knowledge base of the baseline system (n = 5). Conclusions The learning module was able to extract clinically relevant rules for multiple types of antimicrobial alerts. The learned rules were shown to extend the knowledge base of the baseline system by identifying pharmacist interventions that were missed by the baseline system. The learned rules identified inappropriate prescribing practices that were not supported by local experts and were missing from its knowledge base. However, combining the baseline system and the learning module increased the number of false positives.", 
        "author": "Mathieu Beaudoin and Froduald Kabanza and Vincent Nault and Louis Valiquette", 
        "keyword": "Evaluation\", \"Clinical decision support system\", \"Supervised learning\", \"Rule induction\", \"Antimicrobial stewardship", 
        "title": "Evaluation of a machine learning capability for a clinical decision support system to enhance antimicrobial stewardship programs"
    }, 
    {
        "abstract": "Abstract Recently, Deep Learning (DL) method has received a significant breakthrough in the data representation, whose success mainly depends on its deep structure. In this paper, we focus on the \\{DL\\} research based on Support Vector Machine (SVM), and first present an Ex-Adaboost learning strategy, and then propose a new Deep Support Vector Machine (called DeepSVM). Unlike other \\{DL\\} algorithms based on SVM, in each layer, Ex-Adaboost is applied to not only select \\{SVMs\\} with the minimal error rate and the highest diversity, but also to produce the weight for each feature. In this way, new training data is obtained. By stacking these \\{SVMs\\} into multiple layers following the same way, we finally acquire a new set of deep features that can greatly boost the classification performance. In the end, the training data represented by these new features is regarded as the input for a standard \\{SVM\\} classifier. In the experimental part, we offer these answers to the following questions: 1) is the deep structure of DeepSVM really useful for classification problem? 2) Does Ex-Adaboost work, and is it helpful for further improving on DeepSVM\u2019s performance with respect to the deep structure? 3) How much improvement in classification accuracy of DeepSVM, compared with other exist algorithms?", 
        "author": "Zhiquan Qi and Bo Wang and Yingjie Tian and Peng Zhang", 
        "keyword": "Pattern recognition\", \"Deep architectures\", \"Support vector machine", 
        "title": "When Ensemble Learning Meets Deep Learning: a New Deep Support Vector Machine for Classification"
    }, 
    {
        "abstract": "Abstract Action and gesture recognition from motion capture and RGB-D camera sequences has recently emerged as a renowned and challenging research topic. The current methods can usually be applied only to small datasets with a dozen or so different actions, and the systems often require large amounts of time to train the models and to classify new sequences. In this paper, we first extract simple but effective frame-level features from the skeletal data and build a recognition system based on the extreme learning machine. We then propose three modeling methods for post-processing the classification outputs to obtain the recognition results on the action sequence level. We test the proposed method on three public datasets ranging from 11 to 40 action classes. For all datasets, the method can classify the sequences with accuracies reaching 96\u201399% and with the average classification time for one sequence on a single computer core around 4 ms. Fast training and testing and the high accuracy make the proposed method readily applicable for online recognition applications.", 
        "author": "Xi Chen and Markus Koskela", 
        "keyword": "Action and gesture recognition\", \"Extreme learning machine\", \"Support vector machine\", \"Motion keywords =apture\", \"RGB-D\", \"HDM05", 
        "title": "Skeleton-based action recognition with extreme learning machines"
    }, 
    {
        "abstract": "Abstract Wireless sensor networks suffer from a wide range of faults and anomalies which hinder their smooth working. These faults are even more significant for medical wireless sensor networks, which simply cannot afford such inconsistencies. To combat this issue, various fault detection mechanisms have been developed. We tried enhancing the performance of one such mechanism, and our findings are presented in this paper. Using machine learning algorithms, we will show through our experiments on real medical datasets that our approach gives more accurate results than other existing fault detection mechanisms. This research will be critical in detecting sensor faults quickly, accurately and with a low false alarm ratio.", 
        "author": "Girik Pachauri and Sandeep Sharma", 
        "keyword": "Wireless Sensor Networks\", \"Machine Learning Algorithms\", \"Sensor Faults\", \"Healthcare and patient monitoring", 
        "title": "Anomaly Detection in Medical Wireless Sensor Networks using Machine Learning Algorithms"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) has received increasing attention for its simple principle, low computational cost and excellent performance. However, a large number of labeled instances are often required, and the number of hidden nodes should be manually tuned, for better learning and generalization of ELM. In this paper, we propose a Sparse Semi-Supervised Extreme Learning Machine (S3ELM) via joint sparse regularization for classification, which can automatically prune the model structure via joint sparse regularization technology, to achieve more accurate, efficient and robust classification, when only a small number of labeled training samples are available. Different with most of greedy-algorithms based model selection approaches, by using \u2113 2 , 1 -norm, \\{S3ELM\\} casts a joint sparse constraints on the training model of \\{ELM\\} and formulate a convex programming. Moreover, with a Laplacian, \\{S3ELM\\} can make full use of the information from both the labeled and unlabeled samples. Some experiments are taken on several benchmark datasets, and the results show that \\{S3ELM\\} is computationally attractive and outperforms its counterparts.", 
        "author": "Xiaozhuo Luo and F. Liu and Shuyuan Yang and Xiaodong Wang and Zhiguo Zhou", 
        "keyword": "Sparse semi-supervised learning\", \"Extreme learning machine\", \"\u2113 2 , 1 -Norm\", \"Joint sparse keywords =egularization\", \"Laplacian", 
        "title": "Joint sparse regularization based Sparse Semi-Supervised Extreme Learning Machine (S3ELM) for classification"
    }, 
    {
        "abstract": "Abstract Biofuels are important for the reduction of engine exhaust emissions and fossil fuel consumption. To use different blends of biofuels, the electronic control unit (ECU) of the engine must be modified and calibrated. However, the calibration process of \\{ECU\\} is very costly and time-consuming. Therefore, most of the engines can only use one specific biofuel blend; otherwise the engines cannot run properly. To alleviate this problem, a mathematical engine model can be used for predicting the engine performance at different \\{ECU\\} settings and biofuel blends so that the \\{ECU\\} can be re-calibrated in real-time via some controllers. The prediction of the engine model must be very fast and accurate for such online control purpose. It must also be very compact due to the limited memory size of the ECU. As a result, a new method called sparse Bayesian extreme learning machine (SBELM) is proposed in this paper to fulfill these requirements of the mathematical engine model for fast engine performance prediction and \\{ECU\\} online re-calibration. Experiments were conducted to compare \\{SBELM\\} with conventional ELM, Bayesian \\{ELM\\} (BELM) and back-propagated neural network (BPNN). Evaluation results show that \\{SBELM\\} can perform at least similar to, but mostly better than, ELM, \\{BELM\\} and BPNN, in terms of prediction accuracy. In terms of execution time, model size, and insensitivity to hidden neuron number, \\{SBELM\\} completely outperforms the other three methods. By these results, \\{SBELM\\} is verified to better fulfill the practical requirements of mathematical engine model for online engine performance prediction.", 
        "author": "Ka In Wong and Chi Man Vong and Pak Kin Wong and Jiahua Luo", 
        "keyword": "Extreme learning machine\", \"Sparse Bayesian\", \"Biofuel\", \"Dual-fuel engine\", \"Engine performance", 
        "title": "Sparse Bayesian extreme learning machine and its application to biofuel engine performance prediction"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of \\{ELM\\} from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to \\{ELM\\} which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, \\{ELM\\} has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, \\{ELM\\} have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in \\{ELM\\} together with its future perspectives.", 
        "author": "Gao Huang and Guang-Bin Huang and Shiji Song and Keyou You", 
        "keyword": "Extreme learning machine\", \"Classification\", \"Clustering\", \"Feature learning\", \"Regression", 
        "title": "Trends in extreme learning machines: A review"
    }, 
    {
        "abstract": "Abstract Compared with conventional weighted voting methods, class-specific soft voting (CSSV) system has several advantages. On one hand, it not only deals with the soft class probability outputs but also refines the weights from classifiers to classes. On the other hand, the class-specific weights can be used to improve the combinative performance without increasing much computational load. This paper proposes two weight optimization based ensemble methods (CSSV-ELM and SpaCSSV-ELM) under the framework of \\{CSSV\\} scheme for multiple extreme learning machines (ELMs). The designed two models are in terms of accuracy and sparsity aspects, respectively. Firstly, CSSV-ELM takes advantage of the condition number of matrix, which reveals the stability of linear equation, to determine the weights of base \\{ELM\\} classifiers. This model can reduce the unreliability induced by randomly input parameters of a single ELM, and solve the ill-conditioned problem caused by linear system structure of \\{ELM\\} simultaneously. Secondly, sparse ensemble methods can lower memory requirement and speed up the classification process, but only for classifier-specific weight level. Therefore, a SpaCSSV-ELM method is proposed by transforming the weight optimization problem to a sparse coding problem, which uses the sparse representation technique for maintaining classification performance with less nonzero weight coefficients. Experiments are carried out on twenty \\{UCI\\} data sets and Finance event series data and the experimental results show the superior performance of the \\{CSSV\\} based \\{ELM\\} algorithms by comparing with the state-of-the-art algorithms.", 
        "author": "Jingjing Cao and Sam Kwong and Ran Wang and Xiaodong Li and Ke Li and Xiangfei Kong", 
        "keyword": "Extreme learning machine\", \"Soft voting\", \"Condition number\", \"Sparse ensemble", 
        "title": "Class-specific soft voting based multiple extreme learning machines ensemble"
    }, 
    {
        "abstract": "Abstract Experimental datasets in bioengineering are commonly limited in size, thus rendering Machine Learning (ML) impractical for predictive modelling. Novel techniques of multiple runs for model development and surrogate data analysis for model validation are suggested for prediction of biomedical outcomes based on small datasets for classification and regression tasks. The proposed framework was applied to designing a Neural Network model for osteoarthritic bone fracture risk stratification, and a Decision Tree model for prediction of antibody-mediated kidney transplant rejection. Despite the small datasets (35 bone specimens and 80 kidney transplants), the two models achieved high accuracy of 98.3% and 85%, respectively.", 
        "author": "Torgyn Shaikhina and Dave Lowe and Sunil Daga and David Briggs and Robert Higgins and Natasha Khovanova", 
        "keyword": "Machine Learning\", \"Small Data\", \"Biomedical Systems\", \"Decision Tree\", \"Neural Network", 
        "title": "Machine Learning for Predictive Modelling based on Small Data in Biomedical Engineering"
    }, 
    {
        "abstract": "Abstract The online sequential extreme learning machine (OS-ELM) has been used for training without retraining the \\{ELM\\} when a chunk of data is received. However, OS-ELM may be affected by an improper number of hidden nodes settings which reduces the generalization of OS-ELM. This paper addresses this problem in OS-ELM. A new structural tolerance OS-ELM (STOS-ELM), based on the Householder block exact inverse \\{QRD\\} recursive least squares algorithm having numerical robustness is proposed. Experimental results conducted on four regressions and five classification problems showed that STOS-ELM can handle the situation when the network is constructed with an improper number of hidden nodes. Accordingly, the proposed STOS-ELM can be easily applied; the size of the hidden layer of \\{ELM\\} can be roughly approximated. If a chunk of data is received, it can be updated in the existing network without having to worry about the proper number of given hidden nodes. Furthermore, the accuracy of the network trained by STOS-ELM is comparable to that of the batch \\{ELM\\} when the networks have the same configurations. STOS-ELM can also be applied in ensemble version (ESTOS-ELM). We found that the stability of STOS-ELM can be further improved using the ensemble technique. The results show that ESTOS-ELM is also more stable and accurate than both of the original OS-ELM and EOS-ELM, especially in the classification problems.", 
        "author": "Punyaphol Horata and Sirapat Chiewchanwattana and Khamron Sunat", 
        "keyword": "Extreme learning machine\", \"Online sequential extreme learning machine\", \"Householder block exact keywords =nverse \\{QR\\} decomposition\", \"Structural tolerance\", \"Robustness\", \"Ensemble", 
        "title": "Enhancement of online sequential extreme learning machine based on the householder block exact inverse \\{QRD\\} recursive least squares"
    }, 
    {
        "abstract": "Abstract Multilayer perceptron (MLP) and support vector machine (SVM), two popular learning machines, are increasingly being used as alternatives to classical statistical models for ground-level ozone prediction. However, employing learning machines without sufficient awareness about their limitations can lead to unsatisfactory results in modeling the ozone evolving mechanism, especially during ozone formation episodes. With the spirit of literature review and justification, this paper discusses, with respect to the concerning of ozone prediction, the recently developed algorithms/technologies for treating the most prominent model-performance-degradation limitations. \\{MLP\\} has the \u201cblack-box\u201d property, i.e., it hardly provides physical explanation for the trained model, overfitting and local minima problems, and \\{SVM\\} has parameters identification and class imbalance problems. This commentary article aims to stress that the underlying philosophy of using learning machines is by no means as trivial as simply fitting models to the data because it causes difficulties, controversies or unresolved problems. This article also aims to serve as a reference point for further technical readings for experts in relevant fields.", 
        "author": "Wei-Zhen Lu and Dong Wang", 
        "keyword": "Algorithms\", \"Artificial neural networks\", \"Learning machine\", \"Ozone prediction\", \"Multilayer keywords =erceptron\", \"Support vector machine", 
        "title": "Learning machines: Rationale and application in ground-level ozone prediction"
    }, 
    {
        "abstract": "Abstract Control chart pattern recognition (CCPR) is an important issue in statistical process control because unnatural control chart patterns (CCPs) exhibited on control charts can be associated with specific causes that adversely affect the manufacturing processes. In recent years, many machine learning techniques [e.g., artificial neural networks (ANNs) and support vector machines (SVMs)] have been successfully applied to CCPR. However, such existing research for \\{CCPR\\} has mostly been developed for identification of basic CCPs. Little attention has been given to the utilization of ANNs/SVMs for identification of concurrent \\{CCPs\\} (two or more basic \\{CCPs\\} occurring simultaneously) which are commonly encountered in practical manufacturing processes. In addition, these existing research for \\{CCPR\\} cannot provide more detailed \\{CCP\\} parameter information, such as shift magnitude, trend slope, cycle amplitude, etc., which is very useful for quality practitioners to search the assignable causes that give rise to the out-of-control situation. This study proposes a hybrid approach that integrates extreme-point symmetric mode decomposition (ESMD) with extreme learning machine (ELM) to identify typical concurrent \\{CCPs\\} and in addition to accurately quantify the major \\{CCP\\} parameter of the specific basic \\{CCPs\\} involved. The numerical results indicate that the proposed model can effectively identify not only concurrent \\{CCPs\\} but also basic CCPs. Meanwhile, the major \\{CCP\\} parameter of the identified concurrent \\{CCP\\} can also be accurately quantified.", 
        "author": "Wen-An Yang and Wei Zhou and Wenhe Liao and Yu Guo", 
        "keyword": "Statistical process control\", \"Control chart\", \"Pattern recognition\", \"Extreme learning machine\", \"Extreme-point symmetric mode decomposition", 
        "title": "Identification and quantification of concurrent control chart patterns using extreme-point symmetric mode decomposition and extreme learning machines"
    }, 
    {
        "abstract": "Abstract Deep learning (DL) is a family of machine learning methods that has gained considerable attention in the scientific community, breaking benchmark records in areas such as speech and visual recognition. \\{DL\\} differs from conventional machine learning methods by virtue of its ability to learn the optimal representation from the raw data through consecutive nonlinear transformations, achieving increasingly higher levels of abstraction and complexity. Given its ability to detect abstract and complex patterns, \\{DL\\} has been applied in neuroimaging studies of psychiatric and neurological disorders, which are characterised by subtle and diffuse alterations. Here we introduce the underlying concepts of \\{DL\\} and review studies that have used this approach to classify brain-based disorders. The results of these studies indicate that \\{DL\\} could be a powerful tool in the current search for biomarkers of psychiatric and neurologic disease. We conclude our review by discussing the main promises and challenges of using \\{DL\\} to elucidate brain-based disorders, as well as possible directions for future research.", 
        "author": "Sandra Vieira and Walter H.L. Pinaya and Andrea Mechelli", 
        "keyword": "Deep learning\", \"Machine learning\", \"Neuroimaging\", \"Pattern recognition\", \"Multilayer perceptron\", keywords =Autoencoders\", \"Convolutional neural networks\", \"Deep belief networks\", \"Psychiatric disorders\", \"Neurologic disorders", 
        "title": "Using deep learning to investigate the neuroimaging correlates of psychiatric and neurological disorders: Methods and applications"
    }, 
    {
        "abstract": "Abstract This paper presents two adaptive neural control schemes for a class of uncertain continuous-time multi-input multi-output (MIMO) nonlinear dynamic systems. Within these schemes, the single-hidden layer feedforward networks (SLFNs) are applied to approximate the unknown nonlinear functions of the systems and then the neural controller is built based on the approximated neural models. The parameters of the \\{SLFNs\\} are modified using the recently proposed neural algorithm named extreme learning machine (ELM), where the parameters of the hidden nodes are assigned randomly. Different from the original \\{ELM\\} algorithm, the output weights are updated using the adaptive laws derived based on the Lyapunov stability theorem and Barbalat\u05f3s lemma so that the asymptotical stability of the system can be guaranteed. The robustifying control term is also constructed to compensate for approximation errors of the SLFNs. In order to avoid the requirement of the approximation error bounds, the estimation laws derived based on the Lyapunov stability theorem and Barbalat\u05f3s lemma are employed to estimate the error bounds in the second adaptive control scheme. Finally the proposed control schemes are applied to control a two-link robot manipulator. The simulation results demonstrate the effectiveness of the proposed control schemes for the \\{MIMO\\} nonlinear system.", 
        "author": "Hai-Jun Rong and Jin-Tao Wei and Jian-Ming Bai and Guang-She Zhao and Yong-Qi Liang", 
        "keyword": "Single-hidden layer feedforward network\", \"Extreme learning machine\", \"MIMO nonlinear systems", 
        "title": "Adaptive neural control for a class of \\{MIMO\\} nonlinear systems with extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, a new hidden layer construction method for Extreme Learning Machines (ELMs) is investigated, aimed at generating a diverse set of weights. The paper proposes two new \\{ELM\\} variants: Binary ELM, with a weight initialization scheme based on { 0 , 1 } \u2013weights; and Ternary ELM, with a weight initialization scheme based on { \u2212 1 , 0 , 1 } \u2013weights. The motivation behind this approach is that these features will be from very different subspaces and therefore each neuron extracts more diverse information from the inputs than neurons with completely random features traditionally used in ELM. Therefore, ideally it should lead to better ELMs. Experiments show that indeed \\{ELMs\\} with ternary weights generally achieve lower test error. Furthermore, the experiments show that the Binary and Ternary \\{ELMs\\} are more robust to irrelevant and noisy variables and are in fact performing implicit variable selection. Finally, since only the weight generation scheme is adapted, the computational time of the \\{ELM\\} is unaffected, and the improved accuracy, added robustness and the implicit variable selection of Binary \\{ELM\\} and Ternary \\{ELM\\} come for free.", 
        "author": "Mark van Heeswijk and Yoan Miche", 
        "keyword": "Extreme learning machine\", \"Hidden layer initialization\", \"Intrinsic plasticity\", \"Random keywords =rojection\", \"Binary features\", \"Ternary features", 
        "title": "Binary/ternary extreme learning machines"
    }, 
    {
        "abstract": null, 
        "author": "Karmele L\u00f3pez-de-Ipi\u00f1a and Nora Barroso", 
        "keyword": null, 
        "title": "Special issue on \u201cBioinspired intelligence for machine learning\u201d"
    }, 
    {
        "abstract": "Abstract This paper explores the performance of Ensembles of Extreme Learning Machine classifiers for hyperspectral image classification and segmentation in a semisupervised and spatially regularized process. The approach assumes that we have available only a small training set of labeled samples, which we enrich with a set of guessed labelings on selected samples from the vast pool of unlabeled image pixels. Selection and label guessing is conditioned to an unsupervised classification of the image pixel spectra, and to the spatial proximity to the labeled samples in the image domain. Unlabeled pixels falling in the spatial neighborhood of a labeled training sample, and belonging to the same unsupervised class, acquire its label. Unsupervised classification can be performed by any clustering technique, in this paper we have resorted to the classical K-means. The classifier built from the enriched training dataset is applied to the entire hyperspectral image. Finally, we perform a spatial regularization of the classification label image, maximizing a rather general prior smoothness criterion, by the selection of the most frequent class in each pixel neighborhood. This paper reports experiments with homogeneous ensembles of ELM, rELM, and OP-ELM classifiers, including a sensitivity analysis over the ensemble size and the number of hidden nodes. Computational experiments on four well known benchmarking hyperspectral images give state-of-the-art results.", 
        "author": "Borja Ayerdi and Ion Marqu\u00e9s and Manuel Gra\u00f1a", 
        "keyword": "Hyperspectral images\", \"Spatial-spectral segmentation\", \"Extreme Learning Machine\", \"Semisupervised learning", 
        "title": "Spatially regularized semisupervised Ensembles of Extreme Learning Machines for hyperspectral image segmentation"
    }, 
    {
        "abstract": "Abstract In this paper we present M4CVD: Mobile Machine Learning Model for Monitoring Cardiovascular Disease, a system designed specifically for mobile devices that facilitates monitoring of cardiovascular disease (CVD). The system uses wearable sensors to collect observable trends of vital signs contextualized with data from clinical databases. Instead of transferring the raw data directly to the health care professionals, the system performs analysis on the local device by feeding the hybrid of collected data to a support vector machine (SVM) to monitor features extracted from clinical databases and wearable sensors to classify a patient as \u201ccontinued risk\u201d or \u201cno longer at risk\u201d for CVD. As a work in progress we evaluate a proof-of-concept \\{M4CVD\\} using a synthetic clinical database of 200 patients. The results of our experiment show the system was successful in classifying a patient's \\{CVD\\} risk with an accuracy of 90.5%.", 
        "author": "Omar Boursalie and Reza Samavi and Thomas E. Doyle", 
        "keyword": "Support vector machine\", \"SVM\", \"Machine learning\", \"Data mining\", \"Cardiovascular disease\", \"CVD\", keywords =Mobile device\", \"Remote patient monitoring\", \"Wearable system\", \"EHR", 
        "title": "M4CVD: Mobile Machine Learning Model for Monitoring Cardiovascular Disease"
    }, 
    {
        "abstract": "Abstract This paper proposes a unified approach to learning from constraints, which integrates the ability of classical machine learning techniques to learn from continuous feature-based representations with the ability of reasoning using higher-level semantic knowledge typical of Statistical Relational Learning. Learning tasks are modeled in the general framework of multi-objective optimization, where a set of constraints must be satisfied in addition to the traditional smoothness regularization term. The constraints translate First Order Logic formulas, which can express learning-from-example supervisions and general prior knowledge about the environment by using fuzzy logic. By enforcing the constraints also on the test set, this paper presents a natural extension of the framework to perform collective classification. Interestingly, the theory holds for both the case of data represented by feature vectors and the case of data simply expressed by pattern identifiers, thus extending classic kernel machines and graph regularization, respectively. This paper also proposes a probabilistic interpretation of the proposed learning scheme, and highlights intriguing connections with probabilistic approaches like Markov Logic Networks. Experimental results on classic benchmarks provide clear evidence of the remarkable improvements that are obtained with respect to related approaches.", 
        "author": "Michelangelo Diligenti and Marco Gori and Claudio Sacc\u00e0", 
        "keyword": "Learning with constraints\", \"Kernel machines\", \"FOL", 
        "title": "Semantic-based regularization for learning and inference"
    }, 
    {
        "abstract": "Abstract Prediction of surface roughness is always considered important in the manufacturing field. A product may require a particular roughness that may be specified by the designer for various reasons, either functional requirement or aesthetic appeal. While modern manufacturing systems and machines have always contributed towards better control of surface quality, better computational facilities and the availability of newer algorithms attract researchers to understand the prediction of quality in a better manner. In this paper, prediction of surface roughness by multiple regression analysis is presented. The predictors are cutting parameters, tool wear and the statistical parameters extracted from the vibration signals of a turning centre. The contribution of various statistical parameters in prediction of surface roughness is studied. A Machine learning approach using feature reduction using principle component analysis is attempted to achieve higher predictability and low computational effort.", 
        "author": "M. Elangovan and N.R. Sakthivel and S. Saravanamurugan and Binoy.B. Nair and V. Sugumaran", 
        "keyword": "Surface roughness\", \"vibration signals\", \"statistical features\", \"regression analysis\", \"principle keywords =omponent analysis\", \"machine learning ;", 
        "title": "Machine Learning Approach to the Prediction of Surface Roughness Using Statistical Features of Vibration Signal Acquired in Turning"
    }, 
    {
        "abstract": "Abstract Generic object recognition is to classify the object to a generic category. Intra-class variabilities cause big troubles for this task. Traditional methods involve plenty of pre-processing steps, like model construction, feature extraction, etc. Moreover, these methods are only effective for some specific dataset. In this paper, we propose to use local receptive fields based extreme learning machine (ELM-LRF) as a general framework for object recognition. It is operated directly on the raw images and thus suitable for all different datasets. Additionally, the architecture is simple and only requires few computations, as most connection weights are randomly generated. Comparing to state-of-the-art results on NORB, ETH-80 and \\{COIL\\} datasets, it is on par with the best one on ETH-80 and sets the new records for \\{NORB\\} and COIL.", 
        "author": "Zuo Bai and Liyanaarachchi Lekamalage Chamara Kasun and Guang-Bin Huang", 
        "keyword": "Generic object recognition\", \"local receptive fields\", \"Extreme Learning Machine (ELM)", 
        "title": "Generic Object Recognition with Local Receptive Fields Based Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract This paper delivers a study on the change of rank of input matrix in Extreme Learning Machine (ELM) and the relationship between the rank of input matrix and the residence error of training an ELM. From the viewpoint of data analysis, the study reveals why \\{ELM\\} has a decreasing residence error with the increase of number of nodes in hidden layer and what role the Sigmoid function plays in increasing the rank of input matrix. Furthermore the relationship between the stability of solutions and the rank of output matrix is also discussed. An application of residence error to genetic algorithms of minimizing L1-norm \\{ELM\\} is given.", 
        "author": "Ai-Min Fu and Xi-Zhao Wang and Yu-Lin He and Lai-Sheng Wang", 
        "keyword": "Extreme learning machine\", \"Genetic algorithm\", \"Rank of matrix\", \"Residence error\", \"Solution stability", 
        "title": "A study on residence error of training an extreme learning machine and its application to evolutionary algorithms"
    }, 
    {
        "abstract": "Abstract Identifying students\u2019 learning styles has several benefits such as making students aware of their strengths and weaknesses when it comes to learning and the possibility to personalize their learning environment to their learning styles. While there exist learning style questionnaires for identifying a student's learning style, such questionnaires have several disadvantages and therefore, research has been conducted on automatically identifying learning styles from students\u2019 behavior in a learning environment. Current approaches to automatically identify learning styles have an average precision between 66% and 77%, which shows the need for improvements in order to use such automatic approaches reliably in learning environments. In this paper, four computational intelligence algorithms (artificial neural network, genetic algorithm, ant colony system and particle swarm optimization) have been investigated with respect to their potential to improve the precision of automatic learning style identification. Each algorithm was evaluated with data from 75 students. The artificial neural network shows the most promising results with an average precision of 80.7%, followed by particle swarm optimization with an average precision of 79.1%. Improving the precision of automatic learning style identification allows more students to benefit from more accurate information about their learning styles as well as more accurate personalization towards accommodating their learning styles in a learning environment. Furthermore, teachers can have a better understanding of their students and be able to provide more appropriate interventions.", 
        "author": "Jason Bernard and Ting-Wen Chang and Elvira Popescu and Sabine Graf", 
        "keyword": "Intelligent tutoring systems\", \"Distance education and telelearning\", \"Interactive learning keywords =nvironments\", \"Computational intelligence", 
        "title": "Learning style Identifier: Improving the precision of learning style identification through computational intelligence algorithms"
    }, 
    {
        "abstract": "Abstract The data collection and understanding provides better understanding of cancer patients in the regions from north coastal districts of AP, India. The present studies were shown more number of breast cancer patients compares to other types of cancer. Most of the questionnaire provided good understanding about cancer patients. There are more number of females (64.3%) compared to males (35.7%). Most of the patients are using mobile phones and mosquito repellents. \\{KStar\\} was shown 100% accuracy with the dataset compared to other tested machine learning algorithms.", 
        "author": "T. Panduranga Vital and G.S.V. Prasada Raju and I.S. Siva Rao and A.D. Praveen Kumar", 
        "keyword": "Cancer\", \"questionnaire\", \"Statistical analysis\", \"Machine learning", 
        "title": "Data Collection, Statistical Analysis and Machine Learning Studies of Cancer Dataset from North Costal Districts of AP, India"
    }, 
    {
        "abstract": "AbstractObjective Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. \\{EHRs\\} are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient\u2019s clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of \\{EHR\\} computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total \\{EHR\\} records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. Methods Two relational learning \\{ILP\\} approaches and three well-known \\{WEKA\\} (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded \\{EHR\\} data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five \\{ML\\} approaches across phenotypes for statistical significance. Results We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the \\{ML\\} approaches being evaluated. Nine phenotypic models for each \\{ML\\} approach were evaluated, resulting in better overall model performance in \\{AUROC\\} using \\{ILP\\} when compared to \\{PART\\} (p = 0.039), \\{J48\\} (p = 0.003) and \\{JRIP\\} (p = 0.003). Discussion \\{ILP\\} has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. Conclusion Relational learning using \\{ILP\\} offers a viable approach to EHR-driven phenotyping.", 
        "author": "Peggy L. Peissig and Vitor Santos Costa and Michael D. Caldwell and Carla Rottscheit and Richard L. Berg and Eneida A. Mendonca and David Page", 
        "keyword": "Machine learning\", \"Electronic health record\", \"Inductive logic programming\", \"Phenotyping\", \"Relational machine learning", 
        "title": "Relational machine learning for electronic health record-driven phenotyping"
    }, 
    {
        "abstract": "Abstract The combination of spectroscopy and a novel classification algorithm called extreme learning machine (ELM) was developed for food classification. The performance influence of different input dimensionalities was also investigated. The classification accuracy and speed of five chemometrics techniques, including k-nearest neighbor (KNN), partial least-squares discriminant analysis (PLS-DA), back propagation artificial neural network (BP-ANN), least-squares support vector machine (LS-SVM), and \\{ELM\\} were compared. It was presented that the accuracy of \\{ELM\\} was better than its competitors in most cases. Moreover, on the classification stage, \\{ELM\\} performed much faster than KNN, LS-SVM, and BP-ANN, which indicated that \\{ELM\\} may be a promising method for real-time food classification with a comparable accuracy based on near or mid-infrared spectroscopy.", 
        "author": "Wenbin Zheng and Xiaping Fu and Yibin Ying", 
        "keyword": "Spectroscopy\", \"Food\", \"Classification\", \"Extreme learning machine", 
        "title": "Spectroscopy-based food classification with extreme learning machine"
    }, 
    {
        "abstract": "Abstract Travel mode choice prediction of individuals is important in planning new transportation projects. In this paper, we present four machine learning methods namely artificial neural net-MLP, artificial neural net-RBF, multinomial logistic regression, and support vector machines, for predicting travel mode of individuals in city of Luxembourg. The presented methods use individuals\u2019 characteristics, transport mode specifications and data related to places of work and residence. The dataset analyzed comes from a national survey. It contains information on the daily mobility (e.g., from home to work) of individuals who either live or work in Luxembourg. We extracted individual characteristics to relate daily movements (journeys between home and work, in particular) to the characteristics of working individuals. We used the information about public transportation and some geographical location of the residential and work places. We compare the rates of successful prediction obtained by neural networks and several alternative approaches for predicting the travel mode choice using cross-validation. The results show that the artificial neural networks perform better compared to other alternatives. Our analysis can be used to support management decision-making and build predictions under uncertainty related to changes in people's behavior, economic context or environment and transportation infrastructure.", 
        "author": "Hichem Omrani", 
        "keyword": "Data mining\", \"data split\", \"machine learning\", \"validation\", \"neural networks.", 
        "title": "Predicting Travel Mode of Individuals by Machine Learning"
    }, 
    {
        "abstract": "Abstract Time series prediction has been widely used in a variety of applications in science, engineering, finance, etc. There are two different modeling options for constructing forecasting models in time series prediction. Global modeling constructs a model which is independent from user queries. On the contrary, local modeling constructs a local model for each different query from the user. In this paper, we propose a local modeling strategy and investigate the effectiveness of incorporating local modeling with three popular machine learning based forecasting methods, Neural Network (NN), Adaptive Neuro-Fuzzy Inference System (ANFIS), and Least Squares Support Vector Machine (LS-SVM), for time series prediction. Given a series of historical data, a local context of the user query is located and an appropriate number of lags are selected. Then forecasting models are constructed by applying NN, ANFIS, and LS-SVM, respectively. A number of experiments are conducted and the results show that local modeling can enhance the estimation performance of a forecasting method for time series prediction.", 
        "author": "Shin-Fu Wu and Shie-Jue Lee", 
        "keyword": "Time series prediction\", \"Machine learning\", \"Local modeling\", \"Nearest neighbors\", \"Mutual information", 
        "title": "Employing local modeling in machine learning based methods for time-series prediction"
    }, 
    {
        "abstract": "Abstract In this paper, three novel classification algorithms aiming at (semi-)supervised action classification are proposed. Inspired by the effectiveness of discriminant subspace learning techniques and the fast and efficient Extreme Learning Machine (ELM) algorithm for Single-hidden Layer Feedforward Neural networks training, the \\{ELM\\} algorithm is extended by incorporating discrimination criteria in its optimization process, in order to enhance its classification performance. The proposed Discriminant \\{ELM\\} algorithm is extended, by incorporating proper regularization in its optimization process, in order to exploit information appearing in both labeled and unlabeled action instances. An iterative optimization scheme is proposed in order to address multi-view action classification. The proposed classification algorithms are evaluated on three publicly available action recognition databases providing state-of-the-art performance in all the cases.", 
        "author": "Alexandros Iosifidis and Anastasios Tefas and Ioannis Pitas", 
        "keyword": "Extreme learning machine\", \"Semi-supervised learning\", \"Multi-view learning", 
        "title": "Regularized extreme learning machine for multi-view semi-supervised action recognition"
    }, 
    {
        "abstract": "Abstract This paper presents a new approach to model a mixed-integer mathematical programming for a single machine scheduling problem with deteriorating and learning effects. Neglecting the effect of performing a job on its own processing time is mentioned as a deficiency in the literature of industrial scheduling. At first, self-influential factors are defined and then equations are presented to utilize these new factors. \\{GAMS\\} IDE/CPLEX software is used to validate the represented model by solving small to medium-sized sample problems, in which the associate results are compared with a hybrid meta-heuristic algorithm based on Ant Colony Optimization (ACO), Genetic Algorithm (GA) and Imperialist Competitive Algorithm (ICA). The vitality of considering and modeling the effect of learning and deteriorating made by a job, on its own processing time is tested for several sample problems. Then a significant improvement is observed by comparing the results acquired by neglecting the self-influential factors with the results based on considering them. Finally, the computational results are analyzed and the conclusion is given.", 
        "author": "S.H. Pakzad-Moghaddam and H. Mina and R. Tavakkoli-Moghaddam", 
        "keyword": "Single machine scheduling\", \"Learning and deteriorating effects\", \"Self-influential jobs\", keywords =Adapting ability\", \"Genetic algorithm\", \"Imperialist competitive algorithm", 
        "title": "An approach for modeling a new single machine scheduling problem with deteriorating and learning effects"
    }, 
    {
        "abstract": "Abstract Mild cognitive impairment (MCI) is a transitional stage between age-related cognitive decline and Alzheimer's disease (AD). For the effective treatment of AD, it would be important to identify \\{MCI\\} patients at high risk for conversion to AD. In this study, we present a novel magnetic resonance imaging (MRI)-based method for predicting the MCI-to-AD conversion from one to three years before the clinical diagnosis. First, we developed a novel \\{MRI\\} biomarker of MCI-to-AD conversion using semi-supervised learning and then integrated it with age and cognitive measures about the subjects using a supervised learning algorithm resulting in what we call the aggregate biomarker. The novel characteristics of the methods for learning the biomarkers are as follows: 1) We used a semi-supervised learning method (low density separation) for the construction of \\{MRI\\} biomarker as opposed to more typical supervised methods; 2) We performed a feature selection on \\{MRI\\} data from \\{AD\\} subjects and normal controls without using data from \\{MCI\\} subjects via regularized logistic regression; 3) We removed the aging effects from the \\{MRI\\} data before the classifier training to prevent possible confounding between \\{AD\\} and age related atrophies; and 4) We constructed the aggregate biomarker by first learning a separate \\{MRI\\} biomarker and then combining it with age and cognitive measures about the \\{MCI\\} subjects at the baseline by applying a random forest classifier. We experimentally demonstrated the added value of these novel characteristics in predicting the MCI-to-AD conversion on data obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. With the \\{ADNI\\} data, the \\{MRI\\} biomarker achieved a 10-fold cross-validated area under the receiver operating characteristic curve (AUC) of 0.7661 in discriminating progressive \\{MCI\\} patients (pMCI) from stable \\{MCI\\} patients (sMCI). Our aggregate biomarker based on \\{MRI\\} data together with baseline cognitive measurements and age achieved a 10-fold cross-validated \\{AUC\\} score of 0.9020 in discriminating pMCI from sMCI. The results presented in this study demonstrate the potential of the suggested approach for early \\{AD\\} diagnosis and an important role of \\{MRI\\} in the MCI-to-AD conversion prediction. However, it is evident based on our results that combining \\{MRI\\} data with cognitive test results improved the accuracy of the MCI-to-AD conversion prediction.", 
        "author": "Elaheh Moradi and Antonietta Pepe and Christian Gaser and Heikki Huttunen and Jussi Tohka", 
        "keyword": "Low density separation\", \"Mild cognitive impairment\", \"Feature selection\", \"Support vector keywords =achine\", \"Magnetic resonance imaging\", \"Classification\", \"Semi-supervised learning\", \"Alzheimer's keywords =isease\", \"ADNI\", \"Early diagnosis", 
        "title": "Machine learning framework for early MRI-based Alzheimer's conversion prediction in \\{MCI\\} subjects"
    }, 
    {
        "abstract": "Abstract In actual chemical processes, the fact that some essential variables cannot be directly measured makes the production quality out-of-control and even results in large economic losses. In this study, a novel sample clustering extreme learning machine (SC-ELM) model is developed to achieve timely and accurate measurement. SC-ELM is a fast training algorithm with an excellent generalization performance, and the combined sample clustering approach solves the non-optimal input weights of ELM. The network structure is designed by a fast leave-one-out cross-validation (FLOO-CV) method. Meanwhile, the validity of SC-ELM model is firstly tested by two classical regression datasets. With the comparison of other \\{ELM\\} models, SC-ELM is proved to be an effective model in both modeling accuracy and network structure. Then, SC-ELM is applied in measuring the quality index of a high-density polyethylene (HDPE) process running in a chemical plant, and the experiment results demonstrate that SC-ELM model can achieve quality estimation with higher measuring accuracy and less training time.", 
        "author": "Di Peng and Yuan Xu and Yanqing Wang and Zhiqiang Geng and Qunxiong Zhu", 
        "keyword": "Extreme learning machine\", \"Density based K-means clustering algorithm\", \"Fast leave-one-out keywords =ross-validation method\", \"Soft-sensing\", \"High-density polyethylene process", 
        "title": "Soft-sensing in complex chemical process based on a sample clustering extreme learning machine model\u2217"
    }, 
    {
        "abstract": "Abstract A small, but growing, number of flux towers in urban environments measure surface\u2013atmospheric exchanges of carbon dioxide by the eddy covariance method. As in all eddy covariance studies, obtaining annual sums of urban \\{CO2\\} exchange requires imputation of data gaps due to low turbulence and non-stationary conditions, adverse weather, and instrument failures. Gap-filling approaches that are widely used for measurements from towers in natural vegetation are based on light and temperature response models. However, they do not account for key features of the urban environment including tower footprint heterogeneity and localized \\{CO2\\} sources. Here, we present a novel gap-filling modeling framework that uses machine learning to select explanatory variables, such as continuous traffic counts and temporal variables, and then constrains models separately for spatially classified subsets of the data. We applied the modeling framework to a three year time series of measurements from a tall broadcast tower in a suburban neighborhood of Minneapolis-Saint Paul, Minnesota, USA. The gap-filling performance was similar to that reported for natural measurement sites, explaining 64% to 88% of the variability in the fluxes. Simulated carbon budgets were in good agreement with an ecophysiological bottom-up study at the same site. Total annual carbon dioxide flux sums for the tower site ranged from 1064 to 1382\u00a0g\u00a0C\u00a0m\u22122\u00a0yr\u22121, across different years and different gap-filling methods. Bias errors of annual sums resulting from gap-filling did not exceed 18\u00a0g\u00a0C\u00a0m\u22122\u00a0yr\u22121 and random uncertainties did not exceed \u00b144\u00a0g\u00a0C\u00a0m\u22122\u00a0yr\u22121 (or \u00b13.8% of the annual flux). Regardless of the gap-filling method used, the year-to-year differences in carbon exchange at this site were small. In contrast, the modeled annual sums of \\{CO2\\} exchange differed by a factor of two depending on wind direction. This indicated that the modeled time series captured the spatial variability in both the biogenic and anthropogenic \\{CO2\\} sources and sinks in a reproducible way. The gap-filling approach developed here may also be useful for inhomogeneous sites other than urban areas, such as logged forests or ecosystems under disturbance from fire or pests.", 
        "author": "Olaf Menzer and Wendy Meiring and Phaedon C. Kyriakidis and Joseph P. McFadden", 
        "keyword": "Carbon dioxide\", \"Eddy covariance\", \"Gap-filling\", \"Urban ecosystem\", \"Machine learning\", keywords =Uncertainty\", \"Spatial heterogeneity", 
        "title": "Annual sums of carbon dioxide exchange over a heterogeneous urban landscape through machine learning based gap-filling"
    }, 
    {
        "abstract": "Abstract A center issue for system identification is how to get a model estimate that achieves a good balance between the data fit and the model complexity. For the recently introduced kernel-based regularization method for linear system identification, the problem becomes first how to design a suitable kernel structure and second how to determine a right kernel among the kernel structure. In this paper and its companion one, we will focus on the issue of kernel structure design. Depending on the type of the prior knowledge, we provide two different ways: from a machine learning perspective or from a system theory perspective. We will focus on the first perspective here. In particular, we show that both the stable spline kernel and the diagonal correlated kernel belong to the class of the so-called exponentially convex locally stationary (ECLS) kernels. This finding motivates to construct \\{ECLS\\} or \\{LS\\} kernels for this regularization method in different ways, e.g., based on carefully designed state space models.", 
        "author": "Tianshi Chen and Lennart Ljung", 
        "keyword": "System identification\", \"machine learning\", \"regularization methods\", \"kernel methods", 
        "title": "On kernel structures for regularized system identification (I): a machine learning perspective*"
    }, 
    {
        "abstract": "Abstract Modeling problems containing a mixture of Boolean and numerical variables is a long-standing interest of Artificial Intelligence. However, performing inference and learning in hybrid domains is a particularly daunting task. The ability to model these kinds of domains is crucial in \u201clearning to design\u201d tasks, that is, learning applications where the goal is to learn from examples how to perform automatic de novo design of novel objects. In this paper we present Structured Learning Modulo Theories, a max-margin approach for learning in hybrid domains based on Satisfiability Modulo Theories, which allows to combine Boolean reasoning and optimization over continuous linear arithmetical constraints. The main idea is to leverage a state-of-the-art generalized Satisfiability Modulo Theory solver for implementing the inference and separation oracles of Structured Output SVMs. We validate our method on artificial and real world scenarios.", 
        "author": "Stefano Teso and Roberto Sebastiani and Andrea Passerini", 
        "keyword": "Satisfiability modulo theory\", \"Structured-output support vector machines\", \"Optimization modulo keywords =heory\", \"Constructive machine learning\", \"Learning with constraints", 
        "title": "Structured learning modulo theories"
    }, 
    {
        "abstract": "Abstract Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of \\{ML\\} tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of \\{ML\\} methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent \\{ML\\} approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised \\{ML\\} techniques as well as on different input features and data samples. Given the growing trend on the application of \\{ML\\} methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.", 
        "author": "Konstantina Kourou and Themis P. Exarchos and Konstantinos P. Exarchos and Michalis V. Karamouzis and Dimitrios I. Fotiadis", 
        "keyword": "Machine learning\", \"Cancer susceptibility\", \"Predictive models\", \"Cancer recurrence\", \"Cancer survival", 
        "title": "Machine learning applications in cancer prognosis and prediction"
    }, 
    {
        "abstract": "Abstract The use of piezoelectric sensor arrays to measure contact forces has been extensively studied in connection to robotics. In this research, Polyvinylidene Fluoride (PVDF) has been used for direct measurement of the mechanical stress and large bandwidth electromechanical transduction. Additionally, a machine learning algorithm has been specifically designed to deal with the inherent tensor morphology of raw tactile data. An experiment involving 70 participants has been organized to collect the output signals under different modalities of touch. The proposed pattern-recognition system showed good accuracy in performing touch classification in a three-class classification experiment, opening interesting scenarios for the application of tensor-based models to support human\u2013robot interactions.", 
        "author": "P. Gastaldo and L. Pinna and L. Seminara and M. Valle and R. Zunino", 
        "keyword": "\\{PVDF\\} tactile sensors\", \"Array signal processing\", \"Touch modality\", \"Machine learning\", \"Kernel machines", 
        "title": "A tensor-based approach to touch modality classification by using machine learning"
    }, 
    {
        "abstract": null, 
        "author": "Carlos M. Travieso and Janos Fodor and Jes\u00fas B. Alonso", 
        "keyword": "Information processing\", \"Machine learning\", \"Applications of engineering", 
        "title": "Special issue on information processing and machine learning for applications of engineering"
    }, 
    {
        "abstract": "Abstract In this paper, we study the problem of supervised Fully PolSAR (polarimetric synthetic aperture radar) image classification. We estimate a complex Wishart model distribution for each class using training data, and we use such models to design a new classification procedure based on a diffusion-reaction equation. The method relies on simultaneously filtering and classifying pixels within the image. The diffusion term smooths the patches within the image, and the reaction term tends to move the pixel values towards the closest (in the sense of stochastic distances) representative class. We present a detailed study of the method accuracy using both simulated and true data, and we provide optimum parameters for its use. We show that the proposed method outperforms the results obtained using maximum likelihood and usual stochastic distance classification methods.", 
        "author": "Luis Gomez and Luis Alvarez and Luis Mazorra and Alejandro C. Frery", 
        "keyword": "Image processing\", \"Image analysis\", \"Classification\", \"Speckle\", \"SAR polarimetry", 
        "title": "Fully PolSAR image classification using machine learning techniques and reaction-diffusion systems"
    }, 
    {
        "abstract": "Abstract We present a multi-fidelity co-kriging statistical learning framework that combines variable-fidelity quantum mechanical calculations of bandgaps to generate a machine-learned model that enables low-cost accurate predictions of the bandgaps at the highest fidelity level. In addition, the adopted Gaussian process regression formulation allows us to predict the underlying uncertainties as a measure of our confidence in the predictions. Using a set of 600 elpasolite compounds as an example dataset and using semi-local and hybrid exchange correlation functionals within density functional theory as two levels of fidelities, we demonstrate the excellent learning performance of the method against actual high fidelity quantum mechanical calculations of the bandgaps. The presented statistical learning method is not restricted to bandgaps or electronic structure methods and extends the utility of high throughput property predictions in a significant way.", 
        "author": "G. Pilania and J.E. Gubernatis and T. Lookman", 
        "keyword": "Double perovskites\", \"Elpasolites\", \"Materials informatics\", \"Information fusion", 
        "title": "Multi-fidelity machine learning models for accurate bandgap predictions of solids"
    }, 
    {
        "abstract": "Abstract In this paper, we discuss the connection of the kernel versions of the \\{ELM\\} classifier with infinite Single-hidden Layer Feedforward Neural networks and show that the original \\{ELM\\} kernel definition can be adopted for the calculation of the \\{ELM\\} kernel matrix for two of the most common activation functions, i.e., the \\{RBF\\} and the sigmoid functions. In addition, we show that a low-rank decomposition of the kernel matrix defined on the input training data can be exploited in order to determine an appropriate \\{ELM\\} space for input data mapping. The \\{ELM\\} space determined from this process can be subsequently used for network training using the original \\{ELM\\} formulation. Experimental results denote that the adoption of the low-rank decomposition-based \\{ELM\\} space determination leads to enhanced performance, when compared to the standard choice, i.e., random input weights generation.", 
        "author": "Alexandros Iosifidis and Anastastios Tefas and Ioannis Pitas", 
        "keyword": "Extreme learning machine\", \"Single-hidden layer networks\", \"Infinite networks,", 
        "title": "On the kernel Extreme Learning Machine classifier"
    }, 
    {
        "abstract": "Abstract We consider parallel-machine scheduling with deteriorating jobs and DeJong\u2019s learning effect. We focus on the problems to minimize the total completion time and the makespan. We show that the former is polynomially solvable, while the latter is NP-hard, for which we provide a fully polynomial-time approximation scheme.", 
        "author": "Min Ji and Xiaoying Tang and Xin Zhang and T.C.E. Cheng", 
        "keyword": "DeJong\u2019s learning effect\", \"Job deterioration\", \"Scheduling\", \"FPTAS", 
        "title": "Machine scheduling with deteriorating jobs and DeJong\u2019s learning effect"
    }, 
    {
        "abstract": "Abstract Recent advances in neurosciences have revealed that neural information in the brain is encoded through precisely timed spike trains, not only through the neural firing rate. This paper presents a new supervised, multi-spike learning algorithm for multilayer spiking neural networks, which can implement the complex spatio-temporal pattern learning of spike trains. The proposed algorithm firstly defines inner product operators to mathematically describe and manipulate spike trains, and then solves the problems of error function construction and backpropagation among multiple output spikes during learning. The algorithm is successfully applied to different temporal tasks, such as learning sequences of spikes and nonlinear pattern classification problems. The experimental results show that the proposed algorithm has higher learning accuracy and efficiency than the Multi-ReSuMe learning algorithm. It is effective for solving complex spatio-temporal pattern learning problems.", 
        "author": "Xianghong Lin and Xiangwen Wang and Zhanjun Hao", 
        "keyword": "Spiking neural networks\", \"Supervised learning\", \"Inner products of spike trains\", \"Multilayer keywords =eedforward network\", \"Backpropagation algorithm", 
        "title": "Supervised learning in multilayer spiking neural networks with inner products of spike trains"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a Discriminative Group-wise Beta-Bernoulli process restricted Boltzmann machine (DG-BBP RBM), an approach to learn class-specific mid-level features based on the Beta-Bernoulli process restricted Boltzmann machine (BBP RBM), which imposes class-specific sparsity that has discriminative characteristics across different classes to eliminate redundancy among extracted features. With this method, we learn mid-level features that are characteristic of each class and that are shared rarely or not at all with other classes (i.e., are discriminative of that class). In experiments on image classification tasks, our DG-BBP \\{RBM\\} showed much better results than did \\{BBP\\} \\{RBM\\} and related methods and could capture semantic attributes that can be used to discriminate between classes.", 
        "author": "Hui-Jin Lee and Ki-Sang Hong", 
        "keyword": "Mid-level feature\", \"Restricted Boltzman machine\", \"Beta-Bernoulli process\", \"Deep belief keywords =etworks\", \"Discriminative group-wise sparsity\", \"Image classification", 
        "title": "Class-specific mid-level feature learning with the Discriminative Group-wise Beta-Bernoulli process restricted Boltzmann machines"
    }, 
    {
        "abstract": "Abstract Electricity prices have rather complex features such as high volatility, high frequency, nonlinearity, mean reversion and non-stationarity that make forecasting very difficult. However, accurate electricity price forecasting is essential to market traders, retailers, and generation companies. To improve prediction accuracy using each model\u2019s unique features, this paper proposes a hybrid approach that combines the wavelet transform, the kernel extreme learning machine (KELM) based on self-adapting particle swarm optimization and an auto regressive moving average (ARMA). Self-adaptive particle swarm optimization (SAPSO) is adopted to search for the optimal kernel parameters of the KELM. After testing the wavelet decomposition components, stationary series as new input sets are predicted by the \\{ARMA\\} model and non-stationary series are predicted by the SAPSO-KELM model. The performance of the proposed method is evaluated by using electricity price data from the Pennsylvania-New Jersey-Maryland (PJM), Australian and Spanish markets. The experimental results show that the developed method has more accurate prediction, better generality and practicability than individual methods and other hybrid methods.", 
        "author": "Zhang Yang and Li Ce and Li Lian", 
        "keyword": "Electricity price forecasting\", \"ARMA\", \"KELM\", \"Wavelet transform\", \"SAPSO", 
        "title": "Electricity price forecasting by a hybrid model, combining wavelet transform, \\{ARMA\\} and kernel-based extreme learning machine methods"
    }, 
    {
        "abstract": "Abstract Craters are distinctive features on the surfaces of most terrestrial planets. Craters reveal the relative ages of surface units and provide information on surface geology. Extracting craters is one of the fundamental tasks in planetary research. Although many automated crater detection algorithms have been developed to exact craters from image or topographic data, most of them are applicable only in particular regions, and only a few can be widely used, especially in complex surface settings. In this study, we present a machine learning approach to crater detection from topographic data. This approach includes two steps: detecting square regions which contain one crater with the use of a boosting algorithm and delineating the rims of the crater in each square region by local terrain analysis and circular Hough transform. A new variant of Haar-like features (scaled Haar-like features) is proposed and combined with traditional Haar-like features and local binary pattern features to enhance the performance of the classifier. Experimental results with the use of Mars topographic data demonstrate that the developed approach can significantly decrease the false positive detection rate while maintaining a relatively high true positive detection rate even in challenging sites.", 
        "author": "Kaichang Di and Wei Li and Zongyu Yue and Yiwei Sun and Yiliang Liu", 
        "keyword": "Crater detection algorithm\", \"Topographic data\", \"Machine learning\", \"AdaBoost\", \"Martian surface", 
        "title": "A machine learning approach to crater detection from topographic data"
    }, 
    {
        "abstract": "Abstract Knowledge is a key factor of competitive advantages in the current economic crisis and uncertain environment. There are a number of indicators to measure knowledge advances, however, the benefits for stakeholders and policy makers are limited because of a lack of classification models. This paper introduces an approach to classify 54 countries (in 2007\u20132009) according to their progress toward a knowledge economy (KE). To achieve this, the aims of this paper are twofold: first, to find clusters of countries at a similar stage of development toward \\{KE\\} to test if they are meaningful; hence, it will be possible to order the clusters from early \\{KEs\\} (last cluster) to advanced \\{KEs\\} (first cluster). Second, having obtained these clusters, it is possible to build various models to detect the advancement of countries toward \\{KE\\} from one year to another due to its classification. Then, three ordinal classifiers from the machine-learning field were compared in order to select the classifier that performs the best and to confirm the ordinal description of the clusters. Finally, an ordinal model based on the Support Vector Ordinal Regression with Implicit Constraints was selected because of its ability to classify the patterns into the clusters, confirming the appropriateness of the clusters and their ordinal nature. The proposed ordinal classifier could be used for monitoring the progress or stage of transition to \\{KE\\} and for analysing whether a country changes clusters, entering one that performs better or worse.", 
        "author": "M\u00f3nica de la Paz-Mar\u00edn and Pedro Antonio Guti\u00e9rrez and C\u00e9sar Herv\u00e1s-Mart\u00ednez", 
        "keyword": "Decision support systems\", \"Machine learning\", \"Knowledge economy\", \"Hierarchical clustering\", \"Ordinal classification", 
        "title": "Classification of countries\u2019 progress toward a knowledge economy based on machine learning classification techniques"
    }, 
    {
        "abstract": "Purpose This work presents the application of a machine learning (ML) algorithm to automatically generate high-quality, prostate low-dose-rate (LDR) brachytherapy treatment plans. The \\{ML\\} algorithm can mimic characteristics of preoperative treatment plans deemed clinically acceptable by brachytherapists. The planning efficiency, dosimetry, and quality (as assessed by experts) of preoperative plans generated with an \\{ML\\} planning approach was retrospectively evaluated in this study. Methods and Materials Preimplantation and postimplantation treatment plans were extracted from 100 high-quality \\{LDR\\} treatments and stored within a training database. The \\{ML\\} training algorithm matches similar features from a new \\{LDR\\} case to those within the training database to rapidly obtain an initial seed distribution; plans were then further fine-tuned using stochastic optimization. Preimplantation treatment plans\u00a0generated by the \\{ML\\} algorithm were compared with brachytherapist (BT) treatment plans in terms of planning time (Wilcoxon rank sum, \u03b1\u00a0=\u00a00.05) and dosimetry (1-way analysis of variance, \u03b1\u00a0=\u00a00.05). Qualitative preimplantation plan quality was evaluated by expert \\{LDR\\} radiation oncologists using a Likert scale questionnaire. Results The average planning time for the \\{ML\\} approach was 0.84\u00a0\u00b1\u00a00.57\u00a0minutes, compared with 17.88\u00a0\u00b1\u00a08.76\u00a0minutes for the expert planner (P=.020). Preimplantation plans were dosimetrically equivalent to the \\{BT\\} plans; the average prostate V150% was 4% lower for \\{ML\\} plans (P=.002), although the difference was not clinically significant. Respondents ranked the ML-generated plans as equivalent to expert \\{BT\\} treatment plans in terms of target coverage, normal tissue avoidance, implant confidence, and the need for plan modifications. Respondents had difficulty differentiating between plans generated by a human or those generated by the \\{ML\\} algorithm. Conclusions Prostate \\{LDR\\} preimplantation treatment plans that have equivalent quality to plans created by brachytherapists can be rapidly generated using ML. The adoption of \\{ML\\} in the brachytherapy workflow is expected to improve \\{LDR\\} treatment plan uniformity while reducing planning time and resources.", 
        "author": "Alexandru Nicolae and Gerard Morton and Hans Chung and Andrew Loblaw and Suneil Jain and Darren Mitchell and Lin Lu and Joelle Helou and Motasem Al-Hanaqta and Emily Heath and Ananth Ravi", 
        "keyword": null, 
        "title": "Evaluation of a Machine-Learning Algorithm for Treatment Planning in Prostate Low-Dose-Rate Brachytherapy"
    }, 
    {
        "abstract": "Abstract In recent years, the historical data during the search process of evolutionary algorithms has received increasing attention from many researchers, and some hybrid evolutionary algorithms with machine-learning have been proposed. However, the majority of the literature is centered on continuous problems with a single optimization objective. There are still a lot of problems to be handled for multi-objective combinatorial optimization problems. Therefore, this paper proposes a machine-learning based multi-objective memetic algorithm (ML-MOMA) for the discrete permutation flowshop scheduling problem. There are two main features in the proposed ML-MOMA. First, each solution is assigned with an individual archive to store the non-dominated solutions found by it and based on these individual archives a new population update method is presented. Second, an adaptive multi-objective local search is developed, in which the analysis of historical data accumulated during the search process is used to adaptively determine which non-dominated solutions should be selected for local search and how the local search should be applied. Computational results based on benchmark problems show that the cooperation of the above two features can help to achieve a balance between evolutionary global search and local search. In addition, many of the best known Pareto fronts for these benchmark problems in the literature can be improved by the proposed ML-MOMA.", 
        "author": "Xianpeng Wang and Lixin Tang", 
        "keyword": "Multi-objective permutation flowshop scheduling\", \"Memetic algorithm\", \"Data analysis", 
        "title": "A machine-learning based memetic algorithm for the multi-objective permutation flowshop scheduling problem"
    }, 
    {
        "abstract": "Abstract One of the biggest challenges in the design of real-world decision support systems is coming up with a good combinatorial optimization model. Often enough, accurate predictive models (e.g. simulators) can be devised, but they are too complex or too slow to be employed in combinatorial optimization. In this paper, we propose a methodology called Empirical Model Learning (EML) that relies on Machine Learning for obtaining components of a prescriptive model, using data either extracted from a predictive model or harvested from a real system. In a way, \\{EML\\} can be considered as a technique to merge predictive and prescriptive analytics. All models introduce some form of approximation. Citing G.E.P. Box [1] \u201cEssentially, all models are wrong, but some of them are useful\u201d. In EML, models are useful if they provide adequate accuracy, and if they can be effectively exploited by solvers for finding high-quality solutions. We show how to ground \\{EML\\} on a case study of thermal-aware workload dispatching. We use two learning methods, namely Artificial Neural Networks and Decision Trees and we show how to encapsulate the learned model in a number of optimization techniques, namely Local Search, Constraint Programming, Mixed Integer Non-Linear Programming and \\{SAT\\} Modulo Theories. We demonstrate the effectiveness of the \\{EML\\} approach by comparing our results with those obtained using expert-designed models.", 
        "author": "Michele Lombardi and Michela Milano and Andrea Bartolini", 
        "keyword": "Combinatorial optimization\", \"Machine learning\", \"Complex systems\", \"Local search\", \"Constraint keywords =rogramming\", \"Mixed integer non-linear programming\", \"SAT modulo theories\", \"Artificial neural keywords =etworks\", \"Decision trees", 
        "title": "Empirical decision model learning"
    }, 
    {
        "abstract": "Abstract Staff removal is an image processing task that aims to facilitate further analysis of music score images. Even when restricted to images in specific domains such as music score recognition, solving image processing problems usually requires the design of customized algorithms. To cope with image variabilities and the growing amount of data, machine learning based techniques emerge as a natural approach to be employed in image processing problems. In this sense, image operator learning methods are concerned with estimating, from sample pairs of input-output images of a transformation, a local function that characterizes the image transformation. These methods require the definition of some parameters, including the local information to be considered in the processing which is defined by a window. In this work we show how to apply the image operator learning technique to the staff line removal problem. We present an algorithm for window determination and show that it captures visual information relevant for staff removal. We also present a reference window set to be used in cases where the training set is not sufficiently large. Experimental results obtained with respect to synthetic and handwritten music scores under varying image conditions show that the learned image operators are comparable with especially designed state-of-the-art heuristic algorithms.", 
        "author": "Igor S. Montagner and Nina S.T. Hirata and Roberto Hirata Jr", 
        "keyword": "Staff removal\", \"Optical music recognition\", \"Document image analysis\", \"Image operator\", \"Machine learning", 
        "title": "Staff removal using image operator learning"
    }, 
    {
        "abstract": "Abstract There is broad interest in predicting the clinical course of mental disorders from early, multimodal clinical and biological information. Current computational models, however, constitute a significant barrier to realizing this goal. The early identification of trauma survivors at risk of post-traumatic stress disorder (PTSD) is plausible given the disorder's salient onset and the abundance of putative biological and clinical risk indicators. This work evaluates the ability of Machine Learning (ML) forecasting approaches to identify and integrate a panel of unique predictive characteristics and determine their accuracy in forecasting non-remitting \\{PTSD\\} from information collected within10 days of a traumatic event. Data on event characteristics, emergency department observations, and early symptoms were collected in 957 trauma survivors, followed for fifteen months. An \\{ML\\} feature selection algorithm identified a set of predictors that rendered all others redundant. Support Vector Machines (SVMs) as well as other \\{ML\\} classification algorithms were used to evaluate the forecasting accuracy of i) \\{ML\\} selected features, ii) all available features without selection, and iii) Acute Stress Disorder (ASD) symptoms alone. \\{SVM\\} also compared the prediction of a) \\{PTSD\\} diagnostic status at 15 months to b) posterior probability of membership in an empirically derived non-remitting \\{PTSD\\} symptom trajectory. Results are expressed as mean Area Under Receiver Operating Characteristics Curve (AUC). The feature selection algorithm identified 16 predictors, present in \u226595% cross-validation trials. The accuracy of predicting non-remitting \\{PTSD\\} from that set (AUC\u00a0=\u00a0.77) did not differ from predicting from all available information (AUC\u00a0=\u00a0.78). Predicting from \\{ASD\\} symptoms was not better then chance (AUC\u00a0=\u00a0.60). The prediction of \\{PTSD\\} status was less accurate than that of membership in a non-remitting trajectory (AUC\u00a0=\u00a0.71). \\{ML\\} methods may fill a critical gap in forecasting PTSD. The ability to identify and integrate unique risk indicators makes this a promising approach for developing algorithms that infer probabilistic risk of chronic posttraumatic stress psychopathology based on complex sources of biological, psychological, and social information.", 
        "author": "Isaac R. Galatzer-Levy and Karen-Inge Karstoft and Alexander Statnikov and Arieh Y. Shalev", 
        "keyword": "Posttraumatic stress disorder (PTSD)\", \"Course and prognosis\", \"Early prediction\", \"Forecasting\", keywords =Machine Learning\", \"Markov boundary feature selection\", \"Support Vector Machines", 
        "title": "Quantitative forecasting of \\{PTSD\\} from early trauma responses: A Machine Learning application"
    }, 
    {
        "abstract": "Abstract This paper presents a novel approach to the automatic classification of very large data sets composed of terahertz pulse transient signals, highlighting their potential use in biochemical, biomedical, pharmaceutical and security applications. Two different types of \\{THz\\} spectra are considered in the classification process. Firstly a binary classification study of poly-A and poly-C ribonucleic acid samples is performed. This is then contrasted with a difficult multi-class classification problem of spectra from six different powder samples that although have fairly indistinguishable features in the optical spectrum, they also possess a few discernable spectral features in the terahertz part of the spectrum. Classification is performed using a complex-valued extreme learning machine algorithm that takes into account features in both the amplitude as well as the phase of the recorded spectra. Classification speed and accuracy are contrasted with that achieved using a support vector machine classifier. The study systematically compares the classifier performance achieved after adopting different Gaussian kernels when separating amplitude and phase signatures. The two signatures are presented as feature vectors for both training and testing purposes. The study confirms the utility of complex-valued extreme learning machine algorithms for classification of the very large data sets generated with current terahertz imaging spectrometers. The classifier can take into consideration heterogeneous layers within an object as would be required within a tomographic setting and is sufficiently robust to detect patterns hidden inside noisy terahertz data sets. The proposed study opens up the opportunity for the establishment of complex-valued extreme learning machine algorithms as new chemometric tools that will assist the wider proliferation of terahertz sensing technology for chemical sensing, quality control, security screening and clinic diagnosis. Furthermore, the proposed algorithm should also be very useful in other applications requiring the classification of very large datasets.", 
        "author": "X.-X. Yin and S. Hadjiloucas and Y. Zhang", 
        "keyword": "THz\", \"Complex extreme learning machine\", \"Quaternary classification\", \"Lagrangian\", \"Multiclass classification", 
        "title": "Complex extreme learning machine applications in terahertz pulsed signals feature sets"
    }, 
    {
        "abstract": "Abstract This paper addresses the use of computer-aided diagnosis (CAD) system for the cataract classification based on ultrasound technique. Ultrasound A-scan signals were acquired in 220 porcine lenses. B-mode and Nakagami images were constructed. Ninety-seven parameters were extracted from acoustical, spectral and image textural analyses and were subjected to feature selection by Principal Component Analysis (PCA). Bayes, K Nearest-Neighbors (KNN), Fisher Linear Discriminant (FLD) and Support Vector Machine (SVM) classifiers were tested. The classification of healthy and cataractous lenses shows a good performance for the four classifiers (F-measure \u226592.68%) with \\{SVM\\} showing the highest performance (90.62%) for initial versus severe cataract classification.", 
        "author": "Miguel Caxinha and Elena Velte and M\u00e1rio Santos and Fernando Perdig\u00e3o and Jo\u00e3o Amaro and Marco Gomes and Jaime Santos", 
        "keyword": "cataract\", \"classification\", \"machine learning", 
        "title": "Automatic Cataract Classification based on Ultrasound Technique Using Machine Learning: A comparative Study"
    }, 
    {
        "abstract": "Abstract In recent years, there has been significant growth in the use of online learning resources by learners. However, due to information overload, many learners are experiencing difficulties in retrieving useful and relevant learning resources that meet their learning needs. Although existing recommender systems have recorded significant success in e-commerce domain, they still experience drawbacks in making accurate recommendations of learning resources in e-learning domain due to differences in learner characteristics such as learning style, knowledge level as well as learners\u2019 sequential learning patterns. Most of the existing recommendation techniques do not consider differences in learner characteristics. This problem can be alleviated through incorporation of additional information about the learner into the recommendation process. Furthermore, many recommendation techniques experience cold-start and rating sparsity problems. In this paper, we propose a hybrid knowledge-based recommender system based on ontology and sequential pattern mining (SPM) for recommendation of e-learning resources to learners. In the proposed recommendation approach, ontology is used to model and represent the domain knowledge about the learner and learning resources whereas \\{SPM\\} algorithm discovers the learners\u2019 sequential learning patterns. Our approach involves four steps: (1) creating ontology to represent knowledge about the learner and learning resources, (2) computing ratings similarity based on ontology domain knowledge and making predictions for the target learner, (3) generation of top N learning items by the collaborative filtering recommendation engine, and (4) application of \\{SPM\\} algorithm to the top N learning items to generate the final recommendations for the target learner. A number of experiments were carried out to evaluate the proposed hybrid recommender system and results show improved performance. Furthermore, the proposed hybrid approach can alleviate both the cold-start and data sparsity problems by making use of ontological domain knowledge and learner\u2019s sequential access pattern respectively before the initial data to work on is available in the recommender system.", 
        "author": "John K. Tarus and Zhendong Niu and Abdallah Yousif", 
        "keyword": "Recommender systems\", \"E-learning\", \"Ontology\", \"Collaborative filtering\", \"Sequential pattern mining", 
        "title": "A hybrid knowledge-based recommender system for e-learning based on ontology and sequential pattern mining"
    }, 
    {
        "abstract": "Abstract Multi-task learning employs a shared representation of knowledge for learning several instances of the same problem. Multi-step time series problem is one of the most challenging problems for machine learning methods. The performance of a prediction model face challenges for higher prediction horizons due to the accumulation of errors. Cooperative coevolution employs in a divide and conquer approach for training neural networks and has been very promising for single step ahead time series prediction. Recently, co-evolutionary multi-task learning has been proposed for dynamic time series prediction. In this paper, we adapt co-evolutionary multi-task learning for multi-step prediction where predictive recurrence is developed to feature knowledge from previous states for future prediction horizon. The goal of the paper is to present a network architecture with predictive recurrence which is capable of multi-step prediction through a form of multi-task learning. We employ cooperative neuro-evolution and an evolutionary algorithm as baselines for comparison. The results show that the proposed method provides the best generalization performance in most cases. Comparison of results with the literature has shown to be promising which motivates further application of the approach for related real-world problems.", 
        "author": "Rohitash Chandra and Yew-Soon Ong and Chi-Keong Goh", 
        "keyword": "Cooperative coevolution\", \"Neuro-evolution\", \"Feedforward networks\", \"Multi-task learning\", \"Multi-step time series prediction", 
        "title": "Co-evolutionary multi-task learning with predictive recurrence for multi-step chaotic time series prediction"
    }, 
    {
        "abstract": "Abstract This paper studies systems that can be modeled by single-machine scheduling problems with due date assignment. The actual job processing time is a function of the sum of the processing times of the jobs already processed. The due date assignment methods include the common due date (CON) and the slack due date (SLK). The problem is to determine optimal due date values that minimize objective functions which includes the cost of changing the due dates, a possible penalty for the total earliness of the scheduled jobs and the total penalty for discarding jobs. For the common due date and slack due date, we give polynomial-time dynamic programming algorithms to find the optimal jobs sequence, respectively.", 
        "author": "Zhang Xingong and Wang Yong", 
        "keyword": "Single-machine scheduling\", \"Learning effect\", \"CON due date assignment\", \"SLK due date assignment", 
        "title": "Single-machine scheduling CON/SLK due window assignment problems with sum-of-processed times based learning effect"
    }, 
    {
        "abstract": "Abstract This paper deals with the development and the implementation of an electronic nose based on Metal Oxide Semiconductor (MOS) as an innovative instrument to beer aroma recognition. Principal component analysis (PCA) results revealed a good discrimination, as two clearly separated groups (alcoholic and non-alcoholic brands). Linear discriminant analysis (LDA) was performed on the important variables which were detected based on \\{PCA\\} loadings. The results showed that 100% accuracy for both training and test sets was obtained using those variables. Soft independent modeling of class analogy (SIMCA) and partial least square discriminant analysis (PLS-DA) methods confirmed the \\{PCA\\} and \\{LDA\\} results of classification accuracy and their results were (100%, 100%) and (100%, 100%), for training and test sets, respectively. Finally, support vector machine (SVM) was considered and full accuracy (100%) for beer classification was again achieved for both training and test sets. The results showed that if simple methods perform well they may be preferred.", 
        "author": "Mahdi Ghasemi-Varnamkhasti and Seyed Saeid Mohtasebi and Maryam Siadat and Hojat Ahmadi and Seyed Hadi Razavi", 
        "keyword": "Electronic nose\", \"Machine olfaction\", \"Gas sensors\", \"Machine learning\", \"Beer", 
        "title": "From simple classification methods to machine learning for the binary discrimination of beers using electronic nose data"
    }, 
    {
        "abstract": "Summary During motor learning, movements and underlying neural activity initially exhibit large trial-to-trial variability that decreases over learning. However, it is unclear how task-relevant neural populations coordinate to explore and consolidate activity patterns. Exploration and consolidation could happen for each neuron independently, across the population jointly, or both. We disambiguated among these possibilities by investigating how subjects learned de novo to control a brain-machine interface using neurons from motor cortex. We decomposed population activity into the sum of private and shared signals, which produce uncorrelated and correlated neural variance, respectively, and examined how these signals\u2019 evolution causally shapes behavior. We found that initially large trial-to-trial movement and private neural variability reduce over learning. Concomitantly, task-relevant shared variance increases, consolidating a manifold containing consistent neural trajectories that generate refined control. These results suggest that motor cortex acquires skillful control by leveraging both independent and coordinated variance to explore and consolidate neural patterns.", 
        "author": "Vivek R. Athalye and Karunesh Ganguly and Rui M. Costa and Jose M. Carmena", 
        "keyword": "brain-machine interface\", \"neuroprosthetic learning\", \"motor learning\", \"dimensionality reduction\", \"neural variability", 
        "title": "Emergence of Coordinated Neural Dynamics Underlies Neuroprosthetic Learning and Skillful Control"
    }, 
    {
        "abstract": "Abstract The impetus for an interconnected, efficient, and adaptive manufacturing system, as advocated by the Industry 4.0 revolution, together with the latest developments in information technology, advanced manufacturing has become a prominent research topic in recent years. One critical aspect of advanced manufacturing is how to incorporate real-time demand information with a manufacturer's resource information, including workforce data and machine capacity and condition information, among others, to optimally schedule manufacturing processes with multiple objectives. In general, optimized manufacturing scheduling is a non-deterministic polynomial-time hard problem. Due to the complexity, scheduling presents a number of challenges to find the best possible solutions. This research proposes an ontology-based framework to formally represent a synchronized, station-based flow shop with a multi-skill workforce and multiple types of machines. Based on the ontology, this research develops a multi-agent reinforcement learning approach for the optimal scheduling of a manufacturing system of multi-stage processes for multiple types of products with various machines and a multi-skilled workforce. By employing a learning algorithm, this approach enables real-time cooperation between the workforce and the machines, and adaptively updates production schedules according to dynamically changing real-time events.", 
        "author": "Shuhui Qu and Jie Wang and Shivani Govil and James O. Leckie", 
        "keyword": "scheduling\", \"workforce management\", \"reinforcement learning\", \"multi-agent\", \"multi-stage\", keywords =multi-product\", \"multi-skills\", \"real-time information\", \"advanced manufacturing\", \"game theory", 
        "title": "Optimized Adaptive Scheduling of a Manufacturing Process System with Multi-skill Workforce and Multiple Machine Types: An Ontology-based, Multi-agent Reinforcement Learning Approach"
    }, 
    {
        "abstract": "Abstract Short-term building cooling load prediction is the essential foundation for many building energy management tasks, such as fault detection and diagnosis, demand-side management and control optimization. Conventional methods, which heavily rely on physical principles, have limited power in practice as their performance is subject to many physical assumptions. By contrast, data-driven methods have gained huge interests due to their flexibility in model development and the rich data available in modern buildings. The rapid development in data science has provided advanced data analytics to tackle prediction problems in a more convenient, efficient and effective way. This paper investigates the potential of one of the most promising techniques in advanced data analytics, i.e., deep learning, in predicting 24-h ahead building cooling load profiles. Deep learning refers to a collection of machine learning algorithms which are powerful in revealing nonlinear and complex patterns in big data. Deep learning can be used either in a supervised manner to develop prediction models with given inputs and output (i.e., cooling load), or in an unsupervised manner to extract meaningful features from raw data as model inputs. This study exploits the potential of deep learning in both manners, and compares its performance in cooling load prediction with typical feature extraction methods and popular prediction techniques in the building field. The results show that deep learning can enhance the performance of building cooling load prediction, especially when used in an unsupervised manner for constructing high-level features as model inputs. Using the features extracted by unsupervised deep learning as inputs for cooling load prediction can evidently enhance the prediction performance. The findings are enlightening and could bring more flexible and effective solutions for building energy predictions.", 
        "author": "Cheng Fan and Fu Xiao and Yang Zhao", 
        "keyword": "Building cooling load\", \"Building energy prediction\", \"Deep learning\", \"Data mining\", \"Big data", 
        "title": "A short-term building cooling load prediction method using deep learning algorithms"
    }, 
    {
        "abstract": "Abstract This paper presents a novel approach for short-term wind speed prediction based on a Coral Reefs Optimization algorithm (CRO) and an Extreme Learning Machine (ELM), using meteorological predictive variables from a physical model (the Weather Research and Forecast model, WRF). The approach is based on a Feature Selection Problem (FSP) carried out with the CRO, that must obtain a reduced number of predictive variables out of the total available from the WRF. This set of features will be the input of an ELM, that finally provides the wind speed prediction. The \\{CRO\\} is a novel bio-inspired approach, based on the simulation of reef formation and coral reproduction, able to obtain excellent results in optimization problems. On the other hand, the \\{ELM\\} is a new paradigm in neural networks\u2019 training, that provides a robust and extremely fast training of the network. Together, these algorithms are able to successfully solve this problem of feature selection in short-term wind speed prediction. Experiments in a real wind farm in the \\{USA\\} show the excellent performance of the CRO\u2013ELM approach in this \\{FSP\\} wind speed prediction problem.", 
        "author": "S. Salcedo-Sanz and A. Pastor-S\u00e1nchez and L. Prieto and A. Blanco-Aguilera and R. Garc\u00eda-Herrera", 
        "keyword": "Short term wind speed prediction\", \"Feature selection problem\", \"Coral reefs optimization keywords =lgorithm\", \"Extreme learning machines", 
        "title": "Feature selection in wind speed prediction systems based on a hybrid coral reefs optimization \u2013 Extreme learning machine approach"
    }, 
    {
        "abstract": "Abstract Brain imaging genomics is an emerging research topic that has arisen with the advances in high-throughput genotyping and multimodal imaging techniques. Its major task is to examine the association between genetic markers such as single nucleotide polymorphisms and quantitative traits extracted from multimodal neuroimaging data. Bridging imaging and genomic factors and exploring their connections have the potential to provide a better mechanistic understanding of normal or disordered brain functions. In the last decade, statistical and machine learning has been widely employed in this research area and has greatly advanced the association discoveries via univariate, multilocus, and bi-multivariate imaging genomic association analyses, as well as pathway and network enrichment analyses. This chapter describes the traditional and state-of-the-art machine learning models widely used in brain imaging genomic studies.", 
        "author": "J. Yan and L. Du and X. Yao and L. Shen", 
        "keyword": "Imaging genomics\", \"Genome-wide association study\", \"Regression\", \"Canonical correlation analysis\", keywords =Sparse learning\", \"Enrichment analysis", 
        "title": "Chapter 14 - Machine learning in brain imaging genomics"
    }, 
    {
        "abstract": "Abstract There is a shortage of compounds that are directed towards new targets apart from those targeted by the \\{FDA\\} approved drugs used against Mycobacterium tuberculosis. Topoisomerase I (Mttopo I) is an essential mycobacterial enzyme and a promising target in this regard. However, it suffers from a shortage of known inhibitors. We have previously used computational approaches such as homology modeling and docking to propose 38 \\{FDA\\} approved drugs for testing and identified several active molecules. To follow on from this, we now describe the in\u00a0vitro testing of a library of 639 compounds. These data were used to create machine learning models for Mttopo I which were further validated. The combined Mttopo I Bayesian model had a 5 fold cross validation receiver operator characteristic of 0.74 and sensitivity, specificity and concordance values above 0.76 and was used to select commercially available compounds for testing in\u00a0vitro. The recently described crystal structure of Mttopo I was also compared with the previously described homology model and then used to dock the Mttopo I actives norclomipramine and imipramine. In summary, we describe our efforts to identify small molecule inhibitors of Mttopo I using a combination of machine learning modeling and docking studies in conjunction with screening of the selected molecules for enzyme inhibition. We demonstrate the experimental inhibition of Mttopo I by small molecule inhibitors and show that the enzyme can be readily targeted for lead molecule development.", 
        "author": "Sean Ekins and Adwait Anand Godbole and Gy\u00f6rgy K\u00e9ri and L\u00e1szlo Orfi and J\u00e1nos Pato and Rajeshwari Subray Bhat and Rinkee Verma and Erin K. Bradley and Valakunja Nagaraja", 
        "keyword": "Bayesian models\", \"Collaborative drug discovery tuberculosis database\", \"Docking\", \"Function class keywords =ingerprints\", \"Homology model\", \"Mycobacterium tuberculosis\", \"Topoisomerase\", \"Tuberculosis", 
        "title": "Machine learning and docking models for Mycobacterium tuberculosis topoisomerase I"
    }, 
    {
        "abstract": "Abstract After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using \\{MVPA\\} and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. \\{MVPA\\} opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.", 
        "author": "Ian A. Clark and Katherine E. Niehaus and Eugene P. Duff and Martina C. Di Simplicio and Gari D. Clifford and Stephen M. Smith and Clare E. Mackay and Mark W. Woolrich and Emily A. Holmes", 
        "keyword": "Intrusive memories\", \"Trauma\", \"Flashback\", \"MVPA\", \"Machine learning\", \"Functional magnetic keywords =esonance imaging\", \"Mental imagery", 
        "title": "First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage"
    }, 
    {
        "abstract": "Abstract In this paper, a novel approach is developed to learn a tree of multi-task sparse metrics hierarchically over a visual tree to achieve a fast solution to large-scale image classification, where an enhanced visual tree is first learned to organize large numbers of image categories hierarchically in a coarse-to-fine fashion. Over the visual tree, a tree of multi-task sparse metrics is learned hierarchically by: (a) performing multi-task sparse metric learning over the sibling child nodes under the same parent node to explicitly separate their commonly-shared metric from their node-specific metrics; and (b) propagating the node-specific metric for the parent node to its sibling child nodes (at the next level of the visual tree), so that more discriminative metrics can be learned for controlling inter-level error propagation effectively. We have evaluated our hierarchical multi-task sparse metric learning algorithm over three different image sets and the experimental results demonstrated that our hierarchical multi-task sparse metric learning algorithm can obtain better performance than the state-of-the-art algorithms on large-scale image classification.", 
        "author": "Yu Zheng and Jianping Fan and Ji Zhang and Xinbo Gao", 
        "keyword": "Hierarchical multi-task sparse metric learning\", \"Visual tree\", \"Large-scale image classification", 
        "title": "Hierarchical learning of multi-task sparse metrics for large-scale image classification"
    }, 
    {
        "abstract": "Abstract Current electrocardiogram (ECG) signal quality assessment studies have aimed to provide a two-level classification: clean or noisy. However, clinical usage demands more specific noise level classification for varying applications. This work outlines a five-level \\{ECG\\} signal quality classification algorithm. A total of 13 signal quality metrics were derived from segments of \\{ECG\\} waveforms, which were labeled by experts. A support vector machine (SVM) was trained to perform the classification and tested on a simulated dataset and was validated using data from the MIT-BIH arrhythmia database (MITDB). The simulated training and test datasets were created by selecting clean segments of the \\{ECG\\} in the 2011 PhysioNet/Computing in Cardiology Challenge database, and adding three types of real \\{ECG\\} noise at different signal-to-noise ratio (SNR) levels from the MIT-BIH Noise Stress Test Database (NSTDB). The \\{MITDB\\} was re-annotated for five levels of signal quality. Different combinations of the 13 metrics were trained and tested on the simulated datasets and the best combination that produced the highest classification accuracy was selected and validated on the MITDB. Performance was assessed using classification accuracy (Ac), and a single class overlap accuracy (OAc), which assumes that an individual type classified into an adjacent class is acceptable. An Ac of 80.26% and an \\{OAc\\} of 98.60% on the test set were obtained by selecting 10 metrics while 57.26% (Ac) and 94.23% (OAc) were the numbers for the unseen \\{MITDB\\} validation data without retraining. By performing the fivefold cross validation, an Ac of 88.07 \u00b1 0.32% and \\{OAc\\} of 99.34 \u00b1 0.07% were gained on the validation fold of MITDB.", 
        "author": "Qiao Li and Cadathur Rajagopalan and Gari D. Clifford", 
        "keyword": "ECG\", \"Signal quality\", \"Multi-level classification\", \"Machine learning\", \"Support vector machine", 
        "title": "A machine learning approach to multi-level \\{ECG\\} signal quality classification"
    }, 
    {
        "abstract": "Abstract Dictionary learning approaches have been widely applied to solve pattern classification problems and have achieved promising performance. However, most of works aim to learn a discriminative synthesis dictionary and sparse coding coefficients for classification. Until recent years, analysis dictionary learning began to attract interest from researchers. In this paper, we present a novel discriminative analysis dictionary learning frame, named Synthesis Linear Classifier based Analysis Dictionary Learning (SLC-ADL). Firstly, we incorporate a synthesis-linear-classifier-based error term into the basic analysis dictionary learning model, whose classification performance is obviously improved by making full use of the label information. Then, we develop an alternating iterative algorithm to solve the new model and obtain closed-form solutions leading to pretty competitive running efficiency. What is more, we design three classification schemes by fully exploiting the synthesis linear classifier. Finally, extensive comparison experiments on scene categorization, object classification, action recognition and face recognition clearly verify the classification performance of the proposed algorithm.", 
        "author": "Jiujun Wang and Yanqing Guo and Jun Guo and Ming Li and Xiangwei Kong", 
        "keyword": "Analysis dictionary learning\", \"Synthesis linear classifier\", \"Pattern classification", 
        "title": "Synthesis linear classifier based analysis dictionary learning for pattern classification"
    }, 
    {
        "abstract": "Abstract Classification rules and rules describing interesting subgroups are important components of descriptive machine learning. Rule learning algorithms typically proceed in two phases: rule refinement selects conditions for specializing the rule, and rule selection selects the final rule among several rule candidates. While most conventional algorithms use the same heuristic for guiding both phases, recent research indicates that the use of two separate heuristics is conceptually better justified, improves the coverage of positive examples, and may result in better classification accuracy. The paper presents and evaluates two new beam search rule learning algorithms: DoubleBeam-SD for subgroup discovery and DoubleBeam-RL for classification rule learning. The algorithms use two separate beams and can combine various heuristics for rule refinement and rule selection, which widens the search space and allows for finding rules with improved quality. In the classification rule learning setting, the experimental results confirm previously shown benefits of using two separate heuristics for rule refinement and rule selection. In subgroup discovery, DoubleBeam-SD algorithm variants outperform several state-of-the-art related algorithms.", 
        "author": "Anita Valmarska and Nada Lavra\u010d and Johannes F\u00fcrnkranz and Marko Robnik-\u0160ikonja", 
        "keyword": "Rule learning\", \"Subgroup discovery\", \"Inverted heuristics", 
        "title": "Refinement and selection heuristics in subgroup discovery and classification rule learning"
    }, 
    {
        "abstract": "Abstract The possible onset of Cytokine Release Syndrome (CRS) is an important consideration in the development of monoclonal antibody (mAb) therapeutics. In this study, several machine learning approaches are used to analyze \\{CRS\\} data. The analyzed data come from a human blood in vitro assay which was used to assess the potential of mAb-based therapeutics to produce cytokine release similar to that induced by Anti-CD28 superagonistic (Anti-CD28 SA) mAbs. The data contain 7 mAbs and two negative controls, a total of 423 samples coming from 44 donors. Three (3) machine learning approaches were applied in combination to observations obtained from that assay, namely (i) Hierarchical Cluster Analysis (HCA); (ii) Principal Component Analysis (PCA) followed by K-means clustering; and (iii) Decision Tree Classification (DTC). All three approaches were able to identify the treatment that caused the most severe cytokine response. \\{HCA\\} was able to provide information about the expected number of clusters in the data. \\{PCA\\} coupled with K-means clustering allowed classification of treatments sample by sample, and visualizing clusters of treatments. \\{DTC\\} models showed the relative importance of various cytokines such as IFN-\u03b3, TNF-\u03b1 and IL-10 to CRS. The use of these approaches in tandem provides better selection of parameters for one method based on outcomes from another, and an overall improved analysis of the data through complementary approaches. Moreover, the \\{DTC\\} analysis showed in addition that IL-17 may be correlated with \\{CRS\\} reactions, although this correlation has not yet been corroborated in the literature.", 
        "author": "Feiyu Xiong and Marco Janko and Mindi Walker and Dorie Makropoulos and Daniel Weinstock and Moshe Kam and Leonid Hrebien", 
        "keyword": "Cytokine Release Syndrome\", \"Machine learning\", \"Monoclonal antibodies", 
        "title": "Analysis of cytokine release assay data using machine learning approaches"
    }, 
    {
        "abstract": "Abstract This research, which is motivated by real cases in labor-intensive industries where learning effects and the vital-few law take place, integrates learning and job splitting in parallel machine scheduling problems to minimize the makespan. We propose the lower bound of the problem and a job-splitting algorithm corresponding to the lower bound. Subsequently, a heuristic called \\{SLMR\\} is proposed based on the job-splitting algorithm with a proven worst case ratio. Furthermore, a branch-and-bound algorithm, which can obtain optimal solutions for very small problems, and a hybrid differential evolution algorithm are proposed, which can not only solve the problem, but also serve as a benchmark to evaluate the solution quality of the heuristic SLMR. The performance of the heuristic on a large number of randomly generated instances is evaluated. Results show that the proposed heuristic has good solution quality and calculation efficiency.", 
        "author": "Changchun Liu and Chenjie Wang and Zhi-hai Zhang and Li Zheng", 
        "keyword": "Parallel machine scheduling\", \"Makespan\", \"Job splitting\", \"Learning effect\", \"Vital-few law\", \"Worst-case analysis", 
        "title": "Scheduling with job-splitting considering learning and the vital-few law"
    }, 
    {
        "abstract": "Abstract Evaluation of operator Mental Workload (MW) levels via ongoing electroencephalogram (EEG) is quite promising in Human-Machine (HM) collaborative task environment to alarm the temporal operator performance degradation. However, accurate recognition of \\{MW\\} states via a static pattern classifier with training and testing \\{EEG\\} signals recoded on separate days is particularly challenging as \\{EEG\\} features are differently distributed across different sessions. Motivated by the superiority of the deep learning approaches for stable feature abstractions in higher levels, an adaptive Stacked Denoising AutoEncoder (SDAE) is developed to tackling such cross-session \\{MW\\} classification task in which the weights of the shallow hidden neurons could be adaptively updated during the testing procedure. The generalization capability of the adaptive \\{SDAE\\} is first evaluated under within/cross-session conditions. Then, we compare it with the state of the art \\{MW\\} classifiers under different feature selection and the noise corruption paradigms. The results indicate a higher performance of the adaptive \\{SDAE\\} in dealing with the cross-session \\{EEG\\} features. By analyzing the optimal step length, the data augmentation scheme and the computational cost for iterative tuning, the adaptive \\{SDAE\\} is also demonstrated to be acceptable for online implementation.", 
        "author": "Zhong Yin and Jianhua Zhang", 
        "keyword": "Human-machine system\", \"Mental workload\", \"Electroencephalogram (EEG)\", \"Deep learning\", \"Operator functional states", 
        "title": "Cross-session classification of mental workload levels using \\{EEG\\} and an adaptive deep learning model"
    }, 
    {
        "abstract": "Abstract The current study put forward a multi-feature kernel discriminant dictionary learning algorithm for face recognition. It was based on the supervised within-class-similar discriminative dictionary learning algorithm (SCDDL) we introduced previously. The proposed new algorithm was thus named as multi-feature kernel \\{SCDDL\\} (MKSCDDL). In contrast to the weighted combination or the constraint of representation coefficients for the feature combination used by some popular methods, \\{MKSCDDL\\} introduced the multiple kernel learning technique into the dictionary learning scheme. The experimental results on three large well-known face databases suggested that combination multiple features in \\{MKSCDDL\\} improved the recognition rate compared with SCDDL. In addition, adopting multiple kernel learning technique resulted in an excellent multi-feature dictionary learning approach when compared with some state-of-the-art multi-feature algorithms such as multiple kernel learning and multi-task joint sparse representation methods, indicating the effectiveness of the multiple kernel learning technique in the combination of multiple features for classification.", 
        "author": "Xia Wu and Qing Li and Lele Xu and Kewei Chen and Li Yao", 
        "keyword": "Multi-feature kernel discriminative dictionary learning\", \"Face recognition\", \"Multiple kernel learning", 
        "title": "Multi-feature kernel discriminant dictionary learning for face recognition"
    }, 
    {
        "abstract": "Abstract We offer a systematic analysis of the use of deep learning networks for stock market analysis and prediction. Its ability to extract features from a large set of raw data without relying on prior knowledge of predictors makes deep learning potentially attractive for stock market prediction at high frequencies. Deep learning algorithms vary considerably in the choice of network structure, activation function, and other model parameters, and their performance is known to depend heavily on the method of data representation. Our study attempts to provides a comprehensive and objective assessment of both the advantages and drawbacks of deep learning algorithms for stock market analysis and prediction. Using high-frequency intraday stock returns as input data, we examine the effects of three unsupervised feature extraction methods\u2014principal component analysis, autoencoder, and the restricted Boltzmann machine\u2014on the network\u2019s overall ability to predict future market behavior. Empirical results suggest that deep neural networks can extract additional information from the residuals of the autoregressive model and improve prediction performance; the same cannot be said when the autoregressive model is applied to the residuals of the network. Covariance estimation is also noticeably improved when the predictive network is applied to covariance-based market structure analysis. Our study offers practical insights and potentially useful directions for further investigation into how deep learning networks can be effectively used for stock market analysis and prediction.", 
        "author": "Eunsuk Chong and Chulwoo Han and Frank C. Park", 
        "keyword": "Stock market prediction\", \"Deep learning\", \"Multilayer neural network\", \"Covariance estimation", 
        "title": "Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies"
    }, 
    {
        "abstract": "Abstract Reinforcement learning (RL) is a general class of algorithms for solving decision-making problems, which are usually modeled using the Markov decision process (MDP) framework. \\{RL\\} can find exact solutions only when the \\{MDP\\} state space is discrete and small enough. Due to the fact that many real-world problems are described by continuous variables, approximation is essential in practical applications of RL. This paper is focused on learning the value function of a fixed policy in continuous MPDs. This is an important subproblem of several \\{RL\\} algorithms. We propose a least-squares temporal difference (LSTD) algorithm based on the extreme learning machine. \\{LSTD\\} is typically combined with local function approximators, which scale poorly with the problem dimensionality. Our approach allows us to approximate value functions using single-hidden layer feedforward networks (SLFNs), a type of artificial neural network extensively used in many fields. Due to the global nature of SLFNs, the proposed approach is more suitable than traditional methods for high-dimensional problems. The method was empirically evaluated on a set of \\{MDPs\\} whose dimensionality varies from 1 to 6. For comparison purposes, experiments were replicated using a standard \\{LSTD\\} algorithm combined with Gaussian radial basis functions. Experimental results suggest that, although both methods can approximate accurately value functions, the proposed approach requires considerably fewer resources for the same degree of accuracy.", 
        "author": "Pablo Escandell-Montero and Jos\u00e9 M. Mart\u00ednez-Mart\u00ednez and Jos\u00e9 D. Mart\u00edn-Guerrero and Emilio Soria-Olivas and Juan G\u00f3mez-Sanchis", 
        "keyword": "Least-squares temporal difference learning\", \"Extreme learning machine\", \"Reinforcement learning", 
        "title": "Least-squares temporal difference learning based on an extreme learning machine"
    }, 
    {
        "abstract": "Abstract Attribute information from social network users can be used as a basis for grouping users, sharing content, and recommending friends. However, in practice, not all users provide their attributes. In this paper, we try to use information from both the graph structure of the social network and the known attributes of users to predict the unknown attributes of users. Considering the topological structure of a social network and the characteristics of users\u2019 data, we select a graph-based semi-supervised learning algorithm to predict users\u2019 attributes. We design different strategies for computing the relational weights between users. The experimental results on real-world data from Renren demonstrate that the semi-supervised learning method is more suitable for predicting users\u2019 attributes compared with the supervised learning models, and our strategies for computing the relational weights between users are effective. We also analyze the effect of different social relations on predicting users\u2019 attributes.", 
        "author": "Yuxin Ding and Shengli Yan and YiBin Zhang and Wei Dai and Li Dong", 
        "keyword": "Social network analysis\", \"Data mining\", \"Social network privacy\", \"Semi-supervised learning\", \"Information inference", 
        "title": "Predicting the attributes of social network users using a graph-based machine learning method"
    }, 
    {
        "abstract": "Abstract Reinforcement Learning (RL) agents are typically deployed to learn a specific, concrete task based on a pre-defined reward function. However, in some cases an agent may be able to gain experience in the domain prior to being given a task. In such cases, intrinsic motivation can be used to enable the agent to learn a useful model of the environment that is likely to help it learn its eventual tasks more efficiently. This paradigm fits robots particularly well, as they need to learn about their own dynamics and affordances which can be applied to many different tasks. This article presents the texplore with Variance-And-Novelty-Intrinsic-Rewards algorithm (texplore-vanir), an intrinsically motivated model-based \\{RL\\} algorithm. The algorithm learns models of the transition dynamics of a domain using random forests. It calculates two different intrinsic motivations from this model: one to explore where the model is uncertain, and one to acquire novel experiences that the model has not yet been trained on. This article presents experiments demonstrating that the combination of these two intrinsic rewards enables the algorithm to learn an accurate model of a domain with no external rewards and that the learned model can be used afterward to perform tasks in the domain. While learning the model, the agent explores the domain in a developing and curious way, progressively learning more complex skills. In addition, the experiments show that combining the agent's intrinsic rewards with external task rewards enables the agent to learn faster than using external rewards alone. We also present results demonstrating the applicability of this approach to learning on robots.", 
        "author": "Todd Hester and Peter Stone", 
        "keyword": "Reinforcement learning\", \"Exploration\", \"Intrinsic motivation\", \"Developmental learning\", \"Robots", 
        "title": "Intrinsically motivated model learning for developing curious robots"
    }, 
    {
        "abstract": "Abstract A boosting-based method of learning a feed-forward artificial neural network (ANN) with a single layer of hidden neurons and a single output neuron is presented. Initially, an algorithm called Boostron is described that learns a single-layer perceptron using AdaBoost and decision stumps. It is then extended to learn weights of a neural network with a single hidden layer of linear neurons. Finally, a novel method is introduced to incorporate non-linear activation functions in artificial neural network learning. The proposed method uses series representation to approximate non-linearity of activation functions, learns the coefficients of nonlinear terms by AdaBoost. It adapts the network parameters by a layer-wise iterative traversal of neurons and an appropriate reduction of the problem. A detailed performances comparison of various neural network models learned the proposed methods and those learned using the least mean squared learning (LMS) and the resilient back-propagation (RPROP) is provided in this paper. Several favorable results are reported for 17 synthetic and real-world datasets with different degrees of difficulties for both binary and multi-class problems.", 
        "author": "Mirza M. Baig and Mian.M. Awais and El-Sayed M. El-Alfy", 
        "keyword": "Artificial neural network\", \"Boostron\", \"Perceptron\", \"Ensemble learning\", \"AdaBoost", 
        "title": "AdaBoost-based artificial neural network learning"
    }, 
    {
        "abstract": "Abstract Reinforcement learning is a plausible theoretical basis for developing self-learning, autonomous agents or robots that can effectively represent the world dynamics and efficiently learn the problem features to perform different tasks in different environments. The computational costs and complexities involved, however, are often prohibitive for real-world applications. This study introduces a scalable methodology to learn and transfer knowledge of the transition (and reward) models for model-based reinforcement learning in a complex world. We propose a variant formulation of Markov decision processes that supports efficient online-learning of the relevant problem features to approximate the world dynamics. We apply the new feature selection and dynamics approximation techniques in heterogeneous transfer learning, where the agent automatically maintains and adapts multiple representations of the world to cope with the different environments it encounters during its lifetime. We prove regret bounds for our approach, and empirically demonstrate its capability to quickly converge to a near optimal policy in both real and simulated environments.", 
        "author": "Trung Thanh Nguyen and Tomi Silander and Zhuoru Li and Tze-Yun Leong", 
        "keyword": "Model-based reinforcement learning\", \"Transfer learning\", \"Online feature selection", 
        "title": "Scalable transfer learning in heterogeneous, dynamic environments"
    }, 
    {
        "abstract": "Abstract The i-vector representation and modeling technique has been successfully applied in spoken language identification (SLI). The advantage of using the i-vector representation is that any speech utterance with a variable duration length can be represented as a fixed length vector. In modeling, a discriminative transform or classifier must be applied to emphasize the variations correlated to language identity since the i-vector representation encodes several types of the acoustic variations (e.g., speaker variation, transmission channel variation, etc.). Owing to the strong nonlinear discriminative power, the neural network model has been directly used to learn the mapping function between the i-vector representation and the language identity labels. In most studies, only the point-wise feature-label information is fed to the model for parameter learning that may result in model overfitting, particularly when with limited training data. In this study, we propose to integrate pair-wise distance metric learning as the regularization of model parameter optimization. In the representation space of nonlinear transforms in the hidden layers, a distance metric learning is explicitly designed to minimize the pair-wise intra-class variation and maximize the inter-class variation. Using the pair-wise distance metric learning, the i-vectors are transformed to a new feature space, wherein they are much more discriminative for samples belonging to different languages while being much more similar for samples belonging to the same language. We tested the algorithm on an \\{SLI\\} task, and obtained promising results, which outperformed conventional regularization methods.", 
        "author": "Xugang Lu and Peng Shen and Yu Tsao and Hisashi Kawai", 
        "keyword": "Neural network model\", \"Cross entropy\", \"Pair-wise distance metric learning\", \"Spoken language identification,", 
        "title": "Regularization of neural network model with distance metric learning for i-vector based spoken language identification"
    }, 
    {
        "abstract": "Abstract The multi-instance dictionary plays a critical role in multi-instance data representation. Meanwhile, different multi-instance learning applications are evaluated by specific multivariate performance measures. For example, multi-instance ranking reports the precision and recall. It is not difficult to see that to obtain different optimal performance measures, different dictionaries are needed. This observation motives us to learn performance-optimal dictionaries for this problem. In this paper, we propose a novel joint framework for learning the multi-instance dictionary and the classifier to optimize a given multivariate performance measure, such as the \\{F1\\} score and precision at rank k. We propose to represent the bags as bag-level features via the bag-instance similarity, and learn a classifier in the bag-level feature space to optimize the given performance measure. We propose to minimize the upper bound of a multivariate loss corresponding to the performance measure, the complexity of the classifier, and the complexity of the dictionary, simultaneously, with regard to both the dictionary and the classifier parameters. In this way, the dictionary learning is regularized by the performance optimization, and a performance-optimal dictionary is obtained. We develop an iterative algorithm to solve this minimization problem efficiently using a cutting-plane algorithm and a coordinate descent method. Experiments on multi-instance benchmark data sets show its advantage over both traditional multi-instance learning and performance optimization methods.", 
        "author": "Jim Jing-Yan Wang and Ivor Wai-Hung Tsang and Xuefeng Cui and Zhiwu Lu and Xin Gao", 
        "keyword": "Multi-instance learning\", \"Dictionary\", \"Multivariate performance measures\", \"Cutting-plane algorithm", 
        "title": "Multi-instance dictionary learning via multivariate performance measure optimization"
    }, 
    {
        "abstract": "Abstract Expert and intelligent systems are being developed to control many technological systems including mobile robots. However, the \\{PID\\} (Proportional-Integral-Derivative) controller is a fast low-level control strategy widely used in many control engineering tasks. Classic control theory has contributed with different tuning methods to obtain the gains of \\{PID\\} controllers for specific operation conditions. Nevertheless, when the system is not fully known and the operative conditions are variable and not previously known, classical techniques are not entirely suitable for the \\{PID\\} tuning. To overcome these drawbacks many adaptive approaches have been arisen, mainly from the field of artificial intelligent. In this work, we propose an incremental Q-learning strategy for adaptive \\{PID\\} control. In order to improve the learning efficiency we define a temporal memory into the learning process. While the memory remains invariant, a non-uniform specialization process is carried out generating new limited subspaces of learning. An implementation on a real mobile robot demonstrates the applicability of the proposed approach for a real-time simultaneous tuning of multiples adaptive \\{PID\\} controllers for a real system operating under variable conditions in a real environment.", 
        "author": "Ignacio Carlucho and Mariano De Paula and Sebastian A. Villar and Gerardo G. Acosta", 
        "keyword": "Reinforcement learning\", \"Incremental Q-learning\", \"PID\", \"Mobile robots\", \"Non-linear control", 
        "title": "Incremental Q-learning strategy for adaptive \\{PID\\} control of mobile robots"
    }, 
    {
        "abstract": "Abstract Feature learning is a critical step in pattern recognition, such as image classification. However, most of the existing methods cannot extract features that are discriminative and at the same time invariant under some transforms. This limits the classification performance, especially in the case of small training sets. To address this issue, in this paper we propose a novel Partial Differential Equation\u00a0(PDE) based method for feature learning. The feature learned by our \\{PDE\\} is discriminative, also translationally and rotationally invariant, and robust to illumination variation. To our best knowledge, this is the first work that applies \\{PDE\\} to feature learning and image recognition tasks. Specifically, we model feature learning as an evolution process governed by a PDE, which is designed to be translationally and rotationally invariant and is learned via minimizing the training error, hence extracts discriminative information from data. After feature extraction, we apply a linear classifier for classification. We also propose an efficient algorithm that optimizes the whole framework. Our method is very effective when the training samples are few. The experimental results of face recognition on the four benchmark face datasets show that the proposed method outperforms the state-of-the-art feature learning methods in the case of low-resolution images and when the training samples are limited.", 
        "author": "Cong Fang and Zhenyu Zhao and Pan Zhou and Zhouchen Lin", 
        "keyword": "Feature learning\", \"Partial differential equation\", \"Fface recognition", 
        "title": "Feature learning via partial differential equation with applications to face recognition"
    }, 
    {
        "abstract": null, 
        "author": "Nan Liu and Marcus Aik Beng Lee and Andrew Fu Wah Ho and Benjamin Haaland and Stephanie Fook-Chong and Zhi Xiong Koh and Pin Pin Pek and Eric Chern-Pin Chua and Boon Ping Ting and Zhiping Lin and Marcus Eng Hock Ong", 
        "keyword": "Risk stratification\", \"Adverse coronary events\", \"Emergency department\", \"Machine learning\", \"Thrombolysis in myocardial infarction", 
        "title": "Risk stratification for prediction of adverse coronary events in emergency department chest pain patients with a machine learning score compared with the \\{TIMI\\} score"
    }, 
    {
        "abstract": "Abstract Tourette syndrome (TS) is a childhood-onset neurobehavioral disorder characterized by the presence of multiple motor and vocal tics. To date, \\{TS\\} diagnosis remains somewhat limited and studies using advanced diagnostic methods are of great importance. In this paper, we introduce an automatic classification framework for accurate identification of \\{TS\\} children based on multi-modal and multi-type features, which is robust and easy to implement. We present in detail the feature extraction, feature selection, and classifier training methods. In addition, in order to exploit complementary information revealed by different feature modalities, we integrate multi-modal image features using multiple kernel learning (MKL). The performance of our framework has been validated in classifying 44 \\{TS\\} children and 48 age- and gender-matched healthy children. When combining features using MKL, the classification accuracy reached 94.24% using nested cross-validation. Most discriminative brain regions were mostly located in the cortico-basal ganglia, frontal cortico-cortical circuits, which are thought to be highly related to \\{TS\\} pathology. These results show that our method is reliable for early \\{TS\\} diagnosis, and promising for prognosis and treatment outcome.", 
        "author": "Hongwei Wen and Yue Liu and Islem Rekik and Shengpei Wang and Zhiqiang Chen and Jishui Zhang and Yue Zhang and Yun Peng and Huiguang He", 
        "keyword": "Tourette syndrome\", \"DTI\", \"TBSS\", \"SVM\", \"MKL", 
        "title": "Multi-modal multiple kernel learning for accurate identification of Tourette syndrome children"
    }, 
    {
        "abstract": "Abstract Classification can be highly challenging when the dataset is extremely large, or when the training data in the underlying domain are difficult to obtain. One feasible solution to this challenge is transfer learning, which extracts the knowledge from source tasks and applies the knowledge to target tasks. Extant transfer learning schemes typically assume that similarities between the source task and the target task to some degree. This assumption does not hold in certain actual applications; analysts unfamiliar with the learning strategy can be frustrated by the complicated transfer relations and the non-intuitive transfer process. This paper presents a suite of visual communication and interaction techniques to support the transfer learning process. Furthermore, a pioneering visual-assisted transfer learning methodology is proposed in the context of classification. Our solution includes a visual communication interface that allows for comprehensive exploration of the entire knowledge transfer process and the relevance among tasks. With these techniques and the methodology, the analysts can intuitively choose relevant tasks and data, as well as iteratively incorporate their experience and expertise into the analysis process. We demonstrate the validity and efficiency of our visual design and the analysis approach with examples of text classification.", 
        "author": "Yuxin Ma and Jiayi Xu and Xiangyang Wu and Fei Wang and Wei Chen", 
        "keyword": "Visual analytics\", \"Visualization\", \"Transfer learning\", \"Classification", 
        "title": "A visual analytical approach for transfer learning in classification"
    }, 
    {
        "abstract": "Abstract Extracting the underlying low-dimensional space where high-dimensional signals often reside has been at the center of numerous algorithms in the signal processing and machine learning literature during the past few decades. Moreover, working with incomplete large scale datasets has recently been commonplace for diverse reasons. This so called big data era we are currently living calls for devising online subspace learning algorithms that can suitably handle incomplete data. Their anticipated goal is to recursively estimate the unknown subspace by processing streaming data sequentially, thus reducing computational complexity. In this paper, an online variational Bayes subspace learning algorithm from partial observations is presented. To account for the unawareness of the true rank of the subspace, commonly met in practice, low-rankness is explicitly imposed on the sought subspace data matrix by exploiting sparse Bayesian learning principles. Sparsity, simultaneously to low-rankness, is favored on the subspace matrix by the sophisticated hierarchical Bayesian scheme that is adopted. The proposed algorithm is thus adept in dealing with applications whereby the underlying subspace may be also sparse. The new subspace tracking scheme outperforms its state-of-the-art counterparts in terms of estimation accuracy, in a variety of experiments conducted on both simulated and real data.", 
        "author": "Paris V. Giampouras and Athanasios A. Rontogiannis and Konstantinos E. Themelis and Konstantinos D. Koutroumbas", 
        "keyword": "Subspace tracking\", \"Online matrix completion\", \"Online variational Bayes\", \"Incomplete data\", keywords =Sparse subspace learning\", \"Low-rank", 
        "title": "Online sparse and low-rank subspace learning from incomplete data: A Bayesian view"
    }, 
    {
        "abstract": "Abstract Given a face image, the problem of age estimation is to predict the actual age from the visual appearance of the face. In this work, we investigate this problem by means of the deep learning techniques. We comprehensively diagnose the training and evaluating procedures of the deep learning models for age estimation on two of the largest datasets. Our diagnosis includes three different kinds of formulations for the age estimation problem using five most representative loss functions, as well as three different architectures to incorporate multi-task learning with race and gender classification. We start our diagnoses process from a simple baseline architecture from previous work. With appropriate problem formulation and loss function, we obtain state-of-the-art performance with the simple baseline architecture. By further incorporating our newly proposed deep multi-task learning architecture, the age estimation performance is further improved with high-accuracy race and gender classification results obtained simultaneously. With all the insights gained from the diagnosing process, we finally build a deep multi-task age estimation model which obtains a \\{MAE\\} of 2.96 on the Morph \\{II\\} dataset and 5.75 on the WebFace dataset, both of which improve previous best results by a large margin.", 
        "author": "Junliang Xing and Kai Li and Weiming Hu and Chunfeng Yuan and Haibin Ling", 
        "keyword": "Age estimation\", \"Deep learning\", \"Multi-task learning", 
        "title": "Diagnosing deep learning models for high accuracy age estimation from a single image"
    }, 
    {
        "abstract": "AbstractObjective This paper describes NICeSim, an open-source simulator that uses machine learning (ML) techniques to aid health professionals to better understand the treatment and prognosis of premature newborns. Methods The application was developed and tested using data collected in a Brazilian hospital. The available data were used to feed an \\{ML\\} pipeline that was designed to create a simulator capable of predicting the outcome (death probability) for newborns admitted to neonatal intensive care units. However, unlike previous scoring systems, our computational tool is not intended to be used at the patients bedside, although it is possible. Our primary goal is to deliver a computational system to aid medical research in understanding the correlation of key variables with the studied outcome so that new standards can be established for future clinical decisions. In the implemented simulation environment, the values of key attributes can be changed using a user-friendly interface, where the impact of each change on the outcome is immediately reported, allowing a quantitative analysis, in addition to a qualitative investigation, and delivering a totally interactive computational tool that facilitates hypothesis construction and testing. Results Our statistical experiments showed that the resulting model for death prediction could achieve an accuracy of 86.7% and an area under the receiver operating characteristic curve of 0.84 for the positive class. Using this model, three physicians and a neonatal nutritionist performed simulations with key variables correlated with chance of death. The results indicated important tendencies for the effect of each variable and the combination of variables on prognosis. We could also observe values of gestational age and birth weight for which a low Apgar score and the occurrence of respiratory distress syndrome (RDS) could be less or more severe. For instance, we have noticed that for a newborn with 2000 g or more the occurrence of \\{RDS\\} is far less problematic than for neonates weighing less. Conclusions The significant accuracy demonstrated by our predictive model shows that \\{NICeSim\\} might be used for hypothesis testing to minimize in vivo experiments. We observed that the model delivers predictions that are in very good agreement with the literature, demonstrating that \\{NICeSim\\} might be an important tool for supporting decision making in medical practice. Other very important characteristics of \\{NICeSim\\} are its flexibility and dynamism. \\{NICeSim\\} is flexible because it allows the inclusion and deletion of variables according to the requirements of a particular study. It is also dynamic because it trains a just-in-time model. Therefore, the system is improved as data from new patients become available. Finally, \\{NICeSim\\} can be extended in a cooperative manner because it is an open-source system.", 
        "author": "Fabio Ribeiro Cerqueira and Tiago Geraldo Ferreira and Alcione de Paiva Oliveira and Douglas Adriano Augusto and Eduardo Krempser and Helio Jos\u00e9 Corr\u00eaa Barbosa and Sylvia do Carmo Castro Franceschini and Brunnella Alcantara Chagas de Freitas and Andreia Patricia Gomes and Rodrigo Siqueira-Batista", 
        "keyword": "Machine learning in medicine\", \"Artificial neural networks\", \"Support vector machine\", \"Clinical keywords =ecision making\", \"Prenatal care\", \"Perinatal care", 
        "title": "NICeSim: An open-source simulator based on machine learning techniques to support medical research on prenatal and perinatal care decision making"
    }, 
    {
        "abstract": "Abstract Subspace learning methods have played an important role on handling the high-dimensional gait template for human identification. Particularly, linear discriminant analysis (LDA) method has been widely applied to find one discriminant low-dimensional subspace for gait recognition. However, when gait templates changed by clothing, view angle, load carrying and road surface variants, only learning one single subspace is prone to dropping into local optimum. In this paper, a subspace ensemble learning using totally-corrective boosting (SEL_TCB) framework and its tensor-based and local patch-based extensions are proposed for gait recognition. In this framework, multiple discriminant subspaces are iteratively learned using totally-corrective boosting technology to preserve the proximity relationships described by instance triplets. Meanwhile, by constructing different triplet set, the presented framework can deal with complex application environments. Further, we extend SEL_TCB framework to tensor SEL_TCB (TSEL_TCB) framework which effectively preserves the structural information of the gait template. Meanwhile, compared with the holistic appearance-based SEL_TCB framework, a local patch-based SEL_TCB (LPSEL_TCB) framework is proposed, which iteratively learns multiple discriminant subspaces corresponding to several local patches selected from the gait template. The proposed method is compared with the recently published gait recognition approaches on \\{USF\\} HumanID database and \\{CASIA\\} Gait database. Experimental results indicate that the proposed method achieves highly competitive performance against state-of-the-art gait recognition approaches.", 
        "author": "Guangkai Ma and Ligang Wu and Yan Wang", 
        "keyword": "Subspace learning\", \"Boosting\", \"Ensemble learning\", \"Pattern recognition\", \"Gait recognition", 
        "title": "A general subspace ensemble learning framework via totally-corrective boosting and tensor-based and local patch-based extensions for gait recognition"
    }, 
    {
        "abstract": "Abstract As an issue that attracts increasing interests in both academia and industry, multiple-shot person re-identification has shown promising results but suffers from real-scenario complexities and feature-crafting heuristics. To tackle the problems of set-level data variation and sparseness during re-identification, this paper proposes a novel metric learning method, named \u201cFair Set-Collaboration Metric Learning\u201d, motivated by utilizing the opportunities whilst overcoming the challenges from the set of multiple instances. This method optimizes a new set-collaboration dissimilarity measure, which introduces the fairness principle into the collaborative representation based set to sets distance, in the set based metric learning framework. Experiments on widely-used benchmark datasets have demonstrated the advantages of this method in terms of effectiveness and robustness.", 
        "author": "Wei Li and Jianqing Li and Lifeng Zhu", 
        "keyword": "Multiple-shot person re-identification\", \"Metric learning\", \"Set-collaboration dissimilarity\", \"Fairness principle", 
        "title": "Multiple-shot person re-identification via fair set-collaboration metric learning"
    }, 
    {
        "abstract": "Abstract The expectation maximization (EM) algorithm is one of the most enduring ways to estimate the parameters of Gaussian mixture models. However, the \\{EM\\} algorithm needs to know in advance the true number of mixing components, and its performance highly depends on the initial parameters, which leads to use it difficultly in practice. To overcome the above two drawbacks, a variable step learning algorithm is proposed for learning a Gaussian mixture models. The novelty of the algorithm is that a variable step search strategy is proposed to find the actual number of Gaussian mixture components, or slightly above it. This number is obtained by maximizing the Bhattacharyya coefficient criterion, which in turn quantifies how close the Gaussian mixtures models fit the observed data. Furthermore, the initialization parameters are determined by the correlation coefficient criterion representing the shape characteristics between the new \\{GMM\\} and the histograms of the data. Based on these two criteria, the proposed algorithm can make both parameter learning and model selection more efficient, as shown by the conducted experiments.", 
        "author": "Weishi Peng and Yangwang Fang and Renjun Zhan", 
        "keyword": "Gaussian mixture models\", \"EM algorithm\", \"Variable step learning algorithm\", \"Bhattacharyya keywords =oefficient criterion\", \"Correlation coefficient criterion", 
        "title": "A variable step learning algorithm for Gaussian mixture models based on the Bhattacharyya coefficient and correlation coefficient criterion"
    }, 
    {
        "abstract": "Abstract Predicting full load electrical power output of a base load power plant is important in order to maximize the profit from the available megawatt hours. This paper examines and compares some machine learning regression methods to develop a predictive model, which can predict hourly full load electrical power output of a combined cycle power plant. The base load operation of a power plant is influenced by four main parameters, which are used as input variables in the dataset, such as ambient temperature, atmospheric pressure, relative humidity, and exhaust steam pressure. These parameters affect electrical power output, which is considered as the target variable. The dataset, which consists of these input and target variables, was collected over a six-year period. First, based on these variables the best subset of the dataset is explored among all feature subsets in the experiments. Then, the most successful machine learning regression method is sought for predicting full load electrical power output. Thus, the best performance of the best subset, which contains a complete set of input variables, has been observed using the most successful method, which is Bagging algorithm with REPTree, with a mean absolute error of 2.818 and a Root Mean-Squared Error of 3.787.", 
        "author": "P\u0131nar T\u00fcfekci", 
        "keyword": "Prediction of electrical power output\", \"Combined cycle power plants\", \"Machine learning methods", 
        "title": "Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods"
    }, 
    {
        "abstract": "Abstract The relationship between performance and experience is non-linear, thus planning models that seek to manage workforce development through task assignment are difficult to solve. This gets even more complicated when taking into account multi-skilled workers that are capable of performing a variety of tasks. In this paper we develop a competences-based analytical model of the performance of multi-skilled workers undertaking repetitive tasks, taking into account learning and forgetting. A learning curve can be used to estimate improvement when repeating the same operation. Inverse phenomenon is forgetting, which can occur due to interruption in the production process. The Performance Evaluation Algorithm (PEA) was developed for two cases: fixed shift duration and fixed production output. The aim was to build a tool that better describes the capabilities of workers to perform repetitive tasks by binding together hierarchical competences modeled as a weighted digraph together with a learning and forgetting curve model (LFCM) to express individual learning rates.", 
        "author": "Przemyslaw Korytkowski", 
        "keyword": "Multi-skilled worker\", \"Competence\", \"Learning curve\", \"Forgetting\", \"Worker performance", 
        "title": "Competences-based performance model of multi-skilled workers with learning and forgetting"
    }, 
    {
        "abstract": "Abstract This paper proposes a niching evolutionary algorithm with adaptive negative correlation learning, denoted as NEA_ANCL, for training the neural network ensemble. In the proposed NEA_ANCL, an adaptive negative correlation learning, in which the penalty coefficient \u03bb is set to dynamically change during training, has been developed. The adaptation strategy is based on a novel population diversity measure with the purpose of appropriately controlling the trade-off between the diversity and accuracy in the ensemble. Further, a modified dynamical fitness sharing method is applied to preserve the diversity of population during training. The proposed NEA_ANCL has been evaluated on a number of benchmark problems and compared with related ensemble learning algorithms. The results show that our method can be used to design a satisfactory \\{NN\\} ensemble and outperform related works.", 
        "author": "Weiguo Sheng and Pengxiao Shan and Shengyong Chen and Yurong Liu and Fuad E. Alsaadi", 
        "keyword": "Neural network ensemble\", \"Evolutionary algorithm\", \"Negative correlation learning\", \"Adaptation keywords =trategy\", \"Diversity measure", 
        "title": "A niching evolutionary algorithm with adaptive negative correlation learning for neural network ensemble"
    }, 
    {
        "abstract": "Abstract Markov logic networks (MLNs) have emerged as a powerful representation that incorporates first-order logic and probabilistic graphical models. They have shown very good results in many problem domains. However, current implementations of \\{MLNs\\} do not scale well due to the large search space and the intractable clause groundings, which is preventing their widespread adoption. In this paper, we propose a general framework named Ground Network Sampling (GNS) for scaling up \\{MLN\\} learning and inference. \\{GNS\\} offers a new instantiation perspective by encoding ground substitutions as simple paths in the Herbrand universe, which uses the interactions existing among the objects to constrain the search space. To further make this search tractable for large scale problems, \\{GNS\\} integrates random walks and subgraph pattern mining, gradually building up a representative subset of simple paths. When inference is concerned, a template network is introduced to quickly locate promising paths that can ground given logical statements. The resulting sampled paths are then transformed into ground clauses, which can be used for clause creation and probabilistic inference. The experiments on several real-world datasets demonstrate that our approach offers better scalability while maintaining comparable or better predictive performance compared to state-of-the-art \\{MLN\\} techniques.", 
        "author": "Zhengya Sun and Yangyang Zhao and Zhuoyu Wei and Wensheng Zhang and Jue Wang", 
        "keyword": "Markov logic networks\", \"Structure learning\", \"Probabilistic inference\", \"Large scale machine learning", 
        "title": "Scalable learning and inference in Markov logic networks"
    }, 
    {
        "abstract": "Abstract Automatic breast tumor segmentation is a crucial step for breast ultrasound images analysis. Prior knowledge can be used to improve segmentation performance. However, commonly used prior information such as intensity, texture and shape may be useless due to complicated characteristics of breast tumor in ultrasound images. In this paper, we propose a novel prior knowledge of the abnormal tumor regions, which may be complementary to base segmentation model. Based on this idea, we develop a breast tumor segmentation approach with prior knowledge learning. The proposed method mainly consists of two steps: prior knowledge learning and segmentation model construction. In the first step, prior knowledge learning model is developed to learn prior information which can be used to classify abnormal tumor regions correctly. It's difficult for base segmentation model to obtain accurate segmentation result of abnormal tumor areas. Therefore, learned prior knowledge is complementary to base segmentation model. In order to exploit learned prior knowledge, prior knowledge-based constraints are incorporated into the base segmentation model for robust segmentation model construction. In order to verify performance of the proposed method, we construct a breast ultrasound images database contained 186 cases (135 benign cases and 51 malignant cases) by collecting the breast images from four types of ultrasonic devices. Our experimental results on the constructed database demonstrate the effectiveness and robustness of the proposed method.", 
        "author": "Xiaoming Xi and Hao Shi and Lingyan Han and Tingwen Wang and Hong Yu Ding and Guang Zhang and Yuchun Tang and Yilong Yin", 
        "keyword": "Breast tumor segmentation\", \"Breast ultrasound image\", \"Prior knowledge learning", 
        "title": "Breast tumor segmentation with prior knowledge learning"
    }, 
    {
        "abstract": "Abstract Teaching-learning-based optimization (TLBO) algorithm is a novel nature-inspired algorithm that mimics the teaching and learning process. In this paper, an improved version of \\{TLBO\\} algorithm (I-TLBO) is investigated to enhance the performance of original \\{TLBO\\} by achieving a balance between exploitation and exploration ability. Inspired by the concept of historical population, two new phases, namely self-feedback learning phase as well as mutation and crossover phase, are introduced in I-TLBO algorithm. In self-feedback learning phase, a learner can improve his result based on the historical experience if his present state is better than the historical state. In mutation and crossover phase, the learners update their positions with probability based on the new population obtained by the crossover and mutation operations between present population and historical population. The design of self-feedback learning phase seeks the maintaining of good exploitation ability while the introduction of the mutation and crossover phase aims at the improvement of exploration ability in original TLBO. The effectiveness of proposed I-TLBO algorithm is tested on some benchmark functions and a combinatorial optimization problem of heat treating in foundry industry. The comparative results with some other improved \\{TLBO\\} algorithms and classic algorithms show that I-TLBO algorithm has significant advantages due to the balance between exploitation and exploration ability.", 
        "author": "Xiaoyuan Ji and Hu Ye and Jianxin Zhou and Yajun Yin and Xu Shen", 
        "keyword": "Teaching-learning-based optimization\", \"Historical population\", \"Self-feedback learning\", \"Mutation keywords =nd crossover\", \"Combinatorial optimization", 
        "title": "An improved teaching-learning-based optimization algorithm and its application to a combinatorial optimization problem in foundry industry"
    }, 
    {
        "abstract": "Abstract Machine learning (ML)-based segmentation methods are a common technique in the medical image processing field. In spite of numerous research groups that have investigated ML-based segmentation frameworks, there remains unanswered aspects of performance variability for the choice of two key components: \\{ML\\} algorithm and intensity normalization. This investigation reveals that the choice of those elements plays a major part in determining segmentation accuracy and generalizability. The approach we have used in this study aims to evaluate relative benefits of the two elements within a subcortical \\{MRI\\} segmentation framework. Experiments were conducted to contrast eight machine-learning algorithm configurations and 11 normalization strategies for our brain \\{MR\\} segmentation framework. For the intensity normalization, a Stable Atlas-based Mapped Prior (STAMP) was utilized to take better account of contrast along boundaries of structures. Comparing eight machine learning algorithms on down-sampled segmentation \\{MR\\} data, it was obvious that a significant improvement was obtained using ensemble-based \\{ML\\} algorithms (i.e., random forest) or \\{ANN\\} algorithms. Further investigation between these two algorithms also revealed that the random forest results provided exceptionally good agreement with manual delineations by experts. Additional experiments showed that the effect of STAMP-based intensity normalization also improved the robustness of segmentation for multicenter data sets. The constructed framework obtained good multicenter reliability and was successfully applied on a large multicenter \\{MR\\} data set (n &gt; 3000). Less than 10% of automated segmentations were recommended for minimal expert intervention. These results demonstrate the feasibility of using the ML-based segmentation tools for processing large amount of multicenter \\{MR\\} images. We demonstrated dramatically different result profiles in segmentation accuracy according to the choice of \\{ML\\} algorithm and intensity normalization chosen.", 
        "author": "Eun Young Kim and Vincent A. Magnotta and Dawei Liu and Hans J. Johnson", 
        "keyword": "Segmentation\", \"Machine learning\", \"Random forest\", \"Multicenter study", 
        "title": "Stable Atlas-based Mapped Prior (STAMP) machine-learning segmentation for multicenter large-scale \\{MRI\\} data"
    }, 
    {
        "abstract": "Abstract Recent resting-state functional \\{MRI\\} investigations have demonstrated that much of the large-scale functional network architecture supporting motor, sensory and cognitive functions in older pediatric and adult populations is present in term- and prematurely-born infants. Application of new analytical approaches can help translate the improved understanding of early functional connectivity provided through these studies into predictive models of neurodevelopmental outcome. One approach to achieving this goal is multivariate pattern analysis, a machine-learning, pattern classification approach well-suited for high-dimensional neuroimaging data. It has previously been adapted to predict brain maturity in children and adolescents using structural and resting state-functional \\{MRI\\} data. In this study, we evaluated resting state-functional \\{MRI\\} data from 50 preterm-born infants (born at 23\u201329 weeks of gestation and without moderate\u2013severe brain injury) scanned at term equivalent postmenstrual age compared with data from 50 term-born control infants studied within the first week of life. Using 214 regions of interest, binary support vector machines distinguished term from preterm infants with 84% accuracy (p &lt; 0.0001). Inter- and intra-hemispheric connections throughout the brain were important for group categorization, indicating that widespread changes in the brain's functional network architecture associated with preterm birth are detectable by term equivalent age. Support vector regression enabled quantitative estimation of birth gestational age in single subjects using only term equivalent resting state-functional \\{MRI\\} data, indicating that the present approach is sensitive to the degree of disruption of brain development associated with preterm birth (using gestational age as a surrogate for the extent of disruption). This suggests that support vector regression may provide a means for predicting neurodevelopmental outcome in individual infants.", 
        "author": "Christopher D. Smyser and Nico U.F. Dosenbach and Tara A. Smyser and Abraham Z. Snyder and Cynthia E. Rogers and Terrie E. Inder and Bradley L. Schlaggar and Jeffrey J. Neil", 
        "keyword": "Developmental neuroimaging\", \"Functional MRI\", \"Infant\", \"Prematurity\", \"Multivariate pattern analysis", 
        "title": "Prediction of brain maturity in infants using machine-learning algorithms"
    }, 
    {
        "abstract": "Abstract We develop a deep learning model to predict traffic flows. The main contribution is development of an architecture that combines a linear model that is fitted using \u2113 1 regularization and a sequence of tanh layers. The challenge of predicting traffic flows are the sharp nonlinearities due to transitions between free flow, breakdown, recovery and congestion. We show that deep learning architectures can capture these nonlinear spatio-temporal effects. The first layer identifies spatio-temporal relations among predictors and other layers model nonlinear relations. We illustrate our methodology on road sensor data from Interstate I-55 and predict traffic flows during two special events; a Chicago Bears football game and an extreme snowstorm event. Both cases have sharp traffic flow regime changes, occurring very suddenly, and we show how deep learning provides precise short term traffic flow predictions.", 
        "author": "Nicholas G. Polson and Vadim O. Sokolov", 
        "keyword": "Traffic Flows\", \"Deep Learning\", \"Trend filtering\", \"Sparse linear models", 
        "title": "Deep learning for short-term traffic flow prediction"
    }, 
    {
        "abstract": "Abstract Patients who suffer from chronic renal failure (CRF) tend to suffer from an associated anemia as well. Therefore, it is essential to know the hemoglobin (Hb) levels in these patients. The aim of this paper is to predict the hemoglobin (Hb) value using a database of European hemodialysis patients provided by Fresenius Medical Care (FMC) for improving the treatment of this kind of patients. For the prediction of Hb, both analytical measurements and medication dosage of patients suffering from chronic renal failure (CRF) are used. Two kinds of models were trained, global and local models. In the case of local models, clustering techniques based on hierarchical approaches and the adaptive resonance theory (ART) were used as a first step, and then, a different predictor was used for each obtained cluster. Different global models have been applied to the dataset such as Linear Models, Artificial Neural Networks (ANNs), Support Vector Machines (SVM) and Regression Trees among others. Also a relevance analysis has been carried out for each predictor model, thus finding those features that are most relevant for the given prediction.", 
        "author": "Jos\u00e9 M. Mart\u00ednez-Mart\u00ednez and Pablo Escandell-Montero and Carlo Barbieri and Emilio Soria-Olivas and Flavio Mari and Marcelino Mart\u00ednez-Sober and Claudia Amato and Antonio J. Serrano L\u00f3pez and Marcello Bassi and Rafael Magdalena-Benedito and Andrea Stopper and Jos\u00e9 D. Mart\u00edn-Guerrero and Emanuele Gatti", 
        "keyword": "Prediction\", \"Hemoglobin\", \"Chronic renal failure\", \"Hemodialysis\", \"Machine learning", 
        "title": "Prediction of the hemoglobin level in hemodialysis patients using machine learning techniques"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a group-aware deep feature learning (GA-DFL) approach for facial age estimation. Unlike most existing methods which utilize hand-crafted descriptors for face representation, our GA-DFL method learns a discriminative feature descriptor per image directly from raw pixels for face representation under the deep convolutional neural networks framework. Motivated by the fact that age labels are chronologically correlated and the facial aging datasets are usually lack of labeled data for each person in a long range of ages, we split ordinal ages into a set of discrete groups and learn deep feature transformations across age groups to project each face pair into the new feature space, where the intra-group variances of positive face pairs from the training set are minimized and the inter-group variances of negative face pairs are maximized, simultaneously. Moreover, we employ an overlapped coupled learning method to exploit the smoothness for adjacent age groups. To further enhance the discriminative capacity of face representation, we design a multi-path \\{CNN\\} approach to integrate the complementary information from multi-scale perspectives. Experimental results show that our approach achieves very competitive performance compared with most state-of-the-arts on three public face aging datasets that were captured under both controlled and uncontrolled environments.", 
        "author": "Hao Liu and Jiwen Lu and Jianjiang Feng and Jie Zhou", 
        "keyword": "Facial age estimation\", \"Deep learning\", \"Feature learning\", \"Biometrics", 
        "title": "Group-aware deep feature learning for facial age estimation"
    }, 
    {
        "abstract": "Abstract Modern engines are controlled by electronic control units, which operate all the engine actuators based on the signals from various sensors in the engine. Traditionally, the control parameters of the actuators are obtained through huge amount of trial-and-error experiments. However, using traditional approach to calibrate these parameters becomes more challenging with the increasing incorporation of new technologies into advanced engines. In order to reduce the number of experiments required in the calibration process of modern engines, a novel point-by-point engine calibration approach based on machine learning methods is proposed in this study. It is an iterative procedure that, for a given operating point, sequential design of experiment (DoE) strategy is utilized to measure the responses of different engine sensors corresponding to different actuator signals, and a machine learning algorithm called initial-training-free online extreme learning machine is utilized to incrementally learn the relationship between the sensors and actuators based on the measurement acquired. In each iterative cycle, meta-heuristic optimization is performed on the machine-learning-based model to search for the best parameters, which are then used as the initial parameters for generating DoE plan of the next cycle. The iteration is repeated until the optimal parameters of that operating point are found. To verify the effectiveness of the proposed approach, experiments on both simulation engine in commercial software and real engine in test bench have been conducted. The results show that the engine calibration can be carried out with significant fewer experiments and time by using the proposed approach.", 
        "author": "Pak Kin Wong and Xiang Hui Gao and Ka In Wong and Chi Man Vong", 
        "keyword": null, 
        "title": "Efficient point-by-point engine calibration using machine learning and sequential design of experiment strategies"
    }, 
    {
        "abstract": "Abstract Multi-class classification learning can be implemented by the decomposition to binary classification or the direct techniques. The decomposition technique simplifies s the original learning problem into a set of binary subproblems, separately learns each one, and then combines their results to make a final decision. While the direct technique learns a set of multi-class classifiers by directly optimizing one single objective function. Plenty of empirical results have shown that the two techniques achieve comparable performance. However, both the techniques are mainly designed for vector-pattern samples at present. These traditional vector-pattern-oriented decomposition technique has been extended to a new type of matrix-pattern-oriented classifiers which obtain better learning performance and reduce the learning time\u2013cost by utilizing the original structural information of the input matrix. To our best knowledge, no direct multi-class learning method for matrix pattern has been proposed so far. Therefore, this paper aims to propose a direct multi-class classification technique to compensate such a missing, which is a natural extension of the vector-based direct multi-class classification technique. Simultaneously, the left or right vector acting on matrix pattern in the multi-class matrixized objective function plays a role of a tradeoff parameter to balance the capacity of learning and generalization. Finally, based on the original binary-classifier Matrix-pattern-oriented Modified Ho-Kashyap classifier named MatMHKS, we design a corresponding Direct Multi-class Matrixized Learning Machine named McMatMHKS. It is the first direct multi-class classification technique for matrix patterns. To validate both feasibility and effectiveness of McMatMHKS, we conduct the comparative experiments on some benchmark datasets with two multi-class support vector machines and MatMHKS with the decomposition technique including both one-vs-one and one-vs-all. The results show that like its vector-oriented counterpart, McMatMHKS not only has comparable classification accuracy and \\{AUC\\} value, but also owns lower time complexity when compared with its corresponding decomposition machines.", 
        "author": "Zhe Wang and Yun Meng and Yujin Zhu and Qi Fan and Songcan Chen and Daqi Gao", 
        "keyword": "Multi-class classification\", \"Matrixized learning\", \"Direct approach\", \"Decomposition approach\", \"Pattern recognition", 
        "title": "McMatMHKS: A direct multi-class matrixized learning machine"
    }, 
    {
        "abstract": "Abstract Recommendation has provoked vast amount of attention and research in recent decades. Most previous works employ matrix factorization techniques to learn the latent factors of users and items. And many subsequent works consider external information, e.g., social relationships of users and items\u2019 attributions, to improve the recommendation performance under the matrix factorization framework. However, matrix factorization methods may not make full use of the limited information from rating or check-in matrices, and achieve unsatisfying results. Recently, deep learning has proven able to learn good representation in natural language processing, image classification, and so on. Along this line, we propose a new representation learning framework called Recommendation via Dual-Autoencoder (ReDa). In this framework, we simultaneously learn the new hidden representations of users and items using autoencoders, and minimize the deviations of training data by the learnt representations of users and items. Based on this framework, we develop a gradient descent method to learn hidden representations. Extensive experiments conducted on several real-world data sets demonstrate the effectiveness of our proposed method compared with state-of-the-art matrix factorization based methods.", 
        "author": "Fuzhen Zhuang and Zhiqiang Zhang and Mingda Qian and Chuan Shi and Xing Xie and Qing He", 
        "keyword": "Matrix factorization\", \"Dual-Autoencoder\", \"Recommendation\", \"Representation learning", 
        "title": "Representation learning via Dual-Autoencoder for recommendation"
    }, 
    {
        "abstract": "Abstract The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets \\{AR1\\} and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for \\{AR1\\} and \\{AR6\\} data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods.", 
        "author": "Ruchika Malhotra", 
        "keyword": "Software quality\", \"Static code metrics\", \"Logistic regression\", \"Machine learning\", \"Receiver Operating Characteristic (ROC) curve", 
        "title": "Comparative analysis of statistical and machine learning methods for predicting faulty modules"
    }, 
    {
        "abstract": "Abstract E-Learning class formation will take benefit if common learners\u2019 needs are taken into account. For instance, the availability of trust relationships among users can represent an additional motivation for classmates to engage activities. Common experience also suggests that there are many similarities within dynamics of formation for thematic social network groups and e-Learning classrooms. Since Online Social Networks provide data concerning users interactions (e.g. trust relationships), we propose a model aimed at managing the formation and the evolution of e-Learning classes based on information available on Online Social Networks \u2014 skills, interactions, and trust relationships \u2014 which are properly combined in a unique measure. The aim is to suggest both to a user the best classes to join with and to the classes themselves the best students to accept. The proposed approach has been tested by simulating an e-Learning scenario within a large social network. Experiments show that this proposal is able to support students and class managers in order to satisfy their expectations in a scalable manner.", 
        "author": "Pasquale De Meo and Fabrizio Messina and Domenico Rosaci and Giuseppe M.L. Sarn\u00e9", 
        "keyword": "e-Learning\", \"Class formation\", \"Online social networks\", \"Skill\", \"Trust", 
        "title": "Combining trust and skills evaluation to form e-Learning classes in online social networks"
    }, 
    {
        "abstract": "Abstract Acid rock drainage (ARD) is a major pollution problem globally that has adversely impacted the environment. Identification and quantification of uncertainties are integral parts of \\{ARD\\} assessment and risk mitigation, however previous studies on predicting \\{ARD\\} drainage chemistry have not fully addressed issues of uncertainties. In this study, artificial neural networks (ANN) and support vector machine (SVM) are used for the prediction of \\{ARD\\} drainage chemistry and their predictive uncertainties are quantified using probability bounds analysis. Furthermore, the predictions of \\{ANN\\} and \\{SVM\\} are integrated using four aggregation methods to improve their individual predictions. The results of this study showed that \\{ANN\\} performed better than \\{SVM\\} in enveloping the observed concentrations. In addition, integrating the prediction of \\{ANN\\} and \\{SVM\\} using the aggregation methods improved the predictions of individual techniques.", 
        "author": "Getnet D. Betrie and Rehan Sadiq and Kevin A. Morin and Solomon Tesfamariam", 
        "keyword": "Acid rock drainage\", \"Machine learning\", \"Artificial neural network\", \"Support vector machine\", \"Uncertainty analysis", 
        "title": "Uncertainty quantification and integration of machine learning techniques for predicting acid rock drainage chemistry: A probability bounds approach"
    }, 
    {
        "abstract": "Abstract Due to the short duration and low intensity of micro-expressions, the recognition of micro-expression is still a challenging problem. In this paper, we develop a novel multi-task mid-level feature learning method to enhance the discrimination ability of extracted low-level features by learning a set of class-specific feature mappings, which would be used for generating our mid-level feature representation. Moreover, two weighting schemes are employed to concatenate different mid-level features. We also construct a new mobile micro-expression set to evaluate the performance of the proposed mid-level feature learning framework. The experimental results on two widely used non-mobile micro-expression datasets and one mobile micro-expression set demonstrate that the proposed method can generally improve the performance of the low-level features, and achieve comparable results with the state-of-the-art methods.", 
        "author": "Jiachi He and Jian-Fang Hu and Xi Lu and Wei-Shi Zheng", 
        "keyword": "Micro-expression recognition\", \"Multi-task learning", 
        "title": "Multi-task mid-level feature learning for micro-expression recognition"
    }, 
    {
        "abstract": "Abstract In this paper, a new S-Transform and Extreme Learning Machine (ST\u2013ELM)-based event recognition approach for the purpose of classifying power quality (PQ) event signals automatically has been proposed. In this approach, the distinctive features of the \\{PQ\\} event signals have been obtained with the S-Transform-based feature extraction. The feature vector obtained with feature extraction has been applied as input to the \\{ELM\\} classifier. Ten different classification procedures were determined within the framework of this study to assess the performance of the \\{ELM\\} classifier on \\{PQ\\} event data. Real \\{PQ\\} event data and synthetic \\{PQ\\} event data obtained from MATLAB/Simulink environment have been used in these procedures. Also, three different \\{PQ\\} event data sets, which are formed by adding noises of 20, 30 and 50 dB to the synthetic \\{PQ\\} event data respectively, have been used in order to assess the performance of the proposed approach on noisy conditions. According to the results of performance evaluations, the proposed ST\u2013ELM-based \\{PQ\\} event recognition system has a very high performance of recognizing \\{PQ\\} event data. Besides, classification of noisy data showed that the proposed approach is robust at recognizing noisy data. The performance of the ST\u2013ELM-based recognition system on \\{PQ\\} data shows that this approach has an effective recognition structure that can be used in real power systems.", 
        "author": "H\u00fcseyin Eri\u015fti and \u00d6zal Y\u0131ld\u0131r\u0131m and Belk\u0131s Eri\u015fti and Yakup Demir", 
        "keyword": "Power quality events\", \"S-Transform\", \"Extreme Learning Machine\", \"Classification", 
        "title": "Automatic recognition system of underlying causes of power quality disturbances based on S-Transform and Extreme Learning Machine"
    }, 
    {
        "abstract": "Abstract The High Performance Computing (HPC) community has spent decades developing tools that teach practitioners to harness the power of parallel and distributed computing. To create scalable and flexible educational experiences for practitioners in all phases of a career, we turn to Massively Open Online Courses (MOOCs). We detail the design of a unique self-paced online course that incorporates a focus on parallel solutions, personalization, and hands-on practice to familiarize student\u2013users with their target system. Course material is presented through the lens of common \\{HPC\\} use cases and the strategies for parallelizing them. Using personalized paths, we teach researchers how to recognize the alignment between scientific applications and traditional \\{HPC\\} use cases, so they can focus on learning the parallelization strategies key to their workplace success. At the conclusion of their learning path, students should be capable of achieving performance gains on their \\{HPC\\} system.", 
        "author": "Julia Mullen and Chansup Byun and Vijay Gadepally and Siddharth Samsi and Albert Reuther and Jeremy Kepner", 
        "keyword": "Hands-on learning\", \"Open edX\", \"MOOC\", \"Personalized digital learning\", \"Interactive keywords =upercomputing\", \"Professional education\", \"HPC education", 
        "title": "Learning by doing, High Performance Computing education in the \\{MOOC\\} era"
    }, 
    {
        "abstract": "Abstract As top-level predators, common bottlenose dolphins (Tursiops truncatus) are particularly sensitive to chemical and biological contaminants that accumulate and biomagnify in the marine food chain. This work investigates the potential use of microarray technology and gene expression profile analysis to screen common bottlenose dolphins for exposure to environmental contaminants through the immunological and/or endocrine perturbations associated with these agents. A dolphin microarray representing 24,418 unigene sequences was used to analyze blood samples collected from 47 dolphins during capture-release health assessments from five different \\{US\\} coastal locations (Beaufort, NC, Sarasota Bay, FL, Saint Joseph Bay, FL, Sapelo Island, \\{GA\\} and Brunswick, GA). Organohalogen contaminants including pesticides, polychlorinated biphenyl congeners (PCBs) and polybrominated diphenyl ether congeners were determined in blubber biopsy samples from the same animals. A subset of samples (n\u00a0=\u00a010, males; n\u00a0=\u00a08, females) with the highest and the lowest measured values of \\{PCBs\\} in their blubber was used as strata to determine the differential gene expression of the exposure extremes through machine learning classification algorithms. A set of genes associated primarily with nuclear and \\{DNA\\} stability, cell division and apoptosis regulation, intra- and extra-cellular traffic, and immune response activation was selected by the algorithm for identifying the two exposure extremes. In order to test the hypothesis that these gene expression patterns reflect \\{PCB\\} exposure, we next investigated the blood transcriptomes of the remaining dolphin samples using machine-learning approaches, including K-nn and Support Vector Machines classifiers. Using the derived gene sets, the algorithms worked very well (100% success rate) at classifying dolphins according to the contaminant load accumulated in their blubber. These results suggest that gene expression profile analysis may provide a valuable means to screen for indicators of chemical exposure.", 
        "author": "Annalaura Mancia and James C. Ryan and Frances M. Van Dolah and John R. Kucklick and Teresa K. Rowles and Randall S. Wells and Patricia E. Rosel and Aleta A. Hohn and Lori H. Schwacke", 
        "keyword": "Machine learning\", \"Transcriptome\", \"Bottlenose dolphin\", \"Ecogenomics\", \"Environmental contaminant keywords =xposure\", \"Biotoxin exposure", 
        "title": "Machine learning approaches to investigate the impact of \\{PCBs\\} on the transcriptome of the common bottlenose dolphin (Tursiops truncatus)"
    }, 
    {
        "abstract": "Abstract Features act as a key factor in pedestrian detection task. Most widely-used ones like \\{HOG\\} are manually designed and hard to be adaptive, thus now more attention has been paid to the features automatically learned on data. In this paper, a novel approach of learning discriminative features is proposed, addressing two main limitations of the methods in the literature. On one hand, unlike those methods of learning features on low-level pixels, we propose to learn features via a particular sparse coding algorithm enhanced on mid-level image representation, in order to obtain higher-level latent semantics and robustness; On the other hand, those methods usually utilize label information in model training such as deformable part model (DPM) with high computation cost. Instead, we propose to extend the learning process via a maximum margin criterion, in order to better encode discriminative information directly in features by optimizing them to be close to each other if from the same class and far from each other if from different classes. Furthermore, a boosted detection framework rather than the complex \\{DPM\\} is adopted to achieve both high accuracy and efficiency. The proposed approach achieves promising results on several standard pedestrian detection benchmarks.", 
        "author": "Chao Zhu and Yuxin Peng", 
        "keyword": "Pedestrian detection\", \"Feature learning\", \"Latent semantics\", \"Discriminative power", 
        "title": "Discriminative latent semantic feature learning for pedestrian detection"
    }, 
    {
        "abstract": "Abstract Keratoconus (KC) is the most common type of corneal ectasia. A corneal transplantation was the treatment of choice until the last decade. However, intra-corneal ring implantation has become more and more common, and it is commonly used to treat \\{KC\\} thus avoiding a corneal transplantation. This work proposes a new approach based on Machine Learning to predict the vision gain of \\{KC\\} patients after ring implantation. That vision gain is assessed by means of the corneal curvature and the astigmatism. Different models were proposed; the best results were achieved by an artificial neural network based on the Multilayer Perceptron. The error provided by the best model was 0.97D of corneal curvature and 0.93D of astigmatism.", 
        "author": "M.A. Vald\u00e9s-Mas and J.D. Mart\u00edn-Guerrero and M.J. Rup\u00e9rez and F. Pastor and C. Dualde and C. Monserrat and C. Peris-Mart\u00ednez", 
        "keyword": "Machine Learning\", \"Keratoconus\", \"Intracorneal rings\", \"Astigmatism", 
        "title": "A new approach based on Machine Learning for predicting corneal curvature (K1) and astigmatism in patients with keratoconus after intracorneal ring implantation"
    }, 
    {
        "abstract": "Abstract Recognizing semantic category of objects and scenes captured using vision-based sensors is a challenging yet essential capability for mobile robots and \\{UAVs\\} to perform high-level tasks such as long-term autonomous navigation. However, extracting discriminative features from multi-modal inputs, such as RGB-D images, in a unified manner is non-trivial given the heterogeneous nature of the modalities. We propose a deep network which seeks to construct a joint and shared multi-modal representation through bilinearly combining the convolutional neural network (CNN) streams of the \\{RGB\\} and depth channels. This technique motivates bilateral transfer learning between the modalities by taking the outer product of each feature extractor output. Furthermore, we devise a technique for multi-scale feature abstraction using deeply supervised branches which are connected to all convolutional layers of the multi-stream CNN. We show that end-to-end learning of the network is feasible even with a limited amount of training data and the trained network generalizes across different datasets and applications. Experimental evaluations on benchmark RGB-D object and scene categorization datasets show that the proposed technique consistently outperforms state-of-the-art algorithms.", 
        "author": "Hasan F.M. Zaki and Faisal Shafait and Ajmal Mian", 
        "keyword": "RGB-D image\", \"Visual place recognition\", \"Object categorization\", \"Multi-modal deep learning", 
        "title": "Learning a deeply supervised multi-modal RGB-D embedding for semantic scene and object category recognition"
    }, 
    {
        "abstract": "Abstract The spiking neural networks (SNNs) are the third generation of artificial neural networks, which have made great achievements in the field of pattern recognition. However, the existing supervised training methods of \\{SNNs\\} are not efficient enough to meet the real-time requirement in most cases. To address this issue, the normalized perceptron based learning rule (NPBLR) is proposed in this paper for the supervised training of the multi-layer SNNs. Different from traditional methods, our algorithm only trains the selected misclassified time points and the target ones, employing the perceptron based neuron. Furthermore, the weight modification in our algorithm is normalized by a voltage based function, which is more efficient than the traditional time based method because the firing time is calculated by the voltage value. Superior to the traditional multi-layer algorithm ignoring the time accumulation of spikes, our algorithm defines the spiking activity of the postsynaptic neuron as the rate accumulation function of all presynaptic neurons in a specific time-frame. By these strategies, our algorithm overcomes some difficulties in the training of SNNs, e.g., the inefficient and no-fire problems. Comprehensive simulations are conducted both in single and multi-layer networks to investigate the learning performance of our algorithm, whose results demonstrate that our algorithm possesses higher learning efficiency and stronger parameter robustness than traditional algorithms.", 
        "author": "Xiurui Xie and Hong Qu and Guisong Liu and Malu Zhang", 
        "keyword": "Spiking neural networks\", \"Temporal encoding mechanism\", \"Supervised learning\", \"Perceptron based learning rule", 
        "title": "Efficient training of supervised spiking neural networks via the normalized perceptron based learning rule"
    }, 
    {
        "abstract": "Abstract Learning-based planning algorithms are currently gaining popularity for their increasing applications in real-time planning and cooperation of robots. The paper aims at extending traditional multi-agent Q-learning algorithms to improve their speed of convergence by incorporating two interesting properties, concerning (i) exploration of the team-goal and (ii) selection of joint action at a given joint state. The exploration of team-goal is realized by allowing the agents, capable of reaching their goals, to wait at their individual goal states, until remaining agents explore their individual goals synchronously or asynchronously. To avoid unwanted never-ending wait-loops, an upper bound to wait-interval, obtained empirically for the waiting team members, is introduced. Selection of joint action, which is a crucial problem in traditional multi-agent Q-learning, is performed here by taking the intersection of individual preferred joint actions of all the agents. In case the resulting intersection is a null set, the individual actions are selected randomly or otherwise following classical multi-agent Q-learning. It is shown both theoretically and experimentally that the extended algorithms outperform its traditional counterpart with respect to speed of convergence. To ensure selection of right joint action at each step of planning, we offer high rewards to exploration of the team-goal and zero rewards to exploration of individual goals during the learning phase. The introduction of the above strategy results in an enriched joint Q-table, the consultation of which during the multi-agent planning yields significant improvement in the performance of cooperative planning of robots. Hardwired realization of the proposed learning based planning algorithm, designed for object-transportation application, confirms the relative merits of the proposed technique over contestant algorithms.", 
        "author": "Arup Kumar Sadhu and Amit Konar", 
        "keyword": "Multi-agent Q-learning\", \"Team-reward\", \"Team-task\", \"Multi-robot coordination\", \"Object-transportation", 
        "title": "Improving the speed of convergence of multi-agent Q-learning for cooperative task-planning by a robot-team"
    }, 
    {
        "abstract": "Abstract In this paper, a novel optimization technique based on artificial bee colony algorithm (ABC), which is called as PS-ABCII, is presented. In PS-ABCII, there are three major differences from other ABC-based techniques: (1) the opposition-based learning is applied to the population initialization; (2) the greedy selection mechanism is not adopted; (3) the mode that employed bees become scouts is modified. In order to illustrate the superiority of the proposed modified technique over other ABC-based techniques, ten classical benchmark functions are employed to test. In addition, a hybrid model called PS-ABCII-ELM is also proposed in this paper, which is combined of the PS-ABCII and Extreme Learning Machine (ELM). In PS-ABCII-ELM, the PS-ABCII is applied to tune input weights and biases of \\{ELM\\} in order to improve the generalization performance of ELM. And then it is applied to model and optimize the thermal efficiency of a 300 \\{MW\\} coal-fired boiler. The experimental results show that the proposed model is very convenient, direct and accurate, and it can give a general and suitable way to predict and improve the boiler efficiency of a coal-fired boiler under various operating conditions.", 
        "author": "Guoqiang Li and Peifeng Niu and Yunpeng Ma and Hongbin Wang and Weiping Zhang", 
        "keyword": "Artificial bee colony\", \"Extreme learning machine\", \"Greedy selection mechanism\", \"Opposition-based keywords =earning\", \"Coal-fired boilers", 
        "title": "Tuning extreme learning machine by an improved artificial bee colony to model and optimize the boiler efficiency"
    }, 
    {
        "abstract": "Abstract Multi-view data with each view corresponding to a type of feature set are common in real world. Usually, previous multi-view learning methods assume complete views. However, multi-view data are often incomplete, namely some samples have incomplete feature sets. Besides, most data are unlabeled due to a large cost of manual annotation, which makes learning of such data a challenging problem. In this paper, we propose a novel subspace learning framework for incomplete and unlabeled multi-view data. The model directly optimizes the class indicator matrix, which establishes a bridge for incomplete feature sets. Besides, feature selection is considered to deal with high dimensional and noisy features. Furthermore, the inter-view and intra-view data similarities are preserved to enhance the model. To these ends, an objective is developed along with an efficient optimization strategy. Finally, extensive experiments are conducted for multi-view clustering and cross-modal retrieval, achieving the state-of-the-art performance under various settings.", 
        "author": "Qiyue Yin and Shu Wu and Liang Wang", 
        "keyword": "Multi-view learning\", \"Subspace learning\", \"Incomplete and unlabeled data\", \"Multi-view keywords =lustering\", \"Cross-modal retrieval", 
        "title": "Unified subspace learning for incomplete and unlabeled multi-view data"
    }, 
    {
        "abstract": "Abstract Genome-wide prediction of complex traits has become increasingly important in animal and plant breeding, and is receiving increasing attention in human genetics. Most common approaches are whole-genome regression models where phenotypes are regressed on thousands of markers concurrently, applying different prior distributions to marker effects. While use of shrinkage or regularization in \\{SNP\\} regression models has delivered improvements in predictive ability in genome-based evaluations, serious over-fitting problems may be encountered as the ratio between markers and available phenotypes continues increasing. Machine learning is an alternative approach for prediction and classification, capable of dealing with the dimensionality problem in a computationally flexible manner. In this article we provide an overview of non-parametric and machine learning methods used in genome wide prediction, discuss their similarities as well as their relationship to some well-known parametric approaches. Although the most suitable method is usually case dependent, we suggest the use of support vector machines and random forests for classification problems, whereas Reproducing Kernel Hilbert Spaces regression and boosting may suit better regression problems, with the former having the more consistently higher predictive ability. Neural Networks may suffer from over-fitting and may be too computationally demanded when the number of neurons is large. We further discuss on the metrics used to evaluate predictive ability in model comparison under cross-validation from a genomic selection point of view. We suggest use of predictive mean squared error as a main but not only metric for model comparison. Visual tools may greatly assist on the choice of the most accurate model.", 
        "author": "Oscar Gonz\u00e1lez-Recio and Guilherme J.M. Rosa and Daniel Gianola", 
        "keyword": "Animal breeding\", \"Cross validation\", \"Genome wide prediction\", \"Machine learning\", keywords =Nonparametric\", \"Predictive accuracy", 
        "title": "Machine learning methods and predictive ability metrics for genome-wide prediction of complex traits"
    }, 
    {
        "abstract": "AbstractContext Defect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time [1]. Objective Ensemble learning becomes a hot topic in recent years. There have been several studies about applying ensemble learning to defect prediction [2\u20135]. Traditional ensemble learning approaches only have one layer, i.e., they use ensemble learning once. There are few studies that leverages ensemble learning twice or more. To bridge this research gap, we try to hybridize various ensemble learning methods to see if it will improve the performance of just-in-time defect prediction. In particular, we focus on one way to do this by hybridizing bagging and stacking together and leave other possibly hybridization strategies for future work. Method In this paper, we propose a two-layer ensemble learning approach \\{TLEL\\} which leverages decision tree and ensemble learning to improve the performance of just-in-time defect prediction. In the inner layer, we combine decision tree and bagging to build a Random Forest model. In the outer layer, we use random under-sampling to train many different Random Forest models and use stacking to ensemble them once more. Results To evaluate the performance of TLEL, we use two metrics, i.e., cost effectiveness and F1-score. We perform experiments on the datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. Also, we compare our approach with three baselines, i.e., Deeper, the approach proposed by us [6], DNC, the approach proposed by Wang et\u00a0al. [2], and MKEL, the approach proposed by Wang et\u00a0al. [3]. The experimental results show that on average across the six datasets, \\{TLEL\\} could discover over 70% of the bugs by reviewing only 20% of the lines of code, as compared with about 50% for the baselines. In addition, the F1-scores \\{TLEL\\} can achieve are substantially and statistically significantly higher than those of three baselines across the six datasets. Conclusion \\{TLEL\\} can achieve a substantial and statistically significant improvement over the state-of-the-art methods, i.e., Deeper, \\{DNC\\} and MKEL. Moreover, \\{TLEL\\} could discover over 70% of the bugs by reviewing only 20% of the lines of code.", 
        "author": "Xinli Yang and David Lo and Xin Xia and Jianling Sun", 
        "keyword": "Ensemble learning\", \"Just-in-time defect prediction\", \"Cost effectiveness", 
        "title": "TLEL: A two-layer ensemble learning approach for just-in-time defect prediction"
    }, 
    {
        "abstract": "Abstract Computational approaches to the quantitative evaluation of histological and cytological images have been with us in cell biology and pathology for a long time. In biology, the stereological approaches that rely on scene sampling and the projection of quantitative information from 2D to 3D have been used for over 80 years. The introduction of computer science into biology is, however, relatively recent. Moreover, in the last few years, there had been a sharp acceleration of the computing power used in biological investigations. In cellular imaging, this has translated into rapid computer-assisted image acquisition and image analysis and the integration of high-resolution cellular imaging data into the investigations of complex biological processes. The principles of artificial intelligence applied to cellular imaging are beginning to make their way into the mainstream of biologist's and pathologist's daily work. These tools will enable, not replace, the thought processes and methods already extant in the communities of cell biology and pathology. This article reviews some of the principles and practice of machine vision and machine learning in digital pathology.", 
        "author": "J.E. Tomaszewski and J. Hipp and M. Tangrea and A. Madabhushi", 
        "keyword": "Data output\", \"Dimensionality reduction techniques\", \"Feature capture\", \"Feature selection keywords =trategies\", \"Graph embedding features\", \"Image filters\", \"Image segmentation\", \"Label placement\", keywords =Machine classifiers\", \"Machine learning\", \"Machine vision\", \"Manifold learning\", \"Multiclassifier keywords =nsembles\", \"Object classification\", \"Quantitative data fusion\", \"Semisupervised learning\", \"Spatially keywords =nvariant vector quantization\", \"Stereology\", \"Supervised learning\", \"Texture features\", \"Unsupervised learning", 
        "title": "Machine Vision and Machine Learning in Digital Pathology"
    }, 
    {
        "abstract": "Abstract Feedforward neural networks have been extensively used to approximate complex nonlinear mappings directly from the input samples. However, their traditional learning algorithms are usually much slower than required. In this work, two hidden-feature-space ridge regression methods \\{HFSR\\} and centered-ELM are first proposed for feedforward networks. As the special kernel methods, the important characteristics of both \\{HFSR\\} and centered-ELM are that rigorous Mercer's condition for kernel functions is not required and that they can inherently be used to propagate the prominent advantages of \\{ELM\\} into MLFN. Except for randomly assigned weights adopted in both \\{ELM\\} and HFSR, \\{HFSR\\} also exploits another randomness, i.e., randomly selected examplars from the training set for kernel activation functions. Through forward layer-by-layer data transformation, we can extend \\{HFSR\\} and Centered-ELM to MLFN. Accordingly, as the unified framework for \\{HFSR\\} and Centered-ELM, the least learning machine (LLM) is proposed for both \\{SLFN\\} and \\{MLFN\\} with a single or multiple outputs. \\{LLM\\} actually gives a new learning method for \\{MLFN\\} with keeping the same virtues of \\{ELM\\} only for SLFN, i.e., only the parameters in the last hidden layer require being adjusted, all the parameters in other hidden layers can be randomly assigned, and \\{LLM\\} is also much faster than \\{BP\\} for \\{MLFN\\} in training the sample sets. The experimental results clearly indicate the power of \\{LLM\\} on its application in nonlinear regression modeling.", 
        "author": "Shitong Wang and Fu-Lai Chung and Jun Wu and Jun Wang", 
        "keyword": "Feedforward neural network\", \"Extreme learning machine\", \"Hidden-feature-space ridge regression\", \"Least learning machine", 
        "title": "Least learning machine and its experimental studies on regression capability"
    }, 
    {
        "abstract": "Abstract The operation conditions of the rotating machinery are always complex and variable, which makes it difficult to automatically and effectively capture the useful fault features from the measured vibration signals, and it is a great challenge for rotating machinery fault diagnosis. In this paper, a novel deep autoencoder feature learning method is developed to diagnose rotating machinery fault. Firstly, the maximum correntropy is adopted to design the new deep autoencoder loss function for the enhancement of feature learning from the measured vibration signals. Secondly, artificial fish swarm algorithm is used to optimize the key parameters of the deep autoencoder to adapt to the signal features. The proposed method is applied to the fault diagnosis of gearbox and electrical locomotive roller bearing. The results confirm that the proposed method is more effective and robust than other methods.", 
        "author": "Haidong Shao and Hongkai Jiang and Huiwei Zhao and Fuan Wang", 
        "keyword": "Deep autoencoder\", \"Feature learning\", \"Fault diagnosis\", \"Maximum correntropy\", \"Artificial fish swarm algorithm", 
        "title": "A novel deep autoencoder feature learning method for rotating machinery fault diagnosis"
    }, 
    {
        "abstract": "Abstract The productivity of milling processes is limited by the occurrence of chatter vibrations. The correlation of the maximum stable cutting depth and the spindle speed can be shown in a stability lobe diagram (SLD). The stability is different for different width of cut and can change with the axis positions. Today it is already a great effort to estimate the \\{SLD\\} only for one position. Many experiments are necessary to measure the \\{SLD\\} or derive a detailed mathematical model to calculate the SLD. Moreover not only the cutting depth, but also the cutting width should be represented in the SLD. This paper presents a new approach to assess the process stability based on measured acceleration signals. The multidimensional stability lobe diagram (MSLD) are derived during the production using two new continuously learning algorithms. In this paper the application of a continuous learning support vector machine and a continuous neural network is shown. The support vector machine and the neural network are extended to make them capable for continuous learning and time-variant systems. A new trust criterion is introduced, which gives information about the prediction quality of the output for the selected input region. The learned \\{MSLDs\\} are evaluated against analytically calculated \\{MSLDs\\} and the learning algorithms can reproduce the analytical results very well.", 
        "author": "Jens Friedrich and Christoph Hinze and Anton Renner and Alexander Verl and Armin Lechler", 
        "keyword": "Process stability\", \"Milling\", \"Learning algorithms\", \"Support vector machines\", \"Neural network", 
        "title": "Estimation of stability lobe diagrams in milling with continuous learning algorithms"
    }, 
    {
        "abstract": "Abstract In many applications of information systems learning algorithms have to act in dynamic environments where data are collected in the form of transient data streams. Compared to static data mining, processing streams imposes new computational requirements for algorithms to incrementally process incoming examples while using limited memory and time. Furthermore, due to the non-stationary characteristics of streaming data, prediction models are often also required to adapt to concept drifts. Out of several new proposed stream algorithms, ensembles play an important role, in particular for non-stationary environments. This paper surveys research on ensembles for data stream classification as well as regression tasks. Besides presenting a comprehensive spectrum of ensemble approaches for data streams, we also discuss advanced learning concepts such as imbalanced data streams, novelty detection, active and semi-supervised learning, complex data representations and structured outputs. The paper concludes with a discussion of open research problems and lines of future research.", 
        "author": "Bartosz Krawczyk and Leandro L. Minku and Jo\u00e3o Gama and Jerzy Stefanowski and Micha\u0142 Wo\u017aniak", 
        "keyword": "Ensemble learning\", \"Data streams\", \"Concept drift\", \"Online learning\", \"Non-stationary environments", 
        "title": "Ensemble learning for data stream analysis: A survey"
    }, 
    {
        "abstract": "Abstract Eye movement data collection is very expensive and laborious. Moreover, there are usually missing values. Assuming that we are collecting eye movement data from a set of images viewed by different users, there is a possibility that we will not able to collect the data of every user from every image\u2013one or more views may not be represented in the image. We assume that the relationships among the views can be learnt from the whole collection of views (or items). The task is then to reproduce the missing part of the incomplete items from the relationships derived from the complete items and the known part of these items. Using certain properties of tensor algebra, we showed that this problem can be formulated consistently as a regression type learning task. Furthermore, there is a maximum margin based optimisation framework in which this problem can be solved in a tractable way. This problem is similar to learning to predict where a person is looking in an image. Therefore, we proposed an algorithm called \u201cTensor-based Multi-View Learning\u201d(TMVL) in this paper. Furthermore, we also proposed a technique for improving prediction by introducing a new feature set obtained from Kronecker decomposition of the image fused with user\u2019s eye movement data. Using this new feature can improve prediction performance markedly. The proposed approach was proven to be more effective than two well-known saliency detection techniques.", 
        "author": "Kitsuchart Pasupa and Sandor Szedmak", 
        "keyword": "Multi-view learning\", \"Missing data\", \"Tensor algebra\", \"Maximum margin learning\", \"Eye movements\", \"Kronecker decomposition", 
        "title": "Utilising Kronecker Decomposition and Tensor-based Multi-view Learning to predict where people are looking in images"
    }, 
    {
        "abstract": "Abstract Plant phenology is one of the most reliable indicators of species responses to global climate change, motivating the development of new technologies for phenological monitoring. Digital cameras or near remote systems have been efficiently applied as multi-channel imaging sensors, where leaf color information is extracted from the \\{RGB\\} (Red, Green, and Blue) color channels, and the changes in green levels are used to infer leafing patterns of plant species. In this scenario, texture information is a great ally for image analysis that has been little used in phenology studies. We monitored leaf-changing patterns of Cerrado savanna vegetation by taking daily digital images. We extract \\{RGB\\} channels from the digital images and correlate them with phenological changes. Additionally, we benefit from the inclusion of textural metrics for quantifying spatial heterogeneity. Our first goals are: (1) to test if color change information is able to characterize the phenological pattern of a group of species; (2) to test if the temporal variation in image texture is useful to distinguish plant species; and (3) to test if individuals from the same species may be automatically identified using digital images. In this paper, we present a machine learning approach based on multiscale classifiers to detect phenological patterns in the digital images. Our results indicate that: (1) extreme hours (morning and afternoon) are the best for identifying plant species; (2) different plant species present a different behavior with respect to the color change information; and (3) texture variation along temporal images is promising information for capturing phenological patterns. Based on those results, we suggest that individuals from the same species and functional group might be identified using digital images, and introduce a new tool to help phenology experts in the identification of new individuals from the same species in the image and their location on the ground.", 
        "author": "Jurandy Almeida and Jefersson A. dos Santos and Bruna Alberton and Ricardo da S. Torres and Leonor Patricia C. Morellato", 
        "keyword": "Remote phenology\", \"Digital cameras\", \"Machine learning\", \"Image analysis\", \"Tropical forests", 
        "title": "Applying machine learning based on multiscale classifiers to detect remote phenology patterns in Cerrado savanna trees"
    }, 
    {
        "abstract": "Abstract We consider a nonlinear state\u2013space model with the state transition and observation functions expressed as basis function expansions. The coefficients in the basis function expansions are learned from data. Using a connection to Gaussian processes we also develop priors on the coefficients, for tuning the model flexibility and to prevent overfitting to data, akin to a Gaussian process state\u2013space model. The priors can alternatively be seen as a regularization, and helps the model in generalizing the data without sacrificing the richness offered by the basis function expansion. To learn the coefficients and other unknown parameters efficiently, we tailor an algorithm using state-of-the-art sequential Monte Carlo methods, which comes with theoretical guarantees on the learning. Our approach indicates promising results when evaluated on a classical benchmark as well as real data.", 
        "author": "Andreas Svensson and Thomas B. Sch\u00f6n", 
        "keyword": "System identification\", \"Nonlinear models\", \"Regularization\", \"Probabilistic models\", \"Bayesian keywords =earning\", \"Gaussian processes\", \"Monte Carlo methods", 
        "title": "A flexible state\u2013space model for learning nonlinear dynamical systems"
    }, 
    {
        "abstract": "Abstract For robust visual tracking, appearance modeling should be able to well separate the object from its backgrounds, while accurately adapt to its appearance variations. However, most of the existing tracking methods mainly focus on one of the two aspects; or design two different modules to combine them with the price of double computational cost. In this paper, by using pairwise metric learning, we present a novel appearance model for robust visual tracking. Specifically, visual tracking is viewed as a pairwise regression problem, and extreme learning machine (ELM) is utilized to construct the pairwise regression framework. In ELM-based pairwise training, two constraints are enforced: the target observations must have different regression outputs from those background ones; while the various target observations during tracking should have approximate regression outputs. Thus, the discriminative and generative capabilities are fully considered in a single object tracking model. Moreover, online sequential \\{ELM\\} (OS-ELM) is used to update the resulting appearance model, thereby leading to a more robust tracking process. Extensive experimental evaluations on challenging video sequences demonstrate the effectiveness and efficiency of the proposed tracker.", 
        "author": "Chenwei Deng and Baoxian Wang and Weisi Lin and Guang-Bin Huang and Baojun Zhao", 
        "keyword": "Robust visual tracking\", \"Extreme learning machine\", \"Pairwise metric learning\", \"Appearance keywords =odeling\", \"Online sequential updating", 
        "title": "Effective visual tracking by pairwise metric learning"
    }, 
    {
        "abstract": "Abstract This paper addresses parallel machine scheduling with learning effects. The objective is to minimize the makespan. To satisfy reality, we consider the processing times as fuzzy numbers. To the best of our knowledge, scheduling with learning effects and fuzzy processing times on parallel machines has never been studied. The possibility measure will be used to rank the fuzzy numbers. Two heuristic algorithms, the simulated annealing algorithm and the genetic algorithm, are proposed. Computational experiments have been conducted to evaluate their performance.", 
        "author": "Wei-Chang Yeh and Peng-Jen Lai and Wen-Chiung Lee and Mei-Chi Chuang", 
        "keyword": "Scheduling\", \"Learning effect\", \"Parallel-machine\", \"Makespan\", \"Fuzzy number\", \"Possibility measure", 
        "title": "Parallel-machine scheduling to minimize makespan with fuzzy processing times and learning effects"
    }, 
    {
        "abstract": "Abstract It is a challenging problem to design excellent dictionaries to sparsely represent diverse fault information and simultaneously discriminate different fault sources. Therefore, this paper describes and analyzes a novel multiple feature recognition framework which incorporates the tight frame learning technique with an adaptive subspace recognition strategy. The proposed framework consists of four stages. Firstly, by introducing the tight frame constraint into the popular dictionary learning model, the proposed tight frame learning model could be formulated as a nonconvex optimization problem which can be solved by alternatively implementing hard thresholding operation and singular value decomposition. Secondly, the noises are effectively eliminated through transform sparse coding techniques. Thirdly, the denoised signal is decoupled into discriminative feature subspaces by each tight frame filter. Finally, in guidance of elaborately designed fault related sensitive indexes, latent fault feature subspaces can be adaptively recognized and multiple faults are diagnosed simultaneously. Extensive numerical experiments are sequently implemented to investigate the sparsifying capability of the learned tight frame as well as its comprehensive denoising performance. Most importantly, the feasibility and superiority of the proposed framework is verified through performing multiple fault diagnosis of motor bearings. Compared with the state-of-the-art fault detection techniques, some important advantages have been observed: firstly, the proposed framework incorporates the physical prior with the data-driven strategy and naturally multiple fault feature with similar oscillation morphology can be adaptively decoupled. Secondly, the tight frame dictionary directly learned from the noisy observation can significantly promote the sparsity of fault features compared to analytical tight frames. Thirdly, a satisfactory complete signal space description property is guaranteed and thus weak feature leakage problem is avoided compared to typical learning methods.", 
        "author": "Han Zhang and Xuefeng Chen and Zhaohui Du and Boyuan Yang", 
        "keyword": "Sparse representation\", \"Dictionary learning\", \"Transform sparse coding\", \"Discriminative indexes\", keywords =Nonconvex optimization\", \"Multiple feature decoupling", 
        "title": "Sparsity-aware tight frame learning with adaptive subspace recognition for multiple fault diagnosis"
    }, 
    {
        "abstract": "Abstract To select the most representative data points for labeling, two typical active learning methods, Transductive Experimental Design (TED) and Robust Representation and Structured Sparsity (RRSS), have been recently proposed. They yield impressive results. However, both of them neglected the local structure of data points which is helpful for selecting representative data points. Therefore, in this paper, we propose a novel active learning method via local structure reconstruction to select representative data points. Specifically, we construct a simple but effective graph to search the local relationship of data points. Then an optimization model is formulated to fulfill the data point reconstruction and select the most representative data points. Furthermore, we define a simple but useful classifier based on a linear regression model for better exploring the potential classification performance of selected data points. Experimental results on two synthetic datasets and two face databases demonstrate the effectiveness of our method and the efficiency of the defined classifier.", 
        "author": "Qin Li and Xiaoshuang Shi and Linfei Zhou and Zhifeng Bao and Zhenhua Guo", 
        "keyword": "Active learning\", \"Local structure reconstruction\", \"Representative data\", \"Linear regression classifier", 
        "title": "Active learning via local structure reconstruction"
    }, 
    {
        "abstract": "Abstract The main objective of this study is to evaluate and compare the performance of landslide models using machine learning ensemble technique for landslide susceptibility assessment. This technique is a combination of ensemble methods (AdaBoost, Bagging, Dagging, MultiBoost, Rotation Forest, and Random SubSpace) and the base classifier of Multiple Perceptron Neural Networks (MLP Neural Nets). Ensemble techniques have been widely applied in other fields; however, their application is still rare in the assessment of landslide problems. Meanwhile, \\{MLP\\} Neural Nets, which is known as an artificial neural network, has been applied widely and efficiently in landslide problems. In the present study, landslide models of part Himalayan area (India) have been constructed and validated. For the evaluation and comparison of these models, receiver operating characteristic curve and Chi Square test methods have been applied. Overall, all landslide models performed well in landslide susuceptibility assessment but the performance of the MultiBoost model is the highest (AUC = 0.886), followed by Dagging model (AUC = 0.885), the Rotation Forest model (AUC = 0.882), the Bagging and Random SubSpace models (AUC = 0.881), and the AdaBoost model (AUC = 0.876), respectively. Moreover, machine learning ensemble models have improved significantly the performance of the base classifier of \\{MLP\\} Neural Nets (AUC = 0.874). Analysis of results indicates that landslide models using machine learning ensemble frameworks are promising methods which can be used as alternatives of individual base classifiers for landslide susceptibility assessment of other prone areas.", 
        "author": "Binh Thai Pham and Dieu Tien Bui and Indra Prakash and M.B. Dholakia", 
        "keyword": "Landslides\", \"Ensemble techniques\", \"Multilayer Perceptron Neural Network\", \"Himalaya\", \"India", 
        "title": "Hybrid integration of Multilayer Perceptron Neural Networks and machine learning ensembles for landslide susceptibility assessment at Himalayan area (India) using \\{GIS\\}"
    }, 
    {
        "abstract": "Abstract In interactive retrieval tasks, one of the main objectives is to maximize the user information gain throughout search sessions. Retrieving many relevant items is quite important, but it does not necessarily completely satisfy the user needs. When only relevant near-duplicate items are retrieved, the amount of different concepts users are able to extract from the target collection is very limited. Therefore, broadening the number of concepts present in a result set may improve the overall search experience. Diversifying concepts present in the retrieved set is one possibility for increasing the information gain in a single search iteration, maximizing the likelihood of including at least some relevant items for each possible intent of ambiguous or underspecified queries. Relevance feedback approaches may also take advantage of diverse results to improve internal machine learning models. In this context, this work proposes and analyses several multimodal image retrieval approaches built over a learning framework for relevance feedback on diversified results. Our experimental analysis shows that different retrieval modalities are positively impacted by diversity, but achieve best retrieval effectiveness with diversification applied at different moments of a search session. Moreover, the best results are achieved with a query-by-example approach using multimodal information obtained from feedback. In summary, we demonstrate that learning with diversity is an effective alternative for boosting multimodal interactive learning approaches.", 
        "author": "Rodrigo Tripodi Calumby and Marcos Andr\u00e9 Gon\u00e7alves and Ricardo da Silva Torres", 
        "keyword": "Diversity\", \"Multimodal retrieval\", \"Relevance feedback\", \"Machine learning", 
        "title": "Diversity-based interactive learning meets multimodality"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a new version of support vector machine named biased p-norm support vector machine (BPSVM) involved in learning from positive and unlabeled examples. Compared with the previous works, \\{BPSVM\\} can not only improve the performance of classification but also select relevant features automatically based on estimating theoretically the lower bounds for the nonzero components in the solution to the corresponding optimization problem. Preliminary, numerical results show that our \\{BPSVM\\} is effective in both classification and features selection.", 
        "author": "Zhiqiang Zhang and Ting Ke and Naiyang Deng and Junyan Tan", 
        "keyword": "Support vector machine\", \"Feature selection\", \"p-Norm\", \"Positive unlabeled learning", 
        "title": "Biased p-norm support vector machine for \\{PU\\} learning"
    }, 
    {
        "abstract": "Abstract Effective electromyographic (EMG) signal characterization is critical in the diagnosis of neuromuscular disorders. Machine-learning based pattern classification algorithms are commonly used to produce such characterizations. Several classifiers have been investigated to develop accurate and computationally efficient strategies for \\{EMG\\} signal characterization. This paper provides a critical review of some of the classification methodologies used in \\{EMG\\} characterization, and presents the state-of-the-art accomplishments in this field, emphasizing neuromuscular pathology. The techniques studied are grouped by their methodology, and a summary of the salient findings associated with each method is presented.", 
        "author": "Jamileh Yousefi and Andrew Hamilton-Wright", 
        "keyword": "\\{EMG\\} electromyography\", \"EMG characterization\", \"Machine learning\", \"Classification\", keywords =Neuromuscular disease\", \"Myopathy\", \"Neuropathy", 
        "title": "Characterizing \\{EMG\\} data using machine-learning tools"
    }, 
    {
        "abstract": "Abstract In this paper, a new method for nonlinear system identification via extreme learning machine neural network based Hammerstein model (ELM-Hammerstein) is proposed. The ELM-Hammerstein model consists of static \\{ELM\\} neural network followed by a linear dynamic subsystem. The identification of nonlinear system is achieved by determining the structure of ELM-Hammerstein model and estimating its parameters. Lipschitz quotient criterion is adopted to determine the structure of ELM-Hammerstein model from input\u2013output data. A generalized \\{ELM\\} algorithm is proposed to estimate the parameters of ELM-Hammerstein model, where the parameters of linear dynamic part and the output weights of \\{ELM\\} neural network are estimated simultaneously. The proposed method can obtain more accurate identification results with less computation complexity. Three simulation examples demonstrate its effectiveness.", 
        "author": "Yinggan Tang and Zhonghui Li and Xinping Guan", 
        "keyword": "Nonlinear system identification\", \"Extreme learning machine\", \"Hammerstein model\", \"Generalized \\{ELM\\} algorithm", 
        "title": "Identification of nonlinear system using extreme learning machine based Hammerstein model"
    }, 
    {
        "abstract": "Abstract Prognostics, which usually means the prediction of the field reliability or the Remaining Useful Life (RUL), is the basis of Prognostic and Health Management (PHM). Research in this paper focuses on remaining useful life prediction of aircraft engine in the same gradual degradation mode. As the gradual degradation with same failure mechanism has some regularity in macro, there would be certain relation between an arbitrary point of the degradation process and the correspondent RUL. This paper tries to learn this certain relation via neural network and the learned network, which reflects the relation, can be partly perceived as degradation pattern. The main prognostic idea of degradation pattern learning is firstly proposed and illustrated. And then an improved back propagation neural network is designed and analyzed as the implementation technique, in whose loss function an adjacent difference item is added. Next details of implementation via adjacent difference neural network are elaborated. Finally, the proposed approach is validated by two experiments respectively using different aircraft engine degradation datasets. Results of the experiments show a relatively good prediction accuracy, which verifies the correctness, effectiveness and practicability of the idea.", 
        "author": "Zeqi Zhao and Bin Liang and Xueqian Wang and Weining Lu", 
        "keyword": "Prognostic and health management\", \"Remaining useful life prediction\", \"Degradation pattern keywords =earning\", \"Neural network", 
        "title": "Remaining useful life prediction of aircraft engine based on degradation pattern learning"
    }, 
    {
        "abstract": "Abstract Coronal Mass Ejection (CME) is a major solar activity that affects the earth, thus \\{CMEs\\} detection is of great importance for space weather forecast, disaster prevention and reduction. We model the detection of Coronal Mass Ejections (CMEs) as the classification of the brightest block in the current running difference image. Because \\{CMEs\\} usually correspond to the areas with high gray values or complex texture features, multiple features including gray features and texture features are extracted to represent the brightest block. And classifier is designed based on these features. Our method includes four steps: first, because the \\{CMEs\\} spread along the radial direction of the sun, in order to facilitate the analysis, the original coordinate is transformed into the polar coordinate; Secondly, because the typical appearance of the \\{CMEs\\} is bright or complex texture enhancement, we use the brightest block to represent the whole image; Thirdly, we extract the gray, texture and \\{HOG\\} features of the brightest gray blocks. Finally, we use the extracted features to design decision trees as the base classifiers, and AdaBoost is used to obtain the final ensemble classifier. As far as we know, this is the first time that the learning based classification framework is presented in the \\{CMEs\\} detection. Moreover, multiple feature fusion is first used to model the various CMEs. Experimental results show that the integration of multi-feature based detection algorithm proposed can achieve better detection results.", 
        "author": "Jianqin Yin and Hai Yao and Jiaben Lin and Yilong Yin and Ling Zhang and Xiaoli Liu and Zhiquan Feng and Xiaofan Wang", 
        "keyword": "Coronal Mass Ejections detection\", \"Multiple features fusion\", \"Ensemble learning", 
        "title": "Coronal Mass Ejections detection using multiple features based ensemble learning"
    }, 
    {
        "abstract": "Abstract The optimum selection of parameters is great important for the final quality of product in modern industrial manufacturing process. In order to achieve highly product quality, an effective optimization technique is indispensable. In this paper, a new hybrid algorithm named teaching-learning-based cuckoo search (TLCS) is proposed for parameter optimization problems in structure designing as well as machining processes. The \\{TLCS\\} combines the L\u00e9vy flight with teaching-learning process, then evolves with a co-evolutionary mechanism: for solutions to be abandoned in the cuckoo search will perform L\u00e9vy flight to generate new solutions, while for other better solutions, the teaching-learning process is used to improve the local searching ability of the algorithm. Then the proposed \\{TLCS\\} method is adopted into several well-known engineering parameter optimization problems. Experimental results show that \\{TLCS\\} obtains some solutions better than those previously reported in the literature, which reveals that the proposed \\{TLCS\\} is a very effective and robust approach for the parameter optimization problems.", 
        "author": "Jida Huang and Liang Gao and Xinyu Li", 
        "keyword": "Teaching-learning process\", \"Cuckoo search\", \"TLCS\", \"Co-evolutionary\", \"Parameter optimization", 
        "title": "An effective teaching-learning-based cuckoo search algorithm for parameter optimization problems in structure designing and machining processes"
    }, 
    {
        "abstract": "Abstract Due to its ability to eliminate the visual ambiguities in single-shot algorithms, video-based person re-identification has received an increasing focus in computer vision. Visual ambiguities caused by variations in view angle, lighting, and occlusions make the re-identification problem extremely challenging. To overcome the ambiguities, most previous approaches often extract robust feature representations or learn a sophisticated feature transformation. However, most of these approaches ignore the effect of the impostors arising from annotation or tracking process. In this case, impostors are regarded as genuine and applied in training process, leading to the model drift problem. In order to reduce the risk of model drifting, we propose to automatically discover impostors in a multiple instance metric learning framework. Specifically, we propose a kNN based confidence score to evaluate how much an impostor invades the interested target and utilize it as a prior in the framework. In the meanwhile, we integrate an impostor rejection mechanism in the multiple instance metric learning framework to automatically discover impostors, and learn the semantical similarity metrics with the refined training set. Experiments show that the proposed system performs favorably against the state-of-the-art algorithms on two challenging datasets (iLIDS-VID and \\{PRID\\} 2011). We have improved the rank 1 recognition rate on iLIDS-VID and \\{PRID\\} 2011 dataset by 1.0% and 1.2%, respectively.", 
        "author": "Xiaokai Liu and Hongyu Wang and Jie Wang and Xiaorui Ma", 
        "keyword": "Person re-identification\", \"Graphical model\", \"Multiple instance metric learning\", \"Impostor rejection", 
        "title": "Person re-identification by multiple instance metric learning with impostor rejection"
    }, 
    {
        "abstract": "Abstract In supervised learning systems; only labeled samples are used for building a classifier that is then used to predict the class labels of the unlabeled samples. However, obtaining labeled data is very expensive, time consuming and difficult in real-life practical situations as labeling a data set requires the effort of a human expert. On the other side, unlabeled data are often plentiful which makes it relatively inexpensive and easier to obtain. Semi-Supervised Learning methods strive to utilize this plentiful source of unlabeled examples to increase the learning capacity of the classifier particularly when amount of labeled examples are restricted. Since \\{SSL\\} techniques usually reach higher accuracy and require less human effort, they attract a substantial amount of attention both in practical applications and theoretical research. A novel semi-supervised methodology is offered in this study. This algorithm utilizes a new method to predict the class labels of unlabeled examples in a corpus and incorporate them into the training set to build a better classifier. The approach presented here depends on a meaning calculation, which computes the words\u2019 meaning scores in the scope of classes. Meaning computation is constructed on the Helmholtz principle and utilized to various applications in the field of text mining like feature extraction, information retrieval and document summarization. Nevertheless, according to the literature, \\{ILBOM\\} is the first work which uses meaning calculation in a semi-supervised way to construct a semantic smoothing kernel for Support Vector Machines (SVM). Evaluation of the proposed methodology is done by performing various experiments on standard textual datasets. ILBOM's experimental results are compared with three baseline algorithms including \\{SVM\\} using linear kernel which is one of the most frequently used algorithms in text classification field. Experimental results show that labeling unlabeled instances based on meaning scores of words to augment the training set is valuable, and increases the classification accuracy on previously unseen test instances significantly.", 
        "author": "Berna Alt\u0131nel and Murat Can Ganiz and Banu Diri", 
        "keyword": "Text classification\", \"Semantic kernel\", \"Semi-supervised learning\", \"Instance labeling\", \"Helmholtz principle", 
        "title": "Instance labeling in semi-supervised learning with meaning values of words"
    }, 
    {
        "abstract": "Abstract Electronic nose (E-nose) is an intelligent system that we will use in this paper to distinguish different kinds of indoor pollutant gases. We usually need to obtain a large number of the labeled samples, and then E-nose can learn enough useful information from them which can help it make a right decision. In fact, it is always a time-consuming and laborious thing to label the unlabeled samples, and the numbers of collected unlabeled samples are often far greater than that of the labeled samples. On the other hand, if we only use a small number of labeled examples and ignore the valuable information included in the unlabeled samples, the E-nose learning system usually does not have a strong generalization. So an active learning (AL) algorithm based on improved query by committee (QBC) for \\{RBFNN\\} is proposed and applied to E-nose, which is called as EQBC-RBFNN. This technique efficiently combines \\{QBC\\} and \\{RBFNN\\} for E-nose training with both labeled and valuable unlabeled samples. And we employ this method to train the E-nose which is used to distinguish three indoor pollutant gases (toluene, formaldehyde and benzene). The results of data processing prove that in this way, the classification accuracy of the E-nose has been improved when unlabeled samples in application process are used to refine the E-nose compared to an E-nose trained only with labeled samples.", 
        "author": "Xue Jiang and Pengfei Jia and Rudan Luo and Bin Deng and Shukai Duan and Jia Yan", 
        "keyword": "Electronic nose\", \"Active learning\", \"Query by committee\", \"RBFNN\", \"Indoor pollution gas", 
        "title": "A novel electronic nose learning technique based on active learning: EQBC-RBFNN"
    }, 
    {
        "abstract": "Abstract Many computer vision problems involve exploring the synthesis and classification models that map images from the observed source space to a target space. Recently, one popular and effective method is to transform images from both source and target space into a shared single sparse domain, in which a synthesis model is established. Motivated by such a technique, this research attempts to explore an effective and robust linear function that maps the sparse representatio ns of images from the source space to the target space, and simultaneously develop a linear classifier on such a coupled space with both supervised and semi-supervised learning. In order to capture the sparse structure shared by each class, we represent this mapping using a linear transformation with the constraint of sparsity. The performance of our proposed method is evaluated on several benchmark image datasets for low-resolution faces/digits classification and super-resolution, and the experimental results verify the effectiveness of the proposed method.", 
        "author": "Xian Wei and Yuanxiang Li and Hao Shen and Weidong Xiang and Yi Lu Murphey", 
        "keyword": "Sparse representation\", \"Joint dictionary learning\", \"Sparse linear transformation\", \"Geometric keywords =ptimization\", \"Low-resolution image classification", 
        "title": "Joint learning sparsifying linear transformation for low-resolution image synthesis and recognition"
    }, 
    {
        "abstract": "Abstract \\{ALAMO\\} is a computational methodology for learning algebraic functions from data. Given a data set, the approach begins by building a low-complexity, linear model composed of explicit non-linear transformations of the independent variables. Linear combinations of these non-linear transformations allow a linear model to better approximate complex behavior observed in real processes. The model is refined, as additional data are obtained in an adaptive fashion through error maximization sampling using derivative-free optimization. Models built using \\{ALAMO\\} can enforce constraints on the response variables to incorporate first-principles knowledge. The ability of \\{ALAMO\\} to generate simple and accurate models for a number of reaction problems is demonstrated. The error maximization sampling is compared with Latin hypercube designs to demonstrate its sampling efficiency. ALAMO's constrained regression methodology is used to further refine concentration models, resulting in models that perform better on validation data and satisfy upper and lower bounds placed on model outputs.", 
        "author": "Zachary T. Wilson and Nikolaos V. Sahinidis", 
        "keyword": "Model selection\", \"Parametric regression\", \"Feature selection\", \"Mixed-integer optimization", 
        "title": "The \\{ALAMO\\} approach to machine learning"
    }, 
    {
        "abstract": "AbstractBackground and objective Dizziness is a major consequence of imbalance and vestibular dysfunction. Compared to surgery and drug treatments, balance training is non-invasive and more desired. However, training exercises are usually tedious and the assessment tool is insufficient to diagnose patient's severity rapidly. Methods An interactive virtual reality (VR) game-based rehabilitation program that adopted Cawthorne\u2013Cooksey exercises, and a sensor-based measuring system were introduced. To verify the therapeutic effect, a clinical experiment with 48 patients and 36 normal subjects was conducted. Quantified balance indices were measured and analyzed by statistical tools and a Support Vector Machine (SVM) classifier. Results In terms of balance indices, patients who completed the training process are progressed and the difference between normal subjects and patients is obvious. Conclusions Further analysis by \\{SVM\\} classifier show that the accuracy of recognizing the differences between patients and normal subject is feasible, and these results can be used to evaluate patients\u2019 severity and make rapid assessment.", 
        "author": "Shih-Ching Yeh and Ming-Chun Huang and Pa-Chun Wang and Te-Yung Fang and Mu-Chun Su and Po-Yi Tsai and Albert Rizzo", 
        "keyword": "Vestibular dysfunction\", \"Machine learning\", \"Virtual reality\", \"Assessment", 
        "title": "Machine learning-based assessment tool for imbalance and vestibular dysfunction with virtual reality rehabilitation system"
    }, 
    {
        "abstract": "Abstract The use of vibrational spectroscopy for diagnosis and staging of cancer is extremely attractive, promising many benefits over the currently used histopathology methods. The hypothesis underlying this approach is that cancers have characteristic biochemical fingerprints that can be captured using spectroscopy. To relate complex multivariate spectra to disease state, machine-learning methods are typically used to recognize diagnostic spectral patterns. This article provides an extensive review of this field. The average diagnostic performance of the reviewed studies is impressive (&gt;90% sensitivity and specificity) but most studies were small (&lt;40 samples). Furthermore, diagnostic performance has often been calculated using methods now known to be overoptimistic. We conclude that, if the combination of spectroscopy and machine learning is to translate into clinical practice, larger studies are needed and researchers should routinely provide spectral data in support of their publications so that the data can be reanalyzed by other groups.", 
        "author": "Martina Sattlecker and Nicholas Stone and Conrad Bessant", 
        "keyword": "Biochemical fingerprint\", \"Cancer diagnosis\", \"Cancer staging\", \"Data analysis\", \"Machine keywords =earning\", \"Sensitivity\", \"Specificity\", \"Spectroscopy\", \"Validation\", \"Vibrational spectroscopy", 
        "title": "Current trends in machine-learning methods applied to spectroscopic cancer diagnosis"
    }, 
    {
        "abstract": "Abstract PM2.5 concentration have received considerable attention from meteorologists, who are able to notify the public and take precautionary measures to prevent negative effects on health. Therefore, establishing an efficient early warning system plays a critical role in fostering public health in heavily polluted areas. In this study, ensemble empirical mode decomposition and least square support vector machine (EEMD-LSSVM) based on Phase space reconstruction (PSR) is proposed for day-ahead PM2.5 concentration prediction, according to the application of a decomposition-ensemble learning paradigm. The main methods of the proposed model mainly include: first, \\{EEMD\\} is presented to decompose the original data of PM2.5 concentration into some intrinsic model functions (IMFs); second, \\{PSR\\} is applied to determine the input form of each extracted component; third, LSSVM, an effective forecasting tool, is used to predict all reconstructed components independently; finally, another \\{LSSVM\\} is employed to aggregate all predicted components into ensemble results for the final prediction. The empirical results show that this proposed model can outperform the comparison models and can significantly improve the prediction performance in terms of higher predictive and directional accuracy.", 
        "author": "Mingfei Niu and Kai Gan and Shaolong Sun and Fengying Li", 
        "keyword": "PM2.5 concentration forecasting\", \"Decomposition-ensemble learning paradigm\", \"EEMD\", \"PSR\", \"LSSVM", 
        "title": "Application of decomposition-ensemble learning paradigm with phase space reconstruction for day-ahead PM2.5 concentration forecasting"
    }, 
    {
        "abstract": null, 
        "author": "Kenji Suzuki and Luping Zhou and Qian Wang", 
        "keyword": null, 
        "title": "Machine learning in medical imaging"
    }, 
    {
        "abstract": null, 
        "author": "Marcos Rodrigues and Juan de la Riva", 
        "keyword": "Machine learning\", \"Model\", \"Wildfire\", \"Random Forest\", \"Boosted Regression Tree\", \"Support Vector Machine", 
        "title": "An insight into machine-learning algorithms to model human-caused wildfire occurrence"
    }, 
    {
        "abstract": "Abstract Patch-level image representation is very important for object classification and detection, since it is robust to spatial transformation, scale variation, and cluttered background. Many existing methods usually require fine-grained supervisions (e.g., bounding-box annotations) to learn patch features, which requires a great effort to label images may limit their potential applications. In this paper, we propose to learn patch features via weak supervisions, i.e., only image-level supervisions. To achieve this goal, we treat images as bags and patches as instances to integrate the weakly supervised multiple instance learning constraints into deep neural networks. Also, our method integrates the traditional multiple stages of weakly supervised object classification and discovery into a unified deep convolutional neural network and optimizes the network in an end-to-end way. The network processes the two tasks object classification and discovery jointly, and shares hierarchical deep features. Through this jointly learning strategy, weakly supervised object classification and discovery are beneficial to each other. We test the proposed method on the challenging \\{PASCAL\\} \\{VOC\\} datasets. The results show that our method can obtain state-of-the-art performance on object classification, and very competitive results on object discovery, with faster testing speed than competitors.", 
        "author": "Peng Tang and Xinggang Wang and Zilong Huang and Xiang Bai and Wenyu Liu", 
        "keyword": "Patch feature learning\", \"Multiple instance learning\", \"Weakly supervised learning\", \"Convolutional keywords =eural network\", \"End-to-end\", \"Object classification\", \"Object discovery", 
        "title": "Deep Patch Learning for Weakly Supervised Object Classification and Discovery"
    }, 
    {
        "abstract": "Abstract The task of segmenting nuclei and cytoplasm in Papanicolau smear images is one of the most challenging tasks in automated cervix cytological analysis owing to the high degree of overlapping, the multiform shape of the cells and their complex structures resulting from inconsistent staining, poor contrast, and the presence of inflammatory cells. This article presents a robust variational segmentation framework based on superpixelwise convolutional neutral network and a learned shape prior enabling an accurate analysis of overlapping cervical mass. The cellular components of Pap image are first classified by automatic feature learning and classification model. Then, a learning shape prior model is employed to delineate the actual contour of each individual cytoplasm inside the overlapping mass. The shape prior is dynamically modeled during the segmentation process as a weighted linear combination of shape templates from an over-complete shape dictionary under sparsity constraints. We provide quantitative and qualitative assessment of the proposed method using two databases of 153 cervical cytology images, with 870 cells in total, synthesised by accumulating real isolated cervical cells to generate overlapping cellular masses with a varying number of cells and degree of overlap. The experimental results have demonstrated that our methodology can successfully segment nuclei and cytoplasm from highly overlapping mass. Our segmentation is also competitive when compared to the state-of-the-art methods.", 
        "author": "Afaf Tareef and Yang Song and Heng Huang and Yue Wang and Dagan Feng and Mei Chen and Weidong Cai", 
        "keyword": "Overlapping cell segmentation\", \"Convolutional neural network\", \"Feature learning\", \"Sparse keywords =pproximation\", \"Level set evolution", 
        "title": "Optimizing the cervix cytological examination based on deep learning and dynamic shape modeling"
    }, 
    {
        "abstract": "Abstract Human age estimation is an important research topic and has found its applications in such scenarios as commodity recommendation and security monitoring. The design of existing estimators generally follows a same pipeline, i.e., an estimator is built from a given training dataset and then evaluated on a holdout testing set from the same dataset to display its effectiveness. In doing so, an implicit assumption is that both training and testing sets should share the same age distribution and feature representation, consequently-meaning that (1) once the age of a face image to be tested is outside the age range of training set, a mis-estimation is naturally inevitable; (2) an estimator built on a specific dataset usually cannot be directly applied to make evaluations on other datasets, because the dimensions and types of their feature representations are usually different (i.e., these datasets are heterogeneous). That is, existing methods can not be directly employed to perform cross-heterogeneous-dataset age estimation. To the best of our knowledge, the age distributions of existing aging datasets are usually not consistent but complementary to each other. Motivated by such a complementarity characteristic of different datasets in age distributions, we develop a so-called correlation component manifold space learning (CCMSL) to first learn a common feature space by capturing the correlations between the heterogeneous databases, and then in the resulting space establish a single age estimator across such heterogeneous datasets through correlation representation learning (CRL). As a result, not only can the age-distribution-incompleteness of individual aging datasets be compensated, but also the discriminating ability of the estimator be reinforced. Finally, experimental results demonstrate the superiority of the proposed methods.", 
        "author": "Qing Tian and Songcan Chen", 
        "keyword": "Age estimation\", \"Cross-heterogeneous-database\", \"Correlation component manifold space learning\", \"Correlation representation learning", 
        "title": "Cross-heterogeneous-database age estimation through correlation representation learning"
    }, 
    {
        "abstract": null, 
        "author": "Lin Gui and Yu Zhou and Ruifeng Xu and Yulan He and Qin Lu", 
        "keyword": "Sentiment classification\", \"Representation learning\", \"Network embedding\", \"Product reviews", 
        "title": "Learning representations from heterogeneous network for sentiment classification of product reviews"
    }, 
    {
        "abstract": "Abstract In this paper, we propose a novel bottom-up saliency detection algorithm to effectively detect salient objects. Different from most existing methods that are not robust to complex scenes, we utilize multi-graph learning to take various scenes into consideration. First, multiple features are used to represent superpixels, and then measured by multiple distance metrics to construct multiple graphs. The motivation is to take advantage of their complementary information to cope with different environments. Second, fixation and boundary cues are respectively used as foreground and background seeds. The fixation is effective for crowded backgrounds because of the observation that regions within eye fixations are very likely the image foreground. Third, we integrate the multiple graphs and seeds into a regularized and optimized multi-graph based learning framework to effectively generate foreground-based and background-based saliency maps. Finally, we integrate these two saliency maps to obtain a more smooth and accurate saliency map. Extensive experiments are conducted on five benchmark datasets. Experimental results show that the proposed bottom-up saliency detection method yields comparable or better results against the state-of-the-art methods, and is robust to both cluttered and clean scenes.", 
        "author": "Shiqi Li and Cheng Zeng and Yan Fu and Shiping Liu", 
        "keyword": "Salient object detection\", \"Multi-graph learning\", \"Superpixel\", \"Fixation and boundary cues", 
        "title": "Optimizing multi-graph learning based salient object detection"
    }, 
    {
        "abstract": "Abstract This study proposes an adaptive-learning-based method for machine faulty detection and health degradation monitoring. The kernel of the proposed method is an \u201cevolving\u201d model that uses an unsupervised online learning scheme, in which an adaptive hidden Markov model (AHMM) is used for online learning the dynamic health changes of machines in their full life. A statistical index is developed for recognizing the new health states in the machines. Those new health states are then described online by adding of new hidden states in AHMM. Furthermore, the health degradations in machines are quantified online by an AHMM-based health index (HI) that measures the similarity between two density distributions that describe the historic and current health states, respectively. When necessary, the proposed method characterizes the distinct operating modes of the machine and can learn online both abrupt as well as gradual health changes. Our method overcomes some drawbacks of the \\{HIs\\} (e.g., relatively low comprehensibility and applicability) based on fixed monitoring models constructed in the offline phase. Results from its application in a bearing life test reveal that the proposed method is effective in online detection and adaptive assessment of machine health degradation. This study provides a useful guide for developing a condition-based maintenance (CBM) system that uses an online learning method without considerable human intervention.", 
        "author": "Jianbo Yu", 
        "keyword": "Machine faulty detection\", \"Health degradation monitoring\", \"Adaptive learning\", \"Hidden Markov model", 
        "title": "Adaptive hidden Markov model-based online learning framework for bearing faulty detection and performance degradation monitoring"
    }, 
    {
        "abstract": "Abstract Finger vein recognition has drawn increasing attention from biometrics community due to its security and convenience. In this paper, a novel discriminative binary codes (DBC) learning method is proposed for finger vein recognition. First of all, subject relation graph is built to capture correlations among subjects. Based on the relation graph, binary templates are transformed to describe vein characteristics of subjects. To ensure that templates are discriminative and representative, graph transform is formulated into an optimization problem, in which the distance between templates from different subjects is maximized and templates provide maximum information about subjects. At last, supervised information for training instances is provided by the obtained binary templates, and \\{SVMs\\} are trained as the code learner for each bit. Compared with existing binary codes for finger vein recognition, \\{DBC\\} are more discriminative and shorter. In addition, they are generated with considering the relationships among subjects which may be useful to improve performance. Experimental results on PolyU database and \\{MLA\\} database demonstrate the effectiveness and efficiency of \\{DBC\\} for finger vein recognition and retrieval.", 
        "author": "Xiaoming Xi and Lu Yang and Yilong Yin", 
        "keyword": "Biometric recognition\", \"Finger vein recognition\", \"Discriminative binary codes learning", 
        "title": "Learning discriminative binary codes for finger vein recognition"
    }, 
    {
        "abstract": "Abstract Recently, as the building block of deep generative models such as Deep Belief Networks (DBNs), Restricted Boltzmann Machines (RBMs) have attracted much attention. \\{RBM\\} is a Markov Random Field (MRF) associated with a bipartite undirected graph which is famous for powerful expression and tractable inference. While training an RBM, we need to sample from the model. The larger the mixing rate is, the smaller the bias of the samples is. However, neither Gibbs sampling based training methods such as Contrastive Divergence (CD) nor Parallel Tempering based training methods can achieve satisfying mixing rate, which causes poor rendering of the diversity of the modes captured by these trained models. This property may hinder the existing methods to approximate the likelihood gradient. In order to alleviate this problem, we attempt to introduce Tempered Transition, an advanced tempered Markov Chain Monte Carlo method, into training \\{RBMs\\} to replace Gibbs sampling or Parallel Tempering for sampling from RBMs. Experimental results show that our proposed method outperforms the existing methods to achieve better mixing rate and to help approximate the likelihood gradient.", 
        "author": "Jungang Xu and Hui Li and Shilong Zhou", 
        "keyword": "Restricted Boltzmann machines\", \"Tempered transition\", \"Mixing rate\", \"Deep learning", 
        "title": "Improving mixing rate with tempered transition for learning restricted Boltzmann machines"
    }, 
    {
        "abstract": "Abstract This paper presents a learned feature based framework for both outdoor and indoor scene labeling. This framework is combined with a discriminative feature learning process to produce the posteriors of every pixel and a novel strategy to improve the global label consistency of a scene. First, we use Convolutional Neural Networks (ConvNets) to learn the most relevant features of a scene at the multi-scale superpixel level. The effect of both trained and general ConvNets features for our scene labeling framework are investigated. Then, based on the predicted posteriors from the learned features, we propose an algorithm called Region Consistency Activation (RCA) to iteratively improve the global label consistency at different levels of the Ultrametric Contour Map (UCM). In addition, we propose a strategy to make the hyper-parameters of \\{RCA\\} adaptive to the test images, which results in a better generalization ability compared with the hyper-parameters tuning based RCA. Our scene labeling framework were rigorously tested on three popular scene labeling datasets: Stanford Background, \\{SIFT\\} Flow and NYU-Depth V2. Experiments show that our proposed method consistently produces better accuracy and visual consistency compared with the state-of-the-art methods for both outdoor and indoor scenes.", 
        "author": "Yandong Li and Ferdous Sohel and Mohammed Bennamoun and Hang Lei", 
        "keyword": "Scene labelling\", \"Feature learning\", \"Convolutional Neural Networks", 
        "title": "Discriminative feature learning and region consistency activation for robust scene labeling"
    }, 
    {
        "abstract": "Abstract A number of computer vision problems such as facial age estimation, crowd counting and pose estimation can be solved by learning regression mapping on low-level imagery features. We show that visual regression can be substantially improved by two-stage regression where imagery features are first mapped to an attribute space which explicitly models latent correlations across continuously-changing output. We propose an approach to automatically discover \u201cspectral attributes\u201d which avoids manual work required for defining hand-crafted attribute representations. Visual attribute regression outperforms direct visual regression and our spectral attribute visual regression achieves state-of-the-art accuracy in multiple applications.", 
        "author": "Ke Chen and Kui Jia and Zhaoxiang Zhang and Joni-Kristian K\u00e4m\u00e4r\u00e4inen", 
        "keyword": "Facial age estimation\", \"Crowd counting\", \"Head pose estimation\", \"Spectral learning\", keywords =Attributes\", \"Regression", 
        "title": "Spectral attribute learning for visual regression"
    }, 
    {
        "abstract": "Abstract Pervasive social networking (PSN) provides instant social activities such as communications and gaming, which attracts a growing attention. Under this circumstance, the study and analysis of users\u2019 behaviors has a profound meaning, which may be extended to other relevant fields. In this article, we define and quantify users\u2019 patterns to study social behaviors, after discussing and reconsidering social characteristics in PSN. Meanwhile, we treat \\{PSN\\} as a market, based on the standpoint that data can be priced and tradable. After analyzing its market structure, we describe \\{PSN\\} as a monopolistically competitive market, which contains multiple providers selling specialized goods. Afterwards, we study the social behaviors in this market from an economic perspective, namely applying market models. Finally, decentralized deep reinforcement learning is proposed to estimate users\u2019 patterns and to solve market models, the prisoner's dilemma and the Cournot model to be specific. Simulation results demonstrate the flexibility and efficiency of our algorithms.", 
        "author": "Yue Zhang and Bin Song and Peng Zhang", 
        "keyword": "Decentralized deep reinforcement learning\", \"Market models\", \"Monopolistically competitive market\", keywords =Pervasive social networking\", \"Social behavior\", \"Users' patterns", 
        "title": "Social behavior study under pervasive social networking based on decentralized deep reinforcement learning"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel method for the electrocardiographic (ECG) beat classification via deterministic learning. The dynamics of \\{ECG\\} beats is used as a unique feature for \\{ECG\\} beat classification, which is fundamentally different from the time/frequency domain features used in literature. It is the essential feature of \\{ECG\\} beats, and contains complete information of \\{ECG\\} beats. Precisely, the deterministic learning allows us to model and represent the dynamics of a training beat set as constant radial basis function (RBF) networks. As the classification measure, a set of errors is further obtained through the comparison between the test beat and the estimators constructed by the \\{RBF\\} networks. \\{ECG\\} records taken from the MIT-BIH (Massachusetts Institute of Technology-Beth Israel Hospital) arrhythmia database are selected to test the proposed method. With 5% beats used as training beats, the overall accuracies are 97.78% and 97.21% for global and patient-adapting beat classification, respectively. These results indicate the proposed method is reliable and efficient for \\{ECG\\} beat classification.", 
        "author": "Xunde Dong and Cong Wang and Wenjie Si", 
        "keyword": "\\{ECG\\} beat classification\", \"Modeling\", \"Dynamics\", \"Pattern recognition\", \"Deterministic learning", 
        "title": "\\{ECG\\} beat classification via deterministic learning"
    }, 
    {
        "abstract": "Abstract Online pairwise learning algorithms with general convex loss functions without regularization in a Reproducing Kernel Hilbert Space (RKHS) are investigated. Under mild conditions on loss functions and the RKHS, upper bounds for the expected excess generalization error are derived in terms of the approximation error when the stepsize sequence decays polynomially. In particular, for Lipschitz loss functions such as the hinge loss, the logistic loss and the absolute-value loss, the bounds can be of order O ( T \u2212 1 3 log T ) after T iterations, while for the least squares loss, the bounds can be of order O ( T \u2212 1 4 log T ) . In comparison with previous works for these algorithms, a broader family of convex loss functions is studied here, and refined upper bounds are obtained.", 
        "author": "Junhong Lin and Yunwen Lei and Bo Zhang and Ding-Xuan Zhou", 
        "keyword": "Learning theory\", \"Online learning\", \"Reproducing Kernel Hilbert Space\", \"Pairwise learning", 
        "title": "Online pairwise learning algorithms with convex loss functions"
    }, 
    {
        "abstract": "Abstract Conventional machine learning methods can be used to identify protein\u2013protein interaction sites and study the gene regulatory networks and functions. However, when applied to large datasets, the computational complexities of these methods become a major drawback. With a significantly reduced computational complexity, the Extreme Learning Machines provide an attractive balance between computational time and generalization performance. In the method proposed in this paper, after searching for interfacial residues using a dynamic strategy and extracting spatially neighboring residue profiles for a set of 563 non-redundant protein chains, we implement the interface prediction either on multi-chain sets or on single-chain sets, using the two methods Extreme Learning Machines and support vector machines for a comparable study. As a consequence, in both multi-chain and single-chain cases Extreme Learning Machines tend to obtain higher Recall values than support vector machines, and in the multi-chain case Extreme Learning Machines as well show a remarkable advantage in the computational speed.", 
        "author": "Debby D. Wang and Ran Wang and Hong Yan", 
        "keyword": "Protein\u2013protein interaction sites\", \"Extreme Learning Machines\", \"Support vector machines\", \"Residue sequence profile", 
        "title": "Fast prediction of protein\u2013protein interaction sites based on Extreme Learning Machines"
    }, 
    {
        "abstract": "Abstract Prevalent hardware trends towards parallel architectures and algorithms create a growing demand for graduate students familiar with the programming of concurrent software. However, learning parallel programming is challenging due to complex communication and memory access patterns as well as the avoidance of common pitfalls such as dead-locks and race conditions. Hence, the learning process has to be supported by adequate software solutions in order to enable future computer scientists and engineers to write robust and efficient code. This paper discusses a selection of well-known parallel algorithms based on C++11 threads, OpenMP, MPI, and \\{CUDA\\} that can be interactively embedded in an \\{HPC\\} or parallel computing lecture using a unified framework for the automated evaluation of source code\u2014namely the \u201cSystem for \\{AUtomated\\} Code Evaluation\u201d (SAUCE). \\{SAUCE\\} is free software licensed under AGPL-3.0 and can be downloaded at https://github.com/moschlar/SAUCE free of charge.", 
        "author": "Christian Hundt and Moritz Schlarb and Bertil Schmidt", 
        "keyword": "Parallel programming\", \"Black box testing\", \"Web application\", \"Teaching and learning", 
        "title": "SAUCE: A web application for interactive teaching and learning of parallel programming"
    }, 
    {
        "abstract": "Abstract One of the technical challenges in dynamic magnetic resonance imaging (dMRI) is to obtain \\{MR\\} images with high spatiotemporal resolution in a short scan time. Current state-of-the-art recovery algorithms exploit both spatial and temporal sparsity in dMRI to improve the reconstruction quality. In this paper, we proposed a novel algorithm based on 4-frame parallel dictionary learning and dynamic total variation (PDLDTV) for real-time dMRI reconstruction. The dMRI sequence was decomposed into 4-frame subsets and each subset included the first frame (obtained with more k-space sampling for reference to later frames) and any adjacent three frames. A 3D patch-based dictionary learning algorithm and a dynamic total variation algorithm were used to exploit the spatiotemporal sparsity in each subset. High algorithm speed was required for our real-time reconstruction, and a primal-dual algorithm was used to solve the challenging problem. Experiments over two cardiac dMRI sequences indicated that the proposed 4-frame \\{PDLDTV\\} showed better reconstruction performance than the state-of-the-art online and offline methods such as DTV, k-t SLR, and DLTG.", 
        "author": "Yang Wang and Ning Cao and Zuojun Liu and Yudong Zhang", 
        "keyword": "Dynamic magnetic resonance imaging\", \"Dictionary learning\", \"Dynamic total variation\", \"Primal-dual algorithm", 
        "title": "Real-time dynamic \\{MRI\\} using parallel dictionary learning and dynamic total variation"
    }, 
    {
        "abstract": "Abstract In materials science, good representations of materials are important for use with prediction models in order to ensure accurate prediction of the properties of the output. In this paper, in order to address this issue, we use a learning system, linear guided autoencoder (LGAE) we call, which consists of an autoencoder and a linear predictor. For the autoencoder, we adopt a variant of the denoising autoencoder. In the LGAE, the learning addresses the unsupervised and supervised tasks simultaneously. Thus, the \\{LGAE\\} can be regarded as a form of nonlinear partial least squares (PLS) regression. Previous studies have not found the optimal solution for the encoder for an objective that contains both tasks. Our main contributions are a first-order approximation of the optimal solution and determination of the condition for linear solution that applies to the \\{LGAE\\} after training, in order to acquire knowledge from the nonlinear model (i.e., the LGAE). The main drawback of nonlinear \\{PLS\\} regression is that it is difficult to interpret the latent representation. Therefore, we propose a technical method for interpreting the latent representation. Experiments on benchmark datasets are conducted in order to compare the \\{LGAE\\} with kernel \\{PLS\\} regression, which is a powerful nonlinear \\{PLS\\} regression method. We also applied the \\{LGAE\\} to a dataset of methane storage materials in order to interpret the methane uptake based on the input variables and obtained reasonable results.", 
        "author": "Hiroshi Ohno", 
        "keyword": "Representation learning\", \"Denoising autoencoders\", \"Neural networks\", \"Partial least squares keywords =egression\", \"Linear model\", \"Materials informatics", 
        "title": "Linear guided autoencoder: Representation learning with linearity"
    }, 
    {
        "abstract": "Abstract The ability to recognize pedestrians across multiple camera views is of great importance for many applications in the broad field of video surveillance. Due to the absence of the topology and calibration of distributed cameras, spatio-temporal reasoning becomes unavailable, and therefore only appearance information can be used in real-world scenarios, especially for disjoint camera views. This paper proposes a novel approach based on important salient feature and multi-category transfer incremental learning to recognize pedestrians for long-term tracking in multi-camera networks without space-time cues. An accurate and robust model can be built for pedestrian recognition using few samples. We first propose a novel multi-level important salient feature detection method (MImSF11 \\{MImSF\\} is the abbreviation of Multi-level Important Salient Feature detection method ) to formulate the appearance model. Due to environmental changes, the appearances of the pedestrians under the camera can change over time and across space, therefore the classification performance may be impaired. Hence, the appearance models should be continuously updated. We then adopt a novel object recognition multicategory incremental modeling algorithm (ORMIM22 \\{ORMIM\\} is the abbreviation of Object Recognition Multicategory Incremental Modeling algorithm ) to update the appearance model adaptively and recognize the pedestrians based on a classification approach. One of the major advantages of the proposed method is that it can identify new target objects that were never learned in the primary model while improving the matching accuracy of what has been learned. We conduct extensive experiments on CAVIAR, \\{ISCAPS\\} databases and our own databases where the camera views are disjoint and the appearance of objects changes significantly due to variations in the camera viewpoint, illumination, weather and poses. The experiments demonstrate that our proposed model is superior to that of existing classification-based recognition methods in terms of accuracy, robustness and computation efficiency. The developed methodology can be used in retrieval, matching and other real-time video surveillance applications.", 
        "author": "Huiyan Wang and Yixiang Yan and Jing Hua and Yutao Yang and Xun Wang and XiaoLan Li and John Robert Deller and Guofeng Zhang and Hujun Bao", 
        "keyword": "Video pedestrian recognition\", \"Collaborative multi-camera surveillance\", \"MImSF\", \"ORMIM\", keywords =Incremental learning\", \"Non-overlapping camera network", 
        "title": "Pedestrian recognition in multi-camera networks using multilevel important salient feature and multicategory incremental learning"
    }, 
    {
        "abstract": "Abstract An enhanced scatter search (eSS) with combined opposition-based learning algorithm is proposed to solve large-scale parameter estimation in kinetic models of biochemical systems. The proposed algorithm is an extension of eSS with three important improvements in terms of: reference set (RefSet) formation, RefSet combination, and RefSet intensification. Due to the difficulty in estimating kinetic parameter values in the presence of noise and large number of parameters (high-dimension), the aforementioned eSS mechanisms have been improved using combination of quasi-opposition and quasi-reflection, which were under the family of opposition-based learning scheme. The proposed algorithm is tested using one set of benchmark function each from large-scale global optimization (LSGO) problem as well as parameter estimation problem. The \\{LSGO\\} problem consists of 11 functions with 1000 dimensions. For parameter estimation, around 116 kinetic parameters in Chinese hamster ovary (CHO) cells and central carbon metabolism of E. coli are estimated. The results revealed that the proposed algorithm is superior to eSS and other competitive algorithms in terms of its efficiency in minimizing objective function value and having faster convergence rate. The proposed algorithm also required lower computational resources, especially number of function evaluations performed and computation time. In addition, the estimated kinetic parameter values obtained from the proposed algorithm produced the best fit to a set of experimental data.", 
        "author": "Muhammad Akmal Remli and Safaai Deris and Mohd Saberi Mohamad and Sigeru Omatu and Juan Manuel Corchado", 
        "keyword": "Bioinformatics\", \"Artificial intelligence\", \"Metabolic engineering\", \"Evolutionary algorithm\", keywords =Scatter search\", \"Opposition-based learning", 
        "title": "An enhanced scatter search with combined opposition-based learning for parameter estimation in large-scale kinetic models of biochemical systems"
    }, 
    {
        "abstract": "Abstract Activity recognition based on mobile embedded accelerometer is very important for developing human-centric pervasive applications such as healthcare, personalized recommendation and so on. However, the distribution of accelerometer data is heavily affected by varying users. The performance will degrade when the model trained on one person is used to others. To solve this problem, we propose a fast and accurate cross-person activity recognition model, known as TransRKELM (Transfer learning Reduced Kernel Extreme Learning Machine) which uses \\{RKELM\\} (Reduced Kernel Extreme Learning Machine) to realize initial activity recognition model. In the online phase OS-RKELM (Online Sequential Reduced Kernel Extreme Learning Machine) is applied to update the initial model and adapt the recognition model to new device users based on recognition results with high confidence level efficiently. Experimental results show that, the proposed model can adapt the classifier to new device users quickly and obtain good recognition performance.", 
        "author": "Wan-Yu Deng and Qing-Hua Zheng and Zhong-Min Wang", 
        "keyword": "Extreme learning machine\", \"Reduced kernel extreme learning machine\", \"Activity recognition\", \"Support vector machine", 
        "title": "Cross-person activity recognition using reduced kernel extreme learning machine"
    }, 
    {
        "abstract": "Abstract Two-sided assembly lines are usually found in the factories which produce large-sized products. In most literatures, the task times are assumed to be deterministic while these tasks may have varying operation times in real application, causing the reduction of performance or even the infeasibility of the schedule. Moreover, the ignorance of some specific constraints including positional constraints, zoning constraints and synchronism constraints will result in the invalidation of the schedule. To solve this stochastic two-sided assembly line balancing problem with multiple constraints, we propose a hybrid teaching-learning-based optimization (HTLBO) approach which combines both a novel teaching-learning-based optimization algorithm for global search and a variable neighborhood search with seven neighborhood operators for local search. Especially, a new priority-based decoding approach is developed to ensure that the selected tasks satisfy most of the constraints identified by multiple thresholds of the priority value and to reduce the idle times related to sequence-dependence among tasks. Experimental results on benchmark problems demonstrate both remarkable efficiency and universality of the developed decoding approach, and the comparison among 11 algorithms shows the effectiveness of the proposed HTLBO.", 
        "author": "Qiuhua Tang and Zixiang Li and LiPing Zhang and Chaoyong Zhang", 
        "keyword": "Stochastic two-sided assembly line balancing\", \"Teaching-learning-based Optimization\", \"Variable keywords =eighborhood search\", \"Multiple constraints", 
        "title": "Balancing stochastic two-sided assembly line with multiple constraints using hybrid teaching-learning-based optimization algorithm"
    }, 
    {
        "abstract": "Abstract This study extends the state of the art of deep learning convolutional neural network (CNN) to the classification of video images of echocardiography, aiming at assisting clinicians in diagnosis of heart diseases. Specifically, the architecture of neural networks is established by embracing hand-crafted features within a data-driven learning framework, incorporating both spatial and temporal information sustained by the video images of the moving heart and giving rise to two strands of two-dimensional convolutional neural network (CNN). In particular, the acceleration measurement along the time direction at each point is calculated using dense optical flow technique to represent temporal motion information. Subsequently, the fusion of both networks is conducted via linear integrations of the vectors of class scores obtained from each of the two networks. As a result, this architecture maintains the best classification results for eight viewpoint categories of echo videos with 92.1% accuracy rate whereas 89.5% is achieved using only single spatial \\{CNN\\} network. When concerning only three primary locations, 98% of accuracy rate is realised. In addition, comparisons with a number of well-known hand-engineered approaches are also performed, including 2D KAZE, 2D \\{KAZE\\} with Optical Flow, 3D KAZA, Optical Flow, 2D \\{SIFT\\} and 3D SIFT, which delivers accuracy rate of 89.4%, 84.3%, 87.9%, 79.4%, 83.8% and 73.8% respectively.", 
        "author": "Xiaohong Gao and Wei Li and Martin Loomes and Lianyi Wang", 
        "keyword": "Deep learning\", \"Classification architecture for echo video images\", \"Convolutional neural keywords =etwork\", \"Echocardiography\", \"KAZE\", \"SIFT\", \"SURF", 
        "title": "A fused deep learning architecture for viewpoint classification of echocardiography"
    }, 
    {
        "abstract": "Abstract This study proposes a novel approach to the pre-launch forecasting of new product demand based on the Bass model and statistical and machine learning algorithms. The Bass model is used to explain the diffusion process of products while statistical and machine learning algorithms are employed to predict two Bass model parameters prior to launch. Initially, two types of databases (DBs) are constructed: a product attribute \\{DB\\} and a product diffusion DB. Taking the former as inputs and the latter as outputs, single prediction models are developed using six regression algorithms, on the basis of which an ensemble prediction model is constructed in order to enhance predictive power. The experimental validation shows that most single prediction models outperform the conventional analogical method and that the ensemble model improves prediction accuracy further. Based on the developed models, an illustrative example of 3D \\{TV\\} is provided.", 
        "author": "Hakyeon Lee and Sang Gook Kim and Hyun-woo Park and Pilsung Kang", 
        "keyword": "Pre-launch forecasting\", \"Bass model\", \"Multivariate linear regression\", \"Machine learning\", \"Ensemble", 
        "title": "Pre-launch new product demand forecasting using the Bass model: A statistical and machine learning-based approach"
    }, 
    {
        "abstract": "Abstract Accurate weather information is required to assess the performance of sustainable buildings. Currently such performance is assessed using Typical Meteorological Year (TMY) weather files. \\{TMY3\\} is the latest \\{TMY\\} file introduced by Department of Energy (DOE) and it represents the historical 30-year average of weather data more closely than any other available datasets. However, \\{TMY3\\} data reflects the past and do not accurately forecast weather information thus leading to erroneous estimation of performance and economic feasibility. Therefore, more accurate methods are necessary to generate weather files so as to design buildings for sustainability and resilience. This article proposes an effective hybrid modeling methodology based on support vector machine regression and probability estimation to predict long term future weather variables. The methodology has been validated by using a dataset containing historical solar irradiance data for 54 years (1961\u20132014) for Cincinnati, Ohio. By implementing the proposed technique multiple models were trained with different segments of the dataset, which were used to predict the hourly solar irradiance for 8, 9, 10 and 11 years respectively. Subsequently, the predicted data and the current \\{TMY3\\} data was compared with the actual historical data. The average increase in accuracy of the predicted over \\{TMY3\\} direct normal and diffuse horizontal components of solar irradiance was found to be 38.43% and 11.8%. These findings suggest that the long term accuracy of the proposed modeling technique is greater than the current state-of-the-art.", 
        "author": "Debaditya Chakraborty and Hazem Elzarka and Raj Bhatnagar", 
        "keyword": "Weather prediction\", \"Solar irradiance\", \"Energy efficiency\", \"Sustainability\", \"Resilience\", keywords =Support vector machine regression\", \"Probability estimation", 
        "title": "Generation of accurate weather files using a hybrid machine learning methodology for design and analysis of sustainable and resilient buildings"
    }, 
    {
        "abstract": "Abstract Photovoltaic arrays are the means to convert solar power into electricity, and a significant way to generate renewable and clean energy. To be efficient, a photovoltaic must generate constantly the maximum possible power and under different environmental conditions. Finding the maximum generated power has been a known issue in the industry using methods of classic control theory with very good results. However, those solutions are case-specific resulting to increased set-up effort. This work proposes a universal \\{RLMPPT\\} control method based on a reinforcement learning (RL) method that tracks and adjusts the maximum power point of a photovoltaic source without any prior knowledge. A Markov Decision Process (MDP) model for the Maximum Power Point Tracking (MPPT) photovoltaic process is defined and an \\{RL\\} algorithm is proposed and evaluated on a number of photovoltaic sources. The proposed \\{RLMPPT\\} control method has the advantage of being applicable to different \\{PV\\} sources with minimum set-up time. To evaluate the \\{RLMPPT\\} control method performance, a number of simulations run under different environmental and operating conditions and a comparison with the conventional method of Perturb and Observe (P&amp;O) is performed. Results show quick response and close to optimal behavior without requiring any prior knowledge.", 
        "author": "P. Kofinas and S. Doltsinis and A.I. Dounis and G.A. Vouros", 
        "keyword": "Photovoltaic systems\", \"Maximum power point tracking\", \"On line learning\", \"Reinforcement learning \\{MPPT\\} control method", 
        "title": "A reinforcement learning approach for \\{MPPT\\} control method of photovoltaic sources"
    }, 
    {
        "abstract": "Abstract In this paper we propose a method for logo recognition using deep learning. Our recognition pipeline is composed of a logo region proposal followed by a Convolutional Neural Network (CNN) specifically trained for logo classification, even if they are not precisely localized. Experiments are carried out on the FlickrLogos-32 database, and we evaluate the effect on recognition performance of synthetic versus real data augmentation, and image pre-processing. Moreover, we systematically investigate the benefits of different training choices such as class-balancing, sample-weighting and explicit modeling the background class (i.e. no-logo regions). Experimental results confirm the feasibility of the proposed method, that outperforms the methods in the state of the art.", 
        "author": "Simone Bianco and Marco Buzzelli and Davide Mazzini and Raimondo Schettini", 
        "keyword": "Logo recognition\", \"Deep Learning\", \"Convolutional Neural Network\", \"Data augmentation\", \"FlickrLogos-32", 
        "title": "Deep learning for logo recognition"
    }, 
    {
        "abstract": "Abstract This paper discusses the performance of a novel Coral Reefs Optimization \u2013 Extreme Learning Machine (CRO\u2013ELM) algorithm in a real problem of global solar radiation prediction. The work considers different meteorological data from the radiometric station at Murcia (southern Spain), both from measurements, radiosondes and meteorological models, and fully describes the hybrid CRO\u2013ELM to solve the prediction of the daily global solar radiation from these data. The algorithm is designed in such a way that the \\{ELM\\} solves the prediction problem, whereas the \\{CRO\\} evolves the weights of the neural network, in order to improve the solutions obtained. The experiments carried out have shown that the CRO\u2013ELM approach is able to obtain an accurate prediction of the daily global radiation, better than the classical ELM, and the Support Vector Regression algorithm.", 
        "author": "S. Salcedo-Sanz and C. Casanova-Mateo and A. Pastor-S\u00e1nchez and M. S\u00e1nchez-Gir\u00f3n", 
        "keyword": "Daily global solar radiation prediction\", \"Coral Reefs Optimization algorithm\", \"Extreme Learning Machines", 
        "title": "Daily global solar radiation prediction based on a hybrid Coral Reefs Optimization \u2013 Extreme Learning Machine approach"
    }, 
    {
        "abstract": "Abstract The goal of this article is to investigate how human participants allocate their limited time to decisions with different properties. We report the results of two behavioral experiments. In each trial of the experiments, the participant must accumulate noisy information to make a decision. The participants received positive and negative rewards for their correct and incorrect decisions, respectively. The stimulus was designed such that decisions based on more accumulated information were more accurate but took longer. Therefore, the total outcome that a participant could achieve during the limited experiments\u2019 time depended on her \u201cdecision threshold\u201d, the amount of information she needed to make a decision. In the first experiment, two types of trials were intermixed randomly: hard and easy. Crucially, the hard trials were associated with smaller positive and negative rewards than the easy trials. A cue presented at the beginning of each trial would indicate the type of the upcoming trial. The optimal strategy was to adopt a small decision threshold for hard trials. The results showed that several of the participants did not learn this simple strategy. We then investigated how the participants adjusted their decision threshold based on the feedback they received in each trial. To this end, we developed and compared 10 computational models for adjusting the decision threshold. The models differ in their assumptions on the shape of the decision thresholds and the way the feedback is used to adjust the decision thresholds. The results of Bayesian model comparison showed that a model with time-varying thresholds whose parameters are updated by a reinforcement learning algorithm is the most likely model. In the second experiment, the cues were not presented. We showed that the optimal strategy is to use a single time-decreasing decision threshold for all trials. The results of the computational modeling showed that the participants did not use this optimal strategy. Instead, they attempted to detect the difficulty of the trial first and then set their decision threshold accordingly.", 
        "author": "Arash Khodadadi and Pegah Fakhari and Jerome R. Busemeyer", 
        "keyword": "Sequential sampling models\", \"Opportunity cost\", \"Reward rate maximization\", \"Speed-accuracy keywords =rade-off\", \"Reinforcement learning", 
        "title": "Learning to allocate limited time to decisions with different expected outcomes"
    }, 
    {
        "abstract": "Abstract This paper investigates the H \u221e control problem for nonlinear systems with completely unknown dynamics and constrained control input by utilizing a novel data-driven reinforcement learning method. It is known that nonlinear H \u221e control problem relies on the solution of Hamilton-Jacobi-Isaacs (HJI) equation, which is essentially a nonlinear partial differential equation and generally impossible to be solved analytically. In order to overcome this difficulty, firstly, we propose a model-based simultaneous policy update algorithm to learn the solution of \\{HJI\\} equation iteratively and provide its convergence proof. Then, based on this model-based method, we develop a data-driven model-free algorithm, which only requires the real system sampling data generated by arbitrary different control inputs and external disturbances instead of accurate system models, and prove that these two algorithms are equivalent. To implement this model-free algorithm, three neural networks (NNs) are employed to approximate the iterative performance index function, control policy and disturbance policy, respectively, and the least-square approach is used to minimize the \\{NN\\} approximation residual errors. Finally, the proposed scheme is tested on the rotational/translational actuator nonlinear system.", 
        "author": "He Jiang and Huaguang Zhang and Yanhong Luo and Xiaohong Cui", 
        "keyword": "Reinforcement learning\", \"Adaptive dynamic programming\", \"Data-driven\", \"Neural networks", 
        "title": "H\u221e control with constrained input for completely unknown nonlinear systems using data-driven reinforcement learning method"
    }, 
    {
        "abstract": "Abstract Within the past few years, social media platforms such as Facebook, Twitter, and Sina Weibo, have gradually become important channels for information dissemination and communication. However, in the meantime, these platforms are prone to be potentially attacked by spammers, who usually propagate disgusted information such as phishing URLs, false news, and even pornography to other users. Despite rapid increase of social media spammers, the traditional spammer detection methods become less effective. In this paper, we present a novel semi-supervised social media spammer detection approach, making full use of the message content and user behavior as well as the social relation information. First, we adapt the original constrained NMF-based semi-supervised learning (CNMF) algorithm, nonnegative matrix factorization (NMF) by imposing a label information constrain and sparseness constrain. Second, we present a novel CNMF-based integral framework for social media spammer detection by implementing the collaborative factorization on the message content matrix and the user behavior and social relation information matrix. Moreover, we explore the iterative update rule (IUR) and optimization algorithm for the spammer detection model. In addition, its corresponding convergence is also proven. Extensive experiments are conducted on the real-world dataset from Sina Weibo, the experiment results demonstrate that our proposed model performs significantly better than the conventionally applied supervised classifiers for the spammer detection.", 
        "author": "Dingguo Yu and Nan Chen and Frank Jiang and Bin Fu and Aihong Qin", 
        "keyword": "Sina Weibo\", \"Spammer detection\", \"Nonnegative matrix factorization (NMF)\", \"Semi-supervised learning", 
        "title": "Constrained NMF-based semi-supervised learning for social media spammer detection"
    }, 
    {
        "abstract": "Abstract In this study, we propose two analysis dictionary learning algorithms for sparse representation with analysis model. The problem is formulated with the \u21131-norm regularizer and with two penalty terms on the analysis dictionary: the term of \u2212 log det ( \u03a9 T \u03a9 ) and the coherence penalty term. As the processing scheme, we employ a block coordinate descent framework, so that the overall problem is transformed into a set of minimizations of univariate subproblems with respect to a single-vector variable. Each subproblem is still nonsmooth, but it can be solved by a proximal operator and then the closed-form solutions can be obtained directly and explicitly. In particular, the coherence penalty, excluding excessively similar or repeated dictionary atoms, is solved at the same time as the dictionary update, thereby reducing the complexity. Furthermore, a scheme with a group of atoms is introduced in one proposed algorithm, which has a lower complexity. According to our analysis and simulation study, the main advantages of the proposed algorithms are their greater dictionary recovery ratios especially in the low-cosparsity case, and their faster running time of reaching the stable values of the dictionary recovery ratios and the recovery cosparsity compared with state-of-the-art algorithms. In addition, one proposed algorithm performs well in image denoising and in noise cancellation.", 
        "author": "Zhenni Li and Shuxue Ding and Takafumi Hayashi and Yujie Li", 
        "keyword": "Sparse representation model\", \"Analysis dictionary learning\", \"Block coordinate descent framework\", keywords =Incoherence\", \"Proximal operator", 
        "title": "Analysis dictionary learning using block coordinate descent framework with proximal operators"
    }, 
    {
        "abstract": "Abstract In this paper, we propose multiple kernel learning (MKL) based on three discriminant features to learn an efficient \\{P300\\} classifier to improve the accuracy of character recognition in a \\{P300\\} speller BCI. Three discriminant features are specified in raw samples and two morphological features, which can complement the \\{MKL\\} of a \\{P300\\} classification. A linear kernel is established for each discriminant feature. A kernel weight differentiates the linear kernel to both explore complementary information among the three discriminant features and weigh a contribution of each discriminant feature for the MKL. Here, the \u21131 norm regularization of the kernel weight ultimately enforces an optimal discriminant feature set of the \\{MKL\\} of a \\{P300\\} classification. The performance of the proposed method is then evaluated according to the size of the three discriminant feature sets that are generated from dataset \\{II\\} of \\{BCI\\} competition III. Compared to an existing SVM-based classification method, the proposed method consistently obtains better or similar accuracy in terms of character recognition, with a different execution time for the variable size of the three discriminant feature sets. Furthermore, the kernel weight of the raw samples was found to consistently be more dominant than the kernel weight of the two morphological features on the variable size of the three discriminant feature sets. This finding means that the two morphological features supplement the lack of the raw samples for the \\{MKL\\} of a \\{P300\\} classification. We ultimately could conclude that the proposed method is sufficiently robust to improve the accuracy of character recognition with a different time for the variable size of the three discriminant feature sets in a \\{P300\\} speller BCI.", 
        "author": "Kyungae Yoon and Kiseon Kim", 
        "keyword": "Three discriminant features\", \"Multiple kernel learning\", \"Variable size of three discriminant keywords =eature sets\", \"Accuracy of character recognition", 
        "title": "Multiple kernel learning based on three discriminant features for a \\{P300\\} speller \\{BCI\\}"
    }, 
    {
        "abstract": "Abstract This paper investigates the fault tolerant control problem for a class of continuous-time nonlinear systems with completely unknown dynamics via the data-based adaptive dynamic programming method. The proposed controller can be divided into two parts: (1) optimal control policy of the fault-free systems and (2) fault compensator. Firstly, a model-based policy iteration algorithm is introduced to obtain the optimal control law. Subsequently, a fault compensator is derived to get rid of the impact of the actuator fault. The stability analysis of the model-based control scheme is presented by using Lyapunov theory. However, for the complex practical systems, system models are generally unavailable, and thus the model-based approaches may be invalid. To overcome this difficulty, we provide a data-driven reinforcement learning method and an identification approach to design the two parts of the proposed controller, respectively, without any knowledge of the system models. Neural networks are employed to implement these two data-based methods. Finally, two simulation examples are shown in details to demonstrate the effectiveness of our proposed scheme.", 
        "author": "He Jiang and Huaguang Zhang and Yang Liu and Ji Han", 
        "keyword": "Reinforcement learning\", \"Adaptive dynamic programming\", \"Data-driven\", \"Model-free\", \"Neural networks", 
        "title": "Neural-network-based control scheme for a class of nonlinear systems with actuator faults via data-driven reinforcement learning method"
    }, 
    {
        "abstract": "Abstract Various biological factors have been implicated in convulsive seizures, involving side effects of drugs. For the preclinical safety assessment of drug development, it is difficult to predict seizure-inducing side effects. Here, we introduced a machine learning-based in\u00a0vitro system designed to detect seizure-inducing side effects. We recorded local field potentials from the \\{CA1\\} alveus in acute mouse neocortico-hippocampal slices, while 14 drugs were bath-perfused at 5 different concentrations each. For each experimental condition, we collected seizure-like neuronal activity and merged their waveforms as one graphic image, which was further converted into a feature vector using Caffe, an open framework for deep learning. In the space of the first two principal components, the support vector machine completely separated the vectors (i.e., doses of individual drugs) that induced seizure-like events and identified diphenhydramine, enoxacin, strychnine and theophylline as \u201cseizure-inducing\u201d drugs, which indeed were reported to induce seizures in clinical situations. Thus, this artificial intelligence-based classification may provide a new platform to detect the seizure-inducing side effects of preclinical drugs.", 
        "author": "Mengxuan Gao and Hideyoshi Igata and Aoi Takeuchi and Kaoru Sato and Yuji Ikegaya", 
        "keyword": "Artificial intelligence\", \"Side effect\", \"Epilepsy\", \"Clinical\", \"Toxicity", 
        "title": "Machine learning-based prediction of adverse drug effects: An example of seizure-inducing compounds"
    }, 
    {
        "abstract": "Abstract Malware is one of the top most obstructions for expansion and growth of digital acceptance among the users. Both enterprises and common users are struggling to get protected from the malware in the cyberspace, which emphasizes the importance of developing efficient methods of malware detection. In this work, we propose a machine learning based solution to classify a sample as benign or malware with high accuracy and low computation overhead. An integrated feature set has been amalgamated as a combination of portable executable header fields raw value and derived values. Various machine-learning algorithms such as Decision Tree, Random Forest, kNN, Logistic Regression, Linear Discriminant Analysis and Naive Bayes were adopted in the classification of malware. Using existing raw feature set and the proposed integrated feature set we compared performance of each classifier. The empirical evidence indicates 98.4% classification accuracy in the 10-fold cross validation for the proposed integrated feature set. In the experiments conducted on the novel test data set the accuracy was observed as 89.23% for the integrated feature set which is 15% improvement on accuracy achieved with raw-feature set alone. Classification accuracy with only top N features (N = 5, 10, 15, 20, 25) are also experimented and it was observed that with only top 15 features 98% and 97% accuracy can be achieved on integrated and raw feature respectively.", 
        "author": "Ajit Kumar and K.S. Kuppusamy and G. Aghila", 
        "keyword": "Malware\", \"Portable executable\", \"Machine learning\", \"Integrated features", 
        "title": "A learning model to detect maliciousness of portable executable using integrated feature set"
    }, 
    {
        "abstract": "Abstract Device-to-Device (D2D) communication empowers direct communication between two proximal users and helps in offloading network traffic. It is considered as one of the most promising 3GPP Long Term Evolution (LTE)-Advanced technologies for improving the spectrum and energy efficiency of Proximity-based Services (ProSe). However, due to interference posed by the \\{D2D\\} transmitters to the primary cellular users, intelligent resource allocation techniques need to be incorporated for the betterment of the overall system. Overlay \\{D2D\\} communication avoids the interference between cellular and \\{D2D\\} users by dedicating resources for \\{D2D\\} users. With this approach, efficient use of the dedicated Physical Resource Blocks (PRBs) among \\{D2D\\} users is still a concern. To handle the issue of optimum spectral efficiency, efficient allocation of spectrum resources is essential among \\{D2D\\} users. For the first time, we address this problem and propose a \\{PRB\\} allocation scheme that maximizes the \\{PRB\\} utilization among \\{D2D\\} users. The proposed scheme spreads the \\{PRB\\} requirement of a \\{D2D\\} pair over multiple \\{PRBs\\} while reducing the transmit power over each PRB, thereby reducing the overall interference and improving the spectral efficiency of the network. Extensive simulations demonstrate that our scheme does better than the conventional \\{PRB\\} allocation scheme (of assigning \\{PRBs\\} based on their data rate demand), by increasing the overall throughput and energy efficiency of the network. To analytically evaluate the proposed \\{PRB\\} allocation scheme, we present a stochastic geometry based framework to analyze the coverage and average rate of the network, and conclude that the link \\{SINR\\} of the \\{D2D\\} pairs is actually improved on employing our proposed scheme which results in high coverage and overall rate of the system. Finally, we propose a Q-Learning algorithm that learns the optimum number of \\{PRBs\\} to dedicate for overlay \\{D2D\\} communication based on the \\{PRB\\} demand of the cellular and \\{D2D\\} users. Extensive simulations reveal that the proposed algorithm efficiently allocates \\{PRBs\\} to the \\{D2D\\} pairs when compared to the conventional static scheme of dedicating fixed number of PRBs.", 
        "author": "Siba Narayan Swain and Rahul Thakur and C. Siva Ram Murthy", 
        "keyword": "Cellular network\", \"Overlay \\{D2D\\} communication\", \"Channel assignment\", \"Power control\", \"Energy keywords =fficiency\", \"Q-Learning\", \"Stochastic geometry", 
        "title": "Design and stochastic geometric analysis of an efficient Q-Learning based physical resource block allocation scheme to maximize the spectral efficiency of Device-to-Device overlaid cellular networks"
    }, 
    {
        "abstract": null, 
        "author": "Amaury Lendasse and Chi Man Vong and Kar-Ann Toh and Yoan Miche and Guang-Bin Huang", 
        "keyword": null, 
        "title": "Advances in extreme learning machines (ELM2015)"
    }, 
    {
        "abstract": "Abstract One of most important elements of Electric Power Systems (EPS) is the transmission line (TL), which is permanently under adverse conditions especially lightning strokes. At the moment, those phenomena have been the root cause of short circuits and the most important cause of mal-operation of transmission line protection relays. Thus, this paper develops the classification of lightning transient signals with and without fault. Multi-resolution analysis (MRA) is used to analyze those signals considering five mother wavelets and different decomposition levels of three phase voltages. In this manner, Spectral Energy and Machine Learning as Artificial Neural Network, K-Nearest Neighbors and Support Vector Machine are employed to classify those signals. On the other hand, the developed work in this paper analyzes most important parameters of lightning strokes, which are essentials in producing conditions with and without fault. Results show that the methodology presents an acceptable performance.", 
        "author": "J.A. Morales and E. Ordu\u00f1a and C. Rehtanz", 
        "keyword": "Multi-resolution analysis\", \"Machine learning\", \"Lightning stroke\", \"Decomposition level\", keywords =Flashover\", \"Back-flashover", 
        "title": "Classification of lightning stroke on transmission line using multi-resolution analysis and machine learning"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has salient features such as fast learning speed and excellent generalization performance. However, a single extreme learning machine is unstable in data classification. To overcome this drawback, more and more researchers consider using ensemble of ELMs. This paper proposes a method integrating voting-based extreme learning machines (V-ELMs) with dissimilarity (D-ELM). First, based on different dissimilarity measures, we remove a number of \\{ELMs\\} from the ensemble pool. Then, the remaining \\{ELMs\\} are grouped as an ensemble classifier by majority voting. Finally we use disagreement measure and double-fault measure to validate the D-ELM. The theoretical analysis and experimental results on gene expression data demonstrate that (1) the D-ELM can achieve better classification accuracy with less number of ELMs; (2) the double-fault measure based D-ELM (DF-D-ELM) performs better than disagreement measure based D-ELM (D-D-ELM).", 
        "author": "Hui-juan Lu and Chun-lin An and En-hui Zheng and Yi Lu", 
        "keyword": "Extreme learning machine\", \"Dissimilarity ensemble\", \"Double-fault measure\", \"Majority voting\", \"Gene expression data", 
        "title": "Dissimilarity based ensemble of extreme learning machine for gene expression data classification"
    }, 
    {
        "abstract": "Abstract We introduce a fast sparse approximation schemes of extreme learning machine (ELM) named FSA-ELM of extreme learning machine (ELM). Our algorithms have two compelling features: low complexity and sparse solution. Experiments on benchmark data sets show that the proposed algorithm obtains sparse classifiers at a rather low complexity without sacrificing the generalization performance. As validated by the simulation results, FSA-ELM tends to have better scalability and achieves similar or much better generalization performance with much faster learning speed than the traditional \\{ELM\\} algorithm.", 
        "author": "Xiaodong Li and Weijie Mao and Wei Jiang", 
        "keyword": "Fast greedy algorithm\", \"Extreme learning machine (ELM)\", \"Sparse approximation", 
        "title": "Fast sparse approximation of extreme learning machine"
    }, 
    {
        "abstract": "AbstractIntroduction Nonmedical use of prescription medications/drugs (NMUPD) is a serious public health threat, particularly in relation to the prescription opioid analgesics abuse epidemic. While attention to this problem has been growing, there remains an urgent need to develop novel strategies in the field of \u201cdigital epidemiology\u201d to better identify, analyze and understand trends in \\{NMUPD\\} behavior. Methods We conducted surveillance of the popular microblogging site Twitter by collecting 11 million tweets filtered for three commonly abused prescription opioid analgesic drugs Percocet\u00ae (acetaminophen/oxycodone), OxyContin\u00ae (oxycodone), and Oxycodone. Unsupervised machine learning was applied on the subset of tweets for each analgesic drug to discover underlying latent themes regarding risk behavior. A two-step process of obtaining themes, and filtering out unwanted tweets was carried out in three subsequent rounds of machine learning. Results Using this methodology, 2.3M tweets were identified that contained content relevant to analgesic NMUPD. The underlying themes were identified for each drug and the most representative tweets of each theme were annotated for \\{NMUPD\\} behavioral risk factors. The primary themes identified evidence high levels of social media discussion about polydrug abuse on Twitter. This included specific mention of various polydrug combinations including use of other classes of prescription drugs, and illicit drug abuse. Conclusions This study presents a methodology to filter Twitter content for \\{NMUPD\\} behavior, while also identifying underlying themes with minimal human intervention. Results from the study track accurately with the inclusion/exclusion criteria used to isolate NMUPD-related risk behaviors of interest and also provides insight on \\{NMUPD\\} behavior that has a high level of social media engagement. Results suggest that this could be a viable methodology for use in big data substance abuse surveillance, data collection, and analysis in comparison to other studies that rely upon content analysis and human coding schemes.", 
        "author": "Janani Kalyanam and Takeo Katsuki and Gert R.G. Lanckriet and Tim K. Mackey", 
        "keyword": "Nonmedical use of prescription drugs\", \"Prescription opioid abuse\", \"Digital surveillance\", keywords =Substance abuse\", \"Twitter\", \"Social media", 
        "title": "Exploring trends of nonmedical use of prescription drugs and polydrug abuse in the Twittersphere using unsupervised machine learning"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has been intensively studied during the last decade due to its high efficiency, effectiveness and easy to implement. Recently, a variant of \\{ELM\\} named local receptive fields based \\{ELM\\} (ELM-LRF) has been proposed to reduce the global connections and introduce local receptive fields to the input layer. However, an ELM-LRF model with large number of hidden neurons spend plenty of time on solving large scale Moore-Penrose Matrix Inversion (MPMI) problem which has heavy computational cost and needs much more runtime memory. Moreover, this procedure can not be directly accelerated by \\{GPU\\} platforms due to the limited memory of \\{GPU\\} devices. In this paper, we propose three efficient approaches to perform ELM-LRF on \\{GPU\\} platform. First we propose a novel blocked \\{LU\\} decomposition algorithm, which overcomes the limitation of global memory size so that any size of ELM-LRF models can be trained. Furthermore, an efficient blocked Cholesky decomposition algorithm is presented to accelerate blocked \\{LU\\} decomposition algorithm according to matrix characteristics in the ELM-LRF model. Finally we present a heterogeneous blocked CPU-GPU parallel algorithm to fully exploit resources on a \\{GPU\\} node such as to accelerate blocked Cholesky decomposition algorithm furthermore in the ELM-LRF model.", 
        "author": "Shijie Li and Xin Niu and Yong Dou and Qi Lv and Yueqing Wang", 
        "keyword": "ELM-LRF\", \"GPU\", \"Blocked CPU-GPU accelerate algorithm", 
        "title": "Heterogeneous blocked CPU-GPU accelerate scheme for large scale extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, we study the connections between working memory capacity (WMC) and learning in the context of economic guessing games. We apply a generalized version of reinforcement learning, popularly known as the experience-weighted attraction (EWA) learning model, which has a connection to specific cognitive constructs, such as memory decay, the depreciation of past experience, counterfactual thinking, and choice intensity. Through the estimates of the model, we examine behavioral differences among individuals due to different levels of WMC. In accordance with \u2018Miller\u2019s magic number\u2019, which is the constraint of working memory capacity, we consider two different sizes (granularities) of strategy space: one is larger (finer) and one is smaller (coarser). We find that constraining the \\{EWA\\} models by using levels (granules) within the limits of working memory allows for a better characterization of the data based on individual differences in WMC. Using this level-reinforcement version of \\{EWA\\} learning, also referred to as the \\{EWA\\} rule learning model, we find that working memory capacity can significantly affect learning behavior. Our likelihood ratio test rejects the null that subjects with high \\{WMC\\} and subjects with low \\{WMC\\} follow the same \\{EWA\\} learning model. In addition, the parameter corresponding to \u2018counterfactual thinking ability\u2019 is found to be reduced when working memory capacity is low.", 
        "author": "Shu-Heng Chen and Ye-Rong Du", 
        "keyword": "Generalized reinforcement learning\", \"Experience-weighted attraction learning\", \"Cognitive keywords =bility\", \"Granularity", 
        "title": "Heterogeneity in generalized reinforcement learning and its relation to cognitive ability"
    }, 
    {
        "abstract": "Abstract \\{DNA\\} microarray is a very active area of research in the molecular diagnosis of cancer. Microarray data are composed of many thousands of features and from tens to hundreds of instances, which make the analysis and diagnosis of cancer very complex. In this case, gene/feature selection becomes an elemental and essential task in data classification. In this paper, we propose a complete cancer diagnostic process through kernel-based learning and feature selection. First, support vector machines recursive feature elimination (SVM-RFE) is used to prefilter the genes. Second, the SVM-RFE is enhanced by using binary dragonfly (BDF), which is a recently developed metaheuristic that has never been benchmarked in the context of feature selection. The objective function is the average of classification accuracy rate generated by three kernel-based learning methods. We conducted a series of experiments on six microarray datasets often used in the literature. Experiment results demonstrate that this approach is efficient and provides a higher classification accuracy rate using a reduced number of genes.", 
        "author": "Seyyid Ahmed Medjahed and Tamazouzt Ait Saadi and Abdelkader Benyettou and Mohammed Ouali", 
        "keyword": "Classification\", \"Feature selection\", \"Kernel-based learning\", \"Support vector machines recursive keywords =eature elimination\", \"Binary dragon fly", 
        "title": "Kernel-based learning and feature selection analysis for cancer diagnosis"
    }, 
    {
        "abstract": "Abstract While face and eye detection is well known research topics in the field of object detection, eye-pair detection has not been much researched. Finding the location and size of an eye-pair in an image containing a face can enable a face recognition application to extract features from a face corresponding to different entities. Furthermore, it allows us to align different faces, so that more accurate recognition results can be obtained. To the best of our knowledge, currently there is only one eye-pair detector, which is a part of the Viola\u2013Jones object detection framework. However, as we will show in this paper, this eye-pair detector is not very accurate for detecting eye-pairs from different face images. Therefore, in this paper we describe several novel eye-pair detection methods based on different feature extraction methods and a support vector machine (SVM) to classify image patches as containing an eye-pair or not. To find the location of an eye-pair on unseen test images, a sliding window approach is used, and the location and size of the window giving the highest output of the \\{SVM\\} classifier are returned. We have tested the different methods on three different datasets: the IMM, the Caltech and the Indian face dataset. The results show that the linear restricted Boltzmann machine feature extraction technique and principal component analysis result in the best performances. The \\{SVM\\} with these feature extraction methods is able to very accurately detect eye-pairs. Furthermore, the results show that our best eye-pair detection methods perform much better than the Viola\u2013Jones eye-pair detector.", 
        "author": "Mahir Faik Karaaba and Lambert Schomaker and Marco Wiering", 
        "keyword": "Eye detection\", \"Eye-pair detection\", \"Machine learning\", \"Support vector machine\", \"Restricted Boltzmann machine (RBM)", 
        "title": "Machine learning for multi-view eye-pair detection"
    }, 
    {
        "abstract": "Abstract Within the field of image and video recognition, the traditional approach is a dataset split into fixed training and test partitions. However, the labelling of the training set is time-consuming, especially as datasets grow in size and complexity. Furthermore, this approach is not applicable to the home user, who wants to intuitively group their media without tirelessly labelling the content. Consequently, we propose a solution similar in nature to an active learning paradigm, where a small subset of media is labelled as semantically belonging to the same class, and machine learning is then used to pull this and other related content together in the feature space. Our interactive approach is able to iteratively cluster classes of images and video. We reformulate it in an online learning framework and demonstrate competitive performance to batch learning approaches using only a fraction of the labelled data. Our approach is based around the concept of an image signature which, unlike a standard bag of words model, can express co-occurrence statistics as well as symbol frequency. We efficiently compute metric distances between signatures despite their inherent high dimensionality and provide discriminative feature selection, to allow common and distinctive elements to be identified from a small set of user labelled examples. These elements are then accentuated in the image signature to increase similarity between examples and pull correct classes together. By repeating this process in an online learning framework, the accuracy of similarity increases dramatically despite labelling only a few training examples. To demonstrate that the approach is agnostic to media type and features used, we evaluate on three image datasets (15 scene, Caltech101 and FG-NET), a mixed text and image dataset (ImageTag), a dataset used in active learning (Iris) and on three action recognition datasets (UCF11, \\{KTH\\} and Hollywood2). On the \\{UCF11\\} video dataset, the accuracy is 86.7% despite using only 90 labelled examples from a dataset of over 1200 videos, instead of the standard 1122 training videos. The approach is both scalable and efficient, with a single iteration over the full \\{UCF11\\} dataset of around 1200 videos taking approximately 1\u00a0min on a standard desktop machine.", 
        "author": "Andrew Gilbert and Richard Bowden", 
        "keyword": "Action recognition\", \"Data mining\", \"Real-time\", \"Learning\", \"Spatio-temporal\", \"Clustering", 
        "title": "Image and video mining through online learning"
    }, 
    {
        "abstract": "Abstract The hydrologic processes of wetting and drying play a crucial role in agricultural activities involving heavy equipment on unpaved terrain. When soil conditions moisten, equipment can become mired, causing expensive delays. While experienced users may assess soil conditions before entering off-road areas, novice users or those who must remotely assess sites before traveling may have difficulty assessing conditions reliably. One means of assessing dryness is remotely-monitored in situ sensors. Unfortunately, land owners hesitate to place sensors due to monetary costs, complexity, and sometimes infeasibility of physical visits to remote locations. This work addresses these limitations by modeling the wetting/drying process through machine learning algorithms fed by hydrologic data \u2013 remotely assessing soil conditions using only publicly-accessible information. Classification trees, k-nearest-neighbors, and boosted perceptrons deliver statistical soil dryness estimates at a site located in Urbana, IL. The k-nearest-neighbor and boosted perceptron algorithms both performed with 91\u201394% accuracy, with most misclassifications falling within calculated margins of error. These analyses demonstrate that reasonably accurate predictions of current soil conditions are possible with only precipitation and potential evaporation data. These two values are measured throughout the continental United States and are likely to be available globally from satellite sensors in the near future. Through this type of approach, agricultural management decisions can be enabled remotely, without the time and expense of on-site visitations or extensive ground-based sensory grids.", 
        "author": "Evan J. Coopersmith and Barbara S. Minsker and Craig E. Wenzel and Brian J. Gilmore", 
        "keyword": "Soil drying\", \"Field readiness\", \"Machine learning\", \"Nearest neighbors\", \"Soil moisture\", \"Decision support", 
        "title": "Machine learning assessments of soil drying for agricultural planning"
    }, 
    {
        "abstract": "Abstract Dynamic ensemble selection (DES) techniques work by estimating the competence level of each classifier from a pool of classifiers, and selecting only the most competent ones for the classification of a specific test sample. The key issue in \\{DES\\} is defining a suitable criterion for calculating the classifiers\u2019 competence. There are several criteria available to measure the level of competence of base classifiers, such as local accuracy estimates and ranking. However, using only one criterion may lead to a poor estimation of the classifier\u2019s competence. In order to deal with this issue, we have proposed a novel dynamic ensemble selection framework using meta-learning, called META-DES. A meta-classifier is trained, based on the meta-features extracted from the training data, to estimate the level of competence of a classifier for the classification of a given query sample. An important aspect of the META-DES framework is that multiple criteria can be embedded in the system encoded as different sets of meta-features. However, some \\{DES\\} criteria are not suitable for every classification problem. For instance, local accuracy estimates may produce poor results when there is a high degree of overlap between the classes. Moreover, a higher classification accuracy can be obtained if the performance of the meta-classifier is optimized for the corresponding data. In this paper, we propose a novel version of the META-DES framework based on the formal definition of the Oracle, called META-DES.Oracle. The Oracle is an abstract method that represents an ideal classifier selection scheme. A meta-feature selection scheme using an overfitting cautious Binary Particle Swarm Optimization (BPSO) is proposed for improving the performance of the meta-classifier. The difference between the outputs obtained by the meta-classifier and those presented by the Oracle is minimized. Thus, the meta-classifier is expected to obtain results that are similar to the Oracle. Experiments carried out using 30 classification problems demonstrate that the optimization procedure based on the Oracle definition leads to a significant improvement in classification accuracy when compared to previous versions of the META-DES framework and other state-of-the-art \\{DES\\} techniques.", 
        "author": "Rafael M.O. Cruz and Robert Sabourin and George D.C. Cavalcanti", 
        "keyword": "Ensemble of classifiers\", \"Dynamic ensemble selection\", \"Meta-learning\", \"Particle swarm keywords =ptimization\", \"Classifier competence", 
        "title": "META-DES.Oracle: Meta-learning and feature selection for dynamic ensemble selection"
    }, 
    {
        "abstract": "Abstract One of the most striking contemporary developments in the field of machine learning is the meteoric ascent of what has been called \u201cdeep learning,\u201d and this area is now at the forefront of current research. We discuss key differences between traditional neural network architectures and learning techniques, and those that have become popular in deep learning. A detailed derivation of the backpropagation algorithm in vector-matrix form is provided, and the relationship to computational graphs and deep learning software is discussed. Deep convolutional neural networks are covered, as well as autoencoders, recurrent neural networks, and stochastic approaches based on Boltzmann machines. Key practical aspects of training these models with large data sets are discussed, along with the role of \\{GPU\\} computing.", 
        "author": "Ian H. Witten and Eibe Frank and Mark A. Hall and Christopher J. Pal", 
        "keyword": "Deep learning\", \"neural network architectures\", \"backpropagation algorithm\", \"deep convolutional keywords =eural networks\", \"autoencoders\", \"recurrent neural networks\", \"Boltzmann machines\", \"GPU computing", 
        "title": "Chapter 10 - Deep learning"
    }, 
    {
        "abstract": "Abstract Local binary patterns (LBP) and its variants have shown great potentials in texture classification tasks. LBP-like texture classification methods usually follow a two-step feature extraction process: in the first pattern encoding step, the local structure information around each pixel is encoded into a binary string; in the second histogram accumulation step, the binary strings are accumulated into a histogram as the feature vector of a texture image. The performances of these classification methods are closely related to the distinctiveness of the feature vectors. In this paper, we propose a novel feature representation method, namely Completed Discriminative Local Features (CDLF), for texture classification. The proposed \\{CDLF\\} improves the distinctiveness of LBP-like feature vectors in two aspects: in the pattern encoding stage, we learn a transformation matrix using labeled data, which significantly increases the discrimination power of the encoded binary strings; in the histogram accumulation step, we use an adaptive weight strategy to consider the contributions of pixels in different regions. The experimental results on three challenging texture databases demonstrate that the proposed \\{CDLF\\} achieves significantly better results than previous LBP-like feature representation methods for texture classification tasks.", 
        "author": "Zhong Zhang and Shuang Liu and Xing Mei and Baihua Xiao and Liang Zheng", 
        "keyword": "Texture classification\", \"Discriminative learning\", \"Local binary patterns\", \"Adaptive histogram accumulation", 
        "title": "Learning completed discriminative local features for texture classification"
    }, 
    {
        "abstract": "Abstract We elucidate the diffusion kinetics of a heteroepitaxial system consisting of two-dimensional small (1\u20138 atoms) Cu islands on the Ni(111) surface at (100\u2013600) K using the Self-Learning Kinetic Monte Carlo (SLKMC-II) method. Study of the statics of the system shows that compact CuN (3\u2264N\u22648) clusters made up of triangular units on fcc occupancy sites are the energetically most stable structures of those clusters. Interestingly, we find a correlation between the height of the activation energy barrier (Ea) and the location of the transition state (TS). The Ea of processes for Cu islands on the Ni(111) surface are in general smaller than those of their counterpart Ni islands on the same surface. We find this difference to correlate with the relative strength of the lateral interaction of the island atoms in the two systems. While our database consists of hundreds of possible processes, we identify and discuss the energetics of those that are the most dominant, or are rate-limiting, or most contributory to the diffusion of the islands. Since the Ea of single- and multi-atom processes that convert compact island shapes into non-compact ones\u00a0are larger (with a significantly smaller Ea for their reverse processes) than that for the collective (concerted) motion of the island, the later dominate in the system kinetics -- except for the cases of the dimer, pentamer and octamer. Short-jump involving one atom, long jump dimer-shearing, and long-jump corner shearing (via a single-atom) are, respectively, the dominating processes in the diffusion of the dimer, pentamer and octamer. Furthermore single-atom corner-rounding are the rate-limiting processes for the pentamer and octamer islands. Comparison of the energetics of selected processes and lateral interactions obtained from semi-empirical interatomic potentials with those from density functional theory show minor quantitative differences and overall qualitative agreement.", 
        "author": "Shree Ram Acharya and Syed Islamuddin Shah and Talat S. Rahman", 
        "keyword": "Self-Learning Kinetic Monte Carlo\", \"Island diffusion\", \"Single-atom, multi-atom, concerted keywords =rocess\", \"Activation energy barrier\", \"Diffusion coefficient\", \"Lateral interaction", 
        "title": "Diffusion of small Cu islands on the Ni(111) surface: A self-learning kinetic Monte Carlo study"
    }, 
    {
        "abstract": "Abstract Multimodal recognition of affective states is a difficult problem, unless the recording conditions are carefully controlled. For recognition \u201cin the wild\u201d, large variances in face pose and illumination, cluttered backgrounds, occlusions, audio and video noise, as well as issues with subtle cues of expression are some of the issues to target. In this paper, we describe a multimodal approach for video-based emotion recognition in the wild. We propose using summarizing functionals of complementary visual descriptors for video modeling. These features include deep convolutional neural network (CNN) based features obtained via transfer learning, for which we illustrate the importance of flexible registration and fine-tuning. Our approach combines audio and visual features with least squares regression based classifiers and weighted score level fusion. We report state-of-the-art results on the EmotiW Challenge for \u201cin the wild\u201d facial expression recognition. Our approach scales to other problems, and ranked top in the ChaLearn-LAP First Impressions Challenge 2016 from video clips collected in the wild.", 
        "author": "Heysem Kaya and Furkan G\u00fcrp\u0131nar and Albert Ali Salah", 
        "keyword": "EmotiW\", \"Emotion recognition in the wild\", \"Multimodal fusion\", \"Convolutional neural networks\", keywords =Kernel extreme learning machine\", \"Partial least squares", 
        "title": "Video-based emotion recognition in the wild using deep transfer learning and score fusion"
    }, 
    {
        "abstract": null, 
        "author": "Jun Yu and Jitao Sang and Xinbo Gao", 
        "keyword": null, 
        "title": "Machine learning and signal processing for big multimedia analysis"
    }, 
    {
        "abstract": "Abstract Matrix-pattern-oriented Classifier Design (MatCD) has been demonstrated to be effective in terms of the classification performance since it utilizes two-sided weight vectors to constrain the matrix-based patterns. However, the existing MatCD might not be able to acquire the prior distribution knowledge, such as the relationship between two patterns. Inspired by the Pairwise Constraints (PC) method, i.e., must-links and cannot-links between the patterns, this paper introduces a new regularization term named Rp with a modified \\{PC\\} method into MatCD. The new classifier design strategy is expected to not only learn the structural information of each pattern itself, but also acquire the prior distribution knowledge about each constrained pair with both the discrimination metric from the traditional \\{PC\\} and the spatial distance measure from the heat kernel method. In practice, this paper selects one typical matrixized classifier named MatMHKS as the basic building block and introduces the term Rp into it. The newly-proposed classifier is named \\{MLMMPC\\} and the subsequent experiments validate the effectiveness of it. Two major contributions of this paper can be concluded as (1) improving the existing matrix-pattern-oriented classifier design techniques and (2) modifying the traditional \\{PC\\} method by combining the discrimination metric and the distance measure together.", 
        "author": "Yujin Zhu and Zhe Wang and Daqi Gao", 
        "keyword": "Matrixized classifier\", \"Regularized learning\", \"Modified pairwise constraints\", \"Pattern recognition", 
        "title": "Matrixized learning machine with modified pairwise constraints"
    }, 
    {
        "abstract": "Abstract Feature (gene) selection and classification of microarray data are the two most interesting machine learning challenges. In the present work two existing feature selection/extraction algorithms, namely independent component analysis (ICA) and fuzzy backward feature elimination (FBFE) are used which is a new combination of selection/extraction. The main objective of this paper is to select the independent components of the \\{DNA\\} microarray data using \\{FBFE\\} to improve the performance of support vector machine (SVM) and Na\u00efve Bayes (NB) classifier, while making the computational expenses affordable. To show the validity of the proposed method, it is applied to reduce the number of genes for five \\{DNA\\} microarray datasets namely; colon cancer, acute leukemia, prostate cancer, lung cancer II, and high-grade glioma. Now these datasets are then classified using \\{SVM\\} and \\{NB\\} classifiers. Experimental results on these five microarray datasets demonstrate that gene selected by proposed approach, effectively improve the performance of \\{SVM\\} and \\{NB\\} classifiers in terms of classification accuracy. We compare our proposed method with principal component analysis (PCA) as a standard extraction algorithm and find that the proposed method can obtain better classification accuracy, using \\{SVM\\} and \\{NB\\} classifiers with a smaller number of selected genes than the PCA. The curve between the average error rate and number of genes with each dataset represents the selection of required number of genes for the highest accuracy with our proposed method for both the classifiers. \\{ROC\\} shows best subset of genes for both the classifier of different datasets with propose method.", 
        "author": "Rabia Aziz and C.K. Verma and Namita Srivastava", 
        "keyword": "Fuzzy backward feature elimination (FBFE)\", \"Independent component analysis (ICA)\", \"Support vector keywords =achine (SVM)\", \"Na\u00efve Bayes (NB)\", \"Classification", 
        "title": "A fuzzy based feature selection from independent component subspace for machine learning classification of microarray data"
    }, 
    {
        "abstract": null, 
        "author": "Ahmad Mozaffari and Nasser L. Azad", 
        "keyword": "Automotive engine modeling\", \"Coldstart\", \"Negative correlation based ensembles\", \"Regularization\", \"Extreme learning machines", 
        "title": "Optimally pruned extreme learning machine with ensemble of regularization techniques and negative correlation penalty applied to automotive engine coldstart hydrocarbon emission identification"
    }, 
    {
        "abstract": "Abstract The aim of this study was to provide effective solutions for the nominal classification of twelve Spanish goat breeds using nine morphological traits and considering their aptitude (meat, dual purpose and milk). Different statistical and artificial intelligence algorithms were used to compare our hierarchical methodology with a representative of each Machine-Learning typology and several common statistical methods. The most appropriate tool to solve problems of classification, by considering the aptitude, would be the k-Nearest Neighbours used in a hierarchical model. For the first level of this hierarchy, the study was conducted using a 1-Nearest Neighbour classification of individuals by aptitude, and on the second level, the breeds were analysed again using three new 1-Nearest Neighbour classifiers, one for each aptitude. The results obtained improved the accuracy rates for assigning individuals to breed, compared with those usually employed using Linear Discriminant Analysis methodologies. Only 78% correct classification rate (Minimum Sensitivity=19%) was obtain with the Linear Discriminant Analysis, but this result increased to 89.18% with a 1-Nearest Neighbour+1-Nearest Neighbour (1NN+1NN). Hierarchical methodology, thus increasing the classification rate (Minimum Sensitivity=37.08%). Furthermore, the percentage of correct classification was 83.48% (Minimum Sensitivity=35.08%) with 1-Nearest Neighbour+Multi-Layer Perceptron, that justifies the use of hierarchical models. The new second level model (1NN+1NN) permit 100% of goats successful classified in Pirenaica, Retinta and Malague\u00f1a breeds, each of these belongs to a different aptitude. The improve of classification obtained of the majority of the breeds with the application of the hierarchical method, suggested that defining firstly the aptitude class, the unique and distinctive characteristics of the breed are identified more clearly.", 
        "author": "E. Rodero and A. Gonz\u00e1lez and M. Dorado-Moreno and M. Luque and C. Herv\u00e1s", 
        "keyword": "Adscription\", \"Aptitude\", \"Automatic learning\", \"Morphological measurements\", \"Nominal classification", 
        "title": "Classification of goat genetic resources using morphological traits. Comparison of machine learning techniques with linear discriminant analysis"
    }, 
    {
        "abstract": "Abstract Classification of wine represents a multi-criteria decision-making problem characterized by great complexity, non-linearity and lack of objective information regarding the quality of the desired final product. Volatile compounds of wines elaborated from four Galician (NW Spain) autochthonous white Vitis vinifera from four consecutive vintages were analysed by gas chromatography (FID, \\{FPD\\} and \\{MS\\} detectors), and several aroma compounds were used for correctly classifying autochthonous white grape varieties (Albari\u00f1o, Treixadura, Loureira and Dona Branca). The objective of the work is twofold: to find a classification model able to precisely differentiate between existing grape varieties (i.e. assuring the authenticity), and to assess the discriminatory power of different family compounds over well-known classifiers (i.e. guaranteeing the typicality). From the experiments carried out, and given the fact that Principal Component Analysis (PCA) was not able to accurately separate all the wine varieties, this work investigates the suitability of applying different machine learning (ML) techniques (i.e.: Support Vector Machines, Random Forests, MultiLayer Perceptron, k-Nearest Neighbour and Na\u00efve Bayes) for classification purposes. Perfect classification accuracy is obtained by the Random Forest algorithm, whilst the other alternatives achieved promising results using only part of the available information.", 
        "author": "S. G\u00f3mez-Meire and C. Campos and E. Falqu\u00e9 and F. D\u00edaz and F. Fdez-Riverola", 
        "keyword": "Galician white wine varieties\", \"Volatile composition\", \"Assuring authenticity\", \"Machine learning keywords =echniques\", \"Feature selection\", \"Model comparison", 
        "title": "Assuring the authenticity of northwest Spain white wine varieties using machine learning techniques"
    }, 
    {
        "abstract": "Abstract A number of empirical studies have suggested that individual differences in asocial exploration tendencies in animals may be related to those in social information use. However, because the \u2018exploration tendency\u2019 in most previous studies has been measured without considering the information-gathering processes, it is yet hard to conclude that the animal asocial exploration strategies may be tied to social information use. Here, we studied human learning behaviour in both asocial and social two-armed bandit tasks. By fitting reinforcement learning models including asocial and/or social decision processes, we measured each individual's (1) asocial exploration tendency and (2) social information use. We found consistent individual differences in the exploration tendency in the asocial tasks. We also found substantive heterogeneity in the adopted learning strategies in the social task: Nearly one-third of participants used predominantly the copy-when-uncertain strategy, while the remaining two-thirds were most likely to have relied only on asocial learning. However, we found no significant individual association between the exploration frequency in the asocial task and the use of the social information in the social task. Our results suggest that the social learning strategies may be independent from the asocial exploration strategies in humans.", 
        "author": "Wataru Toyokawa and Yoshimatsu Saito and Tatsuya Kameda", 
        "keyword": "Social learning\", \"Individual differences\", \"Reinforcement learning\", \"Two-armed bandit\", \"Copy-when-uncertain", 
        "title": "Individual differences in learning behaviours in humans: Asocial exploration tendency does not predict reliance on social learning"
    }, 
    {
        "abstract": "Abstract The extreme learning machine (ELM) has attracted increasing attention recently with its successful applications in classification and regression. In this paper, we investigate the generalization performance of ELM-based ranking. A new regularized ranking algorithm is proposed based on the combinations of activation functions in ELM. The generalization analysis is established for the ELM-based ranking (ELMRank) in terms of the covering numbers of hypothesis space. Empirical results on the benchmark datasets show the competitive performance of the \\{ELMRank\\} over the state-of-the-art ranking methods.", 
        "author": "Hong Chen and Jiangtao Peng and Yicong Zhou and Luoqing Li and Zhibin Pan", 
        "keyword": "Learning theory\", \"Ranking\", \"Extreme learning machine\", \"Coefficient regularization\", \"Generalization bound", 
        "title": "Extreme learning machine for ranking: Generalization analysis and applications"
    }, 
    {
        "abstract": "Abstract We propose a methodology to predict the cardiac epicardial and mediastinal fat volumes in computed tomography images using regression algorithms. The obtained results indicate that it is feasible to predict these fats with a high degree of correlation, thus alleviating the requirement for manual or automatic segmentation of both fat volumes. Instead, segmenting just one of them suffices, while the volume of the other may be predicted fairly precisely. The correlation coefficient obtained by the Rotation Forest algorithm using \\{MLP\\} Regressor for predicting the mediastinal fat based on the epicardial fat was 0.9876, with a relative absolute error of 14.4% and a root relative squared error of 15.7%. The best correlation coefficient obtained in the prediction of the epicardial fat based on the mediastinal was 0.9683 with a relative absolute error of 19.6% and a relative squared error of 24.9%. Moreover, we analysed the feasibility of using linear regressors, which provide an intuitive interpretation of the underlying approximations. In this case, the obtained correlation coefficient was 0.9534 for predicting the mediastinal fat based on the epicardial, with a relative absolute error of 31.6% and a root relative squared error of 30.1%. On the prediction of the epicardial fat based on the mediastinal fat, the correlation coefficient was 0.8531, with a relative absolute error of 50.43% and a root relative squared error of 52.06%. In summary, it is possible to speed up general medical analyses and some segmentation and quantification methods that are currently employed in the state-of-the-art by using this prediction approach, which consequently reduces costs and therefore enables preventive treatments that may lead to a reduction of health problems.", 
        "author": "\u00c9.O. Rodrigues and V.H.A. Pinheiro and P. Liatsis and A. Conci", 
        "keyword": "Cardiac fat segmentation\", \"Quantification\", \"Regression\", \"Epicardial\", \"Mediastinal\", \"Adipose keywords =issue\", \"Prediction\", \"Correlation\", \"Volume Estimation", 
        "title": "Machine learning in the prediction of cardiac epicardial and mediastinal fat volumes"
    }, 
    {
        "abstract": "Abstract Load demand forecasting is a critical process in the planning of electric utilities. An ensemble method composed of Empirical Mode Decomposition (EMD) algorithm and deep learning approach is presented in this work. For this purpose, the load demand series were first decomposed into several intrinsic mode functions (IMFs). Then a Deep Belief Network (DBN) including two restricted Boltzmann machines (RBMs) was used to model each of the extracted IMFs, so that the tendencies of these \\{IMFs\\} can be accurately predicted. Finally, the prediction results of all \\{IMFs\\} can be combined by either unbiased or weighted summation to obtain an aggregated output for load demand. The electricity load demand data sets from Australian Energy Market Operator (AEMO) are used to test the effectiveness of the proposed EMD-based \\{DBN\\} approach. Simulation results demonstrated attractiveness of the proposed method compared with nine forecasting methods.", 
        "author": "Xueheng Qiu and Ye Ren and Ponnuthurai Nagaratnam Suganthan and Gehan A.J. Amaratunga", 
        "keyword": "Empirical Mode Decomposition\", \"Deep learning\", \"Ensemble method\", \"Time series forecasting\", \"Load keywords =emand forecasting\", \"Neural networks\", \"Support vector regression\", \"Random forests", 
        "title": "Empirical Mode Decomposition based ensemble deep learning for load demand time series forecasting"
    }, 
    {
        "abstract": "Abstract Coastal structures may cease to function properly due to seabed scouring. Hence, prediction of the maximum scour depth is of great importance for the protection of these structures. Since scour is the result of a complicated interaction between structure, sediment, and incoming waves, empirical equations are not as accurate as machine learning schemes, which are being widely employed for the coastal engineering modeling. In this paper, which can be regarded as an extension of Pourzangbar et al. (2016), two soft computing methods, a support vector regression (SVR), and a model tree algorithm (M5\u2032), have been implemented to predict the maximum scour depth due to non-breaking waves. The models predict the relative scour depth (Smax/H0) on the basis of the following variables: relative water depth at the toe of the breakwater (htoe/L0), Shields parameter (\u03b8), non-breaking wave steepness (H0/L0), and reflection coefficient (Cr). 95 laboratory data points, extracted from dedicated experimental studies, have been used for developing the models, whose performances have been assessed on the basis of statistical parameters. The results suggest that all of the developed models predict the maximum scour depth with high precision, the M5\u2032 model performed marginally better than the \\{SVR\\} model and also allowed to define a set of transparent and physically sound relationships. Such relationships, which are in good agreement with the existing empirical findings, show that the relative scour depth is mainly affected by wave reflection.", 
        "author": "Ali Pourzangbar and Maurizio Brocchini and Aniseh Saber and Javad Mahjoobi and Masoud Mirzaaghasi and Mohammad Barzegar", 
        "keyword": "Seabed scour\", \"Non-breaking waves\", \"SVR\", \"M5\u2032 model tree algorithm", 
        "title": "Prediction of scour depth at breakwaters due to non-breaking waves using machine learning approaches"
    }, 
    {
        "abstract": "Abstract An approach, named extended extreme learning machine (ELM), is proposed for training the weights of a class of hierarchical feedforward neural network (HFNN). Unlike conventional single-hidden-layer feedforward networks (SLFNs), this hierarchical \\{ELM\\} (HELM) is based on the hierarchical structure which is capable of hierarchical learning of sequential information online, and one may simply choose hidden layers and then only need to adjust the output weights linking the hidden layer and the output layer. In such \\{HELM\\} implementations, the extended \\{ELM\\} provides better generalization performance during the learning process. Moreover, the proposed extended \\{ELM\\} method is efficient not only for \\{HFNNs\\} with sigmoid hidden nodes but also for \\{HFNNs\\} with radial basis function (RBF) hidden nodes. Finally, the \\{HELM\\} is applied to the activated sludge wastewater treatment processes (WWTPs) for predicting the water qualities. Experimental results and the performance comparison demonstrate the effectiveness of the proposed HELM.", 
        "author": "Hong-Gui Han and Li-Dan Wang and Jun-Fei Qiao", 
        "keyword": "Hierarchical extreme learning machine\", \"Feedforward neural network\", \"Wastewater treatment keywords =rocess\", \"Predicting water qualities", 
        "title": "Hierarchical extreme learning machine for feedforward neural network"
    }, 
    {
        "abstract": "AbstractBackground Early warning scores (EWS) are designed to identify early clinical deterioration by combining physiologic and/or laboratory measures to generate a quantified score. Current \\{EWS\\} leverage only a small fraction of Electronic Health Record (EHR) content. The planned widespread implementation of \\{EHRs\\} brings the promise of abundant data resources for prediction purposes. The three specific aims of our research are: (1) to develop an EHR-based automated algorithm to predict the need for Pediatric Intensive Care Unit (PICU) transfer in the first 24 h of admission; (2) to evaluate the performance of the new algorithm on a held-out test data set; and (3) to compare the effectiveness of the new algorithm's with those of two published Pediatric Early Warning Scores (PEWS). Methods The cases were comprised of 526 encounters with 24-h Pediatric Intensive Care Unit (PICU) transfer. In addition to the cases, we randomly selected 6772 control encounters from 62516 inpatient admissions that were never transferred to the PICU. We used 29 variables in a logistic regression and compared our algorithm against two published \\{PEWS\\} on a held-out test data set. Results The logistic regression algorithm achieved 0.849 (95% \\{CI\\} 0.753\u20130.945) sensitivity, 0.859 (95% \\{CI\\} 0.850\u20130.868) specificity and 0.912 (95% \\{CI\\} 0.905\u20130.919) area under the curve (AUC) in the test set. Our algorithm's \\{AUC\\} was significantly higher, by 11.8 and 22.6% in the test set, than two published PEWS. Conclusion The novel algorithm achieved higher sensitivity, specificity, and \\{AUC\\} than the two \\{PEWS\\} reported in the literature.", 
        "author": "Haijun Zhai and Patrick Brady and Qi Li and Todd Lingren and Yizhao Ni and Derek S. Wheeler and Imre Solti", 
        "keyword": "Clinical status deterioration\", \"Clinical care\", \"PICU\", \"PEWS\", \"Machine learning\", \"EHR", 
        "title": "Developing and evaluating a machine learning based algorithm to predict the need of pediatric intensive care unit transfer for newly hospitalized children"
    }, 
    {
        "abstract": "Abstract Considerable progress has been made in machine learning methods e.g., on the use of flexible nonlinear models, kernel-based methods, regularization techniques, sparsity, probabilistic approaches, different learning schemes and frameworks. This chapter provides a brief introduction to the machine learning section for Library in Signal Processing. The scope and context are specified and a brief overview on the chapter contributions is given.", 
        "author": "Johan A.K. Suykens", 
        "keyword": "Machine learning\", \"Signal processing\", \"Learning theory\", \"Kernel methods\", \"Support vector keywords =achines\", \"Neural networks\", \"Regularization\", \"Probabilistic graphical models\", \"Monte Carlo keywords =ethods\", \"Particle filtering\", \"Clustering\", \"Unsupervised learning\", \"Latent variable models\", keywords =Semi-supervised learning\", \"Compressed sensing\", \"Sparsity-aware learning\", \"Information based keywords =earning\", \"Model selection", 
        "title": "Chapter 13 - Introduction to Machine Learning"
    }, 
    {
        "abstract": "\\{ABSTRACT\\} Effective and efficient monitoring of furnace combustion state and measurement of heat release rate are important and pressing problems in the power industry. However, traditional methods including image segmentation based methods, feature based methods and shallow classifier based methods cannot meet the requirements of highly accurate. These methods are composed with several separating steps, i.e. feature selection and recognition. This paper proposes a novel deep learning based method to identify furnace combustion state and measure heat release rate. With an end-to-end network, feature extraction and classification are integrated into one framework. The deep learning model takes flame images into a multi-layer \\{DNN\\} (Deep Neural Network) or \\{CNN\\} (Convolutional Neural Network) to predict combustion state and heat release rate simultaneously. We also implement smooth and adjustment techniques which can get a trade-off between stability and sensitivity, ensuring both accurate prediction of burner state and fast detection of unstable combustion. The proposed system achieved state-of-the-art 99.9% accuracy in predicting combustion state with a speed of 1ms per image. Experimental results show that this method has great potential for practical applications on power plants.", 
        "author": "Zhenyu Wang and Chunfeng Song and Tao Chen", 
        "keyword": "deep learning\", \"combustion state\", \"heat release rate\", \"flame image\", \"convolutional neural keywords =etwork\", \"smooth and adjustment techniques", 
        "title": "Deep Learning based Monitoring of Furnace Combustion State and Measurement of Heat Release Rate"
    }, 
    {
        "abstract": "Abstract For the online prediction of nonlinear systems with characteristics of time-varying dynamics and uncertainty, a sequential grey prediction approach is proposed based on the online sequential extreme learning machine (OS-ELM). The grey processing of time series alleviates the unfavorable effects of uncertainty in measurement data; the extremely fast learning speed and high generalization accuracy of OS-ELM enable online application of the sequential grey prediction approach. Ship's roll motion at sea is a complex nonlinear process with time-varying dynamics. Its dynamics also involves uncertainty caused by wind, random waves and rudder actions. In this paper, the proposed OS-ELM-based grey prediction approach is implemented for online ship roll prediction. The simulation of prediction is based on measurement data obtained from sea trials of the scientific research and training ship Yu Kun. Simulation results of ship roll prediction demonstrate the effectiveness and efficiency of the proposed grey neural prediction approach in dealing with time-varying nonlinear system with uncertainty.", 
        "author": "Jian-Chuan Yin and Zao-Jian Zou and Feng Xu and Ni-Ni Wang", 
        "keyword": "Extreme learning machine\", \"Grey prediction\", \"Grey relational analysis\", \"Sequential learning\", keywords =Radial basis function network\", \"Ship roll prediction", 
        "title": "Online ship roll motion prediction based on grey sequential extreme learning machine"
    }, 
    {
        "abstract": "AbstractBackground This study sought to predict postsurgical seizure freedom from pre-operative diagnostic test results and clinical information using a rapid automated approach, based on supervised learning methods in patients with drug-resistant focal seizures suspected to begin in temporal lobe. Method We applied machine learning, specifically a combination of mutual information-based feature selection and supervised learning classifiers on multimodal data, to predict surgery outcome retrospectively in 20 presurgical patients (13 female; mean age\u00b1SD, in years 33\u00b19.7 for females, and 35.3\u00b19.4 for males) who were diagnosed with mesial temporal lobe epilepsy (MTLE) and subsequently underwent standard anteromesial temporal lobectomy. The main advantage of the present work over previous studies is the inclusion of the extent of ipsilateral neocortical gray matter atrophy and spatiotemporal properties of depth electrode-recorded seizures as training features for individual patient surgery planning. Results A maximum relevance minimum redundancy (mRMR) feature selector identified the following features as the most informative predictors of postsurgical seizure freedom in this study\u2019s sample of patients: family history of epilepsy, ictal \\{EEG\\} onset pattern (positive correlation with seizure freedom), MRI-based gray matter thickness reduction in the hemisphere ipsilateral to seizure onset, proportion of seizures that first appeared in ipsilateral amygdala to total seizures, age, epilepsy duration, delay in the spread of ipsilateral ictal discharges from site of onset, gender, and number of electrode contacts at seizure onset (negative correlation with seizure freedom). Using these features in combination with a least square support vector machine (LS-SVM) classifier compared to other commonly used classifiers resulted in very high surgical outcome prediction accuracy (95%). Conclusions Supervised machine learning using multimodal compared to unimodal data accurately predicted postsurgical outcome in patients with atypical MTLE.", 
        "author": "Negar Memarian and Sally Kim and Sandra Dewar and Jerome Engel Jr. and Richard J. Staba", 
        "keyword": "Mesial temporal epilepsy\", \"Surgical outcome prediction\", \"Supervised learning\", \"Mutual information", 
        "title": "Multimodal data and machine learning for surgery outcome prediction in complicated cases of mesial temporal lobe epilepsy"
    }, 
    {
        "abstract": "Abstract We describe an approximation to backpropagation algorithm for training deep neural networks, which is designed to work with synapses implemented with memristors. The key idea is to represent the values of both the input signal and the backpropagated delta value with a series of pulses that trigger multiple positive or negative updates of the synaptic weight, and to use the min operation instead of the product of the two signals. In computational simulations, we show that the proposed approximation to backpropagation is well converged and may be suitable for memristor implementations of multilayer neural networks.", 
        "author": "D. Negrov and I. Karandashev and V. Shakirov and Yu. Matveyev and W. Dunin-Barkowski and A. Zenkevich", 
        "keyword": "Deep learning\", \"Memristor\", \"Neural networks\", \"Hardware design\", \"Backpropagation algorithm", 
        "title": "An approximate backpropagation learning rule for memristor based neural networks using synaptic plasticity"
    }, 
    {
        "abstract": "Abstract This paper proposes a learning framework for single-hidden layer feedforward neural networks (SLFN) called optimized extreme learning machine (O-ELM). In O-ELM, the structure and the parameters of the \\{SLFN\\} are determined using an optimization method. The output weights, like in the batch ELM, are obtained by a least squares algorithm, but using Tikhonov's regularization in order to improve the \\{SLFN\\} performance in the presence of noisy data. The optimization method is used to the set of input variables, the hidden-layer configuration and bias, the input weights and Tikhonov's regularization factor. The proposed framework has been tested with three optimization methods (genetic algorithms, simulated annealing, and differential evolution) over 16 benchmark problems available in public repositories.", 
        "author": "Tiago Matias and Francisco Souza and Rui Ara\u00fajo and Carlos Henggeler Antunes", 
        "keyword": "Optimized extreme learning machine\", \"Single-hidden layer feedforward neural networks\", \"Genetic keywords =lgorithms\", \"Simulated annealing\", \"Differential evolution", 
        "title": "Learning of a single-hidden layer feedforward neural network using an optimized extreme learning machine"
    }, 
    {
        "abstract": "Abstract The endpoint parameters of molten steel, such as the steel temperature and the carbon content, directly affect the quality of the production steel. Moreover, these endpoint results cannot be the online continuous measurement in time. To solve the above-mentioned problems, an anti-jamming endpoint prediction model is proposed to predict the endpoint parameters of molten steel. More specifically, the model is constructed on the parameters of extreme learning machine (ELM) adaptively adjusted by the evolutionary membrane algorithm with the global optimization ability. In other words, the evolutionary membrane algorithm may find the suitable parameters of an \\{ELM\\} model which reduces the incidence of the overfitting of \\{ELM\\} affected by the noise in the actual data. Finally, the proposed model is applied to predict the endpoint parameters of molten steel in steel-making. In the simulation experiments, two test problems, including \u2018SinC\u2019 function with the Gaussian noise and the actual production data of basic oxygen furnace (BOF) steel-making, are employed to evaluate the performance of the proposed model. The results indicate that the proposed model has good prediction accuracy and robustness in the data with noise. Therefore, the proposed model has good application prospects in the industrial field.", 
        "author": "Min Han and Chuang Liu", 
        "keyword": "Prediction model\", \"Extreme learning machine\", \"Evolutionary membrane algorithm\", \"Soft keywords =easurement\", \"Basic oxygen furnace\", \"Endpoint carbon content\", \"Endpoint temperature", 
        "title": "Endpoint prediction model for basic oxygen furnace steel-making based on membrane algorithm evolving extreme learning machine"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM), a competitive machine learning technique for single-hidden-layer feedforward neural networks (SLFNNs), is simple in theory and fast in implementation. To deal with high-dimensional data with noise, \\{ELM\\} with a hierarchical structure (HELM) is proposed in this paper. The proposed \\{HELM\\} consists of two parts: some groups of subnets and a main net. The subnets are based on some well-trained auto-associative neural networks (AANNs), which can reduce dimension and filter out noise. The main net is based on the traditional ELM. Additionally, from the perspective of data attributes spaces (DASs), the difficulties in designing subnets are avoided by using a method of Data Attributes Extension Classification (DAEC). Experiments on five high-dimensional datasets with noise are carried out to examine the \\{HELM\\} model. Experimental results show that \\{HELM\\} has higher accuracy with fewer neurons in the main net than ELM.", 
        "author": "Yan-Lin He and Zhi-Qiang Geng and Yuan Xu and Qun-Xiong Zhu", 
        "keyword": "Extreme learning machine\", \"Single-hidden-layer feedforward neural networks\", \"Auto-associative keywords =eural network\", \"Matter-element model\", \"Data attributes extension classification", 
        "title": "A hierarchical structure of extreme learning machine (HELM) for high-dimensional datasets with noise"
    }, 
    {
        "abstract": "Abstract Crude oil is the world's leading fuel, and its prices have a big impact on the global environment, economy as well as oil exploration and exploitation activities. Oil price forecasts are very useful to industries, governments and individuals. Although many methods have been developed for predicting oil prices, it remains one of the most challenging forecasting problems due to the high volatility of oil prices. In this paper, we propose a novel approach for crude oil price prediction based on a new machine learning paradigm called stream learning. The main advantage of our stream learning approach is that the prediction model can capture the changing pattern of oil prices since the model is continuously updated whenever new oil price data are available, with very small constant overhead. To evaluate the forecasting ability of our stream learning model, we compare it with three other popular oil price prediction models. The experiment results show that our stream learning model achieves the highest accuracy in terms of both mean squared prediction error and directional accuracy ratio over a variety of forecast time horizons.", 
        "author": "Shuang Gao and Yalin Lei", 
        "keyword": "Crude oil\", \"Economic geology\", \"Prediction model\", \"Machine learning\", \"Stream learning", 
        "title": "A new approach for crude oil price prediction based on stream learning"
    }, 
    {
        "abstract": "Abstract A fast and outstanding incremental learning algorithm is required to meet the demand of online applications where data comes one by one or chunk by chunk to avoid retraining and save precious time. Although many interesting research results have been achieved, there are still a lot of difficulties in real applications because of their unsatisfying generalization performance or intensive computation cost. This paper presents an Incremental Extreme Learning Machine (IELM) which is developed based on Extreme Learning Machine (ELM), a unified framework of LS-SVM and \\{PSVM\\} presented by Hang et al. (2011) in [15]. Under different application demand and different computational cost and efficiency, three different alternative solutions of \\{IELM\\} are achieved. Detailed comparisons of the \\{IELM\\} algorithm with other incremental algorithms are achieved by simulation on benchmark problems and real critical dimension (CD) prediction problem in lithography of actual semiconductor production line. The results show that kernel based \\{IELM\\} solution performs best while least square \\{IELM\\} solution is the fastest of the three alterative solutions when the number of training data is huge. All the results show that the presented \\{IELM\\} algorithms have better performance than other incremental algorithms such as online sequential \\{ELM\\} (OS-ELM) presented by Liang et al. (2006) [8] and fixed size \\{LSSVM\\} presented by Espinoza et al. (2006) [11].", 
        "author": "Lu Guo and Jing-hua Hao and Min Liu", 
        "keyword": "Incremental learning algorithm\", \"Extreme learning machine (ELM)\", \"Incremental \\{ELM\\} (IELM)\", keywords =Online sequential \\{ELM\\} (OS-ELM)\", \"Fixed size \\{LSSVM\\} (FS-LSSVM)", 
        "title": "An incremental extreme learning machine for online sequential learning problems"
    }, 
    {
        "abstract": "Abstract Breast tumor detection in digital mammography is one of the most important methods of breast cancer prevention. Computer-aided diagnosis (CAD) based on extreme learning machine (ELM) has significant meanings for breast tumor detection as it has good generalization abilities and a high learning efficiency. In this paper, a breast tumor detection algorithm in digital mammography based on \\{ELM\\} is proposed. First, a median filter is used for noise reduction, and contrast enhancement of the digital mammography in data preprocessing. Next, methods of wavelet modulus maxima transform, morphological operation and region growth are used for the breast tumor edge segmentation. Then, five textural features and five morphological features are extracted. Finally, an \\{ELM\\} classifier is used to detect the breast tumor. Comparing breast tumor detection based on Support Vector Machines (SVM), with breast tumor detection based on ELM, not only does \\{ELM\\} have a better classification accuracy than SVM, but it also has a greatly improved training speed.", 
        "author": "Zhiqiong Wang and Ge Yu and Yan Kang and Yingjie Zhao and Qixun Qu", 
        "keyword": "Extreme learning machine\", \"Breast tumor detection\", \"Mammography\", \"Image segmentation\", \"Feature extraction", 
        "title": "Breast tumor detection in digital mammography based on extreme learning machine"
    }, 
    {
        "abstract": "Abstract Lithium-ion (Li-ion) battery state of charge (SOC) estimation is important for electric vehicles (EVs). The model-based state estimation method using the Kalman filter (KF) variants is studied and improved in this paper. To establish an accurate discrete model for Li-ion battery, the extreme learning machine (ELM) algorithm is proposed to train the model using experimental data. The estimation of \\{SOC\\} is then compared using four algorithms: extended Kalman filter (EKF), unscented Kalman filter (UKF), adaptive extended Kalman filter (AEKF) and adaptive unscented Kalman filter (AUKF). The comparison of the experimental results shows that \\{AEKF\\} and \\{AUKF\\} have better convergence rate, and \\{AUKF\\} has the best accuracy. The comparison from the radial basis function neural network (RBF NN) model also verifies that the \\{ELM\\} model has lighter computation load and smaller estimation error in \\{SOC\\} estimation process. In general, the performance of Li-ion battery \\{SOC\\} estimation is improved by the \\{AUKF\\} algorithm applied on the \\{ELM\\} model.", 
        "author": "Jiani Du and Zhitao Liu and Youyi Wang", 
        "keyword": "State of charge (SOC) estimation\", \"Battery modeling\", \"Extreme learning machine (ELM)\", \"Adaptive unscented Kalman filter (AUKF)", 
        "title": "State of charge estimation for Li-ion battery based on model from extreme learning machine"
    }, 
    {
        "abstract": "Abstract Vehicle climate control systems aim to keep passengers thermally comfortable. However, current systems control temperature rather than thermal comfort and tend to be energy hungry, which is of particular concern when considering electric vehicles. This paper poses energy-efficient vehicle comfort control as a Markov Decision Process, which is then solved numerically using Sarsa(\u03bb) and an empirically validated, single-zone, 1D thermal model of the cabin. The resulting controller was tested in simulation using 200 randomly selected scenarios and found to exceed the performance of bang-bang, proportional, simple fuzzy logic, and commercial controllers with 23%, 43%, 40%, 56% increase, respectively. Compared to the next best performing controller, energy consumption is reduced by 13% while the proportion of time spent thermally comfortable is increased by 23%. These results indicate that this is a viable approach that promises to translate into substantial comfort and energy improvements in the car.", 
        "author": "James Brusey and Diana Hintea and Elena Gaura and Neil Beloe", 
        "keyword": "Thermal comfort\", \"Reinforcement learning\", \"Equivalent temperature\", \"Comfort model\", \"Energy consumption", 
        "title": "Reinforcement learning-based thermal comfort control for vehicle cabins"
    }, 
    {
        "abstract": "Abstract In this paper, a novel method is proposed for Facial Expression Recognition (FER) using dictionary learning to learn both identity and expression dictionaries simultaneously. Accordingly, an automatic and comprehensive feature extraction method is proposed. The proposed method accommodates real-valued scores to a probability of what percent of the given Facial Expression (FE) is present in the input image. To this end, a dual dictionary learning method is proposed to learn both regression and feature dictionaries for FER. Then, two regression classification methods are proposed using a regression model formulated based on dictionary learning and two known classification methods including Sparse Representation Classification (SRC) and Collaborative Representation Classification (CRC). Convincing results are acquired for \\{FER\\} on the CK+, CK, \\{MMI\\} and \\{JAFFE\\} image databases compared to several state-of-the-arts. Also, promising results are obtained from evaluating the proposed method for generalization on other databases. The proposed method not only demonstrates excellent performance by obtaining high accuracy on all four databases but also outperforms other state-of-the-art approaches.", 
        "author": "Ali Moeini and Karim Faez and Hossein Moeini and Armon Matthew Safai", 
        "keyword": "Facial Expression Recognition\", \"Dual dictionary learning\", \"Sparse representation\", \"Regression classification", 
        "title": "Facial expression recognition using dual dictionary learning"
    }, 
    {
        "abstract": "Abstract Replacement decisions have a major effect on dairy farm profitability. Dynamic programming (DP) has been widely studied to find the optimal replacement policies in dairy cattle. However, \\{DP\\} models are computationally intensive and might not be practical for daily decision making. Hence, the ability of applying machine learning on a prerun \\{DP\\} model to provide fast and accurate predictions of nonlinear and intercorrelated variables makes it an ideal methodology. Milk class (1 to 5), lactation number (1 to 9), month in milk (1 to 20), and month of pregnancy (0 to 9) were used to describe all cows in a herd in a \\{DP\\} model. Twenty-seven scenarios based on all combinations of 3 levels (base, 20% above, and 20% below) of milk production, milk price, and replacement cost were solved with the \\{DP\\} model, resulting in a data set of 122,716 records, each with a calculated retention pay-off (RPO). Then, a machine learning model tree algorithm was used to mimic the evaluated \\{RPO\\} with DP. The correlation coefficient factor was used to observe the concordance of \\{RPO\\} evaluated by \\{DP\\} and \\{RPO\\} predicted by the model tree. The obtained correlation coefficient was 0.991, with a corresponding value of 0.11 for relative absolute error. At least 100 instances were required per model constraint, resulting in 204 total equations (models). When these models were used for binary classification of positive and negative RPO, error rates were 1% false negatives and 9% false positives. Applying this trained model from simulated data for prediction of \\{RPO\\} for 102 actual replacement records from the University of Wisconsin-Madison dairy herd resulted in a 0.994 correlation with 0.10 relative absolute error rate. Overall results showed that model tree has a potential to be used in conjunction with \\{DP\\} to assist farmers in their replacement decisions.", 
        "author": "Saleh Shahinfar and Afshin S. Kalantari and Victor Cabrera and Kent Weigel", 
        "keyword": "machine learning\", \"dynamic programming\", \"retention pay-off\", \"dairy cow", 
        "title": "Short communication: Prediction of retention pay-off using a machine learning algorithm"
    }, 
    {
        "abstract": "Abstract This paper analyzes the emergent behaviors of pedestrian groups that learn through the multiagent reinforcement learning model developed in our group. Five scenarios studied in the pedestrian model literature, and with different levels of complexity, were simulated in order to analyze the robustness and the scalability of the model. Firstly, a reduced group of agents must learn by interaction with the environment in each scenario. In this phase, each agent learns its own kinematic controller, that will drive it at a simulation time. Secondly, the number of simulated agents is increased, in each scenario where agents have previously learnt, to test the appearance of emergent macroscopic behaviors without additional learning. This strategy allows us to evaluate the robustness and the consistency and quality of the learned behaviors. For this purpose several tools from pedestrian dynamics, such as fundamental diagrams and density maps, are used. The results reveal that the developed model is capable of simulating human-like micro and macro pedestrian behaviors for the simulation scenarios studied, including those where the number of pedestrians has been scaled by one order of magnitude with respect to the situation learned.", 
        "author": "Francisco Martinez-Gil and Miguel Lozano and Fernando Fern\u00e1ndez", 
        "keyword": "Pedestrian simulation and modeling\", \"Multi-Agent Reinforcement Learning (MARL)\", \"Behavioural keywords =imulation\", \"Emergent behaviours", 
        "title": "Emergent behaviors and scalability for multi-agent reinforcement learning-based pedestrian models"
    }, 
    {
        "abstract": "Abstract This paper describes current trends in the prediction of crop pests using machine learning technology. With the advent of data mining, the field of agriculture is also focused on it. Currently, various studies, domestic and overseas, are under progress using machine learning technology, and cases of its utilization are increasing. This paper classifies and introduces \\{SVM\\} (Support Vector Machine), Multiple Linear Regression, Neural Network, and Bayesian Network based techniques, and describes some cases of their utilization.", 
        "author": "Yun Hwan Kim and Seong Joon Yoo and Yeong Hyeon Gu and Jin Hee Lim and Dongil Han and Sung Wook Baik", 
        "keyword": "Regression\", \"Machine Learning Technology\", \"SVM", 
        "title": "Crop Pests Prediction Method Using Regression and Machine Learning Technology: Survey"
    }, 
    {
        "abstract": "Abstract During building operation, a significant amount of energy is wasted due to equipment and human-related faults. To reduce waste, today's smart buildings monitor energy usage with the aim of identifying abnormal consumption behaviour and notifying the building manager to implement appropriate energy-saving procedures. To this end, this research proposes a new pattern-based anomaly classifier, the collective contextual anomaly detection using sliding window (CCAD-SW) framework. The CCAD-SW framework identifies anomalous consumption patterns using overlapping sliding windows. To enhance the anomaly detection capacity of the CCAD-SW, this research also proposes the ensemble anomaly detection (EAD) framework. The \\{EAD\\} is a generic framework that combines several anomaly detection classifiers using majority voting. To ensure diversity of anomaly classifiers, the \\{EAD\\} is implemented by combining pattern-based (e.g., CCAD-SW) and prediction-based anomaly classifiers. The research was evaluated using real-world data provided by Powersmiths, located in Brampton, Ontario, Canada. Results show that the \\{EAD\\} framework improved the sensitivity of the CCAD-SW by 3.6% and reduced false alarm rate by 2.7%.", 
        "author": "Daniel B. Araya and Katarina Grolinger and Hany F. ElYamany and Miriam A.M. Capretz and Girma Bitsuamlak", 
        "keyword": "Anomaly detection\", \"Ensemble learning\", \"Autoencoder\", \"Support vector regression\", \"Random keywords =orest\", \"Building energy consumption", 
        "title": "An ensemble learning framework for anomaly detection in building energy consumption"
    }, 
    {
        "abstract": "Abstract Recently, emotion classification from \\{EEG\\} data has attracted much attention with the rapid development of dry electrode techniques, machine learning algorithms, and various real-world applications of brain\u2013computer interface for normal people. Until now, however, researchers had little understanding of the details of relationship between different emotional states and various \\{EEG\\} features. To improve the accuracy of EEG-based emotion classification and visualize the changes of emotional states with time, this paper systematically compares three kinds of existing \\{EEG\\} features for emotion classification, introduces an efficient feature smoothing method for removing the noise unrelated to emotion task, and proposes a simple approach to tracking the trajectory of emotion changes with manifold learning. To examine the effectiveness of these methods introduced in this paper, we design a movie induction experiment that spontaneously leads subjects to real emotional states and collect an \\{EEG\\} data set of six subjects. From experimental results on our \\{EEG\\} data set, we found that (a) power spectrum feature is superior to other two kinds of features; (b) a linear dynamic system based feature smoothing method can significantly improve emotion classification accuracy; and (c) the trajectory of emotion changes can be visualized by reducing subject-independent features with manifold learning.", 
        "author": "Xiao-Wei Wang and Dan Nie and Bao-Liang Lu", 
        "keyword": "Emotion classification\", \"Electroencephalograph\", \"Brain\u2013computer interface\", \"Feature reduction\", keywords =Support vector machine\", \"Manifold learning", 
        "title": "Emotional state classification from \\{EEG\\} data using machine learning approach"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM), used for the \u201cgeneralized\u201d single-hidden-layer feedforward networks (SLFNs), is a unified learning platform that can use a widespread type of feature mappings. In theory, \\{ELM\\} can approximate any target continuous function and classify any disjoint regions; in application, many experiment results have already demonstrated the good performance of ELM. In view of the good properties of the \\{ELM\\} feature mapping, the clustering problem using \\{ELM\\} feature mapping techniques is studied in this paper. Experiments show that the proposed \\{ELM\\} kMeans algorithm and \\{ELM\\} \\{NMF\\} (nonnegative matrix factorization) clustering can get better clustering results than the corresponding Mercer kernel based methods and the traditional algorithms using the original data. Moreover, the proposed methods have the advantage of being more convenient to implementation and computation, as the \\{ELM\\} feature mapping is much simpler than the Mercer kernel function based feature mapping methods.", 
        "author": "Qing He and Xin Jin and Changying Du and Fuzhen Zhuang and Zhongzhi Shi", 
        "keyword": "Extreme learning machine (ELM)\", \"ELM feature space\", \"Data clustering\", \"Nonnegative matrix keywords =actorization (NMF)\", \"ELM kMeans\", \"ELM \\{NMF\\} clustering", 
        "title": "Clustering in extreme learning machine feature space"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) has shown its good performance in regression applications with a very fast speed. But there is still a difficulty to compromise between better generalization performance and smaller complexity of the \\{ELM\\} (a number of hidden nodes). This paper proposes a method called Delta Test-ELM (DT-ELM), which operates in an incremental way to create less complex \\{ELM\\} structures and determines the number of hidden nodes automatically. It uses Bayesian Information Criterion (BIC) as well as Delta Test (DT) to restrict the search as well as to consider the size of the network and prevent overfitting. Moreover, ensemble modeling is used on different DT-ELM models and it shows good test results in Experiments section.", 
        "author": "Qi Yu and Mark van Heeswijk and Yoan Miche and Rui Nian and Bo He and Eric S\u00e9verin and Amaury Lendasse", 
        "keyword": "Extreme learning machine\", \"Incremental learning\", \"Bayesian information criterion\", \"Delta test\", \"Ensemble modeling", 
        "title": "Ensemble delta test-extreme learning machine (DT-ELM) for regression"
    }, 
    {
        "abstract": "Abstract Devising a representation suitable for characterizing human actions on the basis of a sequence of pose estimates generated by an \\{RGBD\\} sensor remains a research challenge. We here provide two insights into this challenge. First, we show that discriminate sequence of poses typically occur over a short time window, and thus we propose a simple-but-effective local descriptor called a trajectorylet to capture the static and kinematic information within this interval. Second, we show that state of the art recognition results can be achieved by encoding each trajectorylet using a discriminative trajectorylet detector set which is selected from a large number of candidate detectors trained through exemplar-SVMs. The action-level representation is obtained by pooling trajectorylet encodings. Evaluating on standard datasets acquired from the Kinect sensor, it is demonstrated that our method obtains superior results over existing approaches under various experimental setups.", 
        "author": "Ruizhi Qiao and Lingqiao Liu and Chunhua Shen and Anton van den Hengel", 
        "keyword": "Action recognition\", \"Kinect\", \"Motion capture\", \"Feature learning\", \"Exemplar-SVM", 
        "title": "Learning discriminative trajectorylet detector sets for accurate skeleton-based action recognition"
    }, 
    {
        "abstract": "Abstract Thousands of first-millennium \\{BCE\\} ivory carvings have been excavated from Neo-Assyrian sites in Mesopotamia (primarily Nimrud, Khorsabad, and Arslan Tash), hundreds of miles from their Levantine production contexts. At present, their specific manufacture dates and workshop localities are unknown. Relying on subjective, visual methods, scholars have grappled with their classification and regional attribution for over a century. This study combines visual approaches with machine learning techniques to offer data-driven perspectives on the classification and attribution of this Iron Age corpus. The study sample consists of 162 sculptures of female figures that have been conventionally attributed to three main regional carving traditions: \u201cPhoenician,\u201d \u201cNorth Syrian,\u201d and \u201cSyrian/South Syrian\u201d. We have developed an algorithm that clusters the ivories based on a combination of descriptive and anthropometric data. The resulting categories, which are based on purely statistical criteria, show good agreement with conventional art historical classifications, while revealing new insights, especially with regard to the \u201cSyrian/South Syrian\u201d tradition. Specifically, we have determined that objects of the Syrian/South Syrian tradition might be more closely related to Phoenician objects than to North Syrian objects. We also reconsider the classification of a subset of \u201cPhoenician\u201d objects, and we confirm Syrian/South Syrian stylistic subgroups, the geographic distribution of which might illuminate Neo-Assyrian acquisition networks. Additionally, we have identified the features in our cluster assignments that might be diagnostic of regional traditions. In short, our study both corroborates traditional visual classifications and demonstrates how machine learning techniques may be employed to retrieve complementary information not accessible through an exclusively visual analysis.", 
        "author": "Amy Rebecca Gansell and Jan-Willem van de Meent and Sakellarios Zairis and Chris H. Wiggins", 
        "keyword": "Machine learning\", \"Clustering\", \"Mutual information\", \"Ivory sculpture\", \"Iron Age\", \"Levant\", \"Attribution", 
        "title": "Stylistic clusters and the Syrian/South Syrian tradition of first-millennium \\{BCE\\} Levantine ivory carving: a machine learning approach"
    }, 
    {
        "abstract": "Abstract Extreme learning machine (ELM) was proposed as a new learning algorithm to train single-hidden-layer feedforward neural networks (SLFNs). \\{ELM\\} has been proven to perform in high efficiency, however, due to the random determination of parameters for hidden nodes, some un-optimal parameters may be generated to influence the generalization performance and stability. Moreover, \\{ELM\\} may suffer from overtraining problem as the entire training dataset is used to minimize training error. In this paper, a hybrid model is proposed to alleviate such weaknesses of ELM. The model adopts genetic algorithms (GAs) to produce a group of candidate networks first, and according to a specific ranking strategy, some of the networks are selected to ensemble a new network. To verify the performance of our method, empirical comparisons were carried out with the canonical ELM, E-ELM, simple ensemble, EE-ELM, EN-ELM, Bagging and Adaboost to solve both regression and classification problems. The results have shown that our method is able to generate more robust networks with better generalization performance.", 
        "author": "Xiaowei Xue and Min Yao and Zhaohui Wu and Jianhua Yang", 
        "keyword": "Extreme learning machine\", \"Hybrid model\", \"Genetic algorithm\", \"Neural network ensemble", 
        "title": "Genetic ensemble of extreme learning machine"
    }, 
    {
        "abstract": "Abstract Online fault diagnosis system should be able to detect faults, recognize fault types and update the discriminating ability and knowledge of itself automatically in real time. But the class number in fault diagnosis is not constant and it is in a dynamic state with new members enrolled. The traditional recognition algorithms are not able to update diagnosis system efficiently when the class number of failure modes is increasing. To solve the problem, an online fault diagnosis method based on Incremental Support Vector Data Description (ISVDD) and Extreme Learning Machine with incremental output structure (IOELM) is proposed. \\{ISVDD\\} is used to find a new failure mode quickly in the continuous condition monitoring of the equipments. The fixed structure of Extreme Learning Machine is changed into an elastic structure whose output nodes could be added incrementally to recognize the new fault mode efficiently. Recognition experiments on the diesel engine under eleven different conditions show that the online fault diagnosis method based on \\{ISVDD\\} and \\{IOELM\\} works well, and the method is also feasible in fault diagnosis of other mechanical equipments.", 
        "author": "Gang Yin and Ying-Tang Zhang and Zhi-Ning Li and Guo-Quan Ren and Hong-Bo Fan", 
        "keyword": "Incremental Support Vector Data Description\", \"Extreme Learning Machine\", \"Multi-scale principal keywords =omponent analysis\", \"Online fault diagnosis", 
        "title": "Online fault diagnosis method based on Incremental Support Vector Data Description and Extreme Learning Machine with incremental output structure"
    }, 
    {
        "abstract": "Abstract This paper describes the neural controller design for the longitudinal dynamics of a generic hypersonic flight vehicle (HFV). The dynamics are transformed into the strict-feedback form. Considering the uncertainty, the neural controller is constructed based on the single-hidden layer feedforward network(SLFN). The hidden node parameters are modified using extreme learning machine (ELM) by assigning random values. Instead of using online sequential learning algorithm (OSLA), the output weight is updated based on the Lyapunov synthesis approach to guarantee the stability of closed-loop system. By estimating the bound of output weight vector, a novel back-stepping design is presented where less online parameters are required to be tuned. The simulation study is presented to show the effectiveness of the proposed control approach.", 
        "author": "Bin Xu and Yongping Pan and Danwei Wang and Fuchun Sun", 
        "keyword": "Hypersonic aircraft\", \"Extreme learning machine\", \"Neural networks\", \"Single-hidden layer feedforward network", 
        "title": "Discrete-time hypersonic flight control based on extreme learning machine"
    }, 
    {
        "abstract": "Abstract The purpose of supervised learning with temporal encoding for spiking neurons is to make the neurons emit a specific spike train encoded by precise firing times of spikes. The gradient-descent-based (GDB) learning methods are widely used and verified in the current research. Although the existing \\{GDB\\} multi-spike learning (or spike sequence learning) methods have good performance, they work in an offline manner and still have some limitations. This paper proposes an online \\{GDB\\} spike sequence learning method for spiking neurons that is based on the online adjustment mechanism of real biological neuron synapses. The method constructs error function and calculates the adjustment of synaptic weights as soon as the neurons emit a spike during their running process. We analyze and synthesize desired and actual output spikes to select appropriate input spikes in the calculation of weight adjustment in this paper. The experimental results show that our method obviously improves learning performance compared with the offline learning manner and has certain advantage on learning accuracy compared with other learning methods. Stronger learning ability determines that the method has large pattern storage capacity.", 
        "author": "Yan Xu and Jing Yang and Shuiming Zhong", 
        "keyword": "Spiking neurons\", \"Spike sequence learning\", \"Online learning\", \"Gradient descent\", \"Real time error function", 
        "title": "An online supervised learning method based on gradient descent for spiking neurons"
    }, 
    {
        "abstract": "Abstract We propose an algorithm to learn from distributed data on a network of arbitrarily connected machines without exchange of the data-points. Parts of the dataset are processed locally at each machine, and then the consensus communication algorithm is employed to consolidate the results. This iterative two stage process converges as if the entire dataset had been on a single machine. The principal contribution of this paper is the proof of convergence of the distributed learning process in the general case that the learning algorithm is a contraction. Moreover, we derive the distributed update equation of a feed-forward neural network with back-propagation for the purpose of verifying the theoretical results. We employ a toy classification example and a real world binary classification dataset.", 
        "author": "Leonidas Georgopoulos and Martin Hasler", 
        "keyword": "Distributed machine learning\", \"Parallel machine learning\", \"Gradient descent\", \"Consensus\", keywords =Peer-to-peer learning\", \"Neural networks", 
        "title": "Distributed machine learning in networks by consensus"
    }, 
    {
        "abstract": "Abstract We present an approach to optimize the MapReduce architecture, which could make heterogeneous cloud environment more stable and efficient. Fundamentally different from previous methods, our approach introduces the machine learning technique into MapReduce framework, and dynamically improve MapReduce algorithm according to the statistics result of machine learning. There are three main aspects: learning machine performance, reduce task assignment algorithm based on learning result, and speculative execution optimization mechanism. Furthermore, there are two important features in our approach. First, the MapReduce framework can obtain nodes' performance values in the cluster through machine learning module. And machine learning module will daily calibrate nodes' performance values to make an accurate assessment of cluster performance. Second, with the optimization of tasks assignment algorithm, we can maximize the performance of heterogeneous clusters. According to our evaluation result, the cluster performance could have 19% improvement in current heterogeneous cloud environment, and the stability of cluster has greatly enhanced.", 
        "author": "Wen-hui LIN and Zhen-ming LEI and Jun LIU and Jie YANG and Fang LIU and Gang HE and Qin WANG", 
        "keyword": "cloud computing\", \"MapReduce\", \"machine learning\", \"heterogeneity", 
        "title": "MapReduce optimization algorithm based on machine learning in heterogeneous cloud environment"
    }, 
    {
        "abstract": "Abstract: Spectroscopic techniques are only as powerful as the information that can be extracted from the resulting spectral data. Machine learning is the study of techniques for the automated extraction of information from raw data. Proper application of machine learning to spectral data allows users to make decisions as data are collected, without human-in-the-loop processing. This chapter provides an overview of the application of machine-learning techniques to spectroscopic data. Topics such as data pre-processing, feature selection, classifier development, and cross-validation are discussed in light of the high dimensional data typical of laser spectroscopy.", 
        "author": "P. Torrione and L.M. Collins and K.D. Morton Jr.", 
        "keyword": "machine learning\", \"pattern recognition\", \"chemometrics\", \"spectroscopy\", \"cross-validation", 
        "title": "5 - Multivariate analysis, chemometrics, and machine learning in laser spectroscopy"
    }, 
    {
        "abstract": "Abstract Visual saliency has been increasingly studied in relation to image quality assessment. Incorporating saliency potentially leads to improved ability of image quality metrics to predict perceived quality. However, challenges to optimising the combination of saliency and image quality metrics remain. Previous psychophysical studies have shown that distortion occurring in an image causes visual distractions, and alters gaze patterns relative to that of the image without distortion. From this, it can be inferred that the measurable changes of gaze patterns driven by distortion may be used as a proxy for the likely variation in perceived quality of natural images. In this paper, rather than using saliency as an add-on to image quality metrics, we investigate the plausibility of approximating picture quality based on measuring the deviation of saliency induced by distortion. First, we designed and conducted a large-scale eye-tracking experiment to clarify the knowledge on the relationship between the deviation of saliency and the variability of image quality. We then used the results to devise an algorithm which predicts perceived image quality based on visual distraction. Experimental results demonstrate this can provide good results of image quality prediction.", 
        "author": "Wei Zhang and Hantao Liu", 
        "keyword": "Picture quality\", \"Visual distraction\", \"Saliency\", \"Eye-tracking\", \"Statistical learning", 
        "title": "Learning picture quality from visual distraction: Psychophysical studies and computational models"
    }, 
    {
        "abstract": "Abstract Real-time fault diagnostic system is very important to maintain the operation of the gas turbine generator system (GTGS) in power plants, where any abnormal situation will interrupt the electricity supply. The \\{GTGS\\} is complicated and has many types of component faults. To prevent from interruption of electricity supply, a reliable and quick response framework for real-time fault diagnosis of the \\{GTGS\\} is necessary. As the architecture and the learning algorithm of extreme learning machine (ELM) are simple and effective respectively, \\{ELM\\} can identify faults quickly and precisely as compared with traditional identification techniques such as support vector machines (SVM). This paper therefore proposes a new application of \\{ELM\\} for building a real-time fault diagnostic system in which data pre-processing techniques are integrated. In terms of data pre-processing, wavelet packet transform and time-domain statistical features are proposed for extraction of vibration signal features. Kernel principal component analysis is then applied to further reduce the redundant features in order to shorten the fault identification time and improve accuracy. To evaluate the system performance, a comparison between \\{ELM\\} and the prevailing \\{SVM\\} on the fault detection was conducted. Experimental results show that the proposed diagnostic framework can detect component faults much faster than SVM, while \\{ELM\\} is competitive with \\{SVM\\} in accuracy. This paper is also the first in the literature that explores the superiority of the fault identification time of ELM.", 
        "author": "Pak Kin Wong and Zhixin Yang and Chi Man Vong and Jianhua Zhong", 
        "keyword": "Real-time fault diagnosis\", \"Gas turbine generator system\", \"Extreme learning machine\", \"Wavelet keywords =acket transform\", \"Time-domain statistical features\", \"Kernel principal component analysis", 
        "title": "Real-time fault diagnosis for gas turbine generator systems using extreme learning machine"
    }, 
    {
        "abstract": "Abstract Deep brain stimulation (DBS) has been applied as an effective therapy for treating Parkinson's disease or essential tremor. Several open-loop \\{DBS\\} control strategies have been developed for clinical experiments, but they are limited by short battery life and inefficient therapy. Therefore, many closed-loop \\{DBS\\} control systems have been designed to tackle these problems by automatically adjusting the stimulation parameters via feedback from neural signals, which has been reported to reduce the power consumption. However, when the association between the biomarkers of the model and stimulation is unclear, it is difficult to develop an optimal control scheme for other \\{DBS\\} applications, i.e., DBS-enhanced instrumental learning. Furthermore, few studies have investigated the effect of closed-loop \\{DBS\\} control for cognition function, such as instrumental skill learning, and have been implemented in simulation environments. In this paper, we proposed a proof-of-principle design for a closed-loop \\{DBS\\} system, cognitive-enhancing \\{DBS\\} (ceDBS), which enhanced skill learning based on in\u00a0vivo experimental data. The ceDBS acquired local field potential (LFP) signal from the thalamic central lateral (CL) nuclei of animals through a neural signal processing system. A strong coupling of the theta oscillation (4\u20137\u00a0Hz) and the learning period was found in the water reward-related lever-pressing learning task. Therefore, the theta-band power ratio, which was the averaged theta band to averaged total band (1\u201355\u00a0Hz) power ratio, could be used as a physiological marker for enhancement of instrumental skill learning. The on-line extraction of the theta-band power ratio was implemented on a field-programmable gate array (FPGA). An autoregressive with exogenous inputs (ARX)-based predictor was designed to construct a CL-thalamic \\{DBS\\} model and forecast the future physiological marker according to the past physiological marker and applied DBS. The prediction could further assist the design of a closed-loop \\{DBS\\} controller. A \\{DBS\\} controller based on a fuzzy expert system was devised to automatically control \\{DBS\\} according to the predicted physiological marker via a set of rules. The simulated experimental results demonstrate that the ceDBS based on the closed-loop control architecture not only reduced power consumption using the predictive physiological marker, but also achieved a desired level of physiological marker through the \\{DBS\\} controller.", 
        "author": "Ching-Fu Wang and Shih-Hung Yang and Sheng-Huang Lin and Po-Chuan Chen and Yu-Chun Lo and Han-Chi Pan and Hsin-Yi Lai and Lun-De Liao and Hui-Ching Lin and Hsu-Yan Chen and Wei-Chen Huang and Wun-Jhu Huang and You-Yin Chen", 
        "keyword": "Deep brain stimulation\", \"Closed-loop system\", \"Local field potential\", \"Autoregressive exogenous\", keywords =Fuzzy expert system\", \"Instrumental skill learning", 
        "title": "A proof-of-principle simulation for closed-loop control based on preexisting experimental thalamic DBS-enhanced instrumental learning"
    }, 
    {
        "abstract": "Abstract While there have been many articles written on the advantages and techniques of goal setting, there has been far less written to guide practicing managers on how to put this powerful motivational tool to work. This article offers a three-step process that begins by identifying the combination of performance, learning, and behavioral goals to best match the unique knowledge, skills, and abilities of the employee to the task requirements of the job. Once this best-goal combination has been determined, the manager's letter, a managerial tool developed by Peter Drucker, is presented as a well-accepted process for implementing a goal-setting strategy that emphasizes employee participation. The third step in the implementation of a goal-setting strategy is to introduce subconscious primes that can reinforce the value of setting performance, learning, and behavioral goals.", 
        "author": "Robert C. Ford", 
        "keyword": "Goal setting\", \"Management by objectives\", \"Learning goals\", \"Performance goals\", \"Behavioral keywords =oals\", \"Priming\", \"SMART goals", 
        "title": "Combining performance, learning, and behavioral goals to match job with person: Three steps to enhance employee performance with goal setting"
    }, 
    {
        "abstract": "Abstract Automatically driving based on computer vision has attracted more and more attentions from both research and industrial fields. It has two main challenges, high road and vehicle detection accuracy and real-time performance. To study the two problems, we developed a driving simulation platform in a virtual scene. In this paper, as the first step of final solution, the Extreme Learning Machine (ELM) has been used to detect the virtual roads and vehicles. The Support Vector Machine (SVM) and Back Propagation (BP) network have been used as benchmark. Our experimental results show that the \\{ELM\\} has the fastest performance on road segmentation and vehicle detection with the similar accuracy compared with other techniques.", 
        "author": "Wentao Zhu and Jun Miao and Jiangbi Hu and Laiyun Qing", 
        "keyword": "Extreme learning machine\", \"Driving simulation\", \"Vehicle detection\", \"Road segmentation", 
        "title": "Vehicle detection in driving simulation using extreme learning machine"
    }, 
    {
        "abstract": "Abstract How to design water-in-glass evacuated tube solar water heater (WGET-SWH) with high heat collection rates has long been a question. Here, we propose a high-throughput screening (HTS) method based on machine learning to design and screen 3.538125 \u00d7 108 possible combinations of extrinsic properties of WGET-SWH, to discover promising WGET-SWHs by comparing their predicted heat collection rates. Two new-designed WGET-SWHs were installed experimentally and showed higher heat collection rates (11.32 and 11.44 MJ/m2, respectively) than all the 915 measured samples in our previous database. This study shows that we can use the \\{HTS\\} method to modify the design of WGET-SWH with just few knowledge about the highly complicated correlations between the extrinsic properties and heat collection rates of solar water heaters.", 
        "author": "Zhijian Liu and Hao Li and Kejun Liu and Hancheng Yu and Kewei Cheng", 
        "keyword": "Water-in-glass evacuated tube solar water heater (WGET-SWH)\", \"Heat collection rate\", keywords =High-throughput screening (HTS)\", \"Artificial neural networks (ANNs)", 
        "title": "Design of high-performance water-in-glass evacuated tube solar water heaters by a high-throughput screening based on machine learning: A combined modeling and experimental study"
    }, 
    {
        "abstract": "Abstract Visual data classification, which is aimed at determining a unique label for each class, is an increasingly important issue in the machine learning community. In recent years, increasing attention has been paid to the application of metric learning for classification, which has been proven to be a good way to obtain a promising performance. However, as a result of the limited training samples and data with complex distributions, the vast majority of these algorithms usually fail to perform well. This has motivated us to develop a novel locally adaptive maximum margin metric learning (LAM3L) algorithm in order to maximally separate similar and dissimilar classes, based on the changes between the distances before and after the maximum margin metric learning. The experimental results on two widely used \\{UCI\\} datasets and a real hyperspectral dataset demonstrate that the proposed method outperforms the state-of-the-art metric learning methods.", 
        "author": "Yanni Dong and Bo Du and Lefei Zhang and Liangpei Zhang and Dacheng Tao", 
        "keyword": "Visual data classification\", \"Mahalanobis distance\", \"Metric learning\", \"Locally adaptive constraints", 
        "title": "LAM3L: Locally adaptive maximum margin metric learning for visual data classification"
    }, 
    {
        "abstract": "Abstract In this paper, we present one dynamic model hypothesis to perform fish trajectory tracking in the fish ethology research and develop the relevant mathematical criterion on the basis of the Extreme Learning Machine (ELM). It is shown that the proposed scheme can conduct the non-linear and non Gaussian tracking process by multiple historical cues and current predictions \u2013 the state vector motion, the color distribution and the appearance recognition, all of which can be extracted from the single-hidden layer feedforward neural network (SLFN) at diverse levels with ELM. The strategy of the hierarchical hybrid \\{ELM\\} ensemble then combines the individual \\{SLFN\\} of the tracking cues for the performance improvements. The simulation results have shown the excellent performance in both robustness and accuracy of the developed approach.", 
        "author": "Rui Nian and Bo He and Bing Zheng and Mark van Heeswijk and Qi Yu and Yoan Miche and Amaury Lendasse", 
        "keyword": "Extreme learning machine\", \"Fish ethology\", \"Video surveillance system\", \"Dynamic state space\", keywords =Color distribution\", \"Object recognition", 
        "title": "Extreme learning machine towards dynamic model hypothesis in fish ethology research"
    }, 
    {
        "abstract": "Abstract Bankruptcy prediction has been widely studied as a binary classification problem using financial ratios methodologies. In this paper, Leave-One-Out-Incremental Extreme Learning Machine (LOO-IELM) is explored for this task. LOO-IELM operates in an incremental way to avoid inefficient and unnecessary calculations and stops automatically with the neurons of which the number is unknown. Moreover, Combo method and further Ensemble model are investigated based on different LOO-IELM models and the specific financial indicators. These indicators are chosen using different strategies according to the financial expertise. The entire process has shown its good performance with a very fast speed, and also helps to interpret the model and the special ratios.", 
        "author": "Qi Yu and Yoan Miche and Eric S\u00e9verin and Amaury Lendasse", 
        "keyword": "Extreme Learning Machine\", \"Leave-One-Out\", \"Incremental Learning\", \"Bankruptcy Prediction", 
        "title": "Bankruptcy prediction using Extreme Learning Machine and financial expertise"
    }, 
    {
        "abstract": "Abstract Extreme Learning Machine (ELM) as an emergent technology has shown its promising performance in many applications. This paper proposes a parallelized \\{ELM\\} ensemble based on the Min\u2013Max Modular network (M3-network) to meet the challenge of the so-called big data. The proposed M3-ELM first decomposes classification problems into smaller subproblems, then trains an \\{ELM\\} for each subproblem, and in the end ensembles these \\{ELMs\\} with the M3-network. Twelve data sets including both benchmarks and real-world applications are employed to test the proposed method. The experimental results show that M3-ELM not only speeds up the training phrases by 1.6\u20134.6 times but also reduces the test errors by 0.37\u201319.51% compared with the normal ELM. The results also indicate that M3-ELM possesses scalability on large-scale tasks and accuracy improvement on imbalanced tasks.", 
        "author": "Xiao-Lin Wang and Yang-Yang Chen and Hai Zhao and Bao-Liang Lu", 
        "keyword": "Extreme learning machine\", \"Min\u2013max modular network\", \"Big data\", \"Ensemble method\", \"Parallel learning", 
        "title": "Parallelized extreme learning machine ensemble based on min\u2013max modular network"
    }, 
    {
        "abstract": "Abstract In this paper, a novel recognition scheme is proposed for identifying the aircrafts of different types based on multiple modular neural network classifiers. Three moment invariants including Hu moments, Zernike moments and Wavelet moments are extracted from the characteristics exhibited by aircrafts and used as the input variables of each modular neural network respectively. Each modular neural network consists of multiple single-hidden layer feedforward networks which are trained using the extreme learning machine and different clustering data subsets. A clustering and selection method is used to get the classification rate of each modular neural network and then based on their weighted sum the final classification output is obtained. The proposed recognition scheme is finally evaluated by recognizing six different types of aircraft models and the simulation results show the superiority of the proposed method compared with the single \\{ELM\\} classifier and other classification algorithms.", 
        "author": "Hai-Jun Rong and Ya-Xin Jia and Guang-She Zhao", 
        "keyword": "Single-hidden layer feedforward network\", \"Extreme learning machine\", \"Aircraft recognition\", \"Hu keywords =oments\", \"Zernike moments\", \"Wavelet moments", 
        "title": "Aircraft recognition using modular extreme learning machine"
    }, 
    {
        "abstract": "Abstract Nowadays, land-cover change detection plays a more and more important role in environment protection and many other fields. However, the current land-cover change detection methods encounter the problems of low accuracy and low efficiency, especially in dealing with large scale remote sensing (RS) data. This paper presents a novel extreme learning machine (ELM) based land-cover change detection method with high testing accuracy and fast processing speed. The evaluation results show that \\{ELM\\} outperforms the traditional methods, e.g., \\{SVM\\} and \\{BP\\} network, in terms of training speed and generalization performance, when applied in land-cover classification. In our experiments, we apply our method to the analysis of rapid land use change in Taihu Lake region over the past decade.", 
        "author": "Jiaoyan Chen and Guozhou Zheng and Cong Fang and Ningyu Zhang and Huajun Chen and Zhaohui Wu", 
        "keyword": "Extreme learning machine\", \"Remote sensing\", \"Classification\", \"Change detection\", \"Time-series", 
        "title": "Time-series processing of large scale remote sensing data with extreme learning machine"
    }, 
    {
        "abstract": "Abstract This paper investigates the construction of linear-in-the-parameters (LITP) models for multi-output regression problems. Most existing stepwise forward algorithms choose the regressor terms one by one, each time maximizing the model error reduction ratio. The drawback is that such procedures cannot guarantee a sparse model, especially under highly noisy learning conditions. The main objective of this paper is to improve the sparsity and generalization capability of a model for multi-output regression problems, while reducing the computational complexity. This is achieved by proposing a novel multi-output two-stage locally regularized model construction (MTLRMC) method using the extreme learning machine (ELM). In this new algorithm, the nonlinear parameters in each term, such as the width of the Gaussian function and the power of a polynomial term, are firstly determined by the ELM. An initial multi-output \\{LITP\\} model is then generated according to the termination criteria in the first stage. The significance of each selected regressor is checked and the insignificant ones are replaced at the second stage. The proposed method can produce an optimized compact model by using the regularized parameters. Further, to reduce the computational complexity, a proper regression context is used to allow fast implementation of the proposed method. Simulation results confirm the effectiveness of the proposed technique.", 
        "author": "Dajun Du and Kang Li and Xue Li and Minrui Fei and Haikuan Wang", 
        "keyword": "Extreme learning machine\", \"Multi-output linear-in-the-parameters (LITP) model\", \"Regularization\", \"Two-stage stepwise selection", 
        "title": "A multi-output two-stage locally regularized model construction method using the extreme learning machine"
    }, 
    {
        "abstract": "Abstract As an important management tool of winning competitive advantage, induced learning effect has been widely studied in empirical research area. But it is hardly considered in scheduling problems. In this paper, autonomous and induced learning are both taken into consideration. The investment of induced learning is interpreted as specialized time intervals to implement training, knowledge sharing and transferring etc. We present algorithms to determine jointly the optimal job sequence and the optimal position of induced learning intervals, with the objective of minimizing makespan.", 
        "author": "Xiaoqing Zhang and Linyan Sun and Jibo Wang", 
        "keyword": "Learning effect\", \"Autonomous and induced learning\", \"Single machine scheduling\", \"Group balance principle", 
        "title": "Single machine scheduling with autonomous learning and induced learning"
    }, 
    {
        "abstract": "Abstract Kernels for Structured Domains are widely adopted in real-world applications that involve learning on structured data. In this context many kernels have been proposed in literature, but no theoretical comparison among them is present. In this paper we provide different formal definitions of expressiveness of a kernel by exploiting the most recent results in the field of Statistical Learning Theory, and analyze the differences among some state-of-the-art Graph Kernels. Results on real world datasets confirm some known properties of Graph Kernels, showing that Statistical Learning Theory is indeed a powerful and practical tool able to perform this analysis.", 
        "author": "Luca Oneto and Nicol\u00f2 Navarin and Michele Donini and Alessandro Sperduti and Fabio Aiolli and Davide Anguita", 
        "keyword": "Kernel\", \"Structured Domain\", \"Expressivity\", \"Graph Kernels\", \"Statistical Learning Theory\", keywords =Rademacher Complexity\", \"Local Rademacher Complexity\", \"Algorithmic Stability", 
        "title": "Measuring the Expressivity of Graph Kernels through Statistical Learning Theory"
    }, 
    {
        "abstract": "Abstract Automated Tool condition monitoring is critical in intelligent manufacturing to improve both productivity and sustainability of manufacturing operations. Estimation of tool wear in real-time for critical machining operations can improve part quality and reduce scrap rates. This paper proposes a probabilistic method based on a Particle Learning (PL) approach by building a linear system transition function whose parameters are updated through online in-process observations of the machining process. By applying PL, the method helps to avoid developing a complex closed form formulation for a specific tool wear model. It increases the robustness of the algorithm and reduces the time complexity of computation. The application of the \\{PL\\} approach is tested using experiments performed on a milling machine. We have demonstrated one-step and two-step look ahead tool wear state prediction using online indirect measurements obtained from vibration signals. Additionally, the study also estimates remaining useful life (RUL) of the cutting tool inserts.", 
        "author": "Jianlei Zhang and Binil Starly and Yi Cai and Paul H. Cohen and Yuan-Shin Lee", 
        "keyword": "Particle learning\", \"Tool wear\", \"Intelligent manufacturing\", \"Remaining useful life (RUL)", 
        "title": "Particle learning in online tool wear diagnosis and prognosis"
    }, 
    {
        "abstract": "Abstract Rapid, automated determination of the mapping of free text phrases to pre-defined concepts could assist in the annotation of clinical notes and increase the speed of natural language processing systems. The aim of this study was to design and evaluate a token-order-specific na\u00efve Bayes-based machine learning system (RapTAT) to predict associations between phrases and concepts. Performance was assessed using a reference standard generated from 2860 \\{VA\\} discharge summaries containing 567,520 phrases that had been mapped to 12,056 distinct Systematized Nomenclature of Medicine \u2013 Clinical Terms (SNOMED CT) concepts by the \\{MCVS\\} natural language processing system. It was also assessed on the manually annotated, 2010 i2b2 challenge data. Performance was established with regard to precision, recall, and F-measure for each of the concepts within the \\{VA\\} documents using bootstrapping. Within that corpus, concepts identified by \\{MCVS\\} were broadly distributed throughout \\{SNOMED\\} CT, and the token-order-specific language model achieved better performance based on precision, recall, and F-measure (0.95 \u00b1 0.15, 0.96 \u00b1 0.16, and 0.95 \u00b1 0.16, respectively; mean \u00b1 SD) than the bag-of-words based, na\u00efve Bayes model (0.64 \u00b1 0.45, 0.61 \u00b1 0.46, and 0.60 \u00b1 0.45, respectively) that has previously been used for concept mapping. Precision, recall, and F-measure on the i2b2 test set were 92.9%, 85.9%, and 89.2% respectively, using the token-order-specific model. RapTAT required just 7.2 ms to map all phrases within a single discharge summary, and mapping rate did not decrease as the number of processed documents increased. The high performance attained by the tool in terms of both accuracy and speed was encouraging, and the mapping rate should be sufficient to support near-real-time, interactive annotation of medical narratives. These results demonstrate the feasibility of rapidly and accurately mapping phrases to a wide range of medical concepts based on a token-order-specific na\u00efve Bayes model and machine learning.", 
        "author": "Glenn T. Gobbel and Ruth Reeves and Shrimalini Jayaramaraja and Dario Giuse and Theodore Speroff and Steven H. Brown and Peter L. Elkin and Michael E. Matheny", 
        "keyword": "NLP\", \"natural language processing\", \"SNOMED-CT\", \"Systematized Nomenclature of Medicine-Clinical keywords =erms\", \"RapTAT\", \"Rapid Text Annotation Tool\", \"UMLS\", \"Unified Medical Language System\", \"SVM\", keywords =support vector machine\", \"MCVS\", \"Multi-threaded Clinical Vocabulary Server\", \"CSV\", \"comma-separated keywords =alue\", \"TP\", \"true positive\", \"FP\", \"false positive\", \"FN\", \"false negative\", \"IQV\", \"index of keywords =ualitative variation\", \"Opt\", \"optimism\", \"Perf\", \"performance\", \"Natural language processing\", keywords =Bayesian prediction\", \"Machine learning\", \"Systematized nomenclature of medicine", 
        "title": "Development and evaluation of RapTAT: A machine learning system for concept mapping of phrases from medical narratives"
    }, 
    {
        "abstract": "Abstract In this paper, a novel 1-norm extreme learning machine (ELM) for regression and multiclass classification is proposed as a linear programming problem whose solution is obtained by solving its dual exterior penalty problem as an unconstrained minimization problem using a fast Newton method. The algorithm converges from any starting point and can be easily implemented in MATLAB. The main advantage of the proposed approach is that it leads to a sparse model representation meaning that many components of the optimal solution vector will become zero and therefore the decision function can be determined using much less number of hidden nodes in comparison to ELM. Numerical experiments were performed on a number of interesting real-world benchmark datasets and their results are compared with \\{ELM\\} using additive and radial basis function (RBF) hidden nodes, optimally pruned \\{ELM\\} (OP-ELM) and support vector machine (SVM) methods. Similar or better generalization performance of the proposed method on the test data over ELM, OP-ELM and \\{SVM\\} clearly illustrates its applicability and usefulness.", 
        "author": "S. Balasundaram and Deepak Gupta and Kapil", 
        "keyword": "Extreme learning machine\", \"Dual exterior penalty problem\", \"Feedforward neural networks\", \"Linear keywords =rogramming problem\", \"Newton method", 
        "title": "1-Norm extreme learning machine for regression and multiclass classification using Newton method"
    }, 
    {
        "abstract": "AbstractBackground Many investigations based on nonlinear methods have been carried out for the research of seizure detection. However, some of these nonlinear measures cannot achieve satisfying performance without considering the basic rhythms of epileptic EEGs. New method To overcome the defects, this paper proposed a framework on wavelet-based nonlinear features and extreme learning machine (ELM) for the seizure detection. Three nonlinear methods, i.e., approximate entropy (ApEn), sample entropy (SampEn) and recurrence quantification analysis (RQA) were computed from orignal \\{EEG\\} signals and corresponding wavelet decomposed sub-bands separately. The wavelet-based energy was measured as the comparative. Then the combination of sub-band features was fed to \\{ELM\\} and \\{SVM\\} classifier respectively. Results The decomposed sub-band signals show significant discrimination between interictal and ictal states and the union of sub-band features helps to achieve better detection. All the three nonlinear methods show higher sensitivity than the wavelet-based energy analysis using the proposed framework. The wavelet-based SampEn-ELM detector reaches the best performance with a sensitivity of 92.6% and a false detection rate (FDR) of 0.078. Compared with SVM, the \\{ELM\\} detector is better in terms of detection accuracy and learning efficiency. Comparison with existing method(s) The decomposition of original signals into sub-bands leads to better identification of seizure events compared with that of the existing nonlinear methods without considering the time\u2013frequency decomposition. Conclusions The proposed framework achieves not only a high detection accuracy but also a very fast learning speed, which makes it feasible for the further development of the automatic seizure detection system.", 
        "author": "Lan-Lan Chen and Jian Zhang and Jun-Zhong Zou and Chen-Jie Zhao and Gui-Song Wang", 
        "keyword": "Seizure detection\", \"Wavelet decomposition\", \"Approximate entropy (ApEn)\", \"Sample entropy (keywords =ampEn)\", \"Recurrence quantification analysis (RQA)\", \"Extreme learning machine (ELM)\", \"Support vector machine (SVM)", 
        "title": "A framework on wavelet-based nonlinear features and extreme learning machine for epileptic seizure detection"
    }, 
    {
        "abstract": "Abstract Suspended particulate matters (PM10) is considered as a harmful air pollutant. Many models attempt to predict numerical levels of \\{PM10\\} but a simple, clearly defined classification of \\{PM10\\} levels is more readily comprehensible to the general public rather than a numerical value. However, the \\{PM10\\} prediction model often suffers from data imbalance problem in the training dataset that results in failure to forecast the minority class of severe cases. In this study, a warning system using extreme learning machine (ELM), compared with support vector machine (SVM), was constructed to forecast the class of \\{PM10\\} level: Good, Moderate, and Severe. An imbalance strategy called prior duplication was also applied to improve the forecast of minority class. The experimental comparisons between \\{ELM\\} and \\{SVM\\} demonstrate that \\{ELM\\} produces superior accuracy relative to \\{SVM\\} in forecasting minority class (Severe) of \\{PM10\\} level with or without the imbalance strategy. Furthermore, our results show that the required training time and model size in the \\{ELM\\} model are much shorter and smaller than those of \\{SVM\\} respectively, leading to a more efficient and practical implementation of prediction model for large dataset. The performance superiority of \\{ELM\\} is also discussed in this paper.", 
        "author": "Chi-Man Vong and Weng-Fai Ip and Pak-Kin Wong and Chi-Chong Chiu", 
        "keyword": "PM10\", \"Extreme learning machine (ELM)\", \"Support vector machine (SVM)\", \"Imbalance problem\", \"Prior duplication", 
        "title": "Predicting minority class for suspended particulate matters level by extreme learning machine"
    }, 
    {
        "abstract": "Abstract Recently, restricted Boltzmann machines (RBMs) have attracted considerable interest in machine learning field due to their strong ability to extract features. Given some training data, an \\{RBM\\} or a stack of several \\{RBMs\\} can be used to extract informative features. Meanwhile, ensemble learning is an active research area in machine learning owing to their potential to greatly increase the prediction accuracy of a single classifier. However, \\{RBMs\\} have not been studied to work with ensemble learning so far. In this study, we present several methods for integrating \\{RBMs\\} with bagging to generate diverse and accurate individual classifiers. Taking a classification tree as the base learning algorithm, a thoroughly experimental study conducted on 31 real-world data sets yields some promising conclusions. When using the features extracted by \\{RBMs\\} in ensemble learning, the best way is to perform model combination respectively on the original feature set and the one extracted by a single RBM. However, the prediction performance becomes worse when the features detected by a stack of 2 \\{RBMs\\} are also considered. As for the features detected by RBMs, good classification can be obtained only when they are used together with the original features.", 
        "author": "Chun-Xia Zhang and Jiang-She Zhang and Nan-Nan Ji and Gao Guo", 
        "keyword": "Ensemble classifier\", \"Bagging\", \"Restricted Boltzmann machine\", \"Deep learning\", \"Majority keywords =oting\", \"Diversity", 
        "title": "Learning ensemble classifiers via restricted Boltzmann machines"
    }, 
    {
        "abstract": "Abstract This paper proposes a novel approach for intelligent fault diagnosis for stroke Diesel marine engines, which are commonly used in on-road and marine transportation. The safety and reliability of a ship's work rely strongly on the performance of such an engine; therefore, early detection of any type of failure that affects the engine is of crucial importance. Automatic diagnostic systems are of special importance because they can operate continuously in real time, thereby providing efficient monitoring of the engine's performance. We introduce a fully automatic machine learning-based system for engine fault detection. For this purpose, we monitor various signals that are emitted by the engine, and we use them as an input for a pattern classification algorithm. This action is realized by an ensemble of Extreme Learning Machines that work in a decomposition mode. Because we address 14 different faults and a correct operation mode, we must handle a 15-class problem. We tackle this task by binarization in one-vs-one mode, where each Extreme Learning Machine is trained on a pair of classes. Next, Error-Correcting Output Codes are used to reconstruct the original multi-class task. The results from experiments that were conducted on a real-life dataset demonstrate that the proposed approach delivers superior classification accuracy and a low response time in comparison with a number of state-of-the-art methods and thus is a suitable choice for a real-life implementation on board a ship.", 
        "author": "Jerzy Kowalski and Bartosz Krawczyk and Micha\u0142 Wo\u017aniak", 
        "keyword": "Marine engine\", \"Fault diagnosis\", \"Fault detection\", \"Diesel engine\", \"Machine learning\", keywords =Ensemble learning\", \"Extreme learning machines\", \"Multi-class decomposition", 
        "title": "Fault diagnosis of marine 4-stroke diesel engines using a one-vs-one extreme learning ensemble"
    }, 
    {
        "abstract": "Abstract Extreme learning machines (ELM), as a learning tool, have gained popularity due to its unique characteristics and performance. However, the generalisation capability of \\{ELM\\} often depends on the nature of the dataset, particularly on whether uncertainty is present in the dataset or not. In order to reduce the effects of uncertainties in \\{ELM\\} prediction and improve its generalisation ability, this paper proposes a hybrid system through a combination of type-2 fuzzy logic systems (type-2 FLS) and ELM; thereafter the hybrid system was applied to model permeability of carbonate reservoir. Type-2 \\{FLS\\} has been chosen to be a precursor to \\{ELM\\} in order to better handle uncertainties existing in datasets beyond the capability of type-1 fuzzy logic systems. The type-2 \\{FLS\\} is used to first handle uncertainties in reservoir data so that its final output is then passed to the \\{ELM\\} for training and then final prediction is done using the unseen testing dataset. Comparative studies have been carried out to compare the performance of the proposed T2-ELM hybrid system with each of the constituent type-2 \\{FLS\\} and ELM, and also artificial neural network (ANN) and support Vector machines (SVM) using five different industrial reservoir data. Empirical results show that the proposed T2-ELM hybrid system outperformed each of type-2 \\{FLS\\} and ELM, as the two constituent models, in all cases, with the improvement made to the \\{ELM\\} performance far higher against that of type-2 \\{FLS\\} that had a closer performance to the hybrid since it is already noted for being able to model uncertainties. The proposed hybrid also outperformed \\{ANN\\} and \\{SVM\\} models considered.", 
        "author": "S.O. Olatunji and Ali Selamat and Abdulazeez Abdulraheem", 
        "keyword": "Type-2 fuzzy logic systems\", \"Extreme learning machines (ELM)\", \"Feedforward neural networks\", keywords =Permeability\", \"Well logs\", \"Hybrid intelligent systems", 
        "title": "A hybrid model through the fusion of type-2 fuzzy logic systems and extreme learning machines for modelling permeability prediction"
    }, 
    {
        "abstract": "Abstract Fault diagnosis for wind turbine transmission systems is an important task for reducing their maintenance cost. However, the non-stationary dynamic operating conditions of wind turbines pose a challenge to fault diagnosis for wind turbine transmission systems. In this paper, a novel fault diagnosis method based on manifold learning and Shannon wavelet support vector machine is proposed for wind turbine transmission systems. Firstly, mixed-domain features are extracted to construct a high-dimensional feature set characterizing the properties of non-stationary vibration signals from wind turbine transmission systems. Moreover, an effective manifold learning algorithm with non-linear dimensionality reduction capability, orthogonal neighborhood preserving embedding (ONPE), is applied to compress the high-dimensional feature set into low-dimensional eigenvectors. Finally, the low-dimensional eigenvectors are inputted into a Shannon wavelet support vector machine (SWSVM) to recognize faults. The performance of the proposed method was proved by successful fault diagnosis application in a wind turbine's gearbox. The application results indicated that the proposed method improved the accuracy of fault diagnosis.", 
        "author": "Baoping Tang and Tao Song and Feng Li and Lei Deng", 
        "keyword": "Fault diagnosis\", \"Wind turbine transmission system\", \"Manifold learning\", \"Orthogonal neighborhood keywords =reserving embedding (ONPE)\", \"Shannon wavelet support vector machine", 
        "title": "Fault diagnosis for a wind turbine transmission system based on manifold learning and Shannon wavelet support vector machine"
    }, 
    {
        "abstract": "Abstract Early (or preclinical) diagnosis of Parkinson's disease (PD) is crucial for its early management as by the time manifestation of clinical symptoms occur, more than 60% of the dopaminergic neurons have already been lost. It is now established that there exists a premotor stage, before the start of these classic motor symptoms, characterized by a constellation of clinical features, mostly non-motor in nature such as Rapid Eye Movement (REM) sleep Behaviour Disorder (RBD) and olfactory loss. In this paper, we use the non-motor features of \\{RBD\\} and olfactory loss, along with other significant biomarkers such as Cerebrospinal fluid (CSF) measurements and dopaminergic imaging markers from 183 healthy normal and 401 early \\{PD\\} subjects, as obtained from the Parkinson's Progression Markers Initiative (PPMI) database, to classify early \\{PD\\} subjects from normal using Na\u00efve Bayes, Support Vector Machine (SVM), Boosted Trees and Random Forests classifiers. We observe that \\{SVM\\} classifier gave the best performance (96.40% accuracy, 97.03% sensitivity, 95.01% specificity, and 98.88% area under ROC). We infer from the study that a combination of non-motor, \\{CSF\\} and imaging markers may aid in the preclinical diagnosis of PD.", 
        "author": "R. Prashanth and Sumantra Dutta Roy and Pravat K. Mandal and Shantanu Ghosh", 
        "keyword": "Parkinson\u2019s disease\", \"non-motor features\", \"cerebrospinal fluid markers\", \"dopaminergic imaging\", keywords =Computer-aided diagnosis\", \"pattern classification", 
        "title": "High-Accuracy Detection of Early Parkinson's Disease through Multimodal Features and Machine Learning"
    }, 
    {
        "abstract": "Abstract Combining neural networks and wavelet theory as an approximation or prediction models appears to be an effective solution in many applicative areas. However, when building such systems, one has to face parsimony problem, i.e., to look for a compromise between the complexity of the learning phase and accuracy performances. Following that, the aim of this paper is to propose a new structure of connectionist network, the Summation Wavelet Extreme Learning Machine (SW-ELM) that enables good accuracy and generalization performances, while limiting the learning time and reducing the impact of a random initialization procedure. SW-ELM is based on an Extreme Learning Machine (ELM) algorithm for fast batch learning, but with dual activation functions in the hidden layer nodes. This enhances dealing with non-linearity in an efficient manner. The initialization phase of wavelets (of hidden nodes) and neural network parameters (of input-hidden layer) is performed a priori, even before data are presented to the model. The whole proposition is illustrated and discussed by performing tests on three issues related to time-series application: an \u201cinput\u2013output\u201d approximation problem, a one-step ahead prediction problem, and a multi-steps ahead prediction problem. Performances of SW-ELM are benchmarked with ELM, Levenberg Marquardt algorithm for Single Layer Feed Forward Network (SLFN) and \\{ELMAN\\} network on six industrial datasets. Results show the significance of performances achieved by SW-ELM.", 
        "author": "Kamran Javed and Rafael Gouriveau and Noureddine Zerhouni", 
        "keyword": "Wavelet neural network\", \"Extreme learning machine\", \"Parameters initialization\", \"Activation keywords =unctions\", \"Prediction accuracy", 
        "title": "SW-ELM: A summation wavelet extreme learning machine algorithm with a priori parameter initialization"
    }, 
    {
        "abstract": "AbstractBackground Supervised machine learning has been proposed as a revolutionary approach for identifying sensitive medical image biomarkers (or combination of them) allowing for automatic diagnosis of individual subjects. The aim of this work was to assess the feasibility of a supervised machine learning algorithm for the assisted diagnosis of patients with clinically diagnosed Parkinson's disease (PD) and Progressive Supranuclear Palsy (PSP). Method Morphological T1-weighted Magnetic Resonance Images (MRIs) of \\{PD\\} patients (28), \\{PSP\\} patients (28) and healthy control subjects (28) were used by a supervised machine learning algorithm based on the combination of Principal Components Analysis as feature extraction technique and on Support Vector Machines as classification algorithm. The algorithm was able to obtain voxel-based morphological biomarkers of \\{PD\\} and PSP. Results The algorithm allowed individual diagnosis of \\{PD\\} versus controls, \\{PSP\\} versus controls and \\{PSP\\} versus \\{PD\\} with an Accuracy, Specificity and Sensitivity &gt; 90%. Voxels influencing classification between \\{PD\\} and \\{PSP\\} patients involved midbrain, pons, corpus callosum and thalamus, four critical regions known to be strongly involved in the pathophysiological mechanisms of PSP. Comparison with existing methods Classification accuracy of individual \\{PSP\\} patients was consistent with previous manual morphological metrics and with other supervised machine learning application to \\{MRI\\} data, whereas accuracy in the detection of individual \\{PD\\} patients was significantly higher with our classification method. Conclusions The algorithm provides excellent discrimination of \\{PD\\} patients from \\{PSP\\} patients at an individual level, thus encouraging the application of computer-based diagnosis in clinical practice.", 
        "author": "C. Salvatore and A. Cerasa and I. Castiglioni and F. Gallivanone and A. Augimeri and M. Lopez and G. Arabia and M. Morelli and M.C. Gilardi and A. Quattrone", 
        "keyword": "Support Vector Machine (SVM)\", \"Parkinson's disease (PD)\", \"Progressive Supranuclear Palsy (PSP)\", keywords =Magnetic resonance imaging (MRI)\", \"Machine learning", 
        "title": "Machine learning on brain \\{MRI\\} data for differential diagnosis of Parkinson's disease and Progressive Supranuclear Palsy"
    }, 
    {
        "abstract": "Abstract In this study, the impact of multinationality (as measured by foreign sales ratio) and fourteen other financial indicators on firm value (characterized by market capitalization and market-to-book ratio) for the period of 1997\u20132011 was investigated using two popular machine learning techniques: decision trees and artificial neural networks. We divided the time period of 1997\u20132011 into two periods; 1997\u20132004 and 2005\u20132011 to investigate the robustness of results pre- and post-IFRS implementation. To determine the relative importance of factors as the predictors of firm value, first, a number of classification models are developed; then, the information fusion based sensitivity analysis is applied to these classification models to identify the ranked order of the independent variables. Among the independent variables, multinationality was found to determine firm value only moderately. In addition to multinationality, other financial characteristics such as firm size (as measured by natural logarithm of assets), leverage, liquidity, and profitability were consistently found to be affecting firm value.", 
        "author": "Cemil Kuzey and Ali Uyar and Dursun Delen", 
        "keyword": "Machine learning\", \"Predictive analytics\", \"Decision trees\", \"Artificial neural networks\", keywords =Sensitivity analysis\", \"Firm value\", \"Multinationality", 
        "title": "The impact of multinationality on firm value: A comparative analysis of machine learning techniques"
    }, 
    {
        "abstract": "Abstract Pupylation is one of the most important post-translational modifications of prokaryotic proteins playing a key role in regulating a wild range of biological processes. Prokaryotic ubiquitin-like protein can attach to specific lysine residues of substrate proteins by forming isopeptide bonds for the selective degradation of proteins in Mycobacterium tuberculosis. In order to comprehensively understand these pupylation-related biological processes, identification of pupylation sites in the substrate protein sequence is the first step. The traditional wet-lab experimental approaches are both laborious and time-consuming. To timely and effectively discover pupylation sites when facing with the avalanche of new protein sequences emerging during the post-genomic Era, a novel computational predictor called PupS (pupylation site predictor) is proposed. PupS is constructed on the pseudo-amino acid composition and trained with extreme learning machine. The jackknife cross-validation results on the training dataset show that the area under an \\{ROC\\} Curve (AUC) value is 0.6483 by PupS, and an \\{AUC\\} of 0.6779 is obtained on the independent set. Our results also demonstrate that \\{ELM\\} is complementary to other algorithms and that constructing an ensemble classifier will generate better results. PupS software package is available at http://www.csbio.sjtu.edu.cn/bioinf/PupS/.", 
        "author": "Yong-Xian Fan and Hong-Bin Shen", 
        "keyword": "Pupylated protein\", \"Pupylation sites\", \"Pseudo-amino acid composition\", \"Extreme learning keywords =achine\", \"Bioinformatics\", \"PupS", 
        "title": "Predicting pupylation sites in prokaryotic proteins using pseudo-amino acid composition and extreme learning machine"
    }, 
    {
        "abstract": "Abstract In this paper, a novel constructive multi-output extreme learning machine (CM-ELM) is proposed to deal with a large tanker motion dynamics identification. The significant contributions are as follows. (1) Driven by generated tanker dynamics data from the reference model, the CM-ELM method is proposed to identify multi-output dynamic models. (2) The candidate pool for CM-ELM is randomly generated by the \\{ELM\\} strategy, and ranked chunk-by-chunk based on a novel improved multi-response sparse regression (I-MRSR) incorporated with \u03bb weighting. (3) Consequently, the constructive model selection works with fast speed due to chunk-type training process, which also benefits stable hidden node selection and corresponding generalization. (4) Furthermore, output weight update on the final CM-ELM model randomly selected from the elite subset is conducted to enhance the overall performance of the resulting CM-ELM scheme. Finally, the convincing performance of the complete CM-ELM paradigm is verified by simulation studies on not only tanker motion dynamics identification but also benchmark multi-output regressions. Comprehensive comparisons of the CM-ELM with \\{ELM\\} and OP-ELM indicate the remarkable superiority in terms of generalization capability and stable compact structure. Conclusions are steadily drawn that the CM-ELM method is feasibly effective for tanker motion dynamics identification and multi-output regressions.", 
        "author": "Ning Wang and Min Han and Nuo Dong and Meng Joo Er", 
        "keyword": "Extreme learning machine\", \"Constructive method\", \"Improved multi-response sparse regression\", keywords =Multi-output regression\", \"Tanker motion dynamics", 
        "title": "Constructive multi-output extreme learning machine with application to large tanker motion dynamics identification"
    }, 
    {
        "abstract": "Abstract We propose a tool-body assimilation model that considers grasping during motor babbling for using tools. A robot with tool-use skills can be useful in human\u2013robot symbiosis because this allows the robot to expand its task performing abilities. Past studies that included tool-body assimilation approaches were mainly focused on obtaining the functions of the tools, and demonstrated the robot starting its motions with a tool pre-attached to the robot. This implies that the robot would not be able to decide whether and where to grasp the tool. In real life environments, robots would need to consider the possibilities of tool-grasping positions, and then grasp the tool. To address these issues, the robot performs motor babbling by grasping and nongrasping the tools to learn the robot\u2019s body model and tool functions. In addition, the robot grasps various parts of the tools to learn different tool functions from different grasping positions. The motion experiences are learned using deep learning. In model evaluation, the robot manipulates an object task without tools, and with several tools of different shapes. The robot generates motions after being shown the initial state and a target image, by deciding whether and where to grasp the tool. Therefore, the robot is capable of generating the correct motion and grasping decision when the initial state and a target image are provided to the robot.", 
        "author": "Kuniyuki Takahashi and Kitae Kim and Tetsuya Ogata and Shigeki Sugano", 
        "keyword": "Tool-body assimilation\", \"Motor babbling\", \"Deep neural network\", \"Recurrent neural network\", \"Transfer learning", 
        "title": "Tool-body assimilation model considering grasping motion through deep learning"
    }, 
    {
        "abstract": "Abstract In this paper, a single-hidden layer feed-forward neural network (SLFN) is used to model the dynamics of the vapor compression cycle in refrigeration and air-conditioning systems, based on the extreme learning machine (ELM). It is shown that the assignment of the random input weights of the \\{SLFN\\} can greatly reduce the training time, and the regularization based optimization of the output weights of the \\{SLFN\\} ensures the high accuracy of the modeling of the dynamics of vapor compression cycle and the robustness of the \\{SLFN\\} against high frequency disturbances. The new \\{SLFN\\} model is tested with the real experimental data and compared with the ones trained with the back propagation (BP), the support vector regression (SVR) and the radial basis function neural network (RBF), respectively, with the results that the high degree of prediction accuracy and strongest robustness against the input disturbances are achieved.", 
        "author": "Lei Zhao and Wen-Jian Cai and Zhi-Hong Man", 
        "keyword": "Extreme learning machine\", \"Vapor compression refrigeration cycle\", \"Modeling\", \"Back propagation\", keywords =Support vector regression\", \"Radial basis function", 
        "title": "Neural modeling of vapor compression refrigeration cycle with extreme learning machine"
    }, 
    {
        "abstract": "Abstract This paper focuses on the application of Extreme Learning Machines (ELM) to the classification of remote sensing hyperspectral data. The specific aim of the work is to obtain accurate thematic maps of soybean crops, which have proven to be difficult to identify by automated procedures. The classification process carried out is as follows: First, spectral data is transformed into a hyper-spherical representation. Second, a robust image gradient is computed over the hyper-spherical representation allowing an image segmentation that identifies major crop plots. Third, feature selection is achieved by a greedy wrapper approach. Finally, a classifier is trained and tested on the selected image pixel features. The classifiers used for feature selection and final classification are Single Layer Feedforward Networks (SLFN) trained with either the \\{ELM\\} or the incremental OP-ELM. Original image pixel features are computed following a Functional Data Analysis (FDA) characterization of the spectral data. Conventional \\{ELM\\} training of the \\{SLFN\\} improves over the classification performance of state of the art algorithms reported in the literature dealing with the data treated in this paper. Moreover, SLFN-ELM uses less features than the referred algorithms. OP-ELM is able to find competitive results using the \\{FDA\\} features from a single spectral band.", 
        "author": "Ram\u00f3n Moreno and Francesco Corona and Amaury Lendasse and Manuel Gra\u00f1a and L\u00eanio S. Galv\u00e3o", 
        "keyword": "Extreme learning machine\", \"Hyperspectral images\", \"Agricultural remote sensing", 
        "title": "Extreme learning machines for soybean classification in remote sensing hyperspectral images"
    }, 
    {
        "abstract": "Abstract Machine learning schemes are employed to predict which local minimum will result from local energy minimisation of random starting configurations for a triatomic cluster. The input data consists of structural information at one or more of the configurations in optimisation sequences that converge to one of four distinct local minima. The ability to make reliable predictions, in terms of the energy or other properties of interest, could save significant computational resources in sampling procedures that involve systematic geometry optimisation. Results are compared for two energy minimisation schemes, and for neural network and quadratic functions of the inputs.", 
        "author": "Ritankar Das and David J. Wales", 
        "keyword": null, 
        "title": "Machine learning prediction for classification of outcomes in local minimisation"
    }, 
    {
        "abstract": "Abstract Conventional classification algorithms assume that the input data is exact or precise. Due to various reasons, including imprecise measurement, network delay, outdated sources and sampling errors, data uncertainty is common and widespread in real-world applications, such as sensor database, location database, biometric information systems. Though there exist a lot of approaches for classification, few of them address the problem of classification over uncertain data in database. Therefore, in this paper, we propose classification algorithms based on conventional and optimized \\{ELM\\} to conduct classification over uncertain data. Firstly we view the instances of each uncertain data as the training data for learning. Then, the probabilities of uncertain data in any class are computed according to learning results of each instance. Finally, using a bound-based approach, we implement the final classification. We also extend the proposed algorithms to classification over uncertain data in a distributed environment based on OS-ELM and Monte Carlo theory. The experiments verify the performance of our proposed algorithms.", 
        "author": "Yongjiao Sun and Ye Yuan and Guoren Wang", 
        "keyword": "Extreme learning machine\", \"Uncertain data\", \"OS-ELM\", \"SVM\", \"Single hidden layer feedforward neural networks", 
        "title": "Extreme learning machine for classification over uncertain data"
    }, 
    {
        "abstract": "Abstract One of the most challenging problems of sentiment analysis on social media is that labelling huge amounts of instances can be very expensive. Active learning has been proposed to overcome this problem and to provide means for choosing the most useful training instances. In this study, we introduce active learning to a framework which is comprised of most popular base and ensemble approaches for sentiment analysis. In addition, the implemented framework contains two ensemble approaches, i.e. a probabilistic algorithm and a derived version of Behavior Knowledge Space (BKS) algorithm. The Shannon Entropy approach was utilized for choosing among training data during active learning process and it was compared with maximum disagreement method and random selection of instances. It was observed that the former method causes better accuracies in less number of iterations. The above methods were tested on Cornell movie review dataset and a popular multi-domain product review dataset.", 
        "author": "Deniz Aldo\u011fan and Yusuf Yaslan", 
        "keyword": "Active learning\", \"Ensemble learning\", \"Sentiment analysis\", \"Machine learning\", \"Artificial intelligence", 
        "title": "A comparison study on active learning integrated ensemble approaches in sentiment analysis"
    }, 
    {
        "abstract": "Abstract A critical decision-step in the emergency treatment of ischemic stroke is whether or not to administer thrombolysis \u2014 a treatment that can result in good recovery, or deterioration due to symptomatic intracranial haemorrhage (SICH). Certain imaging features based upon early computerized tomography (CT), in combination with clinical variables, have been found to predict SICH, albeit with modest accuracy. In this proof-of-concept study, we determine whether machine learning of \\{CT\\} images can predict which patients receiving tPA will develop \\{SICH\\} as opposed to showing clinical improvement with no haemorrhage. Clinical records and \\{CT\\} brains of 116 acute ischemic stroke patients treated with intravenous thrombolysis were collected retrospectively (including 16 who developed SICH). The sample was split into training (n = 106) and test sets (n = 10), repeatedly for 1760 different combinations. \\{CT\\} brain images acted as inputs into a support vector machine (SVM), along with clinical severity. Performance of the \\{SVM\\} was compared with established prognostication tools (SEDAN and \\{HAT\\} scores; original, or after adaptation to our cohort). Predictive performance, assessed as area under receiver-operating-characteristic curve (AUC), of the \\{SVM\\} (0.744) compared favourably with that of prognostic scores (original and adapted versions: 0.626\u20130.720; p &lt; 0.01). The \\{SVM\\} also identified 9 out of 16 SICHs, as opposed to 1\u20135 using prognostic scores, assuming a 10% \\{SICH\\} frequency (p &lt; 0.001). In summary, machine learning methods applied to acute stroke \\{CT\\} images offer automation, and potentially improved performance, for prediction of \\{SICH\\} following thrombolysis. Larger-scale cohorts, and incorporation of advanced imaging, should be tested with such methods.", 
        "author": "Paul Bentley and Jeban Ganesalingam and Anoma Lalani Carlton Jones and Kate Mahady and Sarah Epton and Paul Rinne and Pankaj Sharma and Omid Halse and Amrish Mehta and Daniel Rueckert", 
        "keyword": "Stroke\", \"Thrombolysis\", \"Prediction\", \"Machine learning\", \"Imaging", 
        "title": "Prediction of stroke thrombolysis outcome using \\{CT\\} brain machine learning"
    }, 
    {
        "abstract": "Abstract Electronic health records contain large amounts of longitudinal data that are valuable for biomedical informatics research. The application of machine learning is a promising alternative to manual analysis of such data. However, the complex structure of the data, which includes clinical events that are unevenly distributed over time, poses a challenge for standard learning algorithms. Some approaches to modeling temporal data rely on extracting single values from time series; however, this leads to the loss of potentially valuable sequential information. How to better account for the temporality of clinical data, hence, remains an important research question. In this study, novel representations of temporal data in electronic health records are explored. These representations retain the sequential information, and are directly compatible with standard machine learning algorithms. The explored methods are based on symbolic sequence representations of time series data, which are utilized in a number of different ways. An empirical investigation, using 19 datasets comprising clinical measurements observed over time from a real database of electronic health records, shows that using a distance measure to random subsequences leads to substantial improvements in predictive performance compared to using the original sequences or clustering the sequences. Evidence is moreover provided on the quality of the symbolic sequence representation by comparing it to sequences that are generated using domain knowledge by clinical experts. The proposed method creates representations that better account for the temporality of clinical events, which is often key to prediction tasks in the biomedical domain.", 
        "author": "Jing Zhao and Panagiotis Papapetrou and Lars Asker and Henrik Bostr\u00f6m", 
        "keyword": "Random subsequence\", \"Time series classification\", \"Electronic health records\", \"Data mining\", \"Machine learning", 
        "title": "Learning from heterogeneous temporal data in electronic health records"
    }, 
    {
        "abstract": "Abstract This paper reports an extension of our previous study on determining structural identifiability of the generalized constraint (GC) models, which are considered to be parameter learning machines. Identifiability defines a uniqueness property to the model parameters. This property is particularly important for those physically interpretable parameters in \\{GC\\} models. We derive identifiability criteria according to the types of models. First, by taking the models as a family of deterministic nonlinear transformations from input space to output space, we provide a criterion for examining identifiability of the Multiple-input Multiple-output (MIMO) models. This result therefore generalizes the previous one for Single-input Single-output (SISO) and Multiple-input Single-output (MISO) models. Second, if considering the models as the mean functions of input-dependent conditional distributions within stochastic framework, we derive an identifiability criterion by means of the Kullback\u2013Leibler divergence (KLD) and regular summary. Third, time-variant models are studied based on the exhaustive summary method. The new identifiability criterion is valid for a range of differential/difference equation models whenever their exhaustive summaries can be obtained. Several model examples from the literature are presented to examine their identifiability property.", 
        "author": "Zhi-Yong Ran and Bao-Gang Hu", 
        "keyword": "Identifiability\", \"Parameter learning machine\", \"Exhaustive summary\", \"Kullback\u2013Leibler keywords =ivergence\", \"Parameter redundancy", 
        "title": "Determining structural identifiability of parameter learning machines"
    }, 
    {
        "abstract": "Abstract With more and more crowdsourcing geo-tagged field photos available online, they are becoming a potentially valuable source of information for environmental studies. However, the labelling and recognition of these photos are time-consuming. To utilise such information, a land cover type recognition model for field photos was proposed based on the deep learning technique. This model combines a pre-trained convolutional neural network (CNN) as the image feature extractor and the multinomial logistic regression model as the feature classifier. The pre-trained \\{CNN\\} model Inception-v3 was used in this study. The labelled field photos from the Global Geo-Referenced Field Photo Library (http://eomf.ou.edu/photos) were chosen for model training and validation. The results indicated that our recognition model achieved an acceptable accuracy (48.40% for top-1 prediction and 76.24% for top-3 prediction) of land cover classification. With accurate self-assessment of confidence, the model can be applied to classify numerous online geo-tagged field photos for environmental information extraction.", 
        "author": "Guang Xu and Xuan Zhu and Dongjie Fu and Jinwei Dong and Xiangming Xiao", 
        "keyword": "Deep learning\", \"Convolutional neural network\", \"Transfer learning\", \"Multinomial logistic keywords =egression\", \"Land cover\", \"Crowdsourced photos", 
        "title": "Automatic land cover classification of geo-tagged field photos by deep learning"
    }, 
    {
        "abstract": "Abstract Recently, methods based on Artificial Intelligence (AI) have been widely used to improve positioning accuracy for land vehicle navigation by integrating the Global Positioning System (GPS) with the Strapdown Inertial Navigation System (SINS). In this paper, we propose the ensemble learning algorithm instead of traditional single neural network to overcome the limitations of complex and dynamic data cased by vehicle irregular movement. The ensemble learning algorithm (LSBoost or Bagging), similar to the neural network, can build the SINS/GPS position model based on current and some past samples of \\{SINS\\} velocity, attitude and \\{IMU\\} output information. The performance of the proposed algorithm has been experimentally verified using \\{GPS\\} and \\{SINS\\} data of different trajectories collected in some land vehicle navigation tests. The comparison results between the proposed model and traditional algorithms indicate that the proposed algorithm can improve the positioning accuracy for cases of \\{SINS\\} and specific \\{GPS\\} outages.", 
        "author": "Jing Li and Ningfang Song and Gongliu Yang and Ming Li and Qingzhong Cai", 
        "keyword": "Sins/gps integration\", \"Gps outages\", \"Neural network\", \"Ensemble learning algorithm", 
        "title": "Improving positioning accuracy of vehicular navigation system during \\{GPS\\} outages utilizing ensemble learning algorithm"
    }, 
    {
        "abstract": "Abstract Artificial neural networks, conceptually and structurally inspired by neural systems, are of great interest along with deep learning, thanks to their great successes in various fields including medical imaging analysis. In this chapter, we describe the fundamental concepts and ideas of (deep) neural networks and explain algorithmic advances to learn network parameters efficiently by avoiding overfitting. Specifically, this chapter focuses on introducing (i) feed-forward neural networks, (ii) gradient descent-based parameter optimization algorithms, (iii) different types of deep models, (iv) technical tricks for fast and robust training of deep models, and (v) open source deep learning frameworks for quick practice.", 
        "author": "Heung-Il Suk", 
        "keyword": "Neural networks\", \"Convolutional neural network\", \"Deep learning\", \"Deep belief network\", \"Deep Boltzmann machine", 
        "title": "Chapter 1 - An Introduction to Neural Networks and Deep Learning"
    }, 
    {
        "abstract": null, 
        "author": "Qinghua Hu and Jusheng Mi and Degang Chen", 
        "keyword": null, 
        "title": "Granular Computing Based Machine Learning in the Era of Big Data"
    }, 
    {
        "abstract": "Abstract Multi-label learning paradigm, which aims at dealing with data associated with potential multiple labels, has attracted a great deal of attention in machine intelligent community. In this paper, we propose a novel multi-label twin support vector machine (MLTSVM) for multi-label classification. \\{MLTSVM\\} determines multiple nonparallel hyperplanes to capture the multi-label information embedded in data, which is a useful promotion of twin support vector machine (TWSVM) for multi-label classification. To speed up the training procedure, an efficient successive overrelaxation (SOR) algorithm is developed for solving the involved quadratic programming problems (QPPs) in MLTSVM. Extensive experimental results on both synthetic and real-world multi-label datasets confirm the feasibility and effectiveness of the proposed MLTSVM.", 
        "author": "Wei-Jie Chen and Yuan-Hai Shao and Chun-Na Li and Nai-Yang Deng", 
        "keyword": "Multi-label classification\", \"Support vector machines\", \"Twin support vector machines\", \"Quadratic keywords =rogramming\", \"Successive overrelaxation", 
        "title": "MLTSVM: A novel twin support vector machine to multi-label learning"
    }, 
    {
        "abstract": "Abstract Recent advances in machine learning yielded new techniques to train deep neural networks, which resulted in highly successful applications in many pattern recognition tasks such as object detection and speech recognition. In this paper we provide a head-to-head comparison between a state-of-the art in mammography \\{CAD\\} system, relying on a manually designed feature set and a Convolutional Neural Network (CNN), aiming for a system that can ultimately read mammograms independently. Both systems are trained on a large data set of around 45,000 images and results show the \\{CNN\\} outperforms the traditional \\{CAD\\} system at low sensitivity and performs comparable at high sensitivity. We subsequently investigate to what extent features such as location and patient information and commonly used manual features can still complement the network and see improvements at high specificity over the \\{CNN\\} especially with location and context features, which contain information not available to the CNN. Additionally, a reader study was performed, where the network was compared to certified screening radiologists on a patch level and we found no significant difference between the network and the readers.", 
        "author": "Thijs Kooi and Geert Litjens and Bram van Ginneken and Albert Gubern-M\u00e9rida and Clara I. S\u00e1nchez and Ritse Mann and Ard den Heeten and Nico Karssemeijer", 
        "keyword": "Computer aided detection\", \"Mammography\", \"Deep learning\", \"Machine learning\", \"Breast cancer\", \"Convolutional neural networks", 
        "title": "Large scale deep learning for computer aided detection of mammographic lesions"
    }, 
    {
        "abstract": "Abstract Species extinction is one of the most important phenomena in conservation biology. Many factors are involved in the disappearance of species, including stochastic population fluctuations, habitat change, resource depletion, and inbreeding. Due to the complexity of the interactions between these various factors and the lengthy time period required to make empirical observations, studying the phenomenon of species extinction can prove to be very difficult in nature. On the other hand, an investigation of the various features involved in species extinction using individual-based simulation modeling and machine learning techniques can be accomplished in a reasonably short period of time. Thus, the aim of this paper is to investigate multiple factors involved in species extinction using computer simulation modeling. We apply several machine learning techniques to the data generated by EcoSim, a predator\u2013prey ecosystem simulation, in order to select the most prominent features involved in species extinction, along with extracting rules that outline conditions that have the potential to be used for predicting extinction. In particular, we used five feature selection methods resulting in the selection of 25 features followed by a reduction of these to 14 features using correlation analysis. Each of the remaining features was placed in one of three broad categories, viz., genetic, environmental, or demographic. The experimental results suggest that factors such as population fluctuation, reproductive age, and genetic distance are important in the occurrence of species extinction in EcoSim, similar to what is observed in nature. We argue that the study of the behavior of species through Individual-Based Modeling has the potential to give rise to new insights into the central factors involved in extinction for real ecosystems. This approach has the potential to help with the detection of early signals of species extinction that could in turn lead to conservation policies to help prevent extinction.", 
        "author": "Morteza Mashayekhi and Brian MacPherson and Robin Gras", 
        "keyword": "Individual-based model\", \"Machine learning\", \"Species extinction\", \"Rule extraction", 
        "title": "A machine learning approach to investigate the reasons behind species extinction"
    }, 
    {
        "abstract": "Abstract We present ClassySeg, a technique for segmenting hand-drawn pen strokes into lines and arcs. ClassySeg employs machine learning techniques to infer the segmentation intended by the drawer. The technique begins by identifying a set of candidate segment windows, each comprising a curvature maximum and its neighboring points. Features are computed for each point in each window based on curvature and other geometric properties. Most of these features are adapted from numerous prior segmentation approaches, effectively combining their strengths. These features are used to train a statistical classifier to identify which candidate windows contain true segment points. ClassySeg is more accurate than previous techniques for both user-independent and user-optimized training conditions. More importantly, ClassySeg represents a movement away from prior, heuristic-based approaches, toward a more general and extensible technique.", 
        "author": "James Herold and Thomas F. Stahovich", 
        "keyword": "Pen stroke segmentation\", \"Sketch understanding\", \"Pen-based user interfaces\", \"Machine learning", 
        "title": "A machine learning approach to automatic stroke segmentation"
    }, 
    {
        "abstract": "Abstract Machine learning algorithms (MLAs) are a powerful group of data-driven inference tools that offer an automated means of recognizing patterns in high-dimensional data. Hence, there is much scope for the application of \\{MLAs\\} to the rapidly increasing volumes of remotely sensed geophysical data for geological mapping problems. We carry out a rigorous comparison of five MLAs: Naive Bayes, k-Nearest Neighbors, Random Forests, Support Vector Machines, and Artificial Neural Networks, in the context of a supervised lithology classification task using widely available and spatially constrained remotely sensed geophysical data. We make a further comparison of \\{MLAs\\} based on their sensitivity to variations in the degree of spatial clustering of training data, and their response to the inclusion of explicit spatial information (spatial coordinates). Our work identifies Random Forests as a good first choice algorithm for the supervised classification of lithology using remotely sensed geophysical data. Random Forests is straightforward to train, computationally efficient, highly stable with respect to variations in classification model parameter values, and as accurate as, or substantially more accurate than the other \\{MLAs\\} trialed. The results of our study indicate that as training data becomes increasingly dispersed across the region under investigation, \\{MLA\\} predictive accuracy improves dramatically. The use of explicit spatial information generates accurate lithology predictions but should be used in conjunction with geophysical data in order to generate geologically plausible predictions. MLAs, such as Random Forests, are valuable tools for generating reliable first-pass predictions for practical geological mapping applications that combine widely available geophysical data.", 
        "author": "Matthew J. Cracknell and Anya M. Reading", 
        "keyword": "Geological mapping\", \"Remote sensing\", \"Machine learning\", \"Supervised classification\", \"Spatial keywords =lustering\", \"Spatial information", 
        "title": "Geological mapping using remote sensing data: A comparison of five machine learning algorithms, their response to variations in the spatial distribution of training data and the use of explicit spatial information"
    }, 
    {
        "abstract": "Abstract Pricing in the online world is highly transparent &amp; can be a primary driver for online purchase. While dynamic pricing is not new &amp; used by many to increase sales and margins, its benefit to online retailers is immense. The proposed study is a result of ongoing project that aims to develop a generic framework and applicable techniques by applying sound machine learning algorithms to enhance right price purchase (not cheapest price) by customers on e-commerce platform. This study focuses more on inventory led e-commerce companies, however the model can be extended to online marketplaces without inventories. Facilitated by statistical and machine learning models the study seeks to predict the purchase decisions based on adaptive or dynamic pricing of a product. Different data sources which capture visit attributes, visitor attributes, purchase history, web data, and context understanding, lays a strong foundation to this framework. The study focuses on customer segments for predicting purchase rather than on individual buyers. Personalization of adaptive pricing and purchase prediction will be the next logical extension of the study once the results for this are presented. Web mining and use of big data technologies along with machine learning algorithms make up the solution landscape for the study.", 
        "author": "Rajan Gupta and Chaitanya Pathak", 
        "keyword": "Machine Learning\", \"Dynamic Pricing\", \"Predictive Modelling\", \"Consumer Behavior", 
        "title": "A Machine Learning Framework for Predicting Purchase by Online Customers based on Dynamic Pricing"
    }, 
    {
        "abstract": "Abstract Multinomial logistic regression and other classification schemes used in conjunction with convolutional networks (convnets) were designed largely before the rise of the now standard coupling with convnets, stochastic gradient descent, and backpropagation. In the specific application to supervised learning for convnets, a simple scale-invariant classification stage is more robust than multinomial logistic regression, appears to result in somewhat lower errors on several standard test sets, has similar computational costs, and features precise control over the actual rate of learning. \u201cScale-invariant\u201d means that multiplying the input values by any nonzero real number leaves the output unchanged.", 
        "author": "Soumith Chintala and Marc'Aurelio Ranzato and Arthur Szlam and Yuandong Tian and Mark Tygert and Wojciech Zaremba", 
        "keyword": "Spectrum\", \"Wavelets\", \"Wavelet packets\", \"Signal processing\", \"Image processing\", keywords =Classification\", \"Equivariant\", \"Invariant\", \"Machine learning\", \"Representation", 
        "title": "Scale-invariant learning and convolutional networks"
    }, 
    {
        "abstract": "Abstract When making the decision about whether or not to breed a given cow, knowledge about the expected outcome would have an economic impact on profitability of the breeding program and net income of the farm. The outcome of each breeding can be affected by many management and physiological features that vary between farms and interact with each other. Hence, the ability of machine learning algorithms to accommodate complex relationships in the data and missing values for explanatory variables makes these algorithms well suited for investigation of reproduction performance in dairy cattle. The objective of this study was to develop a user-friendly and intuitive on-farm tool to help farmers make reproduction management decisions. Several different machine learning algorithms were applied to predict the insemination outcomes of individual cows based on phenotypic and genotypic data. Data from 26 dairy farms in the Alta Genetics (Watertown, WI) Advantage Progeny Testing Program were used, representing a 10-yr period from 2000 to 2010. Health, reproduction, and production data were extracted from on-farm dairy management software, and estimated breeding values were downloaded from the \\{US\\} Department of Agriculture Agricultural Research Service Animal Improvement Programs Laboratory (Beltsville, MD) database. The edited data set consisted of 129,245 breeding records from primiparous Holstein cows and 195,128 breeding records from multiparous Holstein cows. Each data point in the final data set included 23 and 25 explanatory variables and 1 binary outcome for of 0.756 \u00b1 0.005 and 0.736 \u00b1 0.005 for primiparous and multiparous cows, respectively. The na\u00efve Bayes algorithm, Bayesian network, and decision tree algorithms showed somewhat poorer classification performance. An information-based variable selection procedure identified herd average conception rate, incidence of ketosis, number of previous (failed) inseminations, days in milk at breeding, and mastitis as the most effective explanatory variables in predicting pregnancy outcome.", 
        "author": "Saleh Shahinfar and David Page and Jerry Guenther and Victor Cabrera and Paul Fricke and Kent Weigel", 
        "keyword": "machine learning\", \"reproductive management\", \"dairy cattle", 
        "title": "Prediction of insemination outcomes in Holstein dairy cattle using alternative machine learning algorithms"
    }, 
    {
        "abstract": "Abstract In this Letter, we present a novel methodology of searching for biologically active compounds, which is based on the combination of docking experiments and analysis of the results by machine learning methods. The study was performed for 5 different protein kinases, and several sets of compounds (active, inactive and assumed inactives) were docked into their targets. The resulting ligand\u2013protein complexes were represented by the means of structural interaction fingerprints profiles (SIFts profiles) that constituted an input for \\{ML\\} methods. The developed protocol was found to be superior to the combination of classification algorithms with the standard fingerprint MACCSFP.", 
        "author": "Jagna Witek and Sabina Smusz and Krzysztof Rataj and Stefan Mordalski and Andrzej J. Bojarski", 
        "keyword": "Structural interaction fingerprint\", \"Machine learning\", \"Virtual screening\", \"Docking results analysis", 
        "title": "An application of machine learning methods to structural interaction fingerprints\u2014a case study of kinase inhibitors"
    }, 
    {
        "abstract": "Abstract This work presents the application of machine learning techniques to analyse the influence of physical exercise in the physiological properties of the heart, during ventricular fibrillation. To this end, different kinds of classifiers (linear and neural models) are used to classify between trained and sedentary rabbit hearts. The use of those classifiers in combination with a wrapper feature selection algorithm allows to extract knowledge about the most relevant features in the problem. The obtained results show that neural models outperform linear classifiers (better performance indices and a better dimensionality reduction). The most relevant features to describe the benefits of physical exercise are those related to myocardial heterogeneity, mean activation rate and activation complexity.", 
        "author": "Juan Caravaca and Emilio Soria-Olivas and Manuel Bataller and Antonio J. Serrano and Luis Such-Miquel and Joan Vila-Franc\u00e9s and Juan F. Guerrero", 
        "keyword": "Machine learning\", \"Classification\", \"Knowledge extraction\", \"Logistic regression\", \"Multilayer keywords =erceptron\", \"Extreme learning machine\", \"Ventricular fibrillation\", \"Physical exercise", 
        "title": "Application of machine learning techniques to analyse the effects of physical exercise in ventricular fibrillation"
    }, 
    {
        "abstract": "Abstract Background: Machine learning and data mining techniques have been successfully applied on \\{MRI\\} images for detecting Alzheimer's disease (AD). But only a few studies have explored the possibility of \\{AD\\} detection from non-image data. These studies have applied traditional data visualization and classification algorithms. There is a need for new sophisticated learning algorithms, for detecting and quantifying the severity of \\{AD\\} by exploring the complex interactions between the features in \\{AD\\} subjects. Method: In this work, a supervised learning model to effectively capture the complex feature interactions, in the sample space of \\{AD\\} data, is presented for knowledge discovery. The discovered knowledge is further used to quantify the similarity of a test subject to the demented class. Results: Evaluation of the proposed model, on \\{OASIS\\} database of Alzheimer's subjects, validates the well established risk factors and identifiers for AD: Age, Socio-Economic Status, \\{MMSE\\} Score and Whole Brain Volume. The Test subjects are affiliated to either non-demented (ND) or \\{AD\\} class, with non-overlapping and measurable similarity indices: Female \\{ND\\} (CDR=0) [0.48\u20132.90], Female \\{AD\\} (CDR=0.5) [90.16\u2013774.51], Female \\{AD\\} (CDR=1) [1633.90\u20137182.23], Female \\{AD\\} (CDR=2) [55258.51\u201366382.44], Male \\{ND\\} (CDR=0)[0.69\u20133.66], Male \\{AD\\} (CDR=0.5) [99.18\u2013647.51] and Male \\{AD\\} (CDR=1) [3880.16\u20136519.40]. Conclusion: The outcome of the work clearly demonstrates that, supervised learning model can be used effectively to quantify the severity of \\{AD\\} on a standard measurable scale. This scale of distance can be used as a supplement for clinical dementia rating.", 
        "author": "C.R. Aditya and M.B. Sanjay Pande", 
        "keyword": "Alzheimer's disease\", \"Dementia\", \"Multifactor dimensionality reduction\", \"Knowledge discovery\", keywords =Similarity measure\", \"Affiliation analysis", 
        "title": "Devising an interpretable calibrated scale to quantitatively assess the dementia stage of subjects with alzheimer's disease: A machine learning approach"
    }, 
    {
        "abstract": "Abstract This paper introduces a new hub-and-center transportation network problem for a new company competing against an operating company. The new company intends to locate p hubs and assign the center nodes to the located hubs in order to form origin\u2013destination pairs. It desires not only to maximize the total captured flow in the market but also aims to minimize the total transportation cost. Three competition rules are established between the companies which must be abided. According to the competition rules, the new company can capture the full percentage of the traffic in each origin-destination pair if its transportation cost for each route is significantly less than of the competitor. If its transportation cost for each route is not significantly less than one of the competitors, only a certain percentage of the traffic can be captured. A bi-objective optimization model is proposed for the hub location problem on hand under a competitive environment. As the problem is shown to be NP-hard, a novel meta-heuristic algorithm called multi-objective biogeography-based optimization is developed. As there is no benchmark in the literature, a popular non-dominated sorting algorithm is utilized to validate the results obtained. Moreover, to enhance the performance of the proposed Pareto-based algorithms, this paper intends to develop a binary opposition-based learning as a diversity mechanism for both algorithms. The algorithms are tuned to solve the problem, based on which their performances are compared, ranked, and analyzed statistically. Finally, the applicability of the proposed approach and the solution methodologies are demonstrated in three steps.", 
        "author": "Amir Hossein Niknamfar and Seyed Taghi Akhavan Niaki and Seyed Armin Akhavan Niaki", 
        "keyword": "Competitive hub location\", \"Evolutionary computations\", \"Binary opposition-based learning\", keywords =Multi-objective biogeography-based optimization\", \"Non-dominated sorting genetic algorithm", 
        "title": "Opposition-based learning for competitive hub location: A bi-objective biogeography-based optimization algorithm"
    }, 
    {
        "abstract": "Abstract Questioning is widely acknowledged as an effective instructional strategy used by teachers in their interaction with students for variety of purposes. In educational practices, the analysis of classroom questions asked by teachers is of particular benefits. This paper investigates the effectiveness of machine learning techniques on analyzing teacher's classroom questions by automatically classifying them into different cognitive levels identified in Bloom's taxonomy. More specifically, this paper reports on three of the most effective machine learning techniques for text classification: k-Nearest Neighbors, Na\u00efve Bayes, and Support Vector Machine using term frequency as a term selection approach. In doing so, a dataset of questions has been collected and classified manually into Bloom's cognitive levels. Preprocessing steps have been applied to convert questions into a representation suitable for machine learning techniques. Using this dataset, the performance of the three machine learning techniques has been evaluated. The results show a comparable performance of k-Nearest Neighbor and Na\u00efve Bayes and a superior performance of Support Vector Machine in term of \\{F1\\} and accuracy. Moreover the results also indicate that machine learning techniques show different levels of sensitivity to the number of terms used for question representation.", 
        "author": "Anwar Ali Yahya and Addin Osman and Ahmad Taleb and Ahmed Abdu Alattab", 
        "keyword": "Questions analysis\", \"Machine learning\", \"Text classification\", \"Bloom's taxonomy", 
        "title": "Analyzing the Cognitive Level of Classroom Questions Using Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract Classification models are becoming useful tools for finding patterns in neuroimaging data sets that are not observable to the naked eye. Many of these models are applied to discriminating clinical groups such as schizophrenic patients from healthy controls or from patients with bipolar disorder. A more nuanced model might be to discriminate between levels of personality traits. Here, as a proof of concept, we take an initial step toward developing prediction models to differentiate individuals based on a personality disorder: psychopathy. We included three groups of adolescent participants: incarcerated youth with elevated psychopathic traits (i.e., callous and unemotional traits and conduct disordered traits; n = 71), incarcerated youth with low psychopathic traits (n = 72), and non-incarcerated youth as healthy controls (n = 21). Support vector machine (SVM) learning models were developed to separate these groups using an out-of-sample cross-validation method on voxel-based morphometry (VBM) data. Regions of interest from the paralimbic system, identified in an independent forensic sample, were successful in differentiating youth groups. Models seeking to classify incarcerated individuals to have high or low psychopathic traits achieved 69.23% overall accuracy. As expected, accuracy increased in models differentiating healthy controls from individuals with high psychopathic traits (82.61%) and low psychopathic traits (80.65%). Here we have laid the foundation for using neural correlates of personality traits to identify group membership within and beyond psychopathy. This is only the first step, of many, toward prediction models using neural measures as a proxy for personality traits. As these methods are improved, prediction models with neural measures of personality traits could have far-reaching impact on diagnosis, treatment, and prediction of future behavior.", 
        "author": "Vaughn R. Steele and Vikram Rao and Vince D. Calhoun and Kent A. Kiehl", 
        "keyword": "Prediction\", \"Voxel-based morphometry\", \"SVM\", \"Psychopathy", 
        "title": "Machine learning of structural magnetic resonance imaging predicts psychopathic traits in adolescent offenders"
    }, 
    {
        "abstract": "Abstract Extremely randomized trees (ET) classifiers, an extension of random forests (RF) are applied to classification of features such as seamounts derived from bathymetry data. This data is characterized by sparse training data from by large noisy features sets such as often found in other geospatial data. A variety of feature metrics may be useful for this task and we use a large number of metrics relevant to the task of finding seamounts. The major significant results to be described include: an outstanding seamount classification accuracy of 97%; an automated process to produce the most useful classification features that are relevant to geophysical scientists (as represented by the feature metrics); demonstration that topography provides the most important data representation for classification. As well as achieving good accuracy in classification, the human-understandable set of metrics generated by the classifier that are most relevant for the results are discussed.", 
        "author": "Ed Lawson and Denson Smith and Donald Sofge and Paul Elmore and Frederick Petry", 
        "keyword": "Bathymetry\", \"Topography\", \"Seamounts\", \"Random forests\", \"Extremely randomized trees", 
        "title": "Decision forests for machine learning classification of large, noisy seafloor feature sets"
    }, 
    {
        "abstract": "Abstract The figurative \u201clow hanging fruit\u201d of biomedical research in the genomic age is quickly disappearing, leaving the complexity of common disease etiology. Methodologies that are both powerful and flexible will be required to deal with an array of phenomena that obscure the link between predictive factors and disease phenotypes. In this chapter, we highlight these challenges and explore learning classifier systems (LCSs) as a methodology for embracing complexity. These algorithms combine machine learning with evolutionary computing and other heuristics to produce an adaptive rule-set. Uniquely, the resulting \u201cmodel\u201d is a compendium of individual rules, each covering a subset of the problem space. \\{LCS\\} algorithms have the potential to play an important role in the future of biomedical data mining, as they make no assumptions about underlying patterns of association, including linearity, the number of features involved, the order of interactions, or the presence of heterogeneity.", 
        "author": "Ryan J. Urbanowicz and Jason H. Moore", 
        "keyword": "Heterogeneity\", \"Epistasis\", \"Learning classifier system\", \"Machine learning\", \"Data mining\", keywords =Evolutionary algorithms\", \"Genetics\", \"Knowledge discovery\", \"Data visualizations\", \"Common disease", 
        "title": "Chapter 9 - Learning Classifier Systems: The Rise of Genetics-Based Machine Learning in Biomedical Data Mining"
    }, 
    {
        "abstract": null, 
        "author": "Evanthia E. Tripoliti and Theofilos G. Papadopoulos and Georgia S. Karanasiou and Katerina K. Naka and Dimitrios I. Fotiadis", 
        "keyword": "Heart failure\", \"Diagnosis\", \"Prediction\", \"Severity estimation\", \"Classification\", \"Data mining", 
        "title": "Heart Failure: Diagnosis, Severity Estimation and Prediction of Adverse Events Through Machine Learning Techniques"
    }, 
    {
        "abstract": "Abstract Recent advances in high-throughput sequencing allow researchers to examine the transcriptome in more detail than ever before. Using a method known as high-throughput small RNA-sequencing, we can now profile the expression of small regulatory \\{RNAs\\} such as microRNAs and small interfering \\{RNAs\\} (siRNAs) with a great deal of sensitivity. However, there are many other types of small \\{RNAs\\} (&lt;50 nt) present in the cell, including fragments derived from snoRNAs (small nucleolar RNAs), snRNAs (small nuclear RNAs), scRNAs (small cytoplasmic RNAs), tRNAs (transfer RNAs), and transposon-derived RNAs. Here, we present a user\u2019s guide for CoRAL (Classification of \\{RNAs\\} by Analysis of Length), a computational method for discriminating between different classes of \\{RNA\\} using high-throughput small RNA-sequencing data. Not only can CoRAL distinguish between \\{RNA\\} classes with high accuracy, but it also uses features that are relevant to small \\{RNA\\} biogenesis pathways. By doing so, CoRAL can give biologists a glimpse into the characteristics of different \\{RNA\\} processing pathways and how these might differ between tissue types, biological conditions, or even different species. CoRAL is available at http://wanglab.pcbi.upenn.edu/coral/.", 
        "author": "Paul Ryvkin and Yuk Yee Leung and Lyle H. Ungar and Brian D. Gregory and Li-San Wang", 
        "keyword": "Small RNAs\", \"MicroRNAs\", \"Small interfering RNAs\", \"Non-coding RNAs\", \"RNA-seq\", \"Machine learning", 
        "title": "Using machine learning and high-throughput \\{RNA\\} sequencing to classify the precursors of small non-coding \\{RNAs\\}"
    }, 
    {
        "abstract": "Abstract Enabling the paradigm of quality by design requires the ability to quantitatively correlate material properties and process variables to measureable product performance attributes. Conventional, quality-by-test methods for determining tablet breaking force and disintegration time usually involve destructive tests, which consume significant amount of time and labor and provide limited information. Recent advances in material characterization, statistical analysis, and machine learning have provided multiple tools that have the potential to develop nondestructive, fast, and accurate approaches in drug product development. In this work, a methodology to predict the breaking force and disintegration time of tablet formulations using nondestructive ultrasonics and machine learning tools was developed. The input variables to the model include intrinsic properties of formulation and extrinsic process variables influencing the tablet during manufacturing. The model has been applied to predict breaking force and disintegration time using small quantities of active pharmaceutical ingredient and prototype formulation designs. The novel approach presented is a step forward toward rational design of a robust drug product based on insight into the performance of common materials during formulation and process development. It may also help expedite drug product development timeline and reduce active pharmaceutical ingredient usage while improving efficiency of the overall process.", 
        "author": "Ilgaz Akseli and Jingjin Xie and Leon Schultz and Nadia Ladyzhynsky and Tommasina Bramante and Xiaorong He and Rich Deanne and Keith R. Horspool and Robert Schwabe", 
        "keyword": "predictive modeling\", \"tablet formulation\", \"tablet breaking force\", \"disintegration time\", keywords =nondestructive testing\", \"neuroevolution", 
        "title": "A Practical Framework Toward Prediction of Breaking Force and Disintegration of Tablet Formulations Using Machine Learning Tools"
    }, 
    {
        "abstract": "Abstract A new methodology combining the advanced extreme learning machine (ELM) and harmony search (HS) was proposed to model and optimize the operational parameters of the boiler for the control of \\{NOX\\} emissions in a 700 \\{MW\\} pulverized coal-fired power plant. About five days\u2019 worth of real data were obtained from supervisory information system (SIS) of the power plant to build the \\{ELM\\} \\{NOX\\} model. \\{HS\\} was employed to optimize the operational parameters of the boiler to minimize \\{NOX\\} emissions based on the prediction of \\{NOX\\} by ELM. Compared with the widely used learning method such as \\{ANN\\} and SVR, \\{ELM\\} performed better both in accuracy and computing time for the modeling of \\{NOX\\} emission. The proposed comprehensive methodology can provide desired and feasible optimal solutions within one second, which is acceptable for the online optimization.", 
        "author": "Peng Tan and Ji Xia and Cheng Zhang and Qingyan Fang and Gang Chen", 
        "keyword": "\\{NOX\\} emissions\", \"Extreme learning machine\", \"Harmony search\", \"Combustion optimization\", \"Coal-fired power plant", 
        "title": "Modeling and Optimization of \\{NOX\\} Emission in a Coal-fired Power Plant using Advanced Machine Learning Methods"
    }, 
    {
        "abstract": "AbstractBackground Machine-learning models may aid cardiac phenotypic recognition by using features of cardiac tissue\u00a0deformation. Objectives This study investigated the diagnostic value of a machine-learning framework that incorporates speckle-tracking echocardiographic data for automated discrimination of hypertrophic cardiomyopathy (HCM) from physiological hypertrophy seen in athletes (ATH). Methods Expert-annotated speckle-tracking echocardiographic datasets obtained from 77 \\{ATH\\} and 62 \\{HCM\\} patients\u00a0were used for developing an automated system. An ensemble machine-learning model with 3 different machine-learning algorithms (support vector machines, random forests, and artificial neural networks) was developed\u00a0and a majority voting method was used for conclusive predictions with further K-fold cross-validation. Results Feature selection using an information gain (IG) algorithm revealed that volume was the best predictor for differentiating between \\{HCM\\} ands. \\{ATH\\} (IG\u00a0= 0.24) followed by mid-left ventricular segmental (IG\u00a0= 0.134) and average longitudinal strain (IG\u00a0= 0.131). The ensemble machine-learning model showed increased sensitivity and specificity compared with early-to-late diastolic transmitral velocity ratio (p\u00a0&lt; 0.01), average early diastolic tissue velocity (e\u2032) (p\u00a0&lt;\u00a00.01), and strain (p\u00a0= 0.04). Because \\{ATH\\} were younger, adjusted analysis was undertaken in younger \\{HCM\\} patients\u00a0and compared with \\{ATH\\} with left ventricular wall thickness &gt;13 mm. In this subgroup analysis, the automated\u00a0model continued to show equal sensitivity, but increased specificity relative to early-to-late diastolic transmitral velocity ratio, e\u2032, and strain. Conclusions Our results suggested that machine-learning algorithms can assist in the discrimination of\u00a0physiological\u00a0versus pathological patterns of hypertrophic remodeling. This effort represents a step toward\u00a0the\u00a0development of a real-time, machine-learning\u2013based system for automated interpretation of echocardiographic images,\u00a0which may help novice readers with limited experience.", 
        "author": "Sukrit Narula and Khader Shameer and Alaa Mabrouk Salem Omar and Joel T. Dudley and Partho P. Sengupta", 
        "keyword": "cardiomyopathy\", \"decision support systems\", \"left ventricular hypertrophy\", \"speckle-tracking echocardiography", 
        "title": "Machine-Learning Algorithms to Automate Morphological and Functional Assessments in 2D Echocardiography"
    }, 
    {
        "abstract": "Abstract This paper considers identical parallel-machine scheduling problem with past-sequence-dependent (psd) delivery times and learning effect. In electronic manufacturing industry, an electronic component may be exposed to certain electromagnetic field and requires an extra time for eliminating adverse effect after the main processing. The extra time is modeled as past-sequence-dependent delivery time in the literature, which is proportional to the waiting time in the system. It is also observed that the learning process reflects a decrease in the processing time as a function of the number of repetitions, i.e., as a function of the job position in the sequence. In practice, one often has to deal with the scheduling problems with psd delivery times and learning effect. Identical parallel-machine setting is considered because the occurrence of resources in parallel is common in the real world. In this paper, three objectives are the minimization of the total absolute deviation of job completion times, the total load on all machines and the total completion time. We develop polynomial algorithms to optimally solve these problems.", 
        "author": "Ming Liu", 
        "keyword": "Scheduling\", \"Parallel machine\", \"Past-sequence-dependent delivery times\", \"Learning effect", 
        "title": "Parallel-machine scheduling with past-sequence-dependent delivery times and learning effect"
    }, 
    {
        "abstract": "Abstract First episode psychosis (FEP) patients are of particular interest for neuroimaging investigations because of the absence of confounding effects due to medications and chronicity. Nonetheless, imaging data are prone to heterogeneity because for example of age, gender or parameter setting differences. With this work, we wanted to take into account possible nuisance effects of age and gender differences across dataset, not correcting the data as a pre-processing step, but including the effect of nuisance covariates in the classification phase. To this aim, we developed a method which, based on multiple kernel learning (MKL), exploits the effect of these confounding variables with a subject-depending kernel weighting procedure. We applied this method to a dataset of cortical thickness obtained from structural magnetic resonance images (MRI) of 127 \\{FEP\\} patients and 127 healthy controls, who underwent either a 3 Tesla (T) or a 1.5 T \\{MRI\\} acquisition. We obtained good accuracies, notably better than those obtained with standard \\{SVM\\} or \\{MKL\\} methods, up to more than 80% for frontal and temporal areas. To our best knowledge, this is the largest classification study in \\{FEP\\} population, showing that fronto-temporal cortical thickness can be used as a potential marker to classify patients with psychosis.", 
        "author": "Letizia Squarcina and Umberto Castellani and Marcella Bellani and Cinzia Perlini and Antonio Lasalvia and Nicola Dusi and Chiara Bonetto and Doriana Cristofalo and Sarah Tosato and Gianluca Rambaldelli and Franco Alessandrini and Giada Zoccatelli and Roberto Pozzi-Mucelli and Dario Lamonaca and Enrico Ceccato and Francesca Pileggi and Fausto Mazzi and Paolo Santonastaso and Mirella Ruggeri and Paolo Brambilla", 
        "keyword": "Schizophrenia\", \"Affective psychosis\", \"Cortical thickness\", \"MRI\", \"Frontal\", \"Temporal cortex", 
        "title": "Classification of first-episode psychosis in a large cohort of patients using support vector machine and multiple kernel learning techniques"
    }, 
    {
        "abstract": "Abstract Regularized empirical risk minimization including support vector machines plays an important role in machine learning theory. In this paper regularized pairwise learning (RPL) methods based on kernels will be investigated. One example is regularized minimization of the error entropy loss which has recently attracted quite some interest from the viewpoint of consistency and learning rates. This paper shows that such \\{RPL\\} methods and also their empirical bootstrap have additionally good statistical robustness properties, if the loss function and the kernel are chosen appropriately. We treat two cases of particular interest: (i) a bounded and non-convex loss function and (ii) an unbounded convex loss function satisfying a certain Lipschitz type condition.", 
        "author": "Andreas Christmann and Ding-Xuan Zhou", 
        "keyword": "Machine learning\", \"Pairwise loss function\", \"Regularized risk\", \"Robustness", 
        "title": "On the robustness of regularized pairwise learning methods based on kernels"
    }, 
    {
        "abstract": "Abstract This study considers an NP-hard problem of minimizing the total tardiness on a single machine with arbitrary release dates and position-dependent learning effects. A mixed-integer programming (MIP ) model is first formulated to find the optimal solution for small-size problem instances. Some new dominance rules are then presented which provide a sufficient condition for finding local optimality. The branch-and-bound (B&amp; B) strategy incorporating with several dominance properties and a lower bound is proposed to derive the optimal solution for medium- to-large-size problem instances, and four marriage-in-honey-bees optimization algorithms (MBO) are developed to derive near-optimal solutions for the problem. To show the effectiveness of the proposed algorithms, 3600 situations with 20 and 25 jobs, are randomly generated for experiments.", 
        "author": "Yunqiang Yin and Wen-Hung Wu and Wen-Hsiang Wu and Chin-Chia Wu", 
        "keyword": "Scheduling\", \"Single-machine\", \"Tardiness\", \"Learning effect", 
        "title": "A branch-and-bound algorithm for a single machine sequencing to minimize the total tardiness with arbitrary release dates and position-dependent learning effects"
    }, 
    {
        "abstract": "Abstract The research presented in this paper proposes a new machine learning-based evaluation method for assessing the usability of eLearning systems. Three machine learning methods (support vector machines, neural networks and decision trees) along with multiple linear regression are used to develop prediction models in order to discover the underlying relationship between the overall eLearning system usability and its predictor factors. A subsequent sensitivity analysis is conducted to determine the rank-order importance of the predictors. Using both sensitivity values along with the usability scores, a metric (called severity index) is devised. By applying a Pareto-like analysis, the severity index values are ranked and the most important usability characteristics are identified. The case study results show that the proposed methodology enhances the determination of eLearning system problems by identifying the most pertinent usability factors. The proposed method could provide an invaluable guidance to the usability experts as to what measures should be improved in order to maximize the system usability for a targeted group of end-users of an eLearning system.", 
        "author": "Asil Oztekin and Dursun Delen and Ali Turkyilmaz and Selim Zaim", 
        "keyword": "eLearning (web-based learning/distance learning)\", \"Usability engineering\", \"Severity index\", keywords =Information fusion\", \"Sensitivity analysis\", \"Machine learning", 
        "title": "A machine learning-based usability evaluation method for eLearning systems"
    }, 
    {
        "abstract": "Abstract 3He gas based neutron Linear-Position-Sensitive Detectors (LPSDs) have been used for many neutron scattering instruments. Traditional Pulse-height Analysis (PHA) for Neutron-Gamma Discrimination (NGD) resulted in the neutron-gamma efficiency ratio (NGD ratio) on the order of 105\u2013106. The \\{NGD\\} ratios of 3He detectors need to be improved for even better scientific results from neutron scattering. Digital Signal Processing (DSP) analyses of waveforms were proposed for obtaining better \\{NGD\\} ratios, based on features extracted from rise-time, pulse amplitude, charge integration, a simplified Wiener filter, and the cross-correlation between individual and template waveforms of neutron and gamma events. Fisher Linear Discriminant Analysis (FLDA) and three Multivariate Analyses (MVAs) of the features were performed. The \\{NGD\\} ratios are improved by about 102\u2013103 times compared with the traditional \\{PHA\\} method. Our results indicate the \\{NGD\\} capabilities of 3He tube detectors can be significantly improved with subspace-learning based methods, which may result in a reduced data-collection time and better data quality for further data reduction.", 
        "author": "C.L. Wang and L.L. Funk and R.A. Riedel and K.D. Berry", 
        "keyword": "He-3 neutron detectors\", \"Neutron-gamma discrimination\", \"Digital signal processing\", \"Subspace learning methods", 
        "title": "Improved neutron-gamma discrimination for a 3He neutron detector using subspace learning methods"
    }, 
    {
        "abstract": "Abstract Computational color constancy refers to the problem of computing the illuminant color so that the images of a scene under varying illumination can be normalized to an image under the canonical illumination. In this paper, we adopt a deep learning framework for the illumination estimation problem. The proposed method works under the assumption of uniform illumination over the scene and aims for the accurate illuminant color computation. Specifically, we trained the convolutional neural network to solve the problem by casting the color constancy problem as an illumination classification problem. We designed the deep learning architecture so that the output of the network can be directly used for computing the color of the illumination. Experimental results show that our deep network is able to extract useful features for the illumination estimation and our method outperforms all previous color constancy methods on multiple test datasets.", 
        "author": "Seoung Wug Oh and Seon Joo Kim", 
        "keyword": "Computational color constancy\", \"White balancing\", \"Illumination estimation\", \"Machine learning\", \"Convolutional neural network", 
        "title": "Approaching the computational color constancy as a classification problem through deep learning"
    }, 
    {
        "abstract": "Abstract Sentiment analysis is the natural language processing task dealing with sentiment detection and classification from texts. In recent years, due to the growth in the quantity and fast spreading of user-generated contents online and the impact such information has on events, people and companies worldwide, this task has been approached in an important body of research in the field. Despite different methods having been proposed for distinct types of text, the research community has concentrated less on developing methods for languages other than English. In the above-mentioned context, the present work studies the possibility to employ machine translation systems and supervised methods to build models able to detect and classify sentiment in languages for which less/no resources are available for this task when compared to English, stressing upon the impact of translation quality on the sentiment classification performance. Our extensive evaluation scenarios show that machine translation systems are approaching a good level of maturity and that they can, in combination to appropriate machine learning algorithms and carefully chosen features, be used to build sentiment analysis systems that can obtain comparable performances to the one obtained for English.", 
        "author": "Alexandra Balahur and Marco Turchi", 
        "keyword": "Multilingual sentiment analysis\", \"Opinion mining\", \"Machine translation\", \"Supervised learning", 
        "title": "Comparative experiments using supervised learning and machine translation for multilingual sentiment analysis"
    }
]