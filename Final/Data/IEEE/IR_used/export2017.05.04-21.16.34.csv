"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4371027,4367973,4368069,4368033,4370465,4362915,4368023,4374013,4365398,4362907,4365436,4368031,4373987,4368176,4365440,4365403,4368105,4371432,4370588,4371361,4367781,4370934,4368064,4368177,4370762,4370131,4365439,4370825,4370849,4373921,4351450,4353348,4351619,4350821,4353334,4362282,4353125,4354121,4352513,4351694,4352176,4355329,4351415,4362539,4354141,4350818,4351419,4353347,4350808,4351456,4353715,4351691,4351620,4353346,4353187,4351436,4349399,4349392,4346388,4344105,4343808,4343749,4317560,4343899,4337772,4346443,4344056,4347577,4349618,4344053,4346371,4349314,4343740,4343777,4343699,4348164,4341087,4341152,4338421,4338369,4340690,4341090,4338344,4341032,4338413,4338405,4338404,4338332,4338377,4338393,4340667,4338400,4340296,4343441,4340727,4340689,4338953,4339201,4338415,4340291",2017/05/04 21:16:34
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"The Community Structure of Information Content in Mobile Internet","B. Z. Li; Q. H. Zhu","Sch. of Manage. & Eng., Nanjing Univ., Nanjing","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","3849","3851","In the mobile Internet, information users are facing with the conflict between the extensive information and the limited resources such as time, devices, and so on. To get the relative information content, we used the community structure theory about complex network to analyze the k-clique information content, and reduce the retrieving range.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340727","","Bandwidth;Complex networks;Content management;Engineering management;IP networks;Information management;Information resources;Information retrieval;Internet;Resource management","Internet;mobile computing","community structure theory;k-clique information content;mobile Internet","","0","","12","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Performance Analysis of Probabilistic Flooding Using Random Graphs","K. Oikonomou; I. Stavrakakis","Dept. of Informatics, Ionian University, Tsirigoti Square 7, 49100 Corfu, Greece, okon@ionio.gr","2007 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks","20071022","2007","","","1","6","Probabilistic flooding (parameterized by a forwarding probability) has frequently been considered in the past, as a means of limiting the large message overhead associated with traditional (full) flooding approaches that are used to disseminate globally information in unstructured peer-to-peer and other networks. A key challenge in using probabilistic flooding is the determination of the forwarding probability so that global network outreach is achieved while keeping the message overhead as low as possible. By showing that a probabilistic flooding network generated by applying probabilistic flooding to a connected random graph network can be bounded by properly parameterized random graph networks and invoking random graph theory results, bounds on the value of the forwarding probability are derived guaranteeing global network outreach with high probability, while significantly reducing the message overhead. Bounds on the average number of messages Â¿ as well as asymptotic expressions - and on the average time required to complete network outreach are also derived, illustrating the benefits of the properly parameterized probabilistic flooding scheme.","","CD-ROM:978-1-4244-0993-8; POD:978-1-4244-0992-1","10.1109/WOWMOM.2007.4351694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351694","","Floods;Graph theory;Informatics;Information retrieval;Peer to peer computing;Performance analysis;Telecommunications","","","","11","","27","","","18-21 June 2007","","IEEE","IEEE Conference Publications"
"Physical, Social, and Experiential Knowledge in Pervasive Computing Environments","G. R. Hayes; E. S. Poole; G. Iachello; S. N. Patel; A. Grimes; G. D. Abowd; K. N. Truong","Georgia Institute of Technology","IEEE Pervasive Computing","20071015","2007","6","4","56","63","Pervasive computing designers and researchers often create services and applications to help people record their experiences. At the same time, cheap, small, and easy-to-deploy recording technologies are quickly emerging throughout public spaces. In many ways, these technologies are pervasive computing realized. Understanding how people deal with audio and video recording is therefore a good way to explore how people might adopt, adapt, and react to pervasive computing technologies in general. A long-term deployment of a system for recording experiences in informal spaces demonstrates that people use physical, social, and experiential knowledge to determine new technologies' relative utility and safety. In this paper, we aim to add significantly to the research surrounding security and privacy concerns by focusing on them rather than just noting them as a side effect of testing an application's utility and usability.","1536-1268;15361268","","10.1109/MPRV.2007.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343899","capture and access;privacy;record-keeping;security;selective archiving;trust","Audio recording;Cameras;Information retrieval;Information security;Microphones;Pervasive computing;Privacy;Space technology;Testing;Video recording","data privacy;information retrieval systems;records management;security of data;ubiquitous computing","BufferWare;experiential knowledge;informal spaces;pervasive computing;physical knowledge;privacy concerns;recording experiences;security;selective-archiving;social knowledge","","16","","8","","","Oct.-Dec. 2007","","IEEE","IEEE Journals & Magazines"
"Mining Weighted Association Rules with Lucene Index","N. Zhou; J. Wu; S. Zhang; H. Chen; X. Zhang","Res. Center of Inf. Resources, Wuhan Univ., Wuhan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","3697","3700","Discovery of association rules has been found useful in many applications. With large database, the process of mining association rules is time consuming. The efficiency becomes crucial factor. Weighted association is more meaningful in some application. This paper implements a fast and stable algorithm to mining weighted association rules base on the open source library Lucene. The methods to create index in Lucene and utilization of the index to find weighted frequent itemsets are introduced. Based on apriori algorithm, a weighted association rule mining algorithm is implemented. All the rules can be recommended to customer by searching Lucene Index. Experiment shows that this method is more efficient than general apriori algorithm.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340689","","Association rules;Data mining;Indexes;Indexing;Information management;Information resources;Information retrieval;Itemsets;Libraries;Transaction databases","data mining;database indexing;public domain software;software libraries;very large databases","Lucene index;apriori algorithm;association rule discovery;large database;open source library Lucene;weighted association rule mining","","1","","7","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Generating Change Request XML Specification in Customer Business Environment","Z. Stojanov","Technical Faculty "Mihajlo Pupin", Zrenjanin, Serbia, zeljkos@tf.zr.ac.yu","2007 IEEE International Conference on Intelligent Computer Communication and Processing","20071022","2007","","","275","278","Change must be observed as an essential property of software product. Change process is initiated by receiving change request. Change requests might occur in all phases of software product life cycle. After software delivery change requests are usually submitted by customers. Typically, customers submit change requests by filling a form at developers' Web site. This paper presents new approach for change request specification by customer. Standard change request process is modified so that customers might specify change requests in context of their business environment, and after that send them to developers' Web site via HTTP. Standard change request process extension is realized through integration of change request generator into application deployed into customer business environment. Change request generator leads customer through predefined steps and produces XML specification of change request. The purpose of this approach is to provide precise and portable change request specification closely related to business context.","","POD:1-4244-1491-1","10.1109/ICCP.2007.4352176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4352176","","Application software;Computer bugs;Context modeling;Filling;Information retrieval;Open source software;Programming;Software maintenance;Standards development;XML","XML;formal specification;hypermedia;software maintenance","HTTP;Web site;change request XML specification;customer business environment;software delivery change;software product life cycle","","1","","15","","","6-8 Sept. 2007","","IEEE","IEEE Conference Publications"
"User Interest Model-based Image Retrieval Technique","J. Li; M. Liu; Y. Cheng","Department of Computer and Information Engineering, Shijiazhuang railway institute, shijiazhuang, Hebei, china. Email: Lijh","2007 IEEE International Conference on Automation and Logistics","20071008","2007","","","2265","2269","The content-based image retrieval (CBIR) system establishes the feature space by comprehending the content of an image and executing retrieval by measuring the similarity of images. With the development of CBIR, however, there are two problems. One is that since different researchers use different feature spaces, or use the same feature space but different description, then the measure is different, it is difficult for retrieval to be universal, especially in WEB. Another is that currently CBIR tools designed for satisfying the needs of all users, special needs of individual user are not considered. Aimed at above problems, we establish the multi-feature spaces, by features of color layout descriptor and homogeneous texture descriptor, which considering both color and texture by human sense, and adjusting the weight of every feature space by applying PGA (parallel genetic algorithm) for matching the user interest. The result of experiment shows that the system is robust in general format by using MPEG-7, and can match the user profile as well.","2161-8151;21618151","POD:978-1-4244-1530-4","10.1109/ICAL.2007.4338953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338953","Content-based Image Retrieval;MPEG-7;Parallel Genetic Algorithm;User interest","Automotive engineering;Content based retrieval;Data mining;Educational institutions;Feature extraction;Genetic algorithms;Humans;Image retrieval;Information retrieval;MPEG 7 Standard","content-based retrieval;genetic algorithms;image retrieval","color layout descriptor;content-based image retrieval content-based image retrieval;homogeneous texture descriptor;parallel genetic algorithm;user interest model-based image retrieval technique","","1","","8","","","18-21 Aug. 2007","","IEEE","IEEE Conference Publications"
"Robust Invariant Descriptor for Symbol-Based Image Recognition and Retrieval","A. Wong; W. Bishop","University of Waterloo, Canada","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","637","644","This paper presents a robust invariant descriptor for symbol-based image recognition and retrieval. A modified Hough-based Transform is used to extract parameter space information (i.e., position data and angular data) from a symbol image to derive an invariant descriptor. The proposed descriptor provides a compact representation of a symbol image that can be evaluated efficiently. The extracted descriptor is highly robust against geometric transformations such as translation, rotation, reflection, and scaling, and image degradation. A series of experiments were conducted using a set of architectural and engineering symbols subjected to geometric transformations and image degradation. The experimental results clearly show that the proposed descriptor can be used effectively for symbol recognition and retrieval.","","POD:0-7695-2997-6","10.1109/ICSC.2007.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338404","","Content based retrieval;Data mining;Degradation;Image recognition;Image retrieval;Information retrieval;Reflection;Robustness;Shape;Testing","Hough transforms;content-based retrieval;feature extraction;image recognition;image representation;image retrieval","Hough-based transform;feature extraction;geometric transformation;image degradation;image representation;image retrieval;robust invariant descriptor;symbol-based image recognition","","3","","11","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Image Retrieval Using the Curvature Scale Space (CSS) Technique and the Self-Organizing Map (SOM) Model under Affine Transforms","C. W. D. de Almeida; R. M. C. R. de Souza; C. E. B. Rodrigues; N. L. J. Cavalcanti","Cidade Universitaria","7th International Conference on Hybrid Intelligent Systems (HIS 2007)","20071015","2007","","","210","215","In a previous work [1], we presented an approach for shape-based image retrieval using the curvature scale space (CSS) and self-organizing map (SOM) methods. Here, we examine the robustness of the representation under affine transforms. Moreover, the CSS images extracted from a database are processed and described by median vectors that constitutes the training data set for a SOM neural network. This way of description improves the accuracy of image retrieval in comparison with the previous work [1] that used the first principal component of the PCA technique. Experiments with a benchmark database are carried out to demonstrate the usefulness of the proposed methodology.","","CD-ROM:0-7695-2946-1","10.1109/HIS.2007.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344053","","Cascading style sheets;Data mining;Image databases;Image retrieval;Information retrieval;Neural networks;Robustness;Shape;Spatial databases;Training data","affine transforms;image retrieval;principal component analysis;self-organising feature maps","CSS technique;PCA technique;SOM methods;SOM model;affine transforms;curvature scale space technique;image retrieval;median vectors;self-organizing map model;training data set","","0","","17","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Analysis and Comparison of Replicated Declustering Schemes","A. Saman Tosun","Univ. of Texas, San Antonio","IEEE Transactions on Parallel and Distributed Systems","20071008","2007","18","11","1578","1591","Declustering distributes data among parallel disks to reduce the retrieval cost using I/O parallelism. Many schemes were proposed for the single-copy declustering of spatial data. Recently, declustering using replication gained a lot of interest and several schemes with different properties were proposed. An in-depth comparison of major schemes is necessary to understand replicated declustering better. In this paper, we analyze the proposed schemes, tune some of the parameters, and compare them for different query types and under different loads. We propose a three-step retrieval algorithm for the compared schemes. For arbitrary queries, the dependent and partitioned allocation schemes perform poorly; others perform close to each other. For range queries, they perform similarly with the exception of smaller queries in which random duplicate allocation (RDA) performs poorly and dependent allocation performs well. For connected queries, partitioned allocation performs poorly and dependent allocation performs well under a light load.","1045-9219;10459219","","10.1109/TPDS.2007.1082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4339201","Declustering;latin square;parallel I/0;spatial range query","Costs;Data visualization;Geographic Information Systems;Information retrieval;Multidimensional systems;Partitioning algorithms;Relational databases;Scalability;Spatial databases;Visual databases","disc storage;query processing;replicated databases;resource allocation","I/O parallelism;parallel disk;random duplicate allocation;replicated declustering scheme;retrieval algorithm","","8","","49","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
"Modeling Human Reading in Conceptual Networks for Text Representation and Comparison","J. I. Serrano; A. Iglesias; M. D. del Castillo","Bioengineering Group, Instituto de Autom&#225;tica Industrial, Spanish National Research Council (CSIC). Ctra Campo Real km 0.200 - La Poveda, 28500 Arganda del Rey, Spain. Phone: +34 91 871 19 00. Fax: +34 91 871 70 50. Email: nachosm@iai.csic.es, lola@iai.csic.es","2007 International Joint Conference on Neural Networks","20071029","2007","","","613","618","Although machines perform much better than human beings in most of the tasks, it is not the case of natural language processing. Computational linguistics systems use to rely on mathematical and statistical formalisms, which are efficient and useful but far from human procedures and therefore not so skilled. This paper proposes a computational model of natural language reading, called cognitive reading indexing model (CRIM), inspired by some aspects of human cognition, trying to become as more psychologically plausible as possible. The model relies on a semantic neural network and it does not produce vectors but nets of activated concepts as text representations. Based on these representations, an efficient measure of semantic similarity is also defined. The system is not only suitable to human reading modeling but also it can be used in natural language processing applications since results point out that the system improves the performance of other traditional language representations.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371027","","Application software;Cognition;Frequency;Humans;Indexing;Information retrieval;Natural language processing;Natural languages;Neural networks;Psychology","cognitive systems;computational linguistics;natural language processing;neural nets;text analysis","cognitive reading indexing model;computational linguistics;conceptual network;human cognition;human reading modeling;natural language reading;semantic neural network;semantic similarity;text representation","","0","","20","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"Semantic Information Extraction of Video Based on Ontology and Inference","J. Ma; J. Zhang; H. Lu; X. Xue","Fudan University, China","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","721","726","In this paper, a new ontology-based composite concept detection method is proposed, which adopts Bayesian network to construct the ontology and uses the inference rules to perform the composite concept detection providing the concrete concepts in a phrase of video. Furthermore, the probability instead of binary value is gained through the inference pattern of Bayesian network, which can obtain more precise results. The main contribution of this paper is that semantic concept ontology is constructed using Bayesian network and the constructed ontology represents the hierarchical relationship between the concepts which can be used for inference. The method narrows the influence of ""Semantic Gap"" in some extent and achieves good performance in composite concept detection.","","POD:0-7695-2997-6","10.1109/ICSC.2007.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338415","","Airplanes;Bayesian methods;Computer networks;Computer science;Concrete;Data mining;Graphical models;Information retrieval;Ontologies;Videoconference","belief networks;inference mechanisms;ontologies (artificial intelligence);semantic networks;statistical distributions;video retrieval","Bayesian network;inference rules;ontology-based composite concept detection method;probability distribution;semantic concept ontology construction;semantic gap;semantic information extraction;semantic network;video retrieval","","2","13","15","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Music Analysis Using Hidden Markov Mixture Models","Y. Qi; J. W. Paisley; L. Carin","Duke Univ., Durham","IEEE Transactions on Signal Processing","20071022","2007","55","11","5209","5224","We develop a hidden Markov mixture model based on a Dirichlet process (DP) prior, for representation of the statistics of sequential data for which a single hidden Markov model (HMM) may not be sufficient. The DP prior has an intrinsic clustering property that encourages parameter sharing, and this naturally reveals the proper number of mixture components. The evaluation of posterior distributions for all model parameters is achieved in two ways: 1) via a rigorous Markov chain Monte Carlo method; and 2) approximately and efficiently via a variational Bayes formulation. Using DP HMM mixture models in a Bayesian setting, we propose a novel scheme for music analysis, highlighting the effectiveness of the DP HMM mixture model. Music is treated as a time-series data sequence and each music piece is represented as a mixture of HMMs. We approximate the similarity of two music pieces by computing the distance between the associated HMM mixtures. Experimental results are presented for synthesized sequential data and from classical music clips. Music similarities computed using DP HMM mixture modeling are compared to those computed from Gaussian mixture modeling, for which the mixture modeling is also performed using DP. The results show that the performance of DP HMM mixture modeling exceeds that of the DP Gaussian mixture modeling.","1053-587X;1053587X","","10.1109/TSP.2007.898782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4355329","Dirichlet process;Markov chain Monte Carlo (MCMC);hidden Markov model (HMM) mixture;music;variational Bayes","Bayesian methods;Databases;Hidden Markov models;Libraries;Machine learning;Monte Carlo methods;Multiple signal classification;Music information retrieval;Robustness;Statistical distributions","Bayes methods;Monte Carlo methods;hidden Markov models;music;pattern clustering","Bayesian setting;Dirichlet process prior;Gaussian mixture modeling;HMM;Markov chain Monte Carlo method;hidden Markov mixture models;intrinsic clustering property;music analysis;parameter sharing;synthesized sequential data;variational Bayes formulation","","27","","33","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
"Partial Disk Failures: Using Software to Analyze Physical Damage","H. Huang; K. G. Shin","IBM TJ Watson Research","24th IEEE Conference on Mass Storage Systems and Technologies (MSST 2007)","20071029","2007","","","185","198","A good understanding of disk failures is crucial to ensure a reliable storage of data. There have been numerous studies characterizing disk failures under the common assumption that failed disks are generally unusable. Contrary to this assumption, partial disk failures are very common, e.g., caused by a head crash resulting in a small number of inaccessible disk sectors. Nevertheless, the damage can sometimes be catastrophic if the file system meta-data were among the affected sectors. As disk density rapidly increases, the likelihood of losing data also rises. This paper describes our experience in analyzing partial disk failures using the physical locations of damaged disk sectors to assess the extent and characteristics of the damage on disk platter surfaces. Based on our findings, we propose several fault-tolerance techniques to proactively guard against permanent data loss due to partial disk failures.","2160-195X;2160195X","POD:0-7695-3025-7","10.1109/MSST.2007.4367973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4367973","","Computer crashes;Failure analysis;Fault tolerance;File systems;Hard disks;Information retrieval;Magnetic analysis;Magnetic heads;Manufacturing;Portable computers","disc storage;fault tolerance;storage management","data storage;file system meta-data;partial disk failures;physical damage;reliable data storage","","0","1","18","","","24-27 Sept. 2007","","IEEE","IEEE Conference Publications"
"Spoken Document Retrieval Using Multilevel Knowledge and Semantic Verification","C. L. Huang; C. H. Wu","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan","IEEE Transactions on Audio, Speech, and Language Processing","20071015","2007","15","8","2551","2560","This study presents a novel approach to spoken document retrieval based on multilevel knowledge indexing and semantic verification. Multilevel knowledge indexing considers three information sources, namely transcription data, keywords extracted from spoken documents, and hypernyms of the extracted keywords. A semantic network with forward-backward propagation is presented for semantic verification of the retrieved documents. In the forward step for semantic verification, a bag of keywords is chosen based on word significance measures. Semantic relations are estimated and adopted for verification in the backward procedure. The verification score is then utilized to weight and rerank the retrieved documents to obtain the final results. Experiments are performed on 40 h of anchor speech extracted from 198 h of collected broadcast news. Experimental results indicate that multilevel knowledge indexing and semantic verification achieve better retrieval results than other indexing schemes.","1558-7916;15587916","","10.1109/TASL.2007.907429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4317560","Multilevel knowledge;semantic verification;spoken document retrieval (SDR);spoken keyword extraction","Broadcasting;Content based retrieval;Data mining;Frequency;History;Indexing;Information retrieval;Natural languages;Speech recognition;Text recognition","information retrieval;speech recognition","forward-backward propagation;multilevel knowledge indexing;semantic verification;speech recognition;spoken document retrieval","","7","","34","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
"Reconstruction of People Information based on an Event Ontology","Y. J. Han; S. Y. Park; S. B. Park; Y. H. Lee; K. Y. Kim","Department of Computer Engineering, Kyungpook National University, Daegu 702-701, Korea, yjhan@knu.ac.kr","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","446","451","The people information is distributed in various forms such as database, web page, text, and so on, where the world wide web is one of the main sources of publicly-available people information. It has a characteristic that the information on people is intrinsically temporal. Therefore, the reconstruction of the information is needed for an individual or a company to use it efficiently. In order to maintain or manage the temporal people information, it must distinguish the variable information from invariable information of people. However, there have been few examples that construct an ontology from this point of view. In this paper, we propose a method that constructs an ontology based on events to manage the variable people information efficiently. In addition, we present a system which reconstructs people information that satisfies the users' demand with the ontology.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368069","","Data engineering;Distributed computing;Distributed databases;Frequency;History;Information retrieval;Ontologies;Portals;Semantic Web;Web pages","Internet;Web sites;ontologies (artificial intelligence)","World Wide Web;event ontology;people information reconstruction;publicly-available people information","","4","","13","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Identification of Noun Phrase with Various Granularities","Y. Qin; X. Wang; Y. Zhong","School of Information Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, qinyingmail@163.com","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","197","202","Since noun phrases are the most popular phrases in texts, noun phrase identification is one of vital subtasks of natural language processing. Generally Chinese noun phrases have hierarchical inner structures. This paper proposes an approach of defining various levels of granularity for noun phrases, catering for different application demands. Three levels of granularity noun phrases are proposed, that is, concept noun phrase, base noun phrase and entire noun phrase. The task of noun phrase identification is to label word sequences with phrase tags. All granularity noun phrase identifications are cast as classification problem under certain encoding schemes. The experimental dataset is acquired empirically from Chinese Penn Treebank 5.1. F, measure of concept noun phrase, base noun phrase and entire noun phrase identification reaches 92.12%, 84.13% and 85.32% respectively.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368033","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368033","","Data mining;Information retrieval;Morphology;Natural language processing;Natural languages;Sun;Tin","encoding;grammars;natural language processing;pattern classification;text analysis","Chinese noun phrases;classification problem;encoding schemes;granularity noun phrase identification;natural language processing;phrase tags;text phrases;word sequence labelling","","1","","14","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Automatically Constructing a Domain Ontology for Document Classification","Y. H. Chang","Department of information management, Southern Taiwan University of Technology, Taiwan. E-MAIL: yhchang@mail.stut.edu.tw","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","4","","1942","1947","For document classification, a domain ontology is first automatically constructed based on formal concept analysis. A document classification system, DCSO, is then proposed based the domain ontology. The features of DCSO are automatic construction of the system using the theorem of formal concept analysis, proposition of an XML knowledge-based schema for documents storage and quick search, and utilization of the hierarchy's property of ontology offering the accuracy of document classification. Experimental results for the DCSO are illustrated: the domain ontology is automatically constructed for document classification; the behavior of the accuracy for classification with DCSO is well; the searching time for DCSO steadily and slightly even though the queried documents increase rapidly.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370465","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370465","Document classification;Formal concept analysis;Ontology","Abstracts;Cybernetics;Data mining;Information analysis;Information retrieval;Knowledge management;Machine learning;Ontologies;Terminology;Text analysis","XML;document handling;knowledge based systems;ontologies (artificial intelligence)","XML knowledge-based schema;document classification;documents storage;domain ontology;formal concept analysis","","3","","18","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Extracting Meaning from Abbreviated Identifiers","D. Lawrie; H. Feild; D. Binkley","Loyola College, USA","Seventh IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2007)","20071029","2007","","","213","222","Informative identifiers are made up of full (natural language) words and (meaningful) abbreviations. Readers of programs typically have little trouble understanding the purpose of identifiers composed of full words. In addition, those familiar with the code can (most often) determine the meaning of abbreviations used in identifiers. However, when faced with unfamiliar code, abbreviations often carry little useful information. Furthermore, tools that focus on the natural language used in the code have a hard time in the presence of abbreviations. One approach to providing meaning to programmers and tools is to translate (expand) abbreviations into full words. This paper presents a methodology for expanding identifiers and evaluates the process on a code based of just over 35 million lines of code. For example, using phrase extraction, <b>fs_exists</b> is expanded to <b>file_status_exists</b> illustrating how the expansion process can facilitate comprehension. On average, 16 percent of the identifiers in a program are expanded. Finally, as an example application, the approach is used to improve the syntactic identification of violations to Deissenbock and Pizka's rules for concise and consistent identifier construction.","","POD:0-7695-2880-5","10.1109/SCAM.2007.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4362915","Program Comprehension;Program Identifiers;Software Quality","Dictionaries;Documentation;Educational institutions;Information retrieval;Libraries;Natural languages;Programming profession;Software engineering;Software quality;USA Councils","reverse engineering;software quality","abbreviated program identifier meaning extraction;program comprehension;program understandability;software quality;syntactic violation identification","","18","3","27","","","Sept. 30 2007-Oct. 1 2007","","IEEE","IEEE Conference Publications"
"Design of Secure and Low-Cost RFID Tag Baseband","J. Wang; H. Li; F. Yu","Dept. of Integrated Electron., CAS, Shenzhen","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","2066","2069","Nowadays, radio frequency identification (RFID) has been widely used in our everyday life, and has aroused increasing concerns about privacy and security. Cryptographic techniques can be used to protect privacy but are too expensive for low-cost RFID tags. This paper addresses the problem and proposes a new RFID system structure. In our system, the RFID tag sends only the hashed tag ID number to the reader, thus even if the communication data is intercepted, the adversary cannot retrieve any useful information. This paper also presents the RFID tag baseband design based on this new structure. Our design is implemented in an Altera FPGA. The experiment shows that the security of the baseband is largely enhanced compared to non-secure basic tags, while having less gate equivalents than some secure tags with other RFID system structures and cryptographic implementations.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.516","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340291","","Baseband;Communication system security;Cryptography;Data security;Field programmable gate arrays;Information retrieval;Privacy;Protection;RFID tags;Radiofrequency identification","cryptography;field programmable gate arrays;radiofrequency identification;telecommunication security","Altera FPGA;RFID system structure;communication data;cryptographic techniques;hashed tag ID number;nonsecure basic tags;radio frequency identification;secure RFID tag baseband","","3","","12","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Collaborative Quality Management IDSS Based on CBR and MAS","M. Yang; Y. Zhang; R. Chen","Sch. of Mech. Eng., Shandong Univ. of Technol., Jinan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","5133","5136","In the network manufacturing, due to the complexity of manufacturing systems, product diversity, the breadth of information and users higher demands of products, particularly the differences of the parts which compose of the product, make remote product quality control more difficult and complicated. In order to solve the above problem, this paper organically combines case-based retrieval technology, database technology, on-line analysis and multi-agent system technology and decision support systems and uses them for network for remote product manufacturing synergies quality management, bring forward IDSS model structure based on the CBR and MAS and its key technical problems were analyzed.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.1257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4341032","","Collaboration;Data analysis;Databases;Decision support systems;Information retrieval;Manufacturing systems;Multiagent systems;Pulp manufacturing;Quality control;Quality management","database management systems;decision support systems;information retrieval;manufacturing systems;multi-agent systems;product design;product development;production engineering computing;quality control","IDSS model;case-based retrieval;database technology;decision support system;manufacturing system;multiagent system;network manufacturing;online analysis;product diversity;product manufacturing;product quality control;quality management","","0","","3","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Indexing Methods for Similarity Searching","H. Samet","University of Maryland, USA","Eighth Mexican International Conference on Current Trends in Computer Science (ENC 2007)","20071022","2007","","","xv","xv","An overview is given of the various techniques and issues involved in providing indexing support for similarity searching. Similarity searching is a crucial part of retrieval in multimedia databases used for applications such as pattern recognition, image databases, and content-based retrieval. It involves finding objects in a data set S that are similar to a query object q based on some distance measure d which is usually a distance metric. The search process is usually achieved by means of nearest neighbor finding. Existing methods for handling similarity search in this setting fall into one of two classes. The first is based on mapping to a vector space. The vector space is usually of high dimension which requires special handling due to the fact indexing methods do not discriminate well in such spaces. In particular, the query regions often overlap all of the blocks that result from the decomposition of the underlying space. This has led to some special solutions that make use of a sequential scan. An alternative is to use dimension reduction to find a mapping from a high-dimensional space into a low-dimensional space by finding the most discriminating dimensions and then index the data using one of a number of different data structures such as k-d trees, R-trees, quadtrees, etc. The second directly indexes the objects based on distances making use of data structures such as the vp-tree, M-tree, etc.","","POD:0-7695-2899-6","10.1109/ENC.2007.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351415","","Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;Multimedia databases;Nearest neighbor searches;Pattern recognition;Q measurement;Vegetation mapping","data structures;database indexing;multimedia databases","content-based retrieval;data structures;image database;indexing methods;multimedia database;pattern recognition;similarity searching","","2","","","","","24-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Universal Ontology for Sensor Networks Data","M. Eid; R. Liscano; A. el Saddik","Multimedia Communications Research Laboratory - MCRLab, School of Information Technology and Engineering - University of Ottawa, Ottawa, Ontario, KIN 6N5, Canada, eid@mcrlab.uottawa.ca","2007 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications","20071022","2007","","","59","62","In this paper, we present our work towards the development and evaluation of an ontology for searching distributed and heterogeneous sensor networks data. In particular, we propose a two layer prototype ontology that utilizes the IEEE Suggested Upper Merged Ontology (SUMO) as a root definition of general concepts and associations and two sub- ontologies: the sensor data sub-ontology and the sensor hierarchy sub-ontology. The proposed ontology was implemented using Protege 2000 and eventually evaluated using the RDQL language (RDF Data Query Language). The performance analysis demonstrated the ability of the ontology-based search to improve both the precision and recall rates and enhance the interoperability between different sensor networks domains through the use of the universal SUMO ontology.","2159-1547;21591547","CD-ROM:978-1-4244-0824-5; POD:978-1-4244-0823-8","10.1109/CIMSA.2007.4362539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4362539","IEEE 1451;SUMO;ontology design;semantic representation;sensor networks data","Information retrieval;Ontologies;Routing;Semantic Web;Sensor fusion;Sensor phenomena and characterization;Sensor systems;Sensor systems and applications;Temperature sensors;Transducers","ontologies (artificial intelligence);query languages;query processing;sensor fusion","IEEE 1451;Protege 2000;RDF data query language;RDQL language;ontology design;semantic representation;sensor networks data search;suggested upper merged ontology;two layer ontology;universal ontology","","22","","10","","","27-29 June 2007","","IEEE","IEEE Conference Publications"
"Principles and Practice of Accelerated Radical Innovation","J. A. Bers; J. P. Dismukes","Vanderbilt University, Engineering Management Program, Nashville, TN, USA","PICMET '07 - 2007 Portland International Conference on Management of Engineering & Technology","20071015","2007","","","739","752","Two opposing trends characterize the dilemma for radical innovation in the 21st century: the continued explosion of the science and technology base, and the necessarily short-term, profit-driven outlook of the technology sector. Responding to this dilemma, a team of researchers, since 2004, has been developing a methodology for accelerating radical innovation through the industrial technology life cycle. This paper asks what factors drag radical innovation out to the point where momentum and initiative are lost. It then describes the accelerated radical innovation methodology, which addresses the three grand challenge areas responsible for delaying radical innovation: technological/scientific, market/societal, and business/organizational. The methodology is supported by three sets of tools. The first is a systemic approach linking the innovation to underlying market and technological drivers, reframes the problem at higher levels, and develops explicit linkages to interdependent external systems. The second, an interacting triad of information technology tools to support information retrieval, pattern recognition, and knowledge management, helps the innovator manage the overwhelming amount of relevant information. The third consists of a systematic process for developing the communities of practice, clusters, and supply chains necessary to support the radical innovation process. The second and third tool sets are described in companion papers.","2159-5100;21595100","CD-ROM:978-1-8908-4315-1","10.1109/PICMET.2007.4349392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4349392","","Acceleration;Business;Couplings;Delay;Explosions;Information retrieval;Information technology;Joining processes;Knowledge management;Technological innovation","information retrieval;innovation management;knowledge management;production engineering computing;socio-economic effects;supply chains","accelerated radical innovation;industrial technology life cycle;information retrieval;information technology tools;knowledge management;pattern recognition;science and technology;supply chains;technology sector","","2","","100","","","5-9 Aug. 2007","","IEEE","IEEE Conference Publications"
"Keyword Extraction Using Language Network","J. Liu; J. Wang","Beijing University of Posts and Telecommunications, jianyilui@sohu.com","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","129","134","In this paper, we introduced language network and described three kinds of networks. Keyword extraction is an important technology in many areas of document processing. In particularly, a keyword extraction algorithm based on language network and PageRank is proposed. Firstly a semantic network for a single document is build, then Pagerank is applied in the network to decide on the importance of a word, finally top-ranked words are selected as keywords of the document. The algorithm is tested on the corpus of CISTR, and the experiment result proves practical and effective.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368023","","Clustering algorithms;Computer networks;Content based retrieval;Data mining;Information retrieval;Information technology;National electric code;Telecommunication computing;Testing;Text categorization","document handling;feature extraction;natural languages","CISTR corpus;Pagerank;document processing;keyword extraction algorithm;language network","","5","","13","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Specifying and Verifying Cases Retrieval System Combining Event B and Spin","H. Gao; Z. Qin; L. Shao; X. Heng","Xi'an Jiaotong University, China; Ludong University, China","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","53","60","This paper presents a complete study for the specification and mechanical verification of cases retrieval systems (CRS) within the generic framework that supports the many-to-many connection of formal development environments and model checkers. We aim at combining on an example, refinement techniques, verification by theorem proving and model checking in an entire development, to guarantee software correctness properties. We first build a underlying abstract system using a roles-based collaboration model, then describe a practical approach for increasingly developing flexible and reliable formal specifications of CRS using event B, exemplified on contract net protocol (CNP) as interaction contract. A proper translator is introduced as the bridge between formal specifications and model checkers. This entire development is mechanically proved with respect to safety properties using B tool and, complementally, with respect to liveness properties using the SPIN tool.","","POD:0-7695-2997-6","10.1109/ICSC.2007.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338332","","Bridges;Collaboration;Computer science;Contracts;Formal specifications;Information retrieval;Mechanical factors;Power system modeling;Protocols;Safety","formal specification;formal verification;information retrieval;software tools;theorem proving","cases retrieval system verification;contract net protocol;formal development environments;formal specifications;interaction contract;model checkers;refinement techniques;role-based collaboration model;software correctness properties;theorem proving","","0","","17","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Optimizing multiple queries on scientific datasets with partial replicas","L. Weng; U. Catalyurek; T. Kurc; G. Agrawal; J. Saltz","Department of Computer Science and Engineering, Ohio State University, Columbus, 43210, USA","2007 8th IEEE/ACM International Conference on Grid Computing","20071022","2007","","","259","266","We propose strategies to efficiently execute a query workload, which consists of multiple related queries submitted against a scientific dataset, on a distributed-memory system in the presence of partial dataset replicas. Partial replication re-organizes and re-distributes one or more subsets of a dataset across the storage system to reduce I/O overheads and increase I/O parallelism. Our work targets a class of queries, called range queries, in which the query predicate specifies lower and upper bounds on the values of all or a subset of attributes of a dataset. Data elements whose attribute values fall into the specified bounds are retrieved from the dataset. If we think of the attributes of a dataset forming multi-dimensional space, where each attribute corresponds to one of the dimensions, a range query defines a bounding box in this multidimensional space. We evaluate our strategies in two scenarios involving range queries. The first scenario represents the case in which queries have overlapping regions of interest, such as those arising from an exploratory analysis of the dataset by multiple users. In the second scenario, queries represent adjacent rectilinear sections that capture an irregular subregion in the multi-dimensional space. This scenario corresponds to a case where the user wants to query and retrieve a spatial feature from the dataset. We propose cost models and an algorithm for optimizing such queries. Our results using queries for subsetting and analysis of medical image datasets show that effective use of partial replicas can result in reduction in query execution times.","2152-1085;21521085","CD-ROM:978-1-4244-1560-1; POD:978-1-4244-1559-5","10.1109/GRID.2007.4354141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4354141","","Application software;Biomedical engineering;Biomedical informatics;Computer science;Cost function;Data analysis;Data engineering;Hurricanes;Information retrieval;Parallel processing","distributed memory systems;natural sciences computing;query processing","distributed-memory system;multiple query optimization;partial dataset replicas;query workload;scientific datasets","","1","","15","","","19-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Sortie Production Optimization Team (SPOT)","J. P. Goncalves; K. Saade; K. Stevenson; T. Sukhwani; A. Loerch","","2007 IEEE Systems and Information Engineering Design Symposium","20071029","2007","","","1","6","This study evaluates the operational activities on an Air Force base and how they can be improved through integration of new technologies, organization of infrastructure/installations, and applied process improvement leading to a decrease in operational costs and manpower. This effort, called Sierra Bravo, was tasked to Defense Advanced Research Projects Agency (DARPA) by the United States Air Force, our work has been scoped to evaluating the sortie generation of an Air Mobility Command (AMC) base. Currently the AMC bases are slowly integrating the use of the Air Force Smart Operations for the 21<sup>st</sup> Century (AFSO-21) to improve some of their processes and organization of their installations. The study uses the AFSO-21 to evaluate ways of improving current processes, but also includes the use of Value Stream Analysis and Lean Methodology to find processes that are wasteful and develop alternatives for how the Air Force will reduce this waste. This study uses Arena software to model design alternatives and analyze/evaluate their effects on sortie generation processes, which include inspection, maintenance, loading of cargo/passengers, and refueling. The data retrieved from the simulation is then aligned with the design costs to achieve the best alternative.","","CD-ROM:978-1-4244-1286-0; POD:978-1-4244-1285-3","10.1109/SIEDS.2007.4374013","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4374013","","Argon;Costs;Information retrieval;Inspection;Military aircraft;Modems;Production;Software design;Software maintenance;Space missions","inspection;maintenance engineering;military systems;production management","Arena software;Defense Advanced Research Projects Agency;United States Air Force;air mobility command base;lean methodology;sortie production optimization team;value stream analysis","","0","","8","","","27-27 April 2007","","IEEE","IEEE Conference Publications"
"Marginal Fisher Analysis and Its Variants for Human Gait Recognition and Content- Based Image Retrieval","D. Xu; S. Yan; D. Tao; S. Lin; H. J. Zhang","Nanyang Technol. Univ., Singapore","IEEE Transactions on Image Processing","20071015","2007","16","11","2811","2821","Dimensionality reduction algorithms, which aim to select a small set of efficient and discriminant features, have attracted great attention for human gait recognition and content-based image retrieval (CBIR). In this paper, we present extensions of our recently proposed marginal Fisher analysis (MFA) to address these problems. For human gait recognition, we first present a direct application of MFA, then inspired by recent advances in matrix and tensor-based dimensionality reduction algorithms, we present matrix-based MFA for directly handling 2-D input in the form of gray-level averaged images. For CBIR, we deal with the relevance feedback problem by extending MFA to marginal biased analysis, in which within-class compactness is characterized only by the distances between each positive sample and its neighboring positive samples. In addition, we present a new technique to acquire a direct optimal solution for MFA without resorting to objective function modification as done in many previous algorithms. We conduct comprehensive experiments on the USF HumanID gait database and the Corel image retrieval database. Experimental results demonstrate that MFA and its extensions outperform related algorithms in both applications.","1057-7149;10577149","","10.1109/TIP.2007.906769","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4337772","Content-based image retrieval (CBIR);dimensionality reduction;gait recognition;marginal Fisher analysis (MFA);relevance feedback","Biometrics;Content based retrieval;Feedback;Humans;Image analysis;Image databases;Image recognition;Image retrieval;Information retrieval;Principal component analysis","content-based retrieval;gait analysis;image colour analysis;image recognition;image retrieval;matrix algebra;relevance feedback;visual databases","Corel image retrieval database;USF HumanID gait database;content-based image retrieval;dimensionality reduction algorithm;gray-level averaged image;human gait recognition;marginal Fisher analysis;marginal biased analysis;objective function modification;relevance feedback problem;tensor-based dimensionality reduction algorithm","Algorithms;Artificial Intelligence;Biometry;Databases, Factual;Gait;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Joints;Pattern Recognition, Automated;Photography;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique","143","3","34","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
"Developing User-Centred Pervasive Systems for Meeting Capture","S. Whittaker","Prof., University of Sheffield, United Kingdom","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","i","i","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/04365398.png"" border=""0"">","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365398","","Data mining;History;Information retrieval;Laboratories;Management information systems;Multimedia systems;Project management;Psychology;Speech processing","","","","0","","","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"SQuAVisiT: A Software Quality Assessment and Visualisation Toolset","S. Roubtsov; A. Telea; D. Holten","Technische Universiteit Eindhoven, The Netherlands","Seventh IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2007)","20071029","2007","","","155","156","Software quality assessment of large COBOL industrial legacy systems, both for maintenance or migration purposes, mounts a serious challenge. We present the software quality assessment and visualisation toolset (SQuAVisiT), which assists users in performing the above task. First, it allows a fully automatic extraction of metrics, call information, and code duplication from COBOL source code. This information, stored into a database, can be easily converted and exported to a set of visualization tools. We incorporated several such third-party tools for the visualization of call relations and system structure, and metrics visualization. These tools use novel visualization techniques such as bundled edges, matrix plots, and table lens. We illustrate the usage of our toolset with an industrial case study on a COBOL system comprising about 3000 modules and 1.7 million lines of code.","","POD:0-7695-2880-5","10.1109/SCAM.2007.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4362907","","Data mining;Displays;Information retrieval;Java;Lab-on-a-chip;Lenses;Quality assessment;Software quality;Visual databases;Visualization","COBOL;program visualisation;software maintenance;software metrics;software quality","COBOL industrial legacy systems;SQuAVisiT;bundled edges;matrix plots;software maintenance;software metrics visualization;software migration;software quality assessment toolset;software visualisation toolset;source code;table lens","","1","","5","","","Sept. 30 2007-Oct. 1 2007","","IEEE","IEEE Conference Publications"
"A New Method for Semi-Automatic Image Annotation","H. Xuelong; Z. Yuhui; Y. Li","School of Information Engineering, Yangzhou University, Yangzhou 225009, China; Jiangsu Province Key Lab. of Image Processing and Communication, Nanjing University of Post and Telecommunications, Nanjing 215006, China; Jiangsu Province Key Lab. of Computer Information Processing Technology, Suzhou University, Suzhou 215006, China","2007 8th International Conference on Electronic Measurement and Instruments","20071022","2007","","","2-866","2-869","Semantic-based image retrieval bridges the gap between visual features and human understanding of image in the field of image retrieval. Image annotation is one important technology of image retrieval based on the semantic. This paper proposed one method to realize semi-automatic image annotation with the tool Support Vector Machine (SVM). The image collection was divided into two parts, one for manual annotation and the other for testing. After being classified by SVM, the output was changed into a probability, and K-NN algorithm was applied to get the keywords for unlabeled images. The experiments show that the approach is feasible.","","CD-ROM:978-1-4244-1136-8; POD:978-1-4244-1135-1","10.1109/ICEMI.2007.4350818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4350818","Image classification;SVM;image retrieval","Humans;Image classification;Image processing;Image retrieval;Image segmentation;Information retrieval;Instruments;Support vector machine classification;Support vector machines;Testing","feature extraction;image retrieval;support vector machines","K-NN algorithm;SVM;image collection;semantic-based image retrieval;semi-automatic image annotation;support vector machine;unlabeled image keywords;visual features","","0","","5","","","Aug. 16 2007-July 18 2007","","IEEE","IEEE Conference Publications"
"A Graph Modeling of Semantic Similarity between Words","M. A. Alvarez; S. Lim","Utah State University, USA","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","355","362","The problem of measuring the semantic similarity between pairs of words has been considered a fundamental operation in data mining and information retrieval. Nevertheless, developing a computational method capable of generating satisfactory results close to what humans would perceive is still a difficult task somewhat owed to the subjective nature of similarity. In this paper, it is presented a novel algorithm for scoring the semantic similarity (SSA) between words. Given two input words w<sub>1</sub>and w<sub>2</sub>, SSA exploits their corresponding concepts, relationships, and descriptive glosses available in WordNet in order to build a rooted weighted graph G<sub>sim</sub>. The output score is calculated by exploring the concepts present in G<sub>sim</sub> and selecting the minimal distance between any two concepts c<sub>1</sub> and c<sub>2</sub> of w<sub>1</sub> and w<sub>2</sub> respectively. The definition of distance is a combination of: 1) the depth of the nearest common ancestor between c<sub>1</sub> and c<sub>2</sub> in G<sub>sim</sub>, 2) the intersection of the descriptive glosses of c<sub>1</sub> and c<sub>2</sub>, and 3) the shortest distance between c<sub>1</sub> and c<sub>2</sub> in G<sub>sim</sub>. A correlation of 0.913 has been achieved between the results by SSA and the human ratings reported by Miller and Charles (1991) for a dataset of 28 pairs of nouns. Furthermore, using the full dataset of 65 pairs presented by Rubenstein and Goodenough (1965), the correlation between SSA results and the known human ratings is 0.903, which is higher than all other reported algorithms for the same dataset. The high correlations of SSA with human ratings suggest that SSA would be convenient in solving several data mining and information retrieval problems.","","POD:0-7695-2997-6","10.1109/ICSC.2007.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338369","","Clustering algorithms;Computer science;Data mining;Humans;Information retrieval;Natural languages;Ontologies;Speech recognition;Taxonomy;Text recognition","data mining;graph theory;information retrieval;programming language semantics","WordNet;data mining;information retrieval;rooted weighted graph;semantic similarity","","18","","22","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"fMRI Brain Image Retrieval Based on ICA Components","B. Bai; P. Kantor; A. Shoukoufandeh; D. Silver","Rutgers University, USA","Eighth Mexican International Conference on Current Trends in Computer Science (ENC 2007)","20071022","2007","","","10","17","This manuscript proposes a retrieval system for fMRI brain images. Our goal is to find a similarity-metric to enable us to support queries for ""similar tasks"" for retrieval on a large collection of brain experiments. The system uses a novel similarity measure between the result of probabilistic independent component analysis (PICA) of brain images. Specifically, the times series of an fMRI dataset will be represented using a number of ICA components as high level task- related features. The similarity between two datasets is the value of the maximum weight bipartite matching defined on the component-wise similarities. The component-wise similarities are calculated based on the size of the overlap between the ""highly activated"" regions in the corresponding activation maps. We evaluated the performance of the proposed method on a moderate size fMRI image database with considerable variety. The ICA-based component selection in combination with bipartite matching similarity measure outperforms several other component selection methods and similarity measurements. The results also suggest that there is a direct correlation between the involvement of ICA components in cognitive processes and their time course spectrum. Along with other heuristics, this property can be for fMRI image retrieval and classification.","","POD:0-7695-2899-6","10.1109/ENC.2007.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351419","","Blood;Brain;Computer science;Content based retrieval;Image retrieval;Independent component analysis;Information retrieval;Shape;Support vector machine classification;Support vector machines","biomedical MRI;brain;image matching;image retrieval;independent component analysis;medical image processing;probability;time series","component-wise similarities;fMRI brain image retrieval;maximum weight bipartite matching;probabilistic independent component analysis;similarity measure;times series","","7","","23","","","24-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"CLDA: Feature Selection for Text Categorization Based on Constrained LDA","C. Zifeng; X. Baowen; Z. Weifeng; J. Dawei; X. Junling","Southeast University, China","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","702","712","Feature selection is a necessary process before pattern classification, machine learning and data mining. Now feature selection is facing challenge in high dimension space, such as text categorization in information retrieval. Linear discriminant analysis (LDA) is an excellent dimensionality reduction method which transforms the original data into low-dimensional feature space. However, it changes the original physical features and makes features uninterpretable, which motivates us to select but not transform features by LDA idea of preserving structure information of between-class and within-class for text categorization. In the paper, a new approach of feature selection based on constrained LDA (CLDA) is proposed, which models feature selection as a search problem in subspace and finds optimal solution subject to some restrictions. Further, CLDA optimization problem is transformed into a process of scoring and sorting of features. Experiments on 20 newsgroups and Reuters-21578 show that CLDA is consistently better than information gain and chi2-test with lower computational complexity.","","POD:0-7695-2997-6","10.1109/ICSC.2007.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338413","","Computational complexity;Data mining;Information retrieval;Linear discriminant analysis;Machine learning;Pattern classification;Search problems;Sorting;Subspace constraints;Text categorization","data reduction;feature extraction;text analysis","CLDA;constrained linear discriminant analysis;data dimensionality reduction method;data mining;feature selection;machine learning;pattern classification;text categorization","","2","","18","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Calculation Mechanism for Similarity Measure with Clustering an Unbalanced Hierarchical Terminology Structure","M. Wang; P. Hsu; K. C. Lin; J. Hung","NCU; TSINT","2007 International Conference on Parallel Processing Workshops (ICPPW 2007)","20071015","2007","","","30","30","The effective retrieval of reverent information often is quite useful to the user, for example, to query the respectful knowledge or information, especially for on-line e-leaner. The most common method is to make use of synonym and antonym from a dictionary with the most frequent terms. However, sometimes we are focusing on a pair of or a set of associated keywords offered by user, instead of same meaning. Generally, we would probably adopt the association rule to solve the problem. Nonetheless, the keywords or terms sets extracted from huge queries often contain sparse information composed of a wide range of keywords, with each term set only containing a few terms. These data render basket analysis with extremely low item support, lift the term to a higher level of concept hierarchy may get enough support, but missing the detailed information. Although a similarity measure represented by counting the depth of the least common ancestor normalized by the depth of the concept tree lifts the limitation of binary equality, it produces counter intuitive results when the concept hierarchy is unbalanced since two terms in deeper subtrees are very likely to have a higher similarity than two terms in shallower subtrees. The research proposes to calculate the distance between two terms by counting the edge traversal needed yet from user's viewpoint to link them in order to solve the issues. The method is straight forward yet achieves better outcome with information query when concept hierarchy is unbalanced.","0190-3918;01903918","CD-ROM:978-0-7695-2934-9; POD:0-7695-2934-8","10.1109/ICPPW.2007.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4346388","Clustering;Data Mining;Hierarchy;Similarity Measure","Association rules;Clustering algorithms;Data analysis;Data mining;Dictionaries;Information analysis;Information filtering;Information filters;Information retrieval;Terminology","data mining;query processing","data render basket analysis;information query;information retrieval;keywords extraction;similarity measure;sparse information;subtrees;terms sets extraction;unbalanced hierarchical terminology structure","","0","","15","","","10-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"Multi-Agent System as a Platform for Management of Medical Documentation","L. Lhotska","Member, IEEE, Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague, Technicka 2, 166 27 Prague 6, Czech Republic. phone: +420-224353933; fax: +420-224311081; e-mail: lhotska@fel.cvut.cz","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","3661","3664","The paper is focused on description of an ongoing project of a pilot study and implementation of a multi-agent system for management of medical documentation in a hospital. First we analyzed the problem and divided it into four groups of tasks: storing and retrieving stored data, user interaction, data archiving, and system security. All these tasks are performed by corresponding agents, namely user interface agent, database agent, archive agent, and security agent. Communication between the agents is a crucial point of the system operation. The system has been designed as an open system and we assume that it will be extended by additional agents with new functions, e.g. decision support, biomedical signal evaluation, laboratory test evaluation.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353125","","Communication system security;Data security;Databases;Documentation;Hospitals;Information retrieval;Multiagent systems;Project management;Signal design;User interfaces","medical administrative data processing;medical computing;multi-agent systems;open systems;security of data;user interfaces","archive agent;biomedical signal evaluation;data archiving;data retrieval;data storage;database agent;decision support;hospital documentation;laboratory test evaluation;medical documentation management;multi-agent system;open system;security agent;system security;user interface agent","Computer Security;Database Management Systems;Documentation;Information Dissemination;Information Storage and Retrieval;Medical Records Systems, Computerized;User-Computer Interface","0","","9","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"Harnessing Language in Mobile Environments","B. Katz; G. Borchardt; S. Felshin; F. Mora","MIT, USA","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","421","428","We describe StartMobile, a prototype system that enables users of cellular telephones and other mobile devices to access information, create information and execute commands on the basis of written requests expressed in natural language. Interacting with mobile devices through the use of language offers several potential benefits that include: scalability in handling huge numbers of concepts and operations, substantial device-independence, and opportunities for remote interaction. StartMobile uses the START information access system to perform initial interpretation of requests and to generate responses to general information requests. Requests that require further interpretation and/or fulfillment in the distributed mobile environment are encoded in a new, language-based intermediate representation called Moebius, then conveyed to appropriate devices and systems, where special-purpose software serves to complete the interpretation and fulfillment of those requests.","","POD:0-7695-2997-6","10.1109/ICSC.2007.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338377","","Artificial intelligence;Computer science;Humans;Image retrieval;Information retrieval;Mobile computing;Natural languages;Telephony;User interfaces;Web sites","information retrieval;mobile computing;natural language processing","Moebius;START information access system;StartMobile;cellular telephones;command execution;distributed mobile environment;information creation;information request;language-based intermediate representation;mobile devices;natural language;remote interaction;written request","","2","","10","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Formal Ontology Model and its Application to Semantic Retrieval","H. Wang; Z. Liu; C. Yu","Sch. of Econ. & Manage., Tongji Univ., Shanghai","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","5621","5624","Current information retrieval techniques either rely on an encoding process to describe a given item or perform a full-text analysis to search for user-specified words. Because an encoded description might reflect only part of the content, they can't guarantee content matching. Ontology is an explicit specification of conceptualizations, which can explicitly and formally express the semantic of the concepts and their relationship. So ontology is better for information retrieval in semantic level. This paper introduces the basic concept of ontology, and presents a formal ontological model using description logic. Then, an algorithm for checking subsumption relation between terms is given. At last, request mode and response mode are modeled. Based on the two modes, a new semantic-enabling information retrieval mechanism is discussed.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.1377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4341152","","Encoding;Engineering management;Financial management;Information analysis;Information management;Information retrieval;Internet;Logic;Ontologies;Performance analysis","encoding;information retrieval;ontologies (artificial intelligence);text analysis","checking subsumption relation;description logic;encoding process;formal ontology model;full-text analysis;information retrieval techniques;request-response mode;user-specified words","","0","","8","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"3D Model Retrieval Based on U System Rotation Invariant Moments","Li Zongmin; M. Xiuping; Li Hua","School Of Computer Science And Communication Engineering, China University Of Petroleum, Shandong 25 7062, P.R. China 257062; Key Laboratory Intelligent Information Processing Institute of Computing Technology Chinese Academy of Science, Beijing 100080, P.R.China","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","183","188","In this paper, a novel 3D orthogonal polynomial moment based on 3D U system polynomials is proposed, and is used for 3D model retrieval. U system is a kind of complete and orthogonal polynomials system. In this paper, we combine U system with spherical harmonic functions and define a shape descriptor-Usystem rotation invariant moments. The performance of the proposed method is evaluated by constructing precision/recall diagrams. Results clearly demonstrate effectiveness of this new method in the 3D-model retrieval process and superiority over the traditional Zernike moment invariants.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365436","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365436","","Content based retrieval;Feature extraction;Image retrieval;Information processing;Information retrieval;Laboratories;Noise robustness;Polynomials;Shape;Solid modeling","image retrieval;polynomials;solid modelling","3D U system polynomials;3D model retrieval;3D orthogonal polynomial moment;U system rotation invariant moments;shape descriptor;spherical harmonic functions","","1","","7","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"The ""Spree"" Expert Finding System","F. Metze; C. Bauckhage; T. Alpcan","Deutsche Telekom Laboratories, Germany","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","551","558","This paper proposes a system to facilitate exchange of information by automatically finding experts, competent in answering a given question. Our objective is to provide an online tool, which enables individuals within a potentially large organization to search for experts in a certain area, which may not be represented in company organization or reporting lines. The advantage of the proposed system over standard forums or group-ware systems is that full-formatted questions can be compared to stored qualification profiles, which were automatically derived from documents, without Human search effort, and possibly refined manually. This allows us to find competent colleagues (or helpful literature such as How-Tos) for a given problem in a single step, and without intermediate iterations. The system is symmetric in that it does not distinguish between ""questioners"" (asking questions) and ""experts"" (answering them), therefore forming a ""community"" of users, which are distributed over an ontology covering the total knowledge. This ontology can either be given (i.e. in the form of an organizational chart), or it can be derived from the experts' knowledge.","","POD:0-7695-2997-6","10.1109/ICSC.2007.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338393","","Feedback;Humans;Information retrieval;Knowledge management;Laboratories;NIST;Ontologies;Qualifications;Social network services;Web sites","expert systems;information retrieval;online front-ends;ontologies (artificial intelligence)","Web browser;expert knowledge;how-tos;information exchange;online tool;ontology;question answering;spree expert finding system","","5","","15","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Semantic Interpretation of Compound Nominalization Using Automatic Extracted Paraphrase Patterns","J. Zhao; Y. Gao; H. Liu; R. Lu","Department of Computer Science, Shanghai Jiao Tong University, 800 Dongchuan Road Shanghai, China, zjl@sjtu.edu.cn","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","183","189","The interpretation of nominal compounds is one of the most difficult problems in natural language processing. This paper proposes a new algorithm for the automatic interpretation of compound nominalizations in Chinese. A maximum entropy model is applied to label four coarse-grained roles involved in compound nominalizations. The classification features used are automatic extracted functional lexicalized paraphrase patterns. The experimental result shows that the method is superior than previous works that use manually coded paraphrase patterns.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368031","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368031","","Computer science;Entropy;Filtering;Information retrieval;Labeling;Magnetic heads;Morphology;Natural language processing;Natural languages;Satellite navigation systems","natural language processing","automatic extracted paraphrase patterns;coarse-grained roles;maximum entropy model;natural language processing;semantic interpretation","","0","","25","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Crime Incident Association with Consideration of Narrative Information","X. Wang; D. E. Brown; J. H. Conklin","Department of Systems and Information Engineering, University of Virginia, Charlottesville, VA 22904 USA, e-mail: xw4u@virginia.edu","2007 IEEE Systems and Information Engineering Design Symposium","20071029","2007","","","1","4","Law enforcement agencies need to discover underlying patterns of crimes in a short time. One of the key steps is associating related criminal incidents with each other. This paper describes a new methodology to associate crime incidents automatically, as well as, accurately by using narrative information. Specifically this paper shows a new method for measuring the similarity between crime incident narratives. Evaluations show that our method could measure similarity between narrative information quickly and accurately. In addition, a toolkit based on this methodology was developed to perform crime incident association.","","CD-ROM:978-1-4244-1286-0; POD:978-1-4244-1285-3","10.1109/SIEDS.2007.4373987","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4373987","","Biomedical measurements;Data engineering;Data mining;Electronic mail;Frequency;Information analysis;Information retrieval;Systems engineering and theory;Text categorization;Text mining","data mining;law administration;police data processing","crime incident association;law enforcement agency;narrative information;pattern discovery","","1","","6","","","27-27 April 2007","","IEEE","IEEE Conference Publications"
"Rotation-Invariant and Scale-Invariant Steerable Pyramid Decomposition for Texture Image Retrieval","J. A. Montoya-Zegarra; N. J. Leite; R. d. S. Torres","San Pablo Catholic University, Peru; State University of Campinas, Brazil","XX Brazilian Symposium on Computer Graphics and Image Processing (SIBGRAPI 2007)","20071029","2007","","","121","128","This paper proposes a new rotation-invariant and scale-invariant representation for texture image retrieval based on steerable pyramid decomposition. By calculating the mean and standard deviation of decomposed image subbands, the texture feature vectors are extracted. To obtain rotation or scale invariance, the feature elements are aligned by considering either the dominant orientation or dominant scale of the input textures. Experiments were conducted on the Brodatz database aiming to compare our approach to the conventional steerable pyramid decomposition, and a proposal for texture characterization based on Gabor wavelets with regard to their retrieval effectiveness. Results demonstrate the superiority of the proposed method in rotated and scaled image datasets.","1530-1834;15301834","POD:0-7695-2996-8","10.1109/SIBGRAPI.2007.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368176","","Computer graphics;Feature extraction;Filters;Image databases;Image decomposition;Image processing;Image retrieval;Information retrieval;Proposals;Spatial databases","Gabor filters;feature extraction;image representation;image retrieval;image texture;vectors","Brodatz database;Gabor wavelets;mean deviation;rotation-invariant representation;scale-invariant representation;standard deviation;steerable pyramid decomposition;texture characterization;texture feature vector extraction;texture image retrieval","","10","","15","","","7-10 Oct. 2007","","IEEE","IEEE Conference Publications"
"Content Based Image Retrieval based on Wavelet Transform coefficients distribution","M. Lamard; G. Cazuguel; G. Quellec; L. Bekri; C. Roux; B. Cochener","Univ Bretagne Occidentale, U650, Brest, F-29200 France; Inserm, U650, Brest, F-29200 France Mathieu.Lamard@univ-brest.fr","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","4532","4535","In this paper we propose a content based image retrieval method for diagnosis aid in medical fields. We characterize images without extracting significant features by using distribution of coefficients obtained by building signatures from the distribution of wavelet transform. The research is carried out by computing signature distances between the query and database images. Several signatures are proposed; they use a model of wavelet coefficient distribution. To enhance results, a weighted distance between signatures is used and an adapted wavelet base is proposed. Retrieval efficiency is given for different databases including a diabetic retinopathy, a mammography and a face database. Results are promising: the retrieval efficiency is higher than 95% for some cases using an optimization process.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353347","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353347","CBIR;diabetic retinopathy;signature;wavelets","Biomedical imaging;Content based retrieval;Feature extraction;Image databases;Image retrieval;Information retrieval;Medical diagnostic imaging;Spatial databases;Wavelet coefficients;Wavelet transforms","biomedical imaging;medical computing;query processing;visual databases;wavelet transforms","content based image retrieval;database images;diabetic retinopathy;diagnosis aid;face database;mammography;query images;retrieval efficiency;wavelet transform coefficient distribution;weighted signature distance","Databases, Factual;Diabetic Retinopathy;Humans;Image Processing, Computer-Assisted;Mammography","15","","15","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"Human Attention Model for Action Movie Analysis","A. Liu; J. Li; Y. Zhang; S. Tang; Y. Song; Z. Yang","School of Electronic Engineering, Tianjin University, Tianjin, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China. liuanan@ict.ac.cn","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","204","208","Nowadays, automatic detection of highlights for movies is indispensable for video management and browsing. In this paper, we specifically present the formulation of human attention model and its application for action movie analysis. Depending on the relationship between stimuli in both visual and audio modalities and the change of human attention, we construct the visual and audio attention sub-models respectively. By integrating both sub-models, human attention model is formulated and attention flow plot is derived to simulate the change of human attention in the time domain. Based on video structuralization and human attention analysis, we realize action concept annotation for interest-oriented navigation of viewers. The large-scale experiments demonstrate the effectiveness and generality of human attention model for action movie analysis.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365440","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365440","action;attention model;audio;visual","Computational modeling;Computers;Electric shock;Event detection;Humans;Information retrieval;Large-scale systems;Layout;Motion pictures;Navigation","audio signal processing;humanities;video signal processing","action concept annotation;action movie analysis;audio attention submodels;audio modalities;highlights detection;human attention model;interest-oriented navigation;video browsing;video management;video structuralization;visual attention submodels;visual modalities","","4","","10","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"A Study on Scalability of Middleware Systems","C. Miao; M. Shi","Department of Computer Sci. and Eng., Tsinghua University, 100084, Beijing, China. miaocy@csnet4.cs.tsinghua.edu.cn","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","7","12","In the recent years, more and more real applications are embracing the middleware as a vehicle for conveying their data; the issue of efficient and effective interoperation between databases with different storage formats and local geographical locations has been becoming extremely important research topic. A large amount of systems have been developed. In fact, real-world applications of middleware system often require a system to deal with huge amount of data. However, study of scalability for those systems is generally lacking. The main reason is that exploring scalability could be very time consuming and expensive task. In this paper, we present a new approach specifically designed for estimating performance parameters of different middleware systems under different size of data. The comprehensive experimental result based on scientific data and queries demonstrates various kinds of advantages of framework.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365403","Agent Technology;Cooperative Data Management;Empirical study;Scalability","Application software;Databases;Geographic Information Systems;Information retrieval;Middleware;Parameter estimation;Query processing;Scalability;Technology management;Vehicles","middleware;parameter estimation","local geographical location;middleware system scalability;parameter estimation;storage formats","","0","","20","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"Sensibility retrieval method that uses amount of physical feature of traditional craft object","A. Miyakawa; K. Sugita; Y. Shibata","Nanao-City Information Policy Division, Japan","2007 International Conference on Parallel Processing Workshops (ICPPW 2007)","20071015","2007","","","13","13","In this paper, we propose a Kansei* retrieval method based on the design pattern of traditional Japanese crafting object to provide a user with the desired presentation space in digital traditional Japanese crafting system. The visual quantitative feature values are extracted by using visual pattern image coding (VPIC). These values include the total number, the frequency, the dispersion rate and the deviation rate for different edges. The quantitative feature values for traditional Japanese crafting objects are registered in the multimedia database and the relation between Kansei words and the visual feature of traditional Japanese crafting objects are analyzed by using the questionnaire. Then, the visual features are compared with the quantitative feature values. Through the above process, we can find the relation between the design pattern components and edge types using VPIC. By finding this relation, the Kansei retrieval method can be realized.","0190-3918;01903918","CD-ROM:978-0-7695-2934-9; POD:0-7695-2934-8","10.1109/ICPPW.2007.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4346371","","Character generation;Feature extraction;Frequency;Image coding;Information retrieval;Multimedia databases;Process design;Product design;Space technology;Virtual reality","feature extraction;humanities;image coding;image retrieval","Kansei retrieval method;digital traditional Japanese crafting system;sensibility retrieval method;visual pattern image coding;visual quantitative feature value","","0","","9","","","10-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"RFID-Based Intelligent Bookcs Shelving System","T. M. Win@Shamsudin; M. J. E. Salami; W. Martono","Department of Mechatronics Engineering, Faculty of Engineering, International Islamic University Malaysia, Jalan Gombak, 53 100 Kuala Lumpur, Malaysia. Tel: +6019 3419 304, Tel: +603 6196 4494, E-mail: theinmoewin@yahoo.com, momoh@iiu.edu.my","2007 1st Annual RFID Eurasia","20071029","2007","","","1","5","Searching and sorting misplaced books is a difficult task often carried out by the library personnel. Quite often, librarians are busy with searching misplaced books which are left in wrong locations by library users. It is quite difficult and almost impractical to place back all books to their assigned locations daily. To overcome this, radio frequency identification (RFID) based Intelligent shelving system has been proposed to provide an efficient mechanism of books management monitoring through wireless communication between the RFID reader and the books. It is quite essential for the proposed system to have a smooth motion for the RFID reader during the shelving operation; otherwise acquired data will have no value due to inconsistency in reading the tags. Consequently, in this paper, the performance of RFID reader motion and tags data management such as retrieving information, matching with database, sorting out the order and displaying the status of books locations are discussed. A prototype consisting of monitoring PC with embedded controller, two dc motors with drivers, RFID reader and aluminum frame stick on rack have been developed. The performance of the proposed system has been investigated and found to be satisfactory. And it has a lot of potential applications, especially in its ability to alleviate the intensive labors and efforts in shelving cbooks.","","POD:978-975-01566-0-1","10.1109/RFIDEURASIA.2007.4368105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368105","Lab View User Interface;Motion Control;RFID;Tags data management","Books;Information retrieval;Intelligent systems;Libraries;Monitoring;Personnel;Radio spectrum management;Radiofrequency identification;Sorting;Wireless communication","library automation;monitoring;radiocommunication;radiofrequency identification","RFID reader motion;books management monitoring;intelligent library books shelving system;library personnel;radio frequency identification;tags data management;wireless communication","","2","","10","","","5-6 Sept. 2007","","IEEE","IEEE Conference Publications"
"The Study of Taxonomy and Evolutional Trends of Relevant Literatures on Patent Analysis","K. K. Lai; M. L. Lin; S. B. Chang; C. F. Hsu","National Yunlin University of Science & Technology, Douliou, Yunlin, Taiwan","PICMET '07 - 2007 Portland International Conference on Management of Engineering & Technology","20071015","2007","","","22","30","Analysis of patent data is important tool for industrial research. Patent analysis has been used in many research fields and applied for rich topics in technology management. This study was explored the classification and research development of patent analysis literatures for 24 years (1980-2003) and applied by evolutional perspectives, and bibliometrics techniques. The research scope is focused on business and management level. There were some significant literatures retrieved from online electronic database and a citation database was built by their references. After that, the study was analyzed by multivariate methods to classify research taxonomy and literatures relative positions. The study was expected to understanding of current situation of patent analysis research. Additionally, the main purposes of this study were to synthesize core knowledge and research trends in research fields, to point out the major contributors and influential journals, to understand their positions, and to explore evolution life cycle. The research results are classified into five research fields, namely the sources of technology knowledge, patent applications and patent value, patent research and technology position, the indicators of technological and innovative activities, and interdisciplinary applications.","2159-5100;21595100","CD-ROM:978-1-8908-4315-1","10.1109/PICMET.2007.4349314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4349314","","Asset management;Bibliometrics;Databases;Information analysis;Information retrieval;Intersymbol interference;Statistical analysis;Sun;Taxonomy;Technology management","history;patents;technological forecasting","AD 1980 to 2003;bibliometrics;evolutional trends;multivariate methods;patent analysis;patent applications;patent research;patent value;research trends;synthesize core knowledge;taxonomy study;technology management","","0","","60","","","5-9 Aug. 2007","","IEEE","IEEE Conference Publications"
"Ontology-Based Query System Design and Implementation","G. y. LI; S. m. YU; S. s. DAI","Dalian Maritime University","2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)","20071022","2007","","","1010","1015","In order to overcome the shortcomings arisen from the expression-only matching, the ontology-based semantic interpretation of concepts should be introduced into the retrieval process. Based on the study of ontology-based information retrieval, a query system oriented to EBM (Evidence-Based Medicine) data is designed and implemented. Meanwhile, OWL, RDF/RDFS and Jena are respectively employed as description language, semantic annotation language, and reasoning tool. Firstly, a medical ontology is established in this system. Secondly, the metadata is described and the semantic annotation for primitive data is achieved. Based on the above, the more ample semantic information is produced, the primitive data is more easily understood by computers and users. Finally, the goal prototype system and the semantic query using the semantic annotation are successfully implemented and verified. The experimental result reveals that not only the semantic pertinence of query results is improved, but also the query efficiency is promoted.","","POD:0-7695-2943-7","10.1109/NPC.2007.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351619","","Databases;Information retrieval;Ontologies;Parallel processing;Resource description framework;Resource management;Search engines;User interfaces;Vocabulary;World Wide Web","case-based reasoning;medical information systems;meta data;ontologies (artificial intelligence);query processing","description language;evidence-based medicine data;expression-only matching;medical ontology;metadata;ontology-based information retrieval;ontology-based query system design;ontology-based semantic concepts terpretation;query system;reasoning tool;semantic annotation language","","3","","6","","","18-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Incorporating Forgetting in a Category Learning Model","Y. Sakamoto; T. Matsuka","Howe School of Technology Management, Stevens Institute of Technology, Hoboken, NJ 07030, USA. email: Yasuaki.Sakamoto@stevens.edu","2007 International Joint Conference on Neural Networks","20071029","2007","","","2965","2970","We present a computational model of human category learning that learns the essential structures of the categories by forgetting information that is not useful for the given task. The model shifts attention to salient information and learns associations between items and categories. Attention and association strengths are adjusted according to the degree of prediction errors the model makes. The attention and association weights are interpreted as memory strengths in the model and decay over time, allowing the model to focus on the salient structures. Using memory decay mechanisms, our model simultaneously explained human recognition and classification performances that previous models could not.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371432","","Birds;Computational modeling;Computer networks;Delay;Encoding;Humans;Information retrieval;Neural networks;Particle measurements;Predictive models","psychology","association weight;attention weight;human category learning model;memory decay mechanism;salient information","","0","","46","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"LDA-Based Retrieval Framework for Semantic News Video Retrieval","J. Cao; J. Li; Y. Zhang; S. Tang","Chinese Academy of Sciences, China; Graduate University of the Chinese Academy of Sciences, China","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","155","160","Topic-based language model has attracted much attention as the propounding of semantic retrieval in recent years. Especially for the ASR text with errors, the topic representation is more reasonable than the exact term representation. Among these models, Latent Dirichlet Allocation(LDA) has been noted for its ability to discover the latent topic structure, and is broadly applied in many text-related tasks. But up to now its application in information retrieval(IR) is still limited to be a supplement to the standard document models, and furthermore, it has been pointed out that directly employing the basic LDA model will hurt retrieval performance. In this paper, we propose a lexicon-guided two-level LDA retrieval framework. It uses the HowNet to guide the first-level LDA model's parameter estimation, and further construct the second-level LDA models based on the first-level's inference results. We use TRECID 2005 ASR collection to evaluate it, and compare it with the vector space model(VSM) and latent semantic Indexing(LSI). Our experiments show the proposed method is very competitive.","","POD:0-7695-2997-6","10.1109/ICSC.2007.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338344","ASR text;LDA;Semantic video retrieval;Topic-based model","Automatic speech recognition;Computers;Information processing;Information retrieval;Laboratories;Large scale integration;Linear discriminant analysis;Natural languages;Space technology;Videoconference","video retrieval","HowNet;LDA-based retrieval framework;Latent Dirichlet Allocation;information retrieval;semantic news video retrieval;text-related tasks;topic-based language model;vector space model","","7","","13","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Eviction of Misbehaving and Faulty Nodes in Vehicular Networks","M. Raya; P. Papadimitratos; I. Aad; D. Jungels; J. p. Hubaux","EPFL, Lausanne","IEEE Journal on Selected Areas in Communications","20071015","2007","25","8","1557","1568","Vehicular networks (VNs) are emerging, among civilian applications, as a convincing instantiation of the mobile networking technology. However, security is a critical factor and a significant challenge to be met. Misbehaving or faulty network nodes have to be detected and prevented from disrupting network operation, a problem particularly hard to address in the life-critical VN environment. Existing networks rely mainly on node certificate revocation for attacker eviction, but the lack of an omnipresent infrastructure in VNs may unacceptably delay the retrieval of the most recent and relevant revocation information; this will especially be the case in the early deployment stages of such a highly volatile and large-scale system. In this paper, we address this specific problem. We propose protocols, as components of a framework, for the identification and local containment of misbehaving or faulty nodes, and then for their eviction from the system. We tailor our design to the VN characteristics and analyze our system. Our results show that the distributed approach to contain nodes and contribute to their eviction is efficiently feasible and achieves a sufficient level of robustness.","0733-8716;07338716","","10.1109/JSAC.2007.071006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4346443","","Fault detection;Fault diagnosis;Information retrieval;Large-scale systems;Manufacturing;Protocols;Research initiatives;Robustness;Vehicle driving;Vehicle safety","mobile radio;protocols;telecommunication network reliability","faulty network node detection;mobile networking technology;vehicular network","","139","","38","","","Oct. 2007","","IEEE","IEEE Journals & Magazines"
"Automatic Competitive Intelligence Collection Based on Semantic Web Mining","Y. Zhang; J. Wu; C. Wang","Sch. of Inf. Manage., Wuhan Univ., Wuhan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","3701","3704","Accuracy and relativity of information accessed by search engine are not so satisfied. In order to enhance efficiency of information retrieval, semantic Web mining technology is suggested to discovery knowledge hidden in Web information resources and a semantic Web mining framework is constructed. Then its architecture and pivotal technologies are also discussed.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.915","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340690","","Competitive intelligence;Data mining;Information analysis;Information management;Information retrieval;Ontologies;Search engines;Semantic Web;Web mining;Web pages","competitive intelligence;data mining;information retrieval;semantic Web","automatic competitive intelligence collection;hidden knowledge discovery;information resources;information retrieval;search engine;semantic Web mining","","0","","10","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Content-based Image Retrieval Using Fuzzy Hamming Distance","H. Xuelong; Y. Li; Z. Gensheng","School of Information Engineering, Yangzhou University, Yangzhou 225009, China; Jiangsu Province Key Lab. for Image Processing and Communication, Nanjing University of Post and Telecommunications, Nanjing 215006, China; Jiangsu Province Key Lab. for Computer Information Processing Technology, Suzhou University, Suzhou 215006, China","2007 8th International Conference on Electronic Measurement and Instruments","20071022","2007","","","2-826","2-830","This paper addresses an effective issue of content-based image retrieval (CBIR) by presenting fuzzy Hamming distance (FHD). Firstly, the theory of FHD is introduced, which includes degree of difference and cardinality of the fuzzy set, and then follows defuzzification of FHD which is used as a fuzzy similarity measure. In the experiment, the image retrieval results show this method can be employed to capture implicitly some semantic contents of the image in addition to other features such as color, texture and shape. Finally, an implemented prototype system demonstrates a promising retrieval performance for a test database, as compared with FUZZYCLUB system.","","CD-ROM:978-1-4244-1136-8; POD:978-1-4244-1135-1","10.1109/ICEMI.2007.4350808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4350808","Content-based Image Retrieval (CBIR);Fuzzy Hamming Distance (FHD);HSV color space","Content based retrieval;Fuzzy set theory;Hamming distance;Image databases;Image retrieval;Information retrieval;Prototypes;Shape;Spatial databases;System testing","content-based retrieval;fuzzy set theory;image retrieval","FUZZYCLUB system;HSV color space;content-based image retrieval;defuzzification;fuzzy Hamming distance;fuzzy set;fuzzy similarity measure;semantic contents","","2","","6","","","Aug. 16 2007-July 18 2007","","IEEE","IEEE Conference Publications"
"Knowledge Management in Virtual Communities of Practice: Experiments with a Helper Tool","J. C. d. Lima; C. L. d. Carvalho","Universidade Federal de Goias, Brazil","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","645","650","The Web was projected to support resource sharing at global level. Nowadays, this resource sharing is very limited, mainly respect to imperfect information retrieval and hidden Web. The semantic Web comes up as a possible solution to such limitations. The virtual communities of practice are groups of people who get in with each other virtually and share their knowledge. The use of semantic Web technologies can be very useful in construction of tools to support these communities. This text presents a tool constructed to help knowledge management in virtual communities of practice. It was developed based on the semantic Web principles.","","POD:0-7695-2997-6","10.1109/ICSC.2007.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338405","","Filtering;Information processing;Information retrieval;Knowledge management;Ontologies;Organizing;Resource description framework;Resource management;Semantic Web;Software agents","knowledge based systems;semantic Web","hidden Web;information retrieval;knowledge management;resource sharing;semantic Web;virtual communities","","0","","15","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Linear DBSCAN Algorithm Based on LSH","Y. P. Wu; J. J. Guo; X. J. Zhang","Department of Computer Science and Engineering, Yunnan University, Kunming 650091, China; Department of computer Science, City University of Hong Kong, Kowloon, Hong Kong. E-MAIL: kmwyp@mail.ynu.edu.cn, sasa01232@hotmail.com","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","5","","2608","2614","DBSCAN algorithm is used widely because it can effectively handle noise points and deal with data of any type in clustering. However, it has two inherent limitations: high time complexity O(NlogN) and poor ability in dealing large-scale data. In this paper, a linear DBSCAN based on LSH is proposed. In our algorithm the process of Nearest Neighbor Search is optimized by hashing. Compared with the original DBSCAN algorithm, the time complexity of this improved DBSCAN descends to O(N). Experimentally, this improved DBSCAN makes a significant decrease in the running time while maintaining the Cluster quality of the results. Moreover, the speedup (the running time of original DBSCAN algorithm divided by the running time of improved algorithm) increases with the size and dimension of dataset, and the parameter Eps of our algorithm does not have a strong influence on the clustering result. These improved properties enable DBSCAN to be used in a large scope.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370588","Clustering;DBSCAN;LSH;Large-scale data;Unsupervised learning","Clustering algorithms;Computer science;Cybernetics;Image segmentation;Information retrieval;Large-scale systems;Machine learning;Machine learning algorithms;Nearest neighbor searches;Partitioning algorithms","","","","4","","18","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Grid metadata management: Requirements and architecture","O. Corcho; P. Alper; P. Missier; S. Bechhofer; C. Goble","School of Computer Science, University of Manchester, Oxford Road, M13 9PL, United Kingdom","2007 8th IEEE/ACM International Conference on Grid Computing","20071022","2007","","","97","104","Metadata annotations of grid resources can potentially be used for a number of purposes, including accurate resource allocation to jobs, discovery of services, and precise retrieval of information resources. In order to realize this potential on a large scale, various aspects of metadata must be managed. These include uniform and secure access to distributed and independently maintained metadata repositories, as well as management of metadata lifecycle. In this paper we analyze these issues and present a service-oriented architecture for metadata management, called S-OGSA, that addresses them in a systematic way.","2152-1085;21521085","CD-ROM:978-1-4244-1560-1; POD:978-1-4244-1559-5","10.1109/GRID.2007.4354121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4354121","","Bioinformatics;Computer architecture;Computer science;Information resources;Information retrieval;Large-scale systems;Middleware;Ontologies;Project management;Resource management","grid computing;meta data;resource allocation;software architecture","S-OGSA;grid metadata management;information resource;service-oriented architecture;software architecture","","2","3","23","","","19-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Content-based Search using Term Aggregation and Classification over Hybrid Peer-to-Peer Systems","A. Zhou; R. Zhang; Q. H. Vu; W. Qian","Fudan University, China","2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)","20071022","2007","","","28","35","In this paper, we propose a method to support content-based search, one of the challenges in Peer-to-Peer file sharing system. The proposed method is based on a hybrid structure, which is a combination of a Chord ring and a balanced tree. The tree is used to aggregate and classify terms while the Chord ring is used to index terms of nodes in the tree. At every node in the tree, the system classifies terms as either important or unimportant. Important terms of a node, which can distinguish the node from its neighbor nodes, are indexed in the Chord ring while unimportant terms that are either popular or rare terms are aggregated to higher level nodes. Based on the classification, the system can process queries on the fly without the need of global knowledge. Therefore, our system can avoid the problem of bottleneck at nodes keeping global knowledge and the expensive cost of synchronization global knowledge among these nodes. We have done extensive experiments to validate the effectiveness and efficiency of our proposal.","","POD:0-7695-2943-7","10.1109/NPC.2007.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351456","","Aggregates;Classification tree analysis;Computer science;Costs;Information retrieval;Parallel processing;Peer to peer computing;Proposals;Software engineering;Tree data structures","classification;content-based retrieval;peer-to-peer computing;tree data structures","Chord ring structure;balanced tree structure;content-based search;peer-to-peer file sharing system;term aggregation;term classification","","0","","21","","","18-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Text Representations for Text Categorization: A Case Study in Biomedical Domain","M. Lan; C. L. Tan; J. Su; H. B. Low","School of Computing, National University of Singapore, Singapore 117543. phone: 65-65162784; email: lanman@comp.nus.edu.sg, lanman.sg@gmail.com","2007 International Joint Conference on Neural Networks","20071029","2007","","","2557","2562","In vector space model (VSM), textual documents are represented as vectors in the term space. Therefore, there are two issues in this representation, i.e. (1) what should a term be and (2) how to weight a term. This paper examined ways to represent text from the above two aspects to improve the performance of text categorization. Different representations have been evaluated using SVM on three biomedical corpora. The controlled experiments showed that the straightforward usage of named entities as terms in VSM does not show performance improvements over the bag-of-words representation. On the other hand, the term weighting method slightly improved the performance. However, to further improve the performance of text categorization, more advanced techniques and more effective usages of natural language processing for text representations appear needed.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371361","","Data mining;Indexing;Information management;Information retrieval;Local area networks;Natural language processing;Neural networks;Proteins;Support vector machines;Text categorization","classification;medical computing;medical information systems;natural language processing;support vector machines;text analysis","SVM;bag-of-words text representation;biomedical domain;natural language processing;text categorization;textual document representation;vector space model","","1","","19","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"A Collaborative Tagging System for Personalized Recommendation in B2C Electronic Commerce","Y. Jiao; G. Cao","Center for Studies of Inf. Resources, Wuhan Univ., Wuhan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","3609","3612","In recent years, the B2C e-commerce achieved a rapid development on a global scope; more and more people began to use the Internet for shopping. However, the exponentially increasing information provided by Internet enterprises causes the problem of overloaded information, and this inevitably reduces the customer's satisfaction and loyalty. One way to overcome such problem is to build personalized recommender systems to retrieve product information that really interests the customers. The rapid development of Web 2.0 provides new ideas for personalized recommendation. In this paper we introduce the collaborative filtering, knowledge-based approaches and hybrid approaches in building recommender systems and discuss the strengths and weaknesses of each approach, we propose a collaborative tagging system to provide personalized product information to customers in B2C e-commerce websites and describe the system's architecture and point the system's advantage.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.892","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340667","","Buildings;Collaboration;Customer satisfaction;Electronic commerce;Information filtering;Information filters;Information retrieval;Internet;Recommender systems;Tagging","Internet;customer satisfaction;electronic commerce;groupware;information filtering;information filters;knowledge based systems;retail data processing","B2C electronic commerce;Internet shopping;collaborative filtering;collaborative tagging system;customer loyalty;customer satisfaction;e-commerce Web sites;knowledge-based approaches;personalized recommender systems;product information retrieval","","1","","11","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Software Fault Prediction using Language Processing","D. Binkley; H. Feild; D. Lawrie; M. Pighin","Loyola College","Testing: Academic and Industrial Conference Practice and Research Techniques - MUTATION (TAICPART-MUTATION 2007)","20071015","2007","","","99","110","Accurate prediction of faulty modules reduces the cost of software development and evolution. Two case studies with a language-processing based fault prediction measure are presented. The measure, refereed to as a QALP score, makes use of techniques from information retrieval to judge software quality. The QALP score has been shown to correlate with human judgements of software quality. The two case studies consider the measure's application to fault prediction using two programs (one open source, one proprietary). Linear mixed-effects regression models are used to identify relationships between defects and QALP score. Results, while complex, show that little correlation exists in the first case study, while statistically significant correlations exists in the second. In this second study the QALP score is helpful in predicting faults in modules (files) with its usefulness growing as module size increases.","","POD:0-7695-2984-4","10.1109/TAIC.PART.2007.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344105","","Application software;Computer industry;Costs;Humans;Information retrieval;Natural languages;Software engineering;Software measurement;Software quality;Software testing","information retrieval;regression analysis;software fault tolerance;software quality","QALP score;faulty modules;information retrieval;language processing;linear mixed-effects regression models;software development;software fault prediction;software quality","","7","","26","","","10-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Study on Ontology Learning for the Intelligent Search Engine","M. Xiao; J. Hu; Y. Xiao","Dept. of Comput. Sci., Central China Normal Univ., Wuhan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","5369","5372","Intelligent search engine is an effective tool for solving many bottleneck problems in network information retrieval. It involves acquiring, preprocessing, representing and integrating data and information available at different levels of services (e.g. HTML/XML/RDF/OWL etc.) and eventually converts them into useful intelligent semantic information of each domain. This paper proposes firstly a systemic framework for building (semi-)automatically ontology learning from Web pages and considers some key problems about extracting concepts and interrelationships in ontology learning.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.1315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4341090","","Data mining;HTML;Information retrieval;Intelligent networks;OWL;Ontologies;Resource description framework;Search engines;Web pages;XML","Internet;Web sites;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);search engines","Web page;data integration;data preprocessing;data represention;intelligent search engine;intelligent semantic information;network information retrieval;ontology learning","","0","","9","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Exploring Protein Architecture using 3D Shape-based Signatures","E. Paquet; H. L. Viktor","National Research Council of Canada, Ottawa, ON, K1A 0R6, Canada. phone: 613-991-5035; fax: 613-952-0215; e-mail: eric.paquet@nrc-cnrc.gc.ca","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","1204","1208","Consider the scenario where, for a prescription drug designed to treat a terminal illness, a particular protein has been successfully identified as a crucial, beneficial component in the drug compound. However, this protein has contra-indications and causes severe adverse effects in a certain subset of the population. If another protein from the same family, with similar structure and functionality, but without these adverse effects, can be found, the subsequent modification of the harmful drug has obvious benefits. This paper describes a new indexing and similarity search system to retrieve such protein structure family members, based on their 3D shape. Our approach is translation, scale and rotation invariant, which eliminates the need for prior structure alignment. Our experimental evaluation against seven (7) diverse protein families indicate that our system accurately and precisely locate all members of a family. We further illustrate this by showing that our system precisely retrieves the Homo Sapiens Hemoglobin family members, against a database containing 26,000 protein structures.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4352513","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4352513","","Bioinformatics;Databases;Drugs;Genetic mutations;Indexing;Information retrieval;Labeling;Proteins;Prototypes;Shape","biology computing;drugs;indexing;information retrieval;molecular biophysics;proteins","3D indexing;3D retrieval;3D shape-based signatures;Homo Sapiens Hemoglobin family;drug compound;drug design;drug modification;protein architecture;protein functionality discovery;protein structures;statistical distribution;structure alignment;terminal illness","Amino Acid Sequence;Computer Simulation;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular Sequence Data;Protein Conformation;Proteins;Sequence Alignment;Sequence Analysis, Protein","0","","8","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"A new fully-digital anthropomorphic and dynamic thorax/heart model","R. Haddad; I. E. Magnin; P. Clarysse","Creatis-LRMN, CNRS UMR 5220, Inserm U630, INSA B&#226;timent Blaise Pascal, 69621 Villeurbanne Cedex, France. phone: +33 4 72 43 81 48; fax: +33 4 72 43 85 26; e-mail: R.Haddad@creatis.insa-lyon.fr","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","5999","6002","A numerical anthropomorphic model of the breathing thorax and the beating heart is presented. It includes the main thoracic/cardiac anatomical structures, the main vessel junctions as well as the structures' motion. Its main feature is that it is based on a Magnetic Resonance Imaging (MRI) examination performed on the same human subject within the same session from which both structural and motion information are retrieved. This confers to the model a very good consistency. This numerical model is virtually imaged by two simulators: a MRI simulator and a Positron Emission Tomography (PET) simulator. The overall resulting model (structure geometry & dynamics, images) is useful for the evaluation of cardiac image processing algorithms such as heart structure segmentation or multi-modality cardiac image registration.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353715","","Anatomical structure;Anthropomorphism;Heart;Humans;Image retrieval;Information retrieval;Magnetic resonance imaging;Numerical models;Positron emission tomography;Thorax","biomechanics;biomedical MRI;blood vessels;cardiology;medical image processing;molecular biophysics;positron emission tomography","MRI;PET;anatomical structure;anthropomorphic thorax-heart model;cardiac image processing algorithm;cardiac motion;heart structure segmentation;magnetic resonance imaging;main vessel junction;multi-modality cardiac image registration;positron emission tomography;structure dynamics;structure geometry;thoracic motion","0","6","","17","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"Content Based Image Retrieval using a Descriptors Hierarchy","R. E. Patino-Escarcina; J. A. F. Costa","Federal University of Rio Grande do Norte, Natal-RN, Brasil","7th International Conference on Hybrid Intelligent Systems (HIS 2007)","20071015","2007","","","228","233","Content based image retrieval (CBIR), a technique which tries to find a set of images similar to a given example. Low level descriptors can be used to represent and index images. The main problem of CBIR is the gap between these descriptors and abstract concepts. The proposal present in this paper resembles the search process within a set of objects. First, objects can be found in a collection by looking general features and discarding those objects that do not fit into these features to reduce the search space. Next, another more specific feature can help to find these objects in the reduced search space. This work proposes the arrangement of low level descriptors into a hierarchy. This arrangement has to be done considering the detail of information that descriptor gives. Finally, descriptors on each level of the hierarchy are used to index images in the search space and a filter to reduce it has to be executed. This process is repeated until the low level of the hierarchy is reached. Experiments demonstrate the effectiveness of the proposed approach compared with the traditional ones and reveal it as a good option to implement CBIR systems.","","CD-ROM:0-7695-2946-1","10.1109/HIS.2007.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344056","","Adaptive systems;Content based retrieval;Filters;Humans;Hybrid intelligent systems;Image retrieval;Information retrieval;Laboratories;Proposals;Shape","content-based retrieval;image retrieval","content based image retrieval;descriptors hierarchy;low level descriptors","","0","2","22","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Impact Analysis of Missing Values on the Prediction Accuracy of Analogy-based Software Effort Estimation Method AQUA","J. Li; A. Al-Emran; G. Ruhe","University of Calgary, Canada","First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)","20071015","2007","","","126","135","Effort estimation by analogy (EBA) is often confronted with missing values. Our former analogy- based method AUQA is able to tolerate missing values in the data set, but it is unclear how the percentage of missing values impacts the prediction accuracy and if there is an upper bound for how big this percentage might become in order to guarantee the applicability of AQUA. This paper investigates these questions through an impact analysis. The impact analysis is conducted for seven data sets being of different size and having different initial percentages of missing values. The major results are that (i) we confirm the intuition that the more missing values, the poorer the prediction accuracy of AQUA; (ii) there is a quadratic dependency between the prediction accuracy and the percentage of missing values; and (Hi) the upper limit of missing values for the applicability of AQUA is determined as 40%. These results are obtained in the context of AQUA. Further analysis is necessary for other ways of applying EBA, such as using different similarity measures or analogy adaptation methods from those used in AQUA. For that purpose, the experimental design in this study can be adapted.","1949-3770;19493770","CD-ROM:0-7695-2886-4","10.1109/ESEM.2007.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343740","","Accuracy;Collaboration;Design for experiments;Filtering;Information retrieval;Laboratories;Software engineering;Software measurement;Upper bound","software development management","AQUA;analogy-based software effort estimation method;effort estimation by analogy;impact analysis;missing values;prediction accuracy;upper bound","","8","","18","","","20-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Comparing four Methods to Select Keywords that Use n-Grams to Generate Summaries","L. L. Bando; K. R. Lopez; M. T. Vidal; D. V. Ayala; B. B. Martinez","Benemerita Universidad Autonoma de Puebla, Mexico","Electronics, Robotics and Automotive Mechanics Conference (CERMA 2007)","20071029","2007","","","769","773","In this paper an algorithm to generate document extracts is proposed. This extract is composed of the most significative sentences of the current document. These sentences are chosen by considering their similitude with a so-denominated Virtual Paragraph (VP). The VP is formed by the key words that are obtained by the four methods that use n-grams, employed in this research. The experiments are performed over 100 documents of the DUC-2000 collection.","","POD:0-7695-2974-7","10.1109/CERMA.2007.4367781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4367781","","Automation;Automotive engineering;Data mining;FCC;Frequency;Genetic algorithms;Information retrieval;Logic;Robots;Vocabulary","","","","0","","6","","","25-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"Design of History Database for Networked Control Systems","Z. Youzhi; P. Peng; Z. Geng","Lab of Complex Systems and Intelligence Science, Institute of Automation, Chinese Academy of Sciences, Beijing 100080, P. R. China. E-mail: youzhi.zhu@ia.ac.cn","2007 Chinese Control Conference","20071015","2007","","","292","296","History database is used to facilitate the high-performance storage and retrieval of history data which is very valuable in areas like process and manufacturing industries. Networked control systems(NCS) are different from traditional control systems in that they have network inside their control loops. This paper introduced the design of history database which is a part of a novel NCS implementation platform-NetCon system. System architecture is designed for the history database. After that a configurable two stage history data compression/decompression algorithm is introduced for the store and restore of history data. The first stage compression is the preprocess step and the second stage offers some universal lossless byte flow compression algorithms. In order to enable an efficient data retrieval, the storage structure of history data is designed.","1934-1768;19341768","CD-ROM:978-7-900719-22-5; POD:978-7-81124-055-9","10.1109/CHICC.2006.4347577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4347577","Compression/Decompression Algorithm;History Database;Networked Control Systems;Storage Structure;System Architecture","Algorithm design and analysis;Communication system control;Computer architecture;Control systems;Data compression;Databases;History;Information retrieval;Intelligent systems;Networked control systems","database management systems;information retrieval;information storage;software architecture","NetCon system;control loops;history data retrieval;history data storage;history database;networked control systems;system architecture","","0","","8","","","July 26 2007-June 31 2007","","IEEE","IEEE Conference Publications"
"Recursive Feature Extraction for Ordinal Regression","F. Xia; Q. Tao; J. Wang; W. Zhang","Key Laboratory of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, P.R. China; Graduate School, Chinese Academy of Sciences, Beijing, 100080, P.R. China. e-mail: fen.xia@ia.ac.cn","2007 International Joint Conference on Neural Networks","20071029","2007","","","78","83","Most existing algorithms for ordinal regression usually seek an orientation for which the projected samples are well separated, and seriate intervals on that orientation to represent the ranks. However, these algorithms only make use of one dimension in the sample space, which would definitely lose some useful information in its complementary subspace. As a remedy, we propose an algorithm framework for ordinal regression which consists of two phases: recursively extracting features from the decreasing subspace and learning a ranking rule from the examples represented by the new features. In this framework, every algorithm that projects samples onto a line can be used as a feature extractor and features with decreasing ranking ability are extracted one by one to make best use of the information contained in the training samples. Experiments on synthetic and benchmark datasets verify the usefulness of our framework.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4370934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370934","","Automation;Collaboration;Data mining;Feature extraction;Information retrieval;Intelligent systems;Laboratories;Neural networks;Supervised learning;USA Councils","feature extraction;learning (artificial intelligence);pattern classification;regression analysis;trees (mathematics)","ordinal regression;ranking tree;recursive feature extraction","","0","","11","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"Toward Video Bookmarking Search: Search-Target Inference from TV Watching","M. Okamoto; H. Umeki","Toshiba Corporation, Japan","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","605","614","Our goal is to provide a one-button interface called Video Bookmarking Search, which efficiently retrieves information desired by a user with a simple user interface and an intelligent background process without distracting the user's attention from watching TV. We propose a method that infers keywords a user wants to search when watching TV by the Named Entity Recognition and the Semantic Role Analysis techniques for closed captions of Japanese TV shows on city life, travel, or cuisine to perform keyword selection for appropriate keyword-based Web search. According to experiments using actual TV shows with over 200 bookmarks, our method achieved 74.6% recall in the 10 retrieved results of searchable keywords that users want to search.","","POD:0-7695-2997-6","10.1109/ICSC.2007.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338400","Japanese Closed Captions.;Keyword Inference;Named Entity Recognition;Semantic Role Analysis","Cities and towns;Computer interfaces;Content based retrieval;Information retrieval;Keyboards;Laboratories;Layout;TV;User interfaces;Videoconference","Internet;inference mechanisms;information retrieval;television;user interfaces","TV watching;keyword-based Web search;named entity recognition;one-button interface;search-target inference;semantic role analysis techniques;user interface;video bookmarking search","","2","","13","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"Corpus-based Analysis of Japanese-English Emotional Expressions","J. Minato; K. Matsumoto; F. Ren; S. Kuroiwa","The University of Tokushima, Minami-Josanjima, Tokushima-shi, Japan, j","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","413","418","Development of information technology has increased the chances of interaction between human and computer. Understanding not only semantic information but also underlying emotion will make communication with computer more natural and congenial. As preliminary research for emotion estimation from multilingual text, we focused on emotion expressions of Japanese and English and created a corpus with about 1,200 bilingual sentences and tagged emotions on words and sentences. Based on the corpus, we statistically analyzed the characteristics of how emotions were expressed in each language and also the relationships between sentence emotion and word emotion in the sentence. The results show the characteristics of emotion expressions in Japanese and English dialogue sentences.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368064","","Emotion recognition;Humans;Image analysis;Information analysis;Information retrieval;Information technology;Speech analysis;Statistical analysis;Tagging;Text recognition","emotion recognition;human computer interaction;natural language processing","Japanese-English emotional expressions;corpus-based analysis;emotion estimation;emotion expressions;emotion identification;human computer interaction;information technology;multilingual text;semantic information;statistical analysis;tagged emotions","","2","","9","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Bipartite graph matching for video clip localization","Z. K. G. d. Patrocinio Jr.; S. J. F. Guimaraes; H. B. d. Paula","Pontificia Universidade Catolica de Minas Gerais, Brazil","XX Brazilian Symposium on Computer Graphics and Image Processing (SIBGRAPI 2007)","20071029","2007","","","129","138","Video clip localization consists in identifying real positions of a specific video clip in a video stream. To cope with this problem, we propose a new approach considering the maximum cardinality matching of a bipartite graph to measure video clip similarity with a target video stream which has not been prep recessed. We show that our approach locates edited video clips, but it does not deal with insertion and removal of frames/shots, allowing only changes in the temporal order of frames/shots. All experiments performed in this work have achieved 100% of precision for two different video datasets. And according to those experiments, our method can achieve a global recall rate of 90%.","1530-1834;15301834","POD:0-7695-2996-8","10.1109/SIBGRAPI.2007.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368177","","Bipartite graph;Distortion measurement;Image segmentation;Information retrieval;Internet;Multimedia communication;Streaming media;TV broadcasting;Video compression;Video sharing","graph theory;image matching;video streaming","bipartite graph matching;maximum cardinality matching;video clip localization;video stream","","2","2","22","","","7-10 Oct. 2007","","IEEE","IEEE Conference Publications"
"Multimedia medical case retrieval using decision trees","G. Quellec; M. Lamard; L. Bekri; G. Cazuguel; B. Cochener; C. Roux","ENST Bretagne, GET-ENST, Brest, F-29200 France; Inserm, U650, Brest, F-29200 France. gwenole.quellec@enst-bretagne.fr","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","4536","4539","In this paper, we present a case based reasoning (CBR) system for the retrieval of medical cases made up of a series of images with contextual information (such as the patient age, sex and medical history). Indeed, medical experts generally need varied sources of information (which might be incomplete) to diagnose a pathology. Consequently, we derive a retrieval framework from decision trees, which are well suited to process heterogeneous and incomplete information. To be integrated in the system, images are indexed by their digital content. The method is evaluated on a classified diabetic retinopathy database. On this database, results are promising: the retrieval sensitivity reaches 79.5% for a window of 5 cases, which is almost twice as good as the retrieval of single images alone. As a comparison, the retrieval sensitivity is 52.3% for a standard multimodal case retrieval using a linear combination of heterogeneous distances.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353348","CBR;contextual information;decision trees;diabetic retinopathy;image indexing;incomplete information","Biomedical imaging;Decision trees;Diabetes;History;Image databases;Image retrieval;Information resources;Information retrieval;Medical diagnostic imaging;Pathology","case-based reasoning;decision trees;information retrieval;medical information systems;multimedia databases;patient diagnosis","case based reasoning;decision trees;diabetic retinopathy database;medical information system;multimedia medical case retrieval;pathology diagnosis;retrieval sensitivity","Databases, Factual;Decision Making, Computer-Assisted;Diabetic Retinopathy;Humans;Image Processing, Computer-Assisted;Medical Records Systems, Computerized","4","1","13","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"Image Retrieval Technology of Multi-MPEG-7 Features Based on Genetic Algorithm","M. S. Liu; J. H. Li; H. Liu","Handan College, Handan, 056005, China. E-MAIL: liums601001@sina.com, liums@sjzri.edu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","6","","3549","3555","A content-based image retrieval (CBIR) system, especially the WEB-based CBIR system must be able to acknowledge different interpretations, which can be universally passed onto or accessed by a device or a computer code whether they are from CBIR system itself or from outer. In addition, the CBIR system must consider the different angles of human visual system. In order to realize such functions, MPEG-7 is employed with the aim to provide fundamental tools for describing multimedia contents and genetic algorithm is used to optimize the retrieval feature spaces so as to make the retrieval universal and to get the best result set. Experiments show that the retrieval efficiency can be significantly increased in comparison with the efficient content-based image retrieval.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370762","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370762","CBIR;Genetic algorithm;MPEG-7;Optimization","Content based retrieval;Cybernetics;Feature extraction;Genetic algorithms;Image retrieval;Information retrieval;Internet;MPEG 7 Standard;Machine learning;Multimedia systems","genetic algorithms;image retrieval","genetic algorithm;image retrieval;multi-MPEG-7 features","","2","","9","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"DTN-based Content Storage and Retrieval","J. Ott; M. J. Pitkanen","Helsinki University of Technology (TKK), Networking Laboratory, jo@netlab.tkk.fi","2007 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks","20071022","2007","","","1","7","Delay-tolerant networking (DTN) enables nodes to communicate by means of asynchronous messaging witout the need for an end-to-end path. Suitably designed application protocols may operate in DTNs by minimizing end-to-end interactions and using self-contained messages for communication. The store-carry-and-forward operation and message replication of many DTN routing protocols may yield multiple copies of messages spread across many nodes for an axtended period of time. We leverage these properties for application support in (mobile) intermediate DTN nodes which act as ad-hoc routers. We add explicit application hints to messages that are visible to each node, allowing them, e.g., to cache content, act as distributed storage, or perform application-specific forwarding.","","CD-ROM:978-1-4244-0993-8; POD:978-1-4244-0992-1","10.1109/WOWMOM.2007.4351691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351691","","Ad hoc networks;Communication system traffic control;Content based retrieval;Disruption tolerant networking;Information retrieval;Laboratories;Mobile communication;Peer to peer computing;Routing protocols;Traffic control","","","","14","2","27","","","18-21 June 2007","","IEEE","IEEE Conference Publications"
"Parallelization and Performance Analysis of Video Feature Extractions on Multi-Core Based Systems","Q. Zhang; Y. Chen; J. Li; Y. Zhang; Y. Xu","Univ. of Science and Technology of China; Intel Corporation, China","2007 International Conference on Parallel Processing (ICPP 2007)","20071015","2007","","","1","1","Content-based video information retrieval (CBVIR) has becoming one of the best solutions for retrieving useful information from today's video information explosion. And with the rapid development of modern technologies, CBVIR is emerging as a mass market desktop application. There is evidence that visual feature extraction is the most time-consuming part in a CBVIR system. In this paper, we implement three video visual feature extractions in parallel by exploring different kinds of thread-level parallelism. We also conduct detailed scalability and memory performance analysis on two multi-core based systems, in order to gain more insights into video-analysis related applications on future multi-core systems. From our analysis we identify the likely causes of bottlenecks in these kinds of applications and suggest ways to improve scalability.","0190-3918;01903918","CD-ROM:0-7695-2933-X","10.1109/ICPP.2007.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343808","","Content based retrieval;Feature extraction;Frequency domain analysis;Gabor filters;Information retrieval;Kernel;MPEG 7 Standard;NIST;Performance analysis;Scalability","content-based retrieval;feature extraction;video signal processing","content-based video information retrieval;multi-core based systems;thread-level parallelism;video feature extractions;video-analysis","","4","","17","","","10-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"Developing Search Strategies for Detecting Relevant Experiments for Systematic Reviews","O. Dieste; A. G. Padua","Universidad Politecnica de Madrid, Spain","First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)","20071015","2007","","","215","224","Information retrieval is an important problem in any evidence-based discipline. Although evidence- based software engineering (EBSE) is not immune to this fact, this question has not been examined at length. The goal of this paper is to analyse the optimality of search strategies for use in systematic reviews. We tried out 29 search strategies using different terms and combinations of terms. We evaluated their sensitivity and precision with a view to finding an optimum strategy. From this study of search strategies we were able to analyse trends and weaknesses in terminology use in articles reporting experiments.","1949-3770;19493770","CD-ROM:0-7695-2886-4","10.1109/ESEM.2007.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343749","","Abstracts;Costs;Databases;Gold;Immune system;Information retrieval;Software engineering;Software measurement;Standardization;Terminology","information retrieval;query formulation;software engineering","evidence- based software engineering;evidence-based discipline;information retrieval;search strategies;systematic reviews","","4","","19","","","20-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Research and realization of personalized search engine based on Ontology","L. Yong; L. Guan-yu","Dalian Maritime University, P.R.China","2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)","20071022","2007","","","1016","1020","Lack of personalization, poor recall and precision ratios, and lower efficiency of search are main problems of the current search engines, while the application of personalized search engine is an efficient approach. This paper gives the design and implementation of a personalized search engine, including the establishment and application of the shared knowledge base, the collection and mining of the users' interest, the construction and use of the users' interest base, and the combination of semantic query and personalized one. The core of the shared knowledge base and personalized query is ontology technology, and the effective use of which can obviously advance the recall and precision ratios. Moreover, the application of the users' interest base can improve the quality and efficiency of customer service.","","POD:0-7695-2943-7","10.1109/NPC.2007.159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351620","","Electronic mail;Filters;Footwear;HTML;Information retrieval;Internet;Ontologies;Parallel processing;Search engines;Web pages","data mining;knowledge based systems;ontologies (artificial intelligence);query processing;search engines","ontology technology;personalized search engine;semantic query;shared knowledge base","","0","","14","","","18-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Palmprint Matching using Pairwise Relative Angle Histogram","F. Li; M. K. H. Leung; L. T. G. Sim","School of computer engineering, Nanyang Technological University, Singapore 639798. E-MAIL: asfli@ntu.edu.sg","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","1","","151","155","In this paper, we propose a novel approach to retrieve line-patterns from large databases in a rotation and translation invariant manner, at the same time, tackle broken line problem. Line segments are extracted from an image as primitives. Each local structure is represented by a set of pair-wise angle relationships, which are simple, invariant to translation and rotation, robust to end-point erosion, segment error, and sufficient for discrimination. Experiment showed encouraging results which also implicate that line segments could provide sufficient information for palmprint recognition.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370131","Hausdorff distance;Histogram;Line feature;Palmprint;Relative angle","Authentication;Biometrics;Cybernetics;Data engineering;Feature extraction;Histograms;Image segmentation;Information retrieval;Machine learning;Shape","feature extraction;fingerprint identification;image matching;image segmentation","broken line problem;end-point erosion;image line segment extraction;large databases;line-pattern retrieval;pairwise angle relationships;pairwise relative angle histogram;palmprint matching;palmprint recognition","","0","","12","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"RS Image Content-Based Semantic Retrieval System for Mt. Tai Scenic Spots and Historical Relics","W. Yaqin; G. Hua; L. Yong; S. Weixing","College of Geo Info. Science and Technology, Shandong University of Science and Technology, Tsingdao, 266510, Shandong, China; College of Info. Science and Engineering, Shandong Agricultural University, Taian, 271018, Shandong, China; Institute of Mt. Taishan Scenic Area, Management Committee of Mt. Taishan Scenic Spots and Historical Relics, Taian, 271000, Shandong, China","2007 8th International Conference on Electronic Measurement and Instruments","20071022","2007","","","2-880","2-884","The status in quo of remote sensing (RS) image inquiry is discussed in this paper firstly. Then, on the basis of analysis of content-based image inquiry and image data characteristics, an image content-based retrieval method supported by GIS is proposed. This method makes the fusion of image data and vector data's attribute, so it can assign the semantic information to image data indirectly and realize image inquiry. Finally, supported by ""digital Mt. Tai construction"" project, the semantic retrieval method of Mt. Tai scenic spots and historical relics based on RS image data content is studied and a well-planned scheme and framework to construct the retrieval system is proposed. It is ensured that the management level of Mt. Tai scenic spots and historical relics and service level of Mt. Tai tourism industry is promoted.","","CD-ROM:978-1-4244-1136-8; POD:978-1-4244-1135-1","10.1109/ICEMI.2007.4350821","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4350821","GIS;RS image;scenic spot;semantic retrieval","Agricultural engineering;Content based retrieval;Educational institutions;Geographic Information Systems;Image recognition;Image retrieval;Information retrieval;Instruments;Management Committee;Pixel","content-based retrieval;image retrieval;remote sensing","GIS;Mt. Tai scenic spots;historical relics;image content based semantic retrieval system;image data fusion;remote sensing image inquiry;semantic information","","0","","10","","","Aug. 16 2007-July 18 2007","","IEEE","IEEE Conference Publications"
"A Dynamic RFID-Based Mobile Monitoring System in Animal Care Management Over a Wireless Network","J. S. L. Ting; S. K. Kwok; W. B. Lee; A. H. C. Tsang; B. C. F. Cheung","Dept. of Ind. & Syst. Eng., Hong Kong Polytech. Univ., Kowloon","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","2085","2088","Due to the increasing integration of animals into family lifestyles, animal care management becomes an important issue as animals have a direct impact on human psychological and physical health. Even though there are a lot of solutions, maltreatment of animals and risks in animal health are increasing as indicated in the newspapers and statistics. In addition, many identification methods are not efficient and user-friendly. In this paper, an RFID-based mobile monitoring system (RFID-MMS) is designed in helping users to better manage the animals in dynamic information retrieving, location tracking, and behavior analyzing over a wireless network. The proposed system, which is suitable for using in all animals unities, enhances the companionship between humans and animals.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4340296","","Animals;Biomedical monitoring;Engineering management;Humans;Information analysis;Information retrieval;Mobile communication;Radiofrequency identification;Technology management;Wireless networks","health care;mobile communication;mobility management (mobile radio);monitoring;radiofrequency identification","animal care management;dynamic RFID-based mobile monitoring system;dynamic information retrieval;human psychological;location tracking;physical health;wireless network","","3","10","11","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Venous Thrombosis Supervised Image Indexing and Fuzzy Retrieval","A. Dahabiah; J. Puentes; B. Solaiman","ENST Bretagne, GET-ENST D&#233;partement Image et Traitement de l'Information, Brest, France; INSERM, U650, Laboratoire de Traitement de l'Information M&#233;dicale, Brest, France","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","4528","4531","Clinical assessment of venous thrombosis (VT) is essential to evaluate the risk of size increase or embolism. Analyses like echogenecity and echostructure characterization, examine ancillary evidence to improve diagnosis. However, such analyses are inherently uncertain and operator dependent, adding enormous complexity to the task of indexing diagnosed images for medical practice support, by retrieving similar images, or to exploit electronic patient record repositories for data mining. This paper proposes a VT ultrasound image indexing and retrieval approach, which shows the suitability of neural network VT characterization, combined with a fuzzy similarity. Three types of image descriptors (sliding window, wavelet coefficients energy and co-occurrence matrix), are processed by three different neural networks, producing equivalent VT characterizations. Resulting values are projected on fuzzy membership functions and then compared with the fuzzy similarity. Compared to nominal and Euclidean distances, an experimental validation indicates that the fuzzy similarity increases image retrieval precision beyond the identification of images that belong to the same diagnostic class, taking into account the characterization result uncertainty, and allowing the user to privilege any particular feature.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353346","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353346","Similarity;echogenicity;echostructure;fuzzy retrieval;neural network classifier;supervised image indexing;ultrasound;venous thrombosis","Biomedical imaging;Data mining;Image analysis;Image retrieval;Indexing;Information retrieval;Medical diagnostic imaging;Neural networks;Thrombosis;Ultrasonic imaging","biomedical ultrasonics;blood vessels;data mining;image retrieval;indexing;medical image processing;medical information systems;ultrasonic imaging","clinical assessment;co-occurrence matrix;data mining;echogenecity;echostructure characterization;electronic patient record repository;fuzzy membership functions;fuzzy retrieval;fuzzy similarity;image descriptors;patient diagnosis;sliding window;supervised image indexing;ultrasound image indexing;venous thrombosis;wavelet coefficients energy","0","1","","8","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"Clustering Guided SVM for Semantic Image Retrieval","K. Gao; S. x. Lin; Y. d. Zhang; S. Tang","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, 100080; Graduate University, Chinese Academy of Sciences, Beijing, China, 100039. kegao@ict.ac.cn","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","199","203","SVM (support vector machine) enables effective image classification for semantic image retrieval. However, how to train accurate image classifiers in high-dimensional feature space suffers from the problem of choosing proper training samples. To solve this problem, a novel approach named CGSVM (clustering guided SVM) is presented, which utilizes clustering result to select the most informative image samples to be labeled, and optimize the penalty coefficient. Experimental results show that our algorithm achieves higher search accuracy than regular SVM for semantic image retrieval.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365439","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365439","Clustering;Image Retrieval;Semantic;Support Vector Machine","Clustering algorithms;Image classification;Image retrieval;Information processing;Information retrieval;Laboratories;Space technology;Support vector machine classification;Support vector machines;Training data","image classification;image retrieval;pattern clustering;support vector machines","clustering guided SVM;image classification;semantic image retrieval;support vector machine","","1","1","12","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"Detection of Microcalcifications in Digital Mammograms","F. J. Lopez-Aligue; A. Poveda-Pierola; I. Acevedo-Sotoca; F. Garcia-Urra","Department of Electronics and Electrical Engineering, University of Extremadura, Badajoz, Spain. aligue@unex.es","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","3906","3909","A method is described for processing digital mammograms to detect microcalcifications that, although they may be so small that they are almost undetectable visually, could be indicators of a possible malignancy. The process consists of three stages. In the first, zones of the mammogram that potentially correspond to microcalcifications are extracted. This is done by analyzing the distribution of brightnesses over the entire mammogram, seeking structures that are typical of microcalcifications. The resulting images are passed to the second stage, in which localized clusters are identified as regions-of- interest (ROI). The third stage retrieves any information that might have been lost in the previous stages. The end result is a mammogram in which the few ROIs that reached the final phase -and which, in reality, are those that could be of true medical interest- clearly stand out. The system was tested against the DDSM mammogram database. All of the malignant and benign lesions were located perfectly, as well as some difficult-to-classify calcified formations. The system is now fully operational, accepting, as well as the database images, both digital and analogical mammograms.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353187","","Biomedical imaging;Brightness;Data mining;Delta-sigma modulation;Image databases;Information retrieval;Lesions;Magnetic resonance imaging;Mammography;Ultrasonic imaging","biological tissues;mammography","DDSM mammogram database;benign lesions;digital mammograms;malignant lesions;microcalcifications","Calcinosis;Databases, Factual;Female;Humans;Image Processing, Computer-Assisted;Mammography;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted","0","","11","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"The Info-plosion Project","M. Kitsuregawa","University of Tokyo","2007 IFIP International Conference on Network and Parallel Computing Workshops (NPC 2007)","20071022","2007","","","3","6","How much information project in California University examined the volume of information that have been produced so far, and revealed that actually very large volume of information has been produced, even if sensor information is not included in the target of this research. So, if such information is included, the amount becomes much larger. Therefore, we considered that it is a big challenge in information science to make value from such massive volume of data. Recently, it is said that knowledge worker waste more than 30 percent of their work time to search something. It is necessary to make information retrieval more efficient. This paper introduces info-plosion project, which tackles this challenge. In this paper we introduce four core subprojects.","","POD:0-7695-2943-7","10.1109/NPC.2007.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351450","","Computer industry;Dictionaries;Electronic mail;History;Information retrieval;Information science;Natural language processing;Natural languages;Parallel processing;Search engines","information retrieval","California University;info-plosion project;information project;information retrieval;information science","","0","","6","","","18-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Correlation between bug notifications, messages and participants in Debian's bug tracking system","M. P. Francisco; P. B. Perez; G. Robles","Universitat Jaume I, Spain","First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)","20071015","2007","","","455","457","Bugs are an essential part of software projects because they lead its evolution. Without bug notifications developers cannot know if their software is accomplishing its tasks properly. However, few analytical studies have been made about this aspect of projects. We have developed a tool to extract and to store information from Debian's BTS (Bug Tracking System) in a relational database. In this paper we show that there is a strong dependence between three variables which can be used to analyze the activity of a project through its bugs: bug notifications, communications between users and developers and people involved.","1949-3770;19493770","CD-ROM:0-7695-2886-4","10.1109/ESEM.2007.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343777","","Computer bugs;Control systems;Data mining;Information retrieval;Internet;Packaging;Particle measurements;Relational databases;Software engineering;Software measurement","program debugging;relational databases","Debian bug tracking system;bug notifications;relational database;software projects","","0","","7","","","20-21 Sept. 2007","","IEEE","IEEE Conference Publications"
"Software Tools to Enable Information Accelerated Radical Innovation","R. H. Miller; L. K. Miller; C. Eick","University of Detroit Mercy, Department of Mathematics and Computer Science, College of Engineering and Science, Detroit, MI, USA","PICMET '07 - 2007 Portland International Conference on Management of Engineering & Technology","20071015","2007","","","821","833","While information technology is a basic and necessary component to any research and development project leading to innovation, knowledge derived from information is crucial to accelerating radical innovation. Information has become more readily available to researchers in the past decade, with much of this information residing in digital libraries, patent databases, and even on the World Wide Web. However, much of this information is not easily retrievable. As the amount of information has grown throughout the past decade, finding specific information has become nearly impossible. Search engines are not adequate for finding critical knowledge for innovation in this vast sea of information. On the other hand, information must be rapidly retrieved and processed into knowledge in order to accelerate radical innovation. This paper describes a novel accelerated radical innovation methodology for accelerating breakthrough innovation from inception through commercialization, and then describes the required capabilities of a triad of necessary IT technologies that must be integrated with the new methodology if radical innovation is to be accelerated by the envisioned 2-10 times beyond current innovation time horizons. This IT triad includes integrated tools for information retrieval, pattern recognition, and knowledge management which must interact and cooperate.","2159-5100;21595100","CD-ROM:978-1-8908-4315-1","10.1109/PICMET.2007.4349399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4349399","","Acceleration;Databases;Information retrieval;Information technology;Research and development;Search engines;Software libraries;Software tools;Technological innovation;Web sites","information retrieval;innovation management;knowledge management;pattern recognition;software tools","information accelerated radical innovation;information retrieval;knowledge management;pattern recognition;software tools","","0","","117","","","5-9 Aug. 2007","","IEEE","IEEE Conference Publications"
"Agents-Based Intelligent Retrieval Framework for the Semantic Web","Y. Xiao; M. Xiao; F. Zhang","Dept. of Inf. Manage., Central China Normal Univ., Wuhan","2007 International Conference on Wireless Communications, Networking and Mobile Computing","20071008","2007","","","5357","5360","In order to solve the problem that the web data can hardly process automatically because of the lack of semantic, the world wide web consortium (W3C) develops the research project of semantic web which provides the base for the intelligent Web application. The intelligent agents are very suitable for variety applications in semantic web environment. On the basis of the research of semantic web and intelligent agent, combined with other technologies such as information retrieval, knowledge modeling and ontology construction, an agents-based intelligent retrieval framework in semantic web is proposed, which includes information collecting agent, storing agent, reasoning agent and querying agent. These agents implement the Web information retrieval service based on ontology by the collaboration each other, and further improve efficiency and precision of information retrieval.","2161-9646;21619646","CD-ROM:1-4244-1312-5; POD:1-4244-1311-7","10.1109/WICOM.2007.1312","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4341087","","Content based retrieval;Information retrieval;Intelligent agent;Intelligent structures;Intelligent systems;Internet;Ontologies;Resource description framework;Search engines;Semantic Web","information retrieval;multi-agent systems;semantic Web","Web data;World Wide Web Consortium;agents-based intelligent retrieval framework;information collecting agent;information retrieval;intelligent Web application;intelligent agents;knowledge modeling;ontology construction;querying agent;reasoning agent;semantic Web environment;storing agent","","1","","6","","","21-25 Sept. 2007","","IEEE","IEEE Conference Publications"
"Replacing Lost or Stolen E-Passports","J. Yong; E. Bertino","University of Southern Queensland","Computer","20071015","2007","40","10","89","91","Until recently, border control had changed little over the years, despite advancing technology. Now, travelers routinely print out e-tickets from their computers, and many countries have started issuing e-passports with embedded biometric information. However, countries are taking different approaches to e-passports, raising concerns about how travelers can replace them in the event they're lost or stolen. Travelers report the loss or theft of hundreds of thousands of passports each year. The Australian government estimates that 30,000 of the 1 million passports it issues annually are lost or stolen (http://foreignminister.gov.au/releases/2005/fa083_05.html), and in 2006, the United Kingdom reported that more than 290,000 passports were lost or stolen (http://press.home-office.gov.uk/press-releases/passport-warning?version=1).","0018-9162;00189162","","10.1109/MC.2007.360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343699","e-passports;security","Application software;Biometrics;Computer security;Counting circuits;DNA computing;Fingerprint recognition;Information retrieval;Information security;Iris;Licenses","government data processing;security","border control;e-passports;e-tickets;embedded biometric information;stolen E-passports replacement","","4","","","","","Oct. 2007","","IEEE","IEEE Journals & Magazines"
"Efficient Tracking of the Heart Using Texture","A. Noce; J. Triboulet; P. Poignet","LIRMM - UMR 5506 - UM2 CNRS - 161 rue Ada, Montpellier, France. noce@lirmm.fr","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20071022","2007","","","4480","4483","Performing motion tracking in real-time is an old and recurrent problem in computer vision. It has been addressed through a large set of approaches but achieving a high level of robustness is still a challenge, especially with low definition input. In the considered application, tracking the heart motion in endoscopic beating heart sequences, the sensitivity of existing algorithms to visual artifacts and variations in illumination is an issue that calls for improvements. In the prospect of developing a motion compensation architecture for robotically assisted beating heart surgery, we address the problem of visual information retrieval by proposing a new composite tracking algorithm using both template matching and texture analysis. As we will show in this paper, the use of texture characterization of the heart surface improves the overall precision and robustness, in comparison with other prior approaches.","1094-687X;1094687X","CD-ROM:978-1-4244-0788-0; POD:978-1-4244-0787-3","10.1109/IEMBS.2007.4353334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4353334","","Application software;Computer vision;Heart;Information retrieval;Lighting;Motion compensation;Robot sensing systems;Robustness;Surgery;Tracking","biomechanics;biomedical optical imaging;cardiology;computer vision;endoscopes;image matching;image texture;medical image processing;medical robotics;motion compensation;surgery;target tracking","composite tracking algorithm;computer vision;endoscopic beating heart sequences;heart motion tracking;motion compensation architecture;real-time tracking;robotically assisted beating heart surgery;template matching;texture analysis;texture characterization;visual artifacts;visual information retrieval","Heart;Humans;Imaging, Three-Dimensional;Myocardial Contraction;Myocardium;Sensitivity and Specificity;Thoracic Surgery, Video-Assisted","3","","18","","","22-26 Aug. 2007","","IEEE","IEEE Conference Publications"
"TCBPLK: A New Method of Text Categorization","J. S. Xu","School of Economy, BeiJing University, Beijing, 100871, China. E-MAIL: xjsfine@126.com","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","7","","3889","3892","This paper presents a new text categorization method based on P-L theory and Kohonen network, which called TCBPLK method. The Kohonen network is applied to realizing text categorization, which has a defect of too slowly speed of training. To text vector of high dimension, the defect is more obvious. Even the result of text categorization can not be acquired. The new method establishes vector space model of term weight by the theory of P-L, which enhances the function of the words from the viewpoint of categorization effect, and decreases the dimension of vector through eliminating redundant features. Experimental results confirm that TCBPLK method decreases the number of vector, and enhances the generalization and precision of text categorization.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370825","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370825","Kohonen network;P-L theory;Text categorization;Vector space model","Cybernetics;Functional analysis;Information analysis;Information retrieval;Learning systems;Machine learning;Matrix decomposition;Pattern analysis;Text categorization;Vocabulary","text analysis","Kohonen network;P-L theory;text categorization;vector space model","","0","","7","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Adapter Implementation between Wimax Specific Layers and Network/Application Layers","T. Nissil; J. Huusko; I. Harjula; M. Katz","Technical Research Centre of Finland (VTT)","The 2007 International Conference on Next Generation Mobile Applications, Services and Technologies (NGMAST 2007)","20071008","2007","","","328","333","Several recent studies show that future high data rate broadband wireless access (BWA) technologies require the use of adaptive and co-operative techniques to more efficiently utilise the resources in link and system level. In this paper we propose an adapter module to be utilised in the data link layer (DLL) and optionally in the application layer to serve different adaptive triggering routines among the networks. The adapter is used to retrieve the necessary information from hardware (HW) to aid different adaptation processes in system. The adapter is also used to trigger the preferred control and management actions in the media access control (MAC) and physical (PHY) level of the related HW. The usability and performance limits of the designed and implemented adapter solutions were measured with relevant performance evaluations and the derived results validate the feasibility of the proposed adapter solution.","2161-2889;21612889","POD:0-7695-2878-3","10.1109/NGMAST.2007.4343441","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4343441","","Adaptive control;Hardware;Information retrieval;Media Access Protocol;Physical layer;Programmable control;Quality of service;Telephony;Usability;WiMAX","WiMax;access protocols;adaptive systems;resource allocation","Wimax specific layer;adapter module;adaptive co-operative techniques;broadband wireless access;data link layer;information retrieval;media access control level;network/application layers;resource utilisation","","2","","11","","","12-14 Sept. 2007","","IEEE","IEEE Conference Publications"
"Two-Layer Method of Image Retrieval Based on Global Color Histogram and Local Color Spatial Features","J. Zhao; D. M. Yan; G. Z. Men; Y. K. Zhang","The College of Electronic and Information Engineering, Hebei University, Baoding 071002, China. E-MAIL: zhaojie@mail.hbu.edu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","7","","4020","4025","A new method based on two layers image retrieval is proposed. The first layer retrieval feature is global color histogram and the second one consists of the local color histogram, the averages and variances of the multi-scaling 2D wavelet decomposition coefficients. Difference weights are assigned to every block according to the importance of its spatial distribution. This method combines the advantages of the global and the local color histogram, thereby achieving the better retrieval performance.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370849","Color histogram;Feature extraction;Image retrieval;Spatial feature","Content based retrieval;Cybernetics;Educational institutions;Feature extraction;Histograms;Image databases;Image retrieval;Information retrieval;Machine learning;Multimedia databases","image colour analysis;image retrieval;wavelet transforms","2D wavelet decomposition;global color histogram;image retrieval;local color spatial features","","0","","11","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Improving Legal Ontologies through Semantic Representation of Adjectives","A. Bertoldi; R. Chishman","Universidade do Vale do Rio dos Sinos, Brazil","International Conference on Semantic Computing (ICSC 2007)","20071008","2007","","","767","774","The research reported here results from a master's thesis project developed in the scope of SEMANTEC, DIRPI and LOIS projects. The aim of our research was to show what kind of semantic information was carried by adjectives and how this information could improve legal ontologies and legal information retrieval. In this paper we will discuss the main results related to the development of this research. We combine different linguistic theories to approach adjectival semantics. As result of this research, we propose five different adjectival groups. Each group has a specific semantic behavior and can contribute in different ways to legal information retrieval.","","POD:0-7695-2997-6","10.1109/ICSC.2007.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4338421","","Computer architecture;Educational institutions;Information retrieval;Joining processes;Knowledge acquisition;Law;Legal factors;Machine assisted indexing;Natural language processing;Ontologies","computational linguistics;information retrieval;law administration;ontologies (artificial intelligence)","adjectival semantic representation;legal information retrieval;legal ontology;linguistic theory","","0","","22","","","17-19 Sept. 2007","","IEEE","IEEE Conference Publications"
"An Orientation Independent Texture Descriptor for Image Retrieval","C. B. Huang; Q. Liu","School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, 430070, China, E-mail: huang","2007 International Conference on Communications, Circuits and Systems","20071015","2007","","","772","776","In this paper, a new orientation independent texture descriptor based on the relation characteristic of pixels in their local neighbor is proposed, which is termed quantized compound change histogram. For every pixel in the image, the compound rate of change of gray value of the pixel in four different directions in its neighbor is computed and is quantized into 40 bins to get the quantized compound change at the pixel. Calculating the distribution of the quantized compound change over the whole image, the quantized compound change histogram is obtained. It is invariant to image rotation and translation. Experimental results show that the texture descriptor has better descriptive power for natural color images.","","CD-ROM:978-1-4244-1474-1; POD:978-1-4244-1473-4","10.1109/ICCCAS.2007.4348164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4348164","","Chaos;Color;Content based retrieval;Data mining;Gabor filters;Histograms;Image retrieval;Information retrieval;MPEG 7 Standard;Pixel","image colour analysis;image retrieval;image texture","image pixel;image retrieval;image rotation;image translation;natural color image;orientation independent texture descriptor;quantized compound change histogram","","8","","15","","","11-13 July 2007","","IEEE","IEEE Conference Publications"
"A Haptic Data Repository Framework","F. R. El-Far; M. Orozco; A. El Saddik","Multimedia Communications Research Laboratory, University of Ottawa, Canada. fayez@mcrlab.uottawa.ca","2007 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems","20071029","2007","","","19","24","The concept of a data repository is not a new idea; almost any scientific approach to a statistical-based problem requires a data storage effort for the purpose of post-processing and post-examination of acquired data sets. When faced with haptic-data, however, we run into several problematic issues, such as high bandwidth requirements (sampling rates equal to or higher than 600 Hz), data accuracy and relevance, data filtration and presentation. In this paper, we propose a haptic-data repository proof-of-concept capable of retrieving, filtering, and storing the compacted data sets in a local database. We introduce an Intelligent Filtering Algorithm, a Thread Management Algorithm, as well as an I/O optimization algorithm. By combining these algorithms, and as our performance evaluation demonstrates, we have successfully been able to save accurate haptic data at sampling rates equals to or higher than 1 KHz.","","CD-ROM:978-1-4244-0820-7; POD:978-1-4244-0819-1","10.1109/VECIMS.2007.4373921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4373921","","Anthropometry;Application software;Filtering algorithms;Haptic interfaces;Information retrieval;Multimedia communication;Multimedia systems;Rendering (computer graphics);Sampling methods;Virtual environment","data handling;database management systems;haptic interfaces;information filtering;multi-threading;optimisation","I/O optimization algorithm;data filtration;data post-processing;data presentation;data retrieval;data sampling rate;data storage;databases;haptic data repository framework;intelligent filtering algorithm;thread management algorithm","","0","","14","","","25-27 June 2007","","IEEE","IEEE Conference Publications"
"Enhancing Medication Safety and Healthcare for Inpatients Using RFID","C. L. Lai; S. W. Chien; L. H. Chang; S. C. Chen; K. Fang","Department of Information Management, National Yunlin University of Science & Technology, Yunlin, Taiwan, R.O.C.","PICMET '07 - 2007 Portland International Conference on Management of Engineering & Technology","20071015","2007","","","2783","2790","At least 44,000 people, and perhaps as many as 98,000 people, die in hospitals each year as a result of medical errors. Medical errors could be prevented by building a safer healthcare system. Recently, Radio frequency identification (RFID) has been applied in hospital management. RFID is valuable for quickly retrieving patient information and monitoring patient locations in the hospital. The purpose of this paper is to improve the accuracy of patient identification, and any medications the patient is taking. We proposed a framework using RFID, integration with the Hospital Information Systems (HIS) and reengineer the inpatient medication processes to improve patient safety and reduce serious medical errors. Our framework initially focuses on improving the workflow of patient's medication medicalcare and enhancing the patient safety. The framework will implement in the Taichung Hospital, on January 2007. We intend to construct a system integrating RFID into the existing HIS to improve the efficiency of hospital management and patient safety. The purpose of this is to decrease the risk of serious medical error and therapeutic mistakes thereby increase higher quality of patient care.","2159-5100;21595100","CD-ROM:978-1-8908-4315-1","10.1109/PICMET.2007.4349618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4349618","","Biomedical monitoring;Health and safety;Hospitals;Information retrieval;Management information systems;Medical services;Medical treatment;Patient monitoring;Radio spectrum management;Radiofrequency identification","health care;hospitals;medical information systems;patient care;radiofrequency identification;security of data","RFID;healthcare system;hospital information systems;hospital management;hospitals;inpatient medication processes;inpatients;medical errors;medication safety;patient care;patient identification;patient information retrieval;patient location monitoring;patient safety;radio frequency identification;therapeutic mistakes","","5","","19","","","5-9 Aug. 2007","","IEEE","IEEE Conference Publications"
"Modelling and querying sensor databases","J. L. Zechinelli-Martini; I. Elias-Morales","Fundacion Universidad de las Americas, Mexico","Eighth Mexican International Conference on Current Trends in Computer Science (ENC 2007)","20071022","2007","","","138","148","This paper presents and approach for modelling and querying sensor databases for implementing continuous information systems. Our approach defines query processing strategies that exploit as much as possible the computing and energy capacities of sensors. We introduce the concept of broker for representing and associating querying capacities to sensors, so that query processing can be done by making sensors cooperate in order to retrieve data. The paper discusses also implementation issues based on the TinyDB platform.","","POD:0-7695-2899-6","10.1109/ENC.2007.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4351436","","Capacitive sensors;Clocks;Computer networks;Context modeling;Information retrieval;Query processing;Relational databases;Sensor phenomena and characterization;Sensor systems;Temperature sensors","query processing;visual databases","TinyDB platform;continuous information systems;data retrieval;query processing strategies;querying sensor databases","","0","","35","","","24-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"User-oriented Addressing in Wireless Networks: Advanced Strategies and New Technical Solutions","C. Wietfeld; J. Seger","Communication Networks Institute, University of Dortmund, Germany. Christian.Wietfeld@uni-dortmund.de","2006 3rd International Symposium on Wireless Communication Systems","20071022","2006","","","174","178","In this paper, we present the concept of an individual communication address space (ICAS), which provides end users with dramatically improved flexibility in managing and sharing their (voice) communication addresses. The proposed concept puts end users into full control of their communication addresses instead of being tied to telephone numbers: users can define community-specific addresses in an Internet-style, control the lifetime of each address and their mapping to network addresses. In addition to plain-text addresses, RFID tag information can be used as alias names. The key components of the concept are an operator-independent, network-based database system, a client- based retrieval mechanism interacting online with the ICAS database and a proxy service allowing for the decoupling of network addresses and communication service addresses. The presented solution of a fully IP-based prototype implementation has proven the feasibility of the proposed architecture and was tested with end users for usability and performance aspects. As an intermediate solution improvements of the addressing mechanisms used in today's mobile phone clients are introduced by leveraging GPRS/UMTS packet data channels for an overlay signaling protocol.","2154-0217;21540217","CD-ROM:978-1-4244-0398-1; POD:978-1-4244-0397-4","10.1109/ISWCS.2006.4362282","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4362282","Innovative Services and Applications;Innovative User Interfaces;Service and Middleware Platforms;Subscriber Naming and Addressing","Communication system control;Database systems;IP networks;Independent component analysis;Information retrieval;Internet telephony;Mobile communication;Prototypes;RFID tags;Wireless networks","Internet;information retrieval;mobile handsets;packet radio networks;protocols","GPRS/UMTS packet data channels;ICAS;Internet;client- based retrieval mechanism;communication service address;individual communication address space;mobile phone clients;network-based database system;signaling protocol;user-oriented addressing;wireless networks","","3","","8","","","6-8 Sept. 2006","","IEEE","IEEE Conference Publications"
