"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5636537,5628905,5628568,5635157,5635104,5633974,5629302,5634023,5620229,5619057,5585764,5622904,5621702,5614110,5616239,5616626,5614150,5616930,5614607,5616221,5616635,5616236,5616503,5615790,5613451,5608753,5609387,5607556,5609748,5605559,5600340,5597760,5430891,5591985,5591812,5591994,5588987,5592709,5587785,5591001,5587859,5583251,5583187,5583235,5582934,5581311,5583657,5579218,5579069,5580697,5575855,5571401,5571204,5571516,5577956,5569915,5567598,5569667,5518759,5569366,5563672,5431024,5563670,5566039,5562761,5492200,5561518,5561476,5561649,5559799,5561432,5561473,5561613,5561455,5558960,5558904,5556595,5556733,5553404,5552349,5200519,5467165,5337997,5544552,5475235,5546548,5546368,5542894,5542915,5541219,5473215,5521626,5536622,5532434,5521780,5066968,5514505,5506048,5506340,5501488",2017/05/04 20:42:09
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Trademarks recognition based on local regions similarities","A. Zeggari; F. Hachouf; S. Foufou","Le2i Lab, Universit&#x00E9; de Bourgogne, B.P. 47870, 21078 Dijon, France","10th International Conference on Information Science, Signal Processing and their Applications (ISSPA 2010)","20101018","2010","","","37","40","This paper deals with content based image retrieval. We propose a logo recognition algorithm based on local regions, where the trademark (or logo) image is segmented by the clustering of points of interest obtained by Harris corners detector. The minimum rectangle surrounding each cluster is detected forming the regions of interest. Global features such as Hu moments and histograms of each local region are combined to find similar logos in the database. Similarity is measured based on the integrated minimum average distance of the individual components. The results obtained demonstrate tolerance to logos distortions such as rotation, occlusion and noise.","","Electronic:978-1-4244-7167-6; POD:978-1-4244-7165-2","10.1109/ISSPA.2010.5605559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5605559","Clustering;Image color analysis;Image segmentation;Information retrieval;moments;pattern recognition","Databases;Lighting;Trademarks","content-based retrieval;edge detection;image retrieval;image segmentation;pattern clustering","Harris corners detector;Hu moments;content based image retrieval;image segmentation;local regions similarities;logo recognition algorithm;minimum average distance;trademarks recognition","","1","","11","","","10-13 May 2010","","IEEE","IEEE Conference Publications"
"A soft computing approach for the memory storage of a sound signal processor","H. I. Hamzah; A. bin Abdullah","Department of Computer and Information Sciences, Universiti Teknologi Petronas, Tronoh, Perak","2010 International Symposium on Information Technology","20100902","2010","1","","1","5","This paper tries to create a new biologically-inspired abstract model for the sound signal processing. The abstract model also shows the memory storage for the sound signal processor. This research adapts the functions from the biologically-inspired entities, which are the human auditory system and the human brain. This research aims to provide integrated and structured database to store the sound signal processing data. This research provides the framework to the implementation of the soft computing approach for the memory storage of a sound signal processor. This paper is a preliminary investigation paper. Therefore, this research creates the abstract model for the Biologically-Inspired Sound Signal Analyzer (BISSA) as a new idea for information gathering.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561432","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561432","Information retrieval;biologically-inspired;information retrieval;noise filtering;signal processing;software engineering","Biological system modeling;Brain modeling;Ear;Humans;Noise","multimedia computing;storage management","biologically-inspired abstract model;biologically-inspired sound signal analyzer;human auditory system;human brain;memory storage;soft computing;sound signal processor","","0","","15","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Concept Location with Genetic Algorithms: A Comparison of Four Distributed Architectures","F. Asadi; G. Antoniol; Y. G. Gueheneuc","SOCCER Lab. - DGIGL, Ecole Polytech. de Montreal, Montre&#x0301;al, QC, Canada","2nd International Symposium on Search Based Software Engineering","20101111","2010","","","153","162","Genetic algorithms are attractive to solve many search-based software engineering problems because they allow the easy parallelization of computations, which improves scalability and reduces computation time. In this paper, we present our experience in applying different distributed architectures to parallelize a genetic algorithm used to solve the concept identification problem. We developed an approach to identify concepts in execution traces by finding cohesive and decoupled fragments of the traces. The approach relies on a genetic algorithm, on a textual analysis of source code using latent semantic indexing, and on trace compression techniques. The fitness function in our approach has a polynomial evaluation cost and is highly computationally intensive. A run of our approach on a trace of thousand methods may require several hours of computation on a standard PC. Consequently, we reduced computation time by parallelizing the genetic algorithm at the core of our approach over a standard TCP/IP network. We developed four distributed architectures and compared their performances: we observed a decrease of computation time up to 140 times. Although presented in the context of concept location, our findings could be applied to many other search-based software engineering problems.","","Electronic:978-0-7695-4195-2; POD:978-1-4244-8341-9","10.1109/SSBSE.2010.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635157","Concept location;distributed architectures;dynamic analysis;information retrieval","Computer architecture;Computers;Couplings;Gallium;Large scale integration;Servers","distributed processing;genetic algorithms;search problems;software engineering","TCP/IP network;computations parallelization;concept location;distributed architectures;genetic algorithms;latent semantic indexing;search based software engineering problems;source code textual analysis;trace compression techniques","","15","","41","","","7-9 Sept. 2010","","IEEE","IEEE Conference Publications"
"An empirical study on harmonizing classification precision using IE patterns","L. K. Soon; K. B. Hwang; S. H. Lee","Faculty of Information Technology, Multimedia University, Cyberjaya, Selangor, Malaysia","The 2nd International Conference on Software Engineering and Data Mining","20100809","2010","","","251","256","Web pages are conventionally represented by the words found within the contents for classification purpose. However, word-based web page representation suffers several limitations such as synonymy and homonymy. Motivated by the limitations of word-based representation, we explore the potential of representing web pages using information extraction patterns, in addition to words that are identified within the web contents. In this paper, we share the results as well as the findings learned from our experiments. Our empirical study conducted using WebKB dataset indicates that the addition of information extraction patterns in web page representation helps to improve the classification precision, especially in the categories which have much diversified web content.","","Electronic:978-89-88678-22-0; POD:978-1-4244-7324-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542915","information extraction;information retrieval;web classification;web mining","Computer science;Crawlers;Data mining;Information retrieval;Information technology;Multimedia computing;Parallel programming;Search engines;Web mining;Web pages","","","","1","","21","","","23-25 June 2010","","IEEE","IEEE Conference Publications"
"Using ontology evidences to extend belief network IR model","Jian Min Xu; Jin Kun Tian; Yan Chun Zhang; Jin Hua Wang","School of Mathematic and Computer, Hebei University Baoding, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","20101104","2010","10","","V10-31","V10-35","The retrieval performance of an information system usually increases when it uses the relationships among the terms. Belief network IR model provides a framework to combine deferent types of query evidences. In this paper we present an extended belief network model that combines user query terms and its ontology related terms. Then we evaluate the extended model using a reference collection of 1359 documents. The results show that the new model has improved retrieval performance.","2161-9069;21619069","Electronic:978-1-4244-7237-6; POD:978-1-4244-7235-2","10.1109/ICCASM.2010.5622904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5622904","bayesian network;information retrieval;ontology","Semantics","information retrieval;information systems;ontologies (artificial intelligence)","belief network IR model;information system;ontology evidences;retrieval performance","","0","","12","","","22-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Search Engine Result Aggregation Using Analytical Hierarchy Process","A. De; E. Diaz; V. V. Raghavan","TCS-Innovation Labs., Mumbai, India","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","3","","300","303","A metasearch engine queries search engines and collates information returned by them in one result set for the user. Metasearch can be external or internal. In external metasearch, result lists from external, independent search engines are merged. On the other hand, in an internal metasearch, result lists from using different search algorithms on the same corpus are aggregated. Thus result merging is a key function of metasearch. In this work, we propose a model for result merging that is based on the Analytic Hierarchy Process and compares documents and search engines in pair-wise comparison before merging. Our model has the capability to merge result lists based on ranks as well as scores, as returned by search engines. We use the LETOR 2 (LEarning TO Rank) dataset from Microsoft Research Asia for our experiments. When using document ranks, our model improves by 31.60% and 8.58% over the Borda-Fuse and Weighted Borda-Fuse models respectively. When using document scores the improvements are 42.92% and 18.03% respectively.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614607","Information Retrieval;Web Intelligence","Analytical models;Computational modeling;Engines;Fuses;Merging;Metasearch;Search engines","query processing;search engines","LETOR 2 dataset;analytical hierarchy process;learning to rank;metasearch engine queries search engines;search engine result aggregation","","2","","10","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Personalized meta-search engine design and implementation","Jiandong Cao; Yang Tang; Binbin Lou","Software College, Northeast University (NEU), Shenyang, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","7","","305","307","Personalized meta-search engine is one search engine that we teach the machine to learn users' interest, so the search engine can help users to pick up the useful information for them quickly by using their interest keeping in the database. Personalized meta-search engine can sort the results according to users' interest, the results that user likes will be the top of the results. It is a good measure to use Vector Space Model to help us implement the personalization. We use Vector Space Model to model the user and the results' interest, then we use cosine angel to calculate the similarity of these interest. This paper describes the design and implementation of this system by using result and user modeling.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563670","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563670","information retrieval;meta search engine;personalization;search engine","Collaboration;Engines","learning (artificial intelligence);meta data;search engines","cosine angel;machine learning;personalized meta-search engine design;vector space model","","0","","2","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Architecture of a Question-Answering System for a specific repository of documents","M. E. Sucunuta; G. E. Riofrio","UPSI-Investigaci&#x00F3;n Tecnol&#x00F3;gica, UTPL-Universidad T&#x00E9;cnica Particular de Loja, Ecuador","2010 2nd International Conference on Software Technology and Engineering","20101025","2010","2","","V2-12","V2-16","This paper describes the architecture for a Question-Answering System for a repository of documents that are labeled according to a standard. This architecture defines the basic structure into three modules to ensure a recovery process of the appropriate response. The first module performs analysis operations and representation of the question entered by the user in natural language. The second module allows for the operations concerning the search for documents; and finally the third module performs the extraction of the response. For the analysis of a question, Natural Language Processing (NLP) techniques are used in order for the question to be represented in a logical manner. Also, other components are used such as ontology, taxonomy, and knowledge bases that could process the question, place it in a context, and determine the type of question. An information retrieval module that interacts with the document repository, it is used to obtain documents. These documents are analyzed to determine the paragraphs that could be considered as a response. The aim of the model allows for an answer to a question that is asked in natural language of a document repository. This proposal will establish an appropriate mechanism to enable components of the representation of information based on a natural language text and later retrieval.","","Electronic:978-1-4244-8666-3; POD:978-1-4244-8667-0","10.1109/ICSTE.2010.5608753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5608753","Information Retrieval;Natural Language Processing;Ontology;Question-Answering System","Computational modeling;Computer architecture;Information retrieval;Natural language processing;Ontologies;Semantic Web","document handling;information retrieval;knowledge based systems;natural language processing;ontologies (artificial intelligence);software architecture","analysis operation;document repository;document search;information retrieval;knowledge base;natural language processing;ontology;question-answering system;recovery process;response extraction;system architecture;taxonomy","","1","","12","","","3-5 Oct. 2010","","IEEE","IEEE Conference Publications"
"Research on an Algorithm of Metasearch Engine Based on Personalized Demand of Users","X. Yun; S. Xiaoping; C. Jianbin","Bus. Coll., Beijing Union Univ., Beijing, China","2010 International Forum on Information Technology and Applications","20101111","2010","1","","240","243","In order to meet the personalized demand of users and help users to be more effective on selecting potentially useful search engines, this paper presented a metasearch engine algorithm that is based on personalized demands of users. According to practical demands of users, different select strategies of metasearch engine algorithm are designed. The experimental results show that selection strategy of the algorithm can reflect some effects by the certain characteristics of the member search engines. So, this algorithm will be widely used in the future.","","Electronic:978-1-4244-7622-0; POD:978-1-4244-7621-3","10.1109/IFITA.2010.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635104","Algorithm;Information retrieval;Metasearch engine;Personalization","Algorithm design and analysis;Databases;Engines;Metasearch;Search engines;Sorting;Time factors","meta data;search engines","metasearch engine algorithm;personalized users demand","","2","","9","","","16-18 July 2010","","IEEE","IEEE Conference Publications"
"A New Approach for Better Document Retrieval and Classification Performance Using Supervised WSD and Concept Graph","R. Soltanpoor; M. Mohsenzadeh; M. Mohaqeqi","North Branch, Comput. Dept., Islamic Azad Univ., Tehran, Iran","2010 First International Conference on Integrated Intelligent Computing","20100916","2010","","","32","38","Word Sense Disambiguation (WSD) is main task in the area of natural language processing (NLP). Supervised WSD methods are shown to be more effective than other WSD methods with the limitation of the size of manual annotated learning set. On the other hand, Concept graph is a weighted graph with each of its edges representing the relationships between concepts (relevancy of each pair of concepts). In this paper, we propose a method to improve the retrieval and classification performance of documents from different sources by means of concept graph. In our method, some features are initially selected from a training set by applying a well-known feature selection algorithm. Then, by injecting suggested relevant words for each class from the concept graph, a more enriched feature set is produced to apply to the test set. Our experimental results exhibit an improvement of 14.6% and 18.4% (few and more term injection evaluations, respectfully) in classification and also some improvements in retrieval performance.","","Electronic:978-0-7695-4152-5; POD:978-1-4244-7963-4","10.1109/ICIIC.2010.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571516","Concept Graph;Feature Selection;Information Retrieval;Naïve;supervised WSD","Classification algorithms;Context;Feature extraction;Indexing;Support vector machine classification;Text categorization;Training","document handling;graph theory;information retrieval;natural language processing","classification performance;concept graph;document retrieval;feature selection;natural language processing;supervised WSD;weighted graph;word sense disambiguation","","2","","20","","","5-7 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Visual Backchannel for Large-Scale Events","M. Dörk; D. Gruen; C. Williamson; S. Carpendale","","IEEE Transactions on Visualization and Computer Graphics","20101028","2010","16","6","1129","1138","We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.","1077-2626;10772626","","10.1109/TVCG.2010.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5613451","World Wide Web;backchannel;events;information retrieval;information visualization;microblogging;multiple views","Context;Data visualization;Real time systems;Shape;Streaming media;Twitter;Visualization","data visualisation;information filtering;interactive systems;social networking (online)","People Spiral;Topic Streams;Twitter;Web-based coordinated-view system;cross-filtering;data visualization;digital backchannel;graph visualization;image cloud encoding;information retrieval;information stream visualization;interactive visual overview;large-scale event;microblogging community;multifaceted visual overview;natural disaster;online conversation;political speech;sport competition;visual backchannel;visual saliency","","57","1","43","","","Nov.-Dec. 2010","","IEEE","IEEE Journals & Magazines"
"The Design and Implement of Personal Information System","T. Shao; D. Shang","Dept. of Inf. Technol., Shanxi Agric. Vocational Technol. Coll., Yun Cheng, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","1631","1633","Nowadays the information on the Internet is increasing rapidly and being updated in real time. How to acquire the information you need quickly and accurately is a primary research topic. According to the defect of current search engines, this paper presents a model of personal information, to improve examining allowing rate of information search and to perfect mutual function between users. This paper gives a working principle of the model and discuss abstract technology of the model.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5592709","Information retrieval;Intelligence Agent;Interesting model;Personalizing","Information systems;Internet;Natural languages;Search engines;Training;User interfaces","Internet;information systems;search engines","Internet;information search;personal information system;search engines","","0","","3","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Research on similarity of Semantic Web","Hongsheng Wang; Xiaoguang Han","Shenyang University of Technology, School of Information Science and Engineering, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","20101104","2010","2","","V2-166","V2-169","With the rapid increasing of information on Internet and the emergence of the Semantic Web technology, information retrieval based on the Semantic Web has become a researching focus. In the semantic retrieval, the calculating method of semantic similarity is very important to information recall and precision ratio, this paper presents a new calculating method of semantic similarity by improving the flaw of traditional calculating method. The method adopts a directed graph to establish the Semantic Web and calculating the similarity of semantic nodes and semantic relations, then combine them to form the unified semantic similarity values. The analysis of the semantic retrieval and the statistics of the results indicate that this method can get higher recall and precision ratio than traditional method.","2161-9069;21619069","Electronic:978-1-4244-7237-6; POD:978-1-4244-7235-2","10.1109/ICCASM.2010.5619057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5619057","Information Retrieval;Semantic Web;Semantic similarity","Artificial neural networks;Companies;Semantics","directed graphs;information retrieval;semantic Web","Internet;directed graph;information retrieval;semantic Web similarity;semantic nodes;semantic relations;semantic retrieval","","0","","5","","","22-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"AllCall: An automated call for paper information extractor","F. L. Correia; R. F. S. Amaro; L. Sarmento; R. J. F. Rossetti","Artificial Intelligence and Computer Science Laboratory (LIACC), Department of Electrical and Computer Engineering (DEEC)","5th Iberian Conference on Information Systems and Technologies","20100823","2010","","","1","4","The main objective of this paper is to describe a project named AllCall, created to help researchers organize their publication schedule. The technology herein presented intends to be able to automatically extract conference's relevant information - conference name, important dates, location, conference sites and topics - from emails and conveniently present it on a web interface. Differently from other tools, to the best of our knowledge no other application is able to do this sort of information extraction automatically. This paper reports on the first approach of the project and presents the results so far.","2166-0727;21660727","Electronic:978-989-96247-3-3; POD:978-1-4244-7227-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556595","AllCall;Call for Paper;Conference Deadline;E-mail Filtering;Information Retrieval;Search Engine","Data mining;Databases;Electronic mail;Error analysis;Humans;Information filters","electronic mail;information filtering;search engines","AllCall;Web interface;automated call;conference dates;conference deadline;conference location;conference name;conference relevant information;conference site;conference topic;email filtering;information extraction;information retrieval;paper information extractor;publication schedule;search engine","","0","","9","","","16-19 June 2010","","IEEE","IEEE Conference Publications"
"Focused web crawling: A framework for crawling of country based financial data","M. K. Dey; D. Shamanta; H. M. S. Chowdhury; K. E. U. Ahmed","Department of Computer Science & Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh","2010 2nd IEEE International Conference on Information and Financial Engineering","20101025","2010","","","409","412","Crawling the Web quickly and entirely is an expensive, unrealistic goal because of the required enormous amounts of hardware and network resources. But when only information about a predefined topic set is desired, a specialization of the aforementioned process called “focused crawling” is used. A focused crawler is an agent that targets a particular topic and visits and gathers only a relevant, narrow Web segment while trying not to waste resources on irrelevant material. Compared to the standard web search engines, focused crawlers yield good recall as well as good precision by restricting themselves to a limited domain. In this paper we will introduce the technique of focused crawling of country based financial data.","","Electronic:978-1-4244-6928-4; POD:978-1-4244-6927-7","10.1109/ICIFE.2010.5609387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609387","Crawler;Financial data;Focused Crawler;Information retrieval","Bandwidth;Computer science;Crawlers;Electronic mail;Instruction sets;Search engines;Web pages","Internet;financial data processing;information retrieval;search engines","Web search engine;country based financial data;focused Web crawling","","2","","9","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"An Information-Theoretic Foundation for the Measurement of Discrimination Information","D. Cai","University of Wolverhampton, Wolverhampton","IEEE Transactions on Knowledge and Data Engineering","20100723","2010","22","9","1262","1273","Hitherto, it has not been easy to interpret the meaning of the amount of discrimination information conveyed in a term rationally and explicitly within practical application contexts; it has not been simple to introduce the concept of the extent of semantic relatedness between two terms meaningfully and successfully into scientific discussions. This study is part of an attempt to do this. We attempt to answer two important questions: (1) What is the discrimination information conveyed by a term and how to measure it? (2) What is the relatedness between two terms and how to estimate it? We focus on the first question and present an in-depth investigation into the discrimination measures based on several information measures, which are widely used in a variety of applications. The relatedness measures are then naturally defined according to the individual discrimination measures. Some key points are made for clarifying potential problems arising from using the relatedness measures, and solutions are suggested. Two example applications in the contexts of text mining and information retrieval are provided. The aim of this study, of which this paper forms part, is to establish a unified theoretical framework, with measurement of discrimination information (MDI) at the core, for achieving effective measurement of semantic relatedness (MSR). Due to its generality, our method can be expected to be a useful tool with a wide range of application areas.","1041-4347;10414347","","10.1109/TKDE.2009.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5066968","Statistical semantic analysis;information retrieval.;informative term identification;key term extraction;measurement of discrimination information;measurement of semantic relatedness;text mining","","data mining;information retrieval;statistical analysis","discrimination information measurement;information retrieval;information theoretic foundation;semantic relatedness measurement;text mining;unified theoretical framework","","6","","44","","20090605","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Web-Oriented Book Domain Metadata Description Research","H. Guo; J. Chen; T. Guo","Coll. of Comput. & Software, Taiyuan Univ. of Technol., Taiyuan, China","2010 International Conference on Intelligent Computing and Cognitive Informatics","20100907","2010","","","54","57","Web-oriented book domain metadata description criterion is built for the quest of book domain ontology design. We choose web as our data resource. Considering the different role of book information resource in different resource Website and combing book information metadata standard in existence, we build the Web-oriented book domain metadata description criterion. The paper is supported by science and technology department of shanxi province international cooperation and exchange project ”China-Japan Cooperation Research on Chinese Intelligent Interactive Question and Answer System Based on Web ” (Grant No.2009g18).","","Electronic:978-1-4244-6641-2; POD:978-1-4244-6640-5","10.1109/ICICCI.2010.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566039","Dublin Core ElementSet;Information Retrieval;Machine Readable Catalogue;Metadata;Ontology","Books;Libraries;OWL;Ontologies;Resource description framework;Thesauri","Web sites;meta data","China-Japan Cooperation Research;Chinese Intelligent Interactive Question and Answer System;Shanxi province international cooperation;Web oriented book domain;Website;data resource;metadata description;science and technology department","","0","1","7","","","22-23 June 2010","","IEEE","IEEE Conference Publications"
"Improving Collaborative Filtering in Social Tagging Systems for the Recommendation of Scientific Articles","D. Parra-Santander; P. Brusilovsky","Sch. of Inf. Sci., Univ. of Pittsburgh, Pittsburgh, PA, USA","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","136","142","Social tagging systems pose new challenges to developers of recommender systems. As observed by recent research, traditional implementations of classic recommender approaches, such as collaborative filtering, are not working well in this new context. To address these challenges, a number of research groups worldwide work on adapting these approaches to the specific nature of social tagging systems. In joining this stream of research, we have developed and evaluated two enhancements of user-based collaborative filtering algorithms to provide recommendations of articles on Cite ULike, a social tagging service for scientific articles. The result obtained after two phases of evaluation suggests that both enhancements are beneficial. Incorporating the number of raters into the algorithms, as we do in our NwCF approach, leads to an improvement of precision, while tag-based BM25 similarity measure, an alternative to Pearson correlation for calculating the similarity between users and their neighbors, increases the coverage of the recommendation process.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.261","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616221","collaborative filtering;information retrieval;recommender systems;social tagging","","correlation methods;groupware;information filtering;recommender systems;scientific information systems;social networking (online)","Pearson correlation;collaborative filtering;recommender system;social tagging system;tag based BM25 similarity measure;user based collaborative filtering algorithm","","4","","21","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"The Networked Environment for Music Analysis (NEMA)","K. West; A. Kumar; A. Shirk; G. Zhu; J. S. Downie; A. Ehmann; M. Bay","Widget Works Ltd., Halesworth, UK","2010 6th World Congress on Services","20100916","2010","","","314","317","Conducting valid comparative evaluations of techniques in the field of Music Information Retrieval (MIR)presents particular challenges to MIR researchers due to issues of copyright and data sharing. Further, the interdisciplinary nature of MIR research and multi-faceted nature of human music perception make the sharing and reuse of techniques and implementations for particular facets of music perception and music information retrieval tasks highly desirable. In addition the field makes use of a diverse range of file formats, software environments and toolkits for extracting, encoding and accessing MIR data and services, making reuse extremely challenging. The NEMA project aims to provide the MIR field with a high-quality, secure and extensible workflow environment to facilitate: computation over remote audio and resource collections; optimal code reuse, interoperability between data formats and types, sharing and dissemination; standardised, high-quality evaluation procedures; and the encoding of metadata, data and results in a format suitable for distributed systems.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575855","Conten Repository;Music Information Retrieval;RMI;Remote Process Execution;Workflow","Communities;Data models;Encoding;Java;Libraries;Music information retrieval;Software","copyright;information analysis;information retrieval;multimedia computing;music;open systems","comparative evaluation;copyright issues;data sharing;high-quality evaluation procedure;human music perception;interoperability;music analysis;music information retrieval;networked environment;optimal code reuse","","4","","12","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Contextualized question answering","L. Bradeško; L. Dali; B. Fortuna; M. Grobelnik; D. Mladenić; I. Novalija; B. Pajntar","Jo&#x017E;ef Stefan Institute, Jamova 39, 1000 Ljubljana, Slovenia","Proceedings of the ITI 2010, 32nd International Conference on Information Technology Interfaces","20100812","2010","","","73","78","The paper proposes an approach to contextualized answering of questions. The contextualization is achieved by using an ontology. The answers are provided based on a domain specific document collection. The approach consists of several phases as follows: data preparation, data enhancement, data indexing and handling questions. The functioning of the proposed approach is demonstrated on English document collections on Aquatic Sciences and Fisheries - ASFA, using Cyc ontology, ASFA thesaurus as domain specific ontology and WordNet as general ontology. The approach is in general applicable to other datasets in other languages, assuming the necessary natural language processing is handled and the match between the document collection language, domain ontology language and Cyc ontology is ensured.","1330-1012;13301012","Electronic:978-1-4244-5733-5; POD:978-1-4244-5732-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546368","contextualized information retrieval;ontology;question answering","Data mining;Indexing;Natural languages;Ontologies;Semantics;Thesauri","data preparation;document handling;indexing;natural language processing;ontologies (artificial intelligence)","ASFA thesaurus;Cyc ontology;English document collections;WordNet;aquatic sciences and fisheries;contextualized question answering;data enhancement;data handling;data indexing;data preparation;datasets;domain specific document collection;domain specific ontology;natural language processing","","0","","6","","","21-24 June 2010","","IEEE","IEEE Conference Publications"
"An efficient approach for sentence-based opinion retrieval","B. Y. Li; L. J. Zhou; S. Feng; K. F. Wong","Department of Systems Engineering & Engineering Management, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3281","3286","Recently, there is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. Therefore, opinion retrieval, which targets to retrieve documents expressing opinions or comments about the query, has become more and more popular. A typical method for opinion retrieval is document-based and each document is assigned a relevant score and an opinionated score, respectively. Then the documents are ranking based on a combination of the two scores. In this method, however, the document is split into bag-of-word, and the association between the opinion and its corresponding target is broken. In an extreme case, a relevant document full of irrelevant opinions will also be retrieved. In this paper, we propose a sentence-based approach since opinions are always expressed in one sentence where the association between an opinion and its corresponding target is maintained. We assign an individual score to each sentence rather than assign an overall score to the document directly. Moreover, we consider the effectiveness of different positions of sentences in documents to further capture the structural information. Compared with document-based approaches, experimental results on our own dataset show that our approach has achieved significant improvement.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580697","bag-of-word;information retrieval;opinion retrieval;opinion target","Artificial intelligence","document handling;information retrieval","World Wide Web;bag-of-word;document-based;economic analysis;personal opinion sharing;political polls;product reviews;sentence-based opinion retrieval","","1","","17","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Incorporating Seasonality into Search Suggestions Derived from Intranet Query Logs","S. Dignum; U. Kruschwitz; M. Fasli; Y. Kim; D. Song; U. C. Beresi; A. de Roeck","Sch. of Comput. Sci. & Electron. Eng., Univ. of Essex, Colchester, UK","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","425","430","While much research has been performed on query logs collected for major Web search engines, query log analysis to enhance search on smaller and more focused collections has attracted less attention. Our hypothesis is that an intranet search engine can be enhanced by adapting the search system to real users' search behaviour through exploiting its query logs. In this work we describe how a constantly adapting domain model can be used to identify and capture changes in intranet users' search requirements over time. We employ an algorithm that dynamically builds a domain model from query modifications taken from an intranet query log and employs a decay measure, as used in Machine Learning and Optimisation methods, to promote more recent terms. This model is used to suggest query refinements and additions to users and to elevate seasonally relevant terms. A user evaluation using models constructed from a substantial university intranet query log is provided. Statistical evidence demonstrates the system's ability to suggest seasonally relevant terms over three different academic trimesters. We conclude that log files of an intranet search engine are a rich resource to build adaptive domain models, and in our experiments these models significantly outperform sensible baselines.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616635","adaptive domain models;ant colony optimisation;information retrieval;interactive search;intranet search;local Web search","","intranets;learning (artificial intelligence);optimisation;query processing;search engines;user interfaces","Web search engines;decay measurement;intranet query logs;machine learning;optimisation methods;query log analysis;query refinements;search suggestions;user evaluation","","4","2","25","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"On Using Query Logs for Static Index Pruning","H. T. Lam; R. Perego; F. Silvestri","Dept. of Math. & Comput. Sci., Tech. Univ. Eindhoven, Eindhovein, Netherlands","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","167","170","Static index pruning techniques aim at removing from the posting lists of an inverted file the references to documents which are likely to be not relevant for answering user queries. The reduction in the size of the index results in a better exploitation of memory hierarchies and faster query processing. On the other hand, pruning may affect the precision of the information retrieval system, since pruned entries are unavailable at query processing time. Static pruning techniques proposed so far exploit query-independent measures to evaluate the importance of a document within a posting list. This paper proposes a general framework that aims at enhancing the precision of any static pruning methods by exploiting usage information extracted from query logs. Experiments conducted on the TREC WT10g Web collection and a large Altavista query log show that integrating usage knowledge into the pruning process is profitable, and increases remarkably performance figures obtained with the state-of-the art Carmel's static pruning method.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616239","Inverted index;information retrieval;query log;static pruning","","indexing;query processing","Altavista query log;TREC WTlOg Web collection;information extraction;information retrieval system;inverted file;memory hierarchies;query answering;query processing;query-independent measures;static index pruning","","2","","8","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"An evaluation of Lucene for keywords search in large-scale short text storage","L. Qian; L. Wang","Dept. of Computer, Beijing University of Civil Engineering and Architecture, China","2010 International Conference On Computer Design and Applications","20100809","2010","2","","V2-206","V2-209","Some popular Internet applications such as instant message, blog, twitter and Google buzz generate huge data of short text. These data can then be summarized, mined, and queried by other applications. To this end, suitable storage design with outstanding performance must be offered to address the question of real-time full text indexing and searching. This paper studies Lucene indexing and searching performance for short-text. It gives a comparison test between Lucene and Oracle Text, and then presents performance factors of Lucene for short text search. The experimental results show that Lucene can meets the needs and is far superior to Oracle Text in this typical scenario.","","Electronic:978-1-4244-7164-5; POD:978-1-4244-7162-1","10.1109/ICCDA.2010.5541219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5541219","information retrieval;lucene;search;short text","Application software;Computer networks;Electronic mail;Indexing;Information services;Internet;Keyword search;Large-scale systems;Relational databases;Web sites","Internet;indexing;information retrieval","Google buzz;Internet application;Lucene indexing;Oracle text;blog;instant message;keywords search;large-scale short text storage;twitter","","4","","6","","","25-27 June 2010","","IEEE","IEEE Conference Publications"
"Scale Transform in Rhythmic Similarity of Music","A. Holzapfel; Y. Stylianou","Computer Science Department, Multimedia Informatics Lab, Institute of Computer Science, FORTH, and University of Crete, Heraklion Crete, Greece","IEEE Transactions on Audio, Speech, and Language Processing","20101004","2011","19","1","176","185","As a special case of the Mellin transform, the scale transform has been applied in various signal processing areas, in order to get a signal description that is invariant to scale changes. In this paper, the scale transform is applied to autocorrelation sequences derived from music signals. It is shown that two such sequences, when derived from similar rhythms with different tempo, differ mainly by a scaling factor. By using the scale transform, the proposed descriptors are robust to tempo changes, and are specially suited for the comparison of pieces with different tempi but similar rhythm. As music with such characteristics is widely encountered in traditional forms of music, the performance of the descriptors in a classification task of Greek traditional dances and Turkish traditional songs is evaluated. On these datasets accuracies compared to non-tempo robust approaches are improved by more than 20%, while on a dataset of Western music the achieved accuracy improves compared to previously presented results.","1558-7916;15587916","","10.1109/TASL.2010.2045782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5430891","Computational ethnomusicology;music information retrieval (MIR);rhythmic similarity;scale transform","Autocorrelation;Computer science;Histograms;Multiple signal classification;Music information retrieval;Rhythm;Robustness;Signal processing;Speech;Time measurement","audio signal processing;correlation methods;music;transforms","Mellin transform;autocorrelation sequences;music;rhythmic similarity;scale transform","","6","","36","","20100315","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"Determining Relevant Product Information Sources","M. Wauer","Dept. of Comput. Networks, Tech. Univ. Dresden, Dresden, Germany","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","3","","444","447","This position paper describes the challenges related to federated enterprise search over heterogeneous product information sources. It focuses on the aspect of finding relevant information sources w.r.t. the user's information need and identifies core research questions with regards to the design and implementation of a potential solution, based on Semantic Web techniques.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.266","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614150","distributed information retrieval;federated information systems;ontologies;resource selection","Indexes;Ontologies;Semantic Web;Semantics;Taxonomy","information retrieval;semantic Web","I;federated enterprise search;heterogeneous product information sources;semantic Web techniques","","0","","15","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Direct Optimization of Evaluation Measures in Learning to Rank Using Particle Swarm","O. Alejo; J. M. Fernandez-Luna; J. F. Huete; R. Perez-Vazquez","Informatic Fac., Univ. of Cienfuegos Cienfuegos, Cienfuegos, Cuba","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","42","46","One of the central issues in Learning to Rank (L2R) for Information Retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in IR such as Precision at n, Mean Average Precision and Normalized Discounted Cumulative Gain. In this work we propose a new learning-to-rank method, referred as RankPSO. This algorithm is based on Particle Swarm Optimization. It builds a ranking model able to directly optimize evaluation measures used in Information Retrieval. To evaluate performance of RankPSO, we have compared it with other methods referenced in literature. We have carried out an experimental study using Letor OHSUMED dataset. The obtained results were analyzed statistically, demonstrating that RankPSO has significant improvement in precision compared to RankSVM, RankBoost and Regression methods; nevertheless, it does not have significant differences with AdaRank-MAP, AdaRank-NDCG, ListNet and FRank. The results show the advantages to use Particle Swarm Optimization as bio-inspired algorithm for learning to rank.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591994","Information Retrieval;Learning to Rank;Particle Swarm Optimization","Atmospheric measurements;Loss measurement;Machine learning;Optimization;Particle measurements;Particle swarm optimization;Position measurement","information retrieval;learning (artificial intelligence);particle swarm optimisation;regression analysis;support vector machines","Letor OHSUMED dataset;RankBoost;RankPSO;RankSVM;bio-inspired algorithm;evaluation measures;information retrieval;learning-to-rank method;mean average precision;normalized discounted cumulative gain;particle swarm optimization;regression methods","","1","","17","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Organization of Information for the Web Using Hierarchical Fuzzy Clustering Algorithm Based on Co-occurrence Networks","F. Zaidi; G. Melancon","LaBRI, INRIA Bordeaux Sud-Ouest, Bordeaux, France","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","421","424","In this paper, we present a Hierarchical Fuzzy Clustering algorithm which uses domain knowledge to automatically determine the number of clusters and their initial values. The algorithm is applied on a collection of web pages and the results are compared with existing algorithms in the literature.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616626","Fuzzy and Hierarchical Clustering;Information Retrieval;Web Mining","","Internet;data mining;fuzzy set theory;information retrieval;organisational aspects;pattern clustering","Web mining;Web page collection;co-occurrence networks;hierarchical fuzzy clustering algorithm;information retrieval","","1","","13","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Ranking Metrics and Search Guidance for Learning Object Repository","N. Y. Yen; T. K. Shih; L. R. Chao; Q. Jin","Waseda University, Japan","IEEE Transactions on Learning Technologies","20100909","2010","3","3","250","264","In line with the popularity of the Internet and the development of search engine, users request information through web-based services. Although general-purpose searching such as one provided by Google is powerful, searching mechanism for specific purposes could rely on metadata. In distance learning (or e-learning), SCORM provides an efficient metadata definition for learning objects to be searched and shared. To facilitate searching in a federated repository, CORDRA provides a common architecture for discovering and sharing Learning Objects. We followed SCORM and CORDRA specifications to develop a registry system, called the MINE Registry, for storing and sharing 20,738 Learning Objects created in the past five years. As a contribution, we propose the concept of “Reusability Tree” to represent the relationships among relevant Learning Objects and enhance CORDRA. We further collect relevant information, while users are utilizing Learning Objects, such as citations and time period persisted. The feedbacks from the user community are also considered as critical elements for evaluating significance degree of Learning Objects. Through theses factors, we propose a mechanism to weight and rank Learning Objects in the MINE Registry, in addition to other external learning objects repositories. As a practical contribution, we provide a tool called “Search Guider” to assist users in finding relevant information in Learning Objects based on individual requirements.","1939-1382;19391382","","10.1109/TLT.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5518759","CORDRA;LOM;distance learning.;information retrieval;learning object repository;ranking metrics;reusability tree;search guidance;social feedback","Computer aided instruction;Computer architecture;Data mining;Data models;Measurement;Search problems;Time series analysis","distance learning;information storage;meta data;search engines;tree data structures","CORDRA;MINE registry;SCORM;Search Guider;distance learning;information collection;learning object repository;learning object sharing;metadata;ranking metrics;registry system;reusability tree;search guidance;web-based services","","19","","48","","20100723","July-Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Physical and conceptual identifier dispersion: Measures and relation to fault proneness","V. Arnaoudova; L. Eshkevari; R. Oliveto; Y. G. Guéhéneuc; G. Antoniol","SOCCER Lab. - DGIGL, &#x00C9;cole Polytechnique de Montr&#x00E9;al, Qu&#x00E9;bec, Canada","2010 IEEE International Conference on Software Maintenance","20101025","2010","","","1","5","Poorly-chosen identifiers have been reported in the literature as misleading and increasing the program comprehension effort. Identifiers are composed of terms, which can be dictionary words, acronyms, contractions, or simple strings. We conjecture that the use of identical terms in different contexts may increase the risk of faults. We investigate our conjecture using a measure combining term entropy and term context coverage to study whether certain terms increase the odds ratios of methods to be fault-prone. Entropy measures the physical dispersion of terms in a program: the higher the entropy, the more scattered across the program the terms. Context coverage measures the conceptual dispersion of terms: the higher their context coverage, the more unrelated the methods using them. We compute term entropy and context coverage of terms extracted from identifiers in Rhino 1.4R3 and ArgoUML 0.16. We show statistically that methods containing terms with high entropy and context coverage are more fault-prone than others.","1063-6773;10636773","Electronic:978-1-4244-8629-8; POD:978-1-4244-8630-4; USB:978-1-4244-8628-1","10.1109/ICSM.2010.5609748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5609748","Entropy;Fault Models;Information Retrieval;Program Comprehension;Source Code Identifiers","Conferences;Context;Correlation;Entropy;Measurement;Presses;Software engineering","Unified Modeling Language;entropy;software fault tolerance;software metrics;statistical analysis","ArgoUML 0.16;Rhino 1.4R3;conceptual identifier dispersion;fault proneness;physical identifier dispersion;program comprehension;term context coverage;term entropy","","7","","28","","","12-18 Sept. 2010","","IEEE","IEEE Conference Publications"
"Interactive Search Interfaces for Young Children - The PuppyIR Approach","A. Lingnau; I. Ruthven; M. Landoni; F. van der Sluis","Dept. of Comput. & Inf. Sci., Univ. of Strathclyde, Glasgow, UK","2010 10th IEEE International Conference on Advanced Learning Technologies","20100916","2010","","","389","390","Finding and understanding information is key for children's development. The Internet offers exciting new ways to meet people, learn about different cultures and develop their creative potential. However, children's ability to use the Internet is severely hampered by the lack of appropriate search tools. Most Information Retrieval (IR) systems are designed for adults and unsuitable for children. In this paper we present an approach to provide appropriate IR interfaces for children.","2161-3761;21613761","Electronic:978-1-4244-7145-4; POD:978-1-4244-7144-7","10.1109/ICALT.2010.111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571401","Information retrieval;collaboration;multimodal interfaces;technology enhanced learning","Collaboration;Computers;Internet;Libraries;Pediatrics;Software;Vocabulary","Internet;computer aided instruction;information retrieval;interactive systems;user interfaces","Internet;PuppylR approach;creative potential;information retrieval system;interactive search interface;young children","","0","","10","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"Searching Protein 3-D Structures for Optimal Structure Alignment Using Intelligent Algorithms and Data Structures","T. Novosád; V. Snášel; A. Abraham; J. Y. Yang","Dept. of Comput. Sci., Vysoka Skola Banska-Tech. Univ. of Ostrava, Ostrava, Czech Republic","IEEE Transactions on Information Technology in Biomedicine","20101104","2010","14","6","1378","1386","In this paper, we present a novel algorithm for measuring protein similarity based on their 3-D structure (protein tertiary structure). The algorithm used a suffix tree for discovering common parts of main chains of all proteins appearing in the current research collaboratory for structural bioinformatics protein data bank (PDB). By identifying these common parts, we build a vector model and use some classical information retrieval (IR) algorithms based on the vector model to measure the similarity between proteins - all to all protein similarity. For the calculation of protein similarity, we use term frequency inverse document frequency (tf × idf) term weighing schema and cosine similarity measure. The goal of this paper is to introduce new protein similarity metric based on suffix trees and IR methods. Whole current PDB database was used to demonstrate very good time complexity of the algorithm as well as high precision. We have chosen the structural classification of proteins (SCOP) database for verification of the precision of our algorithm because it is maintained primarily by humans. The next success of this paper would be the ability to determine SCOP categories of proteins not included in the latest version of the SCOP database (v. 1.75) with nearly 100% precision.","1089-7771;10897771","","10.1109/TITB.2010.2079939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5585764","Information retrieval (IR);proteins;similarity measure;structural classification of proteins (SCOP);suffix trees;vector model","Amino acids;Clustering algorithms;Data structures;Indexing;Information retrieval;Proteins","bioinformatics;information retrieval;pattern classification;proteins;proteomics;tree data structures;vectors","bioinformatics;cosine similarity measure;data structures;frequency inverse document frequency term weighing schema;information retrieval algorithms;intelligent algorithms;optimal structure alignment;protein 3-D structures;protein similarity;structural classification;vector model","Algorithms;Artificial Intelligence;Computational Biology;Data Mining;Databases, Protein;Humans;Protein Structure, Tertiary;Proteins;Reproducibility of Results;Structural Homology, Protein","4","","29","","20100927","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"Web Spam Detection: New Classification Features Based on Qualified Link Analysis and Language Models","L. Araujo; J. Martinez-Romo","NLP & IR Group, UNED, Madrid, Spain","IEEE Transactions on Information Forensics and Security","20100812","2010","5","3","581","590","Web spam is a serious problem for search engines because the quality of their results can be severely degraded by the presence of this kind of page. In this paper, we present an efficient spam detection system based on a classifier that combines new link-based features with language-model (LM)-based ones. These features are not only related to quantitative data extracted from the Web pages, but also to qualitative properties, mainly of the page links. We consider, for instance, the ability of a search engine to find, using information provided by the page for a given link, the page that the link actually points at. This can be regarded as indicative of the link reliability. We also check the coherence between a page and another one pointed at by any of its links. Two pages linked by a hyperlink should be semantically related, by at least a weak contextual relation. Thus, we apply an LM approach to different sources of information from a Web page that belongs to the context of a link, in order to provide high-quality indicators of Web spam. We have specifically applied the Kullback-Leibler divergence on different combinations of these sources of information in order to characterize the relationship between two linked pages. The result is a system that significantly improves the detection of Web spam using fewer features, on two large and public datasets SUchasWEBSPAM-UK2006 and WEBSPAM-UK2007.","1556-6013;15566013","","10.1109/TIFS.2010.2050767","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5475235","Content analysis;Web spam detection;information retrieval;language models (LMs);link integrity","Coherence;Computer vision;Context modeling;Data mining;Degradation;Information resources;Permission;Search engines;Unsolicited electronic mail;Web pages","Internet;information retrieval;pattern classification;search engines;unsolicited e-mail","Kullback-Leibler divergence;Web page;Web spam detection;hyperlink;language model;qualified link analysis;search engine","","9","","23","","20100601","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Design and Implementation of Amharic Search Engine","T. Mindaye; S. Atnafu","Dept. of Comput. Sci., Addis Ababa Univ., Addis Ababa, Ethiopia","2009 Fifth International Conference on Signal Image Technology and Internet Based Systems","20101111","2009","","","318","325","The Web is a huge repository of information in the form of text, image, audio, and video. People use search engines, such as Google, Yahoo!, etc, to discover resources from this huge repository. These general purpose search engines are designed and optimized for English language. They fell short when they are used for locating web resources of other languages such as Amharic. This is mainly due to the specific features of the language that are not considered by those search engines. Amharic, which is a family of Semitic languages, is the official language of the federal government of Ethiopia. Currently, there are significant number of Amharic documents on the Web. In this study, an attempt is made to design and implement a search engine for Amharic language web documents. The research came up with a complete language specific search engine that has a crawler, an indexer, and a query engine component that are optimized for the language they are designed, Amharic language.","","Electronic:978-1-4244-5741-0; POD:978-1-4244-5740-3; USB:978-0-7695-3959-1","10.1109/SITIS.2009.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5633974","Amharic Language;Amharic Search engine;Amharic crawler;Web Information Retrieval","Crawlers;Encoding;Engines;Indexes;Search engines;Web pages;Writing","Internet;document handling;natural language processing;query processing;search engines","Amharic language Web documents;Amharic search engine;Ethiopia;Google;Semitic languages;Web resources;Yahoo!;crawler;indexer;information repository;language specific search engine;query engine component","","0","","17","","","Nov. 29 2009-Dec. 4 2009","","IEEE","IEEE Conference Publications"
"Efficient high-dimensional retrieval in structured P2P networks","L. Zhang; Z. Wang; D. Feng","School of Information Technologies, University of Sydney, NSW 2006 Australia","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","1439","1444","Known by its exceptional scalability and flexibility, Peer-to-peer (P2P) technique is arguably one of the most important mechanisms for sharing massive data (e.g. media data). It has been challenging to support similarity search in structured P2P networks, though it provides efficient indexing for exact search. In this paper, we present an efficient indexing technique to support complex similarity retrieval on high-dimensional data by improving existing approach Multi-dimensional Rectangulation with Kd-trees (MURK). In order to make search more user-centric, relevance feedback techniques are also investigated. To the best of our knowledge, it is the first attempt of utilizing relevance feedback in structured P2P networks. Simulations for content based music retrieval with multiple acoustic features have been conducted to investigate the properties and efficiency of the proposed approach.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5582934","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582934","High dimensional indexing and retrieval;Music Information Retrieval;Relevance feedback;Structured Peer-to-Peer networks","Indexing;Load management;Mel frequency cepstral coefficient;Music;Peer to peer computing;Radio frequency;Routing","indexing;peer-to-peer computing;relevance feedback;search problems;trees (mathematics)","Kd-tree;P2P network;complex similarity retrieval;indexing technique;multidimensional rectangulation;peer-to-peer;relevance feedback;similarity search;user-centric search technique","","1","","21","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"Semantic Relation Extraction by Analysis of Terms Correlation in Documents","S. W. Botero; I. L. M. Ricarte","Dept. de Eng. de Comput. e Automacao Ind., Univ. Estadual de Campinas (UNICAMP), Campinas, Brazil","2009 Seventh Brazilian Symposium in Information and Human Language Technology","20100729","2009","","","17","26","Ontologies are important to organize and describe information, but are hard to create and maintain, which motivates the development of tools to help in this task. This article presents a strategy to extract, from a corpora of documents in a given domain, semantic elements expressing proximity relations between terms and concepts to help the construction of domain ontologies. The technique presented here, ACT, is based on linguistic processing, machine learning, and biclustering. Results show that concepts obtained by ACT are at least as good as those from similar techniques, such as LSI and NMF. In relation to those techniques, it additionally has the advantage of allowing the supervision by a domain expert.","","Electronic:978-1-4244-6009-0; POD:978-1-4244-6008-3","10.1109/STIL.2009.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5532434","Information retrieval;Information retrieval system;Ontology;Semantic;Text Processing(Computation)","Computer industry;Data mining;Humans;Indexing;Large scale integration;Machine learning;Matrix decomposition;Ontologies;Single event transient","","","","0","","13","","","8-11 Sept. 2009","","IEEE","IEEE Conference Publications"
"Semantic search in digital library semantic technology","N. A. Osman; S. A. M. Noah; N. Omar","Knowledge Technology Research Group Faculty of Information Science & Technology Universiti Kebangsaan Malaysia Selangor, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1504","1507","Semantic search tries to concentrate on the boundaries of text search by performing search in a conceptual space, based on disambiguated concepts rather than exact words, and by exploiting semantic networks of concepts underlying the texts. This paper discusses an on-going research project in developing a semantic digital library in academic institution. It provides another view of semantic information retrieval for a digital library from the perspective of semantic technology. It then proposes a semantic indexing and retrieval approach which includes an ontology based information retrieval framework. The proposed ontology based retrieval model will be based on an adaptation of the classic vector space model, which includes document annotation, weighting and concept-based ranking algorithm.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561476","Information Retrieval;Ontology;Semantic Search","","digital libraries;information retrieval;ontologies (artificial intelligence)","concept-based ranking algorithm;digital library;document annotation;information retrieval;semantic indexing;semantic search;text search;vector space model;weighting","","0","","9","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Automarking: Automatic Assessment of Open Questions","L. A. Cutrone; M. Chang","Sch. of Comput. & Inf. Syst., Athabasca Univ., Athabasca, SK, Canada","2010 10th IEEE International Conference on Advanced Learning Technologies","20100916","2010","","","143","147","A number of Learning Management Systems (LMSs) exist on the market today. A subset of a LMS is the component in which student assessment is managed. In some forms of assessment, such as open questions, the LMS is incapable of evaluating the students' responses and therefore human intervention is necessary. In order to assess at higher levels of Bloom's (1956) taxonomy, it is necessary to include open-style questions in which the student is given the task as well as the freedom to arrive at a response without the comfort of recall words and/or phrases. Automating the assessment process of open questions is an area of research that has been ongoing since the 1960s. Earlier work focused on statistical or probabilistic approaches based primarily on conceptual understanding. Recent gains in Natural Language Processing have resulted in a shift in the way in which free text can be evaluated. This has allowed for a more linguistic approach which focuses heavily on factual understanding. This study will leverage the research conducted in recent studies in the area of Natural Language Processing, Information Extraction and Information Retrieval in order to provide a fair, timely and accurate assessment of student responses to open questions based on the semantic meaning of those responses.","2161-3761;21613761","Electronic:978-1-4244-7145-4; POD:978-1-4244-7144-7","10.1109/ICALT.2010.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571204","Computerized Grading;Information Retrieval;Natural Language Processing;Open Question;Part of Speech Tagging;Semantic Meaning;WordNet","Data mining;Humans;Natural language processing;Semantics;Speech;Tagging","computer aided instruction;information retrieval;learning systems;natural language processing;probability;statistical analysis","Bloom's taxonomy;LMS;automarking;automatic assessment;conceptual understanding;free text;human intervention;information extraction;information retrieval;learning management systems;linguistic approach;natural language processing;open questions;open-style questions;probabilistic approaches;statistical approaches;student assessment","","4","","24","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"Automatic Ontology Constructor for Indonesian Language","G. Virginia; N. H. Son","Fac. of Math., Inf., & Mech., Univ. of Warsaw, Warsaw, Poland","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","3","","440","443","Rich information is scattered under Indonesian Choral Lovers (ICL) mailing list and many of its members prefer posting a query-mail to using the available search engine. A text retrieval system based on ontology is then proposed. However, considering the continual number of emails, developing an automatic ontology constructor (OC) will be the focus of the study while the retrieval system becomes an evaluation tool of the OC developed. Besides using 3,000 emails of ICL as the corpus, this study is challenging for it takes a cognitive approach as the heart of the process and employs Linear Model known in Expert System field as the system life cycle. The effectiveness of OC will be determined based on the automatic-thesaurus effectiveness. Performance measure of information retrieval is going to be computed in technical evaluation while qualitative measures of ontology (consistency, completeness, and conciseness) are going to be used in user's evaluation.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5614110","Ontology;information retrieval system;thesaurus","Conferences;Electronic mail;Information retrieval;Natural languages;Ontologies;Semantics;Thesauri","cognitive systems;electronic mail;expert systems;natural language processing;ontologies (artificial intelligence);query processing;search engines;text analysis;thesauri","Indonesian Choral Lover mailing list;Indonesian language;automatic ontology constructor;automatic thesaurus effectiveness;cognitive approach;expert system;information retrieval;linear model;query mail;search engine;system life cycle;text retrieval system","","2","","17","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Ranking Approaches for Microblog Search","R. Nagmoti; A. Teredesai; M. De Cock","Inst. of Technol., Univ. of Washington, Tacoma, WA, USA","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","153","157","Ranking microblogs, such as tweets, as search results for a query is challenging, among other things because of the sheer amount of microblogs that are being generated in real time, as well as the short length of each individual microblog. In this paper, we describe several new strategies for ranking microblogs in a real-time search engine. Evaluating these ranking strategies is non-trivial due to the lack of a publicly available ground truth validation dataset. We have therefore developed a framework to obtain such validation data, as well as evaluation measures to assess the accuracy of the proposed ranking strategies. Our experiments demonstrate that it is beneficial for microblog search engines to take into account social network properties of the authors of microblogs in addition to properties of the microblog itself.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616236","authority;evaluation;information retrieval;microblog;online social network;ranking;web search","","search engines;social networking (online)","microblog search;ranking approach;ranking strategies;real-time search engine;social network properties;tweets;validation data","","19","","8","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Semantically Enriched Recommender Engine: A Novel Collaborative Filtering Approach Using ""User-to-User Fast Xor Bit Operation""","L. Zhuhadar; O. Nasraoui; R. Wyatt","Dept. of Comput. Eng. & Comput. Sci., Univ. of Louisville, Louisville, KY, USA","2010 IEEE Fourth International Conference on Semantic Computing","20101111","2010","","","349","352","In this paper, we focus on Collaborative Filtering to provide recommendations to users that fit their profiles. We employed two methods: (1) K-Nearest Neighbors classifier, and (2) a fast implementation of Collaborative Filtering approach: “user-to-user fast XOR bit operation”. Both techniques serve the same objective, which is modifying the user's ontology profile (semantic profile). Technically, Collaborative Filtering extends the user's ontology profile based on the interests of a community of similar users. Also, we describe the implementation of the recommender system on a real platform, known as Hyper Many Media at Western Kentucky University. Finally, we evaluate the system based on Top-n-Recall and Top-n-Precision. The results show an improvement in Recall and Precision using Collaborative Filtering.","","Electronic:978-0-7695-4154-9; POD:978-1-4244-7912-2","10.1109/ICSC.2010.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629302","Collaborative Filtering;Information Retrieval;Recommender Search Engine;Semantic Web","Boosting;Collaboration;Data mining;Educational institutions;Filtering;Search engines;Semantics","groupware;information filtering;ontologies (artificial intelligence);recommender systems","K-nearest neighbor classifier;Top-n-Precision;Top-n-Recall;collaborative filtering;recommender engine;user-to-user fast XOR bit operation","","2","","14","","","22-24 Sept. 2010","","IEEE","IEEE Conference Publications"
"Features of a radial user interface to search engines","A. L. Kaczmarek","Faculty of Electronics, Telecommunications and Informatics, Gdansk University of Technology, ul. G. Narutowicza 11/12, 80-233 Gda&#x0144;sk, Poland","2010 2nd International Conference on Information Technology, (2010 ICIT)","20100823","2010","","","29","30","The paper is concerned with a new type of user interface to search engines. Instead of presenting search results in a form of a ranked list, the results are presented in radial arrangement. In the center of the interface the most relevant web page is presented. Other web pages are located around the central one. The location of a web page depends on two factors: its relevance to the query and its content. The relevance has influence on the pages' proximity to the center and the content determines the direction in which web pages are located. The proposed interface has many features which support users in exploring search results including keywords that inform about the subjects of the web pages located in different directions. The design of the interface borrows from Self Organizing Maps (SOM), however the interface has advantages of a typical ranked list.","","Electronic:978-83-60779-02-6; POD:978-1-4244-8182-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5553404","information retrieval;search engines;user interfece","","query processing;search engines;self-organising feature maps;user interfaces","interface design;page proximity;radial arrangement;radial user interface features;ranked list;search engines;search results;self organizing maps;web page","","0","","6","","","28-30 June 2010","","IEEE","IEEE Conference Publications"
"Study on question-answering system based on Meta search engine","Feijuan Li; Haiyan Kang; Yangsen Zhang; Wenjie Su","Computer School, Beijing Information Science & Technology University, Beijing, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","20101104","2010","3","","V3-354","V3-357","Meta search engine which can provide rich information is obviously an ideal source of answers to many types of questions. This paper describes a question answering system based on web, and puts forward to a new method to search information based on Meta search engine and new word discovery. In the information retrieval module, N-gram model and web pages which get from search engine are used to find new words. Experiments show that the addition of new words discovery not only greatly improves the precision of documents retrieval in the module of information retrieval, but also improves the accuracy of answer extraction.","2161-9069;21619069","Electronic:978-1-4244-7237-6; POD:978-1-4244-7235-2","10.1109/ICCASM.2010.5620229","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620229","Answer extraction;Information retrieval;Meta search engine;New word discovery;Question-Answering System","Educational institutions;Libraries","Internet;Web sites;information filters;information retrieval;search engines","Web pages;answer extraction;documents retrieval;information retrieval;meta search engine;question answering system;question-answering system;search information","","0","","7","","","22-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Experimental assessment of the TARGET adaptive ontology-based Web search framework","N. Guelfi; C. Pruski; C. Reynaud","LASSY - University of Luxembourg, Luxembourg","2010 10th Annual International Conference on New Technologies of Distributed Systems (NOTERE)","20100803","2010","","","297","302","Finding relevant information on the Web can be a complex task for most of the users. Although Web search applications are improving, they still need to be more intelligent to adapt to the search domain targeted by users, the evolution of this domain and users' characteristics. In this paper, we present an experimental assessment of the TARGET framework for improving the relevance of the documents when users are searching the Web by using adaptive ontologies. This is done first by introducing the TARGET approach. We will briefly present the used ontologies and their ability to adapt to domain evolution. Then, We detail the TARGET tool used in our experimentations. This includes its architecture, its ability to carry out the ontology adaptation process as well as the way it searches the Web and ranks the returned results. Finally, we discuss the results obtained using the tool through the presentation of our case study devoted to the retrieval of scientific articles.","2162-1896;21621896","Electronic:978-1-4244-7068-6; POD:978-1-4244-7067-9","10.1109/NOTERE.2010.5536622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5536622","Information retrieval;Ontology evolution;Semantic Search","Chromium;Graph theory;Information filtering;Information retrieval;Ontologies;Search engines;Service oriented architecture;Tree graphs;Web search;World Wide Web","","","","0","","12","","","May 31 2010-June 2 2010","","IEEE","IEEE Conference Publications"
"Improving AbraQ: An Automatic Query Expansion Algorithm","G. Robertson; X. Gao","Sch. of Eng. & Comput. Sci., Victoria Univ. of Wellington, Wellington, New Zealand","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","1","","653","656","Our previous research has developed AbraQ, an innovative automatic query expansion algorithm that automatically adds a term to a search query to improve the search results. AbraQ differs from other relevance feedback approaches in that it works independently of the quality of the original search result, which means it works well for hard search tasks when there are not any relevant documents retrieved for the original query. Our experiments showed that it significantly improved precision for hard search tasks with multi-aspect queries, while other query expansion techniques often improve recall with no positive effects on precision. This paper further introduces an improved version called AbraQ2, which changes the way in which aspect vocabularies are constructed, and introduces a new algorithm for automatic relevance judgments. Our experiments show that these improvements help to find better queries that return more relevant documents to the user.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616503","Information retrieval;Query aspects;Query expansion;Query formulation;Web search","","document handling;query processing;state feedback","automatic query expansion algorithm;automatic relevance judgments;feedback approaches;improving AbraQ;relevant documents retrieval","","0","","9","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"CRRA: A collaborative approach to re-ranking search results","Y. Liu","School of Computer Science and Technology, Henan Polytechnic University, Jiaozuo City, Henan Province, China &#x00B7;454000","2010 International Conference on Educational and Information Technology","20101025","2010","2","","V2-214","V2-218","Web search is not only an individual activity, but also a collaborative activity. By analyzing users' search activities at a community level, effectively refining the ranking of search results has received wide attention in information retrieval in recent years. Previous research has proposed approaches that predefined communities to search collaboratively. However, these approaches usually neglected correlation between users. In this study, we propose a novel collaborative approach (CRRA) for re-ranking search results based on user search activities recorded in query logs. The central idea is to establish correlations among three factors: user, query and document terms, by analyzing user logs. These correlations are then employed to determine community dynamically based on probability theory and collaborative filtering technique and calculate re-ranking score of search results. Evaluation results show that CRRA is more effective than other collaborative ranking approaches.","","Electronic:978-1-4244-8035-7; POD:978-1-4244-8033-3","10.1109/ICEIT.2010.5607556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607556","collaborative filtering;community;information retrieval;re-ranking search results","Communities","Internet;groupware;information filtering;probability;query processing;search engines","CRRA;Web search;collaborative filtering technique;probability theory;query log;re-ranking search","","0","","19","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"Enriching Descriptions for Public Web Services Using Information Captured from Related Web Pages on the Internet","L. Wang; F. Liu; L. Zhang; G. Li; B. Xie","Sch. of Electron. Eng. & Comput. Sci., Peking Univ., Beijing, China","2010 Fifth IEEE International Symposium on Service Oriented System Engineering","20100913","2010","","","141","150","With the popularization of Service-Oriented Computing (SOC) and web services technology, more and more developers have become accustomed to searching and utilizing the public web services on the Internet. In order to identify, understand, and utilize needed web services efficiently, service consumers need useful descriptions of the web services. However, existing methods for services discovery could not provide enough descriptions for web services, because they usually try to get descriptions only from services' WSDL files. But according to our investigation, currently a large number of web services do not contain enough available description information in their WSDL files. So, enriching descriptions for public web services using the information outside of WSDL files becomes a great challenge. In this paper, we propose an approach to enrich descriptions for public web services using the information captured from services' related web pages on the Internet. Using our approach, considerable descriptions for web services could be enriched. An experimental study based on the real data acquired from the Internet has been carried out to verify the applicability of our approach.","","Electronic:978-1-4244-7326-7; POD:978-1-4244-7327-4","10.1109/SOSE.2010.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569915","Web services description;information retrieval;services discovery;web services search engine","Data mining;Google;Image retrieval;Web pages;Web services","Web services;information retrieval;software engineering","Internet;WSDL file;Web page;information capture;public Web services;service consumer;service-oriented computing","","6","","14","","","4-5 June 2010","","IEEE","IEEE Conference Publications"
"Improving Information Retieval by Modelling Business Context","H. Chaker; M. Chevalier; C. Soule-Dupuy; A. Tricot","IRIT/D2S2, Univ. Paul Sabatier, Toulouse, France","2010 Third International Conference on Advances in Human-Oriented and Personalized Mechanisms, Technologies and Services","20101014","2010","","","117","122","Retrieving information is a central operation when accomplishing most of today business tasks. Unfortunately, a person has hard time finding relevant information necessary to accomplish its business task due to the complexity of these information processes. In certain corporate bodies (aeronautical, automotive, etc.) these tasks are critical and should be run from specific information. As a solution, information retrieval systems must take into account the user context which integrates the user business task to improve its overall accuracy and facilitate the achievement of the task. To solve this problem we present in this paper the architecture of an information retrieval system applicable to a business situation. It is based on a triptych context model which integrates three dimensions: user, task and environment. This model is associated with a learning process and to a process that creates according to the conjunction of all the contextual factors, a particular situation. This situation will be exploited by the information search system to improve its accuracy in being the entry point of the information retrieval system. We explain how this system can improve the information search in a business context by taking into account cognitive, technical and social aspects.","","Electronic:978-0-7695-4141-9; POD:978-1-4244-7778-4","10.1109/CENTRIC.2010.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600340","Business tasks;Contextual Information Retrieval;Information-related tasks","Adaptation model;Context;Context modeling;Finite element methods;Information retrieval;Organizations","business data processing;information retrieval","account cognitive;business context modelling;business task;information retrieval improvement;information search system;learning process;social aspects;triptych context model;user context","","2","","17","","","22-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"A recommender system based on a generic contextual advertising approach","A. Addis; G. Armano; A. Giuliani; E. Vargiu","Dept. of Electrical and Electronic Engineering, University of Cagliari, Italy","The IEEE symposium on Computers and Communications","20100812","2010","","","859","861","Contextual advertising and automatic recommendation are emerging fields deeply studied by researchers in information retrieval. So far, these fields have been separately investigated and several solutions have been independently proposed in the literature. Nevertheless, in our view, there are common issues that drive us to think that systems devised to solve one of the task above could be simply re-adapted to solve the other. In this paper, we propose a novel recommendation system based on a generic solution typically adopted to solve contextual advertising tasks. Experimental results highlight the effectiveness of the proposed approach.","1530-1346;15301346","Electronic:978-1-4244-7755-5; POD:978-1-4244-7754-8","10.1109/ISCC.2010.5546548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546548","Internet services;applications;contextual advertising;information retrieval;recommender systems","Accuracy","","","","7","","7","","","22-25 June 2010","","IEEE","IEEE Conference Publications"
"Modelling rank-probability of relevance relationship in resultant document list for data fusion","Shengli Wu; Yaxin Bi; Xiaoqin Zeng","School of Computing and Mathematics, University of Ulster, Newtownabbey, UK","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","1","","V1-27","V1-31","In this paper we present a new data fusion method in information retrieval, which uses ranking information of resultant documents. Our method is based on the modelling of rank-probability of relevance of documents in resultant document list using logarithmic models. The proposed method is more effective than other data fusion methods which also use ranking information, and is as effective as some data fusion methods which rely on reliable scoring information.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579069","Data fusion;Information retrieval;Logarithmic relevance model;Meta-search;Performance","","probability;relevance feedback;sensor fusion","data fusion;document relevance probability;information retrieval;logarithmic model;rank-probability;resultant document list","","0","","19","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Assigning geographical focus to documents","M. Chen; X. Lin; Y. Zhang; X. Wang; H. Yu","Institute of Remote Sensing and Geographical Information Systems, Peking University, Beijing, China 100871","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","6","Geographical information becomes a kind of very important attribute for web documents, considering the fact that a large proportion of documents on the web contain geographical information. GIR (Geographical information retrieval) systems can identify those geographical information and extract the geographical focus in the documents automatically, hence supporting geo-related queries for information retrieval. Therefore, GIR has become a hot topic in both GIS and IR (Information Retrieval) areas recently. To take full advantage of geographical information within web documents in support of geo-related IR queries by returning more accurate results to users, a GIR system needs to get the geographical focus of the document, upon which a spatial index could then be established for a more accurate and efficient processing of spatial IR queries. So among all those steps within a GIR system, how to get the geographical focus for each document remains an essential one. In response to this demand, authors of this paper present a novel and promising algorithm. Before our explanation of proposed algorithm, we first briefly introduce SASEIC (Spatial-Aware Search Engine in Chinese)-a GIR prototype System we have implemented for the convenience of our research in GIR field. Then we start our description of proposed algorithm with the analysis of various possible PNPs (Place Name Patterns) within documents. After that, we present the algorithm with detailed principle and steps, which is conceived based on hierarchical structure of placenames within the documents for retrieval. Finally, at the end of this paper, we show the results of evaluation work for the proposed algorithm and draw our conclusions for this paper, as well as important directions of our future research.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567598","Geographical focus;Geographical information retrieval;Hierarchical relationship;Place Name Pattern","Algorithm design and analysis;Cities and towns;Entropy;Pediatrics;Prototypes;Web pages","Internet;document handling;geographic information systems;information retrieval","GIS;SASEIC;Spatial-Aware Search Engine in Chinese;Web documents;geographical focus;geographical information retrieval;place name patterns;spatial index","","1","","18","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"Knowledge-Discounted Event Detection in Sports Video","D. W. Tjondronegoro; Y. P. P. Chen","School of Information Technology, Queensland University of Technology , Brisbane, Australia","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20100816","2010","40","5","1009","1024","Automatic events annotation is an essential requirement for constructing an effective sports video summary. Researchers worldwide have actively been seeking the most robust and powerful solutions to detect and classify key events (or highlights) in different sports. Most of the current and widely used approaches have employed rules that model the typical pattern of audiovisual features within particular sport events. These rules are mainly based on manual observation and heuristic knowledge; therefore, machine learning can be used as an alternative. To bridge the gap between the two alternatives, we propose a hybrid approach, which integrates statistics into logical rule-based models during highlight detection. We have also successfully pioneered the use of play-break segment as a universal scope of detection and a standard set of features that can be applied for different sports, including soccer, basketball, and Australian football. The proposed method uses a limited amount of domain knowledge, making this method less subjective and more robust for different sports. An experiment using a large data set of sports video has demonstrated the effectiveness and robustness of the algorithms.","1083-4427;10834427","","10.1109/TSMCA.2010.2046729","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467165","Information retrieval;man–machine systems;multimedia databases;video signal processing","","content-based retrieval;image retrieval;learning (artificial intelligence);sport;video signal processing","audiovisual features;automatic events annotation;heuristic knowledge;highlight detection;knowledge-discounted event detection;logical rule-based models;machine learning;manual observation;play-break segment;sports video summary","","28","","36","","20100520","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"An information model for managing domain knowledge via Faceted Taxonomies","H. J. Chu; R. Y. C. Chow","Computer and Information Science and Engineering, University of Florida, Gainesville, U.S.A.","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","378","379","Faceted Taxonomies are often used for managing complex knowledge within a domain. They can be used as a reference model for bottom-up new information analysis and integration. This paper proposes a domain information model that quantifies the semantics (indexing concepts) of the faceted taxonomy nodes and uses them as indexer for integrating and managing knowledge such as software requirements. Through a working example, this paper shows how the indexing concepts and concepts in knowledge (indexed concepts) are associated via semantic similarity measurement and how the associations are used for managing domain knowledge, such as merging requirements.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558904","Faceted Taxonomy;Information Retrieval;Knowledge Management;Semantic Similarity Measurement","Business;Computational modeling;Context;Indexing;Ontologies;Semantics;Taxonomy","indexing;knowledge management","domain knowledge management;faceted taxonomies;indexing concepts;information analysis;information model;semantic similarity measurement","","2","","","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"Feature extraction and clustering-based retrieval for mathematical formulas","K. Ma; S. C. Hui; K. Chang","School of Computer Engineering Nanyang Technological University, Singapore 639798, Singapore","The 2nd International Conference on Software Engineering and Data Mining","20100809","2010","","","372","377","Mathematical formulas or expressions are essential for presenting scientific knowledge in many research documents in academic areas such as physics and mathematics. Searching for related mathematical formulas is an important but challenging problem as formulas contain both structural and semantic information. Such information is hidden inside the mathematical expressions of the formulas. To support effective formula search, it is necessary to extract the structural and semantic features from the mathematical presentation of the formulas faithfully. In this paper, we propose an effective approach for formula feature extraction. To evaluate the proposed approach, the extracted features are tested with three popular clustering algorithms, namely K-means, Self Organizing Map (SOM), and Agglomerative Hierarchical Clustering (AHC), for formula retrieval. The performance of the clustering-based retrieval is measured based on a dataset of 881 formulas and promising results have been achieved.","","Electronic:978-89-88678-22-0; POD:978-1-4244-7324-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5542894","clustering;feature extracction;formula search;information retrieval","Automatic testing;Clustering algorithms;Data mining;Feature extraction;Information retrieval;Knowledge engineering;Mathematics;Organizing;Physics computing;Search engines","feature extraction;information retrieval;mathematics computing;pattern clustering;self-organising feature maps","K-mean clustering algorithms;agglomerative hierarchical clustering;clustering-based retrieval;mathematical formulas;self organizing map clustering algorithms;semantic feature extraction;semantic information;structural feature extraction;structural information","","0","","15","","","23-25 June 2010","","IEEE","IEEE Conference Publications"
"Pragmatic analysis based query expansion for Chinese cuisine QA service system","L. Xia; F. Ren","School of Electrical and Information Engineering, Xihua University, Chengdu, 610039, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","This paper proposes a query expansion method for cooking question answering system based on pragmatic analysis. In our approach, the results of question analysis is used. The original queries are generated by means of the question subject, then the query terms are expanded based on pragmatic function. When submitting the expended queries to Google search engine to retrieve related passages, we get an overall improvement of 36.2% on the mean average precision.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587785","information retrieval (IR);pragmatic function;query expansion;question answering (QA) system","Dictionaries;Educational institutions","computational linguistics;natural language processing;query processing","Chinese cuisine QA service system;Google search engine;cooking question answering system;pragmatic analysis based query expansion","","0","","18","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Medical Case Retrieval From a Committee of Decision Trees","G. Quellec; M. Lamard; L. Bekri; G. Cazuguel; C. Roux; B. Cochener","INSTITUT TELECOM/TELECOM Bretagne , Dpt ITI, Brest, France","IEEE Transactions on Information Technology in Biomedicine","20100902","2010","14","5","1227","1235","A novel content-based information retrieval framework, designed to cover several medical applications, is presented in this paper. The presented framework allows the retrieval of possibly incomplete medical cases consisting of several images together with semantic information. It relies on a committee of decision trees, decision support tools well suited to process this type of information. In our proposed framework, images are characterized by their digital content. It was applied to two heterogeneous medical datasets for computer-aided diagnoses: a diabetic retinopathy follow-up dataset (DRD) and a mammography-screening dataset (DDSM). Measure of precision among the top five retrieved results of 0.788 ± 0.137 and 0.869 ± 0.161 was obtained on DRD and DDSM, respectively. On DRD, for instance, it increases by half the retrieval of single images.","1089-7771;10897771","","10.1109/TITB.2010.2053716","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492200","CAD;content-based image retrieval (CBIR);decision trees (DTs);information retrieval;medical databases","","biomedical optical imaging;decision support systems;decision trees;information retrieval;mammography;medical administrative data processing;visual databases","computer aided diagnoses;content based information retrieval framework;decision support tools;decision trees;diabetic retinopathy follow up dataset;image digital content;mammography screening dataset;medical case retrieval;semantic information","Algorithms;Artificial Intelligence;Databases, Factual;Decision Support Systems, Clinical;Decision Trees;Diabetic Retinopathy;Diagnosis, Computer-Assisted;Fundus Oculi;Humans;Image Processing, Computer-Assisted;Information Storage and Retrieval;Mammography;Signal Processing, Computer-Assisted","12","","30","","20100628","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Application of semantic technology in digital library","N. A. R. Alias; S. A. Noah; Z. Abdullah; N. Omar; M. M. Yusof; Y. Yahya","Knowledge Technology Research Group Faculty of Information Science and Technology Selangor, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1514","1518","Digital libraries play an important role in current activities involving digital documents. The research presented in this paper explores the future implementation of digital library by considering the semantic technology. This paper discuss our on-going research in developing a semantic digital library for academic institution. We aim to propose a prototype to populate the domain ontology in order to support semantic search in digital libraries. The research is focusing at the user level in extracting the information of the academic dissertations and populate to the ontology.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561473","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561473","digital library;information retrieval;ontology;semantic technology","Decision support systems;Helium","digital libraries;educational administrative data processing;educational institutions;information retrieval;ontologies (artificial intelligence);semantic networks","academic dissertation;academic institution;digital documents;domain ontology;information extraction;semantic digital library;semantic technology","","1","","10","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Semantically indexed and searched of digital images using lexical ontologies and named entity recognition","D. A. Ali; S. A. Noah","Universiti Kebangsaan Malaysia, Faculty of Information Science & Technology, 43600 UKM Bangi, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1308","1314","Using low-level features to support semantic search of images is a difficult task. As a result, textual content is used to provide semantic description or annotation of images. Such textual description of what we may call as `surrounding text' is a value added features available in most web images particularly on-line newspaper images. Most search engines used them as a feature to provide textual meaning of images. Relying on surrounding text alone, however, unable to provide support for semantic search that go beyond indexed terms. Lexical resources and ontology are potential sources to enhance searching for images. This paper discusses the use of WordNet and ConceptNet to enhance searching for on-line newspaper images. This is further improved with named entity recognition (NER) technique to annotate important entities such as name if a person, location and organization among image searchers. Results show that our semantic search approaches outperform the normal approach for searching images.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561455","Information retrieval;natural language processing;semantic search","Data mining;Indexes;Ontologies;Organizations;Pattern matching;Semantics;Syntactics","image retrieval;ontologies (artificial intelligence);text analysis","Web images;digital images;image annotation;lexical ontologies;lexical resources;low-level features;named entity recognition;online newspaper images;semantic description;semantic search;textual description","","0","","21","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"GMM adaptation based online speaker segmentation for spoken document retrieval","K. Park; J. s. Park; Y. H. Oh","Department of Computer Science, Korea Advanced Institute of Science and Technology (KAIST)","IEEE Transactions on Consumer Electronics","20100715","2010","56","2","1123","1129","This paper proposes an online speaker segmentation approach based on Gaussian Mixture Model (GMM) adaptation for spoken document retrieval. In the conventional approach using the Bayesian Information Criterion (BIC), two single Gaussian models are respectively constructed for two divided speech streams in an analysis window, and the dissimilarity between the two models is estimated according to the BIC principle. This approach has been widely applied to speaker segmentation. However, its performance may deteriorate when speakers change frequently, since the single Gaussian model hardly represent the speaker's explicit characteristics for short speech data. To overcome this limitation, we propose an approach to use adapted GMMs instead of single Gaussian models. The method proposed herein constructs a local UBM for speech in an analysis window and adapts the local UBM to each of two divided speech streams in the same window. Upon the two adapted GMMs obtained from the adaptation, the likelihood of the respective speech stream is estimated and change of speaker is determined according to our criterion based on local maxima of BIC. On speaker segmentation experiments based on HUB4, a well-known broadcast news corpus, the proposed method exhibited superior performance compared to the conventional approaches.","0098-3063;00983063","","10.1109/TCE.2010.5506048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5506048","GMM adaptation, Speaker segmentation, Spoken document retrieval, Bayesian information criterion","Bayesian methods;Digital multimedia broadcasting;Information retrieval;Multimedia communication;Multimedia databases;Music information retrieval;Portable media players;Smart phones;Speaker recognition;Speech analysis","","","","5","","21","","","May 2010","","IEEE","IEEE Journals & Magazines"
"CDIO and Teaching Reform of Document Retrieval Courses","Y. Chun","Libr., Hebei Univercity of Eng., Handan, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","3787","3789","CDIO is a new education model, which cultures students' specialized technical knowledge, individual ability, professional ability and ability of working and communicating in team towards systemic product design. We obtain practical experience using organic combination between document retrieval and analog electronic technology, and try out a teaching model of document retrieval combined with specialized courses which is lectured by professional teachers. The model is formed by the following three stages. First, methods and theories developed by social scientists and mathematical logicians were adopted to conceive the course content structures and the formation rules for project teams. Second, internet based information sharing tools developed by systems engineers were utilized to encourage organized interactions among students and teachers. Then, it leveraged the lecture hours as a“marketing”platform for students to share their findings and exhibit their creativity based on flexibly designed assignments. Practice shows that the organic combination between document retrieval and specialized courses is an ideal education model of document retrieval under CDIO.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591812","CDIO;Engineering education;Information retrieval;Team Teaching","Collaboration;Construction industry;Education;Information retrieval;Internet;Libraries;Mathematical model","computer aided instruction;document handling;educational courses;information retrieval","CDIO;Internet;analog electronic technology;document retrieval courses;individual ability;mathematical logicians;organic combination;professional ability;systemic product design;teaching reform","","0","","5","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Building Concept Network-Based User Profile for Personalized Web Search","H. j. Kim; S. Lee; B. Lee; S. Kang","Sch. of Electr. & Comput. Eng., Univ. of Seoul, Seoul, South Korea","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","20100930","2010","","","567","572","This paper presents a novel way of building the user profile of concept network for personalized search. The user profile is defined as a concept network, in which each concept is approximately represented with the formal concept analysis (FCA) theory. We assume that a concept, called `session interest concept', subsume a user's query intention during a query session and it can reflect the user's preference. Whenever a user issues his/her query, a session interest concept is generated. Then, new concepts are merged into the current concept network (i.e., a user profile) in which recent user preferences are accumulated. According to FCA, a session interest concept is defined as a pair of extent and intent where the extent covers a set of documents selected by the user among the search results and the intent covers a set of keyword features extracted from the selected documents. And, in order to make a concept network grow, we need to calculate the similarity between a new concept and existing concepts, and to this end, we use a reference concept hierarchy called Open Directory Project. The user profile of concept network is eventually used to expand a user's initial query. The empirical results show that our approach improves the accuracy of search results in terms of personal preference.","","Electronic:978-0-7695-4147-1; POD:978-1-4244-8198-9","10.1109/ICIS.2010.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591001","Concept Network;Information Retrieval;Keyword Extraction;Personalized Search;Query Expansion;User Profile","Buildings;Data mining;Feature extraction;History;USA Councils;Vaccines;Web search","Internet;knowledge acquisition;query processing;text analysis;user modelling","concept network-based user profile;formal concept analysis theory;open directory project;personalized Web search;query session;session interest concept;user query intention","","5","","15","","","18-20 Aug. 2010","","IEEE","IEEE Conference Publications"
"Multimedia Analysis + Visual Analytics = Multimedia Analytics","N. A. Chinchor; J. J. Thomas; P. C. Wong; M. G. Christel; W. Ribarsky","ChinchorEclectic","IEEE Computer Graphics and Applications","20100823","2010","30","5","52","60","To deal with the extent and variety of digital media, researchers are combining multimedia analysis and visual analytics to form the new field of multimedia analytics. This article gives some historical background, discusses surveys of related research, describes initial multimedia analytics research, and reports on benchmark datasets.","0272-1716;02721716","","10.1109/MCG.2010.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556733","Informedia;NIST TRECVID;computer graphics;graphics and multimedia;image processing;information retrieval;multimedia analysis;multimedia analytics;visual analytics;visualization","Data visualization;Image processing;Information retrieval;Multimedia communication;Tutorials","multimedia computing","benchmark datasets;digital media;multimedia analysis;multimedia analytics;visual analytics","","11","","20","","","Sept.-Oct. 2010","","IEEE","IEEE Journals & Magazines"
"An IR-Aided Machine Learning Framework for the BioCreative II.5 Challenge","Y. g. Cao; Z. Li; F. Liu; S. Agarwal; Q. Zhang; H. Yu","University of Wisconsin-Milwaukee, Milwaukee","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20100803","2010","7","3","454","461","The team at the University of Wisconsin-Milwaukee developed an information retrieval and machine learning framework. Our framework requires only the standardized training data and depends upon minimal external knowledge resources and minimal parsing. Within the framework, we built our text mining systems and participated for the first time in all three BioCreative II.5 Challenge tasks. The results show that our systems performed among the top five teams for raw F1 scores in all three tasks and came in third place for the homonym ortholog F1 scores for the INT task. The results demonstrated that our IR-based framework is efficient, robust, and potentially scalable.","1545-5963;15455963","","10.1109/TCBB.2010.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473215","Bioinformatics (genome or protein) databases;information search and retrieval;systems and software;text mining.","","biology computing;information retrieval;learning (artificial intelligence);medical computing;text analysis","BioCreative II.5 challenge;IR aided machine learning framework;information retrieval;minimal external knowledge resource;minimal parsing;text mining systems","Artificial Intelligence;Computational Biology;Data Mining;Databases, Genetic;Information Storage and Retrieval;Protein Interaction Mapping;Wisconsin","0","","41","","20100527","July-Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Social search engine research","Jiandong Cao; Yang Tang; Binbin Lou","Software College, Northeast University (NEU), Shenyang, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","7","","308","309","The social search engine, as the meaning of its name, combines the SNS (Social Network Service) and search engine. Its key point is not at social, but at the search engine. The system will use the SNS to help users to get their useful information quickly and accurately. This paper mainly introduces the value of social search engine, forecast and the problem may meet in the future.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563672","information retrieval;search engine;social network service","Search problems","information retrieval;search engines;social networking (online);user interfaces","information retrieval;search engine;social network service","","0","","1","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Evaluating a Cross-Language Semantically Enriched Search Engine","L. Zhuhadar; O. Nasraoui","Dept. of Comput. Eng. & Comput. Sci., Univ. of Louisville, Louisville, KY, USA","2010 Seventh International Conference on Information Technology: New Generations","20100701","2010","","","1074","1079","This paper tackles the problem of a user who is capable of reading or using documents written in a specific language, but who is not fluent enough in this specific language to use the right query terms to find the document. The design of Cross-Language Information Retrieval systems started since 1969 by Gerard Salton who enhanced his SMART system to retrieve documents in multiple languages, English and Spanish; however, the translation process is still considered to be a challenging problem. This paper is devoted to the evaluation of a Cross-Language search engine that uses Natural Language Processing techniques as a means of improving the search process of documents provided by two languages, English and Spanish. The research is implemented and evaluated on a real platform HyperManyMedia at Western Kentucky University. The implementation of the Cross-Language search engine follows a synergistic approach between (1) A Thesaurus-based Approach and (2) A Corpus-based Approach. In the case of the Thesaurus-based Approach, we use a simple bilingual listing of terms, phrases, concepts, and subconcepts where the hierarchical structure of the ontology is used to define the relationship between concepts/subconcepts. Also, we use a specific terminology that captures the domain of E-learning; those terms are associated with college name, course name, and lecture name which is presented in two languages. In the case of the Corpus-based Approach, we use the Term Vector Translation approach; the goal is to find statistical information about term usage between the two languages using techniques which map sets of term weights from English to Spanish and vice-versa.","","Electronic:978-1-4244-6271-1; POD:978-1-4244-6270-4","10.1109/ITNG.2010.237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5501488","cross-language;evaluation;information retrieval;ontology;search engine;semantic web","Information retrieval;Information technology;Knowledge engineering;Knowledge representation;Natural language processing;Natural languages;Ontologies;Search engines;Speech processing;Web mining","computer aided instruction;language translation;natural language processing;ontologies (artificial intelligence);query processing;search engines;thesauri","E-learning;HyperManyMedia;SMART system;Western Kentucky University;corpus-based approach;cross-language information retrieval systems;cross-language semantically enriched search engine;hierarchical ontology structure;natural language processing techniques;query terms;specific language;term vector translation;thesaurus-based approach;translation process","","0","","29","","","12-14 April 2010","","IEEE","IEEE Conference Publications"
"Vocal Melody Extraction in the Presence of Pitched Accompaniment in Polyphonic Music","V. Rao; P. Rao","Dept. of Electr. Eng., Indian Inst. of Technol. Bombay, Mumbai, India","IEEE Transactions on Audio, Speech, and Language Processing","20100907","2010","18","8","2145","2154","Melody extraction algorithms for single-channel polyphonic music typically rely on the salience of the lead melodic instrument, considered here to be the singing voice. However the simultaneous presence of one or more pitched instruments in the polyphony can cause such a predominant-F0 tracker to switch between tracking the pitch of the voice and that of an instrument of comparable strength, resulting in reduced voice-pitch detection accuracy. We propose a system that, in addition to biasing the salience measure in favor of singing voice characteristics, acknowledges that the voice may not dominate the polyphony at all instants and therefore tracks an additional pitch to better deal with the potential presence of locally dominant pitched accompaniment. A feature based on the temporal instability of voice harmonics is used to finally identify the voice pitch. The proposed system is evaluated on test data that is representative of polyphonic music with strong pitched accompaniment. Results show that the proposed system is indeed able to recover melodic information lost to its single-pitch tracking counterpart, and also outperforms another state-of-the-art melody extraction system designed for polyphonic music.","1558-7916;15587916","","10.1109/TASL.2010.2042124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5431024","Fundamental frequency estimation;music information retrieval (MIR);music transcription;predominant pitch detection","Automatic control;Data mining;Frequency estimation;Humans;Instruments;Music information retrieval;Robustness;Signal representations;Switches;System testing","music;speech processing","lead melodic instrument;melody extraction algorithms;pitched accompaniment;singing voice;single-channel polyphonic music;single-pitch tracking counterpart;vocal melody extraction;voice-pitch detection","","19","","39","","20100315","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"Weakly supervised relevance feedback based on an improved language model","Xin-Sheng Li; Si Li; Wei-Ran Xu; Guang Chen; Jun Guo","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, 100876, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","5","Relevance feedback, which traditionally uses the terms in the relevant documents to enrich the user's initial query, is an effective method for improving retrieval performance. This approach has another problem is that Relevance feedback assumes that most frequent terms in the feedback documents are useful for the retrieval. In fact, the reports of some experiments show that it does not hold in reality many expansion terms identified in traditional approaches are indeed unrelated to the query and harmful to the retrieval. In this paper, we propose to select better and more relevant documents with a clustering algorithm. And then we present an improved Language Model to help us identify the good terms from those relevant documents. Ours experiments on the 2008 TREC collection show that retrieval effectiveness can be much improved when the improved Language Model is used.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587859","Information retrieval (IR);cluster;query expansion;relevance feedback;relevant documents","HTML","natural language processing;pattern clustering;relevance feedback","clustering algorithm;language model;relevance feedback","","0","","6","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Aggregating music recommendation Web APIs by artist","B. Marshall","Computer and Information Technology, Purdue University, USA","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","75","79","Through user accounts, music recommendations are refined by user-supplied genres and artists preferences. Music recommendation is further complicated by multiple genre artists, artist collaborations and artist similarity identification. We focus primarily on artist similarity in which we propose a rank fusion solution. We aggregate the most similar artist ranking from Idiomag, Last.fm and Echo Nest. Through an experimental evaluation of 300 artist queries, we compare five rank fusion algorithms and how each fusion method could impact the retrieval of established, new or cross-genre music artists.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558960","artist similarity;music information retrieval;rank aggregation methods","Aggregates;Collaboration;Music information retrieval;Pediatrics;Portals;Recommender systems;Tagging","application program interfaces;information retrieval;music;recommender systems","Web API;application program interfaces;artist collaborations;artist similarity identification;multiple genre artists;music recommendation;music retrieval;rank fusion solution;user accounts","","0","","14","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Search Method That Can Dynamically Learn User's Subjective Feeling","Y. Sakurai; R. Knauf; S. Tsuruta","Sch. of Inf. Environ., Tokyo Denki Univ., Chiba, Japan","2009 Fifth International Conference on Signal Image Technology and Internet Based Systems","20101111","2009","","","221","227","As an approach to search /retrieve such objects as pictures, music, perfumes and apparels on the Internet, sensitivity-vectors or kansei-vectors are useful since textual keywords are not sufficient to find objects that users want. The sensitivity-vector is an array of values each indicates a degree of feeling or impression represented as sensitivity word or kansei word. However, due to the gap between user's subjective sensitivity (image, feeling) value and the corresponding one stored in the database, even such an approach is not enough to search what users want. This paper proposes a search method to automatically and dynamically decrease such gaps by estimating a subjective criterion deviation (we call “SCD”) using the user's search history and fuzzy modeling. The proposed method can avoid users' burden caused by conventional methods such as requiring questionnaires. This method can also reflect the dynamic change of user's preference which cannot be accomplished by using questionnaires. For the evaluation, an experiment was done building and using a perfume search system. Through observing the transition of the deviation elimination degree, it was clarified that the proposed method is effective. In the experiment, the machine could learn users' subjective criteria deviation as well as its dynamic change caused by factors such as user's preference, if the learning rate is well adjusted.","","Electronic:978-1-4244-5741-0; POD:978-1-4244-5740-3; USB:978-0-7695-3959-1","10.1109/SITIS.2009.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5634023","information retrieval;kansei search;kansei word;subjective feeling","Databases;Estimation;History;Search engines;Search problems;Sensitivity","Internet;fuzzy set theory;query formulation;retail data processing","Internet;deviation elimination degree;fuzzy modeling;kansei-vectors;learning rate;perfume search system;search history;sensitivity based retrieval;sensitivity-vectors;subjective criterion deviation;subjective sensitivity;user subjective feeling","","0","","10","","","Nov. 29 2009-Dec. 4 2009","","IEEE","IEEE Conference Publications"
"Multiple Fundamental Frequency Estimation and Polyphony Inference of Polyphonic Music Signals","C. Yeh; A. Roebel; X. Rodet","Inst. de Rech. et Coordination Acoust./Musique (IRCAM), Paris, France","IEEE Transactions on Audio, Speech, and Language Processing","20100816","2010","18","6","1116","1126","This paper presents a frame-based system for estimating multiple fundamental frequencies (F0s) of polyphonic music signals based on the short-time Fourier transform (STFT) representation. To estimate the number of sources along with their F0s, it is proposed to estimate the noise level beforehand and then jointly evaluate all the possible combinations among pre-selected F0 candidates. Given a set of F0 hypotheses, their hypothetical partial sequences are derived, taking into account where partial overlap may occur. A score function is used to select the plausible sets of F0 hypotheses. To infer the best combination, hypothetical sources are progressively combined and iteratively verified. A hypothetical source is considered valid if it either explains more energy than the noise, or improves significantly the envelope smoothness once the overlapping partials are treated. The proposed system has been submitted to Music Information Retrieval Evaluation eXchange (MIREX) 2007 and 2008 contests where the accuracy has been evaluated with respect to the number of sources inferred and the precision of the F0s estimated. The encouraging results demonstrate its competitive performance among the state-of-the-art methods.","1558-7916;15587916","","10.1109/TASL.2009.2030006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5200519","Automatic music transcription;frequency estimation;music information retrieval;noise estimation;signal analysis;source separation","","Fourier transforms;acoustic signal processing;frequency estimation","MIREX;STFT;hypothetical source;multiple fundamental frequency estimation;music information retrieval evaluation exchange;polyphonic music signals;polyphony inference;short-time Fourier transform","","24","","51","","20090811","Aug. 2010","","IEEE","IEEE Journals & Magazines"
"Automated Requirements Traceability: The Study of Human Analysts","D. Cuddeback; A. Dekhtyar; J. Hayes","Comput. Sci. Dept., California Polytech. State Univ., San Luis Obispo, CA, USA","2010 18th IEEE International Requirements Engineering Conference","20101115","2010","","","231","240","The requirements traceability matrix (RTM) supports many software engineering and software verification and validation (V&V) activities such as change impact analysis, reverse engineering, reuse, and regression testing. The generation of RTMs is tedious and error-prone, though, thus RTMs are often not generated or maintained. Automated techniques have been developed to generate candidate RTMs with some success. When using RTMs to support the V&V of mission-or safety-critical systems, however, a human analyst must vet the candidate RTMs. The focus thus becomes the quality of the final RTM. This paper investigate show human analysts perform when vetting candidate RTMs. Specifically, a study was undertaken at two universities and had 26 participants analyze RTMs of varying accuracy for a Java code formatter program. The study found that humans tend to move their candidate RTM toward the line that represents recall = precision. Participants who examined RTMs with low recall and low precision drastically improved both.","1090-705X;1090705X","Electronic:978-0-7695-4162-4; POD:978-1-4244-8022-7","10.1109/RE.2010.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5636537","decision support;information retrieval;requirements;traceability","Accuracy;Computer science;Humans;Information retrieval;Large scale integration;Software;Training","program verification;software engineering","Java code formatter program;automated requirements traceability;human analysts;requirements traceability matrix;software engineering;software verification","","35","","17","","","Sept. 27 2010-Oct. 1 2010","","IEEE","IEEE Conference Publications"
"Breaking News Detection and Tracking in Twitter","S. Phuvipadawat; T. Murata","Dept. of Comput. Sci., Tokyo Inst. of Technol., Tokyo, Japan","2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20101101","2010","3","","120","123","Twitter has been used as one of the communication channels for spreading breaking news. We propose a method to collect, group, rank and track breaking news in Twitter. Since short length messages make similarity comparison difficult, we boost scores on proper nouns to improve the grouping results. Each group is ranked based on popularity and reliability factors. Current detection method is limited to facts part of messages. We developed an application called “Hotstream” based on the proposed method. Users can discover breaking news from the Twitter timeline. Each story is provided with the information of message originator, story development and activity chart. This provides a convenient way for people to follow breaking news and stay informed with real-time updates.","","Electronic:978-0-7695-4191-4; POD:978-1-4244-8482-9","10.1109/WI-IAT.2010.205","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5616930","Information Retrieval;Real-time text-mining;Topic Detection and Tracking;Twitter","Feature extraction;Indexing;Nominations and elections;Real time systems;Reliability;Twitter;User-generated content","information retrieval;social networking (online)","Hotstream;Twitter;breaking news detection;breaking news tracking;popularity factor;reliability factor;short length messages","","27","4","9","","","Aug. 31 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Using Data Fusion and Web Mining to Support Feature Location in Software","M. Revelle; B. Dit; D. Poshyvanyk","Dept. of Comput. Sci., Coll. of William & Mary, Williamsburg, VA, USA","2010 IEEE 18th International Conference on Program Comprehension","20100726","2010","","","14","23","Data fusion is the process of integrating multiple sources of information such that their combination yields better results than if the data sources are used individually. This paper applies the idea of data fusion to feature location, the process of identifying the source code that implements specific functionality in software. A data fusion model for feature location is presented which defines new feature location techniques based on combining information from textual, dynamic, and web mining analyses applied to software. A novel contribution of the proposed model is the use of advanced web mining algorithms to analyze execution information during feature location. The results of an extensive evaluation indicate that the new feature location techniques based on web mining improve the effectiveness of existing approaches by as much as 62%.","1092-8138;10928138","Electronic:978-1-4244-7603-9; POD:978-1-4244-7604-6; USB:978-0-7695-4113-6","10.1109/ICPC.2010.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521780","data fusion;feature location;information retrieval;web mining","Global Positioning System;Information analysis;Information filtering;Information filters;Information resources;Information retrieval;Performance analysis;Software maintenance;Software systems;Web mining","data mining;information retrieval;sensor fusion;software engineering","Web mining;data fusion;dynamic mining;software feature location;textual mining","","29","1","34","","","June 30 2010-July 2 2010","","IEEE","IEEE Conference Publications"
"Efficient retrieval of Malay language documents using Latent Semantic Indexing","R. Sadjirin; N. A. Rahman","Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1410","1415","The main objectives of this research is to investigate whether by using Latent Semantic Indexing (LSI) will improve the retrieval effectiveness on Malay document, compared to by using exact term-matching technique. LSI is a mathematical approach that uses Singular Value Decomposition (SVD) to discover the important association of the relationship between terms and terms, terms and documents and documents and documents. Cosine similarity measurement is used to measure the similarity between the query word and terms as well as the documents. This research uses Malay Language Test Collection consisting of 210 Malay documents, queries, relevant judgment and Malay stemmer to stem Malay terms. Results and analyses show that, LSI retrieval method outperformed the exact term-matching technique despite the longer processing time it took during the indexing. The best result for retrieval effectiveness for Malay documents in this domain is achieved when k-dimension is 4 and the threshold value is 0.8, which is 80.2 percent.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561613","Latent Semantic Analysis;Latent Semantic Indexing;Malay Information Retrieval","DSL;Decision support systems","indexing;information retrieval;natural language processing;singular value decomposition;word processing","Malay language document retrieval;Malay language test collection;Malay stemmer;exact term matching technique;latent semantic indexing;singular value decomposition","","2","","24","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Web service and visualization for higher education information providing service","M. Ida","National Institution for Academic Degrees and University Evaluation 1-29-1 Gakuen-nishimachi, Kodaira, Tokyo 187-8587, Japan","2010 IEEE International Conference on Software Engineering and Service Sciences","20100819","2010","","","415","418","Important and urgent issue of higher education institutions is to provide service to their students, staffs and public with useful education information. In this paper analyzing structure of higher education information, development and improvement of the education information providing service is examined that consists of syllabus database, XML web service, curriculum analyzing system, multivariable analysis methods and other web technologies. Especially correspondence analysis is utilized in text mining in order to deepen global understanding on the characteristics of categorized and accumulated textual information included in syllabuses. This paper also presents the visualization method for higher education curriculum textual information.","2327-0586;23270586","Electronic:978-1-4244-6055-7; POD:978-1-4244-6054-0","10.1109/ICSESS.2010.5552349","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5552349","Service sciences;XML and databases;correspondence analysis;curriculum analysis;evaluation;information retrieval;text mining;visualization;web service;web technologies and information management","Databases;Educational institutions;Springs;Visualization;Web services;XML","Web services;XML;data mining;data visualisation;educational institutions;further education;text analysis","Web service;higher education institutions;information providing service;text mining","","2","","8","","","16-18 July 2010","","IEEE","IEEE Conference Publications"
"Extended balancing ontological and operational factors in refining multiagent neighborhood using ACO","L. C. Yean; L. T. Ming; L. K. Soon","Sunway University College Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1398","1403","In this paper, we present our work extended balancing ontological and operational factors using Ant Colony Optimization (ACO) in building collaborations within multiagent neighborhoods. This innovation overcomes the previous version's problem on better collaboration among agents, reducing message flooding, increase scalability and resolved the “hidden boundary” problem. The domain of application is multiagent, distributed information retrieval, where agents safeguarding their own information or data resources, improve their local services by collaborating with others. Information retrieval is like a food finding for ants. Foods are not always available at the same location and there might be a better location with more foods. Same thing apply to information. In this paper, we adopted ACO as our agent's collaboration technique to enhance the previous work.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561649","Ant colony optimization;agent coordination;information retrieval;multiagent","Biomedical optical imaging;Collaboration;OFDM;Optical fiber communication;Optical modulation;Wireless communication","distributed processing;information resources;information retrieval;multi-agent systems;ontologies (artificial intelligence);optimisation","agent collaboration;ant colony optimization;data resource;distributed information retrieval;hidden boundary problem;information resource;message flooding;multiagent neighborhood;ontological factor;operational factor","","0","","8","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"A framework for extracting musical similarities from peer-to-peer networks","N. Koenigstein; Y. Shavitt; T. Tankel; E. Weinsberg; U. Weinsberg","School of Electrical Engineering, Tel Aviv University","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","1433","1438","The usage of peer-to-peer (p2p) networks for music information retrieval (MIR) tasks is gaining momentum. P2P file sharing networks can be used for collecting both search queries and files from shared folders. The first can be utilized to reveal current taste, users interest, and trends, while the latter can be used for enhancing recommender systems. Both provide opportunities for longitudinal analysis, as queries change over time and content often accumulates. Moreover, spatial analysis can expose cultural differences and the way trends propagate. However, tapping into this fountain of information is far from trivial. This paper presents a novel analysis of the shared folders data-set collected from the Gnutella network. We first present the framework for crawling the network and collecting the data. We then present some data-set characteristics, while focusing on music similarities. The paper sheds light on both the opportunities of using p2p data and its complexities.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583251","Data-mining;File-sharing;Information Retrieval;Peer-to-peer","Collaboration;Crawlers;IP networks;Music;Noise;Peer to peer computing;Recommender systems","information retrieval;music;peer-to-peer computing;recommender systems","Gnutella network;P2P file sharing network;longitudinal analysis;music information retrieval;musical similarities;peer-to-peer networks;recommender system;search queries;spatial analysis","","2","","26","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"Query expansion using thesaurus in improving Malay Hadith retrieval system","N. A. Rahman; Z. A. Bakar; T. M. T. Sembok","Faculty of Computer & Mathematical Sciences, Universiti Teknologi MARA, Shah Alam, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1404","1409","Thesaurus has become another valuable structure in any Information Retrieval system. It is a list of terms and concepts that provide a controlled vocabulary of words to use in document indexing, clustering, searching and retrieval. This paper present the results of expanding user's query using Malay thesaurus in the process of searching Malay documents from Malay Hadith retrieval system. The results obtained shows that the retrieval effectiveness improves by four percent when thesaurus is employed in the process of retrieving Malay translated Hadith documents, compared to when single term queries are employed.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561518","Cluster-based Retrieval;Information Retrieval;Query Expansion;Thesaurus","Books;Clustering algorithms;Couplings;Indexes;Information retrieval;Thesauri","document handling;indexing;information retrieval systems;natural language processing;query processing;thesauri","Malay Hadith retrieval system;Malay documents;Malay thesaurus;Malay translated Hadith documents;controlled vocabulary;document clustering;document indexing;document retrieval;document searching;information retrieval system;query expansion","","3","","21","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"The Binormal Assumption on Precision-Recall Curves","K. H. Brodersen; C. S. Ong; K. E. Stephan; J. M. Buhmann","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4263","4266","The precision-recall curve (PRC) has become a widespread conceptual basis for assessing classification performance. The curve relates the positive predictive value of a classifier to its true positive rate and often provides a useful alternative to the well-known receiver operating characteristic (ROC). The empirical PRC, however, turns out to be a highly imprecise estimate of the true curve, especially in the case of a small sample size and class imbalance in favour of negative examples. Ironically, this situation tends to occur precisely in those applications where the curve would be most useful, e.g., in anomaly detection or information retrieval. Here, we propose to estimate the PRC on the basis of a simple distributional assumption about the decision values that generalizes the established binormal model for estimating smooth ROC curves. Using simulations, we show that our approach outperforms empirical estimates, and that an account of the class imbalance is crucial for obtaining unbiased PRC estimates.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597760","classification performance;false discovery rate;generalizability;information retrieval;receiver operating characteristic","Accuracy;Computational modeling;Data models;Estimation;Mathematical model;Predictive models;Solid modeling","pattern classification","anomaly detection;binormal assumption;binormal model;classification performance;decision values;information retrieval;precision-recall curves;receiver operating characteristic","","9","","11","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Natural Language Processing Based Detection of Duplicate Defect Patterns","Q. Wu; Q. Wang","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2010 IEEE 34th Annual Computer Software and Applications Conference Workshops","20101101","2010","","","220","225","A Defect pattern repository collects different kinds of defect patterns, which are general descriptions of the characteristics of commonly occurring software code defects. Defect patterns can be widely used by programmers, static defect analysis tools, and even runtime verification. Following the idea of web 2.0, defect pattern repositories allow these users to submit defect patterns they found. However, submission of duplicate patterns would lead to a redundancy in the repository. This paper introduces an approach to suggest potential duplicates based on natural language processing. Our approach first computes field similarities based on Vector Space Model, and then employs Information Entropy to determine the field importance, and next combines the field similarities to form the final defect pattern similarity. Two strategies are introduced to make our approach adaptive to special situations. Finally, groups of duplicates are obtained by adopting Hierarchical Clustering. Evaluation indicates that our approach could detect most of the actual duplicates (72% in our experiment) in the repository.","","Electronic:978-0-7695-4105-1; POD:978-1-4244-8089-0","10.1109/COMPSACW.2010.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5615790","Defect Pattern;Duplicate;Information Retrieval;Natural Language Processing","","Internet;entropy;natural language processing;pattern clustering;program diagnostics","Web 2.0;defect pattern repositories;duplicate defect pattern detection;hierarchical clustering;information entropy;natural language processing;software code defects;static defect analysis tools;vector space model","","1","","24","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"Opinion Detection in Blogs: What Is Still Missing?","M. M. S. Missen; M. Boughanem; G. Cabanac","IRIT, Univ. de Toulouse, Toulouse, France","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","270","275","In recent years, a lot of work has been done in the field of Opinion Detection in blogs but most of the research is based on machine learning or lexical based approaches. The objective of this paper is to focus on Social Network based evidences that can be exploited for the task of Opinion Detection. We propose a framework that makes use of the major elements of the blogosphere for extracting opinions from blogs. Besides this, we highlight the tasks of opinion prediction and multidimensional ranking. In addition, we also discuss the challenges that researchers might face while realizing the proposed framework. At the end, we demonstrate the importance of social networking evidences by performing experimentation.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562761","Blogosphere;Blogs;Information Retrieval;Opinion Detection;Opinion Prediction;Polarity Detection;Social Networking;Subjectivity","Blogs;Context;Estimation;Face;Machine learning;Social network services;Time frequency analysis","learning (artificial intelligence);social networking (online)","blogosphere;lexical based approaches;machine learning;opinion detection;social network","","2","","26","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic Classification of Software Change Request Using Multi-label Machine Learning Methods","S. N. Ahsan; J. Ferzund; F. Wotawa","Inst. for Software Technol., Graz Univ. of Technol., Graz, Austria","2009 33rd Annual IEEE Software Engineering Workshop","20101104","2009","","","79","86","Automatic text classification of the software change request (CR) can be used for automating impact analysis, bug triage and effort estimation. In this paper, we focus on the automation of the process for assigning CRs to developers and present a solution that is based on automatic text classification of CRs. In addition our approach provides the list of source files, which are required to be modified and an estimate for the time required to resolve a given CR. To perform experiments, we downloaded the set of resolved CRs from the OSS project's repository for Mozilla. We labeled each CR with multiple labels i.e., the developer name, the list of source files, and the time spent to resolve the CR. To train the classifier, our approach applies the Problem Transformation and Algorithm Adaptation methods of multi-label machine learning to the multi-labeled CR data. With this approach, we have obtained precision levels up to 71.3% with 40.1% recall.","1550-6215;15506215","Electronic:978-1-4244-6864-5; POD:978-1-4244-6863-8","10.1109/SEW.2009.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5621702","bug triage;information retrieval;machine learning;multi-label;software maintenance","Indexing;Information retrieval;Large scale integration;Machine learning algorithms;Semantics;Software;Time division multiplexing","learning (artificial intelligence);pattern classification;software maintenance;text analysis","Mozilla;OSS project;algorithm adaptation;automatic software change request classification;automatic text classification;bug triage;multilabel machine learning methods;problem transformation","","1","","19","","","13-14 Oct. 2009","","IEEE","IEEE Conference Publications"
"A Framework to Answer Questions of Opinion Type","X. Su; G. Gao; Y. Tian","Sch. of Comput. Sci., Inner Mongolia Univ., Hohhot, China","2010 Seventh Web Information Systems and Applications Conference","20100923","2010","","","166","169","In this paper, we propose a framework to answer questions of opinion type. The data source is the web pages returned from the search engine. By using Bayes Classifier, the main texts on the pages are classified into three categories at sentence level: positive review, negative review and neutral review. K-means method is used to cluster the sentences of positive review and negative review respectively. The final answers are extracted from the sentence groups after clustering and presented in the form of quaternion. We design a system to test this framework. The experimental results show that it is effective.","","Electronic:978-0-7695-4193-8; POD:978-1-4244-8440-9","10.1109/WISA.2010.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581311","Classification;Clustering;Information Retrieval;Opinion Mining;Question Answering","Book reviews;Computers;Conferences;Data mining;Feature extraction;Quaternions;Web pages","Bayes methods;Web sites;feature extraction;pattern classification;pattern clustering;query processing;search engines;text analysis","Bayes classifier;K-means method;Web page;answer extraction;data source;negative review;neutral review;opinion type;positive review;question answering;search engine","","0","","13","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"An Explorative Association-Based Search for the Semantic Web","M. Lee; W. Kim; T. G. Wang","Dept. of Inf. Ind. Eng., Yonsei Univ., Seoul, South Korea","2010 IEEE Fourth International Conference on Semantic Computing","20101111","2010","","","206","211","Due to the explosive growth of the amount of Web information, the effectiveness of keyword-based searching methods appears to reach a limit. One major reason is that the mixture of content and presentation information hinders machines in understanding the context of Web information and as a result, the performance of the existing search approaches degenerates. To address this challenge, Tim Berners-Lee of W3C envisioned the Semantic Web. In the Semantic Web, the meaning (semantics) of each term of Web information is defined based on ontologies, thus machines are able to retrieve information that is semantically associated with resources containing input keywords. In this paper, we propose the semantic association search system (SASS), which takes into account the associations between resources (web pages) as well as keywords. To achieve this goal, we first created metrics to evaluate the relative importance of each association between resources, and then developed an exploration mechanism based on the spreading activation paradigm to follow the relevant paths of such associations. Demonstrative cases were tested to validate our approach, and the results showed the effectiveness and great potential of our approach.","","Electronic:978-0-7695-4154-9; POD:978-1-4244-7912-2","10.1109/ICSC.2010.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628905","Semantic association-based search system;ontology;semantic Web;semantic information retrieval;spreading activation","Frequency measurement;Joining processes;Ontologies;Semantic Web;Semantics;Web pages","information retrieval;ontologies (artificial intelligence);semantic Web","Web information;Web pages;exploration mechanism;explorative association-based search;information resource;information retrieval;keyword-based searching method;ontologies;search approach;semantic Web;semantic association search system;spreading activation paradigm","","1","","13","","","22-24 Sept. 2010","","IEEE","IEEE Conference Publications"
"Clustering algorithm in literature-based discovery","C. Ye; F. Leng; X. Guo","National science of Library, Chinese Academy of Science, Beijing, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1625","1629","Literature-based discovery is linking two or more literature concepts that have heretofore not been linked (i.e., disjoint), in order to produce novel, interesting, plausible, and intelligible knowledge. Cluster analysis is the core of literature-based discovery. This paper proposes an improved fuzzy c means (FCM) algorithm based on the analysis of existing clustering analysis of literature-based discovery. The new FCM algorithm mainly focus on the fuzzy degree of membership and make the FCM algorithm achieve better clustering results in despite of the existence of isolated points or low-frequency terms. And because of the relaxation of the normalization condition, the final clustering result is not very sensitive to the number of the pre-determined clusters. The new FCM algorithm takes the low-frequency terms into full account, and reduces the impaction of the pre-determined number of clusters on the final clustering.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569366","Fuzzy c means algorithm;Information retrieval;Literature-based discovery;NFCM;Raynaud's Phenomenon;Subordinative degree","Algorithm design and analysis;Clustering algorithms;Databases;Filtering;Marine animals;Petroleum;Unified modeling language","fuzzy set theory;pattern clustering","FCM algorithm;cluster analysis;clustering algorithm;fuzzy c means;intelligible knowledge;literature-based discovery","","0","","10","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Design and implementation of job-search system based on javaEE","P. Lin; H. Wen; S. Zhou","School of Computer & Information Engineering, Shandong University of Finance, Jinan, China","2010 Second International Conference on Communication Systems, Networks and Applications","20100930","2010","1","","404","407","To help job-seekers to find the job information online conveniently and quickly, this article designs and implements the job-search system based on javaEE. The system combines with Deep Web technology crawling many recruitment websites' job information and saves them into database to provide retrieval service for user. To overcome the difficulties of the current dynamic webpage's data grab. The data capture of this system's background is implemented by watir. The retrieval module for end-users is implemented by JavaEE. The practical application shows that this system can provide a good retrieval service conveniently and quickly.","","Electronic:978-1-4244-7478-3; POD:978-1-4244-7475-2","10.1109/ICCSNA.2010.5588987","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588987","Information Retrieval;Ruby;Watir;information publication;javaEE","Educational institutions;Navigation;Object recognition","Java;Web sites;information retrieval;recruitment","data capture;deep Web technology;javaEE;job search system;recruitment Website job information;retrieval service;watir","","0","","5","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Towards a Search System for the Web Exploiting Spatial Data of a Web Document","S. Dlugolinsky; M. Laclavik; L. Hluchy","Inst. of Inf., Slovak Acad. of Sci., Bratislava, Slovakia","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","27","31","In this paper, we describe our work in progress in the scope of information retrieval exploiting the spatial data extracted from web documents. We discuss problems of a search for web documents by geographic distance, where the geographic distance of a document is determined automatically using information extraction methods. We present here our approach of building a distributed search system, which deals with several problems of this area. Search by geographic distance is useful, for example if we are looking for the nearest restaurant, hotel or any other business near our location (reference point). Almost every company today presents its business on the Internet sharing business information along with contact information. There can be miscellaneous geographic information extracted from the contact information (but no only from it) and used to compute geographic distance of a document. Under a document's geographic distance, we understand the distance between a search reference point and a geographic location related to the document. In our approach, we chose postal addresses and GPS coordinates for spatial data extraction. The reference point can be dynamically changed and one document can be related to more than one geographic location. Geographic locations are automatically discovered in document's textual content. Document is then indexed by all its known geographic locations, so later when searching, the document can be found near different geographic locations to which it is related. Domain of the search is automatically built by crawling through linked web documents.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591985","distance search;geo-coding;information extraction;information retrieval;web crawling","Data mining;Global Positioning System;Google;Indexing;Information retrieval;Semantics","Internet;document handling;information retrieval;visual databases","Internet sharing business information;Web document;Web search system;distributed search system;geographic distance;information extraction methods;information retrieval;spatial data","","0","","10","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"3D Wave field phase retrieval from multi-plane observations","A. Migukin; V. Katkovnik; J. Astola","Department of Signal Processing, Tampere University of Technology (TUT) Korkeakoulunkatu 10, FI-33720, Tampere, Finland","2010 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video","20100708","2010","","","1","4","We reconstruct a spatially distributed three-dimensional (3D) wave field from a number of intensity observations, obtained in different sensor planes, parallel to the object plane. The proposed algorithm can be treated as a multiple plane iterative Gerchberg-Saxton algorithm [1]. It is obtained from the best linear estimate of the complex-valued object distribution derived for the complex-valued observations. This estimator is modified for the intensity measurements in the sensor planes. The algorithm is studied by numerical experiments performed for amplitude and phase object distributions. It is shown that the proposed method allows reconstructing the whole 3D wave fields for different setup parameters. This technique can be applied for 3D imaging. The comparison versus the successive iterative method [2] shows an accuracy advantage of the proposed algorithm provided that the type of modulation in the object plane is known.","2161-2021;21612021","Electronic:978-1-4244-6379-4; POD:978-1-4244-6377-0; USB:978-1-4244-6378-7","10.1109/3DTV.2010.5506340","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5506340","Imaging;holography;information retrieval;inverse problems;iterative methods;phase estimation","Holography;Image reconstruction;Iterative algorithms;Iterative methods;Optical imaging;Optical interferometry;Optical scattering;Phase measurement;Reconstruction algorithms;Signal processing algorithms","computational electromagnetics;electromagnetic wave propagation;image reconstruction;image retrieval;information retrieval","3D imaging;3D wave field phase retrieval;complex-valued object distribution;iterative method;multiple plane iterative Gerchberg-Saxton algorithm;sensor planes","","0","","8","","","7-9 June 2010","","IEEE","IEEE Conference Publications"
"Link spam detection based on genetic programming","X. Niu; S. Li; N. Yuan; X. Niu; C. Zhu","School of Computer Science & Technology, Shandong Jianzhu University, Jinan, China","2010 Sixth International Conference on Natural Computation","20100923","2010","7","","3359","3363","Link spam refers to unfairly gaining a high ranking on search engines for a web page by means of trickily manipulating the link graph to confuse the hyper-link structure analysis algorithms. It seriously affects the quality of the search engine query results. Detecting link spam has become a big challenge for web search. This paper proposes to learn a discriminant function to detect link spam by genetic programming. In this article, the representation of individuals, the genetic operators and the fitness function are studied. The experiments on WEBSPAM-UK2006 are carried out to find the preferable parameters and evaluate the validity of genetic programming. The experimental results show that this method can improve spam classification recall by 27.5%, F-measure by 12.1% and accuracy by 4.6% compared with SVM.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583657","Genetic Programming;Information Retrieval;Link Spam","Accuracy;Binary trees;Feature extraction;Genetic programming;Search engines;Unsolicited electronic mail;Web pages","genetic algorithms;query processing;search engines;unsolicited e-mail","WEBSPAM-UK2006;Web page;Web search;discriminant function;fitness function;genetic programming;hyper-link structure analysis algorithms;link graph manipulation;link spam detection;search engine query;spam classification","","2","","18","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Three Dimensions of Pitched Instrument Onset Detection","A. Holzapfel; Y. Stylianou; A. C. Gedik; B. Bozkurt","Institute of Computer Science, FORTH, Greece","IEEE Transactions on Audio, Speech, and Language Processing","20100816","2010","18","6","1517","1527","In this paper, we suggest a novel group delay based method for the onset detection of pitched instruments. It is proposed to approach the problem of onset detection by examining three dimensions separately: phase (i.e., group delay), magnitude and pitch. The evaluation of the suggested onset detectors for phase, pitch and magnitude is performed using a new publicly available and fully onset annotated database of monophonic recordings which is balanced in terms of included instruments and onset samples per instrument, while it contains different performance styles. Results show that the accuracy of onset detection depends on the type of instruments as well as on the style of performance. Combining the information contained in the three dimensions by means of a fusion at decision level leads to an improvement of onset detection by about 8% in terms of F-measure, compared to the best single dimension.","1558-7916;15587916","","10.1109/TASL.2009.2036298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5337997","Automatic music transcription;group delay;music information retrieval;onset detection","","acoustic signal processing;musical instruments;signal detection","F-measure;group delay-based method;magnitude onset detector;monophonic recordings;phase onset detector;pitched instrument onset detection","","22","1","37","","20091117","Aug. 2010","","IEEE","IEEE Journals & Magazines"
"Towards intelligent query processing based on Attribute-Oriented Generalization","X. Xu; Jiandong Yang","Simulation Center, Academy of Armored Force Engineering, Beijing, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2026","2030","Due to the intrinsic characteristics of the relational model, the standard database user interface forces users to be familiar with the database schema and underlying data to improve the efficiency of information retrieval. It proposes an intelligent query processing based on Attribute-Oriented Generalization (AOG) to better user experience during the information retrieval process. Firstly, it adds semantics discarded by the relational model to raw data through attribute-oriented generalization, and builds instances of Type Abstraction Hierarchy (TAH). Secondly, it constructs the knowledge base, which is designed on a relational mode, so that both the knowledge base and the underlying relational database can be handled in a single formalism by a relational query language. Thirdly, with the derived specific knowledge base incorporated into the underlying database, a prototype intelligent, interactive and straightforward query processing system with B/S architecture has been built at the top of SQL, which returns the semantically neighboring values and higher level more abstract values through the instance of TAH according to the results of the interaction with the user. Finally, three practical query examples are presented to further exemplify the main ideas and demonstrate the usefulness of the proposed query answering processes.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569667","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569667","AOG;information retrieval;intelligent query processing;knowledge base;relational model","Art;Artificial intelligence;Information retrieval;Prototypes;Query processing;Semantics","SQL;knowledge based systems;query processing;relational databases","B/S architecture;SQL;attribute-oriented generalization;information retrieval;intelligent query processing;knowledge based system;relational database;relational query language;type abstraction hierarchy","","0","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A development tool for search in distributed system","Yun Zhou","Department of Computer and Electrical Engineering, Xi'an Technological University, Shaanxi China","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","2","","V2-238","V2-242","A tool for information retrieval research and development in the peer-to-peer file-sharing domain is introduced. It is based on the popular Gnutella protocol granting us access to an enormous user base and a large data set. As an information retrieval tool, this system maintains many statistics and implements a number of information retrieval ranking functions. As a development tool, which is the main focus of this paper, it contains a data logger and an analyzer. The data logger allows users to log both incoming and outgoing queries and query results which eventually provide a way to generate a snapshot of the entire data set shared by the users. The data analyzer provides a simple user interface for performing analysis on collected data. An analysis conducted on a million incoming queries that were collected in our log files is discussed.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579218","Data Analysis;Distributed System;Information Retrieval","Engines","data loggers;information retrieval;peer-to-peer computing;protocols","Gnutella protocol granting;data analyzer;data logger;development tool;distributed system;information retrieval ranking function;peer to peer file sharing domain","","0","","20","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Cross-Media Retrieval Method Based on Temporal-spatial Clustering and Multimodal Fusion","Y. Liu; F. Zheng; K. Cai; B. Jiang","Inst. of Data & Knowledge Eng., Henan Univ., Kaifeng, China","2009 Fourth International Conference on Internet Computing for Science and Engineering","20100803","2009","","","78","84","Aiming at the problem of the ""semantic gap"" and the ""dimensionality curse"", this paper discussed the model of cross-media retrieval. The methods of feature extraction and fusion of multimedia were given for processing high-dimensional data, and a nonlinear hybrid classifier based on support vector hidden Markov models was design for implementation semantic mapping and learning. According to Shannon information theory, calculation methods of similarity and correlation were given to implement temporal-spatial clustering. Typhoon and other multimedia disaster data are selected for experiments and comparisons. Experimental results show that this method improves the performance of cross-media retrieval.","","CD-ROM:978-0-7695-4027-6; Electronic:978-1-4244-6755-6; POD:978-1-4244-6754-9","10.1109/ICICSE.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5521626","Content-based information retrieval;Cross-media retrieval;Multimodal fusion;Temporal-spatial clustering","Content based retrieval;Data engineering;Decision support systems;Educational institutions;Image retrieval;Information retrieval;Knowledge engineering;MPEG 7 Standard;Multimedia databases;Ontologies","hidden Markov models;information retrieval;information theory;multimedia communication","Shannon information theory;cross-media retrieval;dimensionality curse;feature extraction;learning;multimedia disaster data;multimodal fusion;nonlinear hybrid classifier;semantic gap;semantic mapping;support vector hidden Markov model;temporal-spatial clustering;typhoon","","1","","20","","","21-22 Dec. 2009","","IEEE","IEEE Conference Publications"
"A summary based language retrieval method","Peng Jiang; Kaifan Ji; Feng Wang; Weijiang Li","Yunnan Computer Technology Application Key Lab, Kunming University of Science and Technology, China, 650051","2010 International Conference on Computer and Communication Technologies in Agriculture Engineering","20100812","2010","1","","211","214","The performance of language retrieval method is largely determined by the accuracy of document language model. Motivated by the hypothesis that query-biased summary presents the information that is most relevant to a query, we propose a summary-biased approach to study the use of internal structures for the estimationod document language model. This method can be viewed as a two-stage language model, in the first stage, the document language model is smoothed by the query-biased summary, and in the second stage, the smoothed document language model is further smoothed by the collection language model. Moreover, our method can be used in feedback technique to estimate an improved query model.","2161-1092;21611092","Electronic:978-1-4244-6947-5; POD:978-1-4244-6944-4","10.1109/CCTAE.2010.5544552","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5544552","information retrieval;language model;summary","","document handling;information retrieval;linguistics;query languages","document language model;feedback technique;internal structures;language retrieval method summary;query biased summary","","2","","30","","","12-13 June 2010","","IEEE","IEEE Conference Publications"
"Personal assistance support framework for sensor networks","C. Richter; Y. Tanaka","M&#x00EA;me Media Laboratory, Graduate School of Information Science and Technology, Hokkaido University, N13 W8 Kita-ku Sapporo 060-8628 Japan","3rd International Conference on Human System Interaction","20100723","2010","","","620","627","In this paper we introduce a new framework for the development of context-aware knowledge by integrating the user's digital and physical environment. The developed knowledge can contribute to solve problems and challenges of wireless sensor networks within a context that is described by additional cyber-content. Sensor networks are exposed, intentionally or not, to dynamically changing network structures and suffer from unpredictably changing temporally and spatial resolution due to harsh environmental conditions, cost and usability aspects or low accessibility of defect remote wireless sensor nodes.","2158-2246;21582246","Electronic:978-1-4244-7562-9; POD:978-1-4244-7560-5","10.1109/HSI.2010.5514505","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5514505","activity recognition;context-aware knowledge;information retrieval;semantic desktop;semantic sensor-web;social network;wireless sensor network","Costs;Helium;Information retrieval;Social network services;Spatial resolution;Usability;Wireless sensor networks","telecommunication computing;ubiquitous computing;wireless sensor networks","context-aware knowledge;personal assistance support framework;remote wireless sensor nodes;sensor networks;wireless sensor networks","","1","","10","","","13-15 May 2010","","IEEE","IEEE Conference Publications"
"Interactive Music Archive Access System","M. Gallagher; M. Gainza; D. Fitzgerald; D. Barry; M. Cranitch; E. Coyle","Audio Research Group, Dublin Institute of Technology, Kevin St., Dublin 2 Ireland","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","723","724","The goal of the Interactive Music Archive Access System (IMAAS) project was to develop an interactive music archive access system which was capable of allowing an end-user to easily extract rhythmic, melodic and harmonic musical metadata descriptors from audio, and allow the user to interact with the archive contents in a manner not typically allowed in archive access systems. To this end, the IMAAS system incorporates a range of real-time interaction tools which allow the user to modify the retrieved audio in a number of ways including the ability to isolate individual instruments in stereo mixes, pitch and time-scale modification, and beat-synchronous looping. This demo gives an overview of the capabilities of the IMAAS application.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583187","Key and Time Signature Estimation;Music Information Retrieval;Music Transcription;Real-time Audio Processing;Sound Source Separation;Tempo Estimation","Data mining;Estimation;Harmonic analysis;Music;Real time systems;Source separation;Speech processing","information retrieval;music","IMAAS project;interactive music archive access system;real-time interaction tool","","0","","7","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"A new method for fuzzy query processing for document retrieval based on GFNQMA operators","S. J. Chen; H. C. Chu","Department of Information Management, National United University, Miao Li, Taiwan, R.O.C.","2010 International Conference on Electronics and Information Engineering","20100902","2010","2","","V2-364","V2-369","In the quadratic-mean averaging (QMA) operators have been proposed to overcome the drawbacks of the T-operators and the existing averaging operators (i.e., P-Norm operators, Infinite-One operators, Waller-Kraft operators, GMA operators and WPMA operators) to deal with fuzzy information retrieval of the AND and OR operations. However, the QMA operators can not deal with queries represented by generalized fuzzy numbers and interval-valued fuzzy numbers. In this research, we present generalized fuzzy-number quadratic-mean averaging (GFNQMA) operators to deal with queries based on generalized fuzzy numbers and interval-valued fuzzy numbers.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559799","Fuzzy queries;GFNQMA operators;Generalized fuzzy numbers;Information retrieval;Interval-valued fuzzy numbers","Bioinformatics;Decision making;Fuzzy sets;Information retrieval;Pragmatics;Query processing;Risk analysis","document handling;fuzzy set theory;query processing","GFNQMA operators;WPMA operators;Waller-Kraft operators;document retrieval;fuzzy numbers;fuzzy query processing;generalized fuzzy-number quadratic-mean averaging","","1","","29","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"Wearable Video Retrieval and Navigation System using GPS Data","D. Tancharoen; K. Aizawa","Dept. of Inf. Technol., Panyapiwat Inst. of Technol., Bangkok, Thailand","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1667","1672","We have investigated a wearable video system to capture our experiences by a wearable camera, microphone and some sensors including GPS receiver, etc. GPS receiver was used to record the user's tracks and identify the location of user's experiences by latitude and longitude coordinates. GPS receiver can also extract time, speed and direction that are benefit contexts for wearable video navigation. Thus, we attempt to use available data from GPS to extract the key events from wearable video. In this paper, we propose a wearable video retrieval and navigation by using GPS data. Our system provides two types of navigation functions including key frame based navigation and location based navigation. Key frame based navigation is used to extract the key frames from wearable video to summarize the video contents. Location based navigation can be used to retrieve the wearable video based on user's tracks by using a map. Both of them have the relationship and interfaces to present each other. We demonstrate the key frame extraction techniques based on moving speed detection, directional change detection and the comparison between time and distance sampling. The key frame extraction techniques were evaluated based on the performance to detect landmarks and desired events. The results showed that the navigation system using GPS data is helpful to retrieve and extract the key events during traveling scenes in daily life.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577956","GPS;information retrieval;key frame extraction;navigation;wearable video","Context;Data mining;Global Positioning System;Indexing;Receivers;Sensors","Global Positioning System;radio receivers;video retrieval","GPS data;GPS receiver;key frame based navigation;navigation system;wearable video retrieval","","2","","12","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"PAR: Partition-Annotate-Recommend Paradigm for Improved Accessibility in Digital Libraries","Q. Li; C. Zhang; J. Wang; L. Zhao","Southwestern Univ. of Finance & Econ., Chengdu, China","2010 International Conference on Management of e-Commerce and e-Government","20101111","2010","","","3","9","While navigation within complex information spaces is uneasy for all users, it is extremely difficult for visually impaired users who can not simply searching and browsing digital contents with a mouse. These users have to listen line by line using a screen reader program, which may be particularly inefficient in a large documents with complex structures and loose connections of relevant information that are hard to search and navigate. Consequently, they are especially penalized when the information being searched is hidden deeply. In this article, we introduce a partition-annotate-recommend (PAR) paradigm to improve the accessibility of digital libraries for visually impaired users. Our evaluation, involving the participation of visually impaired users, show that the RAIN system, built based on the PAR paradigm, reduces the navigational overhead significantly and enables visually impaired users to access complex digital libraries effectively.","","Electronic:978-0-7695-4245-4; POD:978-1-4244-8507-9","10.1109/ICMeCG.2010.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5628568","Accessibility;Digital Library;Information retrieval;Personalized Summarization;Recommendation;Text segmentation","Books;Clustering algorithms;Collaboration;Libraries;Navigation;Nearest neighbor searches;Rain","digital libraries;information retrieval","digital libraries;information retrieval;partition-annotate-recommend paradigm;recommendation;screen reader program;text segmentation","","1","","23","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Country of origin determination via Web mining techniques","M. Schedl; C. Schiketanz; K. Seyerlehner","Department of Computational Perception, Johannes Kepler University, Linz, Austria","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","1451","1456","The origin of a music artist or a band is an important kind of musical meta-data as it usually influences his/her/its music. In this paper, we propose three approaches to automatically determine the country of origin of a person or institution, which we apply to music artists and bands. The first approach investigates estimates of page counts returned for specific queries to Web search engines. The second approach uses term weighting functions for country-specific terms that occur on the top-ranked Web pages of an artist. The third approach applies to Web pages text distance measures between country-specific terms and key terms related to the concept or origin. We further present a thorough evaluation of the approaches taking into consideration different refinements. We show that we are able to outperform the first, nevertheless recent, approach to determine the origin of a music artist.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583235","Country of Origin Detection;Evaluation;Music Information Retrieval;Term Weighting;Web Mining","Context;Continents;Encyclopedias;Internet;Web pages;Weight measurement","Internet;data mining;information retrieval;music;search engines","Web mining;Web pages text distance measures;Web search engine;country-of-origin determination;music artist;musical meta-data;term weighting function","","1","","22","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
