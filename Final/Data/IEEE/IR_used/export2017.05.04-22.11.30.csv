"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7440478,7439311,7439372,7439346,7438641,7439980,7439315,7439322,7439326,7439305,7439368,7439371,7435747,7435480,7435961,7434288,7436339,7437030,7435477,7436995,7434190,7435182,7433765,7433268,7433253,7430631,7431480,7430101,7427389,7427327,7429135,7427343,7429609,7429390,7429101,7427696,6893023,7429370,7427323,7427563,7429235,7426904,7429350,7425808,7425972,7426111,7425976,7425967,7425914,7426109,7425802,7425818,7425938,7335650,7350158,7424391,7422281,7423597,7424037,7422495,7423977,7424679,7422290,7424074,7422374,7423210,7423589,7424448,7423480,7423997,7424626,7424440,7424184,7424427,7424057,7422311,7423092,7424386,7422988,7421265,7274268,7415452,7413855,7416338,7415169,7414823,7413895,7419534,7419561,7419584,7414689,7419003,7419452,7419466,7419623,7419554,7419596,7415358,7419556,7409020",2017/05/04 22:11:30
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Food hazard event extraction based on news and social media: A preliminary work","Kyoungrok Jang; Kangwook Lee; Gwan Jang; Seungyong Jung; Min-Gwan Seo; Sung-Hyon Myaeng","School of Computing, KAIST, Daejeon, Republic of Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","466","469","Detecting and disseminating food hazard information is a critical task that directly affects the public health. In spite of its importance, however, few systems are developed to automatically gather and analyze food hazard information. In this paper, we introduce our preliminary work to build such system. Our final system aims to detect and extract food hazard event from the live data shared on the Web. We defined information template for food hazard event. Then we used the template to extract informative keywords from the website of Ministry of Food and Drug Safety, the governmental organization responsible for ensuring food safety in Korea. We explain our work process, considerations, as well as our future work to implement our system.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425972","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425972","event extraction;food hazard;news;social media","Companies;Data mining;Feature extraction;Hazards;Media;Presses","food safety;information retrieval;social networking (online)","Korea;Ministry of Food and Drug Safety;Website;food hazard event detection;food hazard event extraction;food safety;information template;informative keyword extraction;news;social media","","","","4","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Smart devices for Intangible Cultural Heritage fruition","A. Pozzebon; S. Calamai","Department of Information Engineering and Mathematical Sciences, University of Siena, Italy","2015 Digital Heritage","20160225","2015","1","","333","336","This paper proposes a novel approach to the fruition of Intangible Cultural Heritage exploiting the technical features of smart devices. In particular, it presents a framework for a “sound tourism”, in which the perception of sites is directly transmitted by the voice of the local communities through the creation of an app model for the fruition of landscape, places, and locations by means of oral archives. That is, the app model aims at boosting the added value of Intangible Cultural Heritage (e.g. popular music, oral history, languages and accents, local tradition, and folklore) by re-using it in real application environments (e.g. for tourist purposes). The proposed solution rejects the use of a smartphone as a mere displayer of information embracing an innovative philosophy that considers the smart device as a tool for the playback of audio material stored in sound archives, leaving the user free to enjoy the site he/she is visiting without the need to interact with a screen.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7413895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413895","Intangible Cultural Heritage;app;smart devices;sound archives;storytelling","Augmented reality;Cultural differences;Europe;Global communication;History;Mobile handsets","Bluetooth;Global Positioning System;audio recording;augmented reality;history;information retrieval systems;interactive systems;mobile computing;near-field communication;travel industry","GPS;audio material playback;bluetooth beacons;innovative philosophy;intangible cultural heritage fruition;local communities;near field communication;oral archives;smart devices;sound archives;sound tourism;technical features","","1","","11","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Digital archiving - the current state at the National Archives of Zimbabwe","A. Bishi","Masvingo Polytechnic College, Zimbabwe","2015 Digital Heritage","20160225","2015","2","","403","404","In the cyber space environment the overwhelming greater part of recently created information is digital. The carriers for recording information have progressed over time from memory to a digital copy. Technological innovations in computing science have now called for the progression from traditional formats to a variety of modern media and further deepened the challenges of digital preservation in houses of memory. In spite of advances in computer technology, African collecting institutions fall short to initiate digitization projects and online access to cultural heritage. This paper seeks to articulate the current landscape of digital heritage preservation at the National Archives of Zimbabwe and examine the barriers that have hindered the development of proficient digital archiving systems. Preservation of digital heritage is becoming important, as they are getting more and more popular in the virtual drama arts communities. In this post-modern environment digital heritage has gained full recognition as cultural assets in various countries. The paper further makes several recommendations on the policies, procedures and strategies for improving the state of digital preservation in Zimbabwean cultural institutions.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419534","Preservation Zimbabwe Access","Africa;Bibliographies;Libraries","art;digital preservation;history;information retrieval systems","National Archives of Zimbabwe;Zimbabwean cultural institution;cultural asset;cultural heritage;cyber space environment;digital archiving system;digital heritage preservation;digital preservation;online access;post-modern environment digital heritage;virtual drama arts community","","","","4","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"On subspace projection autoassociative memories based on linear support vector regression","M. E. Valle; E. P. da Silva","Department of Applied Mathematics - Institute of Mathematics, Statistics, and Scientific Computing., University of Campinas. Campinas - S&#227;o Paulo, Brazil. CEP 13083-859","2015 Latin America Congress on Computational Intelligence (LA-CCI)","20160321","2015","","","1","6","Autossociative memories (AMs) are models inspired by the human brain ability to store and recall information. They should be able to retrieve a stored information upon presentation of a partial or corrupted item. An AM that projects the input onto a linear subspace is called subspace projection autoassociative memory (SPAM). The recall phase of a SPAM model is equivalent to a multi-linear regression problem. In particular, the optimal linear autoassociative memory (OLAM) corresponds to the SPAM model obtained by considering traditional least squares regression in the recall phase. In this paper, we present a novel class of SPAM models obtained by considering linear support vector regression (SVR). Precisely, we introduce three SPAM models based on primal, dual, and bi-level formulations of the linear e-support vector regression. A simple example is used throughout the paper to illustrate the noise tolerance of the proposed memory models.","","Electronic:978-1-4673-8418-6; POD:978-1-4673-8419-3","10.1109/LA-CCI.2015.7435961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435961","","Associative memory;Brain models;Computational modeling;Memory management;Robustness;Support vector machines","brain models;cognition;content-addressable storage;information retrieval;regression analysis;support vector machines","autossociative memories;human brain ability;information retrieval;information storage;linear e-support vector regression;linear support vector regression;memory models;multilinear regression problem;optimal linear autoassociative memory;subspace projection autoassociative memories;subspace projection autoassociative memory","","","","37","","","13-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"A Novel Privacy Preserving Keyword Search Scheme over Encrypted Cloud Data","X. Jiang; J. Yu; F. Kong; X. Cheng; R. Hao","Coll. of Inf. Eng., Qingdao Univ., Qingdao, China","2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)","20160303","2015","","","836","839","As the cloud computing becomes prevalent, data owners are motivated to outsource a large number of documents to the cloud for the great flexibility and convenience. Although encryption before outsourcing can keep user's data confidential, it raises a new challenge for users to retrieve some of the encrypted files containing specific keywords from the cloud. In this paper, we propose a novel privacy preserving keyword search scheme over encrypted cloud data to address this problem. To enable users to search over encrypted data, we firstly adopt a structure named as Inverted Matrix (IM) to build search index. The IM is consisted of a number of index vectors, each of which is associated with a keyword. Then we map a keyword to a value as an address used to locate the corresponding index vector. Finally, we mask index vectors with pseudo-random bits to obtain an Encrypted Enlarged Inverted Matrix (EEIM) to preserve the privacy of users. Through the security analysis, we show that our proposed scheme is secure.","","CD-ROM:978-1-4673-8317-2; Electronic:978-1-4673-9473-4; POD:978-1-4673-9474-1","10.1109/3PGCIC.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424679","cloud computing;keyword search;privacy preserving;searchable symmetric encryption","Cloud computing;Data privacy;Encryption;Indexes;Privacy;Servers","cloud computing;cryptography;data privacy;indexing;information retrieval;matrix algebra;vectors","IM;cloud computing;confidential data;encrypted cloud data;encrypted enlarged inverted matrix;encrypted file retrieval;outsourcing;privacy preserving keyword search scheme;pseudorandom bits;search index vectors","","","","12","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Reformulating the repository, Digital Intangible Heritage, empathic design and Greek/Unani medicinal practices","M. Khan","UNSW Arts & Design, University of New South Wales, Sydney, Australia","2015 Digital Heritage","20160225","2015","2","","487","488","Within the emerging domain of Digital Intangible Heritage, my research focuses on the continuity of cultural knowledge by proposing a new model for access to indigenous methodologies. Through the creation of a digital repository of Greek/Unani medicinal practices and an experimental web-based interface to this archive, the research defines a new framework for the description, representation and transmission of these practices. The Unani medicinal system is entrenched in the Middle Eastern and South Asian regions. Through analytic documentation of these practices, I intend to reveal the intricate relationships between a traditional Unani physician's life experience and clinical practices. For example, I will examine the lifestyle practices of a physician in relation to his diagnostic understanding of lifestyle diseases. Following analytic documentation using a range of digital capture tools and the classification of this material using an extended metadata schema - Dublin Core -the research challenge here is to create a sympathetic interactive information architecture for the repository. Drawing on `empathic design', `design probes' and `experiencing prototyping' the experimental web-based application intends to provide users with an intuitive interface through which to retrieve knowledge and experiences related to accomplished Unani physicians.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419561","Digital Intangible Heritage;Intangible Cultural Heritage;cultural/indigenous knowledge;empathic design;user-centric design","Cultural differences;Documentation;Global communication;Metadata","Internet;diseases;health care;history;information retrieval;meta data;patient diagnosis","Dublin Core;Greek/Unani medicinal practices;Middle Eastern;South Asian regions;Unani medicinal system;Unani physician life experience;analytic documentation;archive;clinical practices;cultural knowledge;design probes;diagnostic understanding;digital capture tools;digital intangible heritage;digital repository;empathic design;experiencing prototyping;experimental Web-based interface;indigenous methodologies;interactive information architecture;lifestyle diseases;material classification;metadata schema;physician lifestyle practices","","","","26","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Semantic Based Query Expansion for Arabic Question Answering Systems","H. Al-Chalabi; S. Ray; K. Shaalan","Inf. Technol. Dept., Al Khawarizmi Int. Coll., Al Ain, United Arab Emirates","2015 First International Conference on Arabic Computational Linguistics (ACLing)","20160303","2015","","","127","132","Question Answering Systems have emerged as a good alternative to search engines where they produce the desired information in a very precise way in the real time. However, one serious concern with the Question Answering system is that despite having answers of the questions in the knowledge base, they are not able to retrieve the answer due to mismatch between the words used by users and content creators. There has been a lot of research in the field of English and some European language Question Answering Systems to handle this issue. However, Arabic Question Answering Systems could not match the pace due to some inherent difficulties with the language itself as well as due to lack of tools available to assist the researchers. In this paper, we are presenting a method to add semantically equivalent keywords in the questions by using semantic resources. The experiments suggest that the proposed research can deliver highly accurate answers for Arabic questions.","","Electronic:978-1-4673-9155-9; POD:978-1-4673-9156-6","10.1109/ACLing.2015.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422290","Arabic;Arabic WordNet;Natural Language Processing;Query Expansion;Question Answering","Encyclopedias;Knowledge discovery;Search engines;Semantics;Syntactics;Text analysis","knowledge based systems;natural language processing;query processing;question answering (information retrieval);search engines","Arabic question answering systems;English;European language question answering systems;knowledge base;search engines;semantic based query expansion;semantic resources;semantically equivalent keywords","","","","33","","","17-20 April 2015","","IEEE","IEEE Conference Publications"
"Accumulated Citation Count as Fertileness of Scientific Article","S. Hirokawa; T. Nakatoh; H. Nakanishi","Res. Inst. for Inf. Technol., Kyushu Univ., Fukuoka, Japan","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","119","122","The literature survey by scientific bibliographic data base is indispensable in the research activities. We can find related articles with appropriate keywords. However, the threads of related research are not easy to grasp from the search result. It is necessary to repeat a search, judge a citation relation and figure out the thread. The present paper proposes the index ""accumulated citation count"" of a scientific article to measure the thread of citations that starts from the article.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424074","bibliometrics;citation;focused citation;impact factor","Bibliometrics;Couplings;Electronic mail;FCC;History;Indexes","bibliographic systems;citation analysis;information retrieval;scientific information systems","citation relation;citation thread measurement;index accumulated citation count;scientific article fertileness;scientific bibliographic data base","","","","20","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"The Evolution of a Sharing Platform into a Sustainable Business","I. Constantiou; B. Eaton; V. K. Tuunainen","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","1297","1306","A number of sharing economy start-ups have taken both digital and physical product markets by storm. These start-ups operate on two-sided platforms and enable sharing of physical products or services based on physical assets. Interestingly, they are subject to both the dynamics of the digital world (i.e., network effects), and the constraints of the physical world (i.e., issues of accountability when physical property is destroyed). We investigate how Airbnb, a sharing platform, evolve into a sustainable business with an in-depth case analysis based on data retrieved from a number of blogs providing information about Airbnb's actions. Our analysis with insights from platform economics and information infrastructures depicts two phases in the evolution process: creating the user base and augmenting the platform. With the two complementary theoretical perspectives we can offer a deeper understanding of the evolution of sharing platforms into sustainable and competitive businesses.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427343","Airbnb;case study;information infrastructures;platform economics;sharing economy","Blogs;Business;Complexity theory;Economics;Ecosystems;Industries;Smart phones","Web sites;electronic commerce;information retrieval","Airbnb platform;blogs;competitive businesses;data retrieval;digital product markets;digital world;in-depth case analysis;information infrastructures;physical assets;physical product markets;physical products sharing;physical services sharing;physical world;platform economics;sharing economy start-ups;sharing platform evolution;sustainable business;two-sided platforms;user base creation","","","","40","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Complex Network Analysis of a Tourism Content Sharing Network","A. Becheru; C. Badica; M. Antonie","","2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)","20160307","2015","","","407","414","This paper presents results of the analysis of a tourism information Web-site (AmFostAcolo.ro) by using Complex Networks (CN) methods. The work accomplished here complements a previous paper, where we discussed data extraction and modelling into a complex network. Properties of the resulted network, communities and vertices are looked upon, in order to extract useful information and detect social phenomena. Temporal analysis methods are employed for examining the evolution of the web-site. The results obtained prove the natural development of the Web-site and the usefulness of CN analysis methods in this scenario.","","Electronic:978-1-5090-0461-4; POD:978-1-5090-0462-1","10.1109/SYNASC.2015.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426111","","Algorithm design and analysis;Companies;Complex networks;Data mining;Electronic mail;Feature extraction;XML","Web sites;information retrieval;travel industry","CN analysis methods;complex network analysis;data extraction;data modelling;information extraction;social phenomena detection;temporal analysis method;tourism content sharing network;tourism information Web-site analysis","","","","30","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"An Approach for Building a Semi-automatic Online Consultancy System","N. Thai-Nghe; Q. D. Truong","Coll. of Inf. & Commun. Technol., Can Tho Univ., Can Tho, Vietnam","2015 International Conference on Advanced Computing and Applications (ACOMP)","20160303","2015","","","51","58","This study proposes an approach for building a semi-automatic consultancy (question-answering) system via mobile/Internet networks. This approach is a combination of natural language (text) processing and machine learning method. For building the system, at first, we need to build modules for sending and receiving messages via SMS/Email/Webpage. These modules are used for users to send/receive their questions that need to be consulted. While waiting for answering from the system, the user will be recommended similar questions which have been answered in the past by using Cosine similarity. Next, a message classification module is built using a combination of text processing (e.g., word segmentation, stop word deletion) and machine learning method (e.g., SVM). Finally, a whole web-based system is conducted to integrate these modules. The proposed approach is applied for a case study of consulting on Vietnam National Entrance Test, which is an important test for the pupils to get into universities. Initial results show that the system can automatically classify the questions at 82.33% of accuracy, thus, this approach could be promising for (semi) automatic online consultancy systems.","","Electronic:978-1-4673-8234-2; POD:978-1-4673-8235-9","10.1109/ACOMP.2015.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422374","Message classification;semi-automatic question-answering system;text classification;text recommendation","Buildings;Classification algorithms;Data models;Support vector machines;Systems architecture;Training;Training data","Internet;educational institutions;learning (artificial intelligence);mobile computing;natural language processing;pattern classification;question answering (information retrieval);support vector machines;text analysis","Internet networks;SVM;Vietnam National Entrance Test;Web-based system;cosine similarity;machine learning method;message classification module;mobile networks;natural language processing;question-answering system;semiautomatic online consultancy system;stop word deletion;text processing;word segmentation","","","","19","","","23-25 Nov. 2015","","IEEE","IEEE Conference Publications"
"Expert Achievements Model for Scientific and Technological Based on Association Mining","X. Qu; R. Hu; L. Zhou; L. Wang; Q. Zhu","Fac. of Comput. Eng., Huaiyin Inst. of Technol., Huaiyin, China","2015 14th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES)","20160310","2015","","","272","275","In order to improve the use value of expert information, the Information technology experts Mining System is designed and realized which based on Mining Association. University website on the Internet, CNKI and Soopat patent website to provide expert information related data. Through the application system designed based on Web crawling, association mining model and page analysis, good results achieved by digging the expert information from universities and first-class hospitals in Jiangsu. According to the data mining from the database of Soo PAT and CNKI, correlation algorithm model of the technology experts mining system is designed and achieved 92% of the associated information accuracy and 97% of the expert information accuracy in experiment, which provided the data support for the system design. Available to the government departments or technology enterprises to browse, the system can meet the demands of the information of scientific and technological information of technology experts of government science and technology departments and science and technology enterprises.","","Electronic:978-1-4673-6593-2; POD:978-1-4673-6594-9","10.1109/DCABES.2015.75","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429609","Association mining;Expert information;Web crawler;Web mining","Crawlers;Databases;Government;Hospitals;Patents;Web mining","Internet;Web sites;data mining;information retrieval;scientific information systems","CNKI database;Internet;Jiangsu;SooPAT database;SooPAT patent Website;University Website;Web crawling;association mining model;data mining;expert achievement model;expert information;expert information digging;government science and technology departments;information technology expert mining system;page analysis;scientific information;technological information","","","","12","","","18-24 Aug. 2015","","IEEE","IEEE Conference Publications"
"Extracting Topical Information of Tweets Using Hashtags","Z. Z. Alp; S. G. Öðüdücü","Inst. of Sci. & Technol., Istanbul Tech. Univ., Istanbul, Turkey","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","644","648","Twitter is one of the largest micro blogging web sites where users share news, their opinions, moods, recommendations by posting text messages, and it is mostly used like a news media. Since the data being shared via Twitter is vast, many researches are focusing on extracting meaningful information with the help of information retrieval systems. Retrieving meaningful information from social media applications became important for several tasks such as sentiment analysis, detecting anomalies, and recommendation systems. Topic modeling is one of the mostly studied and hard problems in information retrieval area, and it is even more challenging to model topics when the documents are too short such as tweets. In this paper, we focus on developing an effective and efficient method to overcome this challenge of tweets being too short for topic modeling. We compare different topic modeling schemes, one of which is not studied before, based on Latent Dirichlet Allocation (LDA) that merges tweets in order to improve LDA performance. We also demonstrate our experimental results with unbiased data collection and evaluation methodologies.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424391","","Data collection;Data mining;Market research;Media;Tagging;Twitter","information retrieval;sentiment analysis;social networking (online)","LDA;Twitter;anomalies detection;data collection;hashtags;information retrieval systems;latent Dirichlet allocation;microblogging Web sites;news media;recommendation systems;sentiment analysis;social media applications;text messages posting;topic modeling;topical information extraction;tweets","","1","","17","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"APEM: Automatic paraphrase evaluation using morphological analysis for the Korean language","S. W. Moon; G. Gweon; H. Choi; J. Heo","Dep. Of Knowledge Service Engineering, KAIST, Daejeon, Rep. Of Korea","2016 18th International Conference on Advanced Communication Technology (ICACT)","20160303","2016","","","680","684","Paraphrase evaluation is used to determine whether two input sentences share a same meaning. The automatic analysis for paraphrase evaluation technology has a potential use in the area of information retrieval technology since correctly paraphrased sentences can be used as alternative input sentences in the retrieval process. In this paper, we suggest an automatic paraphrase evaluation method using morphological analysis (APEM), which is suitable for the Korean language. Using APEM and its variations, we present preliminary results on how our automatic evaluation scores compare to the existing method of bilingual evaluation understudy (BLEU).","","CD:978-8-9968-6507-0; Electronic:978-8-9968-6506-3","10.1109/ICACT.2016.7423597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423597","Morphological analysis;Paraphrase evaluation","Dictionaries;Google;Manuals;Semantics;Standards;Surface morphology","computational linguistics;information retrieval","APEM;BLEU;Korean language;automatic evaluation scores;automatic paraphrase evaluation method using morphological analysis;bilingual evaluation understudy;information retrieval technology","","","","19","","","Jan. 31 2016-Feb. 3 2016","","IEEE","IEEE Conference Publications"
"PrivacyMod: Controlling and Monitoring Abuse of Privacy-Related Data by Android Applications","P. Silva; V. J. P. Amorim; F. N. Ribeiro; I. Muzetti","Dept. of Comput. & Syst., Fed. Univ. of Ouro Preto, Ouro Preto, Brazil","2015 Brazilian Symposium on Computing Systems Engineering (SBESC)","20160303","2015","","","42","47","The Android Open Source Project, currently managed by Google, provides a software stack for Android operating system. Despite the efforts to create a scalable and secure OS, Google is failing to deal with users' privacy information. Any Android application (including third-party ones) can retrieve sensible data from devices without providing any notification to the user. This paper presents a new Android OS source code extension module to monitor and control relevant privacy data on third-party applications. Once a data operation of this type is detected, the user is notified in real time, creating a live history of use/abuse. Results showed many traditional applications making abuse of users' device confidential information. Our proposed mechanism enables the user to be aware and manage the use of every sensible information on his device.","","Electronic:978-1-5090-0182-8; POD:978-1-5090-0183-5","10.1109/SBESC.2015.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423210","","Androids;Google;Humanoid robots;Monitoring;Operating systems;Privacy;Smart phones","Android (operating system);data privacy;information retrieval;public domain software;security of data;software reliability;source code (software)","Android OS source code extension module;Android open source project;Android operating system;Google;OS scalability;OS security;PrivacyMod;data operation;privacy-related data control;privacy-related data monitoring;sensible data retrieval;software stack;user device confidential information;user privacy information","","","","15","","","3-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"MLM-rank: A Ranking Algorithm Based on the Minimal Learning Machine","A. S. C. Alencar; W. L. Caldas; J. P. P. Gomes; A. H. d. Souza; P. A. C. Aguilar; C. Rodrigues; W. Franco; M. F. d. Castro; R. M. C. Andrade","Comput. Sci. Dept., Fed. Univ. of Ceara, Fortaleza, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","305","309","Ranking is an important task in information retrieval and has gained much attention in recent years. Among the most used strategies, machine learning has achieved important results. The current work proposes a new machine learning based ranking algorithm, the MLM-RANK. MLM-RANK is based on the recently proposed Minimal Learning Machine (MLM). MLM is a supervised learning method that requires the adjustment of a single hyper parameter. The proposed method was evaluated against Prank and ELM Rank, both state of the art point wise ranking methods. In these tests MLM-RANK achieved promising results.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424037","minimal learning machine;ranking;regession","Cost function;Estimation;Mathematical model;Supervised learning;Support vector machines;Training;Training data","information retrieval;learning (artificial intelligence)","ELM Rank algorithm;MLM-Rank algorithm;Prank algorithm;information retrieval;minimal learning machine;pointwise ranking methods;ranking algorithm;supervised learning method","","","","15","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Resume Recommendation Model for Online Recruitment","Z. Wang; X. Tang; D. Chen","Sch. of Software Eng., Shanghai Jiao Tong Univ., Shanghai, China","2015 11th International Conference on Semantics, Knowledge and Grids (SKG)","20160310","2015","","","256","259","The traditional information retrieving method, which is based on keyword, cannot meet the needs of users of online recruitment. We proposed an efficient algorithm that is based on an automatically modeling of user demands. We use vector to present job and resume and the core part is the Genetic Algorithm. The GA algorithm is used to learn the recruitment records of a job and then establish the user's demand model such that the job-resume matching model is achieved.","","Electronic:978-1-4673-9808-4; POD:978-1-4673-9809-1","10.1109/SKG.2015.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429390","genetic algorithm;online recruitment","Biological cells;Genetic algorithms;Recruitment;Resumes;Sociology;Statistics;Training","employment;genetic algorithms;information retrieval;job specification;recruitment","GA algorithm;genetic algorithm;information retrieving method;job-resume matching model;online recruitment;recruitment records;resume recommendation model;user demand model;user demands","","1","","4","","","19-21 Aug. 2015","","IEEE","IEEE Conference Publications"
"Features of web subject-related image and its retrieval significance","D. Zhan; Y. Zou","Sun Yat-Sen University, Guangzhou, China","2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20160225","2015","","","1151","1154","Keyword information retrieval is the mainstream way of information retrieval at present. Users need to scan a large amount of text information in the search results to find the information they want, but the process causes inefficiency and poor user experience. In fact, images in the web pages can provide a direct-viewing and fast retrieval way. Through the research on the features of web subject-related image and achieve its automatic identification and extraction, we can display it in the thumbnail together with the page title and summary in the results pages. It can help users filter and browse information in a more convenient way. This paper establishes a web image attribute system from both HTML attributes and external attributes. Then through corresponding automatic extracting algorithms and data analysis it succeeds to gain 16 feature rules of web subject-related image, and finishes building a web subject-related image feature model. The model proves to obtain more than 99% of the extraction rate and filtering rate while applying to the sample data, demonstrating its value in web information retrieval.","","Electronic:978-9-8814-7680-7; POD:978-1-4673-9593-9","10.1109/APSIPA.2015.7415452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415452","","Data mining;Feature extraction;Information filters;Web pages","Internet;Web sites;data analysis;hypermedia markup languages;image retrieval;information retrieval;text analysis","HTML attribute;Web image attribute system;Web information retrieval;Web page;Web subject-related image feature model;automatic extracting algorithm;automatic extraction;automatic identification;data analysis;external attribute;extraction rate;filtering rate;page title;retrieval significance;sample data;text information;user experience","","","","7","","","16-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"Ontological-semantic text analysis and the question answering system using data from ontology","V. A. Kuznetsov; V. A. Mochalov; A. V. Mochalova","Petrozavodsk State University, Lenina str. 33, 185910 Petrozavodsk, Russia","2016 18th International Conference on Advanced Communication Technology (ICACT)","20160303","2016","","","651","658","Today, with an avalanching increase in information, the task of developing the systems that allow user to quickly search desired information in large text volumes is becoming more and more urgent. An example of such system is the question answering one. In the work we describe an architecture of such system which work is based on utilizing data from an ontology. We propose an algorithm for automatic update of the ontology basing on use of an expert system and ontological rules for logical inference. We also describe an ontology with the structure based on object-oriented model and describe the functions that are used to update the ontology and extract data from it. We describe the way to update the ontology and to modify the stored data using the rules stored in the ontology. For writing ontological-semantic rules we use the Drools expert system that utilizes the PHREK algorithm for fast pattern matching. We analyze the issues of using Apache Spark system for distributed implementation of the algorithm.","","CD:978-8-9968-6507-0; Electronic:978-8-9968-6506-3","10.1109/ICACT.2016.7423589","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423589","Question Answering System;expert systems;ontology;semantic analysis","Dictionaries;Joining processes;Knowledge discovery;Object recognition;Ontologies;Semantics;Text processing","expert systems;inference mechanisms;ontologies (artificial intelligence);pattern matching;question answering (information retrieval);text analysis","Apache Spark system;Drools expert system;PHREK algorithm;logical inference;object-oriented model;ontological rules;ontological-semantic text analysis;pattern matching;question answering system","","","","23","","","Jan. 31 2016-Feb. 3 2016","","IEEE","IEEE Conference Publications"
"An Image Digital Archive for Substantiating the Acculturation of Clothing Culture in Japan","H. Takahashi","MCD Project, Nat. Museum of Ethnology, Suita, Japan","2015 International Conference on Culture and Computing (Culture Computing)","20160314","2015","","","219","220","This paper describes the system of Image Digital Archive of Fashion, Dress and Behavior from 1868 to 1945 in Japan. This image digital archive exhibits the history of acculturation of Japanese clothing life through 10,000 pieces of images and photos. It is useful for the study of the clothing culture in Japan.","","CD-ROM:978-1-4673-8231-1; Electronic:978-1-4673-8232-8; POD:978-1-4673-8233-5","10.1109/Culture.and.Computing.2015.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433268","Acculturation;Behavior;Dress;Fashion;Kimono;Westernization","Clothing;Databases;History;Image restoration;Informatics;Metadata;Standards","clothing;information retrieval systems;social sciences computing","Japanese clothing life acculturation history;clothing culture acculturation;image digital archive of fashion-dress-behavior system","","","","2","","","17-19 Oct. 2015","","IEEE","IEEE Conference Publications"
"Archiving broadcasters' websites a discussion of web archiving as context to the radio and television collection","A. Goos","Netherlands Institute for Sound and Vision, Hilversum, The Netherlands","2015 Digital Heritage","20160225","2015","2","","627","630","The Netherlands Institute for Sound and Vision decided, after a series of pilots, to begin archiving websites. Its aim is to archive websites that form a complement to its collection, which is mainly focused on audio visual materials and contains hundreds of thousands of hours of Dutch radio and television shows. The Institute believes radio and television is no longer just the broadcasted show. The program is larger and the internet plays a major role in how radio and television are being consumed. In order to recreate an evening of television from 2015 for future researchers, students or other interested parties, one cannot overlook the importance of the internet.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419584","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419584","radio;television;web archiving;websites","Feeds;Internet;Law;Media;TV;Twitter","Internet;audio-visual systems;information retrieval systems;radio broadcasting;television broadcasting","Dutch radio shows;Dutch television shows;Internet;Netherlands Institute for Sound and Vision;audio-visual materials;broadcaster Web site archiving","","","","6","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Java embedded storage for time series and meta data in Smart Grids","S. Cejka; R. Mosshammer; A. Einfalt","Siemens AG, Corporate Technology","2015 IEEE International Conference on Smart Grid Communications (SmartGridComm)","20160321","2015","","","434","439","We present a Java-based embedded data store for edge-to-cloud storage optimized for Smart Grid time-series measurements. The key performance indicators expected of applications and operators of a Smart Grid monitoring and control system - frequent readouts, immutability, statistical indicators - are optimally supported. Furthermore, the data store is tailored for operation on platforms with limited storage and processing resources. We show that our implementation is superior to state of the art and off-the-shelf solutions in data retrieval time and needed storage size.","","Electronic:978-1-4673-8289-2; POD:978-1-4673-8290-8","10.1109/SmartGridComm.2015.7436339","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436339","","Benchmark testing;Current measurement;Databases;Java;Protocols;Smart grids;Time series analysis","Java;embedded systems;information retrieval;meta data;power system control;power system economics;power system measurement;smart power grids;statistical analysis;storage allocation;time series","Java-based embedded data storage;data retrieval time;edge-to-cloud storage;meta data;performance indicator;smart grid control system;smart grid monitoring system;smart grid time-series measurement;statistical indicator","","2","","9","","","2-5 Nov. 2015","","IEEE","IEEE Conference Publications"
"Neural Modeling and Content Extraction","B. S. Charulatha; Paulrodrigues; T. Chitralekha; A. RajaRaman; SasikumarSreedharan","JNTUK, Kakinada, India","2015 Second International Conference on Soft Computing and Machine Intelligence (ISCMI)","20160225","2015","","","130","133","Internet and mobile computing have become a major societal force in that down-to-earth problems and issues are being addressed and sorted out. For this to be effective, information and content extraction need to be at a basic generic level to address different sources and types of web documents and preferably not dependent on any major software. The present study is a development in this direction and focuses on extraction of information from the available text and media-type data as it is stored in the computer, in digital form. The approach is based on operating generic pixel-maps-as stored for any data-so that issues of language, text-script and format do not pose problems. With the pixel-maps, as bases, different methods are used to convert into a numerical form for suitable neural modeling and content is extracted with ease so that approach is universal. Statistical features of the pixel-maps are extracted from the pixel map matrix of the image. The extracted features are presented to neural model and standard Back Propagation algorithm with hidden layers is used to extract content. The accuracy is compared to give the validity of the approach as to how the content extraction within certain bounds could be possible for any web page.","","Electronic:978-1-4673-9819-0; POD:978-1-4673-9820-6","10.1109/ISCMI.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7414689","Back Propogation;Content Extraction;Informatio;Neural model","Computers;Data mining;Data models;Feature extraction;Matrix converters;Standards;Web pages","Web sites;backpropagation;feature extraction;information retrieval;text analysis","Internet;Web documents;Web page;backpropagation algorithm;content extraction;digital form;feature extraction;generic pixel-maps;information extraction;mobile computing;neural modeling;pixel map matrix;statistical features;text-script","","","","6","","","23-24 Nov. 2015","","IEEE","IEEE Conference Publications"
"NewsCubeSum: A Personalized Multidimensional News Update Summarization System","D. Wang; L. Li; T. Li","Dept. of Copm. & Elc. Eng. & Comput., Sci. Florida Atlantic Univ., Boca Raton, FL, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","981","986","Popular online publishers produce huge amount of news articles every day, so it is important to summarize the most up-to-the-minute information to help users quickly know the progresses of their interested news events. In this paper, we develop NewsCubeSum, a novel personalized news summarization system utilizing OLAP and supervised sentence selection techniques to generate brief summaries delivering news updates in multiple dimensions (such as time, entity, and topic). An illustrative case study and experimental results on summarization performance comparisons are provided to show the effectiveness of NewsCubeSum.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424448","","Conferences;DH-HEMTs;Integrated circuits","Internet;data mining;information retrieval;natural language processing;text analysis","NewsCubeSum;OLAP;brief summary;news articles;news events;online publishers;personalized multidimensional news update summarization system;supervised sentence selection technique;up-to-the-minute information","","","","22","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Literature search framework by analyzing key aspects","Z. Si; G. Dai; Z. Niu","School of Computer Science, Beijing Institute of Technology, Beijing, China","2016 18th International Conference on Advanced Communication Technology (ICACT)","20160303","2016","","","581","585","Quickly moving to an unfamiliar field for researchers is painful due to a mass of scientific articles to study without knowing their research contents. Research point and its implementation method are two helpful aspects. However these two aspects are difficult to be achieved without appropriate semantic tools. This paper proposes a literature search framework which supports a new perspective retrieval of research point and implementation method of articles. This framework contains four components: extracting the above two aspects from articles, analyzing them by semantic similarity, ontology population and index building. The experimental results verify the effectiveness of this framework. And we apply this framework to the field of computer science, demonstrate the prototype system.","","CD:978-8-9968-6507-0; Electronic:978-8-9968-6506-3","10.1109/ICACT.2016.7423480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423480","framework;information extraction;literature search;semantic similarity","Computer science;Data mining;Indexes;Ontologies;Semantics;Sociology;Statistics","information retrieval;ontologies (artificial intelligence)","computer science;index building;literature search framework;ontology population;perspective retrieval;research point;scientific article;semantic similarity;semantic tool","","","","16","","","Jan. 31 2016-Feb. 3 2016","","IEEE","IEEE Conference Publications"
"Design and Implementation of Clinical Data Integration and Management System Based on Hadoop Platform","D. M. Lyu; Y. Tian; Y. Wang; D. Y. Tong; W. W. Yin; J. S. Li","EMR & Intell. Expert Syst. Eng. Res. Center of Minist. of Educ., Zhejiang Univ. Hangzhou, Hangzhou, China","2015 7th International Conference on Information Technology in Medicine and Education (ITME)","20160310","2015","","","76","79","With the increasing size of the medical data, the traditional processing methods and tools could not meet the requirements. So, resolving the challenges that the big medical data faces, is critical to realizing the promise of the big data [1]. Aiming at the problems in the big data integration process, this paper proposes the clinical data integration and management system based on Hadoop platform. As a result, the system can connect with multiple heterogeneous data source, such as EMR, PACS, LIS and so on. And then, on the basis of the data sharing, it can retrieve the patient's medical records and manage the different information.","","CD-ROM:978-1-4673-8301-1; Electronic:978-1-4673-8302-8; POD:978-1-4673-8303-5","10.1109/ITME.2015.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429101","Hadoop platform;clinical data;data integration and management","Big data;Business;Clinical diagnosis;Data integration;Engines;Picture archiving and communication systems;Servers","Big Data;data integration;information retrieval;medical information systems;parallel processing","EMR;Hadoop platform;LIS;PACS;big medical data integration process;clinical data integration and management system design;clinical data integration and management system implementation;data sharing;information management;multiple heterogeneous data source;patient medical record retrieval","","","","9","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"Block-Based Method and Its System for Outsourcing Data by Using Onions of Encryption","S. Ping; H. Wu; L. Wang","Sch. of Comput. Sci. & Commun. Eng., Jiangsu Univ., Zhenjiang, China","2015 Third International Conference on Advanced Cloud and Big Data","20160321","2015","","","241","246","With the rapid development and popularity of cloud computing, data outsourcing has become an essential widely used data service. Data owner uploads their private information to the cloud server and relies on the services that the cloud provides to execute some operations on data. When data is stored in the cloud, performing data retrieval while preserving confidentiality of data is a big challenge. In order to protect data confidentiality and security, the sensitive data need to be encrypted before outsourcing to the cloud. However, with the increasing number of encrypted data stored in the cloud, how to retrieve required information efficiently from the mass encrypted data is still a challenge urgently to be addressed. In this paper, a new ciphertext retrieval method is proposed to solve the above problem. In this method, the database is divided into several block encryption, and each block encryption is assigned to an index file correspondingly. The index files are encrypted with onion encryption, which allows the server to execute the queries while protecting data confidentiality. The experiment indicates that this encryption scheme can improve the efficiency of encrypted database retrieve.","","Electronic:978-1-4673-8537-4; POD:978-1-4673-8538-1","10.1109/CBD.2015.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435480","cloud storage;data retrieval;index encryption;onions of encryption","Cloud computing;Encryption;Indexes;Public key;Servers","cloud computing;cryptography;data protection;information retrieval;outsourcing;storage management","block-based encryption method;ciphertext retrieval method;cloud computing;cloud server;data confidentiality protection;data outsourcing;data owner;data retrieval;data security;data service;mass encrypted data;onion encryption","","","","21","","","Oct. 30 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"How to Effectively Train IBM Watson: Classroom Experience","S. S. Murtaza; P. Lak; A. Bener; A. Pischdotchian","Data Sci. Lab., Ryerson Univ., Toronto, ON, Canada","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","1663","1670","Watson is a question answering system that uses natural language processing, information retrieval, knowledge interpretation, automated reasoning and machine learning techniques. It can analyze millions of documents and answer most of the questions accurately with varying level of confidence. However, training IBM Watson may be tedious and may not be efficient if certain set of guidelines are not followed. In this paper, we discuss an effective strategy to train IBM Watson question answering system. We experienced this strategy during the classroom teaching of IBM Watson at Ryerson University in Big Data Analytics certification program. We have observed that if documents are well segmented, contain relevant titles and have consistent formatting, then the recall of the answers can be as high as 95%.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427389","IBM Watson;Question answering system","Best practices;Guidelines;Knowledge discovery;Natural language processing;Training;Urban areas","Big Data;computer aided instruction;computer science education;data analysis;inference mechanisms;learning (artificial intelligence);natural language processing;question answering (information retrieval);teaching","IBM Watson question answering system;Ryerson University;automated reasoning;big data analytics certification program;classroom experience;classroom teaching;document segmentation;information retrieval;knowledge interpretation;machine learning techniques;natural language processing","","","","17","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Scene recognition based on extreme learning machine for digital video archive management","D. Cheng; W. Yu; X. He; S. Ni; J. Lv; W. Zeng; Y. Yuanlong","Anhui Provincial Power Co. Ltd., State GRIP, China","2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20160225","2015","","","1619","1624","Video is a rich media widely used in many of our daily life applications like education, entertainment, surveillance, etc. In order to retrieve rapidly, it is necessary to establish digital archive for storing these videos. However, it is not realistic to store vast amounts of video data into digital archive artificially. This paper proposes a new method for the task of video digital archive management by employing scene recognition technology based on extreme learning machine (ELM). This paper only focuses on scene recognition technology which is the key step of digital video archive management. Dense scale invariant feature transform (dense SIFT) features are used as features in this proposed method. The 15-Scenes dataset with more than 4000 images is used. Experimental results have shown that this proposed method achieves not only high recognition accuracy but also extremely low computational cost.","","Electronic:978-1-4673-9675-2; USB:978-1-4673-9674-5","10.1109/ROBIO.2015.7419003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419003","dense scale invariant feature transform;extreme learning machine;video digital archive management","Clustering algorithms;Databases;Feature extraction;Histograms;Support vector machines;Training;Transforms","information retrieval systems;learning (artificial intelligence);transforms;video signal processing","ELM;dense SIFT features;dense scale invariant feature transform features;digital video archive management;extreme learning machine;scene recognition technology;video digital archive management;video storage","","","","10","","","6-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Ontology-based model for Arabic lexicons: An application of the Place Nouns in the Holy Quran","W. Alromima; I. F. Moawad; R. Elgohary; M. Aref","Faculty of Computer and Information Science, Ain Shams University, Cairo, Egypt","2015 11th International Computer Engineering Conference (ICENCO)","20160225","2015","","","137","143","Ontology is an explicit specification of conceptualization. It defines the terms with specified relationships between them and can be interpreted by both humans and computers. In general, there are scare semantic resources for Arabic language especially in Arabic ontologies. These semantic resources are very essential components in both Information Retrieval and Natural Language Processing applications like search engines, question answering, machine translation, etc. In recent years, many researchers are interested in building Arabic sematic resources, which are then can be exploited by others to build Arabic sematic applications. Recently, a proposed ontological model for “Time Nouns” vocabulary in the Holy Quran was introduced. To share towards building an integrated and unified ontology for Arabic language, in this paper, we are proposing an ontology-based model for Arabic language vocabulary associated with “Place Nouns” in the Holy Quran. This ontology is represented by the Web Ontology Language (OWL), which is the standard language for the semantic web. The ontology will be useful in the knowledge of the Islamic learning, linguistics researches, and Semantic Web applications.","","Electronic:978-1-5090-0275-7; POD:978-1-5090-0276-4","10.1109/ICENCO.2015.7416338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416338","Arabic Domain;Arabic Language;Domain Ontology;Holy Quran;Place Nouns;Semantic Representation","Chlorine;Cities and towns;Knowledge engineering","information retrieval;knowledge representation languages;linguistics;natural language processing;ontologies (artificial intelligence);semantic Web","Arabic language vocabulary;Arabic lexicons;Arabic ontologies;Arabic sematic applications;Arabic sematic resources;Holy Quran;Islamic learning;OWL;Semantic Web applications;Web Ontology Language;information retrieval;linguistics researches;machine translation;natural language processing;ontology-based model;place nouns;question answering;search engines","","","","","","","29-30 Dec. 2015","","IEEE","IEEE Conference Publications"
"Detection and Visual Inspection of Highly Obfuscated Plagiarisms","A. Schmidt; S. Bühler; R. Senger; S. Scholz; M. Dickerhof","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","4113","4122","In this paper, we present a framework for the detection of highly obfuscated plagiarisms. In contrast to existing plagiarism detection systems, which typically consist of the steps ""source retrieval"" and ""text alignment"", we introduce an intermediate step to detect interfragment relationships. This additional step fills the gap between the document level result of the source retrieval step and the fine granular n-gram input of the text alignment step. In the new intermediate step, fragments of about 50 to 60 words are examined and compared using an extended Jaccard measure to handle synonyms/ hypernyms. Additionally, the Jaccard measure is weighted to consider different relevance of words. The framework also includes an intuitive graphical visualization using heatmaps, which can be used for the easy visual inspection of possible plagiarisms without the final text alignment step. A number of experiments, performed with our implemented prototype, show the suitability of our approach.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427696","cross language plagiarism;obfuscated plagiarism;plagiarism detection system;visual inspection system","Heating;Inspection;Memory management;Plagiarism;Search engines;Visualization;Vocabulary","information retrieval;inspection;text analysis","Jaccard measure;graphical visualization;heatmaps;highly obfuscated plagiarisms;plagiarism detection systems;source retrieval step;text alignment step;visual inspection","","","","17","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Protecting Your Right: Verifiable Attribute-Based Keyword Search with Fine-Grained Owner-Enforced Search Authorization in the Cloud","W. Sun; S. Yu; W. Lou; Y. T. Hou; H. Li","State Key Laboratory of Integrated Services Networks, Xidian University, Xi&#x0027;an, Shaanxi, China","IEEE Transactions on Parallel and Distributed Systems","20160310","2016","27","4","1187","1198","Search over encrypted data is a critically important enabling technique in cloud computing, where encryption-before-outsourcing is a fundamental solution to protecting user data privacy in the untrusted cloud server environment. Many secure search schemes have been focusing on the single-contributor scenario, where the outsourced dataset or the secure searchable index of the dataset are encrypted and managed by a single owner, typically based on symmetric cryptography. In this paper, we focus on a different yet more challenging scenario where the outsourced dataset can be contributed from multiple owners and are searchable by multiple users, i.e., multi-user multi-contributor case. Inspired by attribute-based encryption (ABE), we present the first attribute-based keyword search scheme with efficient user revocation (ABKS-UR) that enables scalable fine-grained (i.e., file-level) search authorization. Our scheme allows multiple owners to encrypt and outsource their data to the cloud server independently. Users can generate their own search capabilities without relying on an always online trusted authority. Fine-grained search authorization is also implemented by the owner-enforced access policy on the index of each file. Further, by incorporating proxy re-encryption and lazy re-encryption techniques, we are able to delegate heavy system update workload during user revocation to the resourceful semi-trusted cloud server. We formalize the security definition and prove the proposed ABKS-UR scheme selectively secure against chosen-keyword attack. To build confidence of data user in the proposed secure search system, we also design a search result verification scheme. Finally, performance evaluation shows the efficiency of our scheme.","1045-9219;10459219","","10.1109/TPDS.2014.2355202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6893023","Cloud computing;attribute-based keyword search;fine-grained owner-enforced search authorization;multi-user search;verifiable search","Authorization;Encryption;Indexes;Keyword search;Servers","authorisation;cloud computing;cryptography;data privacy;information retrieval;trusted computing","ABE;ABKS-UR scheme;attribute-based encryption;attribute-based keyword search scheme with efficient user revocation;chosen-keyword attack;cloud computing;encryption-before-outsourcing;fine-grained owner-enforced search authorization;lazy reencryption technique;multiuser multicontributor case;online trusted authority;owner-enforced access policy;proxy reencryption technique;resourceful semitrusted cloud server;scalable fine-grained search authorization;secure search schemes;secure searchable index;single-contributor scenario;symmetric cryptography;untrusted cloud server environment;user data privacy protection;verifiable attribute-based keyword search","","3","","36","","20140905","April 1 2016","","IEEE","IEEE Journals & Magazines"
"Information-centric networking for the internet of things: challenges and opportunities","M. Amadeo; C. Campolo; J. Quevedo; D. Corujo; A. Molinaro; A. Iera; R. L. Aguiar; A. V. Vasilakos","University Mediterranea of Reggio Calabria","IEEE Network","20160321","2016","30","2","92","100","In view of evolving the Internet infrastructure, ICN is promoting a communication model that is fundamentally different from the traditional IP address-centric model. The ICN approach consists of the retrieval of content by (unique) names, regardless of origin server location (i.e., IP address), application, and distribution channel, thus enabling in-network caching/replication and content-based security. The expected benefits in terms of improved data dissemination efficiency and robustness in challenging communication scenarios indicate the high potential of ICN as an innovative networking paradigm in the IoT domain. IoT is a challenging environment, mainly due to the high number of heterogeneous and potentially constrained networked devices, and unique and heavy traffic patterns. The application of ICN principles in such a context opens new opportunities, while requiring careful design choices. This article critically discusses potential ways toward this goal by surveying the current literature after presenting several possible motivations for the introduction of ICN in the context of IoT. Major challenges and opportunities are also highlighted, serving as guidelines for progress beyond the state of the art in this timely and increasingly relevant topic.","0890-8044;08908044","","10.1109/MNET.2016.7437030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7437030","","IP networks;Information exchange;Internet;Network topology;Routing protocols;Security;Smart grids","Internet of Things;information retrieval","Internet of Things;content retrieval;data dissemination efficiency;data dissemination robustness;heavy traffic patterns;information centric networking","","5","","15","","","March-April 2016","","IEEE","IEEE Journals & Magazines"
"Affective Computing and Sentiment Analysis","E. Cambria","Nanyang Technological University","IEEE Intelligent Systems","20160317","2016","31","2","102","107","Understanding emotions is an important aspect of personal development and growth, and as such it is a key tile for the emulation of human intelligence. Besides being important for the advancement of AI, emotion processing is also important for the closely related task of polarity detection. The opportunity to automatically capture the general public's sentiments about social events, political movements, marketing campaigns, and product preferences has raised interest in both the scientific community, for the exciting open challenges, and the business world, for the remarkable fallouts in marketing and financial market prediction. This has led to the emerging fields of affective computing and sentiment analysis, which leverage human-computer interaction, information retrieval, and multimodal signal processing for distilling people's sentiments from the ever-growing amount of online social data.","1541-1672;15411672","","10.1109/MIS.2016.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435182","affective computing;affective reasoning;emotion;intelligent systems;sentiment analysis","Affective computing;Knowledge based systems;Pragmatics;Semantics;Sentiment analysis;Statistical analysis;Videos","human computer interaction;information retrieval;sentiment analysis;social networking (online)","affective computing;emotion processing;emotion understanding;financial market prediction;human intelligence emulation;human-computer interaction;information retrieval;marketing campaigns;multimodal signal processing;online social data;polarity detection;political movements;public sentiments;scientific community;sentiment analysis;social events","","27","","42","","","Mar.-Apr. 2016","","IEEE","IEEE Journals & Magazines"
"A new approach to digitalization and data management of cultural heritage sites","V. A. Ziparo; F. Cottefoglie; D. Calisi; F. Giannone; G. Grisetti; B. Leibe; M. Proesmans; P. Salonia; L. Van Gool; C. Ventura; C. Stachniss","Algorithmica S.r.l. - Rome, Italy","2015 Digital Heritage","20160225","2015","1","","143","146","In this paper, we describe a novel approach for acquiring and managing digital models of archaeological sites. More in detail, we present an approach to digitization based on a robotic platform and a cloud-based information system. Our robot is the result of over two years of efforts by a group of cultural heritage experts, computer scientists and roboticists. Exploiting the large and heterogeneous amount data provided by the robotic platform requires this data to be managed, organized and analyzed. To this extent we developed ARIS (ARchaeological Information System), a software that exploits modern information retrieval and machine learning systems.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7413855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7413855","","Cultural differences;Information systems;Robot sensing systems;Semantics;Three-dimensional displays","archaeology;cloud computing;history;information retrieval;intelligent robots;learning (artificial intelligence);scientific information systems","ARIS;archaeological information system;archaeological sites;cloud-based information system;computer scientists;cultural heritage experts;cultural heritage sites;data management;digital model acquisition;digital model management;digitization approach;information retrieval;machine learning systems;robotic platform;roboticists","","1","","10","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Urban Archiving for Smarter Cities: Archival Practices beyond Open Data","E. M. Nilsson; V. Wiman","Sch. of Arts & Commun., Malmo Univ., Malmo, Sweden","2015 International Conference on Culture and Computing (Culture Computing)","20160314","2015","","","189","190","Urban Archiving is a research theme within the project Living Archives exploring the roles of archives and archival practices in a digitized society. One of the aims is to create design interventions dedicated to exploring, prototyping and testing relevant possibilities for digital archives and archiving practices in various contexts, such as urban development. The research intervention presented in this paper explores and prototypes tools and archiving practices for capturing, representing, and disseminating the intangible culture heritage of a particular neighbourhood, or an area in a city. The data generated is of a qualitative kind, and can be used as a complement, or maybe even a provocation to the image of a neighbourhood outlined by open data sources. If urban open data can be useful in answering the ""What?"" of a city, the methods and tools we develop can help answering the ""Why?"" and thus deepen our understanding of urban areas, and how we can plan for sustainable cities.","","CD-ROM:978-1-4673-8231-1; Electronic:978-1-4673-8232-8; POD:978-1-4673-8233-5","10.1109/Culture.and.Computing.2015.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433253","Archives;Archiving Practices;Artistic research;Intangible Cultural Heritage;Open Data;Participatory Design;Smart City Learning;Urban Gardening Communities","Art;Context;Cultural differences;Presses;Prototypes;Soil;Urban areas","history;information retrieval systems;smart cities;town and country planning","archival practices;digitized society;intangible culture heritage;open data sources;project living archives;smarter cities;sustainable cities;urban archiving;urban development","","","","6","","","17-19 Oct. 2015","","IEEE","IEEE Conference Publications"
"Integration of GIS Data for Visualization of Virtual Geospatial Environments","M. Mekni","Dept. of Comput. Sci. & Inf. Technol., St. Cloud State Univ., St. Cloud, MN, USA","2015 Second International Conference on Mathematics and Computers in Sciences and in Industry (MCSI)","20160303","2015","","","273","282","In this paper, we propose an approach to generate Virtual Geospatial Environments (VGE) using data provided by Geographic Information System (GIS). The resulting VGE provides a spatial representation of the real world for visualization and simulation purposes. Conventional VGE approaches are generally built upon a grid-based spatial representation, raising the well-known problems of the lack of accuracy of localized data and the difficulty to merge data with multiple semantics. Our approach overcomes these limits by using a precise spatial decomposition technique that relies on a graph-based topological model. Moreover, our approach integrates, merges, and propagates semantics associated with GIS data including when these later spatially overlap. We illustrate this model with an application which extracts geographic, topologic and semantic data from standard GIS files, and allows a user to navigate and retrieve information from the computed VGE.","","CD-ROM:978-1-4799-8672-9; Electronic:978-1-4799-8673-6; POD:978-1-4799-8674-3","10.1109/MCSI.2015.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423977","Geographic Information Systems;Graphs;Spatial Decomposition;Virtual Geospatial Environments","Algorithm design and analysis;Buildings;Containers;Geographic information systems;Roads;Semantics;Shape","data integration;data visualisation;geographic information systems;information retrieval","GIS data integration;VGE visualization;geographic data extraction;geographic information system;information retrieval;semantic data extraction;spatial decomposition technique;topologic data extraction;virtual geospatial environments","","","","15","","","17-17 Aug. 2015","","IEEE","IEEE Conference Publications"
"A system for popular Thai slang extraction from social media content with n-gram based tokenization","R. Jiamthapthaksin; P. Setthawong; N. Ratanasawetwad","Department of Computer Science, Vincent Mary School of Science and Technology, Assumption University, Bangkok, Thailand","2016 8th International Conference on Knowledge and Smart Technology (KST)","20160324","2016","","","130","135","With increased penetration of smart devices and internet connectivity, many Thais are more readily engaged in social media, online forums, and chat groups. As there is an increased consumption of social media content, there is a shift from the consumption of traditional medias in which formal language are used regularly such as broadcast and traditional print medias. Social media posts are a reflection of the trend, where posts usually made by younger generations usually involve communication in slang and non-formal language which is not typically available in formalized dictionaries. As the Thai population like to follow trends, one of behaviors of that many Thai social media users engage in, is to follow the latest popular social media trends in slang and word usage. As slang are changed and evolved over time, it is usually useful to have an online mining tool in which could capture the trends of emerging and popular slang. This paper proposes an approach that extracts popular Thai slang by comparing social media posts and utilizing tokenization, a dictionary based approach to extract unknown words, before expanding it by using n-gram approach to figure what are currently trending and popular slang words.","","Electronic:978-1-4673-8139-0; POD:978-1-4673-8140-6","10.1109/KST.2016.7440478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7440478","Thai slang extraction;data-mining;n-gram;social media trends;tokenization;word segmentation","Decision support systems","Internet;information retrieval;natural language processing;social networking (online)","Internet connectivity;Thai slang extraction;chat groups;dictionary based approach;formal language;formalized dictionaries;n-gram based tokenization;nonformal language;online forums;popular slang words;smart devices;social media content;social media posts;unknown word extraction","","","","13","","","3-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"An Innovative Statistical Tool for Automatic OWL-ERD Alignment","A. Pipitone; F. Anastasio; R. Pirrone","Dept. of Chem., Manage., Comput. & Mech. Eng., Univ. of Palermo, Palermo, Italy","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","96","99","Aligning two representations of the same domain with different expressiveness is a crucial topic in nowadays semantic web and big data research. OWL ontologies and Entity Relation Diagrams are the most widespread representations whose alignment allows for semantic data access via ontology interface, and ontology storing techniques. The term """"alignment"" encompasses three different processes: OWL-to-ERD and ERD-to-OWL transformation, and OWL-ERD mapping. In this paper an innovative statistical tool is presented to accomplish all the three aspects of the alignment. The main idea relies on the use of a HMM to estimate the most likely ERD sentence that is stated in a suitable grammar, and corresponds to the observed OWL axiom. The system and its theoretical background are presented, and some experiments are reported.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439311","","Databases;Erbium;Grammar;Hidden Markov models;OWL;Ontologies;Semantics","Big Data;information retrieval;knowledge representation languages;ontologies (artificial intelligence);semantic Web;statistical analysis","ERD-to-OWL transformation;OWL ontologies;OWL-ERD mapping;OWL-to-ERD transformation;automatic OWL-ERD alignment;big data research;entity relation diagrams;innovative statistical tool;ontology interface;semantic Web;semantic data access","","","","21","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Towards green distributed storage systems","A. M. Ibrahim; A. A. Zewail; A. Yener","Wireless Communications and Networking Laboratory (WCAN), Electrical Engineering Department, The Pennsylvania State University, University Park, PA 16802","2015 49th Asilomar Conference on Signals, Systems and Computers","20160229","2015","","","890","894","We model a distributed storage system consisting of energy harvesting nodes which store multiple files. To investigate the performance of file retrieval and node repair, we formulate two optimization problems: maximizing the number of retrieved (repaired) files given a deadline, and minimizing the retrieval (repair) time of a number of stored files. We derive the necessary and sufficient conditions for the feasibility of retrieving (repairing) a number of files by a deadline. Utilizing these conditions, we reduce the aforementioned problems to a single feasibility problem, which is solved using forward and backward algorithms. Finally, the system performance is illustrated numerically.","","CD-ROM:978-1-4673-8574-9; Electronic:978-1-4673-8576-3; POD:978-1-4673-8577-0","10.1109/ACSSC.2015.7421265","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7421265","","Energy harvesting;Energy storage;Maintenance engineering;Optimization;Resource management;Systems operation;Throughput","distributed memory systems;energy harvesting;green computing;information retrieval;storage management","backward algorithms;deadline;energy harvesting nodes;file retrieval performance;forward algorithms;green distributed storage systems;necessary and sufficient conditions;node repair performance;optimization problems:;retrieval time minimization;retrieved file number maximizing","","","","10","","","8-11 Nov. 2015","","IEEE","IEEE Conference Publications"
"Studying shape semantics of an architectural moulding collection: Classifying style based on shape analysis methods","K. R. Echavarria; R. Song","Cultural Informatics Research Group, University of Brighton, UK","2015 Digital Heritage","20160225","2015","2","","53","60","As technologies for 3D acquisition become widely available, it is expected that 3D content will become increasingly popular. Nevertheless, to provide access and enable the creative use of 3D content, it is necessary to address challenges such as the availability of open repositories dedicated to 3D content and the automatic enrichment of 3D content with suitable metadata so that content does not get lost. To address these challenges, this paper presents research on developing technologies to support the organisation and discoverability of 3D content in the Cultural Heritage (CH) domain. The main contributions of the paper include an ontology for documenting 3D representations of architectural mouldings decorated with ornament. In addition, a shape analysis method to improve the information that is automatically extracted from a 3D shape is proposed. This method is tested on part of a collection of Regency ornament mouldings found in domestic interiors. This content provides a rich dataset on which to explore issues common to many CH artefacts, such as design styles, patterns and motifs.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419452","architectural mouldings;ontologies;shape analysis","Art;Buildings;Cultural differences;Ontologies;Semantics;Shape;Three-dimensional displays","architecture;data acquisition;history;information retrieval;meta data;ontologies (artificial intelligence);pattern classification","3D acquisition;3D architectural moulding representation documentation;3D content discoverability;3D content organisation;CH artefacts;CH domain;architectural moulding collection;automatic 3D content enrichment;automatic information extraction;classifying style;cultural heritage domain;design motifs;design patterns;design styles;domestic interiors;metadata;ontology;regency ornament mouldings;shape analysis method;shape semantics","","1","","41","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"3DHOG for geometric similarity measurement and retrieval for digital cultural heritage archives","K. Eckeren; R. Tausch; P. Santos; A. Kuijper; D. W. Fellner","Fraunhofer Institute for Computer Graphics Research IGD, Germany","2015 Digital Heritage","20160225","2015","2","","117","120","With projects such as CultLab3D, 3D Digital preservation of cultural heritage will become more affordable and with this, the number of 3D-models representing scanned artefacts will dramatically increase. However, once mass digitization is possible, the subsequent bottleneck to overcome is the annotation of cultural heritage artefacts with provenance data. Current annotation tools are mostly based on textual input, eventually being able to link an artefact to documents, pictures, videos and only some tools already support 3D models. Therefore, we envisage the need to aid curators by allowing for fast, web-based, semi-automatic, 3D-centered annotation of artefacts with metadata. In this paper we give an overview of various technologies we are currently developing to address this issue. On one hand we want to store 3D models with similarity descriptors which are applicable independently of different 3D model quality levels of the same artefact. The goal is to retrieve and suggest to the curator metadata of already annotated similar artefacts for a new artefact to be annotated, so he can eventually reuse and adapt it to the current case. In addition we describe our web-based, 3D-centered annotation tool with meta- and object repositories supporting various databases and ontologies such as CIDOC-CRM.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419466","3D object retrieval;classification;descriptor","Cultural differences;Three-dimensional displays","Internet;digital preservation;history;information retrieval;meta data;ontologies (artificial intelligence)","3D digital preservation;3D model quality levels;3D-models;3DHOG;CIDOC-CRM;Web-based semiautomatic 3D-centered annotation;cultural heritage artefact annotation;databases;digital cultural heritage archives;geometric similarity measurement;geometric similarity retrieval;mass digitization;metadata;metarepositories;object repositories;ontologies;scanned artefacts;similarity descriptors;textual input","","","","25","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Tamil to Malayalam Transliteration","K. Raju; S. T. V.; V. P. V.; R. R. R.; R. R. P. C.","Gov. Eng. Coll., Palakkad, India","2015 Fifth International Conference on Advances in Computing and Communications (ICACC)","20160317","2015","","","12","15","Transliteration forms an essential part of transcription which converts text from one writing system to another. The need for translating data has become larger than before as the world is getting together through social media. Machine transliteration has emerged as a part of information retrieval and machine translation projects to translate named entities, that are not registered in the dictionary, based on phonemes and graphemes. This paper proposes a machine learning technique that performs transliteration from Tamil to Malayalam, two languages that belong to Dravidian family. Transliteration can be used to supplement machine translation process by handling the issues that can happen due to the presence of named entities.","","Electronic:978-1-4673-6994-7; POD:978-1-4673-6995-4","10.1109/ICACC.2015.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433765","Artificial intelligence;Computational linguistics;Machine transliteration;Malayalam;Natural language processing;SVM;Statistical learning;Tamil;TnT","Dictionaries;Feature extraction;Pragmatics;Predictive models;Support vector machines;Training","information retrieval;language translation;natural language processing","Dravidian family;Malayalam transliteration;Tamil;data translation;information retrieval;machine learning;machine translation process;machine transliteration;named entities;social media;transcription;writing system","","","","9","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"K-Extractor: Automatic Knowledge Extraction for Hybrid Question Answering","M. Balakrishna; S. Werner; M. Tatu; T. Erekhinskaya; D. Moldovan","Lymba Corp., Richardson, TX, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","390","391","This paper describes an approach to integrate unstructured and structured data and provide a natural language query interface to the consolidated knowledge base. The approach is based on deep semantic representation expressed in RDF triples. Natural language questions are automatically converted into SPARQL queries executed against the RDF store. The approach is implemented in K-Extractor platform. Two domain collections are shown: antibiotic resistant bacteria and illicit drugs.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439372","Natural Language Query;Question Answering;Resource Description Framework (RDF);SPARQL;Semantic Relations","Immune system;Indexes;Knowledge discovery;Microorganisms;Natural languages;Resource description framework;Semantics","knowledge acquisition;natural language interfaces;query processing;question answering (information retrieval)","K-Extractor platform;RDF triples;SPARQL queries;antibiotic resistant bacteria;automatic knowledge extraction;consolidated knowledge base;deep semantic representation;hybrid question answering;illicit drugs;natural language query interface;natural language questions","","","","5","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Enhancing Retrieval and Ranking Performance for Media Search Engine by Deep Learning","X. Ye; J. Li; Z. Qi; X. He","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","1174","1180","Deep learning has emerged as a powerful technique to uncover deep structured, nonlinear features for various information processing tasks, such as image processing, speech recognition, and information retrieval. In this paper, we introduce a framework of utilizing a Deep Structured Semantic Model (DSSM) to build similarity features to enhance search engine relevance. To illustrate the effectiveness of the proposed deep learned similarity features, we applied our method to an Xbox Media Search Engine. Specifically, we leverage a large-scale Bing web search log to train a generic DSSM. We then tune the DSSM parameters - making the model specific to media search - by using a training dataset from the Xbox Media Search Engine. Finally, we conduct a series of experiments in building Xbox search engine with and without the proposed DSSM similarity features. Our experiment results show that adding DSSM-based similarity features significantly improves the retrieval and ranking performance.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427327","Deep Learning;Deep Structured Semantic Model;Media Search Engine","Context;Decision support systems;Machine learning;Media;Search engines;Semantics;Vocabulary","information retrieval;learning (artificial intelligence);search engines","DSSM-based similarity features;Xbox Media Search Engine;deep learning;deep structured semantic model;generic DSSM;information processing;large-scale Bing Web search log;media search engine;ranking performance;retrieval;search engine relevance;training dataset","","","","20","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Implemetation of retrieval system for Prior Art Candidate search","Kyuyeol Han; Jun-Hwan Jang; Jaean Lee; Yeongmin Ahn","WISEnut Emerging Technology R&D Center, Bundang-gu, Seongnam, Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","489","493","In this paper, we present an algorithm for searching documents related to PAC(Prior Art Candidate) more effectively in the search system built to search them. It extracts keywords from the documents, and utilizes the co-occurrence information obtained as extra feature which is able to describe the documents. It is also used as criterion to get similarity among the documents by applying IRadius. We verify that the suggested method contributes to quality improvement of the PAC search.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425976","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425976","Co-occurrence;IRadius;Non-Content-Word;Prior-Art-Candidate","Euclidean distance;Europe;Feature extraction;Patents;Probability;Q measurement;Standards","document handling;information retrieval;law administration;patents","IRadius;PAC search;co-occurrence information;document search;keyword extraction;patent;prior art candidate;retrieval system","","","","9","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Transducers Cascades for an Automatic Recognition of Arabic Named Entities in Order to Establish Links to Free Resources","F. B. Mesmia; N. Friburger; K. Haddar; D. Maurel","Lab. MIRACL, Univ. of Sfax, Sfax, Tunisia","2015 First International Conference on Arabic Computational Linguistics (ACLing)","20160303","2015","","","61","67","Arabic named entities (ANE) are often sources of information. That is why they are used by several applications of natural language processing (NLP) mainly in information retrieval. In order to improve the relevance of the information obtained, links to free resources can be established. Indeed, the recognition of these entities requires the use of adequate formalisms. In this paper, we propose an approach based on transducer cascades which allows the recognition of ANE more precisely the dates. This categorycan be an integral part in the events and the names of places. The implementation of the developed transducers cascades elaborated by using the CasSys tool is available under the Unitex platform. The results are motivating.","","Electronic:978-1-4673-9155-9; POD:978-1-4673-9156-6","10.1109/ACLing.2015.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422281","Arabic named entities;CasSys;Cascade of transducers;Unitex;Wikipedia","Automata;Dictionaries;Hidden Markov models;Natural language processing;Pragmatics;Transducers","information retrieval;natural language processing;relevance feedback;text analysis","ANE recognition;CasSys tool;NLP;Unitex platform;automatic Arabic named entity recognition;information retrieval;information sources;natural language processing;relevance improvement;transducer cascade","","","","15","","","17-20 April 2015","","IEEE","IEEE Conference Publications"
"A survey of temporal information extraction and language independent features","Chae-Gyun Lim","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon 34141, Republic of Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","447","449","Since there has been an explosive growth of online documents, the knowledge extraction from natural language texts becomes more important to complement limited human ability. In this paper, we introduce existing methods for temporal information extraction from input texts in two viewpoints. One is the researches about language-independent feature generation. Even though linguistic features have been generally utilized to extract time expressions, we need different features which are independent from language characteristics in order to overcome the boundary of particular language. Another is the researches about temporal information extraction based on the common patterns or knowledge bases. By summarizing and discussing existing researches, we can see the current research direction on this field to help better understanding of the temporal information extraction methods.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425967","","Computational linguistics;Data mining;Feature extraction;Hidden Markov models;Semantics;Tagging","information retrieval;natural language processing;text analysis","knowledge extraction;language-independent feature generation;natural language texts;online documents;temporal information extraction","","","","20","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Semantic Word Error Rate for Sentence Similarity","C. Spiccia; A. Augello; G. Pilato; G. Vassallo","Italian Nat. Res. Council, Ist. di calcolo e reti ad alte prestazioni, Palermo, Italy","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","266","269","Sentence similarity measures have applications in several tasks, including: Machine Translation, Paraphrase Identification, Speech Recognition, Question-answering and Text Summarization. However, measures designed for these tasks are aimed at assessing equivalence rather than resemblance, partly departing from human cognition of similarity. While this is reasonable for these activities, it hinders the applicability of sentence similarity measures to other tasks. We therefore propose a new sentence similarity measure specifically designed for resemblance evaluation, in order to cover these fields better. Experimental results are discussed.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439346","LSA;Latent Semantic Analysis;SWER;Semantic Word Error Rate;WER;Word Error Rate;sentence resemblance;sentence similarity measure;word relatedness","Atmospheric measurements;Current measurement;Error analysis;Extraterrestrial measurements;Measurement uncertainty;Particle measurements;Semantics","language translation;question answering (information retrieval);text analysis","machine translation;paraphrase identification;question-answering;resemblance evaluation;semantic word error rate;sentence similarity measures;speech recognition;text summarization","","","","","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Content analysis of product usage information from embedded sensors and web 2.0 sources: A first analysis of practical examples","S. Wellsandt; K. Hribernik; K. D. Thoben","BIBA - Bremer Institut f&#252;r Produktion und Logistik GmbH, Bremen, Germany","2015 IEEE International Conference on Engineering, Technology and Innovation/ International Technology Management Conference (ICE/ITMC)","20160324","2015","","","1","9","The middle of a product's life is when the product is with the user. During the middle of life (MOL) phase, useful product information is created (usage information). In the past, research in engineering focused on the transformation of this information into engineering knowledge - for this purpose, demonstrators were developed and described in literature. Apart from demonstrating the feasibility of the approach, little is known about the vast body of usage information. This research is based on the analysis of real information manually extracted from a small selection of contents. Selected contents have been taken from a product embedded sensor device, a shopping website (Amazon.com), a review website (Engadget.com) and a media platform (Youtube.com). Based on the discussion of the findings, a tree-like structure is proposed, summarizing the preliminary content-related characteristics of usage information identified in this paper. Among these characteristics are the originators, sources, lifecycle activities covered, formats and the scope of information from the middle of life.","","Electronic:978-1-4673-7156-8; POD:978-1-4673-7157-5","10.1109/ICE.2015.7438641","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438641","Closed-loop PLM;embedded sensors;product lifecycle;product usage data;usage phase","Boats;Databases;Discussion forums;Maintenance engineering;Sensor phenomena and characterization;Temperature measurement","Internet;information retrieval;intelligent sensors;product life cycle management;retail data processing;social networking (online)","Amazon.com;Engadget.com;Web 2.0 sources;Youtube.com;content analysis;embedded sensors;engineering knowledge;information extraction;information formats;information scope;information transformation;lifecycle activities;media platform;preliminary content-related characteristics;product embedded sensor device;product middle of life phase;product usage information;review Web site;shopping Web site;tree-like structure","","","","16","","","22-24 June 2015","","IEEE","IEEE Conference Publications"
"Contextual Bandits for Multi-objective Recommender Systems","A. Lacerda","Comput. Sci. Dept., Centro Fed. de Educ. Tecnol. de Minas Gerais, Belo Horizonte, Brazil","2015 Brazilian Conference on Intelligent Systems (BRACIS)","20160303","2015","","","68","73","The contextual bandit framework have become a popular solution for online interactive recommender systems. Traditionally, the literature in interactive recommender systems has been focused on recommendation accuracy. However, it has been increasingly recognized that accuracy is not enough as the only quality criteria. Thus, other concepts have been suggested to improve recommendation evaluation, such as diversity and novelty. Simultaneously considering multiple criteria in payoff functions leads to a multi-objective recommendation. In this paper, we model the payoff function of contextual bandits to considering accuracy, diversity and novelty simultaneously. We evaluated our proposed algorithm on the Yahoo! Front Page Module dataset that contains over 33 million events. Results showed that: (a) we are able to improve recommendation quality when equally considering all objectives, and (b) we allow for adjusting the compromise between accuracy, diversity and novelty, so that recommendation emphasis can be adjusted according to the needs of different users.","","Electronic:978-1-5090-0016-6; POD:978-1-5090-0017-3","10.1109/BRACIS.2015.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423997","Multi-armed Bandits;Multi-objective;Online Recommender Systems","Context;Context modeling;Learning (artificial intelligence);Measurement;Portals;Prediction algorithms;Recommender systems","information retrieval;recommender systems","Yahoo! Front Page Module dataset;contextual bandits;multiobjective recommender systems;online interactive recommender systems;payoff function model;recommendation quality","","","","35","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"A Semantic Hash Tree Based Verifiable Data Access Protocol on the Cloud","F. Chen; T. Xiang; J. Chen; W. Yu; X. Fu; S. Zhang","Dept. of Comput. Sci. & Eng., Shenzhen Univ., Shenzhen, China","2015 Third International Conference on Advanced Cloud and Big Data","20160321","2015","","","219","226","With the popularity of outsourcing data to the cloud, security of cloud storage has drawn considerable attention. While many research efforts have been devoted to verifying the availability and integrity of the outsourced data, it remains a critical challenge how to efficiently verify the correctness of the cloud's response on data access request. In particular, when a user requests a data item from a mobile or Web interface, what if the cloud claims that the data item does not exist while the item does exist? We refer to this as verifiable data access. In this paper, we present a formal model for verifiable data access, and then propose a privacy-preserving and provably secure protocol to address the problem. In order to achieve the verifiability, we develop a novel mechanism called semantic hash tree. Through a sophisticated design of such a tree, our protocol supports verifiable data access in constant time with logarithm communication cost. Experimental evaluation further validates the practicality and efficiency of our protocol.","","Electronic:978-1-4673-8537-4; POD:978-1-4673-8538-1","10.1109/CBD.2015.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435477","","Authentication;Cloud computing;Cryptography;Protocols;Semantics;Vegetation","cloud computing;cryptographic protocols;data integrity;information retrieval;outsourcing;trees (mathematics)","Web interface;cloud storage security;data access request;data outsourcing;formal model;mobile interface;outsourced data availability;outsourced data integrity;privacy-preserving protocol;provably secure protocol;semantic hash tree based verifiable data access protocol","","","","25","","","Oct. 30 2015-Nov. 1 2015","","IEEE","IEEE Conference Publications"
"The Bethlen Castle of Boiu - a digital renaissance","R. Bărbulescu; R. Zaharia","Forgotten Monuments Project by Arch&#x00E9; Association, Bucharest, Romania","2015 Digital Heritage","20160225","2015","2","","761","761","The extra urban noble residences from Romania, historical monuments of international, national or local importance are generally in a bad state of conservation and almost lost to the memory of our countries transitional society. The The Bethlen Castle of Boiu used to be a representative example of Renaissance courts belonging to the former nobility of Transylvania. Following its rapid destruction, a digital virtual reconstruction aims to retrieve the memory of this lost monument.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419623","Renaissance;Transylvania;castles;virtual reconstruction","Buildings","history;information retrieval;virtual reality","The Bethlen Castle of Boiu;Transylvania;digital renaissance;historical monument;memory retrieval;virtual reconstruction","","","","3","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Information Quantity in Text and Its Applications","J. Chen; H. Zhuge","Nanjing Univ. of Posts & Telecommun., Nanjing, China","2015 11th International Conference on Semantics, Knowledge and Grids (SKG)","20160310","2015","","","154","161","Human reading process significantly influences text understanding. Previous work has proposed a measure of information by simulating human reading process with a reading aim. The measure reflects both human memory of words in mind and association between words. There are two limitations: 1) interval between documents is an important reading factor and is not considered in the simulation, 2) the usefulness of the measure is limited to text recommendation in the work. This work proposes a multi-document scanning mechanism by exploiting the interval between documents and defines a measure named Information Quantity in Text in the mechanism. The measure is applied in both text recommendation and text summarization. Experiments show the measure outperforms an entropy-based baseline in determining the reading order of text sets according to the Summary Content Unit evaluation, and performs well in multi-document summarization according to the Pyramid evaluation. Experiments also show interval between documents in the scanning mechanism improves the recommendation and the summarization.","","Electronic:978-1-4673-9808-4; POD:978-1-4673-9809-1","10.1109/SKG.2015.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429370","","Analytical models;Context;Entropy;Mathematical model;Semantics;Telecommunications;Text processing","information retrieval;text analysis","IQiT;human reading process;information quantity in text;multidocument scanning mechanism;text recommendation;text summarization;text understanding","","","","19","","","19-21 Aug. 2015","","IEEE","IEEE Conference Publications"
"Affix modification-based bilingual pivoting method for paraphrase extraction in agglutinative languages","H. Park; G. Gweon; J. Heo","Department of Knowledge Service Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","199","206","Paraphrase extraction is a task that involves the extraction of pairs of paraphrase expressions from a large-scale corpus. Because existing extraction methods are mostly designed for morphologically poor languages such as English, we present a method suited for agglutinative languages that are morphologically complex by attaching inflectional affixes to word stems. Specifically, we use the Korean language as a case study to address two types of problems that occur because existing methods model each lexical form as a separate word. The first problem is lexical data sparsity, and the second problem is not considering the morphological word structure. To mitigate these problems, we propose a novel phrasal paraphrase extraction method called affix modification-based bilingual pivoting method (AMBPM), which extends the existing bilingual pivoting method (BPM). Our experiments show that our proposed method significantly outperforms two state-of-the-art paraphrase extraction methods, namely the syntactic constraints-based bilingual pivoting method (SCBPM) and the skip-gram word embedding model with respect to meaning preservation and grammaticality of the extracted paraphrase pairs.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425914","affix modification;agglutinative languages;bilingual pivoting method;paraphrase extraction","Data mining;Knowledge discovery;Natural language processing;Semantics;Syntactics;Telecommunications","data handling;information retrieval;natural language processing","AMBPM;English;Korean language;affix modification-based bilingual pivoting method;agglutinative languages;inflectional affixes;large-scale corpus;lexical data sparsity;phrasal paraphrase extraction method;word stems","","","","28","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Design and Research of Teaching Resources Management Based on SSH and AJAX","Y. P. Jin; Y. Liu; G. Song","Mudanjiang Normal Univ., Mudanjiang, China","2015 Eighth International Conference on Internet Computing for Science and Engineering (ICICSE)","20160303","2015","","","279","285","In this study, according to the characteristics of teaching resources in higher education institutions, a university teaching resource management system is designed. The system is based on the open source SSH framework and Ajax technology. The system mainly includes 7 main functional modules. They are teaching resource library, 4 online sub-systems (courses, teaching, interactive communication and homework), intelligent auto-test/exam-generation, and student quiz/test/exam. The application of the system has been tested and the results demonstrate its feasibilities including scientific classification management, efficient retrieval, and fast sharing and downloading. The integration of SSH and AJAX based information technology into existing teaching system is very straightforward, in aspects of rich architecture, sub-system dependence, simplification of coding, and high performance of Web application development. The proposed system can be used for have broad application prospects with open sources and enterprise-level J2EE development tools.","","Electronic:978-1-5090-0454-6; POD:978-1-5090-0455-3","10.1109/ICICSE.2015.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422495","AJAX;Hibernate;MVC;Network teaching;Resources management;Spring;Struts","Containers;Databases;Education;Object oriented modeling;Resource management;Springs","Internet;Java;computer aided instruction;educational courses;educational institutions;further education;information retrieval;public domain software;teaching","AJAX based information technology;AJAX technology;Web application development;coding simplification;downloading;enterprise-level J2EE development tools;functional modules;higher education institutions;homework;information retrieval;information sharing;intelligent autotest-exam-generation;interactive communication;online subsystems;open source SSH framework;scientific classification management;student exam;student quiz;student test;subsystem dependence;teaching resource library;teaching resource management design;teaching resource management research;teaching resources characteristics;university teaching resource management system","","","","11","","","6-8 Nov. 2015","","IEEE","IEEE Conference Publications"
"Text Mining News System - Quantifying Certain Phenomena Effect on the Stock Market Behavior","M. Tirea; V. Negru","Comput. Sci. Dept., West Univ. of Timisoara, Timisoara, Romania","2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)","20160307","2015","","","391","398","Stock market prediction is influenced by manyinternal and external factors. One of these factors are the newsarticles and financial reports related to each listed company. This paper describes a system that is able to extract relevantinformation from this type of textual documents, correlate themwith the stock price movement and determine whether ornot a new released news can and in which proportion willinfluence the market behavior. Predefined ontologies are used forclassifying the news articles and automated ontology extractionfor classifying concepts and super - concepts, on an attempt tomake a semantic mining of the text news. The system is basedon a Multi-Agent Architecture that will investigate, extract andcorrelate the textual data message with the price evolution inorder to better determine buy/sell moments, the trend directionand optimize an investment portfolio. In order to validate ourmodel a prototype was developed and applied to the BucharestStock Exchange Market listed companies.","","Electronic:978-1-5090-0461-4; POD:978-1-5090-0462-1","10.1109/SYNASC.2015.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426109","Knowledge Extraction;Multi-Agent System;Ontology;Stock Market Prediction","Analytical models;Companies;Market research;Ontologies;Stock markets;Text mining","data mining;electronic publishing;information retrieval;investment;multi-agent systems;ontologies (artificial intelligence);pattern classification;stock markets;text analysis","Bucharest Stock Exchange Market listed companies;automated ontology extraction;buy-sell moments;financial reports;information extraction;investment portfolio;multiagent architecture;news article classification;predefined ontologies;price evolution;semantic mining;stock market behavior;stock market prediction;stock price movement;text mining news system;textual data message;textual documents","","","","26","","","21-24 Sept. 2015","","IEEE","IEEE Conference Publications"
"Social media mapping, as a catalyst for social realm actions","B. Stojanovic","Department of Design, Politecnico di Milano, via Durando 38/A, 20158, Italia","2015 Digital Heritage","20160225","2015","2","","473","474","The following paper focuses on the fact how to formulate a new methodological framework approach of information-based technologies in sense of enhancing the cultural heritage appropriate to the conditions of the contemporary city. Digital technologies should be used to identify techniques and methods to deal with the urban stratification, to help in fostering community ties, sense of the belonging towards places, thereby expanding the traditional disciplinary boundaries. The users interactions can contribute in shaping digital social innovation. This study aims at demonstrating that a users□ involvement might lead to a successful mode of designing and spreading the innovation that could contribute to a further development and creating the higher quality of life in the public sphere. Nowadays, one of the main ideas is framing how the spread of social media and digital technologies can influence the behavior of the people, in particular during the big social events, like concerts, sport manifestations. The problem to face is to understand and measure the hidden data, rhythms and guidelines, during the individual or mass stroke in the virtual world. In fact, this invisible space of social media is giving us possibility to reveal new principles in big - scale behavioral reaction. The social services, as Twitter, Facebook etc. are very useful for this type of analysis, especially when they are seen through the prism of social excitement, when the enthusiasm of people rises as their activity on social networks.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419554","crowd-sourced mapping;digital analysis;historic city centers;public realm;social media","Cities and towns;Data privacy;Facebook;Media;Technological innovation","history;information retrieval;innovation management;social networking (online);technology management","cultural heritage;digital social innovation;digital technology;information extraction;information-based technology;social media mapping;social realm action","","","","8","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Profiling apache HIVE query from run time logs","G. P. Haryono; Ying Zhou","School of Information Technologies, The University of Sydney, NSW 2008, Australia","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","61","68","Apache Hive is a widely used data warehousing and analysis tool. Developers write SQL like HIVE queries, which are converted into MapReduce programs to runs on a cluster. Despite its popularity, there is little research on performance comparison and diagnose. Part of the reason is that instrumentation techniques used to monitor execution can not be applied to intermediate MapReduce code generated from Hive query. Because the generated MapReduce code is hidden from developers, run time logs are the only places a developer can get a glimpse of the actual execution. Having an automatic tool to extract information and to generate report from logs is essential to understand the query execution behavior. We designed a tool to build the execution profile of individual Hive queries by extracting information from HIVE and Hadoop logs. The profile consists of detailed information about MapReduce jobs, tasks and attempts belonging to a query. It is stored as a JSON document in MongoDB and can be retrieved to generate reports in charts or tables. We have run several experiments on AWS with TPC-H data sets and queries to demonstrate that our profiling tool is able to assist developers in comparing HIVE queries written in different formats, running on different data sets and configured with different parameters. It is also able to compare tasks/attempts within the same job to diagnose performance issues.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425802","","Data mining;Electronic mail;Information technology;Instruments;Monitoring;Yarn","data handling;information retrieval;parallel processing;query processing;system monitoring","AWS;Apache HIVE query profiling;HIVE logs;Hadoop logs;JSON document;MapReduce;MongoDB;TPC-H;information extraction","","","","15","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Should Wikipedia and Quora collaborate?","A. Chhabra; S. R. S. Iyengar","Dept of Computer Science and Engineering, IIT Ropar, Punjab, India","2016 8th International Conference on Communication Systems and Networks (COMSNETS)","20160324","2016","","","1","2","Although Wikipedia has been one of the most successful experiments in crowdsourced knowledge building so far, recent statistics show that the growth rate of Wikipedia has decreased. Does it indicate that Wikipedia has come against its limits of growth? A recent survey conducted by us, however, shows that Wikipedia is unable to satisfactorily answer the queries of the users many a times. We believe that the readers can provide a better insight into the shortcomings of the articles. This paper proposes the incorporation of a Q&A facility into Wikipedia as one of the possible measures to fill the knowledge gap. We created a local Wiki, named Q-Wiki, at our institute, coupled with the features of Q&A. The experiment conducted on Q-Wiki verifies the effectiveness of the proposed idea.","","Electronic:978-1-4673-9622-6; POD:978-1-4673-9623-3","10.1109/COMSNETS.2016.7439980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439980","","Computer science;Electronic publishing;Encyclopedias;Internet;Knowledge engineering;Market research","Internet;encyclopaedias;query processing;question answering (information retrieval)","Q&A facility;Q-Wiki;Quora;Wikipedia;crowdsourced knowledge building;local Wiki","","","","6","","","5-10 Jan. 2016","","IEEE","IEEE Conference Publications"
"Public facilities recommendation system based on structured and unstructured data extraction from multi-channel data sources","A. N. Putri; S. Akbar; W. Danar Sunindyo","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia","2015 International Conference on Data and Software Engineering (ICoDSE)","20160321","2015","","","185","190","Nowadays social media data has grown very rapidly by producing a huge amount and variety of data everyday. Those data can be analyzed and processed to deliver useful information especially for public needs. However, most of the data available in social media are unstructured. This paper proposes a recommendation system for public facilities by utilizing both structured and unstructured data gathered from multi-channel data sources. The system uses single-criteria rating, multi-criteria-rating, and text data as the inputs. The challenge is how to handle data variety such that any kind of data from any channel can be integrated. The second challenge is how to extract location-related data from the raw data. There are four data channels used in the system. Three of them are social media channels, i.e. Twitter, Instagram, and Foursquare, while the other is internal data channel built as a part of the system itself. The system deals with three categories of public facility, i.e. park, hospital, and mosque. The whole system consists of two sub systems, i.e. the extractor system including the rating input module and the recommendation system. The recommendation system is implemented as end-user mobile application such that the users are able to use it anytime and anywhere. The system successfully integrate data from different social media channels and in different format to provide users with useful information concerning public facilities in the form of recommendation (rating) and popularity of the facilities. The experiment has shown that above 90% of the data collected from the social media contains location-related information that is useful for further processing. The system has been tested using usability test, and it obtained an average users score 3.9 on a scale of 1 to 5.","","CD-ROM:978-1-4673-8427-8; Electronic:978-1-4673-8430-8; POD:978-1-4673-8431-5","10.1109/ICODSE.2015.7436995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436995","Location Based Service;Point of Interest;Recommendation System;Social Media","Data mining;Data visualization;Media;Sentiment analysis;Software engineering;Twitter","facilities;information retrieval;mobile computing;recommender systems;social networking (online)","Foursquare;Instagram;Twitter;end-user mobile application;extractor system;internal data channel;multichannel data sources;multicriteria rating;public facilities recommendation system;rating input module;single-criteria rating;social media channels;structured data extraction;text data;unstructured data extraction","","","","15","","","25-26 Nov. 2015","","IEEE","IEEE Conference Publications"
"WordNet Powered Faceted Semantic Search with Automatic Sense Disambiguation for Bioenergy Domain","F. Farazi; C. Chapman; P. Raju; L. Melville","Knowledge Based Eng. Lab., Birmingham City Univ., Birmingham, UK","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","112","115","WordNet is a lexicon widely known and used as an ontological resource hosting comparatively large collection of semantically interconnected words. Use of such resources produces meaningful results and improves users' search experience through the increased precision and recall. This paper presents our facet-enabled WordNet powered semantic search work done in the context of the bioenergy domain. The main hurdle to achieving the expected result was sense disambiguation further complicated by the occasional fine-grained distinction of meanings of the terms in WordNet. To overcome this issue, a novel sense disambiguation approach based on automatically built domain specific ontologies, WordNet synset hierarchy and term (or word) sense ranks is proposed.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439315","WordNet;bioenergy;faceted search;faceted semantic search;ontology;semantic search","Algae;Ethanol;Metadata;Ontologies;Production;Semantics;Syntactics","biofuel;information retrieval;natural language processing;ontologies (artificial intelligence);search engines;semantic Web;text analysis","WordNet powered faceted semantic search;WordNet synset hierarchy;automatic sense disambiguation;bioenergy domain;domain specific ontologies;occasional fine-grained distinction;ontological resource;precision;recall;semantically interconnected word collection;term sense ranks;user search experience;word sense ranks","","","","20","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Retrieving patents with inverse patent category frequency","Justin JongSu Song; Wookey Lee; J. Afshar","Department of Industrial Engineering, Inha University, Incheon, South Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","109","114","Patent has currently been captured strong attention as a key enabler for the knowledge and information centric companies and institutes. The higher the patent capability required, the more important an effective and efficient patent retrieval system needed. The conventional patent retrieval systems, however, have produced unsatisfactory results for the patent queries, since the inherent search systems would have come from the traditional keyword based models so that it has been inevitable to result in too many unrelated items. This has made the patent experts keep spending a lot of time to refine the results manually. We propose two dynamic ranking algorithms specialized patent-searching method, in which the dynamic interactive retrieval can be achieved. In the real USPTO dataset experiment, the dynamic ranking method shows substantial improvements with respect to time and cost over conventional static ranking approaches.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425808","","Databases;Heuristic algorithms;Law;Patents;Search problems;Tagging","information retrieval;law administration;patents;pattern clustering","dynamic interactive retrieval;dynamic ranking algorithms;inverse patent category frequency;patent-searching method","","","","19","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Construction of a Geo-Location Service Utilizing Microblogging Platforms","J. Bassi; S. Manna; Y. Sun","Comput. Sci. Dept., California State Polytech. Univ., Pomona, CA, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","162","165","The popularity of social media over the past several years, especially sites such as Twitter, has presented a network for up to the minute information on events across the globe. The information presented on these sites can be extremely helpful in the case of an emergency, however, the vast amount of data to examine and the low adoption of geo-tagging on this site makes it difficult, if not impossible, for emergency services to respond to information gathered from social media. Taking this into consideration, this paper presents a proof of concept for identifying and retrieving different geo-locations from Tweets and extracting the GPS coordinates from this data to approximately plot them in a map.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439322","Tweets;emergency services;geo-location prediction;google maps;tool","Data mining;Emergency services;Graphical user interfaces;Libraries;Natural language processing;Prediction algorithms;Twitter","Global Positioning System;geographic information systems;graphical user interfaces;information retrieval;social networking (online)","GPS coordinate extraction;Twitter;emergency services;geo-location identification;geo-location retrieval;geo-location service construction;geo-tagging;information gathering;microblogging platforms;social media;tweets","","","","8","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Curating a Semantic Bibliographic Catalog","H. S. Bhargav; G. Akalwadi; K. Kishan; K. Mahesh","Dept. of Comput. Sci. & Eng., PES Inst. of Technol., Bangalore, India","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","172","173","Large online libraries are now common across the Web. However these libraries are usually fragmented and are not semantically connected thereby making their search and access difficult. Also there are no large bibliographic Linked Open Datasets available for use in research and analytics. This paper shows how to create a large, comprehensive, RDF triple store of semantic data about books. The primary aim of this work is to establish a linked relation between all the available books in the world and connect them to the already available linked datasets. The Open Library dataset, which has over 45 million records is first serialized by converting it into a triple format and then linked together using predicates from different ontologies. A simple endpoint for a semantic book search engine called BookLOD is created to demonstrate the utility of the dataset.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439326","digital libraries;library catalog;linked data;n-triples","Libraries;Ontologies;Resource description framework;Search engines;Semantics;Vocabulary","bibliographic systems;cataloguing;digital libraries;information retrieval;ontologies (artificial intelligence);search engines;semantic Web","BookLOD;Open Library dataset;bibliographic Linked Open Datasets;dataset utility;large comprehensive RDF triple semantic data store;linked datasets;online libraries;ontologies;semantic Web;semantic bibliographic catalog;semantic book search engine;triple format","","","","6","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"A semantic search technique with Wikipedia-based text representation model","K. J. Hong; H. J. Kim","School of Electrical and Computer Engineering, University of Seoul, Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","177","182","Semantic search is known as a series of activities and techniques to improve the search accuracy by clearly understanding users' search intent. Usually, semantic search engines requires ontology and semantic metadata to analyze user queries. However, building a particular ontology and semantic metadata intended for large amounts of data is a very time-consuming and costly task. In order to resolve this problem, we propose a novel semantic search method that does not require ontologies and semantic metadata by taking advantage of semantically enriched text model. Through extensive experiments using the OSHUMED document collection and SCOPUS library data, we show that our proposed method improves users' search satisfaction.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425818","Semantic search;Tensor;Text mining;Text representation model;Wikipedia","Electronic publishing;Encyclopedias;Mathematical model;Ontologies;Semantics;Tensile stress","information retrieval;text analysis","OSHUMED document collection;SCOPUS library data;Wikipedia;semantic metadata;semantic search technique;text representation model","","","","10","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"On the reliability of diversity and redundancy-based search metrics","A. Tangsomboon; T. Leelanupab","Faculty of Information Technology, King Mongkuts Institute of Technology Ladkrabang (KMITL), Bangkok, Thailand. 10520","2015 7th International Conference on Information Technology and Electrical Engineering (ICITEE)","20160218","2015","","","615","620","Traditional approaches to ranking documents in Information Retrieval (IR) are under the assumption that the representation of information needs is clear and well-defined. This representation, which is usually in the form of a search query, is arguably considered ambiguous or underspecified. To deal with this uncertainty, much recent research has focused on creating IR systems that diversify search results so as to satisfy the multiple possible information needs underlying the query. To validate these IR systems, many new evaluation metrics have been proposed to quantify their effectiveness in terms of diversity and redundancy. Among these, a new diversity-based metric, called normalized Coverage Frequency (nCF), has lately been proposed to quantify diversity in a ranking. When a new metric is proposed, its reliability needs to be validated. This paper conducts an empirical experiment to compares and contrast state-of-the-art diversity and redundancy-based metrics, in term of discriminative power and stability of system rankings. Our experiment shows that the nCF is rated the best among all the studied metrics. Moreover, this finding is confirmed by when nCF is interpolated with other redundancy-based metrics (i.e., ERR-SA and A-nDCG). the nCF is considered more relatively robust than another diversity metric, subtopic-recall.","","Electronic:978-1-4673-7863-5; POD:978-1-4673-7864-2; USB:978-1-4673-7862-8","10.1109/ICITEED.2015.7409020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7409020","","Diversity reception;Electrical engineering;Information technology;Measurement;Redundancy;Stability analysis","document handling;information retrieval;search problems;software reliability","IR;discriminative power;diversity reliability;evaluation metrics;information representation;information retrieval;nCF;normalized coverage frequency;ranking documents;search metrics;search query","","","","23","","","29-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"CURAP: CURating geo-related information on a mAP","T. Kanehira; Y. Arakawa; K. Yasumoto; T. Wada","Nara Institute of Science and Technology, Ikoma, Nara 630-0192, JP","2016 IEEE International Conference on Consumer Electronics (ICCE)","20160314","2016","","","325","326","In this paper, we design and implement CURAP: a unique geo-related information sharing platform. It is a way for people to easily create original maps, and share them with others. Google Maps' My Maps function is currently a widely used platform for the same purpose, but its sharing features have restrictions. For example, the whole map has to be embedded into a certain web page using Google's viewer, and users cannot directly search the map for geo-related information. Users can only search for text information described in the same page. In contrast, CURAP can search for and share geo-related information directly, and it enhances re-use of a good map created in the past on existing systems.","","Electronic:978-1-4673-8364-6; POD:978-1-4673-8365-3","10.1109/ICCE.2016.7430631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7430631","","Conferences;Consumer electronics;Electronic mail;Google;Search methods;Uniform resource locators;Web pages","cartography;information retrieval","CURAP;Google Maps My Maps function;curating geo-related information on a map;geo-related information sharing platform;text searching","","","","2","","","7-11 Jan. 2016","","IEEE","IEEE Conference Publications"
"A puzzle in 4D digital preservation and reconstruction of an Egyptian palace","E. Aspöck; K. Kopetzky; B. Horejs; M. Bietak; M. Kucera; W. Neubauer","OREA Institute for Oriental and European Archaeology, Austrian Academy of Sciences (&#x00D6;AW), Vienna, Austria","2015 Digital Heritage","20160225","2015","2","","675","678","`A puzzle in 4D' is a new project dealing with the general problem of integration of heterogeneous and incomplete digital and non-digital records of archaeological long-term excavations to prepare them for spatio-temporal analysis, long-term archiving based on national and international standards and open-access online publication for specialists and the general public. Our a pilot study will be the resources from the Austrian excavation project at Tell el Daba (TED) in Egypt, where fieldwork has taken place since 1966. During this time, the archaeological discipline has seen major changes. Most notably developments in information technology have caused a shift from analogue to digitally-born data. As a result, the TED archive at the Institute for Oriental and European Archaeology OREA contains a huge and heterogeneous resource of digital and non-digital documents, photographs, plans and drawings. In this paper we will present TED resources and the challenges of archiving and integrating them using a 4D Archaeological Information System (AIS) for digital spatial-temporal post-excavation analysis. We will outline the possibilities we think such a system will add to conventional (2D) methods of analysis.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419596","Excavation data;archaeological Information System;legacy data","Databases;Documentation;Geographic information systems;Image reconstruction;Information systems;Standards;Three-dimensional displays","archaeology;data integration;geographic information systems;information retrieval systems","4D AIS;4D archaeological information system;A-puzzle-in-4D project;Austrian excavation project;Egypt;Egyptian palace;Institute for Oriental and European Archaeology;OREA;TED archive;Tell el Daba;archaeological excavations;digital documents;digital preservation;digital reconstruction;digital spatial-temporal postexcavation analysis;drawings;heterogeneous-incomplete digital-nondigital record integration;information technology;international standards;national standards;nondigital documents;open-access online publication;photographs;plans;spatio-temporal analysis","","","","13","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Negative Correlation Discovery for Big Multimedia Data Semantic Concept Mining and Retrieval","Y. Yan; M. L. Shyu; Q. Zhu","Dept. of Electr. & Comput. Eng., Univ. of Miami, Coral Gables, FL, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","55","62","With massive amounts of data producing each day in almost every field, traditional data processing techniques have become more and more inadequate. However, the research of effectively managing and retrieving these big data is still under development. Multimedia high-level semantic concept mining and retrieval in big data is one of the most challenging research topics, which requires joint efforts from researchers in both big data mining and multimedia domains. In order to bridge the semantic gap between high-level concepts and low-level visual features, correlation discovery in semantic concept mining is worth exploring. Meanwhile, correlation discovery is a computationally intensive task in the sense that it requires a deep analysis of very large and growing repositories. This paper presents a novel system of discovering negative correlation for semantic concept mining and retrieval. It is designed to adapt to Hadoop MapReduce framework, which is further extended to utilize Spark, a more efficient and general cluster computing engine. The experimental results demonstrate the feasibility of utilizing big data technologies in negative correlation discovery.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439305","Big Data;Hadoop;Information Integration;MapReduce;Multimedia Semantic Mining and Retrieval;Negative Correlation;Spark","Big data;Correlation;Data mining;Multimedia communication;Semantics;Streaming media;Videos","Big Data;data mining;information retrieval;multimedia databases;pattern clustering","Big Data management;Big Data retrieval;Hadoop MapReduce framework;big multimedia data semantic concept mining;cluster computing engine;data processing techniques;high-level concepts;low-level visual features;multimedia high-level semantic concept mining;negative correlation discovery;semantic gap","","2","","48","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"A Mixed Generative-Discriminative Based Hashing Method","Q. Zhang; Y. Wang; J. Qian; X. Huang","Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, P.R. China","IEEE Transactions on Knowledge and Data Engineering","20160304","2016","28","4","845","857","Hashing methods have proven to be useful for a variety of tasks and have attracted extensive attention in recent years. Various hashing approaches have been proposed to capture similarities between textual, visual, and cross-media information. However, most of the existing works use a bag-of-words methods to represent textual information. Since words with different forms may have similar meaning, semantic level text similarities can not be well processed in these methods. To address these challenges, in this paper, we propose a novel method called semantic cross-media hashing (SCMH), which uses continuous word representations to capture the textual similarity at the semantic level and use a deep belief network (DBN) to construct the correlation between different modalities. To demonstrate the effectiveness of the proposed method, we evaluate the proposed method on three commonly used cross-media data sets are used in this work. Experimental results show that the proposed method achieves significantly better performance than state-of-the-art approaches. Moreover, the efficiency of the proposed method is comparable to or better than that of some other hashing methods.","1041-4347;10414347","","10.1109/TKDE.2015.2507127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350158","Fisher Vector;Hashing Method;Hashing method;Word Embedding;fisher vector;word embedding","Context modeling;Dictionaries;Hashing methods;Media;Semantics;Visualization","belief networks;file organisation;information retrieval;text analysis","DBN;SCMH;bag-of-words methods;continuous word representations;cross media retrieval task;cross-media data sets;deep belief network;mixed generative-discriminative based hashing method;near-duplicate detection;semantic cross-media hashing;semantic level text similarities;textual information representation","","","","64","","20151209","April 1 2016","","IEEE","IEEE Journals & Magazines"
"Can We Group Similar Amazon Reviews: A Case Study with Different Clustering Algorithms","C. Fry; S. Manna","Comput. Sci. Dept., California State Polytech. Univ., Pomona, Pomona, CA, USA","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","374","377","The amount of unstructured text data available is growing exponentially due to the proliferation of digital information such as emails, text messages, blogs, social media posts, and product reviews. For users of e-commerce websites such as Amazon, navigating thousands of reviews before buying a product can be a daunting task. Unsupervised machine learning techniques can be used to automatically analyze preprocessed data from these websites in order to provide consumers with an improved user experience before purchasing a product. In this work, we leverage two flat clustering algorithms on Amazon review data: K-means and Peak-searching to perform clustering of product reviews based on topic. The experimental results show that K-means clustering performs better than Peak-searching clustering in terms of grouping similar reviews based on topics.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439368","clustering;k-means;peak;reviews","Algorithm design and analysis;Approximation algorithms;Blogs;Clustering algorithms;Computer science;Electronic mail;Measurement","Web sites;electronic commerce;information retrieval;pattern clustering;purchasing;retail data processing;reviews;text analysis;unsupervised learning","Amazon review data;K-means clustering;digital information proliferation;e-commerce Websites;improved user experience;peak-searching clustering;product purchasing;product review clustering algorithms;similar Amazon review grouping;unstructured text data;unsupervised machine learning techniques","","","","12","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Extracting Compact Sets of Features for Question Classification in Cognitive Systems: A Comparative Study","M. Pota; A. Fuggi; M. Esposito; G. D. Pietro","Inst. for High Performance Comput. & Networking, Naples, Italy","2015 10th International Conference on P2P, Parallel, Grid, Cloud and Internet Computing (3PGCIC)","20160303","2015","","","551","556","Question Classification is one of the key tasks of Cognitive Systems based on the Question Answering paradigm. It aims at identifying the type of the possible answer for a question expressed in natural language. Machine learning techniques are typically employed for this task, and exploit a high number of features extracted from labelled questions of benchmark training sets in order to achieve good classification results. However, the high dimensionality of the feature space often limits the possibility of applying more efficient classification approaches, due to high training costs. In this work, more compact sets of lexical and syntactic features are proposed to distinguish question classes. In particular, the widely used unigrams are substituted with a smaller number of features, extracted by modifying typical Natural Language Processing procedures for question analysis. The accuracy values gained on a benchmark dataset by using these different sets of features are compared among them and with the state-of-the-art, taking into account the required complexity at the same time. The new sets of extracted features show a good trade-off between accuracy and complexity.","","CD-ROM:978-1-4673-8317-2; Electronic:978-1-4673-9473-4; POD:978-1-4673-9474-1","10.1109/3PGCIC.2015.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424626","Cognitive Systems;Feature Extraction;NLP;Question Answering;Question Classification","Aspirin;Feature extraction;Natural language processing;Semantics;Support vector machines;Syntactics;Taxonomy","cognitive systems;feature extraction;learning (artificial intelligence);natural language processing;pattern classification;question answering (information retrieval)","benchmark training sets;cognitive systems;feature compact set extraction;feature space;lexical features;machine learning technique;natural language processing procedure;question analysis;question answering paradigm;question classification;syntactic features;unigrams","","1","","27","","","4-6 Nov. 2015","","IEEE","IEEE Conference Publications"
"Achievements Recommendation Framework Based on Scientific Collaboration Network","X. Li; J. Peng; S. Li","Inst. of Sci. & Tech. Inf. of China, Beijing, China","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","929","934","With the rapid growth of the Internet, vast amounts of data available and in other digital repositories make it challenging for users to find the right sources of information. This study presents a hierarchical recommendation framework that enriches the domain ontologies and retrieves more relevant information resources. In this paper, we analyze the features of achievements information related to the scientific and technological domains, and then build an ontology that represents their latent collaborative relations and detect clusters from the collaboration network. We conduct a case study to collect a data set of research achievements in electric vehicle field and better clustering results are obtained. This work also lays out a novel insight into the exploitation of scientific collaboration network to better classify achievements information.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424440","achievements information;clustering;collaboration network;recommender systems","Clustering algorithms;Collaboration;Internet;Libraries;Recommender systems;Social network services","Internet;information retrieval;ontologies (artificial intelligence);pattern clustering;recommender systems","Internet;domain ontology;electric vehicle field;hierarchical recommendation framework;recommendation framework achievement;scientific collaboration network","","","","13","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Java Tool Extensions for Supporting Multiple Recommenders and Distributed Bundles","M. Silaghi; K. Alhamed; R. Stansifer","Dept. of Comput. Sci. & Cybersecurity, Florida Inst. of Technol., Melbourne, FL, USA","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","722","725","A JAR (Java Archive) is typically used to incorporate code and associated resources into one file to distribute Java software. A cryptographically signed JAR file provides assurance about the authorship of the contents of the archive. We use Signed JAR files as part of a recommendation system. In this system different recommenders will evaluate the same software, and they need to sign the exact same JAR file. The user wants to verify that recommendations (i.e., signatures) received independently from multiple parties, e.g., for a software update, pertain to the exact same software. Related problems occur when users try to sign bundles consisting of files maintained on different servers. The tools in the Java Development Kit do not support this kind of application. We propose techniques to enable the signing of distribute bundles and techniques by which recommenders can sign software independently and such that verifiers are enabled to combine the recommendations. There changes to the Java jarsigner tool would avoid special purpose code which duplicates many of the same capabilities of the existing tools.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424184","JAR;recommendation;security;signature;update","Computer security;Computers;Cryptography;Digital signatures;Electronic mail;Java;Software","Java;cryptography;information retrieval systems;recommender systems;software tools","Java archive;Java jarsigner tool;Java software distribution;Java tool extensions;content authorship;distributed bundles;multiple recommenders;recommendation system;signed JAR files;software update","","","","10","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Effects of UAV mobility patterns on data collection in wireless sensor networks","S. Rashed; M. Soyturk","Department of Computer Engineering Marmara University Istanbul, Turkey","2015 IEEE International Conference on Communication, Networks and Satellite (COMNESTAT)","20160321","2015","","","74","79","Sensor nodes in a Wireless Sensor Network (WSN) can be dispersed over a remote sensing area e.g. the regions that cannot be accessed by human beings (inaccessible regions). In such kind of networks, data collection becomes one of the major issues. Getting connected to each sensor node and retrieving the information in time introduces new challenges. Mobile sink usage, especially the Unmanned Aerial Vehicle (UAV), is the most convenient approach to cover the area and access each sensor node in such a large scale WSN. However, the operation of the UAV depends on some parameters such as endurance time, altitude, speed, radio type in use, and the path. In this paper, we explore various mobility patterns of UAV that follow different paths to sweep the playground in order to seek the best area coverage with maximum number of covered nodes in less amount of time needed by the mobile sink. A realistic simulation environment is used in order to compare and evaluate the performance of the system. We present the performance results for the explored UAV mobility patterns. The results are very useful to present the tradeoff between maximizing the covered nodes and minimizing the operation time for choosing the appropriate mobility pattern.","","CD:978-1-4673-8248-9; Electronic:978-1-4673-8249-6","10.1109/COMNETSAT.2015.7434288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434288","","Clustering algorithms;Data acquisition;Data collection;Force;Mobile communication;Tracking;Wireless sensor networks","information retrieval;mobility management (mobile radio);remote sensing;wireless sensor networks","UAV mobility pattern effect;WSN;covered node maximization;data collection;information retrieval;mobile sink usage;operation time minimization;realistic simulation environment;remote sensing;wireless sensor network","","","","13","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"iClass: Combining Multiple Multi-label Classification with Expert Knowledge","M. Moussa; M. Maynard","Dept. of Comput. Sci. & Eng., Univ. of Connecticut, Storrs, CT, USA","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","843","848","Roper Center is one of the largest public opinion data archives in the world. It collects data sets of polled survey questions from numerous media outlets and organizations. The volume of data introduces search complexities over survey questions and poses challenges when analyzing search trends. Roper Center question-level retrieval applications used human metadata experts to assign topics to content. This has been insufficient to reach required levels of consistency and provides an inadequate base for creating an advanced search experience. The objective of this work is to combine the human expert teams' knowledge of the nature of the survey questions and the concepts and topics these questions express, with the ability of multi-label classifiers to learn this knowledge and apply it to an automated, fast and accurate classification mechanism. This approach cuts down the question analysis and tagging time significantly as well as provides enhanced consistency and scalability for topics' descriptions. At the same time, creating an ensemble of machine learning classifiers combined with expert knowledge is expected to enhance the search experience and provide much needed analytic capabilities to the survey questions databases. In our design, we use classification from several machine learning algorithms like SVM and Decision Trees, combined with expert knowledge in form of handcrafted rules, data analysis and result review. We consolidate the different techniques into a Multipath Classifier with a Confidence point system that decides upon the relevance of topics assigned to survey questions with nearly perfect accuracy.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424427","ensembles;expert knowledge;knowledge base;machine learning;multi-label classifiers;supervised learning;survey datasets","Data analysis;Databases;Decision trees;Machine learning algorithms;Support vector machines;Testing;Training","data analysis;human factors;information retrieval;learning (artificial intelligence);pattern classification","Roper Center question-level retrieval application;confidence point system;data analysis;handcrafted rule;human metadata expert;iClass;machine learning algorithm;machine learning classifier;multiple multilabel classifiers ability;public opinion data;search experience","","","","9","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Privacy Preserving Attribute Based Encryption for Multiple Cloud Collaborative Environment","N. Komninos; A. K. Junejo","Dept. of Comput. Sci., City Univ. London, London, UK","2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)","20160314","2015","","","595","600","In a Multiple Cloud Collaborative Environment (MCCE), cloud users and cloud providers interact with each other via a brokering service to request and provision cloud services. The brokering service considers several pieces of data to broker the best deal between users and providers which can subsequently risk the privacy and security of MCCE. In this paper, we propose a Privacy Preserving Attribute-Based Encryption (PPABE) scheme which protects MCCE from a compromised broker. The proposed encryption scheme preserves the privacy by employing data access policy over sets of attributes. The identifying attributes are anonymoized using pseudonyms. The data access policy is further anonymized so as it remains unknown to unauthorized parties. The PP-ABE achieves unlinkability between different data items which flows through the collaborative cloud environment and preserves the privacy of cloud users and cloud providers.","","Electronic:978-0-7695-5697-0; POD:978-1-5090-0343-3","10.1109/UCC.2015.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7431480","Attribute Based Encryption;Multiple Cloud Collaborative Environment;Privacy","Cloud computing;Collaboration;Data privacy;Encryption;Privacy;Quality of service","cloud computing;cryptography;data privacy;information retrieval","MCCE;PP-ABE scheme;brokering service;cloud service;data access policy;data privacy;multiple cloud collaborative environment;privacy preserving attribute-based encryption scheme","","","","13","","","7-10 Dec. 2015","","IEEE","IEEE Conference Publications"
"A robust spoken Q&A system with scarce in-domain resources","L. F. D'Haro; S. Kim; R. E. Banchs","Institute for Infocomm Research - A&#8727;STAR, 1 Fusionopolis Way, Connexis South, Singapore, 138632","2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20160225","2015","","","47","53","Nowadays there is an increasing interest on deploying spoken conversational agents to provide ubiquitous Question and Answering information to customers about corporate services and commercial products and supporting different users' devices such as PC desktops or mobile phones. Unfortunately, creating an accurate system requires a lot of handwork, where developers must consider several factors such as the performance of the ASR system, the presence of typos in the transcribed queries, the large number of possible variations to ask for the same information using different sentences, or the subtle differences that could exist between similar, but semantically different, questions. In this paper, we propose a methodology for quickly creating robust spoken-based conversational agents with very low resources. Our solution only requires few hand-made query samples, which are automatically expanded to deal with the use of different synonyms and wordings; next, spoken queries are automatically generated using a TTS system and then the audio files are corrupted to simulate different noise conditions and environments that the final users can experiment when they query the system using their voice with means of their mobile devices or by using a kiosk. Then, these audio files are subsequently transcribed using a general purpose ASR which produces an n-best list of recognized results that is first used to retrieve relevant documents and then re-ranked in order to select the final answer. Our tests on a set of 21 different topics proves that our proposal can get a 13% absolute better accuracy than a standard IR using an index with only in-domain answers and 6.3% better than a system including millions of negative out-of-domain candidate answers which is what it is expected for a scalable system.","","Electronic:978-9-8814-7680-7; POD:978-1-4673-9593-9","10.1109/APSIPA.2015.7415358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415358","","Feature extraction;Google;Indexes;Positron emission tomography;Robustness;Signal to noise ratio;Speech","question answering (information retrieval);speech recognition;speech synthesis;ubiquitous computing","ASR;TTS system;hand-made query;noise condition;robust spoken Q&A system;scarce in-domain resources;spoken conversational agent;ubiquitous question-and-answering information","","","","23","","","16-19 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Unified Framework for Fine-Grained Opinion Mining from Online Reviews","H. Wang; C. Zhang; H. Yin; W. Wang; J. Zhang; F. Xu","State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","1134","1143","Extracting opinion words and opinion targets from online reviews is an important task for fine-grained opinion mining. Usually, traditional extraction methods under the pipeline-based framework have higher precision but lower recall, while methods in the propagation-based framework possess greater recall but poorer precision. To achieve better performance both in precision and recall, this paper proposes a unified framework for fine-grained opinion mining, combining propagation with refinement in a dynamic and iterative process. In the propagation process, syntactic patterns are chosen as opinion relations to extract new opinion words and targets. Besides, syntactic patterns are further generalized to make them more flexible and scalable. In the refinement process, a three-layer opinion relations graph (ORG) model is constructed based on three types of candidates: opinion word candidates, opinion target candidates and syntactic pattern candidates. A sorting algorithm based on ORG model is proposed to rank all the candidates in their own type, and low-rank candidates are removed from candidate datasets. Repeat propagation and refinement until the syntactic pattern candidate set reaches stable. Experimental results on both English and Chinese online reviews demonstrate the effectiveness of proposed framework and its methods, comparing with the-state-of-the-art methods.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427323","opinion mining;opinion relations graph;sentiment analysis;syntactic pattern","Data mining;Feature extraction;Heuristic algorithms;Hidden Markov models;Pattern matching;Pipelines;Syntactics","consumer behaviour;graph theory;information retrieval;sentiment analysis;sorting","Chinese online reviews;English online reviews;fine-grained opinion mining;low-rank candidate removal;opinion target candidates;opinion target extraction;opinion word candidates;opinion word extraction;propagation process;refinement process;sorting algorithm;syntactic pattern candidates;three-layer ORG model;three-layer opinion relations graph model;unified framework","","","","27","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"Towards a Message-Driven Vocabulary for Promoting the Interoperability of Question Answering Systems","K. Singh; A. Both; D. Diefenbach; S. Shekarpour","Fraunhofer IAIS, St. Augustin, Germany","2016 IEEE Tenth International Conference on Semantic Computing (ICSC)","20160324","2016","","","386","389","Question answering (QA) is one of the biggest challenges for making sense out of data. The Web of Data has attracted the attention of the QA community and recently, a number of schema-aware QA systems have been introduced. While research achievements are individually significant, yet, integrating different approaches is not possible due to lack of a systematic approach for conceptually describing QA systems. In this paper, we present a message-driven vocabulary built upon an abstract level. This vocabulary is concluded from conceptual views of different QA systems. In this way, we are enabling researchers and industry to implement message-driven QA systems and to reuse and extend different approaches without interoperability and extension concerns.","","Electronic:978-1-5090-0662-5; POD:978-1-5090-0663-2","10.1109/ICSC.2016.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7439371","Annotation Model;Ontologies;Question Answering;Semantic Search;Semantic Web;Software Reusability","Data models;Electronic mail;Interoperability;Knowledge discovery;Ontologies;Pipelines;Vocabulary","Internet;open systems;question answering (information retrieval);research and development","QA community;Web of data;abstract level;message-driven QA systems;message-driven vocabulary;question answering systems interoperability;research achievements;schema-aware QA systems","","1","","17","","","4-6 Feb. 2016","","IEEE","IEEE Conference Publications"
"Bloom Filter Tree for Fast Search in Tree-Structured Data","M. Wang; Y. Zhu","Fac. of Bus. & Inf. Technol., Univ. of Ontario Inst. of Technol., Oshawa, ON, Canada","2015 International Conference on Computational Science and Computational Intelligence (CSCI)","20160303","2015","","","18","23","We consider the problem of searching for a data element in a tree-structured data set (e.g., XML). We propose a method which is more efficient than tree traversal and which still retains all the important metadata information that would be lost in the naive method of linear list search. We compute a bloom filter for each interior node of the tree, essentially building a bloom filter tree to enhance the original data tree. Using the bloom filters, we can do fast search by pruning out entire subtrees from being searched. We present a theoretical analysis of the search complexity of selective placement of bloom filters in the tree, which leads to an optimal placement strategy. Our experiments verify the efficiency of our method.","","Electronic:978-1-4673-9795-7; POD:978-1-4673-9796-4; USB:978-1-4673-9794-0","10.1109/CSCI.2015.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424057","data search;information systems;tree-structured data","Buildings;Complexity theory;Filtering algorithms;Metadata;Peer-to-peer computing;Search problems;XML","computational complexity;information retrieval;tree data structures","Bloom filter tree;fast tree-structured data search;linear list search;metadata information;optimal placement strategy;search complexity;subtrees;tree traversal","","","","22","","","7-9 Dec. 2015","","IEEE","IEEE Conference Publications"
"Bagging-based active learning model for named entity recognition with distant supervision","S. Lee; Y. Song; Maengsik Choi; H. Kim","Program of Computer and Communications Engineering, College of IT, Kangwon National University, Chuncheon-si, Gangwon-do, Korea","2016 International Conference on Big Data and Smart Computing (BigComp)","20160307","2016","","","321","324","Named entity recognition (NER) is a preliminary step to performing information extraction and question answering. Most previous studies on NER have been based on supervised machine learning methods that need a large amount of human-annotated training corpus. In this paper, we propose a semi-supervised NER model to minimize the time-consuming and labor-intensive task for constructing the training corpus. The proposed model generates weakly labeled training corpus using a distant supervision method. Then, it improves NER accuracy by refining the weakly labeled training corpus using a bagging-based active learning method. In the experiments, the proposed model outperformed the previous semi-supervised model. It showed F1-measure of 0.764 after 15 times of bagging-based active learning.","","Electronic:978-1-4673-8796-5; POD:978-1-4673-8797-2; USB:978-1-4673-8795-8","10.1109/BIGCOMP.2016.7425938","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7425938","active learning;bagging;distant supervision;named entity recognition","Bagging;Biological system modeling;Data mining;Data models;Dictionaries;Refining;Training","information retrieval;learning (artificial intelligence)","F1-measure;bagging-based active learning method;distant supervision method;information extraction;named entity recognition;semisupervised NER model","","","","14","","","18-20 Jan. 2016","","IEEE","IEEE Conference Publications"
"Predicting best answer using sentiment analysis in community question answering systems","F. Eskandari; H. Shayestehmanesh; S. Hashemi","Department of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran","2015 Signal Processing and Intelligent Systems Conference (SPIS)","20160303","2015","","","53","57","While interests in seeking and sharing questions/ answers through the Community Question Answering (CQA) systems has been increased, predicting the best answer in such systems is one of the main challenges that we are going to tackle in this paper. Considering comments as one of the inputs in our model and extracting features using Natural Language Processing (NLP) and text mining techniques such as Sentiment Analysis (SA) on comments and spell checking for answers, are the main parts of this research. Moreover, we worked on English language websites. On the other hand, users' social behavior and their activities considered as informative features in this paper. As a result, by finding the best combination of different features the performance of our model shows improvement in comparison to the related previous works on ""Stack Exchange"" websites.","","Electronic:978-1-5090-0139-2; POD:978-1-5090-0140-8","10.1109/SPIS.2015.7422311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422311","community question answering;feature extraction;sentiment analysis;text mining;user information","Analytical models;Feature extraction;Knowledge discovery;Sentiment analysis;Text mining","Web sites;data mining;feature extraction;information analysis;natural language processing;question answering (information retrieval);text analysis","CQA system;English language Web sites;NLP;community question answering system;feature extraction;natural language processing;sentiment analysis;stack exchange Web sites;text mining techniques","","","","9","","","16-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"Self-Adaptive Extracting Academic Entities from World Wide Web","P. Yuan; Y. Li; H. Jin; L. Liu","Services Comput. Technol. & Syst. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2015 IEEE Conference on Collaboration and Internet Computing (CIC)","20160303","2015","","","270","277","Huge amount of entities and theirs relationships are posted on the Web. Those entities and theirs relationship networks help many activities. In this paper, we focus on the task of extracting academic entity network from homepages. Homepages usually contain many entities, such as persons, conference/journal and organization and theirs relationship. However, homepages don't follow a unified layout format and often contains similar information, but differs greatly in layouts and styles, which makes it impossible to use a unified set of rules to handle them all. Thus we propose an integrated approach to automatically extract data from unstructured texts. The main idea of the approach is to adopt the most suitable approach to extract entities. Thus, the approach is self-adaptive. Firstly, the approach decomposes web pages into text units and then classifier is used to determine units' type. Once the units' types are known, the different technologies are chosen to deal with them. For example, edit distance and inverted index are used to identify names etc. And Conditional Random Field technology is considered the best solution to extract publication entries. The result shows that LineX has achieved high performance on extracting entities from web pages in academic community.","","Electronic:978-1-5090-0089-0; POD:978-1-5090-0090-6","10.1109/CIC.2015.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423092","CRF;Edit distance;Information extraction;Knowledge base;SVM","Data mining;Electronic mail;HTML;Internet;Knowledge based systems;Organizations;Web pages","Internet;Web sites;educational administrative data processing;information retrieval;random processes;text analysis","LineX;Web page decomposition;World Wide Web;academic community;academic entity network extraction;conditional random field technology;entity relationship networks;inverted index;publication entry extraction;self-adaptive academic entity extraction;unified layout format;unstructured texts","","","","19","","","27-30 Oct. 2015","","IEEE","IEEE Conference Publications"
"GWMEP: Task-Manageras-a-Service in Apache CloudStack","G. Indalecio; F. Gomez-Folgar; A. J. Garcia-Loureiro","Centro Singular de Investigaci&#x00F3;n en Tecnolox&#x00ED;as da Informaci&#x00F3;n (CiTIUS), Universidade de Santiago de Compostela, Spain","IEEE Internet Computing","20160226","2016","20","2","42","49","To provide researchers with the computing capacity that they need, several solutions have emerged. Cloud computing is known for providing on-demand self-service, elasticity, flexibility, and cost reduction. However, open source clouds such as Eucalyptus, OpenNebula, OpenStack, and Apache CloudStack don't provide features to handle computing tasks or workloads on virtual machines. Here, a solution is presented that lets the user execute tasks from within Apache CloudStack's interface, supporting task deployment, management, and retrieval, even in external Secure Shell (SSH)-reachable computing resources.","1089-7801;10897801","","10.1109/MIC.2015.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274268","Internet/Web technologies;cloud computing;computational resources;task manager;virtual machines;workloads","Cloud computing;Computational modeling;Processor scheduling;Resource allocation;Task management;Virtual machining;Web and internet computing","application program interfaces;cloud computing;information retrieval;public domain software;virtual machines","Apache CloudStack interface;Eucalyptus;GWMEP;OpenNebula;OpenStack;cloud computing;cost reduction factor;elasticity factor;external secure shell-reachable computing resources;flexibility factor;on-demand self-service;open source clouds;scientific fields;task deployment;task management;task retrieval;task-manager-as-a-service;virtual machines","","1","","10","","20150923","Mar.-Apr. 2016","","IEEE","IEEE Journals & Magazines"
"Spark-gram: Mining frequent N-grams using parallel processing in Spark","P. A. Utama; B. Distiawan","Faculty of Computer Science, Universitas Indonesia, Jakarta, Indonesia","2015 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20160225","2015","","","129","136","Mining sequence patterns in form of n-grams (sequences of words that appear consecutively) from a large text data is one of the fundamental parts in several information retrieval and natural language processing applications. In this work, we present Spark-gram, a method for large scale frequent sequence mining based on Spark that was adapted from its equivalent method in MapReduce called Suffix-σ. Spark-gram design allows the discovery of all n-grams with maximum length σ and minimum occurrence frequency τ, using iterative algorithm with only a single shuffle phase. We show that Spark-gram can outperform Suffix-σ mainly when τ is high but potentially worse when the value of σ grows higher.","","Electronic:978-1-5090-0363-1; POD:978-1-5090-0364-8; USB:978-1-5090-0362-4","10.1109/ICACSIS.2015.7415169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415169","distributed computing;hadoop;mapreduce;spark;text mining","Adaptation models;Computational modeling;Data mining;Data models;Data processing;Iterative methods;Sparks","data mining;information retrieval;iterative methods;natural language processing;parallel processing;text analysis","MapReduce;Spark-gram design;Suffix-σ;equivalent method;frequent n-gram;information retrieval;iterative algorithm;large scale frequent sequence mining;large text data;natural language processing application;parallel processing;sequence pattern mining;shuffle phase","","","","10","","","10-11 Oct. 2015","","IEEE","IEEE Conference Publications"
"Prediction of Users' Response Time in Q&A Communities","N. Burlutskiy; A. Fish; N. Ali; M. Petridis","Sch. of Comput., Eng. & Math., Univ. of Brighton, Brighton, UK","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","20160303","2015","","","618","623","Social media and online Question and Answer (Q&A) communities in particular have become a successful solution for finding answers on diverse topics. However, not all questions are answered by these communities. Also, many questions are not answered quickly enough. In this paper, we propose a framework for predicting users' response time. The framework uses a diverse set of features including information on users, the content they generate while communicating, question tags, spatial and temporal features. Then these features are used as input for training predictive models by various machine learning algorithms. As a case study, three diverse Q&A communities from Stack Exchange are selected to test the framework. We demonstrate that Deep Belief Networks outperform Logistic Regression (LR), k-nearest neighbors (k-NN), and Decision Trees (DT) in the accuracy of the prediction across the three diverse Q&A communities.","","Electronic:978-1-5090-0287-0; POD:978-1-5090-0288-7","10.1109/ICMLA.2015.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424386","Social media;machine learning;temporal user behavior","Algorithm design and analysis;Context;Electronic mail;Prediction algorithms;Predictive models;Time factors;Twitter","belief networks;decision trees;learning (artificial intelligence);question answering (information retrieval);regression analysis;social networking (online)","DT;LR;Q&A communities;decision trees;deep belief networks;k-NN;k-nearest neighbors;logistic regression;machine learning algorithms;online question and answer communities;predictive modeltraining;social media;stack exchange;user response time prediction","","","","21","","","9-11 Dec. 2015","","IEEE","IEEE Conference Publications"
"Time efficient ranking system on map reduce framework","A. Rawat; S. Saha; S. P. Ghrera","Dept. Computer Science, Jaypee University of Information Technology, India","2015 Third International Conference on Image Information Processing (ICIIP)","20160225","2015","","","496","501","The dimension of World Wide Web (The Internet) is in billions in terms of web pages and increasing rapidly. With the diversity of web pages available on the web, the high degree relevant information retrieval becomes a major issue. Such huge number of pages not only make the computation complex but also raises the issues of fault tolerance and time complexity. Computing ranking for such large number of web graph on a particular system, makes it prone to system failure and time taking. The present work proposes a distributed ranking system to attain fault tolerance and speedy calculation of Pagerank vector. The computation of rank vector is performed by implementing Pagerank on Mapreduce framework. The pagerank vector is calculated via spectral analysis to make the computation even faster and the results are compared to traditional pagerank scores.","","Electronic:978-1-5090-0148-4; POD:978-1-5090-0149-1","10.1109/ICIIP.2015.7414823","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7414823","Pagerank;distributed system;eigenvector;mapreduce;spectral analysis","Computers","Internet;Web sites;computational complexity;eigenvalues and eigenfunctions;fault tolerant computing;information retrieval;parallel processing;system recovery","Mapreduce framework;Pagerank framework;Pagerank vector;Web graph;Web page;World Wide Web;computing ranking;distributed ranking system;fault tolerance;information retrieval;spectral analysis;system failure;time complexity;time efficient ranking system","","","","11","","","21-24 Dec. 2015","","IEEE","IEEE Conference Publications"
"Enhancement of Science fiction collection proposal for standard cataloguing datasheet and engagement best practices for the exhibit","C. Feriotto; M. Marchetto; R. Meschini; M. Fabbri","Quantility srl, Ferrara, Italy","2015 Digital Heritage","20160225","2015","2","","477","478","The cataloguing activity is the base to know collection and cultural heritage. To catalogue objects and to spread the knowledge on the world it is important to use standardized methodologies, instruments and datasheets. There are no standard for the cataloguing activity of Science fiction collections. Quantility srl and Tryeco 2.0 srl developed a project to enhance the collection of a new museum of Science fiction located in Gaiba. The starting point was the cataloguing activity and an in depth study about cataloguing standards, datasheets and the second one was a research of similar realities. Collective Access is the open source platform used for the cataloguing activity, it was used the standard Dublin core and fields were modified to catalogue science fiction objects. Collective Access make possible an online presentation of the catalogue that was integrated in the new web site with an ad hoc design interface. The knowledge of collection permits the development of the exhibits design and the strategies to attract public and to engage it with a fablab, an urban laboratory on street art and smartphone application for contents. In conclusion, the research underlines a proposal for Science fiction cataloguing datasheet to standardized the methodology on this type of objects. It is under development the second part of the project about the exhibit of the collection and the engagement of public as a best practice to link the museum to the community and the territory.","","Electronic:978-1-5090-0048-7; POD:978-1-5090-0049-4; USB:978-1-5090-0047-0","10.1109/DigitalHeritage.2015.7419556","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7419556","Cataloguing activity;Exhibit;Fablab;Participation;Science Fiction;Standards","Best practices;Conferences;Cultural differences;Proposals;Standards;Three-dimensional displays;Web sites","Web sites;art;cataloguing;exhibitions;history;information retrieval;museums;natural sciences computing;public domain software;smart phones;user interfaces","Web site;ad hoc design interface;cataloguing activity;cataloguing standards;collective access;cultural heritage;exhibit design;museum;open source platform;project development;public engagement;science fiction cataloguing datasheet;science fiction collection proposal;smartphone application;standard Dublin core;standard cataloguing datasheet;street art;urban laboratory","","","","3","","","Sept. 28 2015-Oct. 2 2015","","IEEE","IEEE Conference Publications"
"Capturing the Semantics of Key Phrases Using Multiple Languages for Question Retrieval","W. N. Zhang; Z. Y. Ming; Y. Zhang; T. Liu; T. S. Chua","Research Center for Social Computing and Information Retrieval, School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Knowledge and Data Engineering","20160304","2016","28","4","888","900","In the age of Web 2.0, community user contributed questions and answers provide an important alternative for knowledge acquisition through web search. Question retrieval in current community-based question answering (CQA) services do not, in general, work well for long and complex queries, such as the questions. The main reasons are the verboseness in natural language queries and the word mismatch between the queries and the candidate questions in the CQA archive during retrieval. To address these two problems, existing solutions try to refine the search queries by distinguishing the key concepts in the queries and expanding the queries with relevant content. However, using the existing query refinement approaches can only identify the key and non-key concepts, while the differences between the key concepts are overlooked. Moreover, the existing query expansion approaches, not only overlook the weights of key concepts in the queries, but also fail to consider concept level expansion for them. In this paper, we explore a key concept identification approach for query refinement and a pivot language translation based approach to explore key concept paraphrasing. We further propose a new question retrieval model which can seamlessly integrate the key concepts and their paraphrases. The experimental results demonstrate that the integrated retrieval model significantly outperforms the state-of-the-art models in question retrieval.","1041-4347;10414347","","10.1109/TKDE.2015.2502944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335650","Key concept paraphrasing;key concept paraphrasing;query/question expansion;question retrieval","Data engineering;Feature extraction;Knowledge engineering;Semantics;Syntactics;Web search","Internet;natural language processing;query processing;question answering (information retrieval)","CQA services;Web 2.0;Web searching;community-based question answering services;concept identification approach;key concept paraphrasing;key phrase semantics;knowledge acquisition;natural language queries;pivot language translation based approach;query expansion approaches;query refinement;question retrieval;word mismatch","","","","50","","20151123","April 1 2016","","IEEE","IEEE Journals & Magazines"
"An empirical study on text analytics in big data","R. M. Packiam; V. S. J. Prakash","Computer Science, Cauvery College For Women, Tiruchirapalli, India","2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)","20160321","2015","","","1","4","Today's world is flooded with unstructured information. Big data is not just a description of raw volume but it has to real issue of usability. The major part of information retrieval is giant experience in big data. The real challenge is identifying or developing most cost effective and reliable methods for extracting value from all the terabytes and petabytes of data now available. That's where big data analytics become necessary. Conventional analytics focused on structured data but these methods are not appropriate for large volume of unstructured data in order to extract knowledge. Text analytics is the way to extract significance from the unstructured text to find out patterns and transformations. The importance of text analytics is increased more in social media and business intelligence. This study reveals that big data text analytics can breed new insight to the world of text information and discusses various researches carried out in text analytics.","","CD-ROM:978-1-4799-7847-2; Electronic:978-1-4799-7849-6; POD:978-1-4799-7850-2","10.1109/ICCIC.2015.7435747","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435747","Big data;text analytics;unstructured data","","Big Data;data structures;information retrieval;knowledge acquisition;text analysis","Big data text analytics;business intelligence;data structure;information retrieval;knowledge extraction;social media;unstructured text analytic","","","","","","","10-12 Dec. 2015","","IEEE","IEEE Conference Publications"
"Study on Recommendation in Internet of Things Environment","J. Kwon; S. Kim","Dept. of Comput. Sci., Kyonggi Univ., Suwon, South Korea","2015 7th International Conference on Multimedia, Computer Graphics and Broadcasting (MulGraB)","20160321","2015","","","13","14","The Internet of Things(IoT) has emerged as one of the hot research topics. The recommendation method offers useful information to the users. The new researches about recommendation method in IoT are required. We survey background and related researches. This paper describes the basic idea for new recommendation method in IoT environment.","","Electronic:978-1-4673-9831-2; POD:978-1-4673-9832-9","10.1109/MulGraB.2015.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7434190","Internet of Things;collaborative filtering;content-based filtering;recommendation","Collaboration;Information filtering;Internet of things;Multimedia communication;Social network services","Internet of Things;information retrieval","Internet of Things environment;IoT environment;recommendation method","","","","7","","","25-28 Nov. 2015","","IEEE","IEEE Conference Publications"
"Modes of Collaboration for Realizing E-Government Benefits","C. M. Lönn; G. Juell-Skielse; T. Päivärinta","","2016 49th Hawaii International Conference on System Sciences (HICSS)","20160310","2016","","","3031","3040","Collaboration among governmental organizations has been regarded as essential for realizing benefits of e-government investments. Inter-organizational collaboration on e-government can take several forms and can produce varying types of political, organizational, and technological benefits. However, few if any studies have delved deeper into analysis of how chosen modes of collaboration might relate to targeted e-government benefits. This paper studies multiple cases of how contemporary acquisitions and implementations of digital archiving systems have been launched through varying modes of collaboration among Swedish government agencies and municipalities. Our analysis reveals that whereas the target system, digital archive, is the same in all of the studied cases, the expected benefits varies. The article contributes by explaining how selected modes of collaboration in e-government may impact on the particular types of expected benefits.","1530-1605;15301605","Electronic:978-0-7695-5670-3; POD:978-1-5090-1981-6","10.1109/HICSS.2016.380","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427563","","Collaboration;Documentation;Electronic government;Interviews;Investment","government data processing;information retrieval systems;records management","Swedish government agencies;Swedish municipalities;collaboration modes;digital archiving systems;e-government","","","","45","","","5-8 Jan. 2016","","IEEE","IEEE Conference Publications"
"The Development of Personalized Writing Assistant for Electronic Discharge Summaries Based on Named Entity Recognition","S. Li; T. S. Zhou; X. H. Li; Y. W. Tu; J. S. Li","EMR & Intell. Expert Syst. Eng. Res. Center of Minist. of Educ., Zhejiang Univ., Hangzhou, China","2015 7th International Conference on Information Technology in Medicine and Education (ITME)","20160310","2015","","","660","663","Named entity recognition (NER) is one of the fundamental tasks in natural language processing, with a high utilization value in the medical domain. The electronic discharge summary is a comprehensive clinical document, with the important legal effect especially in medical disputes, which contains patients' relevant information during hospitalization. Current main writing mode of electronic discharge summary in China is typing along with copying/pasting or modifying on some existing template files with fixed forms, which inevitably leads to writing inefficiency and transcription errors. In order to solve this problem, this paper intelligently analyses some potential writing style using NER and designs a personalized writing assistant scheme to improve efficiency and reduce errors. The NER model trained by Chinese discharge summaries and rich features set has a good performance. The writing assistant monitors some key words typed in the writing process and timely extracts structural information from electronic medical record database as candidate inputs for the writer.","","CD-ROM:978-1-4673-8301-1; Electronic:978-1-4673-8302-8; POD:978-1-4673-8303-5","10.1109/ITME.2015.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429235","Electronic discharge summary;Named entity recognition;Structural Support Vector Machines;Writing Assistant","Databases;Discharges (electric);Diseases;Medical diagnostic imaging;Support vector machines;Writing","data privacy;electronic health records;information retrieval;natural language processing;support vector machines","China;Chinese electronic discharge summaries;NER;clinical document;electronic medical record database;medical disputes;named entity recognition;natural language processing;patient relevant information;personalized writing assistant development;structural information extraction;template files;transcription errors","","","","7","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"Evaluation of the ambiguity caused by the absence of diacritical marks in Arabic texts: Statistical study","M. Boudchiche; A. Mazroui","Department of Mathematics and Computer Science, Faculty of Sciences, University Mohamed first, B-P 717, 60000, Oujda, Morocco","2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)","20160310","2015","","","1","6","This work falls within the framework of the Natural Language Processing. Its objective is to assess the level of ambiguity caused by the absence of diacritical marks in Arabic texts during the information extraction process. We have carried out a statistical study based on four indicators: the root, the lemma, the stem and the POS tag of the word. For this, we used a large vowelized corpus containing more than 80 million words collected from several sources. The conducted study showed that the absence of diacritical marks in Arabic texts represents the main cause of the ambiguity observed in the information extraction process. Thus, based on this study we can conclude that the use of a vowelized corpus reduces considerably the ambiguity.","","Electronic:978-1-4673-8749-1; POD:978-1-4673-8750-7","10.1109/ICTA.2015.7426904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7426904","Arabic Language;Diacritical marks;Morphosyntactic analysis;Natural Language Processing;Statistical study","Computer science;Context;Natural language processing;Search engines;Semantics;Syntactics","information retrieval;natural language processing","Arabic texts;ambiguity evaluation;information extraction process;natural language processing;vowelized corpus","","1","","20","","","21-23 Dec. 2015","","IEEE","IEEE Conference Publications"
"Extraction of keyphrases from single document based on hierarchical concepts","M. Smatana; P. Butka","Department of Cybernetics and Artificial Intelligence, Faculty of Electrical Engineering and Informatics, Technical University of Ko&#353;ice, Letn&#225; 9, 04001 Ko&#353;ice, Slovakia","2016 IEEE 14th International Symposium on Applied Machine Intelligence and Informatics (SAMI)","20160303","2016","","","93","98","In this paper we provide modification of approaches for extraction of keyphrases from single textual document (without external information) based on the hierarchical concepts created upon the text of particular document. For the creation of hierarchical concepts method from area of Formal Concept Analysis (FCA) is used, which organizes objects into concept lattice (structure of hierarchically organized clusters known as formal concepts) based on the similarity of their attributes. In our case FCA is applied as follows. Input document is preprocessed, extracted objects are sentences or paragraphs and attributes are frequencies of terms in particular objects. For this input data conceptual model is created using FCA-based algorithm known as generalized one-sided concept lattice. Hierarchical concepts from this model are used for extraction of keyphrases for document. Our approach is experimentally tested on selected manually annotated documents and compared to standard keyphrase extraction methods, which beneficially improved their results thanks to usage of hierarchical concepts from concept-based analysis.","","Electronic:978-1-4673-8740-8; POD:978-1-4673-8741-5; USB:978-1-4673-8739-2","10.1109/SAMI.2016.7422988","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422988","","Context;Data mining;Data models;Informatics;Lattices;Measurement;Standards","data mining;formal concept analysis;information retrieval;text analysis","FCA;data conceptual model;formal concept analysis;generalized one-sided concept lattice;hierarchical concept;keyphrases extraction;single textual document","","","","32","","","21-23 Jan. 2016","","IEEE","IEEE Conference Publications"
"Semantic Web for Knowledge Integration between Traditional Chinese Medicine and Biomedicine","T. Yu; J. Liu; S. Yang; J. Li; L. Jia","Inst. of Inf. on Traditional Chinese Med., Beijing, China","2015 7th International Conference on Information Technology in Medicine and Education (ITME)","20160310","2015","","","229","233","The World Wide Web connects a wide variety of communities in medical domain, and provides a platform for knowledge exchange and integration between Traditional Chinese Medicine (TCM) and biomedicine. However, the cultural gaps between TCM and Western Medicine hinder cross-cultural communication. We utilize Semantic Web technologies to build a knowledge base that integrates distributed and heterogeneous knowledge elements from both biomedicine and TCM, and provides various information retrieval and knowledge discovery services. We explain how this integrated knowledge base helps to bridge the linguistic, semantic, and ontological gaps between different communities, and fosters cross-cultural scientific collaboration.","","CD-ROM:978-1-4673-8301-1; Electronic:978-1-4673-8302-8; POD:978-1-4673-8303-5","10.1109/ITME.2015.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429135","knowledge base;knowledge integration;knowledge services;ontology;semantic web;traditional Chiense medicine","Knowledge based systems;Medical diagnostic imaging;Ontologies;Resource description framework;Semantics","Internet;data mining;information retrieval;knowledge management;medical computing;medical information systems;ontologies (artificial intelligence);semantic Web","TCM;Western Medicine;World Wide Web;biomedicine;cross-cultural communication;cross-cultural scientific collaboration;cultural gaps;distributed knowledge elements;heterogeneous knowledge elements;information retrieval;integrated knowledge base;knowledge discovery services;knowledge exchange;knowledge integration;medical domain;semantic Web technologies;traditional Chinese medicine","","","","17","","","13-15 Nov. 2015","","IEEE","IEEE Conference Publications"
"Hashing for Cross-Modal Similarity Retrieval","Y. Liu; Y. Yuan; Q. Huang; Z. Huang","Semantic Grid Lab., Southwest Univ., Chong Qing, China","2015 11th International Conference on Semantics, Knowledge and Grids (SKG)","20160310","2015","","","1","8","Now, cross-modal retrieval similarity on multimedia with texts and images have attracted scholars' more and more attention. The difficulty of cross-modal retrieval is how to effectively construct correlation between multi-modal heterogeneous data. According to canonical correlation analysis, most existing cross-modal methods embed the heterogeneous data into a joint abstraction space by linear projections. The recognition accuracy is an urgent problem. To address this challenge, in this paper, we propose a adaptive boosting method with weighted CCA and Hash to solve cross-modal similarity retrieval. We use hash method to speed up the retrieval efficiency. Using the CCA to connect the image and text data with the original features. The weight is the input parameter of adaboost algorithm. We choose this algorithm to change the weight for reduce the CCA mapping error rate. We first capture the text component which is represented as a sample from a hidden topic model, learned with latent dirichlet allocation, and images are represented as bags of visual (SIFT and GIST) features. Second, the unified hash codes are generated through the high level abstraction space by hash method such as spectral hashing, kernelized locality semantic hashing and iterative quantization. Third, correlations between the two components are learned with weighted canonical correlation analysis. In this part, we use the Adaboost to iterate this process to find the best result. Finally, find out the nearest neighbors. Extensive experiments on two different datasets highlight the advantage of our method.","","Electronic:978-1-4673-9808-4; POD:978-1-4673-9809-1","10.1109/SKG.2015.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429350","Canonical Common Analysis;Cross-modal Retrieval;Hashing Mehtod","Correlation;Electronic publishing;Information services;Internet;Kernel;Media;Semantics","correlation methods;image recognition;image representation;information retrieval;iterative methods;learning (artificial intelligence);quantisation (signal);transforms","Adaboost algorithm;CCA mapping error rate;GIST;SIFT;adaptive boosting method;cross-modal retrieval;cross-modal similarity retrieval;hidden topic model;image representation;iterative quantization;kernelized locality semantic hashing;latent dirichlet allocation;linear projections;multimedia;multimodal heterogeneous data;nearest neighbors;recognition accuracy;spectral hashing;unified hash codes;weighted CCA;weighted canonical correlation analysis","","","","20","","","19-21 Aug. 2015","","IEEE","IEEE Conference Publications"
"Learning Discourse Relations from News Reports: An Event-driven Approach","J. A. Reyes; A. Montes","Dept. de Sist. de la Div. de Cienc. Basicas e Ing., Univ. Autonoma Metropolitana Azcapotzalco, Mexico City, Mexico","IEEE Latin America Transactions","20160310","2016","14","1","356","363","Nowadays, technologies allows us to store large volumes of information in different formats. It represents a challenge due to the lack of semantic in retrieval and extraction process of information efficiently. A possible strategy is to transform unstructured information into structured data. In recent years, ontologies have been widely used as an alternative to represent structured data from texts. This paper presents a new approach based on linguistic markers for ontology learning and population by considering cognitive aspects in order identify discourse relations between events from news reports. The main idea is to find concepts (event type), discourse relations (ontological relations) between events and class instances (real events). Our approach shows promising results for learning discourse relations in terms of F-measure.","1548-0992;15480992","","10.1109/TLA.2016.7430101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7430101","discourse relations;event-driven learning;linguistics markers;ontology learning","Data mining;Ontologies;Pragmatics;Semantics;Sociology;Statistics;Transforms","data structures;electronic publishing;information retrieval;learning (artificial intelligence);linguistics;ontologies (artificial intelligence)","cognitive aspects;event-driven approach;information extraction process;information large volume storage;information retrieval process;linguistic marker;news report;ontology learning discourse relation;structured data representation;text;unstructured information into structured data transformation","","","","","","","Jan. 2016","","IEEE","IEEE Journals & Magazines"
