"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7207023,7207278,7207258,7184689,7185172,7182691,7175958,7175932,7181523,7178056,7178002,7178054,7178060,7178004,7178001,7178386,7178059,7169826,7169835,7168326,7167494,7166592,7164807,7164756,7163034,7160608,7155880,7160901,7155962,7120998,7154988,7153859,7154759,7153879,7153601,7148507,7148367,7140397,7131410,7128883,7130389,7128918,7130148,7129877,7129982,7123536,7120623,7116727,7113548,7113410,7112126,7105541,7105551,7102240,7103220,7100610,7100469,7100347,7100743,7100232,7095870,7091550,7092336,7087079,7086171,7087045,7081831,7054470,7079092,7073365,7077299,7078612,7073836,7078691,7070000,7070064,7065563,7066725,7066694,7066640,7068138,7064994,7060911,7060020,7059659,7058020,7058199,7058053,6803042,6719388,7045531,7050693,7048186,7012074,7048218,7029060,7046906,7044051,7034871,7033476",2017/05/04 20:37:52
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Cache based evaluation of iceberg queries","V. Shankar; C. V. Guru Rao","Department of Computer Science and Engineering, Kakatiya Institute of Technology & Science, Warangal, Telangana, India - 506015","International Conference on Computing and Communication Technologies","20150326","2014","","","1","5","Nowadays, it is more demanded for techniques that are efficient in retrieval of small results from large data sets. Iceberg queries are such a kind of queries which accepts large data as input and process them for retrieve small results upon user specified threshold (T). Earlier, the iceberg queries are processed by many ways but are compromised in speed with which the data is retrieved. Thus lots of researchers are concentrating on improvement of iceberg query evaluation methods. Compressed bitmap index is an efficient technique which is developed recently to answer iceberg queries. In this paper, we proposed “Cache Based Evaluation of Iceberg Queries”. An iceberg query is evaluated using compressed bitmap index technique for threshold equals to 1, save results in cache memory for future reference. For further evaluation of an iceberg query thresholds greater than 1 are just picking the results from the cache memory instead of executing once again on the database table. Thus strategy clearly stating that, an execution time of IBQ is improved by avoiding repetition of an evaluation process by multiple times. Experimental results are demonstrating our cache based evaluation strategy is better than existing strategy.","","Electronic:978-1-4799-8150-2; POD:978-1-4799-8151-9","10.1109/ICCCT2.2014.7066694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066694","Bitmap vector;Cache memory;Data mining;Database;Information retrieval;Threshold","Bismuth;Databases","cache storage;database indexing;query processing","IBQ;cache based evaluation;cache memory;compressed bitmap index technique;database table;execution time;iceberg query evaluation method;iceberg query threshold;user specified threshold","","0","","21","","","11-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Automatic attendance rating of movie content using bag of audio words representation","A. Bleiweiss","Architecture Group, Intel Corporation, Santa Clara, U.S.A.","2013 International Conference on Signal Processing and Multimedia Applications (SIGMAP)","20150813","2013","","","142","150","The sensory experience of watching a movie, links input from both sight and hearing modalities. Yet traditionally, the motion picture rating system largely relies on the visual content of the film, to make its informed decisions to parents. The current rating process is fairly elaborate. It requires a group of parents to attend a full screening, manually prepare and submit their opinions, and vote out the appropriate audience age for viewing. Rather, our work explores the feasibility of classifying age attendance of a movie automatically, resorting to solely analyzing the movie auditory data. Our high performance software records the audio content of the shorter movie trailer, and builds a labeled training set of original and artificially distorted clips. We use a bag of audio words to effectively represent the film sound track, and demonstrate robust and closely correlated classification accuracy, in exploiting boolean discrimination and ranked retrieval methods.","","Electronic:978-9-8975-8129-8; POD:978-1-4799-7136-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7184689","Bag of Words;MFCC;Ranked Information Retrieval;Support Vector Machines;Vector Quantization","Cepstrum;Computational modeling;Feature extraction;Films;Gold;Motion pictures;Semantics","audio signal processing;hearing;information retrieval;signal classification","audio word representation bag;boolean discrimination;correlated classification accuracy;current rating process;film sound track represention;motion picture rating system;movie auditory data;movie content automatic attendance rating;ranked retrieval method","","0","","20","","","29-31 July 2013","","IEEE","IEEE Conference Publications"
"HSim: A novel method on similarity computation by hybrid measure","Q. Zhao; Cheng Wang; C. Jiang","The Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai 200092, China","2015 6th International Conference on Information and Communication Systems (ICICS)","20150507","2015","","","160","165","Link similarity is widely applied in measuring the similarity between objects, e.g., web pages, scientific papers and social networks. However, there are a lot of drawbacks in existing methods of measuring link similarity. In brief, these methods can not handle some semantic-similar content. Moreover, the computation of them are not accurate in some scenes. In this paper, we present a novel method of measuring link similarity called HSim. It introduces the semantic similarity to calculate the similarity between objects, and overcomes the drawback that existing methods ignore the semantic information of objects. We also develop a novel computation function to make the result of similarity more accurate.","","Electronic:978-1-4799-7349-1; POD:978-1-4799-7350-7","10.1109/IACS.2015.7103220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103220","Data Mining;Information Recommendation;Information Retrieval;Link Similarity","Complexity theory;Data mining;Internet;Ontologies;Semantics;Web pages","data mining;information retrieval","HSim;computation function;data mining;hybrid measure;information retrieval;link similarity;object semantic information;objects similarity;semantic similarity;similarity computation","","0","","21","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"A new modeling approach for Arabic opinion mining recognition","W. Cherif; A. Madani; M. Kissi","Laboratory LIMA, Department of Computer Science, Faculty of Sciences, B.P. 20, 24000 El Jadida, Morocco","2015 Intelligent Systems and Computer Vision (ISCV)","20150514","2015","","","1","6","Over recent years, the world has experienced a huge growth in the volume of shared web texts. Its users generate daily a huge volume of comments and reviews related to different aspects of their lives. In general, opinion mining/sentiment analysis refers to the task of identifying positive and negative opinions, emotions and evaluations related to an article, news, products, services, etc [1]. Arabic Opinion mining is conducted in this study using a dataset consisting of 625 Arabic reviews and comments collected from Trip Advisor website. We introduce a new mathematical approach to recognize author's opinion. As the weights computation is determining in the classification, we formulate first a linear program to maximize the distance between the considered classes, then we use these weights to calculate the label of each comment. A further post optimization is also treated to add other contributing descriptors in order to adjust the classification. The results which based on Support Vector Machines showed that the approach is the most influencing on opinion recognition.","","Electronic:978-1-4799-7511-2; POD:978-1-4799-7512-9","10.1109/ISACV.2015.7105541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105541","Arabic text;Automatic language processing;Information retrieval;Low-level light-Stemming;Opinion Mining;Support vector machines","Accuracy;Computational modeling;Computer science;Data mining;Kernel;Sentiment analysis;Support vector machines","Web sites;data mining;linear programming;natural language processing;support vector machines","Arabic opinion mining recognition;Trip Advisor Website;linear program;post optimization;sentiment analysis;shared Web texts;support vector machines","","1","","31","","","25-26 March 2015","","IEEE","IEEE Conference Publications"
"Giantsteps - progress towards developing intelligent and collaborative interfaces for music production and performance","P. Knees; K. Andersen; S. Jordà; M. Hlatky; G. Geiger; W. Gaebele; R. Kaurson","Dept. of Computational Perception, Johannes Kepler University Linz, Austria","2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","20150730","2015","","","1","4","We present the GiantSteps project, an EU-funded project involving institutions from academia, practitioners, and industrial partners with the goal of developing new concepts for intelligent and collaborative interfaces for music production and performance. At the core of the project is an iterative, user-centric research approach to music information retrieval (MIR) and human computer interaction (HCI) that is designed to allow us to accomplish three main targets, namely (1) the development of intelligent musical expert agents to support and inspire music makers, (2) more intuitive and collaborative interfaces, and (3) low-complexity methods addressing lowcost devices to enable affordable and accessible production tools and apps. In this paper, we report on the main findings and achievements of the project's first 18 months.","","Electronic:978-1-4799-7079-7; POD:978-1-4799-7080-3","10.1109/ICMEW.2015.7169826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169826","intelligent agents;live performance;music information retrieval;music production;user interfaces;user-centric design","Collaboration;Conferences;Instruments;Multiple signal classification;Music;Nickel;Production","groupware;human computer interaction;information retrieval;interactive systems;multi-agent systems;music","EU-funded project;GiantSteps project;HCI;MIR;collaborative interfaces;human computer interaction;intelligent interfaces;intelligent musical expert agent development;low-complexity methods;music information retrieval;music performance;music production;user-centric research approach","","0","","15","","","June 29 2015-July 3 2015","","IEEE","IEEE Conference Publications"
"Ontology-Based Integration and Sharing of Big Data Educational Resources","J. Xiong; Y. Liu; W. Liu","Sch. of Comput. & Inf. Eng., Anyang Normal Univ., Anyang, China","2014 11th Web Information System and Application Conference","20150312","2014","","","245","248","In the era of big data, massive educational resources are stored on the internet and mobile networks. However, most of these resources are heterogeneous and decentralized, they have different format. The resources are designed for humans to read and not understandable to the machine. Their low level sharing and reuse make them difficult to acquire. How to access the resources the users need quickly and efficiently and take advantage of them is a serious problem. In order to solve the problem, an ontology-based integration educational resources framework and sharing strategies are proposed. Using the advantages of ontological semantics these educational resources can be annotated semantically, so that the computer can understand and deal with the marked information. The ontology-based integration and sharing strategies can improve the recall and precision of the educational resources retrieval.","","Electronic:978-1-4799-5727-9; POD:978-1-4799-5728-6","10.1109/WISA.2014.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058020","big data;educational resources;information retrieval;ontology;semantic integration","Big data;Cognition;Educational institutions;Electronic learning;Ontologies;Semantics","Big Data;Internet;educational computing;information resources;mobile computing;ontologies (artificial intelligence)","big data educational resources;educational resources retrieval precision improvement;educational resources retrieval recall improvement;internet networks;mobile networks;ontological semantics;ontology-based integration strategy;ontology-based sharing strategy","","1","","11","","","12-14 Sept. 2014","","IEEE","IEEE Conference Publications"
"Page segment recommendation using N-gram for sensemaking tasks based on note taking","B. Thunnom; L. Ramingwong","Department of Computer Engineering, Chiang Mai University, Thailand","2015 12th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","20150820","2015","","","1","6","Internet has become an increasingly important tool for everyone on the planet. The large amount of information accessible from the internet makes web searching a common activity. Yet, such a common activity could take a long time to achieve desired results. Services such as information retrieval, interpretation management and sharing could greatly enhance efficiency of a search. However, such supports are not usually included in common search engines. Sensemaking support tools, on the other hand, can be used to tackle this challenge. Most sensemaking tools highlight on providing some kinds of structured decision support information for individuals and collaborated groups through history, annotation and document analysis rather than aiding users to find what they need. NorCost is, therefore, proposed to fulfill such overlooked objectives of searching.","","Electronic:978-1-4799-7961-5; POD:978-1-4799-7962-2","10.1109/ECTICon.2015.7207023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207023","Content extraction;Information retrieval;Information seek;N-gram;Note taking;Page segment;Recommendation;Sensemaking;Web search","Accuracy;Browsers;Feature extraction;Indexes;Search engines;Web pages","Internet;decision support systems;document handling;information retrieval;search engines","Internet;N-gram;NorCost;Web searching;annotation analysis;collaborated groups;document analysis;history;information retrieval;interpretation management;interpretation sharing;note taking;page segment recommendation;search engines;sensemaking support tools;structured decision support information","","0","","24","","","24-27 June 2015","","IEEE","IEEE Conference Publications"
"Content finder AssistanT","R. Laroche","Orange Labs, Issy les Moulineaux, France","2015 18th International Conference on Intelligence in Next Generation Networks","20150402","2015","","","231","238","This paper focuses on ""how to design and develop a dialogue system with a minimal effort"". It presents a novel model for automatic generation of dialogue systems built from contents. This approach is similar to and relies on a search engine, but with augmented dialogue capabilities: at each dialogue turn, the system propose n keywords, in order to optimise the information gain expectation. Its implementation, CFAsT, endeavours to keep the best from both worlds: the universality and automatic generation from search engines, and the usability, the assistance and the self optimisation provided by the dialogue systems. Thus, a beta dialogue application can be generated with no effort. It may serve to gather a dialogue corpus, or to gain a first return of experience. It can also be used as a low cost service. Afterwards, it can be improved with dedicated dialogue strategies.","","Electronic:978-1-4799-1866-9; POD:978-1-4799-1867-6; USB:978-1-4799-1865-2","10.1109/ICIN.2015.7073836","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073836","Dialogue systems;Information retrieval","Complexity theory;Dictionaries;Entropy;Equations;Mathematical model;Next generation networking;Search engines","content-based retrieval;interactive systems;search engines","CFAsT;Content Finder AssistanT;augmented dialogue capabilities;automatic dialogue system generation;dialogue corpus;information gain expectation;search engine;self optimisation","","0","","31","","","17-19 Feb. 2015","","IEEE","IEEE Conference Publications"
"Opinion detection: Influence factors","F. Belbachir; B. Le Grand","Universit&#x00E9; Paris Ouest Nanterre, 200, avenue de la R&#x00E9;publique, 92001, France","2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)","20150622","2015","","","522","523","Many online social networks (like blogs or Twitter) allow users to post and share their opinions on various topics. The detection and interpretation of these subjective comments is strategic for various organizational and business purposes, e.g., product and service benchmarking, ads placement or market intelligence. This article aims at enhancing the opinion detection process, i.e., the identification of documents that reflect an opinion, whatever their polarities - positive or negative. Our contribution consists in analyzing the factors that influence the detection of opinions. In particular, we investigate three factors: document's time, topic, and topic category. We have conducted an experiment to detect opinions in the TREC Blog 06 dataset, using the IMDB data collection as a reference. Our experimental results report that time, topics and topic categories have an impact on the opinion detection process.","2151-1349;21511349","Electronic:978-1-4673-6630-4; POD:978-1-4673-6631-1; USB:978-1-4673-6629-8","10.1109/RCIS.2015.7128918","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128918","Information retrieval;Opinion detection;Social Networks;categorization;language model","Blogs;Data collection;Data mining;Electronic mail;Internet;Organizations;Social network services","data mining;emotion recognition;information retrieval;social networking (online)","IMDB data collection;TREC Blog 06 dataset;Twitter;ads placement;blogs;business purposes;influence factors;market intelligence;online social networks;opinion detection process;opinion sharing;organizational purposes;product benchmarking;service benchmarking;subjective comment detection;subjective comment interpretation","","0","","4","","","13-15 May 2015","","IEEE","IEEE Conference Publications"
"Riposte: An Anonymous Messaging System Handling Millions of Users","H. Corrigan-Gibbs; D. Boneh; D. Mazières","Stanford Univ., Stanford, CA, USA","2015 IEEE Symposium on Security and Privacy","20150720","2015","","","321","338","This paper presents Riposte, a new system for anonymous broadcast messaging. Riposte is the first such system, to our knowledge, that simultaneously protects against traffic-analysis attacks, prevents anonymous denial-of-service by malicious clients, and scales to million-user anonymity sets. To achieve these properties, Riposte makes novel use of techniques used in systems for private information retrieval and secure multi-party computation. For latency-tolerant workloads with many more readers than writers (e.g. Twitter, Wikileaks), we demonstrate that a three-server Riposte cluster can build an anonymity set of 2,895,216 users in 32 hours.","1081-6011;10816011","Electronic:978-1-4673-6949-7; POD:978-1-4673-6950-3","10.1109/SP.2015.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163034","anonymity;messaging;privacy;private information retrieval","Cryptography;Databases;Privacy;Protocols;Resistance;Servers","Internet;data protection;electronic mail;electronic messaging;information retrieval;security of data;social networking (online)","Riposte;Twitter;Wikileaks;anonymous broadcast messaging system;denial-of-service;latency-tolerant workload;multiparty computation security;private information retrieval;traffic-analysis attack protection","","3","","78","","","17-21 May 2015","","IEEE","IEEE Conference Publications"
"Classification of Classic Turkish Music Makams by using Deep Belief Networks","M. A. Kızrak; B. Bolat","Elektrik ve Elektronik M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Hali&#x00E7; &#x00DC;niversitesi, &#x0130;stanbul, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","527","530","Through this work, six most known Classic Turkish Music Makams (CTM) were classified by using Deep Belief Networks (DBN). The Mel and delta-Mel Frequency Cepstral Coefficients (MFCC) were used as features. The best correct recognition ratio was obtained as 92.70% by using Deep Belief Networks and Mel frequency epstral coefficients. This result is better than the recent works reported in the literature.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129877","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129877","Classic Turkish Music;Deep Belief Networks;Mel Frequency Cepstral Coefficients;Music Information Retrieval","Conferences;Histograms;Mel frequency cepstral coefficient;Multiple signal classification;Signal processing;Speech","belief networks;cepstral analysis;music;pattern classification","CTM;DBN;MFCC;classic Turkish music Makams classification;deep belief networks;delta-Mel frequency cepstral coefficients;recognition ratio","","0","","15","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Patent search and trend analysis","A. M. Supraja; S. Archana; S. Suvetha; T. V. Geetha","Department of Computer Science and Engineering, College of Engineering, Guindy, Anna University, Chennai, India","2015 IEEE International Advance Computing Conference (IACC)","20150713","2015","","","501","506","A patent is an intellectual property document that protects new inventions. It covers how things work, what they do, how they do it, what they are made of and how they are made. The owner of the granted patent application has the ability to take a legal action to stop others from making, using, importing or selling the invention without permission. While applying for a patent, the inventor has issues in identifying similar patents. Citations of related patents, which are referred to as the prior art, should be included while applying for a patent. We propose a system to develop a Patent Search Engine to identify related patents. We also propose a system to predict Business Trends by analyzing the patents. In our proposed system, we carry out a query independent clustering of patent documents to generate topic clusters using LDA. From these clusters, we retrieve query specific patents based on relevance thereby maximizing the query likelihood. Ranking is based on relevancy and recency which can be performed using BM25F algorithm. We analyze the Topic-Company trends and forecast the future of the technology which is based on the Time Series Algorithm - ARIMA. We evaluate the proposed methods on USPTO patent database. The experimental results show that the proposed techniques perform well as compared to the corresponding baseline methods.","","CD-ROM:978-1-4799-8046-8; Electronic:978-1-4799-8047-5; POD:978-1-4799-8048-2","10.1109/IADCC.2015.7154759","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154759","cluster title generation;clustering;information retrieval;patents;technology forecasting","Companies;Databases;Market research;Patents;Search problems;Technological innovation","document handling;patents;pattern clustering;query processing;search engines;technological forecasting;time series","ARIMA time series algorithm;BM25F algorithm;LDA;USPTO patent database;business trend prediction;intellectual property document;patent document query independent clustering;patent search engine;query specific patent retrieval;technology forecasting;topic clusters;topic-company trends","","0","","15","","","12-13 June 2015","","IEEE","IEEE Conference Publications"
"Detecting duplicate bug reports with software engineering domain knowledge","K. Aggarwal; T. Rutgers; F. Timbers; A. Hindle; R. Greiner; E. Stroulia","Department of Computing Science, University of Alberta, Edmonton, Canada","2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20150409","2015","","","211","220","In previous work by Alipour et al., a methodology was proposed for detecting duplicate bug reports by comparing the textual content of bug reports to subject-specific contextual material, namely lists of software-engineering terms, such as non-functional requirements and architecture keywords. When a bug report contains a word in these word-list contexts, the bug report is considered to be associated with that context and this information tends to improve bug-deduplication methods. In this paper, we propose a method to partially automate the extraction of contextual word lists from software-engineering literature. Evaluating this software-literature context method on real-world bug reports produces useful results that indicate this semi-automated method has the potential to substantially decrease the manual effort used in contextual bug deduplication while suffering only a minor loss in accuracy.","1534-5351;15345351","Electronic:978-1-4799-8469-5; POD:978-1-4799-8470-1","10.1109/SANER.2015.7081831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081831","documentation;duplicate bug reports;information retrieval;machine learning;software engineering textbooks;software literature","Accuracy;Androids;Computer bugs;Context;Documentation;Feature extraction;Humanoid robots","program debugging;software engineering","contextual bug deduplication;contextual word list extraction;duplicate bug report detection;semiautomated method;software engineering domain knowledge","","6","","20","","","2-6 March 2015","","IEEE","IEEE Conference Publications"
"Author recognition from lyrics","B. Kırmacı; H. Oğul","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Ba&#x015F;kent &#x00DC;niversitesi, Ankara, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2489","2492","Music information retrieval has been an important task due to the wide use of internet and related technologies for entertainment. In previous studies, the problem has been considered using the meta-data or melodic content. The use of lyrics in this context is not that common. There is not study either for Turkish songs in this respect. In this study, we discuss the predictability of the author using the text data in a Turkish lyric. To this end, we propose a system that can predict the author using the features extracted from text content. The performance of the system is evaluated on a large data set collected from writers with different music styles.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130389","Information retrieval;classification;lyric analysis;music recommendation system;text features","Conferences;Entertainment industry;Feature extraction;Information retrieval;Internet;Mood;Rocks","Internet;feature extraction;information retrieval;music","Internet;Turkish songs;author recognition;feature extraction;lyrics;melodic content;meta-data;music information retrieval","","0","","10","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Exploring Textural Features for Automatic Music Genre Classification","N. Agera; S. Chapaneri; D. Jayaswal","Dept. Electron. & Telecommun. Eng., Univ. of Mumbai Mumbai, Mumbai, India","2015 International Conference on Computing Communication Control and Automation","20150716","2015","","","822","826","In this paper, music genre classification is performed using an approach which converts audio signals into spectrograms and Mel-spectrograms. These spectrograms are treated as texture images from which the following features are extracted: Local Binary Pattern (LBP), uniform Local Binary Pattern (uLBP) and Rotation Invariant LBP (RILBP). The LBP and RILBP features are extracted for having eight equally spaced neighbors and having a radius of one or two but for uLBP, features are extracted using the above parameters and also 16 neighbors and radius of two. Support Vector Machines (SVM) are used as classifiers and its multi-class implementation is used to classify a subset of five genres from GTZAN database namely classical, rock, disco, pop and hip-hop. The experiments resulted in a maximum recognition rate of 84% using spectrogram. The use of Mel-spectrogram to extract LBP, uLBP and RILBP features is novel and has resulted in a maximum recognition rate of 78%.","","Electronic:978-1-4799-6892-3; POD:978-1-4799-6893-0","10.1109/ICCUBEA.2015.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155962","Local Binary Pattern;Music Genre Classification;Music Information Retrieval;Spectrogram;Support Vector Machine","Accuracy;Feature extraction;Multiple signal classification;Music;Rocks;Spectrogram;Support vector machines","feature extraction;image classification;image retrieval;image texture;music;support vector machines","GTZAN database;LBP feature extraction;Mel-spectrograms;RILBP feature extraction;SVM;audio signals;automatic music genre classification;image textural feature extraction;local binary pattern;music information retrieval;rotation invariant LBP;support vector machines;uLBP feature extraction;uniform local binary pattern","","0","","12","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Enhancing higher education experience: The eMadrid initiative at UNED university","M. Rodríguez-Artacho; E. J. Lorenzo; L. S. Robles; J. Cigarrán; R. Centeno; J. I. Mayorga; J. Vélez; M. Castro; E. Sancristóbal; G. Díaz; S. Martín; R. Gil; F. Garcia; J. Cubillo; S. Ros","Departamento de Lenguajes y Sistemas Inform&#x00E1;ticos, Universidad Nacional de Educaci&#x00F3;n a Distancia, Spain","2014 IEEE Frontiers in Education Conference (FIE) Proceedings","20150219","2014","","","1","4","In this paper we focus on the achievements of eMadrid initiative in some fields of technology-enhanced learning, mainly involving the improvement of the mechanisms for open educational content retrieval from Internet, considering Internet resources as potential learning objects. Also we facilitate the integration of remote laboratories and external tools in virtual campuses architectures supporting enriched capabilities and describe a way to cluster and identify learner weaknesses using a learning analytics approach in combination with the item response theory.","0190-5848;01905848","Electronic:978-1-4799-3922-0; POD:978-1-4799-3923-7; USB:978-1-4799-3921-3","10.1109/FIE.2014.7044051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044051","Information Retrieval;Learning Objects;Remote Laboratories;Virtual Campus","Computer architecture;Educational institutions;Internet;Remote laboratories;Software","Internet;computer aided instruction;educational institutions;further education;information retrieval;laboratories","Internet resources;UNED university;eMadrid initiative;external tools;higher education experience enhancement;item response theory;learning analytics approach;learning objects;open educational content retrieval;remote laboratories;technology-enhanced learning;virtual campus architectures","","0","","13","","","22-25 Oct. 2014","","IEEE","IEEE Conference Publications"
"A new approach to hash function construction for textual data: A comparison","V. Skala; R. Petruska","Department of Computer Science and Engineering, University of West Bohemia, Plzen, Czech Republic","2014 4th World Congress on Information and Communication Technologies (WICT 2014)","20150402","2014","","","39","44","Many techniques for text processing are based on efficient data storing and retrieval techniques. Careful selection of data structures used and retrieval techniques play a significant role in efficiency of the whole system of data processing. Hashing technique is one very often used technique with O(1) run-time complexity for data storing and retrieval. A comparison of new technique for hash function construction is presented in the paper without need of division operation. The comparison of the proposed technique is especially convenient for large textual data sets processing. State of the art in hashing of textual data is given (the perfect hashing techniques are not included). The proposed hash function construction and hashing technique have been compared with other comparative techniques for different languages and textual data (chemical data sets etc.).","","Electronic:978-1-4799-8115-1; POD:978-1-4799-8116-8","10.1109/WICT.2014.7077299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077299","Hashing function;data structure;information retrieval;large data processing;summarization;text mining;text processing","Chemicals;Data structures;Databases;Dictionaries;Geophysical measurement techniques;Ground penetrating radar;Java","data structures;information retrieval;text analysis","data retrieval techniques;data storing techniques;data structures;hash function construction;hashing technique;run-time complexity;text processing;textual data","","0","","24","","","8-11 Dec. 2014","","IEEE","IEEE Conference Publications"
"Comparison of similarity metrics in microarray experiment retrieval","K. Açıcı; H. Oğul","Bilgisayar Muhendisligi Bolumu, Baskent Univ., Ankara, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","927","930","Content-based retrieval of biological experiments is a recent challenge in bioinformatics. The task is to search in a database using a query-by-example without any meta-data annotation. In this study, for retrieving relevant microRNA experiments from microarray repositories, performance evaluation of known similarity metrics was conducted to compare experiment fingerprints. It was shown that Spearman correlation coefficient outperformed others by comparison on real datasets. This result shows that ranks of fingerprint values are more important than the exact values in experiment fingerprint.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7129982","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7129982","information retrieval;microRNA;microarray experiment","Bioinformatics;Fingerprint recognition;Gene expression;Genomics;Visual databases","bioinformatics;content-based retrieval;correlation methods;lab-on-a-chip","Spearman correlation coefficient;bioinformatics;biological experiments;content-based retrieval;database;fingerprint values;microRNA experiments;microarray experiment retrieval;microarray repositories;performance evaluation;query-by-example;real datasets;similarity metrics","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Improving REST Service Discovery with Unsupervised Learning Techniques","J. M. Rodriguez; A. Zunino; C. Mateos; F. O. Segura; E. Rodriguez","ISISTAN - Res. Inst., Univ. Nac. del Centro de la Provincia de Buenos Aires (UNICEN), Tandil, Argentina","2015 Ninth International Conference on Complex, Intelligent, and Software Intensive Systems","20150813","2015","","","97","104","Discovery and replacement are two of the main features of Service Oriented Computing. There has been much research on these topics for traditional SOAP-based Web Services, particularly on discovery. Although the original proposal for REST services lacks this feature, some researchers have studied how to perform discovery for REST services using both IR based techniques and semantic techniques. This work presents a novel IR-based discovery approach for REST services described via WADL files. Our approach takes advantage of unsupervised machine learning techniques for improving discovering results. In particular, the approach relies on clustering algorithms, such as K-means or X-means, to reduce the search space for a given query. The experimental results show that using an appropriate clustering technique, our approach achieves nearly 4 times higher F-measure than a traditional IR-based search engine, namely Apache Lucene. Additionally, the paper reports other metrics, such as Recall, Precision, Precision at-10 and Recall at-10, that also point out that the proposed approach outperforms Lucene. Finally, another important contribution is a set of queries and WADL files gathered from the Internet that can be used for evaluating future discovery proposals.","","CD-ROM:978-1-4799-8869-3; Electronic:978-1-4799-8870-9; POD:978-1-4799-8871-6","10.1109/CISIS.2015.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7185172","Information Retrieval;REST;Services Discovery;WADL","Indexing;Measurement;Ontologies;Semantics;Web services","Web services;pattern clustering;query processing;service-oriented architecture;unsupervised learning","IR based techniques;IR-based discovery approach;K-means clustering algorithm;REST service discovery improving;SOAP-based Web services;WADL files;X-means clustering algorithm;f-measure metric;precision at-10 metric;query processing;recall at-10 metric;search space reduction;semantic techniques;service oriented computing;unsupervised machine learning techniques","","0","","26","","","8-10 July 2015","","IEEE","IEEE Conference Publications"
"PHENICX: Innovating the classical music experience","C. C. S. Liem; E. Gómez; M. Schedl","Multimedia Computing Group, Delft University of Technology, The Netherlands","2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","20150730","2015","","","1","4","PHENICX (“Performances as Highly Enriched aNd Interactive Concert eXperiences”) is an EU FP7 project that lasts from February 2013 to January 2016. It focuses on creating novel digital concert experiences, improving the accessibility of classical music concert performances by enhancing and enriching them in novel multimodal ways. This requires a usercentered approach throughout the project. After introducing the project, we discuss its goals, the technological challenges it offers, and current scientific and technological outcomes. Subsequently, we discuss how integrated prototypes combine several technological advances in the project into coherent user-ready interfaces, offering novel ways to experience the timeline of a concert, and rediscover and re-experience it afterwards. Finally, we discuss how PHENICX outcomes have been demonstrated live in concert halls.","","Electronic:978-1-4799-7079-7; POD:978-1-4799-7080-3","10.1109/ICMEW.2015.7169835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169835","audio processing;classical music;concert;creative industries;human-computer interaction;information visualization;music information retrieval;personalization;recommender systems;video analysis","Data visualization;Instruments;Media;Music;Prototypes;Streaming media;Visualization","human computer interaction;information retrieval;music;user centred design","EU FP7 project;PHENICX;classical music concert performance;classical music experience;concert hall;digital concert experience;performances as highly enriched and interactive concert experiences;user centered approach","","2","","15","","","June 29 2015-July 3 2015","","IEEE","IEEE Conference Publications"
"A new relevant document retrieval algorithm via adaptive discrete stochastic optimization","S. H. Ren","Shanghai International Studies University, China","2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP)","20150402","2014","","","79","82","In recent years, information is increasing exponentially which makes it more and more difficult for people to find the needed information from the huge database. To fulfill this demanding, a high accurate and fast-time document retrieval algorithm is highly required for current applications. In this paper, based on the document similarity maximum criterion, we propose a new fast-time document retrieval algorithm based on the adaptive discrete stochastic optimization method. The designed adaptive step-size ensures the proposed algorithm converges fast to the relevant documents in the database and retrieve the optimal document. Numerical results demonstrate that the proposed algorithm gets better converge and retrieval performance than conventional methods in the huge database.","","CD-ROM:978-1-4799-7206-7; Electronic:978-1-4799-7208-1; POD:978-1-4799-7209-8","10.1109/ICCWAMTIP.2014.7073365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073365","Information retrieval;adaptive discrete stochastic optimization;fast-time document retrieval algorithm;vector space model (VSM)","Algorithm design and analysis;Classification algorithms;Databases;Information retrieval;Optimization;Stochastic processes;Vectors","document handling;information retrieval;stochastic programming","adaptive discrete stochastic optimization;adaptive step-size;document similarity maximum criterion;fast-time document retrieval algorithm;retrieval performance","","0","","10","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Risk Aware Query Replacement Approach for Secure Databases Performance Management","O. A. Dia; C. Farkas","Comput. Sci. & Eng. Dept., Univ. of South Carolina, Columbia, SC, USA","IEEE Transactions on Dependable and Secure Computing","20150311","2015","12","2","217","229","Large amount of data and increased demand to extract, analyze and derive knowledge from data are impairing nowadays performance of enterprise mission-critical systems such as databases. For databases, the challenging problem is to manage complex and sometimes non-optimized queries executed on enormous data sets stored across several tables. This generally results in increased query response time and loss of employees productivity. In this paper, we investigate the problem of enterprise computing resources availability. Our goal is to minimize performance degradation arising from resource intensive queries. We propose a risk aware approach that decouples the process of analyzing resource requirements of sql queries from their execution. We leverage XACML to control users' requests and to monitor database loads. This allows us to adjust available resources in a database system to computing resource needs of queries. A query can therefore run in a database if it does not severely impact the performance of the database. Otherwise, we propose to the requester a replacement query denoted what-if-query. Such query proposes results that are similar to the results of the requester's query, is secure and provides acceptable answers when it executes without compromising the performance of the database.","1545-5971;15455971","","10.1109/TDSC.2014.2306675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6803042","XACML;cost estimation;databases;information retrieval;risk adaptive access control;sql","Access control;Availability;Database systems;Monitoring;System performance","SQL;authorisation;database management systems;query processing;resource allocation;risk management","SQL query;XACML;database performance management security;enterprise computing resource availability;performance degradation minimization;risk aware query replacement;user request control","","0","","32","","20140421","March-April 2015","","IEEE","IEEE Journals & Magazines"
"New performance measures in object detection","S. A. Kuzmin","Dept. of Radio Tech. & Optoelectron. Complexes, St. Petersburg State Univ. of Aerosp. Instrum., St. Petersburg, Russia","2015 IEEE NW Russia Young Researchers in Electrical and Electronic Engineering Conference (EIConRusNW)","20150507","2015","","","98","101","The article is devoted to new approaches in accuracy evaluation of information retrieval systems (with tests made for motion detection algorithms). First part of article is devoted to studying of how good is tested motion detection algorithm. New elements are added to ROC for computing new measures. These elements are based on Equal Error Rate criterion. Second part of article is devoted to visualization of progress for multiple-step motion detection algorithms. Any algorithm of this type is a set of blocks and it is important to know which gain in accuracy was achieved in N<sup>th</sup> step. Elements of design of multiple-step motion detection algorithms are discussed. Another discussed type of visualization is dedicated to boosting (combination of two and more algorithms).","","Electronic:978-1-4799-7306-4; POD:978-1-4799-7307-1","10.1109/EIConRusNW.2015.7102240","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102240","Equal Error Rate;ROC;boosting;decision making;false acceptance rate;information retrieval;object detection;performance evaluation;true acceptance rate;visualization","Algorithm design and analysis;Classification algorithms;Coordinate measuring machines;Estimation;Image edge detection;Motion detection;Visualization","error statistics;information retrieval systems;motion estimation;object detection;performance evaluation;sensitivity analysis","ROC;equal error rate criterion;information retrieval systems;multiple-step motion detection algorithms;object detection;performance measures;progress visualization","","0","","5","","","2-4 Feb. 2015","","IEEE","IEEE Conference Publications"
"A Dimensional Contextual Semantic Model for music description and retrieval","M. Buccoli; A. Gallo; M. Zanoni; A. Sarti; S. Tubaro","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Piazza Leonardo da Vinci 32 - 20133, Italy","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","673","677","Several paradigms for high-level music descriptions have been proposed to develop effective system for browsing and retrieving musical content in large repositories. Such paradigms are based on either categorical or dimensional models. The interest in dimensional models has recently grown a great deal, as they define a semantic relation between concepts through graded descriptions. One problem that affects semantic descriptions is the ambiguity that often arises from using the same descriptor in different contexts. In order to overcome this difficulty, it is important to model and address polysemy, which is the property of words to take on different meanings depending on the use-context. In this paper we propose a Dimensional Contextual Semantic Model for defining semantic relations among descriptors in a context-aware fashion. This model is here used for developing a semantic music search engine. In order to evaluate the effectiveness of our model, we compare this engine with two systems that are based on different description models.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178054","information retrieval;music;music recommendation;polysemy;semantic contexts","Computational modeling;Context;Context modeling;Large scale integration;Mood;Search engines;Semantics","information retrieval;music;search engines","context-aware fashion;dimensional contextual semantic model;graded descriptions;high-level music descriptions;music retrieval;musical content;musical content retrieval;polysemy;semantic descriptions;semantic music search engine;use-context","","1","","22","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"On automatic drum transcription using non-negative matrix deconvolution and itakura saito divergence","A. Roebel; J. Pons; M. Liuni; M. Lagrangey","UMR 9912 - IRCAM/UPMC/CNRS, Paris, France","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","414","418","This paper presents an investigation into the detection and classification of drum sounds in polyphonic music and drum loops using non-negative matrix deconvolution (NMD) and the Itakura Saito divergence. The Itakura Saito divergence has recently been proposed as especially appropriate for decomposing audio spectra due to the fact that it is scale invariant, but it has not yet been widely adopted. The article studies new contributions for audio event detection methods using the Itakura Saito divergence that improve efficiency and numerical stability, and simplify the generation of target pattern sets. A new approach for handling background sounds is proposed and moreover, a new detection criteria based on estimating the perceptual presence of the target class sources is introduced. Experimental results obtained for drum detection in polyphonic music and drum soli demonstrate the beneficial effects of the proposed extensions.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178002","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178002","Source separation;audio event detection;drum transcription;music information retrieval;non-negative matrix deconvolution","Algorithm design and analysis;Art;Convergence;Databases;Noise;Training;Training data","audio signal processing;deconvolution;information retrieval;matrix decomposition;music;musical instruments;numerical stability;signal classification;signal detection;source separation","Itakura Saito divergence;NMD;audio event detection methods;audio spectra decomposition;automatic drum transcription;background sound handling;drum loops;drum sound classification;drum sound detection;efficiency improvement;music information retrieval;nonnegative matrix deconvolution;numerical stability improvement;polyphonic music;source separation;target pattern set generation","","3","","21","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Keyword Extraction and Clustering for Document Recommendation in Conversations","M. Habibi; A. Popescu-Belis","Idiap Research Institute, Centre du Parc, Idiap Research Institute and &#x00C9;cole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne (EPFL), 1920 Martigny, Switzerland","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150306","2015","23","4","746","759","This paper addresses the problem of keyword extraction from conversations, with the goal of using these keywords to retrieve, for each short conversation fragment, a small number of potentially relevant documents, which can be recommended to participants. However, even a short fragment contains a variety of words, which are potentially related to several topics; moreover, using an automatic speech recognition (ASR) system introduces errors among them. Therefore, it is difficult to infer precisely the information needs of the conversation participants. We first propose an algorithm to extract keywords from the output of an ASR system (or a manual transcript for testing), which makes use of topic modeling techniques and of a submodular reward function which favors diversity in the keyword set, to match the potential diversity of topics and reduce ASR noise. Then, we propose a method to derive multiple topically separated queries from this keyword set, in order to maximize the chances of making at least one relevant recommendation when using these queries to search over the English Wikipedia. The proposed methods are evaluated in terms of relevance with respect to conversation fragments from the Fisher, AMI, and ELEA conversational corpora, rated by several human judges. The scores show that our proposal improves over previous methods that consider only word frequency or topic similarity, and represents a promising solution for a document recommender system to be used in conversations.","2329-9290;23299290","","10.1109/TASLP.2015.2405482","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045531","Document recommendation;information retrieval;keyword extraction;meeting analysis;topic modeling","Data mining;Encyclopedias;IEEE transactions;Information retrieval;Speech;Speech processing","document handling;pattern clustering;query processing;recommender systems;speech recognition","AMI conversational corpora;ASR system;ELEA conversational corpora;English Wikipedia;Fisher conversational corpora;automatic speech recognition;conversation fragment;document recommendation;document recommender system;information needs;keyword clustering;keyword extraction;submodular reward function;topic diversity;topic modeling techniques;word frequency","","4","","56","","20150219","April 2015","","IEEE","IEEE Journals & Magazines"
"A modified approach for extraction and association of triplets","A. Jaiswal; V. George","Department of Information Technology, Christ University, Bangalore, India","International Conference on Computing, Communication & Automation","20150706","2015","","","36","40","In this paper we present an enhanced algorithm with modified approach to extricate various Triplets i.e. subject-predicate-object from Natural language sentences. The Treebank Structure and the Typed Dependencies obtained from Stanford Parser are used to elicit multiple triplets from English Sentences. Typed Dependencies represents grammatical connections among the words of any sentence and represents how triplets are associated. The intended interpretation behind the extraction of Triplets is that the subject is acting on the object in a way described by the predicate. In graphical form it can be considered that subject and object will be acting as nodes i.e. entities and predicate as edges i.e. relationship. The resulting triplets and relations can be useful for building and analysis of a social network graph and for generating communication pattern and Information retrieval.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148367","extraction;information retrieval;parsing;relationship;triplets","Artificial neural networks;Automation;Conferences;Natural languages;Pragmatics;Random access memory;Syntactics","grammars;graph theory;information retrieval;natural language processing;social networking (online);text analysis","English sentences;Stanford parser;communication pattern generation;grammatical connections;information retrieval;natural language sentences;social network graph analysis;subject-predicate-object;treebank structure;triplet association;triplet extraction;triplet extrication;typed dependencies","","0","","17","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Enhancing Arabic Question Answering System","A. I. Kamal; M. A. Azim; M. Mahmoud","Dept. of Comput. Sci., Arab Acad. for Sci., Technol. & Maritime Transp., Cairo, Egypt","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","641","645","During the last few decades many Arabic question answering systems have been developed. These systems may extract answers from texts or web-pages. None of these systems make use of question answering database where user can present questions in natural language which differ from the stored questions. The proposed system uses information retrieval approaches to get to the closest answers to the input question, so the system gives partially or totally correct answers. The Latent Semantic Indexing (LSI) is implemented to enhance the resultant selections. Arabic natural language processing is used in the proposed system along with LSI.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065563","information retrieval;latent semantic indexing;natural language processing;question answering system","Equations;Indexing;Information retrieval;Knowledge discovery;Large scale integration;Natural languages;Semantics","indexing;natural language processing;question answering (information retrieval)","Arabic natural language processing;Arabic question answering system;information retrieval;latent semantic indexing","","0","","26","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Intelligent metadata web search engines: A brief review of literature on intelligent metadata based search engines","M. N. Mahdi; A. R. Ahmad; R. Ismail","College of Graduate Studies, College of Information Technology, University Tenaga National, Kuala Lumpure, Malaysia","Proceedings of the 6th International Conference on Information Technology and Multimedia","20150326","2014","","","255","258","Search engines are vital in the current digital world. Given the huge amount of information on the internet, search engines are vital tools that internet users are using to search web pages for the required information. However, most of the search engines currently in the market are inadequate and thus do not completely serve the needs of internet users. This is because in most cases they give results that are inaccurate and irrelevant. It is thus important to deploy search engine solutions that are embedded with intelligent agents that enable the search engines to work with enormous amount of information and give the search engines the capability to learn from their environment in order to give accurate and relevant results.","","Electronic:978-1-4799-5423-0; POD:978-1-4799-5424-7","10.1109/ICIMU.2014.7066640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066640","Data;Information Retrieval;Meta search engines;Metadata;Search Engines","Crawlers;Engines;Internet;Metasearch;Search engines;Semantics;Web pages","Internet;Web sites;meta data;multi-agent systems;search engines","Internet;Web pages;digital world;intelligent agent;intelligent metadata Web search engine","","0","","25","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"The model of possible Web data retrieval","A. Bryniarska","Opole University, Institute of Mathematics and Informatics, Poland","2015 IEEE 2nd International Conference on Cybernetics (CYBCONF)","20150806","2015","","","348","353","In the Dempster-Shafer's theory of evidence, for incorporating uncertainty, the valuation assigns to the data tables the degrees of belief for these data. Firstly, we are looking for the answers to the following questions. Is there a valuation-based system in which combination and marginalization operate on valuations? Has this system prosperities analogical to the t-norm system? In the t-norm system of the valuation for the specific database attributes configuration can be described the algebra of possible data set in which can be interpreted the Information Retrieval Logic.","","Electronic:978-1-4799-8322-3; POD:978-1-4799-8323-0","10.1109/CYBConf.2015.7175958","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175958","attribute language IRL;attribute valuation network;attributes configuration;canonical decomposition;evidence system;information retrieval logic;interpretation IRL;logic algebra of valuation;marginalization;possible data set;t-norm valuation system;valuation decomposition","Algebra;Cost accounting;Data models;Databases;Finite element analysis;Information retrieval;Syntactics","Internet;inference mechanisms;information retrieval","Dempster-Shafer evidence theory;Web data retrieval model;data tables;database attribute configuration;information retrieval logic;marginalization;t-norm system;valuation-based system","","0","","15","","","24-26 June 2015","","IEEE","IEEE Conference Publications"
"Matching Musical Themes based on noisy OCR and OMR input","S. Balke; S. P. Achankunju; M. Müller","International Audio Laboratories Erlangen, Friedrich-Alexander-Universit&#x00E4;t (FAU), Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","703","707","In the year 1948, Barlow and Morgenstern published the book “A Dictionary of Musical Themes”, which contains 9803 important musical themes from the Western classical music literature. In this paper, we deal with the problem of automatically matching these themes to other digitally available sources. To this end, we introduce a processing pipeline that automatically extracts from the scanned pages of the printed book textual metadata using Optical Character Recognition (OCR) as well as symbolic note information using Optical Music Recognition (OMR). Due to the poor printing quality of the book, the OCR and OMR results are quite noisy containing numerous extraction errors. As one main contribution, we adjust alignment techniques for matching musical themes based on the OCR and OMR input. In particular, we show how the matching quality can be substantially improved by fusing the OCR- and OMR-based matching results. Finally, we report on our experiments within the challenging Barlow and Morgenstern scenario, which also indicates the potential of our techniques when considering other sources of musical themes such as digital music archives and the world wide web.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178060","Music Information Retrieval;Optical Character Recognition;Optical Music Recognition;Query-by-Example","Adaptive optics;Books;Character recognition;Engines;Metadata;Optical character recognition software;Pipelines","Internet;Web sites;audio databases;audio signal processing;document image processing;electronic music;information retrieval;optical character recognition;text detection","OCR;OMR;Western classical music literature;World Wide Web;alignment techniques;digital music archives;extraction errors;matching quality;musical themes;optical character recognition;optical music recognition;printed book textual metadata;printing quality;symbolic note information","","0","","17","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Mobile recommendation system for cosmeceutical products","Ching-Sheng Hsu; Shu-Fen Tu","Department of Information Management, Ming Chuan University, Taoyuan, Taiwan","2015 Seventh International Conference on Ubiquitous and Future Networks","20150810","2015","","","973","976","Most cosmeceutical products show ingredients in English, which is not easy to understand for consumers. Consumers can link to some existing websites and type these English ingredients to inquiry. However, these English ingredients are usually long and complex, and consumers are prone to making error on typing. Except for ingredients, information about similar commodity is also important for consumers when making decisions on purchasing cosmeceutical products. The purpose of this research is to provide an ingredient retrieval and recommendation system for cosmeceutical products. Our research utilizes 2D barcode to automatically gather ingredients and vector model to search f or commodities with similar ingredients. Our system is implemented on Android mobile phone, so the retrieval and recommendation are prompt.","2165-8528;21658528","Electronic:978-1-4799-8993-5; POD:978-1-4799-8994-2; USB:978-1-4799-8992-8","10.1109/ICUFN.2015.7182691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182691","2D barcode;QR code;information retrieval;product recommendation;vector model","Collaboration;Smart phones","Web sites;bar codes;cosmetics;information retrieval;medical information systems;mobile computing;pharmaceuticals;recommender systems;smart phones","2D barcode;Android mobile phone;English ingredients;English language;Web sites;cosmeceutical products;ingredient retrieval;mobile recommendation system;vector model","","0","","17","","","7-10 July 2015","","IEEE","IEEE Conference Publications"
"Ontology development for agriculture domain","N. Malik; A. Sharan; D. Hijam","JNU, New Delhi, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","738","742","Ontology is recently one of the hot issues in research community. Domain specific Ontologies are being utilized as a search engine on the web page with an objective to make searching on the web page substantially more efficient, especially when it is more important to find the right web page, than searching with usual keywords. Ontology can play a very important role in the process of creating as well as managing the knowledge. This paper addresses the important issues in developing domain specific ontology for agriculture domain. We propose a generic approach for agriculture domain ontology representing entities and their relationships. We have developed a small ontology using the suggested approach. Our work is significant as we have not found any significant work targeting ontology development in agriculture domain.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100347","AGROVOC;Ontology;information retrieval;knowledge representation","Agriculture;Diseases;Information retrieval;Ontologies;Semantics;Text mining","Internet;agriculture;ontologies (artificial intelligence);search engines","Web page;agriculture domain;domain specific ontologies;generic approach;ontology development;search engine","","0","","11","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"An Ontology-Based Approach for Retrieving Information from Disparate Sectors in Government: The Patent System as an Exemplar","K. H. Law; S. Taduri; G. T. Law; J. P. Kesan","Eng. Inf. Group, Stanford Univ., Stanford, CA, USA","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","2096","2105","The ability to access patents and relevant patent-related information pertaining to a patented technology can fundamentally transform the patent system and its functioning and patent institutions such as the USPTO and the federal courts. This paper describes an ontology-based computational framework that can resolve some of difficult issues in retrieving patents and patent related information for the legal and justice system.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070064","Information Retrieval;Ontology;Patent System","Drugs;Law;Ontologies;Patents;Semantics;Technological innovation","government data processing;information retrieval;law administration;ontologies (artificial intelligence);patents","USPTO;federal courts;justice system;legal system;ontology-based approach;ontology-based computational framework;patent institutions;patent related information retrieval;patent system;patented technology","","0","","48","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Playlist generation based on user perception of songs","P. Kalapatapu; U. Dubey; A. Malapati","Dept of CSIS, BITS-Pilani, Hyderabad Campus, India","2015 International Conference on Signal Processing and Communication Engineering Systems","20150312","2015","","","44","47","Large online music collections often frustrate users and have increased the importance of recommender systems. This has led to interesting problem of automated playlist generation. Most of the existing playlist's compare a pair songs based on low-level/mid-level features and calculate the similarity. These systems lack user perception of music. This work supplements such existing systems by providing user perception of songs conveyed in Twitter messages. The proposed system combines audio based features and sentiment associated with the song. This unique fusion not only yields better results but also better user satisfaction. Further a validation on 200 users who used our playlist showed that atleast 67% of the songs in the playlist were liked by the user.","","Electronic:978-1-4799-6109-2; POD:978-1-4799-6110-8","10.1109/SPACES.2015.7058199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058199","Music Information Retrieval;Playlist Generation;Sentiment Analysis","Correlation;Data mining;Databases;Educational institutions;Media;Mel frequency cepstral coefficient;Twitter","music;recommender systems;social networking (online)","Twitter messages;audio based features;automated playlist generation;music user perception;online music collections;playlist generation;recommender systems;song user perception;user satisfaction","","0","","8","","","2-3 Jan. 2015","","IEEE","IEEE Conference Publications"
"A Multi-dimensional Analysis and Data Cube for Unstructured Text and Social Media","S. Lee; N. Kim; J. Kim","Dept. of Comput. Sci., Kangwon Nat. Univ., Chuncheon, South Korea","2014 IEEE Fourth International Conference on Big Data and Cloud Computing","20150209","2014","","","761","764","Recently, unstructured data like texts, documents, or SNS messages has been increasingly being used in many applications, rather than structured data consisting of simple numbers or characters. Thus it becomes more important to analysis unstructured text data to extract valuable information for usres decision making. Like OLAP (On-Line Analytical Processing) analysis over structured data, Multi-dimensional analysis for these unstructured data is popularly being required. To facilitate these analysis requirements on the unstructured data, a text cube model on multi-dimensional text database has been proposed. In this paper, we extended the existing text cube model to incorporate TF-IDF (Term Frequency Inverse Document Frequrency) and LM (Language Model) as measurements. Because the proposed text cube model utilizes new measurements which are more popular in information retrieval systems, it is more efficient and effective to analysis text databases. Through experiments, we revealed that the performance and the effectiveness of the proposed text cube outperform the existing one.","","Electronic:978-1-4799-6719-3; POD:978-1-4799-6720-9","10.1109/BDCloud.2014.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7034871","Multi-dimensional analysis;OLAP;TF-IDF;data cube;information retrieval;language model;text cube;text databases","Analytical models;Computational modeling;Data models;Databases;Frequency measurement;Information retrieval;Mathematical model","data analysis;data mining;database management systems;information retrieval;social networking (online);text analysis","LM;OLAP analysis;SNS messages;TF-IDF;data cube;decision making;information retrieval systems;language model;multidimensional analysis;multidimensional text database;online analytical processing;term frequency inverse document frequency;text cube model;unstructured text data analysis","","0","","14","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Anti-phishing using Hadoop-framework","M. Gavahane; D. Sequeira; A. Pandey; A. Shetty","Department of Computer Engineering, Don Bosco Institute of Technology, Mumbai, India","2015 International Conference on Technologies for Sustainable Development (ICTSD)","20150430","2015","","","1","4","Phishing is an activity that is carried out online inorder to steal the identity of the users online such as their user IDs, passwords and credit card details. Unaware online users easily fall for these phishing web pages because of their high similarities to the real ones. Detecting & Identifying fake websites is a very cumbersome task. Several attributes are needed to be taken into consideration. The existing phishing detection systems are time consuming & heavily rely on the backend database available. In this proposed system, main focus is on retrieving the necessary attributes in real time using Hadoop-MapReduce, which will help us increase both speed & throughput of the system. This new system aims at providing secure browsing experience to the user.","","Electronic:978-1-4799-8187-8; POD:978-1-4799-8188-5","10.1109/ICTSD.2015.7095870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7095870","Anti-Phishing;Data Mining;Hadoop;Information Retrieval;MapReduce;Phishing","Browsers;Crawlers;Data mining;Databases;Generators;Uniform resource locators;Web pages","computer crime;data handling;parallel processing","Hadoop-MapReduce;anti-phishing;browsing security","","0","","14","","","4-6 Feb. 2015","","IEEE","IEEE Conference Publications"
"Ranking model adaptation for domain specific mining using binary classifier for sponsored ads","M. Krishnamurthy; N. A. A. Jaishree; A. S. Pillai; A. Kannan","Department of CSE, KCG College of Technology, Chennai, Tamilnadu, India","2014 14th International Conference on Hybrid Intelligent Systems","20150416","2014","","","35","42","Domain - specific search focuses on one area of knowledge. Applying broad based ranking algorithms to vertical search domains is not desirable. The broad based ranking model builds upon the data from multiple domains existing on the web. Vertical search engines attempt to use a focused crawler that index only relevant web pages to a predefined topic. With Ranking Adaptation Model, one can adapt an existing ranking model of a unique new domain. The binary classifiers classify the members of a given set of objects into two groups on the basis of whether they have some property or not. If it is property of relevancy, it is returned to the search query of that particular domain vertical. Sponsored ads are then placed alongside the organic search results and they are ranked with the help of bid, budget and quality score. The ad with the highest bid is placed first in the ad listings. Later, the ad with a maximum quality score is found by click through logs which is replaced in first position. Thus, both organic search and sponsored ads are returned for the specific domain, making it easy for the users to get access to real time ads and connect directly with advertisers as well as to get information on the search query.","","Electronic:978-1-4799-7633-1; POD:978-1-4799-7634-8","10.1109/HIS.2014.7086171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086171","Information Retrieval;Keyword Auction;Learning to Rank;Online Algorithm;Pay per click;Sponsored Ads","Adaptation models;Classification algorithms;Data models;Databases;Search engines;Support vector machines;Web pages","Internet;data mining;pattern classification;query processing;search engines;support vector machines","SVM;Web page;binary classifier;broad based ranking model;domain specific mining;ranking adaptation model;search engine;search query;sponsored ads;support vector machine","","0","","14","","","14-16 Dec. 2014","","IEEE","IEEE Conference Publications"
"Novel Metaknowledge-Based Processing Technique for Multimediata Big Data Clustering Challenges","N. Bari; R. Vichr; K. Kowsari; S. Y. Berkovich","Dept. of Comput. Sci., George Washington Univ., Washington, DC, USA","2015 IEEE International Conference on Multimedia Big Data","20150713","2015","","","204","207","Past research has challenged us with the task of showing relational patterns between text-based data and then clustering for predictive analysis using Golay Code technique. We focus on a novel approach to extract metaknowledge in multimedia datasets. Our collaboration has been an on-going task of studying the relational patterns between data points based on met features extracted from metaknowledge in multimedia datasets. Those selected are significant to suit the mining technique we applied, Golay Code algorithm. In this research paper we summarize findings in optimization of metaknowledge representation for 23-bit representation of structured and unstructured multimedia data in order to be processed in 23-bit Golay Code for cluster recognition.","","CD-ROM:978-1-4799-8687-3; Electronic:978-1-4799-8688-0; POD:978-1-4799-8689-7","10.1109/BigMM.2015.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153879","23-Bit Meta-knowledge template;Big Multimedia Data Processing and Analytics;Content Identification;Golay Code;Information Retrieval Challenges;Knowledge Discovery;Meta-feature Extraction and Selection;Metalearning System","Big data;Conferences;Multimedia communication","data mining;knowledge representation;multimedia computing;pattern clustering;text analysis","23-bit representation;Golay code technique;cluster recognition;metaknowledge representation;metaknowledge-based processing technique;mining technique;multimedia big data clustering challenges;multimedia datasets;predictive analysis;relational patterns;structured multimedia data;text-based data;unstructured multimedia data","","0","","17","","","20-22 April 2015","","IEEE","IEEE Conference Publications"
"A Chronic Illness System Using Biomedical Knowledge Sources and Relevance Feedback","A. A. Macedo; J. T. Pollettini; E. V. Munson","Biomed. Inf. Group, FFCLRP-USP, Ribeirao, Brazil","2015 IEEE 28th International Symposium on Computer-Based Medical Systems","20150727","2015","","","244","249","CISS+ is a new surveillance system designed to aid clinicians seeking to help patients make healthy decisions about their lifestyle and health. It takes clinical records as queries anduses these records to find articles in the scientific literature that describe risk factors relevant to the patients' history and medical state. CISS+ is a revision of the earlier CISS system, which useda simple n-gram text retrieval strategy. CISS+ enhances CISS byusing higher-relevance terms and concepts taken from the UMLS and MetaMap systems and by using automated techniques related to relevance feedback to refine queries. CISS+ was evaluated viaa small set of experimental queries that were sent to other widely available biomedical research search systems. CISS+ returned asmall number of results that had better relevance to the goal of identifying risks factors.","1063-7125;10637125","Electronic:978-1-4673-6775-2; POD:978-1-4673-6776-9","10.1109/CBMS.2015.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167494","Biomedical Informatics;Epignetics;Information Extraction;Information Retrieval","Bioinformatics;Diabetes;Diseases;Ontologies;Semantics;Surveillance;Unified modeling language","diseases;electronic health records;medical computing;patient care;query processing;text analysis","CISS system;CISS+;MetaMap systems;UMLS systems;automated techniques;biomedical knowledge sources;biomedical research search systems;chronic illness system;clinical records;experimental queries;health;higher-relevance terms;lifestyle;n-gram text retrieval strategy;patient history;patient medical state;relevance feedback;risk factors;risks factors;scientific literature;surveillance system","","0","","20","","","22-25 June 2015","","IEEE","IEEE Conference Publications"
"Fashion Parsing With Video Context","S. Liu; X. Liang; L. Liu; K. Lu; L. Lin; X. Cao; S. Yan","Institute of Information Engineering, Chinese Academy of Sciences and National University of Singapore, Beijing, China","IEEE Transactions on Multimedia","20150715","2015","17","8","1347","1358","In this paper, we propose a novel semi- supervised learning strategy to address human parsing. Existing human parsing datasets are relatively small due to the required tedious human labeling. We present a general, affordable and scalable solution, which harnesses the rich contexts in those easily available web videos to boost any existing human parser. First, we crawl a large number of unlabeled videos from the web. Then for each video, the cross-frame contexts are utilized for human pose co- estimation , and then video co-parsing to obtain satisfactory human parsing results for all frames. More specifically, SIFT flow and super-pixel matching are used to build correspondences across different frames, and these correspondences then contextualize the pose estimation and human parsing in individual frames. Finally these parsed video frames are used as the reference corpus for the non-parametric human parsing component of the whole solution. To further improve the accuracy of video co-parsing, we propose an active learning method to incorporate human guidance, where the labelers are required to assess the accuracies of the pose estimation results of certain selected video frames. Then we take reliable frames as the seed frames to guide the video pose co-estimation. Our human parsing framework can then easily incorporate the human feedback to train a better fashion parser. Extensive experiments on two benchmark fashion datasets as well as a newly collected challenging Fashion Icon dataset well demonstrate the encouraging performance gain from our general pipeline for human parsing.","1520-9210;15209210","","10.1109/TMM.2015.2443559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120998","Information retrieval;professional communication","Estimation;Feature extraction;Learning systems;Reliability;Semantics;Supervised learning","humanities;image classification;image matching;learning (artificial intelligence);pose estimation;transforms;video signal processing","Fashion Icon dataset;SIFT flow;Web videos;active learning method;fashion parsing;human parsing;human pose co-estimation;semisupervised learning strategy;super-pixel matching;video co-parsing;video pose co-estimation","","6","","44","","20150610","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Comparative analysis of recommendation system","A. Chadha; P. Kaur","Dept. of Computer Engineering, Netaji Subhas Institute of Technology, New Delhi, India","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","313","318","During the last two decades we have witnessed the tremendous amount of growth in e-commerce industry. People all over the world buy articles just by a click of mouse. Today recommendation system is an important part of almost every website. A user might not be able to find out all the desired articles and items from the endless information pool available on the internet. Recommender system suggests those items to the user which are most suitable to the user based on his data of items purchased and his ratings collected over a period of time, which helps to predict the buying behavior of the user. In this paper we will present an overall explanation of the recommendation system and compare the features of different types of recommendation systems and try to figure out that which type of recommendation technique gives optimum results in library and information services.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048218","Artificial Intelligence;E-Commerce;Information Filtering;Information Retrieval;Library and Information Science;Machine Learning;Recommendation System","Accuracy;Collaboration;Libraries;Recommender systems;Vectors","Web sites;consumer behaviour;electronic commerce;libraries;mouse controllers (computers);recommender systems","Website;comparative analysis;e-commerce industry;information services;library;mouse;recommendation system;user buying behavior","","0","","21","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"An ontology to integrate multiple information domains in the patent system","S. Taduri; G. T. Lau; K. H. Law; H. Yu; J. P. Kesan","Engineering Informatics Group, Stanford University, Stanford, CA, USA","2011 IEEE International Symposium on Technology and Society (ISTAS)","20150716","2011","","","1","9","In recent years, there has been an explosive growth in scientific and regulatory documents related to the patent system. Relevant information is siloed into many heterogeneous information domains making it very challenging to retrieve information across multiple domains. In this paper, we develop an ontology for the patent system to integrate information from the patent and court case domains. Through a use case erythropoietin, we demonstrate how this ontology can be used to enhance information retrieval across multiple domains.","2158-3404;21583404","Electronic:978-1-4244-9149-0; POD:978-1-4244-9150-6","10.1109/ISTAS.2011.7160608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160608","Court cases;Information Retrieval;Knowledgebase;Ontology;Patent","Database languages;Databases;OWL;Ontologies;Patents;Resource description framework;Semantics","data integration;information retrieval;ontologies (artificial intelligence);patents","information domain integration;information retrieval;ontology;patent system","","1","","40","","","23-25 May 2011","","IEEE","IEEE Conference Publications"
"On Schema.org and Why It Matters for the Web","P. Mika","Yahoo Labs","IEEE Internet Computing","20150623","2015","19","4","52","55","Schema.org has addressed a critical issue for the Web - making it simple to annotate the data inside webpages at least for the most popular types of Web content. This has made it possible to deploy existing applications such as rich snippets more widely. However, schema.org still has a long way to go as new applications arise. In fact, the question often comes up whether schema.org is an end-all solution for defining terminology for the Semantic Web. At the current stage, the answer is definitely no, as much more in-depth vocabularies exist in specialized domains such as medicine. Over time, however, schema.org may provide a core linking hub for these more specialized efforts, the same way Dbpedia has become the linking hub of the Linked Data Web. The main challenge for schema.org is to be able to scale as it receives an increasing number of requests for extensions and alignment with existing efforts. Defining the right extension mechanisms and processes to support our growth is the schema.org steering group's current priority.","1089-7801;10897801","","10.1109/MIC.2015.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131410","Internet/Web technologies;data representation;information retrieval;linked data;schema.org;semantic technology","Data processing;HTML;Information retrieval;Internet;Search engines;Semantics;Vocabulary;Web search","classification;semantic Web","Schema.org;Webpages;data annotation;semantic Web","","0","","1","","","July-Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Design of personalised search system based on user interest and query structuring","S. Sethi; A. Dixit","YMCA University of science and Technology, Faridabad, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","1346","1351","The World Wide Web contains vast amount of interlinked web documents. Retrieving information from such a huge collection is easy using various search engines, but retrieving relevant information is still a challenging task. Since the traditional search engines are based upon keyword matching, therefore semantics of the query is not considered while retrieving the data from web. It is observed that relevant information can be obtained by providing the assistance to the user in constructing the appropriate queries. In this paper, Design of personalized search system is being proposed where alternate query generator is used to capture all the senses of the main query and assist the user with alternate queries, Further, Personalization based upon user profile, click history and last action performed by user is used to improve the ranking of search results. Since the proposed method incorporates the semantics of the query with user behavior, therefore retrieved results are ranked higher in the result list.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100469","Browsing history;Information;Information Retrievals;Personalisation;Quality information;Web search","Context;Cranes;Query processing;Search engines;Semantics;Web pages","Internet;behavioural sciences computing;document handling;hypermedia markup languages;information retrieval systems;query processing;search engines;user interfaces","HTML documents;World Wide Web;click history;information retrieval;interlinked Web documents;keyword matching;personalised search system design;query generator;query semantics;query structuring;search engines;search result ranking improvement;user behavior;user interest;user last action;user profile","","0","","10","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Location identification for crime & disaster events by geoparsing Twitter","N. Dhavase; A. M. Bagade","Dept. of Information Technology, Pune Institute of Computer Technology, Pune, India","International Conference for Convergence for Technology-2014","20150423","2014","","","1","3","Geoparsing means automatically identifying locations in text. The location mentions in messages during crime and disaster events are very crucial, as they can help emergency response teams to quickly identify the place to send rescue teams to the location. Use of social media during such crisis events has been rapidly increasing all over the world, as well as in India. We consider here the source of messages as Twitter because it is realtime, robust and can handle large amounts of data. We collect tweets at real time and then parse those tweets for crisis situation and location information. Extracting the location information to the level of streets & buildings will help to detect the exact location of the event; this is done with the help of NLP methods. We use classifiers to classify tweets to obtain the event occurred.","","Electronic:978-1-4799-3759-2; POD:978-1-4799-3760-8","10.1109/I2CT.2014.7092336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092336","Geoparsing;Twitter;disaster response management;event classification;geographic information retrieval","Buildings;Conferences;Data mining;Event detection;Media;Real-time systems;Twitter","disasters;grammars;natural language processing;program compilers;social networking (online)","NLP methods;Twitter;crime events;crisis situation;disaster events;emergency response teams;geoparsing;location identification;real time;rescue teams;social media","","0","","11","","","6-8 April 2014","","IEEE","IEEE Conference Publications"
"Ambient Ocean: A Web Search Engine for Context-Aware Smart Resource Discovery","D. Carlson; A. Schrader","Ambient Comput. Group Felicitous Comput. Inst., Nat. Univ. of Singapore, Singapore, Singapore","2014 IEEE International Conference on Internet of Things (iThings), and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom)","20150316","2014","","","177","184","Context-awareness is becoming an important foundation of adaptive mobile systems, however, techniques for discovering contextually relevant Web content and Smart Devices (i.e., Smart Resources) remain consigned to small-scale deployments. To address this limitation, this paper introduces Ambient Ocean, a Web search engine for context-aware Smart Resource discovery. Ocean provides scalable mechanisms for supplementing Resources with expressive contextual metadata as a means of facilitating in-situ discovery and composition. Ocean supports queries based on arbitrary contextual data, such as location, biometric details, telemetry data, situational cues, sensor information, etc. Ocean utilizes a combination of crowd-sourcing, context-enhanced query expansion and personalization techniques to continually optimize query results over time. This paper presents Ocean's conceptual foundations, its reference implementation, and a preliminary evaluation that demonstrates significantly improved Smart Resource discovery results in real-world environments.","","Electronic:978-1-4799-5967-9; POD:978-1-4799-5968-6","10.1109/iThings.2014.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7059659","Collaboration;Context-aware services;Information retrieval;Ubiquitous computing;Web search","Computer architecture;Context;Context modeling;Engines;Oceans;Semantics;Service-oriented architecture","mobile computing;search engines","Ambient Ocean;Web search engine;adaptive mobile system;context-aware smart resource discovery;context-enhanced query expansion;contextual metadata;crowd-sourcing;personalization technique;smart device","","0","","35","","","1-3 Sept. 2014","","IEEE","IEEE Conference Publications"
"Multi2Rank: Multimedia Multiview Ranking","D. Etter; C. Domeniconi","","2015 IEEE International Conference on Multimedia Big Data","20150713","2015","","","80","87","Multimedia retrieval is a search and ranking task defined over multiple modalities. These modalities include speech, image, and text, which provide different views of the multimedia object. Queries to a multimedia retrieval system often take the form of a text only query and return a ranked result set which combines these multiple views. The text only query includes multiple phrases which identify features of a specific view. This multiview problem presents a challenge in mapping these phrases into the correct view feature space. A second challenge for the multimedia retrieval system is in building a ranking model which considers the unique feature space of each view. In this paper, we propose a hierarchical multimedia multiview rank learning model, called Multi<sup>2</sup>Rank, to overcome the challenges of this unique ranking problem. The first layer of our model uses natural language processing techniques to identify view specific phrases and output a ranked mapping of the phrases into their respective views. Next, we model the individual feature space for each multimedia view and create a view specific model using gradient boosted regression trees. The ranked set from each unique view is then passed to the final layer of the hierarchy, where the model generates a final ranked result set. We show that our multiview rank learning approach is effective by evaluating the methods using a large Internet video repository, queries, and ground truth, from the TRECVid evaluations.","","CD-ROM:978-1-4799-8687-3; Electronic:978-1-4799-8688-0; POD:978-1-4799-8689-7","10.1109/BigMM.2015.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153859","Information Search and Retrieval;Retrieval models;Search process","Electronic mail;Information retrieval;Multimedia communication;Regression tree analysis;Speech;Streaming media;Visualization","learning (artificial intelligence);multimedia computing;natural language processing;query processing","Multi<sup>2</sup>Rank;TRECVid evaluations;feature space;hierarchical multimedia multiview rank learning model;large Internet video repository;multimedia multiview ranking;multimedia object;multimedia retrieval;natural language processing techniques;text only query","","0","","37","","","20-22 April 2015","","IEEE","IEEE Conference Publications"
"Text mining and information professionals: Role, issues and challenges","V. K. Verma; M. Ranjan; P. Mishra","Indian Institute of Technology Hauz Khas, New Delhi 110016","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","133","137","Information explosion and availability of information in various forms has changed the shape of information centres and nature of information profession and professionals. Information profession and professionals have been impacted by the exponentially increasing volumes of information available - as well as with changing attitudes and behaviour of information seeker toward electronic resources. It is very difficult to find the required pieces of information in the bundled of scattered information. The task becomes more challenging, when we find that over 90% of the information available is in unstructured and semi-structured forms, which is very difficult to search. Here text mining has come as a tool to help Information professionals to find the relevant information and deliver to its users. Text mining is used as a technology for analyzing large volumes of structured/unstructured textual documents. Text mining has very high knowledge and commercial values. The aim of Text mining is generally to strengthen decision making and internal operations processes of any organisation and generation of new domain of knowledge. These technologies help to increase the utilization of Knowledge Management (KM) systems and pro-actively help information professionals to improve their competencies and thus productivity of the organization. This article discusses the basic concept of text mining, its framework and text mining products and tools. It also discusses the benefits and challenges of text mining and examines the role of Information Professionals in Text Mining.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048186","Big data;Data mining;Information retrieval;Knowledge discovery;Text mining;Unstructured data","Databases;Information retrieval;Knowledge discovery;Libraries;Text mining","data mining;knowledge management;text analysis","KM systems;commercial values;decision making;domain knowledge;electronic resources;information availability;information centres;information explosion;information professionals;information seeker attitudes;information seeker behaviour;internal operations processes;knowledge management systems;knowledge values;organisation;productivity;text mining;unstructured textual documents","","0","","9","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Downbeat tracking with multiple features and deep neural networks","S. Durand; J. P. Bello; B. David; G. Richard","Institut Mines-Telecom, Telecom ParisTech, CNRS-LTCI, 37/39, rue Dareau, 75014 - France","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","409","413","In this paper, we introduce a novel method for the automatic estimation of downbeat positions from music signals. Our system relies on the computation of musically inspired features capturing important aspects of music such as timbre, harmony, rhythmic patterns, or local similarities in both timbre and harmony. It then uses several independent deep neural networks to learn higher-level representations. The downbeat sequences are finally obtained thanks to a temporal decoding step based on the Viterbi algorithm. The comparative evaluation conducted on varied datasets demonstrates the efficiency and robustness across different music styles of our approach.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178001","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178001","Deep Networks;Downbeat Tracking;Music Information Retrieval;Music Signal Processing","Estimation;Feature extraction;Multiple signal classification;Robustness;Timbre;Viterbi algorithm","Viterbi decoding;acoustic signal processing;music;neural nets","Viterbi algorithm;automatic estimation;deep neural networks;downbeat positions;downbeat sequences;downbeat tracking;music signals;music styles;rhythmic patterns;temporal decoding step","","3","","33","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Search Engine Results Improvement -- A Review","H. Agrawal; S. Yadav","Dept. of Comput. Sci. & Eng., Ajay Kumar Garg Eng. Coll., Ghaziabad, India","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","180","185","Search engines return SERP which contains results to the user query which may be relevant or irrelevant. Some of the results which are not relevant are the matter of great dissatisfaction to the user who queried the Web to look forward for the desired answer. As the WWW is the huge repository of information so there is a necessity of an intuitive approach that can navigate, filter, summarize and manage such a large collection of data. Hence, diverse approaches have been used to optimize search engine results according to users' need. Our objective is to present different approaches used by various researchers to optimize results which are helpful in maximizing the user satisfaction.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078691","Document Clustering;Information Retrieval;Search Engine;Semantic;Web","Clustering algorithms;Engines;Google;History;Search engines;Semantics;Vectors","Internet;query processing;search engines","SERP;WWW;Web;search engine results improvement;user need;user query;user satisfaction","","0","","28","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"Noise Reduction of Web Pages via Feature Analysis","K. Jiang; Y. Yang","Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2015 2nd International Conference on Information Science and Control Engineering","20150611","2015","","","345","348","Noise information has a serious impact on various studies that using web pages as datasets. As a fundamental work in information retrieval, removing noise in web pages quickly and accurately received widely attention. In this paper, a noise reduction algorithm which uses DOM (Document Object Model) to preserve the original structure of web pages is proposed to the issue of low efficiency of traditional noise reduction algorithms. Using this method, noise information can be located rapidly by a combination of several analyzed features, e.g. Link Density and Punctuation Density. The approach is evaluated by a group of web pages that selected randomly from several well-known websites. Experiments show satisfactory results.","","Electronic:978-1-4673-6850-6; POD:978-1-4673-6851-3","10.1109/ICISCE.2015.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120623","DOM Tree;Feature Analysis;Information Retrieval;Noise Reduction","Accuracy;Algorithm design and analysis;HTML;Noise;Noise reduction;Web pages","Internet;information filtering","DOM;Web pages;Web sites;document object model;information retrieval;link density;noise information;noise reduction algorithm;punctuation density","","0","","14","","","24-26 April 2015","","IEEE","IEEE Conference Publications"
"Big Data Driven Cyber Analytic System","V. Hahanov; W. Gharibi; E. Litvinova; S. Chumachenko","Comput. Eng. Fac., Nat. Univ. of Radioelectron., Kharkov, Ukraine","2015 IEEE International Congress on Big Data","20150820","2015","","","615","622","An infrastructure for parallel analyzing big data in order to search, pattern recognition and decision-making based on the use of the Boolean metric of cyberspace measurement is proposed. It is characterized by using only logical xor-operation for determining the cyber-distance by means of cyclic closing at least one object, which allows significantly increasing the speed of analysis of large data. A new approach to vector-logical big data processing based on the total removal of arithmetic operations, which impact on the performance and hardware complexity, is offered, the approach can be efficiently implemented based on modern multiprocessor digital systems-on-chips and virtual parallel processors, operating under the control of cyber-physical systems or cloud service-filters. A qubit-vector model of computing automaton is proposed, it is characterized by the transactional interaction of memory components, which represent the combinational and sequential elements and are implemented in the form of a qubit or ""quantum"" primitives needed to create parallel virtual computers and cloud-focused processors. A new structural model for analyzing big data is developed, it is characterized by the use of cloud services, cyber-physical and search systems, virtual parallel multiprocessors with a minimal set of vector-logical operations for accurate information retrieval based on the proposed Boolean metric and non-numerical quality criteria, which makes it possible to create a semantic infrastructure of cyberspace by the competence classification and metric ordering big data across the cyber-ecosystem of the planet.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207278","big data;cyber metric for information retrieval;cyber-physical system;cyberspace analytics","Big data;Computers;Cyberspace;Measurement;Planets;Process control","Big Data;decision making;information retrieval;pattern classification;system-on-chip","Boolean metric;arithmetic operation removal;big data driven cyber analytic system;cloud service-filters;cloud-focused processors;combinational element;competence classification;computing automaton;cyber-ecosystem;cyber-physical systems;cyberspace measurement;decision-making;information retrieval;logical xor-operation;memory components;multiprocessor digital systems-on-chips;nonnumerical quality criteria;parallel virtual computers;pattern recognition;quantum primitives;qubit primitives;qubit-vector model;semantic infrastructure;sequential element;structural model;transactional interaction;vector-logical big data processing;vector-logical operations;virtual parallel multiprocessors;virtual parallel processors","","7","","20","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Inferring similarity between time-series microarrays: A content-based approach","D. D. Şener; H. Oğul","Computer Engineering, Ba&#x015F;kent University, Ankara, Turkey","2015 IEEE 2nd International Conference on Cybernetics (CYBCONF)","20150806","2015","","","201","205","Public repositories for gene expression studies have been growing rapidly in the last decade. Retrieval of gene expression experiments based on textual descriptions does not provide sufficient data for biologists and clinicians. Content-based search has recently become more desirable in retrieving similar experiments. Current methods for content-based retrieval cannot address the problem of profiling the gene behaviors in multiple measurement points, i.e. in time course. This study, to the best of our knowledge, is the first attempt to build a fingerprint for each gene by considering all time points to infer its time-course profile to represent the experiment content in an information retrieval framework. An empirical study is performed on a large dataset of Arabidopsis microarrays from Gene Expression Omnibus (GEO). Experimental results show that relevant experiments are retrieved based on content similarity.","","Electronic:978-1-4799-8322-3; POD:978-1-4799-8323-0","10.1109/CYBConf.2015.7175932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175932","Gene expression database;information retrieval;time-course data;time-series data;time-series profile","Bioinformatics;Databases;Fingerprint recognition;Gene expression;Genomics;Time series analysis","biology computing;content-based retrieval;genetics;time series","Arabidopsis microarrays;GEO;content similarity;content-based approach;content-based retrieval;content-based search;gene behaviors;gene expression experiments retrieval;gene expression omnibus;gene fingerprint;information retrieval framework;public repositories;textual descriptions;time points;time-course profile;time-series microarrays","","0","","16","","","24-26 June 2015","","IEEE","IEEE Conference Publications"
"Automatic tonic identification method for Turkish makam music","H. S. Atlı; B. Bozkurt","Ses Teknolojileri Bolumu, Bahcesehir Univ., Istanbul, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1570","1573","Tonic is a fundamental concept in makam. As in many world music cultures, tonic frequency varies among performances. Because of this, correct estimation of tonic frequency is important for other computational research problems like tuning analysis, audio-score alignment, automatic transcription etc. In this work, we present a new methodology for automatic tonic estimation of Turkish makam music recordings. New methodology bases on the frequency estimation of the last note in a performance.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130148","Turkish makam music;audio signal processing;music information retrieval;tonic","Estimation;Frequency estimation;Histograms;Multiple signal classification;Music information retrieval;Tuning","audio signal processing;music","Turkish makam music recording;audio-score alignment;automatic tonic identification method;automatic transcription;computational research problem;music cultures;tonic frequency estimation;tuning analysis","","0","","","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Probabilistic text analytics framework for information technology service desk tickets","E. E. Jan; K. Y. Chen; T. Idé","IBM T.J. Watson Research Center","2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)","20150702","2015","","","870","873","Ticket annotation and search has become an essential research subject for the successful delivery of IT operational analytics. Millions of tickets are created yearly to address business users' IT related problems. In IT service desk management, it is critical to first capture the pain points for a group of tickets to determine root cause; secondly, to obtain the respective distributions in order to layout the priority of addressing these pain points. An advanced ticket analytics system utilizes a combination of topic modeling, clustering and Information Retrieval (IR) technologies to address the above issues and the corresponding architecture which integrates of these features will allow for a wider distribution of this technology and progress to a significant financial benefit for the system owner. Topic modeling has been used to extract topics from given documents; in general, each topic is represented by a unigram language model. However, it is not clear how to interpret the results in an easily readable/understandable way until now. Due to the inefficiency to render top concepts using existing techniques, in this paper, we propose a probabilistic framework, which consists of language modeling (especially the topic models), Part-Of-Speech (POS) tags, query expansion, retrieval modeling and so on for the practical challenge. The rigorously empirical experiments demonstrate the consistent and utility performance of the proposed method on real datasets.","1573-0077;15730077","Electronic:978-1-4799-8241-7; POD:978-1-4799-8242-4","10.1109/INM.2015.7140397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140397","Analytics;IT operations;IT service;ITIL;Ticket;information retrieval;topic modeling","Business;Indexes;Information retrieval;Mobile communication;Pain;Probabilistic logic;Semantics","information services;pattern clustering;probability;query processing;technical support services;text analysis","IR technologies;IT operational analytics;IT related problems;IT service desk management;POS tags;business user;clustering;information retrieval;information technology service desk tickets;part-of-speech tags;probabilistic text analytics framework;query expansion;retrieval modeling;ticket analytics system;ticket annotation;ticket search;topic modeling;topics extraction;unigram language modeling","","1","","14","","","11-15 May 2015","","IEEE","IEEE Conference Publications"
"Audio segmentation using a priori information in the context of Karnatic Music","V. A. Kalyan; S. Sankaranarayanan; S. S. David","Music and Audio Research Group, Department of Electronics and Communication Engineering, National Institute of Technology Karnataka, Surathkal, India","2015 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES)","20150423","2015","","","1","5","Karnatic Music (KM) is distinct because of the prevalence of gamaka - embellishments to musical notes in the form of frequency traversals. Another important aspect of KM is that the performance style is mostly extempore. Hence, Music Information Retrieval (MIR) tasks in the context of KM are highly challenging. This paper deals with the task of Audio Segmentation and its application to MIR challenges of KM at various levels. This work presents a method that incorporates a priori knowledge about the music system and the audio track at hand for segmenting the audio into its constituent notes. The method uses amplitude and energy based features to train a neural network and an accuracy of 95.2% has been achieved on KM audio samples. The paper also elucidates the application of the method to important MIR tasks such as Music Transcription and Score-Alignment in the context of KM.","","DVD:978-1-4799-1821-8; Electronic:978-1-4799-1823-2; POD:978-1-4799-1824-9","10.1109/SPICES.2015.7091550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091550","Audio Segmentation;Karnatic Music;Music Information Retrieval;Onset Detection","Accuracy;Context;Feature extraction;Libraries;Rhythm;Wavelet transforms","information retrieval;music","KM audio samples;Karnatic music;MIR;audio segmentation;audio track;constituent notes;frequency traversals;gamaka-embellishments;music information retrieval tasks;music transcription;musical notes;neural network;score-alignment","","1","","8","","","19-21 Feb. 2015","","IEEE","IEEE Conference Publications"
"A Conditional Random Field system for beat tracking","T. Fillon; C. Joder; S. Durand; S. Essid","Parisson, 16 rue Jacques Louvel-Tessier, 75010 Paris, France","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","424","428","In the present work, we introduce a new probabilistic model for the task of estimating beat positions in a musical audio recording, instantiating the Conditional Random Field (CRF) framework. Our approach takes its strength from a sophisticated temporal modeling of the audio observations, accounting for local tempo variations which are readily represented in the CRF model proposed using well-chosen potentials. The system is experimentally evaluated by studying its performance on 3 datasets of 1394 music excerpts of various western music styles and comparatively to 4 reference systems in the light of 6 reference evaluation metrics. The results show that the proposed system tracks perceptively coherent pulses and is very effective in estimating the beat positions while further work is needed to find the correct salient tempo.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178004","Beat tracking;Conditional Random Fields;Music Information Retrieval","Estimation;Feature extraction;Hidden Markov models;Labeling;Mathematical model;Probabilistic logic;Speech","audio recording;information retrieval;music;probability","beat positions;beat tracking;conditional random field system;local tempo variations;musical audio recording;probabilistic model;sophisticated temporal modeling","","1","","25","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"A fast audio search method based on skipping irrelevant signals by similarity upper-bound calculation","H. Nagano; R. Mukai; T. Kurozumi; K. Kashino","NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, 3-1, Morinosato-Wakamiya, Atsugi-shi, 243-0198, Japan","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","2324","2328","In this paper, we describe an approach to accelerate fingerprint techniques by skipping the search for irrelevant sections of the signal and demonstrate its application to the divide and locate (DAL) audio fingerprint method. The search result for the applied method, DAL3, is the same as that of DAL mathematically. Experimental results show that DAL3 can reduce the computational cost of DAL to approximately 25% for the task of music signal retrieval.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178386","Audio fingerprint;audio search;information retrieval","Acceleration;Accuracy;Computational efficiency;Databases;Fingerprint recognition;Histograms;Multiple signal classification","acoustic signal processing;audio signal processing;fingerprint identification;musical acoustics","DAL audio fingerprint method;divide-and-locate audio fingerprint method;fast audio search method;finger print technology;music signal retrieval;similarity upper-bound calculation;skipping irrelevant signals","","0","","15","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Modeling the Affective Content of Music with a Gaussian Mixture Model","J. C. Wang; Y. H. Yang; H. M. Wang; S. K. Jeng","Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Affective Computing","20150225","2015","6","1","56","68","Modeling the association between music and emotion has been considered important for music information retrieval and affective human computer interaction. This paper presents a novel generative model called acoustic emotion Gaussians (AEG) for computational modeling of emotion. Instead of assigning a music excerpt with a deterministic (hard) emotion label, AEG treats the affective content of music as a (soft) probability distribution in the valence-arousal space and parameterizes it with a Gaussian mixture model (GMM). In this way, the subjective nature of emotion perception is explicitly modeled. Specifically, AEG employs two GMMs to characterize the audio and emotion data. The fitting algorithm of the GMM parameters makes the model learning process transparent and interpretable. Based on AEG, a probabilistic graphical structure for predicting the emotion distribution from music audio data is also developed. A comprehensive performance study over two emotion-labeled datasets demonstrates that AEG offers new insights into the relationship between music and emotion (e.g., to assess the “affective diversity” of a corpus) and represents an effective means of emotion modeling. Readers can easily implement AEG via the publicly available codes. As the AEG model is generic, it holds the promise of analyzing any signal that carries affective or other highly subjective information.","1949-3045;19493045","","10.1109/TAFFC.2015.2397457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7029060","Gaussian mixture model;Music information retrieval;arousal;music emotion recognition;subjectivity;valence","Adaptation models;Computational modeling;Data models;Music;Predictive models;Probabilistic logic","Gaussian processes;acoustic signal processing;audio signal processing;emotion recognition;human computer interaction;information retrieval;learning (artificial intelligence);mixture models;music;probability","AEG;Gaussian mixture model;acoustic emotion Gaussians;affective diversity assessment;affective human computer interaction;audio data characterization;emotion computational modeling;emotion data characterization;emotion distribution prediction;emotion perception;emotion-labeled datasets;fitting algorithm;generative model;model learning process;music affective content modeling;music information retrieval;probabilistic graphical structure;probability distribution;valence-arousal space","","3","","91","","20150202","Jan.-March 1 2015","","IEEE","IEEE Journals & Magazines"
"Valuing Semantic Relatedness","A. Boubacar","School of Computer Science, Beijing Institute of Technology 100081, Beijing China","2014 IEEE 7th Joint International Information Technology and Artificial Intelligence Conference","20150323","2014","","","1","5","Semantic Relatedness is widely used in various domains such as DNA sequence analysis, knowledge representation, natural language processing, data mining, information retrieval, information flow etc... Computing semantic similarity between two entities is a non-trivial task. There are many ways to define semantic similarity. Some measures have been proposed combining both statistical information and lexical similarity. It is difficult for a measure that performs well in a given domain to be applied with accuracy in another domain. A similarity measure may perform better with one language than another. Word is supposed to be not only similar to itself but also to some of its synonyms in a given context, and some words with common roots. Our approach is designed to perform query matching and compute semantic relatedness using word occurrences. It performs better than classical measures like TF-IDF, Cosine etc... Although it is not a metric, the proposed similarity measure can be used for a wide range of content analysis tasks based on semantic distance and its efficacy has been demonstrated. The measure is not corpus dependent so it can establish directly the se-mantic relatedness of two entities.","","CD-ROM:978-1-4799-4421-7; Electronic:978-1-4799-4419-4; POD:978-1-4799-4418-7","10.1109/ITAIC.2014.7064994","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064994","Information Retrieval;Semantic Relatedness;Semantic Similarity","Atmospheric measurements;Biomedical measurement;Frequency measurement;Information retrieval;Particle measurements;Semantics;Vectors","pattern matching;query processing;statistical analysis;text analysis","content analysis tasks;lexical similarity;query matching;semantic distance;semantic relatedness;semantic similarity;similarity measure;statistical information;synonyms;word occurrences","","0","","29","","","20-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"A histogram density modeling approach to music emotion recognition","J. C. Wang; H. M. Wang; G. Lanckriet","Department of Electrical and Computer Engineering, UC San Diego, United States","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","698","702","Music emotion recognition is concerned with developing predictive models that comprehend the affective content of musical signals. Recently, a growing number of attempts has been made to model the music emotion as a probability distribution in the valence-arousal (VA) space to better account for the subjectivity. In this paper, we present a novel histogram density modeling approach that models the emotion distribution by a 2-D histogram over the quantized VA space and learns a set of latent histograms to predict the emotion probability density of a song from audio. The proposed model is free from parametric distribution assumptions over the VA space, easy to implement, and extremely fast to train. We also extend our model to deal with the temporal dynamics of time-varying emotion labels. Comprehensive performance study on two larger-scale datasets demonstrates that our approach achieves comparable performance to the state-of-the-art ones, but with much better training and testing efficiency.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178059","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178059","Affective computing;emotion tracking;music information retrieval;subjectivity;temporal dynamics","Histograms;Unified modeling language","acoustic signal processing;emotion recognition;music;statistical distributions","2D histogram;VA space;emotion distribution;emotion probability density prediction;histogram density modeling approach;music emotion recognition;probability distribution;time varying emotion label temporal dynamics;valence-arousal space","","2","","32","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Personalized web search engine using dynamic user profile and clustering techniques","A. Kumar; M. Ashraf","Department of Computer Science & Engineering, Gautam Buddha University, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","2105","2108","Internet is large interconnection of small networks that is commonly known as World Wide Web. The amount of informations available on internet in digital form are very huge and growing at exponential rate following Moore's law. So, it's makes difficult to find exact search result according to user preferences. In this paper, we proposed a method for personalized web search. Personalized web search is any action taken to optimize the search result according to user's individual preferences. Different information retrieval techniques have been widely used to reduce access latency problem of the internet. This paper comprised and focuses different techniques for efficient personalized web search and also suggest the techniques for personalized web search according to the merits and demerits of various available techniques.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100610","Clustering;Collaborative filtering;Information Retrieval;Personalized web search;Search engine","Computers;Filtering;History;Internet;Search engines;Web search","Internet;information retrieval;pattern clustering;search engines","Internet;Moore law;World Wide Web;access latency problem;clustering techniques;dynamic user profile;exact search result;exponential rate;personalized Web search engine","","0","","10","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient technique for personalized web search using users browsing history","A. Kumar; M. Ashraf","Department of CS&E, Gautam Buddha University, Uttar Pradesh, India","International Conference on Computing, Communication & Automation","20150706","2015","","","919","923","In today's world, every information available on World Wide Web present in digital form. Different Information retrieval (IR) technique are used for retrieving required information on huge heaps of information but there is great difficulty in retrieving relevant information according to user preferences in return of simple short query with generic web search. So, we need to enhance the power of web search to retrieve relevant information. This paper is an attempt to improve the search efficiency of web search. In this paper, we proposed a framework for personalized web search which uses a dynamic user profile to automatically update user profile and collaborative filtering for considering recommendation which helps to retrieve search result and relevant document to user according to its need and preferences by diagnosing its web search behavior according to previous search history. The Experimental result shows the proposed method of personalized web search is more efficient over generic search engine.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148507","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148507","Apache Nutch;Dynamic user profile;Information Retrieval;Personalized web search;Search history","Algorithm design and analysis;History;Indexes;Search engines;Web pages;Web search","Internet;collaborative filtering;information retrieval;recommender systems;search engines","IR technique;Web search;World Wide Web;collaborative filtering;dynamic user profile;information retrieval;recommendation system;user browsing history","","0","","10","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"A Preliminary Approach to Domain-Based Evaluation of Users' Trustworthiness in Online Social Networks","B. Abu-Salih; P. Wongthongtham; S. M. R. Beheshti; D. Zhu","Sch. of Inf. Syst., Curtin Univ., Perth, WA, Australia","2015 IEEE International Congress on Big Data","20150820","2015","","","460","466","Online Social Networks (OSNs) are a fertile medium through which users can unleash their opinions and share their thoughts, activities and knowledge of various topics and domains. This medium allows legitimate users as well as spammers to publish their content, leveraging the open environment and fewer restrictions associated with OSNs. Hence, it is essential to evaluate users' credibility in various domains and accordingly make judgements about potentially influential users in a particular domain(s). Most of the existing trustworthiness evaluation approaches of users and their posts in OSNs are generic-based approaches. There is a lack of domain-based trustworthiness evaluation mechanisms. In OSNs, discovering users' influence in a specific domain has been motivated by its significance in a broad range of applications such as personalized recommendation systems and expertise retrieval. The aim of this paper is to present a preliminary approach to evaluating domain-based user's trustworthiness in OSNs. We provide a novel distinguishing measurement for users in a set of knowledge domains. Domains are extracted from the user's content using semantic analysis. In order to obtain the level of trustworthiness, a metric incorporating a number of attributes extracted from content analysis and user analysis is consolidated and formulated considering temporal factor. The approach presented in this paper is promising since it provides a fine-grained trustworthiness analysis of users and their domains of interest in the OSNs.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207258","Domain-Based Trust;Information Retrieval;Online Social Networks;Semantic Analysis","Art;Frequency-domain analysis;Media;Semantics;Taxonomy;Twitter","social networking (online);trusted computing","OSN;content analysis;domain-based user trustworthiness evaluation mechanisms;expertise retrieval;generic-based approaches;knowledge domains;legitimate users;online social networks;personalized recommendation systems;semantic analysis;spammers;temporal factor;trustworthiness analysis;trustworthiness level;user analysis;users credibility evaluation;users influence;users trustworthiness","","0","","43","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Indexing and retrieval of human motion data based on a growing self-organizing map","Da-Cheng Yu; W. G. Teng","Department of Engineering Science, National Cheng Kung University, Tainan, Taiwan","2014 International Conference on Data Science and Advanced Analytics (DSAA)","20150312","2014","","","66","71","As low-cost depth cameras are released recently, motion data containing 3D coordinates of skeleton joints during a time period can be directly captured. Nevertheless, analyzing the motion data is usually a challenging problem and requires huge computation costs because of the high-dimensionality. Among several alternatives, the self-organizing map (SOM) is verified to be an effective technique to handle such motion data. Specifically, a captured motion sequence can be easily and precisely mapped to form an indexed motion string through the use of a trained SOM. However, the training process of the SOM is high computation complexity and is thus typically tedious. In view of this, we propose in this work to incorporate a hierarchical structure into the SOM technique. Generally speaking, our approach named as GQSOM (growing quadtree self-organizing map) helps to significantly reduce the required computation complexity while preserving the effectiveness of the SOM technique. Empirical studies using the WorkSU-10 exercise dataset show that our approach is both efficient and effective to perform indexing and retrieval tasks of motion data.","","Electronic:978-1-4799-6991-3; POD:978-1-4799-6982-1","10.1109/DSAA.2014.7058053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058053","growing quadtree;information retrieval;motion data;self-organizing map","Indexing;Joints;Neurons;Training;Vectors","computational complexity;image motion analysis;image retrieval;image sequences;indexing;self-organising feature maps","GQSOM;WorkSU-10 exercise dataset;captured motion sequence;computation complexity;depth cameras;growing quadtree self-organizing map;growing self-organizing map;hierarchical structure;human motion data indexing;human motion data retrieval;skeleton joints;training process","","0","","17","","","Oct. 30 2014-Nov. 1 2014","","IEEE","IEEE Conference Publications"
"EM-based phoneme confusion matrix generation for low-resource spoken term detection","D. Xu; Y. Wang; F. Metze","Language Technologies Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","424","429","The idea of using a data-driven phoneme confusion matrix (PCM) to enhance speech recognition and retrieval performance is not new to the speech community. Although empirical results show various degrees of improvements brought by introducing a PCM, the underlying data-driven processes introduced in most papers are rather ad-hoc and lack rigorous statistical justifications. In this paper we will focus on the statistical aspects of PCM generation, propose and justify a novel expectation-maximization based algorithm for data-driven PCM generation. We will evaluate the performance of the generated PCMs under the context of low-resource spoken term detection, with primary focus on out-of-vocabulary keywords.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078612","Expectation-maximization algorithm;information retrieval;machine learning;out-of-vocabulary words;spoken term detection","Estimation;Optimization;Phase change materials;Probabilistic logic;Speech;Speech recognition;Viterbi algorithm","expectation-maximisation algorithm;information retrieval;matrix algebra;speech recognition;statistical analysis","EM-based phoneme confusion matrix generation;data-driven PCM generation;data-driven phoneme confusion matrix;data-driven processes;expectation-maximization based algorithm;low-resource spoken term detection;out-of-vocabulary keywords;speech community;speech recognition;speech retrieval performance;statistical aspects","","0","","22","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"Arabic stemming techniques: Comparisons and new vision","A. Al-Zyoud; W. A. Al-Rabayah","Dept. of Comput. Inf. Syst., Yarmouk Univ., Irbid, Jordan","2015 IEEE 8th GCC Conference & Exhibition","20150316","2015","","","1","6","Arabic information extraction processes have become a popular area of research. Many methods and approaches have designed and introduced algorithms to solve the problem of morphology and stemming of Arabic language. Each researcher proposed his own standards, testing methodology and accuracy measurements to test his algorithm. Therefore, we cannot make an exact comparison between these algorithms. However, this research goes over stemming processes by explaining and discussing Arabic language characteristics and difficulties of stemming it, comparing root-based stemming, suffix and prefix - based stemming, and translation base stemming against each other, representing a modified stemming algorithm which helps go over some missing words in other algorithms. And finally, representing a new vision of Arabic stemming techniques.","","Electronic:978-1-4799-8422-0; POD:978-1-4799-8423-7; USB:978-1-4799-8421-3","10.1109/IEEEGCC.2015.7060020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060020","Arabic language;algorithms;approaches comparisons;information retrieval;stemming","Algorithm design and analysis;Classification algorithms;Conferences;Dictionaries;Morphology;Standards","information retrieval;natural language processing","Arabic information extraction processes;Arabic language characteristics;Arabic language stemming techniques;prefix-based stemming;root-based stemming;suffix-based stemming","","1","","17","","","1-4 Feb. 2015","","IEEE","IEEE Conference Publications"
"A new sustainable prototype USP for education information system","S. Kumar; Shobha; S. K. Pal","Dept. of Comput. Sci., Delhi Univ., Delhi, India","2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE)","20150713","2015","","","174","179","Education Institutions, Recruitment Organizations, Government Authorities and Students are main stockholders in Education System. Education system relies upona lot of paper-work which is cheap but on environment it has negative consequences. Process of planning and execution of government schemes is inefficient, very slow which lacks even feedback mechanism. Stakeholders are required to do lot of paper-work for maintaining information, changing and transferring that information, forgery of information and storage of that crucial information and error detection and recovery from damage if takes place. For getting scholarships, recruitments, admissions related activities, recruitment in government services are not streamlined and needs same information of students which should be shared with efficiently using some technological advancements. Present day systems are based on paper based information flow which faces problems of delay of information processing, Information Retrieval, Delay in Response, Inefficiency and under effective performance of the system. Presently in most of the countries especially in developing countries all the stack holders of the system are not integrated and does not share same platform for information sharing and response which prevents. This makes the communication and information flow slow and non-coordinated which reduces the efficiency and effectiveness of the education systems. In this paper we are proposing a new framework in the form of information system for inclusion of each stakeholder in the system so that problems could be overcome and stack holder with the help of information and communication technology utilise the full potential and effective delivery products and services of the Education system to everyone including students and government. In this paper we propose the framework with complete information of development process following software engineering concepts to solve most of the problems of present day education sy- tem.","","CD-ROM:978-1-4799-8432-9; Electronic:978-1-4799-8433-6; POD:978-1-4799-8434-3","10.1109/ABLAZE.2015.7154988","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7154988","Education Institution;Environment Friendly;Inefficiency;Paper;Prototype and Information Processing and Retrieval;Recruitment;Student;USP","Complexity theory;Education;Government;Industries;Market research;Prototypes;Recruitment","educational computing;educational institutions;information retrieval","USP;education information system;education institutions;feedback mechanism;government authorities;government schemes;government services;information processing;information retrieval;information sharing;paper based information flow;recruitment organizations;scholarships;software engineering concepts;technological advancements;universal student profile","","0","","8","","","25-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Cognitive Computing, Analytics, and Personalization","S. Earley","Earley Information Science","IT Professional","20150716","2015","17","4","12","18","This article discusses the increasing sophistication of search technology and its role in cognitive computing. It provides a concrete example of a personal assistant that is context-aware and can retrieve the information most likely to solve users' problems. It also addresses how search engines predict what information users are likely to need, and how the software retrieves and presents the information. Finally, the article discusses personalization and how machine learning can contribute to this process<i>.</i>","1520-9202;15209202","","10.1109/MITP.2015.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160901","artificial intelligence;cognitive computing;data analysis;information retrieval;search","Cognition;Context modeling;Information retrieval;Machine learning algorithms;Ontologies;Search methods;Semantics","information retrieval;learning (artificial intelligence);search engines","cognitive computing;context-aware personal attendant;information retrieval;machine learning;search engines;search technology","","0","","8","","","July-Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Enabling generic keyword search over raw XML data","M. K. Agarwal; K. Ramamritham","Department of computer Science and Engineering, IIT-Bombay, India","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1496","1499","Classical XML keyword search based on the Lowest Common Ancestor (LCA) framework requires users to be well versed with data and semantic relationships between the query keywords to extract meaningful response, restricting its applicability. GKS (Generic Keyword Search), on the other hand, allows users to browse and navigate XML data without such constraints. GKS enables discovery of deeper insights (DI) in the XML data, found in the context of the search results. Such insights not only expose patterns hidden in the search results but also help users tune their queries, thus enabling the navigation of complex XML repositories with ease. We further show how, for a search query, different insights can be discovered from the data by varying a single parameter.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113410","Analytics;Information Retrieval;XML","Engines;Indexes;Keyword search;Navigation;Semantics;XML","XML;query processing","GKS;XML data;XML keyword search;complex XML repositories;deeper insights;generic keyword search;lowest common ancestor;search query","","1","","12","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Rank aggregation using active learning in meta-searching","B. Boushih; N. Ben Amor","LARODEC, Institut Sup&#x00E9;rieur de Gestion Tunis, Universit&#x00E9; de Tunis, 41, Avenue de la Libert&#x00E9;, Cit&#x00E9; Bouchoucha, 2000 Le Bardo, Tunisie","2014 Second World Conference on Complex Systems (WCCS)","20150316","2014","","","43","48","Existing methods dealing with the problem of rank aggregation in the context of meta-search in information retrieval are considered as a passive learner machine and suffer in the presence of unreliable ranking lists. This paper proposes a novel approach which selects the most informative features and instances to be labeled from which the model will learn. To train an efficient ranking aggregation model from few labeled instances, we use Multiple Hyperplane Ranker algorithm in an active learning environment. Experimental results on the OHSUMED dataset show that our method outperforms the existing methods.","","CD-ROM:978-1-4799-4648-8; Electronic:978-1-4799-4647-1; POD:978-1-4799-4646-4","10.1109/ICoCS.2014.7060911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060911","Active learning;Feature selection;Information retrieval;Meta-Search;Rank aggregation;Semi-supervised learning","Computational modeling;Information retrieval","information retrieval;learning (artificial intelligence)","OHSUMED dataset;active learning;meta-search context;multiple hyperplane ranker algorithm;passive learner machine;rank aggregation model","","0","","17","","","10-12 Nov. 2014","","IEEE","IEEE Conference Publications"
"Towards a new approach for generating user profile from folksonomies","B. Tahar-Rafik; A. O. Rachid","LARI laboratory Department of computer science, Mouloud Mammeri university 15000, Tizi-Ouzou, Algeria","2014 4th International Symposium ISKO-Maghreb: Concepts and Tools for knowledge Management (ISKO-Maghreb)","20150209","2014","","","1","6","The exploitation of social networks and collaborative systems is a phenomenon that is gradually integrated with the practice of information retrieval on the Internet. These systems of Web 2.0, allowing users to collaborate via the free content indexing using keywords or tags; creating structures represented as tripartite hypergraphs of users, tags and resources, called folksonomies. By examining different personalization techniques based on folksonomies, we focused on the community aspect of collaborative systems. We propose to build, through different techniques of social network analysis, user profiles more representative of their various interets. A new approach for generating user profile from foklsonomies is presented.","","Electronic:978-1-4799-7508-2; POD:978-1-4799-7509-9","10.1109/ISKO-Maghreb.2014.7033476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033476","Collaborative systems;Folksonomies;Information retrieval;Social Networks","Adaptation models;Bipartite graph;Collaboration;Communities;Frequency measurement;Social network services;Vectors","Internet;collaborative filtering;graph theory;information retrieval;social networking (online)","Internet;collaborative system;folksonomy;information retrieval;social network;tripartite hypergraph;user profile generation","","0","","9","","","9-10 Nov. 2014","","IEEE","IEEE Conference Publications"
"MTAF: An Adaptive Design for Keyword-Based Content Dissemination on DHT Networks","W. Rao; R. Vitenberg; L. Chen; S. Tarkoma","School of Software Engineering, Tongji University, Shanghai, China","IEEE Transactions on Parallel and Distributed Systems","20150310","2015","26","4","1071","1084","Beyond offering the widely used keyword search function, many peer-to-peer systems nowadays support the subscription function. For example, Vuze allows users to create subscription filters based on the keyword search. Given the subscription, episodic or related content will be delivered to the users whenever new episodes are available. Unfortunately, these applications suffer from the downsides, for example, high network traffic in the nodes maintaining popular terms. In this paper, we propose the MTAF mechanism to overcome the issues. The key of MTAF is to carefully select a subset of terms without incurring false negatives and to forward the content item toward the home nodes of such selected terms for low content forwarding cost. Experimental results based on real datasets indicate that the proposed solutions are efficient compared to existing approaches. In particular, the similarity-based replication of filters is shown to mitigate the effect of hot spots that arise due to the fact that some document terms are substantially more popular than the others.","1045-9219;10459219","","10.1109/TPDS.2014.5","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719388","Information retrieval and filtering;distributed hash table;peer-to-peer networks","Keyword search;Maintenance engineering;Merging;Peer-to-peer computing;Registers;Subscriptions;Vegetation","peer-to-peer computing;telecommunication traffic","DHT networks;MTAF mechanism;P2P systems;adaptive design;keyword-based content dissemination;network traffic;peer-to-peer systems;peer-to-peer technologies;similarity-based replication;subscription filters","","0","","34","","20140122","April 2015","","IEEE","IEEE Journals & Magazines"
"Use of Natural Language Processing to Discover Evidence of Systems Thinking","N. P. Whitehead; W. T. Scherer; M. C. Smith","MITRE Corporation, McLean, VA 22102 USA.","IEEE Systems Journal","","2015","PP","99","1","10","In prior work, we proposed elements of a generalized core language for systems thinking that characterizes a systems approach. We developed this foundational language through the relationship between critical thought and systems in the definition of systems thinking. We submitted our interpretation of this language, i.e., the Dimensions of Systems Thinking (DST), to the systems community for further development. Assuming that the DST provides a basis in language to express systems thought in a systems design or analysis, our objective in this phase is to present a strategy for discovering objective statistical evidence of systems thinking based on the linguistic elements of the DST in an unread corpus of documents. With that goal, we consider statistical semantic characterization of systems thought through a process of supervised learning, term frequency and inverse document frequency (tf–idf), cosine similarity, and naïve Bayes classifiers, specifically Rocchio classifiers and quadratic discriminant classification. Finding evidence of systems thinking in unread text through natural language processing establishes a foundation for computationally assessing systems thinking quality in a document or corpus of design-related documents without having to read the subject document or corpus. Once demonstrated, the method can be applied to systems thinking fluency in design-focused documents across a range of application areas, such as transportation, healthcare, and environmental policy. This study demonstrates that capability with a high degree of selectivity. Our approach establishes correlation and allows us to assess the systems thinking quality of a corpus of unread analysis and design studies on life cycle assessment. We show that assigning a prior probability improves that assessment. We posit that quantitative relations between the specific dimensions of systems thinking and a document would be useful for recognizing good systems thinking and impr- ving the quality of systems analyses.","1932-8184;19328184","","10.1109/JSYST.2015.2426651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7112126","Document classification;information retrieval;naïve Bayes;natural language processing;systems approach;systems thinking;vector space classification (VSC);vector space model (VSM)","Indexes;Information retrieval;Natural language processing;Semantics;Smoothing methods;Supervised learning","","","","0","","","","20150522","","","IEEE","IEEE Early Access Articles"
"Adaptive User Feedback for IR-Based Traceability Recovery","A. Panichella; A. De Lucia; A. Zaidman","Delft Univ. of Technol., Delft, Netherlands","2015 IEEE/ACM 8th International Symposium on Software and Systems Traceability","20150806","2015","","","15","21","Trace ability recovery allows software engineers to understand the interconnections among software artefacts and, thus, it provides an important support to software maintenance activities. In the last decade, Information Retrieval (IR) has been widely adopted as core technology of semi-automatic tools to extract trace ability links between artefacts according to their textual information. However, a widely known problem of IR-based methods is that some artefacts may share more words with non-related artefacts than with related ones. To overcome this problem, enhancing strategies have been proposed in literature. One of these strategies is relevance feedback, which allows to modify the textual similarity according to information about links classified by the users. Even though this technique is widely used for natural language documents, previous work has demonstrated that relevance feedback is not always useful for software artefacts. In this paper, we propose an adaptive version of relevance feedback that, unlike the standard version, considers the characteristics of both (i) the software artefacts and (ii) the previously classified links for deciding whether and how to apply the feedback. An empirical evaluation conducted on three systems suggests that the adaptive relevance feedback outperforms both a pure IR-based method and the standard feedback.","2157-2186;21572186","Electronic:978-0-7695-5593-5; POD:978-1-4673-6768-4","10.1109/SST.2015.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181523","Empirical Software Engineering;Information Retrieval;Software Traceability;User Feedback Analysis","Accuracy;Context;Natural languages;Negative feedback;Software;Software algorithms;Standards","natural language processing;pattern classification;program diagnostics;relevance feedback;software maintenance","IR-based methods;IR-based traceability recovery;adaptive relevance feedback;adaptive user feedback;information retrieval;natural language documents;semiautomatic tools;software artefacts;software maintenance activities;textual similarity;traceability links","","1","","34","","","17-17 May 2015","","IEEE","IEEE Conference Publications"
"Efficient multi-word parameterized matching on compressed text","R. Prasad; R. Garg","Department of Computer Science, Yobe State University, Damaturu, Nigeria","2014 IEEE 6th International Conference on Adaptive Science & Technology (ICAST)","20150326","2014","","","1","6","Searching set of patterns {P<sub>1</sub>, P<sub>2</sub>, P<sub>3</sub>, ....P<sub>r</sub>}, r≥1, inside body of a text T[1...n] is called multi-pattern matching problem. This matching is said to be parameterized match (p-match), if one can be transformed into the other via some bijective mapping. It is mainly used in software maintenance, plagiarism detection and detecting isomorphism in a graph. In the compressed parameterized matching problem, our task is to find all the parameterized occurrences of a pattern (set of patterns) in the compressed text, without decompressing it. Compressing the text before matching reduces the size and minimizes the matching time also. In this paper, we develop an efficient algorithm for parameterized multi-word matching problem on the compressed text, where both patterns and text are compressed before actual matching is performed and pattern is treated as word. For compressing the pattern and text, we use efficient compression code: Word Based Tagged Code (WBTC) and bit-parallel algorithm is used for searching purpose. Experimental results show that our algorithm is up to three times faster than the search on the uncompressed text.","2326-9413;23269413","DVD:978-1-4799-4999-1; Electronic:978-1-4799-4998-4; POD:978-1-4799-4997-7","10.1109/ICASTECH.2014.7068138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7068138","Compressed parameterized matching;String matching;compressed pattern matching;information retrieval;multiple matching and word based tagged code","Algorithm design and analysis;Automata;Image coding;Indexes;Pattern matching;Vocabulary","data compression;parallel algorithms;string matching;text analysis","WBTC;bit-parallel algorithm;compressed text;compression code;parameterized multiword matching problem;word based tagged code","","0","","18","","","29-31 Oct. 2014","","IEEE","IEEE Conference Publications"
"A multi-dimensional meter-adaptive method for automatic segmentation of music","C. Gaudefroy; H. Papadopoulos; M. Kowalski","CNRS-CentraleSupelec-Univ Paris-Sud, L2S, ENSTA ParisTech, Universit&#x00E9; Paris-Saclay","2015 13th International Workshop on Content-Based Multimedia Indexing (CBMI)","20150713","2015","","","1","6","Music structure appears on a wide variety of temporal levels (notes, bars, phrases, etc). Its highest-level expression is therefore dependent on music's lower-level organization, especially beats and bars. We propose a method for automatic structure segmentation that uses musically meaningful information and is content-adaptive. It relies on a meter-adaptive signal representation that prevents from the use of empirical parameters. Moreover, our method is designed to combine multiple signal features to account for various musical dimensions. Finally, it also combines multiple structural principles that yield complementary results. The resulting algorithm proves to already outperform state-of-the-art methods, especially within small tolerance windows, and yet offers several encouraging improvement directions.","1949-3983;19493983","Electronic:978-1-4673-6870-4; POD:978-1-4673-6871-1","10.1109/CBMI.2015.7153601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153601","harmony;metrical structure;music information retrieval;music structure;novelty;repetition;segmentation;timbre","Bars;Estimation;Feature extraction;Kernel;Music;Time-domain analysis;Time-varying systems","adaptive signal processing;feature extraction;music;signal representation","empirical parameter;meter-adaptive signal representation;multiple structural principle;music structure segmentation;signal feature","","0","","36","","","10-12 June 2015","","IEEE","IEEE Conference Publications"
"Quantifying the quality of a systems approach","N. P. Whitehead; W. T. Scherer","The MITRE Corporation, McLean, Virginia 22102, USA","2015 Annual IEEE Systems Conference (SysCon) Proceedings","20150604","2015","","","44","49","Determining a systems design, analysis or approach to be of high or low quality remains a subjective assessment. Our field requires the ability to objectively grade the quality of a systems approach in advance of implementation and then correlate that assessment with outcomes. We issue a call-to-arms and present a strategy for quantitatively assessing the quality of systems thinking in an unread corpus of documents based on the previously published Dimensions of Systems Thinking. This strategy involves statistical semantic characterization through a process of supervised learning, term frequency and inverse document frequency (tf-idf), cosine similarity and Naïve Bayes classifiers, specifically Rocchio classifiers and quadratic discriminant classification. The results of our study demonstrate that our proposed capability can be achieved with a high degree of selectivity.","","Electronic:978-1-4799-5927-3; POD:978-1-4799-5928-0; USB:978-1-4799-5926-6","10.1109/SYSCON.2015.7116727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116727","Systems thinking;document classification;information retrieval;naïve Bayes;natural language processing;systems approach;vector space classification;vector space model","Information retrieval;Joints;Semantics;Smoothing methods;Supervised learning;Systems engineering and theory;Training","formal specification;learning (artificial intelligence);systems analysis","Naive Bayes classifiers;Rocchio classifiers;cosine similarity;dimensions of systems thinking;inverse document frequency;quadratic discriminant classification;statistical semantic characterization;subjective assessment;supervised learning;systems approach quality quantification;systems design;term frequency","","0","","17","","","13-16 April 2015","","IEEE","IEEE Conference Publications"
"Pattern discovery from audio recordings by Variable Markov Oracle: A music information dynamics approach","C. i. Wang; S. Dubnov","University of California, San Diego, CREL, Music Department, United States","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","683","687","In this paper, a framework for automatic pattern discovery within an audio recording is proposed. The concept of the proposed framework stems from music information dynamics and is realized by Variable Markov Oracle. Music information dynamics is the research area focusing on information theoretic measures describing musical structure and is thus closely related to the field of music pattern discovery. Variable Markov Oracle is a data structure that provides both fast retrieval of repeated sub-clips from a signal and efficient calculation of music information dynamics measures. Evaluation of the proposed framework is performed on the JKU Patterns Development Dataset with significantly improved performance of the current state of the art.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178056","Data structures;Music information retrieval;Pattern analysis;Variable Markov Oracle","Music","Markov processes;audio recording;music","JKU Patterns Development Dataset;audio recording;audio recordings;automatic pattern discovery;music information dynamics;music information dynamics approach;music pattern discovery;musical structure;pattern discovery;variable Markov oracle","","2","","22","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Incorporating users location into snippet based Query recommendation system","M. R. Sisode; U. M. Patil","Department of Computer Engineering, R.C. Patel Institute of Technology, Shirpur, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","5","As the access of web has been increased greatly for information retrieval and it is difficult to extract the relevant information in less time. Sometime Search engine does not able to understand user search intend behind query. Thus Query recommendation can be used to help user to state exactly their information need. Search engine can return appropriate result to meet users' information needs. There are various methods based on history of users and snippets to retrieve the information. But these methods fail to satisfy users need. Therefore in addition of history and snippets with users location information will produce better results. Snippet based method with incorporating users preferences and location results the URLs for given query, also it ranks the clicked URLs at the top of the result based on user profile. The performance of the system shows that the snippet based with incorporating users location give better and effective recommendation for all types queries as compared to previous methods including low frequency queries.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087079","information retrieval;query recommendation;snippets;user profile;users location","Androids;Data mining;Databases;Google;Humanoid robots;Search engines","Internet;information needs;query processing;recommender systems;search engines","URL;Web access;information retrieval;search engine;snippet-based query recommendation system;user location;user profile","","0","","14","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Using the Web 1T 5-Gram Database for Attribute Selection in Formal Concept Analysis to Correct Overstemmed Clusters","G. R. Hall; K. Taghva","Dept. of Comput. Sci., Univ. of Nevada, Las Vegas, Las Vegas, NE, USA","2015 12th International Conference on Information Technology - New Generations","20150601","2015","","","651","654","As part of information retrieval processes, words are often stemmed to a common root. The Porter Stemming Algorithm operates as a rule-based suffix-removal process. Stemming can be viewed as a way to cluster related words together according to one common stem. Sometimes Porter includes words in a cluster that are un-related. This experiment attempts to correct this using Formal Concept Analysis (FCA). FCA is the process of formulating formal concepts from a given formal context. A formal context consists of objects and attributes, and a binary relation that indicates the attributes possessed by each object. A formal concept is formed by computing the closure of subsets of objects and attributes. Using the Cranfield document collection, this experiment crafted a comparison measure between each word in the stemmed cluster using the Google Web 1T 5-gram data set. Using FCA to correct the clusters, the results showed a varying level of success dependent upon the error threshold allowed.","","CD-ROM:978-1-4799-8827-3; Electronic:978-1-4799-8828-0; POD:978-1-4799-8829-7","10.1109/ITNG.2015.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113548","formal concept analysis;information retrieval;stemming","Algorithm design and analysis;Clustering algorithms;Context;Formal concept analysis;Standards;Testing;Training","Internet;formal concept analysis;information retrieval;search engines","FCA;Google Web 1T 5-gram data set;Porter stemming algorithm;Web 1T 5-gram database;attribute selection;binary relation;cranfield document collection;error threshold;formal concept analysis;information retrieval processes;overstemmed cluster correction;rule-based suffix-removal process","","0","","8","","","13-15 April 2015","","IEEE","IEEE Conference Publications"
"Indirect Acquisition of Violin Instrumental Controls from Audio Signal with Hidden Markov Models","A. Perez-Carrillo; M. M. Wanderley","IDMIL (Input Devices and Music Interaction Laboratory) and CIRMMT (Centre for Interdisciplinary Research in Music Media and Technology), McGill University, Montreal, Canada","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150409","2015","23","5","932","940","Acquisition of instrumental gestures in musical performances is a field of increasing interest with applications in different areas ranging from acoustics and sound synthesis to motor learning or artistic performances. Direct acquisition approaches are based on measurements with sensors attached on the instrument or the performer, a process that usually involves the use of expensive sensing systems and complex setups that are generally intrusive in practice. An alternative is the indirect acquisition without sensors based on analysis of the audio signal. This paper reports a novel indirect acquisition method for the estimation of continuous violin controls from audio-signal analysis based on the training of statistical models with a database of previously recorded violin performances. The database contains synchronized streams of audio features and instrumental controls. Audio signal was captured with a vibration transducer built into the violin bridge, and instrumental controls were measured with sensors. The controls include bowing parameters (played string, bowing velocity, bowing force, and bowing distance to the bridge) as well as fingering position. Once the model is trained for a specific violin, we can perform indirect acquisition from analysis of the signal captured with its embedded transducer without the need for the sensors any more. The statistical methods used are Hidden Markov Models (HMM) with observation distributions parameterized as Multivariate Gaussian Mixtures (GM). HMMs provide a means for note recognition and following and parameter prediction is based on GM regression. Results show that the presented method constitutes an accurate, non-intrusive and low-cost alternative for instrumental control acquisition of a previously calibrated violin and recording device.","2329-9290;23299290","","10.1109/TASLP.2015.2410140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054470","Indirect acquisition;information retrieval;musical gesture;violin instrumental controls","Databases;Hidden Markov models;Instruments;Sensors;Speech;Transducers;Vibrations","","","","1","","42","","20150304","May 2015","","IEEE","IEEE Journals & Magazines"
"Preprocessing of High Dimensional Dataset for Developing Expert IR System","A. Chaudhari; P. M. Phadatare; P. S. Kudale; R. B. Mohite; R. P. Petare; Y. P. Jagdale; A. Mudiraj","Dept. of Inf. Technol., Pimpri Chinchwad Coll. of Eng., Pune, India","2015 International Conference on Computing Communication Control and Automation","20150716","2015","","","417","421","Now-a-days due to increase in the availability of computing facilities, large amount of data in electronic form is been generated. The data generated is to be analyzed in order to maximize the benefit of intelligent decision making. Text categorization is an important and extensively studied problem in machine learning. The basic phases in the text categorization include preprocessing features like removing stop words from documents and applying TF-IDF is used which results into increase efficiency and deletion of irrelevant data from huge dataset. This paper discusses the implication of Information Retrieval system for text-based data using different clustering approaches. Applying TF-IDF algorithm on dataset gives weight for each word which summarized by Weight matrix.","","Electronic:978-1-4799-6892-3; POD:978-1-4799-6893-0","10.1109/ICCUBEA.2015.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155880","Information retrieval;TF IDF;stopwords;text based clustering","Clustering algorithms;Databases;Flowcharts;Frequency measurement;Information retrieval;Text categorization","decision making;information retrieval systems;learning (artificial intelligence);text analysis","TF-IDF algorithm;clustering approaches;electronic form;expert IR system;high dimensional dataset processing;information retrieval system;intelligent decision making;machine learning;text categorization;text-based data;weight matrix","","0","","16","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"What Just Happened? A Framework for Social Event Detection and Contextualisation","P. Khare; P. Torres; B. R. Heravi","Insight Centre for Data Analytics, NUI, Galway, Ireland","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","1565","1574","In course of a breaking news event, such as natural calamity, political uproar etc., a massive crowd sourced data is generated over social media which makes social media platforms an important source of information in such scenarios. The value of the information being propagated via social media is being increasingly realised by the news organisations and the journalists. Better tools and methodologies are needed to facilitate them in utilising this information for news production. A lot of analysis over social media, by the journalists, is performed via rigorous manual labour. However, the sheer volume of the data produced on social media is overwhelming and acts as a major obstacle for manual inspection of the streaming data for finding, aggregating and contextualising the emerging event in a short time span. This is a day-to-day challenge for journalists and media organisations. This paper addresses the above problem for journalist in handling the voluminous social media data, viewing it from an information retrieval perspective, by proposing an 'event detection and contextualisation' framework that processes an input stream of social media data into the clusters of likely events.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070000","Citizen Journalism;Information Retrieval;Social Event Detection;Social Semantic Journalism;User Generated Content","Context;Data mining;Event detection;Indexes;Media;Semantics;Vectors","data handling;outsourcing;social networking (online)","data crowdsourcing;social event contextualisation;social event detection;social media data","","1","","25","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Clustering Source Code Elements by Semantic Similarity Using Wikipedia","M. Schindler; O. Fox; A. Rausch","Dept. of Inf. - Software Syst. Eng., Clausthal Univ. of Technol., Clausthal-Zellerfeld, Germany","2015 IEEE/ACM 4th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering","20150730","2015","","","13","18","For humans it is no problem to determine if two words have a high or low semantic similarity in a given context. But is it possible to support a software developer or architect by using semantic data extracted from source code in the same way other relations like typical source code relations do? To answer this question we developed an approach to compute the semantic similarity by using Wikipedia as a textual corpus. In a case study we demonstrate this approach with a manageable software system. The results of using semantic similarities are compared with the outcome of using source code relations instead.","","Electronic:978-1-4673-7064-6; POD:978-1-4673-7065-3","10.1109/RAISE.2015.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7168326","Component Structure;Information Retrieval;Modularization;Semantic Similarity;Software Architecture;Spectral Clustering;Wikipedia","Electronic publishing;Encyclopedias;Internet;Semantics;Software systems","Web sites;information retrieval;pattern clustering;semantic Web;software development management;source code (software);text analysis;word processing","Wikipedia;clustering source code element;manageable software system;semantic data extraction;semantic similarity;software developer;source code relations;textual corpus","","0","","21","","","17-17 May 2015","","IEEE","IEEE Conference Publications"
"A Novel Framework for Privacy Preserving in Location Based Services","U. P. Rao; H. Girme","Comput. Eng. Dept., SardarVallabhbhai Nat. Inst. of Technol., Surat, India","2015 Fifth International Conference on Advanced Computing & Communication Technologies","20150406","2015","","","272","277","As availability of the mobile has been increased and many providers have started offering Location Based Services (LBS). There is undoubted potential of location-aware computing, but location awareness also comes up with the inherent threats, perhaps the most important of which is location privacy. This tracking of the location information result into unauthorized access of location data of user and causes serious consequences. It is a challenge to develop effective security schemes which can allow users to freely navigate through different applications, services and also ensure that the user's private information cannot be revealed elsewhere. This paper presents a detailed overview of existing schemes applied to Location Based Services (LBS). It also proposes a novel privacy preserving method (based on PIR) to provide the location privacy to the user.","2327-0632;23270632","Electronic:978-1-4799-8488-6; POD:978-1-4799-8489-3","10.1109/ACCT.2015.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079092","Location based service;Location privacy;Private Information Retrieval (PIR);Trusted third party (TTP)","Accuracy;Collaboration;Computer architecture;Databases;Mobile communication;Privacy;Security","mobile computing;security of data;telecommunication security;trusted computing","location based services;location data;location information;location-aware computing;privacy preserving","","2","","23","","","21-22 Feb. 2015","","IEEE","IEEE Conference Publications"
"Personalization mobile P2P network using FCA based multidimensional aggregation","S. Zammali; K. Arour; A. Bouzeghoub","Faculty of Sciences of Tunis, University Tunis El-Manar, Tunisia","2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)","20150622","2015","","","217","228","Mobile applications, that cover context-aware user modeling, are becoming increasingly prevalent. In this vein, information about the users are needed for the systems in order to provide them relevant services. This information enables the systems to figure out the users and their interests. For these reasons, different applications, in several areas, organize the user's properties, preferences and interests based on a structure, called a user model, which hold all relevant user-related information. In this respect, we propose a context-based user model in mobile Peer-to-Peer (P2P) environment. This model is based on aggregating different user information like past interests and the associated context. These past interests represent information about peers from which results were obtained and which were achieved from similar queries as well as from the user context. The basic idea of our proposal is to guess correlations between past requests, past peers from which results were obtained, associated user location and user interests. The generated correlations are based upon Formal Concept Analysis. We study, the exploitation of the proposed user model in results merging task in Peer-to-Peer Information Retrieval (P2PIR).","2151-1349;21511349","Electronic:978-1-4673-6630-4; POD:978-1-4673-6631-1; USB:978-1-4673-6629-8","10.1109/RCIS.2015.7128883","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128883","Formal Concept Analysis;Peer-to-Peer Information Retrieval;Results merging","Adaptation models;Context;Context modeling;Data models;Mobile communication;Object oriented modeling;Peer-to-peer computing","formal concept analysis;information retrieval;mobile computing;peer-to-peer computing;user interfaces","FCA;P2PIR;context-aware user modeling;formal concept analysis;multidimensional aggregation;peer-to-peer environment;peer-to-peer information retrieval;personalization mobile P2P network;user-related information","","0","","42","","","13-15 May 2015","","IEEE","IEEE Conference Publications"
"Automated updates mailing system for an organization:using named-entity recognition and tree based indexing database","S. Sadineni; B. M. Kilaru; E. Aluguri","Research Scholar, Computer Science Engineering, Jawaharlal Nehru Technological University Hyderabad, India","International Conference on Computing and Communication Technologies","20150326","2014","","","1","5","The current trend for communicating information in an organization is by using letters/ circulars; whereby the letter is prepared for a certain work and then forwarded on to all regardless of whether or not each employee has an interest or need for it. If the organization decides to send the letters to the respective/ interested employees, the job for the person assigned this task would be long and hard in the conventional mailing system. This paper proposes Automated Updates Mailing System (AUMS), a mailing system which identifies all the interested recipients' automatically to forward the letters/circulars in an organization using named-entity recognition and tree based indexing database, instead of an exhaustive manual search for all interested recipients' by mail administrator/sender. Our AUMS mailing scheme is straightforward to establish, fully compatible with any existing mailing systems, yet achieves an efficient way to construct an organization's mailing system. This process will result in a savings in time and money for the organization.","","Electronic:978-1-4799-8150-2; POD:978-1-4799-8151-9","10.1109/ICCCT2.2014.7066725","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066725","information extraction;information retrieval;named entity recognition;tree based indexing database","Dictionaries;Electronic mail;Indexing;Organizations;Postal services","database indexing;information retrieval;mailing systems;tree data structures","AUMS mailing scheme;automated update mailing system;named-entity recognition;organization mailing system;tree based indexing database","","0","","10","","","11-13 Dec. 2014","","IEEE","IEEE Conference Publications"
"Integration of recursive structure of hopfield and ontologies for query expansion","A. Noroozi; R. Malekzadeh","Faculty of Computer and IT Engineering Qazvin Branch, Islamic Azad University Qazvin, Iran","2015 The International Symposium on Artificial Intelligence and Signal Processing (AISP)","20150615","2015","","","18","23","One of the ways to enhance the information retrieval performance is query expansion (QE) which means adding some terms to the query in order to reduce mismatch between information needs and retrieved documents. In this way “Query Drift” occurring for ambiguous queries is a common problem. Special case of this problem is “Outweighting” that usually occurs for long queries, that is, some augmented words strongly related to an individual query words but not to the all. In this paper we propose a new method for QE to reduce the effects of disambiguated query terms and decrease query drifting. In proposed method for word outweighting elimination, query terms are grouped based on their semantic relationships. For each group, candidates are fetched from WordNet that relates to the all of words group. Then by using recursive structure of Hopfield network words with the most relationship with other words are selected. Moreover, the Term Semantic Network has used to overcome some of the shortcomings of WordNet. Evaluation results on CACM and CERC test collections show that the proposed method is effective and improve 4% and 12% of Mean Average Precision respectively.","","Electronic:978-1-4799-8818-1; POD:978-1-4799-8819-8","10.1109/AISP.2015.7123536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123536","Hopfield network;WordNet;information retrieval;query expansion;term semantic network","Association rules;Hopfield neural networks;Ontologies;Search engines;Semantics;Web pages","Hopfield neural nets;document handling;ontologies (artificial intelligence);query processing;semantic networks","CACM test collection;CERC test collection;Hopfield network word;WordNet;augmented word;disambiguated query term;information need;information retrieval performance;mean average precision;ontology;query drifting;query expansion;recursive structure;retrieved document;term semantic network;word outweighting elimination","","0","","22","","","3-5 March 2015","","IEEE","IEEE Conference Publications"
"Improving Query Expansion Using Wikipedia","L. Gan; W. Tu","Sch. of Math & Comput. Sci., Jiangxi Sci. & Technol. Normal Univ., Nanchang, China","2014 International Conference on Management of e-Commerce and e-Government","20150223","2014","","","143","146","Query expansion is one of important technologies used to improve retrieval efficiency. Many studies focus on query expansion with relationships between terms only extracted from the single local domain corpus. In fact, because the single local domain corpus is relatively small, there exist many no-landing terms which have no candidates for query expansion resulting in low retrieval performance. Therefore, to address such problem, relationships between terms captured from Wikipedia are superimposed to the basic Markov network that pre-built using the local domain corpus. A new larger Markov network is formed with more and richer relationships for each term. A graph mining technology, clique, is implemented to measure inter-relationships in Markov network for query expansion. The proposed techniques of superimposed Markov network and clique-based query expansion are benefit to improve precision and recall of information retrieval and to reduce the risk of topic drift.","","Electronic:978-1-4799-6543-4; POD:978-1-4799-6544-1","10.1109/ICMeCG.2014.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7046906","Markov network;Wikipedia;information retrieval;query expansion","Electronic publishing;Encyclopedias;Information retrieval;Internet;Markov random fields","Markov processes;Web sites;data mining;graph theory;network theory (graphs);query processing","Wikipedia;clique-based query expansion;graph mining technology;information retrieval;local domain corpus;query expansion;superimposed Markov network","","0","","16","","","Oct. 31 2014-Nov. 2 2014","","IEEE","IEEE Conference Publications"
"Analysis of aggregation operators in regression analysis","A. Gupta; S. Kohli","Department of Computer Science and Engineering, Birla Institute of Technology, Mesra, Ranchi, India","2015 International Conference on Cognitive Computing and Information Processing(CCIP)","20150504","2015","","","1","4","Regression analysis is one of the components of data mining techniques. Various regression algorithms have been proposed to mine the data efficiently and to propose a suitable business model. Every algorithm caters to a particular need and not necessarily produces the best fit futuristic model for all types of data. On the other hand, todays Web is expanding rapidly and affecting all aspects of our daily life. The complex nature of web data generated as a result of the complex nature of users browsing habit makes it very difficult for regression algorithm to generate the regression model with minimum outliers. This paper studies the use of different mathematical averaging operators in the regression analysis of such web based data and how these can be used to propose a better future model.","","Electronic:978-1-4799-7171-8; POD:978-1-4799-7172-5","10.1109/CCIP.2015.7100743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100743","Averaging operator;Information Retrieval;Regression;Web Analytics","Analytical models;Data mining;Data models;Decision making;Mathematical model;Predictive models;Regression analysis","Internet;data mining;regression analysis","Web based data;aggregation operators;data mining techniques;mathematical averaging operators;regression analysis","","0","","22","","","3-4 March 2015","","IEEE","IEEE Conference Publications"
"Text Search of Surnames in Some Slavic and Other Morphologically Rich Languages Using Rule Based Phonetic Algorithms","D. Zahoranský; I. Polasek","Software Engineering, Faculty of Informatics and Information Technology Slovak University of Technology (FIIT STU), Bratislava","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150226","2015","23","3","553","563","Surnames play a key role as person natural identifiers, essentially in present information systems. This paper deals with the topic of optimizing a phonetic search algorithm as a string matching of surnames usable for communications service providers, person registries, social networks or genealogy databases. It describes a proposed solution for the phonetic searching of Slovak and (territorial) neighboring languages (Czech, Polish, Ukrainian, Russian, German, Hungarian, Jewish) surnames. This solution was designed to improve search precision and recall when searching for people by their surnames originating in these languages.","2329-9290;23299290","","10.1109/TASLP.2015.2393393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7012074","Algorithms;information retrieval;natural languages","Algorithm design and analysis;Databases;Europe;IEEE transactions;Materials;Speech;Speech processing","information retrieval;natural language processing","Czech language;German language;Hungarian language;Jewish language;Polish language;Russian language;Slovak language;Ukrainian language;communications service providers;genealogy databases;information systems;morphologically rich language;natural identifiers;person registries;phonetic search algorithm;rule based phonetic algorithm;search precision;search recall;slavic language;social networks;surname string matching;surname text search","","1","","27","","20150116","March 2015","","IEEE","IEEE Journals & Magazines"
"A graph model based author attribution technique for single-class e-mail classification","Novino Nirmal. A; Kyung-Ah Sohn; T. S. Chung","Department of Computer Engineering, Ajou University, South Korea","2015 IEEE/ACIS 14th International Conference on Computer and Information Science (ICIS)","20150727","2015","","","191","196","Electronic mails have increasingly replaced all written modes of communications for important correspondences including personal and business transactions. An e-mail is given equal significance as a signed document. Hence email impersonation through compromised accounts has become a major threat. In this paper, we have proposed an email style acquisition and classification model for authorship attribution that serves as an effective tool to prevent and detect email impersonation. The proposed model gains knowledge of the author's email style by being trained only with the sample email texts of the author and then identifies if a given email text is a legitimate email of the author or not. Extracting the significant features that represent an author's style from the available concise emails is a big challenge in email authorship attribution. We have proposed to use a graph-based model to precisely extract the unique feature set of the author. We have used one-class SVM classifier to deal with the single-class sample data that consists of only true positive samples. Two classification models have been designed and compared. The first one is a probability model which is based on the probability of occurrence of a feature in the specific email. The second technique is based on inclusive compound probability of a feature to appear in a sentence of an email. Both the models have been evaluated against the public Enron dataset.","","Electronic:978-1-4799-8679-8; POD:978-1-4799-8680-4","10.1109/ICIS.2015.7166592","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7166592","Author Attribution;Graph Model;Information Retrieval;One Class SVM;Stylometry;Text Classification","Compounds;Context;Electronic mail;Sensitivity;Support vector machines;Testing;Training","electronic mail;graph theory;support vector machines","author attribution technique;business transactions;classification model;electronic mails;email style acquisition;graph model;inclusive compound probability;one-class SVM classifier;personal transactions;public Enron dataset;single-class e-mail classification;single-class sample data","","0","","13","","","June 28 2015-July 1 2015","","IEEE","IEEE Conference Publications"
"Comparison of ranking algorithms with dataspace","N. Lal; S. Qamar","Computer Science & Engineering, Research Scholar, Suresh Gyan Vihar University, Jaipur, Rajasthan, India","2015 International Conference on Advances in Computer Engineering and Applications","20150723","2015","","","565","572","With increased in digitization the amount of homogeneous, unstructured, semi-structured, structured or heterogeneous data being created and stored is exploding is collectively called “Dataspace”. Data being generated from various heterogeneous sources like, digital images, audio, video, online transactions, online social media, data from sensor nodes, click streams for different domains including, retails, medical, healthcare, energy, and day to day life utilities. In business, industries, institutions and organizations, individuals contribute the data volume like technical reports, seminar reports, research papers, dissertations, thesis etc. For instance, 30 billion web pages are accessed or the World Wide Web. With terrific number of pages of that exist today; search engines assume a significant role in the current internet of thing (IOT). So with billions of web pages accessible on the web, a user query entered in the search engine may returns thousands of web pages, and thus it becomes extremely important to rank these results in such a way that the most “related” or “important” or “authorized” pages are displayed first. This job of prioritizing the results is performed by ranking algorithms, and various search engines use different schemes for ranking the results. Ranking of data can also do in heterogeneous data to retrieve information from the Dataspace. The aim of this paper is to describe Dataspace and present a survey on ranking algorithms, and their comparison, Comparison is done on the basis of some parameters such as main technique use, methodology, and input parameter, and relevancy, quality of results, importance and limitations, search engines and time complexity of algorithms. In this we also explained how ranking can be used in Dataspace with challenges to information retrieval from heterogeneous data or from Dataspace.","","DVD:978-1-4673-6910-7; Electronic:978-1-4673-6911-4; POD:978-1-4673-6912-1","10.1109/ICACEA.2015.7164756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164756","Dataspace;IOT;database ranking;information retrieval;ranking;ranking algorithms;search engines algorithms","Algorithm design and analysis;Computers;Databases;Google;Search engines;Web pages","Internet of Things;data handling;social networking (online)","IOT;Internet of Thing;Web pages;World Wide Web;audio;click streams;dataspace;digital images;information retrieval;online social media;online transactions;ranking algorithms;search engine;search engines;sensor nodes;user query;video","","1","","31","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Natural language interface to database using modified co-occurrence matrix technique","A. Mohite; V. Bhojane","Department of Computer Engineering, PIIT, New Panvel, Maharashtra, India","2015 International Conference on Pervasive Computing (ICPC)","20150416","2015","","","1","4","Today, database is considered as one of the major source of information. Data stored in database can be accessed by using SQL queries. Those who are expert in SQL language can access information from database but non-technical user cannot retrieve data from database such as MySQL and oracle. There is need to provide natural language interface to database for non-technical users. In this paper we have discussed design and implementation of a system using modified word co-occurrence matrix method which will provide access to database using queries in English language.","","Electronic:978-1-4799-6272-3; POD:978-1-4799-6054-5","10.1109/PERVASIVE.2015.7087045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7087045","Database;Information retrieval;Natural language interface;Natural language processing;Structured Query Language (SQL);Word co-occurrence matrix technique","Aggregates;Computer architecture;Computers;Databases;Natural languages;Remuneration;Semantics","SQL;matrix algebra;natural language interfaces;natural language processing;query processing","English language;SQL language;SQL queries;modified co-occurrence matrix technique;natural language interface;natural language processing;structured query language","","0","","7","","","8-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"A new approach to build a geographical taxonomy of adjacency automatically using the latent semantic indexing method","O. E. Midaoui; A. E. Qadi; M. D. Rahmani; D. Aboutajdine","LRIT Associated Unit to the CNRST - URAC n&#x00B0;29, Faculty of Science, Mohammed V-Agdal University, Rabat, Morocco","2015 Intelligent Systems and Computer Vision (ISCV)","20150514","2015","","","1","6","In this paper, we introduce an approach for constructing a geographical taxonomy of adjacency for a country, to be used in reformulating spatial queries. The proposed approach uses the best-ranked documents retrieved by the search engine while submitting the spatial entity composed of a spatial relationship and a noun of a city A. Then, apply to it the Latent Semantic Indexing method to found the nearest cities B<sub>i</sub> to A, and proceed to a step of validation of each link by verifying if A is also found in the results of the cities B<sub>i</sub>. In our experiments, we constructed a geographical taxonomy of adjacency for Morocco. We varied the spatial relationship used in the step of documents retrieving to compare the results of the different spatial relationships, and we used google web services as a search engine to compare the results returned in every case. Then we used the constructed taxonomy in geographical query reformulation. We have used the Un-interpolated Average Precision (UAP) to compare the returned documents before and after reformulation. According to our results, we note that reformulating geographical queries based on our built taxonomy improves widely the precision of the queries.","","Electronic:978-1-4799-7511-2; POD:978-1-4799-7512-9","10.1109/ISACV.2015.7105551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105551","Geographical Information Retrieval;Geographical Taxonomy;Latent Semantic Indexing;Spatial Query Reformulation","Cities and towns;Error analysis;Large scale integration;Search engines;Semantics;Taxonomy","Web services;geographic information systems;indexing;query processing;search engines","Google Web services;UAP;best-ranked document retrieval;geographical query reformulation;geographical taxonomy;latent semantic indexing method;search engine;spatial query;un-interpolated average precision","","0","","13","","","25-26 March 2015","","IEEE","IEEE Conference Publications"
"Concepts extraction for medical documents using ontology","V. Mala; D. K. Lobiyal","School of Computer and Systems Sciences, Jawaharlal Nehru University, New Delhi, India","2015 International Conference on Advances in Computer Engineering and Applications","20150723","2015","","","773","777","In the biomedical domain large amount of text documents are unstructured information is available in digital text form. Text Mining is the method or technique to find for interesting and useful information from unstructured text. Text Mining is also an important task in medical domain. The technique uses for Information retrieval, Information extraction and natural language processing (NLP). Traditional approaches for information retrieval are based on key based similarity. These approaches are used to overcome these problems; Semantic text mining is to discover the hidden information from unstructured text and making relationships of the terms occurring in them. In the biomedical text, the text should be in the form of text which can be present in the books, articles, literature abstracts, and so forth. Most of information is stored in the text format, so in this paper we will focus on the role of ontology for semantic text mining by using WordNet. Specifically, we have presented a model for extracting concepts from text documents using linguistic ontology in the domain of medical.","","DVD:978-1-4673-6910-7; Electronic:978-1-4673-6911-4; POD:978-1-4673-6912-1","10.1109/ICACEA.2015.7164807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164807","Concept cluster;English WordNet;Information retrieval;Semantic relations;Text mining","Cancer;Clustering algorithms;Diseases;Information retrieval;Ontologies;Semantics;Text mining","document handling;information retrieval;medical administrative data processing;medical computing;natural language processing;ontologies (artificial intelligence)","NLP;WordNet;biomedical domain;concept extraction;digital text;hidden information;information extraction;information retrieval;linguistic ontology;medical documents;medical domain;natural language processing;semantic text mining;text documents;text mining;unstructured information;unstructured text","","0","","16","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"A cluster based multi-keyword search on outsourced encrypted cloud data","R. Handa; R. K. Challa","CSE Department, NITTTR, Chandigarh, INDIA","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","115","120","Cloud provides an illusion of infinite storage to the user at limited setup and usage cost. Due to the availability of resources at low initial investment cost and fast internet speed, the organizations are motivated to outsource their data on cloud. But storing secure and confidential data on cloud introduces many security risks, namely data leakage, data theft and reduced control on data. In order to maintain confidentiality, the data is encrypted before outsourcing it to cloud. But this introduces the problem of efficient searching on the cloud. Several approaches exist for searching on this encrypted data stored on cloud but require large number of comparisons and time to search the desired documents. In this paper, we propose a cluster based privacy preserving multi-keyword search scheme over encrypted cloud data. The proposed search scheme retains the security requirements as proposed in the existing approaches in literature but provides results efficiently. Experimental results demonstrate the effectiveness of the proposed search scheme as it reduces the number of comparisons required to search the desired document by 80% for dataset with 6000 documents. Also, the time required to search the desired documents is also reduced by 70% for the same dataset as compared to the existing efficient search schemes in literature.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100232","Cloud;Cloud security;Cloud storage;Cluster index;Information retrieval;Privacy preserving","Cloud computing;Encryption;Indexes;Keyword search;Servers","cloud computing;cryptography;outsourcing;storage management","cluster based privacy preserving multikeyword search scheme;confidential data storage;data leakage;data theft;outsourced encrypted cloud data;reduced data control;search schemes;secure data storage;security requirements;security risks","","0","","14","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Recommender system algorithms: A comparative analysis based on monotonicity","T. V. R. Himabindu; V. Padmanabhan; V. R. Kagita; A. K. Pujari","Artificial Intelligence Lab, School of Computer and Information Sciences, University of Hyderabad, India 500046","2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)","20150302","2015","","","1","6","Recommender systems are designed in such a way that they sort through massive amounts of data so as to help users in finding their preferred items. Currently much research on recommender systems focus on improving the prediction or classification accuracy of the respective algorithms while behavioral aspects are often overlooked. In this paper we focus on a particular behavioral property called monotonicity which we believe every recommender system should satisfy but has received very little attention. Assume that a recommender system recommends a set R of N items (for example movies) based on some scoring pattern and o<sub>a</sub> ∈ R has the highest score among items in R. Let us also assume that a particular user accepts the recommendation and consumes that item o<sub>a</sub> in the next stage and thereby appends his/her profile with o<sub>a</sub>. We again run the recommendation step with the appended profile to get a recommendation of N items, say R'. Monotonicity refers to the number of items of R {<sub>a</sub>} (R minus {o<sub>a</sub>}) that are retained in R'. In a top-k recommendation, monotonicity tries to measure the number of items continued to be recommended when a technique is utilized incrementally. In this work, in addition to monotonicity, we also consider two other popular measures called precison and recall to provide an experimental analysis of five most popular recommendation algorithms for evaluating the utility of recommendations.","","Electronic:978-1-4799-7458-0; POD:978-1-4799-7459-7","10.1109/ICAPR.2015.7050693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050693","Information Retrieval;Monotonicity;Recommender Systems","Accuracy;Algorithm design and analysis;Collaboration;Joints;Motion pictures;Prediction algorithms;Recommender systems","information retrieval;pattern classification;recommender systems;sorting","classification accuracy;data sorting;monotonicity;precison;prediction accuracy;recall;recommender system algorithms;scoring pattern;top-k recommendation","","0","","15","","","4-7 Jan. 2015","","IEEE","IEEE Conference Publications"
