"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6359745,6394376,6394282,6394583,6331020,6392054,6391938,6392737,6392063,6392671,6386786,6387890,6379275,6376683,6374926,6375257,6366218,6352212,6351662,6349766,6350505,6337203,6339719,6339741,6334966,5963683,5963672,6333366,6175906,6327413,6327433,6328011,6319462,6319542,6322585,6216343,6309607,6311022,6300018,6299417,6298454,6299405,6266401,6291267,6287920,6288906,6289064,6285067,6143906,6180166,6272277,6268055,6210348,6248667,6218157,6095652,6257375,5710921,6240489,6234049,6233416,6228582,6227172,6227101,6227068,6227087,6223245,6220930,6220926,6221738,6216753,6216755,6189746,6204675,6143913,6197566,6182574,6198392,6197785,6197787,6195332,5740827,6185005,6179816,6177734,6111486,6133261,5677516,6155137,6153150,6150545,6146946,6132994,6128439,6122593,6121484,6121491,6116955,6111017,6108545",2017/05/04 20:49:22
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"The design and implementation of an intelligent distributed text retrieval system","Wang Yu; Guohua Wang","School of Educational Technology and Communication, GuangDong Polytechnical Normal University, Guangzhou, China","2012 2nd International Conference on Uncertainty Reasoning and Knowledge Engineering","20121004","2012","","","189","192","Traditional text retrieval techniques greatly consume system resources. Although some file-sharing software realizes file positioning and high-speed downloads, they have no enough capacity to analysis variety format Chinese documents and to extract keywords. At the same time, during the operation of system, it exist hot issues in network routing. This paper proposes an intelligent distributed text retrieval system, which adopts two routing strategies based on the index sub-node and peer nodes and can effectively solve these problems, in the same also can improve the efficiency of finding specific information from the massive data.","","Electronic:978-1-4673-1460-2; POD:978-1-4673-1459-6","10.1109/URKE.2012.6319542","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6319542","distributed networks;segmentation algorithm;text retrieval;two level routing","Algorithm design and analysis;Artificial intelligence;Educational institutions;Indexes;Information retrieval;Peer to peer computing;Routing","information retrieval;network routing;peer-to-peer computing;text analysis","Chinese documents analysis;file positioning;file sharing software;index subnode;intelligent distributed text retrieval system;keyword extraction;network routing;peer node","","0","","5","","","14-15 Aug. 2012","","IEEE","IEEE Conference Publications"
"The impact of IT on curricula design of Information Management and Information System Doctoral Education in China","Yuli Yang; Su Zhang; Tao Chen","Library of Dalian University of Technology, China 116024","2012 International Symposium on Information Technologies in Medicine and Education","20120830","2012","1","","142","145","Although there are a lot of researches on Information Management and Information System education in China, little research is done in examining the impact of IT on doctoral curricula by Information Management and Information System programs in China to reveal: what courses are offered? what is the most popular subject area? how Information Management and Information System schools change their curricula to meet today's challenges? In order to address above questions, this study gives a brief summary of the curricula of Information Management and Information System doctoral programs in China. Findings show that there is no national consensus of what should be the core of the Information Management and Information System discipline for PhD education in China. The largest percentage of the courses offered relate to Management Science and Engineering. Interdisciplinarity is also featured within the Information Management and Information System PhD curricula in China.","","Electronic:978-1-4673-2108-2; POD:978-1-4673-2109-9","10.1109/ITiME.2012.6291267","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6291267","Information Management;Information System","Analytical models;Educational institutions;Finance;Information retrieval;Innovation management;Medical services","biomedical education;educational technology;information management;information systems","China;IT impact;PhD education;curricula design;doctoral curricula;information management and information system doctoral education","","0","","18","","","3-5 Aug. 2012","","IEEE","IEEE Conference Publications"
"Cinefile: A Category-Based Analytic Browser","S. Davies; S. A. Seal; J. Hatfield","University of Mary Washington","Computer","20120817","2012","45","8","62","69","A category-based browser identifies related items and groups them into custom-defined categories that it uses as first-class query constructs, making it possible to view aggregate information and receive approximate answers that might be difficult to state explicitly.","0018-9162;00189162","","10.1109/MC.2012.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143906","Cinefile;data mining;interactive data exploration and discovery;personalization;query formulation","Data mining;Information analysis;Information filtering;Information retrieval;Interactive systems;Query processing;Search engines;Text mining;Web browsers","SQL;online front-ends;query processing;recommender systems;relational databases","Cinefile;category-based analytic browser;custom-defined categories;information aggregation;query constructs;relational database;structured query language","","0","","7","","20120131","August 2012","","IEEE","IEEE Journals & Magazines"
"GEOSS Component and Service Registry: Design, Implementation and Lessons Learned","Y. Bai; L. Di; D. D. Nebert; A. Chen; Y. Wei; X. Cheng; Y. Shao; D. Shen; R. Shrestha; H. Wang","Center for Earth System Science, Tsinghua University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20121228","2012","5","6","1678","1686","Petabytes of Earth science data have been accumulated through space- and air-borne Earth observation programs during the last several decades. The data are valuable both scientifically and socioeconomically. The value of these data could be further increased significantly if the data from these programs can be easily discovered, accessed, integrated, and analyzed. The Global Earth Observation System of Systems (GEOSS) is addressing this need. In particular, the GEOSS Component and Service Registry maintains the descriptive information about available Earth Observation resources that are self-nominated by providers. This registry provides the following capabilities for data providers: user registration, resource registration, and service interface registration. It enables data users to discover these resources through the dedicated graphical user interfaces. It also exposes machine-to-machine interfaces to other GEOSS core components. The captured functional requirements, system design and implementation details of this registry are introduced in this paper, followed by the analysis of the registered resources and the system accessing information. The discussion on the strengths of this registry, the limitations in its current form, and the lessons learned from the system maintenance and upgrade over the last five years may be useful to others building a centralized managed resource catalog to enable a large-scale integrated system following a system-of-systems approach.","1939-1404;19391404","","10.1109/JSTARS.2012.2215914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331020","Component and service registry;Earth observation resources;Global Earth Observation System of Systems (GEOSS);metadata","Catalogs;Global Earth Observation System of Systems;Information retrieval;Portals;Standards;Taxonomy","data acquisition;data analysis;geographic information systems;geophysics computing;graphical user interfaces","Earth science data;GEOSS component;GEOSS service registry;Global Earth Observation System of Systems;air-borne Earth observation programs;descriptive information;graphical user interfaces;machine-to-machine interfaces;resource registration;service interface registration;space-borne Earth observation programs;system-of-systems approach;user registration","","8","","10","","20121015","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Statistical inference on recall, precision and average precision under random selection","P. Zhang; W. Su","Department of Mathematics, Zhejiang University, Hangzhou, 310027 China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","1348","1352","The objective of a rare target detection problem is to identify the rare targets as early as possible. Recall, precision and average precision are three popular performance measures for evaluating different detection methods. However, there is little literature on the statistical properties of these three measures. We develop a framework for conducting statistical inference on recall, precision and average precision through establishing their asymptotic properties. Simulations are used to illustrate the idea. The proposed methods can also be applied in other areas where ranking systems need to be evaluated, such as information retrieval.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234049","","Educational institutions;Equations;Information retrieval;Joints;Mathematical model;Object detection;Vectors","inference mechanisms;information retrieval;object detection;random processes;statistical analysis","asymptotic properties;average precision;detection methods;information retrieval;performance measures;random selection;ranking systems;rare target detection problem;rare target identification;recall;statistical inference","","2","","10","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Cross Language Information Extraction for Digitized Textbooks of Specific Domains","W. Zhu; L. Luo; C. Ju; B. Zhang","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2012 IEEE 12th International Conference on Computer and Information Technology","20121224","2012","","","1114","1118","While the influence of the digitization movement is getting wider and wider, more and more countries have initiated their own digital library projects to preserve the culture by digitize millions of books. Together with all kinds of digital resources, such as videos, audios, images etc., the digital library can provide advanced services far more than reading and browsing. Information extraction is one of the fundamental methods to get structured information out of the digital books. Therefore, due to its importance for content integration and knowledge discovery, information extraction for different languages is becoming a key problem for the development of digital library. In this paper, we present a domain-related information extraction framework that suits for digitized textbooks of different languages. To achieve cross language adaptation, we introduce language independent features and simple language dependent features that bind with domain characters to generate extractors. Finally, we present two preliminary experiments to show the feasibility of this framework.","","Electronic:978-0-7695-4858-6; POD:978-1-4673-4873-7","10.1109/CIT.2012.226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392063","Cross Language;Digitized Textbook;Information Extraction","Data mining;Electronic publishing;Encyclopedias;Feature extraction;Information retrieval;Libraries","data mining;digital libraries;electronic publishing","content integration;cross language information extraction;digital books;digital library projects;digital resources;digitization movement;digitized textbooks;domain-related information extraction framework;knowledge discovery;language independent features;simple language dependent features;specific domains","","0","","10","","","27-29 Oct. 2012","","IEEE","IEEE Conference Publications"
"A SPA-based K-means clustering algorithm for the remote sensing information extraction","X. Xie; J. Zhao; H. Li; W. Zhang; L. Yuan","Faculty of Land and Resource Engineering, Kunming University of Science and Technology, 650093, China","2012 IEEE International Geoscience and Remote Sensing Symposium","20121110","2012","","","6111","6114","Set Pair Analysis (SPA) is a new methodology to describe and process uncertainty system, which has been applied in many fields recently. In this paper, a new approach to remote sensing information extraction, the SPA-based k-means clustering algorithm (SPAKM), has been proposed based on the principle of SPA. The basic ideals and steps of SPAKM are discussed. The proposed algorithm can overcome the limitation of K-means clustering algorithm to certain extent. Finally, cluster analysis experiments of LANDSAT TM image have been made. The results show that the improved K-means clustering algorithm is superior to K-means in classification accuracy of land cover classes of mixed pixels.","2153-6996;21536996","Electronic:978-1-4673-1159-5; POD:978-1-4673-1160-1; USB:978-1-4673-1158-8","10.1109/IGARSS.2012.6352212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6352212","IDC connection degree;K-means;Set Pair Analysis;clustering algorithm;remote sensing image","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Information retrieval;Remote sensing;Satellites;Uncertainty","geophysical image processing;statistical analysis;terrain mapping","LANDSAT TM image;SPA-based K-means clustering algorithm;SPAKM;cluster analysis;land cover;remote sensing information extraction;set pair analysis;uncertainty system","","1","","7","","","22-27 July 2012","","IEEE","IEEE Conference Publications"
"Digital outcrop modeling and geology information extraction based on ground-based Lidar","Z. Qihong; X. Xing; Z. Youyan; Y. Yong; H. Yan; L. Song","Research Institute of Petroleum Exploration and Development, PetroChina, Beijing, China","2012 International Conference on Audio, Language and Image Processing","20121210","2012","","","580","583","Ground-based Lidar (light detection and ranging) can instantly record the 3-dimensional digital outcrop characterization with a high density and high positional accuracy. It is the new method to capture the geological information from outcrop. This paper presents the new methodology for digital outcrop modeling and geology information extraction based on ground-based Lidar. A complete workflow from data acquisition and processing, 3D digital outcrop model building to geology information extraction is discussed. Based on the digital outcrop model, a method of automatic extracting the dip and strike information of structural surface is researched. And a method of automatic lithology classification is studied too. The 3D digital outcrop model has been applied to geological description and analysis in Xinjiang, China.","","Electronic:978-1-4673-0174-9; POD:978-1-4673-0173-2","10.1109/ICALIP.2012.6376683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376683","","Data mining;Data models;Geology;Information retrieval;Laser modes;Laser radar;Solid modeling","data acquisition;feature extraction;geographic information systems;geology;geophysical techniques;optical radar;pattern classification;solid modelling","3-dimensional digital outcrop characterization;3D digital outcrop model;China;Xinjiang;automatic extraction method;automatic lithology classification;data acquisition;data processing;dip information;geological description;ground-based lidar;ground-based lidar-based geology information extraction;high positional accuracy;light detection and ranging;strike information","","0","","13","","","16-18 July 2012","","IEEE","IEEE Conference Publications"
"Subontology Extraction Using Hyponym and Hypernym Closure on is-a Directed Acyclic Graphs","V. Ranwez; S. Ranwez; S. Janaqi","Universit&#x00E9; Montpellier II, Montpellier","IEEE Transactions on Knowledge and Data Engineering","20121019","2012","24","12","2288","2300","Ontologies are successfully used as semantic guides when navigating through the huge and ever increasing quantity of digital documents. Nevertheless, the size of numerous domain ontologies tends to grow beyond the human capacity to grasp information. This growth is problematic for a lot of key applications that require user interactions such as document annotation or ontology modification/evolution. The problem could be partially overcome by providing users with a subontology focused on their current concepts of interest. A subontology restricted to this sole set of concepts is of limited interest since their relationships can generally not be explicit without adding some of their hyponyms and hypernyms. This paper proposes efficient algorithms to identify these additional key concepts based on the closure of two common graph operators: the least common-ancestor (lca) and greatest common descendant (gcd). The resulting method produces ontology excerpts focused on a set of concepts of interest and is fast enough to be used in interactive environments. As an example, we use the resulting program, called OntoFocus (http://www.ontotoolkit.mines-ales.fr/), to restrict, in few seconds, the large Gene Ontology (~30,000 concepts) to a subontology focused on concepts annotating a gene related to breast cancer.","1041-4347;10414347","","10.1109/TKDE.2011.173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963683","Subontology extraction;directed acyclic graph;greatest common descendant;least common ancestor;ontology transformation","Context awareness;Filtering;Indexes;Information retrieval;Ontologies;Semantics;Visualization","directed graphs;ontologies (artificial intelligence)","OntoFocus;breast cancer;digital documents;document annotation;domain ontologies;gcd;gene ontology;greatest common descendant;hypernym closure;hyponym closure;interactive environments;is-a directed acyclic graphs;lca;least common-ancestor;ontology evolution;ontology modification;subontology extraction","","0","","44","","20110728","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"The Methodology of the Maximum Likelihood Approach: Estimation, Detection, and Exploration of Seismic Events","P. J. Chung; J. F. Boehme","University of Edinburgh, Edinburgh, EH9 3JL, UNITED KINGDOM","IEEE Signal Processing Magazine","20120409","2012","29","3","40","46","The retrieval of information con veyed in data recorded by seis mic arrays plays a key role in seismology and geophysical exploration. Accurate localization and reli able detection of seismic events are major tasks in seis mic monitoring systems. The nonstationarity, low signal-to noise ratio (SNR), and weak signal coherence of seismic data remain challenging issues for signal processing algorithms. The maximum likelihood (ML) approach that performs well in such critical conditions is one of the best solutions for simultaneous detec tion and localization of seismic events. This article will discuss the methodology of ML for estimation and detection of seismic data and its extension to geoacoustic model selection.","1053-5888;10535888","","10.1109/MSP.2012.2182949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6179816","","Broadband communication;Geophysical measurements;Geophysical signal processing;Information retrieval;Maximum likelihood estimation;Noise measurement;Seismic measurements;Testing;Vectors","seismic waves;seismology","geoacoustic model selection;geophysical exploration;maximum likelihood approach;seismic arrays;seismic data;seismic events;seismic monitoring systems;signal processing algorithms;signal-to-noise ratio","","1","","33","","","May 2012","","IEEE","IEEE Journals & Magazines"
"A Weighted Cluster-based Chinese Text Categorization Approach: Incorporating with Word Clusters","Y. C. Wu; J. C. Yang","Dept. of Commun. & Manage., Ming-Chuan Univ., Taipei, Taiwan","2012 IIAI International Conference on Advanced Applied Informatics","20121025","2012","","","279","282","Most of the researches on text categorization are focus on using bag of words. Some researches provided other methods for classification such as term phrase, Latent Semantic Indexing, and term clustering. Term clustering is an effective way for classification, and had been proved as a good method for decreasing the dimensions in term vectors. We used hierarchical term clustering and aggregating similar terms. In order to enhance the performance, we present a modify indexing with terms in cluster. Our test collection extracted from Chinese NETNEWS, and used the Centroid-Based classifier to deal with the problems of categorization. The results had shown that term clustering is not only reducing the dimensions but also outperform than bag of words. Thus, term clustering can be applied to text classification by using any large corpus, its objective is to save times and increase the efficiency and effectiveness. In addition to performance, these clusters can be considered as conceptual knowledge base, and kept related terms of real world.","","Electronic:978-0-7695-4826-5; POD:978-1-4673-2719-0","10.1109/IIAI-AAI.2012.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337203","feature selection;text categorization;vector space model;word clustering","Accuracy;Clustering algorithms;Information retrieval;Machine learning;Support vector machines;Testing;Text categorization","pattern classification;pattern clustering;text analysis","Chinese NETNEWS;bag of words;categorization problems;centroid based classifier;conceptual knowledge base;hierarchical term clustering;latent semantic indexing;term phrase;term vectors;text categorization;text classification;weighted cluster-based Chinese text;word clusters","","0","","24","","","20-22 Sept. 2012","","IEEE","IEEE Conference Publications"
"The History of Storage Systems","K. Goda; M. Kitsuregawa","Institute of Industrial Science, The University of Tokyo , Meguro-ku, Tokyo, Japan","Proceedings of the IEEE","20120510","2012","100","Special Centennial Issue","1433","1440","This paper reviews the history of storage systems. The first section begins with the era of early mechanical calculators and the following four sections review historically major storage devices such as magnetic tapes, magnetic disks, optical devices, and solid-state devices. The final two sections focus on recent system technologies such as storage networking and cloud-based storage.","0018-9219;00189219","","10.1109/JPROC.2012.2189787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182574","Mass storage;storage medium;storage system","Computers;Data storage systems;Disk drives;Flash memory;History;Information retrieval;Magnetic recording;Magnetic tunneling;Media;Optical recording","archaeology;digital storage;storage area networks","cloud-based storage;magnetic disks;magnetic tapes;mechanical calculators;optical devices;solid-state devices;storage networking;storage systems","","7","","52","","20120411","May 13 2012","","IEEE","IEEE Journals & Magazines"
"Harvesting and Summarizing User-Generated Content for Advanced Speech-Based HCI","J. Liu; S. Seneff; V. Zue","Comput. Sci. &amp; Artificial Intell. Lab., Massachusetts Inst. of Technol., Cambridge, MA, USA","IEEE Journal of Selected Topics in Signal Processing","20130103","2012","6","8","982","992","There are many Web-based platforms where people could share user-generated content such as reviews, posts, blogs, and tweets. However, online communities and social networks are expanding so rapidly that it is impossible for people to digest all the information. To help users obtain information more efficiently, both the interface for data access and the information representation need to be improved. An intuitive and personalized interface, such as a dialogue system, could be an ideal assistant, which engages a user in a continuous dialogue to garner the user's interest, assists the user via speech-navigated interactions, harvests and summarizes the Web data as well as presenting it in a natural way. This work, therefore, aims to conduct research on a universal framework for developing a speech-based interface that can aggregate user-generated content and present the summarized information via speech-based human-computer interactions. The challenge is two-fold. Firstly, how to interpret the semantics and sentiment of user-generated data and aggregate them into structured yet concise summaries? Secondly, how to develop a dialogue modeling mechanism to present the highlighted information via natural language? This work explores plausible approaches to tackling these challenges. We will investigate a parse-and-paraphrase paradigm and a sentiment scoring mechanism for information extraction from unstructured user-generated content. We will also explore sentiment-involved opinion summarization and dialogue modeling approaches for aggregated information representation. A restaurant-domain prototype system has been implemented for demonstration.","1932-4553;19324553","","10.1109/JSTSP.2012.2229690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359745","Spoken dialogue systems;user-generated content processing","Human computer interaction;Information representation;Information retrieval;Prototypes;Social network services;User interfaces;User-generated content","Internet;human computer interaction;programming language semantics;social networking (online);speech processing","Web-based platform;advanced speech-based HCI;aggregated information representation extraction;continuous dialogue system;data access interface;data aggregation;dialogue modeling mechanism;human-computer interaction;online community;parse-and-paraphrase paradigm;restaurant-domain prototype system;sentiment scoring mechanism;sentiment-involved opinion summarization;social network;speech-navigated interaction;user-generated content","","2","","33","","20121121","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Query translation for CLIR: EWC vs. Google Translate","V. Klyuev; Y. Haralambous","University of Aizu, Aizu-Wakamatsu Fukushima - ken 965-8580, Japan","2012 IEEE International Conference on Information Science and Technology","20120621","2012","","","707","711","A new approach to find accurate translation of search engine queries from Japanese into English for the CLIR task is proposed. The Mecab system and online dictionary SPACEALC are utilized to segment Japanese queries and to get all possible English senses for every term detected. To disambiguate terms, the idea of the shortest path on an oriented graph is applied. Nodes of this graph symbolize word senses and edges connect nodes representing neighboring Japanese terms. The EWC semantic relatedness measure is used to select the most related meanings for the translation results. This measure combines the Wikipedia-based Explicit Semantic Analysis measure, the WordNet path measure and the mixed collocation index. The proposed technique is tested on the NTCIR data collection. Queries generated by Google Translate were used to evaluate the quality of translation.","2164-4357;21644357","Electronic:978-1-4577-0345-4; POD:978-1-4577-0343-0","10.1109/ICIST.2012.6221738","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6221738","","Electronic publishing;Encyclopedias;Google;Information retrieval;Internet;Semantics","dictionaries;language translation;query processing;search engines","CLIR task;EWC semantic relatedness measure;English senses;Google translate;Japanese queries;Mecab system;NTCIR data collection;Wikipedia-based explicit semantic analysis measure;cross-language information retrieval;mixed collocation index;neighboring Japanese terms;online dictionary SPACEALC;oriented graph;query translation;search engine queries;shortest path;word senses","","0","","21","","","23-25 March 2012","","IEEE","IEEE Conference Publications"
"Automated Segmentation of Folk Song Field Recordings","M. Mueller; P. Grosche","","Speech Communication; 10. ITG Symposium","20120925","2012","","","1","4","In this paper, we introduce an automated procedure for segmenting a given folk song field recording into its constituent stanzas. One challenge arises from the fact that these recordings are performed by elderly non-professional singers under poor recording conditions such that the constituent stanzas may reveal significant temporal and spectral deviations. Unlike a previously described segmentation approach that relies on a manually transcribed reference stanza, we introduce a reference-free segmentation procedure, which is driven by an audio thumbnailing procedure in combination with enhanced similarity matrices. Our experiments on a Dutch folk song collection show that our segmentation results are comparable to the ones obtained by the reference-based method.","","Paper:978-3-8007-3455-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6309607","","Frequency estimation;Materials;Music information retrieval;Robustness;Smoothing methods;Speech;USA Councils","","","","0","","","","","26-28 Sept. 2012","","VDE","VDE Conference Publications"
"Mobilizing search of the here and now","J. Michel","Department of Electrical and Computer Engineering, University of Texas at Austin","2012 IEEE International Conference on Pervasive Computing and Communications Workshops","20120510","2012","","","544","545","The escalating number of digitally-accessible devices pervading our everyday environments gives rise to the availability of tremendous amounts of human- and device-generated data. This data possesses strong spatial and temporal semantics, it captures phenomena and states of the environment, and is extremely volatile, being created, moved, stored, and deleted on-demand at rapid rates. The requisite support for general-purpose expressive search of the “here” and “now” has eluded realization due to the complexities of indexing, storing, and retrieving relevant information within a vast collection of highly ephemeral data. We aim to address this gap in the research (i) through search mechanisms that are sensitive to the bearings of space and time on the relevance of search results and (ii) more fundamentally, through the design of a general-purpose data model that facilitates information availability in pervasive computing environments and exposes spatial and temporal relationships between digital data and physical phenomena. Finally, this paper outlines simulation and deployment evaluations of the proposed research.","","Electronic:978-1-4673-0907-3; POD:978-1-4673-0905-9","10.1109/PerComW.2012.6197566","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197566","","Data models;Humans;Information retrieval;Internet;Mobile communication;Pervasive computing;Spatiotemporal phenomena","indexing;information retrieval;storage management;ubiquitous computing","digital data;digitally-accessible devices;general-purpose data model;general-purpose expressive search;here;human-and device-generated data;information availability facilitation;information indexing;information retrieval;information storage;now;pervasive computing environments;physical phenomena;search mechanisms;search mobilization;spatial semantics;temporal semantics","","0","","10","","","19-23 March 2012","","IEEE","IEEE Conference Publications"
"Toward a New Search Paradigm-Can We Learn from Ants?","A. Malizia; K. A. Olsen","Universidad Carlos III de Madrid, Spain","Computer","20120509","2012","45","5","89","91","Modeling Web users as virtual ants offers a promising new solution to the challenge of information-retrieval optimization.","0018-9162;00189162","","10.1109/MC.2012.182","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197785","ant colony optimization;social computing;social search","Ant colony optimization;Information retrieval;Search methods;Social network services;Virtual environments","Internet;information retrieval;optimisation","Web users modeling;information-retrieval optimization;search paradigm;virtual ants","","0","","","","","May 2012","","IEEE","IEEE Journals & Magazines"
"A Combined Music Label Propagation Model","J. Cai; H. Li; B. Lang","State Key Lab. of Software Dev. Environ., Beihang Univ., Beijing, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","1251","1255","Music labels, especially those related to high level semantics are very useful in music retrieval and recommendation, but normally hard to acquire. In the submission to ISMIR'07, Mohamed Sordo proposed a novel model, i.e., propagation of labels, to annotate music with existing labels, by using the content-based music similarity distance. In that model, a partially annotated collection with a lot of non-labeled music was annotated at a high precision and recall. In this paper, we proposed a new model -- label probability prediction model -- and introduce it into the Sordo's work, which makes a combined model, to improve the accuracy of propagation without exploiting any other information. In addition, we also made some modifications to the original Sordo's model that could make the algorithm works better. Then we compare the result of combined model to that yielded by the original on a publicly accessible ground truth data, and find that, the new approach can reach a higher recall. Furthermore, with the same recall, our method obtains a better precision.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128439","content-based similarity;music label;propagation model","Computational modeling;Internet;Music;Music information retrieval;Prediction algorithms;Predictive models;Semantics","information retrieval;music;recommender systems","combined music label propagation model;content based music similarity distance;model label probability prediction model;music annotation;music recommendation;music retrieval;publicly accessible ground truth data","","0","","9","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"Augmenting Mobile Search Engines to Leverage Context Awareness","E. Yndurain; D. Bernhardt; C. Campo","Universidad Carlos III Madrid","IEEE Internet Computing","20120301","2012","16","2","17","25","Mobile phones are becoming the chosen platforms for web access, with a forecast that over the coming decade more users will connect to the internet through mobile than conventional desktop computers. Internet search is likely going to remain one of the major ways to find information and services on the web. In order to provide satisfactory usability, mobile searches will have to take into consideration the nature of handsets. Being both pervasive and person-centric they continuously capture information about users and their context. Context awareness can enhance the mobile search experience by augmenting user queries with context information captured through the handset's sensors. In this paper we propose a unified architecture supporting context-awareness in mobility and show how it can be applied to mobile searches. Based on real life contextual data captured from handsets we discuss design approaches and end-user benefits of making mobile searches more context-aware.","1089-7801;10897801","","10.1109/MIC.2012.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133261","mobile communication systems;search process;ubiquitous computing","Augmented reality;Context modeling;Information retrieval;Internet;Mobile communication;Mobile handsets;Search engines;Web and internet services","Internet;mobile computing;mobile handsets;query processing;search engines","Internet search;Web access;Web service finding;context awareness leveraging;desktop computer;handset sensor;information finding;mobile phones;mobile search engines;person-centric computing;pervasive computing;usability;user query augmentation","","8","2","14","","20120117","March-April 2012","","IEEE","IEEE Journals & Magazines"
"An efficient method for estimating the area of information propagation through electromagnetic radiation","Y. i. Hayashi; N. Homma; T. Ikematsu; T. Mizuki; T. Aoki; H. Sone; J. L. Danger","Tohoku University, 6-6-3 Aramaki Aza, Sendai 980-8579, Japan","2012 IEEE International Symposium on Electromagnetic Compatibility","20121110","2012","","","800","805","Information leakage in the form of electromagnetic (EM) radiation is an emerging security issue for designers and users of electronic devices. The importance of estimating the propagation area of EM responsible for information leakage is increasing due to the high demand for protecting such devices from eavesdropping. In this paper, we propose an efficient method for estimating the propagation area of EM responsible for information leakage. The proposed idea is to examine the temporal variance of noise in the area of interest in addition to the source intensity and the transfer function. We also show that the information acquired by the proposed method is in close agreement with the actual information acquired in an area of interest by measuring leaked EM radiation.","2158-110X;2158110X","Electronic:978-1-4673-2060-3; POD:978-1-4673-2061-0","10.1109/ISEMC.2012.6351662","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6351662","","Cryptography;Current measurement;Information retrieval;Noise measurement;Signal to noise ratio;Transfer functions","electrical faults;electromagnetic waves;magnetic leakage","EM radiation;EM responsible;electromagnetic radiation;information leakage;information propagation;source intensity;temporal variance;transfer function","","0","","16","","","6-10 Aug. 2012","","IEEE","IEEE Conference Publications"
"Centroid Integer Selection Model -- A High Efficiency Method on Dynamic Multi-document Summarization","M. Liu; D. Zheng; T. Zhao; Y. Yu","Machine Intell. & Lranslation Lab., Harbin Inst. of Lechnology, Harbin, China","2011 International Conference on Asian Language Processing","20120102","2011","","","150","153","This paper researches centroid integer selection based on dynamic multi-document summarization (DMS) and presentes a dynamic multi-document summarization model, called Centroid Integer Selection Model (CISM). This model has mainly two steps. First, some abstracts were extracted from the document sets based on different first sentence, respectively. Second, the best abstract was selected based on centroid strategy from all the abstracts created in the first step. The best advantage this model showed was that it eliminated the effect caused by falsely selecting based on the first sentence. Some experiments were conducted on the Update Task test data from TAC2008, and results of new model were compared with results from the TAC2008 evaluation.","","Electronic:978-0-7695-4554-7; POD:978-1-4577-1733-8","10.1109/IALP.2011.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121491","Centroid Integer Selection;Dynamic;multi-document","Abstracts;Computational modeling;Current measurement;Electronic mail;Information retrieval;Laboratories;Silicon","document handling","TAC2008 evaluation;abstract extraction;centroid integer selection model;high efficiency dynamic multidocument summarization method","","0","","7","","","15-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"An Efficient Query-by-Singing/Humming System Based on Fast Fourier Transforms of Note Sequences","W. H. Tsai; Y. M. Tu","Dept. of Electron. Eng., Nat. Taipei Univ. of Technol., Taipei, Taiwan","2012 IEEE International Conference on Multimedia and Expo","20120913","2012","","","521","525","This paper presents a query-by-singing/humming method that enables fast melody comparison. The basic idea is to measure the distances between note sequences in the frequency domain instead of time domain. Thanks to the merit of fast Fourier transform, we can convert different-length note sequences into equal-dimension vectors via zero padding. The equal dimensionality allows us to compare the vectors using Euclidean distance directly, which avoids performing time-consuming alignment between sequences. To take both efficiency and effectiveness into account, the proposed fast melody comparison method is combined with dynamic time warping technique into a two-stage sequence matching system. Our experiments conducted using the MIREX 2006 database demonstrate the feasibility of the proposed system.","1945-7871;19457871","Electronic:978-0-7695-4711-4; POD:978-1-4673-1659-0","10.1109/ICME.2012.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298454","dynamic time warping;fast Fourier transform;query-by-humming;query-by-singing","Complexity theory;Databases;Fast Fourier transforms;Frequency measurement;Multimedia communication;Music information retrieval;Vectors","audio signal processing;distance measurement;fast Fourier transforms;frequency-domain analysis;music;pattern matching;query processing;time-domain analysis","Euclidean distance;MIREX 2006 database;distance measurement;dynamic time warping;equal-dimension vector;fast Fourier transform;fast melody comparison;frequency domain;note sequence;query-by-singing/humming system;time domain;two-stage sequence matching system;zero padding","","1","","","","","9-13 July 2012","","IEEE","IEEE Conference Publications"
"The System Architecture for the Basic Information of Science and Technology Experts Based on Distributed Storage and Web Mining","Q. Zhu; P. Zhou","Fac. of Comput. Eng., Huaiyin Inst. of Technol., Huaiyin, China","2012 International Conference on Computer Science and Service System","20121231","2012","","","527","530","In order to build an efficient basic information system of science and technology experts based on Web mining, a novel system architecture for application is proposed in this paper. The proposed system architecture integrates spider module, local distributed storage and Mongo-DB. The basic experts information of science and technology appeared in the Websites are synthesized as two format and using two strategies to deal with it respectively. The normalized texts which extracted from Web page by URLs are suggested. The extracted results include the name, sex, birth, hometown and professional title of science and technology experts respectively. The data stream flow, the information management model for the users and science and technology experts, the target website URLs and URLs management model, and data processing module are introduced in detailed. The synchronization of multiple databases and replica sets architecture for sharing cluster architecture is proposed in application system. Experiments show that the application system obtains a very high efficiency. The results show as by proposed system architecture can satisfy the application requirements for the customer.","","Electronic:978-0-7695-4719-0; POD:978-1-4673-0721-5","10.1109/CSSS.2012.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394376","Mongo-DB;Web mining;distributed storage;science and technology experts;sharing cluster architecture;spider module;systen architecture","Computer architecture;Data processing;Databases;Educational institutions;Information management;Information retrieval;Web mining","Web sites;data mining;information management;information retrieval;information systems;replicated databases;software architecture;storage management","Mongo-DB;URL management model;Web Mining;Web page;Web sites;basic information system;cluster architecture sharing;data processing module;data stream flow;information management model;local distributed storage;multiple database synchronization;replica sets architecture;science-and-technology experts;spider module;system architecture","","2","","15","","","11-13 Aug. 2012","","IEEE","IEEE Conference Publications"
"iSimp: A sentence simplification system for biomedicail text","Y. Peng; C. O. Tudor; M. Torii; C. H. Wu; K. Vijay-Shanker","Comput. &amp; Inf. Sci., Univ. of Delaware, Newark, DE, USA","2012 IEEE International Conference on Bioinformatics and Biomedicine","20121224","2012","","","1","6","Text mining applications using natural language processing are often confronted with long and complicated sentences. This is observed particularly in the abstracts of scientific articles where authors summarize, in few sentences, the various facts described throughout the manuscript. Being rich in novel and important information, the abstract has been the primary target of biomedicai text mining applications. In this work, we aim to simplify complex sentences in abstracts of biomedicai text so that they can be readily processed by text mining applications. We focus on syntactic constructs that are frequently encountered in the biomedicai literature, such as coordinations, relative clauses, and appositions, with emphasis on their boundary detection. Our approach yielded good detection performance (average F-measure between 86.5% and 92.7%), and aided in improving biomedicai text mining applications, RLIMS-P and Rank<sub>Pref</sub>.","","Electronic:978-1-4673-2560-8; POD:978-1-4673-2559-2","10.1109/BIBM.2012.6392671","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392671","information extraction;natural language processing;sentence simplification;text mining","Abstracts;Information retrieval;Natural language processing;Proteins;Substrates;Syntactics;Text mining","data acquisition;data mining;medical computing;natural language processing;text analysis;word processing","RLIMS-P;RankPref;abstracts;appositions;biomedicai text mining applications;boundary detection;coordinations;detection performance;iSimp;natural language processing;relative clauses;scientific articles;sentence simplification system","","6","","16","","","4-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"Research on XML Element Search Results Clustering","M. J. Zhong; C. X. Wan; D. X. Liu; X. P. Jiao","Sch. of Inf. Technol., Jiangxi Univ. of Finance & Econ., Nanchang, China","2012 International Conference on Management of e-Commerce and e-Government","20121206","2012","","","285","290","Clustering XML search results is an effective way to improve performance. However, the key problem is how to measure similarity between XML documents. This paper studies XML search results clustering based on element granularity and proposes one similarity measurement method. The method firstly uses latent semantic indexing technology(LSI) to obtain term semantics and then combines the XML element node content and semantic structure properties(CASS). To evaluate clustering performance, two new performance evaluation methodologies, namely R_ClusterRatio and R_DocuRatio are introduced. It is motivated by the observations of relevant documents distribution and the fact that the experiment data collection, IEEE CS corpus, do not provide classification information. Experiment results show that proposed similarity method combining term semantics with content and structure semantics integration(LSI-CASS) is feasible, and it produces better clustering quality than LSI-CAS.","","Electronic:978-0-7695-4853-1; POD:978-1-4673-2943-9","10.1109/ICMeCG.2012.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374926","XML element clustering;content and structure semantic;term semantics","Indexing;Information retrieval;Large scale integration;Matrix decomposition;Semantics;Singular value decomposition;XML","XML;pattern clustering","XML documents;XML element node content;XML element search results clustering;classification information;clustering performance;clustering quality;element granularity;latent semantic indexing technology;performance evaluation methodology;semantic structure properties;similarity measurement method;structure semantics integration","","0","","16","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"MedlinePlus Connect: Linking Health IT Systems to Consumer Health Information","W. Ma; S. Dennis; S. Lanka; N. Miller; J. Potvin","US National Library of Medicine","IT Professional","20120523","2012","14","3","22","28","The National Library of Medicine's MedlinePlus Connect service extends the reach of the consumer health website MedlinePlus.gov to deliver relevant information to patients and providers via health IT systems, electronic health records, and patient portals.","1520-9202;15209202","","10.1109/MITP.2012.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143913","MedlinePlus Connect;electronic data interchange;electronic health records;health IT;services computing","Information retrieval;Libraries;Medical diagnostic imaging;Medical information systems;Search engines;Standards organizations;Web services","Web sites;health care","MedlinePlus Connect service;National Library of Medicine;consumer health Website;consumer health information;electronic health records;health IT systems;patient portals","","1","","8","","20120131","May-June 2012","","IEEE","IEEE Journals & Magazines"
"Locating features in dynamically configured avionics software","M. Ouellet; E. Merlo; N. Sozen; M. Gagnon","Computer and Software Engineering Department, &#x00C9;cole Polytechnique de Montr&#x00E9;al, Montr&#x00E9;al, Canada","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1453","1454","Locating features in software is an important activity for program comprehension and to support software reengineering. We present a novel automated approach to locate features in source code based on static analysis and model checking. The technique is aimed at dynamically configured software, which is software in which the activation of specific features is controlled by configuration variables. The approach is evaluated on an industrial avionics system.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227068","Feature;Feature Location;Feature Mapping;Program Comprehension;Reengineering","Aerospace electronics;Aircraft;Analytical models;Feature extraction;Information retrieval;Security;Software","avionics;formal verification;program diagnostics;systems re-engineering","configuration variables;feature location;industrial avionics system;model checking;program comprehension;software reengineering;source code;static analysis","","0","","8","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Matchmaking through semantic annotation and similarity measurement","A. Ensan; Y. Biletskiy","University of New Brunswick, Fredericton, Canada","2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20121022","2012","","","1","5","The proposed work briefly describes an approach to automatically extract structured information from semi-structured documents to match the document creators and users in order to find the best similarities between them and connect them for further collaborations. The general idea is to employ a semantic annotation technique and similarity measurement approach by using the ontology to find best matches between web documents. The proposed approach uses ontologies to annotate the extracted information and for the measuring the similarity between each pair of documents. GATE (General Architecture for Text Engineering) as one of the most famous annotation tools has been utilized to annotate semi-structure documents. A novel algorithm is proposed to update the supported ontology for extraction purpose in GATE by using a training data set. Furthermore, specific domain-based metrics are also utilized to measure semantic similarities between documents with regard to semantic annotations which are implemented in an ontology-based approach. These metrics can be used in order to find the most similar web documents among documents corpus.","0840-7789;08407789","Electronic:978-1-4673-1433-6; POD:978-1-4673-1431-2","10.1109/CCECE.2012.6334966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6334966","Computer Applications;Information Extraction;Matchmaking;Ontology;Semantic Annotation;Semantic Similarity","Data mining;Information retrieval;Logic gates;Ontologies;Semantics;Vectors;XML","groupware;ontologies (artificial intelligence);text analysis","GATE;Web documents;collaborations;document creator-user matching;domain-based metrics;general architecture for text engineering;matchmaking;ontology-based approach;semantic annotation technique;semistructure document annotation;semistructured documents;similarity measurement approach;structured information extraction;training data set","","1","","14","","","April 29 2012-May 2 2012","","IEEE","IEEE Conference Publications"
"Using the Dempster-Shafer theory of evidence to rank documents","J. Zhang; B. Deng; X. Li","Department of Electronic Engineering, Tsinghua University, Beijing 100084, China","Tsinghua Science and Technology","20120615","2012","17","3","241","247","Multi-source information can be utilized collaboratively to improve the performance of information retrieval. To make full use of the document and collection information, this paper introduces a new information retrieval model that relies on the Dempster-Shafer theory of evidence. Each query-document pair is taken as a piece of evidence for the relevance between a document and a query. The evidence is combined using Dempster's rule of combination, and the belief committed to the relevance is obtained. Retrieved documents are then ranked according to the belief committed to the relevance. Several basic probability assignments are also proposed. Extensive experiments over the Text REtrieval Conference (TREC) test collection ClueWeb09 show that the proposed model provides performance similar to that of the Vector Space Model (VSM). Under certain probability assignments, the proposed model outperforms the VSM by 63% in terms of mean average precision.","","","10.1109/TST.2012.6216753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216753","Dempster's rule of combination;Dempster-Shafer theory of evidence;basic probability assignment","Abstracts;Collaboration;Indexing;Information analysis;Information retrieval;Probabilistic logic","","","","0","","","","","June 2012","","TUP","TUP Journals & Magazines"
"A Cloud Computing Service for managing biomedical image collections","R. Alonso-Calvo; J. Crespo; M. Muñoz-Mármol; M. Intriago; A. Jimenez-Castellanos","DLSIIS, Univ. Politec. de Madrid, Madrid, Spain","2012 25th IEEE International Symposium on Computer-Based Medical Systems (CBMS)","20120830","2012","","","1","6","A huge quantity of biomedical images is generated every day. Building effective and agile systems for managing these collections has become an important and expensive issue for hospitals and institutions. In this paper we present a cloud computing service and its application for the storage and analysis of large image collections, specifically for very-large images. This Cloud Computing Service allows users to manage image collections in a relatively low-cost manner. The service is internally implemented by a balanced multiagent system. A novel aspect of the system is that one image could be divided in several, and those can then be stored and managed separately. This feature improves performance in data processing and information retrieval.","1063-7125;10637125","Electronic:978-1-4673-2051-1; POD:978-1-4673-2049-8","10.1109/CBMS.2012.6266401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266401","","Biomedical imaging;Cloud computing;Data structures;Databases;Image color analysis;Information retrieval;Prototypes","cloud computing;content-based retrieval;image retrieval;medical computing;multi-agent systems","balanced multiagent system;biomedical image collection management;cloud computing service;content-based image retrieval;data processing;information retrieval;large image collection analysis;large image collection storage;very-large images","","0","","18","","","20-22 June 2012","","IEEE","IEEE Conference Publications"
"Duplicate-Search-Based Image Annotation Using Web-Scale Data","X. J. Wang; L. Zhang; W. Y. Ma","Microsoft Research Asia, Haidian District, Beijing, China","Proceedings of the IEEE","20120816","2012","100","9","2705","2721","Easy photo-taking and photo-sharing today make image an increasingly important type of media in people's everyday life, which arouses a growing demand for a practical image understanding technique. Traditional computer vision or machine learning methods which learn models based on a set of training data are still in the stage of tackling hundreds of object categories. Such a scale is far from practical usage. In recent years, the technique of search-based image annotation on a large-scale data set has demonstrated great success. Rather than directly mapping visual features to texts which is inevitably hindered by the semantic gap, it understands the content of an image by propagating labels of its similar images in a large-scale data set. Since similarity search is performed among homogenous data, the difficulty is greatly reduced. This paper summarizes the extensive work on web image annotation using the large-scale metadata and social information available on the Web, and introduces the Arista system, which is a nonparametric image annotation platform built upon two billion web images. We propose a highly efficient and scalable duplicate-search technique so that the Arista system can be deployed on a few servers. A few interesting applications such as building large-scale celebrity face database and text-to-image translation are also presented in this paper.","0018-9219;00189219","","10.1109/JPROC.2012.2193109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6210348","Automatic image annotation;duplicate-search-based image annotation","Databases;Feature extraction;Image classification;Information retrieval;Measurement;Semantics;Text mining","","","","8","","46","","20120601","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"On the Helmholtz Principle for Data Mining","B. Dadachev; A. Balinsky; H. Balinsky; S. Simske","Cardiff Sch. of Math., Cardiff Univ., Cardiff, UK","2012 Third International Conference on Emerging Security Technologies","20121011","2012","","","99","102","Unusual behaviour detection and information extraction in streams of short documents and files (emails, news, tweets, log files, messages, etc.) are important problems in security applications. In [1], [2], a new approach to rapid change detection and automatic summarization of large documents was introduced. This approach is based on a theory of social networks and ideas from image processing and especially on the Helmholtz Principle from the Gestalt Theory of human perception. In this article we modify, optimize and verify the approach from [1], [2] to unusual behaviour detection and information extraction from small documents.","","Electronic:978-0-7695-4791-6; POD:978-1-4673-2448-9","10.1109/EST.2012.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6328011","Helmholtz Principle;Keywords Extraction;Small-World Networks;Summarization;Unusual Behaviour Detection","Containers;Data mining;Electronic mail;Humans;Information retrieval;Measurement;Security","data mining;document handling;security of data;social networking (online)","Gestalt human perception theory;Helmholtz principle;change detection;data mining;files stream;image processing;information extraction;large document automatic summarization;security applications;short document stream;social networks theory;unusual behaviour detection","","3","","12","","","5-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Accelerating query by singing/humming on GPU: Optimization for web deployment","C. C. Wang; C. H. Chen; C. Y. Kuo; L. T. Chiu; J. S. R. Jang","Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","477","480","This paper presents the use of GPU for implementing a parallelized comparison method of linear scaling in a query by singing/humming system, which can compare a user's acoustic input to the database containing about 13,000 songs. We focus on the comparison from anywhere in a song, and the optimum setting is found through 3 different schemes of parallelization. With a speedup factor of 66, the proposed scheme with the optimum setting has been successfully implemented in a public QBSH system that is available from the internet.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6287920","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6287920","GPU;Music retrieval;Query-bysinging/humming;linear scaling","Acceleration;Computer architecture;Databases;Graphics processing unit;Instruction sets;Music information retrieval;Vectors","Internet;acoustic signal processing;graphics processing units;optimisation;parallel processing;query processing","GPU;Internet;Web deployment;accelerating query;humming system;linear scaling;optimization;parallelization;parallelized comparison method;public QBSH system;singing system;user acoustic input","","3","","11","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Research on semantic environment-based annotation techniques for knowledge semantic","Cai Yingfang","School of economics and management, Beijing University of Aeronautics & Astronautics, China 100191","2012 International Conference on Information Management, Innovation Management and Industrial Engineering","20121025","2012","1","","527","530","This paper puts forward the Semantic Environment-based Annotation Techniques for Knowledge Semantic in allusion to the problem in dealing with synonymy and in neglecting semantic environment. It improves the Algorithm on key link of ontology annotation. It is from two way that when calculating the correlation degree of word & document, one is to calculate the correlation degree of the “Example Annotation-Document”, the other hand is to calculate the co expression of the “semantic environment”. The efficiency of the annotation had been significantly increased through improving of Algorithm.","2155-1456;21551456","Electronic:978-1-4673-1931-7; POD:978-1-4673-1932-4","10.1109/ICIII.2012.6339719","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339719","knowledge extractive;semantic annotation;semantic environment","Contracts;Equations;Information retrieval;Knowledge based systems;Mathematical model;Ontologies;Semantics","ontologies (artificial intelligence)","example annotation-document;knowledge semantic;ontology annotation;semantic environment-based annotation technique;synonymy","","0","","10","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"Multiple Feature-Classifier Combination in Automated Text Classification","L. S. P. Busagala; W. Ohyama; T. Wakabayashi; F. Kimura","Sokoine Nat. Agric. Libr., Sokoine Univ. of Agric., Morogoro, Tanzania","2012 10th IAPR International Workshop on Document Analysis Systems","20120507","2012","","","43","47","Automatic text classification (ATC) is important in applications such as indexing and organizing electronic documents in databases leading to enhancement of information access and retrieval. We propose a method which employs various types of feature sets and learning algorithms to improve classification effectiveness. Unlike the conventional methods of multi-classifier combination, the proposed method considers the contributions of various types of feature sets and classifiers. It can therefore be known as multiple feature-classifier combination (MFC) method. In this paper we present empirical evaluation of MFC using two benchmarks of text collections to determine its effectiveness. Empirical evaluation show that MFC consistently outperformed all compared methods.","","Electronic:978-0-7695-4661-2; POD:978-1-4673-0868-7","10.1109/DAS.2012.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6195332","Feature reduction;Feature-Classifier Combination;Multi-classifier combination;Text Classification/Categorization;ensembles","Information retrieval;Machine learning;Principal component analysis;Support vector machines;Text categorization;Training;Vectors","learning (artificial intelligence);pattern classification;text analysis","automated text classification;classification effectiveness;electronic document;feature set;information access;information retrieval;learning algorithm;multiple feature-classifier combination;text collection","","0","2","23","","","27-29 March 2012","","IEEE","IEEE Conference Publications"
"Combining a segmentation-like approach and a density-based approach in content extraction","S. Lin; J. Chen; Z. Niu","School of Computer Science, Beijing Institute of Technology, Beijing 100081, China","Tsinghua Science and Technology","20120615","2012","17","3","256","264","Density-based approaches in content extraction, whose task is to extract contents from Web pages, are commonly used to obtain page contents that are critical to many Web mining applications. However, traditional density-based approaches cannot effectively manage pages that contain short contents and long noises. To overcome this problem, in this paper, we propose a content extraction approach for obtaining content from news pages that combines a segmentation-like approach and a density-based approach. A tool called BlockExtractor was developed based on this approach. BlockExtractor identifies contents in three steps. First, it looks for all Block-Level Elements (BLE) & Inline Elements (IE) blocks, which are designed to roughly segment pages into blocks. Second, it computes the densities of each BLE&IE block and its element to eliminate noises. Third, it removes all redundant BLE&IE blocks that have emerged in other pages from the same site. Compared with three other density-based approaches, our approach shows significant advantages in both precision and recall.","","","10.1109/TST.2012.6216755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216755","content extraction;density-based approach;segmentation","HTML;Information analysis;Information retrieval;Noise measurement;Text mining;Training;Web mining;Web pages","","","","1","","","","","June 2012","","TUP","TUP Journals & Magazines"
"A Boosting, Sparsity- Constrained Bilinear Model for Object Recognition","C. Zhang; J. Liu; Q. Tian; Y. Han; H. Lu; S. Ma","National Lab of Pattern Recognition, Chinese Academy of Sciences","IEEE MultiMedia","20120427","2012","19","2","58","68","Using higher-level visual elements to represent images, the authors have developed a sparsity-constrained bilinear model (SBLM) and have combined a set of SBLMs in a boosting-like procedure to enhance performance.","1070-986X;1070986X","","10.1109/MMUL.2011.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740827","computer vision;image processing;image/video retrieval;multimedia;object recognition","Adaptation model;Computer vision;Image processing;Image representation;Information retrieval;Object recognition;Robustness;Video communication;Visualization","image representation;object recognition","SBLM;boosting-like procedure;higher-level visual elements;image representation;object recognition;sparsity-constrained bilinear model","","12","","17","","20110405","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Design and research on network teaching platform of document retrieval course","J. Zhang; X. Li","Institute of Documentation and Information, Shandong University of Science and Technology, Taian, China","2012 International Conference on Systems and Informatics (ICSAI2012)","20120625","2012","","","1183","1186","Compared with the traditional teaching mode, the use of the network teaching platform of document retrieval course has many compelling advantages. The network teaching platform of document retrieval course should be designed to constructivism learning theory as the foundation and basis and implement principles of openness, interactivity, dynamic, and maintainability, and so on. Thus it sets up a “learner centered” main framework with its own characteristics full of Microsoft's technology. The framework of document retrieval course network teaching platform includes the following subsystems, network classroom, communication consultation, exam evaluation, and teaching management. They do their own work and cooperate closely to complete the revolutionary evolution of the document retrieval course teaching mode under network environment.","","Electronic:978-1-4673-0199-2; POD:978-1-4673-0198-5","10.1109/ICSAI.2012.6223245","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223245","document retrieval course;library;network teaching platform;university","Educational institutions;Information retrieval;Internet;Knowledge engineering;Libraries;Navigation","Internet;computer aided instruction;educational courses;information retrieval;teaching","Microsoft technology;communication consultation;constructivism learning theory;document retrieval course network teaching platform;document retrieval course teaching mode;exam evaluation;learner centered main framework;network classroom;network environment;revolutionary evolution;teaching management","","0","","7","","","19-20 May 2012","","IEEE","IEEE Conference Publications"
"One Size Does Not Fit All: Toward User- and Query-Dependent Ranking for Web Databases","A. Telang; C. Li; S. Chakravarthy","University of Texas at Arlington, Arlington","IEEE Transactions on Knowledge and Data Engineering","20120723","2012","24","9","1671","1685","With the emergence of the deep web, searching web databases in domains such as vehicles, real estate, etc., has become a routine task. One of the problems in this context is ranking the results of a user query. Earlier approaches for addressing this problem have used frequencies of database values, query logs, and user profiles. A common thread in most of these approaches is that ranking is done in a user- and/or query-independent manner. This paper proposes a novel query- and user-dependent approach for ranking query results in web databases. We present a ranking model, based on two complementary notions of user and query similarity, to derive a ranking function for a given user query. This function is acquired from a sparse workload comprising of several such ranking functions derived for various user-query pairs. The model is based on the intuition that similar users display comparable ranking preferences over the results of similar queries. We define these similarities formally in alternative ways and discuss their effectiveness analytically and experimentally over two distinct web databases.","1041-4347;10414347","","10.1109/TKDE.2011.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710921","Automated ranking;query similarity;user similarity;web databases;workload","Context awareness;Databases;Image color analysis;Information retrieval;Mathematical model;Search methods;Web services","","","","3","","35","","20110210","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Analysis and evaluation of unstructured data: text mining versus natural language processing","F. S. Gharehchopogh; Z. A. Khalifelu","Hacettepe University Department, Computer Engineering, Ankara, Turkey","2011 5th International Conference on Application of Information and Communication Technologies (AICT)","20111222","2011","","","1","4","Nowadays, most of information saved in companies are as unstructured models. Retrieval and extraction of the information is essential works and importance in semantic web areas. Many of these requirements will be depend on the storage efficiency and unstructured data analysis. Merrill Lynch recently estimated that more than 80% of all potentially useful business information is unstructured data. The large number and complexity of unstructured data opens up many new possibilities for the analyst. We analyze both structured and unstructured data individually and collectively. Text mining and natural language processing are two techniques with their methods for knowledge discovery form textual context in documents. In this study, text mining and natural language techniques will be illustrated. The aim of this work comparison and evaluation the similarities and differences between text mining and natural language processing for extraction useful information via suitable themselves methods.","","Electronic:978-1-61284-832-7; POD:978-1-61284-831-0","10.1109/ICAICT.2011.6111017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111017","","Databases;Information retrieval;Natural language processing;Pragmatics;Text categorization;Text mining","business data processing;computational complexity;data analysis;data mining;information retrieval;information storage;semantic Web;text analysis","business information;document handling;information extraction;information retrieval;knowledge discovery;natural language processing;semantic Web;storage efficiency;text mining;textual context;unstructured data analysis;unstructured data complexity;unstructured data evaluation","","14","","32","","","12-14 Oct. 2011","","IEEE","IEEE Conference Publications"
"Integrating Recognition and Retrieval With Relevance Feedback for Spoken Term Detection","H. y. Lee; C. p. Chen; L. s. Lee","National Taiwan University","IEEE Transactions on Audio, Speech, and Language Processing","20120608","2012","20","7","2095","2110","Recognition and retrieval are typically viewed as two cascaded independent modules for spoken term detection (STD). Retrieval techniques are assumed to be applied on top of automatic speech recognition (ASR) output, with performance depending on ASR accuracy. We propose a framework that integrates recognition and retrieval and consider them jointly in order to yield better STD performance. This can be achieved either by adjusting the acoustic model parameters (model-based) or by considering detected examples (example-based) using relevance information provided by the user (user relevance feedback) or inferred by the system (pseudo-relevance feedback), either for a given query (short-term context) or by taking into account many previous queries (long-term context). Such relevance feedback approaches have long been used in text information retrieval, but are rarely considered and cannot be directly applied to the retrieval of spoken content. The proposed relevance feedback approaches are specific to spoken content retrieval and are hence very different from those developed for text retrieval, which are applied only to text symbols. We present not only these relevance feedback scenarios and approaches for STD, but also propose a framework to integrate them all together. Preliminary experiments showed significant improvements in each case.","1558-7916;15587916","","10.1109/TASL.2012.2196514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189746","Relevance feedback;spoken term detection","Accuracy;Acoustics;Information retrieval;Lattices;Multimedia communication;Speech;Speech recognition","acoustic signal processing;relevance feedback;speech recognition;text analysis","acoustic model parameter;automatic speech recognition;long-term context;pseudo-relevance feedback;short-term context;spoken content retrieval;spoken term detection;text information retrieval;text retrieval;user relevance feedback","","5","","74","","20120425","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Research on Ontology Instance Learning Based on Maximum Entropy Model","M. Zhang; W. Wang","Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China","2012 Fourth International Conference on Computational and Information Sciences","20120913","2012","","","45","48","Ontology Instance learning is a significant part in the research of ontology evolution and is important for the applications of ontology. One of the key points of ontology instance learning is automatic instances learning from large amounts of unstructured data. In this paper, an effective method of ontology instance learning is proposed, while the experience of the methods of information extraction and the structure of ontology model--introducing maximum entropy model to the study of learning ontology instances from free texts--are also focused. The experiment is based on the Chinese Toponym Ontology. Results show that rapid and effective ontology instance learning is available.","","Electronic:978-0-7695-4789-3; POD:978-1-4673-2406-9","10.1109/ICCIS.2012.250","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6300018","maximum entropy model;ontology instance learning","Computational modeling;Educational institutions;Entropy;Geography;Information retrieval;Learning systems;Ontologies","information retrieval;learning (artificial intelligence);maximum entropy methods;ontologies (artificial intelligence);text analysis","Chinese toponym ontology;free texts;information extraction;maximum entropy model;ontology instance learning;unstructured data","","0","","7","","","17-19 Aug. 2012","","IEEE","IEEE Conference Publications"
"A conceptual framework for an interactive personal information management system","M. R. A. Nasar; M. Mohd; N. M. Ali","Knowledge Technology Research Group, Universiti Kebangsaan Malaysia, Bangi, Selangor","2011 International Conference on User Science and Engineering (i-USEr )","20120213","2011","","","100","105","The growth of digital cameras has resulted in the creation of huge collections of personal photographs and video. Thus, in the last few years personal information management (PIM) has become an important topic in the information retrieval area, in which it is playing an interest role in managing and retrieving personal collections. Therefore, many previous studies have tried to visualize these collections in different ways. This paper aims to discuss the importance of visualization techniques that have been proposed in the PIM field in general, and it shows the main factors that have influence on visualizing an interactive PIM system interface for large collections of photographs and video in particular. The factors were identified through reviews of related work. The collated factors form a conceptual framework of interactive PIM system interfaces for photograph and video collections. The aim of the framework is to ensure full understanding about the personal information lifecycle and thus leads to the production of a PIM system that satisfies its intended users.","","Electronic:978-1-4577-1655-3; POD:978-1-4577-1654-6","10.1109/iUSEr.2011.6150545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150545","conceptual framework;information visualization;personal information lifecycle;personal information management","Data visualization;Filtering;Humans;Information management;Information retrieval;Visualization","cameras;data visualisation;information management;information retrieval;interactive systems;personal information systems","conceptual framework;digital cameras;information retrieval area;interactive personal information management system;personal collection management;personal collection retrieval;personal information lifecycle;personal photographs;personal video;visualization techniques","","0","","45","","","Nov. 29 2011-Dec. 1 2011","","IEEE","IEEE Conference Publications"
"Applying Ontology-Based Personal Profile for Product Search System","W. Rungworawut; S. Kachonsri","Dept. of Comput. Sci., Khon Kaen Univ., Khon Kaen, Thailand","2012 International Conference on Information Science and Applications","20120621","2012","","","1","5","Personal profile can be directly derived from personal registration before user uses product search system. However, this personal profile is not used in general product search system although the search product system is to require to present product user's needs. This paper proposes an approach of semantic product search system through ontological personal profiles. Using ontological personal profile is considered and helps filter of search results by semantic relationship and ontology mapping between personal profile and product details. Our experiments of the product search system show search results based on semantic mapping creation from ontological personal profile to relevant product. The evaluation of the system is measured by average precision, recall and F-measure that give a set of information retrieval by difference personal profiles.","2162-9048;21629048","DVD:978-1-4673-1400-8; Electronic:978-1-4673-1401-5; POD:978-1-4673-1402-2","10.1109/ICISA.2012.6220930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6220930","","Computer architecture;Image color analysis;Information retrieval;Mobile communication;Ontologies;Remuneration;Semantics","information retrieval;ontologies (artificial intelligence)","F-measure;average precision;information retrieval;ontology mapping;ontology-based personal profile;personal registration;recall;semantic product search system;semantic relationship","","0","","10","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"A TraceLab-based solution for creating, conducting, and sharing feature location experiments","B. Dit; E. Moritz; D. Poshyvanyk","Department of Computer Science, The College of William and Mary, Williamsburg, Virginia, USA","2012 20th IEEE International Conference on Program Comprehension (ICPC)","20120716","2012","","","203","208","Similarly to other fields in software engineering, the results of case studies involving feature location techniques (FLTs) are hard to reproduce, compare, and generalize, due to factors such as, incompatibility of different datasets, lack of publicly available implementation or implementation details, or the use of different metrics for evaluating FLTs. To address these issues, we propose a solution for creating, conducting, and sharing experiments in feature location based on TraceLab, a framework for conducting research. We argue that this solution would allow rapid advancements in feature location research because it will enable researchers to create new FLTs in the form of TraceLab templates or components, and compare them with existing ones using the same datasets and the same metrics. In addition, it will also allow sharing these FLTs and experiments within the research community. Our proposed solution provides (i) templates and components for creating new FLTs and instantiating existing ones, (ii) datasets that can be used as inputs for these FLTs, and (iii) metrics for comparing these FLTs. The proposed solution can be easily extended with new FLTs (in the form of easily configurable templates and components), datasets, and metrics.","1092-8138;10928138","Electronic:978-1-4673-1216-5; POD:978-1-4673-1213-4; USB:978-1-4673-1215-8","10.1109/ICPC.2012.6240489","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240489","TraceLab;benchmarks;experiments;feature location","Communities;Computer languages;Educational institutions;Gold;Information retrieval;Measurement;Software engineering","software engineering;software metrics","FLT evaluation metrics;TraceLab-based solution;case studies;feature location experiment creation;feature location experiment sharing;feature location technique;software engineering","","11","","12","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"Obtaining High-Quality Relevance Judgments Using Crowdsourcing","J. B. P. Vuurens; A. P. de Vries","The Hague University of Applied Science","IEEE Internet Computing","20121002","2012","16","5","20","27","The performance of information retrieval (IR) systems is commonly evaluated using a test set with known relevance. Crowdsourcing is one method for learning the relevant documents to each query in the test set. However, the quality of relevance learned through crowdsourcing can be questionable, because it uses workers of unknown quality with possible spammers among them. To detect spammers, the authors' algorithm compares judgments between workers; they evaluate their approach by comparing the consistency of crowdsourced ground truth to that obtained from expert annotators and conclude that crowdsourcing can match the quality obtained from the latter.","1089-7801;10897801","","10.1109/MIC.2012.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216343","crowdsourcing;judgment;quality;relevance;spam","Crowdsourcing;Detection algorithms;Information retrieval;Internet;Outsourcing;Query processing;Unsolicited electronic mail","document handling;information retrieval;outsourcing","IR systems;crowdsourcing;expert annotators;high-quality relevance judgments;information retrieval systems;learning method","","11","","18","","20120612","Sept.-Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Neural correlates of visual perception in rapid serial visual presentation paradigms","Y. Huang; K. E. Hild; M. Pavel; S. Mathan; D. Erdogmus","Intel Labs, USA","2012 IEEE International Workshop on Machine Learning for Signal Processing","20121110","2012","","","1","6","Human brain signals associated with visual perceptual processes have been used for image recognition. This paper presents several insights on the neural correlates of human visual perception by analyzing the neural correlates that result when humans view realistic images using a rapid serial visual presentation (RSVP) image display paradigm. We propose an image information extraction model and examine the relationship between the brain evoked response - using event related potential (ERP) characteristics - and the level of difficulty for humans to detect targets as a function of both visual stimulus complexity and task difficulty. We develop a computational model to quantify subject performance and the difficulty of realistic stimuli. Our results show that: (1) more difficult trials produce less prominent ERP patterns, thus reducing the performance of machine-based ERP detection; (2) on average for the same behavioral performance level, a pair of ERP's extracted from two easy trials are more similar than a pair of ERP's from two hard trials; and (3) both stimulus and task difficulty are correlated with neural activity. Our findings indicate that, for dynamic tasks involved in visual information processing, the brain may allocate additional cognitive resources, such as attention, to a given visual stimulus, as the task and/or stimulus difficulty increases.","1551-2541;15512541","Electronic:978-1-4673-1026-0; POD:978-1-4673-1024-6; USB:978-1-4673-1025-3","10.1109/MLSP.2012.6349766","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6349766","Electroencephalography (EEG);event related potential (ERP);rapid serial visual presentation;stimulus complexity;task difficulty;visual information processing","Brain modeling;Computational modeling;Correlation;Electroencephalography;Humans;Information retrieval;Visualization","electroencephalography;feature extraction;image recognition;medical signal processing;visual perception","ERP characteristics;RSVP image display paradigm;brain evoked response;event related potential;human brain signals;image information extraction model;image recognition;neural correlates;rapid serial visual presentation paradigms;realistic images;visual information processing;visual perception","","0","","15","","","23-26 Sept. 2012","","IEEE","IEEE Conference Publications"
"Enhancing the learning to rank using the virtual feature logistic regression with relevance feedback","F. Cai; D. Guo; H. Chen; Z. Shu","Department of Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, OH 410073, China","2012 16th International Conference on System Theory, Control and Computing (ICSTCC)","20121213","2012","","","1","6","Many information retrieval applications have to publish their outputs in the form of ranked lists, in which documents must be sorted in descending order according to their relevance to a given query. Many existing methods perform analysis on multidimensional features distilled from query-document pairs directly and don't take user's interactive feedback into account; hence, they incur a high computation overhead and a low retrieval performance due to inaccurate query expression. In this paper, we propose a Virtual Feature Logistic Regression (VFLR) method that conducts the logistic regression on a set of crucial but independent variables, called virtual features (VF), which are extracted by the principal component analysis (PCA) with the user's relevance feedback. We then predict the ranking score of each queried document to produce a ranked list. We systematically evaluate our method using the MQ2008 dataset. The experimental results validate that the VFLR method outperforms the state-of-the-art methods in terms of the Mean Average Precision (MAP), the Precision at position k (P@k), and the Normalized Discounted Cumulative Gain at position k (NDCG@k).","","Electronic:978-606-834-846-9; POD:978-1-4673-4534-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379275","","Feature extraction;Information retrieval;Logistics;Modeling;Principal component analysis;Training;Vectors","document handling;learning (artificial intelligence);principal component analysis;query processing;regression analysis;relevance feedback","MAP;MQ2008 dataset;NDCG@k;P@k;PCA;VF;VFLR method;document sorting;information retrieval;learning-to-rank;list ranking score prediction;mean average precision;normalized discounted cumulative gain-at-position-k;precision-at-position-k;principal component analysis;query processing;user relevance feedback;virtual feature extraction;virtual feature logistic regression","","0","","24","","","12-14 Oct. 2012","","IEEE","IEEE Conference Publications"
"Music Genre Classification Using GA-Induced Minimal Feature-Set","S. Nayak; A. Bhutani","Dept. of Electr. Eng., IIT Kanpur, Kanpur, India","2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics","20120119","2011","","","33","36","We propose a genetic algorithm-based feature-selection method for music genre classification that not only increases the efficiency of standard classifiers, but also reduces the feature space to a bare-minimum. While previous works have been more focused on finding near-optimal features devoid of noise, we go for a modified fitness function capable of finding both the near-optimal and the near-minimal feature subset for classification. In addition to an enhanced performance, our model can also reduce the computational load for ill-formed sets and has the flexibility to incorporate trade-offs between efficiency and computational load. We finally demonstrate that the modified GA is capable of bringing about an 80% reduction in the feature space dimension at similar classification rates.","","Electronic:978-0-7695-4599-8; POD:978-1-4577-2102-1","10.1109/NCVPRIPG.2011.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6132994","Feature-set Reduction;Genetic Algorithms;Genre Classification;SVM;kNN Classifier","Biological cells;Computational modeling;Feature extraction;Genetic algorithms;Music information retrieval;Support vector machines;Training","classification;genetic algorithms;music;query processing;set theory","GA-induced minimal feature-set;Internet;choice query;computational load reduction;feature space dimension;genetic algorithm-based feature-selection method;modified fitness function;music databases;music genre classification;near-minimal feature subset;near-optimal feature subset;performance enhancement","","0","","18","","","15-17 Dec. 2011","","IEEE","IEEE Conference Publications"
"Bergman iteration for SLC SAR image information extraction","D. Gleich","University of Maribor, Faculty of Electrical Engineering and Computer Science, Smetanova 17, 2000, Slovenia","2012 IEEE International Geoscience and Remote Sensing Symposium","20121110","2012","","","3736","3739","This paper presents a Bergman iteration of SLC Synthetic Aperture Radar image despeckling and information extraction. A split Bergman iteration for solving minimization of cost function is presented in this paper and the information extraction using Auto-binomial model is incorporated into the algorithm. Experimental results showed that parameters of ABM well characterize the spatial characteristics of SAR SLC data.","2153-6996;21536996","Electronic:978-1-4673-1159-5; POD:978-1-4673-1160-1; USB:978-1-4673-1158-8","10.1109/IGARSS.2012.6350505","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6350505","Auto-Binomial model;Synthetic Aperture Radar;information extraction","Bayesian methods;Cost function;Estimation;Information retrieval;Noise;Speckle;Synthetic aperture radar","geophysical image processing;image denoising;iterative methods;minimisation;radar imaging;remote sensing by radar;speckle;synthetic aperture radar","SAR image despeckling;SAR image information extraction;SLC synthetic aperture radar;autobinomial model;cost function minimization;split Bergman iteration","","0","","12","","","22-27 July 2012","","IEEE","IEEE Conference Publications"
"Cool URIs and Dynamic Data","R. Sanderson; H. Van de Sompel","Los Alamos National Laboratory","IEEE Internet Computing","20120802","2012","16","4","76","79","Linked datasets contain descriptions that change over time. Applications that leverage linked data must be aware of these change dynamics to deliver accurate services. Here, the authors highlight important challenges that are involved in dealing with change and review possible solutions.","1089-7801;10897801","","10.1109/MIC.2012.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6257375","Web;dataset dynamics;linked data;resource versioning","Information retrieval;Information services;Navigation;Resource description framework;Service oriented architecture;Uniform resource locators;Vocabulary","Internet;data handling","cool URI;dynamic data;linked datasets;uniform resource identifier","","4","","10","","","July-Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Hierarchical Co-Clustering: A New Way to Organize the Music Data","J. Li; B. Shao; T. Li; M. Ogihara","School of Computing and Information Science, Florida International University, Miami, FL, USA","IEEE Transactions on Multimedia","20120319","2012","14","2","471","481","In music information retrieval (MIR) an important research topic, which has attracted much attention recently, is the utilization of user-assigned tags, artist-related style, and mood labels, which can be extracted from music listening web sites, such as Last.fm (http://www.last.fm/) and All Music Guide (http://www.allmusic.com/). A fundamental research problem in the area is how to understand the relationships among artists/songs and these different pieces of information. Co-clustering is the problem of simultaneously clustering two types of data (e.g., documents and words, and webpages and urls). We can naturally bring this idea to the situation at hand and consider clustering artists and tags together, artists and styles together, or artists and mood labels together. Once such co-clustering has been successfully completed, one can identify co-existing clusters of artists and tags, styles, or mood labels (T/S/M). For simplicity, we use the acronym T/S/M to refer to tag(s), style(s), or mood(s) for the rest of the paper. When dealing with tags it is worth noticing that some tags are more specific versions of others. This naturally suggests that the tags could be organized in hierarchical clusters. Such hierarchical organizations exist for styles and mood labels, so we will consider hierarchical co-clustering of artists and T/S/M. In this paper, we systematically study the application of hierarchical co-clustering (HCC) methods for organizing the music data. There are two standard strategies for hierarchical clustering. One is the divisive strategy, in which we attempt to divide the input data set into smaller groups recursively, and the other is the agglomerative strategy, in which we attempt to combine initially individually separated data points into larger groups by finding the most closely related pair at each iteration. We will compare these two strategies against each other. We apply a previously known divisive hierarchical co-clustering method and a novel a- glomerative hierarchical co-clustering. In addition, we demonstrate that these two methods have the capability of incorporating instance-level constraints to achieve better performance. We perform experiments to show that these two hierarchical co-clustering methods can be effectively deployed for organizing the music data and they present reasonable clustering performance comparing with the other clustering methods. A case study is also conducted to show that HCC provides us a new method to quantify the artist similarity.","1520-9210;15209210","","10.1109/TMM.2011.2181151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111486","Co-clustering;hierarchical clustering;user tags","Clustering algorithms;Mood;Multiple signal classification;Music information retrieval;Organizations;Organizing;Standards organizations","Web sites;information retrieval;music;pattern clustering","All Music Guide;Last.fm;agglomerative hierarchical coclustering;artist similarity;artist-related style;data clustering;hierarchical organization;instance-level constraints;mood labels;music data organization;music information retrieval;music listening Web sites;user-assigned tags","","2","","49","","20111222","April 2012","","IEEE","IEEE Journals & Magazines"
"Relation extraction and scoring in DeepQA","C. Wang; A. Kalyanpur; J. Fan; B. K. Boguraev; D. C. Gondek","IBM Research Division, Thomas J. Watson Research Center, Yorktown Heights, NY, USA","IBM Journal of Research and Development","20120403","2012","56","3.4","9:1","9:12","Detecting semantic relations in text is an active problem area in natural-language processing and information retrieval. For question answering, there are many advantages of detecting relations in the question text because it allows background relational knowledge to be used to generate potential answers or find additional evidence to score supporting passages. This paper presents two approaches to broad-domain relation extraction and scoring in the DeepQA question-answering framework, i.e., one based on manual pattern specification and the other relying on statistical methods for pattern elicitation, which uses a novel transfer learning technique, i.e., relation topics. These two approaches are complementary; the rule-based approach is more precise and is used by several DeepQA components, but it requires manual effort, which allows for coverage on only a small targeted set of relations (approximately 30). Statistical approaches, on the other hand, automatically learn how to extract semantic relations from the training data and can be applied to detect a large amount of relations (approximately 7,000). Although the precision of the statistical relation detectors is not as high as that of the rule-based approach, their overall impact on the system through passage scoring is statistically significant because of their broad coverage of knowledge.","0018-8646;00188646","","10.1147/JRD.2012.2187239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6177734","","Electronic publishing;Encyclopedias;Information analysis;Information retrieval;Internet;Natural language processing;Semantics;Syntactics","","","","5","","31","","","May-June 2012","","IBM","IBM Journals & Magazines"
"Tattoo Image Matching and Retrieval","A. K. Jain; R. Jin; J. E. Lee","Michigan State University","Computer","20120509","2012","45","5","93","96","An automated tattoo image matching system achieves significantly better results for forensic and law enforcement applications than traditional keyword-based matching.","0018-9162;00189162","","10.1109/MC.2012.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197787","identity sciences;tattoo image matching and retrieval","Forensics;Identity-based encryption;Image matching;Information retrieval;Law","computer forensics;image matching;image retrieval","automated tattoo image matching system;forensic;keyword-based matching;law enforcement applications;tattoo image retrieval","","1","","","","","May 2012","","IEEE","IEEE Journals & Magazines"
"The e!DAL JAVA-API: Store, share and cite primary data in life sciences","D. Arend; M. Lange; C. Colmsee; S. Flemming; J. Chen; U. Scholz","Cytogenetics and Genome Analysis / Bioinformatics and Information Technology Leibniz Institute of Plant Genetics and Crop Plant Research (IPK), D-06466 Stadt Seeland, OT Gatersleben, Germany","2012 IEEE International Conference on Bioinformatics and Biomedicine","20121224","2012","","","1","5","Background: Life sciences are data intensive. High throughput technologies, like ""Next-Generation-Sequencing"", ""Phenotyping"" and other -omics technologies produce a huge amount of primary data. In classic scientific publication process, primary data is usually aggregated to a number of paragraphs in a journal article and proven by figures, tables and supplementary material. So it is that the value of primary data, on which the scientific conclusions are based on, do not get proper attention. But, the responsible use and efficient availability of digital resources is an important factor in the nowadays ""e-science"" age. The increased attention in public as well as in the research community leads to novel strategies and concepts for primary data citation, which must be substantively, underpinned by enhancements to classic data management systems. Results: We present the JAVA-based e.!DAL-API, a comprehensive storage backend for primary data management. It stands for (electronical Data Archive Library) and implement a primary data storage infrastructure, but with an intuitive usability like a classical file system. Main features are version and meta data management, data citations, support for information retrieval, persistent identifiers and its easy integration into existing data frontends and information systems. The API has been designed and tested using experiences from several research projects and literature studies. Conclusions: Primary data preservation in life sciences is accompanied by enhanced requirements to data management systems. e.!DAL combines this novel arising requirements with features known from file systems, databases, content management and version control to one homogeneous storage system. It supports an embedded use in stand-alone JAVA software or in server mode a data repositories for collaborative, remote accessible data services. Thus, e.!DAL is an efficient complement for data frontends, information systems and data management systems. The- JAVA libraries, Maven artifacts, sample code, a show case demo, and the API-documentation can be downloaded from: http://projects.ipk-gatersleben.de/eDAL-Project.","","Electronic:978-1-4673-2560-8; POD:978-1-4673-2559-2","10.1109/BIBM.2012.6392737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392737","","Bioinformatics;Databases;Graphical user interfaces;Information retrieval;Java;Servers;Software","Java;biology computing;database management systems","Next Generation Sequencing;Phenotyping;classic data management system;digital resource;e!DAL JAVA-API;e-science age;electronical Data Archive Library;high throughput technology;life sciences;primary data citation;primary data sharing;primary data storage;research community","","0","","15","","","4-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"Extracting refrained phrases from music signals using a frequent episode pattern mining algorithm","J. Fujikawa; T. Kida; T. Katoh","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan","2011 IEEE International Conference on Granular Computing","20120105","2011","","","199","202","In this paper, we discuss a method for extracting refrained phrases from a music signal by a discrete knowledge discovery processing approach instead of a signal processing approach. The proposed method consists of two processes: translating a music signal into a sequence of events that represent pitch information, and then mining the frequent patterns from the event sequences. The former is performed by computing chroma vectors at every beat interval, and the latter is performed by enumerating the frequent episode patterns. We carried out a preliminary experiment on some pieces in the RWC music databases to examine if the extracted patterns represent the refrained phrases.","","Electronic:978-1-4577-0371-3; POD:978-1-4577-0372-0","10.1109/GRC.2011.6122593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122593","data mining algorithm;serial episode pattern;the RWC music database","Conferences;Data mining;Feature extraction;Multiple signal classification;Music information retrieval;Signal processing;Vectors","audio databases;audio signal processing;data mining;music;pattern clustering","RWC music database;chroma vector;discrete knowledge discovery processing;event sequence;extracted pattern representation;frequent episode pattern mining algorithm;music signal processing;pitch information;refrained phrase extraction","","0","","12","","","8-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Integrated impact analysis for managing software changes","M. Gethers; B. Dit; H. Kagdi; D. Poshyvanyk","Computer Science Department, The College of William and Mary, Williamsburg, VA 23185","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","430","440","The paper presents an adaptive approach to perform impact analysis from a given change request to source code. Given a textual change request (e.g., a bug report), a single snapshot (release) of source code, indexed using Latent Semantic Indexing, is used to estimate the impact set. Should additional contextual information be available, the approach configures the best-fit combination to produce an improved impact set. Contextual information includes the execution trace and an initial source code entity verified for change. Combinations of information retrieval, dynamic analysis, and data mining of past source code commits are considered. The research hypothesis is that these combinations help counter the precision or recall deficit of individual techniques and improve the overall accuracy. The tandem operation of the three techniques sets it apart from other related solutions. Automation along with the effective utilization of two key sources of developer knowledge, which are often overlooked in impact analysis at the change request level, is achieved. To validate our approach, we conducted an empirical evaluation on four open source software systems. A benchmark consisting of a number of maintenance issues, such as feature requests and bug fixes, and their associated source code changes was established by manual examination of these systems and their change history. Our results indicate that there are combinations formed from the augmented developer contextual information that show statistically significant improvement over standalone approaches.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227172","","Automation;Couplings;Data mining;History;Information retrieval;Maintenance engineering;Software","data mining;indexing;information retrieval;management of change;public domain software;software maintenance;software management;system monitoring","adaptive approach;best-fit combination;contextual information;data mining;developer knowledge source;dynamic analysis;execution trace;impact set estimation;information retrieval;initial source code entity;integrated impact analysis;latent semantic indexing;maintenance issues;open source software systems;software change management;source code single snapshot;textual change request","","33","1","35","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Designing a Multi-dimensional Space for Hybrid Information Extraction","C. Feilmayr; K. Vojinovic; B. Pröll","Inst. of Applic. Oriented Knowledge Process. (FAW), Johannes Kepler Univ. Linz, Linz, Austria","2012 23rd International Workshop on Database and Expert Systems Applications","20121011","2012","","","121","125","Information extraction systems are developed for various specific application domains to manage an increasing amount of unstructured data. The majority build either upon the knowledge-based approach, which promises high accuracy but involves labour-intensive coding of extraction rules, or upon the automatically trainable systems approach, which produces highly portable solutions but requires an appropriate learning set. In this paper, we present results of a project that aims to provide a new methodology which combines the knowledge-based and the machine learning approach into a hybrid one in order to compensate for their respective shortcomings and to achieve high IE performance. Firstly, we propose the idea of a multi-dimensional space that guides users in selecting appropriate methods, i.e., different hybrid concepts, depending on the extraction task and the level of available features. Secondly, we provide the concept of one hybrid approach, namely the sequential processing of a knowledge-based approach and a selection of different machine learning methods. Thirdly, we present the evaluation of an implementation of the sequential extraction on a curriculum vitae corpus. Thus, we provide first results for filling the multi-dimensional space for hybrid information extraction.","1529-4188;15294188","Electronic:978-0-7695-4801-2; POD:978-1-4673-2621-6","10.1109/DEXA.2012.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327413","(Statistical) Machine Learning;Extraction Methodology;Hybrid Information Extraction","Data mining;Feature extraction;Information retrieval;Knowledge based systems;Learning systems;Machine learning;Training","information retrieval;learning (artificial intelligence)","IE performance;curriculum vitae corpus;extraction rules coding;hybrid information extraction system;knowledge-based approach sequential processing;machine learning approach;multidimensional space design;sequential extraction;trainable systems approach","","0","","17","","","3-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"A Structure Extraction Technique for XML Query Languages","T. Wichaiwong; C. Jaruskulchai","Dept. of Comput. Sci., Kasetsart Univ. Bangkok, Bangkok, Thailand","2012 International Conference on Information Science and Applications","20120621","2012","","","1","6","Querying in structure documents must be respect to content and structure. Since, the Extensible Markup Language(XML) documents have additional information; document representation of these might add up metadata to describe data in context respect to XML language design. Recently, the need for accessing the XML content has been focused on query languages and efficient evaluation algorithms. The structure is very rich and carries important information about contents and their relationships, e.g. e-Commerce data or data published from databases. To improve the result of the retrieval system by using the structure of user query. In this paper, we are proposed a novel structure extraction techniques over a strongly structured collection of XML documents with INEX collection with respect to NEXI query language. It has been discovered that these steps achieve up to 100% respect to our experiments.","2162-9048;21629048","DVD:978-1-4673-1400-8; Electronic:978-1-4673-1401-5; POD:978-1-4673-1402-2","10.1109/ICISA.2012.6220926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6220926","","Data models;Database languages;Databases;Information retrieval;Motion pictures;XML","XML;feature extraction;meta data;query processing","INEX collection;NEXI query language;XML content;XML language design;XML query languages;document representation;extensible markup language;metadata;retrieval system;structure documents;structure extraction technique","","0","","15","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"Methods of Detecting Rules for Discovery of New Concepts for Semantic Networks","D. Ceglarek; K. Haniewicz","Poznan Sch. of Banking, Poznan, Poland","2011 International Conference on Information Management, Innovation Management and Industrial Engineering","20111229","2011","3","","593","596","Successful experiments with extraction of previously uncharted concepts with specialized finite state automata and already stored data in semantic network encouraged authors to further extend capabilities of semi-automatic concept acquisition. This paper focuses on methods of extracting viable proposition that can be included in a rule repository used to retrieve candidates for semantic network extension.","2155-1456;21551456","Electronic:978-1-61284-453-4; POD:978-1-61284-450-3","10.1109/ICIII.2011.417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6116955","","Algorithm design and analysis;Artificial intelligence;Automata;Educational institutions;Frequency domain analysis;Information retrieval;Semantics","finite state machines;semantic networks;storage management","finite state automata;rules detection;semantic networks;semi-automatic concept acquisition;stored data","","0","","11","","","26-27 Nov. 2011","","IEEE","IEEE Conference Publications"
"Evaluating the specificity of text retrieval queries to support software engineering tasks","S. Haiduc; G. Bavota; R. Oliveto; A. Marcus; A. De Lucia","Computer Science Department, Wayne State University, Detroit, MI 48202, USA","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1273","1276","Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227101","Concept location;Query specificity;Text retrieval","Context;Correlation;Entropy;Information retrieval;Measurement;Natural languages;Software","natural languages;query processing;software metrics;text analysis","natural language text;preretrieval metric;query quality;software artifacts;software engineering tasks;source code;specificity evaluation;specificity metric;text retrieval queries;text retrieval-based concept location","","8","","14","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Semantic advisor-assisting framework to select learning materials","M. Tayefeh Mahmoudi; F. Taghiyareh; K. Rajavi; F. Shokri; L. Khamnian","Sch. of ECE, Univ. of Tehran, Tehran, Iran","6th National and 3rd International Conference of E-Learning and E-Teaching","20121018","2012","","","59","64","Selecting appropriate educational documents among enormous existing contents turns advisors into making use of some automatic content assessment systems. There exist various content assessment methods which usually consider at least one of syntactic, semantic and structural perspectives through information retrieval or machine learning algorithms. In this paper, a framework for assessing learning materials based on analytical, combinational learning algorithms is represented that is capable of assisting advisors in their selection for recommending those contents to students. The focus of proposed framework is on determining required fitness in educational summaries by semantic rules. The proposed framework is examined on a dataset of summaries and compared to the expert's assessment on the same learning materials. The comparison results reveal that the proposed semantic advisor-assisting framework was successful in almost 70% of cases.","2163-6982;21636982","DVD:978-1-4673-0956-1; Electronic:978-1-4673-0957-8; POD:978-1-4673-0958-5","10.1109/ICELET.2012.6333366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6333366","advisor assisting system;selecting learning materials;semantic rules;summery assessment;text processing","Databases;Educational institutions;Information retrieval;Machine learning algorithms;Materials;Semantics;Syntactics","combinatorial mathematics;computer aided instruction;document handling;information retrieval;learning (artificial intelligence);semantic networks","analytical combinational learning algorithms;automatic content assessment systems;educational documents;educational summaries;information retrieval algorithm;learning material assessment;learning material selection;machine learning algorithm;semantic advisor-assisting framework;semantic rules","","0","","17","","","14-15 Feb. 2012","","IEEE","IEEE Conference Publications"
"Computing Structural Statistics by Keywords in Databases","L. Qin; J. X. Yu; L. Chang","The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Knowledge and Data Engineering","20120817","2012","24","10","1731","1746","Keyword search in RDBs has been extensively studied in recent years. The existing studies focused on finding all or top-k interconnected tuple-structures that contain keywords. In reality, the number of such interconnected tuple-structures for a keyword query can be large. It becomes very difficult for users to obtain any valuable information more than individual interconnected tuple-structures. Also, it becomes challenging to provide a similar mechanism like group-&-aggregate for those interconnected tuple-structures. In this paper, we study computing structural statistics keyword queries by extending the group-&-aggregate framework. We consider an RDB as a large directed graph where nodes represent tuples, and edges represent the links among tuples. Instead of using tuples as a member in a group, we consider rooted subgraphs. Such a rooted subgraph represents an interconnected tuple-structure among tuples and some of the tuples contain keywords. The dimensions of the rooted subgraphs are determined by dimensional keywords in a data driven fashion. Two rooted subgraphs are grouped into the same group if they are isomorphic based on the dimensions or in other words the dimensional keywords. The scores of the rooted subgraphs are computed by a user-given score function if the rooted subgraphs contain some of general keywords. Here, the general keywords are used to compute scores rather than determining dimensions. The aggregates are computed using an sql aggregate function for every group based on the scores computed. We give our motivation using a real data set. We propose new approaches to compute structural statistics keyword queries, perform extensive performance studies using two large real data sets and a large synthetic data set, and confirm the effectiveness and efficiency of our approach.","1041-4347;10414347","","10.1109/TKDE.2012.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180166","Keyword search;relational database;structural statistics.","Information retrieval;Keyword search;Relational databases;Search methods","","","","1","","30","","20120410","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Fingerprinting for scanned comics content identification","J. Park; S. K. Lee; Y. S. Yoon; W. Y. Yoo","Creative Content Research Laboratory, Electronics and Telecommunications Research Institute, Daejeon, Korea","2012 International Conference on ICT Convergence (ICTC)","20121220","2012","","","92","93","In this paper, we propose a fingerprinting to identify comics content using cut information of a comic image. Based the characteristics of a comic image that it consists of several cuts, we design a fingerprinting method which uses the position information of cuts in comic images. Our fingerprinting includes box frame detection, cut information extraction, and cut sequence analyzing. Box frame detection is to detect a normalized box frame from each comic image. Cut information extraction is to extract cut positions using image histogram. We enhanced the identification rate using a sequence of cut positions.","2162-1233;21621233","Electronic:978-1-4673-4828-7; POD:978-1-4673-4829-4; USB:978-1-4673-4827-0","10.1109/ICTC.2012.6386786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6386786","comics;fingerprinting;identification","Data mining;Design methodology;Feature extraction;Fingerprint recognition;Histograms;Information retrieval;Internet","content management;feature extraction;fingerprint identification;humanities;image sequences","box frame detection;comic image;cut information extraction;cut position sequence;cut sequence analysis;cuts position information;fingerprinting identification;image histogram;normalized box frame;scanned comics content identification rate","","1","","3","","","15-17 Oct. 2012","","IEEE","IEEE Conference Publications"
"Research on SOA Architecture for Scattered Web Knowledge Discovery","W. Zeng; J. Zhang; H. Wei","Software Eng. Coll., Beijing Univ. of Technol., Beijing, China","2012 International Conference on Computer Science and Service System","20121231","2012","","","1370","1373","With the rapid update of internet hardware and software, especially the rise of mobile internet and cloud computing platforms, web-based sites has become the world's largest source of information, and so how to extract the accurate domain-specific knowledge, how to improve the extraction efficiency and how to save the cost during information harvest have become the hot research spot. With the advantage of the theories and techniques of software architecture, the paper presents a web knowledge discovery model based on SOA and cloud computing, through which valid information can be obtained in an automatic or semi-automatic way from the distributed information sources environment. A unique web information extraction system built base on the architecture and the verification results were given in the final chapter.","","Electronic:978-0-7695-4719-0; POD:978-1-4673-0721-5","10.1109/CSSS.2012.345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394583","SOA;UML;Web information extraction;knowledge discovery","Cloud computing;Computer architecture;Data mining;Information retrieval;Service oriented architecture;Unified modeling language","Web sites;cloud computing;data mining;mobile computing;service-oriented architecture","Internet hardware;Internet software;SOA architecture;Web information extraction system;Web-based sites;cloud computing platforms;distributed information sources environment;domain-specific knowledge;information harvest;mobile Internet;scattered Web knowledge discovery","","0","","9","","","11-13 Aug. 2012","","IEEE","IEEE Conference Publications"
"A Budget Optimization Framework for Search Advertisements Across Markets","Y. Yang; J. Zhang; R. Qin; J. Li; F. Y. Wang; W. Qi","State Key Lab of Intelligent Control and Management of Complex Systems, Chinese Academy of Sciences , Beijing, China","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20120815","2012","42","5","1141","1151","Budget optimization is one of the primary decision-making issues faced by advertisers in search auctions. A quality budget optimization strategy can significantly improve the effectiveness of search advertising campaigns, thus helping advertisers to succeed in the fierce competition of online marketing. This paper investigates budget optimization problems in search advertisements and proposes a novel hierarchical budget optimization framework (BOF), with consideration of the entire life cycle of advertising campaigns. Then, we formulated our BOF framework, made some mathematical analysis on some desirable properties, and presented an effective solution algorithm. Moreover, we established a simple but illustrative instantiation of our BOF framework which can help advertisers to allocate and adjust the budget of search advertising campaigns. Our BOF framework provides an open testbed environment for various strategies of budget allocation and adjustment across search advertising markets. With field reports and logs from real-world search advertising campaigns, we designed some experiments to evaluate the effectiveness of our BOF framework and instantiated strategies. Experimental results are quite promising, where our BOF framework and instantiated strategies perform better than two baseline budget strategies commonly used in practical advertising campaigns.","1083-4427;10834427","","10.1109/TSMCA.2011.2172418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095652","Budget optimization;optimal strategy;search auctions;search engine marketing;sponsored search","Advertising;Convex functions;Information retrieval;Marketing management;Optimization;Search engines;Search problems","Internet;advertising;budgeting;decision making;electronic commerce;search engines","BOF framework;budget allocation;budget optimization framework;decision-making issues;online marketing;search advertising campaigns;search advertising markets;search auctions","","24","","36","","20111206","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Identifying Provider Counseling Practices Using Natural Language Processing: Gout Example","O. V. Patterson; G. S. Kerr; J. S. Richards; C. A. Nunziato; D. D. Maron; R. L. Amdur; S. L. DuVall","Univ. of Utah, Salt Lake City, UT, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","127","127","National guidelines for a number of health conditions recommend that practitioners assess and reinforce patient's adherence to specific diet and lifestyle modifications. Counseling intervention has shown to have a long-term positive effect on patient adherence but the extent to which physicians comply is unknown. Evidence of counseling provided by practitioner is recorded only as free text in electronic medical records. To identify physicians' counseling practices we developed a natural language processing system to detect text documentation of dietary counseling in gout patients.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366218","NLP;information extraction;patient education","Cities and towns;Educational institutions;Employee welfare;Information retrieval;Medical services;Natural language processing","information retrieval;medical information systems;natural language processing;text analysis","counseling intervention;diet modifications;dietary counseling;electronic medical records;gout patient adherence;health conditions;lifestyle modifications;national guidelines;natural language processing;physician counseling practice identification;text documentation detection","","0","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Don't Click Here","D. A. Shamma; M. Slaney","Yahoo! Research","IEEE MultiMedia","20120817","2012","19","3","4","6","One of the most important aspects of multimedia research is mining data about user behavior. In a world with one or fewer clicks per piece of content, one needs a lot of users to get a meaningful signal. A monetization ecosystem now directs multimedia research and is changing how we think about people, interaction, media engagement, and data instrumentation. Single clicks, touches, and gestures are now powerful, often complex interactions that are part of our everyday vernacular. Currently, touchless interactions and zero-click interfaces bring us content, push notifications, and recommend playlists. Beyond this, the absence of interaction, the minus one click, is taking the forefront.","1070-986X;1070986X","","10.1109/MMUL.2012.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6272277","Web research;data mining;interaction;media engagement;minus one click;multimedia;multimedia applications;multimedia research;zero-click interfaces","Behavioral science;Computer interfaces;Data mining;Information retrieval;Internet;Patents;Search methods;Streaming media;Web services","","","","0","","8","","","July-Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Machine Learning Algorithms with Co-occurrence Based Term Association for Text Mining","Y. Yi; L. Liu; C. H. Li; W. Song; S. Liu","Dept. of Comput. Sci. & Inf., He Chi Univ., YiZhou, China","2012 Fourth International Conference on Computational Intelligence and Communication Networks","20121206","2012","","","958","962","In this paper, an effective method for computing term association from a text corpus is presented. Two machine learning algorithms are employed to evaluate the effectiveness of the proposed method for text mining. The co-occurrence based term association method is to overcome the problem of lack of relationship between words for keyword based text mining and improve the performance of text mining. The experiments are conducted on the standard Reuter-21578 data set and 20 news group data set. Different number of associated terms are compared in the experiments. Experimental results show that the proposed method can achieve better results on different machine learning algorithms when measured by F measure.","","Electronic:978-0-7695-4850-0; POD:978-1-4673-2981-1","10.1109/CICN.2012.141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375257","Machine learning algorithms;Term association;Text mining","Educational institutions;Information retrieval;Text categorization;Text mining;Thesauri;Training;Vectors","data mining;learning (artificial intelligence);text analysis","F measure;Reuter-21578 data set;cooccurrence based term association;keyword based text mining;machine learning algorithm;text corpus","","0","","22","","","3-5 Nov. 2012","","IEEE","IEEE Conference Publications"
"Soft clustering algorithms based on neural networks","L. Skovajsová; M. Rojćek","Institute of Informatics, Slovak Academy of Sciences, D&#x00FA;bravsk&#x00E1; cesta 9, 845 07 Bratislava 45, Slovakia","2011 IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI)","20111222","2011","","","439","442","This paper is oriented into the text document retrieval area. The aim of the paper is to compare two soft document clustering methods by using neural networks, the modification of KMART and the nonlinear Hebbian neural network with Oja learning rule.","","Electronic:978-1-4577-0045-3; POD:978-1-4577-0044-6","10.1109/CINTI.2011.6108545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6108545","","Clustering algorithms;Informatics;Information retrieval;Neural networks;Subspace constraints;Training;Vectors","Hebbian learning;information retrieval;neural nets;pattern clustering;text analysis","KMART;Oja learning rule;neural networks;nonlinear Hebbian neural network;soft clustering algorithm;soft document clustering methods;text document retrieval area","","1","","14","","","21-22 Nov. 2011","","IEEE","IEEE Conference Publications"
"Automatic error region detection and characterization in LVCSR transcriptions of TV news shows","R. Dufour; G. Damnati; D. Charlet","Orange Labs, France Telecom, Lannion (France)","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","4445","4448","This paper addresses the issue of error region detection and characterization in LVCSR transcriptions. It is a well-known phenomenon that errors are not independent and tend to co-occur in automatic transcriptions. We are interested in automatically detecting these so-called error regions. Additionally, in the context of information extraction in TVBN shows, being able to automatically characterize detected error regions is a crucial step towards the definition of suitable recovery strategies. In this paper we propose to classify error regions in four classes with a particular focus on errors on person names. We propose several sequential detection + classification approaches and an integrated sequence labeling approach. We show that our best classification system can reach 70% classification accuracy on automatically detected error regions. Additionally, the overall system is able to detect and correctly characterize 29.6% of error region corresponding to a person name with a precision of 61.9%.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6288906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6288906","Automatic classification;Error characterization;Error region detection;LVCSR","Accuracy;Context;Focusing;Information retrieval;Labeling;Speech;Speech recognition","speech recognition;television stations","ASR systems;LVCSR transcriptions;TV news shows;TVBN shows;automatic error region detection;automatic speech recognition systems;error region classification;integrated sequence labeling approach;large vocabulary continuous speech recognition;sequential classification approach;sequential detection approach","","2","","13","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Towards Efficient Sport Data Integration through Semantic Annotation","Q. M. Nguyen; T. D. Cao; H. C. Nguyen; T. Hagino","Sch. of Electron. & Telecommun., Hanoi Univ. of Sci. & Technol., Hanoi, Vietnam","2012 Fourth International Conference on Knowledge and Systems Engineering","20120913","2012","","","99","106","In news genre, the sport domain is one of great interest to audiences on many occasions. The explosion of Internet these days leads to many obstacles for users in searching information due to enormous amount of data collected from multiple media streams. In this case, Semantic Web is believed to bring a solution for information integration. In this paper, we introduce a novel approach for an integration system of sports information using semantic web. Semantic annotation of sport news on the web is a way to bring success to our system. We propose an algorithm to generate semantic annotations of sport news that relies on the ontology. Named entities recognition is improved by integrating the KIM information extraction system with this ontology, which is dedicated for sport domain. The concepts and relations of ontology detected in the text are combined with these entities to capture the semantic. Initial experiments on soccer news demonstrated promising results.","","Electronic:978-0-7695-4760-2; POD:978-1-4673-2171-6","10.1109/KSE.2012.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299405","Information integration;Ontology;semantic annotation generation;semantic web","Educational institutions;Information retrieval;Knowledge based systems;Ontologies;Organizations;Semantic Web;Semantics","data integration;knowledge acquisition;ontologies (artificial intelligence);semantic Web;sport","Internet;KIM information extraction system;multiple media streams;named entities recognition;semantic Web;soccer news;sport data integration;sport domain;sport semantic annotation;sports information integration system;text ontology detection","","1","","12","","","17-19 Aug. 2012","","IEEE","IEEE Conference Publications"
"Toward actionable, broadly accessible contests in Software Engineering","J. Cleland-Huang; Y. Shin; E. Keenan; A. Czauderna; G. Leach; E. Moritz; M. Gethers; D. Poshyvanyk; J. H. Hayes; W. Li","DePaul University, Chicago, IL 60604","2012 34th International Conference on Software Engineering (ICSE)","20120628","2012","","","1329","1332","Software Engineering challenges and contests are becoming increasingly popular for focusing researchers' efforts on particular problems. Such contests tend to follow either an exploratory model, in which the contest holders provide data and ask the contestants to discover “interesting things” they can do with it, or task-oriented contests in which contestants must perform a specific task on a provided dataset. Only occasionally do contests provide more rigorous evaluation mechanisms that precisely specify the task to be performed and the metrics that will be used to evaluate the results. In this paper, we propose actionable and crowd-sourced contests: actionable because the contest describes a precise task, datasets, and evaluation metrics, and also provides a downloadable operating environment for the contest; and crowd-sourced because providing these features creates accessibility to Information Technology hobbyists and students who are attracted by the challenge. Our proposed approach is illustrated using research challenges from the software traceability area as well as an experimental workbench named TraceLab.","0270-5257;02705257","Electronic:978-1-4673-1067-3; POD:978-1-4673-1066-6","10.1109/ICSE.2012.6227087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227087","Contest;Empirical Software Engineering;TraceLab;Traceability","Communities;Conferences;Data mining;Information retrieval;Measurement;Software;Software engineering","program diagnostics;social sciences computing;software metrics","TraceLab;actionable broadly accessible contests;crowd-sourced contests;datasets;evaluation mechanisms;evaluation metrics;information technology;software engineering;software traceability area;task-oriented contests","","6","","14","","","2-9 June 2012","","IEEE","IEEE Conference Publications"
"Chunking and Extracting Text Content for Mobile Learning: A Query-Focused Summarizer Based on Relevance Language Model","G. Yang; Kinshuk; E. Sutinen; D. Wen","Sch. of Comput., Univ. of Eastern Finland, Joensuu, Finland","2012 IEEE 12th International Conference on Advanced Learning Technologies","20120816","2012","","","126","128","Millions of text contents and multimedia published on the Web have potential to be shared as the learning contents. However, mobile learners often feel it difficult to extract useful contents for learning. Manually creating content not only requires a huge effort on the part of the teachers but also creates barriers towards reuse of the content that has already been created for e-Learning. In this paper, a text-based content summarizer is introduced to address an approach to help mobile learners to retrieve and process information more quickly by aligning text-based content size to various mobile characteristics. In this work, probabilistic language modeling techniques are integrated into an extractive text summarization system to fulfill the automatic summary generation for mobile learning. Experimental results have shown that our solution is a proper and efficient approach to help mobile learners to summarize important content quickly.","2161-3761;21613761","Electronic:978-0-7695-4702-2; POD:978-1-4673-1642-2","10.1109/ICALT.2012.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268055","content processing;mobile learning;relevance modelling;text summarization","Computational modeling;Computer architecture;Educational institutions;Humans;Information retrieval;Mobile communication;Probabilistic logic","Internet;computer aided instruction;mobile computing;multimedia systems;natural language processing;probability;query processing;text analysis","Web;automatic summary generation;e-learning;extractive text summarization system;information processing;information retrieval;learning contents;mobile learning;multimedia;probabilistic language modeling techniques;query-focused summarizer;relevance language model;text content chunking;text content extraction;text-based content size;text-based content summarizer","","0","","11","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"Research on integration model and application system of enterprise information resources","Jing-Yan Wang; Ren-gen Huang; Guo-jian He; Kai-wei Yu","Foshan University, 528000, China","2012 International Conference on Information Management, Innovation Management and Industrial Engineering","20121025","2012","1","","100","104","With constantly advancing of informatization construction and application, many enterprises have accumulated a wealth of information resources, desiderating to solve the problems of information effectively sharing and developing. Based on discussing the connotation and characteristic of enterprise information resources, this paper introduces the integration model of enterprise information resources. The integration scope covers network information resources, internal information resources and commercial database resources. The integration method of internal information resources, functions and characteristics of integration model are presented in detail. In order to utilize information resources integration technology for providing information service, the deployment scheme of information service system based on cloud computing is proposed in the article, and system implement is also explained at full length.","2155-1456;21551456","Electronic:978-1-4673-1931-7; POD:978-1-4673-1932-4","10.1109/ICIII.2012.6339741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6339741","application system;cloud computing;enterprise information resources;information service;integration model","Cloud computing;Databases;Information retrieval;Information services;Production;Standards","business data processing;cloud computing;information resources","cloud computing;commercial database resource;enterprise information resource;information resources integration technology;information service system;information sharing;informatization application;informatization construction;internal information resource;network information resource","","0","","8","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"Prolog to the Section on Mass Storage and Data Retrieval","X. Zhou","School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, Australia","Proceedings of the IEEE","20120510","2012","100","Special Centennial Issue","1431","1432","","0018-9219;00189219","","10.1109/JPROC.2012.2189914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6198392","","Data storage systems;Database systems;Information retrieval;Information technology;Special issues and sections","","","","0","","","","","May 13 2012","","IEEE","IEEE Journals & Magazines"
"In Tags We Trust: Trust modeling in social tagging of multimedia content","I. Ivanov; P. Vajda; J. S. Lee; T. Ebrahimi","Research assistant and Ph.D. student in the Multimedia Signal Processing Group at the Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland","IEEE Signal Processing Magazine","20120216","2012","29","2","98","107","Tagging in online social networks is very popular these days, as it facilitates search and retrieval of multimedia content. However, noisy and spam annotations often make it difficult to perform an efficient search. Users may make mistakes in tagging and irrelevant tags and content may be maliciously added for advertisement or self-promotion. This article surveys recent advances in techniques for combatting such noise and spam in social tagging. We classify the state-of-the-art approaches into a few categories and study representative examples in each. We also qualitatively compare and contrast them and outline open issues for future research.","1053-5888;10535888","","10.1109/MSP.2011.942345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6153150","","Content management;Information analysis;Information retrieval;Multimedia communication;Noise measurement;Online services;Search problems;Social network services;Tagging","information retrieval;multimedia computing;social networking (online);trusted computing;unsolicited e-mail","multimedia content retrieval;online social networks;social tagging;spam annotations;trust modeling","","10","","49","","","March 2012","","IEEE","IEEE Journals & Magazines"
"A Text Representation and Retrieval Method Based on Concept Algebra","F. Ye; H. Cao; X. Luo","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2012 IEEE 12th International Conference on Computer and Information Technology","20121224","2012","","","1066","1071","This paper introduces the concept algebra (CA) theory as a basis for the conceptual representation and the derivation of text processing to realize a semantic based retrieval system. We also take advantage of Hownet to create the concept attributes space for concept algebra. With the help of LTP, we get the key words and their dependent relations of every sentence to build the CA concept representation of the content with a five-tuple. Concepts make it possible to express both the keyword itself and the semantic relation with its context. According to the demands of text retrieval, some CA operations are optimized to calculate the relations and similarity between concepts. Besides, a text retrieval system framework which processes information based on the concept relations at a concept level is also proposed to verify the advantages of our method.","","Electronic:978-0-7695-4858-6; POD:978-1-4673-4873-7","10.1109/CIT.2012.218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392054","Hownet;LTP;concept algebra;concept relation;concept similarity;semantic;text representation;text retrieval","Algebra;Cognition;Context;Educational institutions;Information retrieval;Knowledge representation;Semantics","information retrieval;knowledge representation;text analysis","Hownet;concept algebra;concept attribute space;concept similarity;conceptual representation;key words;semantic based retrieval system;semantic relation;sentence;text processing;text representation;text retrieval method;text retrieval system","","1","","10","","","27-29 Oct. 2012","","IEEE","IEEE Conference Publications"
"Consensus Clustering Based on a New Probabilistic Rand Index with Application to Subtopic Retrieval","C. Carpineto; G. Romano","Fondazione Ugo Bordoni, Rome","IEEE Transactions on Pattern Analysis and Machine Intelligence","20121018","2012","34","12","2315","2326","We introduce a probabilistic version of the well-known Rand Index (RI) for measuring the similarity between two partitions, called Probabilistic Rand Index (PRI), in which agreements and disagreements at the object-pair level are weighted according to the probability of their occurring by chance. We then cast consensus clustering as an optimization problem of the PRI value between a target partition and a set of given partitions, experimenting with a simple and very efficient stochastic optimization algorithm. Remarkable performance gains over input partitions as well as over existing related methods are demonstrated through a range of applications, including a new use of consensus clustering to improve subtopic retrieval.","0162-8828;01628828","","10.1109/TPAMI.2012.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175906","Consensus clustering;Rand index;probabilistic Rand index;search results clustering;subtopic retrieval","Clustering algorithms;Indexes;Information retrieval;Optimized production technology;Partitioning algorithms;Probabilistic logic;Search problems","information retrieval;optimisation;pattern clustering;probability;stochastic processes","PRI value;consensus clustering;object-pair level agreement;object-pair level disagreement;occurrence probability;optimization problem;performance gain;probabilistic Rand index;similarity measurement;stochastic optimization algorithm;subtopic retrieval","","13","","43","","20120403","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Characterization and Resolution of Incompleteness in (World-Wide-Web) Information Extraction","C. Feilmayr","Inst. of Applic. Oriented Knowledge Process. (FAW), Johannes Kepler Univ. Linz, Linz, Austria","2012 23rd International Workshop on Database and Expert Systems Applications","20121011","2012","","","241","245","Low information quality is one of the reasons why information extraction initiatives fail. Incomplete information has a pervasive negative impact on downstream processing steps. This work addresses this problem with a novel information extraction approach, which integrates data mining and information extraction methods into a single complementary approach in order to benefit from their respective advantages and reduce incompleteness in information extraction. In this context, various types of incompleteness are identified and an approach to their automatic detection is presented. Further, a prototype generic framework that incorporates the complementarity approach is proposed.","1529-4188;15294188","Electronic:978-0-7695-4801-2; POD:978-1-4673-2621-6","10.1109/DEXA.2012.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327433","Data Mining;Information Extraction;Information Integration;Information Quality","Accuracy;Conferences;Context;Data mining;Information retrieval;Null value;Semantics","Internet;data mining;information retrieval","World-Wide-Web;complementarity approach;complementary approach;data mining;downstream processing steps;incompleteness characterization;incompleteness resolution;information extraction approach;low information quality;prototype generic framework","","0","","16","","","3-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Dimension reduction in text document retrieval by Hebbian neural network and nonlinear activation functions","L. Skovajsová; I. Mokriš","Institute of Informatics, Slovak Academy of Sciences, Slovakia","2012 4th IEEE International Symposium on Logistics and Industrial Informatics","20121004","2012","","","59","64","The paper deals with utilization of neural networks for information retrieval. It is focused on reduction of text document space by Hebbian neural networks. The Hebbian neural network with Oja learning rule with linear activation function reduces term space into much lower dimension and gives good results for text document dimension reduction and retrieval. The aim of this paper is to try to increase the retrieval evaluation by F-measure that applies different nonlinear activation functions to the output layer of network. Results show better F-measure when applying other nonlinear activation functions instead of applying classical linear activation function. The results were verified on the collection of 50 documents and 100 terms, where documents were clustered into five different clusters. For each dimension the Precision, Recall and F-measure were computed and the results were depicted graphically.","2156-8790;21568790","Electronic:978-1-4673-4519-4; POD:978-1-4673-4520-0; USB:978-1-4673-4518-7","10.1109/LINDI.2012.6319462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6319462","","Electronic mail;Information retrieval;Neural networks;Organizations;Semantics;Training;Vectors","Hebbian learning;information retrieval;neural nets;nonlinear functions;text analysis;transfer functions","F-measure;Hebbian neural network;Oja learning rule;dimension reduction;information retrieval;linear activation function;nonlinear activation functions;precision;recall;term space reduction;text document retrieval;text document space reduction","","0","","17","","","5-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Bayesian Embedding of Co-occurrence Data for Query-Based Visualization","M. Khoshneshin; W. N. Street; P. Srinivasan","Dept. of Manage. Sci., Univ. of Iowa, Iowa City, IA, USA","2011 10th International Conference on Machine Learning and Applications and Workshops","20120209","2011","1","","74","79","We propose a generative probabilistic model for visualizing co-occurrence data. In co-occurrence data, there are a number of entities and the data includes the frequency of two entities co-occurring. We propose a Bayesian approach to infer the latent variables. Given the intractability of inference for the posterior distribution, we use approximate inference via variational approaches. The proposed Bayesian approach enables accurate embedding in high-dimensional space which is not useful for visualization. Therefore, we propose a method to embed a filtered number of entities for a query -- query-based visualization. Our experiments show that our proposed models outperform co-occurrence data embedding, the state-of-the-art model for visualizing co-occurrence data.","","Electronic:978-0-7695-4607-0; POD:978-1-4577-2134-2","10.1109/ICMLA.2011.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6146946","Bayesian model;Co-occurrence data embedding;query-based visualization;visualization","Bayesian methods;Context;Data models;Data visualization;Indexes;Information retrieval;USA Councils","Bayes methods;data visualisation;inference mechanisms;query processing;statistical distributions;variational techniques","Bayesian embedding;approximate inference;co-occurrence data embedding;co-occurrence data visualization;generative probabilistic model;high-dimensional space;inference intractability;posterior distribution;query based visualization;variational approach","","1","","10","","","18-21 Dec. 2011","","IEEE","IEEE Conference Publications"
"Fuzzy Orders-of-Magnitude-Based Link Analysis for Qualitative Alias Detection","Q. Shen; T. Boongoen","Aberystwyth University, Ceredigion","IEEE Transactions on Knowledge and Data Engineering","20120227","2012","24","4","649","664","Alias detection has been the significant subject being extensively studied for several domain applications, especially intelligence data analysis. Many preliminary methods rely on text-based measures, which are ineffective with false descriptions of terrorists' name, date-of-birth, and address. This barrier may be overcome through link information presented in relationships among objects of interests. Several numerical link-based similarity techniques have proven effective for identifying similar objects in the Internet and publication domains. However, as a result of exceptional cases with unduly high measure, these methods usually generate inaccurate similarity descriptions. Yet, they are either computationally inefficient or ineffective for alias detection with a single-property based model. This paper presents a novel orders-of-magnitude based similarity measure that integrates multiple link properties to refine the estimation process and derive semantic-rich similarity descriptions. The approach is based on order-of-magnitude reasoning with which the theory of fuzzy set is blended to provide quantitative semantics of descriptors and their unambiguous mathematical manipulation. With such explanatory formalism, analysts can validate the generated results and partly resolve the problem of false positives. It also allows coherent interpretation and communication within a decision-making group, using this computing-with-word capability. Its performance is evaluated over a terrorism-related data set, with further generalization over publication and email data collections.","1041-4347;10414347","","10.1109/TKDE.2010.255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5677516","Orders-of-magnitude reasoning;alias detection;fuzzy set;intelligence data.;link analysis;similarity measure","Algebra;Atmospheric measurements;Cognition;Electronic mail;Information retrieval;Particle measurements;Semantics","data analysis;decision making;fuzzy set theory","Internet;computing-with-word capability;decision-making group;estimation process;fuzzy orders-of-magnitude;fuzzy set;intelligence data analysis;link analysis;link property;numerical link-based similarity technique;order-of-magnitude reasoning;orders-of-magnitude based similarity measure;qualitative alias detection;semantic-rich similarity description;similar object identification;single-property based model;terrorism-related data set;text-based measures;unambiguous mathematical manipulation","","4","","61","","20101230","April 2012","","IEEE","IEEE Journals & Magazines"
"Information Extraction for Vietnamese Real Estate Advertisements","L. V. Pham; S. B. Pham","Fac. of Eng. & Technol., Quang Trung Univ., Vietnam","2012 Fourth International Conference on Knowledge and Systems Engineering","20120913","2012","","","181","186","Advertising has appeared in almost all areas of life. The large number of advertisements, especially in real estate domain, has raised a need for an effective way to search and find useful information for users. In this paper, we propose a rule-based approach to build an Information Extraction system for Vietnamese online real estate advertisements. Experimental results shows that our approach is very promising with an overall F-measure of 91% on a collection of data collected from popular Vietnamese real estate websites.","","Electronic:978-0-7695-4760-2; POD:978-1-4673-2171-6","10.1109/KSE.2012.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299417","information extraction;information extraction system;online real-estate advertising;real-estate;real-estate advertising","Data mining;Electronic mail;HTML;Information retrieval;Logic gates;Transducers","Internet;Web sites;advertising;information retrieval;real estate data processing","F-measure;Vietnamese online real estate advertisements;Vietnamese real estate Websites;information extraction;rule-based approach","","2","","","","","17-19 Aug. 2012","","IEEE","IEEE Conference Publications"
"Cost-Aware Rank Join with Random and Sorted Access","D. Martinenghi; M. Tagliasacchi","Politecnico di Milano, Milano","IEEE Transactions on Knowledge and Data Engineering","20121019","2012","24","12","2143","2155","In this paper, we address the problem of joining ranked results produced by two or more services on the web. We consider services endowed with two kinds of access that are often available: 1) sorted access, which returns tuples sorted by score; 2) random access, which returns tuples matching a given join attribute value. Rank join operators combine objects of two or more relations and output the k combinations with the highest aggregate score. While the past literature has studied suitable bounding schemes for this setting, in this paper we focus on the definition of a pulling strategy, which determines the order of invocation of the joined services. We propose the Cost-Aware with Random and Sorted access (CARS) pulling strategy, which is derived at compile-time and is oblivious of the query-dependent score distributions. We cast CARS as the solution of an optimization problem based on a small set of parameters characterizing the joined services. We validate the proposed strategy with experiments on both real and synthetic data sets. We show that CARS outperforms prior proposals and that its overall access cost is always within a very short margin from that of an oracle-based optimal strategy. In addition, CARS is shown to be robust w.r.t. the uncertainty that may characterize the estimated parameters.","1041-4347;10414347","","10.1109/TKDE.2011.161","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963672","Top-k;random access;rank join;sorted access","Context awareness;Information retrieval;Optimization;Relational databases;Search engines;Upper bound","Web services;query processing;search engines","CARS pulling strategy;Web services;bounding schemes;cost-aware rank join;cost-aware with random and sorted access pulling strategy;join attribute value;optimization problem;oracle-based optimal strategy;parameter estimation;pulling strategy;query-dependent score distributions;rank join operators;real data sets;synthetic data sets","","2","","25","","20110728","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Recommending relevant code artifacts for change requests using multiple predictors","O. Denninger","FZI Research Center for Information Technology, Karlsruhe, Germany","2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE)","20120709","2012","","","78","79","Finding code artifacts affected by a given change request is a time-consuming process in large software systems. Various approaches have been proposed to automate this activity, e.g., based on information retrieval. The performance of a particular prediction approach often highly depends on attributes like coding style or writing style of change request. Thus, we propose to use multiple prediction approaches in combination with machine learning. First experiments show that machine learning is well suitable to weight different prediction approaches for individual software projects and hence improve prediction performance.","2327-0934;23270934","Electronic:978-1-4673-1759-7; POD:978-1-4673-1758-0","10.1109/RSSE.2012.6233416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6233416","recommendation systems;software maintenance","Indexing;Information retrieval;Machine learning;Neural networks;Software engineering;Software maintenance","learning (artificial intelligence);recommender systems;software maintenance","automated activity;change requests;code artifacts finding;coding style;individual software projects;information retrieval;large software systems;machine learning;multiple prediction approach;prediction performance;relevant code artifacts recommendation;time-consuming process;writing style","","0","","9","","","4-4 June 2012","","IEEE","IEEE Conference Publications"
"Semantic query expansion and context-based discriminative term modeling for spoken document retrieval","T. w. Tu; H. y. Lee; Y. y. Chou; L. s. Lee","Graduate Institute of Computer Science and Information Engineering, National Taiwan University, Taiwan","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","5085","5088","In this paper, we propose a semantic query expansion approach by extending the query-regularized mixture model to include latent topics and apply it to spoken documents. We also propose to use context feature vectors for spoken segments to train SVM models to enhance the posterior-weighted normalized term frequencies in lattices. Experiments on Mandarin broadcast news showed that this approach offered good improvements when applied on spoken documents including relatively high recognition errors.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6289064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6289064","Semantic Retrieval;Spoken Term Detection","Context;Context modeling;Information retrieval;Lattices;Manuals;Semantics;Support vector machines","natural language processing;query processing;semantic networks;speech recognition;support vector machines","Mandarin broadcast news;SVM models;context feature vectors;context-based discriminative term modeling;posterior-weighted normalized term frequency;query-regularized mixture model;semantic query expansion approach;speech recognition errors;spoken document retrieval;spoken segments;support vector machine","","4","","9","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Web-Scale Multimedia Information Networks","G. J. Qi; M. H. Tsai; S. F. Tsai; L. Cao; T. S. Huang","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana , IL, USA","Proceedings of the IEEE","20120816","2012","100","9","2688","2704","The abundance of multimedia data on the Web presents both challenges (how to annotate, search, and mine) and opportunities (crawling the Web to create large structured multimedia data bases which can be used to do inference effectively). Because of the huge data volume, considering all semantic concepts as on the same (flat) level is not viable. In this paper, we introduce a unified STRUCTURED representation called multimedia information networks (MINets), which incorporates ontology and cross-media links, covering both content and context knowledge. Ontology and cross-media structures are constructed and expanded by automatically constructing MINets from web-scale data by state-of-the-art information extraction and knowledge-based population techniques. The resultant MINet will contain a wide range of linkages, including logical, statistical, and semantic relations among informative concept nodes, which connects proliferative ontology as well as cross-media web-scale resources together. The raw data collected in construction phase often contain much noisy, incomplete, or even conflicting information which could be detrimental to information extraction and utilization. Then, the redundant link structure can be utilized to distill MINets and improve quality of information (QoI). Moreover, advanced inference theory and system can be built upon the linked MINets, and then high-level ontological knowledge can be inferred and integrated in a logically harmonious network structure in MINets which is consistent with human cognition. Even more, as information channels, the ontology and cross-media links in MINets connect informative knowledge resources together, which makes it possible to increase the portability of information between different resources to increase information utilization levels.","0018-9219;00189219","","10.1109/JPROC.2012.2201909","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6248667","Multimedia information networks;web-scale multimedia content","Content management;Feature extraction;Information retrieval;Multimedia communication;Ontologies;Semantics;Streaming media;Web servers","","","","10","","86","","20120725","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Method of Information Extracting from Section Map Based on ActiveX Technology","X. p. Wang; T. c. Jiang","Sch. of Geodesy &amp; Geomatics Eng., Huaihai Inst. of Technol. Name of Organ., Lianyungang, China","2012 International Conference on Computer Science and Service System","20121231","2012","","","147","150","In the production of hydrographic surveying, a lot of inside work are still manually completed, time-consuming and error-prone, such as dimensioning of Basal Area and table. This paper discusses extracting river cross-sectional information from CAD with ActiveX software integration technology, some information is also processed and excavated, and Basal Area and earthwork table are automatically completed. Therefore these works achieve greater efficiency and quality of work. Undoubtedly, it has great applied value.","","Electronic:978-0-7695-4719-0; POD:978-1-4673-0721-5","10.1109/CSSS.2012.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394282","","Data mining;Industries;Information retrieval;Rivers;Software;Software measurement;Surface topography","CAD;distributed object management;geophysics computing;hydrological techniques;information retrieval;integrated software;rivers;surveying","ActiveX software integration technology;CAD;basal area dimensioning;earthwork table;hydrographic surveying production;river cross-sectional information extraction;section map","","0","","6","","","11-13 Aug. 2012","","IEEE","IEEE Conference Publications"
"Statistical Entity Extraction From the Web","Z. Nie; J. R. Wen; W. Y. Ma","Microsoft Research Asia, Beijing, P. R. China","Proceedings of the IEEE","20120816","2012","100","9","2675","2687","There are various kinds of valuable semantic information about real-world entities embedded in webpages and databases. Extracting and integrating these entity information from the Web is of great significance. Comparing to traditional information extraction problems, web entity extraction needs to solve several new challenges to fully take advantage of the unique characteristic of the Web. In this paper, we introduce our recent work on statistical extraction of structured entities, named entities, entity facts and relations from Web. We also briefly introduce iKnoweb, an interactive knowledge mining framework for entity information integration. We will use two novel web applications, Microsoft Academic Search (aka Libra) and EntityCube, as working examples.","0018-9219;00189219","","10.1109/JPROC.2012.2191369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6218157","Crowdsourcing;entity extraction;entity relationship mining;entity search;interactive knowledge mining;named entity extraction;natural language processing;web page segmentation","Data mining;Feature extraction;Information retrieval;Knowledge representation;Layout;Search engines;Semantics;Visualization;Web pages","","","","2","","39","","20120614","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Sensitive Information Acquisition Based on Machine Learning","W. Shang; H. Liu; R. Lv","Sch. of Comput., Commun. Univ. of China, Beijing, China","2012 International Conference on Industrial Control and Electronics Engineering","20121004","2012","","","1117","1119","With the rapid development of Internet, online information has greatly enriched. The Internet becomes a vast treasure of information, but simultaneously it is also flooding various trash information, such as: viruses, Trojans, violence, pornography, gambling and so on. The hostile forces outside of country and criminal elements are using the Internet to engage in illegal activities that endanger national security. So how to recognize this information to find the corresponding website and to carry on the effective supervision has become an urgent problem. For these reasons, this paper designs a new web information extraction system, which calls the extraction rule corresponding to the template by calculating the structural similarity among pages. In addition, a new method based on STU-DOM tree to construct decision tree is proposed. This method can use the classification of decision tree to determine sensitive information node.","","Electronic:978-1-4673-1449-7; POD:978-1-4673-1450-3","10.1109/ICICEE.2012.296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322585","DOM;information extraction;machine learning;sensitive information","Accuracy;Algorithm design and analysis;Data mining;Databases;Decision trees;Feature extraction;Information retrieval","Internet;Web sites;computer crime;computer viruses;decision trees;information dissemination;information retrieval;information retrieval systems;learning (artificial intelligence);national security;pattern classification","Internet;STU-DOM tree;Trojans;Web information extraction system;Website;criminal elements;decision tree classification;extraction rule;gambling;illegal activities;machine learning;national security;online information;pornography;sensitive information acquisition;structural similarity;trash information;violence;viruses","","0","","6","","","23-25 Aug. 2012","","IEEE","IEEE Conference Publications"
"Classification of Turkish Maqam music using k-means algorithm and artificial neural networks","İ. Kalaycı; S. Korukoğlu","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l &#x00FC;m&#x00FC;, Dokuz Eyl&#x00FC;l &#x00DC;niversitesi, Turkey","2012 20th Signal Processing and Communications Applications Conference (SIU)","20120528","2012","","","1","4","In this study a proposal is made to classify the maqams of songs in Turkish Maqam Music. The MIRToolbox (a toolbox for MATLAB) is used to extract the features which are used in audio and music processing. Obtained data are preprocessed by principal component analysis. The songs are clustered by k-means algorithm and classified by feed forward artificial neural networks according to their maqams.","2165-0608;21650608","Electronic:978-1-4673-0056-8; POD:978-1-4673-0055-1; USB:978-1-4673-0054-4","10.1109/SIU.2012.6204675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6204675","","Application software;Feature extraction;Internet;Mel frequency cepstral coefficient;Music information retrieval;Neural networks;USA Councils","audio signal processing;feature extraction;feedforward neural nets;music;pattern clustering;principal component analysis;signal classification","MATLAB toolbox;MIRToolbox;Turkish Maqam music classification;audio processing;clustering;feature extraction;feed forward artificial neural network;k-means algorithm;music processing;principal component analysis","","3","","24","","","18-20 April 2012","","IEEE","IEEE Conference Publications"
"A domain knowledge-based approach for automatic correction of printed invoices","E. Sorio; A. Bartoli; G. Davanzo; E. Medvet","DI3 - Industrial and Information Engineering Dept., University of Trieste, Via Valerio 10, Italy","International Conference on Information Society (i-Society 2012)","20120827","2012","","","151","155","Although OCR technology is now commonplace, character recognition errors are still a problem, in particular, in automated systems for information extraction from printed documents. This paper proposes a method for the automatic detection and correction of OCR errors in an information extraction system. Our algorithm uses domain-knowledge about possible misrecognition of characters to propose corrections; then it exploits knowledge about the type of the extracted information to perform syntactic and semantic checks in order to validate the proposed corrections. We assess our proposal on a real-world, highly challenging dataset composed of nearly 800 values extracted from approximately 100 commercial invoices and we obtained very good results.","","Electronic:978-1-908320-05-6; POD:978-1-4673-0838-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6285067","document understanding;error correction;error detection;optical character recognition","Information retrieval;Joints;Optical character recognition software;Semantics;Syntactics;Text analysis","document handling;error correction;error detection;information retrieval;invoicing;knowledge based systems;optical character recognition","OCR technology;automatic OCR error correction;automatic OCR error detection;automatic information extraction system;automatic printed invoice correction;character misrecognition;character recognition errors;commercial invoices;domain knowledge-based approach;printed documents;semantic checks;syntactic checks","","0","","13","","","25-28 June 2012","","IEEE","IEEE Conference Publications"
"The Answer Is Out There: Online Q&A Sites","A. Uduwage; J. A. Konstan","University of Minnesota","Computer","20120629","2012","45","7","90","92","A diverse set of online question and answer sites has emerged for users seeking information beyond simple search queries.","0018-9162;00189162","","10.1109/MC.2012.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6228582","Q&A sites;social computing;social networks","Information retrieval;Internet;Search engines;Search methods;Social network services;Web sites","Web sites;query processing;question answering (information retrieval)","online Q&A sites;online question and answer sites;query searching","","0","","","","","July 2012","","IEEE","IEEE Journals & Magazines"
"Folksonomy-based Indexing for Retrieving Tutoring Resources","W. C. Shih; S. S. Tseng","Dept. of Appl. Inf. & Multimedia, Asia Univ., Taichung, Taiwan","2012 IEEE Seventh International Conference on Wireless, Mobile and Ubiquitous Technology in Education","20120419","2012","","","97","101","As more and more undergraduate students act as voluntary tutors to rural pupils after school, there is a growing need for a resource repository to support tutors during their tutoring process. However, when tutoring resources are not text-based, such as a clip of Flash animation, the technology of conventional information retrieval cannot be simply applied to retrieve these resources. Therefore, we propose a folksonomy-based indexing method to improve the performance of retrieving non-textual tutoring resources. The proposed approach consists of an initializing phase and a self-organizing phase. This study investigates the performance of constructing and maintaining the folksonomy-based index. In addition, the attitudes of tutors toward the folksonomy-based indexing method are addressed. A prototype of the tutoring resource repository has been designed and implemented, and experiments have been conducted to evaluate the proposed approach. The results show that the folksonomy-based index can be constructed and maintained efficiently. Also, survey on tutors shows the proposed approach can help them find relevant resources efficiently.","","Electronic:978-0-7695-4662-9; POD:978-1-4673-0884-7","10.1109/WMUTE.2012.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185005","folksonomy;relevance;self-organizing indexing;tutoring resource repositories;volunteer tutors","Education;Games;Indexing;Information retrieval;Materials;Ontologies","computer aided instruction;indexing;information retrieval","Flash animation;folksonomy-based indexing;information retrieval;initializing phase;nontextual tutoring resource retrieval;self-organizing phase;tutoring resource repository;undergraduate student;voluntary tutor","","2","","6","","","27-30 March 2012","","IEEE","IEEE Conference Publications"
"Automatic exploitation of multilingual information for military intelligence purposes","S. Noubours; M. Hecking","Fraunhofer Institute for Communication, Information Processing and Ergonomics FKIE, D-53343Wachtberg, Germany","2012 Military Communications and Information Systems Conference (MCC)","20121220","2012","","","1","8","Intelligence plays an important role in supporting military operations. In the course of military intelligence a vast amount of textual data in different languages needs to be analyzed. In addition to information provided by traditional military intelligence, nowadays the internet offers important resources of potential militarily relevant information. However, we are not able to manually handle this vast amount of data. The science of natural language processing (NLP) provides technology to efficiently handle this task, in particular by means of machine translation and text mining. In our research project ISAF-MT we created a statistical machine translation (SMT) system for Dari to German. In this paper we describe how NLP technologies and in particular SMT can be applied to different intelligence processes. We therefore argue that multilingual NLP technology can strongly support military operations.","","Electronic:978-83-920120-9-2; POD:978-1-4673-1422-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6387890","Statistical machine translation;military intelligence;natural language processing;open source intelligence","Data mining;Information retrieval;Internet;Natural language processing;Terrorism;Training;Training data","Internet;data analysis;data mining;information resources;language translation;military computing;natural language processing;statistical analysis;text analysis","Dari language;German language;ISAF-MT research project;Internet;SMT system;data handling;intelligence process;military intelligence purpose;military operations;multilingual NLP technology;multilingual information;natural language processing;potential militarily relevant information resource;statistical machine translation system;text mining;textual data analysis","","0","","21","","","8-9 Oct. 2012","","IEEE","IEEE Conference Publications"
"A Similarity-Oriented RDF Graph Matching Algorithm for Ranking Linked Data","D. Zhang; T. Song; J. He; X. Shi; Y. Dong","Sch. of Software, Yunnan Univ., Kunming, China","2012 IEEE 12th International Conference on Computer and Information Technology","20121224","2012","","","427","434","Linked Data is an RDF-based transition from the document oriented Web into the Semantic Web, and the amount of data published as linked data steadily. Hence, The RDF graph matching algorithm becomes the technical foundation of many tasks in Semantic Web, such as semantic search, data fusion, ontology matching, data filter and dissemination. An RDF-graph-matching-based query can enables searching with additional semantic information, so that it can be utilized for obtaining expected ranking in semantic search and personalized information retrieval on the web of data. Yet, the need for this approach is disregarded. This paper proposes a novel similarity-oriented RDF graph matching approach for ranking linked data, which considering the element-level and structure-level similarity of statements, and also the similarity of URIs and blank nodes in RDF graphs. The efficiency of this approach is improved over the traditional RDF graph matching algorithm. And the effectiveness is improved by analyzing and measuring the structure-level similarity of statements. The experimental results shows that this approach can effectively measure the similarity between RDF graphs, and also returns results with respect to a query RDF graph as a ranked set of promising alternatives.","","Electronic:978-0-7695-4858-6; POD:978-1-4673-4873-7","10.1109/CIT.2012.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391938","RDF Graph Matching Approach;Ranking Linked Data;Structure Similarity","Educational institutions;Information retrieval;Pragmatics;Resource description framework;Semantics;Software;Software algorithms","document handling;graph theory;information filtering;ontologies (artificial intelligence);pattern matching;semantic Web","RDF based transition;Semantic Web;data dissemination;data filter;data fusion;document oriented Web;information retrieval;ontology matching;ranking linked data;resource description framework;semantic search;similarity oriented RDF graph matching algorithm","","1","","25","","","27-29 Oct. 2012","","IEEE","IEEE Conference Publications"
"A Query Reformulation Model Using Markov Graphic Method","J. Zuo; M. Wang","Sch. of Inf. Technol., Jiangxi Univ. of Finance & Econ., Nanchang, China","2011 International Conference on Asian Language Processing","20120102","2011","","","119","122","Information retrieval model is still can not achieve satisfactory performance after decades of development. One of the reasons is the queries can not express information need precisely. Researches have shown that query reformulation can improve the performance of retrieval model. In this paper, we propose a query reformulation model, which use Markov network to represent term relationship to obtain useful information from corpus to reformulate query. Experimental results show that our model can avoid topic drift and then improve the retrieval performance.","","Electronic:978-0-7695-4554-7; POD:978-1-4577-1733-8","10.1109/IALP.2011.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121484","Markov network;query reformulation","Computational modeling;Educational institutions;Graphics;Information retrieval;Markov random fields;Semantics","Markov processes;query processing","Markov graphic method;Markov network;information need;information retrieval model;query reformulation model;satisfactory performance","","1","","18","","","15-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"Searching the Internet","M. Andrews","Microsoft","IEEE Software","20120220","2012","29","2","13","16","This column differs somewhat from previous ones in that the software itself isn't shipped-rather, the results of the software are shipped, and in huge numbers. Mike Andrews of Microsoft reveals some of the intricacies and enormous resources required for successful Web search with a fascinating glimpse into the Bing search engine.","0740-7459;07407459","","10.1109/MS.2012.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155137","bing;hardware;internet scale;microsoft;search engine;servers;software engineering;technology;web","Information retrieval;Search engines;Search problems;Web and internet services","Internet;search engines","Bing search engine;Internet;Microsoft;Web search;software","","5","","1","","","March-April 2012","","IEEE","IEEE Journals & Magazines"
"Smart IVR Service Platform","A. Chotimongkol; N. Thatphithakkul; P. Prathombutr","Nat. Electron. & Comput. Technol. Center (NECTEC), Pathumthani, Thailand","2012 Annual SRII Global Conference","20120924","2012","","","426","434","The traditional IVR or Interactive Voice Response is a voice interface with a computer over a phone line. To avoid the burden to hold the IVR hardware and software, we introduce the Smart IVR which is organized in the same concept with a cloud computing. It includes an IaaS, a PaaS and a SaaS platform. The designed architecture of the IVR composes of APIs for a developer like a Text-to-Speech API in the PaaS layer. In the SaaS layer, one may build their own IVR dialog in a snap over a Dialog Management module. Unlike other cloud IVRs, the proposed IVR smartly handles the text information with the Dialog Management. It could link a dialog to a text message from various platforms such as RSS, Twitter, Facebook, Google Maps and database. The real case of IVR service innovations have been presented in the show case section and the discussion on Service Innovation is provided.","2166-0778;21660778","Electronic:978-1-5090-5643-9; POD:978-1-4673-2318-5; USB:978-0-7695-4770-1","10.1109/SRII.2012.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311022","IVR;Interactive Voice Response;cloud computing;cloud service;speech technology","Cloud computing;Computer architecture;Computers;Hidden Markov models;Information retrieval;Speech;Speech recognition","application program interfaces;cloud computing;interactive systems;speech synthesis","Facebook;Google Maps;IVR dialog;IaaS platform;PaaS platform;RSS;SaaS platform;Twitter;cloud computing;dialog management module;interactive voice response;smart IVR service platform;text information;text message;text-to-speech API;voice interface","","1","","13","","","24-27 July 2012","","IEEE","IEEE Conference Publications"
