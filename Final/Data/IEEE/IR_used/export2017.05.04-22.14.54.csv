"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7079295,6880398,7072807,7074098,7078550,7078635,7072844,7073834,7078615,7072826,7073369,7078623,7072843,7072808,7072846,7072747,7078804,7078674,7078736,7070005,7069959,7071705,7070262,7070320,7065583,7065556,7065543,7065845,7066262,7065895,7065760,7065894,7065550,7065758,7068110,7065709,7065754,7065555,7068176,7069175,7065022,7064416,7061702,7062828,7062720,7058188,7062663,7062690,7061026,7060902,7060095,7061020,7029630,7046419,7057006,7058051,7056791,7057092,7058097,7056849,7057176,7057981,7057984,7054452,7041225,7054141,7055140,6977920,7052497,7052496,6894569,7053841,6909004,6906267,6983613,7054096,6880816,7050816,7052049,7051901,7051984,7050803,7051966,7051421,7050832,7050848,7051937,7051455,7050798,7051329,7048165,7048170,7048275,7048179,7047530,7048210,7049880,7048172,7048202,7048162",2017/05/04 22:14:54
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An online feedback systemfor anonymous and credible feedback identification","D. Manchanda; P. Goyal; N. Khanna","Department of Computer Science and Engineering, Graphic Era University, Dehradun, Uttarakhand, India","2014 International Conference on Power, Control and Embedded Systems (ICPCES)","20150319","2014","","","1","6","This paper focuses on designing an online feedback management system that collects data in the form of suggestions, ratings and comments, and applies machine learning capabilities to automatically extract relevant summaries of the suggestions posted in this automated suggestion system. We have analyzed two key requirements, anonymous feedback and credible feedback, to gain insight on the submitted ""suggestions"" as for how to improve an organization, a course, or any decision involving evolutionary system. These two highly desirable requirements are kind of contradictory since it is perhaps a rather obvious point that unless we know the person how will we know the credibility of his/her feedback - simultaneously addressing both of these requirements is the key research contribution of this paper. The proposed system will help in ensuring the anonymity as well as credibility of the feedback and automatic identification of relevant summaries of suggestions with minimal human endeavor during training phase.","","CD-ROM:978-1-4799-5909-9; Electronic:978-1-4799-5912-9; POD:978-1-4799-5913-6","10.1109/ICPCES.2014.7062828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062828","Anonymous feedback;credible feedback;machine learning;online feedback management system;overall ranking;suggestions","Context;Data privacy;Education;Electronic mail;Filtering;Reliability;Servers","Internet;educational administrative data processing;evolutionary computation;information retrieval;learning (artificial intelligence);security of data","anonymous feedback identification;automated suggestion system;automatic summary extraction;credible feedback identification;data collection;evolutionary system;machine learning capabilities;online feedback management system;training phase","","0","","10","","","26-28 Dec. 2014","","IEEE","IEEE Conference Publications"
"Recommending Documents for Complex Question Exploration by Analyzing Collective Browsing Behavior","A. Asarina; O. Simek","MIT Lincoln Lab., Lexington, MA, USA","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","1248","1255","Vast amounts of data available online and in other digital repositories make it challenging for users to find the right sources of information. In this paper, we present a novel approach for recommending documents to users by analyzing user browsing behavior, and demonstrate the effectiveness of our methods using an original data set. We conducted a study to collect a novel data set of document browsing behavior observed as users research complex questions. Based on this dataset, we developed machine learning algorithms to predict which documents are useful and should therefore be recommended. Following the intuition that useful documents are likely to be similar to other documents that are useful for the same task, we incorporated features based on measures of similarity between pairs of documents. Accurately computing similarity between documents is challenging due to the high dimensionality of bag-of-words representations (tens of thousands of dimensions). We therefore used several dimensionality reduction techniques, including Canonical Correlation Analysis, in order to project bag-of-words representations into meaningfully reduced spaces. We show that our algorithms significantly outperform baseline approaches on three different prediction tasks. Our work thus lays out a new direction for recommendation algorithms based on a relatively small amount of labeled data.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069959","browsing history;dimensionality reduction;document prioritization;question answering;recommender systems","Algorithm design and analysis;Correlation;History;Prediction algorithms;Recommender systems;Semantics;Vectors","data reduction;document handling;information retrieval;learning (artificial intelligence);recommender systems","bag-of-word representations;canonical correlation analysis;digital repositories;dimensionality reduction techniques;document similarity;machine learning algorithms;recommendation algorithms;user document browsing behavior analysis","","0","","29","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"A Fast Classification Scheme in Raman Spectroscopy for the Identification of Mineral Mixtures Using a Large Database With Correlated Predictors","C. J. Cochrane; J. Blacksberg","Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA","IEEE Transactions on Geoscience and Remote Sensing","20150313","2015","53","8","4259","4274","Robust classification methods are vital to the successful implementation of many material characterization techniques, particularly where large databases exist. In this paper, we demonstrate an extremely fast classification method for the identification of mineral mixtures in Raman spectroscopy using the large RRUFF database. However, this method is equally applicable to other techniques meeting the large database criteria, these including laser-induced breakdown, X-ray diffraction, and mass spectroscopy methods. Classification of these multivariate datasets can be challenging due in part to the various obscuring features inherently present within the underlying dataset and in part to the volume and variety of information known a priori. Some of the more specific challenges include the observation of mixtures with overlapping spectral features, the use of large databases (i.e., the number of predictors far outweighs the number of observations), the use of databases that contain groups of correlated spectra, and the ever present, clouding contaminants of noise, undesired background, and spectrometer artifacts. Although many existing classification algorithms attempt to address these problems individually, not many address them as a whole. Here, we apply a multistage approach, which leverages well-established constrained regression techniques, to overcome these challenges. Our modifications to conventional algorithm implementations are shown to increase speed and performance of the classification process. Unlike many other techniques, our method is able to rapidly classify mixtures while simultaneously preserving sparsity. It is easily implemented, has very few tuning parameters, does not require extensive parameter training, and does not require data dimensionality reduction prior to classification.","0196-2892;01962892","","10.1109/TGRS.2015.2394377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7046419","Classification;Raman spectroscopy;elastic net (EN);planetary mineralogy;regression","Databases;Minerals;Noise;Photonics;Prediction algorithms;Raman scattering;Rocks","Raman spectra;Raman spectroscopy;feature extraction;feature selection;geophysical techniques;geophysics computing;image classification;information retrieval systems;minerals;optical correlation;remote sensing","RRUFF database criteria;Raman spectroscopy-based classification scheme;X-ray diffraction technique;constrained regression techniques;correlated predictors;correlated spectra-containing databases;data dimensionality reduction;extensive parameter training;fast image classification scheme;fast mineral mixture classification method;image classification process performance;image classification process speed;laser-induced breakdown technique;mass spectroscopy method;material characterization technique implementation;mineral mixture classification algorithm;mineral mixture identification method;mineral mixture information variety;mineral mixture information volume;mineral mixture overlapping spectral features;multistage approach;multivariate dataset classification;multivariate dataset features;noise clouding contaminant-containing databases;rapid mineral mixture classification method;robust classification methods;sparsity preservation;spectrometer artifact-containing databases;tuning parameters;undesired background-containing databases","","2","","43","","20150220","Aug. 2015","","IEEE","IEEE Journals & Magazines"
"A study on the prevalence of musculoskeletal disorders among health care workers at a private medical centre","B. M. Deros; M. Adilah; D. D. I. Daruis","Department of Mechanical and Materials Engineering, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia, 43600 Bangi, Selangor, Malaysia","2014 IEEE Conference on Biomedical Engineering and Sciences (IECBES)","20150226","2014","","","403","407","A study was conducted among healthcare workers performing manual handling tasks at a private medical center (PMC) in Selangor to determine the prevalence of musculoskeletal disorders (MSDs). A total of 103 workers of the PMC were selected through simple random sampling which comprise of 32 respondents for administrative group and another 71 respondents for operative group of Malaysian citizen, not pregnant and never been involved with any type of accident that involved musculoskeletal system. Modified questionnaire was used to gather the information of respondents. In this study, Body Parts Symptoms Survey (BPSS) form was used to determine which of 12 body parts were exposed to the MSDs risks that can be associated with manual handling tasks. For assessment of manual handling, a posture-based analysis system for Rapid Entire Body Assessment (REBA) responsive to musculoskeletal risks in various tasks was used. Lower back region indicated the highest prevalence (21.4%) of MSDs among workers in PMC followed by shoulder (14.6%) and neck (13.6%). For assessment of manual handling, there was significant difference of REBA score between administrative and operational workers (Z = 3.501, p = 0.001). Manual handling was significantly associated with MSDs that involved all body parts for operative workers while for administrative workers, manual handling was significantly associated with shoulder (r = 0.376, p = 0.034), upper back (r = 0.473, p = 0.010), elbow (r = 0.397, p = 0.024), lower back (r = 0.337, p = 0.050) and arm (r = 0.478, p = 0.016). In conclusion, the prevalence of MSDs among healthcare workers is high at lower back region and there was significant association between manual handling and MSDs among them.","","Electronic:978-1-4799-4084-4; POD:978-1-4799-4083-7","10.1109/IECBES.2014.7047530","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047530","","Back;Manuals;Musculoskeletal system;Neck;Pain;Shoulder","bone;diseases;health care;medical disorders;muscle;patient diagnosis;question answering (information retrieval);research initiatives;sampling methods","BPSS form;MSD prevalence determination;MSD risk-exposed body parts;MSD-associated manual handling;Malaysian citizen;REBA score;Selangor medical centre;administrative group respondents;administratived operational workers;body parts symptoms survey;health care worker disorders;lower back region MSD prevalence;manual handling assessment;manual handling task-associated MSD risk;musculoskeletal disorder prevalence;musculoskeletal risks;musculoskeletal system-related accidents;neck MSD prevalence;operative group respondents;posture-based analysis system;private medical centre health care worker;random sampling;rapid entire body assessment;shoulder MSD prevalence","","0","","20","","","8-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"What Do Doctors Need for Effective Adoption and Integration of Clinical Guidelines into Daily Practice?","M. Campos; B. García; J. M. Juárez; J. M. Guillamón; F. Palacios","Dept. Inf. & Syst., Univ. of Murcia, Murcia, Spain","2014 IEEE International Conference on Healthcare Informatics","20150305","2014","","","247","255","Catheter-related bloodstream infection (CRBSI) is one of the major existing problems in Intensive Care Units (ICU). CRBSI has a high prevalence and its treatment is quite costly in time and medication. One of the essential efforts in the diagnosis and treatment of CRBSI is the use of existing Clinical Guidelines (CG). Nevertheless, its adoption and integration into daily practice is quite complex due to the lack of software tools that cover all the needs. Considering this problem, in this work we identify some of the needs detected in daily work, and we present two tools for ICUs that makes the introduction of CGs and patient's data visualization simple. As a first goal we propose to obtain a computerized model of the clinical guideline. Gewel is an application that allows the mapping of a textual CG into a workflow model. In this tool we propose a process that (1) organizes the parts of the textual document according to GEM, (2) maps concepts to the Electronic Health Record (EHR) system, called CH4, so that it can automatically retrieve data and send HL7 messages, (3) supports the design of a workflow model that assists the following up of the steps and the measure of adherence to the CG, and (4) according to Evidence Based Medicine principles, allows the doctors to trace from the task or decision point of the workflow to the exact part of the document where it was originated. Once the CG is computerized and integrated in the EHR, the next goal is to identify key clinical problems, such as CRBSI, and retrieve the relevant information from the EHR. Due to the big amount of the EHR data registered in an ICU, physician's attention should be drawn to the clinical information related to the problem to be solved. We propose a mobile application, called mProblem View, that permits to establish and visualize relations between the elements of the EHR in a Problem-Oriented EHR approach.","","Electronic:978-1-4799-5701-9; POD:978-1-4799-5702-6; USB:978-1-4799-5700-2","10.1109/ICHI.2014.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7052497","","Computational modeling;Guidelines;Medical diagnostic imaging;Medical services;Mobile communication;Standards;XML","electronic health records;information retrieval;mobile computing","CG;CH4;CRBSI;CRBSI diagnosis;CRBSI treatment;EHR system;Gewel application;ICU;automatic HL7 message sending;automatic data retrieval;catheter-related bloodstream infection;clinical guideline adoption;clinical guideline integration;clinical guidelines;clinical information;computerized model;electronic health record system;evidence based medicine principles;intensive care units;mProblemView;mobile application;patient data visualization;physician attention;problem-oriented EHR approach;relation visualization;textual CG mapping;textual document organization;workflow model","","0","","39","","","15-17 Sept. 2014","","IEEE","IEEE Conference Publications"
"Snap n' shop: Visual search-based mobile shopping made a breeze by machine and crowd intelligence","Q. You; J. Yuan; J. Wang; P. Guo; J. Luo","Department of Computer Science, University of Rochester, NY 14627, USA","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","173","180","The increasing popularity of smartphones has significantly changed the way we live. Today's powerful mobile systems provide us with all kinds of convenient services. Thanks to the wide variety of available apps, it has never been so easy for people to shop, to navigate, and to communicate with others. However, for some tasks we can further improve the user experience by employing newly developed algorithms. In this work, we try to improve visual search based mobile shopping experience by using machine and crowd intelligence. In particular, our system enables precise object selection, which would lead to more accurate visual search results. We also use crowdsourcing to further extend the system's prowess. We conduct experiments on user interface design and retrieval performance, which validate the effectiveness and ease of use of the proposed system. Meanwhile, components in the system are quite modular, allowing the flexibility of adding or improving different modules of the whole system.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050803","","Databases;Internet;Servers","information retrieval;retail data processing;smart phones;user interfaces","Snap n Shop;crowd intelligence;machine intelligence;object selection;retrieval performance;smart phone;user experience;user interface design;visual search-based mobile shopping","","2","","17","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Semantic Search over DICOM Repositories","L. A. B. Silva; C. Costa; J. L. Oliveira","DETI, Univ. of Aveiro, Aveiro, Portugal","2014 IEEE International Conference on Healthcare Informatics","20150305","2014","","","238","246","The integration of semantic representation in medical information systems has been seen as a key opportunity to achieve full interoperability between distinct technical solutions and to extract knowledge from existing repositories. In this paper, we propose an ontology-based medical imaging archive that provides a generic, dynamic and standard architecture to interrogate the repository. Moreover, the solution flexibility makes possible to improve the search results only by updating the ontologies used, without any changes in the software implementation. This archive is based on a triple store that follows the Rad Lex ontology. To validate the proposed system, the performance of storage and search queries were compared against the results obtained in a traditional PACS archive.","","Electronic:978-1-4799-5701-9; POD:978-1-4799-5702-6; USB:978-1-4799-5700-2","10.1109/ICHI.2014.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7052496","DICOM;Medical Imaging;PACS;Semantic Data","DICOM;Medical services;Ontologies;Picture archiving and communication systems;Semantics;Standards","PACS;information retrieval systems;knowledge acquisition;ontologies (artificial intelligence);open systems;query processing","DICOM repository;PACS archive;Rad Lex ontology;interoperability;knowledge extraction;medical information system;ontology-based medical imaging archive;search query;semantic representation;semantic search;software implementation;solution flexibility;triple store","","1","","26","","","15-17 Sept. 2014","","IEEE","IEEE Conference Publications"
"Adaptation of composite E-Learning contents for reusable in smartphone based learning system","H. Toile; K. h. Arai; A. Pinandito","Informatics Department, PTIIK, Brawijaya University, Malang, Indonesia","2014 International Conference on Advanced Computer Science and Information System","20150326","2014","","","502","507","Most of the previous E-Learning contents developed for Personal Computer (PC) is not accessible on the new device like Smartphone. The problem is the learning contents may not be supported by the current mobile devices technology. In this paper, we propose a method for adapting an old composite PC-based e-learning content and delivering it onto mobile devices. The proposed method performs information extraction, transcoding and then generates a new content as a web service for smartphone application. The method performs 100% successfully on extract the samples content using Microsoft Producer and generate new content for accesing on Smartphone. Usability test show the accepted score 94%.","","Electronic:978-1-4799-8075-8; POD:978-1-4799-8076-5; USB:978-1-4799-8074-1","10.1109/ICACSIS.2014.7065895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065895","","Androids;Decision support systems;Electronic learning;Engines;HTML;Humanoid robots;Transcoding","Web services;computer aided instruction;information retrieval;microcomputers;smart phones;software reusability;transcoding","Microsoft Producer;Web service;composite PC-based e-learning content adaptation;information extraction;mobile device technology;personal computer;smartphone application;smartphone based learning system;transcoding;usability test","","1","","12","","","18-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"A study to assess and enhance educational specific search on web for school children","S. Gaurav; J. Y; A. Adil; S. Yadav; B. Kasturi","CSE, SMIT, Sikkim, India","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","260","263","Today, search engines play a vital role in accessing the online content. However, the data in the webpages are not clearly perceived by search engines. As a result, it provides a lot of irrelevant data with little desired information. In addition, it takes a lot of time in searching the appropriate result. By studying the online educational needs of Indian school children, we aim to retrieve appropriate educational information in less time through effective search. Schema.org [5] is a collection of markups which helps webmasters to mark up the webpages for retrieval of relevant information. But, properties related to education are not covered completely. Learning Resource Metadata Initiative (LRMI) [9] has created few properties for education and added in schema.org. We map our study with LRMI's work, and propose some new properties as an extension to the schema, which can be useful for students and teachers.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050816","LRMI;Schema;Schema.org;School children;Semantics;Teachers","Educational institutions;Internet;Materials;Training","Web sites;educational computing;information retrieval;meta data;search engines","Indian school children;LRMI;Web pages;educational information retrieval;educational specific search assessment;learning resource metadata initiative;online content accessment;online educational needs;schema.org;search engines","","0","","9","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Towards activity-based app search","A. Forte; Wei Wang","AT&T Labs, USA","2015 Eighth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)","20150316","2015","","","42","47","We introduce a novel way to search and recommend mobile applications namely, activity-based app search. Keywords used in activity-based app search are terms such as “drinking coffee”, “during a flight”, “cooking with friends”, “driving”. We define context as What, Where, When and Whom. The results returned by activity-based app search are apps that can be used while performing the activity specified in the search (What) at a certain time (When) in a certain place (Where) within a social context (Whom). The use of any of the returned apps and the activity performed by the user will not interfere with each other. For example, activity-based app search for “cooking” will return apps to use while cooking such as Pandora Internet Radio while a traditional search for “cooking” would return apps for cooking such as cookbook apps. Out of all the many challenges that this new search paradigm introduces, we focus on the activity (i.e., What) as it is the most challenging and novel of all four.","","Electronic:978-4-9076-2612-9; POD:978-1-4799-5592-3; USB:978-4-9076-2621-1","10.1109/ICMU.2015.7061026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061026","","Context;Ear;Internet;Mobile communication;Mobile computing;Mouth;Servers","Internet;information retrieval;mobile computing","Pandora Internet Radio;activity-based app search;cookbook apps;returned apps;search paradigm","","0","","19","","","20-22 Jan. 2015","","IEEE","IEEE Conference Publications"
"Design web service academic information system based multiplatform","M. L. Pandini; Z. Arifin; D. M. Khairina","Computer Science, Math and Natural Science Faculty, Mulawarman University, Samarinda, Indonesia","2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering","20150326","2014","","","297","302","Academic Information is very important for college students and should be conveyed to all students equally. But as is well known that a lot of students make the staff of college cannot convey information in a personal one by one on each student. In order to support good communication, synchronized, and quick to students. College facilitates through conventional media announcement. Academic Information that is conveyed conventionally to students through flyers and bulletin board are often distributed ineffectively. Besides that, students are also bothered by having to come to campus every day just to see the latest announcements on the bulletin board. The purpose of this research is to design and build a multiplatform application that can be accessed through android platform and browser with same based code and allow students to access the latest academic information anywhere and anytime as well as reduce the uneven distribution of information. System is built using Representational State Transfer (REST) web service that handle variety of cross platform application. Data is sent in Javascript Object Notation (Json) format, where client application only need to parse data and provide them to students. Based on the results, an application has achieved the goal which is an application of academic information that helps students to access information easily by utilizing web service technology.","","Electronic:978-1-4799-6432-1; POD:978-1-4799-6433-8","10.1109/ICITACEE.2014.7065760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065760","Academic Information Systems;Javascript Object Notation (JSON);Multiplatform;Web Services","Computer architecture;Databases;Peer-to-peer computing;Protocols;Schedules;Servers;Web services","Java;Web services;client-server systems;educational computing;educational institutions;further education;information retrieval;mobile computing;smart phones","Android platform;Javascript Object Notation format;Json format;REST Web service;Web service academic information system;Web service technology;academic information access;browser;bulletin board announcements;client application;college students;conventional media announcement;cross platform application;data parsing;flyers;information distribution;multiplatform application;representational state transfer Web service","","2","","7","","","8-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"Review Selection Using Micro-Reviews","T. S. Nguyen; H. W. Lauw; P. Tsaparas","School of Information Systems, Singapore Management University, Singapore, Singapore","IEEE Transactions on Knowledge and Data Engineering","20150305","2015","27","4","1098","1111","Given the proliferation of review content, and the fact that reviews are highly diverse and often unnecessarily verbose, users frequently face the problem of selecting the appropriate reviews to consume. Micro-reviews are emerging as a new type of online review content in the social media. Micro-reviews are posted by users of check-in services such as Foursquare. They are concise (up to 200 characters long) and highly focused, in contrast to the comprehensive and verbose reviews. In this paper, we propose a novel mining problem, which brings together these two disparate sources of review content. Specifically, we use coverage of micro-reviews as an objective for selecting a set of reviews that cover efficiently the salient aspects of an entity. Our approach consists of a two-step process: matching review sentences to micro-reviews, and selecting a small set of reviews that cover as many micro-reviews as possible, with few sentences. We formulate this objective as a combinatorial optimization problem, and show how to derive an optimal solution using Integer Linear Programming. We also propose an efficient heuristic algorithm that approximates the optimal solution. Finally, we perform a detailed evaluation of all the steps of our methodology using data collected from Foursquare and Yelp.","1041-4347;10414347","","10.1109/TKDE.2014.2356456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6894569","Micro-review;coverage;review selection","Algorithm design and analysis;Approximation algorithms;Approximation methods;Educational institutions;Greedy algorithms;Mobile communication;Optimization","combinatorial mathematics;data mining;heuristic programming;information retrieval;integer programming;linear programming;social networking (online);text analysis","Foursquare;Yelp;check-in services;combinatorial optimization problem;disparate review content sources;heuristic algorithm;integer linear programming;microreviews;mining problem;online review content;review selection;review sentence matching;social media;verbose review","","1","","34","","20140909","April 1 2015","","IEEE","IEEE Journals & Magazines"
"Tourism recommendation based on vector space model using composite social media extraction","H. Khotimah; T. Djatna; Y. Nurhadryani","Graduate School of Computer Science, Bogor Agricultural University","2014 International Conference on Advanced Computer Science and Information System","20150326","2014","","","303","308","Intentionally or not, social media users likely to share others recommendation about things, included tourism activities. In this paper we proposed a technique which was able to structure the joint recommendation of composite social media and extract them into knowledge about the tourist sites by deploying the vector space model. We included advice seeking technique to not only calculate recommendations obtained from the profile itself but also recommendations by social network users. This is a potential solution to handle sparsity problem that usually appears in conventional recommender systems. We further formulated an approach to normalize the unstructured text data of social media to obtain appropriate recommendation. We experimented the real world data from various source of social media in R language. We evaluated our result with Spearman's rank correlation and showed that our formulation has diversity recommendation with positive correlation to user's profile.","","Electronic:978-1-4799-8075-8; POD:978-1-4799-8076-5; USB:978-1-4799-8074-1","10.1109/ICACSIS.2014.7065894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065894","","Abstracts;Computer science;Data mining;Decision support systems;Handheld computers;Media;Vectors","information retrieval;recommender systems;social networking (online);travel industry","Spearman's rank correlation;composite social media extraction;diversity recommendation;positive correlation;recommender systems;social media users;social network users;sparsity problem;tourism activities;tourism recommendation;user profile;vector space model","","0","","20","","","18-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"Spatial data infrastructures: Its metadata and analysis","S. Roy; S. Das","DRTC, Indian Statistical Institute, Bangalore, India","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","43","51","The idea behind the development of spatial data infrastructures is inherently related to the notion of Geographical Information Systems. Nowadays Geographic Information is a key component when it comes to the utilization of natural resources. Geo processing tools, software packages, Global Positioning Systems (GPS), spatial databases provide geographic information or in other words Geo-spatial data With the advent of related technologies it is now possible to geo-tag or geo-refer a wide array of resources like textual material, geographic documents, image data, raster data, historical valued information and legacy database. The present work discusses metadata issues related to Spatial Data Infrastructure; and attempts to propose a three-tired infrastructure aimed towards enhancement of metadata catalogue services in regards of three aspects, i) Incorporating of various geographic information metadata elements and provision of necessary support for spatial data infrastructures ii) Achieving interoperability between different metadata standards that is between those standards used for encoding general information resources and those essential for spatial data infrastructures iii) Enhancement of information retrieval techniques for spatial data infrastructure by the use of disambiguated vocabularies.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048170","GIS;Metadata;digital libraries;semantic disambiguation;spatial data infrastructure","Interoperability;Libraries;Semantics;Spatial databases;Standards organizations","data analysis;geographic information systems;information retrieval;meta data","GPS;Geo processing tools;Global Positioning Systems;data analysis;disambiguated vocabularies;geo-refer;geo-tag;geographic information metadata elements;geographical information systems;information retrieval techniques;interoperability;metadata standards;natural resource utilization;software packages;spatial data infrastructure;spatial database","","0","","7","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Data collection and language understanding of food descriptions","M. Korpusik; N. Schmidt; J. Drexler; S. Cyphers; J. Glass","MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA 02139, USA","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","560","565","This paper presents initial data collection and language understanding experiments conducted as part of a larger effort to create a nutrition dialogue system that automatically extracts food concepts from a user's spoken meal description. We first summarize the data collection and annotation of food descriptions performed via Amazon Mechanical Turk. We then present semantic labeling experiments using a semi-Markov conditional random field (CRF) that obtains an F1 test score of 85.1. Finally, we report food segmentation experiments that explored three methods for associating foods with their corresponding attributes: a generative Markov model, transformation-based learning, and a CRF classifier. The CRF performed best, achieving an F1 test score of 87.1.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078635","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078635","CRF;Data collection;Markov model;Semantic tagging;Transformation-based learning","Dairy products;Data collection;Data models;Labeling;Markov processes;Semantics;Tagging","Markov processes;data handling;health care;information retrieval;interactive systems;learning (artificial intelligence);pattern classification;speech-based user interfaces","Amazon Mechanical Turk;CRF classifier;F1 test score;data collection;food concept extraction;food description annotation;food segmentation experiments;generative Markov model;language understanding;nutrition dialogue system;semantic labeling experiments;semi Markov conditional random field;spoken meal description;transformation-based learning","","2","","16","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"On Evaluating the Contribution of Validation for Question Answering","Á. Rodrigo; A. Peñas","NLP & IR Group, UNED, Madrid, Spain","IEEE Transactions on Knowledge and Data Engineering","20150305","2015","27","4","1157","1161","Validation is arising as a crucial component of new architectures aimed at improving Question Answering technologies. Hence, there is a strong need of appropriate measures for evaluating Validation and, even more, its impact on question answering results. However, common Validation measures do not allow a clear study of this impact, and they might even lead researchers to obtain wrong conclusions. We propose a new approach for evaluating Validation technologies, which offers clear and useful information about the impact on QA performance. We compare our proposal with classic evaluation measures, showing the benefits of our scheme.","1041-4347;10414347","","10.1109/TKDE.2014.2373363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977920","Answer Validation;Evaluation;Question Answering;Question answering;answer validation;evaluation","Accuracy;Atmospheric measurements;Communities;Knowledge discovery;Particle measurements;Proposals;Silicon","information retrieval system evaluation;question answering (information retrieval)","QA performance;answer validation;question answering technologies;validation evaluation measures;validation technologies evaluation","","0","","17","","20141205","April 1 2015","","IEEE","IEEE Journals & Magazines"
"Analyzing Alzheimer's disease gene expression dataset using clustering and association rule mining","B. Le Quéau; O. Shafiq; R. Alhajj","Department of Computer Science, University of Calgary, Calgary, Alberta, Canada","Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)","20150302","2014","","","283","290","Biological data like Gene expression datasets are already complex and are hard to process manually. The larger such types of datasets become, harder it becomes to manually process such datasets and makes more sense to use data mining techniques can be applied to discover or identify interesting patterns in the data. This paper presents various data mining techniques for analyzing Alzheimer's disease Gene Expression Dataset using Clustering and Association Rule Mining. The DNA-microarrays method allows acquiring a lot of data on gene expression. Due to the environmental and experimental factor, the variability of the gene expression is wide and unpredictable. This huge amount of data must be processed in order to retrieve relevant medical information. To do so, numerous methods of clustering are performed. There are two main goals: classify the gene expression and provide tools to retrieve the information. These techniques include basic data mining, two types of clustering and it discusses the use of association rules mining for such data. Emphasis is made on the particular dataset used in this research: the neurofibrillary tangles dataset that contains gene expression data for normal neurons and ""sick"" neurons for ten different patients suffering from a mid-stage Alzheimer's disease.","","Electronic:978-1-4799-5880-1; POD:978-1-4799-5881-8; USB:978-1-4799-5879-5","10.1109/IRI.2014.7051901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051901","Analysis;Association Rule Mining;Bio-Informatics;Clustering;Gene Expression Dataset","Alzheimer's disease;Association rules;Gene expression;Neurons","biocomputing;data analysis;data mining;diseases;information retrieval;medical information systems;pattern clustering","Alzheimer's disease gene expression dataset;DNA-microarrays method;association rule mining;data mining technique;dataset clustering;neurofibrillary tangles dataset;relevant medical information retrieval","","0","","15","","","13-15 Aug. 2014","","IEEE","IEEE Conference Publications"
"Collaboration through Patient Data Access and Sharing in the Cloud","F. Xhafa; T. Qassem; P. Moore","Tech. Univ. of Catalonia, Barcelona, Spain","2014 International Conference on Intelligent Networking and Collaborative Systems","20150312","2014","","","205","212","There have been many socio-political and technological developments in the area of Electronic Patient Records (EPR). The technological aspects include EPR implemented using Online Transaction Processing (OTP) using Internet and Internet based systems, more recently via Cloud- Based systems (CBS) exploiting Cloud Service Models (CSM). Additionally, there are many socio-political considerations comprising: (1) political moves, including UK Government policy, which aims to deliver for patients 27/7 online access to their patient record, (2) considerations around ethical issues and informed permission and acceptance by the public and non-governmental organizations (NGO), (3) technological considerations about identification of suitable CBS and data structures in distributed systems characterized by unstructured data and, finally (4) sharing and collaboration as means of increasing efficiency, security, privacy, etc. In all, the aim is to provide professionals in medical domain with advanced platforms to not only access but also most importantly to share and collaborate at a wide scale level (e.g. National level). Addressing these aspects of EPR requires collaboration between all stakeholders in EPR, this paper considers these and concludes that such collaboration is essential if EPR are ever to become a reality.","","Electronic:978-1-4799-6387-4; POD:978-1-4799-6388-1","10.1109/INCoS.2014.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057092","NoSQL;cloud service models;cloud-based systems;collaboration;electronic patient records;sharing;socio-political issues","Biomedical monitoring;Cloud computing;Collaboration;Medical services;Monitoring;Ontologies;Security","cloud computing;electronic health records;groupware;information retrieval;politics","CBS;CSM;EPR;Internet;NGO;OTP;UK Government policy;cloud service models;cloud-based systems;collaboration;electronic patient records;non-governmental organizations;online transaction processing;patient data access;patient data sharing;public organizations;socio-political considerations","","0","","21","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Digital preservation of manuscripts: An Indian perspective with special reference to Punjab","H. Kaur","Indian Institute of Technology Ropar, Nangal Road, Rupnagar-140001, India","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","271","274","With the development of digital technology, libraries are changing their roles from book providers to e-information providers. Manuscripts are primary source of historic information. Manuscripts are diminishing along with the time. Despite their best efforts, it is difficult to save manuscripts in physical form beyond a time frame. Digital preservation of manuscripts restores it from damage, larceny and decay. Need of digitization of manuscript, digitization initiatives in India, benefits and threats of digital preservation, process of digitization and guiding principles are the key issues discussed in this paper. The paper also discusses manuscripts and rare literature at Panjab University, Chandigarh and digitization projects at Punjab level.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048210","Archives;Digitization;Heritage;Manuscripts;Punjab Digital Library","Cultural differences;Educational institutions;Libraries;Market research;Materials;Standards","academic libraries;digital libraries;history;information retrieval systems","Indian perspective;Panjab University;Punjab;book provider;digital preservation;digital technology;digitization initiative;digitization project;e-information provider;historic information;library;manuscript","","0","","13","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Unsupervised language model adaptation using latent Dirichlet allocation and dynamic marginals","M. A. Haidar; D. O'Shaughnessy","INRS-Energy, Materials and Telecommunications, University of Quebec, 800 de la Gauchetiere Ouest, H5A 1K6, Montreal, Canada","2011 19th European Signal Processing Conference","20150402","2011","","","1480","1484","In this paper, we introduce an unsupervised language model adaptation approach using latent Dirichlet allocation (LDA) and dynamic marginals: locally estimated (smoothed) unigram probabilities from in-domain text data. In LDA analysis, topic clusters are formed by using a hard-clustering method assigning one topic to one document based on the maximum number of words chosen from a topic for that document. The n-grams of the topic generated by hard-clustering are used to compute the mixture weights of the component topic models. Instead of using all the words of the training vocabulary, selected words are used for LDA analysis, which are chosen by incorporating some information retrieval techniques. We adapted the LDA adapted topic model by minimizing the Kullback-Leibler (KL) divergence between the final adapted model and the LDA adapted topic model subject to a constraint that the marginalized unigram probability distribution of the final adapted model is equal to the dynamic marginals. We have compared our approach with the conventional adapted model obtained by minimizing the KL divergence between the background model and the adapted model using the above constraint. We have seen that our approach gives significant perplexity and word error rate (WER) reductions over the traditional approach.","2076-1465;20761465","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7074098","","Adaptation models;Computational modeling;Data models;Equations;Mathematical model;Semantics;Training","information retrieval;mixture models;natural language processing;pattern clustering;statistical distributions;text analysis","KL divergence minimization;Kullback-Leibler divergence minimization;LDA adapted topic model;LDA analysis;WER reduction;background model;component topic models;document handling;dynamic marginal;final adapted model;hard-clustering method;in-domain text data;information retrieval techniques;latent Dirichlet allocation;latent dirichlet allocation;locally estimated smoothed unigram probabilities;marginalized unigram probability distribution;maximum word number;mixture weights;n-grams;perplexity reduction;topic assignment;topic clusters;unsupervised language mod- el adaptation approach;unsupervised language model adaptation;word error rate reduction","","0","","20","","","Aug. 29 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"Phase Retrieval via Wirtinger Flow: Theory and Algorithms","E. J. Candès; X. Li; M. Soltanolkotabi","Department of Mathematics and Statistics, Stanford University, Stanford, CA, USA","IEEE Transactions on Information Theory","20150313","2015","61","4","1985","2007","We study the problem of recovering the phase from magnitude measurements; specifically, we wish to reconstruct a complex-valued signal x ∈ ℂ<sup>n</sup> about which we have phaseless samples of the form y<sub>r</sub> = |〈a<sub>r</sub>, x〉|<sup>2</sup>, r = 1, ..., m (knowledge of the phase of these samples would yield a linear system). This paper develops a nonconvex formulation of the phase retrieval problem as well as a concrete solution algorithm. In a nutshell, this algorithm starts with a careful initialization obtained by means of a spectral method, and then refines this initial estimate by iteratively applying novel update rules, which have low computational complexity, much like in a gradient descent scheme. The main contribution is that this algorithm is shown to rigorously allow the exact retrieval of phase information from a nearly minimal number of random measurements. Indeed, the sequence of successive iterates provably converges to the solution at a geometric rate so that the proposed scheme is efficient both in terms of computational and data resources. In theory, a variation on this scheme leads to a near-linear time algorithm for a physically realizable model based on coded diffraction patterns. We illustrate the effectiveness of our methods with various experiments on image data. Underlying our analysis are insights for the analysis of nonconvex optimization schemes that may have implications for computational problems beyond phase retrieval.","0018-9448;00189448","","10.1109/TIT.2015.2399924","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7029630","Non-convex optimization;Wirtinger derivatives;convergence to global optimum;non-convex optimization;phase retrieval","Accuracy;Computational modeling;Convergence;Diffraction;Fourier transforms;Optimization;Vectors","computational complexity;concave programming;gradient methods;information retrieval","Wirtinger flow;coded diffraction patterns;concrete solution algorithm;gradient descent scheme;low computational complexity;near-linear time algorithm;nonconvex formulation;nonconvex optimization scheme;phase information retrieval;random measurements;spectral method","","60","","69","","20150203","April 2015","","IEEE","IEEE Journals & Magazines"
"A Three Dimensional Model for Image Based Information Security","N. Kumari; A. Kaushik","Deptt. Of Comput. Sc. & App., TIT&S Coll., Bhiwani, India","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","753","757","Images not only represents the information itself but also work as the carrier to keep the information in it. These kind of images work as the cover objects to hold secret communicating information over public network. But steganography itself is not efficient to provide effective security. To attain higher degree, in this work a three dimensional model is defined to improve the communicating data capacity, reliability. To achieve this information cryptography, compression approaches are combined with steganography. To obtain image cryptography bit transformation scheme is used in this work. To perform the compression bit encoding scheme is suggested in this work and finally to hide the information data, LSB scheme is used. As the complete work is based on mathematical formation and operators, effective data retrieval is obtained from stegano image. The results are applied on real time images and the analysis of work in performed based on MSE and PSNR values.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065583","Bit Shuffle;Bit-Encoding;Compression;Cryptography;Steganography","Cryptography;Encoding;Image coding;Information security;Visualization;Watermarking","cryptography;data compression;image coding;image representation;information retrieval;mean square error methods;reliability;steganography","LSB scheme;MSE;PSNR value;communicating data capacity improvement;communicating reliability improvement;compression bit encoding scheme;effective data retrieval;image based information security;image cryptography bit transformation scheme;image representation;image steganography;information cryptography;information data hiding;mathematical formation;mean square error;peak signal to noise ratio;public network;three dimensional model","","0","","12","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Correlation-based re-ranking for semantic concept detection","H. Y. Ha; F. C. Fleites; S. C. Chen; M. Chen","School of Computing and Information Sciences, Florida International University, Miami, FL 33199, USA","Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)","20150302","2014","","","765","770","Semantic concept detection is among the most important and challenging topics in multimedia research. Its objective is to effectively identify high-level semantic concepts from low-level features for multimedia data analysis and management. In this paper, a novel re-ranking method is proposed based on correlation among concepts to automatically refine detection results and improve detection accuracy. Specifically, multiple correspondence analysis (MCA) is utilized to capture the relationship between a targeted concept and all other semantic concepts. Such relationship is then used as a transaction weight to refine detection ranking scores. To demonstrate its effectiveness in refining semantic concept detection, the proposed re-ranking method is applied to the detection scores of TRECVID 2011 benchmark data set, and its performance is compared with other state-of-the-art re-ranking approaches.","","Electronic:978-1-4799-5880-1; POD:978-1-4799-5881-8; USB:978-1-4799-5879-5","10.1109/IRI.2014.7051966","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051966","","Correlation;Data mining;Educational institutions;Equations;Multimedia communication;Semantics;Testing","information retrieval;multimedia systems;pattern classification","MCA;TRECVID 2011 benchmark data set;correlation-based re-ranking;detection ranking score;multimedia data analysis;multimedia data management;multimedia research;multiple correspondence analysis;semantic concept detection;transaction weight","","3","","19","","","13-15 Aug. 2014","","IEEE","IEEE Conference Publications"
"Relationship between class order and parameter approximation in unsupervised learning","Y. S. Jeong; G. Choi; H. J. Choi; Y. Iraqi","Department of Computer Science, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon 305-701, South Korea","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","27","30","Due to the growing number of unlabeled documents, it is becoming important to develop unsupervised methods capable of automatically extracting information. Topic models and neural networks represent two such methods, and parameter approximation algorithms are typically employed to estimate the parameters because it is not possible precisely to compute the parameters when using these methods. One of the well-known weaknesses of these approximation algorithms is that they do not find the global optimum but instead find one of many local optima. It is also known that initialization of the parameters affects the results of the parameter approximation process. In this paper, we hypothesize that the order of data class is also a factor that affects the parameter approximation results. Through digit recognition experiments with MNIST data, we prove that this hypothesis is valid and argue that it will be better always to use fully shuffled data to avoid incorrect conclusions.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072844","class order;digit recognition;machine learning;parameter approximation","Accuracy;Approximation algorithms;Approximation methods;Indexes;Neural networks;Support vector machines;Training","approximation theory;information retrieval;neural nets;parameter estimation;unsupervised learning","MNIST data;data class;information extraction;neural networks;parameter approximation algorithms;parameter approximation process;parameter estimate;topic model;unlabeled documents;unsupervised learning","","0","","14","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"A cloud-based web crawler architecture","M. Bahrami; M. Singhal; Z. Zhuang","University of California, Merced, USA","2015 18th International Conference on Intelligence in Next Generation Networks","20150402","2015","","","216","223","Web crawlers work on the behalf of applications or services to find interesting and related information on the web. For example, search engines use web crawlers to index the Internet. Web crawlers have several challenges, such as complexity between links and highly intensive computation requirements when a web crawler wants to retrieve complex connected links. Another issue is the storage of a massive amount of indexed links or downloaded unstructured data, such as binary files, videos or images. As the volume of information on the Internet increases rapidly and requests may search data in a variety of formats including unstructured data, no cloud-based architecture exists in the literatures for web crawlers that could effectively address both highly intensive computing and storage issues. The cloud computing paradigm provides support for elastic resources and unstructured data, and provides pay-peruse features that allow individual businesses to run their own web crawlers for crawling the Internet or a limited web hosts. In this paper, we propose a cloud-based web crawler architecture that uses cloud computing features and the MapReduce programming technique. The proposed web crawler allows us to crawl the web by using distributed agents and each agent stores its own finding on a Cloud Azure Table (NoSQL database). The proposed web crawler also could store unstructured and massive amount of data on Azure Blob storage. We analyze the performance and scalability of the proposed web crawler and we describe the advantages of the proposed web crawler over traditional distributed web crawlers.","","Electronic:978-1-4799-1866-9; POD:978-1-4799-1867-6; USB:978-1-4799-1865-2","10.1109/ICIN.2015.7073834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073834","big data;cloud computing;cloud-based web crawler;multimedia web crawler;web crawler","Cloud computing;Computer architecture;Crawlers;Servers;Service-oriented architecture;Uniform resource locators","Big Data;SQL;cloud computing;information retrieval;parallel programming;search engines;storage management","Azure Blob storage;Cloud Azure Table;Internet;MapReduce programming technique;NoSQL database;Web hosts;cloud computing paradigm;cloud-based Web crawler architecture;complex connected links;distributed agents;downloaded unstructured data;elastic resources;indexed links;pay-per-use features;performance analysis;search engines","","0","","17","","","17-19 Feb. 2015","","IEEE","IEEE Conference Publications"
"Key-point matching with post-filter using SIFT and BRIEF in logo spotting","V. P. Le; C. D. Tran","Laboratory L3I, Faculty of Science and Technology, La Rochelle University, France","The 2015 IEEE RIVF International Conference on Computing & Communication Technologies - Research, Innovation, and Vision for Future (RIVF)","20150226","2015","","","89","93","In this paper, a method to spot and recognize logos based on key-point matching is proposed. It is applied and tested on a document retrieval system. First, the pairs of matched key-points are estimated by the nearest neighbor matching rule based on the two nearest neighbors in SIFT descriptor space with Euclidean distance. Second, a post-filter with BRIEF descriptor space and hamming distance is used to re-filter the key-points which are rejected by the first step. Tested on a well-known benchmark database of real world documents containing logos Tobacco-800, our method performs an increase in the number of matched key-points of the method combined with BRIEF post-filter at the same accuracy level, and achieves a better performance than the state-of-the-art methods in the field of document retrieval.","","Electronic:978-1-4799-8044-4; POD:978-1-4799-8045-1","10.1109/RIVF.2015.7049880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7049880","document retrieval;key-point matching;logo spotting","Accuracy;Databases;Feature extraction;Hamming distance;Matched filters;Pattern recognition;Vectors","document handling;information filtering;information retrieval systems;pattern matching;transforms","BRIEF descriptor space;Euclidean distance;Hamming distance;SIFT descriptor space;Tobacco-800 logos;document retrieval system;key-point matching;logo recognition;logo spotting;nearest neighbor matching rule;post-filter","","0","","21","","","25-28 Jan. 2015","","IEEE","IEEE Conference Publications"
"A fingerprinting system for musical content","L. Ghouti; A. Bouridane","School of Computer Science, Queen's University of Belfast, BT7 1NN, UK","2006 14th European Signal Processing Conference","20150330","2006","","","1","4","Digital multimedia content (especially audio) is becoming a major part of the average computer user experience. Large digital audio collections of music, audio and sound effects are also used by the entertainment, music, movie and animation industries. Therefore, the need for identification and management of audio content grows proportionally to the increasing widespread availability of such media virtually “any time and any where” over the Internet. In this paper, we propose a novel framework for musical content fingerprinting using balanced multiwavelets (BMW). The framework for generating robust perceptual fingerprint (or hash) values is described. The generated fingerprints are used for identifying, searching, and retrieving audio content from large digital music databases. Furthermore, we illustrate, through extensive computer simulation, the robustness of the proposed framework to efficiently represent musical content and withstand several signal processing attacks and manipulations.","2219-5491;22195491","","10.1109/ICME.2006.262949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7071705","","Computational modeling;Europe;Manganese;Transforms","Internet;audio databases;audio signal processing;computer animation;entertainment;information retrieval;multimedia systems;music;wavelet transforms","BMW;Internet;animation industries;audio content identification;audio content management;audio content retrieval;audio content searching;balanced multiwavelets;digital audio collections;digital multimedia content;digital music database;entertainment;fingerprinting system;movie;musical content;robust perceptual fingerprint value generation;signal processing attacks;sound effects","","2","","8","","","4-8 Sept. 2006","","IEEE","IEEE Conference Publications"
"An MDL analysis framework for eQTL data","G. Chalkidis; S. Sugano","Laboratory of Functional Genomics, Department of Medical Genome Sciences, Graduate School of Frontier Sciences, The University of Tokyo, 4-6-1 Shirokanedai, Minato-ku, Tokyo 108-8639, Japan","Asia-Pacific World Congress on Computer Science and Engineering","20150305","2014","","","1","7","Rapid development of genome sequencing technologies enables novel insights into the mechanisms of complex disease through Big Data analysis. Physicians can nowadays assay a patient's gene variants and gene expression patterns in a timely manner and use the obtained data to study an individual's susceptibility to complex disease and unravel the underlying mechanisms of disease pathogenesis. Massive amounts of correlated genotype, gene expression, and clinical data are collected in eQTL datasets. In this work, we propose an analysis framework based on the minimum description length principle for extracting useful information from eQTL data. This is achieved by minimizing the stochastic complexity of the data by using the universal normalized maximum likelihood code as the global code length optimization criterion. The algorithm simultaneously identifies disease associated features, extracts the optimal model of the complex disease, and estimates its parameters. Applied to a simulated eQTL dataset, our framework successfully reveals the underlying mechanisms of a hypothetical complex disease interaction network.","","Electronic:978-1-4799-1954-3; POD:978-1-4799-7278-4","10.1109/APWCCSE.2014.7053841","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7053841","","Bioinformatics;Biological system modeling;Complexity theory;Data models;Diseases;Gene expression;Genomics","Big Data;data analysis;diseases;genomics;information retrieval;medical computing;optimisation;stochastic processes","Big Data analysis;MDL analysis framework;clinical data collection;complex disease mechanisms;correlated genotype;disease pathogenesis;eQTL datasets;expression quantitative trait loci data;gene expression patterns;genome sequencing technology;global code length optimization criterion;hypothetical complex disease interaction network;information extraction;minimum description length principle;patient gene variants;stochastic complexity;universal normalized maximum likelihood code","","0","","28","","","4-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Hierarchical Multi-Keyword Ranked search for secured document retrieval in public clouds","A. K. Ajai; R. S. Rajesh","Department of Computer Science and Engineering, Manonmaniam Sundaranar University, Tirunelveli, India","2014 International Conference on Communication and Network Technologies","20150319","2014","","","33","37","For providing efficient data security, sensitive data has to be doubly encrypted in public clouds. Recent approaches to perform the two layer encryption the data owners carry out coarse grained encryption, whereas the cloud implements a fine-grained encryption on top of the owner encrypted data. But in this for searchable encryption points, it was done using Plaintext keyword search or Single keyword search or Boolean keyword search. When large amount of data users and documents in the cloud taken into concern, it is necessary to allow multiple keywords in the search request and return documents in the order of their relevance to these keywords. In this paper, for the first time, we define and solve the problem of privacy preserving and data retrieval from encrypted data in public clouds by Double Layer Encryption (DLE) and Hierarchical Multi-Keyword Ranked Search schema (HMRS). Through these two concepts our system assures the confidentiality of the data with ranking and secures the privacy of users from the cloud. On the real-world it shows proposed schemes indeed introduce fast retrieval, more security and less cost in computation and communication in Public Cloud.","","DVD:978-1-4799-6264-8; Electronic:978-1-4799-6266-2; POD:978-1-4799-6267-9","10.1109/CNT.2014.7062720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062720","Decompose rule;Document;Doubly encrypted;Fast Retrieval;Hierarchical;Security","Access control;Cloud computing;Encryption;Keyword search;Protocols","cloud computing;cryptography;data privacy;information retrieval","DLE;HMRS;data confidentiality;data retrieval;data security;double layer encryption;encrypted data;hierarchical multikeyword ranked search schema;privacy preserving;public clouds;secured document retrieval;sensitive data;user privacy","","0","","25","","","18-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"Heterogeneous Data Integration and Fusion System Based on Metadata Conflict Algorithms in USPIOT","J. M. Bao; T. T. Hu; L. Pan; H. Xu; H. F. Hu","Key Lab. of Broadband Wireless Commun. & Sensor Network Technol., Nanjing Univ. of Posts & Telecommun., Nanjing, China","2014 International Conference on Wireless Communication and Sensor Network","20150319","2014","","","95","100","With the development of the Internet of Things, data islands and information redundancy which caused by massive heterogeneous data has become a challenge of many commercial applications and scientific research hot spots. First, we proposed and designed a MapReduce data integration and data fusion architecture, then, we established a stable information processing environment and a unified information retrieval interface for users, and then we analyzed MapReduce implementation processes, management processes, and the connection process. Meanwhile we proposed a conflict processing algorithms in processing heterogeneous redundant data problems by using metadata, and applied them to the processing of creating the virtual database using MapReduce technology, eliminating the redundant information to enhance the utilization of data space. Finally, we established the bench system to provide a unified heterogeneous data programming interface and memory management with heterogeneous data integration and fusion for users in our developed platform USPIOT (Ubiquitous Service Platform for Internet Of Things) and achieved better results.","","Electronic:978-1-4799-7091-9; POD:978-1-4799-7092-6","10.1109/WCSN.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061702","fusion;heterogeneous data sources;integration;mapReduce","Data integration;Data models;Databases;Humidity;Internet of things;Temperature distribution","Internet of Things;data integration;information retrieval;meta data;parallel processing;sensor fusion;storage management","Internet of Things;MapReduce data integration;MapReduce implementation processes;USPIOT;bench system;conflict processing algorithms;connection process;data fusion architecture;data islands;heterogeneous data integration;heterogeneous redundant data problems;information processing environment;information redundancy;management processes;memory management;metadata conflict algorithms;ubiquitous service platform for Internet Of Things;unified heterogeneous data programming interface;unified information retrieval interface;virtual database","","1","","10","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Building digital archives: Design decisions: A best practice example","H. Meyer; I. Bruder; A. Finger; A. Heuer","Database Research Group, University of Rostock, Germany","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","59","64","Building digital library applications is often a search for an applicable and adequate data or document model as well as for software tools which meets the requirements. Especially in digital archives, there are several data and document models to be considered. Unfortunately, there is no one-size-fits-all document model or system. For each application, the requirements and properties of a project have to be analyzed. In many cases, on one hand, a developer mostly together with a domain expert has to carry out time-consuming tests with possible solutions. On the other hand, one of the most important questions is sustainability and long-term archiving. Questions regarding these aspects are raised during the technical implementation, at least. In many academic projects, the maintenance and sustainability aspects leave open questions. Therefore, challenges, problems and solutions regarding document models, software systems, and sustainability are exhaustively analyzed in this paper. This is done in the context of the digital archive project DARL (Digitales Archiv Rostocker Liederbuch, engl. Digital Archive of the Rostock Songbook) conducted at University of Rostock.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048172","Digital archive;Medival song texts;Metadata;Sustainability","Data models;Databases;Educational institutions;Interoperability;Libraries;Software;Standards","data models;digital libraries;information retrieval systems;software maintenance","DARL;Digital Archive of the Rostock Songbook;Digitales Archiv Rostocker Liederbuch;University of Rostock;data model;digital archive project;digital library applications;document model;long-term archiving;maintenance aspect;software systems;software tools;sustainability aspect","","0","","16","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Combining local and broad topic context to improve term detection","J. Wintrode; S. Khudanpur","Johns Hopkins University, Center for Language and Speech Processing, Balitmore, MD, USA","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","442","447","We aim to improve term detection performance by augmenting traditional N-gram language models with multiple levels of topic context. We demonstrate that incorporating complementary aspects of topicality leads to significant improvements in term detection accuracy. We represent broad topic context through document-specific latent topics inferred via a Bayesian topic model. We capture local topic context with a cache-based adaptive language model. Measured on four languages from from the IARPA Babel program, interpolating unigrams from the broad topic context improves term detection performance by up to 1% absolute via lattice re-scoring. Re-decoding with the same document-specific model improves accuracy by up to 2.1%. Adding local context via cached N-grams improves performance by up to 1.6%. A combined approach, re-decoding with latent topic information then re-scoring with the local cached N-grams gives an overall improvement of up to 2.4%. For all languages, combining broad and local topic information outperforms any individual method.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078615","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078615","Speech recognition;language models;speech retrieval;spoken term detection;topic models","Adaptation models;Computational modeling;Context;Context modeling;Hidden Markov models;Lattices;Mathematical model","document handling;inference mechanisms;information retrieval;interpolation;speech recognition","Bayesian topic model;IARPA Babel program;N-gram language models;broad topic context;cache-based adaptive language model;document-specific latent topics;lattice rescoring;local cached N-grams;local topic context;speech recognition;speech retrieval;term detection performance improvement;unigram interpolation","","1","","36","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"An expert search scheme using user activities and reliabilities in social networks","K. Bok; I. Jeon; J. Lim; J. Yoo","School of Information and Communication Engineering, Chungbuk National University, 52 Naesudong-ro, Seowon-gu, Chengju, Chungbuk, Korea","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","157","161","In this paper, we propose an expert search scheme in social networks. The proposed scheme updates a profile by analyzing recent activities, and considers the reliability scores of users and users' ratings that are computed by the updated profile. A user's profile is created by extracting a keyword from the recent activity information and calculating similarity with the keyword. To verify the performance of the proposed scheme, a performance evaluation is conducted through simulations. The performance evaluation results show that the proposed scheme provides a more accurate search and reduces the average time consumption cost by about 43% compared to the existing schemes.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072826","expert;profile;social network;user actvitity","Accuracy;Conferences;Data mining;Performance evaluation;Reliability;Semantics;Social network services","expert systems;information retrieval;social networking (online)","expert search scheme;keyword extraction;performance evaluation;reliability scores;social networks;user actvitity information;user profile;user ratings","","1","","18","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"First-Mover Advantage in a Social Q&amp;A Community","R. Gazan","Univ. of Hawaii, Honolulu, HI, USA","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","1616","1623","Aggregate answer ratings serve as a metric of collective intelligence in social Q&A communities. The patterns by which participants in a social Q&A community rate and recommend answers are analyzed through the lens of first-mover advantage, to address the question of whether the first answer posted has a ratings advantage over those subsequently submitted. As part of a long-term participant observation, ratings for answers submitted to the Answer bag social Q&A site were compared by order of submission and normalized for page views and answer quality. The results suggest that the first-submitted answer consistently accumulates roughly 17% more rating points than the second answer submitted, and that the rating points of each subsequent answer tend to decline. Social factors influencing rating activity and implications for interpreting future social Q&A data are discussed.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070005","Cumulative advantage;Online communities;Recommender systems","Aggregates;Collaboration;Communities;Economics;Measurement;Recommender systems;Social factors","information retrieval;recommender systems;social networking (online)","first-mover advantage;information retrieval;recommender system;social Q&A site","","0","","38","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Mining consumer's opinion target based on translation model and word representation","D. Li; G. Chen; Y. Li; W. Xu","Beijing University of Posts and Telecommunications, Beijing, 100876, China","2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP)","20150402","2014","","","97","101","In recent years, the E-commercial plays an important role in people's daily life. When on the Internet, people often buy commodities from Taobao, Tmall and make comments on them, the comments of the goods may have closely connections with commercial value, which often reflect what's the consumers really care when they choose one piece of good among thousands of other similar ones. How to mining these aspects which the consumers really concern is a problem left unsolved. As a potential effective solution to construct structured information for people's preference, Information Extraction(IE) has attracted more and more scholar's attention. A meaningful research area is Opinion Target Extraction(OTE). This paper proposed a system using translation model as well as word representation method to obtain user's interests on dataset in Chinese. To release the word segmentation error, a finely generated system with new Chinese word detection module is proposed. The experiments on two corpus subjected on digital product verify the effective of our method.","","CD-ROM:978-1-4799-7206-7; Electronic:978-1-4799-7208-1; POD:978-1-4799-7209-8","10.1109/ICCWAMTIP.2014.7073369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073369","Chinese new word detection;User interests mining;opinion target extraction;translation model;word representation","Adaptation models;Bipartite graph;Data mining;Feature extraction;Hidden Markov models;Semantics;Syntactics","consumer behaviour;data mining;information retrieval;marketing data processing","Chinese word detection module;IE;Internet;OTE;Taobao;Tmall;consumer opinion target mining;e-commercial;electronic commercial;information extraction;opinion target extraction;translation model;user interest;word representation;word segmentation error","","0","","16","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Content analysis and application of Zipf's Law in Computer Science literature","Rajneesh; M. S. Rana","Banasthali University, Raiasthan, India","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","223","227","The technique of content analysis is used in construction of thesaurus, subject headings and designing classification schemes for efficient organisation of knowledge in the libraries. Moreover, content analysis is also useful in analyzing the user queries and in designing search formulation. The purpose of paper is to analyze, evaluate and apply Zipf's Law in Computer Science through the content analysis of literature published in ACM journals. The study is focused on the analysis of 13, 053 unique keywords out of 107,467 total keywords retrieved from 1954 to 2008 from Journals. Further, a total of 748 keywords have been chosen for this study which occurred > 20 times. The distribution of keywords shows that the studies have been conducted in a large number of areas of study in computer science. Further, computer science research has been covering all the aspects very well as occurrences of almost all the keywords have increasing trend. However, Zipf's Law only approximates in patches, not in the entire data set.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048202","Bibliometrics;Computer science literature;Content analysis;Empirical laws;Zipf's law","Bibliometrics;Computer science;Indexes;Libraries;Market research","computer science;information analysis;information retrieval;libraries;statistical analysis","Zipf Law;computer science literature;content analysis;libraries","","0","","10","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Hadoop based Deep Packet Inspection system for traffic analysis of e-business websites","J. Luo; Y. Liang; W. Gao; J. Yang","Electronic Information and Networking Research Institute, Chongqing University of Posts and Telecommunications, 400065, China","2014 International Conference on Data Science and Advanced Analytics (DSAA)","20150312","2014","","","361","366","Internet traffic is experiencing an explosive growth, and online shopping is one of the significant drivers. However, alert network operators, unwilling to be dumb pipes, are making every effort to mine mass traffic with the help of Deep Packet Inspection (DPI) which is regarded as a big challenge especially for massive data when traditional methods and programming model are utilized. Hadoop provides an alternative approach with its strength in distributed storage and parallel computing. In this paper, a Hadoop based DPI system was reported, which was integrated with a web crawler. The system architecture and MapReduce models of packet analysis, web URL restoration were presented. As an example, live web traffic visiting the Tmall, the leading e-shopping giant in China, was specifically investigated using this system. Popularity of product, category and brand for a certain period was evaluated from page views of product. The detailed information of products was provided by the product information base built by the web crawler. This work explored the methodology of using Hadoop in DPI and presented valuable guidelines to develop such a system, which can be further used in analyzing other services and mining the value of network traffic by network operators.","","Electronic:978-1-4799-6991-3; POD:978-1-4799-6982-1","10.1109/DSAA.2014.7058097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058097","","Cloud computing;Crawlers;Databases;Inspection;Uniform resource locators;Web pages","Internet;Web sites;data mining;electronic commerce;information retrieval;parallel processing;retail data processing;telecommunication traffic","China;Hadoop based DPI system;Hadoop based deep packet inspection system;Internet traffic;MapReduce models;Web URL restoration;Web crawler;brand;category;distributed storage;e-business Websites;e-shopping giant;mass traffic mining;online shopping;packet analysis;parallel computing;product page view;product popularity;traffic analysis","","1","","17","","","Oct. 30 2014-Nov. 1 2014","","IEEE","IEEE Conference Publications"
"Research on optimal policy of budget allocation cross GSP search engines","B. Zhou; W. Qi; S. Zhang; X. Diao","School of Economics and Management, HIT, Harbin, P.R. China","2014 IEEE 7th Joint International Information Technology and Artificial Intelligence Conference","20150323","2014","","","139","143","Recently, sponsored search has been rapidly growing which increase tremendous interests in improving performance in search engine marketplace. The complexity of market dynamics makes it difficult for advertisers to maximizing the effect of advertising. Simulation analysis is a more viable option than real world testing especially in fast accomplishing different experiments and effectively prompting decision making supports. In this paper, the sponsored search budget allocation problem model integrated with quality score for single search engine has been exploered and then extended to multiple quality-based search engines. Also, several advertising policies have been proposed and verified under the general simulation framework in both single and multiple search engine scenarios.","","CD-ROM:978-1-4799-4421-7; Electronic:978-1-4799-4419-4; POD:978-1-4799-4418-7","10.1109/ITAIC.2014.7065022","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065022","Advertising policies;Budget allocation;GSP Search Engines;Sponsored search","Advertising;Economics;Equations;Mathematical model;Optimal control;Resource management;Search engines","advertising data processing;decision making;information retrieval;search engines","GSP search engine marketing;advertising effect maximization;advertising policies;decision making supports;general simulation framework;market dynamics complexity;multiple quality-based search engines;optimal budget allocation policy;performance improvement;quality score;search engine marketplace;sponsored search budget allocation problem model","","0","","20","","","20-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Comparison of Algorithms for Document Clustering","M. Gupta; A. Rajavat","Dept. of Comput. Sci., SVITS, Indore, India","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","541","545","Clustering is ""the method of organizing objects into groups whose members are related in some way"". A cluster is therefore a collection of objects which are coherent internally, but clearly dissimilar to the objects belonging to other clusters. Document clustering is used in many fields such as data mining and information retrieval. Thus, the main goals of this paper are to identify the comparison of the performance of criterion function in the context of partition clustering approach, k means, and agglomerative hierarchical approach. By comparing all this we establish right clustering algorithm to produce qualitative clustering of real world document. And also modify existing algorithm to establish right algorithm which we try to make more efficient than existing algorithms which we are study in this paper.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065543","BIRCH;Document Clustering;Kmeans;Matrix Representation;Support Vector Model","Algorithm design and analysis;Clustering algorithms;Clustering methods;Computer science;Entropy;Partitioning algorithms;Vectors","data mining;document handling;information retrieval;pattern clustering","data mining;document clustering;information retrieval;object organization","","0","","12","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Paired feature constraints for latent dirichlet topic models","N. B. Sristy; D. V. L. N. Somayajulu; R. B. V. Subramanyam","Department of CSE, NIT Warangal","2013 International Conference on Soft Computing and Pattern Recognition (SoCPaR)","20150305","2013","","","270","275","Non Parametric Bayes models, so called family of Latent Dirichlet Allocation (LDA) Topic Models have found application in various aspects of pattern recognition like sentiment analysis, information retrieval, question answering etc. The topics induced by LDA are used for later tasks such as classification, regression(movie ratings), ranking and recommendation. Recently various approaches are suggested to improve the utility of topics induced by LDA using various side-information such as labeled examples and labeled features. Pair-Wise feature constraints such as cannot-link and must-link, represent weak-supervision and are prevalent in domains such as sentiment analysis. Though must-link constraints are relatively easier to incorporate by using dirichlet tree, the cannot-link constraints are harder to incorporate using the dirichlet forest. In this paper we proposed an approach to address this problem using posterior constraints. We introduced additional latent variables for capturing the constraints, and modified the gibbs sampling algorithm to incorporate these constraints. Our method of Posterior Regularization has enabled us to deal with both types of constraints seamlessly in the same optimization framework. We have demonstrated our approach on a product sentiment review data set which is typically used in text analysis.","","Electronic:978-1-4799-3400-3; POD:978-1-4799-3401-0","10.1109/SOCPAR.2013.7054141","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054141","","Analytical models;Coherence;Data models;Graphical models;Pattern recognition;Sentiment analysis;Vocabulary","Bayes methods;optimisation;question answering (information retrieval);recommender systems;sampling methods;text analysis;trees (mathematics)","Dirichlet forest;Gibbs sampling algorithm;LDA topic models;cannot-link constraint;classification;dirichlet tree;information retrieval;latent Dirichlet allocation;latent Dirichlet topic model;latent variable;movie rating;must-link constraint;nonparametric Bayes model;optimization framework;pair-wise feature constraint;pattern recognition;posterior constraint;posterior regularization;question answering;ranking;recommendation;regression;sentiment analysis;text analysis","","0","1","19","","","15-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Novel Method for Tempo Detection of INDIC Tala-s","S. Bhaduri; S. K. Saha; C. Mazumdar","Dept. of Comput. Sci. & Eng., Jadavpur Univ., Kolkata, India","2014 Fourth International Conference of Emerging Applications of Information Technology","20150302","2014","","","222","227","Perceived tempo for tablaa accompaniment in a composition, is an important parameter to represent and transcript the rhythmic pattern of a composition, in the context of Indian classical music. If such parameters can be detected then it enables organized archiving and retrieval of rhythm data in Music Information Retrieval system. A simple and novel methodology for detecting tempo is presented in this paper. This method is based on the extraction of beat/stroke/bol duration for any theka of INDIC tala-s, rendered with single, composite or absent strokes. Analysis and experiment with number of audio clips of tablaa signal for various tala, tempo and rendering, illustrates the effectiveness and robustness of the proposed methodology.","","Electronic:978-1-4799-4272-5; POD:978-1-4799-4271-8","10.1109/EAIT.2014.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7052049","","Context;Estimation;Harmonic analysis;Hidden Markov models;Histograms;Rendering (computer graphics);Rhythm","acoustic signal processing;information retrieval;music;musical instruments","INDIC tala;Indian classical music;absent-strokes;audio clips;beat duration extraction;bol duration extraction;composite-strokes;composition rhythmic pattern representation;composition rhythmic pattern transcription;music information retrieval system;perceived tempo detection;rendering;rhythm data archiving;rhythm data retrieval;single-strokes;stroke duration extraction;tablaa;tablaa signal;theka","","1","","13","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Expert Finding for Question Answering via Graph Regularized Matrix Completion","Z. Zhao; L. Zhang; X. He; W. Ng","Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China","IEEE Transactions on Knowledge and Data Engineering","20150305","2015","27","4","993","1004","Expert finding for question answering is a challenging problem in community-based question answering (CQA) systems, arising in many real applications such as question routing and identification of best answers. In order to provide high-quality experts, many existing approaches learn the user model from their past question-answering activities in CQA systems. However, the past activities of users in most CQA systems are rather few, and thus the user model may not be well inferred in practice. In this paper, we consider the problem of expert finding from the viewpoint of missing value estimation. We then employ users' social networks for inferring user model, and thus improve the performance of expert finding in CQA systems. In addition, we develop a novel graph-regularized matrix completion algorithm for inferring the user model. We further develop two efficient iterative procedures, GRMC-EGM and GRMC-AGM, to solve the optimization problem. GRMC-EGM utilizes the Extended Gradient Method (EGM), while GRMC-AGM applies the Accelerated proximal Gradient search Method (AGM), for the optimization. We evaluate our methods on the well-known question answering system Quora, and the popular social network Twitter. Our empirical study shows the effectiveness of the proposed algorithms in comparison to the state-of-the-art expert finding algorithms.","1041-4347;10414347","","10.1109/TKDE.2014.2356461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6909004","Expert finding;community-based question answering;expert finding;graph regularized matrix completion","Estimation;Gradient methods;Knowledge discovery;Linear programming;Prediction algorithms;Social network services","gradient methods;graph theory;matrix algebra;optimisation;question answering (information retrieval);social networking (online)","CQA systems;GRMC-AGM iterative procedure;GRMC-EGM iterative procedure;Quora;Twitter;accelerated proximal gradient search method;answer identification;community-based question answering systems;expert finding;extended gradient method;graph regularized matrix completion;missing value estimation;optimization problem;question routing;user social networks","","10","","55","","20140924","April 1 2015","","IEEE","IEEE Journals & Magazines"
"Shallow parsing natural language processing implementation for intelligent automatic customer service system","","","2014 International Conference on Advanced Computer Science and Information System","20150326","2014","","","274","279","This paper introduces implementation of Shallow-Parsing methods in Question Answering System of Natural Language Processing for Indonesian Automatic Customer Service. The main idea of the approach using Shallow-Parsing is indexing the answer. In this paper we present some steps of simple Information Extraction (IE) using Shallow-Parsing such as Part-of-Speech Tagging, IOB Tagging, Text Chunking, Predictive Annotation, Relation Finding, and Answer Retrieval. The main purpose of the task is to identify key information, key phrase and question phrase that contained in each question or answer. With that, information system can index the given question and retrieve the relevant answer to customer. The experiments of Automatic Customer Service reported in this paper show competitive results, given 100 questions; system can respond 89 questions with relevant answer correctly. This experiment shows that the accuracy of the Automatic Customer Service system is 89% of 100 given questions.","","Electronic:978-1-4799-8075-8; POD:978-1-4799-8076-5; USB:978-1-4799-8074-1","10.1109/ICACSIS.2014.7065845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065845","Artificial Intelligence;Customer Service;Dialogue System;Natural Language;POS Tagging;Predictive Annotation;Semantic Role;Shallow Parsing;rule-based;text chunking","Customer services;Indexing;Knowledge discovery;Moon;Natural language processing;Tagging","customer services;grammars;natural language processing;question answering (information retrieval)","IE;IOB tagging;Indonesian automatic customer service;answer retrieval;information extraction;intelligent automatic customer service system;part-of-speech tagging;predictive annotation;question answering system;relation finding;shallow parsing natural language processing implementation;text chunking","","0","","29","","","18-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"Incorporating Social Role Theory into Topic Models for Social Media Content Analysis","W. X. Zhao; J. Wang; Y. He; J. Y. Nie; J. R. Wen; X. Li","School of Information, Renmin University of China, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","20150305","2015","27","4","1032","1044","In this paper, we explore the idea of social role theory (SRT) and propose a novel regularized topic model which incorporates SRT into the generative process of social media content. We assume that a user can play multiple social roles, and each social role serves to fulfil different duties and is associated with a role-driven distribution over latent topics. In particular, we focus on social roles corresponding to the most common social activities on social networks. Our model is instantiated on microblogs, i.e., Twitter and community question-answering (cQA), i.e., Yahoo!Answers, where social roles on Twitter include “originators” and “propagators”, and roles on cQA are “askers” and “answerers”. Both explicit and implicit interactions between users are taken into account and modeled as regularization factors. To evaluate the performance of our proposed method, we have conducted extensive experiments on two Twitter datasets and two cQA datasets. Furthermore, we also consider multi-role modeling for scientific papers where an author's research expertise area is considered as a social role. A novel application of detecting users' research interests through topical keyword labeling based on the results of our multi-role model has been presented. The evaluation results have shown the feasibility and effectiveness of our model.","1041-4347;10414347","","10.1109/TKDE.2014.2359672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906267","Topic models;social media;social role theory","Analytical models;Context modeling;Indexes;Mathematical model;Media;Twitter","question answering (information retrieval);social networking (online)","SRT;Twitter;Yahoo!Answers;cQA;community question-answering;explicit interactions;implicit interactions;latent topics;microblogs;regularization factors;role-driven distribution;social activities;social media content analysis;social networks;social role theory;topic models","","3","","27","","20140922","April 1 2015","","IEEE","IEEE Journals & Magazines"
"Serving the readers of scholarly documents: A grand challenge for the introspective digital library","M. Y. Kan","Web IR / NLP Group, School of Computing, National University of Singapore","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","249","250","The scholarly literature produced by human civilization will soon be considered small data, able to be portably conveyed by the network and carried on personal machines. This semi-structured text centric knowledge base is a focus of attention for scholars, as the wealth of facts, facets and connections in scholarly documents are large. Such machine analysis can derive insights that can inform policy makers, academic and industrial management, as well as scholars as authors themselves. There is another underserved community of scholarly document users that has been overlooked: the readers themselves. I call for the community to put more efforts towards supporting our own scholars (especially beginning scholars, new to the research process) with automation from information retrieval and natural language processing. Techniques that mine information from within the full text of a document could be used to introspect a digital library's materials, inferring better search metadata, improving scholarly document recommendation, and aiding the understanding of the text, figures, presentations and citations of our scholarly literature. Such an introspective digital library will enable scholars to assemble an understanding of other scholars' work more efficiently, and provide downstream machine reading applications with input for their analytics.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072807","","Atmospheric measurements;Big data;Communities;Knowledge based systems;Libraries;Manuals;Natural language processing","digital libraries;information retrieval;natural language processing","digital library;information retrieval;machine reading applications;natural language processing;scholarly document readers;scholarly document recommendation;scholarly literature;search metadata","","0","","3","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"Approximate Life Cycle Assessment via Case-Based Reasoning for Eco-Design","M. G. Jeong; J. R. Morrison; H. W. Suh","Department of Industrial and Systems Engineering, KAIST, Daejeon, South Korea","IEEE Transactions on Automation Science and Engineering","20150403","2015","12","2","716","728","Life cycle assessment (LCA) is a fundamental tool used in eco-design. However, it can be costly and resource intensive. We take steps toward the automation of the inventory and impact analyses stages of LCA via the proposal and development of a case-based reasoning (CBR) procedure to estimate the ecological effects of a product. The case memory in CBR, which contains representations and ecological effects of known products, is organized using an extension of the function-behavior-structure (FBS) representation for products. The extension includes ecological characteristics and values. We develop similarity metrics to measure the distance between cases in the case memory and the new product. The k-medoids algorithm is used to cluster the case memory, our metrics enable cluster retrieval and case selection, and multiple linear regression analysis is employed for adaptation. Using a database of 100 fans, we test the accuracy of the proposed approach on a cross flow fan not in the database. The method gives ecological effect estimates within 3% of the true values when there are similar fans in the retrieved cluster and about 7% when the retrieved cluster does not contain similar fans.","1545-5955;15455955","","10.1109/TASE.2014.2334353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880398","Case-based reasoning (CBR);eco-design;life cycle assessment (LCA);sustainability","Accuracy;Artificial neural networks;Cognition;Databases;Ecodesign;Measurement;Vectors","case-based reasoning;control engineering computing;ecology;environmental factors;information retrieval;inventory management;pattern clustering;product life cycle management;production engineering computing;regression analysis","FBS;LCA;approximate life cycle assessment;case memory;case selection;case-based reasoning procedure;cluster retrieval;distance measurement;eco-design;ecological characteristics;ecological values;function-behavior-structure representation;inventory automation;k-medoids algorithm;multiple linear regression analysis;product ecological effect estimation;similarity metrics","","0","","50","","20140819","April 2015","","IEEE","IEEE Journals & Magazines"
"Syllable based keyword search: Transducing syllable lattices to word lattices","H. Su; J. Hieronymus; Y. He; E. Fosler-Lussier; S. Wegmann","Int. Comput. Sci. Inst., Berkeley, CA, USA","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","489","494","This paper presents a weighted finite state transducer (WFST) based syllable decoding and transduction framework for keyword search (KWS). Acoustic context dependent phone models are trained from word forced alignments. Then syllable decoding is done with lattices generated using a syllable lexicon and language model (LM). To process out-of-vocabulary (OOV) keywords, pronunciations are produced using a grapheme-to-syllable (G2S) system. A syllable to word lexical transducer containing both in-vocabulary (IV) and OOV keywords is then constructed and composed with a keyword-boosted LM transducer. The composed transducer is then used to transduce syllable lattices to word lattices for final KWS. We show that our method can effectively perform KWS on both IV and OOV keywords, and yields up to 0.03 Actual Term-Weighted Value (ATWV) improvement over searching keywords directly in subword lattices. Word Error Rates (WER) and KWS results are reported for three different languages.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078623","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078623","Keyword Search;Lattice Transduction;OOV Keywords;Speech Recognition;Syllable Decoding;WFST","Acoustics;Decoding;Hidden Markov models;Lattices;Training;Training data;Transducers","acoustic signal processing;finite state machines;information retrieval;natural language processing;speech coding;vocabulary","ATWV;G2S system;IV keywords;KWS;LM;OOV keywords;WFST;acoustic context dependent phone models;actual term-weighted value;grapheme-to-syllable system;in-vocabulary keywords;keyword-boosted LM transducer;language model;out-of-vocabulary keywords;syllable based keyword search;syllable decoding;syllable lattices-word lattices transduction;syllable lexicon;syllable-word lexical transducer;weighted finite state transducer based syllable decoding;word error rates;word forced alignments","","2","","21","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"Implementing privacy sensitive governmental systems based on the concept of the Austrian data retention exchange service","M. Schafferer; M. Gruber; T. Grechenig","Vienna University of Technology, Industrial Software (INSO), 1040, Austria","eChallenges e-2014 Conference Proceedings","20150319","2014","","","1","10","With April 1st, 2012 the implementation of Directive 2006/24/EC on the retention of data generated or processed in connection with the provision of publicly available electronic communications services, or of public communications networks came into effect in Austria. With this implementation, not only the obligations of the providers of telecommunications services are controlled with respect to the retention of communications data, but also the powers of the security and law enforcement authorities with respect to request both retention data as well as traditional connection data (e.g., security police in the course of fulfilment of affairs). To make the retrieval of such data as transparent as possible, legally secure and traceable, all requests (with only few exceptions) must be carried out only via the so-called DLS, a central exchange service. This allows preventing unauthorized or hidden inquiries practically and not just legally. Both requests and replies must be transmitted only over HTTPS connections to the DLS and must further be secured using end-2-end encryption, enforcing a blind central service.","2166-1650;21661650","Electronic:978-1-9058-2446-5; POD:978-1-4799-1810-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058188","","Authorization;Data privacy;Data transfer;Portals;Privacy;Telecommunication standards","data privacy;government data processing;information retrieval","Austrian data retention exchange service;HTTPS connections;blind central service;data retrieval;electronic communications services;law enforcement authorities;privacy sensitive governmental systems;public communications networks;retention data;security enforcement authorities;security police;telecommunications services","","0","","17","","","29-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Enabling Efficient Multi-Keyword Ranked Search Over Encrypted Mobile Cloud Data Through Blind Storage","H. Li; D. Liu; Y. Dai; T. H. Luan; X. S. Shen","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Emerging Topics in Computing","20150305","2015","3","1","127","138","In mobile cloud computing, a fundamental application is to outsource the mobile data to external cloud servers for scalable data storage. The outsourced data, however, need to be encrypted due to the privacy and confidentiality concerns of their owner. This results in the distinguished difficulties on the accurate search over the encrypted mobile cloud data. To tackle this issue, in this paper, we develop the searchable encryption for multi-keyword ranked search over the storage data. Specifically, by considering the large number of outsourced documents (data) in the cloud, we utilize the relevance score and k-nearest neighbor techniques to develop an efficient multi-keyword search scheme that can return the ranked search results based on the accuracy. Within this framework, we leverage an efficient index to further improve the search efficiency, and adopt the blind storage system to conceal access pattern of the search user. Security analysis demonstrates that our scheme can achieve confidentiality of documents and index, trapdoor privacy, trapdoor unlinkability, and concealing access pattern of the search user. Finally, using extensive simulations, we show that our proposal can achieve much improved efficiency in terms of search functionality and search time compared with the existing proposals.","2168-6750;21686750","","10.1109/TETC.2014.2371239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6983613","Access pattern;Blind storage;Cloud computing;Multikeyword ranked search;Searchable encryption;access pattern;blind storage;multi-keyword ranked search;searchable encryption","Encryption;Indexes;Mobile communication;Servers;Vectors","cloud computing;cryptography;data privacy;document handling;file servers;information retrieval;mobile computing;outsourcing;storage management","blind storage;confidentiality concerns;data storage;encrypted mobile cloud data;external cloud servers;k-nearest neighbor techniques;mobile cloud computing;mobile data outsourcing;multikeyword ranked search;outsourced documents;privacy concerns;relevance score;search efficiency;search functionality;search time;search user access pattern;searchable encryption;security analysis;trapdoor privacy;trapdoor unlinkability","","16","","29","","20141212","March 2015","","IEEE","IEEE Journals & Magazines"
"Non-sparse infinite-kernel learning for automated identification of Alzheimer's disease using PET imaging","Y. Xia; S. Lu; W. Wei; D. D. Feng; Y. Zhang","Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China","2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)","20150323","2014","","","855","860","Multi-kernel learning machine (MKLM) has recently been introduced to the research of computer-aided dementia identification and pathology progress tracking. Despite its good performance especially in case of using heterogeneous data, such learning schema and its variants usually utilize a L-l norm constraint that promotes sparse solutions, which may cause loss of potentially important information. In this paper, we propose the non-sparse infinite-kernel learning machine (NS-IKLM) for automated identification of Alzheimer cases from normal controls. In our approach, a modified constraint is utilized to promotes non-sparse solutions and kernel parameters are automatically tuned during the learning process. The proposed algorithm has been evaluated on a set of FDG-PET images selected from the Alzheimer's disease neuroimaing initiative (ADNI) cohort. Our results demonstrate that the proposed non-sparse NS-IKLM is able to achieve satisfying dementia identification at a relatively low computational cost.","","Electronic:978-1-4799-5199-4; POD:978-1-4799-5200-7; USB:978-1-4799-5198-7","10.1109/ICARCV.2014.7064416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064416","ADNI;FDG-PET;Infinite kernel learning;dementia","Dementia;Feature extraction;Kernel;Positron emission tomography","brain;computer aided analysis;feature extraction;information retrieval systems;medical disorders;medical image processing;neurophysiology;positron emission tomography;storage automation","ADNI cohort;ADNI-selected PET images;ADNI-selected positron emission tomography images;Alzheimer case identification;Alzheimer's disease neuroimaging initiative;FDG-PET images;L-l norm constraint;MKLM schema evaluation;MKLM variants;PET imaging;automated disease identification;automatic kernel parameter tuning;computer-aided dementia identification;computer-aided dementia pathology progress tracking;heterogeneous data;information loss;learning machine evaluation;learning schema;low computational cost dementia identification;multikernel learning machine;nonsparse NS-IKLM-achieved dementia identification;nonsparse infinite-kernel learning machine;nonsparse solution;positron emission tomography imaging;sparse solutions","","1","","24","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Web Information Search in Emergency Rescue under Disasters","Z. Wang; S. Ma","Sch. of Comput. Sci. & Eng., Beihang Univ., Beijing, China","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","575","580","In view of the requirements for high reliability and strong time constraints in emergency rescue under disasters, an improved template-based information search method is proposed to meet these requirements. The method builds a search template based on features of emergency rescue field. Based on the HTML structure and template, the valid information in webpages can be extracted. A reliable correction method about the webpage updated time is composed after judging the extracted webpage updated time. Finally, the similarity between the webpage and event is calculated based on the event model. Through the relevant comparison and experiment evaluation, the method is proved to be able to improve the precision about Web information search in emergency rescue under disasters.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065550","disaster event model;emergency rescue;information search;page time extraction;template","Data mining;Earthquakes;Feature extraction;Search methods;Uniform resource locators;Vectors","Web sites;disasters;emergency management;information retrieval","HTML structure;Web information search;Web page updated time;Web pages;disasters;emergency rescue field;event model;reliable correction method;search template;template-based information search method","","0","","11","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Evaluation of a Classification System for Best Practices","M. M. S. Alwazae; P. Johannesson; E. Perjons","Stockholm Univ., Stockholm, Sweden","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","3702","3711","The practical problem addressed in this paper is that it can be problematic to find appropriate best practices (BPs) in a large collection of BPs, covering many different domains, within an organizational database. Our goal was to propose a classification system of BP documentation to facilitate effective use and retrieval of BPs documents in such a large collection of BPs, independent of any domains. We have designed such a domain independent classification system and evaluated it with practitioners and academic experts. We found that all the BP characteristics and labeled values in the proposed classification system were recognized and applied by practitioners as well as academic experts. However, it turned out that some of the characteristics were particularly useful. These characteristics were: implementation area, level of formalization, completeness of description, Balanced Scorecard perspectives, and management process.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.446","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070262","Balanced Scorecard Perspectives;Best Practice;Classification System;Kownledge Management;Management Process","Best practices;Context;Interviews;Organizations;Organizing;Process control","classification;information retrieval","BP document retrieval;BP documentation classification system;balanced scorecard perspectives;best practices;domain independent classification system;level of formalization;organizational database","","0","","33","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"An application of fuzzy geographically clustering for solving the Cold-Start problem in recommender systems","L. H. Son; K. M. Cuong; N. T. H. Minh; N. Van Canh","VNU University of Science, Vietnam National University, 334 Nguyen Trai, Thanh Xuan, Hanoi, Vietnam","2013 International Conference on Soft Computing and Pattern Recognition (SoCPaR)","20150305","2013","","","44","49","In this paper, we present a novel method based on fuzzy geographically clustering to solve the Cold-Start problem in Recommender Systems occurring when a new user is migrated into the system. The proposed method can handle the issues of selected demographic attributes, the similarities between items and missing ratings that existed in relevant demographic-based algorithms. Numerical examples are given to illustrate the proposed method. Experimental results show that the new method has better accuracy than other relevant ones.","","Electronic:978-1-4799-3400-3; POD:978-1-4799-3401-0","10.1109/SOCPAR.2013.7054096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054096","Cold-Start;Demographic Approach;Fuzzy Clustering;Recommender Systems","Accuracy;Clustering algorithms;Collaboration;Educational institutions;Motion pictures;Recommender systems","fuzzy set theory;information retrieval;pattern clustering;recommender systems","cold-start problem;demographic attribute;fuzzy geographically clustering;recommender system","","3","","13","","","15-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"Keyword question answering system with report generation for linked data","S. Han; H. Shim; B. Kim; S. Park; S. Ryu; G. G. Lee","Pohang University of Science and Technology","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","23","26","We introduce a question-answering system that responds to a keywords-query by extracting information from linked data and generating reports in natural language (NL). Using entity disambiguation and distributed word similarity, we matched each keyword to a related entity and property in linked data. To extract keyword-related information, we used the entity and property to generate a SPARQL query. NL generation was performed using a NL generation template database. In our experiment, our system answered 95.1% of the user keyword questions in reasonable NL report.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072843","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072843","QA system;keyword system;linked data;natural language generation;query generation;question answering system;report generation","Data mining;Databases;Encyclopedias;Knowledge discovery;Natural languages;Resource description framework;Semantics","SQL;natural language processing;query processing;question answering (information retrieval);text analysis","NL report generation template database;SPARQL query;distributed word similarity;entity disambiguation;keyword matching;keyword question answering system;keyword-query;keyword-related information extraction;linked data;natural language;user keyword questions","","0","","14","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"Providing information sources domain for information seeking agent from organizing knowledge","Istiadi; L. E. Nugroho; P. I. Santosa","Dept. Of Electr. Eng., Widyagama Univ. of Malang, Malang, Indonesia","2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering","20150326","2014","","","286","290","This paper proposes a tracking mechanism to obtain the information sources that are stored on the personal knowledge organization which will be used to direct the search of information on the Internet by a software agent. Semantic representation of the organizer is viewed as a map of the information sources that are classified hierarchically based on the scopes of knowledge domains from the standpoint of the agent. The tracking mechanism by query will look for the information sources in the knowledge domains based on the same scope of a defined knowledge domain. This tracking will produce a list of information sources that will be followed to get the domain location as internet access preferences.","","Electronic:978-1-4799-6432-1; POD:978-1-4799-6433-8","10.1109/ICITACEE.2014.7065758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065758","Knowledge organization;domain information;information seeking","OWL;Ontologies;Organizations;Organizing;Semantics","Internet;information retrieval;software agents","Internet;information searching;information seeking agent;information sources;personal knowledge organization;semantic representation;software agent","","1","","20","","","8-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"A Performance Analysis of Long-Term Archiving Techniques","M. Vigil; C. Weinert; K. Braden; D. Demirel; J. Buchmann","Tech. Univ. Darmstadt, Darmstadt, Germany","2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)","20150312","2014","","","878","889","A challenge for digital archives managing long lived data, such as medical records and land registers, is to guarantee long-term authenticity, integrity, and datedness. Although some techniques have been proposed that provide these security goals, most proposals lack a corresponding performance analysis. Thus, in this paper we provide an analytical analysis of the performance of several proposals. Following, to see the impact of different approaches on the runtime, we implemented the most promising schemes and compared them with respect to their required storage space and verification time. Furthermore, the identified computational bottlenecks of the techniques are presented and corresponding improvements are indicated. Finally, we show how to select a long-term archiving scheme and the appropriate key sizes based on trust assumptions and the number of documents to be archived.","","Electronic:978-1-4799-6123-8; POD:978-1-4799-6124-5","10.1109/HPCC.2014.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056849","CIS;ERS;XAdES;archive;authenticity;datedness;efficiency;existence;integrity;long-term;notarization;performance;times-tamping","Authentication;Conferences;Performance analysis;Proposals;Public key;Syntactics","document handling;information retrieval systems","digital archives;documents;integrity;land registers;long-term archiving scheme;long-term archiving techniques;long-term authenticity;medical records;performance analysis;security goals;storage space;verification time","","1","","25","","","20-22 Aug. 2014","","IEEE","IEEE Conference Publications"
"AQUEOS: A System for Question Answering over Semantic Data","D. Toti","Dept. of Comput. & Electr. Eng. & Appl. Math., Univ. of Salerno, Fisciano, Italy","2014 International Conference on Intelligent Networking and Collaborative Systems","20150312","2014","","","716","719","This paper presents a methodology to automatically answer natural language questions by querying an underlying domain ontology. This methodology is made up of a three-phase process, where the ontological data is firstly read and indexed, the input question is then processed by means of lexical analysis and associated with a specific question type, and finally the corresponding SPARQL queries are generated and executed in order to return the answer to the original question. This process focuses on single-verb phrases in order to guarantee a highest level of precision in providing its answer, and deals with critical lexical aspects like comparatives and superlatives by relying upon language-specific lexicons, nonetheless, it is also able to take into account more complex questions with multiple verbs, provided they meet certain specific criteria. Such a methodology has been implemented in a research prototype and is being currently experimented upon by asking questions either in the English or the Italian language, and could be applied on a number of ontology-driven applications, including advanced help desk support systems, biomedical knowledge bases and intelligent e-learning solutions.","","Electronic:978-1-4799-6387-4; POD:978-1-4799-6388-1","10.1109/INCoS.2014.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057176","RDF;SPARQL;knowledge discovery;natural language processing;ontology;question answering","Indexes;Knowledge discovery;Natural languages;Ontologies;Resource description framework;Rivers;Tagging","SQL;indexing;natural language processing;ontologies (artificial intelligence);query processing;question answering (information retrieval);semantic Web;text analysis","English language;Italian language;SPARQL queries;advanced help desk support systems;biomedical knowledge bases;domain ontology;intelligent e-learning solutions;language-specific lexicons;lexical analysis;natural language question answering;ontological data indexing;ontology-driven applications;single-verb phrases","","2","","17","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Question-answer reflection of an operational space in conceptual designing the family of software intensive systems","P. Sosnin; V. Maklaev; E. Sosnina","Computer Department, Ulyanovsk State Technical University, Ulyanovsk, Russia","2014 IEEE 6th International Conference on Adaptive Science & Technology (ICAST)","20150326","2014","","","1","8","This study is bound with a rational management of experience that is used in a design company for developing the software intensive systems (SISs). The approach applied in the study is based on the creation of a precedent-oriented Experience Base the units of which are built by designers when they conceptually solve the project tasks. The specificity of way-of-working used by designers is a reflection of operational space (processes, people and products) on specialized question-answer memory (QA-memory). QA-memory with its cells is intended for registering the conceptual content of reflected units with taking into account the semantics of their textual descriptions. Reflections open the possibility for conceptual experimenting with units of designers' behavior in the instrumental environment based on question-answering. Realization of the approach promotes increasing the successfulness of designing.","2326-9413;23269413","DVD:978-1-4799-4999-1; Electronic:978-1-4799-4998-4; POD:978-1-4799-4997-7","10.1109/ICASTECH.2014.7068110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7068110","conceptual designing;experience base;precedent;question-answering;software intensive system","Capability maturity model;Grammar;Reflection;Semantics;Software;Standards","question answering (information retrieval);software engineering;storage management","QA-memory;SIS;conceptual design;operational space;precedent-oriented experience base;question-answer memory;question-answer reflection;registration;software intensive systems family;textual description semantics","","0","","17","","","29-31 Oct. 2014","","IEEE","IEEE Conference Publications"
"Semi-randomized hashing for large scale data retrieval","Haichuan Yang; Xiao Bai; Jun Zhou; Peng Ren; Jian Cheng; Lu Bai","School of Computer Since and Engineering, Beihang University, China","2014 International Conference on Data Science and Advanced Analytics (DSAA)","20150312","2014","","","53","58","In information retrieval, efficient accomplishing the nearest neighbor search on large scale database is a great challenge. Hashing based indexing methods represent each data instance as a binary string to retrieve the approximate nearest neighbors. In this paper, we present a semi-randomized hashing approach to preserve the Euclidean distance by binary codes. Euclidean distance preserving is a classic research problem in hashing. Most hashing methods used purely randomized or optimized learning strategy to achieve this goal. Our method, on the other hand, combines both randomized and optimized strategies. It starts from generating multiple random vectors, and then approximates them by a single projection vector. In the quantization step, it uses the orthogonal transformation to minimize an upper bound of the deviation between real-valued vectors and binary codes. The proposed method overcomes the problem that randomized hash functions are isolated from the data distribution. What's more, our method supports an arbitrary number of hash functions, which is beneficial in building better hashing methods. The experiments show that our approach outperforms the alternative state-of-the-art methods for retrieval on the large scale dataset.","","Electronic:978-1-4799-6991-3; POD:978-1-4799-6982-1","10.1109/DSAA.2014.7058051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058051","","Binary codes;Equations;Euclidean distance;Principal component analysis;Training;Vectors","binary codes;file organisation;indexing;information retrieval;vectors","Euclidean distance preserving;approximate nearest neighbors;binary codes;binary string;data distribution;database;hashing based indexing methods;information retrieval;large scale data retrieval;nearest neighbor search;optimized learning strategy;orthogonal transformation;quantization step;randomized hash functions;randomized learning strategy;real-valued vectors;semirandomized hashing;single projection vector","","0","","26","","","Oct. 30 2014-Nov. 1 2014","","IEEE","IEEE Conference Publications"
"Natural Language Interfaces to Database (NLIDB): Question handling and unit conversion","F. Reinaldha; T. E. Widagdo","Informatics Engineering, Institut Teknologi Bandung, Bandung, Indonesia","2014 International Conference on Data and Software Engineering (ICODSE)","20150319","2014","","","1","6","Natural Language Interfaces to Database is a type of database interface that allows the user to access the data using natural language. Recent development used as the base of this paper was made by Wibisono in 2013. Wibisono developed a domain-independent NLIDB using Stanford Dependency Parser as a tool in processing user input. This paper presents a solution to two of Wibisono's NLIDB problems, which are inability to process question-type queries and unit conversion. User input will first be identified, whether it is a question-type query or a directive-type query. Methods from Wibisono's NLIDB are then modified in order to be able to process question-type query. Unit conversion is done using a library called JScience in two phases of the process, before the SQL is produced (if necessary), and before the data is shown to the user. The proposed system was tested and was able to process some questions that follow a pattern and also to convert data in measurement units and some currency units.","","Electronic:978-1-4799-7996-7; POD:978-1-4799-7997-4","10.1109/ICODSE.2014.7062663","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062663","Stanford Dependency Parser;natural language interfaces to database;natural language query;question-type query;units","Grammar;Measurement units;Natural languages;Ontologies;Relational databases;User interfaces","SQL;database management systems;grammars;natural language interfaces;query processing;question answering (information retrieval);software libraries","JScience library;SQL;Stanford dependency parser;Wibisono NLIDB;data access;directive-type query;domain-independent NLIDB;natural language interfaces to database;question handling;question-type queries processing;unit conversion;user input","","0","","6","","","26-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"Digital Library: Demands and expectations","Z. A. Mohideen; K. Kaur","Department of Library Science, FCSIT, University of Malaya, Kuala Lumpur, Malaysia","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","17","21","Digital Library is also known as Digital Repository. Process of building the digital repository to Institutional Repository (IR) is vital. The institutional repository's variation is to meet the users demand and expectation of digital information and services. Digital information is a set of advanced information system. Presently, this information system is meant to support the local needs. This system is also based on specialized missions and has its own user populations. Over the years, digital repository is maturing and handling various types of information. The maturity of digital repository in affording the searching and linking tools are the most important criterions to meet the users' demand. Rich interaction between users and information residing in diverse location commence the effectiveness of digital information accessibility. Thus, digital services are being expanded internationally to meet the users' expectation. Widespread efforts for digital services on the information structures and infrastructures have tied-up the librarians and IT personnel in a digitization county. Barriers in digital information services and retrievals have lead the under way to construct repository institution to meet the users demand and anticipate the future expectations.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048165","Digital Library;Expectation;ICT;Information Structure;Infrastructure;Institutional Repository;Library Technology;Services","Communities;Information systems;Information technology;Libraries;Market research;Personnel","digital libraries;information retrieval","digital information retrieval;digital information service;digital library;digital repository;institutional repository","","0","","17","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Multimedia Retrieval via Deep Learning to Rank","X. Zhao; X. Li; Z. Zhang","Department of Information Scienceand Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Signal Processing Letters","20150311","2015","22","9","1487","1491","Many existing learning-to-rank approaches are incapable of effectively modeling the intrinsic interaction relationships between the feature-level and ranking-level components of a ranking model. To address this problem, we propose a novel joint learning-to-rank approach called Deep Latent Structural SVM (DL-SSVM), which jointly learns deep neural networks and latent structural SVM (connected by a set of latent feature grouping variables) to effectively model the interaction relationships at two levels (i.e., feature-level and ranking-level). To make the joint learning problem easier to optimize, we present an effective auxiliary variable-based alternating optimization approach with respect to deep neural network learning and structural latent SVM learning. Experimental results on several challenging datasets have demonstrated the effectiveness of the proposed learning to rank approach in real-world information retrieval.","1070-9908;10709908","","10.1109/LSP.2015.2410134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054452","Deep neural network;joint learning;latent variable;learning to rank;structural SVM","Adaptation models;Data models;Feature extraction;Joints;Neural networks;Support vector machines;Vectors","information retrieval;learning (artificial intelligence);multimedia systems;neural nets;support vector machines","DL-SSVM approach;auxiliary variable-based alternating optimization approach;deep latent structural SVM;deep learning-to-rank approach;deep neural network learning;feature-level component;information retrieval;multimedia retrieval;ranking-level component;structural latent SVM learning","","1","","24","","20150304","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Design of real-time gas Monitoring system Based-on Wireless Sensor Networks for Merapi volcano","B. Supriyo; S. S. Hidayat; A. Suharjono; M. Anif; S. Koesuma","Dept. of Electrical Engineering, Politeknik Negeri Semarang, Indonesia","2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering","20150326","2014","","","30","34","Focusing on the most active volcano Merapi, the role of ICT is crucial for improving the security and safety of the surrounding population. Wireless Sensor Network (WSN) which has the capability of monitoring remote and rural areas could be a solution to the early detection of local volcanic activity. Focusing on the most active volcano Merapi, the role of ICT is crucial for improving the security and safety of the surrounding population. Wireless Sensor Network (WSN) which has the capability of monitoring remote and rural areas could be a solution to the early detection of local volcanic activity. In this study, the raised topic is how to make the appropriate prototype WSN technology, sensors and integration models. The proposed system is expected to provide early detection of volcanology development solutions for the security and safety of people around Mount Merapi. In the early stages of research, the design is focused on the temperature and gas monitoring. The system is designed to address the challenges related to the location of the sensor where there is no electricity. In addition, to be more accurate, the sensing should be done at some point sources of gas blowouts.","","Electronic:978-1-4799-6432-1; POD:978-1-4799-6433-8","10.1109/ICITACEE.2014.7065709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065709","Merapi volcano;WSN;gas monitoring","Biomedical monitoring;GSM;Ground penetrating radar;Monitoring;Testing;Volcanoes;Wireless sensor networks","cellular radio;gas sensors;geophysical equipment;information retrieval systems;online operation;real-time systems;volcanology;wireless sensor networks","ICT role;Indonesia;Merapi volcano surrounding population;Mount Merapi;WSN area monitoring capability;active volcano;early volcanic activity detection;electricity-challenged sensor location;gas blowout point sources;gas monitoring system design;information and communications technology;integration model construction;local volcanic activity;prototype WSN technology construction;real-time gas monitoring system;remote area monitoring;rural area monitoring;sensor construction;temperature monitoring system;volcanic area population safety;volcanic area population security;volcanology development solutions;wireless sensor networks","","0","","12","","","8-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"A mobile solution for road accident data collection","K. M. Derdus; V. G. Ozianyi","Faculty of Information Technology, Strathmore University, Kenya","Proceedings of the 2nd Pan African International Conference on Science, Computing and Telecommunications (PACT 2014)","20150305","2014","","","115","120","Road accidents are a major cause of injuries and death in developing countries. It is crucial to build a road accident database and data retrieval system as a fundamental resource in improving road safety. Since the accident database needs to hold reliable data, accurate methods for accident data collection must be used. This study focuses on improving accident data collection by using a Smartphone-based application. The application's aim is to improve data collection, while supporting mobility, ubiquity and accuracy. The name of the application is CrashData; it has been developed and tested in Kenya. Using the application, data are sent to a central database for storage and can be retrieved by the same application. The type of information collected is determined by the Model Minimum Uniform Crash Criteria (MMUCC), National Institute of Statistics (NIS) and other accident data sets. Location information recording is supported and depends entirely on Smartphone inbuilt GPS module and Google places API. The application provides a web interface for office based managers, who can use Google maps to identify accident hotspots by mining location information from the database.","","Electronic:978-1-4799-6899-2; POD:978-1-4799-6900-5","10.1109/SCAT.2014.7055140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7055140","Accident Data Collection;Accident Database;Accident data presentation;Android Smartphone Application;Google APIs","Databases;Global Positioning System;Google;Mobile communication;Road accidents;Vehicles","application program interfaces;database management systems;information retrieval;mobile computing;road accidents;road safety;smart phones;traffic information systems","API;CrashData;Google map;Google places;MMUCC;NIS;National Institute of Statistics;Web interface;accident data set;accident hotspot;data retrieval system;developing country;inbuilt GPS module;location information recording;mobile solution;model minimum uniform crash criteria;office based manager;road accident data collection;road accident database;road safety;smartphone-based application","","0","","18","","","14-18 July 2014","","IEEE","IEEE Conference Publications"
"Social CRM using web mining","N. Karna; I. Supriana; U. Maulidevi","Sekolah Teknik Elektro dan Informatika, Institut Teknologi Bandung, Bandung, Indonesia","2014 International Conference on Information Technology Systems and Innovation (ICITSI)","20150226","2014","","","264","268","Traditional CRM (Customer Relationship Management) contains 3 modules, Marketing, Sales, and Support, which rely on the customer relationship and profiling information. While the information contained in those 3 modules is input by operator, it will be prudent to gather much more information from the Internet. We can find relationship between customers and find their profile from the Internet. This information can be used to enrich and direct the CRM to perform better in supporting the business objectives. Gathering information from the Internet means that we need Information Retrieval and Information Extraction that involve many sources from Internet, such as social media, net blog, and news. This research provides the model of data mining utilization in traditional CRM to become social CRM. This research contributes for CRM enhancement where customer centric application becomes automated.","","Electronic:978-1-4799-6527-4; POD:978-1-4799-6528-1","10.1109/ICITSI.2014.7048275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048275","CRM;customer profile;customer relationship;semantic network;social media;web mining","Customer relationship management;Data mining;Information management;Internet;Knowledge representation;Media;Semantics","Internet;customer relationship management;data mining;information retrieval;social networking (online)","Internet;Web mining;customer centric application;customer relationship management;data mining utilization;information extraction;information retrieval;profiling information;social CRM","","0","","12","","","24-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"Enhancing online expert system consultation service with short message service interface","Istiadi; E. B. Sulistiarini; G. D. Putra","Dept. of Electr. Eng., Widyagama Univ. of Malang, Malang, Indonesia","2014 The 1st International Conference on Information Technology, Computer, and Electrical Engineering","20150326","2014","","","266","271","Short message service (SMS) that has been widely used in various fields could potentially utilized for problem-solving consulting services that are based on expert system, so it takes a kind of application platform to implement this service. This paper proposes an expansion of online expert system services (web and wap based) by adding an application use SMS interface. Knowledge base of the expert system, which employs a decision tree approach, is expressed in the form of a database that can be accessed by the application interfaces, including SMS interface. According to the experiment results, the decision tree has been able to play a role directing the consultation mechanism from an initial question to reach a conclusion interactively. Thus, a problem-solving case that can be expressed in the decision tree allows the implementation of this system.","","Electronic:978-1-4799-6432-1; POD:978-1-4799-6433-8","10.1109/ICITACEE.2014.7065754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065754","SMS;database;decision tree;expert system","Databases;Decision trees;GSM;Knowledge based systems;Logic gates;Veins;Wireless application protocol","decision trees;electronic messaging;expert systems;information retrieval systems;mobile computing;problem solving","SMS interface;decision tree;online expert system consultation service;problem-solving consulting services;short message service interface","","1","","17","","","8-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"Case-deletion strategy for maintaining the Case Based Reasoning system","A. Smiti; Z. Elouedi","LARODEC, Universit&#x00E9; de Tunis, Institut Sup&#x00E9;rieur de Gestion de Tunis, Tunisia, 41 Street of liberty, Bouchoucha, 2000 Bardo","2014 Second World Conference on Complex Systems (WCCS)","20150316","2014","","","37","42","Case-Based Reasoning (CBR) is considered a fundamental modality in Computational Intelligence; It has the ability to accumulate previous cases records of particular past reasoning experiences and retrieve and adjust them in order to help new problem-solving in related situations. Undesirably, this incremental store process causes the uncontrolled case base growth. This mess distresses the competence and the performance of CBR systems after few runs, so the importance of maintenance research. This paper proposes a novel case deletion strategy based on a competence model using a clustering technique. Its target is to decrease both the storage requirements and search time and to spotlight on balancing case retrieval performance and competence of the case base. Series ofcase base maintenance approach tests are conducted, on which, our proposed case base maintenance approach will be tested and evaluated by competence and performance criteria.","","CD-ROM:978-1-4799-4648-8; Electronic:978-1-4799-4647-1; POD:978-1-4799-4646-4","10.1109/ICoCS.2014.7060902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060902","Case base maintenance;Case based reasoning;Clustering;Competence model","Europe;Yttrium","case-based reasoning;information retrieval;pattern clustering;problem solving","CBR;case base maintenance approach;case based reasoning system;case retrieval performance;case-deletion strategy;clustering technique;competence model;computational intelligence;incremental store process;performance criteria;problem-solving;search time;storage requirements;uncontrolled case base growth","","0","","19","","","10-12 Nov. 2014","","IEEE","IEEE Conference Publications"
"A Provisioning Service for Automatic Command Line Applications Deployment in Computing Clouds","E. Pyshkin; A. Kuznetsov","Inst. of Comput. & Control, St. Petersburg State Polytech. Univ., St. Petersburg, Russia","2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)","20150312","2014","","","518","521","This paper discusses an approach for deploying command-line applications on cloud computing platforms. The main focus of the paper is on execution of scientific algorithms (such as algorithms from the music information retrieval domain) by enabling the sharing of algorithm implementations, the reproducibility of results, and an easy access to non-experts of distributed environments. We propose a method of automatic deployment of client command line applications in PaaS and IaaS clouds which, unlike to existing approaches, requires neither preliminary platform configuration, nor platform configuration description. We designed a deployment manager using an expert system in order to automatically setup a virtual execution platform, by resolving dependencies and solving configuration issues on the basis of a pre-existing knowledge base.","","Electronic:978-1-4799-6123-8; POD:978-1-4799-6124-5","10.1109/HPCC.2014.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056791","","Cloud computing;Computer architecture;Expert systems;Software algorithms;Virtual machining","client-server systems;cloud computing;expert systems;information retrieval;music","IaaS cloud;PaaS cloud;algorithm implementations;automatic client command line application deployment;automatic command line applications;cloud computing platforms;deployment manager;distributed environments;expert system;music information retrieval domain;platform configuration description;preexisting knowledge base;scientific algorithms;virtual execution platform","","1","","10","","","20-22 Aug. 2014","","IEEE","IEEE Conference Publications"
"The Digitization of News Aggregation: Experimental Evidence on Intention to Use and Willingness to Pay for Personalized News Aggregators","O. Oechslein; M. Haim; A. Graefe; T. Hess; H. B. Brosius; A. Koslow","","2015 48th Hawaii International Conference on System Sciences","20150330","2015","","","4181","4190","Historically, journalists have manually selected news. This process has been changing dramatically with the development of personalized news aggregators (PNAs), which rely on social recommender systems (SRSs) technology. PNAs provide content geared to the personal preferences of news consumers, and thus offer new business opportunities for news providers. However, little research exists on users' intention to use PNAs or their willingness to pay (WTP) for such services. We developed PNA prototypes based on hybrid and social recommender systems and tested their performance in an online experiment. While the results showed little difference in users' intention to use either system, content provided by SRSs was perceived as more accurate. Furthermore, the optimal price point for the social recommender system (€1.68) was 68% higher than the price point for the hybrid recommender system.","1530-1605;15301605","Electronic:978-1-4799-7367-5; POD:978-1-4799-7368-2","10.1109/HICSS.2015.501","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070320","","Accuracy;Bismuth;Collaboration;Databases;Presence network agents;Prototypes;Recommender systems","consumer behaviour;content management;information retrieval;recommender systems","PNA;SRS technology;automated content aggregation;business opportunities;hybrid recommender system;intention of use;news aggregation digitization;news consumers;news providers;optimal price point;personal preferences;personalized news aggregators;social recommender systems;willingness to pay","","0","","62","","","5-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Constructing Query-Driven Dynamic Machine Learning Model With Application to Protein-Ligand Binding Sites Prediction","D. J. Yu; J. Hu; Q. M. Li; Z. M. Tang; J. Y. Yang; H. B. Shen*","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on NanoBioscience","20150227","2015","14","1","45","58","We are facing an era with annotated biological data rapidly and continuously generated. How to effectively incorporate new annotated data into the learning step is crucial for enhancing the performance of a bioinformatics prediction model. Although machine-learning-based methods have been extensively used for dealing with various biological problems, existing approaches usually train static prediction models based on fixed training datasets. The static approaches are found having several disadvantages such as low scalability and impractical when training dataset is huge. In view of this, we propose a dynamic learning framework for constructing query-driven prediction models. The key difference between the proposed framework and the existing approaches is that the training set for the machine learning algorithm of the proposed framework is dynamically generated according to the query input, as opposed to training a general model regardless of queries in traditional static methods. Accordingly, a query-driven predictor based on the smaller set of data specifically selected from the entire annotated base dataset will be applied on the query. The new way for constructing the dynamic model enables us capable of updating the annotated base dataset flexibly and using the most relevant core subset as the training set makes the constructed model having better generalization ability on the query, showing “part could be better than all” phenomenon. According to the new framework, we have implemented a dynamic protein-ligand binding sites predictor called OSML (On-site model for ligand binding sites prediction). Computer experiments on 10 different ligand types of three hierarchically organized levels show that OSML outperforms most existing predictors. The results indicate that the current dynamic framework is a promising future direction for bridging the gap between the rapidly accumulated annotated biological data and the effective mach- ne-learning-based predictors. OSML web server and datasets are freely available at: http://www.csbio.sjtu.edu.cn/bioinf/OSML/ for academic use.","1536-1241;15361241","","10.1109/TNB.2015.2394328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051329","Dynamic learning framework;OSML;machine learning;query-driven prediction model","Biological system modeling;Data models;Feature extraction;Predictive models;Proteins;Training","Internet;biochemistry;bioinformatics;data mining;information retrieval systems;learning (artificial intelligence);proteins;question answering (information retrieval)","OSML dataset;OSML prediction;OSML predictor;OSML web server;annotated base dataset;annotated biological data;annotated dataset base;bioinformatics prediction model;dataset selection;dataset training;dynamic learning framework;dynamic machine learning model;dynamic model construction;dynamic protein-ligand binding site predictor;fixed training dataset;ligand-type computer experiment;machine learning algorithm;machine learning model construction;machine learning-based predictor;machine-learning-based method;on-site model for ligand binding site dataset;on-site model for ligand binding site prediction;on-site model for ligand binding site predictor;on-site model for ligand binding site web server;protein-ligand binding site prediction;query-driven machine learning model;query-driven prediction model construction;query-driven predictor;static approach disadvantage;static approach scalability;static prediction model;traditional static method","0","6","","48","","","Jan. 2015","","IEEE","IEEE Journals & Magazines"
"Personalizing health and food advices by semantic enrichment of multilingual cross-domain questions","A. Al-Nazer; T. Helmy","Information and Computer Science Department, College of Computer Science & Engineering, King Fahd University of Petroleum & Minerals, Dhahran 31216, Mail Box 413, Saudi Arabia","2015 IEEE 8th GCC Conference & Exhibition","20150316","2015","","","1","6","Web search engines help in retrieving the scattered information from the Web, albeit with a number of limitations. They can't understand or enrich the user's natural language questions easily or offer the recommendation that fits the user's exact needs. Health and food information are examples of critical domains where the users have a lot of questions that need to be understood well, enriched and processed to retrieve answers that match the user's needs. Using the personalization and the semantic techniques help us to propose a framework that enriches the user's questions and retrieves more relevant results. In this paper, we analyze the user's preferences related to the health and food domains, and then propose a user's profile ontology that represents these preferences and map them to the pre-defined domain ontologies. The proposed framework has been implemented and the experimental results show promising results with user satisfaction.","","Electronic:978-1-4799-8422-0; POD:978-1-4799-8423-7; USB:978-1-4799-8421-3","10.1109/IEEEGCC.2015.7060095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060095","food and nutrition;ontology;personalization;query manipulation;semantic Web","Computer science;Conferences;Educational institutions;Natural languages;Ontologies;Search engines;Semantics","information needs;information retrieval;natural language interfaces;personal computing;recommender systems;search engines","Web search engines;domain ontologies;food advices;food information;health information;health personalization;multilingual cross-domain questions;recommendation;semantic enrichment;user exact needs;user natural language questions;user preferences;user profile ontology;user questions;user satisfaction","","0","","19","","","1-4 Feb. 2015","","IEEE","IEEE Conference Publications"
"Revised catalogue specifications of speech corpora with user-friendly visualization and search system","S. Itahashi; T. Ohsuga; Y. Ishimoto; H. Kojima; K. Uchimoto; S. Kozawa","Tsukuba University, Japan","2014 17th Oriental Chapter of the International Committee for the Co-ordination and Standardization of Speech Databases and Assessment Techniques (COCOSDA)","20150302","2014","","","1","5","It is well known that speech corpora are indispensable to speech research; several data centers of speech corpora have been set up worldwide in order to meet this demand that serve as a repository for various speech corpora. However, they use different specification systems for their corpora, and so it is difficult for speech corpora users to compare and select suitable corpora. It would be more convenient for the users if each data center used a common specification system for describing its corpora. Based on this idea, we have already proposed a set of specification attributes and items as the first step towards standardization, but the scale of the retrieval system was limited. This paper introduces a revised version of the speech corpora specification attributes and items to be connected with the large-scale metadata database “SHACHI” combined with the “Concentric Ring View (CRV) System” to improve the user interface.","","Electronic:978-1-4799-7094-0; POD:978-1-4799-7095-7","10.1109/ICSDA.2014.7051421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051421","Database;corpus;language;resource;retrieval","Asia;Data visualization;Databases;Europe;Microphones;Speech;Visualization","computer centres;data visualisation;formal specification;human computer interaction;information retrieval;meta data;speech processing","CRV system;SHACHI;concentric ring view system;data centers;large-scale metadata database;revised catalogue specifications;search system;speech corpora specification attributes;user interface;user-friendly visualization system","","0","","10","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Designing digital library of a Kashmiri craft ""Papier Machie"" using greenstone","R. Jan; A. H. Wafaye","Department of Library and Information science, University of Kashmir, Hazaratbal, Srinagar-190006, India","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","95","98","The study focuses on development of digital library of Kashmiri handicraft ""Papier-Machie"". The art is one of the most famous and exported handicraft of Kashmir. The Greenstone Digital Library Software has been used to design digital library of ""Paper-Machie"" handicraft. The digital library will be a knowledge resource providing opportunities for storing, managing and retrieving information about each facet of the craft including designs, products, shapes, sizes and material used etc. The study is first of its kind as it highlights the treasure trove of one of the crafts of Kashmir. It will open a new vista of creation of digital library or heritage repository.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048179","Digital Libraries;Greenstone;Handicrafts;Heritage Repositories;Open Sources Softwares;Papier Machie","Art;Educational institutions;Green products;Libraries;Market research;Materials;Shape","digital libraries;history;information management;information retrieval;information storage","Kashmiri handicraft;Paper-Machie handicraft;Papier Machie;craft including design;greenstone digital library software;heritage repository;information management;information retrieval;information storage","","0","","11","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Drawing on millions of biomedical journal publications to do predictive biology","K. M. Verspoor","Department of Computing and Information Systems, The University of Melbourne, Melbourne, VIC 3010 Australia","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","251","253","The biomedical literature captures the most current biomedical knowledge and is a tremendously rich resource for research. With over 24 million publications currently indexed in the US National Library of Medicine's PubMed index, however, it is becoming increasingly challenging for biomedical researchers to keep up with this literature. Automated strategies for extracting information from it are required. Large-scale processing of the literature enables direct biomedical knowledge discovery. This paper introduces the use of text mining techniques to support analysis of biological data sets, specifically discussing applications in protein function prediction and analysis of genetic variants that are supported by analysis of the literature. Review of the work suggests that methods that integrate simple text analysis with more targeted relation extraction, and methods that combine literature-derived information with complementary biological data, represent the most promising future directions.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072808","","Bioinformatics;Diseases;Feature extraction;Protein engineering;Proteins;Text mining","biology computing;data analysis;data mining;electronic publishing;genetics;information retrieval;medical information systems;text analysis","PubMed index;US National Library of Medicine;biological data set analysis;biomedical journal publications;biomedical knowledge discovery;biomedical researchers;complementary biological data;genetic variants;information extraction;large-scale literature processing;predictive biology;relation extraction;text analysis;text mining techniques","","0","","31","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"Clustering Categorical Data Using Rough Membership Function","B. S. Kumar; H. V. Reddy; T. A. Raju; P. Vennam","Comput. Sci. & Eng., Vardhaman Coll. of Eng., Hyderabad, India","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","602","607","Data mining automates the process of finding predictive records in large databases. Clustering is a very popular technique in data mining and is a significant methodology that is performed based on the principle of similarity. The segregation of a large database is a challenging and time consuming task. For this purpose, an approach called data labeling through sampling technique is used. Using this approach segregating large databases not only gets easier but also it increases the efficiency of clustering technique. Initially a sample data is retrieved from a large database for clustering and the residual unsampled data points are compared with the clustered data from which the similar data points are clustered and the dissimilar one are considered as outliers based on various data labeling techniques. These data labeling techniques are easier to apply in the numerical domains, whereas in the categorical domains this is a complicated task as the distance among data points are incalculable. Further the proposed methodology gives a data labeling technique based on the changes in the similarities after including unlabeled data point into existing cluster for categorical data using cluster entropy in rough set theory. The experimental results show that the proposed algorithm is an efficient and high quality clustering algorithm compared to that of the previous ones.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065555","Categorical Data;Cluster Quality;Data Labeling;Entropy;Outlier;Rough Membership;Rough Sets","Algorithm design and analysis;Clustering algorithms;Data mining;Entropy;Information systems;Labeling;Rough sets","data mining;information retrieval;pattern clustering;rough set theory;very large databases","categorical data clustering;data mining;data retrieval;large databases;predictive records;rough membership function","","0","","32","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Open-domain utterance generation using phrase pairs based on dependency relations","H. Sugiyama; T. Meguro; R. Higashinaka; Y. Minami","NTT Communication Science Laboratories, Japan","2014 IEEE Spoken Language Technology Workshop (SLT)","20150402","2014","","","60","65","The development of open-domain conversational systems remains difficult since user utterances are widely varied for such systems to respond appropriately. To address this is- sue, previous research has retrieved sentences from the web as system utterances by shallow sentence matching with user utterances. However, since the retrieved sentences include the inherent contexts of the document in which the sentences originally appeared, the retrieved sentences have the possibility of containing information that is irrelevant to user utter-ances. We propose combining two strongly related semantic units (phrase pairs with dependency relations) to create a system utterance. Here, the first semantic unit is the one found in the user utterance and the second semantic unit is the one that has a dependency relation with the first one in a large text cor- pus. This way, we can guarantee that the generated utterance is related to the input user utterance. Our experiments, which examine the appropriateness of response sentences, show that our proposed method significantly outperforms other retrieval and rule-based approaches.","","Electronic:978-1-4799-7129-9; POD:978-1-4799-7130-5; USB:978-1-4799-7128-2","10.1109/SLT.2014.7078550","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078550","conversational systems;dependency structures;utterance generation","Context;Databases;Noise measurement;Poles and towers;Semantics;Tropical cyclones;Twitter","information retrieval;speech processing;text analysis","dependency relations;large text corpus;open-domain conversational system development;open-domain utterance generation;phrase pairs;response sentence appropriateness;semantic unit;semantic units;sentence retrieval;system utterance;user utterances","","1","","15","","","7-10 Dec. 2014","","IEEE","IEEE Conference Publications"
"Access to library resources through portable devices: A pre-design prototype for creating library websites","K. J. P. Anbu; S. Kataria","University of Swaziland Swaziland","2015 4th International Symposium on Emerging Trends and Technologies in Libraries and Information Services","20150226","2015","","","1","5","The term Mobile Communication Technology has greatly influenced a number of initiatives in the academic and learning environments, especially in the institutions of higher learning. The internet explosion, proliferation of online resources and the advent of free and open access resources provided the much needed impetus for libraries to inject new energy into providing quality service delivery of its services. The continuous advancements in the mobile communication paradigm, the shifting focus of users towards accepting mobile internet as the primary source of access to information has once again shifted the attention of libraries to provide mobile related services to their users. More and more applications and databases are being provided to the libraries as mobile products. This paper focuses on the overall impact of mobile related services and applications in libraries and looks specifically on the mobile library websites. Library websites are considered to be the face of any library. Most of the library services are offered through library websites. For any Library which wants to provide a better interface for their mobile users are forced to rethink about their websites to see whether it is compatible with the multitude of mobile gadgets. This paper looks at the best practices in creating such mobile library websites along with a prototype of how such websites can be created using a simple start to finish suggestions. The important impetus of this paper comes from an overall experience in creating such a websites for different university libraries, from the inception of the concept to the end.","","CD-ROM:978-1-4799-5531-2; Electronic:978-1-4799-5532-9; POD:978-1-4799-5533-6","10.1109/ETTLIS.2015.7048162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7048162","Library website;Mobile library website;Mobile website validating;Responsive web design","Internet;Libraries;Mobile communication;Smart phones;Web design","Internet;academic libraries;further education;information retrieval;libraries;mobile communication;mobile computing","academic environment;higher learning;information access;learning environment;library Website creation;library resource access;library services;mobile Internet;mobile communication technology;mobile gadgets;mobile library Website;mobile products;mobile related services;mobile users;online resources;open access resources;portable devices;service delivery quality;university libraries","","0","","17","","","6-8 Jan. 2015","","IEEE","IEEE Conference Publications"
"Bridging semantics with physical objects using augmented reality","Y. Sun; H. Bae; S. Manna; J. White; M. Golparvar-Fard","Computer Science Department, California State Polytechnic University, Pomona, USA","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","344","349","Today's industry emphasize greatly on data-driven and data engineering technologies, triggering a tremendous amount of structured and unstructured data across different domains. As a result of which, semantic information is implicitly available in the knowledge base, mainly in the form of data descriptions, and needs to be extracted automatically to better serve the users' need. But how to deliver the data to the end-users in an effective and efficient way, has posed a new challenge, particularly in the context of big data and mobile computing. Traditional search-based approach may suffer from the degraded user experience or scalability. It is very essential to understand meaning (i.e., semantics) rather than pure keywords matching, that might lead to entirely spurious results of no relevance. In this paper, we present the usage of an Augmented Reality (AR) solution to bridge the existing semantic data and information with the real-world physical objects. The AR solution - HD4AR (Hybrid 4-Dimensional Augmented Reality) has been commercialized as a startup company to provide AR service to industry patterns to associate valuable semantic information with the objects in specific contexts, so that users can easily retrieve the data by snapping a photo and having the semantic information rendered on the photo accurately and quickly. Followed by a brief overview of the technology, we present a few use cases as well as the lessons learned from the industry collaboration experience.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050832","","Availability;Computational modeling;Databases;Feature extraction;Semantics","augmented reality;information retrieval","AR service;HD4AR;data retrieval;hybrid 4-dimensional augmented reality;physical objects;semantic data;semantic information","","0","","17","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Extracting information of future events from Arabic newspapers: an overview","M. Alruily; M. Alghamdi","Department of Computer Science, Faculty of Computer Science and Information, Aljouf University, Sakaka, Saudi Arabia","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","444","447","Most Arabic systems developed for newspaper information extraction relate to events that occurred in the past. This paper presents a proposal for developing a web-based system that will be able to regularly collect news reports from Arabic newspaper websites, and then be able to extract information relating to future events, e.g. event type, date and location. Also, the system will be able to deposit the extracted data in an online database in order to enable users to access them. The proposed approach is based on Arabic grammar and on dependency relationships.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050848","Arabic language;future event;information extraction","Artificial intelligence;Filtering;Mobile communication","Web sites;information retrieval","Arabic grammar;Arabic newspaper Web sites;Web-based system;dependency relationship;newspaper information extraction","","0","","18","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Efficient Filtering Algorithms for Location-Aware Publish/Subscribe","M. Yu; G. Li; T. Wang; J. Feng; Z. Gong","Department of Computer Science, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","20150305","2015","27","4","950","963","Location-based services have been widely adopted in many systems. Existing works employ a pull model or user-initiated model, where a user issues a query to a server which replies with location-aware answers. To provide users with instant replies, a push model or server-initiated model is becoming an inevitable computing model in the next-generation location-based services. In the push model, subscribers register spatio-textual subscriptions to capture their interests, and publishers post spatio-textual messages. This calls for a high-performance location-aware publish/subscribe system to deliver publishers' messages to relevant subscribers. In this paper, we address the research challenges that arise in designing a location-aware publish/subscribe system. We propose an R-tree based index by integrating textual descriptions into R-tree nodes. We devise efficient filtering algorithms and effective pruning techniques to achieve high performance. Our method can support both conjunctive queries and ranking queries. We discuss how to support dynamic updates efficiently. Experimental results show our method achieves high performance which can filter 500 messages in a second for 10 million subscriptions on a commodity computer.","1041-4347;10414347","","10.1109/TKDE.2014.2349906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880816","","Computational modeling;Indexes;Keyword search;Semantics;Subscriptions;Time complexity","information filtering;middleware;mobile computing;question answering (information retrieval)","R-tree based index;R-tree nodes;conjunctive queries;efficient filtering algorithms;location-aware answers;location-aware publish/subscribe system;next-generation location-based services;pruning techniques;push model;ranking queries;server-initiated model;spatio-textual messages;subscribers register spatio-textual subscriptions","","5","","36","","20140820","April 1 2015","","IEEE","IEEE Journals & Magazines"
"Paraphrase generation based on lexical knowledge and features for a natural language question answering system","K. J. Oh; H. J. Choi; G. Gweon; J. Heo; P. M. Ryu","Dept. of Computer Science, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","35","38","A question answering (QA) system constructs its answers automatically by querying a structured database known as a knowledgebase or an unstructured collection of documents and a set of questions. Paraphrase approaches are widely used to solve paraphrastic problems in natural language QA systems. In machine-learning-based Korean paraphrase, the system requires a large-scale mono/bi-lingual corpus. However, thus far, a well-structured corpus is lack, and it is difficult to get alignment data between Korean and English without noise for entailment. This paper creates paraphrase sentences using synonym knowledge and the various features of full morphemes. The results here demonstrate that the paraphrase quality can be improved by the following features: the morpheme type, the dependencies, and the semantic arguments. The feature of the semantic role labeling (SRL) results can be of assistance when attempting to solve instances of word sense disambiguation (WSD) for lexical replacement in Korean.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072846","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072846","feature extraction;natural language QA system;paraphrase generation;synonym knowledge","Dictionaries;Feature extraction;Natural languages;Pragmatics;Semantics;Syntactics;Thesauri","natural language processing;question answering (information retrieval)","Korean lexical replacement;QA systems;SRL;WSD;lexical knowledge;morphemes;natural language question answering system;paraphrase generation;paraphrase quality;paraphrase sentences;semantic arguments;semantic role labeling;synonym knowledge;word sense disambiguation","","0","","10","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"Short messaging service as an alternative for pushing information to build efficient information passing systems in academic institutions","V. Krishna; R. Anurag; S. S. Prabhune","Department of Information Technology, Shri Sant Gajanan Maharaj COE, Shegaon, Maharashtra, India","2014 Conference on IT in Business, Industry and Government (CSIBIG)","20150312","2014","","","1","6","Majority Applications in any academic institutions make use of technologies which involves student paying for the service i.e. Internet and most client end cell phones use Wi-Fi or GPRS to achieve these goals. Also institutions have Institutional central database servers and pay service providers for Internet Services, so using Open Source API's and a middleware one can build a service wherein students don't have to pay for Student Information Services. The proposed system is being developed to improve existing levels of communication between teachers and students of an Academic Institution. It involves sending of notices, records, setting up assignments and settling doubts using Short Messaging Service. Users will be shielded from the working and won't have to bother about communication issues. System has a high degree of security and confidentiality of clients will be maintained, also the system will generate information which might come handy in Decision Support System of the institution. It involves constant updation and exhaustive monitoring of user inputs to ensure best user experience. Client applications will be not limited to a singular platform. Being able to interact with teachers and other institution without paying internet costs will significantly increase the rate of knowledge gathering and information retrieval amongst the students and the teacher fraternity.","","CD-ROM:978-1-4799-3062-3; Electronic:978-1-4799-3064-7; POD:978-1-4799-3065-4","10.1109/CSIBIG.2014.7057006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057006","Content Delivery SMS;Data Dictionary;M- Learning;Modified XML;SMS Gateway Provider;Silent SMS","Databases;Dictionaries;GSM;Irrigation;Logic gates","Internet;cellular radio;client-server systems;decision support systems;educational institutions;electronic messaging;information retrieval;knowledge management;middleware;public domain software;security of data;wireless LAN","GPRS;Institutional central database servers;Internet;Internet service;Open Source API;Wi-Fi;academic institutions;client applications;client confidentiality;client end cell phones;client security;decision support system;information retrieval;knowledge gathering;middleware;pay service providers;short messaging service;student information services;user experience","","0","","6","","","8-9 March 2014","","IEEE","IEEE Conference Publications"
"Automatic assessment mark entry system using local binary pattern (LBP) and salient structural features","L. L. Ghai; S. B. Hisham; N. Yahya","Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Tronoh, Malaysia","2014 IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2014)","20150402","2014","","","372","377","Offline handwritten digit recognition continues to be a fundamental research problem in document analysis and retrieval. The common method used in extracting handwritten mark from assessment forms is to assign a person to manually type in the marks into a spreadsheet. This method is found to be time consuming, not cost effective and prone to human mistakes. Thus, a number recognition system is developed using local binary pattern (LBP) technique to extract and convert students' identity numbers and handwritten marks on assessment forms into a spreadsheet. The training data contain three sets of LBP values for each digit. The recognition rate of handwritten digits using LBP is about 50% because LBP could not fully describe the structure of the digits. Instead, LBP is useful in term of scaling the digits `0 to 9' from the highest to the lowest similarity score as compared with the sample using chi square distance. The recognition rate can be greatly improved to about 95% by verifying the ranking of chi square distance with the salient structural features of digits.","","CD-ROM:978-1-4799-5685-2; Electronic:978-1-4799-5686-9; POD:978-1-4799-5687-6","10.1109/ICCSCE.2014.7072747","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072747","chi square distance;handwritten recognition;local binary pattern;structural feature","Conferences;Control systems;Feature extraction;Handwriting recognition;Histograms;Training data","document handling;handwriting recognition;information retrieval","LBP;automatic assessment mark entry system;chi square distance;document analysis;document retrieval;handwritten digits recognition rate;handwritten mark extraction;local binary pattern;offline handwritten digit recognition;salient structural features","","0","","16","","","28-30 Nov. 2014","","IEEE","IEEE Conference Publications"
"Implementation Method of Answering Engine for Vietnamese Questions in Reading Answering System Model (RASM)","S. T. Pham; D. T. Nguyen","Dept. of Inf. Sci. & Eng., Univ. of Inf. Technol., Ho Chi Minh City, Vietnam","2014 8th Asia Modelling Symposium","20150406","2014","","","175","180","This paper aims to present our method of implementation which is introduced to build the answering engine of RASM (Reading Answering System Model). RASM is built to run on Prolog's engine and can read many forms of Vietnamese news titles of ICTNEWS (http://ictnews.vn) to answer several types of Vietnamese questions. In RASM, the answering engine is the central kernel. The RASM's answering engine includes two principal elements: i) first element is a computational grammar which is defined in DCG (Definite Clause Grammar) to determine the semantic representation of Vietnamese questions, ii) second element is a seeking method to answer the questions.","2376-1164;23761164","Electronic:978-1-4799-6487-1; POD:978-1-4799-6488-8","10.1109/AMS.2014.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079295","Computational Semantics;Question Answering System;Reading Answering System;Semantic Representation","Birds;Databases;Engines;Grammar;Internet;Semantics;TV","Internet;grammars;natural language processing;question answering (information retrieval)","DCG;ICTNEWS Vietnamese news titles;Prolog engine;RASM;Vietnamese question answering engine;Vietnamese question semantic representation;computational grammar;definite clause grammar;reading answering system model","","2","","13","","","23-25 Sept. 2014","","IEEE","IEEE Conference Publications"
"Cross-Modal Learning to Rank via Latent Joint Representation","F. Wu; X. Jiang; X. Li; S. Tang; W. Lu; Z. Zhang; Y. Zhuang","College of Computer Science and Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Image Processing","20150306","2015","24","5","1497","1509","Cross-modal ranking is a research topic that is imperative to many applications involving multimodal data. Discovering a joint representation for multimodal data and learning a ranking function are essential in order to boost the cross-media retrieval (i.e., image-query-text or text-query-image). In this paper, we propose an approach to discover the latent joint representation of pairs of multimodal data (e.g., pairs of an image query and a text document) via a conditional random field and structural learning in a listwise ranking manner. We call this approach cross-modal learning to rank via latent joint representation (CML<sup>2</sup>R). In CML<sup>2</sup>R, the correlations between multimodal data are captured in terms of their sharing hidden variables (e.g., topics), and a hidden-topic-driven discriminative ranking function is learned in a listwise ranking manner. The experiments show that the proposed approach achieves a good performance in cross-media retrieval and meanwhile has the capability to learn the discriminative representation of multimodal data.","1057-7149;10577149","","10.1109/TIP.2015.2403240","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041225","Cross-modal Ranking;Cross-modal ranking;Latent Joint Representation;Learning to Rank;latent joint representation;learning to rank","Approximation methods;Correlation;Joints;Loss measurement;Manganese;Vectors","data structures;information retrieval;random processes","CML2R;conditional random field;cross-media retrieval;cross-modal learning;cross-modal ranking;discriminative multimodal data representation;hidden-topic-driven discriminative ranking function;latent joint representation;listwise ranking manner;structural learning","","4","","30","","20150212","May 2015","","IEEE","IEEE Journals & Magazines"
"Extracting local event information from micro-blogs for trip planning","W. Yamada; D. Torii; H. Kikuchi; H. Inamura; K. Ochiai; K. Ohta","NTT Docomo, Inc., Yokosuka, Kanagawa, Japan","2015 Eighth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)","20150316","2015","","","7","12","This paper describes a method to extract local event information from the micro-blog service Twitter. Twitter holds innumerable user-posted short messages called tweets that cover various topics including local events. Our proposal is composed of three steps: 1) extract tweets related to local events from local tweets by the Support Vector Machine (SVM) approach, 2) identify and extract the venues, names and times of local events mentioned in the tweets by applying Conditional Random Fields (CRF), 3) use the venues and similarity of names to aggregate duplicate local event information. We implement the proposed method and confirm that it extracts local event information with higher precision than the conventional methods.","","Electronic:978-4-9076-2612-9; POD:978-1-4799-5592-3; USB:978-4-9076-2621-1","10.1109/ICMU.2015.7061020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7061020","Twitter;local event;local information service;machine learning;natural language processing","Aggregates;Data mining;Feature extraction;Hidden Markov models;Support vector machines;Training data;Twitter","information needs;information networks;information retrieval;social networking (online);support vector machines","CRF;SVM;conditional random fields;innumerable user-posted short messages;local event information;local tweets;microblog service Twitter;microblogs;support vector machine;trip planning","","1","","8","","","20-22 Jan. 2015","","IEEE","IEEE Conference Publications"
"Reuse and integration of healthcare information for subjects in a clinical trial for treatment of recurrent respiratory papillomatosis","A. D. Goldstein","Massachusetts General Hospital Center for Laryngeal Surgery and Voice Rehabilitation, 1 Bowdoin Square, 11th Floor, Boston, MA 02114","Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)","20150302","2014","","","874","879","This paper describes healthcare information reuse and integration in the clinical trial of a drug (Avastin) involving 20 research subjects diagnosed with recurrent respiratory papillomatosis (RRP) of the vocal cords and treated at Massachusetts General Hospital (MGH) Voice Center. The client/server application designed and developed by the author assisted in clinical trial data entry, storage in a relational database, retrieval, and reporting. The developed clinical trial software included data auditing to satisfy FDA requirements. Auxiliary import/export jobs were employed, which allowed to reuse standard MGH outpatient and surgical schedules and increased the efficiency of the clinical trial data management by avoiding data entry duplication. This clinical data processing design allowed the author to preserve integrity of the healthcare data used in the clinical trial. The clinical data integration allowed doctors to track the overall dynamics of the treatment process covering pre-trial, in-trial and post-trial examinations of the research subjects.","","Electronic:978-1-4799-5880-1; POD:978-1-4799-5881-8; USB:978-1-4799-5879-5","10.1109/IRI.2014.7051984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051984","Clinical Trial;Data Integrity;Database for Voice Disorders;Drug Trial;Healthcare Data Reuse;Healthcare Database Integration;Healthcare Information Integration;Healthcare Information Reuse","Aerodynamics;Clinical trials;Databases;Hospitals;Servers;Software","client-server systems;data integration;data integrity;diseases;health care;information retrieval;medical computing;patient treatment;relational databases","Avastin;FDA requirements;MGH outpatient schedule;MGH surgical schedule;Massachusetts General Hospital Voice Center;RRP;auxiliary export jobs;auxiliary import jobs;client-server application;clinical data processing design;clinical trial data management;data auditing;drug clinical trial data entry;healthcare data integrity preservation;healthcare information integration;healthcare information reuse;in-trial examination;post-trial examination;pre trial examination;recurrent respiratory papillomatosis treatment;relational database;reporting;retrieval;vocal cords","","0","","12","","","13-15 Aug. 2014","","IEEE","IEEE Conference Publications"
"Case-based reasoning approach for form interface design","D. H. Widyantoro; U. Ungkawa; B. Hendradjaya","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Indonesia","2014 International Conference on Data and Software Engineering (ICODSE)","20150319","2014","","","1","6","Redesigning process occurs occasionally in the global design. Redesigning is a cognitive process - which requires developers to remember the earlier designs. This paper proposes a system to support the design process to help the cognitive process in form based user interface by utilizing case based reasoning (CBR) approach. The cases consist of problems (form specifications) and their solutions (form designs). In addition to case library, additional information extracted from prior design cases are also included in knowledge base in order to improve the efficiency during case adaptation process. These additional knowledges consist of information about fields (component) grouping, fields ordering as well as group layout. The system also maintains a dictionary of various terms that are commonly used to denote form fields. The system takes user's form specification as input. It then applies normalization to the user's specification to ensure that all field requirements can be precisely identified. The form specification resulting from the normalization process is matched with the stored form specifications in case library. The best match case in library is retrieved and its form-design is used as the initial form design. It then undergoes form-design adaptation process to meet with the user form specification. Adaptation consists of transformation and composition. The composition requires form fields (component) grouping, fields sorting and fields group lay outing.","","Electronic:978-1-4799-7996-7; POD:978-1-4799-7997-4","10.1109/ICODSE.2014.7062690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062690","Form-based user interface;case-based reasoning;form design reuse","Cities and towns;Cognition;Dictionaries;Knowledge based systems;Layout;Libraries;User interfaces","case-based reasoning;formal specification;information retrieval;knowledge based systems;user interfaces","case adaptation process;case library;case-based reasoning approach;cognitive process;form based user interface design;form design adaptation process;global design;information extraction;knowledge base;normalization process;prior design cases;redesigning process;user form specification","","0","","11","","","26-27 Nov. 2014","","IEEE","IEEE Conference Publications"
"The colour-based Autonomous File Extraction Rover","A. A. Takyi; D. Damoah; E. Danso Ansong; H. Quarshie; G. Nagapan","Department of Computer Science, Valley View University, Oyibi, Ghana","Proceedings of IEEE International Conference on Computer Communication and Systems ICCCS14","20150326","2014","","","102","106","The Autonomous File Extraction Rover mobile robot, using NXT 2.0, is presented. A novel proposition is made that millions of file items can be uniquely searched, retrieved or sorted based on their unique colour when both the RGB and HSL colorspaces are used to widen the scope of the object recognition capability of the robotic system, through advanced colour identification devices. Object perception and identification using the NXT RGB colour system is used as a sample demonstration. The agent can search, retrieve and sort using a set of colour sensors, ultrasonic sensor, touch sensor, three servor motors and programmed using the interactive NXT-G programming language. This project involves with an extensive robot construction works with varied algorithms such as path planning, object detection and navigation. The agent is able to search, sort, grab and release items based on the instruction it has received in a highly-controlled environment but requires improvement when operational commercially.","","Electronic:978-1-4799-3672-4; POD:978-1-4799-3673-1","10.1109/ICCCS.2014.7068176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7068176","HCL;NXT-G;RGB;colorspace;retrieve;search;sort","Color;Image color analysis;Object recognition;Tactile sensors","control engineering computing;image colour analysis;image sensors;information retrieval;interactive programming;mobile robots;object recognition;path planning;robot vision;servomotors;sorting;tactile sensors;ultrasonic transducers","HSL colorspaces;NXT 2.0;NXT RGB colour system;RGB colorspaces;colour identification devices;colour sensors;colour-based autonomous file extraction rover mobile robot;file items;interactive NXT-G programming language;navigation;object detection;object identification;object perception;object recognition;path planning;retrieval;robot construction;robotic system;searching;servor motors;sorting;touch sensor;ultrasonic sensor","","0","","22","","","20-21 Feb. 2014","","IEEE","IEEE Conference Publications"
"A Time Based Analysis of Data Processing on Hadoop Cluster","A. Pal; S. Agrawal","Dept. of Comput. Eng. & Applic., Nat. Inst. of Tech. Teachers' Training & Res. Bhopal, Bhopal, India","2014 International Conference on Computational Intelligence and Communication Networks","20150326","2014","","","608","612","Data when it becomes in that much amount that it cannot be managed by the traditional database management system then it is Big data. It is difficult to manage this much amount of the data. Hadoop is a technological answer to the Big Data. Data storage and retrieval of information from the data is done by the Hadoop Distributed File System and the Map Reduce Programming model. MapReduce provides effective bench marks for retrieving the information from the Big Data. In this paper we present our experimental work done on the Hadoop Cluster. We have analyzed the time required by the cluster for processing the data with increasing number of nodes into the cluster. We started with a single node and then increase the node by one each time. We have analyzed three types of time. The real time, user time, system time is analyzed.","","Electronic:978-1-4799-6929-6; POD:978-1-4799-6930-2","10.1109/CICN.2014.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065556","Data Node;Hadoop Distributed File System;Job Tracker;MapReduce;Name Node;Task Tracker","Big data;Distributed databases;File systems;Google;Real-time systems;Sorting","Big Data;information retrieval;storage management","Big Data;Hadoop cluster;Hadoop distributed file system;MapReduce programming model;data processing;data storage;information retrieval;real time;system time;time based analysis;user time","","0","","9","","","14-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Leveraging the web for automating tag expansion for low-content items","A. Singhal; J. Srivastava","Dept. of Computer Science and Eng., University of Minnesota, USA","Proceedings of the 2014 IEEE 15th International Conference on Information Reuse and Integration (IEEE IRI 2014)","20150302","2014","","","545","552","Tags, as high quality semantic descriptors, are used in categorization, clustering and efficient retrieval of various items in the web corpus. Images, videos, songs and similar multimedia items are the most common items which are tagged either manually or in a semiautomatic manner. However, the tagging process becomes complicated when the content structure of an item is not interpretable. Such a problems occurs in items like scientific research datasets or documents with very little text content. In this work, we propose a generalized approach to automate tag expansion for such low-content items. We leverage intelligence of the web to generate secondary content for such items for the tag expansion process. While automating tag expansion, we also address the problem of topic drift by automating removal of the noisy tags from the set of candidate new tags. The effectiveness of the proposed approach is tested on a real world dataset. The performance of the proposed is compared with Wikipedia based nearest neighbor tagging (WikiSem) and non-negative matrix factorization (NMF) based tag expansion approaches. Based on the Mean Reciprocal Rank (MRR) metric, the proposed approach was twice as accurate as the WikiSem baseline (0.27 vs 0.13) and at least 2.25 times the NMF baselines (0.27 vs 0.12).","","Electronic:978-1-4799-5880-1; POD:978-1-4799-5881-8; USB:978-1-4799-5879-5","10.1109/IRI.2014.7051937","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051937","","Databases;Google;Noise measurement;Search engines;Semantics;Tagging","Internet;Web sites;information retrieval;text analysis","MRR metric;NMF based tag expansion approach;Web corpus;WikiSem;Wikipedia based nearest neighbor tagging;high quality semantic descriptors;item content structure;low-content items;mean reciprocal rank metric;multimedia items;nonnegative matrix factorization;tag expansion automation process;text content;topic drift problem","","0","","26","","","13-15 Aug. 2014","","IEEE","IEEE Conference Publications"
"IEEE Recommended Practice for Learning Technology - Open Archives Initiative Object Reuse and Exchange Abstract Model (OAI-ORE) - Mapping to the Conceptual Model for Resource Aggregation","","","IEEE Std 1484.13.6-2015","20150326","2015","","","1","32","Specified in this recommended practice are how the elements and attributes defined in the Open Archives Initiative Object Reuse and Exchange (OAI-ORE) Abstract Model and expressed in the OAI-ORE Resource Map Implementation in RDF/XML relate to the components of the conceptual model for resource aggregation defined in IEEE Std 1484.13.1(TM)-2012.","","Electronic:978-0-7381-9557-5","10.1109/IEEESTD.2015.7069175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069175","IEEE 1484.13.6;OAI-ORE;Open Archives Initiative Object Reuse and Exchange Abstract Model;RAMLET;aggregation format;conceptual model;content aggregation;digital aggregation;digital resource;resource aggregation;resource aggregation format","Aggregation formats;Content aggregation;Digital systems;IEEE Standards;Learning systems;Resource management","IEEE standards;educational technology;information retrieval systems","IEEE Standard 1484.13.1-2012;OAI-ORE resource map implementation;conceptual model;learning technology;open archives initiative object reuse and exchange abstract model;resource aggregation","","0","","","","","March 31 2015","","IEEE","IEEE Standards"
"Review on ""Really Simple Syndication (RSS) Technology Tools""","G. Singh; S. Sahu","M.Tech Comput. Sci. & Eng., Ajay Kumar Garg Eng. Coll., Ghaziabad, India","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","757","761","A user always requires up-to date content from online sources. The content is not always satisfactory for the user as it does not provide the specific information required by user. It is tedious task for common user to get the desirable information from vast Internet. To overcome this type of problem, the user needed RSS technology for ease of access. RSS gives the updated online information to the user. This paper represents review study of Really Simple Syndication (RSS) technology. Here we discuss about many Tools and useful areas where RSS is used and also define many issues due to improper RSS feed. For this research work article from last one decade (2003-2013) has been selected.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078804","RSS Feeds;RSS Tools;Really Simple Syndication (RSS)","Browsers;Clustering algorithms;Feeds;Information filters;Real-time systems;Servers","Internet;information retrieval","Internet;RSS feed;RSS technology;information access;online sources;really simple syndication technology tools","","0","","18","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"Web content extraction based on subject detection and node density","W. Petprasit; S. Jaiyen","Department of Computer Science, Faculty of Science, King Mongkut's Institute of Technology Ladkrabang, Thailand","2015 7th International Conference on Knowledge and Smart Technology (KST)","20150302","2015","","","121","125","Currently, very large data have been transferred from everywhere through World Wide Web. Consequently, the information extraction systems have been arising and many researches have been focusing on those data for utilizing them. These systems are very useful for data pre-processing and cleaning for real-time applications. Moreover, these systems can make other analyzing systems to analyze the data in real time such as social network mining, web mining, data mining, or even special tasks such as false advertisement detection, demand forecasting, and comment extraction on product and service reviews. In this paper, we focus on extracting the content data of web pages in e-commerce web sites based on subject detection and node density. In the experimental results, it can signify that our proposed method is appropriated to extract the data rich region in data-intensive pages in an automatic fashion.","","Electronic:978-1-4799-6049-1; POD:978-1-4799-6050-7","10.1109/KST.2015.7051455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051455","data intensive;e-commerce;node density (SDND);subject detection;web content extraction;web information extraction;web mining;wrapper induction","Cascading style sheets;Data mining;Uniform resource locators;Web pages;XML","Big Data;Internet;Web sites;electronic commerce;information retrieval","Web content extraction;Web pages;World Wide Web;content data extraction;data cleaning;data pre-processing;data rich region;data-intensive pages;e-commerce Web sites;information extraction systems;node density;real-time applications;subject detection;very large data","","2","","15","","","28-31 Jan. 2015","","IEEE","IEEE Conference Publications"
"Big Data Analysis: Recommendation System with Hadoop Framework","J. P. Verma; B. Patel; A. Patel","Inst. of Technol., Nirma Univ., Ahmedabad, India","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","92","97","Recommendation system provides the facility to understand a person's taste and find new, desirable content for them automatically based on the pattern between their likes and rating of different items. In this paper, we have proposed a recommendation system for the large amount of data available on the web in the form of ratings, reviews, opinions, complaints, remarks, feedback, and comments about any item (product, event, individual and services) using Hadoop Framework. We have implemented Mahout Interfaces for analyzing the data provided by review and rating site for movies.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078674","Big Data Analysis;Hadoop Framework;Mahout;Recommendation System","Big data;Business;Collaboration;Data mining;Internet;Recommender systems","Big Data;data handling;information retrieval;parallel processing;recommender systems","Mahout interfaces;big data analysis;comments;complaints;feedback;hadoop framework;opinions;ratings;recommendation system;remarks;reviews","","3","","19","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"Novel Table Based Air Indexing Technique for Full Text Search","S. Vishnoi; V. Goel","Dept. of CSE, Ajay Kumar Garg Eng. Coll., Ghaziabad, India","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","410","415","The mobility feature has become an important characteristics of the human beings living in 21st century. The emergence of new communication generations like 3G and 4G has made the world mobile in nature. Mobile phones have become necessary equipment for not only communication purpose but also for the information purpose. A mobile device is characterized with limited processing and battery power. Continuous use of mobile device for fetching information from the network requires frequent charging of mobile device. Wireless broadcasting emerged as an efficient solution for resolving requests of millions subscribers in one single response. Inclusion of full text search over wireless channel is a hot area of research. In this paper, we proposed a novel table based air indexing technique for full text search over wireless stream. We also developed algorithm for implementation of the proposed work in NS3. We also evaluated and analysed the performance of the proposed technique with the existing literature. Access time and tuning time are the two metrics for evaluating the performance of any indexing technique. Our results shows our scheme is the most efficient scheme for full text search over wireless stream.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078736","Access Latency;Broadcasting;Documents Retrieval;Indexing Techniques;Tuning Time","Broadcasting;Data structures;Dictionaries;Indexing;Tuning;Wireless communication","indexing;information retrieval","3G communication generations;4G communication generations;NS3;access time;full text search;information purpose;mobile device;mobility feature;table based air indexing technique;tuning time;wireless broadcasting;wireless stream","","0","","27","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"Topic oriented semantic parsing","L. K. Sharma; N. Mittal","Department of Computer Science and Engineering, Malaviya National Institute of Technology Jaipur, India","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","159","164","Semantic parsing is still a challenging problem for open domain question answering. In semantic parsing, questions are mapped with their meaning representations. These representations are matched with feasible answers in knowledge bases. In Knowledge bases (e.g. Freebase), knowledge is stored in the form of Topics. For a successful answer extraction from Freebase, it is required to correctly identify the Topic node (or Topic word) of the question and retrieve every type and property associated with this Topic node. In this paper, a Topic Node Identification (TNI) algorithm is proposed for correctly identifying question Topic and Domain Word Identification (DWI) algorithm is proposed for correctly identifying domain of the Topic node. After domain identification the Topic node is further expanded for its all types and properties. Out of all types identified, one of the type and associated property is likely to be an answer of the question. TWI and DWI algorithms use techniques i.e. proposed rulebased and machine learning approach with the help of question dependency parser. Results of proposed approach outperform state of art approaches.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050798","Freebase;Question-answering;Semantic Parsing;Topic node","Awards activities;Films","grammars;knowledge based systems;learning (artificial intelligence);question answering (information retrieval)","DWI algorithm;Freebase;TNI algorithm;answer extraction;domain word identification algorithm;knowledge bases;machine learning approach;meaning representations;open domain question answering;question dependency parser;rule-based approach;topic node identification algorithm;topic oriented semantic parsing","","1","","21","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Predefined clause-based structure to subdue blank node issues","M. Ting; R. A. Kadir; A. Azman; T. M. T. Sembok; F. Ahmad","Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Selangor 43400, Malaysia","2014 14th International Conference on Intelligent Systems Design and Applications","20150326","2014","","","187","192","World Wide Web provides vast of resources to the public. Currently, many researches have been done on resources sharing among users through implementation of ontologies. Knowledge in an ontology are represented in the form of triple(s-p-o), where concepts are brought together by a relation. In a situation where there is a need to represent a resource which exist without IRI, blank node can be implemented in placed of the resource. Increase number of blank nodes implemented will increase the complexity of ontology structure. Since it is impossible to avoid blank nodes implementation in the ontology, increase used of it might lead to the intractable of data during the information retrieval. This paper presents a new clause-based structure that able to handle N-ary, container, collection and reified knowledge issues brought by the blank node application. The result shows that the structure able to store complicated knowledge without the need to implement blank node.","2164-7143;21647143","Electronic:978-1-4799-7938-7; POD:978-1-4799-7939-4","10.1109/ISDA.2014.7066262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066262","N-ary;blank node;clause-based structure;container;reification","Containers;Ontologies;Periodic structures;Portable computers;Resource description framework;Silicon","information retrieval;ontologies (artificial intelligence)","World Wide Web;blank node issues;information retrieval;ontology structure;predefined clause-based structure;resources sharing","","0","","22","","","28-30 Nov. 2014","","IEEE","IEEE Conference Publications"
"Web Data Extraction Based on Visual Information and Partial Tree Alignment","S. Fan; X. Wang; Y. Dong","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China","2014 11th Web Information System and Application Conference","20150312","2014","","","18","23","Web databases contain a huge amount of structured data which are easily obtained via their query interfaces only. The query results are presented in dynamically generated web pages, usually in the form of data records, for human use. The automatical web data extraction is critical in web integration. A number of approaches have been proposed. The early work are most based on the source code or the tag tree of the page. Recent approaches use the visual feature to extract data information, which are better than the previous work. However, these approaches still have inherent limitation. In this paper, we propose a novel approach that make use of visual features to extract data information from web page, including the data records and the data items. The results of this experiment tests on a large set of query result pages in different domain show that the proposed approach is highly effective.","","Electronic:978-1-4799-5727-9; POD:978-1-4799-5728-6","10.1109/WISA.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057981","Web data extraction;Web mining;Wrapper generation","Data mining;Databases;Educational institutions;Feature extraction;Noise;Visualization;Web pages","Internet;feature extraction;information retrieval systems;information services;query processing","Web databases;Web integration;Web pages;automatical Web data extraction;data information extraction;data items;data records;partial tree alignment;query interfaces;structured data;visual feature extraction;visual information","","2","","16","","","12-14 Sept. 2014","","IEEE","IEEE Conference Publications"
"Towards a Media Fragment URI Aware User Agent","T. Wu; Z. Xu; L. Ni; Y. Zhuang; J. Wang; Q. Yan","Coll. of Comput. & Inf., Hohai Univ., Nanjing, China","2014 11th Web Information System and Application Conference","20150312","2014","","","37","42","The W3C's Media Fragments URI 1.0 specification provides for a media-format independent, standard means of addressing media fragments on the Web using Uniform Resource Identifiers (URIs). Thus, a key requirement is for the User Agent (UA) to efficiently retrieve media fragments identified by URIs from the regular media server over the HTTP protocol. This paper addresses the issue of how to construct a Media Fragment URI aware UA. We propose an approach for achieving such a UA, focusing on fully indexable container formats. Our approach consists of a set of algorithms capable of performing URI-based media fragment retrieval. Algorithm implementation and experimental results show that our approach is achievable and is able to greatly reduce time and bandwidth costs compared to the traditional approach of downloading the entire media resource.","","Electronic:978-1-4799-5727-9; POD:978-1-4799-5728-6","10.1109/WISA.2014.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057984","HTTP;MP4;Media Fragment URI;User Agent;fragment-to-byte range mapping;media fragment retrieval","Algorithm design and analysis;Bandwidth;Containers;Media;Protocols;Servers;Videos","Internet;hypermedia;information retrieval;transport protocols","HTTP protocol;UA;W3C media fragments URI 1.0 specification;bandwidth cost reduction;fully indexable container formats;media fragment URI aware user agent;media fragment retrieval;regular media server;time cost reduction;uniform resource identifiers","","0","","10","","","12-14 Sept. 2014","","IEEE","IEEE Conference Publications"
