"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=1316790,1316840,1317299,1312765,1317409,1316115,1311686,1314829,1314749,1313404,1314801,1315833,1311731,1315242,1311696,1315050,1315035,1315836,1316038,1311226,1315204,1316037,1315825,1315215,1311699,1311231,1311697,1315634,1311221,1314379,1313414,1315824,1315950,1314427,1314959,1315173,1315274,1315171,1314726,1311217,1315633,1310916,1311063,1310907,1310152,1311073,1307875,1307920,1307858,1307711,1307587,1307930,1309251,1307800,1307804,1307848,1307816,1307277,1307871,1309252,1307879,1262334,1262183,1307352,1262181,1261831,1306943,1307006,1306404,1306546,1306939,1304883,1261096,1261077,1301465,1301449,1303350,1303649,1302924,1301467,1302595,1303262,1302995,1303252,1302590,1300281,1302283,1300968,1302206,1300364,1302160,1300368,1300975,1299865,1300548,1300555,1300537,1299996,1299895,1299828",2017/05/04 21:52:56
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Optimal multi-channel data allocation with flat broadcast per channel","A. A. Bertossi; M. C. Pinotti; S. Ramaprasad; R. Rizzi; M. V. S. Shashanka","Dept. of Comput. Sci., Bologna Univ., Italy","18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.","20040607","2004","","","18","","Summary form only given. Broadcast is an efficient and scalable way of transmitting data to an unlimited number of clients that are listening to a channel. Cyclically broadcasting data over the channel is a basic scheduling technique, which is known as flat scheduling. When multiple channels are available, partitioning data among channels in an unbalanced way, depending on data popularities, is an allocation technique known as skewed allocation. In this paper, the problem of data broadcasting over multiple channels is considered assuming skewed data allocation to channels and fiat data scheduling per channel, with the objective of minimizing the average waiting time of the clients. Several algorithms, based on dynamic programming, are presented which provide optimal solutions for N data items and K channels. Specifically, for data items with uniform lengths, an O(NKlogN) time algorithm is proposed, which improves over the previously known O(N/sup 2/K) time algorithm. When K /spl les/ 4, faster O(N) time algorithms are exhibited. Moreover, for data items with nonuniform lengths, it is shown that the problem is NP-hard when K = 2, and strong NP-hard for arbitrary K. In the former case, a pseudo-polynomial algorithm is discussed, whose time is O(NZ) where Z is the sum of the data lengths.","","POD:0-7695-2132-0","10.1109/IPDPS.2004.1302924","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302924","","Bandwidth;Broadcasting;Delay effects;Dynamic programming;Dynamic scheduling;Heuristic algorithms;Information retrieval;Optimal scheduling;Telecommunications;Wireless communication","broadcast channels;broadcasting;communication complexity;dynamic programming","NP-hard problem;data broadcasting;data length;data partitioning;dynamic programming;flat scheduling;multiple channels;optimal solution;pseudo-polynomial algorithm;skewed data allocation","","8","","14","","","26-30 April 2004","","IEEE","IEEE Conference Publications"
"Retrieving multimedia presentations from multimedia server","A. Mostefaoui","LIFC, Univ. of Franche-Comte, Montbeliard, France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","515","516","We present the delivery of multimedia presentation from multimedia server. More precisely, we focus on admission control and buffer management. We propose two approaches to optimize the delivery schedules. The first approach optimizes the server workload when the second optimizes the presentation response time. Both of the proposed approaches exploit the presentation flexibilities. In face of presentations with hard presentation constraints, we propose a buffer management policy that plans buffer sharing and data prefetching between presentations. Our experimental results, which are based on realistic distributions, show that the proposed approaches can lead to a gain in server throughput of over 30 % compared to a classical approach. Furthermore, the proposed buffer management policy reduces the storage bandwidth, which is known to be the major bottleneck in a multimedia server.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307858","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307858","","Admission control;Buffer storage;Delay;Electronic mail;Indexing;Information retrieval;Multimedia systems;Processor scheduling;Resource management;Timing","buffer storage;information retrieval;multimedia servers;optimisation;scheduling;telecommunication congestion control;telecommunication network management","admission control;buffer management;buffer sharing planning;data prefetching;multimedia presentation retrieval;multimedia server;optimization;presentation constraint;presentation response time;scheduling;server workload","","0","","","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Context disambiguation in Web search results","P. Deepak; J. Jyothi; S. Parameswaran","Model Eng. Coll., Kochi, India","Proceedings. IEEE International Conference on Web Services, 2004.","20040719","2004","","","700","707","It is a common experience while Web searching that one gets to see pages that are not of interest. Partly these are due to a word or words in the search query having different contexts, the user obviously expecting to find pages related to the context of interest. This paper proposes a method for disambiguating contexts in Web search results.","","POD:0-7695-2167-3","10.1109/ICWS.2004.1314801","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314801","","Dictionaries;Educational institutions;Information retrieval;Natural language processing;Search engines;Web search;Web services","Internet;query formulation;search engines","Web pages;Web search results;context disambiguation;information retrieval;search engines;search query","","2","","4","","","6-9 July 2004","","IEEE","IEEE Conference Publications"
"A technology for retrieval of volume images from biomedical databases","D. Sarioz; G. T. Herman; T. Yung Kong","City Univ. of New York, NY, USA","IEEE 30th Annual Northeast Bioengineering Conference, 2004. Proceedings of the","20040524","2004","","","67","68","To facilitate the retrieval of volume images from a biomedical database (e.g., images of proteins from a macromolecular database), it is necessary to obtain concise descriptors of the images. Relatively recently developed successful algorithms for high-resolution three-dimensional reconstruction of biomedical structures from projections produce volume images represented as linear combinations of spherically symmetric basis functions (called blobs). In this paper, we discuss our work toward obtaining topological and geometric descriptors in the form of Betti triple sequences from such a linear combination of blobs, and give some preliminary experimental results.","","POD:0-7803-8285-4","10.1109/NEBC.2004.1299996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1299996","","Computer science;Image databases;Image reconstruction;Image retrieval;Information retrieval;Linear approximation;Proteins;Shape;Spatial databases;Subspace constraints","image reconstruction;image resolution;image retrieval;image sequences;medical image processing","Betti triple sequences;biomedical databases;geometric descriptors;high-resolution three-dimensional of biomedical structure reconstruction;macromolecular database;protein images;spherically symmetric basis functions;topological descriptors;volume image retrieval","","0","","6","","","17-18 April 2004","","IEEE","IEEE Conference Publications"
"Intelligent soundex function for Arabic names","M. E. Yahia; R. E. A. Elhafez; T. B. Elsherif; O. N. Osman","Fac. of Math. Sci., Khartoum Univ., Sudan","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","407","408","This paper, attempts to explain new and useful search function, which are used in searching and retrieving names written in Arabic language, which can be stored in a database of digital library. We called this function Arabic Soundex Function (ASF), and we present the steps of its algorithm. ASF was designed by using fuzzy logic to determine the 'degree of closeness' between the compared names, and it shows good results in three root letters Arabic names.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307804","","Computer science;Databases;Fuzzy logic;Information retrieval;Intelligent systems;Natural language processing;Natural languages;Software libraries","deductive databases;digital libraries;fuzzy logic;natural languages","ASF;Arabic Soundex Function;Arabic language;database storage;degree of closeness;digital library;fuzzy logic;intelligent retrieval system;name retrieval;natural language processing;root letters Arabic name;search function;searching name","","1","","","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Video object segmentation using Bayes-based temporal tracking and trajectory-based region merging","V. Mezaris; I. Kompatsiaris; M. G. Strintzis","Electr. & Comput. Eng. Dept., Aristotle Univ. of Thessaloniki, Greece","IEEE Transactions on Circuits and Systems for Video Technology","20040601","2004","14","6","782","795","A novel unsupervised video object segmentation algorithm is presented, aiming to segment a video sequence to objects: spatiotemporal regions representing a meaningful part of the sequence. The proposed algorithm consists of three stages: initial segmentation of the first frame using color, motion, and position information, based on a variant of the K-means-with-connectivity-constraint algorithm; a temporal tracking algorithm, using a Bayes classifier and rule-based processing to reassign changed pixels to existing regions and to efficiently handle the introduction of new regions; and a trajectory-based region merging procedure that employs the long-term trajectory of regions, rather than the motion at the frame level, so as to group them to objects with different motion. As shown by experimental evaluation, this scheme can efficiently segment video sequences with fast moving or newly appearing objects. A comparison with other methods shows segmentation results corresponding more accurately to the real objects appearing on the image sequence.","1051-8215;10518215","","10.1109/TCSVT.2004.828341","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302160","Image sequence analysis;temporal tracking;trajectory-based merging;video segmentation","Image segmentation;Information retrieval;MPEG 4 Standard;Merging;Multimedia databases;Object segmentation;Spatiotemporal phenomena;Trajectory;Video compression;Video sequences","Bayes methods;image classification;image colour analysis;image motion analysis;image segmentation;image sequences;video signal processing","Bayes classifier;Bayes-based temporal tracking;digital video;k-means-with-connectivity-constraint algorithm;multimedia application;rule-based processing;spatiotemporal region;trajectory-based region merging;unsupervised video object segmentation;video sequence","","34","2","40","","","June 2004","","IEEE","IEEE Journals & Magazines"
"Similarity measure and learning with gray level aura matrices (GLAM) for texture image retrieval","Xuejie Qin; Yee-Hong Yang","Dept. of Comput. Sci., Alberta Univ., Edmonton, Alta., Canada","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","1","","I-326","I-333 Vol.1","We present a new similarity measure for texture images based on the gray level aura matrices (GLAM), originally proposed by Elfadel and Picard for modeling textures. With the new similarity measure, a support vector machine (SVM) is used to learn pattern similarities for texture image retrieval. In our approach, a texture image is first segmented into clusters of gray level sets. Defined based on the aura measures, a normalized aura matrix is calculated between the gray level sets of the image. The similarity between two texture images computed by the distance of their corresponding normalized aura matrices is defined as the aura matrix distance. The smaller the distance, the more similar are the two textures. To enable the learning of similarity for texture image retrieval, an existing SVM method is adapted to our application, but with a different similarity measure function, different texture feature vectors, and a different similarity ranking scheme for the final retrieved images based on the GLAM. We compare our approach experimentally with existing approaches by performing texture image retrieval from the Brodatz database and the Vistex database. The experimental results show that the proposed approach has performance significantly better than existing approaches with an average successful retrieval rate of 99% - 100% vs 89% - 92% using other approaches.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315050","","Image databases;Image retrieval;Image segmentation;Image texture analysis;Information retrieval;Level set;Matrix decomposition;Spatial databases;Support vector machines;Symmetric matrices","feature extraction;image retrieval;image texture;learning (artificial intelligence);matrix algebra;pattern clustering;statistical analysis;support vector machines;visual databases","Brodatz database;SVM;Vistex database;aura matrix distance;gray level aura matrices;gray level sets;normalized aura matrix;pattern clustering;pattern similarity learning;similarity measure function;statistical analysis;support vector machine;texture feature vectors;texture image retrieval;texture modeling","","5","","37","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Time- and energy-efficient organization of objects in a broadcast environment","Y. C. Chehadeh","","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","235","236","Retrieving related objects from the air channel has two requirements: minimizing the overall response time at the mobile unit; minimizing the amount of power consumed in the retrieval process at the mobile unit. In this paper proper time, energy efficient organization and retrieval techniques for the objects in an effort to meet both requirements in a broadcast environment is proposed and analyzed. The theme of this paper is about to find an allocation scheme that maintains a suitable balance between energy and response time. Object-oriented indexing is also employed in order to investigate the objects on the channel.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307711","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307711","","Bandwidth;Broadcasting;Energy efficiency;Indexing;Information retrieval;Mobile computing;Multimedia communication;Multimedia databases;Object oriented modeling;Power system modeling","database indexing;information retrieval;mobile computing;mobile radio;multimedia databases;object-oriented databases","allocation scheme;broadcast environment;mobile unit;multimedia database;object retrieval techniques;object-oriented indexing;overall response time;time-energy-efficient object organization","","0","","","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Image retrieval by ontological description of shapes (IRONS), early results","A. Chavez-Aragon; O. Starostenko","Universidad de las Americas-Puebla","First Canadian Conference on Computer and Robot Vision, 2004. Proceedings.","20040607","2004","","","341","346","This paper addresses the problem of retrieving documents that contain visual information. Current visual information retrieval systems sometimes retrieve irrelevant documents or documents unrelated to the userÂ¿s query. This problem is caused by the use of low-level image descriptors; furthermore, these descriptors hardly have a semantic weight. In this work we address the image retrieval problem based on shape, since shape has a meaning by itself. On the other hand, an extension of the ontology concept, which is used in information retrieval based on text, is proposed in the image domain. Likewise, we present the Image Retrieval by Ontological Description of Shapes (IRONS) System. IRONS has been implemented and evaluated in order to analyze its utility, efficiency, and advantages comparing with well-known systems.","","POD:0-7695-2127-4","10.1109/CCCRV.2004.1301465","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1301465","","Animation;Computer science;Content based retrieval;Image retrieval;Information retrieval;Internet;Iron;Multimedia systems;Ontologies;Shape","","","","1","","13","","","17-19 May 2004","","IEEE","IEEE Conference Publications"
"Using singular value decomposition to improve a genetic algorithm's performance","J. G. Martin; K. Rasheed","Comput. Sci., Georgia Univ., sAthens, GA, USA","Evolutionary Computation, 2003. CEC '03. The 2003 Congress on","20040524","2003","3","","1612","1617 Vol.3","The focus of this work is to investigate the effects of applying the singular value decomposition (SVD), a linear algebra technique, to the domain of genetic algorithms. Empirical evidence, concerning document comparison, suggests that the SVD can be used to model information in such a way that provides both a saving in storage space and an improvement in information retrieval. It will be shown that these beneficial properties can be extended to many other different types of comparison as well. Briefly, vectors representing the genes of individuals are projected into a new low-dimensional space, obtained by the singular value decomposition of a gene-individual matrix. The information about what it means to be a good or bad individual serves as a basis for qualifying candidate individuals for reinsertion into the next generation. Positive results from different approaches of this application are presented and evaluated. In addition, several possible alternative techniques are proposed and considered.","","POD:0-7803-7804-0","10.1109/CEC.2003.1299865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1299865","","Autocorrelation;Chemical analysis;Computer science;Genetics;Information retrieval;Jacobian matrices;Large scale integration;Linear algebra;Matrix decomposition;Singular value decomposition","genetic algorithms;singular value decomposition","SVD;document comparison;genes;genetic algorithm;information modeling;information retrieval;linear algebra;singular value decomposition;storage space","","1","","13","","","8-12 Dec. 2003","","IEEE","IEEE Conference Publications"
"Fast contour matching using approximate earth mover's distance","K. Grauman; T. Darrell","Lab. for Comput. Sci. & Artificial Intelligence, MIT, Cambridge, MA, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","1","","I-220","I-227 Vol.1","Weighted graph matching is a good way to align a pair of shapes represented by a set of descriptive local features; the set of correspondences produced by the minimum cost matching between two shapes' features often reveals how similar the shapes are. However due to the complexity of computing the exact minimum cost matching, previous algorithms could only run efficiently when using a limited number of features per shape, and could not scale to perform retrievals from large databases. We present a contour matching algorithm that quickly computes the minimum weight matching between sets of descriptive local features using a recently introduced low-distortion embedding of the earth mover's distance (EMD) into a normed space. Given a novel embedded contour, the nearest neighbors in a database of embedded contours are retrieved in sublinear time via approximate nearest neighbors search with locality-sensitive hashing (LSH). We demonstrate our shape matching method on a database of 136,500 images of human figures. Our method achieves a speedup of four orders of magnitude over the exact method, at the cost of only a 4% reduction in accuracy.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315035","","Approximation algorithms;Costs;Earth;Embedded computing;Humans;Image databases;Information retrieval;Nearest neighbor searches;Shape measurement;Spatial databases","computational complexity;image matching;image retrieval;search problems;visual databases","approximate earth mover distance;approximate nearest neighbors search;computing complexity;contour matching algorithm;descriptive local features;embedded contours;fast contour matching;locality sensitive hashing;low distortion embedding;minimum cost matching;minimum weight matching;shape matching;weighted graph matching","","53","1","18","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Dynamic data access to the GT/CERCS Linux mirror site","M. Mansour; M. Wolf; K. Schwan","Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA","18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.","20040607","2004","","","273","","Summary form only given. The purpose of this work is to better understand the dynamic data sharing behavior of certain classes of grid end users. Toward this end, we study a large-scale data repository and the end users' access behaviors to this repository. Interesting insights from the study include that (1) the use of parallel methods for data downloads, via download accelerators, is common, despite qualms expressed by the community about the impacts of such behavior on wide area data distribution networks, (2) high levels of burstiness exist for such data movements, as also observed for scientific or populist data repositories and Web sites (e.g., space imagery, sports events), and (3) a large number of remote data retrievals are by single clients for single files. We finally discuss the impact of our observations on grid applications in general.","","POD:0-7695-2132-0","10.1109/IPDPS.2004.1303350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303350","","Collaboration;Collaborative work;Distributed computing;Educational institutions;Grid computing;Image retrieval;Information retrieval;Large-scale systems;Linux;Mirrors","Internet;Web sites;grid computing;information retrieval;network operating systems","Linux mirror site;Web sites;data downloads;data repositories;data sharing behavior;dynamic data access;grid end users;parallel methods;wide area data distribution networks","","0","","16","","","26-30 April 2004","","IEEE","IEEE Conference Publications"
"OMEGA: a Brazilian case of supporting system to police investigation activities","J. L. de Paula; R. Gomes; A. R. Pereira; A. Dahmer","EBIZ Solution Ltd., Brazil","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","13","14","The public security issue is one of the main concerns in the Brazilian Society. The Civil Police's Intelligence Department idealizes OMEGA, as a tool to support the investigative activities by providing fast access to consolidated and valuable information according to the users needs. OMEGA achieves this challenge by using data integration to a unique database and also an artificial intelligence method that retrieves crime reports through conceptual and contextual analysis of texts inserted in an open-entry field. OMEGA is a Web application accessed mainly by sheriffs and investigators through the police intranet. OMEGA is currently being in restricted use to approximately 100 police departments in order to give the development team a better control of its deployment.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307587","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307587","","Artificial intelligence;Computer aided software engineering;Connectors;Data visualization;Databases;Information resources;Information retrieval;Java;Urban areas;Web services","data mining;deductive databases;intranets;law administration;police data processing","Brazilian Society;Civil Police Intelligence Department;OMEGA;Web application tool;artificial intelligence method;crime reports;data integration;information retrieval;intranet;police investigation activities;public security issue","","0","","4","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"A new algorithm for temperature and spectral emissivity retrieval over active fires in the TIR spectral range","A. Barducci; D. Guzzi; P. Marcoionni; I. Pippi","Inst. of Appl. Phys. "Nello Carrara", Italian Nat. Res. Council, Firenze, Italy","IEEE Transactions on Geoscience and Remote Sensing","20040719","2004","42","7","1521","1529","The problem of temperature and spectral emissivity assessment from hyperspectral remotely sensed data is discussed with reference to monitoring of active fires and hot targets. A new algorithm, called similar pixel addition, was developed, which allows us to retrieve the temperature of burning areas by employing spectral data collected at thermal infrared (TIR) wavelengths. The new algorithm resolves the uncertainty connected with temperature-emissivity separation assuming a slow spatial variation of emissivity, hence reducing the number of unknowns involved in the inversion of a couple of similar pixels at once. Performance of this procedure is thoroughly discussed and compared with results from two other algorithms operating in the TIR and shortwave infrared spectral ranges. This paper shows results obtained applying the new algorithm to hyperspectral images gathered by the Multispectral Infrared and Visible Imaging Spectrometer in Northern Italy (Alps) over a natural fire that broke out in July 1999. This paper is completed with a theoretical discussion of the involved topics.","0196-2892;01962892","","10.1109/TGRS.2004.826785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315836","Fire monitoring;high-temperature event;hyperspectral remote sensing;temperature and emissivity retrieval","Fires;Hyperspectral imaging;Hyperspectral sensors;Information retrieval;Infrared spectra;Remote monitoring;Spatial resolution;Temperature distribution;Temperature sensors;Uncertainty","atmospheric spectra;atmospheric techniques;atmospheric temperature;emissivity;fires;infrared imaging;remote sensing","0.43 to 0.83 micron;1.15 to 1.55 micron;1.98 to 2.48 micron;8.2 to 12.7 micron;Alps;Multispectral Infrared and Visible Imaging Spectrometer;N Italy;TIR spectral range;active fires;fire monitoring;high temperature event;hyperspectral imaging;remote sensing;similar pixel addition;spectral emissivity;temperature measurement;temperature-emissivity separation;thermal infrared wavelengths","","8","1","20","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Intelligent agents on the Web: a review","N. Boudriga; M. S. Obaidat","Commun. Networks & Security Res. Lab, Carthage Univ., Tunisia","Computing in Science & Engineering","20040621","2004","6","4","35","42","Intelligent agents are goal-driven and autonomous, and can communicate and interact with each other. Moreover, they can evaluate information obtained online from heterogeneous sources and present information tailored to an individual's needs. This article covers different facets of the intelligent agent paradigm and applications, while also exploring new opportunities and trends for intelligent agents.","1521-9615;15219615","","10.1109/MCSE.2004.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1306943","","Access protocols;Application software;Communication networks;IP networks;Information retrieval;Intelligent agent;Intelligent networks;Knowledge representation;Load management;Web and internet services","Internet;information analysis;information dissemination;information needs;information retrieval;software agents","Internet;World Wide Web;autonomous agents;communications networks;goal-driven agents;heterogeneous sources;information dissemination;information evaluation;information needs;information service;intelligent agents","","19","","27","","","July-Aug. 2004","","IEEE","IEEE Journals & Magazines"
"Holographic data storage systems","L. Hesselink; S. S. Orlov; M. C. Bashaw","Dept. of Electr. Eng., Stanford Univ., Palo Alto, CA, USA","Proceedings of the IEEE","20040719","2004","92","8","1231","1280","In this paper, we discuss fundamental issues underlying holographic data storage: grating formation, recording and readout of thick and thin holograms, multiplexing techniques, signal-to-noise ratio considerations, and readout techniques suitable for conventional, phase conjugate, and associative search data retrieval. Next, we consider holographic materials characteristics for digital data storage, followed by a discussion on photorefractive media, fixing techniques, and noise in photovoltaic and other media with a local response. Subsequently, we discuss photopolymer materials, followed by a discussion on system tradeoffs and a section on signal processing and en/decoding techniques, succeeded by a discussion on electronic implementations for control, signal encoding, and recovery. We proceed further by presenting significant demonstrations of digital holographic systems. We close by discussing the outlook for future holographic data storage systems and potential applications for which holographic data storage systems would be particularly suited.","0018-9219;00189219","","10.1109/JPROC.2004.831212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316038","Diffraction gratings;gratings;high density data storage;holographic data storage;holographic recording materials;holography;optical data storage;optical storage materials;photopolymer media;photorefractive media;volumetric data storage","Data storage systems;Disk recording;Gratings;Holography;Information retrieval;Memory;Photorefractive materials;Photovoltaic systems;Signal processing;Signal to noise ratio","data recording;decoding;digital readout;digital storage;digital versatile discs;encoding;holographic gratings;holographic storage;multiplexing;optical phase conjugation;optical polymers;photorefractive effect;photorefractive materials;photovoltaic effects","DVD;associative search data retrieval;digital data storage;grating formation;hologram readout;hologram recording;holographic data storage systems;holographic materials;local response;multiplexing;phase conjugate process;photopolymer materials;photorefractive media;photovoltaic media noise;signal decoding;signal encoding;signal processing;signal recovery;signal-noise ratio;thick holograms;thin holograms","","177","13","145","","","Aug. 2004","","IEEE","IEEE Journals & Magazines"
"Data mining source code to facilitate program comprehension: experiments on clustering data retrieved from C++ programs","Y. Kanellopoulos; C. Tjortjis","Dept. of Comput., UMIST, Manchester, UK","Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004.","20040712","2004","","","214","223","This paper presents ongoing work on using data mining to discover knowledge about software systems thus facilitating program comprehension. We discuss how this work fits in the context of tool supported maintenance and comprehension and report on applying a new methodology on C++ programs. The overall framework can provide practical insights and guide the maintainer through the specifics of systems, assuming little familiarity with these. The contribution of this work is two-fold: it provides a model and associated method to extract data from C++ source code which is subsequently to be mined, and evaluates a proposed framework for clustering such data to obtain useful knowledge. The methodology is evaluated on three open source applications, results are assessed and conclusions are presented. This paper concludes with directions for future work.","1092-8138;10928138","POD:0-7695-2149-5","10.1109/WPC.2004.1311063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311063","","Application software;Character recognition;Computer languages;Data mining;Data models;Documentation;Information retrieval;Object oriented modeling;Software maintenance;Software systems","C++ language;data mining;public domain software;reverse engineering;software maintenance","C++ programs;C++ source code;data clustering;data extraction;data mining;open source applications;program comprehension;tool supported maintenance","","4","","20","","","24-26 June 2004","","IEEE","IEEE Conference Publications"
"Optimized management of large-scale data sets stored on tertiary storage systems","B. Reiner; K. Hahn","","IEEE Distributed Systems Online","20040621","2004","5","5","","","We focus on extending RasDaMan's multidimensional query language using a new concept called object framing. With this extension, users no longer are restricted to performing range queries in the shape of multidimensional hypercubes. It can be able to formulate range queries by indicating complex frames. Thus, object framing represents a generalization of geometric operations. A new system, optimized toward high-performance computing, extends the RasDaMan (Raster Data Management) database management system to allow flexible management of multidimensional spatiotemporal data and to reduce tertiary storage access time.","1541-4922;15414922","","10.1109/MDSO.2004.5","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1306404","65;database;hierarchical storage management;high-performance computing;multidimensional array data;storage","Atmospheric modeling;Computational modeling;Database systems;Information retrieval;Knowledge based systems;Knowledge management;Large-scale systems;Magnetic devices;Multidimensional systems;Spatiotemporal phenomena","cache storage;query languages;query processing;temporal databases;very large databases;visual databases","database management system;high-performance computing;multidimensional query language;multidimensional spatiotemporal data;object framing;raster data management;tertiary storage systems","","4","","25","","","2004","","IEEE","IEEE Journals & Magazines"
"Function estimation of protein using finite state automaton based on accumulated amino acid residue scores","S. Chiba; K. Sugawara","Dept. of Inf. Eng., Sendai Nat. Coll. of Technol., Japan","Evolutionary Computation, 2003. CEC '03. The 2003 Congress on","20040524","2003","3","","1833","1839 Vol.3","Today, most effective method to estimate the function of unknown protein is to retrieve similar known sequences. There are some effective techniques for sequence retrieval to estimate protein functions. We propose a method to express the amino acid sequence by finite state automaton. At first, we introduce an accumulated amino acid residue score (ARS). Next, we introduce a finite state automaton (FSA) to describe the alignment of amino acid residues. Combining ARS and FSA, and we can calculate the similarity of known protein sequence and unknown one. We applied this method to a protein family and examined the efficiency of this method.","","POD:0-7803-7804-0","10.1109/CEC.2003.1299895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1299895","","Amino acids;Automata;Bioinformatics;DNA;Dictionaries;Genomics;Information retrieval;Protein engineering;Sequences;State estimation","biology computing;estimation theory;finite automata;proteins;sequences","amino acid array;amino acid residue score;amino acid sequence;finite state automaton;motif retrieval;pairwise alignment;protein function estimation;sequence retrieval","","0","","13","","","8-12 Dec. 2003","","IEEE","IEEE Conference Publications"
"MISSION: an agent-based system for semantic integration of heterogeneous distributed statistical information sources","S. McClean; B. Scotney; H. Rutjes; J. Hartkamp; I. Karali; M. Hatzopoulos; J. Lamb; Defeng Ma","Sch. of Comput. & Inf. Eng., Ulster Univ., Ireland","Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.","20040719","2004","","","337","340","The MISSION system utilises query agents, in particular the matching and negotiation agents that are responsible for pre-integration where the matching agent decomposes the query into sub-queries, and then searches metadata to find datasets that match the query fragments. Such an approach provides a capability of automating the process of executing queries on heterogeneous statistical databases that are distributed over the Internet. The novelty lies in the provision of automated methods for statistical aggregation, where the heterogeneity essentially resides in the classification schemes of categorical data, including both heterogeneity of nomenclature and heterogeneity of granularity. In addition, our solution permits queries to be specified in a goal-driven query-by-example format. Rather than impose an a priori global standard, the user can query through a unified interface where integration is done at run-time.","1099-3371;10993371","POD:0-7695-2146-0","10.1109/SSDM.2004.1311226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311226","","Data engineering;Distributed computing;Distributed databases;Informatics;Information retrieval;Internet;Runtime;Software libraries;Telecommunication computing;Web server","Internet;data mining;distributed databases;meta data;query processing;software agents;statistical databases","Internet;MISSION system;a priori global standard;agent-based system;automated methods;categorical data;data preintegration;dataset finding;goal-driven query-by-example format;granularity heterogeneity;heterogeneous distributed statistical information sources;heterogeneous statistical databases;matching agents;metadata searching;negotiation agents;nomenclature heterogeneity;query agents;query decomposition;query fragments;query specification;run-time integration;semantic integration;statistical aggregation;unified interface;user query","","0","","8","","","21-23 June 2004","","IEEE","IEEE Conference Publications"
"N-parameter retrievals from L-band microwave observations acquired over a variety of crop fields","M. Parde; J. P. Wigneron; P. Waldteufel; Y. H. Kerr; A. Chanzy; S. S. Sobjaerg; N. Skou","Ecologie Fonctionnelle et Phys. de I'Environnement, Inst. Nat. de la Recherche Agronomique, Villenave D'Omon, France","IEEE Transactions on Geoscience and Remote Sensing","20040614","2004","42","6","1168","1178","A number of studies have shown the feasibility of estimating surface soil moisture from L-band passive microwave measurements. Such measurements should be acquired in the near future by the Soil Moisture and Ocean Salinity (SMOS) mission. The SMOS measurements will be done at many incidence angles and two polarizations. This multiconfiguration capability could be very useful in soil moisture retrieval studies for decoupling between the effects of soil moisture and of the various surface parameters that also influence the surface emission (surface temperature, vegetation attenuation, soil roughness, etc.). The possibility to implement N-parameter (N-P) retrieval methods (where N = 2, 3, 4, ..., corresponds to the number of parameters that are retrieved) was investigated in this study based on experimental datasets acquired over a variety of crop fields. A large number of configurations of the N-P retrievals were studied, using several initializations of the model input parameters that were considered to be fixed or free. The best general configuration using no ancillary information (same configuration for all datasets) provided an rms error of about 0.059 m<sup>3</sup>/m<sup>3</sup> in the soil moisture retrievals. If a priori information was available on soil roughness and at least one vegetation model parameter, the rms error decreased to 0.049 m<sup>3</sup>/m<sup>3</sup>. Using specific retrieval configurations for each dataset, the rms error was generally lower than 0.04 m<sup>3</sup>/m<sup>3</sup>.","0196-2892;01962892","","10.1109/TGRS.2004.826820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1304883","L-band radiometry;SMOS;Soil Moisture and Ocean Salinity;model inversion;retrieval;soil moisture;soil roughness;surface temperature;vegetation","Crops;Information retrieval;L-band;Ocean temperature;Rough surfaces;Sea measurements;Sea surface;Soil measurements;Soil moisture;Surface roughness","crops;data acquisition;hydrological techniques;microwave measurement;moisture measurement;radiometry;soil;vegetation mapping","L-band microwave observations;L-band passive microwave measurements;N-parameter retrievals;SMOS mission;Soil Moisture and Ocean Salinity;ancillary information;incidence angles;model inversion;multiconfiguration capability;rms error;soil moisture retrieval;soil roughness;surface emission;surface parameters;surface soil moisture estimation;surface temperature;vegetation attenuation;vegetation model parameter","","33","","36","","","June 2004","","IEEE","IEEE Journals & Magazines"
"Stop-word removal algorithm for Arabic language","R. Al-Shalabi; G. Kanaan; J. M. Jaam; A. Hasnah; E. Hilat","Dept. of Comput. Sci., Yarmouk Univ., Irbid, Jordan","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","545","","Summary form only given. We have designed and implemented an efficient stop-word removal algorithm for Arabic language based on a finite state machine (FSM). An efficient stop-word removal technique is needed in many natural language processing application such as: spelling normalization, stemming and stem weighting, Question answering systems and in information retrieval systems (IR). Most of the existing stop-word removal techniques bases on a dictionary that contains a list of stop-word, it is very expensive, it takes too much time for searching process and required too much space to store these stop-words. The new Arabic removal stop-word technique has been tested using a set of 242 Arabic abstracts chosen from the Proceedings of the Saudi Arabian National Computer conferences, and another set of data chosen from the holy Q'uran, and it gives impressive results that reached approximately to 98%.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307875","","Abstracts;Algorithm design and analysis;Automata;Computational Intelligence Society;Computer science;Dictionaries;Information retrieval;Natural language processing;Testing","finite state machines;natural languages;optimisation;text analysis","Arabic language;dictionary;finite state machine;information retrieval system;information searching process;natural language processing;stop-word removal algorithm","","5","","","","","23-23 April 2004","","IEEE","IEEE Conference Publications"
"Object-based image retrieval using the statistical structure of images","D. Hoiem; R. Sukthankar; H. Schneiderman; L. Huston","Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-490","II-497 Vol.2","We propose a new Bayesian approach to object-based image retrieval with relevance feedback. Although estimating the object posterior probability density from few examples seems infeasible, we are able to approximate this density by exploiting statistics of the image database domain. Unlike previous approaches that assume an arbitrary distribution for the unconditional density of the feature vector (the density of the features taken over the entire image domain), we learn both the structure and the parameters of this density. These density estimates enable us to construct a Bayesian classifier. Using this Bayesian classifier, we perform a windowed scan over images for objects of interest and employ the user's feedback on the search results to train a second classifier that focuses on eliminating difficult false positives. We have incorporated this algorithm into an object-based image retrieval system. We demonstrate the effectiveness of our approach with experiments using a set of categories from the Corel database.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315204","","Bayesian methods;Feedback;Histograms;Image databases;Image retrieval;Image segmentation;Information retrieval;Probability;Robots;Spatial databases","Bayes methods;content-based retrieval;image classification;image retrieval;object-oriented databases;relevance feedback;visual databases","Bayesian approach;Corel database;image database;object-based image retrieval;relevance feedback;statistical structure","","16","7","26","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Holographic Data Storage Systems","R. O'Donnell","","Proceedings of the IEEE","20040719","2004","92","8","1229","1230","","0018-9219;00189219","","10.1109/JPROC.2004.831216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316037","","DVD;Data storage systems;Holographic optical components;Holography;Information retrieval;Material storage;Optical recording;Photorefractive effect;Photorefractive materials;Polymers","","","","1","","","","","Aug. 2004","","IEEE","IEEE Journals & Magazines"
"On the efficient evaluation of probabilistic similarity functions for image retrieval","N. Vasconcelos","Dept. of Electr. & Comput. Eng., Univ. of California, La Jolla, CA, USA","IEEE Transactions on Information Theory","20040621","2004","50","7","1482","1496","Probabilistic approaches are a promising solution to the image retrieval problem that, when compared to standard retrieval methods, can lead to a significant gain in retrieval accuracy. However, this occurs at the cost of a significant increase in computational complexity. In fact, closed-form solutions for probabilistic retrieval are currently available only for simple probabilistic models such as the Gaussian or the histogram. We analyze the case of mixture densities and exploit the asymptotic equivalence between likelihood and Kullback-Leibler (KL) divergence to derive solutions for these models. In particular, 1) we show that the divergence can be computed exactly for vector quantizers (VQs) and 2) has an approximate solution for Gauss mixtures (GMs) that, in high-dimensional feature spaces, introduces no significant degradation of the resulting similarity judgments. In both cases, the new solutions have closed-form and computational complexity equivalent to that of standard retrieval approaches.","0018-9448;00189448","","10.1109/TIT.2004.830760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1306546","","Closed-form solution;Computational complexity;Content based retrieval;Costs;DNA;Histograms;Image databases;Image retrieval;Information retrieval;Multimedia databases","Bayes methods;Gaussian processes;computational complexity;image retrieval;maximum likelihood estimation;vector quantisation;visual databases","Bayes classifier;Gauss mixtures;Kullback-Leibler divergence;MAP;asymptotic equivalence;computational complexity;high-dimensional feature spaces;image databases;maximum a posteriori probability;probabilistic image retrieval;probabilistic similarity functions;vector quantizers","","50","3","65","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Combination methods in microarray analysis","Han-Yu Chuang; Hongfang Liu; Fang-An Chen; Cheng-Yan Kao; D. F. Hsu","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","7th International Symposium on Parallel Architectures, Algorithms and Networks, 2004. Proceedings.","20040524","2004","","","625","630","Microarray technology and experiment can produce thousands or tens of thousands of gene expression measurements in a single cellular mRNA sample. Selecting a list of informative differential genes from these measurement data has been the central problem for microarray analysis. Many methods to identify informative genes have been proposed in the past. However, due to the complexity of biological systems, each proposed method seems to perform nicely in a particular data set or specific experiment. It remains a great challenge to come up with a selection method for a wider spectrum of experiments and a broader variety of data sets. In this paper, we take the approach of method combination using data fusion and rank-score graph which have been used successfully in other application domains such as information retrieval, pattern recognition and tracking, and molecular similarity search. Our method combination is efficient and flexible and can be extended to become a general learning system for microarray gene expression analysis.","1087-4089;10874089","POD:0-7695-2135-5","10.1109/ISPAN.2004.1300548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300548","","Computer science;Data analysis;Gene expression;Head;Information retrieval;Information systems;Medical diagnostic imaging;Neck;Pattern recognition;Surgery","biology computing;genetics;sensor fusion","biological systems;data fusion;gene expression measurement;general learning system;informative differential genes;microarray analysis;microarray gene expression analysis;rank-score graph;single cellular mRNA","","6","","19","","","10-12 May 2004","","IEEE","IEEE Conference Publications"
"WALRUS: a similarity retrieval algorithm for image databases","A. Natsev; Rajeev Rastogi; K. Shim","IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA","IEEE Transactions on Knowledge and Data Engineering","20040628","2004","16","3","301","316","Approaches for content-based image querying typically extract a single signature from each image based on color, texture, or shape features. The images returned as the query result are then the ones whose signatures are closest to the signature of the query image. While efficient for simple images, such methods do not work well for complex scenes since they fail to retrieve images that match the query only partially, that is, only certain regions of the image match. This inefficiency leads to the discarding of images that may be semantically very similar to the query image since they may contain the same objects. The problem becomes even more apparent when we consider scaled or translated versions of the similar objects. We propose WALRUS (wavelet-based retrieval of user-specified scenes), a novel similarity retrieval algorithm that is robust to scaling and translation of objects within an image. WALRUS employs a novel similarity model in which each image is first decomposed into its regions and the similarity measure between a pair of images is then defined to be the fraction of the area of the two images covered by matching regions from the images. In order to extract regions for an image, WALRUS considers sliding windows of varying sizes and then clusters them based on the proximity of their signatures. An efficient dynamic programming algorithm is used to compute wavelet-based signatures for the sliding windows. Experimental results on real-life data sets corroborate the effectiveness of WALRUS'S similarity model.","1041-4347;10414347","","10.1109/TKDE.2003.1262183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1262183","","Area measurement;Clustering algorithms;Data mining;Dynamic programming;Image databases;Image retrieval;Information retrieval;Layout;Robustness;Shape","content-based retrieval;dynamic programming;feature extraction;image colour analysis;image matching;image retrieval;image texture;natural scenes;pattern clustering;visual databases","WALRUS;clustering;content-based image querying;dynamic programming algorithm;image databases;image matching regions;object translation;real-life data sets;region extraction;shape features;similarity retrieval algorithm;sliding windows;texture features;user-specified scenes;wavelet-based signature retrieval","","70","2","26","","","Mar 2004","","IEEE","IEEE Journals & Magazines"
"Efficient 1-out-of-n oblivious transfer schemes with universally usable parameters","Wen-Guey Tzeng","Dept. of Comput. & Inf. Sci., Nat. Chiao Tung Univ., Hsinchu, Taiwan","IEEE Transactions on Computers","20040621","2004","53","2","232","240","We propose efficient and secure (string) oblivious transfer (OT<sup>1</sup><sub>n</sub>) schemes for any n≥2. We build our OT<sup>1</sup><sub>n</sub> scheme from fundamental cryptographic techniques directly. The receiver's choice is unconditionally secure and the secrecy of the unchosen secrets is based on the hardness of the decisional Diffie-Hellman problem. Some schemes achieve optimal efficiency in terms of the number of rounds and the total number of exchanged messages for the case that the receiver's choice is unconditionally secure. The distinct feature of our scheme is that the system-wide parameters are independent of n and universally usable, that is, all possible receivers and senders use the same parameters and need no trapdoors specific to each of them. We extend our OT<sup>1</sup><sub>n</sub> schemes to distributed oblivious transfer schemes. Our distributed OT<sup>1</sup><sub>n</sub> schemes take full advantage of the research results of secret sharing. For applications, we present a method of transforming any (single-database) PIR protocol into a symmetric PIR protocol by slightly increasing the communication cost only.","0018-9340;00189340","","10.1109/TC.2004.1261831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261831","","Complexity theory;Contracts;Costs;Cryptographic protocols;Cryptography;Distributed computing;Information retrieval","communication complexity;cryptography;distributed processing;information retrieval","Diffie-Hellman problem;cryptographic technique;oblivious transfer scheme;private information retrieval","","26","","46","","","Feb 2004","","IEEE","IEEE Journals & Magazines"
"A fast negotiation algorithm for multiple methods agents","H. Belleili; M. Bouzid; M. Sellami","LRI Lab., Badji Mokhtar Univ., Annaba, Algeria","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","495","496","A multiagents negotiation under time constraints is presented. The multiagents system (MAS) is dealt with the task and it is based on two reasoning techniques, which are progressive reasoning and multiple methods. The motivation of progressive reasoning is to adapt the quality of the solution to the available time. Multiple methods is an approach that assumes with a set of methods that trade-off computational resources against the quality of result. The minimal solution is obtained which is incrementally by interchanging all or part of approximate methods. The target system is flexible and can adapt itself to the load of each agent for responding to tasks in time. Responses will be of quality less or better depending on the methods that have been used by each selected agent.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307848","","Artificial intelligence;Computer architecture;Decision making;Delay;Information retrieval;Laboratories;Multiagent systems;Optimized production technology;Search engines;Time factors","multi-agent systems","MAS;fast negotiation algorithm;multiagents system;multiple methods;progressive reasoning;time constraints","","0","","9","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"WS-QDL containing static, dynamic, and statistical factors of Web services quality","SeokHyun Yoon; DongJoon Kim; SangYong Han","Dept. of Comput. Sci. & Eng., Chung-Ang Univ., Seoul, South Korea","Proceedings. IEEE International Conference on Web Services, 2004.","20040719","2004","","","808","809","Web services following distributed object computing technology like DCOM, CORBA provides remote procedure call mechanism based on XML-based open standard such as SOAP, WSDL, and UDDI, and it is spotlighted as means of integration and collaboration at e-business. Especially, UDDI is the Web services registry enabling to register and search Web services that takes charge of providing infrastructure for Web services. However, the existing UDDI has a few problems that searching process is very simple and it cannot provide information of Web services quality and quality-based retrieval. Therefore, this study suggests improved UDDI model that evaluates the Web services quality and use this information for searching.","","POD:0-7695-2167-3","10.1109/ICWS.2004.1314829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314829","","Availability;Collaboration;Computer science;Information retrieval;Ontologies;Q factor;Registers;Simple object access protocol;Telecommunication traffic;Web services","Internet;distributed object management;electronic commerce;groupware;information retrieval;quality of service;remote procedure calls","CORBA;DCOM;SOAP;UDDI model;WS-QDL;WSDL;Web service collaboration;Web service infrastructure;Web service integration;Web service registry;Web service searching;Web services quality;XML-based open standard;distributed object computing technology;e-business;quality-based retrieval;remote procedure call mechanism","","5","","4","","","6-9 July 2004","","IEEE","IEEE Conference Publications"
"Multiresolution histograms and their use for recognition","E. Hadjidemetriou; M. D. Grossberg; S. K. Nayar","","IEEE Transactions on Pattern Analysis and Machine Intelligence","20040524","2004","26","7","831","847","The histogram of image intensities is used extensively for recognition and for retrieval of images and video from visual databases. A single image histogram, however, suffers from the inability to encode spatial image variation. An obvious way to extend this feature is to compute the histograms of multiple resolutions of an image to form a multiresolution histogram. The multiresolution histogram shares many desirable properties with the plain histogram, including that they are both fast to compute, space efficient, invariant to rigid motions, and robust to noise. In addition, the multiresolution histogram directly encodes spatial information. We describe a simple yet novel matching algorithm based on the multiresolution histogram that uses the differences between histograms of consecutive image resolutions. We evaluate it against five widely used image features. We show that with our simple feature we achieve or exceed the performance obtained with more complicated features. Further, we show our algorithm to be the most efficient and robust.","0162-8828;01628828","","10.1109/TPAMI.2004.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300555","Fisher information;Multiresolution histogram;feature comparison.;feature parameter sensitivity;histogram bin width;histogram matching;image sharpness;scale-space;shape feature;texture feature","Histograms;Image databases;Image recognition;Image resolution;Image retrieval;Information retrieval;Spatial databases;Spatial resolution;Video sharing;Visual databases","image coding;image recognition;image resolution;image retrieval;visual databases","image intensity;image recognition;image resolution;image retrieval;matching algorithm;multiresolution histogram;multiresolution histograms;single image histogram;spatial image variation;visual databases","Algorithms;Artificial Intelligence;Data Interpretation, Statistical;Image Enhancement;Image Interpretation, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","108","5","81","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Inference Bayesian network for multitopographic neural network communication: a case study in documentary data","S. A. Shehabi; J. C. Lamirel","LORIA, Nancy, France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","431","432","This paper presents an original approach consisting in assimilating the behavior of the MultiSOM model to the one of a Bayesian inference network in documentary data. This approach is used both for validating the MultiSOM intermap communication principles and for enhancing the accuracy of the probabilistic correlation computation mode. In a complementary way, the approach also led to prove that a neural multimap model provided with unsupervised learning might well behave as a Bayesian inference network in which the estimation of posterior probabilities becomes a simple process only using prior similarity measures. A performance comparison between former probabilistic intercommunication mode and new probabilistic intercommunication mode based on Bayesian inference is finally proposed in the paper.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307816","","Bayesian methods;Computer aided software engineering;Data analysis;Data mining;Information analysis;Information retrieval;Intelligent networks;Neural networks;Performance analysis;Unsupervised learning","belief networks;inference mechanisms;self-organising feature maps;unsupervised learning","MultiSOM model;documentary data;inference Bayesian network;intermap communication principle;multitopographic neural network communication;neural multimap model;posterior probability intercommunication mode;probabilistic correlation computation mode;self-organising feature maps;unsupervised learning","","1","","4","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Change detection in aerial images","M. Borchani; F. Cloppet; A. Volkan; S. Georges","Universite Paris 5","First Canadian Conference on Computer and Robot Vision, 2004. Proceedings.","20040607","2004","","","354","360","This paper deals with how to characterize texture and how to get a good description of images with a minimal number of parameters. This procedure is more objective than textual data. Texture characterization has been used in a matching system to detect changes in couples of aerial images taken at two different times using different order of statistics to describe images. The results are quite encouraging.","","POD:0-7695-2127-4","10.1109/CCCRV.2004.1301467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1301467","","Business;Computer errors;Content based retrieval;Entropy;Frequency;Image matching;Image retrieval;Information retrieval;Neural networks;Statistics","","","","3","","19","","","17-19 May 2004","","IEEE","IEEE Conference Publications"
"Assessing the quality of SeaWinds rain measurements","D. W. Draper; D. G. Long","Microwave Earth Remote Sensing Lab., Brigham Young Univ., Provo, UT, USA","IEEE Transactions on Geoscience and Remote Sensing","20040719","2004","42","7","1424","1432","While SeaWinds was designed to measure ocean winds, it can also measure rain over the ocean. SeaWinds on QuikSCAT active measurements of integrated columnar rain rate obtained via simultaneous wind/rain retrieval are evaluated via Monte Carlo simulation and the Crame´r-Rao lower bound on estimate accuracy. Although sufficiently accurate in many conditions, the simultaneous wind/rain retrieval method used with SeaWinds on QuikSCAT data is ill-conditioned for certain wind directions and measurement geometries, sometimes yielding spurious rain rates in zero-rain conditions. To assess the validity of SeaWinds-derived rain rates, a simple empirically based rain thresholding scheme is presented, derived from simulated data. Thresholded QuikSCAT rain rates are compared to Tropical Rainfall Measuring Mission Microwave Imager monthly-averaged data, demonstrating good correlation for monthly-averaged data.","0196-2892;01962892","","10.1109/TGRS.2004.828194","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315825","Maximum likelihood;Microwave Imager;SeaWinds;TMI;TRMM;Tropical Rainfall Measuring Mission;scatterometer;simultaneous wind/rain retrieval","Backscatter;Geometry;Information retrieval;Microwave measurements;Oceans;Radar measurements;Rain;Scattering;Sea measurements;Wind speed","Monte Carlo methods;atmospheric techniques;hydrological techniques;meteorological radar;microwave measurement;rain;remote sensing by radar;wind","Cramer-Rao lower bound;Monte Carlo simulation;QuikSCAT;SeaWinds;Tropical Rainfall Measuring Mission Microwave Imager;integrated columnar rain rate;ocean winds;rain measurements;rain thresholding;scatterometer;simultaneous wind/rain retrieval;wind directions","","10","","20","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Personalizing semantic information networks","A. Mkadmi; E. Reyes; N. Bouhai","Lab. Paragraphe, Univ. Paris, Paris, France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","645","646","This article has the intention to present a general context situating the problem of Web semantic documents, to make them comprehensible both for computers and for humans. This has become possible thanks to the development of XML as standard language to structure and exchange data. XML allows us not only to separate structure and content in documents, but also to define more precise and pertinent meta-data. We also present a description of some possibilities for creating and recovering information spaces from the Web, commonly not well structured and not entirely exploited, to have them semantically usable with the system ""HyWebMap"".","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307930","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307930","","Coherence;Collaborative work;Databases;Educational institutions;Humans;Indexing;Information retrieval;Navigation;Space technology;XML","electronic data interchange;information retrieval;meta data;semantic Web;semantic networks","HyWebMap system;Web semantic documents;XML databases;XML schemas;information space;meta-data;semantic information networks;structured documents","","0","","","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Probabilistic space-time video modeling via piecewise GMM","H. Greenspan; J. Goldberger; A. Mayer","Dept. of Biomed. Eng., Tel Aviv Univ., Israel","IEEE Transactions on Pattern Analysis and Machine Intelligence","20040628","2004","26","3","384","396","In this paper, we describe a statistical video representation and modeling scheme. Video representation schemes are needed to segment a video stream into meaningful video-objects, useful for later indexing and retrieval applications. In the proposed methodology, unsupervised clustering via Gaussian mixture modeling extracts coherent space-time regions in feature space, and corresponding coherent segments (video-regions) in the video content. A key feature of the system is the analysis of video input as a single entity as opposed to a sequence of separate frames. Space and time are treated uniformly. The probabilistic space-time video representation scheme is extended to a piecewise GMM framework in which a succession of GMMs are extracted for the video sequence, instead of a single global model for the entire sequence. The piecewise GMM framework allows for the analysis of extended video sequences and the description of nonlinear, nonconvex motion patterns. The extracted space-time regions allow for the detection and recognition of video events. Results of segmenting video content into static versus dynamic video regions and video content editing are presented.","0162-8828;01628828","","10.1109/TPAMI.2004.1262334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1262334","","Data mining;Event detection;Image segmentation;Indexing;Information retrieval;Jacobian matrices;Pattern analysis;Streaming media;Video compression;Video sequences","feature extraction;image representation;image segmentation;object recognition;pattern clustering;probability;video signal processing","Gaussian mixture model;feature extraction;nonlinear nonconvex motion patterns;piecewise GMM;probabilistic space time video modeling;statistical video representation;unsupervised clustering;video content editing;video content segmentation","Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Normal Distribution;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;Video Recording","83","6","30","","","March 2004","","IEEE","IEEE Journals & Magazines"
"Learning distance functions for image retrieval","T. Hertz; A. Bar-Hillel; D. Weinshall","Sch. of Comput. Sci. & Eng., Hebrew Univ., Jerusalem, Israel","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-570","II-577 Vol.2","Image retrieval critically relies on the distance function used to compare a query image to images in the database. We suggest learning such distance functions by training binary classifiers with margins, where the classifiers are defined over the product space of pairs of images. The classifiers are trained to distinguish between pairs in which the images are from the same class and pairs, which contain images from different classes. The signed margin is used as a distance function. We explore several variants of this idea, based on using SVM and boosting algorithms as product space classifiers. Our main contribution is a distance learning method, which combines boosting hypotheses over the product space with a weak learner based on partitioning the original feature space. The weak learner used is a Gaussian mixture model computed using a constrained EM algorithm, where the constraints are equivalence constraints on pairs of data points. This approach allows us to incorporate unlabeled data into the training process. Using some benchmark databases from the UCI repository, we show that our margin based methods significantly outperform existing metric learning methods, which are based an learning a Mahalanobis distance. We then show comparative results of image retrieval in a distributed learning paradigm, using two databases: a large database of facial images (YaleB), and a database of natural images taken from a commercial CD. In both cases our GMM based boosting method outperforms all other methods, and its generalization to unseen classes is superior.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315215","","Boosting;Computer aided instruction;Distributed databases;Image databases;Image retrieval;Information retrieval;Partitioning algorithms;Spatial databases;Support vector machine classification;Support vector machines","Gaussian processes;content-based retrieval;image representation;image retrieval;support vector machines;visual databases","Gaussian mixture model;SVM;boosting algorithms;distance function;facial images;image retrieval;metric learning methods;natural images;query image","","43","","19","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"An object zooming model for the semantic Web","T. A. Ta; J. M. Saglio","CNRS, Paris, France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","625","626","As an infrastructure of the semantic Web, a resource description framework, RDF in short, has been recommended for describing metadata on the Web. This work presents a model, which would be helpful when users look for Web resources related to a single class of objects with multiple dimensional attributes. It helps them to figure out the statistical distribution of these objects in a pan-and-zoom approach in a rather smart form in comparison with the first step of a search through a directory of topics. The similarities and differences with related works on object zooming are revised. Ultimately an analogy is made with information retrieval in texts with hierarchical summaries.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307920","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307920","","Information retrieval;Lenses;Ontologies;Resource description framework;Search engines;Semantic Web;Solar system;Statistical distributions;Sun;Visualization","meta data;query formulation;query languages;search engines;semantic Web;statistical distributions","information retrieval;metadata;pan-and-zoom approach;query formulation;query language;resource description framework;semantic Web;topic related search","","0","","5","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Improving CBIR systems by integrating semantic features","D. Brahmi; D. Ziou","Universite de Sherbrooke","First Canadian Conference on Computer and Robot Vision, 2004. Proceedings.","20040607","2004","","","233","240","Nowadays, access to information requires to manage effectively multimedia databases, and among challenges offered to scientific community since last decades, multimedia retrieval techniques (particularly images retrieval) are became an active research direction. Introduced to overcome the main drawbacks encountered by text-based images retrieval, which are the subjective and manual annotation of images, content based images retrieval (CBIR) systems index images according to low-level visual features such as color, texture, shape to retrieve similar images. However, despite the progress achieved in the content based image retrieval, in particular with the relevance feedback approach where the user refine the search via the specification of relevant or not relevant items, the current CBIR systems still have a major difficulty that it has yet to overcome: how to negotiate the ""semantic gap""? This problem comes from the mismatch between their capabilities and the needs of users. In this paper, we address the problem of how relate lowlevel features to high level to bring out semantic concepts from images. Our aim is to combine contentbased and metadata-based approaches for image retrieval from a user perspective to yield better results and overcome to the lacks of these techniques when they are taken separately. To represent the semantic content of images, we propose a model which takes account of the interaction between the user and the metadata. In particular, we model the semantic user' preference by analyzing its answers through the Relevance Feedback process. Furthermore, we introduce a new machine learning technique that modify the weights (i.e. relative importance) of metadata representing the semantic content of images.","","POD:0-7695-2127-4","10.1109/CCCRV.2004.1301449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1301449","","Computer vision;Content based retrieval;Feedback;Image retrieval;Information management;Information retrieval;Multimedia databases;Multimedia systems;Quality management;Shape","","","","3","","18","","","17-19 May 2004","","IEEE","IEEE Conference Publications"
"Content-based medical image retrieval (CBMIR): an intelligent retrieval system for handling multiple organs of interest","P. M. Willy; K. H. Kufer","Fraunhofer ITWM, Kaiserslautern, Germany","Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems","20040719","2004","","","103","108","A medical image usually contains images of several organs, with each organ being unique. It is a prerequisite for a physician to attentively examine more than one organ, so-called organs of interest. In this paper, we present an experimental design of an intelligent content-based medical image retrieval (CBMIR) for handling multiple organs of interest through three main processes. First, CBMIR identifies all such organs by comparing the images directly using the Hausdorff distance to the single, healthy organs stored in an organ database. After that, CBMIR builds image classes using neural networks and, finally, recognizes the proper class for a query image using a multicriteria optimization approach.","1063-7125;10637125","POD:0-7695-2104-5","10.1109/CBMS.2004.1311699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311699","","Biomedical imaging;Content based retrieval;Design for experiments;Image databases;Image recognition;Image retrieval;Information retrieval;Intelligent systems;Neural networks;Shape","content-based retrieval;deductive databases;image classification;image retrieval;medical image processing;neural nets;optimisation","CBMIR;Hausdorff distance;content-based medical image retrieval;image classes;intelligent retrieval system;multicriteria optimization;multiple organs of interest;neural networks;organ database;proper class recognition;query image","","4","3","10","","","24-25 June 2004","","IEEE","IEEE Conference Publications"
"Searching for concepts in the Internet using FIS-CRM","P. J. Garces; J. A. Olivas; F. P. Romero","Dept. of Comput. Sci., Univ. of Castilla-La Mancha, Ciudad Real, Spain","IEEE International Conference on Industrial Informatics, 2003. INDIN 2003. Proceedings.","20040601","2003","","","402","407","This paper presents a search system in the Internet capable to achieve the conceptual matching between the concepts contained in a Web page and the implicit concepts in the user's query, that is, the proposed system is able to retrieve the Web pages that contain the concepts (not the words) specified in the query (called clustered organized conceptual queries in this paper). This system uses the FIS-CRM model (fuzzy interrelations and synonymy based concept representation model) that may be considered a fuzzy extension of the vector space model that is based on fuzzy interrelations between terms (fuzzy synonymy and fuzzy generality at the moment). This model has been also implemented in the FISS metasearcher where it was used to extract the concepts contained in the snippets retrieved by the search engine (Google) making possible to cluster the results of the query into groups of conceptually related Web pages.","","POD:0-7803-8200-5","10.1109/INDIN.2003.1300368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300368","","Computer science;Electronic mail;Fuzzy logic;Fuzzy systems;Information retrieval;Internet;Ontologies;Production facilities;Search engines;Web pages","Internet;fuzzy logic;knowledge representation;query formulation;search engines","Google search engine;Internet searching;Web page;clustered organized conceptual queries;fuzzy interrelations and synonymy based concept representation model;fuzzy logic;metasearcher","","0","","20","","","21-24 Aug. 2003","","IEEE","IEEE Conference Publications"
"Construction of a biomolecular structural information database using object-oriented database management system","M. Inata; A. Makinouchi","Dept. of Syst. Life Sci., Kyushu Univ., Japan","IEEE EMBS Asian-Pacific Conference on Biomedical Engineering, 2003.","20040607","2003","","","84","85","We constructed a biomolecular structural information database using object-oriented database management system (ODBMS). In this paper, evaluation of the constructed DB and an application of data mining method using the DB are shown.","","POD:0-7803-7943-8","10.1109/APBME.2003.1302595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302595","","Amino acids;Database systems;Filling;Frequency;Information retrieval;Object oriented databases;Spatial databases;X-ray diffraction","data mining;medical computing;molecular biophysics;object-oriented databases","biomolecular structural information database;data mining;object-oriented database management system","","0","","3","","","20-22 Oct. 2003","","IEEE","IEEE Conference Publications"
"Exploiting multiple paths to express scientific queries","Z. Lacroix; T. Moths; K. Parekh; L. Raschid; M. E. Vidal","Arizona State Univ., Tuczon, AZ, USA","Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.","20040719","2004","","","357","360","The purpose of this demonstration is to present the main features of the BioNavigation system. Scientific data collection needed in various stages of scientific discovery is typically performed manually. For each scientific object of interest (e.g., a gene, a sequence), scientists query a succession of Web resources following links between retrieved entries. Each of the steps provides part of the intended characterization of the scientific object. This process is sometimes partially supported by hard-coded scripts or complex queries that will be evaluated by a mediation-based data integration system or against a data warehouse. These approaches fail in guiding the scientists during the collection process. In contrast, the BioNavigation approach presented in the paper provides the scientists with information on the available alternative resources, their provenance, and the costs of data collection. The BioNavigation system enhances a mediation-based integration system and provides scientists with support for the following: to ask queries at a high conceptual level; to visualize the multiple alternative resources that may be exploited to execute their data collection queries; to choose the final execution path to evaluate their queries.","1099-3371;10993371","POD:0-7695-2146-0","10.1109/SSDM.2004.1311231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311231","","Access protocols;Costs;Data analysis;Data visualization;Data warehouses;Databases;Diseases;Information resources;Information retrieval;Sequences","biology computing;data handling;distributed databases;information resources;query processing;scientific information systems","BioNavigation system;Web resources;complex queries;data warehouse;hard-coded scripts;mediation-based data integration system;multiple paths;query evaluation;scientific data collection;scientific discovery;scientific information;scientific object of interest;scientific queries","","4","","12","","","21-23 June 2004","","IEEE","IEEE Conference Publications"
"Design and performance analysis of a dynamic hybrid scheduling algorithm for heterogeneous asymmetric environments","Navrati Saxena; Kalyan Basu; S. K. Das","Dept. of Informatics & Telecom., Trento Univ., Italy","18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.","20040607","2004","","","223","","Summary form only given. A hybrid scheduling is introduced that effectively combines broadcasting of more popular data (push data) and dissemination upon-request for less popular data (pull data), for asymmetric environments where the clients outnumber the servers having higher downlink communication (server to client) bandwidth than the uplink communication (client to server) bandwidth. We do not assume prior knowledge of the data access probability; in fact data access probabilities and thereby the cut-off-point to separate the push and the pull set are computed dynamically. In our scheme all the data items are assumed to be of variable length arranged in descending order of their access probabilities. The clients send their requests to the server, which queues them up for the pull items. At any instant of time, the item to be broadcast is designated applying a pure-push scheduling; whereas the item to be pulled is the one stored in the pull-queue, which has accumulated, so far, the highest number of pending requests with minimum service time requirement. The expected waiting time spent by a client in the hybrid schedule is evaluated analytically, and the cut-off point between push and pull items is chosen to minimize waiting time.","","POD:0-7695-2132-0","10.1109/IPDPS.2004.1303262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303262","","Algorithm design and analysis;Bandwidth;Broadcasting;Delay effects;Downlink;Informatics;Information retrieval;Performance analysis;Scheduling algorithm;Telecommunications","client-server systems;dynamic scheduling;performance evaluation;probability;queueing theory","client-server system;data access probability;dynamic hybrid scheduling algorithm;heterogeneous asymmetric environments;performance analysis;pure-push scheduling","","6","","16","","","26-30 April 2004","","IEEE","IEEE Conference Publications"
"Building personal digital photograph libraries: an approach with ontology-based MPEG-7 Dozen Dimensional Digital Content architecture","P. J. Kuo; T. Aoki; H. Yasuda","Yasuda-Aoki Lab., Tokyo Univ., Japan","Proceedings Computer Graphics International, 2004.","20040706","2004","","","482","489","The current trend of image retrieval is to incorporate the image visual features used in content based image retrieval (CBIR) and semantics annotations used in metadata based image retrieval to enhance retrieval performance. Because of the pervasive of consumer imaging devices, building personal digital photograph libraries became an increasingly interested domain. Personal digital photograph collections have specific characteristics compare to general purpose image databases. Hence, annotation architecture specially designed for that plays an important role in building an interoperable data repository for future indexing, browsing and retrieving purposes. We propose a MPEG-7 based multimedia content description architecture, Dozen Dimensional Digital Content (DDDC), which annotates multimedia data with twelve main attributes regarding its semantic representation. In addition, we also proposed a machine-understandable ""spatial and temporal based ontology"" representation for the above DDDC semantics description to enable semiautomatic annotation process","1530-1052;15301052","POD:0-7695-2171-1","10.1109/CGI.2004.1309251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1309251","","Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;MPEG 7 Standard;Multimedia databases;Software libraries","content management;content-based retrieval;digital libraries;digital photography;image coding;information retrieval;meta data;multimedia computing;ontologies (artificial intelligence);semantic Web;visual databases","DDDC semantics description;Dozen Dimensional Digital Content architecture;annotation architecture;content based image retrieval;data browsing;data indexing;data retrieving;image databases;image visual features;interoperable data repository;machine-understandable spatial ontology representation;machine-understandable temporal based ontology representation;metadata based image retrieval;multimedia data annotation;ontology-based MPEG-7 multimedia content architecture;personal digital photograph libraries;semantic representation;semantics annotations;semiautomatic annotation process","","5","2","32","","","19-19 June 2004","","IEEE","IEEE Conference Publications"
"Content-based image retrieval using approximate shape of objects","A. J. M. Traina; A. G. R. Balan; L. M. Bortolotti; C. Traina","Comput. Sci. Dept., Sao Paulo Univ., Sao Carlos, Brazil","Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems","20040719","2004","","","91","96","This paper presents a new approach to retrieve images by content using a composition of relevant features regarding texture, shape and brightness distribution. The first step of the method is a segmentation process based on Markov random fields, which can be done automatically, having as parameter the number of desired classes. The regions obtained in the segmentation guide the extraction of measures from the original image producing a 30-dimensional feature vector used in the image retrieval. The experiments showed that the feature vector has high discrimination power and the time for retrieval operations are only fractions of seconds.","1063-7125;10637125","POD:0-7695-2104-5","10.1109/CBMS.2004.1311697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311697","","Biomedical imaging;Brightness;Content based retrieval;Feature extraction;Histograms;Hospitals;Image retrieval;Image segmentation;Information retrieval;Shape","PACS;content-based retrieval;feature extraction;image colour analysis;image segmentation;image texture;medical image processing","30-dimensional feature vector;Markov random fields;approximate object shape;brightness distribution;content-based image retrieval;extraction;image shape;image texture;segmentation process","","7","","11","","","24-25 June 2004","","IEEE","IEEE Conference Publications"
"Online handwritten script recognition","A. M. Namboodiri; A. K. Jain","Dept. of Comput. Sci., Michigan State Univ., East Lansing, MI, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20040614","2004","26","1","124","130","Automatic identification of handwritten script facilitates many important applications such as automatic transcription of multilingual documents and search for documents on the Web containing a particular script. The increase in usage of handheld devices which accept handwritten input has created a growing demand for algorithms that can efficiently analyze and retrieve handwritten data. This paper proposes a method to classify words and lines in an online handwritten document into one of the six major scripts: Arabic, Cyrillic, Devnagari, Han, Hebrew, or Roman. The classification is based on 11 different spatial and temporal features extracted from the strokes of the words. The proposed system attains an overall classification accuracy of 87.1 percent at the word level with 5-fold cross validation on a data set containing 13,379 words. The classification accuracy improves to 95 percent as the number of words in the test sample is increased to five, and to 95.5 percent for complete text lines consisting of an average of seven words.","0162-8828;01628828","","10.1109/TPAMI.2004.1261096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261096","","Algorithm design and analysis;Data mining;Feature extraction;Handheld computers;Handwriting recognition;Information retrieval;Natural languages;Personal digital assistants;Text recognition;Writing","document image processing;feature extraction;handwriting recognition;online operation","Arabic script;Cyrillic script;Devnagari script;Han script;Hebrew script;Roman script;automatic identification;automatic transcription;feature extraction;handheld devices;handwritten data analysis;handwritten data retrieval;multilingual documents;online handwritten script recognition","Algorithms;Artificial Intelligence;Automatic Data Processing;Computer Graphics;Computer Simulation;Handwriting;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;User-Computer Interface","38","2","24","","","Jan. 2004","","IEEE","IEEE Journals & Magazines"
"Web services for information extraction from the Web","B. Habegger; M. Quafafou","Lab. d'Informatique de Nantes Atlantique, Nantes Univ., France","Proceedings. IEEE International Conference on Web Services, 2004.","20040719","2004","","","279","286","Extracting information from the Web is a complex task with different components which can either be generic or specific to the task, going from downloading a given page, following links, querying a Web-based applications via an HTML form and the HTTP protocol, querying a Web service via the SOAP protocol, etc. Therefore building Web services which proceed to executing an information tasks can not be simply hard coded (i.e. written and compiled once and for all in a given programming language). In order to be able to build flexible information extraction Web Services we need to be able to compose different sub tasks together. We propose a, XML-based language to describe information extraction Web services as the compositions of existing Web services and specific functions. The usefulness the proposed framework is demonstrated by three real world applications. (1) Search engines: we show how to describe a task which queries Google's Web service, retrieves more information on the results by querying their respective HTTP servers, and filters them according to this information. (2) E-commerce sites : an information extraction Web service giving access to an existing HTML-based e-commerce online application such as Amazon is built. (3) Patent extraction: a last example shows how to describe an information extraction Web service which allows to query a Web-based application, extract the set of result links, follow them, and extract the needed information on the result pages. In all three applications the generated description can be easily modified and completed to further respond the user's needs and create value-added Web services.","","POD:0-7695-2167-3","10.1109/ICWS.2004.1314749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314749","","Computer languages;Data mining;HTML;Information filtering;Information filters;Information retrieval;Search engines;Simple object access protocol;Web server;Web services","Web sites;XML;electronic commerce;information filters;information retrieval;knowledge acquisition;search engines","Amazon;Google Web service;HTML;HTML-based e-commerce online application;HTTP protocol;HTTP servers;SOAP protocol;Web information extraction;Web links;Web page downloading;Web service querying;Web-based applications;XML-based language;e-commerce sites;information filtering;information retrieval;patent extraction;search engines;value-added Web services","","1","3","8","","","6-9 July 2004","","IEEE","IEEE Conference Publications"
"Intelligent shape feature extraction and indexing for efficient content-based medical image retrieval","P. A. Mlsna; N. M. Sirakov","Dept. of Electr. Eng., Northern Arizona Univ., Flagstaff, AZ, USA","6th IEEE Southwest Symposium on Image Analysis and Interpretation, 2004.","20040601","2004","","","172","176","We describe the development of novel and efficient approaches and algorithms for a medical image content-based retrieval system capable of extracting and indexing key information about region shape. First, the general structure and the main components of the system are discussed. For grayscale segmentation to locate regions, we have explored a fast active contour approach based on the geometric heat differential equation. Region representation involves a set of extracted shape-based features. A technique for feature organization using N-dimensional feature vectors is employed. The image retrieval process compares similarity of query vectors to the indexed feature vectors. A convex hull model using the heat differential equation is used to organize the index of features to reduce the search space. Some experiments have been performed to test and validate certain portions of our approach. Finally; advantages and disadvantages together with the computational complexity of this system are discussed.","","POD:0-7803-8387-7","10.1109/IAI.2004.1300968","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300968","","Biomedical imaging;Content based retrieval;Data mining;Differential equations;Feature extraction;Image retrieval;Indexing;Information retrieval;Shape;Space heating","computational complexity;content-based retrieval;differential equations;feature extraction;image classification;image representation;image retrieval;image segmentation;medical image processing;vectors","active contour;computational complexity;content-based retrieval;convex hull model;feature organization;feature vectors;geometric heat differential equation;grayscale segmentation;intelligent shape feature extraction;medical image retrieval;shape indexing","","4","1","15","","","28-30 March 2004","","IEEE","IEEE Conference Publications"
"The determination of cloud altitudes using SCIAMACHY onboard ENVISAT","A. A. Kokhanovsky; V. V. Rozanov; W. von Hoyningen-Huene; H. Bovensmann; J. P. Burrows; H. K. Baltink","Inst. of Environ. Phys., Univ. of Bremen, Germany","IEEE Geoscience and Remote Sensing Letters","20040719","2004","1","3","211","214","This letter shows first results for the application of a recently developed semianalytical cloud retrieval algorithm for the determination of cloud top heights from space. The technique is based on the measurements of the top-of-atmosphere reflectance in the oxygen A-band. The depth of the band depends on the cloud top height and its geometrical thickness. The data obtained are compared to ground-based measurements of the cloud top height using a cloud-profiling radar.","1545-598X;1545598X","","10.1109/LGRS.2004.830123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315634","Clouds;ENVISAT;Environmental Satellite;radiative transfer;remote sensing","Absorption;Atmospheric measurements;Clouds;Information retrieval;Instruments;Physics;Pollution measurement;Reflectivity;Satellites;Spatial resolution","atmospheric techniques;clouds;height measurement;remote sensing","SCIAMACHY onboard ENVISAT;cloud altitudes determination;cloud top height;geometrical thickness;onboard measurement;oxygen A-band;semianalytical cloud retrieval algorithm;space;top-of-atmosphere reflectance","","6","","14","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Swarms on continuous data","V. Ramos; A. Abraham","CVRM, Tech. Univ. Lisbon, Portugal","Evolutionary Computation, 2003. CEC '03. The 2003 Congress on","20040524","2003","2","","1370","1375 Vol.2","While being it extremely important, many exploratory data analysis (EDA [J. Tukey (1977)]) systems have the inability to perform classification and visualization in a continuous basis or to self-organize new data-items into the older ones (even more into new labels if necessary), which can be crucial in KDD - knowledge discovery [U.M. Fayyad et al., (1996), (1992)], retrieval and data mining systems [S. Mitra et al., (2002), U.M. Fayyad et al., (1996)] (interactive and online forms of Web Applications are just one example). This disadvantage is also present in more recent approaches using self-organizing maps [R. Brits et al., (2001), H.P. Siemon et al., (1990)]. On the present work, and exploiting past successes in recently proposed stigmergic ant systems [V. Ramos et al., (2002)] a robust online classifier is presented, which produces class decisions on a continuous stream data, allowing for continuous mappings. Results show that increasingly better results are achieved, as demonstrated by other authors in different areas [V. Ramos et al., (1999), A. Lumini et al., (1997)].","","POD:0-7803-7804-0","10.1109/CEC.2003.1299828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1299828","","Chemicals;Cleaning;Data analysis;Data mining;Data visualization;Electronic design automation and methodology;Humans;Information retrieval;Insects;Robustness","data analysis;data mining;evolutionary computation;pattern classification;self-organising feature maps","KDD;continuous stream data;data mining systems;exploratory data analysis;knowledge discovery;self-organizing maps;stigmergic ant systems","","3","","22","","","8-12 Dec. 2003","","IEEE","IEEE Conference Publications"
"Efficient video retrieval system using virtual 3D space","S. Shiitani; T. Baba; S. Endo; Y. Uehara; D. Masumoto; S. Nagata","INFORMATION TECHNOLOGY MEDIA LAB, FUJITSU LABORATORIES LTD, Japan","6th IEEE Southwest Symposium on Image Analysis and Interpretation, 2004.","20040601","2004","","","206","210","We propose a technique for efficient retrieval of video scenes in a large number of digital videos. With the technique, cut frame images are automatically detected from videos, and arranged based on a visual feature in a virtual 3D space so that users can easily catch out the target image. We conducted experiments to confirm the effectiveness of the technique. The results show that retrieval by our technique is about 20 times as fast as retrieval by the fast forward playing mode at three times the normal speed.","","POD:0-7803-8387-7","10.1109/IAI.2004.1300975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300975","","Cameras;Content based retrieval;Histograms;Image retrieval;Information retrieval;Layout;Motion pictures;Multimedia systems;Space technology;TV","image retrieval;video signal processing","cut frame images;digital videos;video retrieval system;video scene retrieval;virtual 3D space;visual feature","","0","","5","","","28-30 March 2004","","IEEE","IEEE Conference Publications"
"Guest Editors' Introduction: Web Engineering--The Evolution of New Technologies","A. I. Vakali; G. I. Papadimitriou","Aristotle University","Computing in Science & Engineering","20040621","2004","6","4","10","11","The Web is now the most popular environment for circulating information as network-accessible data; the exponential growth in this informations dissemination is contributing to the evolution of research topics in the field of Web engineering. This issue of CiSE magazine focuses on understanding and emphasizing engineering topics as theyre applied in todays Web environment and infrastructure.","1521-9615;15219615","","10.1109/MCSE.2004.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1306939","65;Web engineering;XML;search","Data engineering;Information retrieval;Intelligent agent;Network topology;Peer to peer computing;Prefetching;Relational databases;Service oriented architecture;Web mining;XML","","Web engineering;XML;search","","1","","7","","","July-Aug. 2004","","IEEE","IEEE Journals & Magazines"
"Requirements validation by lifting retrenchments in B","M. Poppleton; R. Banach","Sch. of Electron. & Comput. Sci., Southampton Univ., UK","Proceedings. Ninth IEEE International Conference on Engineering of Complex Computer Systems","20040712","2004","","","87","96","Simple retrenchment is briefly reviewed in the B specification language of J.-R. Abrial (1996) as a liberalization of classical refinement, for the formal description of application developments too demanding for refinement. The looser relationships allowed by retrenchment between adjacent models in the development process may capture some of the requirements information of the development. This can make requirements validation more difficult to understand since the locus of requirements should be the models, and not their interrelationships, as far as possible. Hence the universal construction by Banach (2000), originally proposed for simple transition systems, is reformulated in B, in order to ""lift"" a given retrenchment conceptually, thus retracting such requirements information back to the level of abstraction of the abstract, ideal model. Examples demonstrate the cognitive value of retracting requirements to the abstract level, articulated in a well-understood formal language. This is also seen to yield a more understandable way of comparing alternative retrenchment designs. Some new B syntax in the pre- and postcondition style is presented to facilitate expression of the lifted requirements.","1050-4729;10504729","POD:0-7695-2109-6","10.1109/ICECCS.2004.1310907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310907","","Application software;Computer science;Concrete;Control engineering;Formal languages;Information retrieval;Mathematical model;Mathematics;Robustness;Specification languages","formal languages;formal specification;specification languages","B specification language;abstraction level;formal description;formal language;refinement;requirements information;requirements retraction;requirements validation;retrenchment lifting;transition systems","","1","","21","","","14-16 April 2004","","IEEE","IEEE Conference Publications"
"All-nearest-neighbors queries in spatial databases","Jun Zhang; N. Mamoulis; D. Papadias; Yufei Tao","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.","20040719","2004","","","297","306","Given two sets A and B of multidimensional objects, the all-nearest-neighbors (ANN) query retrieves for each object in A its nearest neighbor in B. Although this operation is common in several applications, it has not received much attention in the database literature. In this paper we study alternative methods for processing ANN queries depending on whether A and B are indexed: Our algorithms are evaluated through extensive experimentation using synthetic and real datasets. The performance studies show that they are an order of magnitude faster than a previous approach based on closest-pairs query processing.","1099-3371;10993371","POD:0-7695-2146-0","10.1109/SSDM.2004.1311221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311221","","Application software;Computational geometry;Computer science;Data engineering;Information retrieval;Information systems;Multidimensional systems;Nearest neighbor searches;Query processing;Spatial databases","database indexing;query processing;visual databases","ANN query processing;all-nearest-neighbors queries;closest-pairs query processing;database indexing;multidimensional objects;spatial databases","","12","","27","","","21-23 June 2004","","IEEE","IEEE Conference Publications"
"Digital campus project: a ""dream university"" over the Internet Web","R. Nishide; S. Ueshima","Graduate Sch. of Informatics, Kansai Univ., Japan","Proceedings. Second International Conference on Creating, Connecting and Collaborating through Computing, 2004.","20040719","2004","","","122","129","This work presents the lifestyle of a ""dream university"" of the future, digitalized out of a real university campus. This ""dream university"" is actually a multipurpose digital campus facilitating for a better e-learning environment as the core of the research. It is an elaborate digital campus created with virtual collaborative environment in 3D system in the virtual world where users can learn and experience the campus life of the university while collaborating with other users involved. We propose all the available features that the digital campus can provide and discuss the points that have been proven to be advantageous for the users. Our goal is to create a dream university on the Web so that anybody can participate anytime, anywhere, depending upon his/her needs, removing all the barriers and solving problems involved in the real university.","","POD:0-7695-2166-5","10.1109/C5.2004.1314379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314379","","Collaborative work;Content based retrieval;Data visualization;Electronic learning;Informatics;Information retrieval;Internet;Memory;Online Communities/Technical Collaboration;Space technology","Internet;computer aided instruction;groupware;virtual reality","3D system;Internet Web;digital campus;dream university;e-learning;virtual collaborative environment","","4","","30","","","29-30 Jan. 2004","","IEEE","IEEE Conference Publications"
"Content integration from Web and broadcast information sources","K. Tanaka","Graduate Sch. of Informatics, Kyoto Univ., Japan","International Conference on Informatics Research for Development of Knowledge Society Infrastructure, 2004. ICKS 2004.","20040719","2004","","","99","106","It becomes possible to acquire information from diverse information sources of different media types. For instance, with the spreading of digital TV broadcasting and broadband Internet, it becomes possible for users to acquire more media-rich and more comprehensive contents by integrating Web contents and TV-program contents. Integration or fusion of contents from these multiple information sources requires more effective ways of comparing, complementing and composing those diverse information. A notable difference between Web contents and TV program contents is a way of viewing information. Conventional Web browsing is basically based on active viewing of information. That is, users are required to behave actively in order to access information. On the other hand, conventional TV broadcasting offers a passive way of viewing information. In order to integrate of Web contents and TV broadcast contents, not only contents themselves but also the difference of the viewing methods should be considered. This paper summarizes our research activities that aim at exploring technologies for ""content integration from Web and broadcast information sources"". Our research results are summarized into the following: content transformation between Web and TV broadcasting contents (Web2TV, TV2Web), content synchronization among Web contents and TV broadcasting contents (CWB, WebTelop).","","POD:0-7695-2150-9","10.1109/ICKS.2004.1313414","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1313414","","Broadcast technology;Digital TV;Informatics;Information retrieval;Internet;Speech synthesis;TV broadcasting;Visual databases;Web pages;World Wide Web","Internet;content management;digital video broadcasting;online front-ends","TV-program content integration;Web browsing;Web content integration;broadband Internet;broadcast information sources;content synchronization;digital TV broadcasting;diverse information sources","","1","","15","","","1-2 March 2004","","IEEE","IEEE Conference Publications"
"A generic embedded device for retrieving and transmitting information of various customized applications","Fan-Tien Cheng; Guo-Wei Huang; Chun-Hung Chen; Min-Hsiung Hung","Inst. of Manuf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","Robotics and Automation, 2004. Proceedings. ICRA '04. 2004 IEEE International Conference on","20040706","2004","1","","978","983 Vol.1","A generic embedded device (GED) that can be installed to various kinds of information equipment, such as manufacturing equipment, portal servers, automatic guided vehicles, etc., is successfully developed In this work. GED is equipped with an embedded real-time operating system and several software modules to retrieve, collect, and manage equipment data. In particular, the communication management module of GED can transmit and receive data to/from remote clients via both wired and wireless networks. Moreover, GED has an object-oriented application interface that flexibly enables GED to add-in or update any customized application. Three typical communication mechanisms, namely the standard processes of exception notification, periodic inspection, and data inquiry are built in GED. As such, GED is able to handle a variety of customized applications, such as monitoring, detection, diagnostics, and prognostics of various kinds of information equipment. We believe that GED possesses the potentiality of information acquisition and transmission so that it can assist all kinds of information equipment to reach the goal of equipment-to-system (E2S) communication and facilitate the maintenance tasks.","1050-4729;10504729","POD:0-7803-8232-3","10.1109/ROBOT.2004.1307277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307277","","Application software;Embedded software;Information retrieval;Manufacturing automation;Operating systems;Portals;Real time systems;Software systems;Vehicles;Wireless networks","embedded systems;object-oriented methods;production engineering computing;software maintenance","customized applications;data inquiry;e-diagnostics;e-maintenance;embedded real-time operating system;equipment-to-system communication;exception notification;generic embedded device;information equipment;periodic inspection;software modules","","2","","24","","","26 April-1 May 2004","","IEEE","IEEE Conference Publications"
"Simultaneous wind and rain retrieval using SeaWinds data","D. W. Draper; D. G. Long","Microwave Earth Remote Sensing Lab., Brigham Young Univ., Provo, UT, USA","IEEE Transactions on Geoscience and Remote Sensing","20040719","2004","42","7","1411","1423","The SeaWinds scatterometers onboard the QuikSCAT and the Advanced Earth Observing Satellite 2 measure ocean winds on a global scale via the relationship between the normalized radar backscattering cross section of the ocean and the vector wind. The current wind retrieval method ignores scattering and attenuation of ocean rain, which alter backscatter measurements and corrupt retrieved winds. Using a simple rain backscatter and attenuation model, two methods of improving wind estimation in the presence of rain are evaluated. First, if no suitable prior knowledge of the rain rate is available, a maximum-likelihood estimation technique is used to simultaneously retrieve the wind velocity and rain rate. Second, when a suitable outside estimate of the rain rate is available, wind retrieval is performed by correcting the wind geophysical model function for the known rain via the rain backscatter model. The new retrieval techniques are evaluated via simulation and validation with data from the National Centers for Environmental Prediction and the Tropical Rainfall Measuring Mission Precipitation Radar. The simultaneous wind/rain estimation method yields most accurate winds in the ""sweet spot"" of SeaWinds' swath. On the outer-beam edges of the swath, simultaneous wind/rain estimation is not usable. Wind speeds from simultaneous wind/rain retrieval are nearly unbiased for all rain rates and wind speeds, while conventionally retrieved wind speeds become increasingly biased with rain rate. A synoptic example demonstrates that the new method is capable of reducing the rain-induced wind vector error while producing a consistent (yet noisy) estimate of the rain rate.","0196-2892;01962892","","10.1109/TGRS.2004.830169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315824","Maximum-likelihood;PR;Precipitation Radar;SeaWinds;TRMM;Tropical Rainfall Measuring Mission;scatterometer;simultaneous wind/rain retrieval","Backscatter;Geophysical measurements;Information retrieval;Oceans;Radar measurements;Radar scattering;Rain;Sea measurements;Spaceborne radar;Wind speed","atmospheric techniques;hydrological techniques;maximum likelihood estimation;meteorological radar;rain;remote sensing by radar;spaceborne radar;wind","ADEOS II;Advanced Earth Observing Satellite 2;QuikSCAT;SeaWinds scatterometers;Tropical Rainfall Measuring Mission;maximum-likelihood estimation;precipitation radar;radar attenuation;radar backscattering cross section;radar scattering;rain backscatter;rain rate;simultaneous wind/rain retrieval;wind estimation;wind vector;wind velocity","","49","","34","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Fractionally cascaded information in a sensor network","Jie Gao; L. J. Guibas; J. Hershberger; Li Zhang","Dept. of Comput. Sci., Stanford Univ., CA, USA","Third International Symposium on Information Processing in Sensor Networks, 2004. IPSN 2004","20040628","2004","","","311","319","We address the problem of distributed information aggregation and storage in a sensor network, where queries can be injected anywhere in the network. The principle we propose is that a sensor should know a ""fraction"" of the information from distant parts of the network, in an exponentially decaying fashion by distance. We show how a sampled scalar field can be stored in this distributed fashion, with only a modest amount of additional storage and network traffic. Our storage scheme makes neighboring sensors have highly correlated world views; this allows smooth information gradients and enables local search algorithms to work well. We study in particular how this principle of fractionally cascaded information can be exploited to answer range queries about the sampled field efficiently. Using local decisions only we are able to route the query to exactly the portions of the field where the sought information is stored. We provide a rigorous theoretical analysis showing that our scheme is close to optimal.","","POD:1-58113-846-6","10.1109/IPSN.2004.1307352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307352","","Algorithm design and analysis;Computer science;Distributed databases;Information analysis;Information retrieval;Information systems;Intelligent networks;Permission;Sensor phenomena and characterization;Telecommunication traffic","distributed databases;quadtrees;query processing;wireless sensor networks","exponentially decay;fractional cascading;information aggregation;information gradients;information storage;local decisions;local search algorithm;neighboring sensors;network traffic;query routing;querying;range queries;range searching;scalar field;sensor networks","","1","","","","","26-27 April 2004","","IEEE","IEEE Conference Publications"
"Minimum probability of error image retrieval","N. Vasconcelos","Dept. of Electr. & Comput. Eng., Univ. of California, La Jolla, CA, USA","IEEE Transactions on Signal Processing","20040719","2004","52","8","2322","2336","We address the design of optimal architectures for image retrieval from large databases. Minimum probability of error (MPE) is adopted as the optimality criterion and retrieval formulated as a problem of statistical classification. The probability of retrieval error is lower- and upper-bounded by functions of the Bayes and density estimation errors, and the impact of the components of the retrieval architecture (namely, the feature transformation and density estimation) on these bounds is characterized. This characterization suggests interpreting the search for the MPE feature set as the search for the minimum of the convex hull of a collection of curves of probability of error versus feature space dimension. A new algorithm for MPE feature design, based on a dictionary of empirical feature sets and the wrapper model for feature selection, is proposed. It is shown that, unlike traditional feature selection techniques, this algorithm scales to problems containing large numbers of classes. Experimental evaluation reveals that the MPE architecture is at least as good as popular empirical solutions on the narrow domains where these perform best but significantly outperforms them outside these domains.","1053-587X;1053587X","","10.1109/TSP.2004.831125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315950","Bayesian methods;color and texture;expectation–maximization;feature selection;image retrieval;image similarity;minimum probability of error;mixture models;multiresolution;optimal retrieval systems;wrapper methods","Content based retrieval;Error correction;Image databases;Image retrieval;Information retrieval;Multimedia databases;Probability;Signal generators;Spatial databases;Statistical learning","Bayes methods;error statistics;feature extraction;image classification;image colour analysis;image representation;image resolution;image retrieval;image texture;learning (artificial intelligence);visual databases","Bayesian methods;density estimation errors;expectation-maximization;feature extraction;feature selection techniques;image color;image multiresolution;image retrieval;image similarity;image texture;large databases;minimum error probability;statistical classification;wrapper model","","47","","67","","","Aug. 2004","","IEEE","IEEE Journals & Magazines"
"A study of data fusion in Cayley graphs G(s<sub>n</sub>,p<sub>n</sub>)","D. F. Hsu; A. Palumbo","Dept. of Comput. & Inf. Sci., Fordham Univ., New York, NY, USA","7th International Symposium on Parallel Architectures, Algorithms and Networks, 2004. Proceedings.","20040524","2004","","","557","562","In this paper, we examine a method for the fusion of ranked data in the context of a Cayley graph. We investigate this Cayley graph model for optimization of fusion by rank combination. We outline a method of data fusion by combination of weighted rankings. Information systems are represented as nodes in a Cayley graph. Our goal is to determine a metric of diversity and performance in this graph in order to build a model for optimizing fusion by rank combination. We use the Kendall distance between nodes in the Cayley graph of the symmetric group S<sub>n</sub> as a measure of performance. In doing so we demonstrate that in S<sub>6</sub> there is a quadratic relationship between the weights of the fusion of two information systems and the performance of the fusion in our abstract space. From such a relationship we propose a set of functions for extrapolating optimal fusion weights in the symmetric group S<sub>n</sub>.","1087-4089;10874089","POD:0-7695-2135-5","10.1109/ISPAN.2004.1300537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300537","","Character generation;Diversity reception;Information retrieval;Information science;Information systems;Solid modeling;Tin","graph theory;information retrieval systems;merging;optimisation;sensor fusion","Cayley graphs;Kendall distance;fusion optimization;information systems;rank combination;ranked data fusion","","4","","13","","","10-12 May 2004","","IEEE","IEEE Conference Publications"
"Effective data integration in the presence of temporal semantic conflicts","Hongwei Zhu; S. E. Madnick; M. D. Siegel","MIT Sloan Sch. of Manage., Cambridge, MA, USA","Proceedings. 11th International Symposium on Temporal Representation and Reasoning, 2004. TIME 2004.","20040719","2004","","","109","114","The change in meaning of data over time poses significant challenges for the use of that data. These challenges exist in the use of an individual data source and are further compounded with the integration of multiple sources. In this paper, we identify three types of temporal semantic heterogeneities. We propose a solution based on extensions to the context interchange framework, which has mechanisms for capturing semantics using ontology and temporal context. It also provides a mediation service that automatically resolves semantic conflicts. We show the feasibility of this approach with a prototype that implements a subset of the proposed extensions.","1550-1311;15501311","POD:0-7695-2155-X","10.1109/TIME.2004.1314427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314427","","Databases;Environmental management;Eyes;History;Information retrieval;Insurance;Mediation;Medical services;Ontologies;Prototypes","data mining;database theory;knowledge engineering;temporal databases","context interchange framework;data integration;data source;mediation service;ontology;temporal context;temporal semantic conflicts;temporal semantic heterogeneities","","0","","21","","","1-3 July 2004","","IEEE","IEEE Conference Publications"
"Location-mediated coordination of Web services in ubiquitous computing","A. Sashima; N. Izumi; K. Kurumatani","Cyber Assist Res. Center, AIST/CREST, Tokyo, Japan","Proceedings. IEEE International Conference on Web Services, 2004.","20040719","2004","","","822","823","A fundamental issue of human-centered coordinating services in ubiquitous computing is concerned with dynamic service coordination according to users' intentions. How can we coordinate the services to assist the user in receiving a coordinated service to maximize the user's satisfaction in an environment? In order to solve this issue, we have been developing a sort of agent-based coordination framework, called ""location-mediated agent coordination,"" that orchestrates Web services embedded in the real world and Web services on the Internet. In this paper, we show a prototype application of the framework, context-aware information assist services in a museum.","","POD:0-7695-2167-3","10.1109/ICWS.2004.1314959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314959","","Context-aware services;Home appliances;Information retrieval;Navigation;Pervasive computing;Physics computing;Prototypes;Ubiquitous computing;Web and internet services;Web services","Internet;humanities;mobile computing;software agents;user centred design","Internet;Web service coordination;Web service orchestration;agent-based coordination framework;context-aware information;dynamic service coordination;human-centered coordinating services;location-mediated agent coordination;museum;ubiquitous computing;user intentions;user satisfaction","","5","","7","","","6-9 July 2004","","IEEE","IEEE Conference Publications"
"Urdu computational lexicon","F. Ahmad","","International Multi Topic Conference, 2002. Abstracts. INMIC 2002.","20040712","2002","","","45","45","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/01310152.png"" border=""0"">","","POD:0-7803-7715-X","10.1109/INMIC.2002.1310152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310152","","Computational modeling;Information retrieval;Natural languages;Speech analysis;Speech processing","","","","0","","","","","27-28 Dec. 2002","","IEEE","IEEE Conference Publications"
"Impact of horizontal and vertical heterogeneities on retrievals using multiangle microwave brightness temperature data","E. J. Burke; W. J. Shuttleworth; P. R. Houser","Dept. of Hydrology & Water Resources, Univ. of Arizona, Tucson, AZ, USA","IEEE Transactions on Geoscience and Remote Sensing","20040719","2004","42","7","1495","1501","This paper investigates the impact of heterogeneity at the land surface on geophysical parameters retrieved from multiangle microwave brightness temperature data, such as would be obtained from the Soil Moisture and Ocean Salinity (SMOS) mission. Synthetic brightness temperature data were created using the Common Land (land surface) Model, coupled with a microwave emission model and set within the framework of the North American Land Data Assimilation System (NLDAS). Soil moisture, vegetation optical depth, and effective physical temperature were retrieved using a multiobjective calibration routine similar to the proposed SMOS retrieval algorithm for a typical on-axis range of look angles. The impact of heterogeneity both in the near-surface profiles of soil moisture and temperature and in the land cover on the accuracy of the retrievals was examined. There are significant errors in the retrieved parameters over regions with steep gradients in the near-surface soil moisture profile. These errors are approximately proportional to the difference in the soil water content between the top (at 0.7 cm) and second layer (at 2.7 cm) of the land surface model. The errors resulting from heterogeneity in the land cover are smaller and increase nonlinearly with increasing land-surface heterogeneity (represented by the standard deviation of the optical depth within the pixel). The most likely use of retrieved soil moisture is through assimilation into an LDAS for improved initiation of weather and climate models. Given that information on the soil moisture profile is already available within the LDAS, the error in the retrieved soil moisture as a result of the near-surface profile can be corrected for. The potential errors as a result of land-surface heterogeneity can also be assessed for use in the assimilation process.","0196-2892;01962892","","10.1109/TGRS.2004.828922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315833","Land surface;passive microwave;remote sensing;retrieval;soil moisture","Brightness temperature;Data assimilation;Information retrieval;Land surface;Land surface temperature;Linear discriminant analysis;Ocean temperature;SMOS mission;Sea surface;Soil moisture","hydrological techniques;microwave measurement;remote sensing;soil","North American Land Data Assimilation System;Soil Moisture and Ocean Salinity mission;climate models;effective physical temperature;land surface heterogeneity;microwave emission model;multiangle microwave brightness temperature;multiobjective calibration routine;passive microwave;remote sensing;soil moisture;vegetation optical depth","","4","","27","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Authoring multimedia authoring tools","B. Adams; S. Venkatesh","Curtin Univ. of Technol., Perth, WA, Australia","IEEE MultiMedia","20040726","2004","11","3","1","6","If we are to create effective multimedia authoring tools, we must avail ourselves of the various disciplines that we normally throw in the ""someone-else's-problem"" basket. Discourse theory, domain distinctives such as media aesthetics, human-computer interface issues, and multimedia data description standards all have a part to play. However, none of these fields stands still, so we need to continually query them for new insights that might impact our multimedia authoring endeavor. This paper is all about authoring multimedia authoring tools.","1070-986X;1070986X","","10.1109/MMUL.2004.3","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316790","","Assembly;Bridges;Educational institutions;IEEE Press;Information retrieval;Motion pictures;Multimedia systems;Production;Surgery;Writing","authoring systems;multimedia systems","discourse theory;domain distinctives;human-computer interface;media aesthetics;multimedia authoring tools;multimedia data description standards","","2","","3","","","July-Sept. 2004","","IEEE","IEEE Journals & Magazines"
"Energy-efficient caching and prefetching with data consistency in mobile distributed systems","H. Shen; Mohan Kumar; S. K. Das; Z. Wang","Dept. of Comput. Sci. & Eng., Texas Univ., Arlington, TX, USA","18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.","20040607","2004","","","67","","Summary form only given. In mobile distributed systems, vital resources like battery power and wireless channel bandwidth impose significant challenges in ubiquitous information access. We propose a novel energy and bandwidth efficient data caching mechanism, called greedydual least utility (GD-LU), that enhances dynamic data availability while maintaining consistency. The proposed utility-based caching mechanism considers several characteristics of mobile distributed systems, such as connection-disconnection, mobility handoff, data update and user request patterns to achieve significant energy savings in mobile devices. Based on the utility function derived from an analytical model, we propose a cache replacement algorithm and a passive prefetching algorithm to cache and prefetch data objects. Our comprehensive simulation experiments demonstrate that the proposed mechanism achieves more than 10% energy saving and near-optimal performance tradeoff between access latency and energy consumption.","","POD:0-7695-2132-0","10.1109/IPDPS.2004.1302995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302995","","Analytical models;Bandwidth;Batteries;Delay;Energy consumption;Energy efficiency;Information retrieval;Mobile communication;Mobile computing;Prefetching","bandwidth allocation;cache storage;data integrity;mobile computing;telecommunication channels","analytical model;cache replacement algorithm;data caching mechanism;data consistency;energy consumption;greedydual least utility;mobile distributed systems;passive prefetching algorithm;wireless channel bandwidth","","11","2","23","","","26-30 April 2004","","IEEE","IEEE Conference Publications"
"A blind digital watermarking using index data bits sequences","A. A. Aburas","Dept. of Comput. Sci., Ittihad Univ., Ras Al Khaimah, United Arab Emirates","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","541","542","Digital watermarking is the unique solution that can be used for protecting all the digital multimedia data from any illegal use. In this work, we present a new method as blind watermarking to embed data into digital images, digital audio and scanned text. The method is based on the lower and the upper bit sequences. Each pixel in the digital media keeping the quality as it is. The new technique is very simple for embedding and extractions of the hidden data.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307871","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307871","","Application software;Conferences;Data mining;Digital images;Hardware;Information retrieval;Motion pictures;Multimedia systems;Protection;Watermarking","audio coding;data compression;data encapsulation;image coding;watermarking","blind digital watermarking;digital multimedia data;hidden data;index data bit sequences;lower bit;upper bit sequences","","1","","11","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Dependent data broadcasting for unordered queries in a multiple channel mobile environment","Jiun-Long Huang; Ming-Syan Chen","Dept. of Electr. Eng., Nat. Taiwan Univ., Taipei, Taiwan","IEEE Transactions on Knowledge and Data Engineering","20040726","2004","16","9","1143","1156","Data broadcast is a promising technique to improve the bandwidth utilization and conserve the power consumption in a mobile computing environment. In many applications, the data items broadcast are dependent upon one another. However, most prior studies on broadcasting dependent data are restricted to a single broadcast channel environment, and as a consequence, the results are of limited applicability to the upcoming mobile environments. In view of this, we relax this restriction and explore the problem of broadcasting dependent data in multiple broadcast channels. By analyzing the model of dependent data broadcasting, we derive several theoretical properties for the average access time in a multiple channel environment. In light of the theoretical results, we develop a genetic algorithm to generate broadcast programs. Our experimental results show that the theoretical results derived are able to guide the search of the genetic algorithm very effectively, thus leading to broadcast programs of very high quality.","1041-4347;10414347","","10.1109/TKDE.2004.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316840","65;Index Terms- Data broadcast;dependent data;mobile computing.;mobile information system;unordered query","Bandwidth;Broadcasting;Channel allocation;Energy consumption;Genetic algorithms;Information retrieval;Information systems;Mobile computing;Radio spectrum management;Scalability","bandwidth allocation;broadcast channels;genetic algorithms;mobile computing;multiuser channels;query processing","bandwidth utilization;broadcast channels;dependent data broadcasting;genetic algorithm;multiple channel mobile environment;power consumption;unordered queries","","43","","32","","","Sept. 2004","","IEEE","IEEE Journals & Magazines"
"Using MEDLINE as a knowledge source for disambiguating abbreviations in full-text biomedical journal articles","Hong Yu; Won Kim; V. Hatzivassiloglou; W. John Wilbur","Dept. of Comput. Sci., Columbia Univ., New York, NY, USA","Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems","20040719","2004","","","27","32","Biomedical abbreviations and acronyms are widely used in biomedical literature. Since many abbreviations represent important content in biomedical literature, information retrieval and extraction benefits from identifying the meanings of biomedical abbreviations. Since many abbreviations are ambiguous, it would be important to map abbreviations to their full forms, which ultimately represent the meanings of the abbreviations. In this study, we present a novel unsupervised method that applies MEDLINE records as a knowledge source for disambiguating abbreviations in full-text biomedical journal articles. We first automatically generated from MEDLINE records a knowledge source or dictionary of abbreviation-full pairs. We then trained on MEDLINE records and predicted the full forms of abbreviations in full-text journal articles by applying supervised machine-learning algorithms in an unsupervised fashion. We report up to 92% prediction precision and up to 91% coverage.","1063-7125;10637125","POD:0-7695-2104-5","10.1109/CBMS.2004.1311686","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311686","","Abstracts;Biomedical computing;Biotechnology;Computer science;Data mining;Dictionaries;Information retrieval;Learning systems;Pattern matching;Proteins","dictionaries;information retrieval;learning (artificial intelligence);medical computing;nomenclature;text analysis","MEDLINE;abbreviation disambiguation;dictionary;full-text biomedical journal articles;information extraction;information retrieval;knowledge source;prediction precision;supervised machine-learning algorithms","","0","","19","","","24-25 June 2004","","IEEE","IEEE Conference Publications"
"Universal Report: a generic reverse engineering tool","C. Tadonki","Dept. of Theor. Comput. Sci., Geneva Univ., Switzerland","Proceedings. 12th IEEE International Workshop on Program Comprehension, 2004.","20040712","2004","","","266","267","Source code documentation is a structured report built from the information available in the source of a given program. 'The goal of such a document is to provide more facility for program comprehension and code maintenance. This is particularly crucial for complex program involving a large amount of routines and special statements. Nowadays, there are more and more specialized programs that are provided to programmers through their source code as a module. Their integration into an existing project requires a quick but accurate overview of their technical structure for immediate comprehension. This task needs a so-called source code documentation tool, also called documentation tool, code documenting tool, or reverse engineering tool. Several tools exist, but most of them are dedicated to a specific programming language, probably because they strongly consider the grammar of the target language and the corresponding statements are then hardcoded. In this paper, we present Universal Report, a source code documentation tool developed with C++ Builder, that does not suffer from this limitation and provides several attractive features for a complete documenting task. The tool is generic, specific information being provided by the user as input for the documenting process. This flexibility is due to powerful heuristics and pattern matching algorithms that can identify standard programming statements for a wide range of programming languages. Various options enable the user to format the output documentation at its convenience, and the intuitive interface makes Universal Report the perfect tool for both new and experienced users.","1092-8138;10928138","POD:0-7695-2149-5","10.1109/WPC.2004.1311073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311073","","Computer languages;Computer science;Data mining;Displays;Documentation;Informatics;Information retrieval;Pattern matching;Programming profession;Reverse engineering","pattern matching;reverse engineering;software maintenance;software tools;system documentation","C++ Builder;Universal Report;code documenting tool;code maintenance;documentation tool;heuristics;pattern matching;program comprehension;reverse engineering tool;source code documentation","","0","","","","","24-26 June 2004","","IEEE","IEEE Conference Publications"
"Active wearable vision sensor: recognition of human activities and environments","K. Sumi; A. Sugimoto; T. Matsuyama; M. Toda; S. Tsukizawa","Dept. of Informatics, Kyoto Univ., Japan","International Conference on Informatics Research for Development of Knowledge Society Infrastructure, 2004. ICKS 2004.","20040719","2004","","","15","22","To realize a symbiotic relationship between humans and computers, it is crucial to estimate the external and internal state of the human by observation. One promising approach is to acquire the same visual information as the human acquires. We introduce our wearable vision sensor, which is equipped with a pair of active stereo cameras and a gaze-direction detector. From the visual information obtained by the wearable vision sensor, we present three basic three functionalities: 3D gaze point detection and image retrieval, 3D digitization of a hand-held object, and the measurement of a walking trajectory.","","POD:0-7695-2150-9","10.1109/ICKS.2004.1313404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1313404","","Cameras;Detectors;Humans;Image retrieval;Image sensors;Information retrieval;Object detection;State estimation;Symbiosis;Wearable sensors","feature extraction;image retrieval;image sensors;image texture;motion estimation;object detection;stereo image processing;tracking;video cameras","3D gaze point detection;3D hand-held object digitization;active stereo cameras;gaze-direction detector;image retrieval;trajectory measurement;wearable vision sensor","","3","","17","","","1-2 March 2004","","IEEE","IEEE Conference Publications"
"BoostMap: A method for efficient approximate similarity rankings","V. Athitsos; J. Alon; S. Sclaroff; G. Kollios","Dept. of Comput. Sci., Boston Univ., MA, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-268","II-275 Vol.2","This paper introduces BoostMap, a method that can significantly reduce retrieval time in image and video database systems that employ computationally expensive distance measures, metric or non-metric. Database and query objects are embedded into a Euclidean space, in which similarities can be rapidly measured using a weighted Manhattan distance. Embedding construction is formulated as a machine learning task, where AdaBoost is used to combine many simple, ID embeddings into a multidimensional embedding that preserves a significant amount of the proximity structure in the original space. Performance is evaluated in a hand pose estimation system, and a dynamic gesture recognition system, where the proposed method is used to retrieve approximate nearest neighbors under expensive image and video similarity measures: In both systems, in quantitative experiments, BoostMap significantly increases efficiency, with minimal losses in accuracy. Moreover, the experiments indicate that BoostMap compares favorably with existing embedding methods that have been employed in computer vision and database applications, i.e., FastMap and Bourgain embeddings.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315173","","Database systems;Extraterrestrial measurements;Image databases;Image retrieval;Information retrieval;Machine learning;Multidimensional systems;Performance loss;Time measurement;Weight measurement","computer vision;embedded systems;gesture recognition;learning (artificial intelligence);video databases","BoostMap;Euclidean space;approximate similarity rankings;dynamic gesture recognition system;hand pose estimation system;machine learning task;multidimensional embedding;video database systems;weighted Manhattan distance","","57","","24","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Geometry image matching for similarity estimation of 3D shapes","H. Laga; H. Takahashi; M. Nakajima","Graduate Sch. of Inf. Sci. & Eng., Tokyo Inst. of Technol., Japan","Proceedings Computer Graphics International, 2004.","20040706","2004","","","490","496","We describe our preliminary findings in applying the spherical parametrization and geometry images to the task of 3D shape matching and similarity based comparison of polygon soup models. Unlike traditional approach where multiple 2D views of the same object are required to capture the relevant geometry features, our proposed technique uses spherical parametrization and geometry images for 3D shape matching. This technique reduces the problem to the 2D space without computing 2D projections and guarantees the preservation of small details. Moreover, we take advantage from the hierarchical nature of the parametrization process, through the progressive mesh simplification, to derive a multiresolution analysis technique. Our proposed algorithm is invariant to similarity transformations such as rotation and scaling. The efficiency of this approach is discussed through a set of experiments","1530-1052;15301052","POD:0-7695-2171-1","10.1109/CGI.2004.1309252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1309252","","Geometry;Image databases;Image matching;Information retrieval;Layout;Search engines;Shape;Solid modeling;Spatial databases;Topology","computational geometry;image matching;image resolution;mesh generation;solid modelling","2D projections;3D shape matching;geometry image matching;multiple 2D views;multiresolution analysis;polygon soup models;progressive mesh simplification;similarity estimation;spherical parametrization","","6","","21","","","19-19 June 2004","","IEEE","IEEE Conference Publications"
"Image segmentation of uterine cervix images for indexing in PACS","S. Gordon; G. Zimmerman; H. Greenspan","Dept. of Biomedical Eng., Tel Aviv Univ., Israel","Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems","20040719","2004","","","298","","The National Cancer Institute has collected a large database of digitized 35 mm slides of the uterine cervix, the idea being to build a system enabling to study the evolution of lesions related to cervical cancer. In taking the first few steps towards this goal, the objective of this work is to develop and evaluate methodologies required for visual-based (i.e. content-based) indexing and retrieval that substantially improve information management of such a database. In this paper we model the properties of three tissue types using color and texture features, and use these models for image segmentation. Statistical modeling and segmentation tools are used for the task.","1063-7125;10637125","POD:0-7695-2104-5","10.1109/CBMS.2004.1311731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311731","","Cervical cancer;Content based retrieval;Image databases;Image segmentation;Indexing;Information management;Information retrieval;Lesions;Picture archiving and communication systems;Visual databases","PACS;biological tissues;cancer;content-based retrieval;database indexing;feature extraction;gynaecology;image retrieval;image segmentation;image texture;medical image processing;very large databases","35 mm;PACS;color feature;content-based retrieval;image segmentation;indexing;information management;large database;lesions;statistical modeling;texture feature;tissue types;uterine cervix images;visual-based indexing","","7","4","7","","","24-25 June 2004","","IEEE","IEEE Conference Publications"
"Adaptive routing of QoS-constrained media streams over scalable overlay topologies","G. Fry; R. West","Dept. of Comput. Sci., Boston Univ., MA, USA","Proceedings. RTAS 2004. 10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004.","20040726","2004","","","518","525","Current research on Internet-based distributed systems emphasizes the scalability of overlay topologies for efficient search and retrieval of data items, as well as routing amongst peers. However, most existing approaches fail to address the transport of data across these logical networks in accordance with quality of service (QoS) constraints. Consequently, we investigate the use of scalable overlay topologies for routing real-time media streams between publishers and potentially many thousands of subscribers. Specifically, we analyze the costs of using k-ary n-cubes for QoS-constrained routing. Given a number of nodes in a distributed system, we calculate the optimal k-ary n-cube structure for minimizing the average distance between any pair of nodes. Using this structure, we describe a greedy algorithm that selects paths between nodes in accordance with the real-time delays along physical links. We show this method improves the routing latencies by as much as 40%, compared to approaches that do not consider physical link costs. Additionally, we discuss an approach that dynamically repositions nodes in logical space, to improve the likelihood of meeting service requirements on data routed between publishers and subscribers.","1545-3421;15453421","POD:0-7695-2148-7","10.1109/RTTAS.2004.1317299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1317299","","Costs;Delay;Information retrieval;Internet;Network topology;Peer to peer computing;Quality of service;Routing;Scalability;Streaming media","Internet;algorithm theory;hypercube networks;multicast protocols;multimedia systems;quality of service;real-time systems;telecommunication network routing","Internet-based distributed system;QoS-constrained real-time media stream;adaptive routing;data retrieval;greedy algorithm;k-ary n-cube structure;scalable overlay topology","","2","","22","","","25-28 May 2004","","IEEE","IEEE Conference Publications"
"Multiple Bernoulli relevance models for image and video annotation","S. L. Feng; R. Manmatha; V. Lavrenko","Multimedia Indexing & Retrieval Group, Massachusetts Univ., Amherst, MA, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-1002","II-1009 Vol.2","Retrieving images in response to textual queries requires some knowledge of the semantics of the picture. Here, we show how we can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model. The model assumes that a training set of images or videos along with keyword annotations is provided. Multiple keywords are provided for an image and the specific correspondence between a keyword and an image is not provided. Each image is partitioned into a set of rectangular regions and a real-valued feature vector is computed over these regions. The relevance model is a joint probability distribution of the word annotations and the image feature vectors and is computed using the training set. The word probabilities are estimated using a multiple Bernoulli model and the image feature probabilities using a non-parametric kernel density estimate. The model is then used to annotate images in a test set. We show experiments on both images from a standard Corel data set and a set of video key frames from NIST's video tree. Comparative experiments show that the model performs better than a model based on estimating word probabilities using the popular multinomial distribution. The results also show that our model significantly outperforms previously reported results on the task of image and video annotation.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315274","","Content based retrieval;Distributed computing;Image databases;Image retrieval;Indexing;Information retrieval;Kernel;Probability distribution;Search engines;Testing","image retrieval;statistical distributions","Corel data set;NIST video tree;image annotation;image feature vectors;image retrieval;joint probability distribution;keyword annotations;multiple Bernoulli relevance models;nonparametric kernel density estimate;real-valued feature vector;textual queries;video annotation;video key frames","","244","12","14","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Feature selection for classifying high-dimensional numerical data","Yimin Wu; Aidong Zhang","Dept. of Comput. Sci. & Eng., SUNY, Buffalo, NY, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-251","II-258 Vol.2","Classifying high-dimensional numerical data is a very challenging problem. In high dimensional feature spaces, the performance of supervised learning methods suffers from the curse of dimensionality, which degrades both classification accuracy and efficiency. To address this issue, we present an efficient feature selection method to facilitate classifying high-dimensional numerical data. Our method employs balanced information gain to measure the contribution of each feature (for data classification); and it calculates feature correlation with a novel extension of balanced information gain. By integrating feature contribution and correlation, our feature selection approach uses a forward sequential selection algorithm to select uncorrelated features with large balanced information gain. Extensive experiments have been carried out on image and gene microarray datasets to demonstrate the effectiveness and robustness of the presented method.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315171","","Bioinformatics;Feedback;Filters;Gain measurement;Information retrieval;Multimedia systems;Pattern recognition;Supervised learning;Training data;Uncertainty","data analysis;learning (artificial intelligence);pattern classification","data classification;feature selection method;forward sequential selection algorithm;gene microarray datasets;high-dimensional numerical data;supervised learning methods","","5","","20","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Rendezvous regions: a scalable architecture for service location and data-centric storage in large-scale wireless networks","K. Seada; A. Helmy","Dept. of Electr. Eng., Univ. of Southern California, CA, USA","18th International Parallel and Distributed Processing Symposium, 2004. Proceedings.","20040607","2004","","","218","","Summary form only given. In large-scale wireless networks such as mobile ad hoc and sensor networks, efficient and robust service discovery and data-access mechanisms are both essential and challenging. Rendezvous-based mechanisms provide a valuable solution for provisioning a wide range of services. We describe rendezvous regions (RRs) - a novel scalable rendezvous-based architecture for wireless networks. RR is a general architecture proposed for service location and bootstrapping in ad hoc networks, in addition to data-centric storage, configuration, and task assignment in sensor networks. In RR the network topology is divided into geographical regions, where each region is responsible for a set of keys representing the services or data of interest. Each key is mapped to a region based on a hash-table-like mapping scheme. A few elected nodes inside each region are responsible for maintaining the mapped information. The service or data provider stores the information in the corresponding region and the seekers retrieve it from there. We run extensive detailed simulations, and high-level simulations and analysis, to investigate the design space, and study the architecture in various environments including node mobility and failures. We evaluate it against other approaches to identify its merits and limitations. The results show high success rate and low overhead even with dynamics. RR scales to large number of nodes and is highly robust and efficient to node failures. It is also robust to node mobility and location inaccuracy with a significant advantage over point-based rendezvous mechanisms.","","POD:0-7695-2132-0","10.1109/IPDPS.2004.1303252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303252","","Ad hoc networks;Analytical models;Engineering profession;Information retrieval;Intelligent networks;Large-scale systems;Network topology;Robustness;Wireless networks;Wireless sensor networks","ad hoc networks;computer bootstrapping;file organisation;mobile computing;open systems;wireless sensor networks","bootstrapping;data-centric storage;hash-table-like mapping scheme;mobile ad hoc networks;node failures;node mobility;rendezvous regions;scalable architecture;sensor networks;service location;task assignment;wireless networks","","22","","22","","","26-30 April 2004","","IEEE","IEEE Conference Publications"
"Affine invariant features from the trace transform","M. Petrou; A. Kadyrov","Sch. of Electron. & Phys. Sci., Surrey Univ., Guildford, UK","IEEE Transactions on Pattern Analysis and Machine Intelligence","20040614","2004","26","1","30","44","The trace transform is a generalization of the Radon transform that allows one to construct image features that are invariant to a chosen group of image transformations. In this paper, we propose a methodology and appropriate functionals that can be computed from the image function and which can be used to calculate features invariant to the group of affine transforms. We demonstrate the usefulness of the constructed image descriptors in retrieving images from an image database and compare it with relevant state-of-the-art object retrieval methods.","0162-8828;01628828","","10.1109/TPAMI.2004.1261077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261077","","Computer vision;Fractals;Humans;Image analysis;Image databases;Image retrieval;Information retrieval;Machine vision;Object recognition;Shape","Radon transforms;feature extraction;image retrieval;visual databases","Radon transform generalization;affine invariant features;affine transforms;feature extraction;image database;image function;image retrieval;image transformations;object retrieval methods;trace transform","Algorithms;Animals;Artificial Intelligence;Cluster Analysis;Computer Graphics;Computer Simulation;Databases, Factual;Fishes;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique","59","7","8","","","Jan. 2004","","IEEE","IEEE Journals & Magazines"
"Semantic data model for product support systems","D. T. Pham; S. S. Dimov; A. M. Huneiti","Cardiff Sch. of Eng., Univ. of Wales, Cardiff, UK","IEEE International Conference on Industrial Informatics, 2003. INDIN 2003. Proceedings.","20040601","2003","","","279","285","Organisations need a structured approach for managing the design of their electronic product support systems (PSSs) since, although technology can assist users with faster information retrieval, if the information is incorrect, the technology could actually increase the error rate. We present an approach for the semantic design and analysis of PSSs as part of a systematic methodology for the development of optimal PSSs. A semantic data model for PSSs is proposed based on an information usage analysis. This analysis aims at abstracting the intended purpose for the product information, the supported user tasks, and the functional characteristics of the product information elements. These abstract views are combined together into an activity-based semantic network and set of rules and constraints, which are then mapped into a database schema. This mapping creates a knowledge base that preserves the data semantics, which can then be used by authors in order to implement the PSS. A Web-based technical manual, which is a special type of PSS, is used in order to demonstrate the applicability of the proposed semantic data model.","","POD:0-7803-8200-5","10.1109/INDIN.2003.1300281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300281","","Data engineering;Data models;Databases;Information analysis;Information retrieval;Knowledge based systems;Knowledge engineering;Management training;Manuals;Virtual manufacturing","Internet;data models;information retrieval;knowledge based systems;semantic networks;user manuals","Web-based technical manual;activity-based semantic network;data semantics;database schema;electronic product support system;information retrieval;information usage analysis;knowledge-based system;product information element;semantic analysis;semantic data model;semantic design;systematic methodology","","2","","9","","","21-24 Aug. 2003","","IEEE","IEEE Conference Publications"
"Scalable discriminant feature selection for image retrieval and recognition","N. Vasconcelos; M. Vasconcelos","Stat. Visual Comput. Lab., California Univ., San Diego, CA, USA","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","20040719","2004","2","","II-770","II-775 Vol.2","Problems such as object recognition or image retrieval require feature selection (FS) algorithms that scale well enough to be applicable to databases containing large numbers of image classes and large amounts of data per class. We exploit recent connections between information theoretic feature selection and minimum Bayes error solutions to derive FS algorithms that are optimal in a discriminant sense without compromising scalability. We start by formalizing the intuition that optimal FS must favor discriminant features while penalizing discriminant features that are redundant. We then rely on this result to derive a new family of FS algorithms that enables an explicit trade-off between complexity and classification optimality. This trade-off is controlled by a parameter that encodes the order of feature redundancies that must be explicitly modeled to achieve the optimal solution. Experimental results on databases of natural images show that this order is usually low, enabling optimal FS with very low complexity.","1063-6919;10636919","POD:0-7695-2158-4","10.1109/CVPR.2004.1315242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315242","","Biology computing;Face detection;Image databases;Image recognition;Image retrieval;Information retrieval;Laboratories;Large-scale systems;Scalability;Spatial databases","Bayes methods;feature extraction;image recognition;image retrieval;object recognition","image recognition;image retrieval;minimum Bayes error solutions;object recognition;scalable discriminant feature selection","","13","1","17","","","27 June-2 July 2004","","IEEE","IEEE Conference Publications"
"Concept-oriented indexing of video databases: toward semantic sensitive retrieval and browsing","Jianping Fan; Hangzai Luo; A. K. Elmagarmid","Dept. of Comput. Sci., Univ. of North Carolina, Charlotte, NC, USA","IEEE Transactions on Image Processing","20040607","2004","13","7","974","992","Digital video now plays an important role in medical education, health care, telemedicine and other medical applications. Several content-based video retrieval (CBVR) systems have been proposed in the past, but they still suffer from the following challenging problems: semantic gap, semantic video concept modeling, semantic video classification, and concept-oriented video database indexing and access. In this paper, we propose a novel framework to make some advances toward the final goal to solve these problems. Specifically, the framework includes: 1) a semantic-sensitive video content representation framework by using principal video shots to enhance the quality of features; 2) semantic video concept interpretation by using flexible mixture model to bridge the semantic gap; 3) a novel semantic video-classifier training framework by integrating feature selection, parameter estimation, and model selection seamlessly in a single algorithm; and 4) a concept-oriented video database organization technique through a certain domain-dependent concept hierarchy to enable semantic-sensitive video retrieval and browsing.","1057-7149;10577149","","10.1109/TIP.2004.827232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303649","","Biomedical equipment;Bridges;Computer science;Content based retrieval;Feature extraction;Indexing;Information retrieval;Medical services;Spatial databases;Telemedicine","content-based retrieval;image enhancement;image representation;indexing;parameter estimation;video databases;video signal processing","concept-oriented indexing;digital video;domain-dependent concept hierarchy;flexible mixture model;health care;medical education;parameter estimation;principal video shots;semantic gap;semantic sensitive retrieval;semantic video classification;semantic video concept interpretation;semantic video concept modeling;semantic-sensitive video content representation;telemedicine;video databases","Abstracting and Indexing as Topic;Database Management Systems;Databases, Factual;Documentation;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Medical Records Systems, Computerized;Natural Language Processing;Pattern Recognition, Automated;Semantics;User-Computer Interface;Video Recording","43","1","88","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Managing asynchronous Web services interactions","M. Brambilla; S. Ceri; M. Passamani; A. Riccio","Dipt. di Elettronica e Informazione, Politecnico di Milano, Italy","Proceedings. IEEE International Conference on Web Services, 2004.","20040719","2004","","","80","87","Asynchronous interactions are becoming more and more important in the implementation of complex B2B Web applications. This paper addresses correlation and coordination issues involved with asynchronous Web services, by studying different mechanisms and metadata structures for supporting them; in addition, several interaction patterns for building asynchronous computations are discussed, and the trade-offs between the various patterns are shown. In conclusion, we illustrate the use of asynchronous Web services in the context of some concrete B2B applications.","","POD:0-7695-2167-3","10.1109/ICWS.2004.1314726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314726","","Buildings;Concrete;Context-aware services;Delay;Humans;Information retrieval;Logic;Real time systems;Web services;Yarn","Internet;electronic commerce","B2B Web applications;asynchronous Web service interaction management;asynchronous computations;interaction patterns;metadata structures;service coordination;service correlation","","16","3","18","","","6-9 July 2004","","IEEE","IEEE Conference Publications"
"Rate-distortion approach to databases: storage and content-based retrieval","E. Tuncel; P. Koulgi; K. Rose","Dept. of Electr. Eng., Univ. of California, Riverside, CA, USA","IEEE Transactions on Information Theory","20040601","2004","50","6","953","967","This paper investigates the relationship between rate-distortion theory and efficient content-based data retrieval from high-dimensional databases. We consider database design as the encoding of a data object sequence, and retrieval from the database as the decoding of the sequence using side information (i.e., the query) available only at the decoder. We show that, in this setting, the optimal asymptotic tradeoff between the search time R<sub>s</sub> (bits per data object read from the storage device) and the expected search accuracy D<sub>s</sub> (relevance of the retrieved data set) is given by the Wyner-Ziv solution with a side-information-dependent distortion measure. Moreover, the data indexing and retrieval problem is, in general, inseparable from the data compression problem. Data items selected by the search procedure, which can be stored in the disk with a limited total rate of R<sub>r</sub> ≥ R<sub>s</sub>, need to be presented at a prescribed expected reconstruction quality D<sub>r</sub>. This is, hence, a problem of scalable source coding or successive refinement, albeit with differing layer distortion measures to quantify search and reconstruction quality, respectively. We derive a single-letter characterization of all achievable quadruples {R<sub>s</sub>,R<sub>r</sub>,D<sub>s</sub>,D<sub>r</sub>}, and prove conditions for ""successive refinability"" without rate loss. Finally, we show that the special case D<sub>s</sub>=D<sub>r</sub>=0 is nontrivial and of practical interest in this context, as it can impose ""acceptable"" search and reconstruction qualities for each individual data item and for the entire query space with high probability, in contradistinction with standard average distortion requirements. The region of achievable {R<sub>s</sub>,R<sub>r</sub>} is obtained by adapting Rimoldi's characterization to a new regular scalable coding problem.","0018-9448;00189448","","10.1109/TIT.2004.828068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302283","Approximate similarity searching;Wyner–Ziv problem;content-based retrieval;databases;scalable coding;successive refinability without rate loss;zero–one distortion measures","Content based retrieval;Data compression;Databases;Decoding;Distortion measurement;Encoding;Indexing;Information retrieval;Rate-distortion;Time measurement","content-based retrieval;data compression;database indexing;distortion measurement;rate distortion theory;source coding","Rimoldis characterization;Wyner-Ziv solution;approximate similarity searching;content-based data retrieval;data indexing;data object sequence encoding;decoder;high-dimensional databases;query space probability;rate-distortion theory;scalable source coding;side-information-dependent distortion measure;single-letter characterization;successive refinement","","15","","18","","","June 2004","","IEEE","IEEE Journals & Magazines"
"Case generation using rough sets with fuzzy representation","S. K. Pal; Pabitra Mitra","Machine Intelligent Unit, Indian Stat. Inst., Calcutta, India","IEEE Transactions on Knowledge and Data Engineering","20040628","2004","16","3","293","300","We propose a rough-fuzzy hybridization scheme for case generation. Fuzzy set theory is used for linguistic representation of patterns, thereby producing a fuzzy granulation of the feature space. Rough set theory is used to obtain dependency rules which model informative regions in the granulated feature space. The fuzzy membership functions corresponding to the informative regions are stored as cases along with the strength values. Case retrieval is made using a similarity measure based on these membership functions. Unlike the existing case selection methods, the cases here are cluster granules and not sample points. Also, each case involves a reduced number of relevant features. These makes the algorithm suitable for mining data sets, large both in dimension and size, due to its low-time requirement in case generation as well as retrieval. Superiority of the algorithm in terms of classification accuracy and case generation and retrieval times is demonstrated on some real-life data sets.","1041-4347;10414347","","10.1109/TKDE.2003.1262181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1262181","","Clustering algorithms;Computer aided software engineering;Data mining;Fuzzy logic;Fuzzy set theory;Fuzzy sets;Hybrid power systems;Information retrieval;Rough sets;Set theory","case-based reasoning;data mining;fuzzy set theory;knowledge representation;linguistics;pattern recognition;rough set theory","case generation;case retrieval;case selection methods;case-based reasoning;data mining;fuzzy membership functions;fuzzy set representation;granulated feature space;informative regions;pattern recognition;real-life data sets;rough dependency rules;rough-fuzzy hybridization scheme;soft computing","","90","","26","","","Mar 2004","","IEEE","IEEE Journals & Magazines"
"An optimization criterion for generalized discriminant analysis on undersampled problems","Jieping Ye; R. Janardan; C. H. Park; H. Park","Dept. of Comput. Sci. & Eng., Univ. of Minnesota-Twin Cities, Minneapolis, MN, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","20040621","2004","26","8","982","994","An optimization criterion is presented for discriminant analysis. The criterion extends the optimization criteria of the classical Linear Discriminant Analysis (LDA) through the use of the pseudoinverse when the scatter matrices are singular. It is applicable regardless of the relative sizes of the data dimension and sample size, overcoming a limitation of classical LDA. The optimization problem can be solved analytically by applying the Generalized Singular Value Decomposition (GSVD) technique. The pseudoinverse has been suggested and used for undersampled problems in the past, where the data dimension exceeds the number of data points. The criterion proposed in this paper provides a theoretical justification for this procedure. An approximation algorithm for the GSVD-based approach is also presented. It reduces the computational complexity by finding subclusters of each cluster and uses their centroids to capture the structure of each cluster. This reduced problem yields much smaller matrices to which the GSVD can be applied efficiently. Experiments on text data, with up to 7,000 dimensions, show that the approximation algorithm produces results that are close to those produced by the exact algorithm.","0162-8828;01628828","","10.1109/TPAMI.2004.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307006","Classification;clustering;dimension reduction;generalized singular value decomposition;linear discriminant analysis;text mining.","Approximation algorithms;Clustering algorithms;Computational complexity;Data mining;Face recognition;Information retrieval;Linear discriminant analysis;Matrix decomposition;Scattering;Singular value decomposition","approximation theory;computational complexity;generalisation (artificial intelligence);optimisation;pattern classification;pattern clustering;singular value decomposition","approximation algorithm;computational complexity;generalized discriminant analysis;generalized singular value decomposition;linear discriminant analysis;optimization;pseudoinverse;scatter matrices;undersampled problems","Algorithms;Artificial Intelligence;Cluster Analysis;Discriminant Analysis;Documentation;Information Storage and Retrieval;Natural Language Processing;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sample Size;Sensitivity and Specificity","136","","33","","","Aug. 2004","","IEEE","IEEE Journals & Magazines"
"Adaptive load balancing content address hashing routing for reverse proxy servers","T. Takenaka; S. Kato; H. Okamoto","Graduate Sch. of Eng., Nihon Univ., Tokyo, Japan","2004 IEEE International Conference on Communications (IEEE Cat. No.04CH37577)","20040726","2004","3","","1522","1526 Vol.3","We propose a novel routing algorithm for reverse proxy servers, called adaptive loud balancing content address hashing (AH), and evaluate the performance of the proposed routing algorithm compared with that of the content address hashing (SH) and the hash and slide (HS) routing algorithms. The proposed AH routing algorithm calculates the popularity of pages in the load balancer using an LFU caching technique and periodically makes a popularity list. Using this popularity list, the proposed routing algorithm selects a reverse proxy server as follows. When the requested page appears in the popularity list, the request is routed according to the round robin method; otherwise, it is routed according to the content address hashing method. We evaluate and compare the AH, SH and HS routing algorithms by simulation experiments from the viewpoints of load balancing, consumed cache space and cache hit rate. Simulation experiments show that the proposed AH routing algorithm achieves almost the same degree of load balancing as the HS algorithm and the same cache hit rate as the SH algorithm, for reverse proxy servers in various web site environments.","","POD:0-7803-8533-0","10.1109/ICC.2004.1312765","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1312765","","Electronic commerce;Information retrieval;Load management;Round robin;Routing;Web and internet services;Web pages;Web server;Web services;Web sites","Internet;Web sites;cache storage;content-addressable storage;resource allocation;telecommunication network routing","LFU caching technique;adaptive load balancing content address hashing;cache hit rate;cache space;reverse proxy server;round robin method;routing algorithm;web site environment","","1","1","11","","","20-24 June 2004","","IEEE","IEEE Conference Publications"
"Including conditional operators in content-based image retrieval in large sets of medical exams","C. Traina; A. J. M. Trains; J. M. de Figuciredo","Comput. Sci. Dept., Sao Paulo Univ., Sao Carlos, Brazil","Proceedings. 17th IEEE Symposium on Computer-Based Medical Systems","20040719","2004","","","85","90","Content-based image retrieval systems (CBIR) aim at helping in searching large image collections to find those more likely to answer query conditions based on the information represented in the images. To speed up the search process, selected features are extracted from each image when they are stored in the database, so each one is represented by a feature vector. Subsequent image searching operations are performed using the feature vectors in place of the images. The feature extraction algorithms have important issues in CBIR due to the large semantic gap between the low-level features extracted as compared to the high-level, semantic, results expected by the users. A way to approach a semantic analysis of an image, as performed by humans, is to employ a large number of analyzers whose results are processed by a set of rules based on if-then clauses. In this paper we create a framework to define image processing and feature extraction algorithms for CBIR systems as components of a data flow architecture, including an analysis mechanism to interpret images. It is based on decision components that check the results of previously executed feature extractors to choose from a set of configurable execution paths that leads to the creation of the feature vector of each image. In the paper we will describe a real system that has been implemented based on these concepts, which is being used as a teaching tool in a school hospital.","1063-7125;10637125","POD:0-7695-2104-5","10.1109/CBMS.2004.1311696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311696","","Biomedical imaging;Content based retrieval;Data mining;Feature extraction;Image analysis;Image databases;Image retrieval;Information retrieval;Performance analysis;Spatial databases","PACS;content-based retrieval;data flow graphs;feature extraction;image retrieval;medical image processing","conditional operators;content-based image retrieval;data flow architecture;feature extraction;feature vector;image processing;image searching operations;medical exams;query conditions;semantic analysis;semantic gap","","0","","6","","","24-25 June 2004","","IEEE","IEEE Conference Publications"
"Retrieval of isomorphic substructures in crystallographic databases","H. J. Klein","Inst. fur Informatik und Prakt. Math., Kiel Univ., Germany","Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.","20040719","2004","","","255","264","Local bindings of atoms are often modeled by coordination polyhedra with vertices representing ligands, i.e. atoms with strong bonds to a central atom. Neighbouring polyhedra may be linked by vertices, edges, or faces depending on whether their central atoms share one, two, or more atoms as ligands. Substructures formed by linked polyhedra are of considerable interest for studying crystal structures. We introduce a finite graph representation for infinite polyhedral networks and show how to build an index for a given set of model structures such that the retrieval of isomorphic substructures is supported. A system has been implemented providing this functionality on an interactive graphical Web interface.","1099-3371;10993371","POD:0-7695-2146-0","10.1109/SSDM.2004.1311217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1311217","","Atomic layer deposition;Chemical elements;Crystallography;Crystals;Face detection;Information retrieval;Organic compounds;Search methods;Solid modeling;Spatial databases","Web sites;bonds (chemical);chemistry computing;crystal structure;data models;database indexing;graph theory;graphical user interfaces;isomorphism;visual databases","atom bonds;atom local binding modeling;central atom;coordination polyhedra;crystal structures;crystallographic databases;database indexing;finite graph representation;infinite polyhedral networks;interactive graphical Web interface;isomorphic substructure retrieval;ligand representation;model structures;polyhedra linking","","2","","17","","","21-23 June 2004","","IEEE","IEEE Conference Publications"
"Software engineering challenges in bioinformatics","J. Barker; J. Thornton","Eur. Bioinformatics Inst., Cambridge, UK","Proceedings. 26th International Conference on Software Engineering","20040726","2004","","","12","15","Data from biological research is proliferating rapidly and advanced data storage and analysis methods are required to manage it. We introduce the main sources of biological data available and outline some of the domain specific problems associated with automated analysis. We discuss two major areas in which we are likely experience software engineering challenges over the next ten years: data integration and presentation.","0270-5257;02705257","POD:0-7695-2163-0","10.1109/ICSE.2004.1317409","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1317409","","Bioinformatics;Crystallography;DNA;Data analysis;Genomics;Information retrieval;Memory;Proteins;Sequences;Software engineering","biology computing;data analysis;software engineering","bioinformatics;biological data;biological research;data analysis;data integration;data presentation;data storage;software engineering","","2","","14","","","23-28 May 2004","","IEEE","IEEE Conference Publications"
"Eliminating replica selection - using multiple replicas to accelerate data transfer on grids","Ju Feng; M. Humphrey","Dept. of Comput. Sci., Virginia Univ., USA","Proceedings. Tenth International Conference on Parallel and Distributed Systems, 2004. ICPADS 2004.","20040726","2004","","","356","366","Data-intensive, high-performance computing applications often require the efficient transfer of terabytes or even petabytes of data in wide-area, distributed computing environments. To increase the efficiency of wide area data movement, researchers have devised various techniques such as TCP tuning, multiple streams and asynchronous I/O. This paper adopts an approach to increase performance further by exploiting replica-level parallelism in grids. rFTP, a grid data transferring tool, improves the data transfer rate and reliability on grids by utilizing multiple replica sources concurrently. Experiments on the NPACI grid show as much as a 2.02× speedup over a single data source by adaptively retrieving partial data segments from 4 replicas using the data provided by NWS.","1521-9097;15219097","POD:0-7695-2152-5","10.1109/ICPADS.2004.1316115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316115","","Acceleration;Application software;Computer applications;Computer science;Distributed computing;Grid computing;Information retrieval;Leg;Throughput;Weather forecasting","electronic data interchange;grid computing;parallel processing;wide area networks","NPACI grid;TCP tuning;asynchronous I/O;data transfer rate;data transfer reliability;distributed computing environment;grid data transferring tool;multiple replicas;multiple streams;partial data segment retrieval;rFTP;replica selection;replica sources;replica-level parallelism;single data source;wide area data movement;wide-area computing environment","","6","1","28","","","7-9 July 2004","","IEEE","IEEE Conference Publications"
"Boosting biomedical images indexing","D. V. Tsishkou; P. D. Kukharchik; E. I. Bovbel; I. E. Kheidorov; M. M. Liventseva","Belarusian State Univ., Minsk, Belarus","IEEE EMBS Asian-Pacific Conference on Biomedical Engineering, 2003.","20040607","2003","","","74","75","Indexing and retrieval in biomedical image databases is a challenging problem. Constructing large-scale indexing solutions is typically limited by a choice of appropriate features, complexity constraints of the engine and a way how to combine retrieval results to have a stronger one. Combination of standard feature extraction routines with specific knowledge on a subject, such as precise automatic object segmentation and medical parameters estimation is the first key factor to achieve high accuracy and robustness of the indexing/retrieval solution. We are developing a search engine based on a TTA10 algorithm, which stores data in hierarchical fashion, with logarithmic complexity to access a large data repository in real-time. We propose to use AdaBoost technique to combine independent search results into more robust and accurate one. Initial results on a database of more than 80.000 ultrasound images demonstrate good accuracy and fast speed.","","POD:0-7803-7943-8","10.1109/APBME.2003.1302590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302590","","Biomedical imaging;Boosting;Engines;Image databases;Image retrieval;Indexing;Information retrieval;Large-scale systems;Robustness;Spatial databases","biomedical ultrasonics;database indexing;feature extraction;image retrieval;image segmentation;medical image processing;real-time systems;search engines;visual databases","AdaBoost technique;TTA10 algorithm;biomedical image databases;biomedical images;feature extraction routines;indexing/retrieval solution;large data repository;large-scale indexing solutions;logarithmic complexity;medical parameters estimation;precise automatic object segmentation;real-time system;robustness;search engine;ultrasound images","","0","","8","","","20-22 Oct. 2003","","IEEE","IEEE Conference Publications"
"A proposal of a decision-maker problem to for a better understanding of information needs","N. Bouaka; A. David","Nancy 2 Univ., France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","551","552","This work presents a model of the decision-maker's problem in the economic intelligence context. Our goal is to describe the decision-maker's problem as explicitly as possible in order to help the watcher understand the real information need of the decision-maker. Our model takes into account three data categories: the environmental data, the organizational data and the personal data. In fact, we believe that to satisfy the decision-maker's information needs, the watcher (or the information provider) must understand not only what information to gather but also must understand who poses the problem (the decision-maker) and why, that is the context of the problem.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307879","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307879","","Atmosphere;Context modeling;Decision making;Delta modulation;Economic indicators;Environmental economics;Information analysis;Information resources;Information retrieval;Proposals","decision making;decision support systems;information needs;knowledge management","decision-maker problem;economic intelligence;environmental data;information need;information provider;organizational data;personal data","","1","","1","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Semantic video content indexing and retrieval using conceptual graphs","M. Charhad; G. Quenot","IMAG, Grenoble, France","Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications, 2004.","20040706","2004","","","399","400","This paper proposes a model for the indexing and retrieval of semantic video content using conceptual graphs. Conceptual graph based indexing is even better since not only nonambiguous concepts are used but also relations between these concepts are indexed. The proposed model allows video content representation both at the semantic and at the signal levels. The signal based representation is done via the perceptive view using classical signal descriptors. The representation by conceptual graph allows a more precise description of the content and it also allows the linking between the involved concepts and the sub Medias of the video documents. The various concepts and relations involved in the model can be taken from general and/or domain specific ontologies and completed by lists of instances. the correspondence between the query and any document is searched as a projection of the graph representing the query on the graph representing the document. This projection is done using the substitution rules permitted by the ontology.","","POD:0-7803-8482-2","10.1109/ICTTA.2004.1307800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1307800","","Content based retrieval;Image retrieval;Image segmentation;Indexing;Information retrieval;Joining processes;Multimedia systems;Ontologies;Speech","content-based retrieval;database indexing;document image processing;graph theory;image representation;image retrieval;multimedia databases;ontologies (artificial intelligence);video databases;video signal processing","classical signal descriptor;conceptual graph based indexing;graph projection;graph represention;multimedia information retrieval;ontology;perceptive view;query processing;semantic video content indexing;signal representation;video content representation;video content retrieval;video document","","5","2","2","","","19-23 April 2004","","IEEE","IEEE Conference Publications"
"Inverse problems theory and application: analysis of the two-temperature method for land-surface temperature and emissivity estimation","L. F. Peres; C. C. DaCamara","Centro de Geofisica, Univ. de Lisboa, Lisbon, Portugal","IEEE Geoscience and Remote Sensing Letters","20040719","2004","1","3","206","210","The two-temperature method (TTM) allows the separation of land-surface temperature and land-surface emissivity information from radiance measurements, and therefore, the solution can be uniquely determined by the data. However, the inverse problem is still an ill-posed problem, since the solution does not depend continuously on the data. Accordingly, we have used some mathematical tools, which are suited for analyses of ill-posed problems in order to show TTM properties, evaluate it, and optimize its estimations. Related to this last point, we have shown that it is necessary to constrain the problem, either by defining a region of physically admissible solutions and/or by using regularization methods, in order to obtain stable results. Besides, the results may be improved by using TTM with systems that possess a high temporal resolution, as well as by acquiring observations near the maximum and minimum of the diurnal temperature range.","1545-598X;1545598X","","10.1109/LGRS.2004.830613","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315633","Emissivity;LST;SVD;information theory;infrared imaging;inverse problems;land surface temperature;remote sensing;singular value decomposition","Information analysis;Information retrieval;Information theory;Inverse problems;Land surface;Land surface temperature;Satellites;Temperature distribution;Temperature sensors;Time to market","inverse problems;terrain mapping","emissivity estimation;ill-posed problems;inverse problems theory;land-surface emissivity information;land-surface temperature;radiance measurements;regularization methods;two-temperature method","","6","","14","","","July 2004","","IEEE","IEEE Journals & Magazines"
"Population-based incremental interactive concept learning for image retrieval by stochastic string segmentations","S. Ghebreab; C. C. Jaffe; A. W. M. Smeulders","Departments of Radiol. & Med. Informatics, Biomed. Imaging Group Rotterdam, Netherlands","IEEE Transactions on Medical Imaging","20040601","2004","23","6","676","689","We propose a method for concept-based medical image retrieval that is a superset of existing semantic-based image retrieval methods. We conceive of a concept as an incremental and interactive formalization of the user's conception of an object in an image. The premise is that such a concept is closely related to a user's specific preferences and subjectivity and, thus, allows to deal with the complexity and content-dependency of medical image content. We describe an object in terms of multiple continuous boundary features and represent an object concept by the stochastic characteristics of an object population. A population-based incrementally learning technique, in combination with relevance feedback, is then used for concept customization. The user determines the speed and direction of concept customization using a single parameter that defines the degree of exploration and exploitation of the search space. Images are retrieved from a database in a limited number of steps based upon the customized concept. To demonstrate our method we have performed concept-based image retrieval on a database of 292 digitized X-ray images of cervical vertebrae with a variety of abnormalities. The results show that our method produces precise and accurate results when doing a direct search. In an open-ended search our method efficiently and effectively explores the search space.","0278-0062;02780062","","10.1109/TMI.2004.826942","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1302206","","Biomedical imaging;Feedback;Image databases;Image retrieval;Image segmentation;Information retrieval;Space exploration;Spine;Stochastic processes;X-ray imaging","Gaussian distribution;content-based retrieval;image retrieval;image segmentation;learning (artificial intelligence);medical expert systems;medical image processing;relevance feedback;visual databases","adaptive Gaussian probabilistic model;cervical vertebrae;concept customization;concept-based medical image retrieval;content-based image retrieval;digitized X-ray images;direct search;image database;incremental formalization;interactive formalization;multifeature object description;multiple continuous boundary features;open-ended search;population-based incremental learning;relevance feedback;semantic-based image retrieval;stochastic string segmentations;visual concept learning","Algorithms;Artificial Intelligence;Cervical Vertebrae;Database Management Systems;Humans;Information Storage and Retrieval;Medical Records Systems, Computerized;Models, Biological;Models, Statistical;Pattern Recognition, Automated;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sample Size;Sensitivity and Specificity;Stochastic Processes","8","","26","","","June 2004","","IEEE","IEEE Journals & Magazines"
"Web intelligence: conceptual search engine and navigation","M. Nikravesh","Dept. of Electr. Eng. & Comput. Sci., California Univ., Berkeley, CA, USA","IEEE International Conference on Industrial Informatics, 2003. INDIN 2003. Proceedings.","20040601","2003","","","390","395","Design of any new intelligent search engine should be at least based on two main motivations. 1) The Web environment is, for the most part, unstructured and imprecise. To deal with information in the Web environment what is needed is a logic that supports modes of reasoning which are approximate rather than exact. While searches may retrieve thousands of hits, finding decision-relevant and query-relevant information in an imprecise environment is a challenging problem, which has to be addressed and 2) another, and less obvious, is deduction in an unstructured and imprecise environment given the huge stream of complex information.","","POD:0-7803-8200-5","10.1109/INDIN.2003.1300364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1300364","","Context modeling;Fuzzy sets;Indexing;Information retrieval;Internet;Logic;Navigation;Ontologies;Search engines;Telephony","Internet;competitive intelligence;decision support systems;fuzzy logic;information retrieval;query processing;search engines","Web intelligence;Web navigation;intelligent search engine;query-relevant information","","0","","15","","","21-24 Aug. 2003","","IEEE","IEEE Conference Publications"
"A Web-based infrastructure for the management of semantic meta-data","V. Del Bianco; G. Ripa; E. Tracanella; L. Lavazza","CEFRIEL, Politecnico di Milano, Milan, Italy","Proceedings. Ninth IEEE International Conference on Engineering of Complex Computer Systems","20040712","2004","","","181","190","Professional operators who deal with the cultural goods of Italy constantly face the problem of retrieving the needed information from heterogeneous sources. Such information has also to be combined and elaborated; this operation is made difficult by the heterogeneity of the data models and vocabularies employed at the different information sources. This paper illustrates the architecture of a Web-based system that provides users with a unified view of the metadata describing the information available from the various sources. In this way the user can navigate through and choose among homogeneous virtual descriptions that finally bring him/her to the sought real data. The peculiarities of the illustrated system are: it is built exclusively employing open source software, it allows the data sources to maintain their ""independence"", i.e., they remain the unique managers of their own data, it supports different virtual communities of users, each with its own vocabulary and ontology.","1050-4729;10504729","POD:0-7695-2109-6","10.1109/ICECCS.2004.1310916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310916","","Cultural differences;Data models;Global communication;Government;Information retrieval;Isolation technology;Navigation;Ontologies;Open source software;Vocabulary","data models;humanities;information retrieval;meta data;vocabulary","Italy;Web-based infrastructure;Web-based system;cultural goods;data models;data sources;heterogeneous sources;homogeneous virtual descriptions;information retrieval;information sources;open source software;professional operators;semantic meta-data management;virtual communities","","0","","7","","","14-16 April 2004","","IEEE","IEEE Conference Publications"
