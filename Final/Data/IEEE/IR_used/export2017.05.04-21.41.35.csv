"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=1661251,1648741,1651299,1656119,1651315,1652422,1648906,1661249,1651981,1660704,1660295,1661252,1661324,1644327,1651316,1652415,1652423,1644297,1651365,1660545,1651331,1651337,1651303,1660365,1651360,1657472,1660087,1648752,1651352,1652537,1644295,1660361,1660369,1658035,1658036,1658034,1648475,1640325,1652923,1652111,1652048,1652139,1652073,1652119,1652206,1652236,1652178,1652237,1640288,1647680,1650516,1647783,1647546,1647560,1650405,1647785,1647552,1647873,1647851,1640558,1647875,1647545,1647852,1650199,1647681,1647799,1640845,1647879,1647780,1647850,1647648,1640555,1649663,1647684,1647874,1647786,1647781,1647632,1647776,1647807,1647782,1647763,1647846,1649689,1647554,1647895,1640775,1647766,1640673,1640202,1631130,1631139,1631116,1619416,1645271,1631213,1639474,1639494,1639804,1639305",2017/05/04 21:41:35
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Multimedia correlation analysis in unstructured peer-to-peer networks","Bo Yang; A. R. Hurson; Yu Jiao; T. E. Potok","Dept. of Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2006 International Symposium on a World of Wireless, Mobile and Multimedia Networks(WoWMoM'06)","20060710","2006","","","7 pp.","338","Recent years saw the rapid development of peer-to-peer (P2P) networks in a great variety of applications. However, similarity-based k-nearest-neighbor retrieval (k-NN) is still a challenging task in P2P networks due to the multiple constraints such as the dynamic topologies and the unpredictable data updates. Caching is an attractive solution that reduces network traffic and hence could remedy the technological constraints of P2P networks. However, traditional caching techniques have some major shortcomings that make them unsuitable for similarity search, such as the lack of semantic locality representation and the rigidness of exact matching on data objects. To facilitate the efficient similarity search, we propose semantic-aware caching scheme (SAC) in this paper. The proposed scheme is hierarchy-free, fully dynamic, non-flooding, and do not add much system overhead. By exploring the content distribution, SAC drastically reduces the cost of similarity-based k-NN retrieval in P2P networks. The performance of SAC is evaluated through simulation study and compared against several search schemes as advanced in the literature","","POD:0-7695-2593-8","10.1109/WOWMOM.2006.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648475","","Content based retrieval;Contracts;Costs;Floods;Information retrieval;Intelligent networks;Network topology;Peer to peer computing;Streaming media;Telecommunication traffic","cache storage;content-based retrieval;correlation theory;multimedia communication;peer-to-peer computing","P2P;SAC;k-NN;k-nearest-neighbor retrieval;multimedia correlation analysis;peer-to-peer network;semantic-aware caching scheme","","0","","29","","","0-0 0","","IEEE","IEEE Conference Publications"
"Rapid Answer Retrieval from Clinical Practice Guidelines at the Point of Care","Sek-Kwong Poon; R. A. Rocha; G. De Fiol","University of Utah, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","143","150","We describe and report preliminary results of a prototype XML-based method that facilitates the retrieval and navigation of common practice guidelines by physicians at the point of care. The method can be invoked by clicking at ""infobuttons"" linked to problems in an electronic medical record. Each infobutton displays a list of questions that are categorized and sorted according to the classification proposed by Ely et al. The navigation is achieved through hyperlinks from each question to relevant parts of the guideline. Preliminary results indicate high physician acceptance. A prospective evaluation is now being launched, with the expectation that it would confirm this method as an efficient option for retrieving information from reference documents","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647560","","Cities and towns;Frequency;Guidelines;Information resources;Information retrieval;Medical diagnostic imaging;Medical services;Navigation;Taxonomy;User interfaces","XML;information retrieval;medical information systems","clinical practice guidelines;electronic medical record;infobutton;information retrieval;prototype XML method;rapid answer retrieval;reference documents","","0","","11","","","0-0 0","","IEEE","IEEE Conference Publications"
"On the role of measurement configuration in contactless GPR data processing by means of linear inverse scattering","","","IEEE Transactions on Antennas and Propagation","20060705","2006","54","7","2062","2071","This paper deals with a linear two-dimensional inverse scattering problem within a half space geometry with data gathered far away from the interface, which is relevant in ground penetrating radar contactless data processing. In particular, the role of the measurement configuration is discussed with regard to the information retrievable from multifrequency data.","0018-926X;0018926X","","10.1109/TAP.2006.877170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1650405","Born approximation;ground penetrating radar (GPR) prospecting;inverse scattering","Data processing;Frequency diversity;Geometry;Ground penetrating radar;Information retrieval;Inverse problems;Performance evaluation;Radar scattering;Soil;Wavelength measurement","electromagnetic wave scattering;ground penetrating radar;information retrieval","contactless GPR data processing;ground penetrating radar;half space geometry;information retrieval;linear inverse scattering;measurement configuration;multifrequency data","","9","","22","","","July 2006","","IEEE","IEEE Journals & Magazines"
"The NODC Archive Management System: archiving marine data for ocean exploration and beyond","D. W. Collins; S. B. Rutz","NOAA Nat. Oceanogr. Data Center, Silver Spring, MD, USA","Proceedings of OCEANS 2005 MTS/IEEE","20060626","2005","","","2820","2823 Vol. 3","The stewardship of the nation's oceanographic data archive is an essential responsibility of the U.S. National Oceanographic Data Center (NODC). The NODC continues to focus on the long-term preservation, integrity, and accessibility of irreplaceable observational data through multiple technological and scientific generations. Recently implemented processes improve the ability of NODC to meet data archive stewardship responsibilities, expand online data discovery and retrieval services, and provide adequate supporting metadata to guide use of the archived data. The NODC Archive Management System (AMS) facilitates accessioning and archiving oceanographic data and information, and disseminating data and information in a web-enabled, browser-based environment NODC's collection of over 21,000 unique accessioned datasets, ranging from individual observations to large collections by major programs, is documented and discoverable in this unified system. A growing collection of digital data obtained by the NOAA Office of Ocean Exploration (OE) are archived at NODC and accessible through the generic AMS search and retrieval sub-system (the Ocean Archive System, or OAS, at http://www.nodc.noaa.gov/Archive/Search/). This paper briefly describes the four major components of the AMS (Accession Tracking Data Base, File Management, NODC Metadata Manager and Repository, and OAS) and the relationship between the AMS and other parts of the end-to-end data management capabilities developed to manage OE data.","0197-7385;01977385","Paper:0-933957-34-3","10.1109/OCEANS.2005.1640202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640202","","Costs;Databases;Educational institutions;Environmental management;Information retrieval;Marine technology;Ocean temperature;Road transportation;Silver;Technology management","data acquisition;information retrieval;oceanographic techniques;oceanography;records management","NOAA Office of Ocean Exploration;NODC Archive Management System;NODC Metadata Manager and Repository;Ocean Archive System;U.S. National Oceanographic Data Center;accession tracking database;browser-based environment;data dissemination;file management;information retrieval services;ocean exploration;oceanographic data archives;online data discovery","","5","","7","","","17-23 Sept. 2005","","IEEE","IEEE Conference Publications"
"Automatic Video Annotation by Mining Speech Transcripts","A. Velivelli; T. S. Huang","University of Illinois at Urbana-Champaign","2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)","20060705","2006","","","115","115","We describe a model for automatic prediction of text annotations for video data. The speech transcripts of videos, are clustered using an aspect model and keywords are extracted based on aspect distribution. Thus we capture the semantic information available in the video data. This technique for automatic keyword vocabulary construction makes the labelling of video data a very easy task. We then build a video shot vocabulary by utilizing both static images and motion cues. We use a maximum entropy criterion to learn the conditional exponential model by defining constraint features over the shot vocabulary, keyword vocabulary combinations. Our method uses a maximum a posteriori estimate of exponential model to predict the annotations. We evaluate the ability of our model to predict annotations, in terms of mean negative log-likelihood and retrieval performance on the test set. A comparison of exponential model with baseline methods indicates that the results are encouraging.","2160-7508;21607508","POD:0-7695-2646-2","10.1109/CVPRW.2006.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640558","","Content based retrieval;Data mining;Entropy;Information retrieval;Labeling;Predictive models;Speech;Streaming media;Testing;Vocabulary","","","","7","8","15","","","17-22 June 2006","","IEEE","IEEE Conference Publications"
"Correlating Scenes as Series of Document Sentences with Images","Y. Itabashi; Y. Masunaga","Graduate Division of Mathematics and Computer Science, Ochanomizu University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1235","1235","With the popularization of the Internet and the development of multimedia technology, various data are produced and disseminated in different media such as documents, images, photographs, pictures, and movies. Therefore, there are a variety of data in different media which represent the same contents. However, the method of correlating data in different media having the same contents has not yet been established. This paper proposes a method of correlating a document with an image, both of which express the similar contents. This method bases upon the observation that a series of sentences in a document could constitute a scene, and by utilizing the similarity measure of the vector space model as a criterion, we could correlate a scene with an image if their similarity is high. An experimental result of the above-mentioned method is shown taking ""The Tale of Genji"" and the photographs taken on the subject of this tale, as an example. It is shown that the method works fairly good as it is intended, however there still remain difficult problems for improvement.","","POD:0-7695-2657-8","10.1109/ICDE.2005.208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647852","","Biographies;Computer science;Electronic mail;Image converters;Image retrieval;Information retrieval;Internet;Layout;Mathematics;Motion pictures","","","","1","","12","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Enhanced 2D/3D Approaches Based on Relevance Index for 3D-Shape Retrieval","M. Chaouch; A. Verroust-Blondet","INRIA Rocquencourt, France","IEEE International Conference on Shape Modeling and Applications 2006 (SMI'06)","20060626","2006","","","36","36","We present a new approach for 3D model indexing and retrieval using 2D/3D shape descriptors based on silhouettes or depth-buffer images. To take into account the dispersion of information in the views, we associate to each view a relevance index which will be afterward used in the dissimilarity computation. The performance of this new approach is evaluated on the Princeton 3D shape benchmark database","","POD:0-7695-2591-1","10.1109/SMI.2006.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631213","","Chaos;Electric shock;Image databases;Image retrieval;Indexing;Information retrieval;Internet;Rendering (computer graphics);Robustness;Shape measurement","image retrieval;relevance feedback;solid modelling","3D-shape retrieval;depth-buffer images;enhanced 2D approach;enhanced 3D approach;relevance index;silhouettes image","","7","","26","","","14-16 June 2006","","IEEE","IEEE Conference Publications"
"Link Information Consistency Methods Using Update Notification on theWeb","Y. Takasago; A. Kobayashi; K. Yamaoka; Y. Sakai","Tokyo Institute of Technology","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1256","1256","The Cooperative Web Architecture (CWA) was proposed for relevant information retrieval using Web-Graph. In CWA, the Web servers maintain and deliver the neighboring link information (Web-Subgraph). When events that change the Web-Graph occur, the Web servers notify each other of the change in order to synchronize Web-Subgraphs. In this paper, we propose a synchronization method to solve a problem of inconsistency among Web-Subgraphs. This problem occurs because of the time difference between notifications. When multiple events occur simultaneously, the range of notification becomes invalid. Therefore the inconsistency problem occurs. We proposed two types of synchronization methods, then we compare and analyze their respective characteristics. Moreover we discuss feasibility from the viewpoint of traffic.","","POD:0-7695-2657-8","10.1109/ICDE.2005.236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647873","","Communications technology;Data engineering;HTML;Information retrieval;Navigation;Search engines;Service oriented architecture;Traffic control;Visualization;Web server","","","","0","","10","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"An effective visibility culling method based on cache block","Moon-Hee Choi; Woo-Chan Park; F. Neelamkavil; Tack-Don Han; Shin-Dug Kim","Dept. of Comput. Sci., Yonsei Univ., South Korea","IEEE Transactions on Computers","20060705","2006","55","8","1024","1032","As the complexity of 3D scenes is on the increase, the search for an effective visibility culling method has become one of the most important issues to be addressed in the design of 3D rendering processors. In this paper, we propose a new rasterization pipeline with visibility culling; the proposed architecture performs the visibility culling at an early stage of the rasterization pipeline (especially at the traversal stage) by retrieving data in a pixel cache without any significant hardware logics such as the hierarchical z-buffer. If the data to be retrieved does not exist in the pixel cache, the proposed architecture performs a prefetch operation in order to reduce the miss penalty of the pixel cache. That is, the cache miss penalty can be reduced as the transfer of a missed cache block from the frame memory into the pixel cache can be handled simultaneously with the rasterization pipeline executions. Simulation results show that the proposed architecture can achieve a performance gain of about 32 percent compared with the conventional pretexturing architecture and about 7 percent compared to the hierarchical z-buffer visibility scheme","0018-9340;00189340","","10.1109/TC.2006.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1650199","Computer graphics;cache memories;graphics processors;visible/surface algorithms.","Computer architecture;Computer displays;Computer graphics;Hardware;Information retrieval;Layout;Pipelines;Prefetching;Rendering (computer graphics);Testing","cache storage;computer graphic equipment;image resolution;image texture;rendering (computer graphics)","3D rendering processor;3D scene complexity;cache miss penalty;data prefetch operation;data retrieval;frame memory;hardware logics;hierarchical z-buffer visibility scheme;pixel cache block;pretexturing architecture;rasterization pipeline;visibility culling method","","3","","19","","","Aug. 2006","","IEEE","IEEE Journals & Magazines"
"Fighting the Semantic Gap on CBIR Systems through New Relevance Feedback Techniques","A. J. M. Traina; J. Marques; C. Traina","University of S&#227;o Paulo at S&#227;o Carlos , Brazil","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","881","886","This paper introduces two novel relevance feedback techniques that integrate a new way to implement the query center movement with a suitable weighting on the similarity function. These techniques integrated to a content-based image retrieval (CBIR) system, improves the precision of the results when using texture features up to 42%, and employing at most 5 iterations. Thus, the user satisfaction with the system is increased as our experiments demonstrated. Besides being effective, the new RF techniques are very fast as they take less than one second to reprocess the queries at each iteration. The experiments also show that with three iterations the users are satisfied with the query results, and the major gain in precision happens in the first iteration, achieving improvements of up to 30%, what lessens the user efforts and anxiety","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647681","","Computer science;Content based retrieval;Data mining;Feature extraction;Feedback;Humans;Image analysis;Image retrieval;Information retrieval;Radio frequency","content-based retrieval;image retrieval;relevance feedback","CBIR systems;content-based image retrieval;query center movement;relevance feedback;semantic gap","","6","","10","","","0-0 0","","IEEE","IEEE Conference Publications"
"Building a Navigation Structure from a Fuzzy Relationship for Image Retrieval","E. Loisant; J. Martinez; H. Ishikawa; M. Ohta; K. Katayama","ATLAS Team, INRIA and IRIN/BaDRI","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1179","1179","Going one step further feedback querying in integrating user into retrieval process, navigation is the more recent approach to find images in a large image collection using contentbased information. However, while properties extracted from images are usually fuzzy data, most of the time a navigation structure will deal with binary links from an image (or a group of images) to another. A trivial solution to get a binary relationship from fuzzy data is to apply a threshold, but this solution not only leads to a loss of information but fails to distinguish noise from interesting elements. In this paper, we propose two techniques to eliminate isolated elements and lead to a structure made of more compact subparts. The first one is based on a variable threshold depending on the number of neighbours. The second one, specific to Galois lattice, is based on taking into account the existing navigation structure for binarisation of descriptions. Experiments showed that it improves the resulting structure by reducing the number of nodes without loosing information on image description, thus improving user experience.","","POD:0-7695-2657-8","10.1109/ICDE.2005.201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647785","","Buildings;Content based retrieval;Feedback;Image retrieval;Information retrieval;Lattices;Navigation;Noise reduction;Proposals;User interfaces","","","","0","","12","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"A Study of Performance Improvement for Video Retrieval System Based on Relevance Feedback","Y. Fujisaki; T. Miyata; A. Kobayashi; K. Yamaoka; Y. Sakai; Y. Inazumi","Tokyo Institute of Technology","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1234","1234","Recently, an effective retrieval system for video data based on its content is required. In such system, queries are given by natural video data or drawing sketches. However, preparing natural video data and drawing sketches require high operating costs for users. Therefore, we proposed novel method that uses ""Relevance Feedback(RF)"" for creating query. RF is an approach that is used in general information retrieval. RF allows us to give a query to the system by simple operation. Then, we performed an experiment to retrieve video data by using the system that uses the method. The experimental results lead us to conclude that the system is effective at reducing a users operating costs. Furthermore, we show the future direction for research.","","POD:0-7695-2657-8","10.1109/ICDE.2005.173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647851","","Content based retrieval;Costs;Data engineering;Data mining;Engineering drawings;Feedback;Histograms;Information retrieval;Radio frequency;User interfaces","","","","0","","6","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"On Small World Graphs in Non-uniformly Distributed Key Spaces","S. Girdzijauskas; A. Datta; K. Aberer","Federale de Lausanne (EPFL), Switzerland","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1187","1187","In this paper we show that the topologies of most logarithmic-style P2P systems like Pastry, Tapestry or P-Grid resemble small-world graphs. Inspired by Kleinbergs small-world model [7] we extend the model of building ""routing-efficient"" small-world graphs and propose two new models. We show that the graph, constructed according to our model for uniform key distribution and logarithmic outdegree, will have similar properties as the topologies of structured P2P systems with logarithmic outdegree. Moreover, we propose a novel model of building graphs which support uneven node distributions and preserves all desired properties of Kleinbergs small-world model. With such a model we are setting a reference base for nowadays emerging P2P systems that need to support uneven key distributions.","","POD:0-7695-2657-8","10.1109/ICDE.2005.254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647799","Distributed Hash Tables;Routing;Small-World graphs;Storage Load Balancing","Bandwidth;Buildings;Costs;Data engineering;Data processing;Information retrieval;Load management;Routing;Scalability;Topology","","Distributed Hash Tables;Routing;Small-World graphs;Storage Load Balancing","","12","","19","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Implementation of a programmable array processor architecture for approximate string matching algorithms on FPGAs","P. D. Michailidis; K. G. Margaritis","Dept. of Appl. Informatics, Macedonia Univ., Thessaloniki, Greece","Proceedings 20th IEEE International Parallel & Distributed Processing Symposium","20060626","2006","","","4 pp.","","Approximate string matching problem is a common and often repeated task in information retrieval and bioinformatics. This paper proposes a generic design of a programmable array processor architecture for a wide variety of approximate string matching algorithms to gain high performance at low cost. Further, we describe the architecture of the array and the architecture of the cell in detail in order to efficiently implement for both the preprocessing and searching phases of most string matching algorithms. Further, the architecture performs approximate string matching for complex patterns that contain don't care, complement and classes symbols. We also implement and evaluate the proposed architecture on a field programmable gate array (FPGA) device using the JHDL tool for synthesis and the Xilinx Foundation tools for mapping, placement, and routing. Finally, our programmable implementation achieves about 9-340 times faster than a desktop computer with a Pentium 4 3.5 GHz for all algorithms when the length of the pattern is 1024","1530-2075;15302075","POD:1-4244-0054-6","10.1109/IPDPS.2006.1639474","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639474","","Algorithm design and analysis;Bioinformatics;Computer architecture;Costs;Field programmable gate arrays;Information retrieval;Pattern matching;Performance gain;Phased arrays;Routing","field programmable gate arrays;microprocessor chips;string matching","FPGA architecture;JHDL tool;Xilinx Foundation tools;approximate string matching algorithms;desktop computer","","0","","13","","","25-29 April 2006","","IEEE","IEEE Conference Publications"
"Static and Dynamic Scoring by Web Page Grouping","H. Nakakubo; T. Sato","Osaka Kyoiku University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1258","1258","Web Search System exists to retrieve necessary information on the WWW space. However, these are not accuracy enough. Then, we propose the technique for using Web Page Grouping together with the link structure analysis, and aim at the improvement in accuracy. Our proposal is composed of four techniques. The first technique is Web Page Grouping to enhance it related to adjacent the link structure. The second technique is static scoring by link structure analysis using Web Page Grouping. The third technique is dynamic scoring which tempers the link structure analysis of the retrieval result set with Web Page Grouping. And, the fourth technique is a ranking technique for annexing a static score and a dynamic score. This paper describes these techniques, and reports on the experiment results.","","POD:0-7695-2657-8","10.1109/ICDE.2005.290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647875","","Data mining;HTML;Information processing;Information retrieval;Information science;Internet;Proposals;Web pages;Web search;World Wide Web","","","","0","1","9","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Geometric Hashing with Local Affine Frames","O. Chum; J. Matas","Czech Technical University in Prague, Czech Republic","2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)","20060705","2006","1","","879","884","We propose a novel representation of local image structure and a matching scheme that are insensitive to a wide range of appearance changes. The representation is a collection of local affine frames that are constructed on outer boundaries of maximally stable extremal regions (MSERS) in an affine-covariant way. Each local affine frame is described by a relative location of other local affine frames in its neighborhood. The image is thus represented by quantities that depend only on the location of the boundaries of MSERs. Inter-image correspondences between local affine frames are formed in constant time by geometric hashing. Direct detection of local afine frames removes the requirement of a point-based hashing to establish reference frames in a combinatorial way, which has in the case of affine transform complexily that is cubic in the number of points. Local affine frames, which are also the quantities represented in the hash table, occupy a 6 0 space and hence data collisions are less likely compared with 2 0 point hashing. Experimentally, the robustness of the method and its insensitiviq to photometric changes is demonstrated on images from different spectral bands of satellite sensor; on images of a transparent object and on images of an object taken during day and night.","1063-6919;10636919","POD:0-7695-2597-0","10.1109/CVPR.2006.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640845","","Application software;Computer vision;Image recognition;Image retrieval;Information retrieval;Object recognition;Photometry;Real time systems;Robustness;Satellites","","","","14","2","21","","","17-22 June 2006","","IEEE","IEEE Conference Publications"
"Efficient Retrieval of DNA Sequences Using Multi-way Clustering","Sungmin Joo; M. Toyama","Department of Information and Computer Science,Keio University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1262","1262","A retrieval on large DNA sequence data is very important in bioinformatics. However, it takes much time to search and comparison on large DNA sequence data. In this paper, we propose multi-way clustering for improving both the speed of retrieval and implement them. The result shows that multi-way clustering is a more efficient approach for retrieval of DNA sequence.","","POD:0-7695-2657-8","10.1109/ICDE.2005.215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647879","","Bioinformatics;Clustering algorithms;DNA computing;Databases;Genetics;Heuristic algorithms;Humans;Information analysis;Information retrieval;Sequences","","","","0","","11","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"MPI-IO/L: efficient remote I/O for MPI-IO via logistical networking","Jonghyun Lee; R. Ross; S. Atchley; M. Beck; R. Thakur","Math. & Comput. Sci. Div., Argonne Nat. Lab., IL, USA","Proceedings 20th IEEE International Parallel & Distributed Processing Symposium","20060626","2006","","","10 pp.","","Scientific applications often need to access remotely located files, but many remote I/O systems lack standard APIs that allow efficient and direct access from application codes. This work presents MPI-IO/L, a remote I/O facility for MPI-IO using logistical networking. This combination not only provides high-performance and direct remote I/O using the standard parallel I/O interface but also offers convenient management and sharing of remote files. We show the performance trade-offs with various remote I/O approaches implemented in the system, which can help scientists identify preferable I/O options for their own applications. We also discuss how logistical networking could be improved to work better with parallel I/O systems such as ROMIO.","1530-2075;15302075","POD:1-4244-0054-6","10.1109/IPDPS.2006.1639305","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639305","","Bandwidth;Code standards;Costs;Fault tolerance;Information management;Information retrieval;Intelligent networks;Laboratories;Libraries;Testing","file organisation;input-output programs","MPI-IO/L;logistical networking;parallel I/O interface;remote I/O systems;remote file management;remote file sharing","","0","","16","","","25-29 April 2006","","IEEE","IEEE Conference Publications"
"High-Dimensional Similarity Searches Using A Metric Pseudo-Grid","C. Digout; M. A. Nascimento","Univ. of Alberta, Canada","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1174","1174","Despite the proposal of numerous tree-based access structures for high dimensional similarity searches, techniques based on a sequential scan have been shown to be simple yet quite efficient alternatives. Given that random accesses to disk are expensive, a linear scan of the (smaller) pre-processed dataset is often much more efficient than even a relatively small number of random disk accesses yielded by tree-based indices. In this paper we present a technique which uses a pseudo-partition of a general metric space analog to the VA-files partition of the vector space. The rationale is to use a number of pivot objects in the metric space, each one determining a number of hyper-rings in this space. The intersection of those rings, determine pseudo-cells analog to the VA-file cells in the vector space. In order to speedup query processing the data set is clustered (using any applicable clustering technique). Clusters not intersecting cells intersected by the query region cannot contribute to the answer set. Thus, only a few clusters are searched using an I/O efficient linear scan of the clusters data. The proposed technique, which we call the M-GRID, is, by construction, applicable to both general metric spaces and to traditional vector spaces as long as a metric distance function is used. The M-GRID is robust to several parameters and experiments with synthetic and real data sets show that it is able to perform nearest neighbor queries up to 10 times faster than the VA-File.","","POD:0-7695-2657-8","10.1109/ICDE.2005.226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647780","","Clustering algorithms;Extraterrestrial measurements;Indexing;Information retrieval;Nearest neighbor searches;Proposals;Protein sequence;Query processing;Robustness;Vectors","","","","4","","23","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"SemPub: An Ontology Based Semantic Literature Retrieval System","R. Loganantharaj; V. B. Narayan","University of Louisiana at Lafayette, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","875","880","The World Wide Web has grown exponentially and has become the most pervasive source of information in the last few years. Since most of this information is scattered and heterogeneous in nature, efficient and accurate retrieval of literature on the Web is a challenging area of research. Most of the time the users are not aware of what they are looking for or they have an abstract view of what they want. Modern search engines help them narrow their search but are not sophisticated enough to understand their needs. The semantic Web is a vision of next generation World Wide Web where the information is defined with an explicit meaning, which machines can understand, process and integrate without human intervention. SemPub centers on semantic retrieval and user customization. In semantic search, we search for terms in a concept space (a graph of terms occurring in documents linked to each other by the frequency and relationships between them and with which they occur together). Hence by reducing the high dimensional and complex object space into a more manageable automatically-generated, meaningful concept space, customized retrieval and information routing is made easy","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647680","","Frequency;Humans;Information resources;Information retrieval;Ontologies;Routing;Scattering;Search engines;Semantic Web;Web sites","Internet;information retrieval;ontologies (artificial intelligence);search engines","SemPub;World Wide Web;ontology;search engines;semantic Web;semantic literature retrieval system","","0","","18","","","0-0 0","","IEEE","IEEE Conference Publications"
"Semantic Matching to Achieve Web Service Discovery and Composition","R. Akkiraju; A. Ivan; R. Goodwin; B. Srivastava; T. Syeda-Mahmood","IBM T. J. Watson Research Center, NY","The 8th IEEE International Conference on E-Commerce Technology and The 3rd IEEE International Conference on Enterprise Computing, E-Commerce, and E-Services (CEC/EEE'06)","20060710","2006","","","70","70","In this paper, we present a novel algorithm to discover and compose Web services in the presence of semantic ambiguity by combining semantic matching and AI planning algorithms. Specifically, we use cues from domain-independent and domain-specific ontologies to compute an overall semantic similarity score between ambiguous terms. This semantic similarity score is used by AI planning algorithms to guide the searching process when composing services. In addition, we integrate semantic and ontological matching with an indexing method, which we call attribute hashing, to enable fast lookup of semantic ally related concepts","2378-1963;23781963","POD:0-7695-2511-3","10.1109/CEC-EEE.2006.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640325","","Artificial intelligence;Drives;Indexing;Information retrieval;Laboratories;Ontologies;Process planning;Service oriented architecture;Thesauri;Web services","Web services;ontologies (artificial intelligence);planning (artificial intelligence)","AI planning;Web service composition;Web service discovery;domain-independent ontologies;domain-specific ontologies;indexing method;ontological matching;semantic matching;semantic similarity score","","3","","6","","","26-29 June 2006","","IEEE","IEEE Conference Publications"
"Relevance Feedback Query Refinement for PDF Medical Journal Articles","A. Christiansen; D. J. Lee","Brigham Young University, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","57","62","This paper addresses relevance feedback as an alternative to keyword-based search engines for sifting through large PDF document collections and extracting the most relevant documents (especially for literature review purposes). Until now, relevance feedback has only been used in content-based image and video retrieval due to the inability to query those media types without keywords. Since PDF journal articles contain many valuable non-keyword features such as structure and formatting information as well as embedded figures, they would benefit from relevance feedback. Stripping a PDF into ""full-text"" for indexing purposes disregards these important features. We discuss how they can be used to our advantage and look to integrate the wealth of knowledge from relevance feedback text-based information retrieval. We argue for the benefits of placing the burden of relevance judgement on the user rather than the retrieval system and present alternative document views that quickly allow the user to deem relevance","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647546","","Biomedical imaging;Content based retrieval;Data mining;Feature extraction;Feedback;Frequency;Image retrieval;Indexing;Information retrieval;Search engines","medical information systems;relevance feedback","content-based image;medical journal articles;relevance feedback query refinement;relevance feedback text-based information retrieval;video retrieval","","2","","10","","","0-0 0","","IEEE","IEEE Conference Publications"
"Musical Genre Classification VIA Generalized Gaussian and Alpha-Stable Modeling","C. Tzagkarakis; A. Mouchtaris; P. Tsakalides","Department of Computer Science, University of Crete and Institute of Computer Science (FORTH-ICS), 711 10 Heraklion, Crete, Greece","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","5","","V","V","This paper describes a novel methodology for automatic musical genre classification based on a feature extraction/statistical similarity measurement approach. First, we perform a 1-D wavelet decomposition of the music signal and we model the resulting subband coefficients using the generalized Gaussian density (GGD) and the alpha-stable distribution. Subsequently, the GGD and alpha-stable distribution parameters are estimated during the feature extraction step, while the similarity between two music signals is measured by employing the Kullback-Leibler divergence (KLD) between their corresponding estimated wavelet distributions. We evaluate the performance of the proposed methodology by using a dataset consisting of six different musical genre sets","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1661251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1661251","","Computer science;Feature extraction;Iron;Multimedia databases;Multiple signal classification;Music information retrieval;Parameter estimation;Samarium;Wavelet coefficients;Wavelet transforms","Gaussian processes;audio signal processing;feature extraction;music;signal classification;statistical analysis;wavelet transforms","Kullback-Leibler divergence;alpha-stable modeling;feature extraction;generalized Gaussian density;musical genre classification;statistical similarity measurement approach;wavelet decomposition;wavelet distributions","","2","","10","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Video Classification Using Normalized Information Distance","K. Kaabneh; A. Abdullah; Z. Al-Halalemah","Amman Arab University for Graduate Studies, Jordan","Geometric Modeling and Imaging--New Trends (GMAI'06)","20060724","2006","","","34","40","There has been a vast collection of multimedia resources on the net. This has opened an opening for researchers to explore and advance the science in the field of research in storing, handling, and retrieving digital videos. Video classification and segmentation are fundamental steps for efficient accessing; retrieving, browsing and compressing large amount of video data. The basic operation video analysis is to design a system that can accurately and automatically segments video material into shots and scenes. This paper presents a detailed video segmentation technique based on pervious researches which lacks performance and since some of the videos is stored in a compressed form using the normalized information distance (NID) which approximates the value of a theoretical distance between objects using the Kolmogrov complexity theory. This technique produced a better result in reference to performance, high recall of 95.5% and a precision of 89.7%","","POD:0-7695-2604-7","10.1109/GMAI.2006.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648741","Kolmogorov;Normalized Information Distance.;Shot-Boundary Detection;complexity","Cameras;Complexity theory;Computer science;Educational institutions;Image coding;Image segmentation;Information retrieval;Layout;Pixel;Video compression","computational complexity;content-based retrieval;image classification;image segmentation;indexing;video coding;video retrieval","Kolmogrov complexity theory;digital video retrieval;digital video storage;multimedia resource collection;normalized information distance;shot-boundary detection;video browsing;video classification;video compression;video segmentation","","4","","10","","","16-18 Aug. 1993","","IEEE","IEEE Conference Publications"
"A multimedia user preference model that supports semantics and its application to MPEG 7/21","C. Tsinaraki; S. Christodoulakis","TUC/MUSIC, Germany","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","8 pp.","","Semantic interoperability is usually provided in open environments through standards and domain ontology. The dominant standards for multimedia content and service descriptions are MPEG-7 and MPEG-21. The MPEG-7 semantic DS has powerful semantic description capabilities and supports using semantic entities specified in domain ontology in multimedia content descriptions. However, the MPEG-7/21 usage environment allows neither the specification of semantic user preferences nor the exploitation of domain knowledge and MPEG-7 semantic metadata descriptions. In addition, the users cannot explicitly specify, in the hierarchical MPEG-7/21 filtering and search preferences, the Boolean operators that should be used during content filtering to combine the hierarchy components. We think these as serious limitations and we propose a hierarchical semantic user preference model that allows for the explicit specification of Boolean operators. Then, we present the application of the model in MPEG-7/21 and the model implementation within the DS-MIRF framework","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651299","","Context modeling;Context-aware services;Filtering;Information retrieval;MPEG 7 Standard;Multiple signal classification;OWL;Ontologies;Software libraries;TV","Boolean algebra;multimedia computing;open systems;video coding","Boolean operators;DS-MIRF framework;MPEG 7/21;hierarchical semantic user preference model;multimedia content;multimedia user preference model;semantic interoperability;service descriptions","","8","","17","","","0-0 0","","IEEE","IEEE Conference Publications"
"A new efficient algorithm for analyzing and optimizing the system of sensors","A. Fijany; F. Vatan","Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA","2006 IEEE Aerospace Conference","20060724","2006","","","8 pp.","","In this paper, we propose a new algorithmic approach for design of a sensor system that maximizes the diagnosability of the system and minimizes the cost of the sensor placement. This approach also allows us to analyze extend of the coverage of the sensor system and to determining its diagnosability degree. The quality and efficiency of a diagnosis system depends on the availability and relevance of the information it can retrieve from the diagnosed plant. The quality of the measurements is expressed by the diagnosability degree, i.e., given a set of sensors, which faults can be discriminated? There is no straightforward relation between the number of sensors and diagnosability of the systems; increasing the number of sensors alone does not guarantee a higher level of diagnosability. The relevance of information provided by an additional sensor and its correlation with information provided by other sensors must also be taken into account. Besides the issue of diagnosability, we also consider economics issues. We must provide a sensor system that achieves a desired degree of diagnosability at the lowest possible cost. Our new algorithmic approach allows us to find efficient solutions for these two important problems regarding the system of sensors. The first problem is to analyze and certify the sensor system. Here the main problem is to determine the diagnosability degree of the system, i.e., characterize the set of the faults that can be discriminated. Our method also determines an optimal set of new sensors that needs to be added to the system to enhance its diagnosability. The second issue is the optimization problem of sensor placement. In this regard, the main questions are as follows. (1) Minimal sensor set: finding a minimal additional sensor set that guarantees a specific degree of diagnosability. (2) Minimal cost sensors: in the case that different sensors are assigned with different costs, finding the minimal cost additional sensors which achieve a specifi- - c degree of diagnosability. The primary application of this method is at the design level where the number and position of sensors are not known. Our new approach for solving these problems is motivated by our successful method for solving the diagnosis problem. For sensor placement, we start by observing that it can be mapped onto a 0-1 IP problem. The objective function, in the most general case, is not linear, but the constraints are linear and defined by a 0-1 matrix. For the sensor placement problem, we start with the structural model of the system. The structure analysis of the system and the potential information carried by each sensor provide a set of relations usually called the analytical redundant relations (ARRs). We can also consider the additional sensors (the potential sensors that will provide the desired degree of diagnosability) and their corresponding ARRs. The information of all these ARRs can be summarized in a signature matrix. Then the above sensor optimization problems can be formulated as combinatorial problem regarding the signature matrix, or as integer programming problem involving this matrix. The existing methods for solving these combinatorial problems usually boil down to exhaustive search methods. For solving the diagnosis problem, we have found a new branch-and-bound technique which has achieved order of magnitude speedup over the standard algorithms. Combination of this new algorithm and the ARR approach would provide a powerful efficient technique for solving the difficult problem of sensor placement optimization. We have developed a Mathematica code for validating and benchmarking this algorithm","1095-323X;1095323X","POD:0-7803-9545-X","10.1109/AERO.2006.1656119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1656119","","Algorithm design and analysis;Biosensors;Costs;Information analysis;Information retrieval;Laboratories;Linear programming;Propulsion;Sensor phenomena and characterization;Sensor systems","fault diagnosis;integer programming;mathematics computing;sensors;tree searching","Mathematica code;additional sensors;algorithmic approach;analytical redundant relations;branch-and-bound technique;combinatorial problem;diagnosability degree;diagnosis problem;integer programming;minimal cost sensors;minimal sensor set;sensor optimization problems;sensor placement;sensor system;signature matrix;structural model;structure analysis","","7","1","11","","","0-0 0","","IEEE","IEEE Conference Publications"
"Semantic image retrieval and auto-annotation by converting keyword space to image space","E. Celebi; A. Alpkocak","Dept. of Comput. Eng., Dokuz Eylul Univ., Izmir, Turkey","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","8 pp.","","In this paper, we propose a novel strategy at an abstract level by combining textual and visual clustering results to retrieve images using semantic keywords and auto-annotate images based on similarity with existing keywords. Our main hypothesis is that images that fall in to the same text-cluster can be described with common visual features of those images. In order to implement this hypothesis, we set out to estimate the common visual features in the textually clustered images. When given an un-annotated image, we find the best image match in the different textual clusters by processing their low-level features. Experiments have demonstrated that good accuracy of proposal and its high potential use in annotation of images and for improvement of content based image retrieval","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651315","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651315","","Content based retrieval;Disaster management;Image converters;Image recognition;Image retrieval;Image segmentation;Information retrieval;Internet;Proposals;Shape","content-based retrieval;image retrieval;pattern clustering","auto-annotation;content based image retrieval;image space;keyword space;semantic image retrieval;semantic keyword;textual clustering;textually clustered image;visual clustering","","4","","15","","","0-0 0","","IEEE","IEEE Conference Publications"
"Integrating User Feedback Log into Relevance Feedback by Coupled SVM for Content-Based Image Retrieval","S. C. H. Hoi; M. R. Lyu; Rong Jin","The Chinese University of Hong Kong","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1177","1177","Relevance feedback has been shown as an important tool to boost the retrieval performance in content-based image retrieval. In the past decade, various algorithms have been proposed to formulate relevance feedback in contentbased image retrieval. Traditional relevance feedback techniques mainly carry out the learning tasks by focusing lowlevel visual features of image content with little consideration on log information of user feedback. However, from a long-term learning perspective, the user feedback log is one of the most important resources to bridge the semantic gap problem in image retrieval. In this paper we propose a novel technique to integrate the log information of user feedback into relevance feedback for image retrieval. Our algorithms construction is based on a coupled support vector machine which learns consistently with the two types of information: the low-level image content and the user feedback log. We present a mathematical formulation of the problem and develop a practical algorithm to solve the problem effectively. Experimental results show that our proposed scheme is effective and promising.","","POD:0-7695-2657-8","10.1109/ICDE.2005.233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647783","","Bridges;Computer science;Content based retrieval;Feature extraction;Focusing;Image retrieval;Information retrieval;Multimedia databases;State feedback;Support vector machines","","","","3","","35","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"An Automatic Extraction Method of Time-Series Impression-Metadata for Color Information of Video Streams","N. Miura; S. Kurabayashi; Y. Kiyoki","Faculty of Policy Management,Keio University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1233","1233","In this paper, we present a metadata extraction method for temporal transitional impression of video streams. The main feature of our method is automatic extraction of timeseries impression-metadata, which represent temporal transitional impressions according to color information. In our method, users can intuitively search various video streams regarding color information on the basis of abstract impression preference. In this paper, we also show the feasibility of our method by several experimental results.","","POD:0-7695-2657-8","10.1109/ICDE.2005.187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647850","","Atomic layer deposition;Data mining;Environmental management;Feature extraction;Information retrieval;Layout;Spatial databases;Streaming media;Transaction databases;Video compression","","","","0","","9","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Efficient Rotation Invariant Retrieval of Shapes with Applications in Medical Databases","S. Chu; S. Narayanan; C. C. J. Kuo","University of Southern California, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","673","678","Recognition of shapes in images is an important problem in computer vision with application in various medical problems, including robotic surgery and cell analysis. The similarity measures for such purpose must be robust to various transformations and modest occlusions. Transformations, such as scaling and translation can be handled easily by techniques through data representations or similarity measures. Rotation invariance is an inherently more difficult problem and can be handled through data representation, but at the expense of poor discrimination. Approaches which provide excellent discrimination require a complexity of O(n<sup>3</sup>) for each shape comparison. In this paper, we present a framework that provides a speedup over the slow but accurate approaches. The algorithm is inspired by the iterative deepening framework in artificial intelligence, by examining the data at increasingly fine levels of approximation until it is either considered irrelevant or submits to the full calculations. Although we examine the data several times at different levels of abstractions, because the time required for the last iteration dwarfs all others, this apparent redundancy is inconsequential. We show that our method provides at least a 3-4 orders of magnitude in speedup without generating any false dismissals","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647648","","Application software;Biomedical imaging;Computer vision;Image databases;Image recognition;Information retrieval;Medical robotics;Robot vision systems;Shape;Surgery","computational complexity;computer graphics;computer vision;data structures;database management systems;image matching;medical computing","artificial intelligence;computer vision;data representations;medical databases;occlusions;rotation invariant retrieval;shape recognition;similarity measures","","0","","21","","","22-23 June 2006","","IEEE","IEEE Conference Publications"
"Auto-Adaptive Questions in E-Learning System","E. Lazcorreta; F. Botella; A. Fernandez-Caballero; J. M. Gascuena","Universidad Miguel Hern&#225;ndez de Elche, Spain","Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)","20060724","2006","","","270","274","All books entitled ""Learn ... with 1000 exercises"" have in common the same basic principle. They aim to supply enough material to students so that they may better understand the studied subject, starting from their own practice. If there is no instructor who helps students during the reading of the book, the students will not be able to understand the subject, as the excessive amount of information provided in this kind of books does not enable learners to pursue the learning goals. There is a great boom in e-learning through the so-called intelligent tutoring systems, excellent virtual instructors which guide their learners through the reading of such kinds of books and help their learners to classify all the exercises and recommend them which ones to solve first. Nowadays instructors and teachers are entrusted to produce these books and to classify all exercises, whatever implies an overload to teachers. In this work we introduce a scalable system that only requires teachers to write the questions and their answers. The system will classify and manage all the questions. So the teacher will obtain, with the minimal effort, hundreds of exercises at the end of the course (and for future courses) which will reinforce individually his students","2161-3761;21613761","POD:0-7695-2632-2","10.1109/ICALT.2006.1652422","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652422","","Books;Computer science;Electronic learning;Information retrieval;Intelligent systems;Operations research;Proposals;Rhythm;Technology management","intelligent tutoring systems","auto-adaptive questions;e-learning system;intelligent tutoring systems;virtual instructors","","0","","6","","","5-7 July 2006","","IEEE","IEEE Conference Publications"
"Semantic Data Extraction for B2B Integration","B. Silva; J. Cardoso","University of Madeira, Funchal, Portugal","26th IEEE International Conference on Distributed Computing Systems Workshops (ICDCSW'06)","20060724","2006","","","16","16","Business-to-business (B2B) data exchange and integration is a common daily operation in todays organizations. These operations are crucial since they affect organizations capability to compete in todays marketplace. Data exchange and integration has been proven to be a challenge due to the heterogeneity of the information systems involved.""This paper described a Syntactic-to-Semantic (S2S) middleware which, when based on a single query, integrates data residing in different data sources possibly with different formats, structures, schema, and semantics. The middleware uses an ontology-based multi-source data extractor/wrapper approach to transform syntactic data into semantic knowledge.","1545-0678;15450678","POD:0-7695-2541-5","10.1109/ICDCSW.2006.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648906","","Computer architecture;Data engineering;Data mining;Information management;Information retrieval;Information systems;Mathematics;Middleware;OWL;Ontologies","","","","0","","10","","","04-07 July 2006","","IEEE","IEEE Conference Publications"
"Semantic Learning for Audio Applications: A Computer Vision Approach","R. Sukthankar; Yan Ke; D. Hoiem","Intel Research Pittsburgh, Carnegie Mellon","2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)","20060705","2006","","","112","112","Recent work in machine learning has significantly benefited semantic extraction tasks in computer vision, particularly for object recognition and image retrieval. We argue that the computer vision techniques that have been successfully applied in those settings can effectively be translated to other domains, such as audio. This claim is supported by recent results in music vs. speech classification, structure from sound, robust music identification and sound object recognition. This paper focuses on two such audio applications and demonstrates how ideas from computer vision map naturally to these problems.","2160-7508;21607508","POD:0-7695-2646-2","10.1109/CVPRW.2006.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640555","","Acoustic noise;Application software;Computer vision;Image analysis;Machine learning;Music information retrieval;Object detection;Object recognition;Robustness;Speech analysis","","","","2","","36","","","17-22 June 2006","","IEEE","IEEE Conference Publications"
"Color-based descriptors for image fingerprinting","M. A. Gavrielides; E. Sikudova; I. Pitas","Dept. of Inf., Aristotelian Univ. of Thessaloniki, Greece","IEEE Transactions on Multimedia","20060717","2006","8","4","740","748","Typically, content-based image retrieval (CBIR) systems receive an image or an image description as input and retrieve images from a database that are similar to the query image in regard to properties such as color, texture, shape, or layout. A kind of system that did not receive much attention compared to CBIR systems, is one that searches for images that are not similar but exact copies of the same image that have undergone some transformation. In this paper, we present such a system referred to as an image fingerprinting system, since it aims to extract unique and robust image descriptors (in analogy to human fingerprints). We examine the use of color-based descriptors and provide comparisons for different quantization methods, histograms calculated using color-only and/or spatial-color information with different similarity measures. The system was evaluated with receiver operating characteristic (ROC) analysis on a large database of 919 original images consisting of randomly drawn art images and similar images from specific categories, along with 30 transformed images for each original, totaling 27570 images. The transformed images were produced with attacks that typically occur during digital image distribution, including different degrees of scaling, rotation, cropping, smoothing, additive noise and compression, as well as illumination contrast changes. Results showed a sensitivity of 96% at the small false positive fraction of 4% and a reduced sensitivity of 88% when 13% of all transformations involved changing the illuminance of the images. The overall performance of the system is encouraging for the use of color, and particularly spatial chromatic descriptors for image fingerprinting","1520-9210;15209210","","10.1109/TMM.2006.876290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1658036","Color histogram;color quantization;image fingerprinting;image indexing;image representation;retrieval;spatial chromatic histogram","Content based retrieval;Data mining;Fingerprint recognition;Humans;Image databases;Image retrieval;Information retrieval;Quantization;Robustness;Shape","content-based retrieval;fingerprint identification;image representation;image retrieval","color-based descriptors;content-based image retrieval system;digital image distribution;image fingerprinting system;quantization methods;query image;receiver operating characteristic analysis","","9","1","17","","","Aug. 2006","","IEEE","IEEE Journals & Magazines"
"Web-based visualization of 3D geospatial data using Java3D","G. Hobona; P. James; D. Fairbairn","Newcastle upon Tyne Univ., UK","IEEE Computer Graphics and Applications","20060710","2006","26","4","28","33","Spatial database servers allow for the storage and access of 3D geospatial data using open geospatial consortium standards. The Geospatial Database Online Visualization Environment (GeoDOVE) is a prototype 3D Web-based geographic information system that demonstrates how Java3D can reduce bandwidth and allow direct connectivity to spatially enabled database systems. We've developed GeoDOVE, a Java3D-based prototype system that retrieves geospatial data from conventional spatial database servers, allows modification of the visualization during runtime, and lets users remotely modify attributes using the structured query language (SQL)","0272-1716;02721716","","10.1109/MCG.2006.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652923","Geovisualization;Java;RDBMS;visualization","Bandwidth;Data visualization;Database systems;Geographic Information Systems;Information retrieval;Java;Prototypes;Runtime;Spatial databases;Visual databases","Internet;SQL;data visualisation;geographic information systems;visual databases","3D Web-based geographic information system;3D geospatial data;GeoDOVE;Geospatial Database Online Visualization Environment;Java3D-based prototype system;SQL;Web-based visualization;open geospatial consortium standard;spatial database server;structured query language","","5","","9","","","July-Aug. 2006","","IEEE","IEEE Journals & Magazines"
"A Robust Perceptual Audio Hashing using Balanced Multiwavelets","L. Ghouti; A. Bouridane","School of Computer Science, Queen's University of Belfast, Belfast BT7 1NN, UK. Email: LGhouti01@qub.ac.uk","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","5","","V","V","Digital multimedia content (especially audio) is becoming a major part of the average computer user experience. Large digital audio collections of music, audio and sound effects are also used by the entertainment, music, movie and animation industries. Therefore, the need for identification and management of audio content grows proportionally to the increasing widespread availability of such media virtually ""any time and any where"" over the Internet. In this paper, we propose a novel framework for robust perceptual hashing of audio content using balanced multiwavelets (BMW). The framework for generating robust perceptual hash values (or fingerprints) is described. The generated hash values are used for identifying, searching, and retrieving audio content from large audio databases. Furthermore, we illustrate, through extensive computer simulation, the robustness of the proposed framework to efficiently represent audio content and withstand several signal processing attacks and manipulations","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1661249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1661249","","Animation;Audio databases;Content based retrieval;Content management;Fingerprint recognition;Information retrieval;Internet;Motion pictures;Music;Robustness","audio coding;audio databases;cryptography;wavelet transforms","audio content;audio databases;balanced multiwavelets;digital multimedia content;robust perceptual audio hashing;signal processing attacks","","6","","8","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Investigating the Effect of an Attack on a Distributed Database","R. Samara; B. Panda","Dept. of Comput. Sci. & Comput. Eng., Arkansas Univ., Fayetteville, AR","2006 IEEE Information Assurance Workshop","20060710","2006","","","312","317","After an attack on a database system, evaluation of damage must be performed as soon the attack is identified. Otherwise, the initial damage would spread to other parts of the database via valid transactions, consequently resulting in denial-of-service. Damage assessment in a distributed database system is a complicated task due to intricate transaction relationships among distributed sites. In these systems, when any sub-transaction reads a damaged data at any site, the entire transaction of which the sub-transaction is a part, is considered affected by the damage. Hence, the data items updated by that transaction irrespective of sites are also considered damaged. This research focuses on damage assessment procedure for distributed database systems and uses a two-pass algorithm to obtain the final list of affected data items. The advantages of this method are: (1) the process is fully distributed in the sense that every site would execute the same algorithm, (2) the amount of data to be exchanged between the sites is minimized to the list of affected items at each site instead of the entire log, and (3) the local damage assessors can be executed in parallel at their respective sites","","POD:1-4244-0130-5","10.1109/IAW.2006.1652111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652111","","Availability;Computer crime;Data security;Database systems;Distributed databases;Information retrieval;Performance evaluation;Protection;Real time systems;Transaction databases","distributed databases;security of data;transaction processing","damage assessment;denial-of-service;distributed database;intricate transaction relationships;two-pass algorithm","","0","","12","","","21-23 June 2006","","IEEE","IEEE Conference Publications"
"A new paradigm in data intensive computing: Stork and the data-aware schedulers","T. Kosar","Dept. of Comput. Sci., Louisiana State Univ., Baton Rouge, LA, USA","2006 IEEE Challenges of Large Applications in Distributed Environments","20060710","2006","","","5","12","The unbounded increase in the computation and data requirements of scientific applications has necessitated the use of widely distributed compute and storage resources to meet the demand. In a widely distributed environment, data is no more locally accessible and has thus to be remotely retrieved and stored. Efficient and reliable access to data sources and archiving destinations in such an environment brings new challenges. Placing data on temporary local storage devices offers many advantages, but such ""data placements"" also require careful management of storage resources and data movement, i.e. allocating storage space, staging-in of input data, staging-out of generated data, and de-allocation of local storage after the data is safely stored at the destination. Traditional systems closely couple data placement and computation, and consider data placement as a side effect of computation. Data placement is either embedded in the computation and causes the computation to delay, or performed as simple scripts which do not have the privileges of a job. The insufficiency of the traditional systems and existing CPU-oriented schedulers in dealing with the complex data handling problem has yielded a new emerging era: the data-aware schedulers. One of the first examples of such schedulers is the Stork data placement scheduler. In this paper, we discuss the limitations of the traditional schedulers in handling the challenging data scheduling problem of large scale distributed applications; give our vision for the new paradigm in data-intensive scheduling; and elaborate on our case study: the Stork data placement scheduler","","POD:1-4244-0420-7","10.1109/CLADE.2006.1652048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652048","","Bioinformatics;Delay;Distributed computing;Embedded computing;Genomics;Information retrieval;Moore's Law;Network servers;Processor scheduling;Resource management","distributed processing;scheduling;storage allocation;storage management","Stork data placement scheduler;data handling;data placement;data-aware scheduler;data-intensive computing;distributed computing;scientific application;storage resource management","","3","","34","","","0-0 0","","IEEE","IEEE Conference Publications"
"A New Way for Multidimensional Medical Data Management: Volume of Interest (VOI)-Based Retrieval of Medical Images With Visual and Functional Features","J. Kim; W. Cai; D. Feng; H. Wu","Biomed. & Multimedia Inf. Technol., Univ. of Sydney, NSW","IEEE Transactions on Information Technology in Biomedicine","20060705","2006","10","3","598","607","The advances in digital medical imaging and storage in integrated databases are resulting in growing demands for efficient image retrieval and management. Content-based image retrieval (CBIR) refers to the retrieval of images from a database, using the visual features derived from the information in the image, and has become an attractive approach to managing large medical image archives. In conventional CBIR systems for medical images, images are often segmented into regions which are used to derive two-dimensional visual features for region-based queries. Although such approach has the advantage of including only relevant regions in the formulation of a query, medical images that are inherently multidimensional can potentially benefit from the multidimensional feature extraction which could open up new opportunities in visual feature extraction and retrieval. In this study, we present a volume of interest (VOI) based content-based retrieval of four-dimensional (three spatial and one temporal) dynamic PET images. By segmenting the images into VOIs consisting of functionally similar voxels (e.g., a tumor structure), multidimensional visual and functional features were extracted and used as region-based query features. A prototype VOI-based functional image retrieval system (VOI-FIRS) has been designed to demonstrate the proposed multidimensional feature extraction and retrieval. Experimental results show that the proposed system allows for the retrieval of related images that constitute similar visual and functional VOI features, and can find potential applications in medical data management, such as to aid in education, diagnosis, and statistical analysis","1089-7771;10897771","","10.1109/TITB.2006.872045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1650516","Functional imaging;image segmentation;multidimensional features;region-based image retrieval","Biomedical imaging;Content based retrieval;Feature extraction;Image databases;Image retrieval;Image storage;Information retrieval;Medical diagnostic imaging;Multidimensional systems;Spatial databases","content-based retrieval;feature extraction;image retrieval;image segmentation;medical image processing;medical information systems;positron emission tomography;statistical analysis","content-based image retrieval;digital medical imaging;dynamic PET images;functional image retrieval system;image segmentation;image storage;integrated databases;medical data management;medical image archives;medical images;multidimensional feature extraction;multidimensional medical data management;region-based query feature;statistical analysis;visual feature extraction;volume-of-interest-based image retrieval","","23","","34","","","July 2006","","IEEE","IEEE Journals & Magazines"
"Fault Tolerant Non-trivial Repeating Pattern Discovering for Music Data","Yu-lung Lo; Chun-yu Chen","Chaoyang University of Technology","5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06)","20060724","2006","","","130","135","A non-trivial repeating pattern is commonly used in analyzing the repeated part of a music object and looking for the theme. Non-trivial repeating patterns exclude those patterns included in other longer patterns such that they can reduce the redundancy and speedup music search. So far, existing approaches discover a repeating pattern in such a way that the sequence of notes in a music object appears more than once in exactly matching. If we allow the similar sequences with partial different notes also being a repeating pattern, it can reduce the number of repeating patterns and construct more efficient music indexes. The more accurate music theme also could be analyzed. Therefore, in this paper, we propose a fault-tolerant non-trivial repeating pattern discovering technique. The experimental results show that our approach can not only reduce the number of non-trivial repeating patterns but also improve the hit ratios of queries for music databases","","POD:0-7695-2613-6","10.1109/ICIS-COMSAR.2006.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651981","","Chaos;Content based retrieval;Councils;Fault tolerance;Information analysis;Information management;Multiple signal classification;Music information retrieval;Pattern analysis;Redundancy","audio databases;data mining;database indexing;fault tolerance;music;query processing","fault tolerant nontrivial repeating pattern discovery;music database query;music index;music object;music search;music theme analysis","","1","","19","","","10-12 July 2006","","IEEE","IEEE Conference Publications"
"Fault Tolerance of Tornado Codes for Archival Storage","M. Woitaszek; H. M. Tufo","Colorado Univ., Boulder, CO","2006 15th IEEE International Conference on High Performance Distributed Computing","20060710","2006","","","83","92","This paper examines a class of low density parity check (LDPC) erasure codes called Tornado codes for applications in archival storage systems. The fault tolerance of Tornado code graphs is analyzed and it is shown that it is possible to identify and mitigate worst-case failure scenarios in small (96 node) graphs through use of simulations to find and eliminate critical node sets that can cause Tornado codes to fail even when almost all blocks are present. The graph construction procedure resulting from the preceding analysis is then used to construct a 96-device Tornado code storage system with capacity overhead equivalent to RAID 10 that tolerates any 4 device failures. This system is demonstrated to be superior to other parity-based RAID systems. Finally, it is described how a geographically distributed data stewarding system can be enhanced by using cooperatively selected Tornado code graphs to obtain fault tolerance exceeding that of its constituent storage sites or site replication strategies","1082-8907;10828907","POD:1-4244-0307-3","10.1109/HPDC.2006.1652139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652139","","Analytical models;Availability;Failure analysis;Fault diagnosis;Fault tolerance;Fault tolerant systems;Information retrieval;Parity check codes;Throughput;Tornadoes","RAID;fault tolerant computing;graph theory;parity check codes;storage management","LDPC erasure code;Tornado code graph;archival storage system;distributed data stewarding system;fault tolerance;low density parity check;parity-based RAID system","","2","","15","","","0-0 0","","IEEE","IEEE Conference Publications"
"An advanced positioning algorithm for the optical disc driver","EunHee Kim","LG Electron. Inc., South Korea","IEEE Transactions on Consumer Electronics","20060705","2006","52","2","451","453","An advanced algorithm to improve the performance of the small track jumps in the optical disc driver is suggested. By fitting the track error signal to a sinusoidal function, the relative position of the optical pickup on the disc is estimated. This estimation make it possible to control the track cross velocity to be constant. The experimental results are shown.","0098-3063;00983063","","10.1109/TCE.2006.1649663","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1649663","","Acceleration;Actuators;Bang-bang control;Error correction;Information retrieval;Optical design;Optical recording;Servomechanisms;Target tracking;Velocity control","disc drives;optical disc storage;pick-ups;position control;velocity control","advanced positioning algorithm;optical disc driver;optical pickup;sinusoidal function;small track jumps;track cross velocity control;track error signal tracking","","0","","2","","","May 2006","","IEEE","IEEE Journals & Magazines"
"Distance Functions Association for Content-Based Image Retrieval using Multiple Comparison Criteria","I. R. V. Pola; A. J. M. Traina; C. Traina","University of Sao Paulo at Sao Carlos, Brazil","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","899","904","The comparison operators available in traditional database management systems (DBMS) are not adequate to handle complex data such as images, rather comparing them using similarity operators is the option of choice. Similarity operators need a way to measure the similarity between pairs of objects. Although there are many interesting works dealing with similarity queries and functions to measure similarity, they all rely on a single similarity function that must be applicable over the whole dataset. However, images from medical exams often require several ways to measure similarity, depending on many factors, such as the particular pathological condition being searched, or the existence of specific clinical condition revealed in the images compared. Therefore, the ability to handle several ways to compare images by similarity is important in medical software handling images. This work develop a technique to allow several similarity functions to be combined when indexing a large set of images, allowing queries to probe the dataset regarding distinct comparison criteria. This technique also allows a flexible way to pose queries supporting fast retrieval of the answers","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647684","","Biomedical imaging;Computer science;Content based retrieval;Database systems;Feature extraction;Image retrieval;Indexing;Information retrieval;Particle measurements;Pathology","content-based retrieval;image retrieval;medical image processing","content-based image retrieval;distance functions association;medical software handling images;multiple comparison criteria","","0","","10","","","0-0 0","","IEEE","IEEE Conference Publications"
"JIRiSS - an Eclipse plug-in for Source Code Exploration","D. Poshyvanyk; A. Marcus; Yubo Dong","Wayne State University","14th IEEE International Conference on Program Comprehension (ICPC'06)","20060626","2006","","","252","255","JIRiSS (information retrieval based software search for Java) is a software exploration tool that uses an indexing engine based on an information retrieval method. JIRiSS is implemented as a plug-in for Eclipse and it allows the user to search Java source code for the implementation of concepts formulated as natural language queries. The results of the query are presented as a ranked list of software methods or classes, ordered by the similarity to the user query. In addition to that, JIRiSS includes other advanced features like automatically generated software vocabulary, advanced query formulation options including spell-checking as well as fragment-based search","1092-8138;10928138","POD:0-7695-2601-2","10.1109/ICPC.2006.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631130","","Computer science;Documentation;Indexing;Information retrieval;Java;Natural languages;Search engines;Software systems;Software tools;Vocabulary","Java;information retrieval;program testing;software tools","Eclipse;JIRiSS;Java;fragment-based search;information retrieval method;natural language queries;query formulation;software exploration tool;software search;software vocabulary;source code exploration","","18","1","14","","","0-0 0","","IEEE","IEEE Conference Publications"
"Spectral Analysis of Irregularly Sampled Data Using a Bernoulli-Gaussian Model with Free Frequencies","S. Bourguignon; H. Carfantan","Laboratoire d' Astrophysique de l'Observatoire Midi-Pyr&#233;n&#233;es, Universit&#233; Paul Sabatier - Toulouse III 14, avenue &#233;douard Belin, 31400 Toulouse, France. bourgui@ast.obs-mip.fr","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","3","","III","III","Line spectra estimation is addressed for irregularly sampled astrophysical data. A formulation with a large number of discretized frequencies is used and sparseness is encouraged via a Bernoulli-Gaussian (BG) model on the corresponding amplitudes. Contrary to classic BG models, here the frequency parameters are not constrained on a fixed grid, theoretically enabling unlimited frequency precision. We propose a posterior mean unsupervised estimation scheme combined with an hybrid MCMC algorithm, that allows us to derive crucial information in an astrophysical context, such as confidence levels and variances for each detected spectral line. Simulations confirm the validity of this model with satisfactory estimation results, in addition to a more solid behaviour than parametric methods towards classic astrophysical perturbations","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660704","","Constraint theory;Extrasolar planet;Frequency estimation;High definition video;Information retrieval;Inverse problems;Parametric statistics;Sampling methods;Solid modeling;Spectral analysis","Gaussian processes;Markov processes;Monte Carlo methods;astronomy computing;spectral analysis","Bernoulli-Gaussian model;Markov chain Monte Carlo methods;irregularly sampled astrophysical data;line spectra estimation;posterior mean unsupervised estimation;spectral analysis","","3","","8","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Pre-Classification for Automatic Image Orientation","H. Le Borgne; N. E. O'Connor","Centre for Digital Video Processing, Dublin City University, Dublin 9, Ireland. e-mail: hlborgne@eeng.dcu.ie","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","2","","II","II","In this paper, we propose a novel method for automatic orientation of digital images. The approach is based on exploiting the properties of local statistics of natural scenes. In this way, we address some of the difficulties encountered in previous works in this area. The main contribution of this paper is to introduce a pre-classification step into carefully defined categories in order to simplify subsequent orientation detection. The proposed algorithm was tested on 9068 images and compared to existing state of the art in the area. Results show a significant improvement over previous works","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660295","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660295","","Content management;Digital cameras;Digital images;Image processing;Information retrieval;Layout;Statistics;Support vector machine classification;Support vector machines;Testing","image classification","automatic image orientation;image preclassification;subsequent orientation detection","","0","","11","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"A Comparative Study of Algorithms for Finding Web Communities","H. Ino; M. Kudo; A. Nakamura","Hokkaido University, Sapporo, Japan","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1257","1257","Recently, researches on extraction of densely connected subgraphs, which are called communities, from the graph representing link structure inWWW, are very popular. However, few methods guarantee that extracted subgraphs satisfy community conditions which are strictly defined. In this paper, we consider the problem of extracting subgraphs that strictly satisfy the community conditions proposed in [3]. It is known that finding all such communities is computationally hard. As methods that possibly find many communities efficiently, we experimentally compared two methods, a method with a Gomory-Hu tree construction and a method with calculating edge-betweenness. We also proposed evaluation criterion for ranking found communities.","","POD:0-7695-2657-8","10.1109/ICDE.2005.159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647874","","Data mining;Information retrieval;Information science;Internet;Joining processes;NP-complete problem;Partitioning algorithms;Tree graphs;Web pages;World Wide Web","","","","3","2","9","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Design and Implementation of a File Transfer and Web Services Guard Employing Cryptographically Secured XML Security Labels","A. Thummel; K. Eckstein","NATO C3 Agency, The Hague","2006 IEEE Information Assurance Workshop","20060710","2006","","","26","33","This publication introduces the concept of cryptographically secured, extensible markup language (XML) based security labels, which either globally label any non-XML electronic document, or label individual sections of an XML infoset. It further describes the architecture and construction of a guard prototype for file transfer and Web services based applications. This prototype employs the XML security labels to verify information classification prior to releasing information across a security domain boundary separating enclaves belonging to different security domains. If necessary, XML infosets containing information at multiple security levels can be redacted by the guard filtering algorithms to create a releasable subset of the original XML infoset or document","","POD:1-4244-0130-5","10.1109/IAW.2006.1652073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652073","","Cryptography;Filtering algorithms;Information retrieval;Information security;Labeling;Prototypes;Service oriented architecture;Transport protocols;Web services;XML","Internet;XML;cryptography","Web services;XML security labels;cryptography;extensible markup language;file transfer;guard filtering algorithms","","2","1","23","","","21-23 June 2006","","IEEE","IEEE Conference Publications"
"A New Method for Image Classification by Using Multilevel Association Rules","V. S. Tseng; Ming-Hsiang Wang; Ja-Hwung Su","National Cheng Kung University, Taiwan","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1180","1180","With the popularity of multimedia applications, the huge amount of image and video related to real life have led to the proliferation of emerging storage techniques. Contented-based image retrieval and classification have become attractive issues in the last few years. Most researches concerning image classification focus primarily on low-level image features (e.g. color, texture, shape, etc.) and ignore the conceptual associations among the objects in the images. In this paper, we propose a new image classification method by using multiple-level association rules based on the image objects. The approach we proposed can be decomposed of three phases: (1) building of conceptual object hierarchy, (2) discovery of classification rules, and (3) classification and prediction of images. At the first phase, we use a hierarchical clustering method to build the conceptual hierarchy based on the low-level features of image objects. At the second phase, we devise a multi-level mining algorithm for finding the image classification rules. The classification task is performed at the last phase. Empirical evaluations show that our approach performs better than other approaches in terms of classification accuracy.","","POD:0-7695-2657-8","10.1109/ICDE.2005.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647786","","Association rules;Content based retrieval;Data mining;Feature extraction;Image classification;Image retrieval;Image segmentation;Image storage;Information retrieval;Multimedia databases","","","","13","","20","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Combining Probabilistic Ranking and Latent Semantic Indexing for Feature Identification","D. Poshyvanyk; A. Marcus; V. Rajlich; Y. G. Gueheneuc; G. Antoniol","Wayne State University, Detroit Michigan","14th IEEE International Conference on Program Comprehension (ICPC'06)","20060626","2006","","","137","148","The paper recasts the problem of feature location in source code as a decision-making problem in the presence of uncertainty. The main contribution consists in the combination of two existing techniques for feature location in source code. Both techniques provide a set of ranked facts from the software, as result to the feature identification problem. One of the techniques is based on a scenario based probabilistic ranking of events observed while executing a program under given scenarios. The other technique is defined as an information retrieval task, based on the latent semantic indexing of the source code. We show the viability and effectiveness of the combined technique with two case studies. A first case study is a replication of feature identification in Mozilla, which allows us to directly compare the results with previously published data. The other case study is a bug location problem in Mozilla. The results show that the combined technique improves feature identification significantly with respect to each technique used independently","1092-8138;10928138","POD:0-7695-2601-2","10.1109/ICPC.2006.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631116","","Computer science;Data mining;Decision making;Indexing;Information analysis;Information retrieval;Software debugging;Software engineering;Software systems;Uncertainty","indexing;information retrieval;probability;program debugging;program diagnostics;software prototyping","Mozilla;bug location;decision-making;feature identification;feature location;information retrieval task;latent semantic indexing;probabilistic ranking;source code","","50","1","27","","","0-0 0","","IEEE","IEEE Conference Publications"
"Towards a universal client for grid monitoring systems: design and implementation of the Ovid browser","M. D. Dikaiakos; A. Artemiou; G. Tsouloupas","Dept. of Comput. Sci., Cyprus Univ., Nicosia, Cyprus","Proceedings 20th IEEE International Parallel & Distributed Processing Symposium","20060626","2006","","","8 pp.","","In this paper, we present the design and implementation of Ovid, a browser for grid-related information. The key goal of Ovid is to support the seamless navigation of users in the grid information space. Key aspects of Ovid are: (i) a set of navigational primitives, which are designed to cope with problems such as network disorientation and information overloading; (ii) a small set of Ovid views, which present the end-user with high-level, visual abstractions of grid information; these abstractions correspond to simple models that capture essential aspects of a grid infrastructure; (iii) support for embedding and implementing hyperlinks that connect related entities represented within different information views; (iv) a plug-in mechanism, which enables the seamless integration with Ovid of third-party software that retrieves and displays data from various grid information sources; and (v) a modular software design, which allows the easy integration of different visualization algorithms that support the graphical representation of large amounts of grid-related information in the context of Ovid's views","1530-2075;15302075","POD:1-4244-0054-6","10.1109/IPDPS.2006.1639494","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639494","","Algorithm design and analysis;Context modeling;Data visualization;Displays;Embedded software;Information retrieval;Monitoring;Navigation;Software algorithms;Software design","grid computing;information retrieval;online front-ends","Ovid browser;data display;data retrieval;graphical representation;grid monitoring systems;seamless navigation","","0","","15","","","25-29 April 2006","","IEEE","IEEE Conference Publications"
"Local analysis of MISR surface BRF and albedo over GSFC and mongu AERONET sites","A. Lyapustin; Yujie Wang; J. Martonchik; J. L. Privette; B. Holben; I. Slutsker; A. Sinyuk; A. Smirnov","GEST Univ. of Maryland Baltimore County, Catonsville, MD, USA","IEEE Transactions on Geoscience and Remote Sensing","20060626","2006","44","7","1707","1718","We have developed an atmospheric correction algorithm to retrieve the surface bidirectional reflectance factor (BRF) and albedo from Multiangle Imaging SpectroRadiometer (MISR) measurements for small areas around Aerosol Robotic Network (AERONET) sunphotometer sites, using AERONET aerosol and column water vapor information. Our goal is to develop an indirect validation method for MISR surface reflectance products over heterogeneous land. Our algorithm makes independent retrievals with both the Li Sparse-Ross Thick kernel BRF model and the modified Rahman-Pinty-Verstraete BRF model used in the Moderate Resolution Imaging Spectroradiometer and MISR land algorithms, respectively. In this study, we report the first results of processing MISR Collection 4 data for 2003-2004 for two sites, Mongu, Zambia, and Greenbelt, MD. We found that MISR generally provides accurate retrievals of BRF and albedo in both clear and hazy atmospheric conditions, correctly reproducing the parameter time series and spatial distribution. We found that the MISR BRF, on average, is less anisotropic in the visible bands. The difference is greatest in the blue band, but decreases with increasing wavelength such that it is negligible in the near-IR band. This discrepancy originates in part in the MISR aerosol retrieval algorithm over heterogeneous land, which tends to select an aerosol model that favors spectrally invariant shapes of surface BRF. The other part of the discrepancy comes from the surface hemispherical-directional reflectance factor retrieval algorithm where the iteration loop that removes the diffuse atmospheric transmittance is currently turned off. Our initial results suggest that the MISR surface albedo is on average lower than our retrievals by about 0.005 in the green and red bands. In the near-IR, it agreed with our retrievals with the modified Rahman-Pinty-Verstraete model for the Mongu site, but was systematically lower over the Greenbelt site by about 0.016. When significant- - aerosol absorption is present (Mongu), the albedo discrepancy is additionally biased by the difference between the MISR and AERONET retrievals of aerosol absorption","0196-2892;01962892","","10.1109/TGRS.2005.856678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1645271","Aerosol Robotic Network (AERONET);Multiangle Imaging SpectroRadiometer (MISR);albedo;atmospheric correction;bidirectional reflectance;validation","Absorption;Aerosols;Area measurement;Atmospheric modeling;Bidirectional control;Image retrieval;Information retrieval;Land surface;Reflectivity;Spectroradiometers","aerosols;albedo;atmospheric humidity;atmospheric optics;geophysical signal processing;radiometry;reflectivity;remote sensing;water","AERONET;Aerosol Robotic Network;Greenbelt;H<sub>2</sub>O;MISR measurements;Maryland;Mongu;Multiangle Imaging SpectroRadiometer;Zambia;aerosol retrieval algorithm;atmospheric correction algorithm;column water vapor;diffuse atmospheric transmittance;modified Rahman-Pinty-Verstraete model;parameter time series;sunphotometer sites;surface albedo;surface bidirectional reflectance factor;surface reflectance products","","11","","22","","","July 2006","","IEEE","IEEE Journals & Magazines"
"Analyzing DICOM and non-DICOM Features in Content-Based Medical Image Retrieval: A Multi-Layer Approach","A. da Luz; D. D. Abdala; A. V. Wangenheim; E. Comunello","Federal University of Santa Catarina, Brazil","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","93","98","This paper presents a hybrid approach to perform content-based retrieval on medical image databases. It takes advantage of a pre-processed case base that is batch updated. DICOM information is used to perform pre-filtering to speed up the retrieval process and an image processing knowledge base is used to dynamically reconfigure the most appropriated image processing procedures to perform the image feature extraction. It shows that pre-filtering can speed up considerably the retrieval process and also that some image features produce very similar results what leads to future work on defining the needed digital image processing knowledge base","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647552","","Biomedical imaging;Content based retrieval;DICOM;Digital images;Feature extraction;Image analysis;Image databases;Image processing;Image retrieval;Information retrieval","content-based retrieval;feature extraction;image retrieval;medical image processing;visual databases","DICOM information;content-based medical image retrieval;image feature extraction;image processing procedures;medical image databases","","0","","11","","","0-0 0","","IEEE","IEEE Conference Publications"
"Automatically Building an Information-Security Vulnerability Database","A. D. Armold; B. M. Hyla; N. C. Rowe","US Naval Postgraduate Sch., Monterey, CA","2006 IEEE Information Assurance Workshop","20060710","2006","","","376","377","Our goal was to collect data from the myriad computer vulnerability notices that exist on the World Wide Web and to mine it for interesting information and patterns. Surprisingly, no single database currently brings together all the various kinds of data from the vulnerability sites. Of particular interest to us was author and discoverer information since this provides valuable information about who is active in information security and occasionally might indicate the authors of exploits; current databases do not connect this to other relevant information. We found that the searchable parameters of the existing vulnerability databases were limited and inconsistent. Consequently, it is very difficult to get complete information about computer vulnerabilities by searching Web sites. Our approach was to bring together this information into a composite database. We did automated data collection from the existing Web vulnerability databases by creating Web bots that traversed Web sites and retrieved selected information from them, then imported the collected Web data into a relational database. A browser provides Web-based access to this database. (J. Steffan, et al., March 2002) and (R. Iyer, et al., Oct. 2003) shows how such information can be used to build models of attacks in the form of graphs, trees, and finite-state machines, and thereby develop methods for system protection","","POD:1-4244-0130-5","10.1109/IAW.2006.1652119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652119","","Data mining;HTML;Information retrieval;Information security;Java;Protection;Relational databases;Tree graphs;Web sites;XML","Internet;finite state machines;information services;relational databases;security of data;trees (mathematics)","Web sites;World Wide Web;finite-state machines;information-security vulnerability database;myriad computer vulnerability;relational database;trees","","1","","2","","","21-23 June 2006","","IEEE","IEEE Conference Publications"
"A Hindi Question Answering system for E-learning documents","P. Kumar; S. Kashyap; A. Mittal; S. Gupta","Department of Electronics and Computer Engineering, Indian Institute of Technology, Roorkee, India 247667. Email: praveen.kverma@gmail.com","2005 3rd International Conference on Intelligent Sensing and Information Processing","20060626","2005","","","80","85","To empower the general mass through access to information and knowledge, organized efforts are being made to develop relevant content in local languages and provide local language capabilities to utility software. We have developed a question answering (QA) system for Hindi documents that would be relevant for masses using Hindi as the primary language of education. The user should be able to access information from e-learning documents in a user friendly way, that is by questioning the system in their native language Hindi and the system returns the intended answer (also in Hindi) by searching in context from the repository of Hindi documents. The language constructs, query structure, common words, etc. are completely different in Hindi as compared to English. A novel strategy, in addition to conventional search and NLP techniques, was used to construct the Hindi QA system. The focus is on context based retrieval of information. For this purpose we implemented a Hindi search engine that works on locality-based similarity heuristics to retrieve relevant passages from the collection. It also incorporates language analysis modules like stemmer and morphological analyzer as well as self constructed lexical database of synonyms. The experimental results over corpus of two important domains of agriculture and science show effectiveness of our approach","","POD:0-7803-9588-3","10.1109/ICISIP.2005.1619416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1619416","","Agriculture;Computer science education;Databases;Educational institutions;Electronic learning;Information retrieval;Knowledge engineering;Natural languages;Search engines;Utility programs","computer aided instruction;natural languages;search engines;utility programs","Hindi question answering system;Hindi search engine;NLP technique;context based information retrieval;conventional search technique;e-learning documents;language analysis modules;local languages;locality-based similarity heuristics;morphological analyzer;self constructed lexical database;utility software","","1","","13","","","14-17 Dec. 2005","","IEEE","IEEE Conference Publications"
"The Quality vs. Time Trade-off for Approximate Image Descriptor Search","R. Siguroardottir; B. P. Jonsson; H. Hauksson; L. Amsaleg","Reykjavik University, Iceland","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1175","1175","In recent years, content-based image retrieval has become more and more important in many application areas. Similarity retrieval is inherently a very demanding process, in particular when performing exact searches. Therefore, there is an increasing interest in performing approximate searches, where result quality guarantees are traded for reduced query execution time. The goal of approximate retrieval systems should be to obtain the best possible result quality in the minimum amount of time. As a result, typical indexing strategies divide the data set into many data chunks. Minimizing the search time suggests to generate uniformly sized chunks to best overlap I/O costs with CPU costs. Maximizing quality, on the other hand, suggests to strongly limit the intra-chunk dissimilarity of data. The paper addresses the question to what extent guaranteeing the query processing time, using uniform chunk sizes, compromises the quality of the results, and vice versa. Using a large collection of 5 million 24-dimensions local descriptors computed over more than 50 thousand real life images, we show that minimizing the query processing time may in fact lead to better quality of the intermediate results.","","POD:0-7695-2657-8","10.1109/ICDE.2005.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647781","","Biomedical imaging;Content based retrieval;Costs;Geography;Image retrieval;Indexing;Information retrieval;Laboratories;Query processing;Weather forecasting","","","","0","","20","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Musical Instrument Classification using Non-Negative Matrix Factorization Algorithms and Subset Feature Selection","E. Benetos; M. Kotti; C. Kotropoulos","Department of Informatics, Aristotle Univ. of Thessaloniki, Box 451, Thessaloniki 541 24, Greece. E-mail: empeneto@zeus.csd.auth.gr","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","5","","V","V","In this paper, a class, of algorithms for automatic classification of individual musical instrument sounds is presented. Several perceptual features used in sound classification applications as well as MPEG-7 descriptors were measured for 300 sound recordings consisting of 6 different musical instrument classes. Subsets of the feature set are selected using branch-and-bound search, obtaining the most suitable features for classification, A class of classifiers is developed based on the non-negative matrix factorization (NMF). The standard NMF method is examined as well as its modifications: the local, the sparse, and the discriminant NMF. The experimental results compare feature subsets of varying sizes alongside the various NMF algorithms. It has been found that a subset containing the mean and die variance of the first mel-frequency cepstral coefficient and the audiospectrumflatness descriptor along with the means of the audiospectrumenvelope and the audiospectrumspread descriptors when is fed to a standard NMF classifier yields an accuracy exceeding 95%","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1661252","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1661252","","Cepstral analysis;Classification algorithms;Electronic mail;Feature extraction;Informatics;Instruments;MPEG 7 Standard;Music information retrieval;Spatial databases;Testing","acoustic signal processing;feature extraction;matrix algebra;musical instruments;signal classification;tree searching","MPEG-7 descriptors;audiospectrumenvelope;audiospectrumflatness descriptor;branch-and-bound search;mel-frequency cepstral coefficient;musical instrument classification;musical instrument sounds;nonnegative matrix factorization algorithms;sound recordings;subset feature selection","","16","","12","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Soccer Video Retrival Using Adaptive Time-Frequency Methods","J. Marchal; C. Ioana; E. Radoi; A. Quinquis; S. Krishnan","ENSIETA, E3I2 Laboratory, 2 rue Fran&#231;ois Verny, Brest - FRANCE. E-mail: marchajo@ensieta.fr","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","5","","V","V","The retrieval of soccer highlights is a suitable technique for video indexing, required by the multimedia database management or for the development of television on demand. For these purposes, it should be interesting to have an automatic annotation of events happened in soccer games. One solution consists in analyzing the audio soundtrack associated to the soccer video and to detect the interesting frames. In this paper we use the adaptive time-frequency decomposition of the soundtrack as a feature extraction procedure. This decomposition is based on the matching pursuit concept and a dictionary composed of Gabor functions. The parameters provided by these transformations constitute the input of the classification stage. The results provided for real soccer video will prove the efficiency of the adaptive time-frequency representation as a feature extraction stage","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1661324","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1661324","","Dictionaries;Feature extraction;Games;Indexing;Information retrieval;Matching pursuit algorithms;Multimedia databases;TV;Time frequency analysis;Video on demand","feature extraction;image classification;image matching;sport;time-frequency analysis;video retrieval","Gabor functions;adaptive time-frequency methods;feature extraction procedure;matching pursuit concept;multimedia database management;soccer games;soccer video retrieval;soundtrack;television on demand;video indexing","","0","","7","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Accuracy Control in Compressed Multidimensional Data Cubes for Quality of Answer-based OLAP Tools","A. Cuzzocrea","University of Calabria, Italy","18th International Conference on Scientific and Statistical Database Management (SSDBM'06)","20060724","2006","","","301","310","An innovative technique supporting accuracy control in compressed multidimensional data cubes is presented in this paper. The proposed technique can be efficiently used in QoA-based OLAP tools, where OLAP users/applications and DW servers are allowed to mediate on the accuracy of (approximate) answers, similarly to what happens in QoS-based systems for the quality of services. The compressed data structure KLSA, which implements the technique, is also extensively presented and discussed. We complement our analytical contributions with an experimental evaluation on several kinds of synthetic multidimensional data cubes, demonstrating the superiority of our approach in comparison with other similar techniques","1551-6393;15516393","POD:0-7695-2590-3","10.1109/SSDBM.2006.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1644327","","Data processing;Data structures;Databases;Information retrieval;Least squares approximation;Multidimensional systems;Proposals;Quality of service;Scalability;Warehousing","data mining;data structures;data warehouses;query processing","KLSA compressed data structure;data warehouse server;multidimensional data cube compression;quality of answer-based OLAP tool;quality of service","","3","1","24","","","0-0 0","","IEEE","IEEE Conference Publications"
"A Hybrid Model of Context-aware Service Provisioning Implemented on Smart Phones","O. Riva; S. Toivonen","Helsinki Inst. for Inf. Technol.","2006 ACS/IEEE International Conference on Pervasive Services","20060710","2006","","","47","56","Mobile users of future ubiquitous environments require novel means for locating relevant services available in their daily surroundings, where relevance has a user-specific definition. In this paper, we propose the hybrid service provisioning model which complements the traditional model of interaction service provider to consumer with peer-to-peer functionalities. In addition to being notified proactively and in a context-aware manner about services available in the surroundings, users can generate several types of contextual messages, attach them to services or to the environment, and share them with other peers. We have designed and implemented a platform that supports this hybrid service provisioning model. The current application prototype runs on commercial smart phones. To demonstrate the feasibility and technical deployability of our approach, we conducted field trials in which the research subject was a community of recreational boaters","","POD:1-4244-0237-9","10.1109/PERSER.2006.1652206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652206","","Context modeling;Context-aware services;Information filtering;Information filters;Information retrieval;Information technology;Motion pictures;Peer to peer computing;Prototypes;Smart phones","mobile computing;mobile radio;peer-to-peer computing","context-aware service;hybrid service provisioning model;interaction service provider;mobile user;peer-to-peer functionality;smart phone;ubiquitous environment;user-specific definition","","6","","28","","","26-29 June 2006","","IEEE","IEEE Conference Publications"
"An approach for cross-media retrieval with cross-reference graph and PageRank","Yueting Zhuang; Hanhuai Shan; Fei Wu","Coll. of Comput. Sci. & Eng., Zhejiang Univ., Hangzhou, China","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","8 pp.","","In this paper, we propose a novel cross-media retrieval method. The most important feature of it is to integrate the multi-modal data seamlessly via a cross-reference graph, and then based on the graph, it is able to use improved personalized PageRank to calculate how close the media object associates with the query on semantic and content level. It is also able to adjust the cross-reference graph according to user's relevance feedback, which refines the semantic relationship between the media objects, so as to improve the retrieval accuracy progressively. As demonstrated by the experiments, our method achieves satisfactory retrieval efficiency on multi-modal datasets","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651316","","Content based retrieval;Data mining;Educational institutions;Feedback;Information retrieval;Information technology;Learning systems;Modems;Software libraries;Technology management","content-based retrieval;multimedia databases;relevance feedback","PageRank;cross-media retrieval;cross-reference graph;multimodal data;relevance feedback","","0","","29","","","0-0 0","","IEEE","IEEE Conference Publications"
"A Distributed Flocking Approach for Information Stream Clustering Analysis","Xiaohui Cui; T. E. Potok","Oak Ridge National Laboratory, TN","Seventh ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD'06)","20060626","2006","","","97","102","Intelligence analysts are currently overwhelmed with the amount of information streams generated everyday. There is a lack of comprehensive tool that can real-time analyze the information streams. Document clustering analysis plays an important role in improving the accuracy of information retrieval. However, most clustering technologies can only be applied for analyzing the static document collection because they normally require a large amount of computation resource and long time to get accurate result. It is very difficult to cluster a dynamic changed text information streams on an individual computer. Our early research has resulted in a dynamic reactive flock clustering algorithm which can continually refine the clustering result and quickly react to the change of document contents. This character makes the algorithm suitable for cluster analyzing dynamic changed document information, such as text information stream. Because of the decentralized character of this algorithm, a distributed approach is a very natural way to increase the clustering speed of the algorithm. In this paper, we present a distributed multi-agent flocking approach for the text information stream clustering and discuss the decentralized architectures and communication schemes for load balance and status information synchronization in this approach","","POD:0-7695-2611-X","10.1109/SNPD-SAWN.2006.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640673","","Algorithm design and analysis;Biological system modeling;Birds;Clustering algorithms;Data mining;Data visualization;Information analysis;Information retrieval;Laboratories;Text analysis","document handling;information analysis;information retrieval;multi-agent systems;pattern clustering;resource allocation","distributed flocking approach;distributed multiagent flocking approach;document clustering analysis;document contents;dynamic changed text information streams;dynamic reactive flock clustering;information retrieval;information stream clustering analysis;load balancing;static document collection;status information synchronization;text information stream clustering","","0","","17","","","19-20 June 2006","","IEEE","IEEE Conference Publications"
"Biomedical Ontology MeSH Improves Document Clustering Qualify on MEDLINE Articles: A Comparison Study","Illhoi Yoo; Xiaohua Hu","Drexel University, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","577","582","Document clustering has been used for better document retrieval, document browsing, and text mining. In this paper, we investigate if biomedical ontology MeSH improves the clustering quality for MEDLINE articles. For this investigation, we perform a comprehensive comparison study of various document clustering approaches such as hierarchical clustering methods (single-link, complete-link, and complete link), bisecting K-means, K-means, and suffix tree clustering (STC) in terms of efficiency, effectiveness, and scalability. According to our experiment results, biomedical ontology MeSH significantly enhances clustering quality on biomedical documents. In addition, our results show that decent document clustering approaches, such as bisecting K-means, K-means and STC, gains some benefit from MeSH ontology while hierarchical algorithms showing the poorest clustering quality do not reap the benefit of MeSH ontology","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647632","","Clustering algorithms;Clustering methods;Educational institutions;Information retrieval;Information science;Iterative algorithms;Ontologies;Partitioning algorithms;Scalability;Text mining","bibliographic systems;document handling;medical computing;ontologies (artificial intelligence);pattern clustering","MEDLINE articles;biomedical ontology MeSH;bisecting K-means;document clustering;hierarchical clustering methods;suffix tree clustering","","3","","26","","","0-0 0","","IEEE","IEEE Conference Publications"
"Application Profiles for Learning","E. Duval; N. Smith; M. Van Coillie","Katholieke Universiteit Leuven","Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)","20060724","2006","","","242","246","Application profiles enable ""mixing and matching"" metadata elements, in order to meet specific requirements for a particular context. As an example, some communities may want to make certain elements mandatory or restrict the value space of a particular element. However, there is much confusion and only limited experience and expertise in the development and deployment of application profiles. That is why the CEN/ISSS Learning Technologies Workshop has decided to develop guidelines on the use of application profiles for (e-)learning. This paper highlights the main results of this work, and was co-authored by the three experts that drafted the CEN document (N. Smith et al., 2005)","2161-3761;21613761","POD:0-7695-2632-2","10.1109/ICALT.2006.1652415","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652415","","Electronic learning;Guidelines;ISO standards;Information retrieval;Libraries;Space technology;Standardization;Standards development;Vocabulary","computer aided instruction;meta data","CEN document;CEN/ISSS Learning Technologies Workshop;e-learning;learning application profiles;metadata element matching;metadata element mixing","","8","","5","","","5-7 July 2006","","IEEE","IEEE Conference Publications"
"Automatic Generation of Metadata for Learning Objects","P. S. Saini; M. Ronchetti; D. Sona","University Of Trento, Italy","Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)","20060724","2006","","","275","279","Proper reuse of learning objects depends both on the amount and quality of attached semantic metadata such as ""learning objective'"", ""related concept"", etc. Manually expressing such metadata is a time consuming and expensive task. Here we present an approach based on a probabilistic model, which through the automatic classification of learning resources on a given taxonomic organization of the knowledge, allows to associate ontological metadata to the learning resources","2161-3761;21613761","POD:0-7695-2632-2","10.1109/ICALT.2006.1652423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652423","","Communications technology;Electronic learning;Humans;Information retrieval;Least squares approximation;Ontologies;Taxonomy;Training data;Visualization;Web pages","computer aided instruction;meta data;ontologies (artificial intelligence)","associate ontological metadata;knowledge taxonomic organization;learning objects;learning resource automatic classification;metadata automatic generation;probabilistic model;semantic metadata","","3","","17","","","5-7 July 2006","","IEEE","IEEE Conference Publications"
"Statistical similarity search applied to content-based video copy detection","A. Joly; O. Buisson; C. Frelicot","Institut National de l&#146;Audiovisuel,France","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1285","1285","Content-based copy detection (CBCD) is one of the emerging multimedia applications for which there is a need of a concerted effort from the database community and the computer vision community. Recent methods based on interest points and local fingerprints have been proposed to perform robust CBCD of images and video. They include two steps: the search of similar fingerprints in the database and a voting strategy that merges all the local results in order to perform a global decision. In most image or video retrieval systems, the search of similar features in the database is performed by a geometrical query in a multidimensional index structure. Recently, the paradigm of approximate knearest neighbors query has shown that trading quality for time can be widely profitable in that context. In this paper, we introduce a new approximate search paradigm, called Statistical Similarity Search (S3), dedicated to local fingerprints and we describe the original indexing structure we have developped to compute efficiently the corresponding queries. The key-point relates to the distribution of the relevant fingerprints around a query. Since a video query can result from (a combination of ) more or less transformations of an original one, we modelize the distribution of the distorsion vector between a referenced fingerprint and a candidate one. Experimental results show that these statistical queries allow high performance gains compared to classical e-range queries. By studying the influence of this approximate search on a complete CBCD scheme based on local video fingerprints, we also show that trading quality for time during the search does not degrade seriously the global robustness of the system, even with very large databases including more than 20,000 hours of video.","","POD:0-7695-2657-8","10.1109/ICDE.2005.291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647776","","Application software;Computer vision;Fingerprint recognition;Image databases;Image retrieval;Information retrieval;Multimedia databases;Robustness;Spatial databases;Voting","","","","6","7","27","","","3-4 April 2005","","IEEE","IEEE Conference Publications"
"Optimizing Ranked Retrieval over Categorical Attributes","Seung-won Hwang","Pohang University of Science and Technology, Korea","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","51","56","As the entry and archival of medical data are being digitized, more and more medical data are becoming accessible. This paper studies how to enable an effective retrieval of medical data by ranked retrieval of only the most relevant highly-ranked data. While ranked retrieval has been actively studied lately, existing works have focused mainly on supporting ranking over numerical or text data. However, many existing medical data contain a large amount of categorical attributes, e.g., gender, race profile, or pain type, which cannot be efficiently supported by either line of existing algorithms Unlike numerical attributes where a natural ordering is inherent, formulating and processing ranked retrieval over categorical attributes with no such ordering are challenging. This paper studies an efficient and effective support of ranking over categorical data, and also a uniform support with other types of attributes, e.g., numerical attributes","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647545","","Cardiac disease;Computer displays;Computer errors;Costs;Data mining;Handheld computers;Information retrieval;Lattices;Pain;Turning","information retrieval;medical administrative data processing","categorical attributes;medical data;medical record entry;ranked retrieval","","0","","11","","","0-0 0","","IEEE","IEEE Conference Publications"
"Data-Preservation in Scientific Workflow Middleware","D. T. Liu; M. J. Franklin; G. M. Abdulla; J. Garlick; M. Miller","UC Berkeley","18th International Conference on Scientific and Statistical Database Management (SSDBM'06)","20060724","2006","","","49","58","This paper investigates data-preservation, a feature of scientific workflow middleware (SWM) useful for supporting data provenance and ""smart recomputation."" We observe that in order for an SWM supporting data preservation to achieve decent performance, it should execute on top of copy-on-write file systems. Unfortunately, most file systems in-use at scientific computing facilities were designed without copy-on-write semantics. In response, we design, implement and evaluate a middleware-level solution that is based on user-provided hints and parallelization. The solution can be deployed on top of current file systems and is able to scale almost arbitrarily. Our validation is based on real use-cases from astrophysics and experiments on a cluster with 4 file systems","1551-6393;15516393","POD:0-7695-2590-3","10.1109/SSDBM.2006.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1644297","","Astrophysics;Collaborative work;Concurrent computing;File systems;Grid computing;Information retrieval;Laboratories;Middleware;Productivity;Scientific computing","distributed databases;middleware;natural sciences computing;network operating systems","astrophysics;copy-on-write semantics;data provenance;data-preservation;file systems;scientific computing;scientific workflow middleware;smart recomputation","","3","","24","","","3-5 July 2006","","IEEE","IEEE Conference Publications"
"Image retrieval based on user-specified features in queries with multiple examples","Khanh Vu; Kien Hua; S. Koompairojn","Dept. of Comput. Sci., Central Florida Univ., Orlando, FL, USA","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","4 pp.","","Many current image retrieval techniques allow queries to be defined with multiple examples from a presented set. In these systems, all visual features are extracted from these images and used to determine relevant images from the database. As a result, users are left to decide whether or not to include images that not only contain desirable features but also irrelevant ones. Fewer examples or a contaminated set of more either would compromise the retrieval effectiveness of most similarity measures. In this work, we examine this popular case when desired features present in image examples define the intent of the queries. We show how this consideration affects the selection of the representative query points and retrieval sets, and discuss the options whether or not to retrieve partially relevant images. Our experimental results have shown a remarkable improvement in retrieval performance","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651365","","Content based retrieval;Feature extraction;Image databases;Image retrieval;Indexing;Information retrieval;Shape;Spatial databases;System performance;Visual databases","feature extraction;image retrieval;visual databases","image retrieval;query points;retrieval sets;similarity measures;user-specified features;visual feature extraction","","0","","14","","","0-0 0","","IEEE","IEEE Conference Publications"
"Ultrasound Backscatter Characterization by Using Markov Random Field Model","N. Bouhlel; S. Sevestre-Ghalila; M. Jaidane; C. Graffigne","Lab. MAP5, Univ. Rene Descartes, Paris","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","2","","II","II","This paper evaluates a K-Markov random field model for retrieving information about backscatter characteristics, especially regularity spacing scatterers in simulated ultrasound image. The model combines a statistical K-distribution that describes the envelope of backscattered echo and spatial interaction given by Markov random field (MRF). Parameters estimated by the conditional least squares (CLS) estimation method on simulated radio-frequency (RF) envelope image show that the interaction parameters measure the degree of the randomness of the scatterers","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660545","","Backscatter;Image retrieval;Information retrieval;Least squares approximation;Markov random fields;Parameter estimation;Radio frequency;Scattering;Ultrasonic imaging;Ultrasonic variables measurement","Markov processes;backscatter;biomedical ultrasonics;least squares approximations;statistical distributions","Markov random field model;RF envelope image;conditional least squares estimation;radio-frequency envelope image;statistical K-distribution;ultrasound backscatter characterization;ultrasound image","","1","","13","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Efficient implementation of vector quantization for image retrieval","Shyh Wei Teng; Guojun Lu","GSIT, Monash Univ., Clayton, Vic., Australia","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","8 pp.","","Vector quantization histogram (VQH) is a content-based image retrieval technique that has high retrieval effectiveness. However, as VQH's image indexing process is highly computationally intensive, it is not ideal as an online system. We propose an efficient image encoding technique to address this issue. Our experimental results show the proposed technique greatly improves the retrieval efficiency of VQH and it also has little adverse effects on VQH's retrieval effectiveness","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651331","","Content based retrieval;Decoding;Delay;Histograms;Image coding;Image retrieval;Indexing;Information retrieval;Usability;Vector quantization","content-based retrieval;image coding;image retrieval;vector quantisation","content-based image retrieval;image encoding;vector quantization histogram","","2","","10","","","0-0 0","","IEEE","IEEE Conference Publications"
"Privacy-Preserving Basic Operations on Outsourced Search Trees","Dang Tran Khanh","Middlesex University London, United Kingdom","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1194","1194","Security issues in outsourcing database services have recently attracted special attention in the research community. However, to the best of our knowledge, none of the previous work has radically addressed the problem of preserving privacy for basic operations on outsourced search trees. Basic operations of search trees include search and updates. Search trees have played a fundamental and vital role in both traditional and modern database application domains due to their efficiency in managing the storage and retrieval of data. The outsourced search trees and data are all encrypted and stored at some untrusted server. In this paper, we will discuss security issues in outsourced databases that come together with search trees, and present techniques to ensure privacy in the execution of these trees basic operations on the untrusted server. By privacy, we mean the outsourced tree structure and data as well as users queries are all hidden from unauthorized people.","","POD:0-7695-2657-8","10.1109/ICDE.2005.264","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647807","","Cryptography;Data privacy;Data security;Databases;Hardware;Information retrieval;Network servers;Outsourcing;Protection;Protocols","","","","1","","30","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Improving Comprehensibility of Source Code via Traceability Information: a Controlled Experiment","A. De Lucia; R. Oliveto; F. Zurolo; M. Di Penta","University of Salerno, Italy","14th IEEE International Conference on Program Comprehension (ICPC'06)","20060626","2006","","","317","326","The presence of traceability links between software artefacts is very important to achieve high comprehensibility and maintainability. This is confirmed by several researches and tools aiming at support traceability link maintenance and recovery. We propose to use traceability information combined with Information Retrieval techniques within an Eclipse plug-in to show the software engineer the similarity between source code components being developed and the high level artefacts they should be traced on. Such a similarity suggests actions aiming at improving the correct usage of identifiers and comments in source code and, as a consequence, the traceability and the comprehensibility level. The approach and tool have been assessed with a controlled experiment performed with master students","1092-8138;10928138","POD:0-7695-2601-2","10.1109/ICPC.2006.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1631139","empirical studies.;traceability recovery","Computer aided software engineering;Informatics;Information resources;Information retrieval;Maintenance engineering;Mathematics;Programming profession;Software engineering;Software maintenance;Terminology","information retrieval;program diagnostics;reverse engineering;software maintenance","Eclipse plug-in technology;information retrieval techniques;software artifacts;software comprehensibility;source code;traceability link maintenance","","22","","35","","","0-0 0","","IEEE","IEEE Conference Publications"
"Multi-level index for global and partial content-based image retrieval","G. Jomier; M. Manouvrier; V. Oria; M. Rukoz","Paris Dauphine University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1176","1176","This article presents a quadtree-based data structure for effective indexing of images. An image is represented by a multi-level feature vector, computed by a recursive decomposition of the image into four quadrants and stored as a full fixed-depth balanced quadtree. A node of the quadtree stores a feature vector of the corresponding image quadrant. A more general quadtree-based structure called QUIP-tree (QUadtree-based Index for image retrieval and Pattern search) is used to index the multi-level feature vectors of the images and their quadrants. A QUIP-tree node is an entry to a set of clusters that groups similar quadrants according to some pre-defined distances. The QUIP-tree allows a multi-level filtering in content-based image retrieval as well as partial queries on images.","","POD:0-7695-2657-8","10.1109/ICDE.2005.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647782","","Content based retrieval;Data structures;Educational institutions;Filtering;Image databases;Image retrieval;Information retrieval;Pixel;Spatial databases;Visual databases","","","","2","","35","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Content based image retrieval using topological models","H. Hacid; A. D. Zighed","ERIC Lab., Bron, France","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","4 pp.","","This paper presents a step in a long process of analyzing, structuring, and retrieving multimedia databases. Indeed, we propose to bring an improvement to an existing content based image retrieval approach. We propose an effective method for locally updating neighborhood graphs which constitute our multimedia index. This method is based on an intelligent way for locating points in a multidimensional space. Promising results are obtained after experimentations on various databases. Future issues of the proposed approach are very relevant","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651337","","Content based retrieval;Humans;Image analysis;Image databases;Image processing;Image retrieval;Information retrieval;Laboratories;Multidimensional systems;Multimedia databases","content-based retrieval;graph theory;image retrieval;multimedia databases","content based image retrieval;locally updating neighborhood graphs;multimedia database analysis;multimedia database retrieval;multimedia database structuring;multimedia index;topological models","","2","","12","","","0-0 0","","IEEE","IEEE Conference Publications"
"Flexible video coding scheme for content-based video storage and retrieval","Jianning Zhang; Lifeng Sun; Shiqiang Yang; Yuzhuo Zhong","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","6 pp.","","In this paper, we proposed a flexible video coding scheme for content-based video storage and retrieval. The proposed flexible video coding scheme applies shot clustering on the uncompressed video in the first pass and encodes the video in multi-clusters based on different video contents in the second pass. The compressed video can be flexibly decoding to meet the different requirements such as video indexing, video summary and structure extraction without fully decoding and re-analyzing. Also the flexible encoder can achieve global coding optimization by encoding similarity video shots continuously. It is very important to reduce the process complexity at the decoder and provide the flexible video content access on the compressed videos in many off-line video storage and retrieval applications. The experiments on sport and film videos illustrate the coding performance increase and the effect of the proposed coding scheme for content-based video storage","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651303","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651303","","Content based retrieval;Decoding;Indexing;Information retrieval;Spatial databases;Streaming media;Sun;Video coding;Video compression;Video sequences","content-based retrieval;data compression;video coding;video retrieval","content-based video retrieval;content-based video storage;film videos;global coding optimization;process complexity;shot clustering;similarity video shots;sport videos;structure extraction;video coding;video content access;video indexing;video summary","","0","","6","","","0-0 0","","IEEE","IEEE Conference Publications"
"Optimizing Metrics Combining Low-Level Visual Descriptors for Image Annotation and Retrieval","Qianni Zhang; E. Izquierdo","Multimedia and Vision Lab, Queen Mary, University of London, Mile End Road, E1 4NS, London, UK. qianni.zhang@elec.qmul.ac.uk","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","2","","II","II","An object oriented approach for key-word based image annotation and classification is presented. It considers combinations of low-level descriptors and suitable metrics to represent and measure similarity between semantically meaningful objects. The objective is to obtain ""optimal"" metrics based on a linear combination of single metrics and descriptors in a multi-feature space. The proposed approach estimates an optimal linear combination of predefined metrics by applying a multi-objective optimization technique based on a Pareto archived evolution strategy. The proposed approach has been evaluated and tested for annotation of objects in images","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660365","","Bridges;Extraterrestrial measurements;Image processing;Image retrieval;Image segmentation;Information retrieval;Layout;Multimedia databases;Pareto optimization;Testing","Pareto analysis;image classification;image retrieval;optimisation","Pareto archived evolution strategy;image annotation;image classification;image retrieval;key-word based image annotation;low-level visual descriptors;multiobjective optimization technique;optimal linear combination","","1","","10","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Direct kernel biased discriminant analysis: a new content-based image retrieval relevance feedback algorithm","Dacheng Tao; Xiaoou Tang; Xuelong Li; Yong Rui","Sch. of Comput. Sci. & Inf. Syst., London Univ., UK","IEEE Transactions on Multimedia","20060717","2006","8","4","716","727","In recent years, a variety of relevance feedback (RF) schemes have been developed to improve the performance of content-based image retrieval (CBIR). Given user feedback information, the key to a RF scheme is how to select a subset of image features to construct a suitable dissimilarity measure. Among various RF schemes, biased discriminant analysis (BDA) based RF is one of the most promising. It is based on the observation that all positive samples are alike, while in general each negative sample is negative in its own way. However, to use BDA, the small sample size (SSS) problem is a big challenge, as users tend to give a small number of feedback samples. To explore solutions to this issue, this paper proposes a direct kernel BDA (DKBDA), which is less sensitive to SSS. An incremental DKBDA (IDKBDA) is also developed to speed up the analysis. Experimental results are reported on a real-world image collection to demonstrate that the proposed methods outperform the traditional kernel BDA (KBDA) and the support vector machine (SVM) based RF algorithms","1520-9210;15209210","","10.1109/TMM.2005.861375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1658034","Biased discriminant analysis (BDA);content-based image retrieval (CBIR);direct kernel biased discriminant analysis (DKBDA);incremental direct kernel biased discriminant analysis (IDKBDA);kernel biased discriminant analysis (KBDA);relevance feedback (RF)","Algorithm design and analysis;Content based retrieval;Feedback;Image analysis;Image retrieval;Information retrieval;Kernel;Linear discriminant analysis;Radio frequency;Support vector machines","content-based retrieval;image retrieval;relevance feedback","content-based image retrieval relevance feedback algorithm;direct kernel biased discriminant analysis;real-world image collection;small sample size problem;support vector machine","","107","","36","","","Aug. 2006","","IEEE","IEEE Journals & Magazines"
"Using Medical Test Collection Relevance Judgements to Identify Ontological Relationships Useful for Query Expansion","D. Wollersheim; W. J. Rahayu","La Trobe University,Melbourne, Australia","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1160","1160","In this paper we describe an innovative query expansion evaluation framework (QEEF) which discovers the ontological and algorithmic characteristics that drive successful query expansion. The method consists of identifying UMLS (Unified Medical Language System) concepts in the Ohsumed corpus queries and documents, and then applying variety of query expansion algorithms to the query concepts, both individually and at the query level. We analyse the results, discovering the characteristics of high relevance medical query expansions. We directly evaluate query expansion success, and this enables discovery of the relationship between the UMLS facets and this success. The paper details the methods used, and then discusses the influence of both UMLS attributes, and choice of query expansion algorithm, on query expansion success.","","POD:0-7695-2657-8","10.1109/ICDE.2005.300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647763","","Back;Biomedical engineering;Computer science;Drives;Information resources;Information retrieval;Joining processes;Medical tests;Ontologies;Unified modeling language","","","","3","","14","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Schema update operations preserving the expressive power in XML databases","K. Hashimoto; Y. Ishihara; T. Fujiwara","Osaka University","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1229","1229","This paper proposes schema update operations preserving the expressive power in XML databases. XML documents are modeled as labeled ordered trees and schemas are modeled as regular tree grammars. Under these models, the notion of embeddability between tree languages is defined. We say that a schema G_2 has more expressive power than G_1 if the tree language generated by G_1 is embeddable in that generated by G-2. Then, four update operations on schemas are introduced. It is shown that the operations are sound with respect to preservation of the expressive power. Moreover, it is shown that the operations are also complete for local tree grammars, which correspond to DTDs.","","POD:0-7695-2657-8","10.1109/ICDE.2005.276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647846","","Data engineering;Databases;Distributed power generation;IEEE Staff;Information retrieval;Information science;Power generation;Remuneration;Usability;XML","","","","2","","10","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Supervised and unsupervised classification post-processing for visual video summaries","G. Ciocca; R. Schettini","Dept. of IT, Syst. & Commun., Milano-Bicocca Univ., Milan, Italy","IEEE Transactions on Consumer Electronics","20060705","2006","52","2","630","638","Representation of the video content using a set of key frames is one of the most common techniques for video summarization. Summaries composed of key frames allow users to grasp the overall content of a video, and access specific sequences. The post-processing algorithm presented in this paper makes it possible to create visual video summaries that are exhaustive, but not redundant, in three steps the method removes meaningless key frames, groups the key frames into clusters to allow multi-level summary presentation, and determines the default summary level. The algorithm utilizes both supervised and unsupervised classification strategies to perform these tasks. It requires no previous knowledge about the video contents, nor is any assumption made about the input data.","0098-3063;00983063","","10.1109/TCE.2006.1649689","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1649689","","Clustering algorithms;Gunshot detection systems;Image databases;Information retrieval;Layout;Multimedia databases;Multimedia systems;Resumes;Video sequences;Visual databases","image classification;image representation;video signal processing","classification post-processing algorithm;multilevel summary presentation;unsupervised classification strategies;video content representation;visual video summarization","","11","","26","","","May 2006","","IEEE","IEEE Journals & Magazines"
"Personalizing Pervasive Services on Top of Heterogeneous Networks","Yuping Yang; R. Everson; R. Dewar; M. H. Williams","Sch. of Eng., Comput. Sci. & Math., Exeter Univ.","2006 ACS/IEEE International Conference on Pervasive Services","20060710","2006","","","257","260","One of the challenges in pervasive computing is to provide personalized services which satisfy individual user goals. To achieve this, rich context information including user preferences need to be considered. This paper describes a personalization approach which is adopted in the European project Daidalos. It plays a paramount role in service composition, assists in QoS configuration, and provides support to the underlying network layer whilst user privacy is taken into account","","POD:1-4244-0237-9","10.1109/PERSER.2006.1652236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652236","","Collaboration;Computer science;Context awareness;Context-aware services;Information retrieval;Internet;Mathematics;Pervasive computing;Privacy;Security","data privacy;personal computing;quality of service;telecommunication security;ubiquitous computing","QoS configuration;heterogeneous networks;personalized services;pervasive computing;pervasive services;user preferences;user privacy","","0","","8","","","26-29 June 2006","","IEEE","IEEE Conference Publications"
"Concept hypotaxis semantic network: a knowledge representation model for multimedia data mining","He Ling; Wu Ling-da; Cai Yi-chao","Dept. of Inf. Syst. & Manage., Nat. Univ. of Defense Technol., Changsha, China","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","5 pp.","","Multimedia data mining (MDM) is one of the focused problems in current multimedia research domain. During MDM, based on user's annotations of corresponding media, it is crucial to represent those annotations correctly and completely to discover expected latent information. In other words, knowledge representation plays an important role in MDM. Existing representation models can express only static attributions of objects. But there are many important dynamic features in multimedia objects, especially in videos that should be represented correctly. In order to solve this problem, this paper proposes a new knowledge representation model - concept hypotaxis semantic network, whose significant contribution is to enable users to take the continuous and dynamic semantic features of media into account in MDM. Qualitative analyses and evaluations indicate that this model can be more flexible and general than others that only reflect static features of objects","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651360","","Content based retrieval;Data mining;Electronic mail;Helium;Information retrieval;Knowledge representation;Multimedia databases;Multimedia systems;Technology management;Videos","data mining;multimedia systems;semantic networks","concept hypotaxis semantic network;continuous semantic media features;dynamic semantic media features;expected latent information discovery;knowledge representation model;media annotations;multimedia data mining;multimedia objects","","0","","10","","","0-0 0","","IEEE","IEEE Conference Publications"
"Application of stochastic hybrid systems in power management of streaming data","Jianghai Hu","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","2006 American Control Conference","20060724","2006","","","6 pp.","","In this paper, we study the optimal power management problem for a pipeline of streaming data consisting of several components and buffers in between. The production rate of the source component is assumed to be random. We aim to find the optimal switching strategy and the optimal size of the buffers so that the expected average power consumption of the pipeline system is minimized. For the case of two components with one buffer in between, we model the system by a stochastic hybrid system, and derive analytically the solution to the optimal power management problem","0743-1619;07431619","Electronic:1-4244-0210-7; POD:1-4244-0209-3","10.1109/ACC.2006.1657472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1657472","","Buffer storage;Decoding;Energy consumption;Energy management;Information retrieval;Personal digital assistants;Pipelines;Power system management;Production;Stochastic systems","buffer storage;optimal systems;stochastic systems","average power consumption;data streaming;optimal power management;optimal switching strategy;pipeline system;source component;stochastic hybrid systems","","1","","15","","","14-16 June 2006","","IEEE","IEEE Conference Publications"
"Pre-Indexing for Fast Partial Shape Matching of Vertebrae Images","Xiaoqian Xu; D. J. Lee; S. Antani; L. R. Long","Brigham Young University, USA","19th IEEE Symposium on Computer-Based Medical Systems (CBMS'06)","20060705","2006","","","105","110","Fast retrieval of images from large databases especially from large medical image databases is of great interest to researchers. We have developed shape-based image retrieval system for spine X-ray images that applies dynamic programming (DP) in partial shape matching (PSM) techniques to vertebral boundary data. As we enable Internet access to this system with an aim to enable CBIR access to the entire NHANES II spine X-ray image collection, retrieval efficiency has become critical. In this paper, we present enhancements to our existing sequential retrieval model to provide faster partial-shape-based vertebrae retrieval. Based on the characteristics of vertebral osteophyte pathology, anterior superior and anterior inferior parts are the areas with the most interest to the users and are indexed for each shape. Pair-wise distances between indexed parts are pre-calculated and used by agglomerative clustering algorithm to index the whole database. To increase the retrieval speed, PSM with DP is therefore conducted only on a small selected set of shapes by the pre-indexing retrieval","1063-7125;10637125","POD:0-7695-2517-1","10.1109/CBMS.2006.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647554","","Biomedical imaging;Dynamic programming;Image databases;Image retrieval;Information retrieval;Internet;Pathology;Shape;Spine;X-ray imaging","PACS;bone;diagnostic radiography;image retrieval;medical image processing;statistical analysis","Internet access;NHANES II spine X-ray image collection;agglomerative clustering algorithm;anterior inferior;anterior superior;dynamic programming;fast partial shape matching;medical image databases;pairwise distances;preindexing retrieval;shape-based image retrieval system;vertebrae images;vertebral osteophyte pathology","","0","","15","","","0-0 0","","IEEE","IEEE Conference Publications"
"Optimization of Nested XQuery Expressions with Orderby Clauses","Song Wang; E. A. Rundensteiner; M. Mani","Worcester Polytechnic Institute, MA","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1277","1277","XQuery, the defacto XML query language, is a functional language with operational semantics, which precludes the direct application of classical query optimization techniques. The features of XQuery, such as nested expressions and ordered semantics, further aggravate this situation. The appropriate extension of existing optimization techniques to XQuery processing hence represents an important and non-trivial task. We propose an algebraic rewriting technique of nested XQuery expressions containing explicit orderby clauses. Unlike prior work, this technique enables the optimization of nested XQuery expressions not only with set but also with ordered sequence semantics. Our technique is based on two steps. First, we perform algebraic query unnesting. Second, we apply query minimization techniques that exploit pairwise XPath set containment after pulling up ordersensitive operations. We illustrate how our proposed technique is able to not only successfully tackle the XQuery logical optimization problem solved in the NEXT framework, but in addition to also to correctly support ordered semantics. We have implemented the proposed optimization techniques on top of the XAT algebraic framework in our RainbowCore project. We show the performance gain achievable by our approach using an experimental study with the RainbowCore engine.","","POD:0-7695-2657-8","10.1109/ICDE.2005.256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647895","","Application software;Books;Computer science;Database languages;Engines;Information retrieval;Performance gain;Query processing;Relational databases;XML","","","","1","","27","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Joint Segmentation and Classification of Dialog Acts in Multiparty Meetings","M. Zimmermann; A. Stolcke; E. Shriberg","International Computer Science Institute, USA. zimmerma@icsi.berkeley.edu","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","1","","I","I","This paper investigates a scheme for joint segmentation and classification of dialog acts (DAs) of the ICSI Meeting Corpus based on hidden-event language models and a maximum entropy classifier for the modeling of word boundary types. Specifically, the modeling of the boundary types takes into account dependencies between the duration of a pause and its surrounding words. Results for the proposed method compare favorably with our previous work on the same task","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660087","","Ambient intelligence;Computer science;Contracts;Degradation;Entropy;Information retrieval;Speech processing","maximum entropy methods;signal classification;speech processing","ICSI Meeting Corpus;dialog act classification;dialog act segmentation;hidden-event language models;maximum entropy classifier;multiparty meetings;word boundary types","","4","1","15","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"Web services: evolving techniques in net-centric operations","R. Ladner; E. Warner; F. Petry; U. Katikaneni; K. Shaw; K. Gupta; P. Moore","U.S. Naval Res. Lab., Stennis Space Center, MS, USA","Proceedings of OCEANS 2005 MTS/IEEE","20060626","2005","","","441","448 Vol. 1","Web services are often seen as the net-centric enabling technology for many US Navy operations. While Web services are increasingly used for data distribution in a network centric environment, Web services only constitute a baseline specification that provides the foundation on which application developers, under current approaches, write specialized software in order to retrieve data over the Internet. Software development and maintenance can increase with the increase in number of different available Web services due to such factors as new XML schema, XML schema versioning differences and variations in interface methods. In this paper, we provide an overview of Web services and provide examples of Web services for Navy net-centric operations as applied to meteorological and oceanographic (MetOc) data. We then present issues related to the evolution of MetOc Web services to particular Navy needs. Finally, we describe a new project we have begun, the Advanced MetOc Broker (AMB), which will assist with minimizing specialized software development for new and ad hoc Web services for the MetOc domain. The AMB will apply MetOc ontologies to knowledge-based techniques in order to support an advanced approach to the use of Web services; namely, the automated identification and retrieval of MetOc data.","0197-7385;01977385","Paper:0-933957-34-3","10.1109/OCEANS.2005.1639804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639804","Automated Reasoning;Intelligent Systems;MetOc Data;MetOc Ontology;Net-Centric Warfare;Web Services","Application software;IP networks;Information retrieval;Meteorology;Ontologies;Programming;Software maintenance;Web and internet services;Web services;XML","Internet;XML;data acquisition;information retrieval;information services;knowledge acquisition;knowledge based systems;naval engineering computing","Advanced MetOc Broker;Internet data retrieval;MetOc ontologies;United States Navy;Web services;XML schema;automated identification;automated reasoning;data distribution;intelligent systems;knowledge-based techniques;meteorological data;net-centric operations;net-centric warfare;oceanographic data;software development;software maintenance","","0","","16","","","17-23 Sept. 2005","","IEEE","IEEE Conference Publications"
"Graphics and the Understanding of Perceptual Mechanisms: Analogies and Similarities","L. Hess; B. Mayoh","Instituto Militar de Engenharia, Brazil","Geometric Modeling and Imaging--New Trends (GMAI'06)","20060724","2006","","","107","112","Graphics give an alternative representation model for images and graphic rewriting gives another viewpoint for image matching, image retrieval and identity of shape constancy - all subjects that have raised passionate discussion of mathematical models for both machine and human vision. Attributed graph grammars are a powerful way of describing transformations of complex structures. Attributed graph grammars have been applied to describe visual languages, distributed systems, chemical reactions, music analysis and much else. Graphics combine the geometry of human vision with the geometry of visual space. Graphic vertices model basic percept elements, graphic edges model percept and neighbour relations, attribute Sigma-algebras formalise space locations on space and transformations, while graphic grammars give rules that express perceived shapes. Graphics production can capture similarities of shapes, as a restriction of the graphic analogy reasoning on visual space. Composition of shapes by specific operations causes gradual distortions","","POD:0-7695-2604-7","10.1109/GMAI.2006.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648752","","Chemical analysis;Geometry;Graphics;Humans;Image matching;Image retrieval;Mathematical model;Music information retrieval;Power system modeling;Shape","attribute grammars;computational geometry;computer graphics;computer vision;graph grammars","attributed graph grammar;computational geometry;computer graphics;graphic edges model;graphic vertices model;machine vision","","0","","30","","","16-18 Aug. 1993","","IEEE","IEEE Conference Publications"
"PetaCache: A memory-Based Data-Server System","C. Boeheim; S. J. Gowdy; A. Hanushevsky; D. Leith; R. Melen; R. Mount; T. Pulliam; B. Weeks","","2006 15th IEEE International Conference on High Performance Distributed Computing","20060710","2006","","","349","350","Scientific advances depend increasingly on agility in the analysis of data, along with access to massive computation. The PetaCache project addresses the data-access issue by recognizing that the future for intense, non-sequential, data access must be based on low latency solid-state storage. The PetaCache architecture aims at a minimum unit cost, highly scalable hardware and software approach that can take advantage of existing and emerging solid-state storage technologies providing data-access latencies in the range 10-100 microseconds. A prototype system has been constructed as a cluster of 64 nodes hosting a total of one terabyte of memory. Client processors retrieve data from the data-server nodes over a switched Ethernet infrastructure using SLAC's xrootd data-server software. The system is in use for performance testing, optimization and trial deployments for scientific data analysis. It also provides an excellent platform for testing new data access paradigms","1082-8907;10828907","POD:1-4244-0307-3","10.1109/HPDC.2006.1652178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652178","","Computer architecture;Costs;Data analysis;Delay;Ethernet networks;Hardware;Information retrieval;Prototypes;Software prototyping;Solid state circuits","cache storage;data analysis;file servers;memory architecture","PetaCache architecture;SLAC xrootd data-server software;client processor;data access;memory-based data-server system;switched Ethernet infrastructure","","0","","5","","","0-0 0","","IEEE","IEEE Conference Publications"
"Factors affecting music retrieval in query-by-melody","T. De Mulder; J. P. Martens; S. Pauws; F. Vignoli; M. Lesaffre; M. Leman; B. De Baets; H. De Meyer","Dept. of Electron. & Inf. Syst., Ghent Univ., Belgium","IEEE Transactions on Multimedia","20060717","2006","8","4","728","739","This paper assesses the impact of three factors on the music retrieval accuracy of a query-by-melody (QBM) system. The investigated factors are the accuracy of the query provider (the singer), the query transcription accuracy of the acoustic front-end and the length of the query. The music retrieval accuracy is described in terms of a new concept, called the remaining information fraction (RIF). With this new concept it is possible to get more insight in the way the individual factors affect the music retrieval accuracy. The experimental results reported in this paper support the following conclusions: i) the music retrieval accuracy of a QBM system, as assessed on a large set of queries, is strongly correlated with the query transcription accuracy of its front-end, as assessed on a small set of manually transcribed queries, ii) there is still a significant gap between the accuracies obtained with manual and automatically generated query transcriptions, and iii) the music retrieval accuracy starts to drop quickly as soon as the query consists of less than 20 notes","1520-9210;15209210","","10.1109/TMM.2006.876291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1658035","Error analysis;man&#8211;machine systems;multimedia systems;music","Consumer products;Content based retrieval;Information systems;Instruments;Mathematics;Mining industry;Multimedia systems;Multiple signal classification;Music information retrieval;Performance analysis","error analysis;information retrieval;music","error analysis;music retrieval;query provider;query transcription accuracy;query-by-melody system","","2","","23","","","Aug. 2006","","IEEE","IEEE Journals & Magazines"
"A novel regions-of-interest based image retrieval using multiple features","Wang Xiangyang; Hu Fengli; Yang Hongying","Sch. of Comput. & Inf. Technique, Liaoning Normal Univ., Dalian, China","2006 12th International Multi-Media Modelling Conference","20060724","2006","","","4 pp.","","In this paper, a new ROI based color image retrieval is proposed. Firstly, the ROI are extracted in DWT domain by using the human visual characteristic and K-mean clustering. Secondly, the ROI is segmented into subregions, and the ROI features are extracted from the subregions (the dominant color and its percentage is used for color feature, the pixel distribution in the subregion is used for shape feature). Finally, the average similarity between images is computed according to the ROI above features. Experimental results show that our image retrieval is more accurate and efficient in retrieving the user-interested images when there are ROI in the image (especially for the image with simple background)","1550-5502;15505502","POD:1-4244-0028-7","10.1109/MMMC.2006.1651352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651352","Image retrieval;multi features;regions-of-interest;subregion","Color;Content based retrieval;Data mining;Frequency;Image retrieval;Image segmentation;Information retrieval;Multimedia databases;Visual perception;Wavelet transforms","discrete wavelet transforms;feature extraction;image colour analysis;image matching;image retrieval;image segmentation;pattern clustering","DWT;K-mean clustering;color image retrieval;feature extraction;human visual characteristic;images similarity;multiple features;regions-of-interest based image retrieval;user-interested images","","5","","12","","","0-0 0","","IEEE","IEEE Conference Publications"
"Toward Robust Distance Metric Analysis for Similarity Estimation","Jie Yu; Qi Tian; J. Amores; N. Sebe","University of Texas at San Antonio, TX, USA","2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)","20060705","2006","1","","316","322","In this paper, we present a general guideline to establish the relation between a distribution model and its corresponding similarity estimation. A rich set of distance metrics, such as harmonic distance and geometric distance, is derived according to Maximum Likelihood theory. These metrics can provide a more accurate feature model than the conventional Euclidean distance (SSD) and Manhattan distance (SAD). Because the feature elements are from heterogeneous sources and may have different influence on similarity estimation, the assumption of single isotropic distribution model is often inappropriate. We propose a novel boosted distance metric that not only finds the best distance metric that fits the distribution of the underlying elements but also selects the most important feature elements with respect to similarity. We experiment with different distance metrics for similarity estimation and compute the accuracy of different methods in two applications: stereo matching and motion tracking in video sequences. The boosted distance metric is tested on fifteen benchmark data sets from the UCI repository and two image retrieval applications. In all the experiments, robust results are obtained based on the proposed methods.","1063-6919;10636919","POD:0-7695-2597-0","10.1109/CVPR.2006.310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640775","","Benchmark testing;Euclidean distance;Guidelines;Image retrieval;Information retrieval;Maximum likelihood estimation;Motion estimation;Robustness;Tracking;Video sequences","","","","4","","18","","","17-22 June 2006","","IEEE","IEEE Conference Publications"
"An Enhanced Service Discovery Protocol for Bluetooth Scatternets","R. Favade; V. S. Kaulgud; S. A. Mondal","SETLabs., Infosys Technol. Ltd., Bangalore","2006 ACS/IEEE International Conference on Pervasive Services","20060710","2006","","","261","264","Service discovery lies at the heart of practical utility of Bluetooth scatternets. Even though Bluetooth incorporates a simple, lightweight SDP, it fails to provide efficient service discovery in complex usage scenarios such as service discovery on scatternets. In this paper, we propose augmentation to Bluetooth SDP to make it suitable for scatternets. We also present a detailed numerical and simulation analysis of the augmented SDP. The results validate the efficiency and practical utility of the enhanced SDP","","POD:1-4244-0237-9","10.1109/PERSER.2006.1652237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652237","","Analytical models;Availability;Bluetooth;Heart;Information retrieval;Numerical simulation;Personal area networks;Personal digital assistants;Probes;Routing protocols","Bluetooth;numerical analysis;protocols","bluetooth scatternets;numerical analysis;service discovery protocol;simulation analysis","","0","","9","","","26-29 June 2006","","IEEE","IEEE Conference Publications"
"Mining e-Learning Domain Concept Map from Academic Articles","Nian-Shing Chen; P. Kinshuk; Chun-Wang Wei; Hong-Jhe Chen","National Sun Yat-Sen University, Taiwan","Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)","20060724","2006","","","694","698","Recent research has demonstrated the important of ontology and its applications. For example, while designing adaptive learning materials, designers need to refer to the ontology of a subject domain. Moreover, ontology can show the whole picture and core knowledge about a subject domain. Research from literature also suggested that graphical representation of ontology can reduce the problems of information overload and learning disorientation for learners. However, ontology constructions used to rely on domain experts in the past; it is a time consuming and high cost task. Ontology creation for emerging new domains like e-learning is even more challenging. The aim of this paper is to construct e-learning domain concept maps, an alternative form of ontology, from academic articles. We adopt some relevant journal articles and conferences papers in e-learning domain as data sources, and apply text-mining techniques to automatically construct concept maps for e-learning domain. The constructed concept maps can provide a useful reference for researchers, who are new to e-leaning field, to study related issues, for teachers to design adaptive courses, and for learners to understand the whole picture of e-learning domain knowledge","2161-3761;21613761","POD:0-7695-2632-2","10.1109/ICALT.2006.1652537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1652537","","Costs;Education;Electronic learning;Information management;Information retrieval;Information technology;Knowledge representation;Management information systems;Natural language processing;Ontologies","computer aided instruction;data mining;educational administrative data processing;ontologies (artificial intelligence);text analysis","academic articles;adaptive learning materials;e-learning domain concept map mining;elearning domain knowledge;graphical representation;ontology constructions;text-mining","","1","","25","","","5-7 July 2006","","IEEE","IEEE Conference Publications"
"Minimizing I/O Costs of Multi-Dimensional Queries with Bitmap Indices","D. Rotem; K. Stockinger; Kesheng Wu","Lawrence Berkeley National Laboratory, UC Berkeley","18th International Conference on Scientific and Statistical Database Management (SSDBM'06)","20060724","2006","","","33","44","Bitmap indices have been widely used in scientific applications and commercial systems for processing complex, multi-dimensional queries where traditional tree-based indices would not work efficiently. A common approach for reducing the size of a bitmap index for high cardinality attributes is to group ranges of values of an attribute into bins and then build a bitmap for each bin rather than a bitmap for each value of the attribute. Binning reduces storage costs, however, results of queries based on bins often require additional filtering for discarding false positives, i.e., records in the result that do not satisfy the query constraints. This additional filtering, also known as candidate checking, requires access to the base data on disk and involves significant I/O costs. This paper studies strategies for minimizing the I/O costs for candidate checking for multi-dimensional queries. This is done by determining the number of bins allocated for each dimension and then placing bin boundaries in optimal locations. Our algorithms use knowledge of data distribution and query workload. We derive several analytical results concerning optimal bin allocation for a probabilistic query model. Our experimental evaluation with real life data shows an average I/O cost improvement of at least a factor of 10 for multi-dimensional queries on datasets from two different applications. Our experiments also indicate that the speedup increases with the number of query dimensions","1551-6393;15516393","POD:0-7695-2590-3","10.1109/SSDBM.2006.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1644295","","Costs;Cyclotrons;Data warehouses;Databases;Filtering;Indexing;Information retrieval;Laboratories;Query processing;Warehousing","cost reduction;data warehouses;database indexing;probability;query processing;scientific information systems","I/O cost minimization;bin allocation;bitmap indices;candidate checking;data distribution;data warehousing;multidimensional queries;probabilistic query model;query constraints;scientific applications;tree-based indices","","1","","22","","","0-0 0","","IEEE","IEEE Conference Publications"
"A Short-Term and Long-Term Learning Approach for Content-Based Image Retrieval","M. Wacht; J. Shan; Xiaojun Qi","Computer Science Department, Slippery Rock University, Slippery Rock, PA 16057, michael.wach@gmail.com","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","2","","II","II","This paper proposes a short-term and long-term learning approach for content-based image retrieval. The proposed system integrates the user's positive and negative feedback from all iterations to construct a semantic space to remember the user's intent in terms of the high-level hidden semantic features. The short-term learning further refines the query by updating its associated weight vector using both positive and negative examples together with the long-term-learning-based semantic space. The similarity score is computed as the dot product between the query weight vector and the high-level features of each image stored in the semantic space. Our proposed retrieval approach demonstrates a promising retrieval performance for an image database of 6000 general-purpose images from COREL, as compared with the conventional retrieval systems","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660361","","Computer science;Content based retrieval;Feature extraction;Image databases;Image retrieval;Information retrieval;Machine learning;Negative feedback;Shape;Support vector machines","content-based retrieval;image retrieval","content-based image retrieval;image database;long-term learning approach;negative feedback;positive feedback;query weight vector;semantic space;short-term learning approach","","5","","9","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
"An Automatic Method to Extract Data from an Electronic Contract Composed of a Number of Documents in PDF Format","T. Kwok; Thao Nguyen","IBM Research Division Thomas J. Watson Research Center, Hawthorne, NY","The 8th IEEE International Conference on E-Commerce Technology and The 3rd IEEE International Conference on Enterprise Computing, E-Commerce, and E-Services (CEC/EEE'06)","20060710","2006","","","33","33","An electronic contract can encompass a large number of collateral contract documents in PDF format. These contract documents are of different contract document types and converted from different original formats. Data extraction and thus data mining for this kind of electronic contracts is very difficult. In this paper, we present a novel method to automatically extract contract data from this kind of electronic contracts. Our automatic electronic contract data extraction system comprises an administrator module, a PDF parser, a pattern recognition engine and a contract data extraction engine. The administrator module provides templates for inputting document patterns and a list of contract data tags for each contract document type. It also constructs the pattern matrices and stores them in a database. The PDF parser converts the contract PDF document into the contract text document with the insertion of formatting bookmarks, such as a new page, paragraph or line. The pattern recognition engine determines a list of contract document types in the electronic contract by comparing and matching the patterns of all known contract document types with the pattern of the contract text document. The contract data extraction engine retrieves the corresponding list of contract data tags and then extracts contract data accordingly for each contract document type on the list. Our automatic electronic contract data extraction system has found to be very accurate, efficient and useful in extracting contract data for data mining","2378-1963;23781963","POD:0-7695-2511-3","10.1109/CEC-EEE.2006.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640288","","Business;Companies;Contracts;Data mining;Databases;Information retrieval;Matrix converters;Pattern matching;Pattern recognition;Search engines","contracts;data mining;document handling;electronic commerce;pattern recognition","PDF format;PDF parser;administrator module;contract data extraction engine;contract data tag;contract document type;data mining;electronic contract;pattern matching;pattern recognition engine","","3","","12","","","26-29 June 2006","","IEEE","IEEE Conference Publications"
"A Sentence Classification System for Multi Biomedical Literature Summarization","Y. Yamamoto; T. Takagi","University of Tokyo, Tokyo, Japan","21st International Conference on Data Engineering Workshops (ICDEW'05)","20060705","2005","","","1163","1163","A PubMed search often returns a long list of queryrelated papers that a researcher cannot cope with in a short time. As a first step to address this issue by summarizing retrieved papers, we developed a system to classify sentences of abstracts obtained from the MEDLINE database into five rhetorical statuses: background, purpose, method, result, or conclusion. We used Support Vector Machine (SVM) classifiers and trained each of them for a different rhetorical status on structured abstracts. A structured abstract is one that has labels indicating rhetorical statuses of the sentences, while an unstructured abstract does not. The classifiers were tested on both structured and unstructured abstracts. The former were randomly obtained from the MEDLINE database and the latter were manually labeled by humans. We compared our method with a previously reported one. In addition, we combined them and evaluated the combined method. Our method outperformed the previously reported one, and the combined method showed even better results. Classified abstracts can be used for multi-document summarization that provides researchers with a way of learning a research topic efficiently and effectively.","","POD:0-7695-2657-8","10.1109/ICDE.2005.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1647766","","Abstracts;Computer science;Costs;Databases;History;Humans;Information retrieval;Protein engineering;Support vector machine classification;Support vector machines","","","","1","","13","","","05-08 April 2005","","IEEE","IEEE Conference Publications"
"Context-Based Conceptual Image Indexing","S. Ayache; G. Quenot; S. Satoh","CLIPS-IMAG, BP 53, 38041 Grenoble Cedex 9, France","2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings","20060724","2006","2","","II","II","Automatic semantic classification of image databases is very useful for users searching and browsing but it is at the same time a very challenging research problem. Local features based image classification is one of the promising way to bridge the semantic gap in detecting concepts. This paper proposes a framework for incorporating contextual information into the concept detection process. The proposed method combines local and global classifiers (SVMs) with stacking. We studied the impact of topologic and semantic contexts in concept detection performance and proposed solutions to handle the large amount of dimensions involved in classified data. We conducted experiments on TRECVID'04 data set with 48104 images and 5 concepts. We found that the use of context yields a significant improvement both for the topologic and semantic contexts","1520-6149;15206149","POD:1-4244-0469-X","10.1109/ICASSP.2006.1660369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1660369","","Bridges;Fuses;Image classification;Image databases;Image retrieval;Indexing;Informatics;Information retrieval;Spatial databases;Stacking","database indexing;image classification;visual databases","SVM;automatic semantic classification;concept detection process;context-based conceptual image indexing;image databases","","3","1","15","","","14-19 May 2006","","IEEE","IEEE Conference Publications"
