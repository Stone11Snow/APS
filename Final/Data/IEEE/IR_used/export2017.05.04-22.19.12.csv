"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6814684,6815302,6595093,6741547,6742577,6384736,6805995,6807904,6808599,6808235,6804850,6802594,6802528,6802784,6798296,6799914,6799493,6799536,6799616,6799116,6787157,6787142,6787131,6787190,6786172,6784629,6785899,6658945,6785880,6786129,6785897,6785902,6785882,6785805,6785758,6785807,6784659,6784639,6785750,6785745,6785813,6785760,6785814,6785686,6781332,6755149,6781335,6781269,6781351,6781348,6755111,6781494,6780069,6780086,6754896,6778929,6778204,6779514,6778643,6778620,6778624,6778337,6778612,6778317,6779449,6778688,6778664,6778629,6779492,6654144,6775871,6775845,6765498,6766349,6761567,6632881,6549154,6516061,6725686,6477044,6761171,6761170,6758967,6758781,6758777,6758741,6681917,6755337,6753915,6753859,6755720,6755320,6755778,6755338,6755317,6753956,6754943,6753902,6753958,6756042",2017/05/04 22:19:12
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A re-ranking technique for diversified recommendations","C. B. Patil; R. B. Wagh","RCPIT, Shirpur, India","2013 Nirma University International Conference on Engineering (NUiCONE)","20140331","2013","","","1","6","User satisfaction is the most important challenge for any user oriented system. Especially in today's world where tremendous amount of information is available, which can be used for knowledge discovery to find out user's interest. Recommender systems which are simulations of web personalization are now days widely integrated in various domains for quality improvements. Recent studies has shown that to improve user satisfaction one should also consider other quality factors such as diversity rather than relying only on accuracy of recommendations. We propose a hybrid approach of recommendation which re-ranks the most relevant predicted items according to the specified criteria MCBRT. We aim at maintaining substantially higher aggregate diversity across all users while maintaining adequate level of recommendation accuracy.","2375-1282;23751282","Electronic:978-1-4799-0727-4; POD:978-1-4799-0725-0","10.1109/NUiCONE.2013.6780086","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6780086","MCBRT;accuracy;diversity;web personalization","Accuracy;Aggregates;Algorithm design and analysis;Diversity reception;Measurement;Motion pictures;Recommender systems","information retrieval;recommender systems","MCBRT criteria;Web personalization;diversified recommendations;knowledge discovery;recommendation accuracy;recommender systems;reranking technique;user oriented system;user satisfaction","","0","","14","","","28-30 Nov. 2013","","IEEE","IEEE Conference Publications"
"Rebuilding KEGG Maps: Algorithms and Benefits","A. Gerasch; M. Kaufmann; O. Kohlbacher","Dept. of Comput. Sci., Univ. of Tubingen, Tubingen, Germany","2014 IEEE Pacific Visualization Symposium","20140414","2014","","","97","104","Static drawings of biological pathways are still an important research tool for biologists. Gerhard Michal created his seminal drawings of metabolic networks in the 1960s and thus defined canonical representations of some key pathways. The Kyoto Encyclopedia of Genes and Genomes (KEGG) provides the most popular static drawings of biological networks of different types, used in a huge number of publications. These drawings are so widely known that they are immediately recognizable to most biologists. This enables collaborative work and simplifies the communication of analysis results. Automatic layout of these pathway maps is complicated by the fact that the information available from KEGG does not contain the entire layout information of the reference maps. Here we present a fully automated algorithm for interactive KEGG layout construction. The algorithm conserves the original KEGG layout to the extent possible while improving readability by removing unnecessary elements (in organism-specific maps). Multiple pathway maps can be laid out simultaneously to facilitate the navigation of larger networks. The algorithm supports the hierarchical layout of sub networks and thus supports interactive exploration of large datasets.","2165-8765;21658765","Electronic:978-1-4799-2874-3; POD:978-1-4799-2875-0","10.1109/PacificVis.2014.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787142","Computer Applications Life and Medical Sciences Medical Information Systems;Computing Methodologies Computer Graphics Applications","Biochemistry;Compounds;Data visualization;Layout;Routing;Visualization","biology computing;data visualisation;graph theory;information retrieval;information retrieval systems;interactive systems","KEGG maps;Kyoto Encyclopedia of Genes and Genomes;automated algorithm;automatic pathway map layout;biological pathways;biologists;hierarchical subnetwork layout;interactive KEGG layout construction;interactive large dataset exploration;layout information;metabolic networks;readability improvement;static drawings","","0","","29","","","4-7 March 2014","","IEEE","IEEE Conference Publications"
"Research and design of system on monitoring and analyzing the internet information for food safety","F. L. Yang; J. Y. Cui; J. H. Li; W. S. Gui; H. Y. Wang","Comput. Network Inf. Center, Beijing, China","IET International Conference on Information Science and Control Engineering 2012 (ICISCE 2012)","20140306","2012","","","1","7","For the actual demand on food safety emergency management, this paper researches some key techniques such as web page crawling that collects subject-related and timely information, the deceptive spam opinion identification which based on the machine learning method of “learning from positive and unlabeled examples”, the food safety incidents' information extraction and warning which based on the ontology and so on. On the basis above, this paper researches and designs the system on monitoring and analyzing the Internet information for food safety, and the system prototype has been achieved.","","Electronic:978-1-84919-641-3","10.1049/cp.2012.2399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755778","Food Safety;Information Analyzing;Information Monitoring;Vertical Search","","Internet;emergency management;food safety;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);production engineering computing","Internet information;Web page crawling;deceptive spam opinion identification;food safety emergency management;food safety incidents;information extraction;machine learning method;ontology;system prototype;unlabeled examples","","0","","","","","7-9 Dec. 2012","","IET","IET Conference Publications"
"A novel approach for content extraction from web pages","A. Bhardwaj; V. Mangat","UIET, Panjab Univ., Chandigarh, India","2014 Recent Advances in Engineering and Computational Sciences (RAECS)","20140417","2014","","","1","4","The rapid development of the internet and web publishing techniques create numerous information sources published as HTML pages on World Wide Web. However, there is lot of redundant and irrelevant information also on web pages. Navigation panels, Table of content (TOC), advertisements, copyright statements, service catalogs, privacy policies etc. on web pages are considered as relevant and irrelevant content. Such information makes various web mining tasks such as web page crawling, web page classification, link based ranking, topic distillation complex. This paper discusses various approaches for extracting informative content from web pages and a new approach for content extraction from web pages using word to leaf ratio and density of links.","","CD-ROM:978-1-4799-2290-1; Electronic:978-1-4799-2291-8; POD:978-1-4799-2292-5","10.1109/RAECS.2014.6799616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799616","Content Structure Tree;Content extraction;Document object Model;Entropy;Vision Based Page Segmentation;anchor text;clustering;hub and authority;ontology generation;template;web page segmentation","Clustering algorithms;Data mining;Entropy;Feature extraction;HTML;Navigation;Web pages","Web sites;content management;hypermedia markup languages;information retrieval","HTML pages;Internet;TOC;Web mining tasks;Web page classification;Web page crawling;Web publishing techniques;World Wide Web;advertisements;copyright statements;information sources;informative content extraction;link based ranking;links density;navigation panels;privacy policies;service catalogs;table of content;topic distillation complex;word to leaf ratio","","2","","20","","","6-8 March 2014","","IEEE","IEEE Conference Publications"
"Searching application for Southern Thailand Travel Guide on iPhone","H. Ketmaneechairat; P. Yoksiri; T. Jaisiri","Coll. of Ind. Technol., King Mongkut's Univ. of Technol. North Bangkok, Bangkok, Thailand","The Fifth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT 2014)","20140515","2014","","","195","200","Recently, the travel guides have become an important tool to support tourists around the world. The tourists will search the tourist attraction and travel information from the book, brochure or website. In this paper, the searching application for Southern Thailand Travel Guide on iPhone is proposed. The proposed application is developed to search for travel guide information on different provinces of the Southern Thailand. The searching application function is divided into two modes: online and offline mode. The language can be displayed in two languages: Thai and English language. This paper presents the design and implementation by using Apple's iOS Software Development Kit. The results show that the tourists can search tourist attraction including history, picture, address, phone number, website, map and travel detail. The maps can show the current location of the users. In addition, these maps can display in three modes: standard, satellite and hybrid. Overall information on tourist attraction can be shared on Facebook, Twitter and E-mail. The proposed application is better support for the foreign tourists and Thai tourists that they are used iPhone mobile.","","Electronic:978-1-4799-2259-8; POD:978-1-4799-2260-4","10.1109/ICADIWT.2014.6814684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6814684","Searching Application;Southern Thailand;Tourist Attraction;Travel Guide;iPhone","Computer languages;Databases;Educational institutions;History;Mobile communication;Mobile handsets;Software","cartography;electronic mail;information retrieval;mobile computing;natural language processing;operating systems (computers);smart phones;social networking (online);travel industry","Apple iOS software development kit;English language;Facebook;Southern Thailand travel guide;Thai language;Twitter;Website;address;book;brochure;e-mail;history;iPhone;map;offline mode;online mode;phone number;picture;searching application function;tourist attraction search;travel detail;travel information search","","1","","11","","","17-19 Feb. 2014","","IEEE","IEEE Conference Publications"
"Solving task scheduling problem in multi-processors with genetic algorithm and task duplication","H. A. Bazoobandi; M. Khorashadizadeh; M. Eftekhari","Comput. Eng. Dept., Univ. of Birjand, Birjand, Iran","2014 Iranian Conference on Intelligent Systems (ICIS)","20140421","2014","","","1","4","Parallel arithmetic are methods for processing in distributed and multi processors environments. The purpose of parallel arithmetic is to accelerate executing a group of tasks, dividing applications to sub-tasks and executing them at the same time. In this paper, we propose a genetic based technique for solving task scheduling in multi-processor systems. In some cases, the cost to execute a task becomes more than retrieving the information of task from one processor to another. To address this property we use a thought-out task duplication policy to decrease the overall computation time. Because each task can duplicate more than once, the length of chromosomes in the proposed method will change dynamically. Furthermore, a simple and efficient strategy is proposed for task priority assignment. Experimental results confirm the effectiveness of our proposed method in seven benchmark problems in comparison with previous works.","","Electronic:978-1-4799-3351-8; POD:978-1-4799-3352-5","10.1109/IranianCIS.2014.6802528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802528","Genetic Algorithm;Multi-processor Task Scheduling;Parallel Processing;Task Duplication","Biological cells;Computers;Genetic algorithms;Processor scheduling;Program processors;Scheduling;Sociology","benchmark testing;distributed arithmetic;genetic algorithms;information retrieval;parallel processing;processor scheduling","distributed environments;genetic algorithm;genetic based technique;information retrieval;multiprocessor environments;multiprocessor systems;parallel arithmetics;task scheduling;task scheduling problem;thought-out task duplication policy","","0","","16","","","4-6 Feb. 2014","","IEEE","IEEE Conference Publications"
"What is he/she like?: Estimating Twitter user attributes from contents and social neighbors","J. Ito; T. Hoshide; H. Toda; T. Uchiyama; K. Nishida","NTT Service Evolution Laboratories, NTT Corporation, 1-1 Hikari-no-oka, Yokosuka-shi, Kanagawa 239-0847, Japan","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","1448","1450","We propose a new method for estimating user attributes (gender, age, occupation, and interests) of a Twitter user from the user's contents (profile document and tweets) and social neighbors, i.e. those whom the user has mentioned. Our labeling method is able to collect a large amount of training data automatically by using Twitter users associated with a blog account. Furthermore, we experiment estimation methods using social neighbors with three adjustable levels of its information and show that our method, which uses the target user's profile document and tweets and the neighbors' profile documents (not including tweets), achieves the best accuracy.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492585","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785899","","Accuracy;Blogs;Estimation;Labeling;Manuals;Training data;Twitter","document handling;information retrieval;social networking (online)","Twitter user attributes estimation;blog account;labeling method;neighbor profile documents;social neighbors;target user profile document;training data;user contents","","1","1","7","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Information-centric communication architecture for vehicular networking","S. Ata; H. Kitamura; M. Murata","Grad. Sch. of Eng., Osaka City Univ., Osaka, Japan","2013 International Conference on Connected Vehicles and Expo (ICCVE)","20140417","2013","","","853","854","In the network of connected vehicles with various devices and sensors, the most of communications should be information centric by short messages, which are delivered to the appropriate receivers according to the content itself. However, developing a new communication architecture is not feasible not only in aspect of cost and deployment, but also the interoperability to IP networks to retrieve the information from the Internet. In this paper, we propose a new communication architecture to support information-centric by using IP infrastructure. For this purpose we design name mapping and completion scheme for efficient and lightweight information retrieval.","2378-1289;23781289","Electronic:978-1-4799-2491-2; POD:978-1-4799-2492-9","10.1109/ICCVE.2013.6799914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799914","","Abstracts;Computer architecture;Educational institutions;IP networks;Security;Servers;Vehicles","IP networks;Internet;information retrieval;mobile communication;radio receivers","IP networks;Internet;information retrieval;information-centric communication architecture;sensors;short messages;vehicular networking","","1","","6","","","2-6 Dec. 2013","","IEEE","IEEE Conference Publications"
"Web search personalization using machine learning techniques","T. Bibi; P. Dixit; R. Ghule; R. Jadhav","Comput. Dept., PICT, Pune, India","2014 IEEE International Advance Computing Conference (IACC)","20140327","2014","","","1296","1299","Information on the web is increasing at an enormous speed. Every user has a distinct background and aspecific goal when searching for information on the web. Present search engines produce results that are best suited to given query. But these engines are unaware of user's individual preferences which in turn can vary with individual interest and these interests most of the time change with individual working environment time. To provide such personalized results, user's topical preferences could be stored and utilized for the purpose. Different approaches have been implemented for the same such as, Collaborative Filtering, Document-Based or Concept based profiling etc. We are proposing hybrid approach based on Document Based as well as Concept Based Profiling. Proposed framework aims to re-rank results for a given query obtained from existing search engines. Thus this system would provide an adaptive methodology for learning changing user preferences to re-rank results according to one's individual interests.","","CD-ROM:978-1-4799-2571-1; Electronic:978-1-4799-2572-8; POD:978-1-4799-2573-5","10.1109/IAdCC.2014.6779514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6779514","Web Personalization;click-through data;concept;ontology;user preference;user profile","Browsers;Computers;Conferences;Data mining;Search engines;Taxonomy;Web search","Internet;information retrieval;learning (artificial intelligence);search engines","Web search personalization;World Wide Web;concept based profiling;document based profiling;machine learning;search engine","","0","","12","","","21-22 Feb. 2014","","IEEE","IEEE Conference Publications"
"SAFAL: A MapReduce Spatio-temporal Analyzer for UNAVCO FTP Logs","K. Hodgkinson; A. Rezgui","Plate Boundary Obs., UNAVCO, Boulder, CO, USA","2013 IEEE 16th International Conference on Computational Science and Engineering","20140306","2013","","","1083","1090","UNAVCO is a National Science Foundation (NSF) funded consortium that facilitates geoscience research and education using geodesy. It is responsible for the collection, archiving and distribution of data from GPS sites installed in every continent of the world. In addition to GPS data, UNAVCO collects borehole seismic, strain meter, meteorological, and digital imagery data. One of UNAVCO's largest programs is the Plate Boundary Observatory (PBO), the geodetic component of the NSF funded Earth scope program. PBO consists of over 1100 continuous GPS sites plus 80 borehole strain and seismic sites. In this paper, we present SAFAL, a Spatio-temporal Analyzer of FTP Access Logs collected by UNAVCO's data center. We developed SAFAL using Hadoop/MapReduce. The motivation for this work was to build an efficient system able to quickly identify trends in GPS data usage. The system is able to processes millions of lines of data in minutes. It supports queries such as: (i) what is the most downloaded GPS site, (ii) who is downloading the data most, or (iii) what periods of data are of greatest interest. Answers to these and similar queries are useful for planning network growth, allocating Web resources, and tracking hot topics in geoscience research. They also may be extremely useful to help UNAVCO illuminate dark data.","","Electronic:978-0-7695-5096-1; POD:978-1-4799-4897-0","10.1109/CSE.2013.157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755338","FTP access logs;GPS sites;Hadoop;MapReduce;Web usage mining","Data mining;Geoscience;Global Positioning System;Planning;Servers;US Government","Global Positioning System;Internet;data acquisition;data mining;geodesy;geographic information systems;information retrieval","FTP access logs;GPS data usage;GPS sites;Hadoop;MapReduce spatio-temporal analyzer;NSF funded Earth scope program;NSF funded consortium;National Science Foundation;PBO;SAFAL;UNAVCO FTP logs;UNAVCO data center;Web usage mining;borehole seismic data;borehole strain;data archiving;data collection;data distribution;digital imagery data;geodesy;geodetic component;geoscience education;geoscience research;meteorological data;plate boundary observatory;strain meter","","0","","5","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Storing Sparse Messages in Networks of Neural Cliques","B. K. Aliabadi; C. Berrou; V. Gripon; X. Jiang","Electronics Department, Brest, France","IEEE Transactions on Neural Networks and Learning Systems","20140410","2014","25","5","980","989","An extension to a recently introduced binary neural network is proposed to allow the storage of sparse messages, in large numbers and with high memory efficiency. This new network is justified both in biological and informational terms. The storage and retrieval rules are detailed and illustrated by various simulation results.","2162-237X;2162237X","","10.1109/TNNLS.2013.2285253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658945","Associative memory;error correcting code;machine learning;parsimony;recurrent neural network;sparse coding;sparse coding.","Biological information theory;Dictionaries;Error correction codes;Indexes;Neural networks;Neurons;Robustness","content-addressable storage;information retrieval systems;neural nets","associative memory;binary neural network;error correcting code;machine learning;neural cliques networks;retrieval rules;sparse messages storage","1","10","","32","","20131108","May 2014","","IEEE","IEEE Journals & Magazines"
"Modified weighting method in TF∗IDF algorithm for extracting user topic based on email and social media in Integrated Digital Assistant","L. H. Pramono; A. S. Rohman; D. H. Hindersah","Electr. Eng. Dept., Bandung Inst. of Technol., Bandung, Indonesia","2013 Joint International Conference on Rural Information & Communication Technology and Electric-Vehicle Technology (rICT & ICeV-T)","20140508","2013","","","1","6","Integrated Digital Assistant (IDA) is a system designed to be a ""personal secretary"" who worked in full for the user. IDA will be active when the user is relaxing at home, office activities and even while traveling or outside activities. IDA works to minimize the interaction between user and system. The system will be able to find out information from the outside that is needed by users by searching users' topics through email and social media data. Searching and extracting user interest or topics in social media and email data of IDA is using TF*IDF weighting modification algorithm named TF*IDF*DF which is extend of TF*IDF method. Expected with TF*IDF weighting modification algorithm, topics that obtained more representative and in accordance with the information needed by the user. From extraction by using TF*IDF*DF, the number of terms (words) that has a value of document frequency (df) more than one are increases. On the other hand the computational load is also increasing due to the multiplier factor of df. News taken based on the extracted topic using the TF*IDF*DF increased and more diverse. The term from topic extraction result still have noisy text that not appropriate to grammar writing and need to be fixed, so the term that found will be more perfect.","","CD-ROM:978-1-4799-3364-8; Electronic:978-1-4799-3365-5; POD:978-1-4799-3366-2","10.1109/rICT-ICeVT.2013.6741547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6741547","TF∗IDF;feature selection;topic extraction;topic model;user topic","Algorithm design and analysis;Conferences;Data mining;Electronic mail;Feature extraction;Media;Twitter","Internet;electronic mail;information retrieval;social networking (online);text analysis","IDA;TF*IDF*DF algorithm;document frequency;email;grammar writing;integrated digital assistant;modified weighting method;personal secretary;social media;user topic extraction","","0","","20","","","26-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"Discovery and Analysis of Usage Data Based on Hadoop for Personalized Information Access","D. Xia; Z. Rong; Y. Zhou; B. Wang; Y. Li; Z. Zhang","Sch. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China","2013 IEEE 16th International Conference on Computational Science and Engineering","20140306","2013","","","917","924","The discovery and analysis of valuable information hidden in the usage data become more and more important with the exponential growth of Web users, for offering personalized information access. Since the traditional methods are unable to effectively solve the tasks of mining semi-structured and/or unstructured data in the single platform, in this paper, we propose three methods for respectively mining user browsing preference, visiting frequency and participating characteristics, based on the Hadoop cluster by MapReduce. Moreover, we apply our methods to the Web server logs and Developer mailing lists, and analyze the visualization of mining results in order to gain a deeper understanding of user access patterns and interactive behaviors. The experimental results show that our methods can provide further insights into some useful information from usage data for decision making with a good speedup and scalability.","","Electronic:978-0-7695-5096-1; POD:978-1-4799-4897-0","10.1109/CSE.2013.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755317","big data analytics;data visualization;hadoop mapreduce;web usage mining","Data mining;Electronic mail;NASA;Scalability;Visualization;Web servers;Web sites","Internet;data loggers;data mining;data visualisation;information retrieval","Developer mailing lists;Hadoop cluster;MapReduce;Web server logs;Web user exponential growth;decision making;interactive behaviors;participating characteristics;personalized information access;usage data analysis;usage data discovery;user access patterns;user browsing preference mining;valuable information analysis;valuable information discovery;visiting frequency;visualization","","0","","42","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Zombies Walk Among Us: Cross-Platform Data Mining for Event Monitoring","E. L. Tonkin; H. D. Pfeiffer","Digital Humanities, King's Coll. London, London, UK","2013 IEEE 13th International Conference on Data Mining Workshops","20140306","2013","","","452","459","Social networks such as Facebook, Orkut and so on, are repositories of information that are viewed as users' opinions. However, data mining across multiple social websites can reveal valuable factual information for both monitoring and reconstructing events. Crowd sourcing can be used on these sites to monitor `flash mob' group behaviors, loosely or formally planned activities, such as `zombie walks'. In certain contexts, these walks are `marketed' to social site users in order to promote charitable or social engagements, in others, analysis suggests that participation is a form of political engagement. We use multi-platform information extraction to build an atlas of geographic and demographic events, which leads us to compelling, yet imperfect, understanding of why events are successful and regionally relevant factors that encourage people to pick up behaviors or participate in movements. More generally, this case study confirms that `big-data'-led analysis of this kind is reasonably straightforward and rewarding, as well as providing a useful basis for Bayesian reasoning: the use of available evidence to evaluate propositions about this type of events.","2375-9232;23759232","Electronic:978-1-4799-3142-2; POD:978-1-4799-3144-6","10.1109/ICDMW.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753956","Data Mining;Social Networks;Zombie Walks","Cities and towns;Data mining;Facebook;Media;MySpace;Twitter","Bayes methods;Big Data;data analysis;data mining;information retrieval;social networking (online)","Bayesian reasoning;big-data-led analysis;charitable engagement;cross-platform data mining;crowd sourcing;demographic events;event monitoring;factual information;flash mob group behavior monitoring;formally planned activities;geographic events;loosely planned activities;multiplatform information extraction;political engagement;social engagement;social network;social websites;zombie walks","","0","","26","","","7-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"A comparison of Web robot and human requests","D. Doran; K. Morillo; S. S. Gokhale","Dept. of Computer Science and Engineering, Univ. of Connecticut, Storrs, 06269, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","1374","1380","Sophisticated Web robots sport a wide variety of functionality and visiting characteristics, constituting a significant percentage of the requests serviced by a Web server. Unlike human clients that retrieve information off a site by navigating links and ignoring irrelevant information, Web robots may collect many different types of resources, and employ varying navigation strategies to find the knowledge on the site they desire. Thus, the resource request patterns of their visits are unpredictable and cannot be inferred based on our knowledge of human request patterns. In this paper, we perform an analysis on the types of resources requested by Web robots using recent Web logs from an academic Web server. We study the distribution of response sizes and response codes, the types of resources requested, and popularity of resources for requests from Web robots. Throughout, we contrast our findings against human resource request patterns. We find reasons to suggest that robots severely handicaps the ability of Web server caches to operate with high performance.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2500239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785880","","Browsers;HTML;Market research;Navigation;Robots;Web servers","Internet;cache storage;file servers;information retrieval","Web logs;Web robot;Web server caches;academic Web server;human clients;human request patterns;human resource request patterns;information retrieve;resource request patterns;response codes;response sizes;visiting characteristics","","1","","36","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Learning Relevance of Web Resources across Domains to Make Recommendations","J. Hoxha; P. Mika; R. Blanco","Karlsruhe Inst. of Technol., Karlsruhe, Germany","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","325","330","Most traditional recommender systems focus on the objective of improving the accuracy of recommendations in a single domain. However, preferences of users may extend over multiple domains, especially in the Web where users often have browsing preferences that span across different sites, while being unaware of relevant resources on other sites. This work tackles the problem of recommending resources from various domains by exploiting the semantic content of these resources in combination with patterns of user browsing behavior. We overcome the lack of overlaps between domains by deriving connections based on the explored semantic content of Web resources. We present an approach that applies Support Vector Machines for learning the relevance of resources and predicting which ones are the most relevant to recommend to a user, given that the user is currently viewing a certain page. In real-world datasets of semantically-enriched logs of user browsing behavior at multiple Web sites, we study the impact of structure in generating accurate recommendations and conduct experiments that demonstrate the effectiveness of our approach.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786129","cross-domain recommendations;hybrid semantic recommender;semantic logs;support vector machines","HTML;Ontologies;Recommender systems;Semantics;Vectors;Web pages","Web sites;information retrieval;learning (artificial intelligence);recommender systems;support vector machines","Web page;Web resource relevance learning;Web sites;real-world datasets;recommendation accuracy improvement;recommender systems;resource recommendation;semantic Web resource content;semantically-enriched logs;support vector machines;user browsing behavior patterns;user browsing preferences","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Location-specific tweet detection and topic summarization in Twitter","V. Rakesh; C. K. Reddy; D. Singh; M. Ramachandran","Department of Computer Science, Wayne State University, Detroit, MI, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","1441","1444","Automatic detection of tweets that provide Location-specific information will be extremely useful in conveying geo-location based knowledge to the users. However, there is a significant challenge in retrieving such tweets due to the sparsity of geo-tag information, the short textual nature of tweets, and the lack of pre-defined set of topics. In this paper, we develop a novel framework to identify and summarize tweets that are specific to a location. First, we propose a weighting scheme called Location Centric Word Co-occurrence (LCWC) that uses the content of the tweets and the network information of the twitterers to identify tweets that are location-specific. We evaluate the proposed model using a set of annotated tweets and compare the performance with other weighting schemes studied in the literature. This paper reports three key findings: (a) top trending tweets from a location are poor descriptors of location-specific tweets, (b) ranking tweets purely based on users' geo-location cannot ascertain the location specificity of tweets, and (c) users' network information plays an important role in determining the location-specific characteristics of the tweets. Finally, we train a topic model based on Latent Dirichlet Allocation (LDA) using a large collection of local news database and tweet-based Urls to predict the topics from the location-specific tweets and present them using an interactive web-based interface.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785897","","Resource management","information retrieval;social networking (online)","LCWC;LDA;Twitter;annotated tweets;geo-location based knowledge;geo-tag information sparsity;interactive Web-based interface;latent Dirichlet allocation;local news database;location centric word cooccurrence;location-specific information;location-specific tweet detection;network information;topic summarization;tweet automatic detection;user network information","","1","","12","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Service-Oriented Remote Operation System for J-TEXT Tokamak","W. Zheng; M. Zhang; G. Li; J. Zhang; G. Zhuang","State Key Lab. of Adv. Electromagn. Eng. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","IEEE Transactions on Plasma Science","20140307","2014","42","3","477","481","To fully use the tokamak facility, it is necessary to allow researchers to remotely participate in the tokamak experiments via the Internet. Being able to control the operation of the tokamak is a key point. In this paper, the design and implementation of the remote operation system for the Joint Texas Experimental Tokamak (J-TEXT) are presented. To make this system flexible, the service-oriented design is applied. Instead of just providing software or website that controls devices and instruments on the tokamak, a series of Application Programming Interfaces are exposed as web services. All the operations of the J-TEXT tokamak are wrapped in these services. The representational state transfer design practice has been adopted to ensure that these services are accessible by various clients. A remote operation website based on these services has been developed. However, users can build their own websites or remote control rooms, which consume these services to operate the J-TEXT tokamak. An authorization and authentication system is included to prevent the users from consuming unauthorized services. The proposed remote operation system is compatible with Experimental Physics and Industrial Control System and has been integrated within the J-TEXT control, data access, and communication system.","0093-3813;00933813","","10.1109/TPS.2013.2292713","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681917","Control data access and communication (CODAC);experimental physics and industrial control system (EPICS);remote participation;tokamak control system;web service","Authentication;Browsers;Control systems;Instruments;Monitoring;Tokamaks;Web services","Tokamak devices;Web services;data communication;information retrieval;physics computing;plasma toroidal confinement;service-oriented architecture","Internet;J-TEXT control;J-TEXT tokamak;Joint Texas Experimental Tokamak;Web services;Website;authentication system;authorization system;control devices;data access system;data communication system;programming interface application;representational state transfer design;service-oriented remote operation system;software","","1","","19","","20131211","March 2014","","IEEE","IEEE Journals & Magazines"
"5WTAG: Detecting the Topics of Chinese Microblogs Based on 5W Model","Z. Zhibin; J. Yanfeng; Y. Lan; Y. Ge; L. Xiangyang","Coll. of Inf. Sci. & Eng., Northeastern Univ., Shenyang, China","2013 10th Web Information System and Application Conference","20140327","2013","","","237","242","A hash tag is an important metadata in micro blogs and used to mark topics or index messages. However, statistics show hash tags are absent from most of the micro blogs. It poses great challenges to the retrieve and analysis of these tagless micro blogs. In this paper, we summarize the similarity between micro blogs and short message news, and then propose an algorithm named 5WTAG for detecting micro blog topics based on 5W (When, Where, Who, What, how) model. Since 5W attributes are the core components in event description, it is guaranteed theoretically that 5WTAG can extract the semantics of the micro blogs properly. We introduce the detailed procedure of 5WTAG in this paper including the candidate hash tag construction and recommendation computation. Finally, we verify the semantical correctness of the candidate hash tags as well as the effectiveness of recommendation computation using the real data set from Sina Weibo.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778643","5W model;hashtag;microblog;topic detection","Computational modeling;Educational institutions;Indexes;Particle separators;Semantics;Syntactics;Twitter","electronic messaging;information retrieval;meta data;recommender systems;social networking (online)","5W attributes;5W model;5WTAG;Chinese microblog topic detection;Sina Weibo;candidate hashtag construction;event description;metadata;recommendation computation;semantics extraction;short message news","","0","","14","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Ubiquitous Data Accessing Method in IoT-Based Information System for Emergency Medical Services","B. Xu; L. D. Xu; H. Cai; C. Xie; J. Hu; F. Bu","Coll. of Econ. & Manage., Shanghai Jiao Tong Univ., Shanghai, China","IEEE Transactions on Industrial Informatics","20140502","2014","10","2","1578","1586","The rapid development of Internet of things (IoT) technology makes it possible for connecting various smart objects together through the Internet and providing more data interoperability methods for application purpose. Recent research shows more potential applications of IoT in information intensive industrial sectors such as healthcare services. However, the diversity of the objects in IoT causes the heterogeneity problem of the data format in IoT platform. Meanwhile, the use of IoT technology in applications has spurred the increase of real-time data, which makes the information storage and accessing more difficult and challenging. In this research, first a semantic data model is proposed to store and interpret IoT data. Then a resource-based data accessing method (UDA-IoT) is designed to acquire and process IoT data ubiquitously to improve the accessibility to IoT data resources. Finally, we present an IoT-based system for emergency medical services to demonstrate how to collect, integrate, and interoperate IoT data flexibly in order to provide support to emergency medical services. The result shows that the resource-based IoT data accessing method is effective in a distributed heterogeneous data environment for supporting data accessing timely and ubiquitously in a cloud and mobile computing platform.","1551-3203;15513203","","10.1109/TII.2014.2306382","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6742577","Decision support system (DSS);Internet of things (IoT);emergencymedical service;resource model;ubiquitous data accessing","Business;Data models;Distributed databases;Hospitals;Information systems","Internet of Things;cloud computing;data acquisition;data integration;emergency services;health care;information retrieval;medical information systems;mobile computing;open systems","Internet of Things;IoT data collection;IoT data integration;IoT data interoperability;IoT data resources accessibility;IoT technology;IoT-based information system;UDA-IoT;cloud computing platform;data format heterogeneity problem;data interoperability methods;distributed heterogeneous data environment;emergency medical services;healthcare services;information intensive industrial sectors;information storage;mobile computing platform;object diversity;resource-based IoT data accessing method;semantic data model;smart objects;ubiquitous data accessing method","","54","","47","","20140217","May 2014","","IEEE","IEEE Journals & Magazines"
"Vehicle counting and speed measurement using headlight detection","I. Sina; A. Wibisono; A. Nurhadiyatna; B. Hardjono; W. Jatmiko; P. Mursanto","Fac. of Comput. Sci., Univ. Indonesia, Depok, Indonesia","2013 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","20140313","2013","","","149","154","CCTV is one of the tools that can be used to extract the needed traffic Information. Extracted information from image sequences of CCTV can give us real information about the number of passing vehicles and vehicles speed. In this paper we propose a new method in detecting the number of vehicles and vehicle speed measurement in low light conditions. Headlight detection is used in order to identify the existing vehicle. There are few steps in order to extract the information from CCTV. First for vehicle headlight detection, the vehicles are detected with normalized cross-correlation method and centroid-area-difference. The second step is vehicle tracking. Headlight is used to track the movements of the vehicle. The third step is vehicle counting and vehicle speed measurement; pin-hole and euclidean distance methods are used to estimate the vehicle speed. We have compared the vehicle detection algorithm and vehicle counting-speed measurement. The result shows that the normalized cross correlation method has a higher accuracy than area-centroid difference. The pinhole model also is better in estimating vehicle speed compared to euclidean distance.","","Electronic:978-1-4799-4692-1; POD:978-1-4799-2489-9","10.1109/ICACSIS.2013.6761567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6761567","","Cameras;Correlation;Data mining;Estimation;Euclidean distance;Vehicles;Velocity measurement","angular velocity measurement;closed circuit television;computerised monitoring;correlation methods;image sequences;information retrieval;object detection;object recognition;object tracking;road traffic;road vehicles;traffic engineering computing;video surveillance","CCTV;centroid area difference;euclidean distance method;image sequences;normalized cross-correlation method;passing vehicle detection;pin hole method;traffic information extraction;vehicle counting;vehicle headlight detection;vehicle movement tracking;vehicle speed estimation;vehicle speed measurement","","6","","13","","","28-29 Sept. 2013","","IEEE","IEEE Conference Publications"
"Assessing trust in the long-term protection of documents","M. Vigil; D. Cabarcas; J. Buchmann; J. Huang","Tech. Univ. Darmstadt, Darmstadt, Germany","2013 IEEE Symposium on Computers and Communications (ISCC)","20140306","2013","","","000185","000191","Digital archives rely on trusted parties, such as certification authorities, to ensure authenticity, integrity and proof of existence protection for documents. In this paper, we analyse the trust assumptions that a verifier has to make in order to trust in the protection of a document. We show that trust fades out in the long term due to the ever-growing number of trusted parties. Despite such a dire prospect, current technologies such as X.509 PKI do not assess trust, thereby leaving verifiers in the dark. We present a certification scheme for documents that provides verifiers with a better assessment of trust than in X.509 PKI. In the proposed scheme, trusted parties are rated based on the correctness of their performance. From the ratings, verifiers can assess quantitatively the trust in the trusted parties for the short term, and in the protection of documents for the long term. The proposed scheme encourages trusted parties to work properly.","1530-1346;15301346","Electronic:978-1-4799-3755-4; POD:978-1-4799-3756-1; USB:978-1-4799-3754-7","10.1109/ISCC.2013.6754943","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754943","Authenticity;Digital signatures;Integrity;Long term;Notary;Proof of existence;Timestamping;Trust assessment;Trusted party;X.509","Communities;Context;Digital signatures;Peer-to-peer computing;Public key","certification;data protection;document handling;information retrieval systems;trusted computing","X.509 PKI;certification authorities;digital archives;document certification scheme;long-term document protection;trust assessment;trust assumptions;trusted parties","","0","","20","","","7-10 July 2013","","IEEE","IEEE Conference Publications"
"Analyzing Query Trails and Satisfaction Based on Browsing Behaviors","J. Guo; C. Gao; N. Xu; G. Lu; H. Han","Coll. of Inf. Sci. & Technol., Beijing Univ. of Chem. Technol., Beijing, China","2013 10th Web Information System and Application Conference","20140327","2013","","","107","112","Nowadays, more and more web users use global search engines, such as Google and Bing, to hunt required information through query. At the same time, many Community-based Question Answering (C-Q&A) web sites supply large repositories of valuable information, knowledge and inner search engines to response the queries sent from users. In this paper, we do an exploratory analysis of the users' browsing behaviors to answer the following three questions. a)In users' search actions, which pattern is most used? They use the web sites that have inner search engine directly to get information, or use global search engines first, then go to certain web sites to get information, or use other patterns. b)How often can users find satisfying answers in C-Q&A web sites when web pages of C-Q&A web sites are listed as searching results in searching processes? c)Whether different categories in C-Q&A web sites have almost same satisfaction rate? In addition, is there any feature showing that the information of different categories has different life cycle? The analysis of query trails and satisfaction is based on browsing behaviors containing 81,168,263 access records which are created by 24,498 panel users. Analyzing results show that most frequent pattern of users' searching trails is from ”inner-site search engines” to web pages. If web pages of CQ&A web sites occurred in a searching process, about 50% are satisfying pages completely or on certain level. Experimental results also show that different categories of checked C-Q&A web site have different satisfaction rate.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778620","C-Q&amp;A web site;browsing behavior;information life cycle;information seeker satisfaction","Educational institutions;Equations;Internet;Mathematical model;Search engines;Web pages","Web sites;query processing;question answering (information retrieval);search engines","C-Q&A Web sites;Web pages;Web users;browsing behaviors;community-based question answering Web sites;exploratory analysis;global search engines;information repositories;inner search engines;knowledge search engines;query satisfaction;query trail analysis","","0","","16","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"IEEE Standard for Software Interface for Maintenance Information Collection and Analysis (SIMICA): Exchanging Maintenance Action Information via the Extensible Markup Language (XML)","","","IEEE Std 1636.2-2010 (Full_Use)","20140401","2013","","","1","78","Interoperability between components of automatic test systems (ATS) is promoted and facilitated. The standard facilitates the capture of maintenance action information (MAI) associated with the removal, repair, and replacement of a particular system component (e.g., unit(s) under test) in order to maintain/support that particular operational system. The MAI schema becomes a class of information that can be used within the SIMICA family of standards. The exchange format utilizes the XML formats.","","","10.1109/IEEESTD.2013.6781494","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781494","Software Interface for Maintenance Information Collection and Analysis (SIMICA);XML schema;automated test system (ATS);eXtensible markup language (XML);maintenance action information (MAI)","Automatic test equipment;IEEE standards;Information analysis;Markup languages;Software engineering;Software interfaces;Software maintenance;XML","IEEE standards;XML;information retrieval;open systems;software maintenance","ATS;IEEE standard;MAI schema;SIMICA;XML format;automatic test systems;extensible markup language;interoperability;software interface for maintenance information collection and analysis","","0","","","","","Feb. 1 2013","","IEEE","IEEE Standards"
"Embedding and retrieving patient's identification and compression of ECG signal","B. Halder; S. S. Bose; N. Mishra; S. Mitra","Dept. of Inf. Technol., Neotia Inst. of Technol., Manage. & Sci., Sarisha, India","Students' Technology Symposium (TechSym), 2014 IEEE","20140501","2014","","","1","6","In this paper, the authors propose a new ECG compression algorithm which embeds patient's identification inside the ECG data. The compressed file contains only ASCII characters. The proposed scheme also allows the decompression technique where the original ECG waveform can be exactly reconstructed and retrieve patient's identification from the ECG signal. The whole module has been applied to various ECG data of all the 12 leads taken from PTB diagnostic database (PTB-DB) of physioNet (www.physionet.org) and gives a highly compressed result that can be stored using far less digital space without distorting important ECG characteristics which are essential for proper medical diagnosis. Moreover, the compression, embedding, decompression and retrieving of data are achieved in a series of sequential, simplistic logical processes that can be easily executed. It is observed that the proposed algorithm gives a high compression ratio (CR=7.3593, an excellent Quality Score (QS=1362) and very low difference between original and reconstructed ECG signal (PRD=O.0054).","","Electronic:978-1-4799-2608-4; POD:978-1-4799-2609-1","10.1109/TechSym.2014.6807904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6807904","ASCII Character;Grouping;PRD;Sign Bit","Arrays;Compression algorithms;Data compression;Electrocardiography;Medical treatment;Watermarking","data compression;data encapsulation;electrocardiography;information retrieval;information storage;information theory;medical signal processing;signal reconstruction","ASCII characters;ECG characteristics;ECG compressed file storage;ECG data;ECG decompression technique;ECG signal compression algorithm;ECG waveform reconstruction;PTB diagnostic database;PTB-DB;compression ratio;digital space;medical diagnosis;module application;patient identification embedding;patient identification retrieval;physioNet;quality score","","1","","9","","","Feb. 28 2014-March 2 2014","","IEEE","IEEE Conference Publications"
"TUCAN: Twitter User Centric ANalyzer","L. Grimaudo; H. Song; M. Baldi; M. Mellia; M. Munafò","Politecnico di Torino, Italy","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","1455","1457","Twitter has attracted millions of users that generate a humongous flow of information at constant pace. The research community has thus started proposing tools to extract meaningful information from tweets. In this paper, we take a different angle from the mainstream of previous works: we explicitly target the analysis of the timeline of tweets from “single users”. We define a framework - named TUCAN - to compare information offered by the target users over time, and to pinpoint recurrent topics or topics of interest. First, tweets belonging to the same time window are aggregated into “bird songs”. Several filtering procedures can be selected to remove stop-words and reduce noise. Then, each pair of bird songs is compared using a similarity score to automatically highlight the most common terms, thus highlighting recurrent or persistent topics. TUCAN can be naturally applied to compare bird song pairs generated from timelines of different users. By showing actual results for both public profiles and anonymous users, we show how TUCAN is useful to highlight meaningful information from a target user's Twitter timeline.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785902","","Birds;Cleaning;Conferences;Correlation;Media;Twitter","information retrieval;social networking (online);user interfaces","TUCAN;Twitter user centric analyzer;information extraction;information flow;noise reduction;stop-words","","1","","6","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Bridging Electronic Health Record Access to the Cloud","B. Coats; S. Acharya","Towson Univ., Towson, MD, USA","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","2948","2957","Healthcare providers are faced with mounting pressure to facilitate pervasive access to their electronic health record systems for their patients; the Meaningful Use incentive programs perhaps the most significant driver. Meanwhile the Cloud has expended immense time and resources on the establishment of proficient, easy-to-use digital identities for individuals, while also allowing those identities to be portable across a myriad of disparate systems. This research proposes the success and proliferation of the Clouds' digital identities to be part of the solution to the healthcare industry's access issue. By analyzing industry standards and other ongoing identity related work in other industries, a trust model was produced to enable the exchange of identity information. As such, this research proposes a comprehensive framework for healthcare providers to follow to integrate their EHRs with the Cloud for provide identity validation, while ensuring compliance guidelines for security and privacy. To demonstrate the viability of this research, a number of pilots and concept projects have been implemented at a large regional hospital that have already produced immediate and tangible improvements.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758967","OpenID;healthcare information security;identity assurance;identity management;portable identity","Authentication;Guidelines;Industries;Medical services;NIST","cloud computing;data privacy;electronic data interchange;health care;hospitals;information retrieval;medical information systems;trusted computing","EHR;Meaningful Use incentive programs;cloud digital identities;compliance guidelines;easy-to-use digital identities;electronic health record access;electronic health record systems;healthcare access;healthcare industry;healthcare providers;identity information exchange;identity validation;industry standards;large regional hospital;pervasive access;privacy;security;trust model","","1","","12","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"FlowString: Partial Streamline Matching Using Shape Invariant Similarity Measure for Exploratory Flow Visualization","J. Tao; C. Wang; C. K. Shene","Michigan Technol. Univ., Houghton, MI, USA","2014 IEEE Pacific Visualization Symposium","20140414","2014","","","9","16","Measuring the similarity of integral curves is fundamental to many important flow data analysis and visualization tasks such as feature detection, pattern querying, streamline clustering and hierarchical exploration. In this paper, we introduce FlowString, a novel approach that extracts shape invariant features from streamlines and utilizes a string-based method for exploratory streamline analysis and visualization. Our solution first resamples streamlines by considering their local feature scales. We then classify resampled points along streamlines based on the shape similarity around their local neighborhoods. We encode each streamline into a string of well-selected shape characters, from which we construct meaningful words for querying and retrieval. A unique feature of our approach is that it captures intrinsic streamline similarity that is invariant under translation, rotation and scaling. Leveraging the suffix tree, we enable efficient search of streamline patterns with arbitrary lengths with the complexity linear to the size of the respective pattern. We design an intuitive interface and user interactions to support flexible querying, allowing exact and approximate searches for robust partial streamline similarity matching. Users can perform queries at either the character level or the word level, and define their own characters or words conveniently for customized search. We demonstrate the effectiveness of FlowString with several flow field data sets of different sizes and characteristics.","2165-8765;21658765","Electronic:978-1-4799-2874-3; POD:978-1-4799-2875-0","10.1109/PacificVis.2014.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787131","","Feature extraction;Graphics processing units;Shape;Spirals;Timing;Vocabulary;Windings","computational fluid dynamics;data flow analysis;data visualisation;flow visualisation;information retrieval;pattern classification;pattern matching;user interfaces","FlowString;computational fluid dynamics;exploratory flow visualization;exploratory streamline analysis;feature detection;flow data analysis;hierarchical exploration;integral curves similarity;intrinsic streamline similarity;intuitive interface;pattern querying;robust partial streamline similarity matching;shape invariant similarity measure;streamline clustering;string-based method;suffix tree;user interaction","","0","","22","","","4-7 March 2014","","IEEE","IEEE Conference Publications"
"Technology and Effect Matrix for Patent Clustering","C. Xu; P. Zhiyong; L. Bin","Comput. Sch., Wuhan Univ., Wuhan, China","2013 10th Web Information System and Application Conference","20140327","2013","","","128","132","Patents contain important technical, legal and economic information. Their annual publication accounts for a quarter of the books and journals in the world. Along with the growing number of patents, patent clustering analysis is becoming more and more important. We focus on two key issues in patent clustering, namely patent representation and data visualization. Firstly, patents are represented as technology and effect pairs, and then patents are clustered based on technology and effect matrix, finally a multi-layer patent map is generated. The experiments results show that our method has higher efficiency and better clustering effect than traditional vector space model and the visualization of clustering result is more practical and scalable.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778624","information extraction;information visualization;patent clustering;sematic annotation;text representation","Abstracts;Clustering algorithms;Conferences;Hamming distance;Patents;Semantics;Vectors","data visualisation;information retrieval;patents;pattern clustering","data visualization;economic information;information extraction;legal information;multilayer patent map;patent clustering analysis;patent representation;technical information;technology and effect matrix;technology and effect pairs","","0","","18","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Framework for Recommender Systems in Online Social Network Recruiting: An Interdisciplinary Call to Arms","R. Buettner","Inst. of Manage. & Inf. Syst., FOM Univ. of Appl. Sci., Germany","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","1415","1424","I sketch an interdisciplinary framework for recommender systems searching online social networks for future employees. In contrast to previous approaches my Framework covers the whole person-organization environment (P-OE) fit, and so it also includes crucial social components (e.g. workgroup fabric, and organizational culture). In a rudimentary way I show how information extracted from online social networks can be used to determine the P-OE fit. Due to a more accurate way of calculating the P-OE fit my framework facilitates higher quality recommendations. Furthermore my framework enables a better understanding of the P-OE fit problem.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758781","e-recruiting;human resource management;online social network;person-organization fit;personality traits;recommender system","Correlation;Data mining;Fabrics;Facebook;Instruments;Organizations","business data processing;information retrieval;organisational aspects;personnel;recommender systems;recruitment;social networking (online)","P-OE fit problem;future employees;information extraction;interdisciplinary framework;online social network recruiting;organizational culture;person-organization environment;quality recommendations;recommender systems;social components;workgroup fabric","","1","","90","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"Automatic Elements Extraction of Chinese Web News Using Prior Information of Content and Structure","S. Chengru; W. Shifeng; Z. Changshui","Dept. of Autom., Tsinghua Univ., Beijing, China","2013 2nd IAPR Asian Conference on Pattern Recognition","20140327","2013","","","340","345","We propose a set of efficient processes for extracting all four elements of Chinese news web pages, namely news title, release date, news source and the main text. Our approach is based on a deep analysis of content and structure features of current Chinese news. We take content indicators as the key to recover tree structure of the main text. Additionally, we come up with the concept of Length-Distance Ratio to help improve performance. Our method rarely depends on selection of samples and has strong generalization ability regardless of training process, distinguishing itself from most existing methods. We have tested our approach on 1721 labeled Chinese news pages from 429 web sites. Results show that an 87% accuracy was achieved for news source extraction, and over 95% accuracy for other three elements.","0730-6512;07306512","Electronic:978-1-4799-2190-4; POD:978-1-4799-2191-1","10.1109/ACPR.2013.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778337","LDR;TF-IDF;news extraction;term vector model","Accuracy;Data mining;Educational institutions;Feature extraction;HTML;Media;Vectors","Web sites;data mining;information retrieval;natural language processing;text analysis;tree data structures","Chinese Web news;Chinese news Web pages;Web sites;automatic elements extraction;content indicators;deep analysis;generalization ability;length-distance ratio;news source extraction;news title;release date;training process;tree structure","","0","","8","","","5-8 Nov. 2013","","IEEE","IEEE Conference Publications"
"Segmental Analysis and Evaluation of User Focused Search Process","C. Hendahewa; C. Shah","Dept. of Comput. Sci., Rutgers Univ., Piscataway, NJ, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","291","294","In general, IR systems assist searchers by predicting or assuming what could be useful for their information needs by providing query suggestions or pseudo-relevance feedback. Most of these approaches are based on analyzing information objects (documents, queries) seen or used in the past and then proposing other related objects that may be relevant. Such approaches often ignore the underlying process of information seeking that guides how a searcher performs during information seeking episode, thus forgoing opportunities for making process-based recommendations. In order to address this, we propose a search process-based analysis of discovering different segments, which leads to analyzing different search action based features and evaluating the search performance for each stage. Further, we propose a query recommendation strategy to improve the search performance of each low performing user for each stage, which shows that the proposed overall model yields effective search performance improvements above 90% in most cases. This could lead to better recommendations and optimizations within each segment in order to enhance the overall search performance of a user.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784629","Evaluation;Exploratory search;Sequence Analysis;Time Series Analysis","Educational institutions;Logistics;Predictive models;Recommender systems;Search problems;Time measurement;Time series analysis","information filtering;information retrieval system evaluation;performance evaluation;query formulation;query processing;relevance feedback;time series","IR systems;information objects;information retrieval systems;information seeking;pseudorelevance feedback;query recommendation strategy;query suggestions;search process-based analysis;time series analysis;user focused search process;user search performance evaluation","","1","","12","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Improved Regularized Latent Semantic Indexing with L1/2 Regularization and Non-negative Constraints","Y. Chen; H. Zhang; Y. Zuo; D. Wang","State Key Lab. of Software Dev. Environ., Beihang Univ., Beijing, China","2013 IEEE 16th International Conference on Computational Science and Engineering","20140306","2013","","","1075","1082","Recently topic model has been more and more popular in lots of fields such as information retrieval and semantic relatedness computing, but its practical application is limited to the scalability of data. It cannot be efficiently executed on large-scale datasets in a parallel way. In this paper, we introduce an improved Regularized Latent Semantic Indexing(RLSI) with L1/2 regularization and non-negative constraints. This method formalizes topic model as a problem of minimizing a quadratic loss function regularized by L1/2 and L2 norm with non-negative constraints. This formulation allows the learning process to be decomposed into a series of mutually independent sub-optimization problems which can be processed in parallel, therefore, it has the ability to handle large-scale data. The non-negative constraints and L1/2 regularization allow our model to be more practical and more conducive to information retrieval and semantic relatedness computing. Extensive experimental results show that our improved model can deal with large-scale text data, and compared with some of the-state-of-the-art topic models, it is also very effective.","","Electronic:978-0-7695-5096-1; POD:978-1-4799-4897-0","10.1109/CSE.2013.156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755337","L1/2 regularization;Latent Semantic Indexing;large scale;non-negative constraints;topic model","Algorithm design and analysis;Approximation algorithms;Computational modeling;Data models;Matrix decomposition;Semantics;Vectors","information retrieval;optimisation","L1/2 regularization;RLSI;data scalability;improved regularized latent semantic indexing;independent suboptimization problems;information retrieval;nonnegative constraints;quadratic loss function","","1","","18","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"An empirical analysis of a network of expertise","T. V. Le; M. T. Nguyen","School of Information Systems, Singapore Management University, 80 Stamford Rd., Singapore 178902","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","1387","1394","In this paper, we analyze the network of expertise constructed from the interactions of users on the online question-answering (QA) community of Stack Overflow. This community was built with the intention of helping users with their programming tasks and, thus, questions are expected to be highly factual. This also indicates that the answers one provides may be highly indicative of one's level of expertise on the subject matter. Therefore, our main concern is how to model and characterize the user's expertise based on the constructed network and its centrality measures. We used the user's reputation established on Stack Overflow as a direct proxy to their expertise. We further made use of linear models and principal component analysis for the purpose. We found out that the current reputation system does a decent job at representing the user's expertise and that focus matters when answering factual questions. However, our model was not able to capture the other larger half of reputation which is specifically designed to reflect a user's trustworthiness besides their expertise. Along the way, we also discovered facts that have been known in earlier studies of the other/same QA communities such as the power-law degree distribution of the network and the generalized reciprocity pattern among its users.","","Electronic:978-1-4503-2240-9","10.1109/ASONAM.2013.6785882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785882","","Communities;Conferences;Correlation;Educational institutions;Principal component analysis;Social network services;Standards","principal component analysis;question answering (information retrieval)","QA communities;Stack Overflow;generalized reciprocity pattern;linear models;network of expertise analysis;online question-answering community;power-law degree distribution;principal component analysis;programming tasks;user expertise;user reputation;user trustworthiness","","0","","14","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"A Survey of Resource Sharing Cloud Using Data Mining","D. Pratiba; G. Shobha","Dept. of Comput. Sci. & Eng., Visvesvaraya Technol. Univ., Bangalore, India","2014 Fifth International Conference on Signal and Image Processing","20140331","2014","","","323","327","With the development of information technologies, Data Mining and Cloud Computing have been put forward and in wide search. Data Mining is defined as the process of analyzing data from different perspectives and summarizing it into useful information. It is also used for extracting the useful and potential information from the cloud. Most institutions and organizations have their own libraries and computer Servers, retrieving the data available in the above consortia is a difficult task. To overcome this, the resources can be shared using Data Mining and Cloud computing technology. Thus the end users would have access to all information.","","Electronic:978-0-7695-5100-5; POD:978-1-4799-1394-7","10.1109/ICSIP.2014.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754896","Analyze;Resources;Retrieve","Classification algorithms;Cloud computing;Clustering algorithms;Conferences;Data mining;Distributed databases;Libraries","cloud computing;data mining;information retrieval;network servers;resource allocation","cloud computing technology;computer servers;data mining technology;data retrieval;information access;information extraction;information summarization;information technologies;resource sharing cloud","","1","","19","","","8-10 Jan. 2014","","IEEE","IEEE Conference Publications"
"Analysis of the reputation system and user contributions on a question answering website: StackOverflow","D. Movshovitz-Attias; Y. Movshovitz-Attias; P. Steenkiste; C. Faloutsos","Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","886","893","Question answering (Q&A) communities have been gaining popularity in the past few years. The success of such sites depends mainly on the contribution of a small number of expert users who provide a significant portion of the helpful answers, and so identifying users that have the potential of becoming strong contributers is an important task for owners of such communities. We present a study of the popular Q&A website StackOverflow (SO), in which users ask and answer questions about software development, algorithms, math and other technical topics. The dataset includes information on 3.5 million questions and 6.9 million answers created by 1.3 million users in the years 2008-2012. Participation in activities on the site (such as asking and answering questions) earns users reputation, which is an indicator of the value of that user to the site. We describe an analysis of the SO reputation system, and the participation patterns of high and low reputation users. The contributions of very high reputation users to the site indicate that they are the primary source of answers, and especially of high quality answers. Interestingly, we find that while the majority of questions on the site are asked by low reputation users, on average a high reputation user asks more questions than a user with low reputation. We consider a number of graph analysis methods for detecting influential and anomalous users in the underlying user interaction network, and find they are effective in detecting extreme behaviors such as those of spam users. Lastly, we show an application of our analysis: by considering user contributions over first months of activity on the site, we predict who will become influential long-term contributors.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2500242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785805","","Blogs;Communities;Computer science;Conferences;Electronic mail;Knowledge engineering;Social network services","Web sites;human factors;question answering (information retrieval)","Q and A Web site StackOverflow;SO reputation system;extreme behaviors;high quality answers;participation patterns;question answering communities;software development;spam users;user interaction network;user reputation","","8","","28","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"A Framework for Goal-Oriented Discovery of Resources in the RESTful Architecture","J. I. Fernández-Villamor; C. A. Iglesias; M. Garijo","Departamento de Ingenier&#237;a de Sistemas Telem&#225;ticos, Universidad Polit&#233;cnica de Madrid, Madrid, Spain","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20140513","2014","44","6","796","803","One of the challenges facing the current web is the efficient use of all the available information. The Web 2.0 phenomenon has favored the creation of contents by average users, and thus the amount of information that can be found for diverse topics has grown exponentially in the last years. Initiatives such as linked data are helping to build the Semantic Web, in which a set of standards are proposed for the exchange of data among heterogeneous systems. However, these standards are sometimes not used, and there are still plenty of websites that require naive techniques to discover their contents and services. This paper proposes an integrated framework for content and service discovery and extraction. The framework is divided into several layers where the discovery of contents and services is made in a representational stateless transfer system such as the web. It employs several web mining techniques as well as feature-oriented modeling for the discovery of cross-cutting features in web resources. The framework is used in a scenario of electronic newspapers. An intelligent agent crawls the web for related news, and uses services and visits links automatically according to its goal. This scenario illustrates how the discovery is made at different levels and how the use of semantics helps implement an agent that performs high-level tasks.","2168-2216;21682216","","10.1109/TSMCC.2013.2259231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595093","Agents;contents;discovery;information extraction;representational stateless transfer system (REST);services","HTML;Object oriented modeling;Protocols;Resource description framework;Semantics;Standards","Web services;Web sites;data mining;electronic publishing;information retrieval;multi-agent systems;semantic Web;software architecture","RESTful architecture;Web 2.0 phenomenon;Web crawling;Web mining technique;Web resource;Web sites;content discovery;content extraction;cross-cutting feature discovery;data exchange;electronic newspapers;feature oriented modeling;goal oriented resource discovery;heterogeneous systems;intelligent agent;naive technique;representational stateless transfer system;semantic Web;service discovery","","5","","45","","20130910","June 2014","","IEEE","IEEE Journals & Magazines"
"Semantic graph based approach for text mining","C. S. Yadav; A. Sharan; M. L. Joshi","Sch. of Comput. & Syst. Sci., JNU, New Delhi, India","2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)","20140403","2014","","","596","601","A semantic network is a graphical notation, for representing knowledge in form of interconnected nodes and arcs. In this paper we propose a novel approach to construct a semantic graph from a text document. Our approach considers all the nouns of a document and builds a semantic graph, such that it represents entire document. We think that our graph captures many properties of the text documents and can be used for different application in the field of text mining and NLP, such as keyword extraction and to know the nature of the document. Our approach to construct a semantic graph is independent of any language. We performed an experimental analysis to validate our results to extract keywords of document and to derive nature of graph. We present the experimental result on construction of graph on FIRE data set and present its application for keyword extraction and commenting on the nature of document.","","DVD:978-1-4799-2899-6; Electronic:978-1-4799-2900-9; POD:978-1-4799-2901-6","10.1109/ICICICT.2014.6781348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781348","Keyword extraction;Language Network;Nature of Document;Semantic graph;Text mining;WordNet","Choppers (circuits);Floods;Force;Ink;Manuals;Semantics;Visualization","data mining;information retrieval;natural language processing;network theory (graphs);semantic networks;text analysis","FIRE data set;NLP;arcs;graphical notation;keyword extraction;knowledge representation;nodes interconnection;semantic graph;semantic network;text document;text mining","","2","","16","","","7-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Extraction Rule Language for Web Information Extraction and Integration","W. Wei; S. Shi; Y. Liu; H. Wang; C. Yuan; Y. Huang","Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China","2013 10th Web Information System and Application Conference","20140327","2013","","","65","70","The Web is the largest data source that contains a lot of valuable information of interests to users or applications. However, how to automatically navigate and extract useful data from web pages is an important issue to study. There have been a number of existing studies on this area. However, most of them do not take enough consideration on complete process of web information extraction and lack of powerful rule expression ability to describe the navigation, extraction and integration rules. In this paper, we study and propose a new web information extraction rule language toward a general model for web information extraction and integration. We first introduce a source data objects to extract different type of web data records. Then we adopt the XML to define the target data entity structure and use scripts to perform target data record integration. The results show that our extraction rule language can provide powerful and flexible ability to describe extraction logic to achieve accurate web data records extraction from complex web pages.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778612","Data record;Extraction model;Extraction rule language;Web information extraction","Data mining;Data models;Feature extraction;HTML;Navigation;Web pages","Internet;Web sites;XML;data integration;information retrieval","Web data records extraction;Web information extraction;Web information extraction rule language;Web information integration;Web pages;XML;complex Web pages;data entity structure;data record integration;data source;rule expression ability","","1","","19","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"E-government: The gate for attracting foreign investments","A. Al-Azzam; E. Abu-Shanab","MIS Dept. IT Coll., Yarmouk Univ., Irbid, Jordan","2014 6th International Conference on Computer Science and Information Technology (CSIT)","20140501","2014","","","161","165","There is a growing recognition of the role that e-government has on promoting country attractiveness to foreign investors, hence, governments around the globe are deploying e-government services as a promotion technique that helps eliminating Foreign Direct Investment (FDI) barriers, in particular those related to information retrieval and accessibility, business procedures, bureaucratic protocols facing investors in a host country. This paper addresses the relationship between country attractiveness to Foreign Direct Investment (FDI) and E-government development of the host country, the study utilized two indices measured in Global Opportunity Index (GOI) measured in E-government Readiness Index (EGRI), Results suggests a significant association between the two measures.","","Electronic:978-1-4799-3999-2; POD:978-1-4799-4000-4","10.1109/CSIT.2014.6805995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6805995","E-government;FDI;Foreign investments;Global data;secondary data","Economics;Electronic government;Indexes;Internet;Investment","government data processing;information retrieval;investment","EGRI;FDI barriers;GOI;bureaucratic protocols;business procedures;country attractiveness;e-government readiness index;e-government services;foreign direct investment barriers;global opportunity index;information accessibility;information retrieval","","0","","28","","","26-27 March 2014","","IEEE","IEEE Conference Publications"
"DeepQA Jeopardy! Gamification: A Machine-Learning Perspective","A. K. Baughman; W. Chuang; K. R. Dixon; Z. Benz; J. Basilico","IBM Special Events, Research Triangle Park, NC, USA","IEEE Transactions on Computational Intelligence and AI in Games","20140313","2014","6","1","55","66","DeepQA is a large-scale natural language processing (NLP) question-and-answer system that responds across a breadth of structured and unstructured data, from hundreds of analytics that are combined with over 50 models, trained through machine learning. After the 2011 historic milestone of defeating the two best human players in the Jeopardy! game show, the technology behind IBM Watson, DeepQA, is undergoing gamification into real-world business problems. Gamifying a business domain for Watson is a composite of functional, content, and training adaptation for nongame play. During domain gamification for medical, financial, government, or any other business, each system change affects the machine-learning process. As opposed to the original Watson Jeopardy!, whose class distribution of positive-to-negative labels is 1:100, in adaptation the computed training instances, question-and-answer pairs transformed into true-false labels, result in a very low positive-to-negative ratio of 1:100 000. Such initial extreme class imbalance during domain gamification poses a big challenge for the Watson machine-learning pipelines. The combination of ingested corpus sets, question-and-answer pairs, configuration settings, and NLP algorithms contribute toward the challenging data state. We propose several data engineering techniques, such as answer key vetting and expansion, source ingestion, oversampling classes, and question set modifications to increase the computed true labels. In addition, algorithm engineering, such as an implementation of the Newton-Raphson logistic regression with a regularization term, relaxes the constraints of class imbalance during training adaptation. We conclude by empirically demonstrating that data and algorithm engineering are complementary and indispensable to overcome the challenges in this first Watson gamification for real-world business problems.","1943-068X;1943068X","","10.1109/TCIAIG.2013.2285651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6632881","Gamification;machine learning;natural language processing (NLP);pattern recognition","Accuracy;Games;Logistics;Machine learning algorithms;Pipelines;Training","business data processing;computer games;learning (artificial intelligence);natural language processing;question answering (information retrieval);text analysis","DeepQA Jeopardy! gamification;NLP algorithms;NLP question-and-answer system;Newton-Raphson logistic regression;Watson gamification;Watson machine-learning pipelines;algorithm engineering;business domain;configuration settings;data engineering techniques;domain gamification;extreme class imbalance;ingested corpus sets;large-scale natural language processing question-and-answer system;machine-learning process;nongame play;positive-to-negative ratio;question-and-answer pairs;real-world business problems;regularization term;structured data;training instances;true-false labels;unstructured data","","2","","31","","20131017","March 2014","","IEEE","IEEE Journals & Magazines"
"Domain specific search of nearest hospital and Healthcare Management System","R. A. Nimbalkar; R. A. Fadnavis","Dept. of Inf. Technol., Yeshwantrao Chavan Coll. of Eng., Nagpur, India","2014 Recent Advances in Engineering and Computational Sciences (RAECS)","20140417","2014","","","1","5","Developed and developing countries have recognized the importance of Electronic Health Record in Healthcare Management System. Emergency Medical System (EMS) is a revolutionary approach to emergency medical treatment in some medical emergency. It also describes a mobile system that enables electronic healthcare data storage, update and retrieval using Cloud Computing. It observed that people in unknown area are in severe danger if they don't able to find hospital quickly. In emergency case a single minute counts so it is very important that automatic applications must be used for decision making, maintain up to date status of the hospital. Saving the time which can be save life of the patient. When the doctor or family receives the alarm message, they can immediately take measures to rescue the user. It can also manage the health record of the user. The user can take online medical to send their physical condition and then get prescription from doctor who will send the prescription on the user's phone. The proposed system locates nearest available hospital, contacts its ambulance emergency system, accesses a Electronic Health Record of emergency patient that can critically assist in pre-hospital treatments. The system will identify availability of the nearest available specialized hospital all through EMS server which provides continuous information about the incoming patient to the hospital. This paper proposes Android Based Tracking for EMS (Emergency Medical System) on cloud.","","CD-ROM:978-1-4799-2290-1; Electronic:978-1-4799-2291-8; POD:978-1-4799-2292-5","10.1109/RAECS.2014.6799536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799536","Cloud Computing;Emergency Medical Service;Health Record;Hospital Tracking","Databases;Electronic medical records;Hospitals;Mobile communication;Servers;Smart phones","cloud computing;decision making;electronic health records;emergency management;health care;hospitals;information retrieval;storage management","Android based tracking;EMS server;ambulance emergency system;cloud computing;decision making;domain specific search;electronic health record;electronic healthcare data storage;emergency medical system;emergency medical treatment;emergency patient;healthcare management system;nearest hospital;pre-hospital treatments;user phone","","2","","19","","","6-8 March 2014","","IEEE","IEEE Conference Publications"
"Cloud Storage and Retrieval - A User Perspective","V. Abhishek; S. N. Megha","Dept. of MCA, R.V. Coll. of Eng., Bangalore, India","2014 World Congress on Computing and Communication Technologies","20140403","2014","","","84","87","The young upcoming industry is the cloud storage with lots of potential in terms of growth of storage capacity and the potential of faster retrieval. The architecture of the cloud is designed so as to not only offer unlimited storage capacity, but also has to eliminate the old data backups - created as a part of the constant replication of data. In this paper, the key component is storage-as-a-service solution, that is, the cloud storage is analyzed and comprehended for the storage and retrieval speeds on various free cloud storage sites. The experiments were piloted for files varying in sizes and various time spans. Time spans are deliberated based on network traffic. This paper overall tries to give a snapshot of the data working on different free clouds available. The analysis done gives an identification of the free cloud storage capacity, its performance, betterments and evaluation.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-5085-0","10.1109/WCCCT.2014.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755111","Amazon cloud drive;Box;Cloud Storage Providers (CSP);Download;Download duration;Google Drive;Host-market;MiMedia;Upload;Upload duration;free storage space","Cloud computing;Electronic mail;Google;Organizations;Servers;Telecommunication traffic","cloud computing;information retrieval;software architecture;storage management;telecommunication traffic","cloud architecture;cloud retrieval;cloud storage sites;file size variation;free cloud storage capacity;network traffic;storage as a service;time span","","0","","8","","","Feb. 27 2014-March 1 2014","","IEEE","IEEE Conference Publications"
"A New Framework for Distilling Higher Quality Information from Health Data via Social Network Analysis","M. Baglioni; S. Pieroni; F. Geraci; F. Mariani; S. Molinaro; M. Pellegrini; E. Lastres","Ist. di Inf. e Telematica, Pisa, Italy","2013 IEEE 13th International Conference on Data Mining Workshops","20140306","2013","","","48","55","Personalized medicine as well as systems biology poses the challenge of developing new models to connect health data coming from many different flows and extract from them new information to support clinicians in their therapeutic activity. In this scenario we developed a novel framework, tailored to clinicians needs, which exploits the strength of the social network model to provide a representation of the health care system as a whole. In this paper we also propose a data analysis approach inspired to the humans' cognitive process where the awareness of a phenomenon is the result of an exploration step in which situations of possible interest are identified, and a subsequent in-depth examination step in which the phenomenon is characterized. Experiments have shown that our framework is able to provide effective answers to complex enquiries submitted by clinicians for which standard statistical methods fail.","2375-9232;23759232","Electronic:978-1-4799-3142-2; POD:978-1-4799-3144-6","10.1109/ICDMW.2013.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753902","","Algorithm design and analysis;Data models;Drugs;Layout;Pathology;Social network services","cognition;data analysis;health care;information retrieval;medical computing;patient treatment;social sciences","clinicians needs;data analysis approach;exploration step;health care system;health data;higher quality information distillation;human cognitive process;information extraction;personalized medicine;social network analysis;social network model;subsequent in-depth examination step;systems biology;therapeutic activity","","1","","25","","","7-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"Organic streams: Data aggregation and integration based on individual needs","X. Zhou; Q. Jin; B. Wu; W. Wang; J. Pan; W. Zheng","Grad. Sch. of Human Sci., Waseda Univ., Tokorozawa, Japan","2013 International Joint Conference on Awareness Science and Technology & Ubi-Media Computing (iCAST 2013 & UMEDIA 2013)","20140313","2013","","","535","541","With the high accessibility of the social media, more and more people have been accustomed to sharing their personal contents across the social networks, which results in an explosive increase of data scale. In this study, in order to support information and knowledge discovery in big data, we propose an approach to aggregation and integration of personal big data from life logs in accordance with individual needs, which can benefit the sustainable information utilization process. In details, the organic stream, which is designed as an extensible data carrier, is introduced and developed to formulize and organize the personal big data, in order to extract dynamical individual needs from the tremendous amount of data posted through social media, and further aggregate and integrate the related data in a meaningful way, which can also facilitate the personalized information retrieval and reuse process. The architecture of the system with the foundational modules is given, and the experiment result is presented to demonstrate the usability and effectiveness of our approach.","","Electronic:978-1-4799-2364-9; POD:978-1-4799-4400-2","10.1109/ICAwST.2013.6765498","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6765498","Big Data;Data Aggregation;Data Integration;Individual Need;Life Log","Data handling;Data integration;Data mining;Data models;Data storage systems;Information management;Magnetic resonance imaging","data integration;data mining;information retrieval;social networking (online)","data aggregation;data integration;knowledge discovery;organic stream;personalized information retrieval;reuse process;social media;social network","","0","","27","","","2-4 Nov. 2013","","IEEE","IEEE Conference Publications"
"Enhancing Online Music Lessons with Applications in Automating Self-Learning Tutorials and Performance Assessment","N. H. Sephus; T. O. Olubanjo; D. V. Anderson","Sch. of Electr. & Comput. Eng., Georgia Inst. of Technol., Atlanta, GA, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","568","571","Online music lessons are growing more and more prevalent with resources such as Massive Open Online Courses (MOOCs) and lessons via YouTube videos. We discuss two issues in online music lessons that machine learning techniques may be used to solve: finding or developing a music lesson based on the student's learning style, musical background, or preference and quantitative assessment of the student's performance (whether as an online-instructor or self-taught through online videos). In particular, we discuss two solutions with specific applications. First, we propose a method for automating music lessons for learning how to play pre-recorded songs via existing music information retrieval (MIR) techniques for adaptability to various learning styles. Secondly, we propose a method for automating the assessment of rhythmic structures (such as tremolo, vibrato, etc.) via quantitative metrics of comparing modulation spectral features. We then list some resources and software that are currently available to integrate these methods to enhance online music education.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.178","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786172","machine learning;modulation spectrum;music lessons;student assessment","Education;Frequency modulation;Instruments;Measurement;Software;Tutorials","computer aided instruction;information retrieval;learning (artificial intelligence);music","MIR techniques;MOOC;YouTube videos;machine learning techniques;massive open online courses;music information retrieval;musical background;online music education;online music lessons;performance assessment;quantitative assessment;quantitative metrics;rhythmic structures;self-learning tutorials;student learning style;student performance","","0","","10","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Performance Evaluation of Semantic Approaches for Automatic Clustering of Similar Web Services","G. Vadivelou; E. Ilavarasan","Dept. of Comput. & Eng., Bharathiar Univ., Coimbatore, India","2014 World Congress on Computing and Communication Technologies","20140403","2014","","","237","242","In current web applications, more businesses are gradually publishing their business as services over the web. This growing number of web services available within an organization and on the Web raises a new and challenging search problem: locating desired web services. Searching for web services with conventional web search engines is insufficient in this context. Automatically clustering Web Service Description Language (WSDL) files on the web into functionally similar homogeneous service groups can be seen as a bootstrapping step for creating a service search engine and, at the same time, reducing the search space for service discovery. In order to overcome some the limitations of pattern-matching approach, the proposed work uses two semantic approaches to cluster similar services. An experimental study based on an information retrieval technique known as latent semantic analysis is applied to the collection of WSDL files and the another semantic approach is based on WordNet which is a lexical database to cluster similar services, as a predecessor step to retrieve the relevant Web services for a user request by search engines. The baseline approach and the two approaches based on semantic is applied on a collection of WSDL documents consisting of to test the quality of clusters formed. As a result, WordNet based approach for clustering shows better cluster quality.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-5085-0","10.1109/WCCCT.2014.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755149","WSDL;Web service;WordNet;latent semantic analysis;pattern-matching","Clustering algorithms;Context;Feature extraction;Search engines;Semantics;Standards;Web services","Web services;data mining;document handling;information retrieval;natural language processing;pattern clustering;pattern matching;search engines;semantic Web;specification languages","WSDL document collection;Web search engine;Web service description language;WordNet;automatic similar Web service clustering;baseline approach;bootstrapping;business as service;cluster quality;homogeneous service groups;information retrieval technique;latent semantic analysis;lexical database;organization;pattern matching approach;performance evaluation;search problem;search space reduction;semantic approach;service discovery;service search engine;similar service clustering;user request","","1","","24","","","Feb. 27 2014-March 1 2014","","IEEE","IEEE Conference Publications"
"A novel approach of automatic music genre classification based on timbrai texture and rhythmic content features","B. K. Baniya; D. Ghimire; J. Lee","Div. of Comput. Enigneering, Chonbuk Nat. Univ., Jeonju, South Korea","16th International Conference on Advanced Communication Technology","20140327","2014","","","96","102","Music genre classification is an essential component for the music information retrieval system. There are two important components to be considered for better genre classification, which are audio feature extraction and classifier. This paper incorporates two different kinds of features for genre classification, timbrai texture and rhythmic content features. Timbrai texture contains the Mel-frequency Cepstral Coefficient (MFCC) with other several spectral features. Before choosing a timbrai feature we explore which feature plays an insignificant role on genre discrimination. This facilitates the reduction of feature dimension. For the timbrai features up to the 4-th order central moments and the covariance components of mutual features are considered to improve the overall classification result. For the rhythmic content the features extracted from beat histogram are selected. In the paper Extreme Learning Machine (ELM) with bagging is used as the classifier for classifying the genres. Based on the proposed feature sets and classifier, experiment is performed with well-known datasets: GTZAN with ten different music genres. The proposed method acquires better classification accuracy compared to the existing methodologies.","1738-9445;17389445","CD-ROM:978-89-968650-2-5; Electronic:978-89-968650-3-2; POD:978-1-4799-3217-7","10.1109/ICACT.2014.6778929","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778929","bagging;covariance;music genre;rhythmic content;timbrai texture","Accuracy;Bagging;Feature extraction;Histograms;Mel frequency cepstral coefficient;Standards;Training","audio signal processing;feature extraction;information retrieval;learning (artificial intelligence);music;signal classification;spectral analysis","4-th order central moments;ELM;GTZAN;MFCC;Mel-frequency cepstral coefficient;audio feature extraction;automatic music genre classification;beat histogram;classifier;extreme learning machine;feature dimension reduction;genre discrimination;music genre classification;music information retrieval system;mutual features covariance components;rhythmic content features;spectral features;timbrai feature;timbrai texture","","5","","16","","","16-19 Feb. 2014","","IEEE","IEEE Conference Publications"
"A framework for detecting public health trends with Twitter","J. Parker; Y. Wei; A. Yates; O. Frieder; N. Goharian","Department of Computer Science, Georgetown University, Washington DC, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","556","563","Traditional public health surveillance requires regular clinical reports and considerable effort by health professionals to analyze data. Therefore, a low cost alternative is of great practical use. As a platform used by over 500 million users worldwide to publish their ideas about many topics, including health conditions, Twitter provides researchers the freshest source of public health conditions on a global scale. We propose a framework for tracking public health condition trends via Twitter. The basic idea is to use frequent term sets from highly purified health-related tweets as queries into a Wikipedia article index - treating the retrieval of medically-related articles as an indicator of a health-related condition. By observing fluctuations in frequent term sets and in turn medically-related articles over a series of time slices of tweets, we detect shifts in public health conditions and concerns over time. Compared to existing approaches, our framework provides a general a priori identification of emerging public health conditions rather than a specific illness (e.g., influenza) as is commonly done.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785758","Twitter;Wikipedia;health surveillance;item-set mining","Electronic publishing;Encyclopedias;Internet;Labeling;Public healthcare","information retrieval;medical information systems;social networking (online)","Twitter;Wikipedia article index;health-related condition;medically-related article retrieval;public health conditions;public health trends detection","","5","","35","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Questioning the Question -- Addressing the Answerability of Questions in Community Question-Answering","C. Shah; V. Kitzie; E. Choi","Sch. of Commun. & Inf., Rutgers Univ., New Brunswick, NJ, USA","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","1386","1395","In this paper, we investigate question quality among questions posted in Yahoo! Answers to assess what factors contribute to the goodness of a question and determine if we can flag poor quality questions. Using human assessments of whether a question is good or bad and extracted textual features from the questions, we built an SVM classifier that performed with relatively good classification accuracy for both good and bad questions. We then enhanced the performance of this classifier by using additional human assessments of question type as well as additional question features to first separate questions by type and then classify them. This two-step classifier improved the performance of the original classifier in identifying Type II errors and suggests that our model presents a novel approach for identifying bad questions with implications for query revision and routing.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758777","","Accuracy;Communities;Feature extraction;Guidelines;Predictive models;Support vector machines;Training","feature extraction;pattern classification;query processing;question answering (information retrieval);social networking (online);statistical testing;support vector machines","SVM classifier;Yahoo! answers;classification accuracy;community question-answering;human assessments;query revision;query routing;question quality assessment;textual feature extraction;type II errors identification","","1","","32","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"A Distinguishing Attack with a Neural Network","W. A. R. D. Souza; A. Tomlinson","Inf. Security Group, Univ. of London, Egham, UK","2013 IEEE 13th International Conference on Data Mining Workshops","20140306","2013","","","154","161","This paper proposes a new distinguishing-type attack to identify block ciphers. This attack utilises a multidisciplinary approach to the problem. It is grounded in a neural network, by means of a linguistic and an information retrieval approach, from patterns found on a set of cipher texts. This result is possible due to the existence of intrinsic properties in the mathematical basis of ciphers, which create signatures in the cipher texts. Experiments were performed on a set of cipher texts, which were encrypted by the finalist algorithms of AES contest: MARS, RC6, Rijndael, Serpent and Two fish, with a unique 128-bit key. The processes of clustering and classification were successful, allowing the formation of well-defined groups, where cipher texts encrypted by the same algorithm stayed close to each other, from a topological standpoint, which allow the identification of the cipher.","2375-9232;23759232","Electronic:978-1-4799-3142-2; POD:978-1-4799-3144-6","10.1109/ICDMW.2013.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753915","block cipher;cryptography;distinguishing attack;neural network","Ciphers;Clustering algorithms;Encryption;Neural networks;Neurons;Vectors","cryptography;information retrieval;neural nets;text analysis","128-bit key;MARS algorithm;RC6 algorithm;Rijndael algorithm;Serpent algorithm;Two fish algorithm;block ciphers identification;cipher texts;distinguishing-type attack;information retrieval approach;linguistic approach;neural network","","0","","24","","","7-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"An approach to visualize unorganized collections of documents","D. Karina Trejo T.; Ma. Auxilio Medina N.; M. Jorge de la Calleja; É. A. Martínez M.; J. Alfredo Sánchez","Lab. de Percepcion por Computadora, Univ. Politec. de Puebla, Juan C. Bonilla, Mexico","2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)","20140501","2014","","","248","255","In order to support search and retrieval of documents in digital libraries, this paper proposes an approach to visualize unorganized collections based on the results of two clustering algorithms namely k-means and COBWEB. These algorithms are implemented in Weka and they were chosen experimentally to produce a structure that can be explored by users in a 3D interface. Documents need to be processed before Weka can use them. We describe the main components of the proposed interface and show preliminary results of the application of those algorithms.","","Electronic:978-1-4799-3469-0; POD:978-1-4799-3470-6","10.1109/CONIELECOMP.2014.6808599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808599","Information visualization;clustering;digital libraries","Classification algorithms;Clustering algorithms;Libraries;Machine learning algorithms;Organizations;Partitioning algorithms;Vectors","data visualisation;digital libraries;document handling;information retrieval;pattern clustering","3D interface;COBWEB clustering algorithm;Weka;digital libraries;document processing;document retrieval;document searching;k-means clustering algorithm;unorganized document collection visualization","","0","","6","","","26-28 Feb. 2014","","IEEE","IEEE Conference Publications"
"Multi-modal Subspace Learning with Joint Graph Regularization for Cross-Modal Retrieval","K. Wang; W. Wang; R. He; L. Wang; T. Tan","Center for Res. on Intell. Perception & Comput., Inst. of Autom., Beijing, China","2013 2nd IAPR Asian Conference on Pattern Recognition","20140327","2013","","","236","240","This paper investigates the problem of cross-modal retrieval, where users can search results across various modalities by submitting any modality of query. Since the query and its retrieved results can be of different modalities, how to measure the content similarity between different modalities of data remains a challenge. To address this problem, we propose a joint graph regularized multi-modal subspace learning (JGRMSL) algorithm, which integrates inter-modality similarities and intra-modality similarities into a joint graph regularization to better explore the cross-modal correlation and the local manifold structure in each modality of data. To obtain good class separation, the idea of Linear Discriminant Analysis (LDA) is incorporated into the proposed method by maximizing the between-class covariance of all projected data and minimizing the within-class covariance of all projected data. Experimental results on two public cross-modal datasets demonstrate the effectiveness of our algorithm.","0730-6512;07306512","Electronic:978-1-4799-2190-4; POD:978-1-4799-2191-1","10.1109/ACPR.2013.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778317","cross-modal retrieval;joint graph regularization;subspace learning","Correlation;Databases;Eigenvalues and eigenfunctions;Encyclopedias;Joints;Manifolds;Multimedia communication","graph theory;information retrieval;learning (artificial intelligence)","JGRMSL algorithm;LDA;between-class covariance;content similarity;cross-modal correlation;cross-modal retrieval;intermodality similarity;intramodality similarity;joint graph regularization;linear discriminant analysis;local manifold structure;multimodal subspace learning;within-class covariance","","0","","15","","","5-8 Nov. 2013","","IEEE","IEEE Conference Publications"
"Research of the user search behavior on multiple agent intelligent agent technology","C. Li; L. Pei","Coll. of Inf. Sci. & Technol., Bohai Univ., Jinzhou, China","2013 Chinese Automation Congress","20140320","2013","","","812","817","Traditional search behavior analysis was too single to meet the individual needs of the user information search. This paper introduces the artificial intelligence agent technology analysis of user search behavior, analyzes 5 kinds of user search behavior by the use of multiple agent Intelligent agent technology advantage, and gather five kinds of user search behavior analysis results, output user information satisfaction, personalized service to meet user. To improve the efficiency of the search engines to provide a new method.","","Electronic:978-1-4799-0333-7; POD:978-1-4799-0334-4","10.1109/CAC.2013.6775845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775845","intelligence agent technology;multiple agent;personalized service;search behavior","Analytical models;Intelligent agents;Monitoring;Search engines;Servers;Web pages;Web search","information retrieval;multi-agent systems;search engines","artificial intelligence agent technology;multiple agent intelligent agent technology;search engine efficiency;user information satisfaction;user information search;user search behavior","","0","","60","","","7-8 Nov. 2013","","IEEE","IEEE Conference Publications"
"Analysis of the match probabilities for the iTrust information network with message forwarding","L. E. Moser; P. M. Melliar-Smith","Dept. of Electr. & Comput. Eng., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","The International Conference on Information Networking 2014 (ICOIN2014)","20140417","2014","","","340","345","The iTrust system is a completely distributed and decentralized information publication, search and retrieval system, that is designed to defend against censorship of information in the Internet. In this paper, we investigate the iTrust system with message forwarding, which spreads the responsibility of message distribution more widely across the nodes in the network. We present an analysis of the match probabilities of the iTrust system with message forwarding, in terms of the forwarding fanout, the number of levels of forwarding, and the forwarding probability. We show that, with a forwarding probability of 1.0, relatively small values of the forwarding fanout and the number of levels of forwarding suffice to achieve a high match probability and a reasonable message cost.","1550-445X;1550445X","Electronic:978-1-4799-3689-2; POD:978-1-4799-3690-8","10.1109/ICOIN.2014.6799493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799493","distributed and decentralized information publication;iTrust;match probability;message forwarding;search and retrieval","Algorithm design and analysis;Approximation algorithms;Computer crashes;Equations;Internet;Peer-to-peer computing;Probability density function","Internet;information retrieval systems;message passing;probability;trusted computing","Internet;decentralized information publication;distributed information publication;forwarding fanout;forwarding probability;iTrust information network;iTrust system;information censorship;match probabilities;message cost;message distribution;message forwarding;network nodes;search and retrieval system","","1","","22","","","10-12 Feb. 2014","","IEEE","IEEE Conference Publications"
"A framework for restricted domain Question Answering System","P. Biswas; A. Sharan; N. Malik","Jawaharlal Nehru Univ., New Delhi, India","2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)","20140403","2014","","","613","620","This paper proposes a framework for developing Question Answering System for restricted domain using advanced NLP tools. The proposed model basically works over the concept of Information Extraction rather than the old technique of information Retrieval used by the search engines. The main objective of the model is to extract the exact and precise answer for the given question from a large dataset. This framework is simple and easy to implement against the previously developed complex architectures. The Framework is divided into four modules namely: Question Processing Module, Document Processing Module, Paragraph extraction module and Answer extraction module. The paper also proposes various algorithms separately for Definition Type, Descriptive Type and Factoid Type of questions for extracting most potential answer from the large dataset.","","DVD:978-1-4799-2899-6; Electronic:978-1-4799-2900-9; POD:978-1-4799-2901-6","10.1109/ICICICT.2014.6781351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781351","Answer Extraction Module;Definition Type Question;Descriptive Type Question;Document Processing Module;Factoid Type Question;Paragraph Extraction Module;Question Answering System;Question Processing Module","Agriculture;Indexing","document handling;natural language processing;question answering (information retrieval)","NLP tools;answer extraction module;definition type;descriptive type;document processing module;factoid type;information extraction;paragraph extraction module;question processing module;restricted domain question answering system","","1","","32","","","7-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Dimensionality, Discriminability, Density and Distance Distributions","M. E. Houle","Nat. Inst. of Inf., Tokyo, Japan","2013 IEEE 13th International Conference on Data Mining Workshops","20140306","2013","","","468","473","For many large-scale applications in data mining, machine learning, and multimedia, fundamental operations such as similarity search, retrieval, classification, clustering, and anomaly detection generally suffer from an effect known as the `curse of dimensionality'. As the dimensionality of the data increases, distance values tend to become less discriminative, due to their increasing relative concentration about the mean of their distribution. For this reason, researchers have considered the analysis of structures and methods in terms of measures of the intrinsic dimensionality of the data sets. This paper is concerned with a generalization of a discrete measure of intrinsic dimensionality, the expansion dimension, to the case of continuous distance distributions. This notion of the intrinsic dimensionality of a distribution is shown to precisely coincide with a natural notion of the indiscriminability of distances and features. Furthermore, for any distance distribution with differentiable cumulative density function, a fundamental relationship is shown to exist between probability density, the cumulative density (cumulative probability divided by distance), intrinsic dimensionality, and discriminability.","2375-9232;23759232","Electronic:978-1-4799-3142-2; POD:978-1-4799-3144-6","10.1109/ICDMW.2013.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753958","discriminability;distance distribution;features;intrinsic dimensionality;statistical copula","Density functional theory;Distribution functions;Joints;Random variables;Search problems;Size measurement;Vectors","data mining;information retrieval;learning (artificial intelligence)","anomaly detection;continuous distance distributions;data mining;differentiable cumulative density function;dimensionality curse;distance distributions;intrinsic data set dimensionality;large-scale applications;machine learning;multimedia;probability density;similarity search","","1","","26","","","7-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"A situational analysis on the availability and access to computers for educational purposes by learners with visual impairements in Zambi: A case of three basic and three high schools for the blinds","T. Mtonga","Dept. Of Educ. Psychol., Sociology & Special Educ., Univ. Of Zambia, Lusaka, Zambia","Fourth International Conference on Information and Communication Technology and Accessibility (ICTA)","20140515","2013","","","1","5","Computers have become a huge and indispensable gadget in supporting the daily activities of all human beings. One of the areas which seem to benefit a lot from computers is the educational sector. Using computers, lessons are made simple through printing work in bulk, searching for information, communicating with learners and so on. This study sought to establish the availability of computers in Zambian schools for the blind and determine how accessible the computers were to blind learners. Furthermore, the study sought to investigate the benefits of using computers for the blind in the country. The study revealed alarming low levels of computers in schools for the blind. The ratios for one computer to the number of learners were intriguing and very saddening. The study also showed that 16/18 learners with visual impairments had no access to computers. Meaning the majority of blind learners significantly miss out on the benefit that can come from computers. In order to collect the information presented above, a qualitative research approach was used. Thirty respondents participated in the study. Twelve were administrators and teachers while eighteen were pupils. The respondents recommended that schools needed to be stocked with working computers installed with speech programs.","2379-4399;23794399","Electronic:978-1-4799-2725-8; POD:978-1-4799-2726-5","10.1109/ICTA.2013.6815302","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815302","formatting;insert;style;styling","Availability;Computer aided instruction;Computers;Educational institutions;Interviews;Visualization","computer aided instruction;educational technology;handicapped aids;information retrieval;speech processing","Zambi;blind learners;computer access;educational purposes;educational sector;high schools;information searching;printing;situational analysis;speech programs;visual impairements","","0","","7","","","24-26 Oct. 2013","","IEEE","IEEE Conference Publications"
"Maps of Computer Science","D. Fried; S. G. Kobourov","Dept. of Comput. Sci., Univ. of Arizona, Tucson, AZ, USA","2014 IEEE Pacific Visualization Symposium","20140414","2014","","","113","120","We describe a practical approach for visual exploration of research papers. Specifically, we use the titles of papers from the DBLP database to create what we call maps of computer science (MoCS). Words and phrases from the paper titles are the cities in the map, and countries are created based on word and phrase similarity, calculated using co-occurence. With the help of heatmaps, we can visualize the profile of a particular conference or journal over the base map. Similarly, heatmap profiles can be made of individual researchers or groups such as a department. The visualization system also makes it possible to change the data used to generate the base map. For example, a specific journal or conference can be used to generate the base map and then the heatmap overlays can be used to show the evolution of research topics in the field over the years. As before, individual researchers or research group profiles can be visualized using heatmap overlays over a specific journal or conference base map. We outline a modular and extensible system for term extraction using natural language processing techniques, and show the applicability of methods of information retrieval to calculation of term similarity and creation of a topic map. The system is available at mocs.cs.arizona.edu.","2165-8765;21658765","Electronic:978-1-4799-2874-3; POD:978-1-4799-2875-0","10.1109/PacificVis.2014.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787157","Content Analysis and IndexingLinguistic processing;Information Search and RetrievalClustering;MiscellaneousInformation visualization;Topic visualization;clustering;term mapping","Algorithm design and analysis;Computer science;Data visualization;Heating;Semantics;Tag clouds;Visualization","data visualisation;information retrieval;natural language processing;principal component analysis;visual databases","conference base map;heatmap overlays;information retrieval;journal base map;maps of computer science;natural language processing technique;principal component analysis;topic map;visualization system","","5","","36","","","4-7 March 2014","","IEEE","IEEE Conference Publications"
"Measurement and understanding of Cyberlocker URL-sharing sites: Focus on movie files","M. Liu; Z. Zhang; P. Hui; Y. Qin; S. R. Kulkarni","University of Electronic Science and Technology of China, Chengdu, China","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","902","909","Recently, Cyberlocker services have gained great popularity in the file-sharing market. Driven by tremendous benefits a large number of files such as popular movies are uploaded to Cyberlockers. We explore the profit chain of file-sharing networks based on Cyberlockers and find that an important issue is how to collect the download URLs of popular files stored at different Cyberlockers and share them with public users. In this paper, we focus on these sites collecting and sharing the Cyberlocker URLs of movies, called Cyberlocker URL-sharing sites. First, we extract 1,587 URL-sharing sites based on 31,525 valid pages returned by Google search and demonstrate that the quality distribution of these sites follows a power-law. Second, we analyze the link citations among URL-sharing sites and build the directed link citation graph. By characterizing basic metrics of the graph, such as cited strength and in/out-degree, we understand the structure of URL-sharing sites in depth. Furthermore, we discover that Cyberlocker URLs can be disseminated dynamically through crawler mechanisms among different sites, and highlight the implications of such metrics in this context. Additionally, we study the security risks of 1,587 URL-sharing sites. The results show that security risks do exist when surfing 155 suspicious URL-sharing sites such as myrls.me and rapid4me.com although the majority sites (90.23%) are safe. Finally, some preliminary suggestions are discussed from the industry point of view for how to improve the effectiveness of searching, collecting and disseminating Cyberlocker URLs. To the best of our knowledge, this is the first work on the measurement and understanding of Cyberlocker URL-sharing sites.","","Electronic:978-1-4503-2240-9","10.1109/ASONAM.2013.6785807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785807","","Conferences;Crawlers;Google;Measurement;Motion pictures;Security;Social network services","graph theory;information dissemination;information retrieval;peer-to-peer computing;security of data","Cyberlocker URL-sharing sites;Cyberlocker services;Google search;crawler mechanisms;directed link citation graph;download URL;file-sharing market;graph metrics;movie files;myrls.me;power-law;public users;rapid4me.com;security risks","","0","","16","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Context-aware graph modeling for object search and retrieval in a wide area camera network","S. Sunderrajan; J. Xu; B. S. Manjunath","Dept. of Electr. & Comput. Eng., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","2013 Seventh International Conference on Distributed Smart Cameras (ICDSC)","20140327","2013","","","1","7","This paper addresses the problem of context-aware object search and retrieval in a wide area distributed camera network. With the proliferation of smart cameras in urban networks, it is a challenge to process this big data in an efficient manner. A novel graph based model is proposed to represent relationships, and for search and retrieval tasks. This representation exploits the fact that objects occurring in close spatial-temporal proximity are not completely independent and serve as context for each other. Additional information such as appearance and scene context can also be encoded into the graph model to improve the overall accuracy. A manifold ranking strategy is used to order the items based on similarity with an emphasis on diversity. Extensive experimental results on a ten camera network are presented.","","Electronic:978-1-4799-2164-5; POD:978-1-4799-2166-9","10.1109/ICDSC.2013.6778204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778204","Context-aware camera networks;Graph based ranking;Object search and Retrieval","Cameras;Computational modeling;Context;Context modeling;Histograms;Tracking;Vectors","graph theory;information retrieval;object detection;ubiquitous computing","appearance;context-aware graph modeling;manifold ranking strategy;object retrieval;object search;scene context;smart camera;spatial-temporal proximity;wide area distributed camera network","","1","","22","","","Oct. 29 2013-Nov. 1 2013","","IEEE","IEEE Conference Publications"
"A Privacy-Preserving Fuzzy Keyword Search Scheme over Encrypted Cloud Data","D. Wang; S. Fu; M. Xu","Coll. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2013 IEEE 5th International Conference on Cloud Computing Technology and Science","20140306","2013","1","","663","670","Fuzzy keyword search is an important and necessary functionality for information retrieval in modern cloud storage services, since cloud users may submit queries with typos errors or have deficient knowledge about the underlying keywords of cloud data sets. However, for the purpose of privacy preservation, data is usually encrypted before outsourcing to the cloud, which greatly compromises the data utilization flexibility and efficiency. In this paper, we propose F2SE as a novel fuzzy keyword search scheme over encrypted cloud data. Using keyword fingerprint extraction and secure kNN encryption, F2SE can achieve a top-k ranked fuzzy keyword search according to the keyword similarity. Meanwhile, F2SE can return keywords containing special sub strings customized by cloud users with deficient background knowledge, which can be used for exploratory search or uncertain search. Thorough security analysis shows F2SE is KPA-secure while extensive experiments over real data sets demonstrate that F2SE has a low memory overhead and practical searching time cost.","","Electronic:978-0-7695-5095-4; POD:978-1-4799-1548-4","10.1109/CloudCom.2013.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753859","cloud storage security;fuzzy keyword search;privacy-preserving","Cloud computing;Encryption;Indexes;Keyword search;Vectors","cloud computing;cryptography;data privacy;fuzzy set theory;information retrieval","KPA-secure F2SE;cloud users;data utilization efficiency;data utilization flexibility;encrypted cloud data;information retrieval;keyword fingerprint extraction;keyword similarity;modern cloud storage services;outsourcing;privacy-preserving fuzzy keyword search scheme;secure kNN encryption;top-k ranked fuzzy keyword search","","2","","16","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"An analysis of semantic heterogeneity issues and their countermeasures prevailing in semantic web","V. Rana; G. Singh","Punjab Tech. Univ., Jalandhar, India","2014 International Conference on Reliability Optimization and Information Technology (ICROIT)","20140417","2014","","","80","85","Nowadays, wisdom information retrieval system is available on the web, which enables a new generation of intelligent web that utilizes this semantic information as source of knowledge. The vision of semantic web crafts an environment where the information available on the web can be semantically interpreted. However, with abundance of information on the web, it is complicated to interpret the information with their intended meaning. Achieving this by interoperability among different information systems is very laborious, tedious and error-prone task which results out of semantic heterogeneity. Semantic web suggested solution of retrieval of specific information through the use of ontology matching technique and intelligent agent technology. In this paper we have proposed a knowledge-based grid for retrieving valuable information according to users necessitates. This paper also conducts a review of research in the area of intelligent communities and identifies the major theoretical and practical issues which need to be addressed.","","Electronic:978-1-4799-2995-5; POD:978-1-4799-2997-9","10.1109/ICROIT.2014.6798296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6798296","Intelligent Agent;Ontology Matching;Semantic Heterogeneity;Semantic Web","Databases;Ontologies;Semantics;Servers","information retrieval;knowledge based systems;ontologies (artificial intelligence);open systems;semantic Web;software agents","intelligent Web;intelligent agent;interoperability;knowledge-based grid;ontology matching;semantic Web;semantic heterogeneity;semantic heterogeneity issues;semantic information;wisdom information retrieval system","","2","","21","","","6-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Indoor Place Name Annotations with Mobile Crowd","Y. C. Fan; W. H. Lee; C. T. Iam; G. H. Syu","Dept. of Comput. Sci. & Eng., Nat. Chung Hsing Univ., Taichung, Taiwan","2013 International Conference on Parallel and Distributed Systems","20140501","2013","","","546","551","With the popularity of mobile devices, numerous mobile applications have been and will continue to be developed for various interesting usage scenarios. Riding this trend, recent research community envisions a novel information retrieving and information-sharing platform, which views the users with mobile devices and being willing to accept crowd sourcing tasks as crowd sensors. With the neat idea, a set of crowd sensors applications have emerged. Among the applications, the geospatial information systems based on crowd sensors show significant potentials beyond traditional ones by providing real time geospatial information. In the applications, user positioning is of great importance. However, existing positioning techniques have their own disadvantages. In this paper, we study using pervasive Wi-Fi access point as a position indicator. The major challenge for using Wi-Fi access point is that there is no mechanism for mapping observed Wi-Fi signals to human-defined places. To this end, our idea is to employ crowd sourcing model to perform place name annotations by mobile participants to bridge the gap between signals and human-defined places. In this paper, we propose schemes for effectively enabling based-based place name annotation, and conduct real trials with recruited participants to study the effectiveness of the proposed schemes. The experiment results demonstrate the effectiveness of the proposed schemes over existing solutions.","1521-9097;15219097","Electronic:978-1-4799-2081-5; POD:978-1-4799-2082-2; USB:978-1-4799-2080-8","10.1109/ICPADS.2013.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808235","Crowdsourcing;Geospatial Information System;Mobile Application","Clustering algorithms;Geospatial analysis;Global Positioning System;IEEE 802.11 Standards;Mobile communication;Mobile handsets;Sensors","geographic information systems;information retrieval;mobile computing;wireless LAN","crowd sensors;crowd sourcing model;crowd sourcing task;geospatial information system;human-defined places;indoor place name annotation;information retrieving platform;information-sharing platform;mobile crowd;mobile devices;pervasive wi-fi access point;position indicator;positioning techniques;real time geospatial information;recent research community;user positioning;wi-fi signals","","2","","19","","","15-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"EmailMap: Visualizing Event Evolution and Contact Interaction within Email Archives","S. J. Luo; L. T. Huang; B. Y. Chen; H. W. Shen","Nat. Taiwan Univ., Taipei, Taiwan","2014 IEEE Pacific Visualization Symposium","20140414","2014","","","320","324","Email archives contain rich information about how we interact with different contacts and how events evolve throughout time. Making sense of the archived messages can be a good way to understand how things evolved and progressed in the past. Although much work has been devoted to email visualization, most work has focused on presenting one of the two aspects of email archives: discovering the evolution of emails and events, or the relationship between the email owner and his/her contacts over time. In this paper, we present Email Map, an email visualization which integrates the information of both events and contacts into a single view, enabling users to make sense of their email archives with complementary contextual information. Two visualization components are designed to portray complex information within the email archives: event flow and contact tracks. The event flow illustrates the evolution of past events, helping the users to grasp high-level pictures and patterns of their email archives. The contact tracks reveal the interaction between the email owner and his/her contacts.","2165-8765;21658765","Electronic:978-1-4799-2874-3; POD:978-1-4799-2875-0","10.1109/PacificVis.2014.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6787190","Applications;User Interfaces","Context;Educational institutions;Electronic mail;Layout;Optimization;Visualization","data visualisation;electronic mail;graphical user interfaces;information retrieval systems","complementary contextual information;contact interaction visualization;contact tracks;email archives;email visualization;emailMap;event evolution visualization;event flow;visualization components","","0","","24","","","4-7 March 2014","","IEEE","IEEE Conference Publications"
"A Trust-Aware System for Personalized User Recommendations in Social Networks","M. Eirinaki; M. D. Louta; I. Varlamis","Dept. of Comput. Eng., San Jose State Univ., San Jose, CA, USA","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20140313","2014","44","4","409","421","Social network analysis has recently gained a lot of interest because of the advent and the increasing popularity of social media, such as blogs, social networking applications, microblogging, or customer review sites. In this environment, trust is becoming an essential quality among user interactions and the recommendation for useful content and trustful users is crucial for all the members of the network. In this paper, we introduce a framework for handling trust in social networks, which is based on a reputation mechanism that captures the implicit and explicit connections between the network members, analyzes the semantics and dynamics of these connections, and provides personalized user recommendations to the network members.","2168-2216;21682216","","10.1109/TSMC.2013.2263128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549154","Personalization;recommendation;reputation;social networks;trust","","information retrieval;recommender systems;social networking (online);trusted computing","blogs;connection dynamics analysis;connection semantics analysis;customer review sites;explicit connection;implicit connection;microblogging;network members;personalized user recommendations;reputation mechanism;social media;social network analysis;social networking application;trust handling;trust-aware system;trustful users;useful content recommendation;user interaction","","21","","44","","20130628","April 2014","","IEEE","IEEE Journals & Magazines"
"GCAR: A Group Composite Alternatives Recommender Based on Multi-criteria Optimization and Voting","H. Mengash; A. Brodsky","George Mason Univ., Fairfax, VA, USA","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","1113","1121","This paper proposes a Group Composite Alternatives Recommender (GCAR) framework, which provides recommendations on dynamically defined composite bundles of products and services. This framework is based on: (1) defining the space of alternatives, (2) eliciting the utility function for each individual decision maker, (3) estimating the group utility function, (4) using the group utility function to find an optimal recommendation alternative, (5) constructing a set of diverse recommendations which contains the optimal recommendation alternative, and (6) applying the Instant Runoff Voting (IRV) method, from social choice theories, to refine the recommendations. A preliminary experimental study is conducted which shows that the proposed framework significantly outperforms three popular aggregation strategies normally used for group recommendations.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758741","","Aggregates;Educational institutions;Motion pictures;Optimization;Recommender systems;TV;Vectors","information retrieval;optimisation;recommender systems","GCAR;IRV method;group composite alternative recommender;group utility function;instant runoff voting;multicriteria optimization;multicriteria voting","","2","","25","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"Data Retrieval Scheduling for Multi-Item Requests in Multi-Channel Wireless Broadcast Environments","Z. Lu; Y. Shi; W. Wu; B. Fu","Department of Computer Science , University of Texas at Dallas, Mail Station EC 31, 2601 North Floyd Road, Richardson","IEEE Transactions on Mobile Computing","20140311","2014","13","4","752","765","Wireless data broadcast is a popular data dissemination method in mobile computing environments because of its capability of concurrently disseminating data to multiple users. In this paper, we study the data retrieval scheduling problem for multi-item requests in multi-channel broadcast environments. To maximize the number of downloads given a deadline, we define a problem called largest number data retrieval (LNDR). We prove the decision problem of LNDR is NP-hard, and we investigate approximation algorithm for it. We also define another problem called minimum cost data retrieval (MCDR), which aims at downloading a set of requested data items with the least response time and energy consumption. We prove MCDR is NP-hard to approximate to within any non-trivial factor. Therefore, we investigate heuristic algorithm for it. Finally we provide simulation results to demonstrate the practical efficiency of the proposed algorithms.","1536-1233;15361233","","10.1109/TMC.2013.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6477044","Multi-channel;NP-hard;approximability;data retrieval scheduling;multi-item request;wireless data broadcast","Energy consumption;Indexes;Schedules;Scheduling;Servers;Switches;Time factors","broadcast channels;information retrieval;mobile computing;optimisation;wireless channels","NP hard;approximation algorithm;data dissemination method;data retrieval scheduling;heuristic algorithm;largest number data retrieval;minimum cost data retrieval;mobile computing;multichannel wireless broadcast environments;multiitem requests;wireless data broadcast","","5","","38","","20130311","April 2014","","IEEE","IEEE Journals & Magazines"
"Intelligent web mining technique using evolutionary algorithms","S. More; U. Bharambe","Thadomal Shahani Eng. Coll., Mumbai, India","2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)","20140403","2014","","","508","514","Many conventional search engines satisfy the need of information retrieval from WWW, but the results obtained still hold a chance for refinement and accuracy. This problem of getting irrelevant results is specifically observed for complex queries i.e. queries with many key words. We propose an intelligent method for web mining based on Genetic Algorithm (GA). The results produced by conventional search engine i.e. snippets, are further processed and refined further to extract only the most relevant snippets. A significant improvement is observed in the search results by using a modified GA with additional local searching technique of Memetic Algorithm (MA).","","DVD:978-1-4799-2899-6; Electronic:978-1-4799-2900-9; POD:978-1-4799-2901-6","10.1109/ICICICT.2014.6781335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781335","Evolutionary Algorithms;Genetic Algorithm;Memetic Algorithm;Web Mining;snippets","Abstracts;Biological cells;Engines;Genetic algorithms;Sociology;Statistics","Internet;data mining;genetic algorithms;information retrieval;search engines","GA;MA;WWW;World Wide Web;evolutionary algorithms;genetic algorithm;information retrieval;intelligent web mining technique;memetic algorithm;search engines;snippets","","0","","9","","","7-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Motion Retrieval Using Probability Graph Model","Q. Xiao; J. Li; Y. Wang; Z. Li; H. Wang","Dept. of Electron. Inf. Eng., Xi'an Technol. Univ., Xi'an, China","2013 Sixth International Symposium on Computational Intelligence and Design","20140424","2013","2","","150","153","In this paper, we propose a content-based motion retrieval algorithm. In this work, firstly, each motion is represented by a set of sequence frames. Representative frames are first selected from the motions and the corresponding weights are provided. Secondly, the graph model is built with these selected frames. For searching the optimal measurement between query motion and relevant motions in database, an object function is built. The task to find the maximal a posterior (MAP) in the motion level is equivalent to find the minimal objective function value. At last, based on probability calculation, the KM (Kuhn-Munkres) algorithm is used to find the optimal matching between motions. The matching result is used to measure the similarity between two motions. Experimental results and comparison with existing methods show the effectiveness of the proposed algorithm.","","Electronic:978-0-7695-5079-4; POD:978-1-4799-0906-3","10.1109/ISCID.2013.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6804850","Kuhn-Munkres;motion retrieval;probability graph model","Algorithm design and analysis;Computational modeling;Indexing;Linear programming;Quaternions;Radio frequency","content-based retrieval;graph theory;image matching;image motion analysis;image representation;image sequences;information retrieval;probability","KM algorithm;Kuhn-Munkres algorithm;MAP;content-based motion retrieval algorithm;maximal a posterior;minimal objective function value;motion level;optimal matching;optimal measurement;probability calculation;probability graph model;representative frame;sequence frame","","0","","17","","","28-29 Oct. 2013","","IEEE","IEEE Conference Publications"
"Implementation of MD algorithm for text extraction from video","Sonam; M. Kumar","Dept. of Comput. Eng., Technol. Inst. of Textile & Sci., Bhiwani, India","2013 Nirma University International Conference on Engineering (NUiCONE)","20140331","2013","","","1","5","With fast intensification of existing multimedia documents and mounting demand for information indexing and retrieval, much effort has been done on extracting the text from images and videos. Extracting the text from video is demanding due to complex background, varying font size, different style, high blurring, lower resolution, different position, viewing angle and so on. In this paper, implementation of text extraction from the video has been done by using the MD algorithm. In this paper, a region based approach is used to perform such kind of text extraction. The approach is divided into the three main layers: first, extraction of unique frames from video; second, identify the text frame from these unique frames; third, extraction of the text from these text frames. DWT performs the decomposition in the region and Morphological Operator performs the edge detection and the region classification.","2375-1282;23751282","Electronic:978-1-4799-0727-4; POD:978-1-4799-0725-0","10.1109/NUiCONE.2013.6780069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6780069","DWT (Discrete wavelet transform);MD (Morphology-DWT);MIP (Mathematical image processing);TIE (Text information extraction system)","Algorithm design and analysis;Data mining;Discrete wavelet transforms;Image resolution;Morphology;Shape","discrete wavelet transforms;edge detection;feature extraction;information retrieval;mathematical morphology;text detection","DWT;MD algorithm;edge detection;images;information indexing;information retrieval;morphological operator;multimedia documents;region classification;text extraction;video","","0","","9","","","28-30 Nov. 2013","","IEEE","IEEE Conference Publications"
"A Retrieval Strategy for Case-Based Reasoning Using Similarity and Association Knowledge","Y. B. Kang; S. Krishnaswamy; A. Zaslavsky","Fac. of Inf. Technol., Monash Univ., Melbourne, VIC, Australia","IEEE Transactions on Cybernetics","20140313","2014","44","4","473","487","Retrieval is a key phase in case-based reasoning (CBR), since it lays the foundation for the overall effectiveness of CBR systems. Its aim is to retrieve useful cases that can be used to solve the target problem. To perform the retrieval process, CBR systems typically exploit similarity knowledge and is called similarity-based retrieval (SBR). However, SBR tends to rely strongly on similarity knowledge, ignoring other forms of knowledge that can be further leveraged to improve the retrieval performance. This paper argues and motivates that association analysis of stored cases can significantly strengthen SBR. We propose a novel retrieval strategy USIMSCAR that substantially outperforms SBR by leveraging association knowledge, encoded via a certain form of association rules, in conjunction with similarity knowledge. We also propose a novel approach for extracting association knowledge from a given case base using various association rule mining techniques. We evaluate the significance of USIMSCAR in three application domains-medical diagnosis, IT service management, and product recommendation.","2168-2267;21682267","","10.1109/TCYB.2013.2257746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6516061","Association knowledge (AK);CBR retrieval;association rule mining (ARM);case-based reasoning (CBR)","","case-based reasoning;data mining;information retrieval","CBR systems;IT service management;SBR;USIMSCAR;association knowledge;association rule mining techniques;case-based reasoning;medical diagnosis;product recommendation;retrieval strategy;similarity knowledge;similarity-based retrieval","","10","","36","","20130514","April 2014","","IEEE","IEEE Journals & Magazines"
"Phrase Based Topic Modeling for Semantic Information Processing in Biomedicine","Z. Yu; T. R. Johnson; R. Kavuluru","Dept. of Biostat., Univ. of Kentucky, Lexington, KY, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","440","445","Given that unstructured data is increasing exponentially everyday, extracting and understanding the information, themes, and relationships from large collections of documents is increasingly important to researchers in many disciplines including biomedicine. Latent Dirichlet Allocation (LDA) is an unsupervised topic modeling technique based on the ""bag-of-words"" assumption that has been applied extensively to unveil hidden semantic themes within large sets of textual documents. Recently, it was extended using the ""bag-of-n-grams"" paradigm to account for word order. In this paper, we present an alternative phrase based LDA model to move from a bag of words or n-grams paradigm to a ""bag-of-key-phrases"" setting by applying a key phrase extraction technique, the C-value method, to further explore latent themes. We evaluate our approach by using a phrase intrusion user study and demonstrate that our model can help LDA generate better and more interpretable topics than those generated using the bag-of-n-grams approach. Given topic models essentially are statistical tools, an important problem in topic modeling is that of visualizing and interacting with the models to understand and extract new information from a collection. To evaluate our phrase based modeling approach in this context, we incorporate it in an open source interactive topic browser. Qualitative evaluations of this browser with biomedical experts demonstrate that our approach can aid biomedical researchers gain better and faster understanding of their document collections.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784659","topic models;visual processing;word intrusion","Biological system modeling;Browsers;Computational modeling;Context;Context modeling;Pain;Semantics","biology computing;information retrieval;medicine;statistical analysis;text analysis","C-value method;bag-of-n-grams paradigm;bag-of-words assumption;biomedicine;document collections;key phrase extraction technique;latent Dirichlet allocation;open source interactive topic browser;phrase based topic modeling;phrase intrusion user study;semantic information processing;statistical tools;textual documents;unsupervised topic modeling technique","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Multimodal Similarity-Preserving Hashing","J. Masci; M. M. Bronstein; A. M. Bronstein; J. Schmidhuber","Swiss AI Lab (IDSIA), Manno, the Faculty of Informatics, University of Lugano (USI), and the SUPSI, Switzerland","IEEE Transactions on Pattern Analysis and Machine Intelligence","20140324","2014","36","4","824","830","We introduce an efficient computational framework for hashing data belonging to multiple modalities into a single representation space where they become mutually comparable. The proposed approach is based on a novel coupled siamese neural network architecture and allows unified treatment of intra- and inter-modality similarity learning. Unlike existing cross-modality similarity learning approaches, our hashing functions are not limited to binarized linear projections and can assume arbitrarily complex forms. We show experimentally that our method significantly outperforms state-of-the-art hashing approaches on multimedia retrieval tasks.","0162-8828;01628828","","10.1109/TPAMI.2013.225","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654144","Similarity-sensitive hashing;feature descriptor;metric learning;neural network","Databases;Measurement;Neural networks;Optimization;Standards;Training;Vectors","file organisation;information retrieval;learning (artificial intelligence);multimedia computing;neural nets","coupled siamese neural network architecture;cross-modality similarity learning approaches;hashing data;hashing functions;intermodality similarity learning;intramodality similarity learning;multimedia retrieval tasks;multimodal similarity-preserving hashing;single representation space;unified treatment","","23","","50","","20131104","April 2014","","IEEE","IEEE Journals & Magazines"
"A novel approach for link context extraction using Bison parser","S. Gupta; S. Yadav","AKGEC, Ghaziabad, India","2014 IEEE International Advance Computing Conference (IACC)","20140327","2014","","","941","945","With the advent of World Wide Web, link context has been widely used for finding the theme of the target web page. Many approaches have been used to take advantage of the link context to get the precise context of link but the approaches were not very efficient. Link Context has been used in many areas like classification of web page, search engines, topical crawlers. In this paper we have derived the link context using LALR parser (Bison parser). For this different web pages have been collected and with the help of tag tree concepts are found out. Then using Bison parser link context have been derived. We have also compared the technique with the anchor text based method using Jaccard coefficient.","","CD-ROM:978-1-4799-2571-1; Electronic:978-1-4799-2572-8; POD:978-1-4799-2573-5","10.1109/IAdCC.2014.6779449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6779449","Anchor text;Crawling;Indexing;LALR parsing;Link Context;Tag tree","Conferences;Context;Crawlers;Flexible printed circuits;Grammar;HTML;Web pages","Internet;classification;context-free grammars;indexing;information retrieval;search engines;text analysis","Bison parser;Jaccard coefficient;LALR parser;Web page classification;World Wide Web;anchor text based method;link context extraction;search engine classification;topical crawler classification","","0","","16","","","21-22 Feb. 2014","","IEEE","IEEE Conference Publications"
"ACQA_onto: An ontology approach for restrain domain question answering system","D. Hu; W. Wang; N. Xie; C. Cao","Inst. of Agric. Inf., Chinese Acad. of Agric. Sci., Beijing, China","IET International Conference on Information Science and Control Engineering 2012 (ICISCE 2012)","20140306","2012","","","1","5","This paper presented a restrained domain ontology model for agriculture cultivation question answering system - ACQA_onto. The question answering system (QA) has become one effective approach for knowledge engineering research. Ontologies could make the restrain domain concepts of semantics being understood by computer, which have been one significant technique for question answering system. This paper provided introduction ontologies in general and subsequently, in particularly, shortly provided the definition of domain ontology for agriculture cultivation. In main part, this paper presented the restricted domain ontology models and concept level vector space model of information retrieval (IR). The ontological representations of documents for agriculture cultivation question answering system was presented, and descript the prototype of ACQA_onto, in which part focalized with the process of generating answers from question. The result of ACQA_onto was proposed and the future work of question answering system for agriculture cultivation was introduced briefly.","","Electronic:978-1-84919-641-3","10.1049/cp.2012.2341","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755720","agriculture cultivation;domain ontology;question answering system;vector space model","","agriculture;knowledge engineering;ontologies (artificial intelligence);question answering (information retrieval)","ACQA_onto;agriculture cultivation question answering system;document ontological representations;information retrieval;knowledge engineering research;restrain domain question answering system;restrained domain ontology model;restricted domain ontology models;semantics;vector space model","","0","","","","","7-9 Dec. 2012","","IET","IET Conference Publications"
"Dhiya: A stemmer for morphological level analysis of Gujarati language","J. Sheth; B. Patel","SRIMCA, Uka Tarsadia Univ., Gopal Vidyanagar, India","2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)","20140403","2014","","","151","154","To understand a language, analysis has to be done at word level, sentence level, context level and discourse level. Morphological analysis comes at the base of all, as it is the first step to understand a given sentence. One of the tasks that can be done at morphological level is stemming. To identify the stem term of a given word is stemming. Stemming is one of the important activities which is not just related to Natural Language Processing domain, but is equally important in Information Retrieval domain. In this paper, authors suggest DHIYA a stemmer for Gujarati language. This stemmer is based on the morphology of Gujarati language. To develop the stemmer, inflections which appeared most in Gujarati text were identified. Based on it, the rule set was created. For training and evaluation of the stemmer's performance the EMILLE corpus is used. The accuracy of the stemmer is 92.41%.","","DVD:978-1-4799-2899-6; Electronic:978-1-4799-2900-9; POD:978-1-4799-2901-6","10.1109/ICICICT.2014.6781269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781269","Gujarati;Indian languages;Morphemes;Stemmer","Computers;Gold;Hidden Markov models;Quantum cascade lasers","information retrieval;natural language processing;text analysis;word processing","DHIYA;EMILLE corpus;Gujarati language morphology;Gujarati text;context level;discourse level;information retrieval domain;morphological level analysis;sentence level;stemmer performance evaluation;stemming;training;word level","","1","","16","","","7-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Searching Desktop Files Based on Synonym Relationship","X. Zhao; Y. Li; J. Liu; Y. Xiao","Key Lab. of Intell. Comput. & Novel Software Technol., Tianjin, China","2013 10th Web Information System and Application Conference","20140327","2013","","","483","488","Users sometimes cannot remember the exact words of desktop filenames and meet trouble in re-finding these desktop files. In this condition the existing keyword based desktop search tools cannot work well. In this paper, we first analyze the synonym relationship among the words utilized in naming personal desktop files. Then, we propose a synonym-based desktop search method to solve the problem, and name it SynDS. By comparing it with a popular desktop search tool ""MS Desktop Search"", SynDS shows better recall and precision, which means it can help users re-find desktop files in some conditions when the traditional methods fail to work.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778688","Desktop File Searching;Personal Information Management;Synonym","Catalogs;Computers;Indexing;Vectors;Vocabulary;Writing","information management;information retrieval;microcomputers;naming services;personal computing","MS Desktop Search;SynDS;desktop file searching;personal desktop file naming;personal information management;precision;recall;synonym relationship;synonym-based desktop search method","","0","","19","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Privacy Preserving Support Vector Machine Using Non-linear Kernels on Hadoop Mahout","S. G. Teo; S. Han; V. C. S. Lee","Monash Univ., Clayton, VIC, Australia","2013 IEEE 16th International Conference on Computational Science and Engineering","20140306","2013","","","941","948","Four main challenges (volume, velocity, variety, veracity) have confronted computation algorithm designers in big data mining. Homomorphic cryptosystem with secured multi-party computation of matrix operations has been shown to yield high privacy preserving while data miners perform information retrieval from big data. This research concerns with the computation complexity of the big data with specific focus on computational load reduction while preserving data privacy. We propose a Teo-Han-Lee (THL) algorithm with various matrix operations to reduce the cryptographic cost significantly by cutting off at least one-third or more total computational operations. In THL, a pre-generated random key technique that we propose to apply here can decrease the computational time in which the random keys can be retrieved from memory without being generated on the fly. We further develop a collusion-resistant secure sum product protocol (CRSSPP) which is integrated in THL algorithm over arbitrary partitioned data. Experimental results demonstrated that THL-CRSSPP algorithm is more efficient than Vaidya et al SVM method [2] (state-of-the-art SVM method) and hence would be more applicable to the cloud-based big data mining. The THL-CRSSPP algorithm can also be integrated into Hadoop Mahout with a minimal effort.","","Electronic:978-0-7695-5096-1; POD:978-1-4799-4897-0","10.1109/CSE.2013.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755320","Classification;Security;Support Vector Machine;and Privacy","Data privacy;Encryption;Kernel;Protocols;Support vector machines","cryptography;data mining;data privacy;information retrieval;matrix algebra;support vector machines","CRSSPP;Hadoop Mahout;THL algorithm;Teo-Han-Lee;collusion resistant secure sum product protocol;computation complexity;data mining;data privacy;homomorphic cryptosystem;information retrieval;matrix operations;nonlinear kernels;privacy preserving support vector machine","","1","","27","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"iFlatLFS: Performance optimization for accessing massive small files","S. Fu; C. Huang; L. He; N. Chaudhary; X. Liao; S. Yang; X. Wang; B. Li","Sch. of Comput. Sci., Nat. Univ. of Defense Technol., Changsha, China","20th Annual International Conference on High Performance Computing","20140417","2013","","","10","19","The processing of massive small files is a challenge in the design of distributed file systems. Currently, the combined-block-storage approach is prevalent. However, the approach employs traditional file systems like ExtFS and may cause inefficiency for random access to small files. This paper focuses on optimizing the performance of data servers in accessing massive small files. We present a Flat Lightweight File System (iFlatLFS) to manage small files, which is based on a simple metadata scheme and a flat storage architecture. iFlatLFS aims to substitute the traditional file system on data servers that are mainly used to store small files, and it can greatly simplify the original data access procedure. The new metadata proposed in this paper occupies only a fraction of the original metadata size based on traditional file systems. We have implemented iFlatLFS in CentOS 5.5 and integrated it into an open source Distributed File System (DFS), called Taobao FileSystem (TFS), which is developed by a top B2C service provider, Alibaba, in China and is managing over 28.6 billion small photos. We have conducted extensive experiments to verify the performance of iFlatLFS. The results show that when the file size ranges from 1KB to 64KB, iFlatLFS is faster than Ext4 by 48% and 54% on average for random read and write in the DFS environment, respectively. Moreover, after iFlatLFS is integrated into TFS, iFlatLFS-based TFS is faster than the existing Ext4-based TFS by 45% and 49% on average for random read access and hybrid access (the mix of read and write accesses), respectively.","1094-7256;10947256","Electronic:978-1-4799-0730-4; POD:978-1-4799-0728-1","10.1109/HiPC.2013.6799116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799116","","Analytical models;Distributed databases;File systems;Indexes;Optimization;Performance evaluation;Servers","data structures;distributed databases;information retrieval;meta data;storage management","DFS;combined-block-storage approach;data access procedure simplification;data server performance optimization;flat lightweight file system;flat storage architecture;iFlatLFS;massive small file processing;metadata scheme;open source distributed file system","","0","","21","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Research on Large Scale Hierarchical Classification Based on Candidate Search","L. He; Y. Jia; Z. Ding; W. Han","Sch. of Comput. Sci., Nat. Univ. of Defense Technol., Changsha, China","2013 10th Web Information System and Application Conference","20140327","2013","","","355","360","Large scale hierarchical classification problem researches how to classify web documents into the categories among a class hierarchy. As the class hierarchy is very large that containing thousands or even tens of thousands of categories, the performance of the classification is still lower. While a reduce-and-conquer strategy has been proposed to make the problem tractable, candidate search is a bottleneck in classification. In this paper, we first analyze the computational complexity of category candidate search problem, and prove that it is an NP-hard problem. Then a candidate search algorithm which adopts a greedy strategy is proposed, and we prove that the proposed greedy strategy is a local optimum choice in the heuristic solving process. In the classification stage, we find that ancestor categories may help classification of candidates. Experiments are conducted on the dataset of web pages from the Chinese Simplified branch of the DMOZ directory. The results show that the proposed algorithm achieves a performance improvement for candidate search compared to existing methods, and further improves the classification accuracy of two-stage approaches.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778664","candidate search problem;category candidate;class hierarchy;large scale hierarchical classification;text categorization","Accuracy;Buildings;Classification algorithms;Heuristic algorithms;NP-hard problem;Search problems","Internet;computational complexity;greedy algorithms;information retrieval;optimisation;pattern classification;text analysis","Chinese Simplified branch;DMOZ directory;NP-hard problem;Web document classification;Web pages;ancestor categories;category candidate search problem;class hierarchy;classification performance improvement;computational complexity;greedy strategy;heuristic solving process;large scale hierarchical classification problem;local optimum choice;two-stage approach classification accuracy","","0","","10","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Efficient use of training data for sinhala speech recognition using active learning","T. Nadungodage; R. Weerasinghe; M. Niranjan","Sch. of Comput., Language Technol. Res. Lab., Univ. of Colombo, Colombo, Sri Lanka","2013 International Conference on Advances in ICT for Emerging Regions (ICTer)","20140310","2013","","","149","153","Automatic Speech Recognition is an area which requires a large amount of training data. Collecting such quantities of data involves significant time and cost owing to the tedious nature of collecting speech recordings and manual nature of transcribing it. For a low resourced language such as Sinhala, collecting a sufficient data set is a major problem. To address this issue we used the Active Learning technique from the Machine Learning paradigm which is applied to many tasks such as information retrieval. Our experiment using a simple Sinhala speech corpus shows that through the use of Active Learning, the amount of utterances that need to be transcribed can be reduced by some 42% to achieve the same accuracy as using the whole data set without such a strategy. This suggests that Active Learning techniques can be successfully applied to make optimal use of scarce resources for speech recognition for new languages.","","Electronic:978-1-4799-1276-6; POD:978-1-4799-1273-5","10.1109/ICTer.2013.6761170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6761170","ASR;Active Learning;Automatic Speech Recognition;Confidence scoring;Information extraction;Low Resourced Languages;NLP;Natural Language Processing;Sinhala;Word posterior probabilities","Accuracy;Acoustics;Computational modeling;Speech;Speech recognition;Training;Vocabulary","information retrieval;learning (artificial intelligence);speech recognition","Sinhala speech corpus;Sinhala speech recognition;active learning technique;automatic speech recognition;information retrieval;machine learning;training data","","0","","21","","","11-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Self-Adaptive Semantic Focused Crawler for Mining Services Information Discovery","H. Dong; F. K. Hussain","Sch. of Inf. Syst., Curtin Univ. of Technol., Perth, WA, Australia","IEEE Transactions on Industrial Informatics","20140502","2014","10","2","1616","1626","It is well recognized that the Internet has become the largest marketplace in the world, and online advertising is very popular with numerous industries, including the traditional mining service industry where mining service advertisements are effective carriers of mining service information. However, service users may encounter three major issues - heterogeneity, ubiquity, and ambiguity, when searching for mining service information over the Internet. In this paper, we present the framework of a novel self-adaptive semantic focused crawler - SASF crawler, with the purpose of precisely and efficiently discovering, formatting, and indexing mining service information over the Internet, by taking into account the three major issues. This framework incorporates the technologies of semantic focused crawling and ontology learning, in order to maintain the performance of this crawler, regardless of the variety in the Web environment. The innovations of this research lie in the design of an unsupervised framework for vocabulary-based ontology learning, and a hybrid algorithm for matching semantically relevant concepts and metadata. A series of experiments are conducted in order to evaluate the performance of this crawler. The conclusion and the direction of future work are given in the final section.","1551-3203;15513203","","10.1109/TII.2012.2234472","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6384736","Mining service industry;ontology learning;semantic focused crawler;service advertisement;service information discovery","Advertising;Business;Crawlers;Industries;Internet;Ontologies;Semantics","Internet;advertising;indexing;information retrieval;learning (artificial intelligence);meta data;mining industry;ontologies (artificial intelligence);vocabulary","Internet;SASF crawler;Web environment;ambiguity;concept matching;heterogeneity;metadata;mining service advertisements;mining service industry;mining service information formatting;mining service information indexing;mining services information discovery;online advertising;self-adaptive semantic focused crawler;ubiquity;unsupervised framework;vocabulary-based ontology learning","","6","","25","","20121220","May 2014","","IEEE","IEEE Journals & Magazines"
"Event Causality Identification Using Conditional Random Field in Geriatric Care Domain","S. Mehrabi; A. Krishnan; E. Tinsley; J. Sligh; N. Crohn; H. Bush; J. Depasquale; J. Bandos; M. Palakal","Sch. of Inf. & Comput., Indiana Univ., Indianapolis, IN, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","339","343","Event extraction is a key step in many text-mining applications such as question-answering, information extraction and summarization systems. In this study we used conditional random field (CRF) to extract causal events from PubMed articles related to Geriatric care. Abstracts of geriatric care domain were manually reviewed and categorized into 42 different sub domains. There are a total of 19, 677 sentences in the collected abstracts from PubMed, out of which 2, 856 sentences were selected and manually annotated with cause and effect events. The data set was then divided into training (2, 520), validation (252) and test (84) sentence sets. Features such as tokens, token categories, affixes, part of speech and shallow parser were used as inputs to the CRF model. A window of features before and after each token was used to determine its causal event label using CRF. A window of four features had the best performance with 84.6% precision, 87% recall, 85% and F-measure.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784639","conditional random fields;event extraction;natural language processing","Abstracts;Data models;Geriatrics;Hidden Markov models;Natural language processing;Training;Unified modeling language","data mining;geriatrics;health care;information retrieval;text analysis","PubMed articles;causal event extraction;conditional random field;event causality identification;geriatric care domain;text mining","","1","","25","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Routing questions for collaborative answering in Community Question Answering","S. Chang; A. Pal","Dept. of Computer Science, University of Minnesota, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","494","501","Community Question Answering (CQA) service enables its users to exchange knowledge in the form of questions and answers. By allowing the users to contribute knowledge, CQA not only satisfies the question askers but also provides valuable references to other users with similar queries. Due to a large volume of questions, not all questions get fully answered. As a result, it can be useful to route a question to a potential answerer. In this paper, we present a question routing scheme which takes into account the answering, commenting and voting propensities of the users. Unlike prior work which focuses on routing a question to the most desirable expert, we focus on routing it to a group of users - who would be willing to collaborate and provide useful answers to that question. Through empirical evidence, we show that more answers and comments are desirable for improving the lasting value of a question-answer thread. As a result, our focus is on routing a question to a team of compatible users.We propose a recommendation model that takes into account the compatibility, topical expertise and availability of the users. Our experiments over a large real-world dataset shows the effectiveness of our approach over several baseline models.","","Electronic:978-1-4503-2240-9","10.1109/ASONAM.2013.6785750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785750","","Availability;Collaboration;Communities;Computational modeling;Java;Knowledge discovery;Routing","Internet;collaborative filtering;question answering (information retrieval)","CQA service;collaborative answering;collaborative effort;community question answering;compatibility;compatible users team;question routing scheme;question-answer thread;real-world dataset;topical expertise;user availability","","1","","19","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"The best answers? Think twice: Online detection of commercial campaigns in the CQA forums","C. Chen; K. Wu; V. Srinivasan; K. Bharadwaj R","Dept. of Computer Science, University of Victoria, BC, Canada","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","458","465","In an emerging trend, more and more Internet users search for information from Community Question and Answer (CQA) websites, as interactive communication in such websites provides users with a rare feeling of trust. More often than not, end users look for instant help when they browse the CQA websites for the best answers. Hence, it is imperative that they should be warned of any potential commercial campaigns hidden behind the answers. Existing research focuses more on the quality of answers and does not meet the above need. Textual similarities between questions and answers are widely used in previous research. However, this feature will no longer be effective when facing commercial paid posters. More context information, such as writing templates and a user's reputation track need to be combined together to form a new model to detect the potential campaign answers. In this paper, we develop a system that automatically analyzes the hidden patterns of commercial spam and raises alarms instantaneously to end users whenever a potential commercial campaign is detected. Our detection method integrates semantic analysis and posters' track records and utilizes the special features of CQA websites largely different from those in other types of forums such as microblogs or news reports. Our system is adaptive and accommodates new evidence uncovered by the detection algorithms over time. Validated with real-world trace data from a popular Chinese CQA website over a period of three months, our system shows great potential towards adaptive online detection of CQA spams.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785745","","","information resources;question answering (information retrieval);semantic Web;unsolicited e-mail","CQA;CQA forums;Community Question and Answer websites;Internet;commercial campaigns;commercial spam;interactive communication;microblogs;semantic analysis","","1","","20","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Biomedical text disambiguation using UMLS","W. G. El-Rab; O. R. Zaïane; M. El-Hajj","University of Alberta, Edmonton, Canada","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","943","947","Interest in extracting information from biomedical documents has increased significantly in recent years but has always been challenged by the ambiguity of natural language. An important source of ambiguity is the usage of polysemous words: words with multiple meanings. Word sense disambiguation algorithms attempt to solve this problem by finding the correct meaning of a polysemous word in a given context, but very few algorithms were designed to disambiguate biomedical text. In this study we propose a word sense disambiguation algorithm focused on biomedical text. The proposed algorithm does not need to be trained and uses a relatively small knowledge base.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2500251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785813","MetaMap;UMLS;Word Sense Disambiguation","Conferences;Social network services","Unified Modeling Language;bioinformatics;information retrieval;medical information systems;natural language processing;text analysis","UMLS;biomedical documents;biomedical text disambiguation;information extraction;natural language ambiguity;polysemous words;unified medical language system;word sense disambiguation algorithms","","0","","17","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Detection and confirmation of web robot requests for cleaning the voluminous web log data","T. H. Sardar; Z. Ansari","Dept. of Inf. Sci. & Eng., P.A. Coll. of Eng., Mangalore, India","2014 International Conference on the IMpact of E-Technology on US (IMPETUS)","20140320","2014","","","13","19","Web robots are software applications that run automated tasks over the internet. They traverse the hyperlink structure of the World Wide Web so that they can retrieve information. There are many reasons to distinguish web robot requests and user requests. Some tasks of web robots can be harmful to the web. Firstly, Web robots are employed for assemble business intelligence at e-commerce sites. In such a state of affairs, the e-commerce site may need to detect robots. Secondly, many e-commerce sites carry out Web traffic scrutiny to deduce the way their customers have accessed the site. Unfortunately, such scrutiny can be erroneous by the presence of Web robots. Thirdly, Web robots often consume considerable network bandwidth and server resources at the expense of other users. A web log file is a web server file automatically created and maintained by a web server to check the activity performed by it. It maintains a history of page requests on its site. In this paper we have used four methods together to detect and finally confirm requests as a robot request. Experiments have been performed on the log file generated from the server of an operational web site named vtulife.com which contains data of march-20l3. In our research results o.f web robot detection using various techniques have been compared and an integrated approach is proposed for the confirmation of the robot request.","","Electronic:978-93-329-0264-0; POD:978-1-4799-2603-9","10.1109/IMPETUS.2014.6775871","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775871","web log file;web robot detection;web usage mining","Browsers;IP networks;Robots;Search engines;Web servers;Web sites","Internet;competitive intelligence;electronic commerce;file servers;information retrieval;software agents;telecommunication traffic","Internet;Web log file;Web robot request confirmation;Web robot request detection;Web server file;Web traffic scrutiny;World Wide Web;business intelligence;e-commerce sites;hyperlink structure;information retrieval;voluminous Web log data cleaning;vtulife.com","","0","","21","","","10-11 Jan. 2014","","IEEE","IEEE Conference Publications"
"Detecting changes in content and posting time distributions in social media","K. Saito; K. Ohara; M. Kimura; H. Motoda","University of Shizuoka, 422-8526, Japan","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","572","578","We address a problem of detecting changes in information posted to social media taking both content and posting time distributions into account. To this end, we introduce a generative model consisting of two components, one for a content distribution and the other for a timing distribution, approximating the shape of the parameter change by a series of step functions. We then propose an efficient algorithm to detect change points by maximizing the likelihood of generating the observed sequence data, which has time complexity almost proportional to the length of observed sequence (possible change points). We experimentally evaluate the method on synthetic data streams and demonstrate the importance of considering both distributions to improve the accuracy. We, further, apply our method to real scoring stream data extracted from a Japanese word-of-mouth communication site for cosmetics and show that it can detect change points and the detected parameter change patterns are interpretable through an in-depth investigation of actual reviews.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785760","","Data models;Equations;Mathematical model;Media;Social network services;Timing;Vectors","computational complexity;content management;data analysis;information retrieval;social networking (online)","content distribution;generative model;observed sequence data generation;parameter change pattern detection;posting time distribution;social media;stream data extraction;synthetic data stream;time complexity;timing distribution","","0","","23","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Methodology to review chamber type equipment performance","Leong Pei Shan; Leong Kok Chee; Sharon Su","Syst. on Silicon Mfg Co. Pte.Ltd., Singapore, Singapore","2013 e-Manufacturing & Design Collaboration Symposium (eMDC)","20140306","2013","","","1","2","1. Background · In the general practice, we review the equipment performance; uptime, efficiency, and moves base on “main frame” tool level using CIM report system. · The main frame performance review methodology cannot distinguish the “real” uptime and efficiency performance for “chamber” base tool (Refer to Figure 1). We may overestimate the uptime performance and underestimate the efficiency performance because the chamber down and PM time were not reflected in the main frame statement (Refer to Figure 2). · Current report system only provides tool level information. When individual chambers in one main frame are running different process groups, the main tool performance review methodology/report becomes redundant. From capacity point view, we need to differentiate each individual process group performance and not the main tool performance as this data did not correctly reflect each individual process group performance · Due to the limitation of existing CIM report, we are unable to get the required chamber information. Current system only provide time log information of the “main frame” and equipment moves is only available at mainframe level which is determined by the number of lots tracked in. 2. Purpose · Derive a new methodology which can indicate the chamber base tools performance.. Create a new report system based on new methodology, so we can review the chamber tools performance precisely (Refer Figure 3). 3. Approach · Re-define the equipment performance KPI (Key Performance Index) based on the chamber level (Refer to Figure 4). · Re-define the process move based on chamber capability to measure the individual process group performance. Therefore corrective action plan can be executed effectively to optimize the chamber tools performance. · Retrieve the required data from CIM based on new definitions. · Revamp the repo- t system for all the chamber base tools (ex. Etch, CVD, PVD, RTA) 4. Achieved Results . By introducing the new chamber level report system (Refer to Figure 5), we are able to tackle the chamber base tool performance more clearly and even for those same main frame but running different process chamber's performance. · For example, our Fab has 18 Lam Poly Etch tools which have total 54 chambers to support 10 process groups. Before introducing the new methodology and report system, we had difficulty to measure each process group performance. After implemented the new chamber report system, we had derived the key improvement productivity for the critical chamber to support our business growing.","","Electronic:978-1-4799-4709-6; POD:978-1-4799-2412-7","10.1109/eMDC.2013.6756042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6756042","Chamber;Efficiency;Moves;Performance;Process Group;Uptime","Abstracts;Joints;Welding","computer integrated manufacturing;information retrieval","CIM report system;KPI;Lam Poly Etch tools;PM time;chamber base tool;chamber down time;chamber report system;equipment efficiency;equipment performance;equipment uptime;key performance index;main frame tool level;productivity improvement;time log information","","0","","","","","6-6 Sept. 2013","","IEEE","IEEE Conference Publications"
"Economic impact of software security activities in software development","G. Chehrazi","EC SPRIDE, Tech. Univ. Darmstadt, Darmstadt, Germany","2013 International Conference on Risks and Security of Internet and Systems (CRiSIS)","20140313","2013","","","1","4","The aim of this research is to enhance the knowledge about investments and treatment of IT Security issues and their financial impact on software projects taking into account the lifecycle of projects on one hand and to build up an infrastructure which allows to automatically retrieve IT Security related information and relate it with economic and success factors on the other hand. IT security relevant practical metrics whose measurement can be automatized to a high extend will be provided. A model will be designed and an infrastructure for automatic IT Security related data retrieval will be built with which economic consequences and effectivity of IT security activities can be measured based on selected development, product and environmental indicators.","2151-4763;21514763","Electronic:978-1-4799-3488-1; POD:978-1-4799-3489-8","10.1109/CRiSIS.2013.6766349","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6766349","empirical analysis;measurement;metrics;open source;software security","Area measurement;Monitoring;Reliability;Security;Software;Software measurement","information retrieval;project management;security of data;software cost estimation;software engineering","IT security activities;IT security issues;IT security related information retrieval;automatic IT security related data retrieval;economic analysis;economic impact;environmental indicators;financial impact;project lifecycle;software development;software projects;software security activities;usable metrics","","0","","17","","","23-25 Oct. 2013","","IEEE","IEEE Conference Publications"
"Extracting Dense Bipartite Graph Block in Web Community Discovery","N. Yang","Inf. Sch., Renmin Univ. of China, Beijing, China","2013 10th Web Information System and Application Conference","20140327","2013","","","159","166","Community is a very important structure in the Web. The discovery of these communities is a challenging task. In many researches, it is an effective way of exhaustively extracting dense sub graphs to find communities. The pioneer works in[1], [2] uses a CBG(Complete Bipartite Graph) as a signature of a community core and discovers many implicit communities. However, the CBG is too strict and it excludes many possible community structures. Therefore, instead of CBG, DBG(Dense Bipartite Graph) is chosen as a signature. For instance, Reddy et al. [3] proposed degree-based (a, ß)density, Gibson et al. [4] and Dourisboure et al. [5] use a ratio-based ?-dense function to qualify the density of a DBG. In this paper, we analyze two previous density measurements and point out that in low density the structure of bipartite graph may be unreasonable because of the existence of cutting nodes. For this reason, we introduce DBGB(Dense Bipartite Graph Block). Subsequently, we employ two-step expansion to construct bipartite graph which decreases the number of unnecessary nodes and edges. In order to get optimal bipartite structure, we propose max DBGB and design an extracting algorithm. The new method is tested under 4 datasets collected by a Web crawler and dense cores have been extracted. We check 200 random sampling cores and 89 percent of them make sense. Meanwhile, we apply Dourisboure's method on one of the datasets with different scale and the cores extracted contain many cutting nodes. Consequently, the experiment results show that our method is effective.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778629","dense bipartite graph;link analysis;web communities","Algorithm design and analysis;Bipartite graph;Communities;Density measurement;Educational institutions;Fans;Organizations","Internet;data mining;directed graphs;information retrieval;random processes;sampling methods;social networking (online)","Web community discovery;Web crawler;cutting nodes;dense bipartite graph block extraction;dense cores;density measurements;extracting algorithm;max DBGB;optimal bipartite structure;random sampling cores;two-step expansion","","0","","16","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Document analysis based automatic concept map generation for enterprises","E. L. Karannagoda; H. M. T. C. Herath; K. N. J. Fernando; M. W. I. D. Karunarathne; N. H. N. D. de Silva; A. S. Perera","Dept. of Comput. Sci. & Eng., Univ. of Moratuwa, Moratuwa, Sri Lanka","2013 International Conference on Advances in ICT for Emerging Regions (ICTer)","20140310","2013","","","154","159","Ever growing knowledge bases of enterprises present the demanding challenge of proper organization of information that would enable fast retrieval of related and intended information. Document repositories of enterprises consist of large collections of documents of varying size, format and writing styles. This diversified and unstructured nature of documents restrict the possibilities of developing uniform techniques for extracting important concepts and relationships for summarization, structured representation and fast retrieval. The documented textual content is used as the input for the construction of a concept map. Here a rule based approach is used to extract concepts and relationships among them. Sentence level breakdown enables these rules to identify those concepts and relationships. These rules are based on elements in a phase structure tree of a sentence. For improving accuracy and the relevance of the extracted concepts and relationships, the special features such as titles, bold and upper case texts are used. This paper discusses how to overcome the above mentioned challenges by utilizing high level natural language processing techniques, document pre-processing techniques and developing easily understandable and extractable compact representation of concept maps. Each document in the repository is converted to a concept map representation to capture concepts and relationships among concepts described in the said document. This organization would represent a summary of the document. These individual concept maps are utilized to generate concept maps that represent sections of the repository or the entire document repository. This paper discusses how statistical techniques are used to calculate certain metrics which are used to facilitate certain requirements of the solution. Principle component analysis is used in ranking the documents by importance. The concept map is visualized using force directed type graphs which represent concepts by nodes and r- lationships by edges.","","Electronic:978-1-4799-1276-6; POD:978-1-4799-1273-5","10.1109/ICTer.2013.6761171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6761171","Concept Map;Concepts/Relationships Extraction;Natural Language Processing","Data mining;Feature extraction;Java;Natural language processing;Optimization;Sun","document handling;graph theory;information retrieval;natural language processing;principal component analysis","automatic concept map generation;concept extraction;concept map construction;document analysis;document pre-processing techniques;document repositories;document summary;documented textual content;enterprises;fast information retrieval;force directed type graphs;graph edge;graph node;information organization;natural language processing techniques;phase structure tree;principle component analysis;rule based approach;sentence level breakdown;structured representation;summarization","","0","","14","","","11-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Improvement of an abstractive summarization evaluation tool using lexical-semantic relations and weighted syntax tags in Farsi language","A. Estiri; M. Kahani; H. Ghaemi; M. Abasi","Web Technol. Lab., Ferdowsi Univ. of Mashhad, Mashhad, Iran","2014 Iranian Conference on Intelligent Systems (ICIS)","20140421","2014","","","1","6","In recent years, high increase in the amount of published web elements and the need to store, classify, restore, and process them have intensified the importance of natural language processing and its related tools such as automatic summarizers and machine translators. In this paper, a novel approach for evaluating automatic abstractive summarization system is proposed which can also be used in the other Natural Language Processing and Information Retrieval Applications. By comparing auto-abstracts (abstracts created by machine) with human abstracts (ideal abstracts created by human), the metrics introduced in the proposed tool can automatically measure the quality of auto-abstracts. Evidently, we can't semantically compare texts of abstractive summaries by comparison of just their words' appearance. So it is necessary to use a lexical database such as WordNet. We use FerdowsNet with a proper idea for Farsi language and it notably improves the evaluation results. This tool has been assessed by linguistic experts. This tool contains metric for determining the quality of summaries automatically by comparing them with summaries generated by humans (Ideal summaries). Evidently, we can't semantically compare texts of abstractive summaries by comparison of just their words' appearance and it is necessary to use a lexical database. We use this database with a proper idea together with Farsi parser in order to identify groups forming sentences and the results of evaluation improve significantly.","","Electronic:978-1-4799-3351-8; POD:978-1-4799-3352-5","10.1109/IranianCIS.2014.6802594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802594","Automatic Abstractive Summarizer;Evaluation;Farsi Natural Language Processing (NLP);Parse tree;Semantics;Sentences groups;parser","Abstracts;Databases;Equations;Measurement;Natural language processing;Semantics;Standards","database management systems;information retrieval;language translation;natural language processing","Farsi language;Web elements;WordNet;abstractive summaries;abstractive summarization evaluation tool;automatic abstractive summarization system;human abstracts;information retrieval applications;lexical database;lexical semantic relations;linguistic experts;machine translators;natural language processing;weighted syntax tags","","1","","24","","","4-6 Feb. 2014","","IEEE","IEEE Conference Publications"
"Combining information extraction and text mining for cancer biomarker detection","K. Dawoud; S. Gao; A. Qabaja; P. Karampelas; R. Alhajj","Dept. of Computer Science, University of Calgary, Alberta, Canada","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","948","955","Information technology is advancing faster than anticipated. The amount of data captured and stored in electronic form by far exceeds the capabilities available for comprehensive analysis and effective knowledge discovery. There is always a need for new sophisticated techniques that could extract more of the knowledge hidden in the raw data collected continuously in huge repositories. Biomedicine and computational biology is one of the domains overwhelmed with huge amounts of data that should be carefully analyzed for valuable knowledge that may help uncovering many of the still unknown information related to various diseases threatening the human body. Biomarker detection is one of the areas which have received considerable attention in the research community. There are two sources of data that could be analyzed for biomarker detection, namely gene expression data and the rich literature related to the domain. Our research group has reported achievements analyzing both domains. In this paper, we concentrate on the latter domain by describing a powerful tool which is capable of extracting from the content of a repository (like PubMed) the parts related to a given specific domain like cancer, analyze the retrieved text to extract the key terms with high frequency, present the extracted terms to domain experts for selecting those most relevant to the investigated domain, retrieve from the analyzed text molecules related to the domain by considering the relevant terms, derive the network which will be analyzed to identify potential biomarkers. For the work described in this paper, we considered PubMed and extracted abstracts related to prostate and breast cancer. The reported results are promising; they demonstrate the effectiveness and applicability of the proposed approach.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2500281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785814","cancer biomarkers;information extraction;knowledge discovery;network analysis;text analysis;text mining","Abstracts;Buildings;Data mining;Diseases;Prostate cancer;Proteins","biology computing;cancer;data mining;genetics;information retrieval;medical expert systems;medicine;molecular biophysics;storage management;text analysis","PubMed;biomedicine;breast cancer;cancer biomarker detection;comprehensive analysis;computational biology;data capture;data storage;domain experts;gene expression data;information extraction;information technology;knowledge discovery;knowledge extraction;prostate cancer;retrieved text analysis;text mining;text molecules","","0","","32","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"The Design and Implementation of the Unified Framework of the Device Insertion and Adaptation","Z. Wenfeng; Z. Shuai; Z. Yang","Beijing Univ. of Posts & Telecommun., Beijing, China","2014 Sixth International Conference on Measuring Technology and Mechatronics Automation","20140421","2014","","","676","680","Nowadays, the Internet of Things is more widely used than ever before. It is a tendency to get and analyze the data retrieved from the sensor device. Considering that the sensor device is always large, heterogeneous, and have a limited capacity, it is necessary to develop a middleware platform to do these jobs. In this paper, we design and implement a middleware system based on the OSGI, which can supports modular protocol developing and dynamically plug in and out. Our paper mainly contains 3 parts. First, we will have a brief introduction about the background and requirement of the system. Then we will introduce the design and implementation of our system in detail. Finally, we will validate and test our system in real situation.","2157-1473;21571473","CD-ROM:978-1-4799-3434-8; Electronic:978-1-4799-3435-5; POD:978-1-4799-3436-2","10.1109/ICMTMA.2014.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802784","Dynamically Plug in and out;Internet of Things;Middleware;Modular Programming","Computer architecture;Message systems;Protocols;Resource management;Web services","Internet of Things;computerised instrumentation;information retrieval;middleware;sensors","Internet of Things;data anlysis;device adaptation;device insertion;middleware platform;middleware system;modular protocol;sensor device;unified framework","","0","","11","","","10-11 Jan. 2014","","IEEE","IEEE Conference Publications"
"An approach to automatic text summarization using WordNet","A. R. Pal; D. Saha","Dept. of Comput. Sci. & Eng., Coll. of Eng. & Manage., Kolaghat, India","2014 IEEE International Advance Computing Conference (IACC)","20140327","2014","","","1169","1173","Text Summarization is the procedure by which the significant portions of a text are retrieved. Most of the approaches perform the summarization based on some hand tagged rules, such as format of the writing of a sentence, position of a sentence in the text, frequency of few particular words in a sentence etc. But according to different input sources, these pre-defined constraints greatly affect the result. The proposed approach performs the summarization task by unsupervised learning methodology. The importance of a sentence in an input text is evaluated by the help of Simplified Lesk algorithm. As an online semantic dictionary WordNet is used. First, this approach evaluates the weights of all the sentences of a text separately using the Simplified Lesk algorithm and arranges them in decreasing order according to their weights. Next, according to the given percentage of summarization, a particular number of sentences are selected from that ordered list. The proposed approach gives best results upto 50% summarization of the original text and gives satisfactory result even upto 25% summarization of the original text.","","CD-ROM:978-1-4799-2571-1; Electronic:978-1-4799-2572-8; POD:978-1-4799-2573-5","10.1109/IAdCC.2014.6779492","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6779492","Abstract;Automatic Text Summarization;Extract;Lesk algorithm;WordNet","Abstracts;Conferences;Data mining;Dictionaries;Presses;Semantics","database management systems;information retrieval;text analysis;unsupervised learning","automatic text summarization;hand tagged rules;online semantic dictionary WordNet;simplified lesk algorithm;text retrieval;unsupervised learning methodology","","2","","30","","","21-22 Feb. 2014","","IEEE","IEEE Conference Publications"
"Personalized web search using browsing history and domain knowledge","R. Kumar; A. Sharan","Sch. of Comput. & Syst. Sci., Jawaharlal Nehru Univ., New Delhi, India","2014 International Conference on Issues and Challenges in Intelligent Computing Techniques (ICICT)","20140403","2014","","","493","497","Generic search engines are important for retrieving relevant information from web. However these engines follow the “one size fits all” model which is not adaptable to individual users. Personalized web search is an important field for tuning the traditional IR system for focused information retrieval. This paper is an attempt to improve personalized web search. User's Profile provides an important input for performing personalized web search. This paper proposes a framework for constructing an Enhanced User Profile by using user's browsing history and enriching it using domain knowledge. This Enhanced User Profile can be used for improving the performance of personalized web search. In this paper we have used the Enhanced User Profile specifically for suggesting relevant pages to the user. The experimental results show that the suggestions provided to the user using Enhanced User Profile are better than those obtained by using a User Profile.","","DVD:978-1-4799-2899-6; Electronic:978-1-4799-2900-9; POD:978-1-4799-2901-6","10.1109/ICICICT.2014.6781332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6781332","Domain Knowledge;Enhanced User Profile;Personalized Web Search;User Modeling","Analytical models;Business;Engines;Games;Meteorology;Robustness;Web search","Internet;information retrieval;search engines","IR system;browsing history;domain knowledge;enhanced user profile;generic search engines;information retrieval;one size fits all model;personalized Web search","","3","","6","","","7-8 Feb. 2014","","IEEE","IEEE Conference Publications"
"Social ranking techniques for the web","T. H. Nguyen; B. K. Szymanski","Rensselaer Polytechnic Institute, 110 8th St, Troy, NY 12180, USA","2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)","20140410","2013","","","49","55","The proliferation of social media has the potential for changing the structure and organization of the web. In the past, scientists have looked at the web as a large connected component to understand how the topology of hyperlinks correlates with the quality of information contained in the page and they proposed techniques to rank information contained in web pages. We argue that information from web pages and network data on social relationships can be combined to create a personalized and socially connected web. In this paper, we look at the web as a composition of two networks, one consisting of information in web pages and the other of personal data shared on social media web sites. Together, they allow us to analyze how social media tunnels the flow of information from person to person and how to use the structure of the social network to rank, deliver, and organize information specifically for each individual user. We validate our social ranking concepts through a ranking experiment conducted on web pages that users shared on Google Buzz and Twitter.","","Electronic:978-1-4503-2240-9","10.1145/2492517.2492604","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785686","","Facsimile;Google;Media;Topology;Twitter","graph theory;information retrieval;social networking (online)","Google Buzz;Twitter;Web organization;Web pages;Web structure;hyperlinks topology;information delivery;information organization;information quality;information ranking;personalized Web;social media;social ranking techniques;social relationships;socially connected Web","","1","","18","","","25-28 Aug. 2013","","IEEE","IEEE Conference Publications"
"Personalized Geo-Specific Tag Recommendation for Photos on Social Websites","J. Liu; Z. Li; J. Tang; Y. Jiang; H. Lu","Nat. Lab. of Pattern Recognition, Inst. of Autom., Beijing, China","IEEE Transactions on Multimedia","20140313","2014","16","3","588","600","Social tagging becomes increasingly important to organize and search large-scale community-contributed photos on social websites. To facilitate generating high-quality social tags, tag recommendation by automatically assigning relevant tags to photos draws particular research interest. In this paper, we focus on the personalized tag recommendation task and try to identify user-preferred, geo-location-specific as well as semantically relevant tags for a photo by leveraging rich contexts of the freely available community-contributed photos. For users and geo-locations, we assume they have different preferred tags assigned to a photo, and propose a subspace learning method to individually uncover the both types of preferences. The goal of our work is to learn a unified subspace shared by the visual and textual domains to make visual features and textual information of photos comparable. Considering the visual feature is a lower level representation on semantics than the textual information, we adopt a progressive learning strategy by additionally introducing an intermediate subspace for the visual domain, and expect it to have consistent local structure with the textual space. Accordingly, the unified subspace is mapped from the intermediate subspace and the textual space respectively. We formulate the above learning problems into a united form, and present an iterative optimization with its convergence proof. Given an untagged photo with its geo-location to a user, the user-preferred and the geo-location-specific tags are found by the nearest neighbor search in the corresponding unified spaces. Then we combine the obtained tags and the visual appearance of the photo to discover the semantically and visually related photos, among which the most frequent tags are used as the recommended tags. Experiments on a large-scale data set collected from Flickr verify the effectivity of the proposed solution.","1520-9210;15209210","","10.1109/TMM.2014.2302732","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6725686","Geo-location preference;personalized tag recommendation;subspace learning;tagging history;user preference","Context;History;Linear programming;Optimization;Semantics;Tagging;Visualization","classification;convergence of numerical methods;information retrieval;iterative methods;learning (artificial intelligence);optimisation;recommender systems;social networking (online)","Flickr;convergence proof;geo-location-specific identification;high-quality social tag generation;iterative optimization;large-scale community-contributed photo organization;large-scale community-contributed photo searching;large-scale data set;nearest neighbor search;personalized geo-specific tag recommendation;personalized tag recommendation task;progressive learning strategy;research interest;social Web sites;social tagging;subspace learning method;textual information;visual features","","10","","42","","20140127","April 2014","","IEEE","IEEE Journals & Magazines"
