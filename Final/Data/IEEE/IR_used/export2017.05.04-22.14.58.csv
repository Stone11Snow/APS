"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7288403,7287025,7288426,7282280,7282737,7281807,7284190,7282358,7281093,7282364,7282294,7284220,7280395,7282574,7279928,7282724,7275820,7275645,7275980,7275894,7275575,7275610,7275388,7276780,7275720,7275698,7273442,7273699,7273157,7273289,7266529,7273053,7270733,7272630,7271507,7272590,7272642,7266945,7266849,7265326,7266688,7266656,7270249,7264307,7263779,7263579,7248487,7250399,7251967,7248483,7248485,7250218,7249177,7106535,7238452,7238456,7238549,7238338,7238319,7181436,6902795,7238375,7243222,7230512,7230946,7231763,7237206,7231439,7230735,7227060,7229758,7229741,7219851,7224907,7226689,7219916,7226727,7226043,7224874,7224806,7220019,7218542,7218426,7217963,7217011,7216959,7218539,7218041,7207413,7207254,7207263,7208196,7214069,7210335,7207300,7210332,7207297,7207302,7203065,7195560",2017/05/04 22:14:58
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A combined approach for the extraction of the multi-word and nested biomedical entity","L. Gong; R. Yang; J. Feng; G. Yang","School of Computer Science & Technology, School of Software, Nanjing University of Posts and Telecommunications, China","2015 IEEE International Conference on Digital Signal Processing (DSP)","20150910","2015","","","708","711","Name entity recognition is the fundamental task in text mining area. This work focuses on the problems of multi-word and nested entity names. A combined approach is proposed for identifying multi-word and nested bio-entity names, which achieve an F-measure of 80.8% in extracting the total of bio-entity names and an F-measure of 82.2% aiming at nested entities. Experimental results show the combined approach is promising for developing text mining technology.","1546-1874;15461874","Electronic:978-1-4799-8058-1; POD:978-1-4799-8059-8; USB:978-1-4799-8057-4","10.1109/ICDSP.2015.7251967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7251967","VSSWA;bioinformatics;name entity recognition;text mining","Dictionaries;Protein engineering;Proteins;Tagging;Telecommunications;Text mining","bioinformatics;data mining;information retrieval;text analysis","F-measure;bioinformatics;multiword bioentity name identification;multiword biomedical entity extraction;name entity recognition;nested bioentity name identification;nested biomedical entity extraction;text mining technology","","0","","13","","","21-24 July 2015","","IEEE","IEEE Conference Publications"
"Efficient Answering of Why-Not Questions in Similar Graph Matching","M. S. Islam; C. Liu; J. Li","Swinburne University of Technology, Melbourne, Australia","IEEE Transactions on Knowledge and Data Engineering","20150909","2015","27","10","2672","2686","Answering why-not questions in databases is promised to have wide application prospect in many areas and thereby, has attracted recent attention in the database research community. This paper addresses the problem of answering these so-called why-not questions in similar graph matching for graph databases. Given a set of answer graphs of an initial query graph q and a set of missing (why-not) graphs, we aim to modify q into a new query graph q* such that the missing graphs are included in the new answer set of q*. We present an approximate solution to address the above as the optimal solution is NP-hard to compute. In our approach, we first compute the bounded search space and the distance to be minimized for q*. Then, we present a two-phase algorithm to find the new query q*. In the first phase, we generate a set of candidate edges to be added/deleted into/from the initial query q within the bounded search space and in the second phase, we select a subset of candidate edges generated in the first phase to minimize the distance for q*. We also demonstrate the effectiveness and efficiency of our approach by conducting extensive experiments on two real datasets.","1041-4347;10414347","","10.1109/TKDE.2015.2432798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106535","Graph Distance;Graph distance;Similar Graph Matching;Why-not Questions and Graph Query Refinement;similar graph matching;why-not questions and graph query refinement","Approximation algorithms;Chemical compounds;Cloning;Databases;Drugs;NP-hard problem;Search problems","computational complexity;graph theory;query processing;question answering (information retrieval);search problems","NP-hard problem;bounded search space;database research;graph database;missing graphs;query graph;similar graph matching;two-phase algorithm;why-not question answering","","4","","34","","20150513","Oct. 1 2015","","IEEE","IEEE Journals & Magazines"
"Personalized Event Recommendations Using Social Networks","I. Boutsis; S. Karanikolaou; V. Kalogeraki","Dept. of Inf., Athens Univ. of Econ. & Bus., Athens, Greece","2015 16th IEEE International Conference on Mobile Data Management","20150914","2015","1","","84","93","In recent years we have observed a significant increase in the popularity of location-based social networks for exchanging news and experiences, sharing location information, or publishing real world events. One important challenge in such networks is to understand human crowd mobility behavior based on user social activities and interactions. In this paper we introduce PRESENT, our middleware that utilizes a Mixed Markov Model to extract the behavioral patterns of the users in social groups, to make personalized event recommendations. Our detailed experimental evaluation, using data from the Meet up location-based social network, illustrates that our approach is efficient, practical and achieves an average prediction for the user attendance of over 73%.","1551-6245;15516245","Electronic:978-1-4799-9972-9; POD:978-1-4799-9973-6","10.1109/MDM.2015.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7264307","Event Recommendations;Social Networks","Business;Hidden Markov models;Markov processes;Middleware;Motion pictures;Predictive models;Social network services","Markov processes;behavioural sciences computing;electronic publishing;information retrieval;recommender systems;social networking (online)","PRESENT;behavioral pattern extraction;experiences exchange;human crowd mobility behavior;location information sharing;location-based social networks;middleware;mixed Markov model;news exchange;personalized event recommendations;real world event publishing;user attendance;user social activities;user social interactions","","1","","35","","","15-18 June 2015","","IEEE","IEEE Conference Publications"
"Efficient analysis of pharmaceutical compound structure based on pattern matching algorithm in data mining techniques","V. Palanisamy; A. Kumarkombaiya","Department of Computer Science and Engineering, Alagappa University, India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","5","The proposed methodology involved to finding the chain details of pharmaceutical compound by retrieving the data in numeric format which is taken from functional group. The data mining technique of Enhanced Knuth-Morris-Pratt algorithm used to readily implement to identify the pattern of chemical compounds as in string data based on functional groups connected to one another which is similar from the numeric data.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238456","Boyer Moore algorithm;Enhanced Knuth-Morris-Pratt algorithm;Knuth-Morris-Pratt algorithm;Pharamaceutical Compounds","Algorithm design and analysis;Clustering algorithms;Compounds;Data mining;Lead;Pattern matching;Pharmaceuticals","data mining;information retrieval;medical computing;string matching","Knuth-Morris-Pratt algorithm enhancement;chemical compounds;data mining techniques;functional group;numeric format;pattern matching algorithm;pharmaceutical compound structure;string data","","0","","10","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Traffic condition monitoring using weighted kernel density for intelligent transportation","C. C. Lee; W. C. Lee; H. Cai; H. R. Chi; C. K. Wu; J. Haase; M. Gidlund; B. Li","School of Science and Technology, The Open University of Hong Kong","2015 IEEE 13th International Conference on Industrial Informatics (INDIN)","20151001","2015","","","624","627","Smart transportation is an application of intelligent system on transportation domain, expected to bring the society environmental and economic advantages. By combining with IoT techniques, the concept is being enhanced and raised to a system level. Numerous data are able to collect and effective analysis technique is needed. Here in this paper, we proposed a framework of employing IoT technique to construct a free time navigation system. The system aims at providing a real-time quantification of traffic conditions and suggests optimal route based on the information retrieved. The system can be basically separated into two major components: (i) the traffic condition estimation module and the (ii) real-time routing algorithm. In the first component, traffic conditions of roads will be estimated based the information collected from sensors installed on vehicles. Based on these location and speed information, the traffic condition can be quantified using a weighted kernel density estimation (WKDE) function. This function is a function of time and provides a real time insight of the overall traffic condition. By combining this information and the topological structure of the road network, a more accurate time consumption on each road can be estimated and hence enable a better routing.","1935-4576;19354576","Electronic:978-1-4799-6649-3; POD:978-1-4799-6650-9; USB:978-1-4799-6648-6","10.1109/INDIN.2015.7281807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281807","","Estimation;Internet;Kernel;Navigation;Real-time systems;Vehicles","Internet of Things;information retrieval;intelligent transportation systems;road traffic","Internet of Things;IoT techniques;WKDE function;information retrieval;intelligent transportation;location information;realtime routing algorithm;smart transportation;speed information;traffic condition estimation module;traffic condition monitoring;traffic condition quantification;weighted kernel density estimation","","","","23","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Modeling randomized data streams in caching, data processing, and crawling applications","S. T. Ahmed; D. Loguinov","Texas A&M University, College Station, TX 77843, USA","2015 IEEE Conference on Computer Communications (INFOCOM)","20150824","2015","","","1625","1633","Many BigData applications (e.g., MapReduce, web caching, search in large graphs) process streams of random key-value records that follow highly skewed frequency distributions. In this work, we first develop stochastic models for the probability to encounter unique keys during exploration of such streams and their growth rate over time. We then apply these models to the analysis of LRU caching, MapReduce overhead, and various crawl properties (e.g., node-degree bias, frontier size) in random graphs.","0743-166X;0743166X","Electronic:978-1-4799-8381-0; POD:978-1-4799-8382-7","10.1109/INFOCOM.2015.7218542","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7218542","","Analytical models;Computational modeling;Computers;Conferences;Random variables;Stochastic processes;Yttrium","Big Data;cache storage;information retrieval;parallel processing;stochastic processes","Big Data applications;LRU caching;MapReduce overhead;caching application;crawl properties;crawling application;data processing;frequency distribution;probability;random graphs;randomized data streams;stochastic model","","1","","21","","","April 26 2015-May 1 2015","","IEEE","IEEE Conference Publications"
"Efficient botnet detection based on reputation model and content auditing in P2P networks","K. Kalaivani; C. Suguna","Computer Science and Engineering, V.S.B Engineering College, Karur, India","2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO)","20151001","2015","","","1","4","Botnet is a number of computers connected through internet that can send malicious content such as spam and virus to other computers without the knowledge of the owners. In peer-to-peer (p2p) architecture, it is very difficult to identify the botnets because it does not have any centralized control. In this paper, we are going to use a security principle called data provenance integrity. It can verify the origin of the data. For this, the certificate of the peers can be exchanged. A reputation based trust model is used for identifying the authenticated peer during file transmission. Here the reputation value of each peer can be calculated and a hash table is used for efficient file searching. The proposed system can also verify the trustworthiness of transmitted data by using content auditing. In this, the data can be checked against trained data set and can identify the malicious content.","","Electronic:978-1-4799-6480-2; POD:978-1-4799-6481-9","10.1109/ISCO.2015.7282358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282358","Data provenance integrity;content auditing;reputation value;trained data set","Computational modeling;Cryptography;Measurement;Peer-to-peer computing;Privacy;Superluminescent diodes","authorisation;computer network security;data integrity;information retrieval;invasive software;peer-to-peer computing;trusted computing","P2P networks;authenticated peer;botnet detection;content auditing;data provenance integrity;file searching;file transmission;hash table;malicious content;peer-to-peer architecture;reputation based trust model;reputation model;reputation value;security principle;spam;transmitted data trustworthiness;virus","","","","13","","","9-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Extracting unknown words from Sina Weibo via data clustering","K. Lei; W. Zhang; K. Zhang; K. Xu","Institute of Big Data Technologies, Shenzhen Key Lab for Cloud Computing Technology & Applications, School of Electronics and Computer Engineering(SECE), Peking University, China","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","1182","1187","Sina Weibo, a Twitter-like microblogging site attracting over 240 million monthly active users to tweet, retweet, and comment, has rapidly become one of the most popular social media sites in China. As many users create new and innovative words on their tweets and comments, it is necessary to extract these emerging words, which do not exist in today's Chinese vocabulary or dictionary. Towards this end, this paper proposes a novel method based on data clustering of Weibo users and tweets for extracting unknown words from Weibo tweets and comments. Specifically, relying on the similarity of the users who post the tweets, we apply a hierarchical clustering to divide Weibo data into distinct groups, e.g., sports, news stories, movies, before extraction. Comparing with the method of unclustered Weibo data, our experimental results have successfully demonstrated the benefits of the proposed data clustering scheme for improving the recall and accuracy of extracting unknown Chinese words from tweets and comments.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7248483","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248483","","Clustering algorithms;Clustering methods;Context;Couplings;Data mining;Entropy;Social network services","information retrieval;natural language processing;pattern clustering;social networking (online)","Chinese vocabulary;Chinese words;Sina Weibo;Twitter-like microblogging site;data clustering scheme;unknown word extraction","","1","","19","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"AGRI-QAS question-answering system for agriculture domain","S. Gaikwad; R. Asodekar; S. Gadia; V. Z. Attar","Department of Computer Engineering, College Of Engineering, Pune, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1474","1478","In this paper, we focus on the need for a robust domain specific question answering system targeting agriculture domain. It aims to help farmers get information and resolve their queries related to agriculture and thereby improving agriculture literacy. The system is based on the principles of natural language processing and information retrieval. Most of the currently available information retrieval tools return ranked list of documents instead of precise answers and do not support runtime answer retrieval. Thus we focus on developing a system which processes unstructured data and returns actual answer for FACTOID questions such as `which', `what', `who', `where'. For example, “which diseases affect the wheat crop?”, “what are the prevalent diseases in North-America region?” etc.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275820","","Accuracy;Agriculture;Computers;Diseases;Knowledge discovery;Tagging;XML","agriculture;natural language processing;question answering (information retrieval)","AGRI-QAS question-answering system;FACTOID question;agriculture domain;agriculture literacy;domain specific question answering system;information retrieval;natural language processing;runtime answer retrieval","","","","13","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Integrity checking Over Encrypted Cloud Data","Mithuna R.; Suguna M.","Department of CSE, Kumaraguru College of Technology, Coimbatore, India","2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN)","20150827","2015","","","1","5","Cloud providers provide various promising services to users and this makes the cloud to be very popular among users. Cloud computing is a location independent computing wherein files are outsourced as a service. Users outsource their data to the third party cloud server to reduce various costs such as storage, management etc. The outsourced data may have sensitive and valuable information that needs to be secured. In order to assure confidentiality, users encrypt their data before outsourcing it to the cloud server. But the searching and retrieval of encrypted files becomes too complex. The existing works on searchable encryption focus on Single keyword search, Multi-keyword search, Boolean keyword search and rarely vary the search results. In Multi-Keyword Ranked Search Over Encrypted Cloud Data (MRSE), ranked searchable symmetric encryption scheme is used for efficient retrieval of similar data from the cloud server based on the ranking. Even though the ranking scheme provides most similar files from the cloud server, one cannot assure whether the retrieved files are having same fields are not. In this paper for the first time, ranking fixed by the cloud server is being tested to check the correctness of its order. Rank test method is used to check the integrity of the rank order over the search results. Since the rank fixed by cloud server is checked, the user can get accurate results and so privacy can be improved.","","CD-ROM:978-1-4673-6822-3; Electronic:978-1-4673-6823-0; POD:978-1-4673-6824-7","10.1109/ICSCN.2015.7219916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219916","cloud computing;encrypted file;integrity;privacy preserving;ranked results","Encryption;Legged locomotion;Outsourcing;Privacy;Servers","cloud computing;cryptography;data integrity;data privacy;information retrieval;outsourcing","Boolean keyword search;MRSE;cloud computing;cloud provider;data confidentiality;encrypted file;integrity checking;location independent computing;multikeyword ranked search over encrypted cloud data;multikeyword search;outsourced data;outsourcing;rank test method;ranked searchable symmetric encryption scheme;ranking scheme;retrieved file;searchable encryption focus;single keyword search;third party cloud server","","0","","18","","","26-28 March 2015","","IEEE","IEEE Conference Publications"
"Application of Sparse Database in Multimedia Management and Retrieval","L. Chao; W. Lingda","Acad. of Equip., Beijing, China","2014 International Conference on Virtual Reality and Visualization","20151001","2014","","","361","366","Multimedia retrieval demands better efficience and accuracy to satisfy increasing extensive application. Since multimedia is enormous with various elements and complex features, it will waste storage to manage it with traditional RDBMS. Combined with researches on sparse database, this research explores how to use sparse database to manage multimedia and perform characteristic-based retrieval on it. It mainly works on methods of decreasing the storage cost while ensuring retrieval efficiency.","","Electronic:978-1-4799-6854-1; POD:978-1-4799-6855-8","10.1109/ICVRV.2014.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281093","Characteristic-based;Multimedia retrieval;Relationship table;Sparse database","Data mining;Feature extraction;Multimedia communication;Multimedia databases;Semantics;Visualization","information retrieval;multimedia computing;relational databases;storage management","RDBMS;characteristic-based retrieval;multimedia management;multimedia retrieval;sparse database;storage cost","","","","9","","","30-31 Aug. 2014","","IEEE","IEEE Conference Publications"
"Textual Analysis for Code Smell Detection","F. Palomba","Dept. of Manage. & Inf. Technol., Univ. of Salerno, Fisciano, Italy","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","20150817","2015","2","","769","771","The negative impact of smells on the quality of a software systems has been empirical investigated in several studies. This has recalled the need to have approaches for the identification and the removal of smells. While approaches to remove smells have investigated the use of both structural and conceptual information extracted from source code, approaches to identify smells are based on structural information only. In this paper, we bridge the gap analyzing to what extent conceptual information, extracted using textual analysis techniques, can be used to identify smells in source code. The proposed textual-based approach for detecting smells in source code, coined as TACO (Textual Analysis for Code smell detectiOn), has been instantiated for detecting the Long Method smell and has been evaluated on three Java open source projects. The results indicate that TACO is able to detect between 50% and 77% of the smell instances with a precision ranging between 63% and 67%. In addition, the results show that TACO identifies smells that are not identified by approaches based on solely structural information.","0270-5257;02705257","Electronic:978-1-4799-1934-5; POD:978-1-4799-1935-2","10.1109/ICSE.2015.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203065","","Accuracy;Conferences;Data mining;Societies;Software engineering;Software systems","Java;information retrieval","Java open source projects;TACO;long method smell;software systems;structural information;textual analysis for code smell detection;textual analysis techniques","","2","","32","","","16-24 May 2015","","IEEE","IEEE Conference Publications"
"Optimized Storage and Fast Retrieval of Large Monitoring Datasets without Compromising Granularity","S. Cabaniols; N. Viollet; C. Poulain","HPCCF, EMEA Ind. Stand. Servers Competency Center, Grenoble, France","2015 IEEE International Conference on Autonomic Computing","20150917","2015","","","135","136","The adoption of low power, small footprint systems such as Hewlett Packard Moons hot cartridge servers massively increases the number of servers in cloud/farms implementations. Understanding problems, bottlenecks, and scaling of distributed applications running on such clusters requires the ability to replay the exhaustive data collected by monitoring systems. Current monitoring solutions make compromises, simplify (i.e. Destroy) the data over time or do not scale. Moreover, in the cloud model, server roles and assignments often change, making it mandatory to correlate monitoring data with higher level information such as task assignments known by scheduling software. We present an optimized and fast process to store and retrieve monitoring data, allowing access to all samples collected without any granularity loss and, at the same time, a generic mechanism to correlate with information from orchestrators.","","Electronic:978-1-4673-6971-8; POD:978-1-4673-6972-5","10.1109/ICAC.2015.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266945","compute farm monitoring data compression for disk streaming job playback","Conferences","cloud computing;information retrieval;storage management","Hewlett Packard Moons;cloud model;fast dataset retrieval;monitoring dataset;optimized storage;scheduling software;server assignments;server roles;task assignment","","","","3","","","7-10 July 2015","","IEEE","IEEE Conference Publications"
"Private Browsing Mode Not Really That Private: Dealing with Privacy Breach Caused by Browser Extensions","B. Zhao; P. Liu","Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA","2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks","20150917","2015","","","184","195","Private Browsing Mode (PBM) is widely supported by all major commodity web browsers. However, browser extensions can greatly undermine PBM. In this paper, we propose an approach to comprehensively identify and stop privacy breaches under PBM caused by browser extensions. Our approach is primarily based on run-time behavior tracking. We combine dynamic analysis and symbolic execution to represent extensions' behavior to identify privacy breaches in PBM caused by extensions. Our analysis shows that many extensions have not fulfilled PBM's guidelines on handling private browsing data. To the best of our knowledge, our approach also provides the first work to stop privacy breaches through instrumentation. We implemented a prototype SoPB on top of Firefox and evaluated it with 1,912 extensions. The results show that our approach can effectively identify and stop privacy breaches under PBM caused by extensions, with almost negligible performance impact.","1530-0889;15300889","Electronic:978-1-4799-8629-3; POD:978-1-4799-8630-9","10.1109/DSN.2015.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266849","Browser extensions;Dynamic analysis;Privacy breach;Private Browsing Mode","Browsers;Data privacy;Guidelines;History;Instruments;Privacy;Security","Internet;data privacy;information retrieval","Firefox;PBM;dynamic analysis;privacy breach;private browsing mode;run-time behavior tracking;symbolic execution","","","","33","","","22-25 June 2015","","IEEE","IEEE Conference Publications"
"Enabling central access to marine data: Data portal German marine research","R. Koppe; A. Schäfer","Alfred Wegener Institute, Helmholtz Centre for Polar and Marine Research, Bremerhaven, Germany","OCEANS 2015 - Genova","20150921","2015","","","1","5","Timely access to quality data and linkage of data beyond disciplinary boundaries is essential for the marine research community. Therefore the national “Marine Network for Integrated Data Access” is establishing the “Data Portal German Marine Research” to facilitate seamless access to marine data and services and to promote the exchange and dissemination of marine data interlinked with corresponding scientific publications. In that course the data portal was conceptualized and developed to provide a “one-stop-shop” approach to marine research data from various data providers in terms of coherent discovery, view, download and dissemination of scientific data and publications. The data portal is based on a central harvesting and interfacing approach by connecting distributed data sources. To achieve interoperability the data portal makes use of internationally endorsed standards (e.g., ISO, OGC, OAI-PMH). In this paper we provide information on details of content, functionality, services, architecture, interfaces and standards of the data portal and the network of contributing data providers.","","Electronic:978-1-4799-8736-8; POD:978-1-4799-8737-5","10.1109/OCEANS-Genova.2015.7271507","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271507","data access;data citation;data portal;data providers;data publication;data retrieval;data workflows;interfaces;portal architecture;standards;web services","Distributed databases;Feature extraction;ISO Standards;Metadata;Portals;XML","Web services;information retrieval;portals","Data Portal German Marine Research;data access;data retrieval;marine data","","","","44","","","18-21 May 2015","","IEEE","IEEE Conference Publications"
"Medical data Opinion retrieval on Twitter streaming data","V. Sindhura; Y. Sandeep","Department of Information Technology, V R Siddhartha Engineering College, Vijayawada, India","2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)","20150827","2015","","","1","6","Human generated enormous amount text can be analyzed to obtain useful information. A sparingly popular communication tool amongst Internet users today is Micro blogging. Opinions are shared by millions of public on different aspects of life. Analyzing the opinions that are extracted from various sources using computational techniques is referred as Opinion Mining. Opinion mining exemplifies the techniques and approaches that promise to precisely facilitate the opinion-oriented information seeking techniques that involved computational regimen of opinion or subjectivity in the text. The approach is to collect data from Twitter, a micro blogging social networking site and analyze various Opinion mining techniques. A little effort is made to review in detail about various approaches to perform a computational analysis of opinions. Various data-driven techniques for opinion mining as Feature based Opinion Mining Technique, Machine learning based Opinion Mining Technique and Ranking model with an opinionatedness feature are reviewed and their strengths and weakness are touched upon.","","Electronic:978-1-4799-6085-9; POD:978-1-4799-6086-6","10.1109/ICECCT.2015.7226043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226043","Feature based Opinion Mining Technique;Machine learning based Opinion Mining Technique;Opinion Mining;Ranking model with an opinionatedness feature","Blogs;Filtering algorithms;Protocols;Support vector machines","data mining;information retrieval;learning (artificial intelligence);medical administrative data processing;social networking (online)","Twitter streaming data;feature based opinion mining technique;machine learning based opinion mining technique;medical data opinion retrieval;microblogging social networking site;opinion-oriented information seeking techniques;ranking model with opinionatedness feature","","0","","16","","","5-7 March 2015","","IEEE","IEEE Conference Publications"
"Enterprise Search with Development for Network Management System","M. Wang; R. Grindrod; J. O'Meara; M. Zuzuarregui; E. Martinez; E. Fallon","Network Manage. Lab., Ericsson, Athlone, Ireland","2015 IEEE International Congress on Big Data","20150820","2015","","","430","437","Browsing and searching network information for observation, analysis and troubleshooting is an inherent part of using the features and functions of any Network Management System. Enterprise search has capabilities for handling various data types and sources and big data scalability, and is becoming an emerging technology for such network management functions development. In this paper, we give an overview on work done in our research and prototype team regarding an advanced search project. We provide a brief report on search fundamental knowledge and study of Solr search platform stack. It answers common questions from management and development teams regarding adopting search technology for production development, and gives a Solr reference card for developers. We also introduce two advanced search features, user experience based search recommendation and anomaly detection enhanced search ranking from our research work. Two features are developed to make network searches more efficient as it can help user quickly locate the most valuable search results, but the concept can be adopted for search applications in other domains.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207254","Anomaly detection;Big data analytics;Enterprise search;Network management;Search ranking;Search recommendation;Solr","Big data;Indexing;Navigation;Search engines;Software","data handling;feature extraction;information networks;information retrieval;recommender systems;search engines","Solr search platform stack;anomaly detection;data handling;enterprise search;network information browsing;network information searching;network management system;search feature;search ranking;user experience based search recommendation","","0","","13","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"ReMBF: A Reliable Multicast Brute-Force Co-allocation Scheme for Multi-user Data Grids","M. C. Lee; F. Y. Leu; Y. P. Chen","Dept. of Comput. Sci., Nat. Chiao Tung Univ., Hsinchu, Taiwan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","2","","774","783","In this paper we propose a novel co-allocation scheme, called a Reliable Multicast Brute-Force co-allocation scheme (ReMBF for short), which employs a reliable multicast (RM for short) technique with the Brute-Force (BF for short) scheme to accelerate data retrieval and delivery, and reliably transmit data to its users for data grids. Several types of data access patterns, including Zipf-like, geometric, and uniform distributions, are utilized to model user access behaviors and evaluate the performance of ReMBF. The simulation results demonstrate that ReMBF can efficiently deliver a bulk of data in a shorter time period compared with two state-of-the-art schemes.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273699","brute-force;co-allocation scheme;data grids;multi-user perspectives;reliable multicast","Bandwidth;Data communication;Distributed databases;Encoding;Reed-Solomon codes;Reliability;Resource management","data handling;grid computing;information retrieval","ReMBF;Zipf-like distributions;data access patterns;data delivery;data retrieval;geometric distributions;multiuser data grids;reliable multicast brute-force coallocation scheme;uniform distributions","","","","52","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"An Ontology-Driven Visual Question-Answering Framework","G. Besbes; H. Baazaoui-Zghal; H. B. Ghezela","Campus Univ. de la Manouba, Riadi Lab., ENSI, Manouba, Tunisia","2015 19th International Conference on Information Visualisation","20150921","2015","","","127","132","Question Answering systems aim at providing answers to natural language questions and provide a solution to the problem of response accuracy. This paper describes a visual QA framework based on ontolgoies, that relies on two main components: question analysis component and answer extraction component. Our goal consists on performing an efficient question answering by: (1) Improving the representation of the question's structure using question ontology and typed attributed graphs, (2) Improving the results of question reformulation using domain ontologies and lexicosyntactic patterns (3) Extracting answers based on the question graph, lexico-syntactic patterns and score computation and (4)Offering a visual representation of the graphs and ontologies. Our framework has been implemented and evaluated.","1550-6037;15506037","Electronic:978-1-4673-7568-9; POD:978-1-4673-7569-6","10.1109/iV.2015.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272590","ontology;question-answering;visualization","Data mining;Data visualization;Ontologies;Search engines;Semantics;Syntactics;Visualization","graph theory;natural language processing;ontologies (artificial intelligence);question answering (information retrieval)","answer extraction component;domain ontologies;lexico-syntactic patterns;natural language questions;ontology-driven visual question-answering framework;question analysis component;question ontology;typed attributed graphs;visual QA framework;visual representation","","1","","15","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Proof of Storage for Video Deduplication in the Cloud","F. Rashid; A. Miri; I. Woungang","Dept. of Comput. Sci., Ryerson Univ., Toronto, ON, Canada","2015 IEEE International Congress on Big Data","20150820","2015","","","499","505","With the advent of cloud computing and its technologies, including data deduplication, more freedom are offered to the users in terms of cloud storage, processing power and efficiency, and data accessibility. The digital data has attained unexceptional growth due to the common use of internet and digital devices giving rise to Big Data problem world wise. These huge volumes of data need some practical platforms for the storage, processing and availability and cloud technology offers all the potentials to fulfil these requirements. Data deduplication is referred to as a strategy offered to cloud storage providers (CSPs) to eliminate the duplicate data and keep only a single unique copy of it for storage space saving purpose to condense Big Data issues. But these benefits also come with data security and privacy issues associated with the cloud technology since the data owner looses the physical control of its data once uploaded in the cloud storage and the CSP gains a complete ownership of the data. In this paper, assuming that the CSP is semi-honest (i.e. Honest but curious and cannot be completely trusted), a proof of retrievability (POR) and a proof of ownership (POW) are proposed for video deduplication in cloud storage environments. The POW protocol is meant to be used by the CSP to authenticate the true owner of the data video before releasing it whereas the POR protocol is meant to allow the user to check that his/her data video stored in the cloud is secured against any malicious user or the semi-honest CSP. These schemes are proposed as complement to our earlier proposed scheme for securing the video deduplication in the cloud storage through the H.264 compression algorithm. Some experimental results are provided, showing the effectiveness of our proposed POR and POW protocols.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207263","Big Data;Cloud computing;H.264 compression algorithm;Merkle hash tree;error correcting codes;proof of ownership;proof of retrieval;video compression","Big data;Cloud computing;Compression algorithms;Encoding;Encryption;Protocols","cloud computing;data compression;data privacy;information retrieval;security of data;video coding","Big Data;CSP;H.264 compression algorithm;Internet;POR;POW;cloud computing;cloud storage providers;data accessibility;data privacy;data security;digital devices;proof of ownership;proof of retrievability;video deduplication","","0","","15","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Efficient Location Privacy for Moving Clients in Database-Driven Dynamic Spectrum Access","E. Troja; S. Bakiras","Grad. Center, City Univ. of New York, New York, NY, USA","2015 24th International Conference on Computer Communication and Networks (ICCCN)","20151005","2015","","","1","8","Dynamic spectrum access (DSA) is envisioned as a promising framework for addressing the spectrum shortage caused by the rapid growth of connected wireless devices. In contrast to the legacy fixed spectrum allocation policies, DSA allows license-exempt users to access the licensed spectrum bands when not in use by their respective owners. More specifically, in the database-driven DSA model, mobile users issue location-based queries to a white-space database, in order to identify idle channels in their area. To preserve location privacy, existing solutions suggest the use of private information retrieval (PIR) protocols when querying the database. Nevertheless, these methods are not communication efficient and fail to take into account user mobility. In this paper, we address these shortcomings and propose an efficient privacy-preserving protocol based on the Hilbert space filling curve. We provide optimizations for mobile users that require privacy on-the-fly and users that have full a priori knowledge of their trajectory. Through experimentation with two real life datasets, we show that, compared to the current state-of-the-art protocol, our methods reduce the query response time at the mobile clients by a large factor.","1095-2055;10952055","Electronic:978-1-4799-9964-4; POD:978-1-4799-9965-1; USB:978-1-4799-9963-7","10.1109/ICCCN.2015.7288403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288403","","Computer architecture;Databases;Microprocessors;Mobile communication;Privacy;Protocols;Trajectory","Hilbert spaces;information retrieval;mobility management (mobile radio);optimisation;protocols;radio spectrum management;wireless channels","Hilbert space filling curve;PIR protocol;database-driven DSA model;database-driven dynamic spectrum access;idle channel identification;legacy fixed spectrum allocation policy;location privacy;location privacy preservation;location-based query;mobile client;mobile user;privacy-preserving protocol;private information retrieval protocol;query response time reduction;white-space database;wireless device","","","","22","","","3-6 Aug. 2015","","IEEE","IEEE Conference Publications"
"Knowminer Search - A Multi-visualisation Collaborative Approach to Search Result Analysis","M. Rauch; W. Klieber; R. Wozelka; S. Singh; V. Sabol","Know-Center GmbH, Graz, Austria","2015 19th International Conference on Information Visualisation","20150921","2015","","","379","385","The amount of information available on the internet and within enterprises has reached an incredible dimension. Efficiently finding and understanding information and thereby saving resources remains one of the major challenges in our daily work. Powerful text analysis methods, a scalable faceted retrieval engine and a well-designed interactive user interface are required to address the problem. Besides providing means for drilling-down to the relevant piece of information, a part of the challenge arises from the need of analysing and visualising data to discover relationships and correlations, gain an overview of data distributions and unveil trends. Visual interfaces leverage the enormous bandwidth of the human visual system to support pattern discovery in large amounts of data. Our Know miner search builds upon the well-known faceted search approach which is extended with interactive visualisations allowing users to analyse different aspects of the result set. Additionally, our system provides functionality for organising interesting search results into portfolios, and also supports social features for rating and boosting search results and for sharing and annotating portfolios.","1550-6037;15506037","Electronic:978-1-4673-7568-9; POD:978-1-4673-7569-6","10.1109/iV.2015.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272630","Search interface;faceted search;multi-visualisation analysis;shared result portfolios","Data mining;Data visualization;Metadata;Portfolios;Search engines;Semantics;Visualization","data visualisation;information analysis;information retrieval;user interfaces","data analysis;data visualization;human visual system;interactive user interface;knowminer search approach;multivisualisation collaborative approach;pattern discovery;portfolio annotation;portfolio search;scalable faceted retrieval engine;search result analysis;visual interface","","2","","30","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Review on keyword searching techniques in uncertain graph data","N. B. Zambare; S. Manekar","Dept. of Comput. Sci. & Eng., G.H. Raisoni Coll. of Eng., Nagpur, India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","3","Searching for Keywords is an impulsive procedure for searching useful and relevant data from various sources like documents, graphs, relational databases, texts etc. The Uncertain Graph Data are widely used in real life applications. Uncertain Graphs pervasively exist in real applications, where data frequently exhibit uncertainties. Because of presence of uncertainty, it is a critical task for keyword searching on Uncertain Graph Data. Sometimes Keyword Searching phenomenon provides improper underlying results. Techniques discussed in this paper help to cover all these issues. Effective results are provided with the employed methods. This survey is done to decide which keyword searching technique is appropriate to derive the perfect results. These techniques prove to be very invoking to non-expert users in real applications.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238549","Keyword search;Uncertain graph;algorithm;databases;graph data","","data analysis;information retrieval","documents;keyword searching techniques;non-expert users;real life applications;relational databases;uncertain graph data","","0","","","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Semantic context extraction from collaborative networks","V. Franzoni; A. Milani","Dept. of Computer, Control and Mgmt. Engineering, University of Rome La Sapienza, Italy","2015 IEEE 19th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20150903","2015","","","131","136","A novel method for the automatic online extraction of contexts from collaborative explanation network is introduced. The method explore an unknown online collaborative network in order to find multiple explanatory paths between seed concepts. The exploration is driven by an online randomized walk informed by a heuristics based on semantic proximity measures. A pheromone-like model is then applied to the analysis of the relevance of concepts in multiple explanatory paths in order to extract the relevant contexts. Experiments held on the collaborative network Wikipedia and accepted datasets show that the proposed method is able to determine contexts with high degree of relevance which outperforms other methods. The methodology have general aim and it can be easily extended to other online collaborative networks and to non-textual domains.","","CD-ROM:978-1-4799-2001-3; Electronic:978-1-4799-2002-0; POD:978-1-4799-8541-8","10.1109/CSCWD.2015.7230946","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230946","Heuristic Search;Proximity Measures;Web Mining","Context;Convergence;Google;Navigation","Web sites;groupware;information retrieval;semantic networks","Wikipedia;collaborative explanation network;online randomized walk;pheromone-like model;semantic context extraction;semantic proximity measure","","3","","33","","","6-8 May 2015","","IEEE","IEEE Conference Publications"
"A graph digital signal processing method for semantic analysis","M. Trifan; B. Ionescu; C. Gadea; D. Ionescu","School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Ontario, Canada","2015 IEEE 10th Jubilee International Symposium on Applied Computational Intelligence and Informatics","20150820","2015","","","187","192","This paper focuses on the problem of devising a computationally tractable procedure for representing the natural language understanding (NLU). It approaches this goal, by using distributional models of meaning through a method from graph-based digital signal processing (DSP) which only recently grabbed the attention of researchers from the field of natural language processing (NLP) related to big data analysis. The novelty of our approach lies in the combination of three domains: advances in deep learning algorithms for word representation, dependency parsing for modeling inter-word relations and convolution using orthogonal Hadamard codes for composing the two previous areas, generating a unique representation for the sentence. Two types of problems are resolved in a new unified way: sentence similarity given by the cos function of the corresponding vectors and question-answering where the query is matched to possible answers. This technique resembles the spread spectrum methods from telecommunication theory where multiple users share a common channel, and are able to communicate without interference. In the content of this paper the case of individual words play the role of users sharing the same sentence. Examples of the method application to a standard set of sentences, used for benchmarking the accuracy and the execution time is also given.","","Electronic:978-1-4799-9911-8; POD:978-1-4799-9912-5; USB:978-1-4799-9910-1","10.1109/SACI.2015.7208196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7208196","CDMA;Hadamard matrix;SICK corpus;dependency parser;distributional semantic composition;similarity","Correlation;Digital signal processing;Error correction;Error correction codes;Natural language processing;Semantics;Signal processing algorithms","graph theory;natural language processing;question answering (information retrieval);signal processing","DSP;NLP;NLU;big data analysis;distributional models;graph based digital signal processing;graph digital signal processing method;natural language understanding;orthogonal Hadamard codes;question answering;semantic analysis;sentence similarity;spread spectrum methods;telecommunication theory","","0","","36","","","21-23 May 2015","","IEEE","IEEE Conference Publications"
"A novel spoken document retrieval system using Auto Associative Neural Network based keyword spotting","J. Sangeetha; S. Jothilakshmi","Department of Computer Science & Engineering, Annamalai University, Chidambaram, India","2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO)","20151001","2015","","","1","6","This paper formulates a novel approach to spoken document information retrieval for instinctive speech corpora. The conventional method for this problem is to make use of an Automatic Speech Recognizer (ASR) integrated with the typical information retrieval method. However, ASRs tend to produce transcripts of spontaneous speech with momentous word error rate, which is a negative aspect of standard retrieval system. To prevail over such a constraint, we propose a method for spoken document retrieval based on spoken keyword spotting using Auto Associative Neural Networks (AANN). The proposed work concerns the exploit of the distribution capturing capability of an auto associative neural network for spoken keyword detection. It involves sliding a frame-based keyword template along the audio documents and by means of confidence score acquired from the normalized squared error of AANN to competently search for a match. This work provides a new spoken keyword spotting algorithm based spoken documents clustering. The experimental results recommend that the proposed method is promising for retrieving relevant documents of a spoken query as a key.","","Electronic:978-1-4799-6480-2; POD:978-1-4799-6481-9","10.1109/ISCO.2015.7282280","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282280","Auto associative neural networks;Confidence Score;Document Retrieval;Mel frequency cepstral coefficients;Spoken Keyword Spotting","Data models;Feature extraction;Filter banks;Hidden Markov models;Mel frequency cepstral coefficient;Neural networks;Speech","information retrieval;neural nets;speech recognition","AANN;audio documents;auto associative neural network;confidence score;frame-based keyword template;instinctive speech corpora;normalized squared error;spoken document retrieval system;spoken documents clustering;spoken keyword detection;spoken keyword spotting algorithm;spoken query","","","","29","","","9-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Crowd Trust: A Context-Aware Trust Model for Worker Selection in Crowdsourcing Environments","B. Ye; Y. Wang; L. Liu","Dept. of Comput., Macquarie Univ., Sydney, NSW, Australia","2015 IEEE International Conference on Web Services","20150817","2015","","","121","128","On a crowd sourcing platform consisting of task publishers and workers, it is critical for a task publisher to select trustworthy workers to solve human intelligence tasks (HITs). Currently, the prevalent trust evaluation mechanism employs the overall approval rate of HITs, with which dishonest workers can easily succeed in pursuing the maximal profit by quickly giving plausible answers or counterfeiting HITs approval rates. In crowd sourcing environments, a worker's trustworthiness varies in contexts, i.e. It varies in different types of tasks and different reward amounts of tasks. Thus, we propose two classifications based on task types and task reward amount respectively. On the basis of the classifications, we propose a trust evaluation model, which consists of two types of context-aware trust: task type based trust (TaTrust) and reward amount based trust (RaTrust). Then, we model trustworthy worker selection as a multi-objective combinatorial optimization problem, which is NP-hard. For solving this challenging problem, we propose an evolutionary algorithm MOWS_GA based on NSGA-II. The results of experiments illustrate that our proposed trust evaluation model can effectively differentiate honest workers and dishonest workers when both of them have high overall HITs approval rates.","","Electronic:978-1-4673-7272-5; POD:978-1-4673-7273-2","10.1109/ICWS.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7195560","Combinatorial Optimization;Contextual Trust;Crowdsourcing;Worker Selection","Australia;Computational modeling;Context;Context modeling;Crowdsourcing;Evolutionary computation;Optimization","computational complexity;genetic algorithms;human resource management;information retrieval;personnel;trusted computing;ubiquitous computing","MOWS_GA evolutionary algorithm;NP-hard problem;RaTrust;TaTrust;context-aware trust model;crowd trust model;crowdsourcing environment;human intelligence task;multiobjective combinatorial optimization;reward amount based trust;task publisher;task type based trust;trustworthy worker selection;worker selection;worker trustworthiness","","2","","29","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Mining restaurants information by micro blog text analysis","Z. L. Xiang; X. R. Yu; D. K. Kang","Computer Software Institute, Weifang University of Science & Technology, Shouguang 262-700, Shandong, China","2015 17th International Conference on Advanced Communication Technology (ICACT)","20150827","2015","","","634","638","Micro-blogging is widely used nowadays. Most of the users normally write down their daily experience, feeling or emotion on their wall. This includes uploading photos of food they have taken. Some friends of this user might be interested in trying this food of which the photo has been uploaded by this user. However, it could be difficult for the friends to search that particular food on the Web as well as the exact location of the restaurant. In this paper, we provide a system that allows the users to search a particular food and produce the nearby restaurants on the Google Map. The proposed system will make the users to get the exact location of the restaurant easily.","1738-9445;17389445","CD-ROM:978-8-9968-6504-9; Electronic:978-8-9968-6505-6; POD:978-1-4673-8116-1","10.1109/ICACT.2015.7224874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224874","Cloud computing;Food store searching;Google map;Micro-blogging;Web Application","Blogs;Computer science;Data mining;Google;Twitter;Writing","Web sites;data mining;information retrieval;text analysis","Google Map;World Wide Web;food searching;microblog text analysis;restaurant information mining;restaurant location","","1","","5","","","1-3 July 2015","","IEEE","IEEE Conference Publications"
"Design and Development of a Cloud-Based Trip-Tracking System","T. A. N. Thi; Y. C. Chen","Dept. of Comput. Sci., Nat. Chiao Tung Univ., Hsinchu, Taiwan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","3","","636","637","A trip-tracking system records people traveled route which could be retrieved immediately or latter for certain purposes. The recent tracking application does not integrate both passive and real-time tracking function into one system. The aim of this work is to build a tracking system that integrates both passive and real-time tracking functions. A new system architecture consisting the client side which is a map tracking application on smart devices, and the server side which includes a server and a database in the cloud, was developed. Because of the ability to store and process database on the cloud, the system would be more secure, available and durable. More importantly, it can be tracked at any time and from anywhere. The results demonstrated a complete system with three real-world experiments on Android application and web interface.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273442","Android application;Cloud computing;Real-time tracking;Tracking system","Androids;Databases;Global Positioning System;Google;Humanoid robots;Real-time systems;Servers","Android (operating system);cloud computing;information retrieval;real-time systems;security of data;software architecture;user interfaces","Android application;Web interface;cloud-based trip-tracking system;data security;information retrieval;real-time tracking function;system architecture;traveled route","","","","11","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Based on bibliometrics and content analysis of the literature on science and technology media","Xiaoli Sun; Dan Wu; Chao Zhang","China Research Institute for Science Popularization, Beijing, China","2015 Portland International Conference on Management of Engineering and Technology (PICMET)","20150924","2015","","","1339","1344","Taking “science and technology media” as the topic words, CNKI database as retrieval sources of date, 132 papers published during the period of 2004-2013 were obtained. Using the method of bibliometrics and content analysis, summarizing the general research of “science and technology media” articles in past ten years(2004-2013), the frequency of download count, citation frequency, subjects, authors, research field, literature research quantity, sources, influence, research status, research field and research themes were analyzed. The research development and dynamic on science and technology media were summarized, it was also proposed the improvements and methods in research field, for exploring the direction of future development in “science and technology media” field. In addition, the characteristics of papers which were published in different journals, the distribution and regional units of the first authors, were analyzed, with the hope to help the publishing of papers on “science and technology media”, and exploring new research field.","2159-5100;21595100","Electronic:978-1-8908-4331-1; POD:978-1-4799-1767-9; USB:978-1-8908-4332-8","10.1109/PICMET.2015.7273157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273157","","Bibliometrics;Databases;Market research;Media;Technological innovation;Time-frequency analysis","citation analysis;information retrieval","CNKI database;bibliometrics analysis;citation frequency;literature content analysis;science and technology media articles","","","","11","","","2-6 Aug. 2015","","IEEE","IEEE Conference Publications"
"Authorship Semantical Identification Using Holomorphic Chebyshev Projectors","C. Napoli; E. Tramontana; G. L. Sciuto; M. Wozniak; R. Damaevicius; G. Borowik","Dept. of Math. & Inf., Univ. of Catania, Catania, Italy","2015 Asia-Pacific Conference on Computer Aided System Engineering","20151005","2015","","","232","237","Text attribution and classification, for both information retrieval and analysis, have become one of the main issues in the matter of security, trust and copyright preservation. This paper proposes an innovative approach for text classification using Chebyshev polynomials and holomorphic transforms of the coefficients space. The main advantage of this choice lies in the generality and robustness of the proposed semantical identifier, which can be applied to various contexts and lexical domains without any modification.","","Electronic:978-1-4799-7588-4; POD:978-1-4799-7589-1","10.1109/APCASE.2015.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7287025","authorship identification;data mining;natural language;neural networks;text mining","Chebyshev approximation;Databases;Feature extraction;Modeling;Polynomials;Radiation detectors;Transforms","copyright;information retrieval;pattern classification;security of data;text analysis;trusted computing","Chebyshev polynomial;authorship semantical identification;coefficients space;copyright preservation;holomorphic Chebyshev projector;holomorphic transform;information analysis;information retrieval;security;semantical identifier;text attribution;text classification;trust","","2","","41","","","14-16 July 2015","","IEEE","IEEE Conference Publications"
"Fusing feature and similarity for multimodal search","G. Song; S. Wang; Q. Tian","University of Chinese Academy of Sciences","2015 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP)","20150903","2015","","","787","791","It is well known that multiple information fusion can enhance the retrieval performance of multimedia systems. However, what to fuse and how to fuse them are still open issues for multimodal correlation learning. In this paper, we address the problem of combining multiple resources to enhance the multimodal correlation learning ability. We propose two fusion strategies: multi-feature fusion and multi-similarity fusion. For multi-feature fusion, feature concatenation is used to integrate various features. For multi-similarity fusion, three fusion rules are investigated: MIN, MAX, and weighted AVG fusion. The effectiveness of the fusion strategies is evaluated on several state-of-the-art multimodal correlation learning models for cross-modal retrieval tasks. Results suggest that with proper fusion strategy selection, the multimodal retrieval performance can be significantly enhanced.","","Electronic:978-1-4799-1948-2; POD:978-1-4799-1949-9; USB:978-1-4799-1947-5","10.1109/ChinaSIP.2015.7230512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230512","Multimodal search;data fusion;similarity measure","Correlation;Data integration;Feature extraction;Multimedia communication;Semantics;Streaming media;Weight measurement","information retrieval;learning (artificial intelligence);multimedia systems;sensor fusion","MAX fusion rule;MIN fusion rule;feature concatenation;fusion strategy selection;information fusion;multifeature fusion;multimedia systems retrieval performance;multimodal correlation learning;multimodal retrieval performance;multisimilarity fusion;weighted AVG fusion rule","","0","","11","","","12-15 July 2015","","IEEE","IEEE Conference Publications"
"FLATM: A fuzzy logic approach topic model for medical documents","A. Karami; A. Gangopadhyay; B. Zhou; H. Karrazi","Information Systems Department, University of Maryland Baltimore County, 21250, USA","2015 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS) held jointly with 2015 5th World Conference on Soft Computing (WConSC)","20151001","2015","","","1","6","One of the challenges for text analysis in medical domains is analyzing large-scale medical documents. As a consequence, finding relevant documents has become more difficult. One of the popular methods to retrieve information based on discovering the themes in the documents is topic modeling. The themes in the documents help to retrieve documents on the same topic with and without a query. In this paper, we present a novel approach to topic modeling using fuzzy clustering. To evaluate our model, we experiment with two text datasets of medical documents. The evaluation metrics carried out through document classification and document modeling show that our model produces better performance than LDA, indicating that fuzzy set theory can improve the performance of topic models in medical domains.","","Electronic:978-1-4673-7248-0; POD:978-1-4673-7249-7; USB:978-1-4673-7247-3","10.1109/NAFIPS-WConSC.2015.7284190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284190","","Analytical models;Bioinformatics;Biomedical imaging;Computational modeling;Data models;Fuzzy set theory;Medical services","data mining;fuzzy set theory;information retrieval;medical information systems;pattern classification;pattern clustering;text analysis","FLATM model;document classification;document modeling;fuzzy clustering;fuzzy logic approach topic model;fuzzy set theory;information retrieval;medical documents analysis;text analysis","","1","","41","","","17-19 Aug. 2015","","IEEE","IEEE Conference Publications"
"Cloud Hopfield neural network: Analysis and simulation","N. Singh; A. Kapoor","Information Communication and Instrumentation Training Center, India Meteorological Department, Ministry of Earth Sciences, Delhi, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","203","209","In this paper we present modifications in the dynamics of Hopfield neural network. We compare our modified retrieval algorithms with both synchronous and asynchronous retrieval algorithms used in Hopfield dynamics. Our results show that a modified Hopfield neural network consisting of a cloud with r number of unique neurons, (in the simulation given in this paper r=3% i.e. 4 neurons out of total 120) is better in terms of both retrieval capabilities and convergence time in comparison to the asynchronous retrieval algorithm. Moreover, unlike synchronous retrieval algorithm it does not enter oscillation states.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275610","Hopfield;artificial neural network;asynchronous retrieval;cloud;convergence time;machine learning;synchronous retrieval","Biological neural networks;Convergence;Distortion;Hopfield neural networks;Mathematical model;Neurons;Oscillators","Hopfield neural nets;information retrieval","Hopfield dynamics;asynchronous retrieval algorithms;cloud Hopfield neural network;modified Hopfield neural network;modified retrieval algorithms","","","","25","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"A survey of tools and applications in big data","S. P. Menon; N. P. Hegde","Department of CSE, K.L.E.Institute of Technology, Hubli, India","2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO)","20151001","2015","","","1","7","Big data brings with it the promise of data-driven decision-making. Complexity, Privacy, Heterogeneity impede the progress of making valuable decisions from this voluminous data. In this paper, we have reviewed the challenges related to big data, the technologies available for the same. Data Analysis and Retrieval, Spurious data, Noise Accumulation are the other challenges. The discussions here are aimed at providing a comprehensive overview to this new age data. We have concluded this survey by throwing light on the open problems and research issues.","","Electronic:978-1-4799-6480-2; POD:978-1-4799-6481-9","10.1109/ISCO.2015.7282364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282364","Big Data;Dryad;Hadoop;Hadoop Distributed File System;MapReduce","Authorization;Data models;Indexes;Libraries","Big Data;data analysis;information retrieval","Big Data;data analysis;data retrieval;noise accumulation;spurious data","","4","","9","","","9-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Provably delay efficient data retrieving in storage clouds","Y. Sun; Z. Zheng; C. E. Koksal; K. H. Kim; N. B. Shroff","Dept. of ECE, The Ohio State University, Columbus, OH","2015 IEEE Conference on Computer Communications (INFOCOM)","20150824","2015","","","585","593","One key requirement for storage clouds is to be able to retrieve data quickly. Recent system measurements have shown that the data retrieving delay in storage clouds is highly variable, which may result in a long latency tail. One crucial idea to improve the delay performance is to retrieve multiple data copies by using parallel downloading threads. However, how to optimally schedule these downloading threads to minimize the data retrieving delay remains to be an important open problem. In this paper, we develop low-complexity thread scheduling policies for several important classes of data downloading time distributions, and prove that these policies are either delay-optimal or within a constant gap from the optimum delay performance. These theoretical results hold for an arbitrary arrival process of read requests that may contain finite or infinite read requests, and for heterogeneous MDS storage codes that can support diverse storage redundancy and reliability requirements for different data files. Our numerical results show that the delay performance of the proposed policies is significantly better than that of First-Come-First-Served (FCFS) policies considered in prior work.","0743-166X;0743166X","Electronic:978-1-4799-8381-0; POD:978-1-4799-8382-7","10.1109/INFOCOM.2015.7218426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7218426","","Cloud computing;Conferences;Delays;Instruction sets;Optimized production technology;Redundancy;Servers","cloud computing;information retrieval;multi-threading;reliability;storage management","FCFS policies;data downloading time distributions;data retrieving delay;first-come-first-served policies;heterogeneous MDS storage codes;infinite read requests;latency tail;low-complexity thread scheduling policies;optimal downloading thread scheduling;optimum delay performance;parallel downloading threads;reliability requirements;storage cloud;system measurements","","3","","37","","","April 26 2015-May 1 2015","","IEEE","IEEE Conference Publications"
"Social recommendation based on interest propagation","X. Xing; Z. Jia","School of Information Science and Technology, Bohai University, Jinzhou, China 121013","2014 International Conference on Mechatronics and Control (ICMC)","20150903","2014","","","1304","1307","In this paper, we propose an social recommendation method based on interest propagation, which focuses on the interest influence by other user interest in social networks. Our method combines the user-item click information, social relationship, as well as social action information between users in social networks for recommendations. The effectiveness of the proposed method is evaluated on Sina Weibo, one of the most popular social network sites in China. The experimental results show that the proposed method outperforms the traditional collaborative filtering based method.","","Electronic:978-1-4799-2538-4; POD:978-1-4799-2539-1","10.1109/ICMC.2014.7231763","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7231763","collaborative filtering;interest propagation;recommendation method;social network;social recommendation","Collaboration;Data mining;Data models;Facebook;Filtering;Sparse matrices","information retrieval;recommender systems;social networking (online)","China;Sina Weibo;interest propagation;social action information;social networks;social recommendation method;social relationship;user-item click information","","0","","14","","","3-5 July 2014","","IEEE","IEEE Conference Publications"
"Real-time detection of twitter social events from the user's perspective","S. Gaglio; G. Lo Re; M. Morana","DICGIM, University of Palermo, Viale delle Scienze, Ed. 6, 90128, ITALY","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","1207","1212","Over the last 40 years, automatic solutions to analyze text documents collection have been one of the most attractive challenges in the field of information retrieval. More recently, the focus has moved towards dynamic, distributed environments, where documents are continuously created by the users of a virtual community, i.e., the social network. In the case of Twitter, such documents, called tweets, are usually related to events which involve many people in different parts of the world. In this work we present a system for real-time Twitter data analysis which allows to follow a generic event from the user's point of view. The topic detection algorithm we propose is an improved version of the Soft Frequent Pattern Mining algorithm, designed to deal with dynamic environments. In particular, in order to obtain prompt results, the whole Twitter stream is split in dynamic windows whose size depends both on the volume of tweets and time. Moreover, the set of terms we use to query Twitter is progressively refined to include new relevant keywords which point out the emergence of new subtopics or new trends in the main topic. Tests have been performed to evaluate the performance of the framework and experimental results show the effectiveness of our solution.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7248487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248487","Social Sensing;Topic Detection;Twitter Analysis","Algorithm design and analysis;Detectors;Heuristic algorithms;Market research;Real-time systems;Twitter","data analysis;data mining;information retrieval;real-time systems;social networking (online)","Twitter social events;Twitter stream;dynamic environments;dynamic windows;information retrieval;real time detection;real-time Twitter data analysis;social network;soft frequent pattern mining;tweet documents;user perspective;virtual community","","1","","19","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Volatile Internet evidence extraction from Windows systems","N. Joseph; S. Sunny; S. Dija; K. L. Thomas","ER&DC Institute of Technology, Centre for Development of Advanced Computing, Thiruvananthapuram, India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","5","Internet users are increasing day by day and hence browser related evidence provides crucial information regarding a cyber crime. The rate of possible cyber crimes are increased unimaginably with this high usage of popular social networking Web sites and online Internet services for banking, shopping etc. Thus the need for collecting Internet browsing related information through a Browser Forensics Analysis is inevitable in a cyber crime investigation. Browser Forensics can be done as part of offline forensics by analyzing browser related files containing cookies, cache and other history information available in the hard disk. But, these files usually stores limited information and its content varies based on user settings. On the other hand, when a live forensics approach is adopted, the prime source of forensically relevant information is physical memory. So, in an Internet related cyber crime, the chance of getting crucial information by analyzing physical memory content collected from the Suspect's machine is very high. This paper presents a methodology for extracting user credentials of popular Web applications by analyzing a Windows system's physical memory content. It helps cyber crime investigators to retrieve usernames and associated passwords used in various Web based mail accounts, online banking and shopping sites etc. Another important methodology the paper presents is for the retrieval of high profile browser forensics information related to the suspect's Internet activity by memory dump analysis.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238452","Digital Evidence;Digital Forensics;Live Acquisition;Live Forensics;User Credentials","Browsers;Electronic mail;Facebook;Forensics;Hard disks;Internet;Postal services","Web sites;digital forensics;information retrieval;online front-ends","Internet browsing related information collection;Web applications;Windows system;browser forensics analysis;browser related file analysis;cache;cookies;cyber crime;hard disk;high-profile browser forensics information retrieval;history information;live forensics approach;memory dump analysis;offline forensics;online Internet services;password retrieval;physical memory content analysis;social networking Web sites;user credential extraction;username retrieval;volatile Internet evidence extraction","","0","","10","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Multimedia Indexing and Retrieval: Recent research work and their challenges","S. Kaavya; LakshmiPriya G G","SITE, VIT University, Vellore, Tamil Nadu, India","2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN)","20150827","2015","","","1","5","The need for Multimedia Indexing and Retrieval (MIR) is rising because of huge amount of videos are producing day by day. This requires techniques for indexing and retrieving multimedia information. This paper surveys the multimedia indexing and retrieval techniques. In order to perform video indexing and retrieval video annotation is required in which keyframe extraction plays a major role. So, a new algorithm based on divide and conquer strategy is proposed for keyframe extraction. Based on the motion activity of the events in the shot/scene, the shot is declared as static or dynamic, According to the native of shot, it can be further divided into subshots and so on. The proposed algorithm reduces redundancy in keyframes and suitable for diverse content of video.","","CD-ROM:978-1-4673-6822-3; Electronic:978-1-4673-6823-0; POD:978-1-4673-6824-7","10.1109/ICSCN.2015.7219851","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219851","CBIR;MIRl;Semantic indexing","Indexing;Media;Multimedia communication;Multimedia databases;NASA;Streaming media;Three-dimensional displays","divide and conquer methods;feature extraction;indexing;information retrieval;multimedia computing;video signal processing","MIR;divide and conquer strategy;keyframe extraction;multimedia indexing and retrieval;video annotation;video indexing","","0","","24","","","26-28 March 2015","","IEEE","IEEE Conference Publications"
"Risk intelligence retrieval based on ontology","R. Sarala; V. Vijayalakshmi; G. Zayaraz; E. Priyanka","Department of Computer Science and Engineering, Pondicherry Engineering College","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","4","Information Security Risk Management is one of the key factors in ensuring security of the Information Assets of any organization. Information Security Risk Management has gained more importance recently as information security breaches increase and information infrastructures are constantly being targeted by various attacks. The risk assessment activity in information security risk management helps in identifying the potential risks to the information assets. To perform proactive risk management, the attack related information is required to construct the attack patterns which could be used to predict the future attacks. Attack patterns can be stored as they help in extracting risk intelligence for effective risk management. Storing of attack patterns is achieved by constructing Ontology. Ontologies are used to formally represent domain knowledge. The ontology stores patterns of attacks against that target the confidentiality, integrity and availability of the information assets. The extraction of risk intelligence is done by mapping the log files of the currently monitored network activity with the stored attack patterns to predict forth coming attacks. The ontology created can also help in sharing attack related information among different organizations interested in performing Information Security Risk Management.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238338","Attack Patterns;Attack Prediction;Information Security Risk Management;Ontology;Proactive Approach;Risk Intelligence","Information security;Internet;Monitoring;Ontologies;Organizations;Risk management","data integrity;information retrieval;ontologies (artificial intelligence);risk management;security of data","attack pattern storage;domain knowledge representation;information asset;information asset availability;information asset confidentiality;information asset integrity;information infrastructure;information security breach;information security risk management;log file mapping;ontology;proactive risk management;risk assessment activity;risk identification;risk intelligence extraction;risk intelligence retrieval","","0","","14","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"UniCrawl: A Practical Geographically Distributed Web Crawler","D. L. Quoc; C. Fetzer; P. Felber; É. Rivière; V. Schiavoni; P. Sutra","Syst. Eng. Group, Dresden Univ. of Technol., Dresden, Germany","2015 IEEE 8th International Conference on Cloud Computing","20150820","2015","","","389","396","As the wealth of information available on the web keeps growing, being able to harvest massive amounts of data has become a major challenge. Web crawlers are the core components to retrieve such vast collections of publicly available data. The key limiting factor of any crawler architecture is however its large infrastructure cost. To reduce this cost, and in particular the high upfront investments, we present in this paper a geo-distributed crawler solution, UniCrawl. UniCrawl orchestrates several geographically distributed sites. Each site operates an independent crawler and relies on well-established techniques for fetching and parsing the content of the web. UniCrawl splits the crawled domain space across the sites and federates their storage and computing resources, while minimizing thee inter-site communication cost. To assess our design choices, we evaluate UniCrawl in a controlled environment using the ClueWeb12 dataset, and in the wild when deployed over several remote locations. We conducted several experiments over 3 sites spread across Germany. When compared to a centralized architecture with a crawler simply stretched over several locations, UniCrawl shows a performance improvement of 93.6% in terms of network bandwidth consumption, and a speedup factor of 1.75.","2159-6182;21596182","Electronic:978-1-4673-7287-9; POD:978-1-4673-7288-6","10.1109/CLOUD.2015.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214069","cloud federation;geo-distributed system;map-reduce;storage;web crawler","Computer architecture;Crawlers;Distributed databases;Internet;Uniform resource locators;Web pages","Internet;Web sites;information retrieval","ClueWeb12 dataset;Germany;UniCrawl;Web content fetching;Web content parsing;Web sites;centralized architecture;computing resources;crawler architecture;data retrieval;geo-distributed crawler solution;geographically distributed Web crawler;intersite communication cost;network bandwidth consumption;storage","","2","","35","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Flip classroom design and implementation of the literature retrieval course network teaching platform","T. Zhu; L. Zhang","Library Changchun Institute of Technology, Changchun, China","2015 10th International Conference on Computer Science & Education (ICCSE)","20150910","2015","","","1005","1008","The face of major changes in traditional higher education flip classroom triggered, this article will be the network teaching platform for IT support, flipped classroom building pre-design models, as well as the late feedback analysis, evaluation of teaching and other teaching embodiments of teaching literature search, flip the simultaneous analysis of classroom teaching process prone to problems, to promote the depth of integration of information technology and University Library retrieval Course provides online teaching opportunity.","","Electronic:978-1-4799-6600-4; POD:978-1-4799-6601-1; USB:978-1-4799-6599-1","10.1109/ICCSE.2015.7250399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7250399","Network teaching platform;database retrieval;flipped classroom;literature retrieval course","Databases;Education;Knowledge engineering;Online services;Search problems;Software;Videos","Internet;computer aided instruction;design;educational courses;educational institutions;further education;information retrieval;libraries;teaching","feedback analysis;flip classroom design;higher education;information technology;network teaching platform;online teaching;university library retrieval course","","0","","7","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Developing a framework that utilizes intelligent agents to extract multi-lingual web news","A. Al-Daraiseh; W. Haddoush","Computer Information Systems, King Saud University, Riyadh, Saudi Arabia","2015 2nd World Symposium on Web Applications and Networking (WSWAN)","20150820","2015","","","1","5","This paper proposes a framework for personalized news application that utilizes intelligent agents to aggregate specific articles from web news based on users' preferences. It shows how to extract web news stories in Arabic language, in particular, in addition to English language. Intelligent agents learn user's interests by exploiting data gathered from social media, web browsing history and also explicit and implicit feedback from the user. To suit the various facets of the user's interests, the system adopt multiagent with different genres. Each agent covers a particular task to fulfil the desired functionality of the framework.","","Electronic:978-1-4799-8172-4; POD:978-1-4799-8173-1","10.1109/WSWAN.2015.7210335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210335","bi-lingual;intelligent agent;machine learning;personalized news","Data mining;Feature extraction;History;Intelligent agents;Internet;Media;Monitoring","Internet;data handling;information retrieval;learning (artificial intelligence);multi-agent systems;natural language processing;social networking (online)","Arabic language;English language;Web browsing history;data gathering;explicit feedback;implicit feedback;intelligent agent utilization;machine learning;multilingual Web news stories extraction;personalized news application;social media;user interest learning","","0","","20","","","21-23 March 2015","","IEEE","IEEE Conference Publications"
"Relay selection in wireless networks for optimal delay anonymity tradeoff","O. Javidbakht; P. Venkitasubramaniam","Dep. of Electrical & Computer Eng., Lehigh University, PA, USA","2015 IEEE 16th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","20150831","2015","","","360","364","Wireless networks are susceptible to eavesdropping by unauthorized intruders who aim to extract information about the networked exchanges. Even when packets are encrypted, unsophisticated energy detectors can be used to identify the source destination pairs using the packet transmission timing on the wireless medium. Anonymous network protocols aim to prevent this information retrieval through the use of special intermediate relays that add artificial delays so as to confuse the eavesdropper. Previous studies have demonstrated that a tradeoff exists between the anonymity- secrecy of source destination pairs from timing analysis- provided by such relays and the latency incurred. The focus of this work is the tradeoff between anonymity and delay when a network of such relays are employed, as in practical anonymous systems such as Tor. Specifically, the problem of best route selection in anonymous networks that optimally trades off delay for anonymity has been investigated in this work. Using Shannon Entropy as the metric of anonymity, sufficient conditions on network parameters to achieve maximum anonymity are derived. The optimal route selection algorithm to obtain a desired tradeoff is shown to be computationally impractical, and a suboptimal route selection algorithm that effectively balances delay and anonymity has been proposed which has a negligible gap to the optimal solution, but requires far less computational resources. An incremental optimization which allows for real time addition of new users to the anonymous system is investigated and the performance compared with the centralized schemes.","1948-3244;19483244","Electronic:978-1-4799-1931-4; POD:978-1-4799-1932-1; USB:978-1-4799-1930-7","10.1109/SPAWC.2015.7227060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7227060","","Bandwidth;Delays;Optimization;Relays;Security;Wireless communication","information retrieval;optimisation;relay networks (telecommunication);telecommunication network routing;telecommunication security","Shannon Entropy;energy detector;information retrieval;optimal delay anonymity tradeoff;optimization;packet transmission timing;relay selection;suboptimal route selection algorithm;wireless network","","1","","15","","","June 28 2015-July 1 2015","","IEEE","IEEE Conference Publications"
"Web spam detection using SVM classifier","R. C. Patil; D. R. Patil","Department of Computer Engineering, R. C. Patel Institute of Technology, Shirpur, Dist.Dhule, maharashtra, India","2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO)","20151001","2015","","","1","4","Web spam is one of the recent problems of search engines because it powerfully reduced the quality of the Web page. Web spam has an economic impact because spammers provide a large free advertising data or sites on the search engines and so an increase in the web traffic. In this paper we have implemented spam detection system based on a SVM classifier that combines new link features with content and qualified link analysis. We have used the kullback-Leibler divergence for characterizing the relationship between the two linked pages. The experimental result shows the F-measure 0.95% for WEBSPAM-UK2006 and 0.44% for WEBSPAM-UK2007 datasets.","","Electronic:978-1-4799-6480-2; POD:978-1-4799-6481-9","10.1109/ISCO.2015.7282294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282294","Kullback-Leibler divergence (KLD);Language Model (LMs);Qualified link analysis (QL);Support vector machine (SVM);Web spam detection","Conferences;Feature extraction;Search engines;Support vector machines;Unsolicited electronic mail;Web pages","Internet;Web sites;feature extraction;information retrieval;pattern classification;search engines;support vector machines;unsolicited e-mail","F-measure;Kullback-Leibler divergence;SVM classifier;Web page quality;Web spam detection system;Web traffic;content based feature;economic impact;free advertising data;link feature;linked pages;qualified link analysis;search engine","","","","11","","","9-10 Jan. 2015","","IEEE","IEEE Conference Publications"
"Queriosity: Automated Data Exploration","A. Wasay; M. Athanassoulis; S. Idreos","","2015 IEEE International Congress on Big Data","20150820","2015","","","716","719","Curiosity, a fundamental drive amongst higher living organisms, is what enables exploration, learning and creativity. In our increasingly data-driven world, data exploration, i.e., Making sense of mounting haystacks of data, is akin to intelligence for science, business and individuals. However, modern data systems -- designed for data retrieval rather than exploration -- only let us retrieve data and ask if it is interesting. This makes knowledge discovery a game of hit-and-trial which can only be orchestrated by expert data scientists. We present the vision toward Queriosity, an automated and personalized data exploration system. Designed on the principles of autonomy, learning and usability, Queriosity envisions a paradigm shift in data exploration and aims to become a a personalized ""data robot"" that provides a direct answer to what is interesting in a user's data set, instead of just retrieving data. Queriosity autonomously and continuously navigates toward interesting findings based on trends, statistical properties and interactive user feedback.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207300","Curious data systems;Data analysis;Data exploration;Data systems","Big data;Context;Data mining;Learning (artificial intelligence);Usability","data mining;information retrieval;learning (artificial intelligence);statistical analysis","Queriosity;automated personalized data exploration system;autonomy;data retrieval;interactive user feedback;knowledge discovery;learning;personalized data robot;statistical properties;usability","","1","","11","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Using photomosaic and steganographic techniques for hiding information inside image mosaics","A. H. Pascaline; L. C. F. Christopher; M. H. M. Khan; S. Pudaruth","Computer Science and Engineering Department, University of Mauritius, Mauritius","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1893","1897","In this digital world, transferring sensitive data electronically has become inevitable. The objective of this work is to hide and retrieve confidential information in image mosaics. The photomosaic approach has been used for the creation of the mosaic and the least significant bit (LSB) technique has been adopted for the embedding of the hidden information. The construction of the photomosaic is done by selecting an image, splitting it into smaller images (tiles) of sizes 8×8, 16×16 and 32×32. These tiles are then compared from a very large amount of photos of the same sizes. Next, the user can either hide a secret image or a secret text into them. The final mosaic image contains secret information that is well-concealed and is impossible to find out with the naked eye. This technique is more robust compared to modifying the bits of the original image directly.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275894","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275894","confidentiality;mosaic;secret message;steganography","Computer science;Cryptography;Databases;Genetic algorithms;Image color analysis;Visualization","image coding;information retrieval;steganography","LSB technique;confidential information hiding;confidential information retrieval;hidden information embedding;image mosaics;least significant bit technique;photomosaic technique;steganographic technique","","","","14","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Developing tailored-made online materials for academic use","B. Klimova","Department of Applied Linguistics, University of Hradec Kralove, Czech Republic","2015 International Conference on Information Technology Based Higher Education and Training (ITHET)","20150824","2015","","","1","4","English now dominates the research world because it is the language of academic publications. Therefore, non-native English speaking academics, especially those working outside the inner circle English speaking countries, need skills of formal writing in English in order to get their research presented and published in the world's prestigious databases, such as the Web of Science, or in a journal with an impact factor. Nevertheless, as many research studies confirm, writing skills are the most difficult skills to be learned. In addition, the findings of contrastive rhetoric show that there are differences between the schemata of L2 and L1 writers in their preferred ways of organizing ideas and these also have an impact on written communication. Thus, the purpose of this article is to demonstrate how these skills of academic writing can be enhanced with the help of tailored-made materials focused on the development of these skills. The author of this article discusses the structure of these materials, their content and particularly the ways of delivering them to academic staff with respect to their needs and time constraints.","","Electronic:978-1-4799-1756-3; POD:978-1-4799-1757-0; USB:978-1-4799-1755-6","10.1109/ITHET.2015.7217963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217963","English;academics;materials development;online study materials","Electronic learning;Grammar;Portals;Pragmatics;Rhetoric","information retrieval systems;information services","academic publications;academic writing;contrastive rhetoric findings;formal writing;non-native English speaking academics;tailored-made online materials;writing skills;written communication","","0","","17","","","11-13 June 2015","","IEEE","IEEE Conference Publications"
"Shamir's key based confidentiality on cloud data storage","D. Kamalraj; B. Balamurugan; S. Jegadeeswari; M. Sugumaran","Research Scholar, Bharathiar University, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","418","423","Confidentiality is used on accessing the set of cloud database information with high security level. The conventional encryption and decryption mechanism for the privacy maintenance in cloud zone acquire additional processing time. Hence, the cloud service did not explore effective confidentiality on information retrieval process. A new key distribution scheme for efficient privacy preserving query plans on the cloud data achieves a higher percentage of confidentiality by residing the cloud data with polynomial interpolation. To ensure high confidentiality and providing privacy to the cloud users the Shamir's Key Distribution based Confidentiality (SKDC) scheme is employed. SKDC scheme generates a polynomial of degree with the secret as the first coefficient and the remaining coefficients picked up at random to improve the privacy preserving level on the cloud infrastructure. Shamir's Key Distribution supports batch auditing where multiple user requests for data auditing is held concurrently at a higher confidentiality rate. SKDC scheme handles query processing using the matrix-structure form. An Experimental evaluation is performed with Amazon Simple Storage Service dataset to evaluate the confidentiality and privacy performance with Shamir's Key Distribution based Confidentiality (SKDC) scheme is compared with two well-known privacy schemes such as Trusted Third Party Model (TTPM) and Trusted Hardware Based Database. As a result, the SKDC scheme increases confidentiality level of the user by 22 % as compared to existing TTPM method.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275645","Cloud Computing;Confidentiality;SKDC;privacy preserving and polynomial interpolation","Cloud computing;Data privacy;Interpolation;Memory;Polynomials;Privacy;Query processing","cloud computing;cryptography;data privacy;information retrieval;interpolation;storage management","Amazon simple storage service dataset;SKDC scheme;Shamir's key based confidentiality;Shamir's key distribution based confidentiality scheme;cloud data storage;cloud database information;cloud infrastructure;data auditing;decryption mechanism;encryption mechanism;information retrieval process;key distribution scheme;matrix-structure form;polynomial interpolation;privacy maintenance;privacy preserving query plans;query processing","","","","20","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"XML document retrieval by developing an effective indexing technique","A. M. Posonia; V. L. Jyothi","Department of Computer Science, Sathyabama University, Chennai, India","2014 Sixth International Conference on Advanced Computing (ICoAC)","20150831","2014","","","120","123","A Semistructured data can be represented in a tree structure which is an efficient tool for describing different kinds of data. This paper furnishes the method of full text data searches that can be integrated with XML database and the performance can be improved by implementing structured and text index based technique. The searching keyword of structure index should be a node identifier whereas the searching keyword of text index should be a content fragment of an XML document. The experimental results exhibit the improved performance of document retrieval.","2377-6927;23776927","Electronic:978-1-4799-8159-5; POD:978-1-4799-8160-1","10.1109/ICoAC.2014.7229758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229758","Indexing;XML Document;XML Schema;XPath Query","Labeling;Multimedia communication;XML","XML;indexing;information retrieval;tree data structures","XML database;XML document retrieval;effective indexing technique;full text data;node identifier;semistructured data;structure index keyword;text index based technique;tree structure","","0","","22","","","17-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"Logic-based approach for improving Arabic question answering","W. Bakari; O. Trigui; M. Neji","Computer Science, MIR@CL, Sfax, Tunisia","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","6","Logical and inference approaches in Arabic question answering are in their first steps compared to other languages like English. This paper deals with the automatic Arabic text comprehension of question answering. Our goal is to understand a given text then answer a list of questions related to it. To do that, we have proposed an approach with which we can analyze a given text in an open domain and generate from them logical representations. Our approach is based on recognizing the textual entailment method. We have implemented this approach in a question answering system called NArQAS: New Arabic Question Answering System.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238319","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238319","logical representatio;question answering system;reading comprehension;recognizing textual entailment","Computational intelligence;Conferences;Databases;Knowledge discovery;Natural languages;Semantics;Text recognition","inference mechanisms;question answering (information retrieval);text analysis","NArQAS;New Arabic Question Answering System;automatic Arabic text comprehension;inference approaches;logical representations;textual entailment method","","1","","32","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"Online trendy topics detection in microblogs with selective user monitoring under cost constraints","Z. Miao; K. Chen; Y. Zhou; H. Zha; J. He; X. Yang; W. Zhang","Shanghai Jiao Tong University, China","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","1194","1200","As microblog services such as Twitter become a fast and convenient communication approach, identification of trendy topics in microblog services has great academic and business value. However detecting trendy topics is very challenging due to huge number of users and short-text posts in microblog diffusion networks. In this paper we introduce a trendy topics detection system under computation and communication resource constraints. In stark contrast to retrieving and processing the whole microblog contents, we develop an idea of selecting a small set of microblog users and processing their posts to achieve an overall acceptable trendy topic coverage, without exceeding resource budget for detection. We formulate the selection operation of these subset users as mixed-integer optimization problems, and develop heuristic algorithms to compute their approximate solutions. The proposed system is evaluated with real-time test data retrieved from Sina Weibo, the dominant microblog service provider in China. It's shown that by monitoring 500 out of 1.6 million microblog users and tracking their microposts (about 15,000 daily) with our system, nearly 65% trendy topics can be detected, while on average 5 hours earlier before they appear in Sina Weibo official trends.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7248485","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7248485","","Real-time systems","information retrieval;social networking (online)","cost constraints;microblogs;microposts;mixed-integer optimization problems;online trendy topics detection;selection operation;selective user monitoring","","1","","13","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"A survey on how to cross-reference web information sources","J. Raad; A. Bertaux; C. Cruz","CheckSem Department, Le2i Laboratory, University of Burgundy, Dijon, France","2015 Science and Information Conference (SAI)","20150903","2015","","","609","618","The goal of giving information a well-defined meaning is currently shared by different research communities. Once information has a well-defined meaning, it can be searched and retrieved more effectively. Therefore, this paper is a survey about the methods that compare different textual information sources in order to determine whether they address a similar information or not. The improvement of the studied methods will eventually lead to increase the efficiency of documentary research. In order to achieve this goal, the first category of methods focuses on semantic measure definitions. A second category of methods focuses on paraphrase identification techniques, and the last category deals with improving event extraction techniques. A general discussion is given at the end of the paper presenting the advantages and disadvantages of these methods.","","Electronic:978-1-4799-8547-0; POD:978-1-4799-8548-7; USB:978-1-4799-8546-3","10.1109/SAI.2015.7237206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237206","Cross-Reference Web Information Sources;Documentary Research;Event Extraction;Paraphrase Identification;Semantic Measures;Semantic Relatedness;Similarity Definition","Encyclopedias;Internet;Length measurement;Ontologies;Position measurement;Semantics","Internet;information retrieval;text analysis","cross-reference Web information sources;documentary research;event extraction techniques;paraphrase identification techniques;semantic measure definitions;textual information sources","","0","","52","","","28-30 July 2015","","IEEE","IEEE Conference Publications"
"A novel method to compress high-throughput DNA sequence read archive","Xiaojuan Zhan; Dengju Yao","Coll. of Comput. Sci. & Technol., Heilongjiang Inst. of Technol., Harbin, China","International Conference on Software Intelligence Technologies and Applications & International Conference on Frontiers of Internet of Things 2014","20151001","2014","","","58","61","The exponential growth of high-throughput DNA sequence data has brought great challenges in data processing, archive and transmission. How to improve compression techniques for large datasets of sequence read archive has become a critical problem in store and analyzes biological data. The paper compared the existing data compression methods on five high-throughput sequence datasets, and proposed a novel method to compress high-throughput sequence read archive data. The experiment results show that the proposed compression method could get good compression ration and implement higher processing speed.","","Paper:978-1-84919-970-4","10.1049/cp.2014.1536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284220","DNA sequence read archive;data compression;high-throughput data;next generation sequencing","","DNA;bioinformatics;data compression;information retrieval systems","biological data analysis;biological data storage;compression ration;compression technique improvement;data archive;data processing;data transmission;high-throughput DNA sequence read archive compress;high-throughput sequence datasets","","","","","","","4-6 Dec. 2014","","IET","IET Conference Publications"
"Question Answering over Knowledge Bases","K. Liu; J. Zhao; S. He; Y. Zhang","Institute of Automation, Chinese Academy of Sciences","IEEE Intelligent Systems","20150904","2015","30","5","26","35","Question answering over knowledge bases is a challenging task for next-generation search engines. The core of this task is to understand the meaning of questions and translate them into structured language-based queries. Previous research has focused on a specific knowledge base with a constrained domain, but with the increase in the size and domain of existing knowledge bases, fulfilling this aim is even more challenging. This article introduces the mainstream methods for question answering over knowledge bases, describing typical semantic meaning representation models and state-of-the-art systems for converting questions to predefined logical forms. It also puts a particular focus on the approaches for question answering over a large-scale knowledge base and multiple heterogeneous knowledge bases.","1541-1672;15411672","","10.1109/MIS.2015.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243222","NLP;intelligent systems;knowledge base;natural language processing;question answering;semantic parsing","Adaptation models;Grammar;Knowledge based systems;Knowledge discovery;Natural languages;Semantics;Syntactics","knowledge based systems;question answering (information retrieval);search engines","constrained domain;heterogeneous knowledge base;knowledge base;large-scale knowledge base;logical forms;next-generation search engines;question answering;semantic meaning representation models","","2","","56","","","Sept.-Oct. 2015","","IEEE","IEEE Journals & Magazines"
"Minimizing Bandwidth Cost of CCN: A Coordinated In-Network Caching Approach","Y. Xu; Z. Wang; Y. Li; T. Lin; W. An; S. Ci","Dept. of Comput. Sci., Beijing Foreign Studies Univ., Beijing, China","2015 24th International Conference on Computer Communication and Networks (ICCCN)","20151005","2015","","","1","7","To reduce data access latency, network traffic volume and server load, in-network caching was proposed and has become an intrinsic component of the content-centric network (CCN) architecture. The content-oriented characteristics of in-network caching, such as arbitrary topology, volatile content locations and line speed requirements, make routers content-aware and supportive of fast content distribution. Meanwhile, they also raise new challenges in content placement and request routing, namely, how to optimally make content storage decisions and provision individual router's bandwidth to serve user requests, so as to minimize the bandwidth cost under storage and link capacity limit. To address this problem, we build a distributed in-network caching model to formulate the content placement and request routing in CCN, aiming at minimizing the bandwidth cost with strict storage and bandwidth constraints. Based on the proposed model, we design a scalable, adaptive and low-complexity in-network caching scheme for content placement and request routing and analyze the performance gains via simulations on a real ISP network topology and traffic traces. The experimental results show the proposed model and scheme are superior. Compared with the existing works, we also observe significant performance enhancements in terms of hit ratio of requests, reduction of server load, and bandwidth cost.","1095-2055;10952055","Electronic:978-1-4799-9964-4; POD:978-1-4799-9965-1; USB:978-1-4799-9963-7","10.1109/ICCCN.2015.7288426","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7288426","","Adaptation models;Bandwidth;Nickel;Peer-to-peer computing;Routing;Servers;Uplink","Internet;cache storage;content-addressable storage;information retrieval;telecommunication network routing;telecommunication network topology;telecommunication traffic","CCN architecture;ISP network topology;bandwidth cost;content distribution;content placement;content storage decisions;content-centric network;content-oriented characteristics;coordinated in-network caching;data access latency;distributed in-network caching model;in-network caching scheme;network traffic volume;request routing;router bandwidth","","2","","18","","","3-6 Aug. 2015","","IEEE","IEEE Conference Publications"
"SASM: A tool for sentiment analysis on Twitter","O. F. W. Onifade; M. A. Malik","Department of Computer Science, University of Ibadan, Ibadan, Nigeria","2015 2nd World Symposium on Web Applications and Networking (WSWAN)","20150820","2015","","","1","5","With Twitter ranking as one of the fastest growing social media platform, it represents a means via which simultaneous sharing of opinion is made possible. This huge resources for information is however limited in its ability to present human readers and opinion seekers relevant information tailored towards experience, ability to extract, read, summarize and finally organize them in appropriately usable forms. The volume of available tweets is not actually the problem, but the nature of the data which harbors a lot of sentiment. This paper is set to present improved means of accurately providing analysis of automatically retrieved opinions and presenting the results to the user after performing sentiment analysis on the retrieved data.","","Electronic:978-1-4799-8172-4; POD:978-1-4799-8173-1","10.1109/WSWAN.2015.7210332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210332","opinion mining;sentiment analysis;text summarization;tweets","Analytical models;Data mining;Feature extraction;Media;Sentiment analysis;Speech;Twitter","data mining;information retrieval;social networking (online);text analysis","SASM;Twitter ranking;data retrieval;opinion mining;opinion sharing;sentiment analysis;social media platform;text summarization","","0","","18","","","21-23 March 2015","","IEEE","IEEE Conference Publications"
"Biomedical data integration and ontology-driven multi-facets visualization","C. De Maio; G. Fenza; V. Loia; M. Parente","Deparment of Computer Science, University of Salerno, Fisciano (SA), Italy","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","8","With the proliferation of different heterogeneous biomedical data sources and with the growing amount of their content available over the Web, there is, on one side, the need to support mashing and data integration and, on the other side, the more urgent need to relate literature and research results that are often enclosed in unstructured textual documents. Nowadays, ontologies have been used as a common access knowledge layer playing a crucial role to support categorized access to the information resources. Moreover, manual construction of a domain-specific ontology and content categorization is a labor intensive and a time-consuming process. This work focuses on the development of a novel biomedical ontology-driven multi-facets visualization to support categorized access to heterogeneous and unstructured biomedical data sources (e.g., PubMed, WikiGenes). Specifically, the framework relies on: knowledge extraction methodology, to automatically extract ontology exploiting the Fuzzy Formal Concept Analysis theory; and ontology matching strategy to find relation between extracted ontology and the available ones in the field of biomedicine (e.g., Ontology of Gene and Genomes, Gene Ontology, Protein Ontology). The evaluation will be shown in terms of Precision and Recall by using biomedical ontology concepts as input query to the multi-facets visualization engine.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280395","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280395","","Bioinformatics;Genomics;Mashups;Ontologies","data integration;data visualisation;distributed databases;formal concept analysis;fuzzy set theory;information retrieval;knowledge acquisition;medical information systems;ontologies (artificial intelligence)","PubMed;WikiGenes;access knowledge layer;biomedical data integration;biomedical ontology-driven multifacets visualization;biomedicine;categorized access;content categorization;domain-specific ontology;fuzzy formal concept analysis theory;heterogeneous biomedical data sources;information resources;knowledge extraction methodology;mashing;ontology matching strategy;precision and recall;unstructured biomedical data sources;unstructured textual documents","","1","","29","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"Building a parallel Corpora: Translation issues and remedial case","Archana G P; Jithesh V S; Remya L B; E. Sherly","Virtual Resource Center for Language Computing, Indian Institute of Information Technology and Management- Kerala, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","2414","2417","In a multilingual country like India, language translation plays a prominent role in the field of text processing and applications, such as, machine learning, machine translation, information extraction, information retrieval, and natural language understanding systems. There are many issues and challenges in translation between languages such as lexical divergences, ambiguities, lexical mismatches, reordering, syntactic and semantic issues, structural changes etc. In this paper, we have presented a comparative analysis by highlighting some of the crucial issues, challenges and solutions in translation from Hindi to Malayalam language, while executing Indian Language Corpora Initiative (ILCI) project of DeitY, GoI. In this analysis, we have found that Malayalam and Hindi have very distinct structures in linguistic levels like phonological, lexical and syntactic, which has to be handled carefully in translation.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275980","parallel corpus;translation","Agriculture;Buildings;Context;Informatics;Information technology;Semantics;Syntactics","information retrieval;language translation;learning (artificial intelligence);natural language processing;text analysis","Hindi language;ILCI project;Indian language corpora initiative;Malayalam language;ambiguity;comparative analysis;information extraction;information retrieval;language translation;lexical divergence;lexical mismatch;machine learning;machine translation;multilingual country;natural language understanding system;parallel corpora;remedial case;semantic issue;syntactic issue;text processing;translation issue","","","","14","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Development of the folk implements database for the digital archive","T. Hanyu; S. Miyata; T. Morizumi; H. Kinoshita","Kanagawa University 3-27-1 Rokkakubashi, Kanagawa-ku, Yokohama, 221-8686, Japan","2015 IEEE International Conference on Consumer Electronics - Taiwan","20150824","2015","","","484","485","In recent years, digitization of museum material information has been promoted. Some museums provide digital material information at online. However, digital archives and museum databases are not unified in each museum. Since folk implements are basic materials for understanding the ordinary people production activities and daily lives, there are many classification methods for these materials. Thus, it is difficult to search the folk implements adequately. In this paper, we propose a folk implements classification method. This method can effectively classify the folk implements by normalized relational model, and avoid the database redundancy.","","Electronic:978-1-4799-8745-0; POD:978-1-4799-8746-7","10.1109/ICCE-TW.2015.7217011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217011","Database;Digital archive;Folk implements;Museum","Internet;Production;Redundancy;Relational databases;Standards;Time measurement","digital libraries;information retrieval systems;museums;relational databases","database redundancy;digital archives;digital material information;folk implements classification method;folk implements database development;museum database;museum material information digitization;normalized relational model","","0","","5","","","6-8 June 2015","","IEEE","IEEE Conference Publications"
"Phase retrieval with masks using convex optimization","K. Jaganathan; Y. Eldar; B. Hassibi","Department of Electrical Engineering, Caltech, USA","2015 IEEE International Symposium on Information Theory (ISIT)","20151001","2015","","","1655","1659","Signal recovery from the magnitude of the Fourier transform, or equivalently, from the autocorrelation, is a classical problem known as phase retrieval. Due to the absence of phase information, some form of additional information is required in order to be able to uniquely identify the underlying signal. In this work, we consider the problem of phase retrieval using masks. Due to our interest in developing robust algorithms with theoretical guarantees, we explore a convex optimization-based framework. In this work, we show that two specific masks (each mask provides 2n Fourier magnitude measurements) or five specific masks (each mask provides n Fourier magnitude measurements) are sufficient for a convex relaxation of the phase retrieval problem to provably recover almost all signals (up to global phase). We also show that the recovery is stable in the presence of measurement noise. This is a significant improvement over the existing results, which require O(log<sup>2</sup> n) random masks (each mask provides n Fourier magnitude measurements) in order to guarantee unique recovery (up to global phase). Numerical experiments complement our theoretical analysis and show interesting trends, which we hope to explain in a future publication.","2157-8095;21578095","Electronic:978-1-4673-7704-1; POD:978-1-4673-7705-8; USB:978-1-4673-7703-4","10.1109/ISIT.2015.7282737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282737","autocorrelation;convex optimization;masked signals;phase retrieval;semidefinite programming","Correlation;Extraterrestrial measurements;Fourier transforms;Noise;Noise measurement;Phase measurement;Pollution measurement","Fourier transforms;convex programming;information retrieval;relaxation theory;signal processing","Fourier transform;autocorrelation;convex optimization;phase retrieval problem convex relaxation;signal recovery","","3","1","27","","","14-19 June 2015","","IEEE","IEEE Conference Publications"
"Data arrangement and dimensional compression using Vivaldi for similarity search on structured peer-to-peer network","Y. Sugaya; K. Motoyama; S. Omachi","Tohoku University, Sendai, Japan","2015 IEEE International Conference on Consumer Electronics - Taiwan","20150824","2015","","","39","40","Peer-to-peer system is a promising solution to manage a large amount of data, but similarity search on peer-to-peer network with a restricted small number of messages is a challenging problem. Existing methods that can perform similarity search work only with low-dimensional data. We propose a method to transform the very high-dimensional data into low-dimensional vectors in order to perform similarity search.","","Electronic:978-1-4799-8745-0; POD:978-1-4799-8746-7","10.1109/ICCE-TW.2015.7216959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7216959","","Accuracy;Distributed databases;Indexes;Overlay networks;Peer-to-peer computing;Principal component analysis;Transforms","data analysis;information retrieval;peer-to-peer computing;vectors","Vivaldi;data arrangement;dimensional compression;low-dimensional data;low-dimensional vectors;similarity search;structured peer-to-peer network;very high-dimensional data","","0","","8","","","6-8 June 2015","","IEEE","IEEE Conference Publications"
"User Interface Considerations for Browser-Based Just-in-Time-Retrieval","C. Seifert; J. Schlötterer; M. Granitzer","Univ. of Passau, Passau, Germany","2015 19th International Conference on Information Visualisation","20150921","2015","","","460","467","With the availability of free online enrichment services injection of additional, external resources in existing Web content becomes more and more widespread. For the specific area of just-in-time retrieval of digital resources based on web page content, there are no specific guidelines of how to design and integrate the additional user interface components. In this paper, we conceptualise related user interface issues, investigating the central questions: (i) how can a user be visually notified that additional results are available, and (ii) with which user interface elements should the results be presented. Concretely, we identified four different notification styles and six different result presentation styles. In a survey-based study with 75 participants we elicited the users' preferences, revealing a clear preference for the representation style (split pane) and a strong preference for three notification styles (notification bubble, icon appearance and change of icon's appearance). The latter preferences are related to the preferred browser. The results can serve as guideline for designing web-based user interfaces for just-in-time retrieval.","1550-6037;15506037","Electronic:978-1-4673-7568-9; POD:978-1-4673-7569-6","10.1109/iV.2015.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272642","just-in-time retrieval;user issues;web browser","Browsers;Context;Electronic mail;Guidelines;User interfaces;Visualization;Web pages","Internet;information retrieval;online front-ends;user interfaces","Web page content;Web-based user interface design;browser-based just-in-time-retrieval;digital resources;free online enrichment services","","","","12","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Word concept extraction using HOSVD for automatic text summarization","A. Biyabangard; M. S. Abadeh","Faculty of Computer and Information Technology Engineering Qazvin Branch, Islamic Azad University Qazvin, Iran","2015 AI & Robotics (IRANOPEN)","20150921","2015","","","1","6","Computers understand little about the meaning of human language. Vector space models of semantics are beginning to overcome these limits. In this regard, one of the modern issues is using high dimensional data, which is formulated as tensors. Also, due to the increased information and texts, automatic text summarization has become one of the most important issues in information retrieval and natural language processing. In this paper, we propose a new method, using higher-order singular value decomposition (HOSVD) for extracting the concept of the words from word-document-time three-dimensional tensor and then select important sentences with more cosine similarity to this concept. In the following, we measure WordNet-based semantic similarity between sentences and remove redundancy sentences with less importance. The evaluation of the proposed method is done using the ROUGE evaluation on the DUC 2007 standard data set that the obtained results indicate the predominance of our method over many dominant systems.","","Electronic:978-1-4799-8733-7; POD:978-1-4799-8734-4","10.1109/RIOS.2015.7270733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270733","Multi-document summarization;higher-order singular value decomposition;tensor decomposition","Computers;Data mining;Matrix decomposition;Redundancy;Semantics;Singular value decomposition;Tensile stress","information retrieval;natural language processing;singular value decomposition;tensors;text analysis;vectors;word processing","DUC 2007 standard data set;HOSVD;ROUGE evaluation;WordNet-based semantic similarity;automatic text summarization;cosine similarity;high dimensional data;higher-order singular value decomposition;information retrieval;natural language processing;vector space models;word concept extraction;word-document-time 3D tensor","","","","21","","","12-12 April 2015","","IEEE","IEEE Conference Publications"
"A Cloud-Focused Mobile Forensics Methodology","Q. Do; B. Martini; K. K. R. Choo","University of South Australia","IEEE Cloud Computing","20150916","2015","2","4","60","65","The ubiquity of the smartphone means that there is a high probability that a suspect under investigation uses one. Because of society's growing dependence on smartphones, such devices will likely contain a wealth of incriminating data such as emails, text messages, phone logs, and sensitive documents. Furthermore, with the prevalence of cloud-based storage, it is also possible that the evidential data that forensic investigators seek would not be located directly on the device. Thus, there is a need for a forensically sound and specialized methodology to access this remote data, which might be critical in a forensic investigation. This column describes one such methodology.","2325-6095;23256095","","10.1109/MCC.2015.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270249","access control;android forensics;cloud;cloud and the law;cloud forensics;cloud storage","Authentication;Cloud computing;Databases;Forensics;Mobile communication;Smart phones;XML","cloud computing;digital forensics;information retrieval;law administration;mobile computing;smart phones","cloud-based storage;cloud-focused mobile forensics methodology;emails;evidential data;forensic investigation;forensic investigators;forensically sound methodology;incriminating data;phone logs;remote data access;sensitive documents;smartphone ubiquity;specialized methodology;text messages","","7","","9","","","July-Aug. 2015","","IEEE","IEEE Journals & Magazines"
"Public audit on dynamic data preserving user identity and data freshness","K. Swathy; N. Velvizhi","Department of Computer Science and Engineering, R.M.D Engineering College, Thiruvallur Dist-601206, Tamilnadu, India","2014 Sixth International Conference on Advanced Computing (ICoAC)","20150831","2014","","","32","35","In Cloud, data can be stored and retrieved by data owner and also by several users. The consistency of data which is stored is not ensured properly, because of hardware and software failure and also due to error made by humans. Several mechanisms are available that allows the public verifiers to audit data stored in the cloud with no need of retrieving the whole data from cloud server. Usually public auditing might reveal private and confidential information to public verifiers. In the Existing system public auditing is done and it maintains private identity of users while supporting batch audit, but does not prove data freshness and support traceability. In this proposed system, batch auditing can be done that support dynamic operations by computing signatures that preserves structures and using an index hash table. It also ensures data freshness during public auditing. The future enhancement can be done on ability of group manager revealing the identity of the user in some special situations.","2377-6927;23776927","Electronic:978-1-4799-8159-5; POD:978-1-4799-8160-1","10.1109/ICoAC.2014.7229741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7229741","Batch auditing;Data freshness;Dynamic operations;Identity preserving;Public auditing","Authentication;Cryptography;Privacy;Service computing","auditing;cloud computing;data privacy;information retrieval","batch auditing;cloud server;computing signatures;data consistency;data freshness preservation;data retrieval;data storage;dynamic data;dynamic operations;hardware failure;index hash table;public auditing;public verifiers;software failure;user identity preservation","","0","","9","","","17-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"The study of document filter for smart device","S. Jo; J. Kim; D. Choi","Cryptography Research Section, Cyber Security Research Division, ETRI (Electronics and Telecommunications Research Institute), Daejeon, Korea","2015 17th Asia-Pacific Network Operations and Management Symposium (APNOMS)","20150928","2015","","","515","518","Document filter extracts text of UTF-16, Unicode or UTF-8 format from documents files of smart device. The extracted text is used at viewer and index search of smart device. This paper researches document filter of text based smart device files. The result of this research is useful to develop the mobile device search, which lets you find easily all your docs, pdf, text and email on smart device.","","Electronic:978-4-8855-2296-3; POD:978-1-4673-7226-8","10.1109/APNOMS.2015.7275388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275388","Document Filter;Smart Devices","Encoding;Forensics;HTML;Indexes;Portable document format;Smart phones","file organisation;information retrieval;text detection","UTF-16 format;UTF-8 format;Unicode format;document filter;documents files;index search;mobile device search;text based smart device files","","","","6","","","19-21 Aug. 2015","","IEEE","IEEE Conference Publications"
"Source code retrieval on StackOverflow using LDA","A. Arwan; S. Rochimah; R. J. Akbar","Department of Informatics, Faculty of Computer Science, University of Brawijaya, Malang, Indonesia","2015 3rd International Conference on Information and Communication Technology (ICoICT)","20150903","2015","","","295","299","Internet code search is quite popular research area. StackOverflow allows developers to ask and answer questions about code. Previous approach to search code on StackOverflow uses tf-idf method that based on number of occurrences of words to recommend source code. This method has the disadvantage that variable or method identifiers are considered as normal words, even though identifiers are often a combination of two or more words. For example, there is an identifier named “randomString”. In that case, if we search using a keyword “random” the system probably will not recommend “randomString” because both words are different. Concept location can tackle this problem. Concept location has been used widely to obtain the correlation between code with a specific concepts or features. Previous research of concept location only focused on source code's comments, and relation among the objects within the source code. This research proposes a mechanism for finding code on StackOverflow uses Latent Dirichlet Allocation (LDA) using concept location in the preprocessing stage. Questions, answers, and code snippets about Java programming are downloaded from StackOverflow to a local repository. Corpuses are generated by extracting questions, answers and code snippets. Inferencing concept location from source code is created using LDA algorithm. Developers query concepts and then system will recommend source code based on the relevant concepts. The result of the experiment shows that the system is able to recommend source code with 48% average of precision and 58% average of recall.","","DVD:978-1-4799-7751-2; Electronic:978-1-4799-7752-9; POD:978-1-4799-7753-6","10.1109/ICoICT.2015.7231439","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7231439","Concept Location;Latent Dirichlet Allocation;Source Code Searching","Conferences;Data preprocessing;Java;Programming;Resource management;Software","Java;query processing;question answering (information retrieval);recommender systems;source code (software)","Internet code search;Java programming;LDA algorithm;StackOverflow;code snippets;concept location;corpus generation;latent Dirichlet allocation;local repository;method identifiers;normal words;precision value;query concepts;question answering;question asking;randomString identifier;recall value;source code recommendation;source code retrieval;tf-idf method;variable identifiers;word occurrences","","0","","20","","","27-29 May 2015","","IEEE","IEEE Conference Publications"
"A personal agents hybrid architecture for question answering featuring social dialog","M. Coronado; C. A. Iglesias; A. Mardomingo","Intelligent Systems Group, Universidad Polit&#x00E9;cnica de Madrid, Madrid, Spain","2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)","20150928","2015","","","1","8","There exists a growing trend in using NLIs (Natural Language Interfaces) that ranges from research to commercial products. Conversational agents beneath these interfaces have become more sophisticated, being able to either perform a task in behalf of the user or give a precise response to a question as Question Answering systems do. When combining Conversational Agents with QA capabilities the maintenance cost exponentially increases. In this paper we propose a hybrid architecture for a Question Answering system that features social dialog. We claim that including social dialog in QA systems increases users satisfaction and makes them easily engage with the system. Finally, we present an evaluation that supports these hypotheses.","","Electronic:978-1-4673-7751-5; POD:978-1-4673-7752-2; USB:978-1-4673-9096-5","10.1109/INISTA.2015.7276780","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7276780","","Data mining;Knowledge based systems;Knowledge discovery;Natural languages;Ontologies;Semantics;Speech","multi-agent systems;natural language interfaces;question answering (information retrieval)","NLIs;QA systems;conversational agents;maintenance cost;natural language interfaces;personal agents hybrid architecture;question answering systems;social dialog","","","","38","","","2-4 Sept. 2015","","IEEE","IEEE Conference Publications"
"An Audio and Image-Based On-Demand Content Annotation Framework for Augmenting the Video Viewing Experience on Mobile Devices","V. Gatteschi; F. Lamberti; A. Sanna; C. Demartini","Dipt. di Autom. e Inf., Politec. di Torino, Turin, Italy","2015 IEEE International Conference on Mobile Services","20150827","2015","","","468","472","The availability of annotated multimedia contents is a crucial requirement for a number of applications. In the context of education it could support the automatic summarization of recorded lessons or the retrieval of learning material. In the field of entertainment, it could serve to recommend audio and video resources based on user's attitudes. In this work, a framework supporting video viewing experience augmentation on mobile devices by means of image- and text-based annotations extracted on-demand from Wikipedia is presented. Speech recognition is exploited to periodically get text snaps from the audio track of the video currently displayed on the mobile device, while query-by-images is used to generate a text summary of extracted video frames. Keywords obtained are treated by semantic techniques to find named entities associated with the multimedia contents, which are then superimposed to the video and displayed to the user in a synchronized way. Promising results obtained with a prototype implementation showed the feasibility of the proposed solution, which could be possibly combined with other systems, e.g., Providing information about user's location, preferences, etc. To build up more sophisticated context-aware applications.","2329-6429;23296429","Electronic:978-1-4673-7284-8; POD:978-1-4673-7285-5","10.1109/MobServ.2015.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226727","Wikipedia;multimedia content annotation;query by images;semantics;speech recognition","Conferences;Mobile communication","computer aided instruction;content management;entertainment;information retrieval;mobile computing;multimedia computing;speech recognition;video signal processing","Wikipedia;audio-based on-demand content annotation framework;automatic summarization;context-aware applications;education;entertainment;image-based on-demand content annotation framework;learning material retrieval;mobile devices;multimedia contents;speech recognition;video viewing","","0","","13","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Automatic music genre classification using timbral texture and rhythmic content features","B. K. Baniya; D. Ghimire; J. Lee","Division of Computer Science and Engineering, Chonbuk National University, Jeonju 761-756, South Korea","2015 17th International Conference on Advanced Communication Technology (ICACT)","20150827","2015","","","434","443","Music genre classification is a vital component for the music information retrieval system. There are two important components to be considered for better genre classification, which are audio feature extraction and classifier. This paper incorporates two different kinds of features for genre classification, timbral texture and rhythmic content features. Timbral texture contains the Mel-frequency Cepstral Coefficient (MFCC) with other several spectral features. Before choosing a timbral feature we explore which feature contributes a less significant role on genre discrimination. This facilitates the reduction of feature dimension. For the timbral features up to the 4-th order central moments and the covariance components of mutual features are considered to improve the overall classification result. For the rhythmic content the features extracted from beat histogram are selected. In the paper Extreme Learning Machine (ELM) with bagging is used as the classifier for classifying the genres. Based on the proposed feature sets and classifier, experiments are performed with two well-known datasets: GTZAN and the ISMIR2004 databases with ten and six different music genres, respectively. The proposed method acquires better and competitive classification accuracy compared to the existing approaches for both data sets.","1738-9445;17389445","CD-ROM:978-8-9968-6504-9; Electronic:978-8-9968-6505-6; POD:978-1-4673-8116-1","10.1109/ICACT.2015.7224907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224907","Classification;ELM (Extreme Learning Machine) with bagging;covariance matrix;music genres;rhythmic contents;timbral texture","Bagging;Feature extraction;Histograms;Mel frequency cepstral coefficient;Speech;Standards","audio signal processing;feature extraction;information retrieval systems;learning (artificial intelligence);music;signal classification","ELM with bagging;GTZAN database;ISMIR2004 database;MFCC;Mel-frequency cepstral coefficient;audio feature classifier;audio feature extraction;classification accuracy;extreme learning machine;feature dimension reduction;genre discrimination;music genre classification;music information retrieval system;rhythmic content feature;timbral texture","","0","","27","","","1-3 July 2015","","IEEE","IEEE Conference Publications"
"State-Driven and Brick-Based Mobile Mashup","S. P. Ma; Y. S. Ma; W. T. Lee","Dept. of Comput. Sci. & Eng., Nat. Taiwan Ocean Univ., Keelung, Taiwan","2015 IEEE International Conference on Mobile Services","20150827","2015","","","190","196","Mobile applications (i.e., Mobile apps or apps) are becoming an important software delivery model. Users can employ a wide range of services associated with mobile apps, such as entertainment, news, travel, and social networking. Unfortunately, the retrieval of information from multiple apps, services, or local resources can be time-consuming, costly, and inconvenient. This paper proposes a novel mobile mash up approach, referred to as brick-based, state-driven mobile service composition (BSMSC) to overcome these difficulties. BSMSC comprises two primary mechanisms: (1) Android-fragment-based service bricks, and (2) a state-driven linkage for composite Restful services, which supports one-shot service flow execution as well as stateful service flow execution. The proposed BSMSC approach makes it possible to assemble fully-fledged, reconfigurable mobile mash up applications.","2329-6429;23296429","Electronic:978-1-4673-7284-8; POD:978-1-4673-7285-5","10.1109/MobServ.2015.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226689","RESTful service composition;mobile mashup;service brick","Androids;Couplings;Engines;Humanoid robots;Mashups;Mobile communication","Android (operating system);information retrieval;mobile computing","Android-fragment-based service bricks;BSMSC;brick-based mobile mashup;brick-based state-driven mobile service composition;composite Restful services;information retrieval;one-shot service flow execution;software delivery model;state-driven mobile mashup;stateful service flow execution","","1","","18","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Wrapper induction of news information for feeding to social networking service on smartphone","Z. L. Xiang; X. R. Yu; D. K. Kang","Computer Software Institute, Weifang University of Science & Technology, Shouguang 262-700, Shandong, China","2015 17th International Conference on Advanced Communication Technology (ICACT)","20150827","2015","","","292","295","In this paper, we propose NewsFeedAndroid, a novel system that interconnects a social networking service and online newspaper sites in order to extracts news articles from the online news sites and to perform feeding of news articles to social network service (SNS) users. In NewsFeedAndroid, news information agents extract news article information from the news and portal sites using Minimum Description Length (MDL) wrapper induction algorithm. The news document collecting module regularly gathers news list information from news list page in the news sites and portals. In the collected documents, the document preprocessing module removes tags that are unnecessary for news information extraction. Lexical analyzer converts the rest text information and tags to a sequence of tokens, and news information is obtained by matching token patterns to the sequence. Those extracted news information from the various sites are integrated in the system and supplied to the end users through the social networking service on a smartphone. NewsFeedAndroid demonstrates a novel usage of integrating social networking services and online newspaper sites.","1738-9445;17389445","CD-ROM:978-8-9968-6504-9; Electronic:978-8-9968-6505-6; POD:978-1-4673-8116-1","10.1109/ICACT.2015.7224806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224806","Cellphone;Minimum description length;NewsFeedAndroid;Smartphone;Social network service;Wrapper","Computers;Data mining;HTML;Social network services;Visualization","Internet;feature extraction;information retrieval;mobile computing;smart phones;social networking (online);string matching","MDL wrapper induction algorithm;NewsFeedAndroid;SNS;minimum description length;news article information extraction;news information feeding;online newspaper site;smart phone;social networking service;token pattern matching","","0","","21","","","1-3 July 2015","","IEEE","IEEE Conference Publications"
"Synonym Suggestion for Tags on Stack Overflow","S. Beyer; M. Pinzger","Software Eng. Res. Group, Univ. of Klagenfurt, Klagenfurt, Austria","2015 IEEE 23rd International Conference on Program Comprehension","20150907","2015","","","94","103","The amount of diverse tags used to classify posts on Stack Overflow increased in the last years to more than 38,000 tags. Many of these tags have the same or similar meaning. Stack Overflow provides an approach to reduce the amount of tags by allowing privileged users to manually create synonyms. However, currently exist only 2,765 synonym-pairs on Stack Overflow that is quite low compared to the total number of tags. To comprehend how synonym-pairs are built, we manually analyzed the tags and how the synonyms could be created automatically. Based on our findings, we then present TSST, a tag synonym suggestion tool, that outputs a ranked list of possible synonyms for each input tag. We first evaluated TSST with the 2,765 approved synonym-pairs of Stack Overflow. For 88.4% of the tags TSST finds the correct synonyms, for 72.2% the correct synonym is within the top 10 suggestions. In addition, we applied TSST to 10 randomly selected Android related tags and evaluated the suggested synonyms with 20 Android app developers in an online survey. Overall, in 80% of their ratings, developers found an adequate synonym suggested by TSST.","1092-8138;10928138","Electronic:978-1-4673-8159-8; POD:978-1-4673-8160-4","10.1109/ICPC.2015.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181436","Stack Overflow;synonyms;tags","Accuracy;Androids;Databases;Humanoid robots;Java;Radiation detectors;Terminology","Internet;question answering (information retrieval)","Android app;Stack Overflow;Web 2.0;social bookmarking;synonym-pairs;tag synonym suggestion tool","","1","","27","","","18-19 May 2015","","IEEE","IEEE Conference Publications"
"Social-P2P: An Online Social Network Based P2P File Sharing System","H. Shen; Z. Li; K. Chen","Department of Electrical and Computer Engineering, Clemson University, Clemson, SC","IEEE Transactions on Parallel and Distributed Systems","20150907","2015","26","10","2874","2889","A peer-to-peer (P2P) file sharing system provides a platform that enables a tremendous number of nodes to share their files. Retrieving desired files efficiently and trustworthily is critical in such a large and jumbled system. However, the issues of efficient searching and trustworthy searching have only been studied separately. Simply combining the methods to achieve the two goals doubles system overhead. In this paper, we first study trace data from Facebook and BitTorrent. Guided by the observations, we propose a system that integrates a social network into a P2P network, named Social-P2P, for simultaneous efficient and trustworthy file sharing. It incorporates three mechanisms: (1) interest/trust-based structure, (2) interest/trust-based file searching, and (3) trust relationship adjustment. By exploiting the social interests and relationships in the social network, the interest/trust-based structure groups common-multi-interest nodes into a cluster and further connects socially close nodes within a cluster. The comparably stable nodes in each cluster form a Distributed Hash Table (DHT) for inter-cluster file searching. In the interest/trust-based file searching mechanism, a file query is forwarded to the cluster of the file by the DHT routing first. Then, it is forwarded along constructed connections within a cluster, which achieves high hit rate and reliable routing. Moreover, sharing files among socially close friends discourages nodes from providing faulty files because people are unlikely to risk their reputation in the real-world. In the trust relationship adjustment mechanism, each node in a routing path adaptively decreases its trust on the node that has forwarded a faulty file in order to avoid routing queries towards misbehaving nodes later on. We conducted extensive trace-driven simulations and implemented a prototype on PlanetLab. Experimental results show that Social-P2P achieves highly efficient and trustworthy file sharing compared to current fi- e sharing systems and trust management systems.","1045-9219;10459219","","10.1109/TPDS.2014.2359020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6902795","P2P networks;file sharing;online social networks","Facebook;Maintenance engineering;Peer-to-peer computing;Routing;Servers;Vectors","file organisation;information retrieval;peer-to-peer computing;social networking (online);trusted computing","BitTorrent;DHT;Facebook;P2P file sharing system;Social-P2P;distributed hash table;file retrieval;interest/trust-based file searching;interest/trust-based structure;online social network;peer-to-peer file sharing system;trust relationship adjustment;trustworthy file sharing","","3","","40","","20140918","Oct. 1 2015","","IEEE","IEEE Journals & Magazines"
"Stickipedia: A Search Engine and Repository for Explanatory Analogies","V. Kumar; S. Bhat; N. Pedanekar","Tata Res. Dev. & Design Centre, Tata Consultancy Services, Pune, India","2015 IEEE 15th International Conference on Advanced Learning Technologies","20150917","2015","","","280","284","Sticky learning refers to learning that is retained by a learner over a long period of time. Explanatory analogies are often used by good teachers to explain complex concepts in a sticky manner. Such analogies explain an unfamiliar target concept by mapping it onto a more familiar source concept. However, the use of analogies in teaching and learning often relies on the imagination of individual teachers or the initiative taken by students in finding them. In this paper, we present Stickipedia, an analogy search engine that automatically retrieves analogies populated on the internet for a searched target concept. Based on a student survey, we also suggest attributes of analogies which could aid students in choosing the analogies they prefer. We populate some of these attributes in Stickipedia for the retrieved analogies.","2161-3761;21613761","Electronic:978-1-4673-7334-0; POD:978-1-4673-7335-7","10.1109/ICALT.2015.106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265326","Analogy;Explanation;Search;Sticky learning","Cache memory;Computer science;Education;Google;Heating;Internet;Search engines","Internet;computer aided instruction;information retrieval;search engines;teaching","Internet;Stickipedia;analogy retrieval;explanatory analogy;learning analogy;repository;search engine;sticky learning;teaching analogy","","","","28","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"An optimal replica relocation scheme for improving service availability in mobile Ad Hoc Networks","K. Muralidhar; N. P. Bharathi","Department of Computer Science & Engineering, Ananthalakshmi Institute of Technology & Sciences, Anantapuramu, Andhra Pradesh, India","2014 IEEE International Conference on Computational Intelligence and Computing Research","20150907","2014","","","1","4","This paper proposes an optimal replica relocation scheme improving service availability in Mobile Ad Hoc Networks (MANETs) that relocates replicas as necessary so that the actual data items are available to the nodes which are in need of them. Since MANET's topology is highly dynamic, data items should be made available to the nodes that are required by them in a minimum distance. The nodes which initially store data may move far because of the dynamic topology and the nodes that are selected for relocation should be nearer to the nodes that are in need of them. Also the nodes which store the replicas may drain out in servicing excessive data access requests. This proposed scheme not only considers the minimum distance parameter, but also considers the vital parameters like storage availability, and residual energy parameters in selecting the node for relocation. The proposed scheme was implemented in NS2 and when compared to the no relocation scheme, our proposed scheme proved to be superior.","","Electronic:978-1-4799-3975-6; POD:978-1-4799-3976-3","10.1109/ICCIC.2014.7238375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7238375","MANETs;distance;relocation;replicas;residual energy;service availability;storage","Heuristic algorithms;Mobile ad hoc networks;Mobile computing;Mobile nodes;Resource management","information retrieval;mobile ad hoc networks;telecommunication network topology;telecommunication power management;telecommunication services","MANET;data access requests;dynamic topology;mobile ad hoc networks;optimal replica relocation scheme;residual energy parameters;service availability","","0","","13","","","18-20 Dec. 2014","","IEEE","IEEE Conference Publications"
"An improved algorithm for locality-sensitive hashing","W. Cen; K. Miao","School of Information Science and Engineering, Xiamen University Xiamen, China","2015 10th International Conference on Computer Science & Education (ICCSE)","20150910","2015","","","61","64","We present an improved Locality-Sensitive Hashing for similarity search under high dimension search. Our scheme improves the running time based on the earlier algorithm Locality-Sensitive Hashing for hamming distance and euclidean distance. In this paper we have collected a database of The MNIST DATABASE, we proposed nearest neighbor search in the database and can get a good result in an acceptable time. The experimental results show that our data structure is up to about 10 times faster than ordinary Locality-Sensitive Hashing when working on a database of 60000 samples. At the same time, the accuracy rate and recall rate are higher than earlier algorithms.","","Electronic:978-1-4799-6600-4; POD:978-1-4799-6601-1; USB:978-1-4799-6599-1","10.1109/ICCSE.2015.7250218","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7250218","Locality-Sensitive Hashing;data structure;high dimension;nearest neighbor","Accuracy;Data structures;Euclidean distance;Hamming distance;Indexes;Nearest neighbor searches","database management systems;file organisation;information retrieval","Euclidean distance;Hamming distance;The MNIST database;locality-sensitive hashing;nearest neighbor search;similarity search","","1","","16","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Multilevel diversity coding with regeneration","C. Tian; T. Liu","Dept. of Electrical Engineering and Computer Science, The University of Tennessee Knoxville, TN 37996, USA","2015 IEEE International Symposium on Information Theory (ISIT)","20151001","2015","","","844","848","The digital contents in large distributed storage systems may have different reliability and access delay requirements, and for this reason, erasure codes with different strengths need to be utilized to achieve the best storage efficiency. At the same time, in such large distributed storage systems, nodes fail on a regular basis, and the contents stored on them need to be regenerated and stored on other healthy nodes. We formulate the problem of multilevel diversity coding with regeneration to address these considerations, for which the storage vs. repair-bandwidth tradeoff is investigated. We show that the extreme point on this tradeoff corresponding to the minimum possible storage can be achieved by a simple coding scheme, where contents with different reliability requirements are encoded separately using individual regenerating codes without any mixing. On the other hand, we completely characterize the optimal storage-repairbandwidth tradeoff for the case of four storage nodes, and show that a non-vanishing gap exists between the optimal tradeoffs of mixing and non-mixing solutions.","2157-8095;21578095","Electronic:978-1-4673-7704-1; POD:978-1-4673-7705-8; USB:978-1-4673-7703-4","10.1109/ISIT.2015.7282574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282574","Data storage;regenerating codes","Bandwidth;Bismuth;Encoding;Maintenance engineering;Reliability;Writing","encoding;information retrieval;reliability;storage area networks","access delay;coding scheme;digital contents;distributed storage systems;erasure codes;multilevel diversity coding;optimal storage-repair bandwidth tradeoff;regenerating codes;regeneration;reliability;storage efficiency;storage nodes","","2","","12","","","14-19 June 2015","","IEEE","IEEE Conference Publications"
"Early result from adaptive combination of LRU, LFU and FIFO to improve cache server performance in telecommunication network","Tanwir; G. Hendrantoro; A. Affandi","Department of Electrical Engineering, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2015 International Seminar on Intelligent Technology and Its Applications (ISITIA)","20150827","2015","","","429","432","telecommunications system network server is a multimedia storage medium, load server is storing data transmission can be reduced with an additional caches servers which store data while making it easier for clients to access informations. The more clients to access information causing increasing caches capacity is needed deletion of caches with using a combination of algorithm LRU, LFU and FIFO Queue method, in time of the initial data to be deleted (FIFO), the other algorithm will detect if such data has the most references (LFU) or LRU algorithm so that frequently accessed data to be stored is cached it will reduce delay time, Throughput and Loss Browsing.","","DVD:978-1-4799-7709-3; Electronic:978-1-4799-7711-6; POD:978-1-4799-7712-3","10.1109/ISITIA.2015.7220019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7220019","Algorithms;Cache Server;FIFO;LFU;LRU","Cache memory;Delays;Multimedia communication;Object recognition;Servers;Telecommunications;Throughput","Internet;cache storage;client-server systems;information retrieval;network servers","FIFO queue method;LFU queue method;LRU queue method;cache server performance improvement;caches capacity;clients access;data transmission storage;delay time reduction;load server;loss browsing reduction;multimedia storage medium;telecommunication system network server;throughput reduction","","0","","10","","","20-21 May 2015","","IEEE","IEEE Conference Publications"
"Use Case Model of QoS with Extensible Registry Protocol","A. Kaur; R. Soni","Dept. of Comput. Applic., Chitkara Univ., Rajpura, India","2015 Fifth International Conference on Communication Systems and Network Technologies","20151001","2015","","","297","302","Web Services provides almost similar functionalities, but finding best service is the basic objective of this paper. In this paper, focus on quantifiable measurements is done. The main objective of this paper is to investigate how dynamic web service discovery can be realized to satisfy a customer's QoS requirements using an approach that can be accommodated within existing basic web service protocols like UDDI, WSDL, but the limitation of UDDI is that it provides syntactic information only .To solve this problem, we proposed a quality manager to handle quality database along with UDDI as well as proposed a model of rating similar web service. The model provides quick discovery with high probability of web services.","","Electronic:978-1-4799-1797-6; POD:978-1-4799-1798-3","10.1109/CSNT.2015.277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279928","Agent;OWL;QoS;SOAP;UDDI;WSDL","Databases;Protocols;Quality of service;Semantic Web;Simple object access protocol;XML","Web services;information retrieval;protocols;quality of service","QoS;UDDI porotocol;Web service protocol;dynamic web service discovery;extensible registry protocol;quality database;quality manager;use case model","","","","20","","","4-6 April 2015","","IEEE","IEEE Conference Publications"
"Personalized Internet Advertisement Recommendation Service Based on Keyword Similarity","W. H. Hwang; Y. S. Chen; T. M. Jiang","Dept. of Comput. Sci., Nat. Taipei Univ. of Educ., Taipei, Taiwan","2015 IEEE 39th Annual Computer Software and Applications Conference","20150924","2015","1","","29","33","Internet advertising, or E-Marketing, is an important marketing tool in today's on-line world. This study focus on developing a framework for personalized Internet advertisement recommendation service. At first, all the advertisements are categorized by referring to the commercial categories provided by Yahoo. Then, keywords are extracted from each advertisement, and the most correlated keywords to each category are identified through Term Frequency and Inverted Domain Frequency (TF-IDF) analysis. Thus, the ontology of the advertisement world is built. Normalized Google Distance (NGD) values between keywords are computed to derive the characteristic vector of each advertisement. Also, through Logistic Regression, the user profile, which describes a user's preferences, is established based on the user's responses to some certain advertisements. Finally, for a new advertisement, a recommendation value is computed by using the characteristic vector of this advertisement and the user profile. The value is thus used to determine whether this advertisement should be recommended to the user or not. A prototype website for verifying the proposed schemes was developed. Experiment results showed that better marketing effectiveness can be achieved with the proposed personalized advertisement recommendation.","","Electronic:978-1-4673-6564-2; POD:978-1-4673-6565-9","10.1109/COMPSAC.2015.202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273289","component; Internet advertisement; Recommendation; Term Frequency and Inverted Domain Frequency; Normalized Google Distance; Logistic","Advertising;Frequency-domain analysis;Google;Internet;Logistics;Ontologies;Prototypes","Internet;advertising;data mining;information retrieval;ontologies (artificial intelligence);recommender systems;regression analysis","E-marketing;Internet advertising;Normalized Google Distance;TF-IDF analysis;Website;Yahoo;advertisement categorization;commercial categories;inverted domain frequency;keyword NGD values;keyword extraction;keyword similarity;logistic regression;marketing effectiveness;marketing tool;ontology;personalized Internet advertisement recommendation service;recommendation value;term frequency;user preference;user profile;user response","","1","","10","","","1-5 July 2015","","IEEE","IEEE Conference Publications"
"Around the web in six weeks: Documenting a large-scale crawl","S. T. Ahmed; C. Sparkman; H. T. Lee; D. Loguinov","Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843, USA","2015 IEEE Conference on Computer Communications (INFOCOM)","20150824","2015","","","1598","1606","Exponential growth of the web continues to present challenges to the design and scalability of web crawlers. Our previous work on a high-performance platform called IRLbot [28] led to the development of new algorithms for realtime URL manipulation, domain ranking, and budgeting, which were tested in a 6.3B-page crawl. Since very little is known about the crawl itself, our goal in this paper is to undertake an extensive measurement study of the collected dataset and document its crawl dynamics. We also propose a framework for modeling the scaling rate of various data structures as crawl size goes to infinity and offer a methodology for comparing crawl coverage to that of commercial search engines.","0743-166X;0743166X","Electronic:978-1-4799-8381-0; POD:978-1-4799-8382-7","10.1109/INFOCOM.2015.7218539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7218539","","Admission control;Bandwidth;Crawlers;HTML;Robots;Servers;Uniform resource locators","information retrieval;search engines","IRLbot platform;URL manipulation;Web crawlers;budgeting;crawl coverage;crawl dynamics;crawl size;data structures;domain ranking;large-scale crawl documentation","","0","","42","","","April 26 2015-May 1 2015","","IEEE","IEEE Conference Publications"
"A novel cost effective access control and auto filling form system using QR code","D. Khandal; D. Somwanshi","Department of CSE, Poornima College of Engineering, Jaipur, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","1","5","QR codes are used to store information in two dimensional grids which can be decoded quickly. The proposed work here deals with Quick response (QR) code extending its encoding and decoding implementation to design a new articulated user authentication and access control mechanism. The work also proposes a new simultaneous registration system for offices and organizations. The proposed system retrieves the candidate's information from their QR identification code and transfers the data to the digital application form, along with granting authentication to authorized QR image from the database. The system can improve the quality of service and thus it can increase the productivity of any organization.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275575","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275575","Authentication;Automated filling form;Code Reader;Embedded system;Encoding-Decoding;Proteus;QR codes;Security","Decoding;Handwriting recognition;IEC;ISO;Image recognition;Magnetic resonance imaging;Monitoring","QR codes;authorisation;cryptography;decoding;image coding;information retrieval;information storage;quality of service","QR identification code;articulated user authentication design;authorized QR image;auto filling form system;candidate information retrieval;cost effective access control system;data transfer;decoding implementation;digital application form;encoding implementation;information storage;offices;organizations;quality of service improvement;quick response code;registration system;two-dimensional grid","","","","13","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Security issues related to web services in e-commerce","P. Chandratre; U. Kulkarni","ME computer, Vidyalankar Institute of Technology, Mumbai, India","2014 International Conference on Advances in Communication and Computing Technologies (ICACACT 2014)","20150903","2014","","","1","5","E-commerce web sites how to use web mining technology for providing security on e-commerce web sites. The connection between web mining security and ecommerce analyzed based on user behavior on web. Different web mining algorithms and security algorithm are used to provided security on e-commerce web sites. Based on customer behavior different web mining algorithms like page rank algorithm and trust rank algorithm is used for developing web mining framework in e-commerce web sites. This application will develop false hit database algorithm and nearest neighbor algorithm to provide security on e-commerce web site.","","CD-ROM:978-1-4799-7317-0; Electronic:978-1-4799-7319-4; POD:978-1-4799-7320-0","10.1109/EIC.2015.7230735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230735","E- commerce;Security;Web mining","Algorithm design and analysis;Business;Security;Web mining;Web pages","Web services;data mining;electronic commerce;information retrieval;security of data","Web mining technology;Web services;customer behavior;e-commerce;electronic commerce;false hit database algorithm;nearest neighbor algorithm;page rank algorithm;security issues;trust rank algorithm;user behavior","","0","","9","","","10-11 Aug. 2014","","IEEE","IEEE Conference Publications"
"Supporting Data Driven Access through Automatic Keyword Extraction and Summarization","W. Xu; W. Luo; N. Woodward; Y. Zhang","Univ. of Texas at Austin, Austin, TX, USA","2015 IEEE International Congress on Big Data","20150820","2015","","","704","707","The ever-increasing user generated digital data available through the Internet has become an important source of information for individuals, organizations and government agencies. And yet, for users to fully discover and utilize those information remains a complex tasks. Existing popular information access models based on keyword and/or facet searches become less effective in providing access to specific sets of user generated data. To address their limitation, we propose an approach where keywords and summarization of subset of document could be automatically generated during an interactive user session to facilitate user's information seeking process. In this paper, we present our preliminary development including a new algorithm for keyword extraction and summarization generation simultaneously over a subset of documents and visual representations of those results to assist user explorations.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207297","Web archive;keyword extraction;visual exploration","Clustering algorithms;Data mining;Data visualization;Internet;Tag clouds;Visual analytics","Internet;information retrieval;text analysis","Internet;automatic keyword extraction;data driven access;facet searches;government agencies;information access models;information seeking process;interactive user session;organizations;summarization generation;user explorations;user generated digital data;visual representations","","0","","20","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Achieving secure and scalable data access control in information-centric networking","Q. Zheng; G. Wang; R. Ravindran; A. Azgin","Huawei Research Center, Santa Clara, CA, USA","2015 IEEE International Conference on Communications (ICC)","20150910","2015","","","5367","5373","Shifting from host-oriented to data-oriented, information-centric networking (ICN) adopts several key design principles, e.g., in-network caching, to cope with the tremendous internet growth. In the ICN setting, data to be distributed can be cached by ICN routers anywhere and accessed arbitrarily by customers without data publishers' permission, which imposes new challenges when achieving data access control: (i) security: How can data publishers protect data confidentiality (either data cached by ICN routers or data accessed by authorized users) even when an authorized user's decryption key was revoked or compromised, and (ii) scalability: How can data publishers leverage ICN's promising features and enforce access control without complicated key management or extensive communication. This paper addresses these challenges by using the new proposed dual-phase encryption that uniquely combines the ideas from one-time decryption key, proxy re-encryption and all-or-nothing transformation, while still being able to leverage ICN's features. Our analysis and performance show that our solution is highly efficient and provable secure under the existing security model.","1550-3607;15503607","Electronic:978-1-4673-6432-4; POD:978-1-4673-6430-0","10.1109/ICC.2015.7249177","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7249177","","Access control;Distributed databases;Encryption;Public key;Routing protocols","Internet;authorisation;cryptography;information retrieval;telecommunication control;telecommunication network routing","ICN routers;Internet growth;all-or-nothing transformation;data access control;dual-phase encryption;in-network caching;information-centric networking;key management;proxy reencryption;user decryption key","","0","","29","","","8-12 June 2015","","IEEE","IEEE Conference Publications"
"Internet Archives as a Tool for Research: Decay in Large Scale Archival Records","H. Nguyen; M. S. Weber","Dept. of Comput. Sci., Rutgers Univ., New Brunswick, NJ, USA","2015 IEEE International Congress on Big Data","20150820","2015","","","724","727","Web archiving provides social scientists and digital humanities researchers with a data source that enables the study of a wealth of historical phenomena. One of the most notable efforts to record the history of the World Wide Web is the Internet Archive (IA) project, which maintains the largest repository of archived data in the world. Understanding the quality of archived data and the completeness of each record of a single website is a central issue for scholarly research, and yet there is no standard record of the provenance of digital archives. Indeed, although present day records tend to be quite accurate, archived Web content deteriorates as one moves back in time. This paper analyzes a subset or archived Web data, measures the degree of degradation in a subset of data, and proposes statistical inference to such overcome limitations.","2379-7703;23797703","Electronic:978-1-4673-7278-7; POD:978-1-4673-7279-4","10.1109/BigDataCongress.2015.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207302","analytics;archival data;big data;research;statistical validity","Big data;Data mining;Degradation;Internet;Libraries;Standards;Uniform resource locators","Internet;Web sites;information retrieval systems;records management","IA project;Internet archive project;Web archiving;Web site;World Wide Web;archival records;digital archives;historical phenomena;statistical inference","","1","","14","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"The Design and Implementation of Computer Full-Text Search Engine System","B. Zhi-Jing; F. Yan; Y. Jian-Wen; C. Lin","Nanchang Branch, Jiangxi Broadcast&TV Univ., Nanchang, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","1163","1167","This article mainly aims at the design principle and architecture of the full-text search engines and make corresponding analysis, based on various sources of the implementation of search engine system of some technical research and development, realize the web information extraction, indexing system, etc. In the process of analysis.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263779","Design;Search engine;full-text search;implementation","Computers;Engines;Indexing;Internet;Search engines","Internet;indexing;information retrieval;research and development;search engines","Web information extraction;computer full-text search engine system;design principle;indexing system;technical research and development","","","","4","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"Data-driven detection and context-based classification of maritime anomalies","G. Pallotta; A. L. Jousselme","NATO-STO Centre for Maritime Research and Experimentation (CMRE), La Spezia, Italy","2015 18th International Conference on Information Fusion (Fusion)","20150917","2015","","","1152","1159","Discovering anomalies at sea is one of the critical tasks of Maritime Situational Awareness (MSA) activities and an important enabler for maritime security operations. This paper proposes a data-driven approach to anomaly detection, highlighting challenges specific to the maritime domain. This work builds on unsupervised learning techniques which provide models for normal traffic behaviour. A methodology to associate tracks to the derived traffic model is then presented. This is done by the pre-extraction of contextual information as the baseline patterns of life (i.e., routes) in the area under investigation. In addition to a brief description of the approach to derive the routes, their characterization and representation is presented in support of exploitable knowledge to classify anomalies. A hierarchical reasoning is proposed where new tracks are first associated to existing routes based on their positional information only and “off-route” vessels” are detected. Then, for on-route vessels further anomalies are detected such as “speed anomaly” or “heading anomaly”. The algorithm is illustrated and assessed on a real-world dataset supplemented with synthetic abnormal tracks.","","Electronic:978-0-9824-4386-6; POD:978-1-4799-7404-7; USB:978-0-9824-4387-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266688","","Data mining;Detectors;Feature extraction;Radar tracking;Sea measurements;Tracking;Trajectory","information retrieval;marine engineering;pattern classification;security of data;traffic engineering computing;unsupervised learning","anomaly detection;context-based classification;contextual information pre-extraction;data driven detection approach;hierarchical reasoning;maritime security operation;maritime situational awareness;normal traffic behaviour;off route vessel;on route vessel;synthetic abnormal track;traffic model;unsupervised learning technique","","","","21","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"Anti-scraping application development","A. Haque; S. Singh","Department of Information & Communication Technology, Manipal Institute of Technology, Manipal University, -576104, INDIA","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","869","874","Scraping is the activity of retrieving data from a website, often in an automated manner and without the permission of the owner. This data can further be used by the scraper in whatever way he desires. The activity is deemed illegal, but the change in legality has not stopped people from doing the same. Anti-scraping solutions are being offered as rather expensive services, which although are effective, are also slow. This paper aims to list challenges and proposes mitigations techniques to develop a Software as a Product (SaaP) anti-scraping application for small to medium scale websites.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275720","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275720","","CAPTCHAs;Databases;IP networks;Loading;Security;Servers;Software","Web sites;information retrieval","SaaP;anti-scraping application development;data retrieval;mitigation techniques;small to medium scale Web sites;software as a product","","","","21","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"Design and Application of Reserve Information Dispatching System","L. Chen; J. Liu; C. Zhou","State Grid Corp., China NARI Group Corp. Inf. Technol. & Commun. Co., Nanjing, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","335","338","To ensure the stability and effectiveness of information scheduling business of State Grid, a reserve dispatching mechanism is proposed. Taking the concentrated dispatching requirements of State Grid into full consideration, the mechanism conducts specific research on four major phases, including reserve dispatching detection, Reserve dispatching analysis, Reserve dispatching execution and dispatching data recovery. Based on these steps, experimental results are given to verify that the proposed mechanism is an efficient, economical and reliable reserve dispatching method which exerts much influence on improving the reliability of dispatching monitoring service in State Grid, as well as reducing the risks and costs of information management system.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263579","data recovery;information scheduling;reserve dispatching","Companies;Dispatching;Fault detection;Monitoring;Reliability;Scheduling;Switches","information management;information retrieval;power engineering computing;power generation dispatch;power generation scheduling;smart power grids","State Grid;dispatching data recovery;information management system;information scheduling;reserve dispatching analysis;reserve dispatching detection;reserve dispatching execution;reserve information dispatching system","","","","8","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"Time-Aware Semantic Web Service Recommendation","Y. Lei; Z. Jiantao; Z. Junxing; W. Fengqi; W. Juan","Inner Mongolia Eng. Lab. of Cloud Comput. & Service Software, Inner Mongolia Univ., Hohhot, China","2015 IEEE International Conference on Services Computing","20150820","2015","","","664","671","New Web services are emerging on the Internet, while some other Web services are obsolete for some reasons. Unfortunately, not all services are developed in accordance with rules of loose coupling in the software engineering. The consequence is that some services work well only with other services of older versions. The situation is much worse when we deal with composite services. Moreover, using current technology to discover proper semantic services for a composite service is time-consuming and inaccurate. To deal with these problems, we proposed a Web service similarities measurement method and a recommendation method. Based on ontology and information retrieval techniques, we compute among Web services. Then the similarities are used to classify services according to their topics, functionality and semantics. Our recommendation method is able to recommend proper component services to the composite service according to the history information of invocations and similar composite services. The experiments show that our clustering method, which is based on matrix decomposition and Ontology technologies, is more accurate than others, and our recommendation method has less average error than others in the series of missing rate.","","Electronic:978-1-4673-7281-7; POD:978-1-4673-7282-4","10.1109/SCC.2015.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7207413","Recommendation;Time-aware;ontology;semantic","Collaboration;Computational modeling;Matrix decomposition;Ontologies;Quality of service;Semantics;Web services","Web services;information retrieval;matrix decomposition;ontologies (artificial intelligence);pattern clustering;semantic Web;software engineering","Internet;clustering method;composite service;history information;information retrieval techniques;matrix decomposition;measurement method;ontology technologies;software engineering;time-aware semantic Web service recommendation","","1","","19","","","June 27 2015-July 2 2015","","IEEE","IEEE Conference Publications"
"Trust-based storage in a Kademlia network infected by Sybils","R. Pecori","eCAMPUS University, School of Engineering, Via Isimbardi 10, 22060, Novedrate, CO, Italy","2015 7th International Conference on New Technologies, Mobility and Security (NTMS)","20150924","2015","","","1","5","Coping with multiple false identities, also known as a Sybil attack, is one of the main challenges in securing structured peer-to-peer networks. Poisoning routing tables through these identities may make the process for storing and retrieving resources within a DHT (Distributed Hash Table) extremely difficult and time consuming. We investigate current possible countermeasures and propose a novel adaptive method for making the storage and retrieval process, in a Kademlia-based network, more secure. This is done through the use of a trust-based storage algorithm, exploiting reputation techniques. Our solution shows promising results in thwarting a Sybil attack in a Kademlia network, also in comparison with similar methods.","2157-4952;21574952","Electronic:978-1-4799-8784-9; POD:978-1-4799-8785-6","10.1109/NTMS.2015.7266529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266529","Incorrect storage;Kademlia;Structured peer-to-peer networks;Sybil attack;Trust and reputation","Computational modeling;Conferences;Measurement;Peer-to-peer computing;Positron emission tomography;Routing;Standards","computer network security;information retrieval;information storage;peer-to-peer computing;telecommunication network routing;trusted computing","DHT;Kademlia network;Sybil attack;distributed hash table;peer-to-peer networks;reputation techniques;retrieval process;routing tables;storage process;trust-based storage algorithm","","","","27","","","27-29 July 2015","","IEEE","IEEE Conference Publications"
"Consensus: A comprehensive solution to the grand challenges of information fusion","D. A. Lambert; A. Saulwick; K. Trentelman","Defence Science and Technology Organisation, Edinburgh, Australia","2015 18th International Conference on Information Fusion (Fusion)","20150917","2015","","","908","915","The information fusion community faces at least five grand challenges. In this paper we describe how our revolutionary implementation of an automated high level information fusion system addresses these grand challenges. Our innovative system processes real-time heterogeneous information sources, including track data, as well as spoken and written English language, transforming all inputs into a rich canonical semantic form for deep automated reasoning. Users can engage in real-time Question Answering with Virtual Advisers and a Virtual Battlespace using spoken and written English and haptic devices. This solution offers the prospect of comprehensive situation awareness.","","Electronic:978-0-9824-4386-6; POD:978-1-4799-7404-7; USB:978-0-9824-4387-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266656","Avatars;Computational Linguistics;Computer interfaces;Data Fusion;Information Fusion;Intelligent control;Knowledge representation;Multi-agent Systems;Natural Language Processing","Data integration;Military aircraft;Monitoring;Position measurement;Psychology;Real-time systems;Semantics","haptic interfaces;natural language processing;question answering (information retrieval);sensor fusion","English language;automated high level information fusion system;deep automated reasoning;haptic device;innovative system processes real-time heterogeneous information source;real-time question answering;revolutionary implementation;spoken English;track data;virtual adviser;virtual battlespace;written English","","","","29","","","6-9 July 2015","","IEEE","IEEE Conference Publications"
"STEP-archival: Storage integrity and anti-tampering using data entanglement","H. Mercier; M. Augier; A. K. Lenstra","Institute of Computer Science, Universit&#x00E9; de Neuch&#x00E2;tel, Switzerland","2015 IEEE International Symposium on Information Theory (ISIT)","20151001","2015","","","1590","1594","We present STEP-archives, a model for censorship-resistant storage systems where an attacker cannot censor or tamper with data without causing a large amount of obvious collateral damage. MDS erasure codes are used to entangle unrelated data blocks, in addition to providing redundancy against storage failures. We show a tradeoff for the attacker between attack complexity, irrecoverability, and collateral damage. We also show that the system can efficiently recover from attacks with imperfect irrecoverability, making the problem asymmetric between attackers and defenders. Finally, we present sample heuristic attack algorithms that are efficient and irrecoverable (but not collateral-damage-optimal), and demonstrate how some strategies and parameter choices allow to resist these sample attacks.","2157-8095;21578095","Electronic:978-1-4673-7704-1; POD:978-1-4673-7705-8; USB:978-1-4673-7703-4","10.1109/ISIT.2015.7282724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282724","Distributed storage;MDS codes;anti-tampering;data entanglement;data integrity","Censorship;Complexity theory;Decoding;Grippers;Memory;Resistance;Security","data integrity;data protection;information retrieval;redundancy","STEP-archival;antitampering;censorship-resistant storage system;data entanglement;heuristic attack algorithm;imperfect irrecoverability;storage integrity","","2","","14","","","14-19 June 2015","","IEEE","IEEE Conference Publications"
"Novel self-learning based crawling and data mining for automatic information extraction","Arun Kumar A V; H. K. Rath; S. M. Nadaf; A. Simha","CTO Networks Lab, Tata Consultancy Services, Bangalore, India","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","20150928","2015","","","732","738","In this paper, we propose techniques using a novel combination of self-learning based crawling and rule based data mining. Using the crawling techniques smaller relevant data sets can be obtained pertaining to a domain from multi-dimensional data sets available in on-line as well as off-line sources. We then process the crawled data sets and mine to extract meaningful information. Our techniques are generic in nature and can be used for automatic information extraction in different domains such as biomedical, health-care, enterprise infrastructure planning, etc. The proposed schemes are of reduced time, space and processor complexity due to the assisted and learning nature of the crawling. The data mining is based on configurable classification rules and decision trees, which are scalable and easy to implement in practice. We evaluate our proposed techniques through Java based implementation and integration with TCS in-house enterprise network design tool NetDes.","","Electronic:978-1-4799-8792-4; POD:978-1-4799-8793-1; USB:978-1-4799-8791-7","10.1109/ICACCI.2015.7275698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275698","","Complexity theory;Crawlers;Data mining;Java;Planning;Vegetation","data mining;decision trees;information retrieval;pattern classification;unsupervised learning","Java based implementation;NetDes;TCS in-house enterprise network design tool;automatic information extraction;biomedical;configurable classification rules;crawled data sets;crawling techniques;decision trees;enterprise infrastructure planning;health-care;multidimensional data sets;off-line sources;on-line sources;processor complexity;rule based data mining;self-learning based crawling;space complexity;time complexity","","","","13","","","10-13 Aug. 2015","","IEEE","IEEE Conference Publications"
"A novel approach to identify research fronts of tourism literature","L. Y. Y. Lu; J. S. Liu","Yuan Ze University, Chung-Li - Taiwan","2015 Portland International Conference on Management of Engineering and Technology (PICMET)","20150924","2015","","","2211","2217","This study applies a novel approach to identify the research fronts of literature in tourism over the past decades. A research front is a coherent topic addressed by a group of researchers in recent years. It is difficult to adopt any traditional methodology to explore the research fronts of tourism literature due to the large amount of data. We retrieve tourism articles over the period 1977 to 2013 from ISI Web of Science database and acquire 8799 articles for analysis. A citation network based edge-betweenness clustering approach is applied to group the tourism literature and then a key-route main path analysis is used to identify the influential articles of each group. The keywords of all articles in each group and the major topics of the articles on the key-route main path are integrated to figure out the research focus. Five groups with more than 400 articles each are reported and the major topics of each group are `tourism sustainability', `tourism destination choice', `sociology of tourism', `tourism demand forecasting', and `climate change'. The methodology presented in this study is a good means for identifying the research fronts of tourism literature. We believe that it is also applicable to other scientific or technological fields.","2159-5100;21595100","Electronic:978-1-8908-4331-1; POD:978-1-4799-1767-9; USB:978-1-8908-4332-8","10.1109/PICMET.2015.7273053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273053","","Databases;Demand forecasting;Economics;Image edge detection;Meteorology;Sociology;Trajectory","citation analysis;information retrieval;pattern clustering;travel industry","ISI Web of Science database;citation network based edge-betweenness clustering approach;climate change;key-route main path analysis;sociology of tourism;tourism demand forecasting;tourism destination choice;tourism literature;tourism sustainability","","","","80","","","2-6 Aug. 2015","","IEEE","IEEE Conference Publications"
"Wiki course builder: A system for retrieving and sequencing didactic materials from Wikipedia","C. Limongelli; F. Gasparetti; F. Sciarrone","Department of Engineering, Roma Tre University, Via della Vasca Navale 79, Rome, Italy","2015 International Conference on Information Technology Based Higher Education and Training (ITHET)","20150824","2015","","","1","6","The designing and delivering of a new online course is a crucial task for teachers that have to face two main problems: building, or retrieving, and sequencing learning materials. Retrieving learning materials requires a great effort and a waste of time, while sequencing them requires an accurate didactic project. On the other hand, thanks to the Internet, teachers and instructional designers today can search and retrieve learning materials from Learning Objects Repositories freely available on the Web, such as Mertlot or Ariadne. In this paper we investigate the possibility of using the Wikipedia free encyclopedia, that is the biggest repository of educational material which is visited daily by about sixty million people with its 49 millions of registered people. It is a matter of facts that teachers consult this encyclopedia to arrange, integrate or enrich their courses. So here we propose a system, now at its early stage of development, aiming at supporting teachers to build courses basing on Wikipedia only. The system retrieves learning materials form Wikipedia and sequences them on the basis of the links embedded in the Wikipedia HTML pages, following a course building process based on the Grasha teaching styles and on a social didactic approach. A first questionnaire has been submitted to a sample of teachers with encouraging results.","","Electronic:978-1-4799-1756-3; POD:978-1-4799-1757-0; USB:978-1-4799-1755-6","10.1109/ITHET.2015.7218041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7218041","","Collaboration;Context;Electronic publishing;Encyclopedias;Internet;Java","Internet;computer aided instruction;educational courses;information retrieval;teaching","Grasha teaching styles;Internet;Wiki course builder;Wikipedia;didactic material retrieving;didactic material sequencing;educational material repository;free encyclopedia;learning material retrieval;learning material sequencing;learning objects repositories;online course;social didactic method","","2","","28","","","11-13 June 2015","","IEEE","IEEE Conference Publications"
