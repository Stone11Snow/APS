"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=959131,914864,979973,953135,1006298,931976,929932,962716,958600,1011350,909601,1000405,938548,1004129,944690,901157,941191,994766,934680,1006299,943824,938455,1010067,999889,1013957,918865,925354,953036,994713,940741,999952,938553,916487,1000357,994697,1013816,953919,1006722,962799,938546,1006704,951074,926306,1004977,959798,941248,962748,938102,942553,958596,953835,953162,941247,960678,951984,953817,956109,962546,958595,991485,937645,904480,993952,1007747,943719,992136,938083,1000145,981848,988221,991371,995005,958594,925048,953118,999514,924952,923210,999935,923290,953175,940963,937269,1017736,953901,949609,916360,968705,935845,995281,916370,933905,918832,925457,953977,995535,962745,925317,914814,956107",2017/05/04 22:01:32
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Rewrite rules for quantified subqueries in a federated database","G. J. L. Kemp; P. M. D. Gray; A. R. Sjostedt","Dept. of Comput. Sci., Aberdeen Univ., UK","Proceedings Thirteenth International Conference on Scientific and Statistical Database Management. SSDBM 2001","20020807","2001","","","134","143","Transforming queries for efficient execution is particularly important in federated database systems since a more efficient execution plan can require many fewer data requests to be sent to the component databases. Also, it is important to do as much as possible of the selection and processing close to where the data are stored, making best use of facilities provided by the federation's component database management systems. We address the problem of processing complex queries including quantifiers, which have to be executed against different databases in an expanding heterogeneous federation. This is done by transforming queries within a mediator for global query improvement, and within wrappers to make best use of the query processing capabilities of external databases. Our approach is based on pattern matching and query rewriting. We introduce a high level language for expressing rewrite rules declaratively, and demonstrate the use and flexibility of such rules in improving query performance for existentially quantified subqueries. Extensions to this language that allow generic rewrite rules to be expressed are also presented. The value of performing final transformations within a wrapper for a given remote database is shown in several examples that use AMOS II-an SQLS-like system","1099-3371;10993371","POD:0-7695-1218-6","10.1109/SSDM.2001.938546","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938546","","Data engineering;Database languages;Database systems;Distributed databases;Educational institutions;Information retrieval;Internet;Pattern matching;Pattern recognition","distributed databases;pattern matching;query processing","AMOS II;SQLS;complex query processing;federated database;high level language;pattern matching;quantified subqueries;quantifiers;query rewriting;rewrite rules;wrappers","","2","1","27","","","2001","18 Jul 2001-20 Jul 2001","IEEE","IEEE Conference Publications"
"Transitivity of comparison measures","S. Janssens; B. De Baets; H. De Meyer","Dept. of Appl. Math., Biometrics & Process Control, Ghent Univ., Belgium","Fuzzy Systems, 2002. FUZZ-IEEE'02. Proceedings of the 2002 IEEE International Conference on","20020807","2002","2","","1369","1374","A family of fuzzification schemes is proposed for transforming cardinality-based similarity and inclusion measures for ordinary sets into similarity and inclusion measures for fuzzy sets in a finite universe. The family is based on rules for fuzzy set cardinality and for the standard operations on fuzzy sets. In particular, the fuzzy set intersections are pointwisely generated by Frank t-norms. The fuzzification schemes are applied to a variety of previously studied rational cardinality-based similarity and inclusion measures for ordinary sets and it is demonstrated that transitivity is preserved in the fuzzification process. Finally, we introduce a new parametrized family of similarity measures and a new parametrized family of inclusion measures and investigate the transitivity properties of both families and their fuzzification","","POD:0-7803-7280-8","10.1109/FUZZ.2002.1006704","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1006704","","Biometrics;Computer science;Data mining;Fuzzy sets;Information retrieval;Length measurement;Mathematics;Process control;Psychology;Statistics","fuzzy set theory","fuzzy relation;fuzzy set theory;inclusion measure;rational cardinality;similarity measure;transitivity;triangular norm","","0","","26","","","2002","12 May 2002-17 May 2002","IEEE","IEEE Conference Publications"
"Query-by-shape in meteorological image archives using the point diffusion technique","F. Dell'Acqua; P. Gamba","Dipt. di Elettronica, Pavia Univ., Italy","IEEE Transactions on Geoscience and Remote Sensing","20020807","2001","39","9","1834","1843","The authors work on meteorological satellite image archives and provide a novel and useful query-by-shape tool. To this aim, they first present the point diffusion technique (PDT), a fast and efficient method for shape similarity evaluation. Thanks to its very structure, this approach is suitable to handle objects whose shape is not well defined and can be represented by a set of sparse points. PDT is thus suitable for application to similarity-based retrieval from remotely sensed image archives, where shapes are hardly defined but are still among the major features of interest. Moreover, they prove here that PDT is almost as effective as more standard procedures for shape-based database queries, although significantly faster. In other words, it manages to combine retrieval speed and precision, the features of greatest importance for a first remote sensing data prescreening in many applications. Archives of meteorological satellite images are typical examples of very large-sized, remote sensing-based databases with a special attention for shape features. Each meteorological satellite produces terabytes of data every day, a large part of which is not immediately analyzed and ends being stored in archives. The application of PDT to such a database is presented and discussed, and a comparison with a standard method developed for meteorological shape analysis is provided","0196-2892;01962892","","10.1109/36.951074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=951074","","Image analysis;Image databases;Image retrieval;Information retrieval;Meteorology;Remote sensing;Satellites;Shape;Spatial databases;Standards development","atmospheric techniques;clouds;feature extraction;geophysical signal processing;geophysics computing;image retrieval;meteorology;query formulation","cloud;database query;image archive;image feature;image processing;measurement technique;meteorology;point diffusion;point diffusion technique;precision;query-by-shape;querying;remote sensing;retrieval speed;searching;shape feature;shape similarity evaluation","","7","","26","","","Sep 2001","","IEEE","IEEE Journals & Magazines"
"Denormalization effects on performance of RDBMS","G. L. Sanders; Seungkyoon Shin","Manage. Sci. & Syst., State Univ. of New York, Buffalo, NY, USA","Proceedings of the 34th Annual Hawaii International Conference on System Sciences","20020807","2001","","","9 pp.","","Presents a practical view of denormalization, and provides fundamental guidelines for incorporating denormalization. We have suggested using denormalization as an intermediate step between logical and physical modeling, to be used as an analytic procedure for the design of the applications requirements criteria. Relational algebra and query trees are used to examine the effect on the performance of relational database management systems (RDBMS). The guidelines and methodology presented are sufficiently general, and they can be applicable to most databases. It is concluded that denormalization can enhance query performance when it is deployed with a complete understanding of application requirements.","","POD:0-7695-0981-9","10.1109/HICSS.2001.926306","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=926306","","Algebra;Data models;Data warehouses;Guidelines;Information retrieval;Relational databases;Spatial databases;Stability;System performance;Transaction databases","database theory;query processing;relational algebra;relational databases;software performance evaluation","analytic procedure;applications requirements criteria design;denormalization;logical modeling;physical modeling;query performance;query trees;relational DBMS performance;relational algebra","","10","4","24","","","6-6 Jan. 2001","","IEEE","IEEE Conference Publications"
"Discovering related Web pages through fuzzy-context reasoning","V. Loia; S. Senatore; M. I. Sessa","Dipt. Matematica e Informatica, Universita di Salemo, Baronissi, Italy","Fuzzy Systems, 2002. FUZZ-IEEE'02. Proceedings of the 2002 IEEE International Conference on","20020807","2002","1","","150","155","The rapid growth of Web resources makes very difficult the task of Web search engines. Nevertheless powerful search crawlers have been developed to aid in locating unfamiliar document (by means of category, contents or subject based approaches), often queries return inconsistent results. The main lack of Web searching is in the deduction capability: nowadays Web searching put much attention in matching user's queries that are too weak to cope with the user's expressiveness. First attempts in extending searching towards deduction capability are essentially based on two-valued logic and standard probability theory. The complexity of the problem (8.4 million of Web sites), the features of the space domain (unstructured data, immature standards) demand a strong deviation from this trend. This work presents some results stemmed from a research projects where different technologies (in particular mobile agents and approximate reasoning) have been merged into an operational architecture suitable for Web searching/Web discovering. This paper discusses a different approach to Web searching where the input to the retrieval process is described through a Web page. The system reacts to this kind of query by returning a set of Web pages that reflect a similar context and deals with related arguments","","POD:0-7803-7280-8","10.1109/FUZZ.2002.1004977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1004977","","Crawlers;Indexing;Information retrieval;Probabilistic logic;Search engines;Service oriented architecture;Space technology;Web and internet services;Web pages;Web search","Internet;fuzzy logic;information resources;multivalued logic;online front-ends;probability;search engines","Web search engines;World Wide Web;deduction capability;fuzzy-context reasoning;immature standards;inconsistent results;probability theory;related Web page discovery;search crawlers;two-valued logic;unstructured data;user expressiveness","","2","","11","","","2002","12 May 2002-17 May 2002","IEEE","IEEE Conference Publications"
"An integrated probe for planar near-field only intensity measurements","S. Costanzo; G. Di Massa","Dipt. di Elettronica, Informatica e Sistemistica, Calabria Univ., Italy","IEEE Antennas and Propagation Society International Symposium. 2001 Digest. Held in conjunction with: USNC/URSI National Radio Science Meeting (Cat. No.01CH37229)","20020807","2001","2","","614","617 vol.2","An innovative procedure for phaseless near-field measurements is presented. The squared intensity data received by two co-planar probes simultaneously scanning a planar near-field surface are used to retrieve the near-field phase and subsequently to perform the near-field/far-field transformation. The approach requires reduced scan times and low-cost facilities, when compared with existing phase retrieval techniques. Measurements on a microstrip patch antenna for SAR applications are used as experimental validations of the method.","","POD:0-7803-7070-8","10.1109/APS.2001.959798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=959798","","Antenna measurements;Frequency measurement;Information retrieval;Microstrip;Microwave antennas;Microwave theory and techniques;Performance evaluation;Phase measurement;Printed circuits;Probes","antenna radiation patterns;antenna testing;electric field measurement;magnetic field measurement;microstrip antennas;probes;radar antennas;synthetic aperture radar","SAR applications;co-planar probes;integrated probe;low-cost facilities;microstrip patch antenna;near-field phase;near-field/far-field transformation;phase retrieval techniques;phaseless near-field measurements;planar near-field only intensity measurements;planar near-field surface scanning;squared intensity data","","3","","4","","","8-13 July 2001","08 Jul 2001-13 Jul 2001","IEEE","IEEE Conference Publications"
"Distance-from-boundary as a metric for texture image retrieval","Guodong Guo; Hong-Jiang Zhang; S. Z. Li","Microsoft Res. China, Beijing, China","2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)","20020807","2001","3","","1629","1632 vol.3","A new metric is proposed for texture image retrieval, which is based on the signed distance of the images in the database to a boundary chosen by the query. This novel metric has three advantages: (1) the boundary distance measures are relatively insensitive to the sample distributions; (2) the same retrieval results can be obtained with respect to different (but visually similar) queries; (3) retrieval performance can be improved. The boundaries are obtained by using a statistical learning algorithm called support vector machine (SVM), and hence the boundaries can be simply represented by some vectors and their combination coefficients. Experimental results on the Brodatz texture database indicate that a significantly better retrieval performance can be achieved as compared to the traditional Euclidean distance-based approach. This technique can be further developed to learn pattern similarities among different texture classes and used in relevance feedback","1520-6149;15206149","POD:0-7803-7041-4","10.1109/ICASSP.2001.941248","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=941248","","Content based retrieval;Euclidean distance;Feedback;Image databases;Image retrieval;Information retrieval;Machine learning;Spatial databases;Support vector machines;Visual databases","content-based retrieval;database indexing;image representation;image retrieval;image texture;learning automata;visual databases","Brodatz texture database;SVM;boundary distance measures;combination coefficients;content-based image retrieval;database query;distance-from-boundary metric;image database;retrieval performance;statistical learning algorithm;support vector machine;texture image retrieval;texture indexing;vector representation","","2","1","13","","","2001","07 May 2001-11 May 2001","IEEE","IEEE Conference Publications"
"Multi-view free-form 3-D object retrieval with incomplete data","F. Mokhtarian; S. Abbasi","Dept. of Electron. & Electr. Eng., Surrey Univ., Guildford, UK","2001 IEEE Fourth Workshop on Multimedia Signal Processing (Cat. No.01TH8564)","20020807","2001","","","287","292","This paper describes a novel approach to multi-view 3D object retrieval. To represent each view of the object, its edge contours are extracted at different levels of scale. Each edge contour, in turn, is segmented by its curvature zero crossing points in a multi-scale fashion. This procedure is carried out using the curvature scale space technique which has been selected for MPEG-7 standardisation. A number of features are then computed for each segment of each edge contour. The image is finally represented by the locations of its segments and the values of their associated features. In response to an input query, geometric hashing is first used to find the best locally matched candidates for the verification stage where the goal is to measure the distance between the input query edge contours and the corresponding model contours after applying a proper transformation. The measurement is then optimised and used as the match value. The method has been successfully tested on a collection of 3D objects consisting of 15 aircraft of different shapes","","POD:0-7803-7025-2","10.1109/MMSP.2001.962748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=962748","","Data mining;Detectors;Filters;Image edge detection;Image segmentation;Information retrieval;MPEG 7 Standard;Shape;Smoothing methods;Speech processing","content-based retrieval;edge detection;feature extraction;image matching;image representation;image resolution;image retrieval;image segmentation;visual databases","3D object retrieval;MPEG-7 standardisation;curvature scale space;curvature zero crossing points;edge contour extraction;feature extraction;geometric hashing;image matching;image query;image representation;image segmentation;incomplete data;multi-scale procedure;multi-view object retrieval","","0","","6","","","2001","03 Oct 2001-05 Oct 2001","IEEE","IEEE Conference Publications"
"A study on content-based classification and retrieval of audio database","Mingchun Liu; Chunru Wan","Sch. of Electr. & Electron. Eng., Nanyang Technol. Inst., Singapore","Proceedings 2001 International Database Engineering and Applications Symposium","20020807","2001","","","339","345","Nowadays, available audio corpora are rapidly increasing from fast growing Internet and digitized libraries. How to effectively classify and retrieve such huge databases is a challenging task. Content based technology is studied to automatically classify audio into hierarchy classes. Based on a small set of features selected by the sequential forward selection (SFS) method from 87 extracted ones, four classifiers, namely nearest neighbor (NN), modified k-nearest neighbor (k-NN), Gaussian mixture model (GMM), and probabilistic neural network (PNN) are compared. Experiments were conducted on a common database and a more comprehensive database built by the authors. Finally, the PNN classifier combined with Euclidean distance measurement was chosen for audio retrieval, using query by example","","POD:0-7695-1140-6","10.1109/IDEAS.2001.938102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938102","","Acoustic measurements;Audio databases;Cognition;Content based retrieval;Humans;Information retrieval;Neural networks;Prototypes;Psychology;Spatial databases","audio signal processing;content-based retrieval;multimedia databases;neural nets;very large databases","Euclidean distance measurement;Gaussian mixture model;Internet;PNN classifier;audio corpora;audio database retrieval;audio retrieval;classifiers;common database;comprehensive database;content based classification;content based technology;digitized libraries;hierarchy classes;huge databases;modified k-nearest neighbor;nearest neighbor;probabilistic neural network;query by example;sequential forward selection","","4","","14","","","2001","16 Jul 2001-18 Jul 2001","IEEE","IEEE Conference Publications"
"Passive microwave remote sensing of snow constrained by hydrological simulations","Chi-Te Chen; B. Nijssen; Jianjun Guo; Leung Tsang; A. W. Wood; Jenq-Neng Hwang; D. P. Lettenmaier","Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA","IEEE Transactions on Geoscience and Remote Sensing","20020807","2001","39","8","1744","1756","This paper describes a snow parameter retrieval algorithm from passive microwave remote sensing measurements. The three components of the retrieval algorithm include a dense media radiative transfer (DMRT) model, which is based on the quasicrystalline approximation (QCA) with the sticky particle assumption, a physically-based snow hydrology model (SHM) that incorporates meteorological and topographical data, and a neural network (NN) for computational efficient inversions. The DMRT model relates physical snow parameters to brightness temperatures. The SHM simulates the mass and heat balance and provides initial guesses for the neural network. The NN is used to speed up the inversion of parameters. The retrieval algorithm can provide speedy parameter retrievals for desired temporal and spatial resolutions, Four channels of brightness temperature measurements: 19V, 19H, 37V, and 37H are used. The algorithm was applied to stations in the northern hemisphere. Two sets of results are shown. For these cases, the authors use ground-truth precipitation data, and estimates of snow water equivalent (SWE) from SHM give good results. For the second set, a weather forecast model is used to provide precipitation inputs for SHM. Additional constraints in grain size and density are used. They show that inversion results compare favorably with ground truth observations","0196-2892;01962892","","10.1109/36.942553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942553","","Approximation algorithms;Brightness temperature;Hydrologic measurements;Information retrieval;Microwave measurements;Neural networks;Passive microwave remote sensing;Quantum cellular automata;Snow;Weather forecasting","geophysics computing;hydrological techniques;neural nets;radiometry;remote sensing;snow","19 GHz;37 GHz;EHF;SHF;brightness temperature;dense media radiative transfer model;hydrological simulation;hydrology;inversion;measurement technique;microwave radiometry;microwave remote sensing;neural net;neural network;physically-based snow hydrology model;quasicrystalline approximation;remote sensing;snow cover;snow parameter retrieval algorithm;snow water equivalent;snowcover;snowpack;sticky particle assumption","","17","","22","","","Aug 2001","","IEEE","IEEE Journals & Magazines"
"Subject region segmentation in disparity maps for image retrieval","S. Satoh; Y. Idehara; H. Mo; T. Hamada","Nat. Inst. of Informatics, Tokyo, Japan","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","20020807","2001","2","","725","728 vol.2","The paper presents a method to automatically extract subject regions to be used as a key for image retrieval. If one wants to look up a particular object in an image database, a key image region of the object should be properly indicated to the system. However, this task is not trivial. In our approach, we assume that we have an actual object in the real world to be looked up in the image database. Taking advantage of disparity images using a commercially available stereo range finder, we automate subject region extraction. We assume that 3-D points in a dense disparity map yield a multimodal Gaussian probability distribution, and subject regions are extracted by properly selecting particular modes of Gaussian densities. We demonstrate that the system somehow extracts regions which correspond to ""subjects."" The system achieves adaptive and quick extraction, and it enables experimental image retrieval by a real object system which runs interactively","","POD:0-7803-6725-1","10.1109/ICIP.2001.958596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958596","","Cameras;Data mining;Design methodology;Image databases;Image retrieval;Image segmentation;Informatics;Information retrieval;Layout;Probability distribution","Gaussian distribution;adaptive signal processing;image retrieval;image sampling;image segmentation;maximum likelihood estimation;stereo image processing;visual databases","Gaussian densities;Gaussian sampling;MLE;adaptive feature extraction;automatic region extraction;automatic subject region extraction;commercially stereo range finder;dense disparity map;disparity maps;image database;image region;image retrieval;maximum likelihood estimation;multimodal Gaussian probability distribution;subject region segmentation","","0","","4","","","7-10 Oct 2001","07 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"Incremental hierarchical discriminant regression for online image classification","Juyang Weng; Wey-Shiuan Hwang","Dept. of Comput. Sci. & Eng., Michigan State Univ., East Lansing, MI, USA","Proceedings of Sixth International Conference on Document Analysis and Recognition","20020807","2001","","","476","480","This paper presents an incremental algorithm for image classification problems. Virtual labels are automatically formed by clustering in the output space. These virtual labels are used for the process of deriving discriminating features in the input space. This procedure is performed recursively in a coarse-to-fine fashion resulting in a tree, called incremental hierarchical discriminating regression (IHDR) method. Embedded in the tree is a hierarchical probability distribution model used to prune unlikely cases. A sample size dependent negative-log-likelihood (NLL) metric is introduced to deal with large-sample size cases, small-sample size cases, and unbalanced-sample size cases, measured among different internal nodes of the IHDR algorithm. We report the experimental results of the proposed algorithm for an OCR classification problem and an image orientation classification problems","","POD:0-7695-1263-1","10.1109/ICDAR.2001.953835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953835","","Computer science;Decision trees;Image classification;Image databases;Information retrieval;Linear discriminant analysis;Neural networks;Optical character recognition software;Principal component analysis;Spatial databases","image classification;online operation;pattern clustering;statistical analysis;trees (mathematics)","IHDR method;NLL metric;OCR;clustering;discriminating features;hierarchical probability distribution model;image orientation classification problems;incremental hierarchical discriminant regression;online image classification;recursive coarse-to-fine feature derivation;sample size dependent negative-log-likelihood metric;tree;unlikely case pruning;virtual labels","","5","","5","","","2001","10 Sep 2001-13 Sep 2001","IEEE","IEEE Conference Publications"
"Query evaluation and presentation planning within a spatial mediator: extending XML-based mediation to heterogeneous sources of GIS and imagery data","I. Zaslavsky; A. Gupta; B. Ludascher; S. Tambawala","San Diego Supercomput. Center, La Jolla, CA, USA","12th International Workshop on Database and Expert Systems Applications","20020807","2001","","","853","855","This paper reviews challenges and accomplishments of spatial information mediation extending the SDSC MIX (mediation of information using XML) framework. enhancements to MIX necessitated by the spatio-temporal nature of queries and underlying GIS and imagery data sources, include mediator-level development of query evaluation and results presentation strategies which take into account the source data quality and query context, and define integrated views over heterogeneous sources in terms of mediation algebra for spatial types (MAST). Development of query and presentation plans at the spatial mediator is based on source schema and query capability descriptions exported by source wrappers. A set of tools supporting XML-based spatial markup, query and presentation is also introduced","","POD:0-7695-1230-5","10.1109/DEXA.2001.953162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953162","","Algebra;Assembly;Geographic Information Systems;Information retrieval;Mediation;Middleware;Project management;Query processing;Supercomputers;XML","geographic information systems;image retrieval;multimedia computing;visual databases","GIS data sources;SDSC MIX;XML;imagery data;query process;spatial information mediation;spatial markup","","2","","8","","","2001","03 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"Content-based retrieval of video shot using the-improved nearest feature line method","Li Zhao; Wei Qi; S. Z. Li; S. Q. Yang; H. J. Zhang","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)","20020807","2001","3","","1625","1628 vol.3","Shot-based classification and retrieval is very important for video database organization and access. We present a new approach: 'nearest feature line - NFL' used in shot retrieval. We look at key-frames in a shot as feature points to represent the shot in feature space. Lines connecting the feature points are further used to approximate the variations in the whole shot. The similarity between the query image and the shots in video database are measured by calculating the distance between the query image and the feature lines in feature space. To make it more suited to video data, we improved the original NFL method by adding constraints on the feature lines. Experimental results show that our improved NFL method is better than the traditional classification methods such as nearest neighbor (NN) and nearest center (NC)","1520-6149;15206149","POD:0-7803-7041-4","10.1109/ICASSP.2001.941247","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=941247","","Computer science;Content based retrieval;Extraterrestrial measurements;Image databases;Information retrieval;Joining processes;Nearest neighbor searches;Neural networks;Prototypes;Spatial databases","approximation theory;content-based retrieval;feature extraction;image classification;image representation;image retrieval;video databases","content-based retrieval;feature points;feature space distance;image query similarity;key frames;nearest feature line method;shot representation;shot retrieval;shot-based classification;variation approximation;video database","","3","","9","","","2001","07 May 2001-11 May 2001","IEEE","IEEE Conference Publications"
"Decision logics for knowledge representation in data mining","Tuan-Fang Fan; Wu-Chih Hu; Churn-Jung Liau","Dept. of Inf. Eng., Nat. Penghu Inst. of Technol., Taiwan","25th Annual International Computer Software and Applications Conference. COMPSAC 2001","20020807","2001","","","626","631","In this paper the qualitative and quantitative semantics for rules in data tables are investigated from a logical viewpoint. In modern data analysis, knowledge can be discovered from data tables and is usually represented by some rules. However the knowledge is useful for a human user only when he can understand the meaning of the rules. This is called the interpretability problem of intelligent data analysis. The solution of the problem depends on the selection of the rule representation language. A good representation language should have clear semantics so that a rule can be effectively validated with respect to the given data tables. In this regard, logic is one of the best choices. Starting from reviewing the decision logic for data tables, we subsequently generalize it to fuzzy and possibilistic decision logics. The rules are then viewed as the implications between well-formed formulas of these logics and their semantics with respect to precise or uncertain data tables are presented. The validity, support, and confidence of a rule are also rigorously defined in the framework","0730-3157;07303157","POD:0-7695-1372-7","10.1109/CMPSAC.2001.960678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=960678","","Artificial intelligence;Data analysis;Data engineering;Data mining;Fuzzy logic;Humans;Information retrieval;Information science;Knowledge representation;Modems","data mining;decision theory;formal logic;knowledge representation","data analysis;data mining;data table semantics;decision logic;fuzzy logics;intelligent data analysis;knowledge representation;possibilistic logics;rule representation","","1","","19","","","2001","08 Oct 2001-12 Oct 2001","IEEE","IEEE Conference Publications"
"Recent advances in wireless networking","D. P. Agrawal","University of Cincinnati","Proceedings International Conference on Parallel Processing Workshops","20020807","2001","","","443","443","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/00951984.png"" border=""0"">","1530-2016;15302016","POD:0-7695-1260-7","10.1109/ICPPW.2001.951984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=951984","","Data communication;Databases;Distributed computing;Information retrieval;Intelligent networks;Military computing;Mobile communication;Mobile computing;Wireless LAN;World Wide Web","","","","0","","","","","2001","","IEEE","IEEE Conference Publications"
"Networking digital document images","F. Le Bourgeois; H. Emptoz; E. Trinh; J. Duong","Equipe de Reconnaissance de Formes et Vision, Inst. Nat. des Sci. Appliquees de Lyon, Villeurbanne, France","Proceedings of Sixth International Conference on Document Analysis and Recognition","20020807","2001","","","379","383","Digital libraries create new services and open rare collections to a larger and wider audience. The development of online digital libraries in image mode is today limited by the narrow bandwidth of the network and the heavy storage requirements. Moreover, efficient networking of text content images requires specific compression schemes and particular file formats that describe the contents of the images and provide additional information such as document layout descriptions. The paper describes problems concerning the networking of digital document images and provides solutions for image compression. A file format, which enables editing and annotation, is presented. Our proposal mainly uses automatic document layout analysis algorithms, which constitutes a new field of application for this research area. This work, granted by the European community, has been applied to 16<sup>th</sup> century books for the project DEBORA","","POD:0-7695-1263-1","10.1109/ICDAR.2001.953817","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953817","","Bandwidth;Books;Image coding;Image storage;Information retrieval;Proposals;Reconnaissance;Software libraries;Text analysis;XML","computer networks;content-based retrieval;data compression;digital libraries;document image processing;history;image coding;text analysis","16th century books;DEBORA;European community;annotation;automatic document layout analysis algorithms;compression schemes;digital document image networking;digital libraries;document layout description;editing;file format;file formats;heavy storage requirement;image compression;image mode;online digital libraries;rare collections;text content image networking","","4","","19","","","2001","10 Sep 2001-13 Sep 2001","IEEE","IEEE Conference Publications"
"Scalable color image indexing and retrieval using vector wavelets","E. Albuz; E. Kocalar; A. A. Khokhar","Sony Electron., San Jose, CA, USA","IEEE Transactions on Knowledge and Data Engineering","20020807","2001","13","5","851","861","This paper presents a scalable content-based image indexing and retrieval system based on vector wavelet coefficients of color images. Highly decorrelated wavelet coefficient planes are used to acquire a search efficient feature space. The feature space is subsequently indexed using properties of all the images in the database. Therefore, the feature key of an image not only corresponds to the content of the image itself but also to how much the image is different from the other images being stored in the database. The search time linearly depends on the number of images similar to the query image and is independent of the database size. We show that, in a database of 5,000 images, query search takes less than 30 msec on a 266 MHz Pentium II processor, compared to several seconds of retrieval time in the earlier systems proposed in the literature","1041-4347;10414347","","10.1109/69.956109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=956109","","Color;Content based retrieval;Delay;Image databases;Image retrieval;Indexing;Information retrieval;Space technology;Spatial databases;Wavelet coefficients","content-based retrieval;database indexing;image colour analysis;visual databases;wavelet transforms","Pentium II processor;color image indexing;content-based retrieval;decorrelated wavelet coefficient planes;image database;query by example;scalable content-based image indexing;search time;vector wavelet coefficients;wavelet transform","","32","6","24","","","Sep/Oct 2001","","IEEE","IEEE Journals & Magazines"
"Partial replication in the Database State Machine","A. Sousa; F. Pedone; R. Oliveira; F. Moura","","Proceedings IEEE International Symposium on Network Computing and Applications. NCA 2001","20020807","2001","","","298","309","This paper investigates the use of partial replication in the Database State Machine approach introduced earlier for fully replicated databases. It builds on the order and atomicity properties of group communication primitives to achieve strong consistency and proposes two new abstractions: Resilient Atomic Commit and Fast Atomic Broadcast. Even with atomic broadcast, partial replication requires a termination protocol such as atomic commit to ensure transaction atomicity, With Resilient Atomic Commit our termination protocol allows the commit of a transaction despite the failure of some of the participants. Preliminary performance studies suggest that the additional cost of supporting partial replication can be mitigated through the use of Fast Atomic Broadcast","","POD:0-7695-1432-4","10.1109/NCA.2001.962546","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=962546","","Access protocols;Atomic measurements;Banking;Broadcasting;Context;Distributed databases;Information retrieval;Magnetic heads;Transaction databases;Voting","concurrency control;database machines;protocols;replicated databases;transaction processing","Database State Machine;Fast Atomic Broadcast;Resilient Atomic Commit;atomic broadcast;partial replication;protocols;replicated databases;termination protocol;transaction processing","","19","2","21","","","2001","08 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"Support vector machine learning for image retrieval","Lei Zhang; Fuzong Lin; Bo Zhang","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","20020807","2001","2","","721","724 vol.2","A novel method of relevance feedback is presented based on support vector machine learning in the content-based image retrieval system. A SVM classifier can be learned from training data of relevance images and irrelevance images marked by users. Using the classifier, the system can retrieve more images relevant to the query in the database efficiently. Experiments were carried out on a large-size database of 9918 images. It shows that the interactive learning and retrieval process can find correct images increasingly. It also shows the generalization ability of SVM under the condition of limited training samples","","POD:0-7803-6725-1","10.1109/ICIP.2001.958595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958595","","Content based retrieval;Image databases;Image retrieval;Information retrieval;Learning systems;Machine learning;Space technology;Support vector machine classification;Support vector machines;Training data","content-based retrieval;image classification;image retrieval;learning automata;relevance feedback;visual databases","SVM classifier;content-based image retrieval system;image classifier;interactive image retrieval;interactive learning;irrelevance images;large-size image database;limited training samples;relevance feedback;relevance images;support vector machine learning;training data","","66","1","7","","","7-10 Oct 2001","07 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"A requirements description metamodel for use cases","T. Nakatani; T. Urai; S. Ohmura; T. Tamai","SLagoon Co., Ltd., Chiba, Japan","Proceedings Eighth Asia-Pacific Software Engineering Conference","20020807","2001","","","251","258","Engineers have little time for requirements elicitation and their validation, because they still have to make a great effort to write down concrete use cases. Although concrete use cases are important for deriving test cases, it is possible to free engineers from the routine work of defining similar use cases repeatedly and at the same time keeping consistency in requirements elicitation. We propose one solution concerning these difficulties. The requirements description metamodel called RD-metamodel integrates the activity graph metamodel and use case metamodel. It supplies a mechanism of use case writing with multiple perspectives: resource-reference, resource-structure, activity-sequence, process, and the actor's perspective.","1530-1362;15301362","POD:0-7695-1408-1","10.1109/APSEC.2001.991485","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=991485","","Computer aided software engineering;Concrete;Data processing;Information retrieval;Information systems;Memory;Productivity;Skeleton;Testing;Writing","formal specification","RD-metamodel;activity graph metamodel;activity-sequence perspective;actor perspective;process perspective;requirements description metamodel;resource-reference perspective;resource-structure perspective;use case metamodel;use case writing","","4","","15","","","4-7 Dec. 2001","","IEEE","IEEE Conference Publications"
"An EM algorithm for video summarization, generative model approach","X. Orriols; X. Binefa","Comput. Vision Center, Univ. Autonoma de Barcelona, Bellaterra, Spain","Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001","20020807","2001","2","","335","342 vol.2","In this paper, we address the visual video summarization problem in a Bayesian framework in order to detect and describe the underlying temporal transformation symmetries in a video sequence. Given a set of time correlated frames, we attempt to extract a reduced number of image-like data structures which are semantically meaningful and that have the ability of representing the sequence evolution. To this end, we present a generative model which involves jointly the representation and the evolution of appearance. Applying Linear Dynamical System theory to this problem, we discuss how the temporal information is encoded yielding a manner of grouping the iconic representations of the video sequence in terms of invariance. The formulation of this problem is driven in terms of a probabilistic approach, which affords a measure of perceptual similarity taking both learned appearance and time evolution models into account","","POD:0-7695-1143-0","10.1109/ICCV.2001.937645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=937645","","Application software;Bayesian methods;Cameras;Computer vision;Content based retrieval;Data mining;Data structures;Databases;Information retrieval;Video sequences","content-based retrieval;image sequences;video databases","Bayesian framework;Linear Dynamical System;evolution models;generative model;perceptual similarity;retrieval;temporal transformation symmetries;video data-bases;video sequence;video summarization","","13","1","9","","","2001","07 Jul 2001-14 Jul 2001","IEEE","IEEE Conference Publications"
"Towards a temporal World-Wide Web: a transaction-time server","C. E. Dyreson","Dept. of Electr. Eng. & Comput. Sci., Washington State Univ., Pullman, WA, USA","Proceedings 12th Australasian Database Conference. ADC 2001","20020807","2001","","","169","175","Transaction time is the time of a database transaction, i.e., an insertion, update, or deletion. A transaction time database stores the transaction-time history of a database and supports transaction timeslice queries that retrieve past database states. The paper introduces transaction time to the World-Wide Web. In a Web context, transaction time is the modification time of a resource such as an XML document. A transaction-time Web server archives resource versions and supports transaction timeslice. Unlike a database server, a Web server is typically uninvolved in the update of a resource, instead it is only active when a resource is requested. The paper describes a lazy update protocol that enables a Web server to manage resource versions during resource reads. An important benefit of our approach is that transaction-time can be supported by a transparent, minimal Web server extension; no changes to legacy resources, HTTP, XML, or HTML are required. Furthermore, a Web server can seemlessly become a transaction-time server at any time without affecting or modifying the resources it services or other Web servers","1530-0919;15300919","POD:0-7695-0966-5","10.1109/ADC.2001.904480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=904480","","Computer science;History;Information retrieval;Protocols;Resource management;Search engines;Transaction databases;Uniform resource locators;Web server;XML","Internet;file servers;information resources;resource allocation;temporal databases;transaction processing","Web context;XML document;database transaction;lazy update protocol;legacy resources;modification time;past database states;resource reads;resource versions;temporal World-Wide Web;transaction time database;transaction timeslice queries;transaction-time Web server;transaction-time history;transparent minimal Web server extension","","2","","13","","","2001","29 Jan 2001-02 Feb 2001","IEEE","IEEE Conference Publications"
"Modeling and analysis of temporal failure and degradation behavior of critical infrastructure systems","M. Bassiouni; R. Guha","Sch. of Electr. Eng. & Comput. Sci., Univ. of Central Florida, Orlando, FL, USA","Proceedings of the 35th Annual Hawaii International Conference on System Sciences","20020807","2002","","","689","694","We present an approach for modeling and analyzing the temporal failure and degradation behavior of critical infrastructure systems (CISs) using advanced temporal database management systems. We class the possible failure and/or degraded performance of CISs into different temporal categories, namely, crisp or exact intervals, nonvanishing imprecise intervals and vanishing imprecise intervals. The three temporal operators: Union (OR), Overlap (AND) and Not are extended to operate on the above categories of precise and imprecise intervals. The temporal operators are used recursively to capture the fault tolerance topology of CIS. For example, if a component of CIS has built-in redundancy for fault tolerance, the fault behavior of this component propagates to the outside only when all the redundant units of this component fail simultaneously. In this case, the failure temporal expressions of the redundant units are joined by temporal Overlap operators to indicate that the failure of the composite component is contingent on the failure of all units. We show how query languages with temporal extensions can be used to obtain useful answers for time-related queries and retrieve useful information about the exact and potential time points for degraded modes of operation. The storage overhead of incorporating the imprecise intervals in a temporal database is analyzed.","","POD:0-7695-1435-9","10.1109/HICSS.2002.993952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=993952","","Computational Intelligence Society;Data analysis;Database languages;Database systems;Degradation;Failure analysis;Fault tolerance;Information retrieval;Redundancy;Topology","fault tolerant computing;query languages;safety-critical software;temporal databases;temporal logic","CISs;Not;Overlap;Union;advanced temporal database management systems;built-in redundancy;composite component;crisp intervals;critical infrastructure systems;degradation behavior;degraded operation modes;degraded performance;exact intervals;failure temporal expressions;fault behavior;fault tolerance topology;nonvanishing imprecise intervals;query languages;redundant units;storage overhead;temporal categories;temporal extensions;temporal failure modeling;temporal operators;time impreciseness;time-related queries;vanishing imprecise intervals","","2","","11","","","7-10 Jan. 2002","","IEEE","IEEE Conference Publications"
"","","","Computer Systems and Software Engineering, Israel Conference on","20120418","","","","","","","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1000145","","","","","","","","","","","","","IEEE","IEEE Conference Publications"
"Co-operative neural networks and 'integrated' classification","K. Ahmad; B. Vrusias; M. Tariq","Surrey Univ., Guildford, UK","Neural Networks, 2002. IJCNN '02. Proceedings of the 2002 International Joint Conference on","20020807","2002","2","","1546","1551","'Integrated' classification refers to the conjunctive or competitive use of two or more (neural) classifiers. A cooperative neural network system comprising two independently trained Kohonen networks and co-operating with the help of a Hebbian network, is described. The effectiveness of such a network is demonstrated by using it to retrieve images and related texts from a multi-media database. Preliminary results of such an approach appear to be encouraging","1098-7576;10987576","POD:0-7803-7278-6","10.1109/IJCNN.2002.1007747","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1007747","","Artificial intelligence;Artificial neural networks;Communication system control;Image databases;Image retrieval;Information retrieval;Learning systems;Multimedia databases;Natural language processing;Neural networks","Hebbian learning;image classification;image retrieval;multimedia databases;neural nets","Hebbian network;Kohonen networks;cooperative neural networks;integrated classification;multimedia database;neural classifiers","","1","","18","","","2002","12 May 2002-17 May 2002","IEEE","IEEE Conference Publications"
"A term-based algorithm for hierarchical clustering of Web documents","A. Schenker; M. Last; A. Kandel","Dept. of Comput. Sci. & Eng., Univ. of South Florida, Tampa, FL, USA","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","20020807","2001","","","3076","3081 vol.5","In this paper we introduce the novel class hierarchy construction algorithm (CHCA) in order to create hierarchical clusterings of Web documents. Unlike most clustering methods, CHCA operates on nominal data (the words occurring in each document) and it differs from other hierarchical clustering techniques in that it uses the object-oriented concept of inheritance to create the parent/child relationship between clusters. A prototype system has been developed using CHCA to create cluster hierarchies from web search results returned by conventional search engines. CHCA, without any guidance, creates term-based clusters from the contents of the retrieved pages and assigns each page to a cluster; the clusters correspond to topics and sub-topics in the investigated domain. The performance of our system is compared with a similar web search clustering system (Vivisimo)","","POD:0-7803-7078-3","10.1109/NAFIPS.2001.943719","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943719","","Clustering algorithms;Content based retrieval;Data mining;Information retrieval;Knowledge representation;Natural language processing;Search engines;Systems engineering and theory;Web mining;Web search","information resources;inheritance;pattern clustering","CHCA;World Wide Web documents;class hierarchy construction algorithm;hierarchical clustering;object-oriented inheritance;parent/child relationship;term-based algorithm","","3","","24","","","25-28 July 2001","25 Jul 2001-28 Jul 2001","IEEE","IEEE Conference Publications"
"Blind high-resolution localization and tracking of multiple frequency hopped signals","Xiangqian Liu; N. D. Sidiropoulos; A. Swami","Dept. of Electr. & Comput. Eng., Minnesota Univ., Minneapolis, MN, USA","IEEE Transactions on Signal Processing","20020807","2002","50","4","889","901","This paper considers the problem of blind localization and tracking of multiple frequency-hopped spread-spectrum signals using a uniform linear antenna array without knowledge of hopping patterns or directions of arrival. As a preprocessing step, we propose to identify a hop-free subset of data by discarding high-entropy spectral slices from the spectrogram. High-resolution localization is then achieved via either quadrilinear regression of four-way data generated by capitalizing on both spatial and temporal shift invariance or a new maximum likelihood (ML)-based two-dimensional (2-D) harmonic retrieval algorithm. The latter option achieves the best-known model identifiability bound while remaining close to the Cramer-Rao bound even at low signal-to-noise ratios (SNRs). Following beamforming using the recovered directions, a dynamic programming approach is developed for joint ML estimation of signal frequencies and hop instants in single-user tracking. The efficacy of the proposed algorithms is illustrated in pertinent simulations","1053-587X;1053587X","","10.1109/78.992136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=992136","","Directive antennas;Frequency estimation;Information retrieval;Linear antenna arrays;Maximum likelihood estimation;Multifrequency antennas;Signal to noise ratio;Spectrogram;Spread spectrum communication;Two dimensional displays","antenna theory;array signal processing;direction-of-arrival estimation;dynamic programming;frequency hop communication;harmonic analysis;linear antenna arrays;maximum likelihood estimation;signal resolution;spread spectrum communication;tracking","Cramer-Rao bound;ML-based 2-D harmonic retrieval algorithm;beamforming;blind high-resolution localization;blind localization;dynamic programming;four-way data;hop instants;hop-free subset;maximum likelihood-based two-dimensional harmonic retrieval algorithm;model identifiability bound;multiple frequency hopped signals;multiple frequency-hopped spread-spectrum signals;quadrilinear regression;signal frequencies;signal-to-noise ratios;single-user tracking;spatial shift invariance;temporal shift invariance;tracking;uniform linear antenna array","","42","1","26","","","Apr 2002","","IEEE","IEEE Journals & Magazines"
"Interactive ROLAP on large datasets: a case study with UB-trees","F. Ramsak; V. Markl; R. Fenk; R. Bayer; T. Ruf","Bayerisches Forschungszentrum, Munchen, Germany","Proceedings 2001 International Database Engineering and Applications Symposium","20020807","2001","","","167","176","Online analytical processing (OLAP) requires query response times within the range of a few seconds in order to allow for interactive drilling, slicing, or dicing through an OLAP cube. While small OLAP applications use multidimensional database systems, large OLAP applications like the SAP BW rely on relational (ROLAP) databases for efficient data storage and retrieval. ROLAP databases use specialized data models like star or snowflake schemata for data storage and create a large set of indexes or materialized views in order to answer queries efficiently. In our case study, we show the performance benefits of TransBase HyperCube, a commercial RDBMS, whose kernel fully integrates the UB-Tree, a multi-dimensional extension of the B-Tree. With this newly developed access structure, TransBase HyperCube enables interactive OLAP without the need for storing a large set of materialized views or creating a large set of indexes. We compare not only the query performance, but also consider index size and maintenance costs. For the case study we use a 42 million record ROLAP database of GfK, the largest German market research company","","POD:0-7695-1140-6","10.1109/IDEAS.2001.938083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938083","","Data models;Database systems;Delay;Drilling;Hypercubes;Indexes;Information retrieval;Memory;Multidimensional systems;Relational databases","data mining;interactive systems;query processing;relational databases;tree data structures;very large databases","B-Tree;GfK;OLAP cube;ROLAP database;ROLAP databases;SAP BW;TransBase HyperCube;UB-trees;access structure;case study;commercial RDBMS;data storage;dicing;index size;interactive OLAP;interactive ROLAP;interactive drilling;large OLAP applications;large datasets;large set;largest German market research company;maintenance costs;materialized views;multi-dimensional extension;multidimensional database systems;online analytical processing;performance benefits;query performance;query response times;slicing;small OLAP applications;specialized data models","","0","9","23","","","2001","16 Jul 2001-18 Jul 2001","IEEE","IEEE Conference Publications"
"Ranking a list of discrete-event models","H. de Swaan Arons; C. A. Boer","Erasmus Univ., Rotterdam, Netherlands","Proceedings 35th Annual Simulation Symposium. SS 2002","20020807","2002","","","151","159","It has been demonstrated that Arena simulation models can be parameterized and stored in a relational database for later use. In this way an Arena model can be uniquely described by assigning the right values to the corresponding parameters. These parameters contain detailed information concerning type and number of modules, entities and routes which entities follow through the system. A modeler could query such a database hoping that it would contain the Arena (sub)model that one has in mind. Unfortunately, an exact match will seldom occur but the database might contain one or more similar models. In earlier work a numerical algorithm was proposed resulting in a ranked list of simulation models in the database. According to this the lower a model is ranked the more it resembles the specified model. This model depends on a number of weight factors. In this paper the ranking algorithm is evaluated by carrying out a number of experiments.","1082-241X;1082241X","POD:0-7695-1552-5","10.1109/SIMSYM.2002.1000145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1000145","","Discrete event simulation;Distribution functions;Information retrieval;Packaging;Relational databases;Wheels","discrete event simulation;relational databases","Arena simulation models;discrete-event models;relational database;simulation models","","0","","5","","","14-18 April 2002","","IEEE","IEEE Conference Publications"
"ThemeRiver: visualizing thematic changes in large document collections","S. Havre; E. Hetzler; P. Whitney; L. Nowell","Battelle Pacific Northwest Div., Richland, WA, USA","IEEE Transactions on Visualization and Computer Graphics","20020807","2002","8","1","9","20","The ThemeRiver visualization depicts thematic variations over time within a large collection of documents. The thematic changes are shown in the context of a time-line and corresponding external events. The focus on temporal thematic change within a context framework allows a user to discern patterns that suggest relationships or trends. For example, the sudden change of thematic strength following an external event may indicate a causal relationship. Such patterns are not readily accessible in other visualizations of the data. We use a river metaphor to convey several key notions. The document collection's time-line, selected thematic content and thematic strength are indicated by the river's directed flow, composition and changing width, respectively. The directed flow from left to right is interpreted as movement through time and the horizontal distance between two points on the river defines a time interval. At any point in time, the vertical distance, or width, of the river indicates the collective strength of the selected themes. Colored ""currents"" flowing within the river represent individual themes. A current's vertical width narrows or broadens to indicate decreases or increases in the strength of the individual theme","1077-2626;10772626","","10.1109/2945.981848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981848","","Computer Society;Data visualization;Displays;Graphics;Humans;Information retrieval;Rivers;Self organizing feature maps;Wire","data visualisation;information analysis","ThemeRiver;causality;coloured currents;context framework;directed flow;external events;large document collections;pattern discernment;relationships;river composition;river metaphor;river width;selected thematic content;temporal change;thematic change visualization;thematic strength;thematic variations;time-line;trend analysis","","223","6","21","","","Jan/Mar 2002","","IEEE","IEEE Journals & Magazines"
"Precision current monitor system for the power supplies at SRRC","Yuan-Chen Chien; Chen-Yao Liu; J. Chiou; Kuo-Bin Liu; Keng Tzong Sheu","Synchrotron Radiat. Res. Center, Hsinchu, Taiwan","PACS2001. Proceedings of the 2001 Particle Accelerator Conference (Cat. No.01CH37268)","20020807","2001","5","","3690","3692 vol.5","At SRRC, a precision output current monitoring system is installed to monitor the output performance of all the booster/storage ring power supplies. Accurate DC current transformers (DCCTs) are attached to the output terminal of every power supply system. Each transformer's gain/offset are carefully calibrated against a high precision current source and approximated using high-order polynomial curve fitting. The output of each DCCT is connected to a multi-channel data logger for realtime data collection, the collected data are calibrated using the interpolated DCCT gain/offset value. A PC station is set up to serve as host to store the current output for real-time monitoring. This monitoring system provides a precise real-time database for rapid fault diagnosing whenever there is malfunction of the beam operation","","POD:0-7803-7191-7","10.1109/PAC.2001.988221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=988221","","Calibration;Current transformers;Fault diagnosis;Information retrieval;Power supplies;Radiation monitoring;Real time systems;Resistors;Temperature sensors;Voltage","constant current sources;current transformers;data loggers;electron accelerators;fault diagnosis;monitoring;particle accelerator accessories;power supplies to apparatus;storage rings;synchrotron radiation","DC current transformers;SRRC;booster/storage ring power supplies;current output;high precision current source;high-order polynomial curve fitting;multi-channel data logger;precision current monitor system;rapid fault diagnosing;realtime data collection","","0","","3","","","2001","18 Jun 2001-22 Jun 2001","IEEE","IEEE Conference Publications"
"Open source acceptance grows","A. Stone","yahoo","IEEE Software","20020807","2002","19","2","102","102","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/00991371.png"" border=""0"">","0740-7459;07407459","","10.1109/MS.2002.991371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=991371","","Application software;Information retrieval;Internet;Linux;Marketing and sales;Open source software;Source coding;Testing;Web server","","","","0","","","","","March-April 2002","","IEEE","IEEE Journals & Magazines"
"Address code and arithmetic optimizations for embedded systems","J. Ramanujam; S. Krishnamurthy; J. Hong; M. Kandemir","Dept. of Electr. & Comput. Eng., Louisiana State Univ., Baton Rouge, LA, USA","Proceedings of ASP-DAC/VLSI Design 2002. 7th Asia and South Pacific Design Automation Conference and 15h International Conference on VLSI Design","20020807","2002","","","619","624","An important class of problems used widely in both the embedded systems and scientific domains perform memory intensive computations on large data sets. These data sets get to be typically stored in main memory, which means that the compiler needs to generate the address of a memory location in order to store these data elements and generate the same address again when they are subsequently retrieved. This memory address computation is quite expensive, and if it is not performed efficiently, the performance degrades significantly. In this paper, we have developed a new compiler approach for optimizing the memory performance of subscripted or array variables and their address generation in stencil problems that are common in embedded image processing and other applications. Our approach makes use of the observation that in all these stencils, most of the elements accessed are stored close to one other in memory. We try to optimize the stencil codes with a view of reducing both the arithmetic and the address computation overhead. The regularity of the access pattern and the reuse of data elements between successive iterations of the loop body means that there is a common sub-expression between any two successive iterations; these common sub-expressions are difficult to detect using state-of-the-art compiler technology. If we were to store the value of the common sub-expression in a scalar, then for the next iteration, the value in this scalar could be used instead of performing the computation all over again. This greatly reduces the arithmetic overhead. Since we store only one scalar in a register, there is almost no register pressure. Also all array accesses are now replaced by pointer dereferences, where the pointers are incremented after each iteration. This reduces the address computation overhead. Our solution is the only one so far to exploit both scalar conversion and common sub-expressions. Extensive experimental results on several codes show that our approach performs better than the other approaches","","POD:0-7695-1441-3","10.1109/ASPDAC.2002.995005","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995005","","Arithmetic;Computer architecture;Degradation;Embedded computing;Embedded system;Information retrieval;Optimizing compilers;Programming profession;Random access memory;Registers","embedded systems;image processing;optimising compilers;storage allocation","access pattern;address code;arithmetic optimization;common sub-expression;embedded system;image processing;memory address computation;optimizing compiler;pointer dereference;scalar conversion;stencil code","","1","2","21","","","2002","07 Jan 2002-11 Jan 2002","IEEE","IEEE Conference Publications"
"Feature guide: a statistically based feature selection scheme","J. You; T. Dillon; E. Pissaloux","Hong Kong Polytech. Univ., China","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","20020807","2001","2","","717","720 vol.2","This paper presents a new approach to content-based image retrieval by addressing three primary issues: image feature extraction and representation, similarity measure, and search methods. A statistically based feature selection scheme is introduced to guide the selection of the most appropriate image features for dynamic image indexing and similarity measures. In addition, a fractional discrimination function is proposed to enhance image feature points in conjunction with image decomposition and contextual filtering for image classification. Furthermore, a feature component code is used to facilitate the hierarchical search for the best matching, where images are queried by different features or combinations. The experimental results demonstrate the effectiveness of the proposed method","","POD:0-7803-6725-1","10.1109/ICIP.2001.958594","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958594","","Content based retrieval;Feature extraction;Feedback;Histograms;Image processing;Image retrieval;Indexing;Information retrieval;Search methods;Shape","database indexing;feature extraction;filtering theory;image classification;image enhancement;image matching;image representation;image retrieval;statistical analysis;visual databases","content-based image retrieval;contextual filtering;dynamic image indexing;feature component code;feature guide;fractional discrimination function;image classification;image decomposition;image feature extraction;image feature points enhancement;image matching;image representation;search methods;similarity measure;similarity measures;statistically based feature selection","","0","","7","","","7-10 Oct 2001","07 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"A comparison between single-agent and multi-agent classification of documents","S. Peng; S. Mukhopadhyay; R. Raje; M. Palakal; J. Mostafa","Indiana University Purdue University","Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001","20020807","2001","","","935","944","<div style=""font-variant: small-caps; font-size: .9em;"">First Page of the Article</div><img class=""img-abs-container"" style=""width: 95%; border: 1px solid #808080;"" src=""/xploreAssets/images/absImages/00925048.png"" border=""0"">","1530-2075;15302075","POD:0-7695-0990-8","10.1109/IPDPS.2001.925048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925048","","Collaboration;Computer science;Information filtering;Information filters;Information retrieval;Information science;Libraries;Multiagent systems;Thesauri;Vocabulary","","","","3","","12","","","23-27 April 2000","","IEEE","IEEE Conference Publications"
"Mobile database procedures in MDBAS","R. Vlach","Fac. of Math. & Phys., Charles Univ., Prague, Czech Republic","12th International Workshop on Database and Expert Systems Applications","20020807","2001","","","559","563","MDBAS is a prototype of a multidatabase management system based on mobile agents. The system integrates a set of autonomous databases distributed over a network, enables users to create a global database scheme, and manages transparent distributed execution of user requests and procedures including distributed transactions. The paper highlights the issues related to mobile database procedures, especially the MDBAS execution strategy. In order to adequately assess MDBAS's qualities and bottlenecks, we have carried out complex performance evaluation with real databases distributed in a real Internet. The evaluation included a comparison to a commercial database with distributed database capabilities. The most interesting results are presented and commented","","POD:0-7695-1230-5","10.1109/DEXA.2001.953118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953118","","Distributed computing;Distributed databases;Employment;Information retrieval;Java;Mathematics;Mobile agents;Sections;Software engineering;Transaction databases","Internet;client-server systems;distributed databases;multi-agent systems;performance evaluation;query processing;software agents","Internet;MDBAS;autonomous databases;commercial database;distributed transactions;global database scheme;mobile agents;mobile database procedures;multidatabase management system;performance evaluation;transparent distributed execution;user requests","","0","","10","","","2001","03 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"Improvement of spine implant performance through analysis of retrieved implants: preliminary results","J. L. Turner; J. R. Boatwright; A. R. Vaccaro; A. S. Hilibrand; T. J. Albert; M. L. Villarraga; P. A. Cripton","Sch. of Biomed. Eng. & Health Syst., Drexel Univ., Philadelphia, PA, USA","Proceedings of the IEEE 28th Annual Northeast Bioengineering Conference (IEEE Cat. No.02CH37342)","20020807","2002","","","159","160","A spine implant retrieval program has recently been established at the Implant Research Center at Drexel University in collaboration with the Rothman Institute at Thomas Jefferson University. Engineering failure analysis of the retrieved implants, tissue analysis and medical record evaluations are performed and synthesized. The relevant failure mechanisms can then be definitively identified. The results of these evaluations will ultimately lead to improvements in the longterm clinical performance of spinal implants","","POD:0-7803-7419-3","10.1109/NEBC.2002.999514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=999514","","Biomedical engineering;Biomedical imaging;Collaboration;Failure analysis;Implants;Information analysis;Information retrieval;Medical diagnostic imaging;Performance analysis;Surgery","biomechanics;fracture mechanics;orthopaedics;prosthetics;stress analysis;wear","engineering failure analysis;fracture mechanics evaluations;fracture mechanism;light microscopy;long-term clinical performance;material degradation;mechanical degradation;medical record evaluations;radiographic reports;revision surgery;rod/hook connector failure;rod/screw connector failure;scanning electron microscopy;spine implant performance improvement;spine implant retrieval program;stress analysis;tissue analysis","","0","","2","","","2002","20 Apr 2002-21 Apr 2002","IEEE","IEEE Conference Publications"
"Performance analysis of a distributed question/answering system","M. Surdeanu; D. I. Moldovan; S. M. Harabagin","Dept. of Comput. Sci. & Eng., Southern Methodist Univ., Dallas, TX, USA","Proceedings 15th International Parallel and Distributed Processing Symposium. IPDPS 2001","20020807","2001","","","6 pp.","","The problem of question/answering (Q/A) is to find answers to open-domain questions by searching a large collection of documents. Unlike Internet search engines, Q/A systems provide short, relevant answers to questions. Due to the complex natural language processing involved that is CPU intensive, and the retrieval of large number of documents that is disk intensive, the time performance of sequential Q/A systems is rather slow. This paper presents the design and performance analysis of a distributed state-of-the-art Q/A system. The design is modular and parallelism is dynamically exploited at inter and intra-question levels. Several schedule points are used to balance the load. An analytical performance model is given backed up by experimental results","1530-2075;15302075","POD:0-7695-0990-8","10.1109/IPDPS.2001.924952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=924952","","Distributed computing;Dynamic scheduling;Information retrieval;Internet;Load management;NIST;Natural language processing;Parallel processing;Performance analysis;Throughput","distributed processing;natural language interfaces;performance evaluation;resource allocation","distributed question/answering;documents;natural language processing;open-domain questions;performance analysis;performance model;schedule points","","1","","8","","","Apr 2001","23 Apr 2001-27 Apr 2001","IEEE","IEEE Conference Publications"
"Scheduling aspects for image retrieval in cluster-based image databases","O. Kao; G. Steinert; F. Drews","Dept. of Comput. Sci., Tech. Univ. Clausthal, Germany","Proceedings First IEEE/ACM International Symposium on Cluster Computing and the Grid","20020807","2001","","","329","336","Systems for the archival and retrieval of images are used in many areas, for example medical applications, news agencies, etc. The state-of-the-art approach for image description considers a priori extracted features. The disadvantageous reduction of the image content onto a few low-level features limits the applicability of image databases. A search for objects and other important image components requires dynamic feature extraction. The related computational and storage requirements exceed the possibilities of computer architectures with a single processing element. Therefore we developed a cluster platform, which supports the implementation of this novel retrieval approach in existing systems. We introduce the basic principles of image retrieval with dynamic feature extraction and a cluster platform. The main focus regards thereby the workload balancing across the cluster. For this purpose we developed a scheduling heuristic and executed performance measurements with the implemented prototype. The obtained results are discussed","","POD:0-7695-1010-8","10.1109/CCGRID.2001.923210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=923210","","Biomedical equipment;Computer architecture;Data mining;Feature extraction;Focusing;Image databases;Image retrieval;Information retrieval;Medical services;Processor scheduling","feature extraction;image retrieval;resource allocation;scheduling;software performance evaluation;visual databases;workstation clusters","cluster platform;cluster-based image databases;dynamic feature extraction;image description;image retrieval;performance measurements;scheduling;workload balancing","","7","","11","","","2001","15 May 2001-18 May 2001","IEEE","IEEE Conference Publications"
"Subband-based, memory-efficient JPEG2000 images indexing in compressed-domain","Ziyou Xiong; T. S. Huang","Dept. of Electr. & Comput. Eng., Illinois Univ., Urbana, IL, USA","Proceedings Fifth IEEE Southwest Symposium on Image Analysis and Interpretation","20020807","2002","","","290","294","The contribution of this paper is the development of a fast, subband-based JPEG2000 image indexing system in the compressed domain which achieves high memory efficiency. This is the extended work on a previously block-based indexing system. The feature extracted is variance of each wavelet subband in the compressed domain with the emphasis that subbands are not buffered to maintain memory efficiency. Retrieval performance on VisTex image database indexing has shown the effectiveness and speed up of execution of the proposed features","","POD:0-7695-1537-1","10.1109/IAI.2002.999935","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=999935","","Decoding;Discrete wavelet transforms;Feature extraction;Image coding;Image databases;Image retrieval;Indexing;Information retrieval;Transform coding;Wavelet domain","code standards;data compression;database indexing;feature extraction;image coding;image retrieval;transform coding;visual databases;wavelet transforms","JPEG2000;VisTex image database;feature extraction;image compression;memory efficiency;retrieval performance;speed up;subband-based image indexing;wavelet subband variance","","1","","9","","","2002","07 Apr 2002-09 Apr 2002","IEEE","IEEE Conference Publications"
"Multiple classifiers for color flag and trademark image retrieval","Ing-Sheen Hsieh; Kuo-Chin Fan","Inst. of Comput. Sci. & Inf. Eng., Nat. Central Univ., Chung-Li, Taiwan","IEEE Transactions on Image Processing","20020807","2001","10","6","938","950","A novel region-based multiple classifier color image retrieval system is presented. In our approach, a region-growing technique is first employed to cluster connected color pixels with the same color in an image to form color regions which are the primitive elements utilized in our proposed approach. Then, three complementary region-based classifiers that we developed are selected in the classifier selection stage, which include color classifier, shape classifier, and relational classifier. In each classifier, a virtue probability representing the probability that an image is similar to the query image is defined. Thereafter a set of virtue probabilities is calculated in each classifier. Next, the measurement dependent methods are applied to combine the virtue probabilities of classifiers in the decision combination stage. The dynamic selection scheme designed in the decision combination stage can further improve the system performance dramatically. Experimental results reveal the feasibility and validity of our proposed approach in solving the color image retrieval problem","1057-7149;10577149","","10.1109/83.923290","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=923290","","Color;Image databases;Image matching;Image retrieval;Information retrieval;Pattern recognition;Pixel;Probability;Shape;Trademarks","image classification;image colour analysis;image retrieval;probability","color classifier;color flag image retrieval;color image retrieval system;color regions;color trademark image retrieval;connected color pixels clustering;decision combination stage;dynamic selection;measurement dependent methods;primitive elements;query image;region-based multiple classifier;region-growing technique;relational classifier;shape classifier;system performance;virtue probability","","9","1","28","","","Jun 2001","","IEEE","IEEE Journals & Magazines"
"Towards a two-layered video metadata model","C. Tsinaraki; S. Papadomanolakis; S. Christodoulakis","Lab. of Distributed Multimedia Inf. Syst. & Appl., Tech. Univ. Crete, Khania, Greece","12th International Workshop on Database and Expert Systems Applications","20020807","2001","","","937","941","We propose a model for video metadata that supports video retrieval based on video content, video structure and/or video attributes. Our model supports video retrieval based on the relationships among videos and between videos and real world objects. This model is also appropriate for providing personalization and recommendation functionality in video based services, while it takes into account events covered by more than one cameras. Our model is two-layered: in the first layer, a set of core classes appropriate for supporting any video type (e.g. news, movies, football matches, etc.) is defined; in the second layer, we define a set of classes, specific for each video type, that permit a more complete description of the videos of that type. We decided to implement our model using the functionality provided by MPEG-7","","POD:0-7695-1230-5","10.1109/DEXA.2001.953175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953175","","Cameras;Content based retrieval;Information retrieval;Information systems;Motion pictures;Multimedia systems;Relational databases;Software libraries;TV;Video on demand","content-based retrieval;digital libraries;meta data;video databases","MPEG-7;personalization;real world objects;recommendation functionality;two-layered video metadata model;video attributes;video based services;video content;video retrieval;video structure;video type","","1","","13","","","2001","03 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"A trial for data retrieval using conceptual fuzzy sets","T. Takagi; K. Kawase","Dept. of Comput. Sci., Meiji Univ., Kanagawa, Japan","IEEE Transactions on Fuzzy Systems","20020807","2001","9","4","497","505","We describe trial applications of fuzzy sets to data retrieval. The objectives are to test their ability to achieve conceptual matching between retrieved objects and the user's intention and to connect real data with symbolic notations. The algorithm proposed retrieves data that conceptually fit the meanings of the entered keyword. An algorithm is described that uses fuzzy sets to handle word ambiguity (the main cause of vagueness in the meaning of a word). It is based on conceptual fuzzy sets (CFSs), which represent the meaning of words by chaining other related words. Two trial applications of this algorithm to data retrieval are described. First, an application to image retrieval shows variation of data retrieval with conceptual matching and transformation of numeric values into symbols. Next, an application to the agent recommending a TV program shows the method that lets CFSs fit to the sense of a user by Hebbian learning","1063-6706;10636706","","10.1109/91.940963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=940963","","Application software;Computer science;Fuzzy sets;Hebbian theory;Image retrieval;Information retrieval;Prototypes;TV;Testing;Vehicles","Hebbian learning;fuzzy set theory;image retrieval;pattern matching;uncertainty handling","Hebbian learning;conceptual fuzzy sets;conceptual matching;data retrieval;fuzzy set theory;image retrieval;vagueness;word meaning","","7","","17","","","Aug 2001","","IEEE","IEEE Journals & Magazines"
"User-interaction supported data-retrieving engine for distributed multimedia presentations","Chun-Chuan Yang","Multimedia & Commun. Lab., Nat. Chi-Nan Univ., Taiwan","ICC 2001. IEEE International Conference on Communications. Conference Record (Cat. No.01CH37240)","20020807","2001","10","","3244","3250 vol.10","Distributed multimedia presentation enables users to view a multimedia presentation in the distributed manner, in which the objects of the presentation are located in remote sites. User-interaction provides the viewer with convenient viewing styles like fast forward and fast backward for a presentation, but it also introduces complexity to the data-retrieving engine. A smart data-retrieving engine that supports user interactions for the Synchronization Multimedia Integration Language (SMIL) based multimedia presentation is proposed in the paper. The SMIL script of the presentation is first converted to real-time synchronization model (RTSM) in order to provide a systematic view of the synchronization relationship. The algorithm for determining the proper objects to be retrieved as well as the pre-fetch time of the object under user actions is proposed for the data-retrieving engine","","POD:0-7803-7097-1","10.1109/ICC.2001.937269","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=937269","","Computer networks;Computer science;Distributed computing;Engines;High-speed networks;Information retrieval;Laboratories;Multimedia communication;Multimedia systems;Network servers","distributed object management;multimedia servers;multimedia systems;search engines;synchronisation","SMIL-based distributed multimedia presentation;Synchronization Multimedia Integration Language;data-retrieving engine;fast backward;fast forward;object pre-fetch time;object retrieval process;real-time synchronization model;smart engine;synchronization relationship;user-interaction;viewing styles","","2","1","16","","","2001","11 Jun 2001-14 Jun 2001","IEEE","IEEE Conference Publications"
"The GC-tree: a high-dimensional index structure for similarity search in image databases","Guang-Ho Cha; Chin-Wan Chung","Dept. of Multimedia Sci., Sookmyung Women's Univ., Seoul, South Korea","IEEE Transactions on Multimedia","20020807","2002","4","2","235","247","We propose a new dynamic index structure called the GC-tree (or the grid cell tree) for efficient similarity search in image databases. The GC-tree is based on a special subspace partitioning strategy which is optimized for a clustered high-dimensional image dataset. The basic ideas are threefold: 1) we adaptively partition the data space based on a density function that identifies dense and sparse regions in a data space; 2) we concentrate the partition on the dense regions, and the objects in the sparse regions of a certain partition level are treated as if they lie within a single region; and 3) we dynamically construct an index structure that corresponds to the space partition hierarchy. The resultant index structure adapts well to the strongly clustered distribution of high-dimensional image datasets. To demonstrate the practical effectiveness of the GC-tree, we experimentally compared the GC-tree with the IQ-tree, LPC-file, VA-file, and linear scan. The result of our experiments shows that the GC-tree outperforms all other methods.","1520-9210;15209210","","10.1109/TMM.2002.1017736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1017736","","Degradation;Density functional theory;Image databases;Image retrieval;Indexes;Indexing;Information retrieval;Multimedia databases;Nearest neighbor searches;Vectors","database indexing;multimedia databases;query processing;search problems;tree data structures;visual databases","GC-tree;data space;dynamic index structure;grid cell tree;high-dimensional indexing;image database;nearest neighbor search;similarity search","","28","","23","","","Jun 2002","","IEEE","IEEE Journals & Magazines"
"Visual exploration and functional document labeling","W. Eglin; A. Gagneux","Lab. de Reconnaissance de Formes et Vision RFV, Inst. Nat. des Sci. Appliquees de Lyon, Villeurbanne, France","Proceedings of Sixth International Conference on Document Analysis and Recognition","20020807","2001","","","816","820","This paper presents a new approach to textual data labeling based on texture analysis. Texture is used here to show the impact of document composition on visual exploration. We demonstrate how textural properties are well adapted to typography characterization by categorizing document regions into visual text classes (such as headings, head- and footnotes, paragraphs, abstracts, etc.). We reference and classify different types of text fonts according to their visual aspect and the visual impression that emerges from the textual data. Experiments on a set of various document images show a good accuracy and robustness for our method","","POD:0-7695-1263-1","10.1109/ICDAR.2001.953901","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953901","","Abstracts;Content based retrieval;Frequency;Information analysis;Information retrieval;Labeling;Pareto analysis;Reconnaissance;Robustness;Text analysis","document image processing;image classification;indexing","abstracts;classification procedure;document composition;document images;document indexing;footnotes;headings;paragraphs;text fonts;textual data;textual data labeling;texture analysis;typography characterization;visual text classes;zone labeling","","2","","14","","","2001","10 Sep 2001-13 Sep 2001","IEEE","IEEE Conference Publications"
"Extended concept-based image retrieval system (E-COIRS)","Yong-Il Kim; Jae-Dong Yang; Hyung-Jeong Yang","Dept. of Comput. Sci., Chonbuk Nat. Uni., South Korea","Proceedings of IEEE Region 10 International Conference on Electrical and Electronic Technology. TENCON 2001 (Cat. No.01CH37239)","20020807","2001","1","","335","340 vol.1","In this paper, we design and implement E-COIRS enabling users to query with concepts and image features used for further refining the concepts. For example, E-COIRS supports the query 'retrieve images that a black home appliance is to north of reception set'. The query includes two types of concepts: IS-A and aggregation-'home appliance' is an IS-A concept, and 'reception set' is an aggregation concept. For evaluating such a query, E-COIRS includes three Important components: a visual image indexer, thesauri and a query processor. Each pair of objects in an image captured by the visual image indexer is converted into a triple. The triple consists of two object identifiers (oids) and their spatial relationship. All the feature of an object is referenced by its old. The thesauri, which are mainly used by the query processor to detect concepts, consist of a triple rule-based thesaurus and a term thesaurus. The query processor obtains an image set associated with each triple in a user query by looking up an inverted file and CS-Tree. To support efficient storage use and fast retrieval on high-dimensional feature vectors, E-COIRS uses a new Cell-based Signature tree. E-COIRS is a more advanced content-based image retrieval system than other systems which support only concepts or image features","","POD:0-7803-7101-1","10.1109/TENCON.2001.949609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=949609","","Computer science;Content based retrieval;Home appliances;Image converters;Image retrieval;Indexing;Information retrieval;Shape;Telephony;Thesauri","content-based retrieval;image retrieval;visual databases","E-COIRS;content-based image retrieval;image indexing;image retrieval system;query processor","","0","","7","","","2001","19 Aug 2001-22 Aug 2001","IEEE","IEEE Conference Publications"
"A new query processing technique for XML based on signature","S. Park; Hyoung-Joo Kim","Sch. of Comput. Sci. & Eng., Seoul Nat. Univ., South Korea","Proceedings Seventh International Conference on Database Systems for Advanced Applications. DASFAA 2001","20020807","2001","","","22","29","XML is represented as a tree and the query as a regular path expression. The query is evaluated by traversing each node of the tree. Several indexes are proposed for regular path expressions. In same cases these indexes may not cover all possible paths because of storage requirements. We propose a signature-based query optimization technique to minimize the number of nodes retrieved from the database when the indexes cannot be used. The signature is a hint attached to each node, and is used to prune unnecessary sub-trees as early as possible when traversing nodes. For this goal, we propose a signature-based DOM(s-DOM) as a storage model and a signature-based query executor(s-NFA). Our experimental results show that the signature method outperforms the original.","","POD:0-7695-0996-7","10.1109/DASFAA.2001.916360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=916360","","Computer science;Data models;Database systems;Finance;Indexes;Information retrieval;Object oriented modeling;Query processing;Telephony;XML","database indexing;hypermedia markup languages;object-oriented databases;query processing;tree data structures","XML;experimental results;object oriented database;query processing;regular path expression;signature method;signature-based query executor;signature-based query optimization;storage model;storage requirements;tree data structure","","4","10","24","","","21-21 April 2001","18 Apr 2001-21 Apr 2001","IEEE","IEEE Conference Publications"
"Using the CLEAN algorithm to restore undersampled synthetic aperture sonar images","K. M. Chick; K. Warman","Dynamics Technol. Inc., Torrance, CA, USA","MTS/IEEE Oceans 2001. An Ocean Odyssey. Conference Proceedings (IEEE Cat. No.01CH37295)","20020807","2001","1","","170","178 vol.1","We present an implementation of the CLEAN algorithm for synthetic aperture sonar. The algorithm is designed to restore image degradation due to gaps in data. We have studied its performance on a variety of scenes based on both simulated and real sonar data. When the scene is composed of point-like targets, the algorithm performs very well, rapidly retrieving the true image that would be derived from fully sampled data. This success can be achieved in spite of a substantial 50% undersampling fraction, corresponding to a platform tow-speed twice as fast as the synthetic aperture limit. However, when the scene is composed of extended bright regions, the algorithm tends to either converge extremely slowly, or fail entirely. Quantitative measures of the rate and degree of restoration are discussed, as well as images before and after the CLEAN process. If the data gaps are caused by towing a sonar platform at a speed in excess of the natural synthetic aperture limit, the successful repair of images derived from undersampled data permits an acceleration in the rate at which the seafloor may be surveyed for mines","","POD:0-933957-28-9","10.1109/OCEANS.2001.968705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=968705","","Acceleration;Algorithm design and analysis;Degradation;Image converters;Image restoration;Image retrieval;Information retrieval;Layout;Sonar measurements;Synthetic aperture sonar","image restoration;image retrieval;image sampling;sonar imaging;synthetic aperture sonar","CLEAN algorithm;extended bright regions;image degradation;image restoration;image retrieval;mines;platform tow-speed;point-like targets;quantitative measures;real sonar data;restoration degree;restoration rate;seafloor survey;simulated sonar data;sonar platform;synthetic aperture limit;undersampled synthetic aperture sonar images;undersampling fraction","","3","4","8","","","2001","05 Nov 2001-08 Nov 2001","IEEE","IEEE Conference Publications"
"Best-match retrieval for structured images","A. Ferro; G. Gallo; R. Giugno; A. Pulvirenti","Dipartimento di Matematica e Inf., Catania Univ., Italy","IEEE Transactions on Pattern Analysis and Machine Intelligence","20020807","2001","23","7","707","718","Propose a methodology for fast best-match retrieval of structured images. A triangle inequality property for the tree-distance introduced by Oflazer (1997) is proven. This property is, in turn, applied to obtain a saturation algorithm of the trie used to store the database of the collection of pictures. The new approach can be considered as a substantial optimization of Oflazer's technique and can be applied to the retrieval of homogeneous hierarchically structured objects of any kind. The new technique inscribes itself in the number of distance-based search strategies and it is of interest for the indexing and maintenance of large collections of historical and pictorial data. We demonstrate the proposed approach on an example and report data about the speed-up that it introduces in query processing. Direct comparison with an MVP-trees algorithm is also presented","0162-8828;01628828","","10.1109/34.935845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=935845","","Computer Society;Data structures;Image databases;Image retrieval;Indexing;Information retrieval;Memory;Query processing;Robustness;Web sites","image retrieval;optimisation;query formulation;tree searching","MVP-trees algorithm;best-match retrieval;distance-based search strategies;homogeneous hierarchically structured objects;pictures collection;saturation algorithm;structured images;tree-distance;triangle inequality property","","2","","26","","","Jul 2001","","IEEE","IEEE Journals & Magazines"
"Integrating document and workflow management systems","L. Aversano; G. Canfora; A. De Lucia; P. Gallucci","Fac. of Eng., Univ. of Sannio, Benevento, Italy","Proceedings IEEE Symposia on Human-Centric Computing Languages and Environments (Cat. No.01TH8587)","20020807","2001","","","328","329","A critical point for developing successful information systems for distributed organisations is the need for integrating heterogeneous technologies and tools. This paper reports on an experience of integrating two key enabling technologies, namely workflow and document management","","POD:0-7803-7198-4","10.1109/HCC.2001.995281","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995281","","Communications technology;Computer networks;Information retrieval;Management information systems;Project management;Relational databases;Space technology;Technology management;Web server;XML","document handling;hypermedia;visual languages;workflow management software","GIANO;distributed organisations;document management system;heterogeneous technologies;hypertext;information systems;visual languages;workflow management systems","","2","","3","","","2001","05 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"Encapsulating classification in an OODBMS for data mining applications","L. Al-Jadir","Dept. of Math. & Comput. Sci., American Univ. of Beirut, Lebanon","Proceedings Seventh International Conference on Database Systems for Advanced Applications. DASFAA 2001","20020807","2001","","","100","106","Classification is an important task in data mining. Encapsulating classification in an object-oriented database system requires additional features: we propose multiobjects and schema evolution. Our approach allows us to store classification functions, and to store instances of each group in order to retrieve them later. Since the database is operational, it allows us also to perform dynamic classification, i.e. add/remove instances to/from groups over time. Moreover it allows us to update classification functions (if we choose another population sample or apply another classifier) and have the instances of groups consequently reclassified. We illustrate our approach with a target mailing application.","","POD:0-7695-0996-7","10.1109/DASFAA.2001.916370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=916370","","Application software;Computer science;Data mining;Database systems;History;Information retrieval;Mathematics;Medical diagnosis;Object oriented databases;Spatial databases","data mining;marketing data processing;object-oriented databases;pattern classification","classification encapsulation;classification function storage;classification function updating;data mining;dynamic classification;multiobjects;object-oriented database system;schema evolution;target mailing application","","1","","21","","","21-21 April 2001","18 Apr 2001-21 Apr 2001","IEEE","IEEE Conference Publications"
"Data classification and management in very large data warehouses","K. Chelluri; V. Kumar","Comput. Sci. Telecommun. Program, Missouri Univ., Kansas City, MO, USA","Proceedings Third International Workshop on Advanced Issues of E-Commerce and Web-Based Information Systems. WECWIS 2001","20020807","2001","","","52","57","A data warehouse mainly deals with historical data and specialized retrieval. In this research, we classify historical data and present a scheme for its efficient handling. Our classification of historical data is based on its inherent properties and frequency of use, which involves time. We have used a multi-dimensional grid file organization for storing historical data and supporting its efficient management. We have defined operations, such as merge, split, reorganize, etc., which are essential for managing the storage organization. The dynamic nature of the multi-dimensional grid file is used to identify and archive stale data and to optimize storage usage","","POD:0-7695-1224-0","10.1109/WECWIS.2001.933905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=933905","","Cities and towns;Computer science;Data warehouses;Database systems;Degradation;Frequency;Information analysis;Information management;Information retrieval;Telephony","classification;data warehouses;file organisation;temporal databases","data classification;data handling;data management;data operations;data use frequency;historical data;multi-dimensional grid file organization;optimized storage usage;real-time database;specialized data retrieval;stale data archiving;storage organization;temporal database;very large data warehouses","","2","1","9","","","2001","21 Jun 2001-22 Jun 2001","IEEE","IEEE Conference Publications"
"Searching and surfing the Web using a semi-adaptive meta-engine","A. Castellucci; G. Ianni; D. Vasile; S. Costa","DEIS, Calabria Univ., Italy","Proceedings International Conference on Information Technology: Coding and Computing","20020807","2001","","","416","420","Global Search is a World Wide Web agent which integrates and enhances many well-known search techniques in order to improve the quality of information gathered from the usual Web search engines. It features intelligent merging of relevant documents from different search engines, anticipated adaptive exploration and evaluation of links from the current result set, and automated derivation of refined queries based on user relevance feedback","","POD:0-7695-1062-0","10.1109/ITCC.2001.918832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=918832","","Explosives;Feedback;Indexing;Information retrieval;Internet;Merging;Search engines;Web pages;Web search;Web sites","adaptive systems;hypermedia;information resources;merging;relevance feedback;search engines;software agents;user modelling","Global Search;Web agent;Web surfing;World Wide Web;anticipated adaptive exploration;automated query derivation;hyperlink evaluation;information quality improvement;intelligent document merging;refined queries;result set;search engines;search techniques;semi-adaptive meta-engine;user relevance feedback","","2","2","22","","","Apr 2001","02 Apr 2001-04 Apr 2001","IEEE","IEEE Conference Publications"
"A speech recognition and speech corpus system based on Matlab","Qiang He; Youwei Zhang","Dept. of Electr. Eng., Tsinghua Univ., Beijing, China","Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing. ISIMP 2001 (IEEE Cat. No.01EX489)","20020807","2001","","","559","562","In this paper, an educational mandarin syllable speech recognition and speech corpus system based on Matlab and SQL is introduced. The system includes a set of mixture CDHMM training and recognition algorithms both in Matlab M-files and optimized MEX-files, which can deal with multi-observations and scaling problems; a database toolbox to save and retrieve binary speech samples to and from a SQL database; a real-time speech recording ActiveX control to record speech samples and perform endpoint-detection. The three parts are integrated into Matlab to build up a speech recognition system mainly for educational purposes. It has been used in 408 mandarin syllables speech recognition; and a baseline recognition rate of 91.5% is reached","","POD:962-85766-2-3","10.1109/ISIMP.2001.925457","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925457","","Control systems;Databases;Helium;Hidden Markov models;Information retrieval;Information science;MATLAB;Programming profession;Real time systems;Speech recognition","SQL;hidden Markov models;mathematics computing;real-time systems;relational databases;speech recognition","ActiveX;CDHMM;Matlab;SQL;binary speech samples;education;endpoint-detection;hidden Markov model;mandarin syllable speech recognition;optimized MEX-files;real-time speech recording;relational database;speech corpus system","","1","","9","","","2001","02 May 2001-04 May 2001","IEEE","IEEE Conference Publications"
"Indexing of technical line drawings based on F-signatures","S. Tabbone; L. Wendling; K. Tombre","LORIA, Vandoeuvre-les-Nancy, France","Proceedings of Sixth International Conference on Document Analysis and Recognition","20020807","2001","","","1220","1224","We propose a method for indexing technical drawings. Our features are based on the notion of F-signature, which is a particular histogram of forces. The force histogram has low time complexity and describes a signature which is invariant to scaling, translation, symmetry and rotation. This article presents a new application of such signatures in the field of document analysis, and tests different characteristics of the F-signatures, like their sensitivity to the shape of the objects and to noise. Finally, experimental results show the effectiveness of such an approach. A brief overview of pattern recognition approaches dedicated to technical document indexing is given. The notions of histogram of forces and of its properties are presented","","POD:0-7695-1263-1","10.1109/ICDAR.2001.953977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953977","","Graphics;Histograms;Indexing;Information retrieval;Labeling;Noise shaping;Pattern recognition;Shape;Testing;Text analysis","engineering graphics;indexing;pattern recognition","F-signatures;force histogram;indexing;pattern recognition;shape Discrimination;technical drawings","","3","","15","","","2001","10 Sep 2001-13 Sep 2001","IEEE","IEEE Conference Publications"
"Evolutionary patterns of agent organizations","C. V. Goldman; J. S. Rosenschein","Dept. of Comput. Sci., Massachusetts Univ., Amherst, MA, USA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20020807","2002","32","1","135","148","Problems approached by multi-agent systems are typically complex. It is usually difficult to know at system design stage how many agents need to be in the system, what each agent's role is, and how the agents should interact to get optimal performance out of the group. The aim of the testbed presented here is to investigate which kinds of multi-agent systems could be developed to solve ranges of problems, avoiding the need to reorganize the agents from scratch for each task. The agent organization process explored here is based on the agents' knowledge, and not on their tasks. This opens up a new approach for distributed artificial intelligence designers to have their domain organized before the allocation of tasks among agents. These kinds of organizations should be more robust for solving different problems related to the same knowledge. We define information oriented domains for that purpose. An evolutionary approach to the design of a multi-agent system is suggested. Our model is based on a cellular automaton whose rules of dynamics induce the formation of an organization of agents. Patterns of organization obtained empirically are presented. Our knowledge-based organization approach is analyzed both from theoretical and practical perspectives","1083-4427;10834427","","10.1109/3468.995535","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995535","","Artificial intelligence;Automata;Computer science;Evolutionary computation;Information retrieval;Multiagent systems;Organizing;Problem-solving;Robustness;System testing","cellular automata;evolutionary computation;knowledge based systems;knowledge representation;multi-agent systems","agent organization;cellular automata;distributed artificial intelligence;expert agents;information domain;information oriented domains;knowledge-based organization;multiple agent systems","","10","1","36","","","Jan 2002","","IEEE","IEEE Journals & Magazines"
"Constraint adaptive segmentation for color image coding and content-based retrieval","G. Qiu","Sch. of Comput. Sci., Nottingham Univ., UK","2001 IEEE Fourth Workshop on Multimedia Signal Processing (Cat. No.01TH8564)","20020807","2001","","","269","274","We present a constraint adaptive image segmentation technique designed to achieve the combined purposes of color image coding/compression, indexing and content-based retrieval. An image is segmented into homogeneous squared regions of variable sizes such that it can be encoded very efficiently. From the segmented image, we derive an effective and efficient image content description feature termed the region and color co-occurrence matrix (RACOM) as image index for content-based indexing and retrieval. Experimental results are presented to demonstrate that RACOM is a very effective image content description feature and has comparable performance to state of the art methods, colour correlogram and MPEG7 colour structure histogram, in content-based image retrieval from large image databases","","POD:0-7803-7025-2","10.1109/MMSP.2001.962745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=962745","","Color;Content based retrieval;Histograms;Image coding;Image databases;Image retrieval;Image segmentation;Indexing;Information retrieval;MPEG 7 Standard","content-based retrieval;data compression;database indexing;feature extraction;image coding;image colour analysis;image retrieval;image segmentation;very large databases;visual databases","RACOM;color image coding;constraint adaptive image segmentation;content description feature;content-based indexing;content-based retrieval;homogeneous squared regions;image compression;image index;large image databases;performance;region and color co-occurrence matrix","","0","","9","","","2001","03 Oct 2001-05 Oct 2001","IEEE","IEEE Conference Publications"
"Automatic main melody extraction from midi files with a modified Lempel-Ziv algorithm","Hsuan-Huei Shih; S. S. Narayanan; C. C. J. Kuo","Dept. of Electr. Eng. Syst., Univ. of Southern California, Los Angeles, CA, USA","Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing. ISIMP 2001 (IEEE Cat. No.01EX489)","20020807","2001","","","9","12","A dictionary based approach for extracting repetitive patterns in music aimed at music feature extraction and indexing for audio database management is proposed. Segmentation is achieved based on the tempo information and a music score is decomposed into bars. Each bar is indexed and a bar index table is built. Then, an adaptive dictionary based compression algorithm known as Lempel Ziv 78 (LZ-78) is applied to the bar-represented music scores to extract repetitive patterns (J. Ziv and A. Lempel, 1978). Finally, pruning is performed to this dictionary to remove non-repeating patterns and combine shorter repeating patterns into a longer repeating pattern. The LZ78 algorithm is slightly modified to achieve better results in the current context. Experiments are performed to MIDI files, and the proposed algorithm has demonstrated an excellent performance","","POD:962-85766-2-3","10.1109/ISIMP.2001.925317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925317","","Audio databases;Data engineering;Data mining;Dictionaries;Feature extraction;Hidden Markov models;Indexing;Multimedia databases;Music information retrieval;Spatial databases","audio signal processing;data compression;multimedia databases;music;pattern classification","LZ-78;Lempel Ziv 78;adaptive dictionary based compression algorithm;audio database management;automatic main melody extraction;bar index table;bar-represented music scores;dictionary based approach;midi files;modified Lempel-Ziv algorithm;music feature extraction;music score;non-repeating patterns;pruning;repetitive pattern extraction;repetitive patterns;segmentation;shorter repeating patterns;tempo information","","4","1","9","","","2001","02 May 2001-04 May 2001","IEEE","IEEE Conference Publications"
"The importance of extensible database systems for e-commerce","S. DeFazio; R. Krishnan; J. Srinivasan; S. Zeldin","New England Dev. Center, Oracle Corp., Nashua, NH, USA","Proceedings 17th International Conference on Data Engineering","20020807","2001","","","63","70","Over the last decade, database system products have been extended to provide support for defining, storing, updating, indexing and retrieving complex data with full transaction semantics. Oracle, IBM, Informix and others have used extensibility technology to build database system extensions for text, image, spatial, audio/video, chemical, genetic and other types of complex data. Currently, we find database systems being deployed in support of e-commerce. In many cases, these e-commerce database applications use only simple SQL data types to represent items such as office supplies, computers, books and CDs. There is also a large and important set of e-commerce applications that employ complex data formats such as EDI, SWIFT and HL7. The database extensibility features initially developed to support text, spatial and similar forms of complex data are now being used to build e-commerce applications. Thus, database extensibility technology is evolving into an important mechanism to enable the development of e-commerce systems","1063-6382;10636382","POD:0-7695-1001-9","10.1109/ICDE.2001.914814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=914814","","Application software;Books;Chemical technology;Database systems;Genetics;Image databases;Indexing;Information retrieval;Spatial databases;Transaction databases","abstract data types;database indexing;database management systems;electronic commerce;management information systems","SQL data types;complex data formats;database extensibility technology;database system extensions;electronic commerce;extensible database systems;transaction semantics","","5","","26","","","2001","02 Apr 2001-06 Apr 2001","IEEE","IEEE Conference Publications"
"Learning similarity matching in multimedia content-based retrieval","Joo-Hwee Lim; W. Jian Kang; S. Singh; D. Narasimhalu","Kent Ridge Digital Labs., Singapore, Singapore","IEEE Transactions on Knowledge and Data Engineering","20020807","2001","13","5","846","850","Many multimedia content-based retrieval systems allow query formulation with the user setting the relative importance of features (e.g., color, texture, shape, etc.) to mimic the user's perception of similarity. However, the systems do not modify their similarity matching functions, which are defined during the system development. We present a neural network-based learning algorithm for adapting the similarity matching function toward the user's query preference based on his/her relevance feedback. The relevance feedback is given as ranking errors (misranks) between the retrieved and desired lists of multimedia objects. The algorithm is demonstrated for facial image retrieval using the NIST Mugshot Identification Database with encouraging results","1041-4347;10414347","","10.1109/69.956107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=956107","","Content based retrieval;Image databases;Image retrieval;Information retrieval;Multimedia databases;Multimedia systems;NIST;Neural networks;Neurofeedback;Shape","content-based retrieval;image matching;learning (artificial intelligence);multimedia databases;neural nets;query formulation;relevance feedback;visual databases","NIST Mugshot Identification Database;content-based retrieval;facial image retrieval;image retrieval;learning;multimedia databases;neural network;query formulation;query preference;ranking;relevance feedback;similarity matching","","8","","8","","","Sep/Oct 2001","","IEEE","IEEE Journals & Magazines"
"","","","Consumer Electronics (ISCE), IEEE International Symposium on","20120418","","","","","","","","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1000405","","","","","","","","","","","","","IEEE","IEEE Conference Publications"
"Region-based color image indexing and retrieval","I. Kompatsiaris; E. Triantafillou; M. G. Strintzis","Inf. Process. Lab., Aristotle Univ. of Thessaloniki, Greece","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","20020807","2001","1","","658","661 vol.1","A region-based color image indexing and retrieval algorithm is presented. As a basis for the indexing, a novel K-Means segmentation algorithm is used, modified so as to take into account the coherence of the regions. A new color distance is also defined for this algorithm. Based on the extracted regions, characteristic features are estimated using color, texture and shape information. An important and unique aspect of the algorithm is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Experimental results demonstrate the performance of the algorithm. The development of an intelligent image content-based search engine for the World-Wide Web is also presented, as a direct application of the presented algorithm","","POD:0-7803-6725-1","10.1109/ICIP.2001.959131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=959131","","Color;Data mining;Feature extraction;Image retrieval;Image segmentation;Indexing;Information retrieval;Search engines;Shape;Web sites","content-based retrieval;database indexing;feature extraction;image colour analysis;image representation;image retrieval;image segmentation;image texture;information resources;knowledge based systems;search engines;very large databases;visual databases","K-Means segmentation algorithm;World Wide Web;characteristic feature estimation;color distance;color image indexing;content-based search;image databases;image query;image retrieval;image texture;intelligent search engine;internal image representation;performance;region coherence;region extraction;region-based indexing;shape information;similarity-based querying;very large databases","","7","","11","","","2001","07 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"Approximate nearest neighbor searching in multimedia databases","H. Ferhatosmanoglu; E. Tuncel; D. Agrawal; A. El Abbadi","California Univ., Santa Barbara, CA, USA","Proceedings 17th International Conference on Data Engineering","20020807","2001","","","503","511","Develops a general framework for approximate nearest-neighbor queries. We categorize the current approaches for nearest-neighbor query processing based on either their ability to reduce the data set that needs to be examined, or their ability to reduce the representation size of each data object. We first propose modifications to well-known techniques to support the progressive processing of approximate nearest-neighbor queries. A user may therefore stop the retrieval process once enough information has been returned. We then develop a new technique based on clustering that merges the benefits of the two general classes of approaches. Our cluster-based approach allows a user to progressively explore the approximate results with increasing accuracy. We propose a new metric for evaluation of approximate nearest-neighbor searching techniques. Using both the proposed and the traditional metrics, we analyze and compare several techniques with a detailed performance evaluation. We demonstrate the feasibility and efficiency of approximate nearest-neighbor searching. We perform experiments on several real data sets and establish the superiority of the proposed cluster-based technique over the existing techniques for approximate nearest-neighbor searching","1063-6382;10636382","POD:0-7695-1001-9","10.1109/ICDE.2001.914864","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=914864","","Euclidean distance;Humans;Image databases;Information retrieval;Internet;Large-scale systems;Multimedia databases;Multimedia systems;Nearest neighbor searches;Performance analysis","multimedia databases;pattern clustering;query processing;software metrics;software performance evaluation","accuracy;approximate nearest-neighbor searching;clustering;data object representation size reduction;data set reduction;evaluation metric;multimedia databases;nearest-neighbor query processing;performance evaluation;progressive processing;retrieval process termination","","31","3","18","","","2001","02 Apr 2001-06 Apr 2001","IEEE","IEEE Conference Publications"
"Indexing and retrieval for genomic databases","H. E. Williams; J. Zobel","Dept. of Comput. Sci., R. Melbourne Inst. of Technol., Vic., Australia","IEEE Transactions on Knowledge and Data Engineering","20020807","2002","14","1","63","78","Genomic sequence databases are widely used by molecular biologists for homology searching. Amino acid and nucleotide databases are increasing in size exponentially, and mean sequence lengths are also increasing. In searching such databases, it is desirable to use heuristics to perform computationally intensive local alignments on selected sequences and to reduce the costs of the alignments that are attempted. We present an index-based approach for both selecting sequences that display broad similarity to a query and for fast local alignment. We show experimentally that the indexed approach results in significant savings in computationally intensive local alignments and that index-based searching is as accurate as existing exhaustive search schemes","1041-4347;10414347","","10.1109/69.979973","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=979973","","Bioinformatics;Databases;Genomics;Indexing;Information retrieval","data structures;database indexing;information retrieval;scientific information systems","abstract-genomic sequence databases;computationally intensive local alignments;genomic databases retrieval;heuristics;homology searching;index-based approach;index-based searching;mean sequence lengths;molecular biologists;scientific databases","","30","5","58","","","Jan/Feb 2002","","IEEE","IEEE Journals & Magazines"
"An information concierge for the Web","Feifei Li; Zehua Liu; Yangfeng Huang; Wee Keong Ng","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore","12th International Workshop on Database and Expert Systems Applications","20020807","2001","","","672","676","WWW Information Collection, Collaging and Programming (WICCAP) system is a software system for the generation of logical views of web resources, and the extraction of desired information in the form of a structured document. It is designed to enable people to obtain information of interests in a simple and effective manner as well as to make information from the WWW accessible to applications so as to afford automation, inter-operation and Web-awareness among services. A key factor in making this system useful in practice is that it provides tools to automate and facilitate the process of constructing logical representation of websites, to identify and define information of interest, and to retrieving them. In this paper we present the design of the WICCAP system and its two main components, namely Mapping Wizard and Network Extraction Agent","","POD:0-7695-1230-5","10.1109/DEXA.2001.953135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953135","","Application software;Data mining;Database languages;HTML;IIR filters;Information filtering;Information filters;Information retrieval;Internet;World Wide Web","Internet;information resources;information retrieval systems","WICCAP system;WWW information collection, collaging and programming system;Web-awareness;software system;web resources","","0","","8","","","2001","03 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"Architecture of a mediator for a bioinformatics database federation","G. J. L. Kemp; N. Angelopoulos; P. M. D. Gray","Dept. of Comput. Sci., Univ. of Aberdeen, UK","IEEE Transactions on Information Technology in Biomedicine","20020807","2002","6","2","116","122","Developments in our ability to integrate and analyze data held in existing heterogeneous data resources can lead to an increase in our understanding of biological function at all levels. However, supporting ad hoc queries across multiple data resources and correlating data retrieved from these is still difficult. To address this, we are building a mediator based on the functional data model database, P/FDM, which integrates access to heterogeneous distributed biological databases. Our architecture makes use of the existing search capabilities and indexes of the underlying databases, without infringing on their autonomy. Central to our design philosophy is the use of schemas. We have adopted a federated architecture with a five-level schema, arising from the use of the ANSI-SPARC three-level schema to describe both the existing autonomous data resources and the mediator itself. We describe the use of mapping functions and list comprehensions in query splitting, producing execution plans, code generation, and result fusion. We give an example of cross-database querying involving data held locally in P/FDM systems and external data in SRS.","1089-7771;10897771","","10.1109/TITB.2002.1006298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1006298","","Bioinformatics;Biological information theory;Biology;Computer architecture;Data analysis;Data models;Database systems;Distributed databases;Information retrieval;Internet","biology computing;data models;distributed databases;program compilers;query processing;scientific information systems","ANSI-SPARC three-level schema;P/FDM functional data model database;ad hoc queries;autonomous data resources;bioinformatics database federation;biological function;code generation;cross-database querying;data analysis;data correlation;data integration;execution plans;five-level schema;heterogeneous data resources;heterogeneous distributed biological databases;indexes;list comprehensions;mapping functions;mediator architecture;multiple data resources;query splitting;result fusion;search","Algorithms;Artificial Intelligence;Computational Biology;Computer Communication Networks;Database Management Systems;Databases, Factual;Decision Support Techniques;Feasibility Studies;Information Storage and Retrieval;Internet","5","","21","","","June 2002","","IEEE","IEEE Journals & Magazines"
"Intelligent shopping mall agent based on user's preference","Eui-Seok Hwang; Kyung-Il Lee; Choong-Ho Cho","Dept. of Comput. Sci., Korea Univ., Seoul, South Korea","ISIE 2001. 2001 IEEE International Symposium on Industrial Electronics Proceedings (Cat. No.01TH8570)","20020807","2001","3","","1762","1765 vol.3","In this paper, we propose an improved intelligent search engine for electronic commerce shopping mall. At present, most intelligent search engines search goods simply based on input of customer's preference. However, it is hard to exactly understand the propensity of consumers, such as not dealing effectively with multiple interests. We offer internet shopping mall stores a more intellectual search engine that does not depend on customer's inadequate ready-made response but analyzes the preference of customers after tracking and gathering enough purchasing pattern data. This allows the system to display product information of the customer's taste","","POD:0-7803-7090-2","10.1109/ISIE.2001.931976","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=931976","","Displays;Electronic commerce;Image reconstruction;Information retrieval;Intelligent agent;Internet;Music information retrieval;Neural networks;Pattern analysis;Search engines","artificial intelligence;electronic commerce;home shopping;neural nets;search engines","customer's preference;intellectual search engine;intelligent search engine;intelligent shopping mall agent;multiple interests;neural network;product information display;purchasing pattern data;user's preference","","0","","6","","","2001","12 Jun 2001-16 Jun 2001","IEEE","IEEE Conference Publications"
"Virtual library - paths to knowledge","M. Bugajska; A. Vande Moere","Eidgenossische Tech. Hochschule, Zurich, Switzerland","Proceedings Second International Workshop on User Interfaces in Data Intensive Systems. UIDIS 2001","20020807","2001","","","116","126","The paper focuses on the use of elaborated computer visualization techniques to support multi-user browsing within a digital collection of library books and subject categories. First, a short description of the research project is given, and the two different interfaces of the developed application, called `Explore Interface' and `Browse Interface' are described. Then, some of the theoretical issues and practical use of the interfaces are presented. Finally, the experiences gathered from this research project and their impact on possible future working directions are summarized","1530-1893;15301893","POD:0-7695-0834-0","10.1109/UIDIS.2001.929932","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=929932","","Application software;Art;Books;Computer architecture;Decision making;Design automation;Information retrieval;Shape;Software libraries;Visualization","data visualisation;digital libraries;groupware;information retrieval;interactive systems;user interfaces","Browse Interface;Explore Interface;digital collection;elaborated computer visualization techniques;future working directions;library books;multi-user browsing;research project;subject categories;virtual library","","1","","17","","","2001","31 May 2001-01 Jun 2001","IEEE","IEEE Conference Publications"
"Scene structural matrix for image indexing and retrieval","G. Qiu; S. Sudirman","Sch. of Comput. Sci., Nottingham Univ., UK","2001 IEEE Fourth Workshop on Multimedia Signal Processing (Cat. No.01TH8564)","20020807","2001","","","85","90","We present a new image indexing and retrieval method for image database applications. We introduce a novel image content description feature termed scene structural matrix (SSM). The SSM captures the overall structural information of the scene by indexing the geometric features of the image. We also introduce a constraint adaptive image segmentation method termed middle cut (MC) to partition the image and derive the multi-scale geometric structures of the image. Experimental results show that SSM is particularly effective in retrieving images with strong structural features, such as landscape photographs. It is also shown that SSM is robust against spatial and spectral distortions thus making it superior to the traditional colour histogram, colour correlogram and MPEG7-color structure histogram in certain applications","","POD:0-7803-7025-2","10.1109/MMSP.2001.962716","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=962716","","Computer science;Content based retrieval;Histograms;Image databases;Image retrieval;Image segmentation;Indexing;Information retrieval;Layout;Robustness","adaptive signal processing;content-based retrieval;database indexing;feature extraction;image colour analysis;image segmentation;visual databases","MPEG7-color structure histogram;SSM;colour correlogram;colour histogram;constraint adaptive image segmentation;content-based indexing;content-based retrieval;geometric features;image content description feature;image database;image indexing;image retrieval;landscape photographs;middle cut;scene structural matrix;spatial distortions;spectral distortion","","0","","8","","","2001","03 Oct 2001-05 Oct 2001","IEEE","IEEE Conference Publications"
"A recursive optimal relevance feedback scheme for content based image retrieval","N. Doulamis; A. Doulamis","Dept. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Greece","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","20020807","2001","2","","741","744 vol.2","An optimal relevance algorithm is proposed, which adapts the response of a content based image retrieval (CBIR) system to the user's information needs. In particular, the importance of each descriptor to the similarity measure of the system is estimated so that the correlation between the query image and all images marked by the user as relevant is maximized while simultaneously the correlation over all irrelevant images is minimized. Other degree of relevance can be also included in the proposed scheme. In case the user applies more than one feedback iteration, a recursive algorithm is introduced for increasing the system efficiency. Convergence of the proposed scheme is achieved if ""consistent"" relevant and irrelevant images are selected by the user","","POD:0-7803-6725-1","10.1109/ICIP.2001.958600","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958600","","Computational complexity;Content based retrieval;Convergence;Face;Feedback;Humans;Image retrieval;Information retrieval;Information systems;Particle measurements","content-based retrieval;correlation methods;image processing;image retrieval;iterative methods;relevance feedback","content-based retrieval;feedback iteration;image retrieval;irrelevant images;recursive algorithm;recursive optimal relevance feedback scheme;relevant images;similarity measure","","3","","8","","","7-10 Oct 2001","07 Oct 2001-10 Oct 2001","IEEE","IEEE Conference Publications"
"A health care information system for neonatology support","C. N. Gorga; J. N. Marchaukoski; M. S. Sunye; O. R. P. Bellon; L. Silva; M. N. L. Cat","Departamento de Informatica, Univ. Fed. do Parana, Curitiba, Brazil","Proceedings of 15th IEEE Symposium on Computer-Based Medical Systems (CBMS 2002)","20020807","2002","","","29","34","The determination of gestational age in newborn children is fundamental to the evaluation of their survival possibilities. In many cases, when the qualified pre-natal attendance has not occurred, the post-birth evaluation of the gestational age becomes the only alternative. This paper presents a medical image retrieval system whose goal is to help to confirm a new method (called FootScan) for gestational age determination, through the digital image of the dermatoglyphics from the plantar (sole of the foot) region of the newborn. The system includes a level of knowledge, associated with the database, which stores information from the patients, together with image features and their logical relationships.","1063-7125;10637125","POD:0-7695-1614-9","10.1109/CBMS.2002.1011350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1011350","","Biomedical imaging;Digital images;Image databases;Image retrieval;Information retrieval;Information systems;Medical diagnostic imaging;Medical services;Medical treatment;Pediatrics","health care;image retrieval;medical information systems;obstetrics;paediatrics;skin;visual databases","FootScan;dermatoglyphics;foot sole;gestational age determination;health care information system;image features;knowledge level;logical relationships;medical image retrieval system;neonatology support;newborn children;patient information;plantar region;post-birth evaluation;qualified pre-natal attendance;survival possibility evaluation","","0","","13","","","2002","","IEEE","IEEE Conference Publications"
"A probabilistic framework for semantic video indexing, filtering, and retrieval","H. R. Naphide; T. S. Huang","Dept. of Electr. & Comput. Eng., Illinois Univ., Urbana, IL, USA","IEEE Transactions on Multimedia","20020807","2001","3","1","141","151","Semantic filtering and retrieval of multimedia content is crucial for efficient use of the multimedia data repositories. Video query by semantic keywords is one of the most difficult problems in multimedia data retrieval. The difficulty lies in the mapping between low-level video representation and high-level semantics. We therefore formulate the multimedia content access problem as a multimedia pattern recognition problem. We propose a probabilistic framework for semantic video indexing, which call support filtering and retrieval and facilitate efficient content-based access. To map low-level features to high-level semantics we propose probabilistic multimedia objects (multijects). Examples of multijects in movies include explosion, mountain, beach, outdoor, music etc. Semantic concepts in videos interact and to model this interaction explicitly, we propose a network of multijects (multinet). Using probabilistic models for six site multijects, rocks, sky, snow, water-body forestry/greenery and outdoor and using a Bayesian belief network as the multinet we demonstrate the application of this framework to semantic indexing. We demonstrate how detection performance can be significantly improved using the multinet to take interconceptual relationships into account. We also show how the multinet can fuse heterogeneous features to support detection based on inference and reasoning","1520-9210;15209210","","10.1109/6046.909601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=909601","","Content based retrieval;Explosions;Filtering;Forestry;Indexing;Information retrieval;Motion pictures;Music information retrieval;Pattern recognition;Snow","content-based retrieval;database indexing;multimedia databases;video databases","Bayesian belief networks;ROC curves;content access problem;content-based access;hidden Markov models;inference;likelihood ratio test;multimedia content;multimedia data repositories;multimedia data retrieval;multimedia pattern recognition;multimedia understanding;multinet;probabilistic graphical networks;query by example;query by keywords;reasoning;semantic filtering;semantic keywords;semantic video indexing;video indexing;video query;video representation","","110","20","28","","","Mar 2001","","IEEE","IEEE Journals & Magazines"
"STED: a system for topic enumeration and distillation","G. Greco; S. Greco; E. Zumpano","DEIS, Univ. della Calabria, Rende, Italy","Proceedings. International Conference on Information Technology: Coding and Computing","20020807","2002","","","294","299","Search services on hyperlinked data are becoming popular among users because of the huge amount of data available and the consequent difficulty of retrieving and filtering relevant documents. Traditional term-based search engines are not very useful for this purpose since the resulting ranking depends on the users's precision in expressing the query. Current research, instead, takes a different approach, called topic distillation, which consists of finding documents related to the query topic, but these do not necessarily contain the query string. Current algorithms for topic distillation first compute a base set containing all the relevant pages and then apply an iterative procedure to obtain the authoritative pages. In this paper we present STED, a system for topic distillation and enumeration (i.e. identification of different communities) of Web documents. The system is based on a technique which computes authoritative pages by analyzing the structure of the base set. More specifically, the system applies a statistical approach to the co-citation matrix associated with the base set, to find the most co-cited pages and analyzes both the link structure and the content of pages. Several experiments have demonstrated the effectiveness and efficiency of the system.","","POD:0-7695-1506-1","10.1109/ITCC.2002.1000405","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1000405","","Databases;Filtering;Information processing;Information resources;Information retrieval;Iterative algorithms;Search engines;Statistical analysis;Web sites;World Wide Web","citation analysis;information resources;information retrieval","STED;Web documents;co-citation matrix;co-cited pages;document filtering;document retrieval;hyperlinked data;iterative procedure;query string;ranking;search services;statistical approach;topic distillation;topic enumeration","","0","","19","","","8-10 April 2002","","IEEE","IEEE Conference Publications"
"BitCube: a three-dimensional bitmap indexing for XML documents","J. P. Yoon; V. Raghavan; V. Chakilam","Centre for Adv. Comput. Studies, Louisiana Univ., Lafayette, LA, USA","Proceedings Thirteenth International Conference on Scientific and Statistical Database Management. SSDBM 2001","20020807","2001","","","158","167","We describe a new bitmap indexing based technique to cluster XML documents. XML is a new standard for exchanging and representing information on the Internet. Documents can be hierarchically represented by XML-elements. XML documents are represented and indexed using a bitmap indexing technique. We define the similarity and popularity operations available in bitmap indexes and propose a method for partitioning a XML document set. Furthermore, a 2-dimensional bitmap index is extended to a 3-dimensional bitmap index, called BitCube. We define statistical measurements in the BitCube: mean, mode, standard derivation, and correlation coefficient. Based on these measurements, we also define the slice, project, and dice operations on a BitCube. BitCube can be manipulated efficiently and improves the performance of document retrieval","1099-3371;10993371","POD:0-7695-1218-6","10.1109/SSDM.2001.938548","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938548","","Content based retrieval;Frequency;Image databases;Indexing;Information retrieval;Internet;Object oriented databases;Relational databases;Venus;XML","Internet;database indexing;hypermedia markup languages;query processing;visual databases","BitCube;Internet;XML documents;document clustering;document partitioning;document retrieval;popularity operations;similarity operations;statistical measurements;three-dimensional bitmap indexing","","6","","13","","","2001","18 Jul 2001-20 Jul 2001","IEEE","IEEE Conference Publications"
"An appearance-based framework for 3D hand shape classification and camera viewpoint estimation","V. Athitsos; S. Sclaroff","Dept. of Comput. Sci., Boston Univ., MA, USA","Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition","20020807","2002","","","40","45","An appearance-based framework for 3D hand shape classification and simultaneous camera viewpoint estimation is presented. Given an input image of a segmented hand, the most similar matches from a large database of synthetic hand images are retrieved. The ground-truth labels of those matches, containing hand-shape and camera-viewpoint information, are returned by the system as estimates for the input image. Database retrieval is done hierarchically, by first quickly rejecting the vast majority of all database views, and then ranking the remaining candidates in order of similarity to the input. Four different similarity measures are employed, based on edge location, edge orientation, finger location and geometric moments, respectively","","POD:0-7695-1602-5","10.1109/AFGR.2002.1004129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1004129","","Application software;Cameras;Computer science;Humans;Image databases;Information retrieval;Rendering (computer graphics);Shape measurement;Spatial databases;Video compression","cameras;computer vision;edge detection;geometry;image classification;image matching;image retrieval;image segmentation;sorting;visual databases","3D hand shape classification;appearance-based framework;camera viewpoint estimation;database view ranking;edge location;edge orientation;finger location;geometric moments;ground-truth labels;hierarchical image retrieval;image matching;segmented hand image;similarity measures;similarity order;synthetic hand image database","","28","7","26","","","20-21 May 2002","20 May 2002-21 May 2002","IEEE","IEEE Conference Publications"
"Query term expansion and reweighting using term co-occurrence similarity and fuzzy inference","Byeong Man Kim; Ju Youn Kim; Jongwan Kim","Sch. of Comput. & Software Eng., Kumoh National Univ. of Tech, Kyungpook, South Korea","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","20020807","2001","2","","715","720 vol.2","To improve the effectiveness of the classic relevance techniques for the vector model, a novel technique for term expansion and term reweighting is suggested. The advantages of the classic techniques are simplicity and good results. However, due to the simplicity, the term occurrence pattern is not considered explicitly. To supplement the classic relevance techniques, we introduce the term cooccurrence similarity as a measure of how similar the distributions within the feedbacked documents of a given term and the initial query are. With this similarity and additional information, the weight in the new query of the term is calculated by fuzzy inference. Although the experiments are performed on the small collection, the results show that the technique proposed in the paper yields substantial improvements in retrieval effectiveness","","POD:0-7803-7078-3","10.1109/NAFIPS.2001.944690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=944690","","Feedback;Frequency measurement;Information retrieval;Search engines;Software;Testing;Web search;World Wide Web","document handling;fuzzy set theory;inference mechanisms;pattern classification;relevance feedback;uncertainty handling","classic relevance techniques;feedbacked documents;fuzzy inference;initial query;query term expansion;query term reweighting;retrieval effectiveness;term co-occurrence similarity;term occurrence pattern;vector model","","2","","14","","","25-28 July 2001","25 Jul 2001-28 Jul 2001","IEEE","IEEE Conference Publications"
"Harmonizing data, setting standards [genomics, information sets]","S. K. Moore","","IEEE Spectrum","20020807","2001","38","1","111","112","With a working copy of the human genome in hand, the hard task of making sense of the terabytes of data has begun. One way of doing that job is by comparing gene sequences with other types of biological information, including protein sequences and structures or genes identified or expressed in other creatures. The trouble is that this other information is held in hundreds of databases out in research institutions and companies around the world. They are not stored in any common format but use different syntaxes and a variety of sometimes incompatible database technologies, ranging from ad hoc systems to relational databases to object-oriented systems. But help is in the offing. Several groups have developed tools to fuse the sprawling horde into distributed-federated systems, collections of otherwise incompatible sets of data that can be searched as if they were one database. For the effort really to succeed, some bioinformatics experts say that standards must eventually be set for how data is stored and retrieved. Since data comes in different formats, queries must be targeted at each database in ways that are peculiar to each system-an irksome task for the busy biologist. Linking the databases so that they appear to be a single unit is done with software that understands the format of the associated systems and can translate queries into the syntax and schema used by individual databases","0018-9235;00189235","","10.1109/6.901157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=901157","","Bioinformatics;Distributed databases;Fuses;Genomics;Humans;Information retrieval;Joining processes;Object oriented databases;Proteins;Relational databases","biology computing;database management systems;genetics;information retrieval systems;medical computing;scientific information systems;standardisation","ad hoc systems;bioinformatics;data retrieval;data storage;distributed-federated systems;gene sequences comparison;genomics;human genome;incompatible database technologies;information sets;object-oriented systems;relational databases","","2","4","","","","Jan 2001","","IEEE","IEEE Journals & Magazines"
"Speech retrieval with video parsing for television news programs","H. M. Meng; Xiaoou Tang; Pui Yu Hui; Xinbo Gao; Yuk Chi Li","Human-Computer Commun. Lab., Chinese Univ. of Hong Kong, Shatin, China","2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)","20020807","2001","3","","1401","1404 vol.3","We have been working on speech retrieval from Chinese (Cantonese) television news programs. The use of automatic speech recognition for audio indexing produces imperfect transcriptions, and recognition errors affect retrieval performance. A news story typically contains a brief report by the anchor person(s) in the studio, as well as news footage from the field. Investigation shows that our recognizer performs better when indexing audio from the studio, compared to that from the field. In order to automatically extract the ""reliable"" audio segments for speech retrieval, we attempt to detect studio-to-field transitions by means of video parsing. Our study is based on 146 news stories collected from local television Cantonese news programs. We formulated a known-item retrieval task and adopted the average inverse rank (AIR) as our evaluation metric. Retrieval is performed based on syllable bigram units, augmented with skipped syllable bigrams. Retrieval using the entire audio track of each news story gave AIR=0.759. With the incorporation of video parsing, we performed retrieval based only on the studio recordings, which produced AIR=0.768","1520-6149;15206149","POD:0-7803-7041-4","10.1109/ICASSP.2001.941191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=941191","","Automatic speech recognition;Content based retrieval;Digital audio broadcasting;Digital video broadcasting;Indexing;Information retrieval;Laboratories;Natural languages;TV broadcasting;Video on demand","content-based retrieval;database indexing;feature extraction;multimedia databases;speech recognition;video signal processing","Cantonese speech;Chinese speech;audio indexing;audio segments;automatic extraction;automatic speech recognition;average inverse rank;known-item retrieval task;multimedia information retrieval;retrieval evaluation;skipped syllable bigrams;speech retrieval;studio-to-field transitions;syllable bigram units;television news programs;video parsing","","6","","9","","","2001","07 May 2001-11 May 2001","IEEE","IEEE Conference Publications"
"Content-based video indexing for the support of digital library search","M. Petkovic; R. van Zwol; H. E. Blok; W. Jonker; P. M. G. Apers; M. Windhouwer; M. Kersten","Twente Univ., Enschede, Netherlands","Proceedings 18th International Conference on Data Engineering","20020807","2002","","","494","495","Presents a digital library search engine that combines efforts of the AMIS and DMW research projects, each covering significant parts of the problem of finding the required information in an enormous mass of data. The most important contributions of our work are the following: (1) We demonstrate a flexible solution for the extraction and querying of meta-data from multimedia documents in general. (2) Scalability and efficiency support are illustrated for full-text indexing and retrieval. (3) We show how, for a more limited domain, like an intranet, conceptual modelling can offer additional and more powerful query facilities. (4) In the limited domain case, we demonstrate how domain knowledge can be used to interpret low-level features into semantic content. In this short description, we focus on the first and fourth items","1063-6382;10636382","POD:0-7695-1531-2","10.1109/ICDE.2002.994766","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=994766","","Australia;Content based retrieval;Data mining;Event detection;Indexing;Information retrieval;Search engines;Service oriented architecture;Software libraries;Videoconference","content-based retrieval;database indexing;digital libraries;meta data;search engines;video databases","AMIS project;DMW project;content-based video indexing;digital library search engine;domain knowledge;intranet;limited domain;low-level feature interpretation;meta-data extraction;meta-data querying;multimedia documents;semantic content","","3","","4","","","2002","26 Feb 2002-01 Mar 2002","IEEE","IEEE Conference Publications"
"An intelligent system for integrating semantic and iconic features for image retrieval","L. H. Tang; R. Hanka; H. H. S. Ip; K. K. T. Cheung; R. Lam","Sch. of Electron., Surrey Univ., Guildford, UK","Proceedings. Computer Graphics International 2001","20020807","2001","","","240","246","The I-Browse project aimed to develop a prototype system to provide facilities for supporting intelligent retrieval of medical images through a combination of iconic and semantic content. The resulting prototype system, I-Browse, is able to extract and represent relevant iconic and semantic information from input images and to automatically generate textual annotations for images. Techniques were also developed for retrieving relevant images from the database given either an example image query or a textual query. The facilities provided by I-Browse were evaluated by medical colleagues and judged to have the potential of alleviating some of the time-consuming tasks that doctors now have to perform daily and providing a means of identifying previously unknown relationships between visual appearance and histological events","1530-1052;15301052","POD:0-7695-1007-8","10.1109/CGI.2001.934680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=934680","","Biomedical imaging;Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;Intelligent systems;Magnetic resonance imaging;Medical diagnostic imaging;Prototypes","deductive databases;image retrieval;medical image processing;medical information systems;visual databases","I-Browse project;histological events;iconic features;image database;image query;intelligent system;medical image processing;medical image retrieval;prototype system;semantic features;textual annotations;textual query;visual appearance","","1","","7","","","2001","03 Jul 2001-06 Jul 2001","IEEE","IEEE Conference Publications"
"Biological data integration: wrapping data and tools","Z. Lacroix","Arizona State Univ., Tempe, AZ, USA","IEEE Transactions on Information Technology in Biomedicine","20020807","2002","6","2","123","128","Scientific data is inevitably digital and stored in a wide variety of formats in heterogeneous systems. Scientists need to access an integrated view of remote or local heterogeneous data sources with advanced data access, analysis, and visualization tools. Building a digital library for scientific data requires accessing and manipulating data extracted from flat files or databases, documents retrieved from the Web as well as data generated by software. We present an approach to wrapping web data sources, databases, flat files, or data generated by tools through a database view mechanism. Generally, a wrapper has two tasks: it first sends a query to the source to retrieve data and, second builds the expected output with respect to the virtual structure. Our wrappers are composed of a retrieval component based on an intermediate object view mechanism called search views mapping the source capabilities to attributes, and an Extensible Markup Language (XML) engine, respectively, to perform these two tasks. The originality of the approach consists of: 1) a generic view mechanism to access seamlessly data sources with limited capabilities and 2) the ability to wrap data sources as well as the useful specific tools they may provide. Our approach has been developed and demonstrated as part of the multidatabase system supporting queries via uniform object protocol model (OPM) interfaces.","1089-7771;10897771","","10.1109/TITB.2002.1006299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1006299","","Access protocols;Data analysis;Data mining;Data visualization;Engines;Information retrieval;Software libraries;Visual databases;Wrapping;XML","biology computing;data analysis;digital libraries;distributed databases;hypermedia markup languages;information resources;scientific information systems","Web documents;XML engine;biological data integration;data access;data analysis;data retrieval;data visualization;data wrapping;databases;digital library;flat files;generic view mechanism;heterogeneous data sources;multidatabase system;query;search views;uniform object protocol model interfaces;virtual structure","Algorithms;Artificial Intelligence;Computational Biology;Computer Communication Networks;Database Management Systems;Databases, Bibliographic;Databases, Factual;Databases, Nucleic Acid;Decision Support Techniques;Feasibility Studies;Information Storage and Retrieval;Internet;MEDLINE;Programming Languages","21","","47","","","June 2002","","IEEE","IEEE Journals & Magazines"
"Modular preference Moore machines in news mining agents","S. Wermter; G. Arevian","Inf. Centre, Sunderland Univ., UK","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","20020807","2001","3","","1792","1797 vol.3","This paper focuses on hybrid symbolic neural architectures that support the task of classifying textual information in learning agents. We give an outline of these symbolic and neural preference Moore machines. Furthermore, we demonstrate how they can be used in the context of information mining and news classification. Using the Reuters newswire text data, we demonstrate how hybrid symbolic and neural machines can provide an effective foundation for learning news agents","","POD:0-7803-7078-3","10.1109/NAFIPS.2001.943824","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943824","","Data mining;Encoding;Informatics;Information retrieval;Internet;Machine learning;Manuals;Robustness;Routing;Web sites","data mining;information retrieval;learning (artificial intelligence);learning automata","Reuters newswire text data;hybrid symbolic neural architectures;information mining;learning agents;modular preference Moore machines;news classification;news mining agents;textual information classification","","0","","33","","","25-28 July 2001","25 Jul 2001-28 Jul 2001","IEEE","IEEE Conference Publications"
"Incorporating asymmetry into SOM and Sammon algorithms for visual map generation","M. Martin-Merino; A. Munoz; Y. Dimitriadis","Univ. of Pontificia of Salamanca, Spain","Neural Networks, 2001. Proceedings. IJCNN '01. International Joint Conference on","20020807","2001","3","","1908","1913 vol.3","The interest in developing visual word maps that help users to find information in the web has grown. Neural based techniques have been proposed to generate word maps but most of them rely on the use of symmetric measures. We propose extended versions of self organizing maps (SOM) and Sammon mapping algorithms that can handle efficiently asymmetric dissimilarities. The modified algorithms are compared to their symmetric counterparts in a real document database using two objective error measures. Our proposed asymmetric algorithms improve the maps generated by their symmetric counterparts","1098-7576;10987576","POD:0-7803-7044-9","10.1109/IJCNN.2001.938455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938455","","Data mining;Databases;Fuzzy sets;Information retrieval;Multidimensional systems;Pain;Psychology;Self organizing feature maps;Sociology;Symmetric matrices","fuzzy logic;information retrieval;self-organising feature maps","Sammon algorithms;World Wide Web;asymmetric dissimilarities;asymmetry;document database;neural based techniques;objective error measures;self organizing maps;visual map generation;visual word maps","","0","","24","","","2001","15 Jul 2001-19 Jul 2001","IEEE","IEEE Conference Publications"
"The use of punched cards in US libraries and documentation centers, 1936-1965","R. V. Williams","Coll. of Libr. & Inf. Sci., South Carolina Univ., Columbia, SC, USA","IEEE Annals of the History of Computing","20020807","2002","24","2","16","33","Librarians, particularly those in traditional academic and public libraries, were slow to take advantage of punched cards. In contrast, special librarians and documentalists, with their small systems and focus on retrieving information for users, readily adopted punched cards. The results were dramatic: improved ability to index scientific and technical information and better user service. The paper presents a history of the use of punched cards in US libraries","1058-6180;10586180","","10.1109/MAHC.2002.1010067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1010067","","Books;Cities and towns;Costs;Documentation;Europe;Information retrieval;Information science;Libraries;Pressing;Statistics","academic libraries;history;information centres;library automation;public libraries;punched card equipment","US libraries;academic libraries;documentalists;documentation centers;history;information retrieval;librarians;public libraries;punched cards;scientific information;technical information;user service","","5","","105","","","Apr-Jun 2002","","IEEE","IEEE Journals & Magazines"
"Video preprocessing for audiovisual indexing","A. Albiol; L. Torres; E. J. Delp","Commun. Dept., Univ. Politecnica de Valencia, Spain","Proceedings Fifth IEEE Southwest Symposium on Image Analysis and Interpretation","20020807","2002","","","57","61","We address the problem of detecting shots of subjects that are interviewed in news sequences. This is useful since usually these kinds of scenes contain important and reusable information that can be used for other news programs. In a previous paper, we presented a technique based on a priori knowledge of the editing techniques used in news sequences which allowed a fast search of news stories (see Albiol, A. et al., 3rd Int. Conf. on Audio and Video-based Biometric Person Authentication, p.366-71, 2001). We now present a new shot descriptor technique which improves the previous search results by using a simple, yet efficient, algorithm, based on the information contained in consecutive frames. Results are provided which prove the validity of the approach","","POD:0-7695-1537-1","10.1109/IAI.2002.999889","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=999889","","Audio databases;Explosions;Gunshot detection systems;Image sequence analysis;Indexing;Information retrieval;Layout;Video coding;Video sequences;Visual databases","audio signal processing;audio-visual systems;image classification;image retrieval;image segmentation;image sequences;object detection;video databases;video signal processing","audio segmentation;audiovisual indexing;digital videobases;information retrieval;news programs;news sequences;shot descriptor technique;video preprocessing;video segmentation","","0","","14","","","2002","07 Apr 2002-09 Apr 2002","IEEE","IEEE Conference Publications"
"Faster distance calculation in image retrieval systems","G. Voulgaris; J. Jiang","Sch. of Comput., Univ. of Glamorgan, Pontypridd, UK","2002 Digest of Technical Papers. International Conference on Consumer Electronics (IEEE Cat. No.02CH37300)","20020807","2002","","","124","125","In this paper we describe two methods for the improvement of the speed of image retrieval systems. The methods include alterations over the typical calculation of the L2 distance and a strategy for prefiltering of the feature signatures database. The paper concludes with representative experimental results.","","POD:0-7803-7300-6","10.1109/ICCE.2002.1013957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1013957","","Content based retrieval;Gravity;Histograms;Image databases;Image retrieval;Indexing;Information retrieval;Query processing;Spatial databases;Usability","content-based retrieval;feature extraction;image retrieval;information retrieval system evaluation;visual databases","CBIR;L2 distance;content-based image retrieval;feature signatures database;prefiltering;speed improvement","","1","","6","","","18-20 June 2002","","IEEE","IEEE Conference Publications"
"Inverted-space storage organization for persistent data of very high dimensionality","R. Orlandic; Byunggu Yu","Dept. of Comput. Sci., Illinois Inst. of Technol., Chicago, IL, USA","Proceedings International Conference on Information Technology: Coding and Computing","20020807","2001","","","616","621","Contemporary database technology is severely limited in managing the high-dimensional data of many advanced applications, such as multimedia systems and data mining. The main concern of this paper is the well-known performance degradation of multi-dimensional access methods in spaces with many dimensions. The paper proposes an elaborate storage organization, called the inverted space, which can support efficient processing of data in spaces with very high dimensionality. The organization allows system administrators to control the size of spatial indexes and thereby to avoid the negative impact of extremely high data dimensionality on the retrieval performance. In addition, this paper introduces a new point access method designed to address numerous other problems that contemporary retrieval schemes experience in high-dimensional situations. This mechanism is envisioned to serve as the core indexing structure of inverted-space storage organizations","","POD:0-7695-1062-0","10.1109/ITCC.2001.918865","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=918865","","Control systems;Data mining;Degradation;Information retrieval;Multimedia databases;Multimedia systems;Size control;Space technology;Spatial indexes;Technology management","data mining;database indexing;file organisation;information retrieval;multimedia databases;persistent objects","data dimensionality;data mining;database technology;efficient data processing;high-dimensional persistent data;indexing structure;inverted-space storage organization;multi-dimensional access methods;multi-dimensional databases;multimedia systems;performance degradation;point access method;retrieval performance;spatial index size control;system administration","","0","4","20","","","Apr 2001","02 Apr 2001-04 Apr 2001","IEEE","IEEE Conference Publications"
"NewsEye: a news video browsing and retrieval system","Xiaoon Tang; Xinbo Gao; Chun Yu Wong","Dept. of Inf. Eng., Chinese Univ. of Hong Kong, Shatin, China","Proceedings of 2001 International Symposium on Intelligent Multimedia, Video and Speech Processing. ISIMP 2001 (IEEE Cat. No.01EX489)","20020807","2001","","","150","153","A news video browsing and retrieval system, NewsEye, is developed in this work. The system provides high-accuracy news story segmentation and text caption extraction. Its main features include keyword-based news story search, key-frame-based video abstract, and caption-text-based news story abstract","","POD:962-85766-2-3","10.1109/ISIMP.2001.925354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925354","","Cameras;Data mining;Digital images;Feature extraction;Gunshot detection systems;Image segmentation;Information retrieval;Layout;Search engines;Software libraries","Internet;electronic news gathering;information retrieval;video coding","NewsEye;caption-text-based news story abstract;key-frame-based video abstract;keyword-based news story search;news story segmentation;news video browsing and retrieval system;text caption extraction","","0","","4","","","2001","02 May 2001-04 May 2001","IEEE","IEEE Conference Publications"
"Designing a three-layer ontology in a Web-based interconnection scenario","S. Castano; V. De Antonellis; S. De Capitani di Vimercati; M. Melchiori","Dipt. di Sci. dell'Informazione, Milan Univ., Italy","12th International Workshop on Database and Expert Systems Applications","20020807","2001","","","21","26","We consider an interconnection scenario over the Web, where diverse pre-existing and independent companies wish to cooperate and use XML as a common language for information interchange. To effectively support cooperation and information sharing, we propose an integration approach to design a three-layer ontology providing a semantic representation of the interorganizational knowledge in the considered domain. The ontology is organized into global concepts and concept relationships at different levels of detail, with a topic-based view. Global concepts are derived by analyzing exchange information and associated descriptions provided by each involved company, using integration techniques. Subject categories are superimposed to global concepts to give a summary, topic-based view of the interorganizational knowledge of the considered scenario, and to provide involved users with a meaningful way for information search and localization","","POD:0-7695-1230-5","10.1109/DEXA.2001.953036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953036","","Environmental management;Information analysis;Information retrieval;LAN interconnection;Mediation;Ontologies;Portals;Research and development management;XML","electronic data interchange;groupware;hypermedia markup languages;information resources;information retrieval;internetworking","Web based interconnection scenario;XML;common language;concept relationships;exchange information;global concepts;independent companies;information interchange;information search;information sharing;integration approach;integration techniques;interorganizational knowledge;localization;semantic representation;subject categories;three-layer ontology;topic based view","","1","","16","","","2001","03 Sep 2001-07 Sep 2001","IEEE","IEEE Conference Publications"
"Efficient filtering of XML documents with XPath expressions","Chee-Yong Chan; P. Felber; M. Garofalakis; R. Rastogi","Lucent Technol. Bell Labs, Middletown, NJ, USA","Proceedings 18th International Conference on Data Engineering","20020807","2002","","","235","244","We propose a novel index structure, termed XTrie, that supports the efficient filtering of XML documents based on XPath expressions. Our XTrie index structure offers several novel features that make it especially attractive for large scale publish/subscribe systems. First, XTrie is designed to support effective filtering based on complex XPath expressions (as opposed to simple, single-path specifications). Second, our XTrie structure and algorithms are designed to support both ordered and unordered matching of XML data. Third, by indexing on sequences of element names organized in a trie structure and using a sophisticated matching algorithm, XTrie is able to both reduce the number of unnecessary index probes as well as avoid redundant matchings, thereby providing extremely efficient filtering. Our experimental results over a wide range of XML document and XPath expression workloads demonstrate that our XTrie index structure outperforms earlier approaches by wide margins","1063-6382;10636382","POD:0-7695-1531-2","10.1109/ICDE.2002.994713","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=994713","","Algorithm design and analysis;Buildings;Filtering algorithms;Information filtering;Information filters;Information retrieval;Internet;Matched filters;Subscriptions;XML","database indexing;hypermedia markup languages;information retrieval;tree data structures","XML document filtering;XPath expressions;XTrie;experimental results;index structure;large scale publish subscribe systems;ordered matching data;trie structure;unordered matching data","","66","7","19","","","2002","26 Feb 2002-01 Mar 2002","IEEE","IEEE Conference Publications"
"DOLPHIN: Digital Online Library Providing Human-Like Interactive Navigation","Y. Seki; T. Hidaka","Dev. Center, NTT EAST, Tokyo, Japan","IEEE Transactions on Knowledge and Data Engineering","20020807","2001","13","4","703","704","In a digital library environment, we propose a novel support concept that is like a reference service in real libraries. Based on the concept, we have developed a prototype, called DOLPHIN, using a frame based knowledge base to support reference services in a digital library. DOLPHIN can guide the user to the appropriate service","1041-4347;10414347","","10.1109/69.940741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=940741","","Bibliographies;Databases;Dolphins;Information retrieval;Intelligent networks;Navigation;Network servers;Prototypes;Software libraries;Web server","digital libraries;frame based representation;human factors;information retrieval;interactive systems;online front-ends","DOLPHIN;Digital Online Library Providing Human-Like Interactive Navigation;digital library environment;frame based knowledge base;question and answer;reference service;support concept","","1","","7","","","Jul/Aug 2001","","IEEE","IEEE Journals & Magazines"
"Searching in compressed dictionaries","S. T. Klein; D. Shapira","Dept. of Comput. Sci., Bar-Ilan Univ., Ramat-Gan, Israel","Proceedings DCC 2002. Data Compression Conference","20020807","2002","","","142","151","We introduce two new methods to represent a prefix omission method (POM) file so that direct search can be done in these compressed dictionaries. The processing time is typically twice as fast for the Fibonacci variant than for the Huffman based algorithm, and also compared to decoding a Huffman encoded POM file and searching on the uncompressed version. We see that in the case of small files, which is the important application since dictionaries are usually kept in small chunks, the Fibonacci variant is much faster than decoding and searching or than the POM-Huffman method. Even though the compression performance might be slightly inferior to the character version of Huffman (but still generally better than the bit version), this might well be a price worth paying for faster processing.","1068-0314;10680314","POD:0-7695-1477-4","10.1109/DCC.2002.999952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=999952","","Computer science;Decoding;Dictionaries;Encoding;Gallium nitride;Information retrieval;Large-scale systems;Natural languages;Pattern matching;Production systems","Huffman codes;data compression;dictionaries;information retrieval system evaluation;search problems;text analysis","Fibonacci variant;Huffman based algorithm;POM file;compressed dictionaries;direct search;performance;prefix omission method","","4","","11","","","2002","","IEEE","IEEE Conference Publications"
"Efficient disk allocation schemes for parallel retrieval of multidimensional grid data","Chung-Min Chen; R. Sinha; R. Bhatia","Telcordia Technol., Morristown, NJ, USA","Proceedings Thirteenth International Conference on Scientific and Statistical Database Management. SSDBM 2001","20020807","2001","","","213","222","Declustering schemes enable parallel data retrieval by placing data blocks across multiple disk devices. Various declustering schemes have been proposed for multidimensional data to reduce the response time of range queries. However, efficient schemes, which must be easy to compute and provide good performance, are only known for a restricted number of disks and dimensions. In this paper, we propose a novel technique to construct efficient multidimensional declustering schemes, for any number of disks and dimensions. Simulation results show that the new schemes outperform the best previously-known non-exhaustive search-based multidimensional declustering schemes","1099-3371;10993371","POD:0-7695-1218-6","10.1109/SSDM.2001.938553","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938553","","Computational modeling;Computer aided manufacturing;Delay;High performance computing;Information retrieval;Multidimensional systems;North America;Remote sensing;Satellites;Tiles","disc storage;information retrieval;performance evaluation;storage allocation","data blocks;disk allocation schemes;multidimensional grid data;multiple disk devices;nonexhaustive search-based multidimensional declustering schemes;parallel data retrieval;performance;range query response time;simulation","","4","","30","","","2001","18 Jul 2001-20 Jul 2001","IEEE","IEEE Conference Publications"
"Enabling personalized recommendation on the Web based on user interests and behaviors","Yi-Hung Wu; Yong-Chuan Chen; A. L. P. Chen","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan","Proceedings Eleventh International Workshop on Research Issues in Data Engineering. Document Management for Data Intensive Business and Scientific Applications. RIDE 2001","20020807","2001","","","17","24","The dramatic growth of the Web has brought about the rapid accumulation of data and the increasing possibility of information sharing. As the population on the Web grows, the analysis of user interests and behaviors will provide hints on how to improve the quality of service. We define user interests and behaviors based on the documents read by the user. A method for mining such user interests and behaviors is then presented. In this way, each user is associated with a set of interests and behaviors, which is stored in the user profile. In addition, we define six types of user profiles and a distance measure to classify users into clusters. Finally, three kinds of recommendation services using the clustered results are realized. For performance evaluation, we implement these services on the Web to make experiments on real data/users. The results show that the average acceptance rates of these services range from 71.5% to 94.6%","","POD:0-7695-0957-6","10.1109/RIDE.2001.916487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=916487","","Collaboration;Computer science;Costs;Indexing;Information filtering;Information filters;Information retrieval;Quality of service;Search engines;Web pages","Internet;data mining;information needs;information resources;information retrieval","Internet;World Wide Web;data mining;experiments;information sharing;performance evaluation;personalized recommendation;quality of service;user behavior;user interests;user profile","","10","6","23","","","2001","01 Apr 2001-02 Apr 2001","IEEE","IEEE Conference Publications"
"Trends in multimedia Web searching: excite queries","S. Ozmutlu; A. Spink; H. C. Ozmutlu","Dept. Ind. Eng., Uludag Univ., Bursa, Turkey","Proceedings. International Conference on Information Technology: Coding and Computing","20020807","2002","","","40","45","This paper provides results from a study analyzing current trends in multimedia Web searching. The following results were found: (1) multimedia searches are more complex than general searches in queries per user session and terms per query, and (2) audio queries are the most popular type of multimedia queries (compared to video and image queries) in the number of queries submitted and query durations.","","POD:0-7695-1506-1","10.1109/ITCC.2002.1000357","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1000357","","Data analysis;Image analysis;Industrial engineering;Information analysis;Information retrieval;Information technology;Large-scale systems;Search engines;Statistics;Web search","information retrieval;multimedia computing;search engines","Excite queries;audio queries;multimedia Web searching;multimedia queries","","0","","6","","","8-10 April 2002","","IEEE","IEEE Conference Publications"
"Reverse engineering for Web data: from visual to semantic structures","C. Y. Chung; M. Gertz; N. Sundaresan","Verity Inc., Sunnyvale, CA, USA","Proceedings 18th International Conference on Data Engineering","20020807","2002","","","53","63","Despite the advancement of XML, the majority of documents on the Web is still marked up with HTML for visual rendering purposes only, thus building a huge amount of legacy data. In order to facilitate querying Web based data in a way more efficient and effective than just keyword based retrieval, enriching such Web documents with both structure and semantics is necessary. We describe a novel approach to the integration of topic specific HTML documents into a repository of XML documents. In particular, we describe how topic specific HTML documents are transformed into XML documents. The proposed document transformation and semantic element tagging process utilizes document restructuring rules and minimum information about the topic in the form of concepts. For the resulting XML documents, a majority schema is derived that describes common structures among the documents in the form of a DTD. We explore and discuss different techniques, and rules for document conversion and majority schema discovery. We finally demonstrate the feasibility and effectiveness of our approach by applying it to a set of resume HTML documents gathered by a Web crawler","1063-6382;10636382","POD:0-7695-1531-2","10.1109/ICDE.2002.994697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=994697","","Computer science;Crawlers;Database languages;HTML;Information retrieval;Query processing;Reverse engineering;Semantic Web;Writing;XML","Internet;hypermedia markup languages;information resources;query processing;reverse engineering","HTML;Web crawler;World Wide Web data;XML;document conversion;document restructuring rules;document transformation;keyword based retrieval;majority schema;querying;reverse engineering;semantic element tagging;semantic structures;semantics;topic specific documents;visual structures","","10","6","27","","","2002","26 Feb 2002-01 Mar 2002","IEEE","IEEE Conference Publications"
"Information ethics in the design, creation and use of metadata","R. Brody","Queens Coll., City Univ. of New York, NY, USA","Technology and Society, 2002. (ISTAS'02). 2002 International Symposium on","20020807","2002","","","197","201","Just as information contains the explicit and implicit values of its creators, so does the metadata that represents these objects. This paper discusses issues of fair representation in the ethical design, creation and use of metadata, data about data. Ethical issues arise in the planned design of metadata, the creation of surrogates as representative of data or text, as well as in the use and ownership of the metadata in electronic environments","","POD:0-7803-7284-0","10.1109/ISTAS.2002.1013816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1013816","","Assembly;Educational institutions;Ethics;Information retrieval;Information systems;Music information retrieval;Real time systems;Spatial databases;Thesauri;Vocabulary","data analysis;information use;meta data;professional aspects","electronic environments;ethical creation;ethical design;ethical use;information ethics;metadata;surrogates","","0","","10","","","2002","06 Jun 2002-08 Jun 2002","IEEE","IEEE Conference Publications"
"Document filtering for fast approximate string matching of erroneous text","A. Takasu","Nat. Inst. of Inf., Tokyo, Japan","Proceedings of Sixth International Conference on Document Analysis and Recognition","20020807","2001","","","916","920","It is important to utilize retrospective documents. OCR is the most widely applied technology for this purpose; however, error-tolerant methods are essential for utilizing OCR-processed documents. This paper discusses a filtering problem for OCR-processed documents that enables the handling of large numbers of OCR-processed documents in an error-tolerant way. It proposes a systematic index design method for filtering and shows that the filtering method speeds up by about 360 times for a database consisting of about two million records, with little decrease in accuracy","","POD:0-7695-1263-1","10.1109/ICDAR.2001.953919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953919","","Data mining;Document handling;Filtering;Image analysis;Image databases;Informatics;Matched filters;Music information retrieval;Optical character recognition software;Text recognition","document image processing;information retrieval;optical character recognition;string matching;visual databases","OCR;database;document filtering;erroneous text;error tolerant methods;fast approximate string matching;index design method;retrospective documents","","4","","7","","","2001","10 Sep 2001-13 Sep 2001","IEEE","IEEE Conference Publications"
"Soft fusion of information accesses","G. Bordogna","Inst. for Multimedia Technol., CNR, Milan, Italy","Fuzzy Systems, 2002. FUZZ-IEEE'02. Proceedings of the 2002 IEEE International Conference on","20020807","2002","2","","1466","1471","In this paper the definition of a meta search engine model, named SOFIA (soft fusion of information accesses), is proposed that applies a flexible and soft fusion of the ranked lists of documents retrieved by distinct search engines available over the Internet. The decision function that specifies the fusion criterion is expressed by a linguistic quantifier modeled by an induced ordered average (IOWA) operator. Fuzzy quantifiers make soft fusion criteria possible. Further flexibility is obtained by computing the distinct fitness scores of the search engines based on a relevance feedback mechanism and using these scores to define the IOWA reorder vector. In this way the search engines with highest fitness influence more heavily the ranking of the documents in the fused list","","POD:0-7803-7280-8","10.1109/FUZZ.2002.1006722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1006722","","Decision making;Feedback;Indexing;Information retrieval;Internet;Metasearch;Search engines","Internet;fuzzy set theory;information retrieval;relevance feedback;search engines","IOWA;Internet;SOFIA;document retrieval;fuzzy quantifiers;induced ordered average operator;information accesses;linguistic quantifier;meta search engine model;relevance feedback;soft fusion","","2","","17","","","2002","12 May 2002-17 May 2002","IEEE","IEEE Conference Publications"
"Low level processing of audio and video information for extracting the semantics of content","N. Adami; A. Bugatti; R. Leonardi; P. Migliorati","Brescia Univ., Italy","2001 IEEE Fourth Workshop on Multimedia Signal Processing (Cat. No.01TH8564)","20020807","2001","","","607","612","The problem of semantic indexing of multimedia documents is actually of great interest due to the wide diffusion of large audio-video databases. We first briefly describe some techniques used to extract low-level features (e.g., shot change detection, dominant color extraction, audio classification etc.). Then the ToCAI (table of contents and analytical index) framework for content description of multimedia material is presented, together with an application which implements it. Finally we propose two algorithms suitable for extracting the high level semantics of a multimedia document. The first is based on finite-state machines and low-level motion indices, whereas the second uses hidden Markov models","","POD:0-7803-7025-2","10.1109/MMSP.2001.962799","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=962799","","Audio databases;Change detection algorithms;Data mining;Electronic mail;Feature extraction;Gunshot detection systems;Indexing;Information retrieval;Multimedia databases;Spatial databases","audio signal processing;content-based retrieval;feature extraction;finite state machines;hidden Markov models;multimedia databases;video signal processing","analytical index;audio classification;audio information;audio-video databases;content description;content semantics extraction;dominant color extraction;finite-state machines;hidden Markov models;information retrieval;joint audio-video analysis;low level processing;low-level feature extraction;low-level motion indices;multimedia documents;multimedia material;semantic indexing;shot change detection;table of contents;video information","","2","","9","","","2001","03 Oct 2001-05 Oct 2001","IEEE","IEEE Conference Publications"
