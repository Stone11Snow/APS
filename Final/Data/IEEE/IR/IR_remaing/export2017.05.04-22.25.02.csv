"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6382642,6382564,6385178,6379066,6377807,6381155,6379699,6377362,6378978,6378072,6378975,6379429,6377385,6380066,6377345,6331538,6376749,6376016,6376781,6376530,6376406,6376528,6376654,6376619,6375469,6374887,6375090,6375106,6374874,6374920,6375385,6375263,6366205,6366206,6366238,6365960,6366185,6366211,6366217,6365902,6366236,6365928,6366192,6366228,6366221,6366235,6366195,6366047,6366224,6366196,6366198,6148196,6364368,6171175,6362992,6364056,6362976,6362975,6363781,6364828,6364739,6363788,6360568,6360099,6360139,6357983,6360638,6359169,6360869,6360144,6359434,6360790,6359649,6356996,6357640,6360114,6360582,6356214,6354844,6354725,6354896,6354353,6354898,6354427,6354413,6354473,6354463,6007135,5989808,6175904,6353338,5601675,6351157,6352417,6349807,6349477,6345842,6340213,6341574,6347334",2017/05/04 22:25:02
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A Social Label Automatic Tagging Based Method on Situation Semantics in Web Service Discovery","S. Li; J. Hu","Sch. of Inf. & Safety Eng., Zhongnan Univ. of Econ. & Law, Wuhan, China","2012 International Conference on Management of e-Commerce and e-Government","20121206","2012","","","91","94","The traditional approach to describe web services using ontology is a departure from the perspective of web service provider which can not ensure high precision and recall ratios, that is the consistency of the service designing intent and the service using intent, the conformance of the excepted using environment and the actual using environment, and the possibility of being detected by potential users. In this paper, a social label automatic tagging based method on situation semantics in web service discovery is proposed, which takes into account both semantic web technology and user situation semantics.","","Electronic:978-0-7695-4853-1; POD:978-1-4673-2943-9","10.1109/ICMeCG.2012.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374887","service discovery;situation semantics;social tagging;web service","Context;Educational institutions;Engines;Ontologies;Semantics;Tagging;Web services","Web services;information retrieval;ontologies (artificial intelligence);semantic Web","Web service discovery;ontology;semantic Web technology;service designing intent;situation semantics;social label automatic tagging based method;user situation semantics","","0","","7","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"Cloud Log Forensics Metadata Analysis","S. Thorpe; I. Ray; T. Grandison; A. Barbir","Fac. of Eng. & Comput., Univ. of Technol., Kingston, Jamaica","2012 IEEE 36th Annual Computer Software and Applications Conference Workshops","20121110","2012","","","194","199","The increase in the quantity and questionable quality of the forensic information retrieved from the current virtualized data cloud system architectures has made it extremely difficult for law enforcement to resolve criminal activities within these logical domains. This paper poses the question of what kind of information is desired from virtual machine (VM) hosted operating systems (OS) investigated by a cloud forensic examiner. The authors gives an overview of the information that exists on current VM OS by looking at it's kernel hypervisor logs and discusses the shortcomings. An examination of the role that the VM kernel hypervisor logs provide as OS metadata in cloud investigations is also presented.","","Electronic:978-0-7695-4758-9; POD:978-1-4673-2714-5","10.1109/COMPSACW.2012.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341574","Cloud;Forensics;Hypervisor;Logs;Metadata","Cloud computing;Digital forensics;File systems;Kernel;Virtual machine monitors","cloud computing;computer forensics;information retrieval;law;meta data;operating systems (computers);virtual machines;virtualisation","OS metadata;VM hosted OS;VM kernel hypervisor logs;cloud forensic examiner;cloud investigations;cloud log forensics metadata analysis;criminal activities;current virtualized data cloud system architectures;forensic information retrieval;law enforcement;logical domains;virtual machine hosted operating systems","","6","","24","","","16-20 July 2012","","IEEE","IEEE Conference Publications"
"Decentralized search and retrieval for mobile networks using SMS","I. M. Lombera; L. E. Moser; P. M. Melliar-Smith; Y. T. Chuang","Department of Electrical and Computer Engineering, University of California, Santa Barbara, 93106 USA","2012 IEEE 8th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)","20121213","2012","","","134","141","This paper describes the iTrust over SMS decentralized search and retrieval system for mobile networks. Any mobile device in the iTrust network can communicate with any other mobile device in the iTrust network to distribute, search for, and retrieve information. Third-party developers can use the iTrust over SMS API on the Android platform to add this search and retrieval functionality to existing applications quickly and easily. Developers of applications for other mobile device platforms can use the iTrust over SMS protocol to create compatible applications that can communicate using iTrust over SMS. In addition to the iTrust over SMS components and protocol, this paper presents a performance evaluation of the iTrust over SMS system, which shows that the probability of information retrieval is high, even if some of the mobile devices are not available. It also shows that the average search latency is consistently less if all of the participating nodes use the same mobile service provider, and is consistently more if the nodes use different mobile service providers.","2160-4886;21604886","Electronic:978-1-4673-1430-5; POD:978-1-4673-1429-9","10.1109/WiMOB.2012.6379066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379066","SMS;mobile network;peer-to-peer network;retrieval;search;social network","Databases;Mobile communication;Peer to peer computing;Protocols;Receivers;Smart phones","application program interfaces;electronic messaging;information retrieval;mobile computing;mobile radio;operating systems (computers);probability;protocols","SMS decentralized search-retrieval system;iTrust;information retrieval probability;mobile networks;mobile service providers","","1","","20","","","8-10 Oct. 2012","","IEEE","IEEE Conference Publications"
"Micro-Blogging System Based on Geographic Information in Google Map","Z. You; H. Xu; J. Xu; J. Xu; D. Shi","Integrated Circuit Appl. Software Lab., Northeastern Univ., Shenyang, China","2012 Fourth International Conference on Computational Intelligence and Communication Networks","20121206","2012","","","150","153","This paper discussed the development of domestic Micro-blogging and analyzed the status in the future. Moreover, it involves a number of technical difficulties encounters, including how to make further development based on the open source framework Status Net, and how to create HTML language based on object-oriented programming using PHP and how to use Google Map API. Then, we combine the requirements of Micro-blogging and Google map service to build the system architecture and implement this system. In this system you can view information, distribute information, reply information, forward information and search information according to Google Map service. And the most important is that our system provides a platform that enables users to communicate with the Google map, and allows users to locate any place to send messages to increase the users' experience and flexibility.","","Electronic:978-0-7695-4850-0; POD:978-1-4673-2981-1","10.1109/CICN.2012.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375090","Google Map;Micro-blogging;PHP objectoriented programming;StatusNet;open source framework","Blogs;Business;Databases;Google;Servers;Software;XML","Web sites;application program interfaces;geographic information systems;hypermedia markup languages;information retrieval;object-oriented programming;public domain software","Google Map API;Google Map service;HTML language;PHP;Status Net;geographic information;information distribution;information forwarding;information reply;information searching;information viewing;message sending;microblogging system;object-oriented programming;open source framework;system architecture;user experience","","1","","6","","","3-5 Nov. 2012","","IEEE","IEEE Conference Publications"
"MashMap: Application Framework for Map-Based Visualization of Lifelog with Location","K. Takahashi; A. Shimojo; S. Matsumoto; M. Nakamura","Grad. Sch. of Syst. Inf., Kobe Univ., Kobe, Japan","2012 9th Asia-Pacific Symposium on Information and Telecommunication Technologies (APSITT)","20121213","2012","","","1","6","This paper presents an application framework, called MashMap framework, which facilitates development of location-based lifelog services. The proposed framework imports various types of location log data, and stores them in a database with the Life Log Common Data Model (LLCDM). A developer first creates a data source consisting of a filter and a display format. The filter extracts necessary data from the database, while the display format defines how the data is shown on the map. The developer then defines a MashMap by choosing a single or multiple data sources. The MashMap is an object, which aggregates several data sources on a single map, shown in the designated display format. The object is finally visualized on a Google Map by MashMap renderer. We conduct a case study developing a travel log review service and a conference history map using MashMap framework.","","Electronic:978-4-88552-265-9; POD:978-1-4673-2434-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379699","","Data visualization;Databases;Global Positioning System;Google;Meteorology;Twitter;Web services","data visualisation;geographic information systems;information retrieval;rendering (computer graphics)","Google Map;LLCDM;MashMap framework;data extraction;data source;data visualization;database management system;display format;life log common data model;location log data;location-based lifelog service;rendering;travel log review service","","1","","11","","","5-9 Nov. 2012","","IEEE","IEEE Conference Publications"
"Project development management system of financial equipment enterprises based on PDM","W. Cui; X. Liu; J. Wang","School of Control Science and Engineering, Dalian University of Technology, Liaoning, China","Proceedings of the 10th World Congress on Intelligent Control and Automation","20121124","2012","","","4135","4140","Based on the project flowchart management information system model in the process of enterprise products development, a UML model of the project management information system based on the PDM technology for the financial equipment enterprises is proposed. The design and debarment of the proposed project management information system are finished completely. The UML modeling method and .NET technologies are adopted to exploit the data accessing model and the project management information model. The system plays emphasis on the product project flowchart management and document management, whose major function modules include of project view management, test view management, document view management and organization view management.","","Electronic:978-1-4673-1398-8; POD:978-1-4673-1397-1","10.1109/WCICA.2012.6359169","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359169","PDM;UML modeling;XML;financial instruments","Data models;Educational institutions;Flowcharts;Information systems;Internet;Project management;Unified modeling language","Unified Modeling Language;corporate modelling;document handling;information retrieval;management information systems;network operating systems;organisational aspects;project management;stock markets",".net technologies;PDM-based financial equipment enterprises;UML modelling method;data access model;document management;document view management;enterprise product development;function modules;organization view management;project development management system;project flowchart management information system model;project view management;test view management","","0","","3","","","6-8 July 2012","","IEEE","IEEE Conference Publications"
"A Hierarchical Logo Detection and Recognition Algorithm Using Two-Stage Segmentation and Multiple Classifiers","H. Pourghassem","Dept. of Electr. Eng., Islamic Azad Univ., Isfahan, Iran","2012 Fourth International Conference on Computational Intelligence and Communication Networks","20121206","2012","","","227","231","Logo detection and recognition module is a principle requirement in official automation systems for document image archiving and retrieval applications. In this paper, we present a logo detection and recognition algorithm based on sequential segmentation and classification strategy of document image. In this framework, using a two-stage segmentation algorithm (consisting of wavelet-based and threshold-based segmentation algorithm) and hierarchical classification by two multilayer perceptron (MLP) classifiers and a k-nearest neighbor (KNN) classifier, a document image divides to text, pure picture and logo candidate regions. Ultimately, in final decision, class of logo candidate region is determined based on pre-defined classes. In the hierarchical classification and logo recognition stages, the best feature space is selected by forward selection algorithm from a perfect set of texture and shape features. The proposed structure is evaluated on a variety and vast database consisting of the document and non-document images with Persian and international logos. The obtained results show efficiency of the proposed framework in the real and operational conditions.","","Electronic:978-0-7695-4850-0; POD:978-1-4673-2981-1","10.1109/CICN.2012.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375106","Logo detection and recognition;document image;hierarchical classification;two-stage segmentation","Accuracy;Classification algorithms;Feature extraction;Image recognition;Image segmentation;Shape;Wavelet transforms","document image processing;feature extraction;image classification;image segmentation;image texture;information retrieval systems;multilayer perceptrons","KNN classifier;MLP classifiers;Persian logos;best feature space;document image archiving applications;document image classification strategy;document image retrieval applications;hierarchical classification;hierarchical logo detection;hierarchical logo recognition algorithm;international logos;k-nearest neighbor;logo candidate regions;logo recognition stages;multilayer perceptron;multiple classifiers;official automation systems;sequential segmentation;shape features;texture features;threshold-based segmentation algorithm;two-stage segmentation;wavelet-based segmentation algorithm","","3","","17","","","3-5 Nov. 2012","","IEEE","IEEE Conference Publications"
"Using Social Media to Enhance Emergency Situation Awareness","J. Yin; A. Lampert; M. Cameron; B. Robinson; R. Power","CSIRO ICT Centre","IEEE Intelligent Systems","20121129","2012","27","6","52","59","The described system uses natural language processing and data mining techniques to extract situation awareness information from Twitter messages generated during various disasters and crises.","1541-1672;15411672","","10.1109/MIS.2012.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148196","Clustering algorithms;Data mining;Feature extraction;Medical information processing;Medical services;Natural language processing;Social network services;Twitter;burst detection;emergency response;online clustering;situation awareness;social media;text classification","Clustering algorithms;Data mining;Feature extraction;Medical information processing;Medical services;Natural language processing;Social network services;Twitter","data mining;disasters;emergency services;information retrieval;natural language processing;social networking (online)","Twitter message;crises;data mining technique;disaster;emergency situation awareness;natural language processing;situation awareness information extraction;social media","","119","","12","","20120207","Nov.-Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Data Tethers: Preventing information leakage by enforcing environmental data access policies","C. Fleming; P. Peterson; E. Kline; P. Reiher","Computer Science Department, University of California, Los Angeles, Los Angeles, California 90095","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","835","840","Protecting data from accidental loss or theft is crucial in today's world of mobile computing. Data Tethers provides flexible environmental policies, which can be attached to data, specifying security requirements that must be met before accessing that data. Data Tethers uses fine-grain data flow tracking to maintain these policies on derivative data. This is implemented by dynamic recompilation of legacy applications without the need to recompile from source. We demonstrate the system's feasibility with microbenchmarks that show individual component performance and benchmarks of real user applications like word processors and spreadsheets.","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6364368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6364368","","Benchmark testing;Cryptography;Instruments;Monitoring;Operating systems;Servers","computer network security;information retrieval;mobile computing","data protection;data tethers;dynamic recompilation;environmental data access policies;fine-grain data flow tracking;information leakage prevention;legacy applications;mobile computing;real user applications;security requirements;spreadsheets;word processors","","0","","28","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Discovering Video Shot Categories by Unsupervised Stochastic Graph Partition","X. Duan; L. Lin; H. Chao","Sun Yat-Sen University, Guangzhou, P.R. China","IEEE Transactions on Multimedia","20121212","2013","15","1","167","180","Video shots are often treated as the basic elements for retrieving information from videos. In recent years, video shot categorization has received increasing attention, but most of the methods involve a procedure of supervised learning, i.e., training a multi-class predictor (classifier) on the labeled data. In this paper, we study a general framework to unsupervisedly discover video shot categories. The contributions are three-fold in feature, representation, and inference: (1) A new feature is proposed to capture local information in videos, defined with small video patches (e.g., 11 × 11 × 5 pixels). A dictionary of video words can be thus clustered off-line, characterizing both appearance and motion dynamics. (2) We pose the problem of categorization as an automated graph partition task, in that each graph vertex represents a video shot, and a partitioned sub-graph consisting of connected graph vertices represents a clustered category. The model of each video shot category can be analytically calculated by a projection pursuit type of learning process. (3) An MCMC-based cluster sampling algorithm, namely Swendsen-Wang cuts, is adopted to efficiently solve the graph partition. Unlike traditional graph partition techniques, this algorithm is able to explore the nearly global optimal solution and eliminate the need for good initialization. We apply our method on a wide variety of 1600 video shots collected from Internet as well as a subset of TRECVID 2010 data, and two benchmark metrics, i.e., Purity and Conditional Entropy, are adopted for evaluating performance. The experimental results demonstrate superior performance of our method over other popular state-of-the-art methods.","1520-9210;15209210","","10.1109/TMM.2012.2225029","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331538","Category discovery;graph partition;unsupervised categorization;video shot","Clustering algorithms;Dictionaries;Dynamics;Image color analysis;Manifolds;Stochastic processes;Vectors","information retrieval;learning (artificial intelligence);stochastic processes;video retrieval;video signal processing","MCMC-based cluster sampling algorithm;Swendsen-Wang cuts;TRECVID 2010 data;automated graph partition task;benchmark metrics;conditional entropy;connected graph vertices;graph vertex;local information;motion dynamics;multiclass predictor;nearly global optimal solution;purity entropy;supervised learning;traditional graph partition techniques;unsupervised stochastic graph partition;video information retrieval;video patches;video shot categorization;video shot category discovery;video words","","6","","46","","20121016","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"Audio fingerprint based on Spectral Flux for audio retrieval","W. Wang; X. Yu; Y. H. Wang; R. Swaminathan","Shool of Commun. &amp; Inf. Eng., Shanghai Univ., Shanghai, China","2012 International Conference on Audio, Language and Image Processing","20121210","2012","","","1104","1107","In audio fingerprinting, an audio clip must be recognized by matching an extracted fingerprint to a database of previously computed fingerprints. The fingerprints should reduce the dimensionality of the input significantly, provide discrimination among different audio clips, and, at the same time, be invariant to distorted versions of the same audio clip. In this paper, we design fingerprints addressing the above issues by extracting the audio fingerprints from the Spectral Flux of the clipped signal. Spectral Flux (SF) is a measure of how quickly the power spectrum of a signal is changing, calculated by comparing the power spectrum for one frame against the power spectrum from the previous frame. More precisely, it is usually calculated as the 2-norm (also known as the Euclidean distance) between the two normalised spectra. By using the AF as the feature of our algorithm we retrieval the audio clips from the database which has store some fingerprints computed previously. We test the robustness of the fingerprints under a large number of distortions. And the experimental results show that the proposed algorithm performance well in audio retrieval.","","Electronic:978-1-4673-0174-9; POD:978-1-4673-0173-2","10.1109/ICALIP.2012.6376781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376781","","Algorithm design and analysis;Audio recording;Databases;Fingerprint recognition;Noise;Robustness;Signal processing algorithms","audio databases;audio signal processing;feature extraction;information retrieval;spectral analysis","2-norm;Euclidean distance;SF;audio clip recognition;audio fingerprint;audio retrieval;dimensionality reduction;fingerprint extraction matching;frame power spectrum;spectral flux","","2","","7","","","16-18 July 2012","","IEEE","IEEE Conference Publications"
"Scalable and Secure Sharing of Personal Health Records in Cloud Computing Using Attribute-Based Encryption","M. Li; S. Yu; Y. Zheng; K. Ren; W. Lou","Utah State University, Logan","IEEE Transactions on Parallel and Distributed Systems","20121129","2013","24","1","131","143","Personal health record (PHR) is an emerging patient-centric model of health information exchange, which is often outsourced to be stored at a third party, such as cloud providers. However, there have been wide privacy concerns as personal health information could be exposed to those third party servers and to unauthorized parties. To assure the patients' control over access to their own PHRs, it is a promising method to encrypt the PHRs before outsourcing. Yet, issues such as risks of privacy exposure, scalability in key management, flexible access, and efficient user revocation, have remained the most important challenges toward achieving fine-grained, cryptographically enforced data access control. In this paper, we propose a novel patient-centric framework and a suite of mechanisms for data access control to PHRs stored in semitrusted servers. To achieve fine-grained and scalable data access control for PHRs, we leverage attribute-based encryption (ABE) techniques to encrypt each patient's PHR file. Different from previous works in secure data outsourcing, we focus on the multiple data owner scenario, and divide the users in the PHR system into multiple security domains that greatly reduces the key management complexity for owners and users. A high degree of patient privacy is guaranteed simultaneously by exploiting multiauthority ABE. Our scheme also enables dynamic modification of access policies or file attributes, supports efficient on-demand user/attribute revocation and break-glass access under emergency scenarios. Extensive analytical and experimental results are presented which show the security, scalability, and efficiency of our proposed scheme.","1045-9219;10459219","","10.1109/TPDS.2012.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6171175","Personal health records;attribute-based encryption;cloud computing;data privacy;fine-grained access control","Access control;Encryption;Medical services;Scalability;Servers","cloud computing;cryptography;data privacy;health care;information retrieval;medical information systems","attribute-based encryption;cloud computing;data access;data privacy;health information exchange;patient-centric model;personal health records;scalable sharing;secure sharing","","173","1","38","","20120319","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"Highly secured remote user authentication scheme using smart cards","R. S. Pippal; J. C. D.; S. Tapaswi","ABV-Indian Institute of Information Technology and Management, Gwalior, India","2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA)","20121124","2012","","","1001","1005","In the present Internet age, one of the main challenging tasks is to provide confidentiality for user's transaction. Various authentication schemes have been proposed to secure the data from unauthorized users. One of the most prominent schemes is password based smart card authentication scheme used to withstand the possible attacks for verification table. However, most of these schemes are vulnerable to one or the other possible attacks. In this paper, highly secured smart card authentication scheme is proposed to resist all the identified attacks and satisfy the needs of user. Its security is based on one way hash function and the discrete logarithm problem. Security analysis proves that the given scheme is more secure as compared to other existing schemes. It can be easily extended to various applications such as Multi-server authentication, Internet protocol television broadcasting, Wireless communication and Healthcare applications, where the user needs to access data from server.","2156-2318;21562318","Electronic:978-1-4577-2119-9; POD:978-1-4577-2118-2","10.1109/ICIEA.2012.6360869","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360869","mutual authentication;nonce;security;smart card","Authentication;Computers;Cryptography;Resists;Servers;Smart cards","IPTV;cryptographic protocols;formal verification;health care;information retrieval;smart cards;user interfaces","Internet protocol television broadcasting;data access;healthcare;multiserver authentication;secured remote user authentication;smart cards;unauthorized users;user transaction;verification table;wireless communication","","1","","21","","","18-20 July 2012","","IEEE","IEEE Conference Publications"
"University of California Research eXchange (UCReX): A Federated Cohort Discovery System","A. J. Mandel; M. Kamerick; D. Berman; L. Dahm","Recombinant Data Corp., Newton, MA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","146","146","The University of California has committed to the development of a system to encourage collaboration among its 5 Medical Center campuses. The name of this system is UCReX, for the UC Research eXchange. The goals of UCReX are to: (1) Enhance access to clinical data for research, (2) Build a technical infrastructure to allow crossinstitutional sharing of harmonized clinical data, (3) Inform data collection processes.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366238","","Educational institutions;Organizations;Servers;Standards organizations;Terminology;USA Councils","data mining;information retrieval;medical information systems;peer-to-peer computing","Medical Center campuses;UCReX;University of California Research Exchange;cross-institutional sharing;data collection process;federated cohort discovery system;harmonized clinical data access;technical infrastructure","","1","","4","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"PATHS: Personalising access to cultural heritage spaces","K. Fernie; J. Griffiths; M. Stevenson; P. Clough; P. Goodale; M. Hall; P. Archer; K. Chandrinos; E. Agirre; O. L. de Lacalle; A. de Polo; R. Bergheim","MDR Partners, London, UK","2012 18th International Conference on Virtual Systems and Multimedia","20121203","2012","","","469","474","Digitisation of the cultural heritage means that a significant amount of material is now available through online digital library portals. However, the vast quantity of cultural heritage material can also be overwhelming for many users who lack knowledge of the collections, subject knowledge and the specialist language used to describe this content. Search portals often provide little or no guidance on how to find and interpret this information. The situation is very different in museums and galleries where collections are organized in exhibitions which offer themes and stories that visitors can explore. The PATHS project, which is funded under the European Commission's FP7 programme, is developing a system that explores the familiar metaphor of a trail (pathway) to enhance the discovery and use of the content made available in digital libraries. This paper will report on the findings of the user requirements analysis and the specifications for the first prototype of the PATHS system which is based on contents from Europeana and the Alinari Archives.","","Electronic:978-1-4673-2565-3; POD:978-1-4673-2564-6","10.1109/VSMM.2012.6365960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365960","Europeana;cultural heritage;digital libraries;pathways;storytelling","Cultural differences;Data visualization;Europe;Libraries;Materials;Portals;Prototypes","digital libraries;history;information retrieval;museums;portals","Alinari Archives;European Commission FP7 programme;Europeana;PATHS project;PATHS system prototype;content discovery;cultural heritage digitisation;cultural heritage material;cultural heritage spaces;exhibitions;galleries;information interpretation;museums;online digital library portals;search portals;subject knowledge","","0","","18","","","2-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Community Site for Music Therapists Based on the Session Records of Music Therapy","N. Kosugi; M. Kondo","NTT Commun. Sci. Labs., Atsugi, Japan","2012 15th International Conference on Network-Based Information Systems","20121120","2012","","","319","325","This paper describes the design of a community site especially for music therapists. This site is made to achieve win-win relationship between music therapists and music information processing researchers. The clients of the music therapists have a lot of kinds of difficult conditions and backgrounds. Thus, the therapists need to exchange clinical information each other and to learn continuously about patients. They need a tool that can support storing, retrieving, and exchangeing therapeutic information. On the other hand, music information processing researchers, such as the first author is, have to collect data from real field where music is utilized to find new research topic and continuously contribute the human society with the new technologies. Thus, as a way of exchanging and storing information and also a way that is benefit able for both music therapists and music information processing researchers, we are designing a music therapists' community site that can mainly support making daily records of their sessions. Input information is stored in the database inside the site. The information is expected to be used for the information retrieval for music therapists and also is expected to be important resources to find new research topics for music information processing researchers. In this paper, we describe the community site especially for music therapists that is designed and developed according to the interviews of music therapists.","2157-0418;21570418","Electronic:978-0-7695-4779-4; POD:978-1-4673-2331-4","10.1109/NBiS.2012.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354844","Community Site;Music Information Processing Research;Music Therapy;Music Therapy Session Records","Communities;Databases;Information processing;Instruments;Senior citizens","health care;information retrieval;music;patient treatment","community site;healthcare;information retrieval;music information processing;music therapists;session records;therapeutic information","","0","","6","","","26-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Data standardization and modeling in a web based information system","T. Funkenberg; V. Klinger; C. Künzer","Julius-Maximilians-University W&#x00FC;rzburg, Institute of Geography, Department of Remote Sensing, Germany","2012 IEEE International Geoscience and Remote Sensing Symposium","20121110","2012","","","5282","5284","This paper describes data handling within a web-based information system in terms of data standardization, data modeling and data ingestion. The information system developed under the premise to make all datasets generated within the WISDOM project available for regional decision makers is based on a PostgreSQL object-relational database. Data standardization in this context is implemented by project specific guidelines that follow international standards like IS019115/19139 or OGC compliant Styled Layer Descriptors (SLD). Data modeling on the other hand improves data retrieval and accessibility by adding contextual information to all datasets through the registration to spatial, thematic and temporal reference objects. Ingesting new datasets into the information system is done in an automatic way for spatial datasets using a Java application, while non-spatial datasets have to be ingested by SQL commands. Implementing web-based interfaces to enable registered users to upload new datasets is a future task.","2153-6996;21536996","Electronic:978-1-4673-1159-5; POD:978-1-4673-1160-1; USB:978-1-4673-1158-8","10.1109/IGARSS.2012.6352417","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6352417","Data modeling;Data standardization;Information system;Metadata;Vietnam","","Internet;Java;SQL;data handling;data models;decision making;information retrieval;relational databases;standardisation","Java application;OGC SLD;OGC compliant styled layer descriptors;PostgreSQL object-relational database;SQL commands;WISDOM project;Web-based information system;Web-based interfaces;automatic way;contextual information;data accessibility;data handling;data ingestion;data modelling;data retrieval;data standardization;international standards;project specific guidelines;regional decision makers;registration reference objects;spatial datasets;spatial reference objects;temporal reference objects;thematic reference objects","","0","","6","","","22-27 July 2012","","IEEE","IEEE Conference Publications"
"Building an Ontology of Phenotypes for Existing GWAS Studies","N. Alipanah; H. Kim; L. Ohno-Machado","Dept. of Med., Univ. of California, San Diego, La Jolla, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","111","111","The database of Genotypes and Phenotypes (dbGaP) is archiving the results of different Genome Wide Association Studies (GWAS). dbGaP has a multitude of phenotype variables, but they are not harmonized across studies. Unfortunately, dbGaP lacks semantic relations among its variables. This prevents efficient information retrieval and accurate searches to find studies that contain common phenotypes. Our goal is to standardize dbGaP information to allow accurate, reusable and quick retrieval of information.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366205","","Clustering algorithms;Conferences;Medical services;Ontologies;Semantics;Systems biology;Unified modeling language","biology computing;genomics;information retrieval;information retrieval systems;ontologies (artificial intelligence)","GWAS;Genome Wide Association Studies;database of genotypes and phenotypes;information retrieval;information reusability;ontology;phenotype variables;semantic relations;standardize dbGaP information","","0","","2","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"A New Methodology for Collecting and Exploiting Vast Amounts of Dynamic Data","J. Legrand; E. Soulier; F. Bugeaud; F. Rousseaux; P. Saurel; H. Neffati","CERSA, Univ. Paris II, Paris, France","2012 Third International Conference on Emerging Intelligent Data and Web Technologies","20121120","2012","","","81","88","The current approaches aiming at collective intelligence modelling often rely on traditional methods (ontologies, graphs). Even if those traditional methods may have reached their limitations in front of demanding emerging practices, the major conceptual tools enrolled for current and future Web are deeply rooted in the information storage and retrieval practices. The focus is on developing more original technologies for capturing, analyzing, exploiting and visualizing data. The age cements/arrangements provide the appropriate epistemological context of our contribution. The simplicial complexes are the mathematical support of the methodology. The result is a shift from networks studied towards graph theory to higher dimensional networks structures. The representation is more than graphs, or even hyper graphs. A geometric perspective shows the arrangement as assembling polyhedra of all sizes. Their contacts can form chains of adjacencies. It does not only generalize the notion of path graphs but it also makes available a range of quantitative and qualitative tools on the structure. Thus, separate parts, which can be more or less strongly linked, length of paths to traverse, and even loops or ""missing parts"", are meaningful metadata representations.","","Electronic:978-0-7695-4734-3; POD:978-1-4673-1986-7","10.1109/EIDWT.2012.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354725","Agencement;Arrangement;Dynamic Knowledge;Emerging Knowledge;Simplicial Complexes","Abstracts;Finite element methods;Humans;Mathematical model;Ontologies;Social network services;Topology","Internet;data structures;data visualisation;graph theory;information retrieval;information storage;meta data","collective intelligence modelling;data collection;data visualization;dynamic data;future Web;graph theory;information retrieval;information storage;meta data representations","","1","","29","","","19-21 Sept. 2012","","IEEE","IEEE Conference Publications"
"Tibetan Web Information Collection System","G. Xu; D. Zhong; X. Gao; Y. Lin; X. Zhao; G. Yang","Coll. of Inf. Eng., Minzu Univ. of China, Beijing, China","2012 Fifth International Conference on Intelligent Networks and Intelligent Systems","20121210","2012","","","236","238","Nutch is an open source web-search software project. This paper introduces a system called Tibetan web information collection system, which bases on Apache Nutch. It points out original program's shortcomings and proposes an improved method, which can utilize the Nutch to deal with Tibetan web pages and generate the files that we need. Besides, this paper shows how to update the data regularly and delete the duplicate data. It is useful and helpful for the study of Tibetan information processing.","","Electronic:978-0-7695-4855-5; POD:978-1-4673-3083-1","10.1109/ICINIS.2012.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376530","Information Collection;Tibetan information processing;Web crawler","Crawlers;Data mining;Educational institutions;HTML;Information processing;Software;Web pages","Internet;Web sites;information retrieval;public domain software","Apache Nutch;Tibetan Web information collection system;Tibetan Web pages;Tibetan information processing;data update;duplicate data deletion;file generation;open source Web-search software project","","0","","5","","","1-3 Nov. 2012","","IEEE","IEEE Conference Publications"
"Towards a distributed federated architecture for digital documents","S. Sarasvady","Amrita Vishwa Vidyapeetham, Ettimadai, Coimbatore 641005, India","Seventh International Conference on Digital Information Management (ICDIM 2012)","20121124","2012","","","159","164","Creating the federated architecture is the most significant issues in the field of digital library. Human perception is not uniform while measuring the relevance to automate the retrieval process. In this work we have designed a system for integrating the existing architectures for digital library. This architecture uses integrated systems such as metadata, standard descriptors, feature extraction etc for text searching and retrieval. Databases of different size were used to estimate the accuracy of the system. The proposed algorithm works on the concept of minimum weight tree that removes the irrelevant texts from the retrieved hits, based on the dynamic threshold provided to the algorithm. We found out that careful combination of the different features based on our proposed heuristic, can increase the creation of a unified architecture for digital libraries.","pending","Electronic:978-1-4673-2430-4; POD:978-1-4673-2428-1","10.1109/ICDIM.2012.6360144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360144","Databases;Digital library;Federated Architecture;Text mining","Data engineering;Standards","digital libraries;distributed processing;information retrieval;text analysis;trees (mathematics)","digital documents;digital library;distributed federated architecture;dynamic threshold;feature extraction;integrated systems;irrelevant texts;metadata;minimum weight tree;standard descriptors;text retrieval;text searching","","0","","10","","","22-24 Aug. 2012","","IEEE","IEEE Conference Publications"
"Estimating Information from Image Colors: An Application to Digital Cameras and Natural Scenes","I. Marín-Franch; D. H. Foster","Indiana University of Optometry, Bloomington and City University London, London","IEEE Transactions on Pattern Analysis and Machine Intelligence","20121115","2013","35","1","78","91","The colors present in an image of a scene provide information about its constituent elements. But the amount of information depends on the imaging conditions and on how information is calculated. This work had two aims. The first was to derive explicitly estimators of the information available and the information retrieved from the color values at each point in images of a scene under different illuminations. The second was to apply these estimators to simulations of images obtained with five sets of sensors used in digital cameras and with the cone photoreceptors of the human eye. Estimates were obtained for 50 hyperspectral images of natural scenes under daylight illuminants with correlated color temperatures 4,000, 6,500, and 25,000 K. Depending on the sensor set, the mean estimated information available across images with the largest illumination difference varied from 15.5 to 18.0 bits and the mean estimated information retrieved after optimal linear processing varied from 13.2 to 15.5 bits (each about 85 percent of the corresponding information available). With the best sensor set, 390 percent more points could be identified per scene than with the worst. Capturing scene information from image colors depends crucially on the choice of camera sensors.","0162-8828;01628828","","10.1109/TPAMI.2012.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175904","Color vision;color constancy;color information;color processing;digital color cameras;information theory;kth-nearest-neighbor statistics;natural scenes","Cameras;Entropy;Image color analysis;Lighting;Mutual information;Random variables;Sensors","CCD image sensors;cameras;geophysical image processing;image colour analysis;information retrieval;lighting;natural scenes","camera sensors;daylight illuminants;digital cameras;human eye cone photoreceptors;hyperspectral images;image color values;image simulation;imaging conditions;information estimation;information retrieval;natural scenes","Algorithms;Artificial Intelligence;Color;Colorimetry;Humans;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Signal Processing, Computer-Assisted","6","","58","","20120403","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"Research on Recommendation Model of Technology Literature Based on User Preference","X. Li; B. Sun","Sch. of Inf., Central Univ. of Finance & Econ., Beijing, China","2012 International Conference on Management of e-Commerce and e-Government","20121206","2012","","","22","25","How to describe the features of users 'literature searching behavior has much more influences upon the efficiency of literature recommendation. Based on analyzing three key literature searching behavior, we assign several weight for those behavior so as to evaluate users' preferences. And then propose a user preference based recommendation model. Through simulation experiment, it is proved that our model had good performance and could improve the literature service quality effectively.","","Electronic:978-0-7695-4853-1; POD:978-1-4673-2943-9","10.1109/ICMeCG.2012.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374874","collaborative filtering;technology litrature recommendation;user preference","Clustering algorithms;Collaboration;Correlation;Educational institutions;Libraries;Recommender systems","behavioural sciences computing;information retrieval;literature;recommender systems","key literature searching behavior;literature recommendation model;user preference based recommendation model","","0","","10","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"SPOT the Drug! An Unsupervised Pattern Matching Method to Extract Drug Names from Very Large Clinical Corpora","A. Coden; D. Gruhl; N. Lewis; M. Tanenblatt; J. Terdiman","T.J. Watson Res. Center, IBM, Hawthorne, NY, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","33","39","Although structured electronic health records are becoming more prevalent, much information about patient health is still recorded only in unstructured text. “Understanding” these texts has been a focus of natural language processing (NLP) research for many years, with some remarkable successes, yet there is more work to be done. Knowing the drugs patients take is not only critical for understanding patient health (e.g., for drug-drug interactions or drug-enzyme interaction), but also for secondary uses, such as research on treatment effectiveness. Several drug dictionaries have been curated, such as RxNorm, FDA's Orange Book, or NCI, with a focus on prescription drugs. Developing these dictionaries is a challenge, but even more challenging is keeping these dictionaries up-to-date in the face of a rapidly advancing field-it is critical to identify grapefruit as a “drug” for a patient who takes the prescription medicine Lipitor, due to their known adverse interaction. To discover other, new adverse drug interactions, a large number of patient histories often need to be examined, necessitating not only accurate but also fast algorithms to identify pharmacological substances. In this paper we propose a new algorithm, SPOT, which identifies drug names that can be used as new dictionary entries from a large corpus, where a “drug” is defined as a substance intended for use in the diagnosis, cure, mitigation, treatment, or prevention of disease. Measured against a manually annotated reference corpus, we present precision and recall values for SPOT. SPOT is language and syntax independent, can be run efficiently to keep dictionaries up-to-date and to also suggest words and phrases which may be misspellings or uncatalogued synonyms of a known drug. We show how SPOT's lack of reliance on NLP tools makes it robust in analyzing clinical medical text. SPOT is a generalized bootstrapping algorithm, seeded with a known dictionary - nd automatically extracting the context within which each drug is mentioned. We define three features of such context: support, confidence and prevalence. Finally, we present the performance tradeoffs depending on the thresholds chosen for these features.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366185","Dictionary expansion;context matching;drug interactions;drugs;healthcare;medications;pattern discovery;pattern matching;unsupervised learning","Accuracy;Context;Dictionaries;Drugs;Semantics;Syntactics;Training","dictionaries;diseases;drugs;health care;information retrieval;medical information systems;natural language processing;patient diagnosis;patient treatment;pattern matching;statistical analysis;text analysis","FDA Orange Book;NCI;NLP;RxNorm;SPOT algorithm;clinical corpora;clinical medical text analysis;disease cure;disease diagnosis;disease mitigation;disease prevention;drug dictionaries;drug name extraction;drug-drug interactions;drug-enzyme interaction;generalized bootstrapping algorithm;natural language processing;patient health information;patient history;patient treatment;pharmacological substances;prescription drugs;prescription medicine Lipitor;structured electronic health records;uncatalogued synonym;unstructured text;unsupervised pattern matching method","","2","1","16","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Diversified Gesture Generation for Chinese Sign Language Animation","L. Jinghua; Y. Baocai; W. Lichun; K. Dehui; W. Yufei","Beijing Key Lab. of Multimedia & Intell. Software Technol., Beijing Univ. of Technol., Beijing, China","2012 Fourth International Conference on Digital Home","20121210","2012","","","179","183","In concatenating-based sign language synthesis, sign language words are usually captured in context free environment to construct database, and then the words corresponding with the input nature text are selected from the database and concatenated into sentences for synthesis. One problem here is that sign language words would exhibit diversified expression while embedded in different context. Including all kinds of expression for all sign language words is infeasible due to the difficulty in capturing, reserving and retrieving. Based on formatted sign language description and nonlinear magnification, this paper proposes a novel diversified gesture generation method for sign language expression in different context. Our method trains a computing model for diversified sign language gesture in ""emphasis"" context based on the data in the neutral state and the biggest intensity of emphasis collected from the teacher of deaf, and generates sign language gesture with any intensity of ""emphasis"" from the model and the data in neutral state, which makes the synthesized sign language animation more accurate and intelligible.","","Electronic:978-1-4673-1350-6; POD:978-1-4673-1348-3","10.1109/ICDH.2012.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376406","CSLML;Chinese Sign Language synthesis;Gesture generation","Animation;Computational modeling;Context;Educational institutions;Gesture recognition;Handicapped aids;Stress","computer animation;information retrieval;natural language processing;sign language recognition;word processing","Chinese sign language animation;computing model;concatenating-based sign language synthesis;context free environment;database construction;deaf student teacher;diversified gesture generation method;emphasis context;gesture generation;neutral state;nonlinear magnification;sign language word capturing;sign language word reservation;sign language word retrieval","","1","","17","","","23-25 Nov. 2012","","IEEE","IEEE Conference Publications"
"WebCap: Inferring the user's interests based on a real-time implicit feedback","N. Zemirli","Information System Department, King Saud University, Riyadh, KSA","Seventh International Conference on Digital Information Management (ICDIM 2012)","20121124","2012","","","62","67","In the context of the personalized information retrieval, this paper presents WebCap, a smart web browser for inferring the user's interests based on a real time implicit feedback. WebCap aims to collect implicitly the relevant documents, during the user's search session by inference of the degree of interest based on a combination of some relevant implicit indicators. The main advantage of our approach is that it does not require any log file. Indeed, WebCap, a browser side tool, calculates the degree of interest in real time and decides if the web page is quite relevant to feed the search history dimension. Our experimental framework, with real users, shows that WebCap can collected implicitly 80% of the relevant documents compared to the explicit approach.","pending","Electronic:978-1-4673-2430-4; POD:978-1-4673-2428-1","10.1109/ICDIM.2012.6360099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360099","","Browsers;History;Inference algorithms;Mice;Printing;Real-time systems;Web pages","Web sites;document handling;information retrieval","Web page;WebCap;documents;personalized information retrieval;real-time implicit feedback;smart Web browser;user interests","","1","","28","","","22-24 Aug. 2012","","IEEE","IEEE Conference Publications"
"A web service-based framework for an online 3D model viewer","H. F. ElYamany; M. E. Elawady; E. E. Abdelhay; A. I. Khalil","Computer Science Department, Faculty of Computers and Informatics, Suez Canal University, Ismailia, Egypt","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","1405","1410","Building Information Model (BIM) is an IT methodology to construct a facility virtually in details. The digital format representation is essential to facilitate information sharing and exchange among multiple contractors. Industry Foundation Classes (IFC) is utilized to embed the shared data in an XML standard structure to improve the interoperability among all interrelated participants within the facility construction process. Web Service (WS) is an XML component which encapsulates and transfers a business process and its contiguous data safely, concurrently, and less-cost among several sides through accessing the web. In this paper, a web service-based framework is introduced to enhance the performance of IFC elements exchange and accessibility through the web. The framework employs multiple web service replicas in order to obtain a fast real-time 3D view. Each individual service replica retrieves a specific section of the IFCs information from the DB backend and draws its corresponding object. Experimental evaluation shows that the framework effectively enhances the time required to sketch the overall 3D view for the participant.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354353","Building Information Systems;Performance and Scalability;Web Services and Systems","Browsers;Databases;Servers;Solid modeling;Standards;Web services","Web services;building;civil engineering computing;information retrieval;open systems;software performance evaluation;solid modelling;virtual reality","BIM;IFC;IFC information retrieval;IT methodology;Web service-based framework;XML standard structure;building information model;business process;digital format representation;facility construction process;industry foundation classes;information exchange facilitation;information sharing facilitation;interoperability improvement;multiple Web service replicas;online 3D model viewer;performance enhancement","","0","","17","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Design of Original Search Model Based on Broadcast and DHT in Peer to Peer Environment","Y. Gao; J. Zhan","Sch. of Inf., Capital Univ. of Econ. & Bus., Beijing, China","2012 International Conference on Management of e-Commerce and e-Government","20121206","2012","","","258","263","The file retrieval based on key words in P2P network is a challenging problem. In this paper, we propose a new solution: the search model identifies the frequency of key words automatically and applies inverted index based on DHT to fetch the sparse key words, the model can judge adopting whether inverted index or broadcast search under the condition of basing on key words retrieval, when fetch frequent key words, the model improves the broadcast algorithm in P2P system and adopts pointer of DHT to avoid repetitive messages.","","Electronic:978-0-7695-4853-1; POD:978-1-4673-2943-9","10.1109/ICMeCG.2012.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374920","DHT;P2P system;broadcast search;frequent key words","Bandwidth;Educational institutions;Indexes;Network topology;Peer to peer computing;Search problems;Standards","file organisation;information retrieval;peer-to-peer computing","DHT;P2P network;broadcast algorithm;file retrieval;frequent key word;inverted index;key words retrieval;peer to peer environment;search model;sparse key word","","0","","13","","","20-21 Oct. 2012","","IEEE","IEEE Conference Publications"
"Proposal for Cloud Search Engine as a Service","T. Miyano; M. Uehara","Dept. of Inf. & Comput. Sci., Toyo Univ., Kawagoe, Japan","2012 15th International Conference on Network-Based Information Systems","20121120","2012","","","627","632","In cloud and big data era, search engine is important. Especially, data is collected to cloud now. So, search engine that search documents in cloud is required. We developed Cooperative Search Engine (CSE), which is a distributed search engine suited for fresh information retrieval. Furthermore, we have developed Cloud Search Engine (ClSe), which is based on CSE and extended for searching data stored into cloud. However, in order to use ClSe, it is necessary to provide ClSe as all-in package and by deploying all components in suited way. This is not so easy. So, in this paper, we propose a service that provides ClSe as all-in-package in cloud. We call such a service CSEaaS (Cloud Search Engine as a Service). In this paper, we describe the design and implementation of CSEaaS. In CSEaaS, we realize easy setting and flexible deployment of ClSe. Furthermore, we show 3 typical use cases of ClSe.","2157-0418;21570418","Electronic:978-0-7695-4779-4; POD:978-1-4673-2331-4","10.1109/NBiS.2012.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354896","Cloud Computing;distributed search engine","Cloud computing;Engines;Google;Indexes;Reliability;Search engines;Servers","cloud computing;information retrieval;search engines","CSEaaS;cloud search engine as a service;cooperative search engine;distributed search engine;information retrieval","","1","","14","","","26-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"WiFiTag: Direct Link from the Real World to Online Digital Contents","Y. Arakawa; Y. Sonoda; S. Tagashira; A. Fukuda","Grad. Sch. of Inf. Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan","2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20121129","2012","","","339","344","WiFiTag is a simple and low cost solution for associating the real world to the online media such as web sites and YouTube. Our idea is to redirect a user's access based on the information of surrounding WiFi access points. Compared with WiFi-based indoor positioning system, our system requires no calculation and no much access points. This is because our system associates the digital content not with the location but with the AP itself. as the information of AP, we use ESSID, BSSID, and RSSI. by uploading a scanned WiFi information to the WiFiTag server, a terminal can get the proper URL as a response. Relationship between the WiFiTag and the URL have been defined ahead. WiFiTag realize ""real to virtual"" connection easily. for example, by associating lab's SSID to lab's HP, a visitor can access a lab's HP easily and directly, when the visitor comes to our lab. a camera required for QR code don't need for our system. in addition, a special card reader and touch action required for NFC are also unnecessary. If WiFi has already exist, no additional cost is necessary for our system. in this paper, we describe a overall concept of WiFiTag and show the availability and feasibility of our proposed system through some experimental evaluation results.","","Electronic:978-0-7695-4841-8; POD:978-1-4673-2991-0","10.1109/3PGCIC.2012.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362992","BSSID;ESSID;NFC;QR code;RSSI;WiFi","Buildings;Companies;Global Positioning System;Google;IEEE 802.11 Standards;Registers;Servers","content management;information retrieval;social networking (online);wireless LAN","AP;BSSID;ESSID;NFC;QR code;RSSI;URL;WiFi access point;WiFiTag;online digital content;online media;user access","","2","2","9","","","12-14 Nov. 2012","","IEEE","IEEE Conference Publications"
"Patient data tracking in a collaborative healthcare","Q. A. Memon; S. A. Khoja","","Proceedings of the 10th World Congress on Intelligent Control and Automation","20121124","2012","","","5045","5050","It has been found that patients do suffer from queuing at reception, pharmacy, appointments, and services departments of the hospitals. In this paper, patient tracking is presented such that it enables not only presence of the patient within each service area of the hospital but helps in retrieving relevant medical records of the patient from another hospital within a collaborative healthcare domain. The architectural challenges are investigated, and a framework for such a collaborative region is presented. The patient record database is developed, and technologies are chosen to exemplify a typical environment. The issues related to its deployment are also discussed.","","Electronic:978-1-4673-1398-8; POD:978-1-4673-1397-1","10.1109/WCICA.2012.6359434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359434","","Collaboration;Databases;Hospitals;RFID tags;Servers","database management systems;groupware;health care;hospitals;information retrieval;medical information systems;queueing theory","appointments;architectural challenges;collaborative healthcare;collaborative region;hospitals;patient data tracking;patient record database;pharmacy;reception queuing;relevant medical record retrieval;services departments","","0","","17","","","6-8 July 2012","","IEEE","IEEE Conference Publications"
"A low cost scalable predictive server architecture for embedded systems applications","D. Mezzalira; L. C. Trevelin","Computing Department, Federal University of S&#x00E3;o Carlos, SP 13565-905 Brazil","2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20121213","2012","","","692","696","The objective of this study is to propose a low cost scalable architecture for embedded applications, using pools of personal computers for high performance storage, retrieval and processing of information through the study of traces and real solutions for companies operating in this niche market. By predictable intelligence (Box-Jenkins) it's possible to predict the future behavior of the application and make adjustments to keep the deadlines of the different classes of information.","1062-922X;1062922X","Electronic:978-1-4673-1714-6; POD:978-1-4673-1713-9; USB:978-1-4673-1712-2","10.1109/ICSMC.2012.6377807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377807","Architecture;Box-Jenkis;Distributed Systems;Embedded Systems;Performance;Queuing Systems;Simulation","Computational modeling;Computer architecture;Databases;Embedded systems;Message systems;Quality of service;Servers","agriculture;file servers;information retrieval","Box-Jenkins;agricultural mechanization;embedded systems applications;information processing;information retrieval;information storage;low cost scalable predictive server architecture;niche market;personal computers;predictable intelligence","","0","","10","","","14-17 Oct. 2012","","IEEE","IEEE Conference Publications"
"Busfinder: A Personalized Multimodal Transportation Guide with Dynamic Routing","D. Tsolkas; N. Passas; C. Xenakis; V. Papataxiarhis; V. Tsetsos","Dept. of Inf. & Telecommun., Univ. of Athens, Athens, Greece","2012 16th Panhellenic Conference on Informatics","20121213","2012","","","25","30","Multimodal routing services with public transportation are already present in many large cities across the globe. In this paper we describe a mobile guide that goes beyond existing solutions, mainly due to its service personalization and its dynamic routing algorithm. Personalization is based on knowledge engineering principles and Semantic Web technologies. The dynamic routing algorithm is based on short term history and estimators and supports cities with pre-installed fleet management systems in the public transport means.","","Electronic:978-0-7695-4825-8; POD:978-1-4673-2720-6","10.1109/PCi.2012.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377362","dynamic routing;multimodal transportation;personalized location services","Algorithm design and analysis;Cities and towns;Heuristic algorithms;Ontologies;Real-time systems;Routing;Transportation","graph theory;information retrieval;knowledge engineering;mobile computing;search problems;semantic Web;traffic information systems;transportation","Busfinder;dynamic routing algorithm;fleet management system;graph search algorithm;knowledge engineering principle;mobile guide;multimodal routing service;personalized multimodal transportation guide;public transportation;semantic Web technology;service personalization;short term history","","1","","13","","","5-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"A dynamic Proof of Retrievability (PoR) scheme with O(logn) complexity","Z. Mo; Y. Zhou; S. Chen","Dept. of Comput. &amp; Inf. Sci. &amp; Eng., Univ. of Florida, Gainesville, FL, USA","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","912","916","Cloud storage has been gaining popularity because its elasticity and pay-as-you-go manner. However, this new type of storage model also brings security challenges. This paper studies the problem of ensuring data integrity in cloud storage. In the Proof of Retrievability (PoR) model, after outsourcing the preprocessed data to the server, the client will delete its local copies and only store a small amount of meta data. Later the client will ask the server to provide a proof that its data can be retrieved correctly. However, most of the prior PoR works apply only to static data. The existing dynamic version of PoR scheme has an efficiency problem. In this paper, we extend the static PoR scheme to dynamic scenario. That is, the client can perform update operations, e.g., insertion, deletion and modification. After each update, the client can still detect the data losses even if the server tries to hide them. We develop a new version of authenticated data structure based on a B+ tree and a merkle hash tree. We call it Cloud Merkle B+ tree (CMBT). By combining the CMBT with the BLS signature, we propose a dynamic version of PoR scheme. Compared with the existing dynamic PoR scheme, our worst case communication complexity is O(logn) instead of O(n).","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6364056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6364056","","Cloud computing;Complexity theory;Computers;Data structures;Indexes;Security;Servers","cloud computing;communication complexity;data structures;information retrieval;trees (mathematics)","BLS signature;CMBT;PoR model;authenticated data structure;cloud Merkle B+ tree;cloud storage model;communication complexity;dynamic proof of retrievability scheme;merkle hash tree;meta data;server;static PoR scheme","","5","","14","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Systematic Analysis of Cross-Institutional Medication Description Patterns in Clinical Notes","S. Sohn; S. P. Murphy; S. R. Jonnalagadda; K. Wagholikar; S. T. Wu; C. G. Chute; H. Liu; S. Halgrim","Mayo Clinic, Rochester, MN, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","118","118","In clinical notes, medication information follows certain semantic patterns and some medication descriptions contain additional word(s) between medication attributes. Therefore, it is essential to understand the semantic patterns as well as the patterns of the context interspersed among them for natural language processing tools to effectively extract comprehensive medication information. We examined both semantic and context patterns and compared those found in Mayo Clinic and i2b2 challenge data. We found that some variations exist between the institutions but the dominant patterns are common.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366211","","Aspirin;Biomedical imaging;Conferences;Context;Informatics;Semantics","information retrieval;medical information systems;natural language processing;pattern classification;text analysis","Mayo Clinic data;clinical notes;comprehensive medication information extraction;context patterns;cross-institutional medication description pattern analysis;i2b2 challenge data;medication attributes;natural language processing tools;semantic patterns;systematic analysis","","0","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Gaussian mixture model based volume visualization","S. Liu; J. A. Levine; P. T. Bremer; V. Pascucci","","IEEE Symposium on Large Data Analysis and Visualization (LDAV)","20121213","2012","","","73","77","Representing uncertainty when creating visualizations is becoming more indispensable to understand and analyze scientific data. Uncertainty may come from different sources, such as, ensembles of experiments or unavoidable information loss when performing data reduction. One natural model to represent uncertainty is to assume that each position in space instead of a single value may take on a distribution of values. In this paper we present a new volume rendering method using per voxel Gaussian mixture models (GMMs) as the input data representation. GMMs are an elegant and compact way to drastically reduce the amount of data stored while still enabling realtime data access and rendering on the GPU. Our renderer offers efficient sampling of the data distribution, generating renderings of the data that flicker at each frame to indicate high variance. We can accumulate samples as well to generate still frames of the data, which preserve additional details in the data as compared to either traditional scalar indicators (such as a mean or a single nearest neighbor down sample) or to fitting the data with only a single Gaussian per voxel. We demonstrate the effectiveness of our method using ensembles of climate simulations and MRI scans as well as the down sampling of large scalar fields as examples.","","Electronic:978-1-4673-4733-4; POD:978-1-4673-4732-7","10.1109/LDAV.2012.6378978","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378978","Ensemble Visualization;Gaussian Mixture Model;Uncertainty Visualization;Volume Rendering","Computational modeling;Data models;Data visualization;Graphics processing units;Rendering (computer graphics);Transfer functions;Uncertainty","Gaussian processes;data reduction;data structures;data visualisation;information retrieval;natural sciences computing;real-time systems;rendering (computer graphics)","GMM;GPU;Gaussian mixture model;MRI scans;climate simulations;data distribution;data fitting;data reduction;down sampling;input data representation;large scalar fields;real-time data access;scientific data analysis;uncertainty representation;volume rendering method;volume visualization","","1","","18","","","14-15 Oct. 2012","","IEEE","IEEE Conference Publications"
"The discounted cumulative margin penalty: Rank-learning with a list-wise loss and pair-wise margins","C. Renjifo; C. Carmen","The Johns Hopkins University Applied Physics Laboratory, Laurel MD 20723, USA","2012 IEEE International Workshop on Machine Learning for Signal Processing","20121110","2012","","","1","6","In recent years, the fields of rank-learning and information retrieval have received substantial attention. Algorithms developed within these domains have shown promising results in a variety of problem spaces, especially in document retrieval and web search. In this paper, a new rank-learning algorithm is proposed that combines list-wise loss measurements with pair-wise margins. The list-wise loss term is inspired by the Normalized Discounted Cumulative Gain (NDCG) metric, and the resulting objective function is solvable with gradient-free optimization techniques. Experiments using the LETOR 3.0 and 4.0 collections demonstrate that the ranking performance achieved by an algorithm using this loss measure is competitive with reported baselines.","1551-2541;15512541","Electronic:978-1-4673-1026-0; POD:978-1-4673-1024-6; USB:978-1-4673-1025-3","10.1109/MLSP.2012.6349807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6349807","Discounted Cumulative Margin Penalty;Large Margins;Learning to Rank;Normalized Discounted Cumulative Gain;Pair-wise and List-wise Constraints","Computational modeling;Linear programming;Loss measurement;Signal processing algorithms;Training;Vectors","gradient methods;information retrieval;learning (artificial intelligence)","LETOR 3.0;LETOR 4.0 collections;NDCG metric;Web search;discounted cumulative margin penalty;document retrieval;gradient-free optimization techniques;information retrieval;list-wise loss measurements;normalized discounted cumulative gain metric;objective function;pair-wise margins;rank-learning algorithm","","6","","19","","","23-26 Sept. 2012","","IEEE","IEEE Conference Publications"
"Long Term Management of Web Cache for Web Archive","R. Ozawa; M. Uehara","Dept. of Inf. & Comput. Sci., Toyo Univ., Kawagoe, Japan","2012 15th International Conference on Network-Based Information Systems","20121120","2012","","","639","644","Today, Internet is usually used as large databases. However, Web pages published by an author is often modified and deleted by the author but not by viewers. Therefore, it is difficult for viewers to guarantee the contents of Web pages referred by an official documents. So, in this paper, we propose a system that guarantees Web page existence. This system checks whether the contents of a page accessed at a time is the same or not. It does not need to collect all pages and can guarantee only pages accessed at once. In this system, the log of cache server is always monitored and cached pages are copied from cache to archive. Furthermore, a user can search pages by a query specified with a time and gets the contents created/modified at that time.","2157-0418;21570418","Electronic:978-0-7695-4779-4; POD:978-1-4673-2331-4","10.1109/NBiS.2012.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354898","Web Archive;Web Cache","Databases;Engines;Internet;Search engines;Servers;Web pages","Internet;Web sites;cache storage;content management;document handling;information retrieval systems;query processing","Internet;Web archive;Web cache;Web page content;Web page existence;cache server log;large databases;long term management;official documents;query","","1","","15","","","26-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Web user navigation patterns discovery from WWW server log files","P. Weichbroth; M. Owoc; M. Pleszkun","PHD Student, Katowice University of Economics, Katowice, Poland","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","1171","1176","Continued growth of user number and size of shared content on Web sites cause the necessity of automatic adjusting content to users' needs. In the literature of Web Mining, such actions are referred to personalization and recommendation which led to improve the visibility of presented content. To perform adequacy actions which correspond to the expected users' needs we can utilize web server log files. Mining such data with accurate constraints can lead to the discovery of web user navigation patterns. Such knowledge is used by personalization and recommendation systems (PRS) due to performed actions against user behavior during a visit on the web portal. In these paper we present the system framework for mining web user navigation patterns in order to knowledge management. We focus on constraints which are critical factors to evaluate the effectiveness of the implemented algorithm. On the other hand, these constraints can be perceived as knowledge validation criteria due to its adequacy. Thus only adequate knowledge can be added to existing in PRS knowledge base.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354427","","Association rules;Electronic mail;Navigation;Software algorithms;Web servers","Web sites;data mining;file servers;information needs;information retrieval;knowledge management;portals","PRS knowledge base;WWW server log files;Web Mining;Web portal;Web sites;Web user navigation pattern discovery;automatic content adjustment;data Mining;knowledge management;personalization and recommendation systems;shared content;user behavior;user needs","","1","","36","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Automatic content extraction and visualization of Thai websites for improved information representation","W. Thanadechteemapat; C. C. Fung","School of Information Technology, Murdoch University, Western Australia","2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20121213","2012","","","2229","2234","This paper presents an integrated approach to automatically provide an overview of content on Thai websites based on tag cloud. This approach is intended to address the information overload issue by presenting the overview to users in order that they could assess whether the information meets their needs. The approach has incorporated Web content extraction, Thai word segmentation, and information presentation to generate a tag cloud in Thai language as an overview of the key content in the webpage. From the experimental study, the generated Thai Tag clouds are able to provide an overview of the tags which frequently appear in the title and body of the content. Moreover, the first few lines in the tag cloud offer an improved readability.","1062-922X;1062922X","Electronic:978-1-4673-1714-6; POD:978-1-4673-1713-9; USB:978-1-4673-1712-2","10.1109/ICSMC.2012.6378072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378072","Keyword Extraction;Maximum Term Frequency;Thai Word Segmentation;Thai tag cloud;Web Content Extraction","Accuracy;Compounds;Data mining;Dictionaries;Feature extraction;Tag clouds;Visualization","Web sites;cloud computing;data visualisation;information retrieval;natural language processing;word processing","Thai Web sites;Thai language;Thai tag clouds;Thai word segmentation;Web page;automatic content extraction;automatic content visualization;content body;content title;information overload issue;information representation;readability improvement","","1","","26","","","14-17 Oct. 2012","","IEEE","IEEE Conference Publications"
"High Presence Digital Archive of Disaster Experience","T. Ogi; H. Lee; Y. Ishiyama; Y. Kubota","SDM, Keio Univ., Yokohama, Japan","2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20121129","2012","","","245","249","In order to keep the awareness of the problem without fading the experience of past disaster, it is effective to reexperience it with high presence sensation. in this study, earthquake disaster experience system that records the scene of the disaster and represents it with high presence sensation was developed. in this method, the scene of the real world is recorded using virtual sphere model and it can be represented in immersive projection display such as CAVE or dome display. by using this system, the user can experience high presence scene using the effect of virtual depth sensation.","","Electronic:978-0-7695-4841-8; POD:978-1-4673-2991-0","10.1109/3PGCIC.2012.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362976","CAVE;digital archive;disaster experience;dome environment;high presence sensation","Cameras;Earthquakes;Educational institutions;Humans;Image resolution;Internet;Lenses","disasters;humanities;information retrieval systems;natural scenes;video recording","CAVE;disaster scene recording;dome display;earthquake disaster experience system;high presence digital archive;high presence sensation;immersive projection display;past disaster experience;virtual depth sensation effect;virtual sphere model","","0","","9","","","12-14 Nov. 2012","","IEEE","IEEE Conference Publications"
"A Study on Studies: Exploring the Metadata Associated with dbGaP Studies","K. Truong; M. Conway","Dept. of Med., Univ. of California, San Diego, La Jolla, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","126","126","The database of Genotypes and Phenotypes (dbGaP) was developed by the National Heart Lung, and Blood Institute (NHLBI) to archive genome-wide association studies (GWAS) data. As of July 17th 2012, dbGaP contained 305 top-level studies. The metadata for each study (available from the dbGaP website) are organized into distinct sections, including a study description, inclusion/exclusion criteria, policies for authorized access requests, MeSH terms, PubMed identifiers, study histories, and the names of principal and co-investigators. We here tabulate the salient characteristics of dbGaP metadata as part of the Phenotype Discoverer (PhD) project, a research project at the University of California San Diego Division of Biomedical Informatics which aims to enhance the ""searchability"" of the current dbGaP website through the alignment of phenotypes to a standard information model. In particular, we are interested in using the extracted metadata PubMed identifiers, principal investigator names, associated journal names, etc. as input to a statistical text.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366217","","Biomedical informatics;Blood;Databases;Diabetes;Educational institutions;Heart;Lungs","Web sites;authorisation;bioinformatics;genomics;information retrieval;meta data;statistical analysis;text analysis","GWAS data;MeSH terms;NHLBI;National Heart Lung and Blood Institute;PhD project;Phenotype Discoverer project;PubMed identifiers;University of California San Diego Division of Biomedical Informatics;authorized access request policy;database of genotypes and phenotypes;dbGaP Website;dbGaP studies;genome-wide association studies data;inclusion-exclusion criteria;metadata;research project;searchability enhancement;standard information model;statistical text;study description;study histories","","1","","4","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Temporary made permanent: Turning temporary exhibitions into fixed memories","G. Morlando; L. Lamera; G. Guidi","Dept. INDACO, Politecnico di Milano, Milan, Italy","2012 18th International Conference on Virtual Systems and Multimedia","20121203","2012","","","19","24","The museum institution deals with the study, the storage and the fruition of cultural heritage. To fulfill these functions the museum uses, as well as the opinion of experts, even the most modern technologies. In this article we present some cases in which the use of digital and virtual reality effectively contributes to increase the knowledge on cultural heritage. In the last years there have been many studies to allow cultural heritage to be preserved with great care, ensuring the memory for scholars but also for future generations. The methods for storing a cultural object are widely studied, but the best techniques to preserve different forms of heritage like temporary or intangible items, are still under discussion. In particular this article refers to the possibility of keeping track of the information contained in a temporary exhibition project, that by its nature exists for a limited amount of time before being finally destroyed or transferred. With the use of standard tools like photogrammetry and three-dimensional modeling we try to define a process in order to turn the temporary into permanent, both for archiving purposes or for allowing the public to access the temporary installation once the physical object has been dismounted.","","Electronic:978-1-4673-2565-3; POD:978-1-4673-2564-6","10.1109/VSMM.2012.6365902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365902","3D Modeling;Museum;Photogrammetry;Temporary exhibition;temporary installation","Art;Catalogs;Cultural differences;Image reconstruction;Lighting;Rendering (computer graphics);Solid modeling","exhibitions;history;information retrieval systems;museums;virtual reality","archiving purpose;cultural heritage;cultural object;digital reality;fixed memories;museum institution;photogrammetry;physical object;temporary exhibition project;three-dimensional modeling;virtual reality","","0","","10","","","2-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Identifying named entities on a University intranet","M. Althobaiti; U. Kruschwitz; M. Poesio","School of Computer Science and Electronic Engineering, University of Essex, Colchester, UK","2012 4th Computer Science and Electronic Engineering Conference (CEEC)","20121206","2012","","","94","99","Named entities (NEs) are textual references via proper names, such aspeople names, company names, places and so on. The importance of NEs has been observed in intranet search engines, including university web sites. In this paper, a mechanism is built exclusively to recognize the three named entities, which are constantly referenced in the University of Essex domain: names, course codes, and room numbers. While a person name is considered a common named entity, course codes and room numbers are specific to the University domain. We developed a technique specifically to train three different classifiers on electronic corpora, consisting of 16,629 examples in total, which were collected and annotated manually from the University domain. The resulting models were then incorporated into the NER system that was built to use pre-trained classifiers in the detection process, mark these NEs, and cross-reference them to the related documents. The proposed method performed well on a test corpus, with the average precision reaching nearly 0.97. The recall varied, but was lower overall than precision with an average of 0.82. Moreover, in terms of name recognition in the University domain, our system outperformed two other systems: the OpenNLP name finder and ANNIE system.","","Electronic:978-1-4673-2666-7; POD:978-1-4673-2665-0","10.1109/CEEC.2012.6375385","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375385","Corpus-based methods;Information Extraction from the web;Machine learning;Named Entity Recognition;Natural Language Processing;Statistical approach","Computer science;Educational institutions;Entropy;Search engines;Training;Training data;Web pages","Web sites;educational computing;educational institutions;information retrieval;intranets;learning (artificial intelligence);natural language processing;search engines;statistical analysis;text analysis","ANNIE system;NE;OpenNLP name finder;University of Essex;company names;corpus-based methods;course codes;detection process;electronic corpora;information extraction;machine learning;name recognition;named entity identification;named entity recognition;natural language processing;people names;pretrained classifiers;proper names;room numbers;statistical approach;textual references;university Web sites;university domain;university intranet search engines","","0","","24","","","12-13 Sept. 2012","","IEEE","IEEE Conference Publications"
"A Task-Based Approach for Large-Scale Evaluation of the Gene Ontology","S. Loguercio; E. L. Clarke; B. M. Good; A. I. Su","Dept. of Mol. & Exp. Med., Scripps Res. Inst., La Jolla, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","144","144","The Gene Ontology (GO) provides a framework to systematically classify and annotate gene function. The annotations associated with GO play a critical role in modern biology and cover many organisms. For the human genome, over 10,000 GO terms are used to annotate gene function in an expansive database of over 200,000 annotations. Due to the importance of the GO annotations in modern biology, significant effort has been put into assessing the quality of the annotations. Providing measures of annotation completeness, accuracy, and precision is critical if researchers are to use the annotations in real-world applications with confidence. Here, we describe a task-based approach that examines the completeness and utility of GO annotations through the lens of gene enrichment analysis. Our approach can be used to model the progression of the GO annotations over time, either for a particular area of interest or for the body of annotations as a whole. Using this framework, we conducted a large-scale analysis of gene expression datasets from the NCBI Gene Expression Omnibus (GEO). In particular, we identified terms of interest for each dataset through semantic annotation of biomedical data, then tracked the behavior of these terms as a function of time. The preliminary results provide significant information about the progress and character of GO annotations over time. This framework is flexible enough to examine all or part of the GO annotations, across multiple species, and with various enrichment methods. We also discuss how this framework can be used to evaluate different annotation methods. For example, by comparing the performance of annotations generated with a particular method to the performance of canonical annotations, it is possible to determine their relative quality.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366236","","Bioinformatics;Conferences;Gene expression;Genomics;Ontologies;Semantics","genetics;information retrieval;medical computing;ontologies (artificial intelligence);pattern classification","GEO;GO;NCBI Gene Expression Omnibus;gene enrichment analysis;gene expression datasets;large-scale gene ontology evaluation;systematic gene function annotation;systematic gene function classification;task-based approach","","0","","3","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Salient time steps selection from large scale time-varying data sets with dynamic time warping","X. Tong; T. Y. Lee; H. W. Shen","The Ohio State University","IEEE Symposium on Large Data Analysis and Visualization (LDAV)","20121213","2012","","","49","56","Empowered by rapid advance of high performance computer architectures and software, it is now possible for scientists to perform high resolution simulations with unprecedented accuracy. Nowadays, the total size of data from a large-scale simulation can easily exceed hundreds of terabytes or even petabytes, distributed over a large number of time steps. The sheer size of data makes it difficult to perform post analysis and visualization after the computation is completed. Frequently, large amounts of valuable data produced from simulations are discarded, or left in disk unanalyzed. In this paper, we present a novel technique that can retrieve the most salient time steps, or key time steps, from large scale time-varying data sets. To achieve this goal, we develop a new time warping technique with an efficient dynamic programming scheme to map the whole sequence into an arbitrary number of time steps specified by the user. A novel contribution of our dynamic programming scheme is that the mapping between the whole time sequence and the key time steps is globally optimal, and hence the information loss is minimum. We propose a high performance algorithm to solve the dynamic programming problem that makes the selection of key times run in real time. Based on the technique, we create a visualization system that allows the user to browse time varying data at arbitrary levels of temporal detail. Because of the low computational complexity of this algorithm, the tool can help the user explore time varying data interactively and hierarchically. We demonstrate the utility of our algorithm by showing results from different time-varying data sets.","","Electronic:978-1-4673-4733-4; POD:978-1-4673-4732-7","10.1109/LDAV.2012.6378975","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378975","","Dynamic programming;Equations;Heuristic algorithms;Isosurfaces;Silicon;Time series analysis","computational complexity;data analysis;data visualisation;dynamic programming;information retrieval;interactive systems","computational complexity;data visualization;dynamic programming;dynamic time warping;globally optimal key time steps;hierarchical data exploration;high performance algorithm;high performance computer architectures;high performance software;high resolution simulations;interactive data exploration;key time step retrieval;large scale time-varying data sets;large-scale simulation;levels of temporal detail;minimum information loss;post analysis;salient time step retrieval;salient time step selection;sheer data size;time varying data browsing;visualization system;whole time sequence","","4","","21","","","14-15 Oct. 2012","","IEEE","IEEE Conference Publications"
"Creating missing classes automatically to improve question classification in question answering systems","M. Bakhtyar; A. Kawtrakul; J. Baber; S. M. Doudpota","Department of CS and IM, Asian Institute of Technology, Thailand","Seventh International Conference on Digital Information Management (ICDIM 2012)","20121124","2012","","","99","103","Internet is one of the main sources for information which attracts million of users to find the answers for their questions. Finding the accurate answer of the question from giant databases or web pages is a very challenging task. Question answering systems answer the question from structured or unstructured databases. Question answering is different from the traditional ad-hoc document retrieval tasks in a way that in simple document search engine, the set of relevant documents are returned in response of the query, whereas, in the question answering systems the response of the query is the correct answer to what is asked. Finding the exact answer is more interesting and useful than getting a list of documents to look through and find the answer manually. Generally, the question classification is first phase in question answering systems. This phase reduces the answer space by pruning out the extra information that is irrelevant by finding out the expected answer type. This paper mainly focuses on Numeric type questions and also discusses briefly about the questions of type Entity and Location. Almost all the previous question classification algorithms evaluated their work by using the classes defined by Li and Roth [1]. The coarse grained class Numeric has fine grained class Other. In this paper, we target and present the mechanism to create new classes to replace the Other class in Numeric class. We present an automatic hierarchy creation method to add new class nodes using the knowledge resources and shallow language processing.","pending","Electronic:978-1-4673-2430-4; POD:978-1-4673-2428-1","10.1109/ICDIM.2012.6360139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360139","","Search engines;Semantics;Sociology;Statistics;Taxonomy;USA Councils","Internet;classification;knowledge based systems;question answering (information retrieval);search engines;very large databases","Internet;Web pages;ad hoc document retrieval tasks;document search engine;giant databases;information sources;knowledge resources;missing classes;question answering systems;question classification;shallow language processing;unstructured databases","","0","","15","","","22-24 Aug. 2012","","IEEE","IEEE Conference Publications"
"Semi-supervised classification of hyperspectral data using spectral unmixing concepts","I. Dópido; J. Li; A. Plaza; P. Gamba","Hyperspectral Computing Laboratory, University of Extremadura, Avda. de la Universidad s/n, 10003 C&#x00E1;ceres, Spain","2012 Tyrrhenian Workshop on Advances in Radar and Remote Sensing (TyWRRS)","20121213","2012","","","353","358","Spectral unmixing and classification have been widely used in the recent literature to analyze remotely sensed hyperspectral data. However, possible connections between semi-supervised classification and spectral unmixing concepts have been rarely investigated. In this work, we propose a new method to perform semi-supervised classification of hyperspectral images by exploiting the information retrieved with spectral unmixing. The proposed method integrates a well-established discriminative classifier (multinomial logistic regression) with different spectral unmixing chains, thus bridging the gap between unmixing and classification. Furthermore, the proposed method uses active learning when generating new unlabeled samples for classification. The proposed method is experimentally validated using real hyperspectral data sets, indicating that the combination of spectral unmixing and semi-supervised classification can lead to powerful new algorithms for hyperspectral data interpretation.","","Electronic:978-1-4673-2443-4; POD:978-1-5090-0000-5","10.1109/TyWRRS.2012.6381155","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381155","","Accuracy;Hyperspectral imaging;Logistics;Probabilistic logic;Semisupervised learning;Training","image classification;information retrieval;regression analysis;remote sensing","active learning;discriminative classifier;hyperspectral images;information retrieval;multinomial logistic regression;remotely sensed hyperspectral data;semisupervised classification;spectral classification;spectral unmixing concepts;unlabeled samples","","1","","27","","","12-14 Sept. 2012","","IEEE","IEEE Conference Publications"
"Ranking on Data Manifold with Sink Points","X. Q. Cheng; P. Du; J. Guo; X. Zhu; Y. Chen","Chinese Academy of Sciences, Beijing","IEEE Transactions on Knowledge and Data Engineering","20121119","2013","25","1","177","191","Ranking is an important problem in various applications, such as Information Retrieval (IR), natural language processing, computational biology, and social sciences. Many ranking approaches have been proposed to rank objects according to their degrees of relevance or importance. Beyond these two goals, diversity has also been recognized as a crucial criterion in ranking. Top ranked results are expected to convey as little redundant information as possible, and cover as many aspects as possible. However, existing ranking approaches either take no account of diversity, or handle it separately with some heuristics. In this paper, we introduce a novel approach, Manifold Ranking with Sink Points (MRSPs), to address diversity as well as relevance and importance in ranking. Specifically, our approach uses a manifold ranking process over the data manifold, which can naturally find the most relevant and important data objects. Meanwhile, by turning ranked objects into sink points on data manifold, we can effectively prevent redundant objects from receiving a high rank. MRSP not only shows a nice convergence property, but also has an interesting and satisfying optimization explanation. We applied MRSP on two application tasks, update summarization and query recommendation, where diversity is of great concern in ranking. Experimental results on both tasks present a strong empirical performance of MRSP as compared to existing ranking approaches.","1041-4347;10414347","","10.1109/TKDE.2011.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007135","Diversity in ranking;manifold ranking with sink points;query recommendation;update summarization","Algorithm design and analysis;Convergence;Diversity reception;Eigenvalues and eigenfunctions;Query processing;Ranking systems;Redundancy","data handling;information retrieval;natural language processing","MRSP;computational biology;data manifold;information retrieval;manifold ranking with sink points;natural language processing;query recommendation;sink points;social sciences","","13","","39","","20110901","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"A scalable repository infrastructure for CH digital object management","X. Pan; T. Schiffer; M. Schröttner; S. Havemann; M. Hecher; R. Berndt; D. W. Fellner","Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Inffeldgasse 16c, 8010 Graz, Austria","2012 18th International Conference on Virtual Systems and Multimedia","20121203","2012","","","219","226","In recent decades, researchers of archaeological 3D digitalization found that the collection and archive of processing intermediate data are extremely tiresome tasks. They need large of man power and material resources, even though, mistakes can be raised and break the whole working chain. The traditional documentation of digitalization process is also a pending challenge, although, the ISO standard CIDOC-CRM (ISO 21127:2006) has been introduced to the archaeologists and museum professionals since years, but there are still some obvious gaps between practice and theory: (1) How to connect the discrete archaeologists, museums, CH research institutions, and the public? (2) How to ensure the integrity of whole digitalization process and simplify the process? (3) How to maximize the usability of the public digital objects in CH community? (4) How to long term preserve the huge amount of datasets? (5) How to present and disseminate the digital object to the public? This paper presents an operational and optimal infrastructure that realizes not only a distributed storage system, but also a content management system. This infrastructure works as a backbone of whole digitalization process, provides a complete solution suite for archaeologists, museum professionals, museum visitors, and IT technicians.","","Electronic:978-1-4673-2565-3; POD:978-1-4673-2564-6","10.1109/VSMM.2012.6365928","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365928","Distributed application;data warehouse and repository;distributed system design","Data models;Databases;Semantics;Servers;Solid modeling;System analysis and design;Usability","archaeology;content management;data warehouses;distributed processing;information retrieval systems;storage management","CH digital object management;CH research institutions;CIDOC-CRM ISO standard;ISO 21127:2006;archaeological 3D digitalization;content management system;data repository;data warehouse;digitalization process;distributed storage system;processing intermediate data archive;processing intermediate data collection;public digital object usability maximization;repository infrastructure","","1","","20","","","2-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Implementing web of data with VWBE & H2X","C. H. Tseng","Department of Computer Information and Network Engineering, Lunghwa University of Science and Technology, Taoyuan, R.O.C.","2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA)","20121124","2012","","","558","563","Today, the explosive amount of information on the Web has become the major challenge for Web searchers. Despite the improvements of search engine technologies, searching for specific information is sometimes still an uneasy task. There are two major problems: first, the relatedness of information is not handled by search engines, and second, HTML is a presentation-oriented language, not an information-oriented one. The former issue results in inconvenience. Result list from most modern search engines contain standalone Web pages, however, multiple Web pages can be needed to solve a Web user's request. On the other hand, the latter issue results in difficulties for processing the returned data. Thinking of the Web as a huge set of databases, a more efficient approach for accessing data than the current search engine is needed. In this paper, a mechanism and implementation based on the author's previous work, H2X and VWBE, to address these issues is proposed. The result is a better framework for realizing the concept of Web of data.","2156-2318;21562318","Electronic:978-1-4577-2119-9; POD:978-1-4577-2118-2","10.1109/ICIEA.2012.6360790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360790","mashup;web page clustering;web2.0","Grammar;HTML;Navigation;Search engines;Software agents;Web pages;XML","Internet;Web sites;hypermedia markup languages;information retrieval;search engines","H2X;HTML;VWBE;Web of data;Web pages;Web searcher;information relatedness;information searching;presentation-oriented language;search engine technology","","0","","18","","","18-20 July 2012","","IEEE","IEEE Conference Publications"
"CRM as integration environment of the process organization","P. Skopiński; P. Zaskórski","Military University of Technology in Warsaw, Faculty of Cybernetics ul. Gen. Sylwestra Kaliskiego 2, 00-908 Warszawa 49","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","1029","1033","In the paper attempts to identify the systemic aspects of the use of CRM tools for the integration of distributed processes organization. The overriding criterion for the applicability of CRM is to increase the efficiency of management the virtual organization. Presents the requirements and restrictions for the virtualization of access to technical resources, technology and information in the so-called. ""Cloud"" as a way to reduce costly IT investments especially in the SME-class organizations.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354413","","Companies;Customer relationship management;Databases;Marketing and sales;Standards organizations","cloud computing;cost reduction;customer relationship management;information retrieval;investment;organisational aspects;resource allocation;virtual enterprises;virtualisation","CRM applicability;CRM tools;IT investments;SME-class organizations;cost reduction;customer relationship management system;distributed process organization integration environment;information access;management efficiency;technical resource access virtualization;virtual organization","","0","","6","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Web service matchmaking for the development of context-aware applications","G. M. Kapitsaki","Department of Computer Science, University of Cyprus, 1 University Avenue, 2109 Aglantzia, Cyprus","IET Software","20121115","2012","6","6","536","548","Context-awareness is related to the application capability to respond proactively to environment conditions. The reuse of existing components is an important challenge in the development of context-aware applications. Web services (WSs), usually exploited in this field acting either as business services by providing specific functionality or as context sources by exposing the retrieval of context information, need to be discovered and matched. In this study, the matchmaking of WSs for the identification of potential context sources is proposed. Descriptions are matched based on context adaptation cases, whereas the process is based on adequate WS descriptions that derive from the proposed semantic WS profile. The procedure is illustrated through a proof of concept based on service descriptions retrieved from online service registries.","1751-8806;17518806","","10.1049/iet-sen.2012.0016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6353338","","","Web services;information retrieval;ubiquitous computing","Web service matchmaking;context information retrieval;context-aware application;online service registry;potential context source identification;semantic WS profile;service description","","1","","","","","Dec. 2012","","IET","IET Journals & Magazines"
"Identifying context of text documents using Naïve Bayes classification and Apriori association rule mining","A. R. Kulkarni; V. Tokekar; P. Kulkarni","Cummins College of Engineering for Women, Karvenagar, Pune 411052. India","2012 CSI Sixth International Conference on Software Engineering (CONSEG)","20121110","2012","","","1","4","Huge amount of unstructured data is available in the form of text documents. Ranking these text documents by considering their context will be very useful in information retrieval. We propose classification of abstracts by considering their context using Naïve Bayes classifier and Apriori association rule algorithm - i.e. Context Based Naive Bayesian and Apriori (CBNBA). In proposed approach, we initially classify the documents using Naïve Bayes. We find the context of an abstract by looking for associated terms which help us understand the focus of the abstract and interpret the information beyond simple keywords. The results indicate that context based classification increases accuracy of classification to great extent and in turn discovers different contexts of the documents. Further this approach can found to be very useful for applications beyond abstract classification where word speaks very little and lead to ambiguous state but context can lead you to right decision/classification.","","Electronic:978-1-4673-2177-8; POD:978-1-4673-2174-7","10.1109/CONSEG.2012.6349477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6349477","","Abstracts;Association rules;Classification algorithms;Computer networks;Context;Operating systems;Training","Bayes methods;abstracting;data mining;information retrieval;pattern classification;text analysis","Apriori association rule mining;CBNBA;Naïve Bayes classification;abstract classification;context based Naive Bayesian and Apriori;context based classification;context identification;information retrieval;text document ranking;unstructured data","","2","","14","","","5-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Problems of automatic processing and analysis of information from Polish legal texts","W. Cyrul; T. Pełech-Pilichowski; P. Potiopa","Jagiellonian University, ul. Go&#x0142;&#x0119;bia 24, 31-007 Krak&#x00F3;w, Poland","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","939","943","In the paper, problems of legal information digitalization are investigated. Conditions for extraction information from legal texts related to the common ones processing (non-legal terms) are outlined. Sample results of similarity analysis are presented. Further research aimed at semantic analysis of legal texts are outlined.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354473","","Data mining;Law;Semantics;Standards;Vectors;XML","information analysis;information retrieval;natural language processing;text analysis","Polish legal texts;automatic information analysis;automatic information processing;information extraction;legal information digitalization problems;nonlegal terms;semantic analysis;similarity analysis","","0","","16","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Text Mining for Personal Health Information on Twitter","M. Sokolova; Y. Jafer; D. Schramm","Fac. of Med., Univ. of Ottawa, Ottawa, ON, Canada","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","112","112","With millions people discussing their Personal Health Information (PHI) online, there is a need for the development of tools that can extract and analyze such information. We introduce two semantic-based methods for mining PHI. One method uses WordNet as a source of health-related knowledge, another - terms of personal relations. Incorporating semantics gives a significant improvement in retrieval of text with PHI (paired t-test, P = 0.0001).","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366206","Personal Health Information;Text Mining","Educational institutions;Medical services;Ontologies;Power capacitors;Semantics;Text mining;Twitter","data mining;information retrieval;medical information systems;personal information systems;social networking (online);text analysis","Twitter;WordNet;health-related knowledge source;information analysis;information extraction;online PHI text mining;paired t-test;personal health information;personal relations;semantic-based methods;text retrieval improvement","","2","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Automatic Extraction Method of Tibetan New Valid Words","Y. Sun; X. Yan; X. Zhao; G. Yang","Minority Languages Branch, Nat. Language Resource & Monitoring Res. Center, Beijing, China","2012 Fifth International Conference on Intelligent Networks and Intelligent Systems","20121210","2012","","","228","231","This paper proposes a model to automatically extract Tibetan new valid words. Through building the dynamic Tibetan corpus from 2009 to 2012, which covers more than 18 Tibetan network media of Tibet, Qinghai, Sichuan, Gansu and Yunnan, we research on the key techniques of Tibetan new valid word extraction: (1) using statistical method to establish Tibetan new word knowledge base, (2) using information entropy to filter Tibetan new valid words, (3) using vector space module similarity calculation to extract Tibetan new valid word.","","Electronic:978-0-7695-4855-5; POD:978-1-4673-3083-1","10.1109/ICINIS.2012.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376528","Tibetan new valid word;dynamic Tibetan corpus;extraction","Compounds;Data mining;Dictionaries;Educational institutions;Information processing;Statistical analysis","information filters;information retrieval;natural language processing;statistical analysis","Tibetan new valid words;automatic extraction method;dynamic Tibetan corpus;information entropy;information filter;statistical method;vector space module similarity calculation","","0","","13","","","1-3 Nov. 2012","","IEEE","IEEE Conference Publications"
"Linking Medications and Their Attributes in Clinical Notes and Clinical Trial Announcements for Information Extraction: A Sequence Labeling Approach","Q. Li; H. Zhai; L. Deleger; T. Lingren; M. Kaiser; L. Stoutenborough; I. Solti","Med. Center, Div. of Biomed. Inf., Cincinnati Children's Hosp., Cincinnati, OH, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","84","84","The goal of this work is to evaluate binary classification and sequence labeling methods for medication-attribute linkage detection in two clinical corpora. The results show that with parsimonious feature sets both the Support Vector Machine (SVM)-based binary classification and Conditional Random Field (CRF)-based multi-layered sequence labeling methods are achieving high performance.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366192","","Biological system modeling;Biomedical imaging;Couplings;Joining processes;Labeling;Medical services;Support vector machines","information retrieval;medical administrative data processing;medicine;pattern classification;statistical analysis;support vector machines","CRF-based multilayered sequence labeling;SVM-based binary classification;clinical notes;clinical trial announcements;conditional random field-based multilayered sequence labeling;information extraction;medication-attribute linkage detection;parsimonious feature sets;support vector machine-based binary classification","","0","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Disease-Disease Relationships for Rheumatic Diseases: Web-Based Biomedical Textmining an Knowledge Discovery to Assist Medical Decision Making","A. Holzinger; K. M. Simonic; P. Yildirim","Inst. for Med. Inf., Stat. &amp; Documentation, Med. Univ. Graz, Graz, Austria","2012 IEEE 36th Annual Computer Software and Applications Conference","20121110","2012","","","573","580","The MEDLINE database (Medical Literature Analysis and Retrieval System Online) contains an enormously increasing volume of biomedical articles. There is urgent need for techniques which enable the discovery, the extraction, the integration and the use of hidden knowledge in those articles. Text mining aims at developing technologies to help cope with the interpretation of these large volumes of publications. Co-occurrence analysis is a technique applied in text mining and the methodologies and statistical models are used to evaluate the significance of the relationship between entities such as disease names, drug names, and keywords in titles, abstracts or even entire publications. In this paper we present a method and an evaluation on knowledge discovery of disease-disease relationships for rheumatic diseases. This has huge medical relevance, since rheumatic diseases affect hundreds of millions of people worldwide and lead to substantial loss of functioning and mobility. In this study, we interviewed medical experts and searched the ACR (American College of Rheumatology) web site in order to select the most observed rheumatic diseases to explore disease-disease relationships. We used a web based text-mining tool to find disease names and their co-occurrence frequencies in MEDLINE articles for each disease. After finding disease names and frequencies, we normalized the names by interviewing medical experts and by utilizing biomedical resources. Frequencies are normally a good indicator of the relevance of a concept but they tend to overestimate the importance of common concepts. We also used Pointwise Mutual Information (PMI) measure to discover the strength of a relationship. PMI provides an indication of how more often the query and concept co-occur than expected by change. After finding PMI values for each disease, we ranked these values and frequencies together. The results reveal hidden knowledge in articles regarding rheumatic diseases indexed by MEDLINE, the- eby exposing relationships that can provide important additional information for medical experts and researchers for medical decision-making.","0730-3157;07303157","Electronic:978-1-5090-5637-8; POD:978-1-4673-1990-4; USB:978-0-7695-4736-7","10.1109/COMPSAC.2012.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6340213","Biomedical text mining;Pointwise Mutual Information (PMI);co-occurrence analysis;diseasedisease relationships;rheumatic diseases","Arthritis;Databases;Joints;Medical diagnostic imaging;Osteoarthritis;Text mining","Web sites;data mining;decision making;diseases;information retrieval systems;medical information systems;statistical analysis;text analysis","ACR Web site;American college of rheumatology;MEDLINE database;PMI;Web based text-mining tool;Web-based biomedical text mining;biomedical articles;biomedical resources;cooccurrence analysis;disease-disease relationships;knowledge discovery;medical decision making;medical experts;medical literature analysis and retrieval system online;pointwise mutual information measure;publications;rheumatic diseases;statistical models","","4","","12","","","16-20 July 2012","","IEEE","IEEE Conference Publications"
"The intelligent agents in the study of web-based medical information search system","Chun-Jung Lin; Yi-Ling Jhao; Shou-Hsiung Cheng; Wen-Ni Yeh","Department of Computer Science and Information Management, Hungkuang University, Taichung City, Taiwan","2012 International Conference on Machine Learning and Cybernetics","20121124","2012","5","","1801","1806","For general patients, the physician information on clinics or large hospitals is very scarce. Because the physician in different medical fields, areas of expertise are different, and most patients are also have no similar or related symptoms produced by the experience of seeing patients. They usually spend a lot of time in the physician information search and compare. In this study, we combined the search engine, Intelligent Agent (IA) and Business Intelligence (BI) technologies to build a web-based medical information search and analysis system. The intelligent agent can at any time to the site of the medical institutions to retrieve data. BI systems can be real-time analysis and presents visual charts and trends of medical information and can quickly to provide the most immediate, reliable and complete medical information to assist users to obtain relevant medical information.","2160-133X;2160133X","Electronic:978-1-4673-1487-9; POD:978-1-4673-1484-8","10.1109/ICMLC.2012.6359649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359649","Business Intelligence;Intelligent Agent;Medical Information fusion;Search Engine;Web-based","Abstracts;Artificial intelligence;Databases;Engines;Hospitals;Reliability","Internet;competitive intelligence;data visualisation;information retrieval;medical information systems","BI;IA;Web-based medical information search system;business intelligence;clinics;data retrieval;general patients;hospitals;intelligent agents;physician information search;visual charts","","0","","13","","","15-17 July 2012","","IEEE","IEEE Conference Publications"
"Does Domain Knowledge Matter for Assertion Annotation in Clinical Texts?","D. L. Mowery; P. W. Jordan; J. M. Wiebe; W. W. Chapman; L. Liu","Biomed. Inf., Learning Resource &amp; Dev. Center, Univ. of Pittsburgh, Pittsburgh, PA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","136","136","This pilot study aims to determine how well subjects annotate assertions about problem mentions in clinical text and determine if a statistical difference exists between subjects with and without clinical domain knowledge.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366228","","Biomedical informatics;Educational institutions;Medical diagnostic imaging;Medical services;Natural language processing;Standards","information retrieval;medical computing;natural language processing;statistical analysis;text analysis","assertion annotation;clinical domain knowledge;clinical texts;natural language processing;statistical difference","","0","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Extracting relevant learning objects using a semantic annotation method","B. Smine; R. Faiz; J. P. Desclés","LaLIC, Paris Sorbonne University, 28 Rue Serpente Paris 75006, France","International Conference on Education and e-Learning Innovations","20121124","2012","","","1","6","Information research refers, in our context, to information retrieval to obtain further learning information from documents. However, automatic tools for learning information retrieval from these documents based on semantic tags are not yet effective. We propose here a model which aims at automatically annotating texts with semantic metadata. These metadata will allow us to index and extract learning objects from texts. This model is composed of two parts: the first part consists of a semantic annotation of learning objects according to their semantic categories (definition, example, exercise, etc.). The second part uses automatic semantic annotation which is generated by the first part to create a semantic inverted index able to find relevant learning objects for queries associated with semantic categories. We have implemented a system called SRIDOP, on the basis of the proposed model and we have verified its effectiveness.","","CD:978-1-4673-2224-9; Electronic:978-1-4673-2225-6; Paper:978-1-4673-2226-3","10.1109/ICEELI.2012.6360568","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360568","Contextual Exploration;learning objects;semantic annotation","Context;Indexing;Pragmatics;Search problems;Semantics","computer aided instruction;document handling;information retrieval;meta data","SRIDOP;documents;e-learning concept;information research;information retrieval learning;relevant learning object extraction;semantic annotation method;semantic inverted index;semantic metadata","","1","","16","","","1-3 July 2012","","IEEE","IEEE Conference Publications"
"Considerations of Effectiveness of Media Switching and QoS Functions","K. Sugita; M. Yokota","Dept. of Inf. & Commun. Eng., Fukuoka Inst. of Technol., Fukuoka, Japan","2012 Seventh International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20121129","2012","","","241","244","In our previous work, we already proposed a new concept of 'universal multimedia access' to narrow the digital divide by providing appropriate multimedia expressions according to users' (mental and physical) abilities, computer facilities, and network environments. In our approach, multimedia contents are played to support some switching functions such as user interface switching, media switching and QoS switching. In our previous work, we have evaluated some types of user interfaces for different age groups and terminal devices. In this paper, we consider the effectiveness of media switching and QoS Control functions.","","Electronic:978-0-7695-4841-8; POD:978-1-4673-2991-0","10.1109/3PGCIC.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6362975","Multimedia;QoS Control;digital divide;media switching;user interface","Computers;Media;Multimedia communication;Quality of service;Switches;User interfaces","Digital Divide;information retrieval;multimedia computing;quality of service;user interfaces","QoS function;digital divide;media switching;multimedia content;multimedia expression;network environment;terminal device;universal multimedia access;user interface","","5","","8","","","12-14 Nov. 2012","","IEEE","IEEE Conference Publications"
"History education through creative computing: Multi-dimensional views and interactive navigation of the historical development of a town","R. Millham; D. Moore; J. W. Millham","University of Bahamas/Durban, University of Technology","International Conference on Education and e-Learning Innovations","20121124","2012","","","1","6","This paper introduces an emerging (research-in-progress) creative computing prototype, refined iteratively through user feedback, to retrieve and display information regarding a historical timeline composition of a town, in particular a Canadian prairie town. The purpose of this prototype is to use the advantages of creative computing, by means of multi-dimensional visual and aural content within an n-tier system of historical period layers, to provide an interactive, multiple style (visual, textual, and aural) approach to education, notably the teaching of the developmental history of a small town with the significant historical factors affecting it. As part of the iterative development approach of the prototype and to ensure that the historical context was conveyed adequately to the user, a series of usability studies were conducted using a small but representative group of users. The feedback from these usability studies helped direct and validate the refinement of the prototype to enable it to convey its historical composition's content to the user/learner more effectively.","","CD:978-1-4673-2224-9; Electronic:978-1-4673-2225-6; Paper:978-1-4673-2226-3","10.1109/ICEELI.2012.6360638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360638","","Buildings;Cities and towns;Computers;Educational institutions;Prototypes;Usability;Visualization","computer aided instruction;history;information retrieval;interactive systems;teaching","Canadian prairie town;creative computing;historical composition content;historical period layers;history education;information display;information retrieval;interactive navigation;multidimensional aural content;multidimensional views;multidimensional visual content;n-tier system;town developmental history teaching;town historical development;town historical timeline composition;usability studies;user feedback","","0","","11","","","1-3 July 2012","","IEEE","IEEE Conference Publications"
"Detecting offensive user video blogs: An adaptive keyword spotting approach","M. S. Barakat; C. H. Ritz; D. A. Stirling","ICT Research Institute / School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, Australia","2012 International Conference on Audio, Language and Image Processing","20121210","2012","","","419","425","This paper proposes a speaker independent keyword spotting (KWS) approach applied to the audio track of user video blogs that can help in their automatic analysis, indexing, search and retrieval. The approach, which relies on matching of keyword templates to speech segments using an adaptive similarity threshold that is estimated automatically for each utterance, does not require training data or language model as required in existing approaches such as those based on the Hidden Markov Model (HMM). This is a particular advantage for user video blogs since they usually contain words of interest that have not been adequately represented in a training database. Experiments conducted to detect offensive words in video blogs achieved much higher accuracy than existing speech-to-text based approaches.","","Electronic:978-1-4673-0174-9; POD:978-1-4673-0173-2","10.1109/ICALIP.2012.6376654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376654","","Blogs;Databases;Hidden Markov models;Histograms;Speech;Speech recognition;Vectors","audio signal processing;indexing;information retrieval;social networking (online);speaker recognition;speech synthesis","KWS approach;adaptive keyword spotting approach;adaptive similarity threshold;audio track;automatic analysis;indexing;keyword template matching;offensive user video blog detection;retrieval;search;speaker independent keyword spotting approach;speech segments;speech-to-text based approach","","2","","28","","","16-18 July 2012","","IEEE","IEEE Conference Publications"
"Doubly Penalized LASSO for Reconstruction of Biological Networks","B. Asadi; D. M. Tartakovsky; M. R. Maurya; S. Subramaniam","Dept. of Mech. &amp; Aerosp. Eng., Univ. of California, San Diego, La Jolla, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","129","129","Reconstruction of biological and biochemical networks is a crucial step in extracting information from a large volume of biological data. There are several methods developed recently to reconstruct biological networks using dynamic data, each with specific benefits and some drawbacks. Here, we have developed a new method called Doubly Penalized Linear Absolute Shrinkage and Selection Operator (DPLASSO) for reconstruction of dynamic biological networks. In this approach, we have integrated two distinct methods viz., statistical significance testing of model coefficients and penalized/constrained optimization. Principal component analysis with statistical significance testing acts as a supervisory-level filter to extract the most informative components of the network from a dataset (Layer 1). In the lower level (Layer 2), LASSO with extra weights on the smaller parameters obtained in the first layer is employed to retain the main predictors and to set the small coefficients to zero. Two case studies are used to compare the relative performance of DPLASSO and LASSO in terms of several metrics, such as sensitivity, specificity, accuracy and fractional-error in the estimates of the coefficients. In the first case study, with a synthetic data set, our simulation results show substantial improvements over LASSO for the reconstruction of the network in terms of accuracy and specificity. The second case study relies on experimental datasets for cell division cycle of fission yeast. This case study illustrates that DPLASSO performs better than LASSO in terms of sensitivity, specificity and accuracy in reconstructing networks.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366221","","Accuracy;Educational institutions;Image reconstruction;Iron;Sensitivity;Systems biology","information retrieval;medical computing;optimisation;principal component analysis;statistical testing","accuracy metrics;biochemical network reconstruction;constrained optimization;doubly-penalized LASSO;doubly-penalized linear absolute shrinkage-and-selection operator;dynamic biological network reconstruction;dynamic data;fission yeast cell division cycle;fractional-error metrics;information extraction;model coefficients;penalized optimization;principal component analysis;sensitivity metrics;specificity metrics;statistical significance testing;supervisory-level filter;synthetic data set","","0","","4","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"A multimedia based hybrid system for healthcare application","W. D. Yu; A. Panwar; V. Dahuja; Y. Goyal","Computer Engineering Department, San Jose State University, (Silicon Valley), California, USA 95192-0180","2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom)","20121213","2012","","","321","324","The objective in the paper is to design a multimedia hybrid system which provides communication methods and file types for performing better communication among hospitals, physicians and patients. All the data is stored on a server and accessible only by authorized users. The data includes text, voice, video, and image data. The system is not only accessible through desktops and laptops but also mobile devices such as smartphones and tablets.","","Electronic:978-1-4577-2040-6; POD:978-1-4577-2039-0; USB:978-1-4577-2038-3","10.1109/HealthCom.2012.6379429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379429","Android OS;Multimedia;Smartphone;healthcare;mobile device;tablet","Ash;Benchmark testing;Biomedical imaging;Medical services;Schedules;Servers;Silicon","authorisation;health care;information retrieval;mobile computing;multimedia systems;smart phones","authorized users;communication methods;data access;file types;healthcare application;hospitals;image data;mobile devices;multimedia-based hybrid system design;patients;physicians;smart phone;tablet;text data;video data;voice data","","0","","13","","","10-13 Oct. 2012","","IEEE","IEEE Conference Publications"
"Improving Content-Centric networks performance with progressive, diversity-load driven caching","J. M. Wang; B. Bensaou","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology","2012 1st IEEE International Conference on Communications in China (ICCC)","20121124","2012","","","85","90","Today, the main usage of the Internet has become increasingly about content generation, sharing, retrieval and massive distribution. Widely used P2P applications, UserGenerated Content (UGC) (e.g., Youtube, Flickr) and increasingly popular Social Networks make the Internet service model become more content-oriented than host-oriented as it has been this far. To match the Internet infrastructure to this service model, a new Internet architecture has been proposed under the generic name of Content-Centric networking (CCN, see also Named-data Networking or NDN). One of the main features of this architecture is its ability to cache packets in intermediate routers to take advantage of spatio-temporal locality in serving multiple requests for the same content, reducing thus considerably the transit traffic. In this paper, we propose a new in-network caching scheme for CCN and evaluate its performance by comparing it to that of the default proposed policy via simulation.","2377-8644;23778644","Electronic:978-1-4673-2815-9; POD:978-1-4673-2814-2; USB:978-1-4673-2813-5","10.1109/ICCChina.2012.6356996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6356996","","Correlation;Internet;Measurement;Peer to peer computing;Proposals;Routing;Servers","Internet;computer network performance evaluation;information retrieval;peer-to-peer computing;service-oriented architecture;social networking (online)","Internet service model;P2P applications;UGC;cache packets;content generation;content retrieval;content sharing;content-centric networks performance;diversity-load driven caching;in-network caching scheme;intermediate routers;massive distribution;service model;social networks;spatio-temporal locality;user-generated content","","1","","11","","","15-17 Aug. 2012","","IEEE","IEEE Conference Publications"
"Privacy Protection in Sharing Personal Genome Sequencing Data","X. Wang; H. Tang","Sch. of Inf. & Comput., Indiana Univ., Bloomington, IN, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","143","143","The past few years has witnessed rapid development in human genome research, in particular the genome-wide association studies (GWAS) and personalized medicine, which has been made possible by the advance in the Next Generation Sequencing (NGS) technologies that produces a large amount of sequencing data at an exceedingly low cost. New technologies for large-scale meta-analysis on genomic data continue to be developed, enabling the application of human genome research to clinical diagnosis and therapy, a trend dubbed “base pairs to bedside”. However, further progress in this area has been increasingly impeded by the constraints in accessing sequencing data, due in part to privacy concerns involved in data sharing. The current approach to protecting human genomic data is mainly based upon data-use agreements, which involves a time-consuming application/review/agreement process. To enable more convenient data access, this paper proposes a data analysis model that allows biomedical researchers and healthcare practitioners to use the sensitive genomic data that cannot be directly released in an efficient fashion, through the computing service over the data (instead of direct access to the data) provided by a large data center.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366235","","Bioinformatics;Data privacy;Educational institutions;Genomics;Informatics;Noise;Privacy","data analysis;data privacy;genomics;health care;information retrieval;medicine;personal computing","GWAS;NGS technologies;biomedical researchers;data access;data analysis model;data-use agreements;genome-wide association studies;genomic data;healthcare practitioners;human genome research;large data center;large-scale meta-analysis;next generation sequencing technologies;personal genome sequencing data sharing;personalized medicine;privacy protection","","0","","3","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Attribute reduction method using Water-Filling principle for Case-based reasoning","H. Zhao; A. j. Yan; C. x. Zhang; P. Wang","Coll. of Electron. Inf. &amp; Control Eng., Beijing Univ. of Technol., Beijing, China","Proceedings of the 10th World Congress on Intelligent Control and Automation","20121124","2012","","","779","782","As the large number of feature attributes in Case-based reasoning system (CBR) brings a huge information redundancy which reduces the retrieval efficiency, a novel reduction method based on Water-Filling is proposed to remove those unnecessary attributes. In the method, the importance of each attribute could be calculated by utilizing the ratio of the standard deviation and the mean value of each attribute data as evaluation parameter, and the impotance result of each attribute is then used to guide the reduction process. The experiments on glass identification showed that the new method could get a better retrieval accuracy as well as a greater efficiency compared with the methods which do not conduct the reduction process.","","Electronic:978-1-4673-1398-8; POD:978-1-4673-1397-1","10.1109/WCICA.2012.6357983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357983","Water-Filling;attribute reduction;case retrieve","Accuracy;Cognition;Educational institutions;Glass;History;Standards;Wireless communication","case-based reasoning;information retrieval","CBR;attribute reduction;case-based reasoning;feature attribute;glass identification;information redundancy;retrieval efficiency;water-filling principle","","0","","10","","","6-8 July 2012","","IEEE","IEEE Conference Publications"
"Using .tel domains to support knowledge management","A. Kotwica","Uniwersytet Ekonomiczny we, Wroc&#x0142;awiu Katedra System&#x00F3;w, Sztucznej Inteligencji","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","1155","1158","The .tel domain seem to be a very good tool for construction of expert database serving both stationary and mobile devices. Additionally, TelFriends system facilitates to protect data and to provide access to data exclusively to persons authorised to it. One of the obvious advantages of .tel domains is a possibility of simple construction of structures reflecting the enterprise's or organisation's hierarchy.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354463","","Databases;Electronic mail;Internet;Knowledge management;Mobile communication;Mobile handsets;Servers","database management systems;information retrieval;knowledge management;mobile computing;organisational aspects;security of data",".tel domains;TelFriends system;authorisation;data access;data protection;expert database construction;knowledge management;mobile devices;organisation hierarchy;stationary devices","","0","","4","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Analogical Reasoning for Answer Ranking in Social Question Answering","X. Tu; D. Feng; X. J. Wang; L. Zhang","Huazhong University of Science &#x0026; Technology","IEEE Intelligent Systems","20121115","2012","27","5","28","35","Answer ranking is important to social question-answering services. An analogical reasoning approach measures the similarity between new question-answer pairs and existing positive examples.","1541-1672;15411672","","10.1109/MIS.2010.130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601675","analogical reasoning;ranking;social question answering","Cognition;Intelligent systems;Maximum likelihood estimation;Measurement;Predictive models;Question-answering services;Training data","information retrieval;natural language processing","analogical reasoning;answer ranking;social question answering","","2","","10","","20101014","Sept.-Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Semantic Categorization of Web Services Based on Feature Space Transformation","E. Mavridou; G. Hassapis; D. D. Kehagias; D. Tzovaras","Dept. of Electr. & Comput. Eng., Aristotle Univ. of Thessaloniki, Thessaloniki, Greece","2012 16th Panhellenic Conference on Informatics","20121213","2012","","","162","167","Automatic semantic web service annotation mechanisms are required for enabling more efficient and accurate search and discovery of services on the web. In this context new mechanisms are necessary for improving the overall accuracy of the semantic characterization process, preserving the overall performance at an acceptable level. Existing semantic categorization mechanisms take into account all tokens that are included in web service description documents thus resulting in poor performing categorization tasks. This paper demonstrates how a significant improvement in performance can be achieved by applying the Bayes' theorem for transforming the feature space in order to decrease its dimension, without sacrificing prediction accuracy. Experimental evaluation of our approach with respect to other feature selection techniques shows that the former achieves better prediction accuracy, as well as performance when the categorization of a web service in an application domain is concerned.","","Electronic:978-0-7695-4825-8; POD:978-1-4673-2720-6","10.1109/PCi.2012.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377385","Knowledge retrieval;Web Services;machine learning","Accuracy;Feature extraction;Ontologies;Principal component analysis;Semantics;Training;Web services","Bayes methods;Web services;document handling;information retrieval;learning (artificial intelligence);semantic Web","Bayes theorem;Web service description documents;Web service discovery;Web service search;Web service semantic categorization;application domain;automatic semantic Web service annotation mechanisms;feature space transformation;prediction accuracy","","0","","16","","","5-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"Enhanced data extraction, transforming and loading processing for Traditional Chinese Medicine clinical data warehouse","Xishui Pan; X. Zhou; Hongmei Song; Runshun Zhang; Tingting Zhang","School of Computer Science and Information Technology, Beijing Jiaotong University, China","2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom)","20121213","2012","","","57","61","Clinical data warehouse has been developed as a fundamental data infrastructure for large scale TCM clinical data management and decision support services. However, as a key component, data extraction, transforming and loading (ETL) is a complicated and labor intensive task to ensure high data quality before all kinds of data analyses. This paper introduces an enhanced ETL technique framework, which includes operational data store (ODS) model and two step data preprocessing subcomponents, to perform the ETL tasks. The ODS data model was designed to integrate the heterogeneous clinical data sources and support the direct copy from these data sources to ODS database by ETL. Therefore, ETL task has been separated into two core steps in enhanced ETL component: (1) dynamic filter and copy of the original operational data sources to ODS; (2) specialized transforming the ODS data to detailed clinical data warehouse. This enhanced technique framework improves the ETL performance to be used in clinical data center since there would have various kinds of operational data sources that need be integrated in this data environments. This paper has a description of the related enhanced ETL framework and proposes some key procedures to accomplish the tasks.","","Electronic:978-1-4577-2040-6; POD:978-1-4577-2039-0; USB:978-1-4577-2038-3","10.1109/HealthCom.2012.6380066","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6380066","clinical data warehouse;detailed data warehouse;extraction-transforming-loading;operational data store","Data analysis;Data mining;Data models;Data warehouses;Databases;Hospitals;Medical diagnostic imaging","data handling;data warehouses;decision support systems;information retrieval;medical information systems","ETL tasks;ETL technique framework;ODS data model;TCM clinical data management;TCM clinical data warehouse;TCM decision support services;data copying;data extraction;data infrastructure;data loading processing;data transformation;dynamic data filtering;heterogeneous clinical data sources;operational data sources;operational data store model;traditional Chinese medicine;two step data preprocessing subcomponents","","0","","8","","","10-13 Oct. 2012","","IEEE","IEEE Conference Publications"
"Enhancing candidate link generation for requirements tracing: The cluster hypothesis revisited","N. Niu; A. Mahmoud","Department of Computer Science and Engineering, Mississippi State University, USA","2012 20th IEEE International Requirements Engineering Conference (RE)","20121110","2012","","","81","90","Modern requirements tracing tools employ information retrieval methods to automatically generate candidate links. Due to the inherent trade-off between recall and precision, such methods cannot achieve a high coverage without also retrieving a great number of false positives, causing a significant drop in result accuracy. In this paper, we propose an approach to improving the quality of candidate link generation for the requirements tracing process. We base our research on the cluster hypothesis which suggests that correct and incorrect links can be grouped in high-quality and low-quality clusters respectively. Result accuracy can thus be enhanced by identifying and filtering out low-quality clusters. We describe our approach by investigating three open-source datasets, and further evaluate our work through an industrial study. The results show that our approach outperforms a baseline pruning strategy and that improvements are still possible.","1090-705X;1090705X","Electronic:978-1-4673-2785-5; POD:978-1-4673-2783-1","10.1109/RE.2012.6345842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6345842","clustering;requirements tracing;traceability","Algorithm design and analysis;Clustering algorithms;Context;Gold;Humans;Software;Software algorithms","formal verification;information retrieval;program diagnostics;public domain software","baseline pruning strategy;candidate link generation;cluster hypothesis;correct links;false positives;incorrect links;information retrieval methods;low-quality clusters;open-source datasets;requirements tracing process;requirements tracing tools","","15","","32","","","24-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"EDR<sup>2</sup>: A sink failure resilient approach for WSNs","M. Valero; M. Xu; N. Mancuso; W. Z. Song; R. Beyah","Department of Computer Science, Georgia State University, Atlanta, Georgia 30303, USA","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","616","621","Data collection, redistribution and retrieval are essential components of wireless sensor networks (WSNs). In dense WSN deployments, the sensor data are usually sent to a sink that can be reached through one or multiple hops. In the case where communications with the sink are disrupted due to various reasons, the data must be stored in the network for later retrieval. When considering in-network storage, we must redistribute the data among an energy-constrained network with sensors that have a low storage capacity. In previous works, the data redistribution problem has been studied, but the focus was only on the redistribution costs while the data retrieval costs (which have been analyzed in other works as an independent problem) were ignored. We recognize that these two problems should be studied in concert and therefore, in this paper, we combine both data redistribution and retrieval into a single problem. We propose a graph transformation, formulate the problem as a minimum cost flow optimization problem and use linear programming to find the optimal solution. Moreover, we introduce an algorithm named EDR<sup>2</sup>: energy-efficient data redistribution and retrieval. EDR<sup>2</sup> is a distributed energy-efficient algorithm for in-network storage and later retrieval in WSNs. To evaluate our solution on a large scale, we modeled different scenarios in a 400-node network, used the GNU Linear Programming Kit (GLPK) to obtain the optimal solutions, and ran simulations to find the solutions using our algorithm. Finally, we implemented EDR<sup>2</sup> using real sensors to demonstrate the feasibility of our algorithm. We compared EDR<sup>2</sup> with two heuristic algorithm and show that our approach is an energy-efficient solution for node selection when redistributing data in a WSN for eventual retrieval.","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6363781","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363781","","Algorithm design and analysis;Approximation algorithms;Distributed databases;Heuristic algorithms;Linear programming;Memory;Wireless sensor networks","graph grammars;information retrieval;linear programming;telecommunication network reliability;wireless sensor networks","400-node network;EDR<sup>2</sup>;GLPK;GNU linear programming kit;WSN deployments;data collection;distributed energy-efficient algorithm;energy-constrained network;energy-efficient data redistribution;energy-efficient data retrieval;graph transformation;heuristic algorithm;in-network storage;low storage capacity;minimum cost flow optimization problem;multiple hops;optimal solution;sensor data;sink failure resilient approach;wireless sensor networks","","2","","8","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"An energy-efficient content-centric approach in mesh networking","M. Amadeo; A. Molinaro; G. Ruggeri","University &#x201C;Mediterranea&#x201D; of Reggio Calabria - DIMET Department","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","5736","5740","Content-centric is an emerging networking paradigm conceived for the future Internet. Data retrieval and distribution are based on content names instead of host addresses. In this paper we propose a content-centric architecture for energy-efficient multihop communications in a wireless mesh network and compare its performances against a legacy IP-based approach.","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6364828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6364828","Content Centric Networking;Energy Efficiency;Mesh Networks","Ad hoc networks;IEEE 802.11 Standards;IP networks;Internet;Media Access Protocol;Routing protocols;Wireless communication","IP networks;Internet;information retrieval;wireless mesh networks","Internet;content-centric architecture;data distribution;data retrieval;energy-efficient content-centric;energy-efficient multihop communications;legacy IP-based approach;mesh networking;networking paradigm;wireless mesh network","","3","","15","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Designing a semantic web ontologs of agricultural domain","S. Chowdhury; M. M. Kaysar; K. Deb","Department of Computer Science and Engineering, Chittagong University of Engineering & Technology, Chittagong Bangladesh","2012 7th International Forum on Strategic Technology (IFOST)","20121124","2012","","","1","4","Agricultural knowledge is so distributed, heterogeneous and polymorphic that current web architecture may unable to find the desired search results. So ontology of semantic web architecture is used for better search results. Semantic web makes the data of the web machine understandable and ontology is the core step of semantic web technology. Ontology captures the domain knowledge in a generic way and provides a commonly agreed understanding of a domain. It helps the search engine to find out the meaningful and scientifically correct information. In this paper, an ontology (Fruit Ontology) is proposed of agricultural sub-domain which is designed with OWL Description Logic (DL) language. Agricultural ontology is used by many organizations for better agricultural information service (AIS) or for adapting reliable information and communication system in agriculture. This paper also describes the each steps of designing the “Fruit” ontology briefly. For designing ontology AGROVOC is used as the base vocabulary. AGROVOC is developed by the Food and Agricultural Organization (FAO) of United Nations which is used all over the world for indexing, retrieving and organizing data in agriculture information system.","","Electronic:978-1-4673-1773-3; POD:978-1-4673-1772-6","10.1109/IFOST.2012.6357640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357640","AGROVOC;Domain knowledge;OWL DL;Ontology;Semantic web","Agriculture;Computer architecture;OWL;Ontologies;Organizations;Service oriented architecture","agriculture;information retrieval;information systems;knowledge acquisition;knowledge representation languages;ontologies (artificial intelligence);search engines;semantic Web;software architecture","AGROVOC design;AIS;FAO;Food and Agricultural Organization;Fruit ontology;OWL DL language;OWL description logic language;United Nations;Web machine;agricultural domain;agricultural information service;agricultural knowledge;agricultural ontology;communication system;data indexing;data organization;data retrieval;domain knowledge;information search;information system;search engine;search results;semantic Web architecture;semantic Web ontology design","","0","","11","","","18-21 Sept. 2012","","IEEE","IEEE Conference Publications"
"Application of Digital Content Management System Based on Data Warehouse and Data Mining Technology","Y. Luo; Y. Peng","Dept. of Mech. & Electr. Eng., Hubei Univ. of Educ. Wuhan, Wuhan, China","2012 Fourth International Conference on Computational Intelligence and Communication Networks","20121206","2012","","","988","992","At present, digital content has permeated every part of human social life, and has become a valuable resource. However, while the vast amounts of information continue to occur, human beings are persecuted by the loss of information, especially those carrying human culture and civilization. The prolonged preservation technology of digital content faces enormous challenges. Therefore, the managers should consider how to supervise, manage and utilize the digital content for a long time by the scientific and reasonable measures. OAIS provides a conceptual model for the long-term preservation of digital content, it satisfy the basic need of the long-term preservation of digital content from the aspect of system function. But in the practice of preservation, the explicit data model is necessary, moreover, the model should meet the management need of whole life cycle in the long-term preservation of digital content, meanwhile it's necessary to choose the coding formats of media files. In this paper, firstly, we study the digital content management data model and propose a 7-layer reference model of digital content management according to the hierarchical idea. And then using data mining techniques, we implicit in all the associated data layer data extraction, comparison, analysis, and selectively format digital information for maintenance and preservation according to the appropriate standards. Finally, we process the corresponding data resources through data warehouse and online analytical. At the same time, establish the function of the system of internal links and with the external interface, and a series of high-level services on top of these interfaces.","","Electronic:978-0-7695-4850-0; POD:978-1-4673-2981-1","10.1109/CICN.2012.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375263","OAIS;data mining technology;data warehouse;digital content management system","Content management;Data mining;Data models;Decision trees;Humans;Indexes;Standards","content management;data analysis;data mining;data models;data warehouses;information retrieval systems","7-layer reference model;OAIS;civilization;conceptual model;data analysis;data comparison;data extraction;data layer;data maintenance;data mining technique;data mining technology;data resource;data warehouse technology;digital content management system;digital content preservation technology;digital content supervision;digital content utilization;digital information;explicit data model;human culture;human social life;information resource;media file coding format;open archival information system;system function","","0","","15","","","3-5 Nov. 2012","","IEEE","IEEE Conference Publications"
"Evaluating Data Reliability: An Evidential Answer with Application to a Web-Enabled Data Warehouse","S. Destercke; P. Buche; B. Charnomordic","CIRAD, UMR IATE, Campus SupAgro, Montpellier","IEEE Transactions on Knowledge and Data Engineering","20121119","2013","25","1","92","105","There are many available methods to integrate information source reliability in an uncertainty representation, but there are only a few works focusing on the problem of evaluating this reliability. However, data reliability and confidence are essential components of a data warehousing system, as they influence subsequent retrieval and analysis. In this paper, we propose a generic method to assess data reliability from a set of criteria using the theory of belief functions. Customizable criteria and insightful decisions are provided. The chosen illustrative example comes from real-world data issued from the Sym'Previus predictive microbiology oriented data warehouse.","1041-4347;10414347","","10.1109/TKDE.2011.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989808","Belief functions;confidence;data quality;evidence;information fusion;maximal coherent subsets;relevance;trust","Belief systems;Data models;Fuzzy sets;Pragmatics;Quality of data;Reliability engineering;Reliability theory","data integrity;data warehouses;inference mechanisms;information retrieval","Sym'Previus predictive microbiology oriented data warehouse;belief functions;data analysis;data confidence;data retrieval;generic method;information source reliability integration;reliable data assess;web-enabled data warehouse","","10","","35","","20110818","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"TheMa: An API for Mining Linked Datasets","C. Tsoukalas; D. Dervos; J. Martinez-Gil; J. F. Aldana-Montes","Dept. of Inf. Technol., A.T.E.I of Thessaloniki, Thessaloniki, Greece","2012 16th Panhellenic Conference on Informatics","20121213","2012","","","449","453","Linked Open Data is a paradigm for linking the data available on the Web in a structured format in order to make it accessible for computers and people. This leads to having more people and services publish their data on the web and as a result the graph that contains all this information is getting bigger. This paper proposes the usage of some network analysis algorithms on a Linked Dataset in order to extract useful information which in turn leads to a better understanding/interpretation of the data involved, plus comprises a first step in the direction of mining hidden information from the dataset.","","Electronic:978-0-7695-4825-8; POD:978-1-4673-2720-6","10.1109/PCi.2012.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377345","Graph Mining;Linked Open Data;Network Theory","Algorithm design and analysis;Bridges;Computers;Data mining;Joining processes;Network theory (graphs);World Wide Web","application program interfaces;data mining;information retrieval;network theory (graphs)","API;Web service;data access;data publishing;graph theory;information extraction;linked dataset mining;network analysis algorithm;structured data format","","0","","10","","","5-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"Context-aware data discovery","D. Namiot; M. Sneps-Sneppe","Lomonosov Moscow State University, Faculty of Computational Math and Cybernetics, Russia","2012 16th International Conference on Intelligence in Next Generation Networks","20121210","2012","","","134","141","This paper discusses context-aware data browsing and data retrieval for mobile subscribers. We describe existing models as well as provide a new description for our SpotEx approach. Our model for context-aware data discovery uses mobile phones as proximity sensors. In our concept, any existing or even specially created wireless network node could be used as a presence sensor that can open (discover) access to some dynamic or user-generated content. The content itself could also be linked to social media. An appropriate mobile service (context-aware browser) can present that information to mobile subscribers. Potential use-cases for the proposed approach include any project associated with hyper-local news data. For example, projects providing Smart City data, delivering indoor retail information, etc.","","Electronic:978-1-4673-1526-5; POD:978-1-4673-1527-2; USB:978-1-4673-1525-8","10.1109/ICIN.2012.6376016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376016","Wi-Fi;browsing;collaborative location;context-ware computing;data mining;proximity","Browsers;Context;IEEE 802.11 Standards;Mobile communication;Mobile handsets;Sensors;Web pages","content management;information retrieval;mobile computing;mobile handsets;social networking (online)","SpotEx approach;context-aware data browsing;context-aware data discovery;data retrieval;dynamic content;hyper-local news data;indoor retail information;mobile phones;mobile service;mobile subscribers;proximity sensors;smart city data;social media;user-generated content;wireless network node","","2","","29","","","8-11 Oct. 2012","","IEEE","IEEE Conference Publications"
"An integrated security scheme for ID/locator split architecture of future network","V. P. Kafle; R. Li; D. Inoue; H. Harai","National Institute of Information and Communications Technology","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","5866","5871","For the sake of better scalability and flexibility in the mobile and multihoming environments, future networks are expected to be based on the concept of ID/locator split. The ID/locator split architectures require storing, updating and retrieving of ID/locator mappings frequently, for which they need built-in security. To address this issue, this paper presents an integrated security scheme for securely storing, updating and retrieving hostnames to IDs and locators mapping records in two layers of name registries: domain name registries and host name registries. It then utilizes the mapping records retrieved from the registries for securing the network access, communication sessions, and mobility management functions. The scheme provides comprehensive protection of the ID/locator split architecture through an effective combination of asymmetric and symmetric cryptographic functions.","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6364739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6364739","ID/locator split architecture;future network;new generation network;security","Authentication;Context;Mobile communication;Protocols;Public key;Servers","Internet;cryptography;information retrieval;mobile computing;mobility management (mobile radio)","ID-locator mappings;ID-locator split architecture;built-in security;communication sessions;domain name registries;host name registries;hostname retrieval;integrated security scheme;locator mapping recording;mapping record retrieval;mobile environments;mobility management functions;multihoming environments;network access security;secure storage;symmetric cryptographic functions","","5","","11","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Technology of VOD and Video Compression in Online Question Answering System of Campus Network","G. Jiao","Shanghai Gench Coll., Shanghai, China","2012 Second International Conference on Business Computing and Global Informatization","20121220","2012","","","747","749","With the rapid development of network bandwidth, video resource use is everywhere, especially in teaching. Video question answering system in campus network realizes the framework and main functions based on the flash platform technology and provides a good platform for the students' autonomous learning. This paper mainly discusses the realization of the video function, in the question answering system, including compression, uploading and downloading and HD VOD.","2378-8941;23788941","Electronic:978-0-7695-4854-8; POD:978-1-4673-4469-2","10.1109/BCGIN.2012.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6382642","flash platform technology;flv;mencoder;serv-U","Education;Resource management;Servers;Software;Streaming media;Video compression","computer aided instruction;data compression;educational institutions;question answering (information retrieval);video coding;video on demand","RD VOD downloading;RD VOD uploading;VOD technology;campus network;flash platform technology;network bandwidth;online question answering system;student autonomous learning;teaching;video compression;video function;video question answering system;video resource","","0","","9","","","12-14 Oct. 2012","","IEEE","IEEE Conference Publications"
"The urge to merge: When cellular service providers pool capacity","S. Hua; P. Liu; S. S. Panwar","Polytechnic Institute of New York University, Brooklyn, NY, 11201, USA","2012 IEEE International Conference on Communications (ICC)","20121129","2012","","","5020","5025","As cellular networks are turning into a platform for ubiquitous data access, cellular operators are facing a severe data capacity crisis due to the exponential growth of traffic generated by mobile users. In this work, we investigate the benefits of sharing infrastructure and spectrum among two cellular operators. Specifically, we provide a multi-cell analytical model using stochastic geometry to identify the performance gain under different sharing strategies, which gives tractable and accurate results. To validate the performance using a realistic setting, we conduct extensive simulations for a multi-cell OFDMA system using real base station locations. Both analytical and simulation results show that even a simple cooperation strategy between two similar operators, where they share spectrum and base stations, roughly quadruples capacity as compared to the capacity of a single operator. This is equivalent to doubling the capacity per customer, providing a strong incentive for operators to cooperate, if not actually merge.","1550-3607;15503607","Electronic:978-1-4577-2053-6; POD:978-1-4577-2052-9; USB:978-1-4577-2051-2","10.1109/ICC.2012.6363788","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363788","","Analytical models;Bandwidth;Corporate acquisitions;Fading;Interference;Resource management;Throughput","OFDM modulation;cellular radio;cooperative communication;frequency division multiple access;information retrieval;mobile computing;radio spectrum management;stochastic processes;telecommunication traffic","base station location;cellular network;cellular operator;cellular service;cooperation strategy;data capacity crisis;data traffic;mobile user;multicell OFDMA system;multicell analytical model;spectrum sharing scheme;stochastic geometry;ubiquitous data access","","8","","13","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"Distributed PACS using distributed file system with hierarchical meta data servers","T. Hiroyasu; Y. Minamitani; M. Miki; H. Yokouchi; M. Yoshimi","Department of Life and Medical Sciences, Doshisha University, Japan","2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","20121110","2012","","","5891","5894","In this research, we propose a new distributed PACS (Picture Archiving and Communication Systems) which is available to integrate several PACSs that exist in each medical institution. The conventional PACS controls DICOM file into one data-base. On the other hand, in the proposed system, DICOM file is separated into meta data and image data and those are stored individually. Using this mechanism, since file is not always accessed the entire data, some operations such as finding files, changing titles, and so on can be performed in high-speed. At the same time, as distributed file system is utilized, accessing image files can also achieve high-speed access and high fault tolerant. The introduced system has a more significant point. That is the simplicity to integrate several PACSs. In the proposed system, only the meta data servers are integrated and integrated system can be constructed. This system also has the scalability of file access with along to the number of file numbers and file sizes. On the other hand, because meta-data server is integrated, the meta data server is the weakness of this system. To solve this defect, hieratical meta data servers are introduced. Because of this mechanism, not only fault - tolerant ability is increased but scalability of file access is also increased. To discuss the proposed system, the prototype system using Gfarm was implemented. For evaluating the implemented system, file search operating time of Gfarm and NFS were compared.","1094-687X;1094687X","Electronic:978-1-4577-1787-1; POD:978-1-4244-4119-8; USB:978-1-4244-4120-4","10.1109/EMBC.2012.6347334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6347334","","DICOM;Hospitals;Medical diagnostic imaging;Picture archiving and communication systems;Servers;XML","PACS;distributed databases;information retrieval;meta data;software fault tolerance","DICOM file;Gfarm;distributed PACS;distributed file system;fault-tolerant ability;file search operating time;hierarchical meta data servers;image data;image file access;medical institution;picture archiving-and-communication systems","Information Storage and Retrieval;Programming Languages;Radiology Information Systems;Systems Integration","0","","14","","","Aug. 28 2012-Sept. 1 2012","","IEEE","IEEE Conference Publications"
"Feature Terms Analyzing Strategy for Recruiting Websites","X. Hong; Y. Zhang; Z. Jiong","Sch. of Inf. Technol., Shandong Inst. of Commerce & Technol., Jinan, China","2012 Second International Conference on Business Computing and Global Informatization","20121220","2012","","","451","453","As we know text information on web page has grown exponentially. It is a hot research area in data processing by reasonably extracting and analysis for unstructured information, so as to mine novel, latent useful pattern. Focusing on imprecise classified text set about job hunting web site, discovering topic relevant feature terms is an effective way to find new tendency for work ability demanding. In this paper, we propose a job relevant feature extracting method better than methods of TF-IDF, maximum entropy and lexical chain to reflect the demanding of tendency, and prove that it is effective by contrast testing.","2378-8941;23788941","Electronic:978-0-7695-4854-8; POD:978-1-4673-4469-2","10.1109/BCGIN.2012.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6382564","concurrent terms;feature term extraction;maximum relevance","Agricultural products;Business;Educational institutions;Entropy;Feature extraction;Filtering algorithms;Information technology","Web sites;classification;feature extraction;information retrieval;text analysis","Web page;classified text set;data processing;feature terms analyzing strategy;job relevant feature extracting method;latent useful pattern;text information;unstructured information analysis;unstructured information extraction","","0","","6","","","12-14 Oct. 2012","","IEEE","IEEE Conference Publications"
"Introducing faceted views in diversity of online novels","E. Ito; S. Hirokawa; K. Shimizu","Research Institute for Information Technology, Kyushu University, Fukuoka, Japan","Seventh International Conference on Digital Information Management (ICDIM 2012)","20121124","2012","","","1","4","In recent years, user generated content services have become popular. The authors are interested in online novel services. Classification of online novels is difficult because keywords and genre are assigned by the author of the novel without control. In order to overcome the problem faced when category classifying and searching online novels, faceted views were introduced and a cross tabulation search and analysis system was developed. This system can discover relations between novel genres and keywords, and can find the author's trend.","pending","Electronic:978-1-4673-2430-4; POD:978-1-4673-2428-1","10.1109/ICDIM.2012.6360114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360114","cross tabulation;keyword frequency;online novel;recommendation;search engine;user generated content","Educational institutions;History;Indium tin oxide;Market research;Motion pictures;Search problems;User-generated content","classification;content management;information retrieval","analysis system;classification;cross tabulation search;faceted views;keyword;novel genre;online novel searching;online novel service;user generated content service","","2","","7","","","22-24 Aug. 2012","","IEEE","IEEE Conference Publications"
"An Approach for Incorporating Context in Building Probabilistic Predictive Models","J. A. Wu; W. Hsu; A. A. T. Bui","Med. Imaging Inf. Group, Univ. of California, Los Angeles, Los Angeles, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","96","105","With the increasing amount of information collected through clinical practice and scientific experimentation, a growing challenge is how to utilize available resources to construct predictive models to facilitate clinical decision making. Clinicians often have questions related to the treatment and outcome of a medical problem for individual patients; however, few tools exist that leverage the large collection of patient data and scientific knowledge to answer these questions. Without appropriate context, existing data that have been collected for a specific task may not be suitable for creating new models that answer different questions. This paper presents an approach that leverages available structured or unstructured data to build a probabilistic predictive model that assists physicians with answering clinical questions on individual patients. Various challenges related to transforming available data to an end-user application are addressed: problem decomposition, variable selection, context representation, automated extraction of information from unstructured data sources, model generation, and development of an intuitive application to query the model and present the results. We describe our efforts towards building a model that predicts the risk of vasospasm in aneurysm patients.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366195","","Aneurysm;Computational modeling;Context;Context modeling;Data mining;Data models;Predictive models","decision making;medical information systems;patient treatment;probability;query processing;question answering (information retrieval)","aneurysm patients;automated information extraction;clinical decision making;clinical question answering;context representation;electronic health record;end-user application;model generation;patient treatment;probabilistic predictive model;problem decomposition;scientific knowledge;unstructured data sources;variable selection;vasospasm risk","","0","1","28","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Case based Indonesian closed domain question answering system with real world questions","A. Fikri; A. Purwarianti","School of Electrical Engineering and Informatics, Institut Teknologi Bandung (ITB), Bandung, Indonesia","2012 7th International Conference on Telecommunication Systems, Services, and Applications (TSSA)","20121203","2012","","","181","186","Number of people having expertise in a certain domain is less than people who need information in that domain. In this situation, an automatic question answering (QA) system is necessary. Observing available manual QA sites on internet, the real world question that people usually ask have different expected answer type (EAT) compared to a common automatic QA. Addressing a case study of a religion domain which makes it a closed domain QA, we proposed the EAT into 6 types: LAW, DEFINITION, COMPARISON, METHOD, TIME and PERSON. Different with common QA approach, we built the QA system using case based approach which consists of two main components: Question Analyzer and Case Retriever. Related with the case based reasoning (CBR) framework, these two main components act as the Retrieve and Reuse process while the Revise and Retain process is handle by Case Retainer component. The QA system was built using available Indonesian Natural Language Processing (NLP) tools and FreeCBR as the CBR library. The experiments were done to calculate the accuracy and testing the system with unknown case. By using 77 cases collected from internet with assumption that all answers are available, the experiments achieved 97% accuracy. And by using 10 test cases for the unknown case, the similarity score calculated by the system showed that the test questions have no answer in the available case base.","","Electronic:978-1-4673-4550-7; POD:978-1-4673-4549-1","10.1109/TSSA.2012.6366047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366047","Case Based Reasoning;Closed Domain;Question Answering System;Real World Questions","Accuracy;Cognition;Equations;Internet;Semantics;Telecommunications","case-based reasoning;natural language processing;question answering (information retrieval)","CBR framework;CBR library;EAT;FreeCBR;Indonesian NLP tool;Indonesian natural language processing tool;Internet;automatic QA system;automatic question answering system;case retainer component;case retriever;case-based Indonesian closed domain question answering system;case-based reasoning framework;comparison type;definition type;expected answer type;law type;method type;person type;question analyzer;real world question;religion domain;retrieve-reuse process;revise-retain process;time type","","0","","14","","","30-31 Oct. 2012","","IEEE","IEEE Conference Publications"
"Temporal Relation Extraction from Medical Discharge Summaries","E. Silgard; M. Tharp; R. Mulkar-Mehta","Univ. of California, San Diego, La Jolla, CA, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","132","132","In this paper we discover temporal relations in patient discharge summaries, when the relevant medical events and temporal expressions were provided in the training data.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366224","Biomedical Informatics;Temporal Relation","Conferences;Data mining;Discharges (electric);Hospitals;Machine learning;Medical diagnostic imaging","information retrieval;medical information systems","biomedical informatics;medical discharge summary;medical events;patient discharge summary;temporal relation extraction;training data","","0","","3","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"A Novel URL Assignment Model Based on Multi-objective Decision Making Method","Q. Huang; Q. Li; Z. Yan","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China","2012 Ninth Web Information Systems and Applications Conference","20121220","2012","","","31","34","With the tremendous growth of the Web, it has become a huge challenge for the single-process crawlers to locate the resources that are precise and relevant to some topics in an appropriate amount of time, so it is increasingly important to use the parallel crawler. However, due to the parallelism of crawlers, one headache problem we have to face is how to distribute the URLs to crawlers to make the parallel system work coordinately and thereby make sure that the Web pages fetched are of high quality. In this paper, a novel URL assignment model for the parallel crawler is described, which is based on multi-objective decision making method and considers multiple factors synthetically such as load balance, overlap and so on. Extensive experiments test and validate our techniques.","","Electronic:978-0-7695-4819-7; POD:978-1-4673-3054-1","10.1109/WISA.2012.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385178","URL assignment model;multi-objective decision making method;parallel crawler;web crawler","Computational modeling;Computer architecture;Crawlers;Decision making;Load modeling;Loading;Web pages","Web sites;decision making;information retrieval;resource allocation","URL assignment model;Web pages;load balance;multiobjective decision making method;parallel crawler;single-process crawlers","","0","","11","","","16-18 Nov. 2012","","IEEE","IEEE Conference Publications"
"Cheap, Fast, and Good Enough for the Non-biomedical Domain but is It Usable for Clinical Natural Language Processing? Evaluating Crowdsourcing for Clinical Trial Announcement Named Entity Annotations","H. Zhai; T. Lingren; L. Deleger; Q. Li; M. Kaiser; L. Stoutenborough; I. Solti","Div. of Biomed. Inf., Cincinnati Children's Hosp. Med. Center, Cincinnati, OH, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","106","106","Building upon previous work from the general crowdsourcing research, this study investigates the usability of crowdsourcing in the clinical NLP domain for annotating medical named entities and entity linkages in a clinical trial announcement (CTA) corpus. The results indicate that crowdsourcing is a feasible, inexpensive, fast, and practical approach to annotate clinical text (without PHI) on large scale for medical named entities. The crowdsourcing program code was released publicly.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366196","","Biomedical imaging;Clinical trials;Hospitals;Joining processes;Natural language processing;Pediatrics;Usability","information retrieval;medical computing;natural language processing;outsourcing;text analysis","CTA corpus;clinical NLP domain;clinical natural language processing;clinical text annotation;clinical trial announcement corpus;crowdsourcing evaluation;crowdsourcing program code;crowdsourcing usability;entity linkages;medical named entity annotation","","0","","1","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Integration of multi-media technologies to facilitate reflection and learning, particularly in the area of digital storytelling","R. Malkawi; P. Davies","Faculty of Advanced Technology, Department of Computing and Mathematical Sciences, University of Glamorgan, Pontypridd, Mid Glamorgan CF37 1DL, United Kingdom","International Conference on Education and e-Learning Innovations","20121124","2012","","","1","5","The development of computer skills by individuals of various ages and backgrounds in this age of mass digital technology has been phenomenal. By combining various digital technologies it is possible to provide the users with an enhanced interface that produces a more attractive, interactive and functional experience for them. Commercial programmes or authoring tools such as iMovie, PowerPoint and/or PhotoStory are not designed in accordance with pedagogical or andagogical purposes, for example not wizard based. The main hypothesis associated with this study is that, there are significant benefits to be accrued by the development or viewing of digital stories with regard to enhancing the learning and reflective processes of students within higher education. So the main aim of this study is to ascertain whether this hypothesis is true or not, and report upon the findings from utilising both qualitative and quantitative research methods. The issue the hypothesis tackles is not easy. To this effect there is a need to develop a Wizard-based digital storytelling tool that helps students develop reflective stories. The wizard, which is integrated with the story seven elements and encapsulate them, does not only provide technical guidance but more importantly it will direct and support the user in developing a digital story that meets the expectations and structure of what is considered to be appropriate. There are many technical barriers present in developing a digital story by non-computer literate individuals. The development of a user-friendly tool that supports the creation of these stories is a key component of this study. Tutors /students develop digital stories in different learning subject areas using the same prototype depending upon the users' needs and requirements. The initial work has concentrated upon the design of an appropriate `Wizard-based' digital story tool that supports both tutors and students in the development of stories. This tool incorporates t- e fundamental guidelines for the development of digital stories mapped to various media templates. It is both flexible and powerful making use of an asset library of media objects that can be retrieved by a metadata search engine and are then included within the digital story scenes.","","CD:978-1-4673-2224-9; Electronic:978-1-4673-2225-6; Paper:978-1-4673-2226-3","10.1109/ICEELI.2012.6360582","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360582","Digital storytelling;media objects;metadata;reflection;teaching and learning;templates","Educational institutions;Libraries;Media;Multimedia communication;Production;Prototypes","computer aided instruction;further education;human computer interaction;information retrieval;meta data;multimedia computing;search engines;user interfaces","asset library;attractive experience;computer skills development;functional experience;higher education;interactive experience;learning facilitation;learning process enhancement;mass digital technology;media templates;metadata search engine;multimedia technologies;reflection facilitation;reflective process enhancement;wizard-based digital storytelling tool","","0","","14","","","1-3 July 2012","","IEEE","IEEE Conference Publications"
"Dynamic entity and relationship extraction from news articles","M. U. Haq; H. Ahmed; A. M. Qamar","Department of Computing, School of Electrical Engineering and Computer Science (SEECS), National University of Sciences And Technology (NUST), Islamabad, Pakistan","2012 International Conference on Emerging Technologies","20121206","2012","","","1","5","In structured as well as unstructured data, information extraction (IE) and information retrieval (IR) techniques are gaining popularity in order to produce a realistic output. The Internet users are growing day by day and becoming a popular source for spreading the information through news/blogs etc. To monitor this information, a lot of quality work has been done in that perspective. Related to news monitoring, our proposed unsupervised machine learning approach will fetch the entities and relationships from the news document itself and through comparison with other related news documents, it will form a cluster. We propose, in this paper, a dynamic model for entity extraction and relationship in order to monitor the news reported in the news articles.","","CD-ROM:978-1-4673-4450-0; Electronic:978-1-4673-4451-7; POD:978-1-4673-4452-4","10.1109/ICET.2012.6375469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375469","Entity extraction;document grouping;relationship extraction;unsupervised classification","Assembly;Context;Data mining;Machine learning;Manuals;Monitoring;Tagging","Web sites;data structures;document handling;information retrieval;unsupervised learning","blogs;dynamic entity extraction;dynamic relationship extraction;information extraction technique;information retrieval technique;news articles;news documents;news monitoring;structured data technique;unstructured data technique;unsupervised machine learning","","0","","10","","","8-9 Oct. 2012","","IEEE","IEEE Conference Publications"
"Noise removal of audio clips for fingerprint matching","Y. Wang; X. Yu; W. Wang; W. Wan; R. Swaminathan","Shanghai HanPan Inf. S&amp;T Ltd., Shanghai, China","2012 International Conference on Audio, Language and Image Processing","20121210","2012","","","942","946","With the rapid expansion of modern multimedia data, accurate and efficient retrieval of audio information has become one of the most important issues that need to be resolved especially in the actual noise environment. As an important part of the multimedia information, audio data provides an indispensable element for the people of auditory perception. However, in the transmission process, it will inevitably be subject to a variety of noise interference. There are generally two kinds of noise, fully distributed type and burst mixed type. In this paper, we mainly focused on noise removal of the latter kind. Combined with commonly used Philips fingerprinting algorithm, noise-removed clean audio clips are used to extract fingerprints and put into the process of retrieval. The results show that our methods can better locate noise, and get a relatively high similarity and matching accuracy.","","Electronic:978-1-4673-0174-9; POD:978-1-4673-0173-2","10.1109/ICALIP.2012.6376749","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376749","","Accuracy;Fingerprint recognition;Multimedia communication;Signal processing algorithms;Signal to noise ratio;Standards","audio signal processing;feature extraction;information retrieval;signal denoising;signal detection","Philips fingerprinting algorithm;VAD algorithm;audio clips;audio fingerprint matching;audio information retrieval;auditory perception;multimedia data expansion;noise environment;noise interference reduction;noise removal;transmission process;voice activity detection","","0","","26","","","16-18 July 2012","","IEEE","IEEE Conference Publications"
"Techniques of abstraction and use of metadata structures","L. A. Andrei; F. Constantin; A. Boicea; F. Radulescu","Faculty of Automatic Control and Computer Science, Politehnica University of Bucharest, Bucharest, Romania","2012 IEEE 8th International Conference on Intelligent Computer Communication and Processing","20121124","2012","","","361","365","Metadata integration and use represents an open problem due to the rapid expansion of data resources in a nonstandard compliant environment. The increasing need to access and retrieve relevant data based on semantic similarity from distributed, autonomous and heterogeneous sources demands innovative solutions that can offer an integrated global view over various local schemas. The framework proposed in this paper aims to achieve metadata integration and aggregation while preserving initial semantics and minimal data loss. Main problems are metadata reduction to a generic structure as well as identifying only those resources that match the crawling profile.","","Electronic:978-1-4673-2952-1; POD:978-1-4673-2953-8","10.1109/ICCP.2012.6356214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6356214","crawler;data integration;metadata;mining;ontology;profile;schema;semantic","Catalogs;Crawlers;Data mining;Educational institutions;HTML;Semantics;Web pages","information retrieval;meta data","abstraction technique;autonomous sources;crawling profile;data access;data resources;data retrieval;distributed sources;heterogeneous sources;initial semantics;local schemas;metadata aggregation;metadata integration;metadata structures usage;minimal data loss;semantic similarity","","0","","7","","","Aug. 30 2012-Sept. 1 2012","","IEEE","IEEE Conference Publications"
"Refined filtering of interferometric phase from INSAR data","C. F. Chao; K. S. Chen; J. S. Lee; C. T. Wang","Institute of Space science, National Central University, Taiwan","2012 IEEE International Geoscience and Remote Sensing Symposium","20121110","2012","","","1821","1824","Radar interferometry has been widely applied in measuring the surface height. The information about surface can be derived from phase interferograms. However, phase noise reduces the accuracy and reliability of that information. Hence, the minimization of phase noise is essential to the retrieval of surface information. This work presents a refined filter that is based on the Lee adaptive INSAR filter and the sigma filter. The basic idea is to filter adaptively the interferometric phase according to the local noise level to minimize the loss of signal for a particular shape of fringes, including in such extreme cases as involve broken fringes, following the elimination of unreliable pixels of phase noise. The goal is to reduce the phase deviation and the number of residues, and minimize the phase error. The proposed filter was inspected herein using both simulated data and real interferometer data. Results reveal that the filtering performance is better than that of commonly used filters.","2153-6996;21536996","Electronic:978-1-4673-1159-5; POD:978-1-4673-1160-1; USB:978-1-4673-1158-8","10.1109/IGARSS.2012.6351157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6351157","INSAR filter;interferometry;phase noise filtering;refined filter","Filtering algorithms;Information filters;Phase noise;Synthetic aperture radar","adaptive filters;geophysical image processing;information retrieval;phase noise;radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar","INSAR data;Lee adaptive INSAR filter;interferometric phase;local noise level;phase error minimization;phase interferograms;phase noise;phase noise minimization;real interferometer data;refined filter;sigma filter;surface height measurement;surface information retrieval","","0","","11","","","22-27 July 2012","","IEEE","IEEE Conference Publications"
"A Comparison of Computational Approaches in the Molecular Identification of Pathogenic Organisms","D. R. Bastola; S. McGrath; S. Bhowmick; I. Thapa","Sch. of Interdiscipl. Inf., Univ. of Nebraska at Omaha, Omaha, NE, USA","2012 IEEE Second International Conference on Healthcare Informatics, Imaging and Systems Biology","20121203","2012","","","73","73","Molecular based identification of pathogenic organism is becoming a routine procedure in many diagnostic laboratories. Ribosomal RNA is particularly the most popular choice for this purpose. Although, other targets such as `cytochrome b', `rpoB' and `actin' are highly effective, they have not been extensively used. This could be due to the lack of effective data collection method. We used sequence based exhaustive search of public sequence database to obtain all target sequences. This approach is currently being extended to collect such molecular targets for Nocardia and other slow growing medically important organisms.","","Electronic:978-0-7695-4921-7; POD:978-1-4673-4803-4","10.1109/HISB.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6366198","","Databases;Educational institutions;Informatics;Medical diagnostic imaging;Organisms;RNA","RNA;information retrieval;medical computing;microorganisms;molecular biophysics","Nocardia;computational approaches;data collection method;diagnostic laboratories;molecular-based identification;pathogenic organisms;public sequence database;ribosomal RNA;target sequence-based search","","0","","","","","27-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Multi-theme analysis of music emotion similarity for jukebox application","C. Y. Lin; S. Cheng","Master Program of Sound and Music Innovative Technologies, National Chiao Tung University, Hsinchu, Taiwan, ROC","2012 International Conference on Audio, Language and Image Processing","20121210","2012","","","241","246","This study proposes a music linkage jukebox system that recommends listeners a ranked list retrieved by the resemblance of music-induced emotions between the query clip and music bank. The retrieval results also provide a time-varying interface of dynamic emotional transition caused by music in a predetermined emotion plane. In the system, the multi-theme phrases of musical structure, including Intro, Verse, and the Chorus are analyzed by autocorrelation function as an input test structure, then using feature-weighted scoring algorithms to analyze the ingredients of music emotion with five audio characteristics sets of the testing music clips. The similarity of emotions between music clips and music bank are measured by Euclidean distance algorithms. Preliminary evaluations of the system illustrate the novelty with the emotion ratios and the real-time emotion locus evoked by music clips. The proposed system also shows the rapid browsing in the process for emotion similarity of music retrieval.","","Electronic:978-1-4673-0174-9; POD:978-1-4673-0173-2","10.1109/ICALIP.2012.6376619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376619","","Equations;Feature extraction;Frequency domain analysis;Indexes;Mathematical model;Timbre","audio signal processing;audio user interfaces;correlation methods;feature extraction;information retrieval;music;recommender systems","Euclidean distance algorithms;audio characteristics sets;autocorrelation function;chorus;dynamic emotional transition;emotion ratios;feature-weighted scoring algorithms;intro;jukebox application;listener recommendation;multitheme analysis;music bank;music clips;music emotion similarity;music linkage jukebox system;music retrieval;musical structure multitheme phrases;query clip;real-time emotion locus;time-varying interface;verse","","2","","14","","","16-18 July 2012","","IEEE","IEEE Conference Publications"
