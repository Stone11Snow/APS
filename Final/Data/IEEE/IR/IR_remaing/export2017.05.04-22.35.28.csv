"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5607605,5610528,5610599,5607479,5607456,5607438,5607459,5607416,5607419,5606471,5607461,5600464,5607370,5605999,5607427,5607428,5605363,5605508,5570869,5596936,5603340,5596595,5596470,5602362,5604475,5603443,5604111,5603866,5604187,5603125,5602088,5603190,5603349,5600308,5602285,5601040,5602083,5600854,5602755,5599723,5599733,5599839,5599102,5589007,5595172,5597019,5595905,5596454,5597349,5597107,5597524,5588965,5597516,5598227,5597302,5597523,5597051,5597527,5597861,5590802,5591520,5587804,5591255,5590395,5587838,5592075,5590600,5587849,5406493,5591334,5588602,5590464,5590986,5591246,5593318,5590577,5590530,5591289,5591322,5591403,5592000,5587854,5590602,5589653,5591131,5591304,5587844,5590981,5590681,5593608,5593740,5591585,5591055,5591976,5591298,5587847,5591400,5587834,5593358,5587774",2017/05/04 22:35:28
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A 2-pronged proposal relating to appropriate healthcare technology for the developing world","P. M. Coyle; R. P. Alfred","R. Prince Alfred Hosp., Sydney, NSW, Australia","3rd IEE Seminar on Appropriate Medical Technology for Developing Countries","20101007","2004","","","24/1","24/3","The paper discussed the following: 1. An online database of a range of items relevant to the provision of healthcare in the 3<sup>rd</sup> world and 2. An online brokerage service to match offers of, and requests for, healthcare items appropriate for 3<sup>rd</sup> world healthcare facilities.","","Paper:978-1-84919-309-2","10.1049/ic.2004.0694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596454","","","health care;information retrieval systems","3<sup>rd</sup> world healthcare facility;healthcare technology;online brokerage service;online database","","0","","","","","4-4 Feb. 2004","","IET","IET Conference Publications"
"Learning Naive Bayes Classifiers for Music Classification and Retrieval","Z. Fu; G. Lu; K. M. Ting; D. Zhang","","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4589","4592","In this paper, we explore the use of naive Bayes classifiers for music classification and retrieval. The motivation is to employ all audio features extracted from local windows for classification instead of just using a single song-level feature vector produced by compressing the local features. Two variants of naive Bayes classifiers are studied based on the extensions of standard nearest neighbor and support vector machine classifiers. Experimental results have demonstrated superior performance achieved by the proposed naive Bayes classifiers for both music classification and retrieval as compared to the alternative methods.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597349","Music Classification;Naive Bayes","Artificial neural networks;Equations;Feature extraction;Nearest neighbor searches;Niobium;Support vector machines;Training","Bayes methods;audio signal processing;feature extraction;information retrieval;music;signal classification","audio feature extraction;music classification;music retrieval;naive Bayes classifiers;song-level feature vector","","8","","6","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"News Filtering and Summarization on the Web","X. Wu; G. Q. Wu; F. Xie; Z. Zhu; X. G. Hu","University of Vermont , Burlington","IEEE Intelligent Systems","20100930","2010","25","5","68","76","The news filtering and summarization (NFAS) system can automatically recognize Web news pages, retrieve each news page's title and news content, and extract key phrases. This extraction method substantially outperforms methods based on term frequency and lexical chains.","1541-1672;15411672","","10.1109/MIS.2010.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406493","Web news;classification;information filtering;information summarization;intelligent systems","Automation;Computer science;Data mining;Educational institutions;Electronic mail;Frequency;Information filtering;Information filters;Uniform resource locators;Web pages","Web sites;data mining;information retrieval;text analysis;word processing","Web news page;key phrase extraction;news content;news filtering system;news summarization system","","14","2","11","","20100205","Sept.-Oct. 2010","","IEEE","IEEE Journals & Magazines"
"A hybrid intelligent system combining self organizing maps and case based reasoning for evaluating postural control","A. U. Alahakone; S. M. N. A. Senanayake","Monash University, Sunway Campus, Jalan Lagoon Selatan, 46150, Bandar Sunway, Malaysia","2010 IEEE Conference on Multisensor Fusion and Integration","20101014","2010","","","38","43","Evaluating performance is crucial in stability assessments and training as it provides a valuable measure to examine postural control and recommend rehabilitation strategies for improvement. This paper proposes a novel methodology combining self organizing maps and case based reasoning implemented using a relational database management system to access, examine, diagnose and propose recommendations for improving trunk postural control. A self organizing map was developed to classify the input dataset gathered during a tandem Romberg stability test which behaved as the knowledgebase of the system. Case based reasoning was incorporated based on its ability to solve new problems by adopting previously defined, successful solutions to analogous problems. The case based reasoning architecture was implemented using a relational database with the self organizing map integrated to retrieve analogous case records to solve a new case. The prediction accuracy of the hybrid system to accurately produce the most similar case for a given new case was tested using leave-one-out-cross-validation method. The results demonstrated a high prediction accuracy of over 90% confirming the effectiveness of the hybrid methodology for evaluating and predicting recommendations for performance improvement based on existing knowledgebase for postural control.","","DVD:978-1-4244-5425-9; Electronic:978-1-4244-5426-6; POD:978-1-4244-5424-2","10.1109/MFI.2010.5604475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604475","Case Based Reasoning;Hybrid Systems;Postural Control;Relational Database;Self Organizing Maps","Accuracy;Cognition;Graphical user interfaces;Kinematics;Neurons;Stability analysis;Training","biocontrol;biology computing;case-based reasoning;information retrieval;knowledge based systems;relational databases;self-organising feature maps;stability","analogous case record retrieval;case based reasoning;hybrid intelligent system;knowledgebase system;leave one out cross validation method;postural control;rehabilitation strategy;relational database management system;self organizing map;stability assessment;tandem Romberg stability test","","2","","26","","","5-7 Sept. 2010","","IEEE","IEEE Conference Publications"
"Detecting duplicates with shallow and parser-based methods","S. Hartrumpf; T. Vor Der Br√ºck; C. Eichhorn","IICS, Fern Universit&#x00E4;t in Hagen, Germany","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","Identifying duplicate texts is important in many areas like plagiarism detection, information retrieval, text summarization, and question answering. Current approaches are mostly surface-oriented (or use only shallow syntactic representations) and see each text only as a token list. In this work however, we describe a deep, semantically oriented method based on semantic networks which are derived by a syntactico-semantic parser. Semantically identical or similar semantic networks for each sentence of a given base text are efficiently retrieved by using a specialized semantic network index. In order to detect many kinds of paraphrases the current base semantic network is varied by applying inferences: lexico-semantic relations, relation axioms, and meaning postulates. Some important phenomena occurring in difficult-to-detect duplicates are discussed. The deep approach profits from background knowledge, whose acquisition from corpora like Wikipedia is explained briefly. This deep duplicate recognizer is combined with two shallow duplicate recognizers in order to guarantee high recall for texts which are not fully parsable. The evaluation shows that the combined approach preserves recall and increases precision considerably, in comparison to traditional shallow methods. For the evaluation, a standard corpus of German plagiarisms was extended by four diverse components with an emphasis on duplicates (and not just plagiarisms), e.g., news feed articles from different web sources and two translations of the same short story.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587838","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587838","Duplicate detection;Entailments;Paraphrases;Plagiarism;Semantic networks;Support vector machine","Density estimation robust algorithm;Detectors;Pragmatics;Tin","grammars;information retrieval;text analysis","German plagiarisms;deep duplicate recognizer;duplicate text detection;parser-based methods;syntactico-semantic parser","","0","","15","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Geometric Pattern-based Method to Build Hierarchies of Geo-Referenced Tags","D. Jung; H. Park; R. Maeng; S. Han","Grad. Sch. of Culture Technol., KAIST, Daejeon, South Korea","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","546","551","To extract and structure knowledge from unstructured tag sets is a challenge for the tagging system. Although several methods have shown the ability to assign structures to the tags, their limitation still remains. Accordingly, this study investigates a method to build the place hierarchy of geo-referenced tags. In particular, the method is based on analyzing geometric patterns of footprints, derived from the tags. The objectives are to understand the structure of vernacular geography and to improve the image search by constructing tag semantics. First, the geographical regions are represented based on the large sets of the clustered collaborative tags on the place. Herein, the method to generate the chi-shape derives the footprints of the geographical regions. According to its geometric condition such as position, area, and centroid of the polygon, derived from each footprint, the place-tag hierarchies are constructed. The geographical boundaries between the place tags are established throughout the assigned footprints as well. In addition, our method enhances the accuracy of the tag hierarchies when compared to the previous research. Furthermore, the study also contributes to the development of the tag semantics and the comprehension of the vernacular geography.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591334","Flickr;cluster;geo-referenced tag;geo-tag;geometric pattern;place hierarchy","Accuracy;Clocks;Clustering algorithms;Data visualization;Geography;Tag clouds","geographic information systems;geometry;information retrieval;knowledge acquisition","geo-referenced tags;geometric pattern-based method;geometric patterns;knowledge extraction;knowledge structure;tag semantics;tagging system;vernacular geography","","0","","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Semantic annotation in academic search engine","S. Jian; X. Jungang; C. Zhiwang","School of Information Science and Engineering, Graduate University of Chinese Academy of Sciences, Beijing, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","165","169","Web information can be given more explicit meanings through semantic annotation, so that computer can understand and deal with the information automatically, which is important to improve recall ratio and precision ratio of search engine. An ontology-based semantic annotation method is represented in this paper, and which has been applied in an academic search. Construction of academic ontology, semantic annotation algorithm and semantic retrieval are described.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607459","","Data mining;Dictionaries;Indexes;Ontologies;Resource description framework;Search engines;Semantics","Internet;information retrieval;ontologies (artificial intelligence);search engines","Web information;academic ontology;academic search engine;recall ratio;semantic annotation algorithm;semantic retrieval","","0","2","15","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"On monitoring information flow of outsourced data","A. V. D. M. Kayem","Department of Computer Science, University of Cape Town, Private Bag X3, Rondebosch, 7701 South Africa","2010 Information Security for South Africa","20100930","2010","","","1","8","Data outsourcing is an Internet-based paradigm that allows organizations to share data cost-effectively by transferring data to a third-party service provider for management. Enforcing outsourced data privacy in untrustworthy environments is challenging because the data needs to be kept secret both from unauthorized users and the service provider (SP). Existing approaches propose that the data owner(s) encrypt the data before it is transferred to the service provider to preserve confidentiality. Access is only granted to a user initiated program if the key presented can decrypt the data into a readable format. Therefore the data owner can control access to the data without having to worry about the management costs. However, this approach fails to monitor the data once it has been retrieved from the SP's end. So, a user can retrieve information from the SP's end and share it with unauthorized users or even the SP. We propose a conceptual framework, based on the concept of dependence graphs, for monitoring data exchanges between programs in order to prevent unauthorized access. The framework has a distributed architecture which is suitable for data outsourcing environments and the web in general. Each data object contains a cryptographic tag (like an invisible digital watermark) that is computed by using a cryptographic hash function to combine the checksum of the data and the encryption key. In order to execute an operation with a data object the key presented for decryption must match the one associated with the user's role and generate a cryptographic tag that matches the one embedded into the data. Tracing data exchanges, in this way, can leverage data privacy for organizations that transfer data management to third party service providers.","2330-9881;23309881","Electronic:978-1-4244-5495-2; POD:978-1-4244-5493-8","10.1109/ISSA.2010.5588602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588602","","Access control;Cryptography;Data privacy;Monitoring;Organizations;Service oriented architecture","Internet;cryptography;data privacy;electronic data interchange;information retrieval;outsourcing","Internet based paradigm;cryptographic hash function;cryptographic tag;data decryption;data encryption;data exchange;data management;data monitoring;data outsourcing;data privacy;dependence graph;distributed architecture;information retrieve;management cost;monitoring information flow;outsourced data privacy;service provider;unauthorized user;untrustworthy environment","","4","","18","","","2-4 Aug. 2010","","IEEE","IEEE Conference Publications"
"Web information extraction based on news domain ontology theory","J. Shi; L. Liu","School of Information Engineering, University of Science & Technology Beijing, Beijing, 100083, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","416","419","For the current web information extraction can't adapt to the various page structures, this paper proposes a Web Information Extraction Method based on News Domain Ontology. The areas are accurately found out and the interested information was extracted exactly based on information extraction rules which is generated by news domain ontology. Using the technology of page processing, page conversion, XPath etc, the information extraction system based on news domain ontology is implemented. Testing from news site shows that the approach proposed doesn't rely on the page structure and it can increase the recall and precision of information extraction.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607416","","Data mining;HTML;Navigation;Ontologies;Pattern matching;Web pages;XML","Internet;information retrieval","Web information extraction;XPath;information extraction rules;information extraction system;news domain ontology theory;page conversion;page processing;page structures","","1","","9","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"When is phonetic search with FPGAs efficient?","I. Mr√°zov√°; O. S√Ωkora","Department of Theoretical Computer Science and Mathematical Logic, Faculty of Mathematics and Physics, Charles University, Malostransk&#x00E9; n&#x00E1;m. 25, 118 00 Prague, Czech Republic","ICSES 2010 International Conference on Signals and Electronic Circuits","20101007","2010","","","359","362","Phonetic search represents a new area in information retrieval. Its goal is to search texts for all words that have the same pronunciation as the word heard and written by the user. The user is assumed to be a foreigner who uses in general a different alphabet and different transcription rules. With rapid advances in programmable hardware (FPGA), a natural idea would be to use FPGA-implementations for phonetic search. This paper provides an original methodology to assess their benefits based on the given hardware, search string, language, availability of a dictionary and length of the searched text.","","Electronic:978-83-904743-4-2; POD:978-1-4244-5307-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595172","","Automata;Dictionaries;Field programmable gate arrays;Hardware;Hardware design languages;Registers;Synchronization","field programmable gate arrays;information retrieval;speech processing","FPGA;information retrieval;phonetic search;programmable hardware;search string;search texts","","0","","11","","","7-10 Sept. 2010","","IEEE","IEEE Conference Publications"
"On the Navigability of Social Tagging Systems","D. Helic; C. Trattner; M. Strohmaier; K. Andrews","Knowledge Manage. Inst., Graz Univ. of Technol., Graz, Austria","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","161","168","It is a widely held belief among designers of social tagging systems that tag clouds represent a useful tool for navigation. This is evident in, for example, the increasing number of tagging systems offering tag clouds for navigational purposes, which hints towards an implicit assumption that tag clouds support efficient navigation. In this paper, we examine and test this assumption from a network-theoretic perspective, and show that in many cases it does not hold. We first model navigation in tagging systems as a bipartite graph of tags and resources and then simulate the navigation process in such a graph. We use network-theoretic properties to analyse the navigability of three tagging datasets with regard to different user interface restrictions imposed by tag clouds. Our results confirm that tag resource networks have efficient navigation properties in theory, but they also show that popular user interface decisions (such as ‚Äúpagination‚Äù combined with reverse-chronological listing of resources) significantly impair the potential of tag clouds as a useful tool for navigation. Based on our findings, we identify a number of avenues for further research and the design of novel tag cloud construction algorithms. Our work is relevant for researchers interested in navigability of emergent hypertext structures, and for engineers seeking to improve the navigability of social tagging systems.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590464","","Algorithm design and analysis;Bipartite graph;Limiting;Navigation;Tag clouds;User interfaces","graph theory;information retrieval;social networking (online);user interfaces","bipartite graph;network-theoretic perspective;social tagging systems;tag cloud construction algorithms;user interface restrictions","","5","","39","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic Mining of Human Activity Attributes from Weblogs","N. M. The; T. Kawamura; H. Nakagawa; Y. Tahara; A. Ohsuga","Grad. Sch. of Inf. Syst., Univ. of Electro-Commun., Chofu, Japan","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","20100930","2010","","","633","638","In this paper, we define an activity by five basic attributes: actor, action, object, time and location. The goal of this paper is to describe a method to automatically extract all attributes in each sentence retrieved from Japanese weblogs. Previous work had some limitations, such as high setup cost, inability of extracting all attributes, limitation on the types of sentences that can be handled, and insufficient consideration of interdependency among attributes. To resolve these problems, this paper proposes a novel approach that uses conditional random fields and self-supervised learning. This approach treats the activity extraction as a sequence labeling problem, and has advantages such as domain-independence, scalability, and does not require any hand-tagged data. Since it is unnecessary to fix the positions and the number of the attributes in activity sentences, this approach can extract all attributes by making only a single pass over its corpus. Additionally, by converting to simpler sentences, the proposed approach can deal with complex sentences retrieved from Japanese weblogs. In an experiment, this approach achieves high precision (activity: 88.87%, attributes: over 90%).","","Electronic:978-0-7695-4147-1; POD:978-1-4244-8198-9","10.1109/ICIS.2010.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590986","Conditional Random Fields;Human Activity;Self-Supervised Learning;Semantic Network;Web Mining","Data mining;Feature extraction;Logic gates;Markov processes;Syntactics;Testing;Training data","Web sites;data mining;information retrieval;learning (artificial intelligence);semantic networks;text analysis","Japanese Weblogs;activity extraction;automatic mining;human activity attribute;self-supervised learning;semantic network;sentence retrieval;sequence labeling problem","","0","","26","","","18-20 Aug. 2010","","IEEE","IEEE Conference Publications"
"Analyzing Sentiment Markers Describing Radical and Counter-Radical Elements in Online News","H. Davulcu; S. T. Ahmed; S. Gokalp; M. H. Temkit; T. Taylor; M. Woodward; A. Amin","Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","335","340","In this study, we aim to obtain ‚Äúnatural groupings‚Äù of 151 local non-government organizations and institutions mentioned in a news archive of 77,000 articles spanning a decade (May 1999 to Jan 2010) from Indonesia. One of our goals is to enhance our understanding of counter-radical movements in critical locations in the Muslim world. We present information extraction techniques to recognize entities, and their beliefs and practices in text as a step towards identifying socially significant scales with explanatory power. Then, we proceed to cluster organizations based on these scales. We present experimental results, and discuss challenges in reasoning with the complex interactions of many simultaneous beliefs, practices and attitudes held by the leaders and followers of various organizations.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591246","Web information extraction;component;hierarchical clustering;markers;organizations;scales;spectral clustering","Clustering algorithms;Data mining;Feature extraction;Labeling;Measurement;Organizations;Semantics","information retrieval;social networking (online)","Muslim world;counter-radical movements;information extraction techniques;online news;sentiment markers;social network analysis","","3","1","24","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Natural Language Processing in Web data mining","Y. Chen","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","388","391","This paper describes the research about Web data mining using Natural Language Processing. System accepts arbitrary data as input from Web document and then extracts information from the document. A new method to implement Web data mining is proposed in this paper. There are three steps in this system. First, the Web document will be decomposed to paragraph, sentence and phrase level. Second, extract information from all sentences. Finally, add the information to the knowledge model. The methods used have proved to be efficient for Web data mining with the experimental corpus.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607419","","Data mining;Data models;Feature extraction;Image color analysis;Knowledge engineering;Semantics;Web pages","Internet;data mining;information retrieval;natural language processing;text analysis","Web data mining;Web document;information extraction;knowledge model;natural language processing;paragraph level;phrase level;sentence level","","1","","10","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"Tourism domain ontology construction from the unstructured text documents","S. Tang; Z. Cai","School of Information Science and Engineering, Central South University, Changsha 410083 China, School of Computer Science and Information, Engineering, Guangxi Normal University, Guilin, 541004 China","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","297","301","Ontologies is playing an increasingly important role in knowledge management and the Semantic Web. The tourism information ontology is becoming a core research field in the realm of information retrieval. An ontology construction method based on Formal Concept Analysis (FCA) to extract domain ontology from unstructured text documents is proposed. Under the framework of our ontology construction method, the knowledge engineers could reach a new ontology of tourism information that was demonstrated as useful to support their ontology construction tasks.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599723","format concept analysis;ontology construction;tourism information;unstructured text documents","Conferences;Context;Knowledge based systems;Ontologies;Pragmatics;Semantics","data analysis;information retrieval;ontologies (artificial intelligence);semantic Web;text analysis;travel industry","formal concept analysis;information retrieval;knowledge management;semantic Web;tourism domain ontology construction;tourism information ontology;unstructured text documents","","2","","21","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"The construction and maintenance of the frequently asked question","F. Li; L. Liu","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","296","300","With the development of Question Answering System which is a hot topic in the area of Artificial Intelligence, the set of FAQ (Frequently Asked Question) has become a widely used knowledge base and it do play an important role in Question Answering System. Besides this, it is also important in Information Retrieval. Therefore, the problem of how to construct and maintain the FAQ automatically has attracted many researchers ' attention. In this paper, we put forward a method aims at solving the problem. We quote the ‚ÄúConcept Hierarchy Structure‚Äù for the first time which combined with the theory of text classification. We implement a method of computing similarity between sentences named TFIDF in the construction and maintenance of the FAQ. We do some experiments to verify our method and analyze the shortcomings of the method. From the experiment, we can see that the method introduced in this paper can reach a nice result.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607438","","Computers;Hardware;Internet;Maintenance engineering;Monitoring;Search engines;Software","classification;information retrieval;knowledge based systems;software maintenance;text analysis","FAQ construction;FAQ maintenance;TFIDF method;artificial intelligence;concept hierarchy structure;frequently asked question;information retrieval;knowledge base;question answering system;text classification","","0","","8","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"A human-like TORCS controller for the Simulated Car Racing Championship","J. Mu√±oz; G. Gutierrez; A. Sanchis","Computer Science Department, Universidad Carlos III de Madrid, Avda. de la Universidad 30, 28911 Legan&#x00E9;s, Spain","Proceedings of the 2010 IEEE Conference on Computational Intelligence and Games","20100930","2010","","","473","480","This paper presents a controller for the 2010 Simulated Car Racing Championship. The idea is not to create the fastest controller but a human-like controller. In order to achieve this, first we have created a process to build a model of the tracks while the car is running and then we used several neural networks which predict the trajectory the car should follow and the target speed. A scripted policy is used for the gear change and to follow the predicted trajectory with the predicted speed. The neural networks are trained with data retrieved from a human player, and are evaluated in a new track. The results shows an acceptable performance of the controller in unknown tracks, more than 20% slower than the human in the same tracks because of the mistakes made when the controller tries to follow the trajectory.","2325-4270;23254270","Electronic:978-1-4244-6297-1; POD:978-1-4244-6295-7; USB:978-1-4244-6296-4","10.1109/ITW.2010.5593318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593318","","Artificial neural networks;Games;Gears;Humans;Sensors;Trajectory;Wheels","automobiles;computer games;human factors;information retrieval;neural nets","data retrieval;human like TORCS controller;human player;neural network;scripted policy;simulated car racing championship;speed prediction;the open racing car simulator;trajectory prediction","","5","","17","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"A hierarchical semantically enhanced multimedia data warehouse","A. Vanea; R. Potolea","Technical University of Cluj-Napoca, Romania","Proceedings of the 2010 IEEE 6th International Conference on Intelligent Computer Communication and Processing","20101021","2010","","","3","9","Data warehouses are used in many domains. Their purpose is to store historical data and to assist in the decision making process. Multimedia data warehouses are used for storing files which contain texts, graphics, videos and sound. These kinds of files are produced in large quantities, in fields such as medicine or space research. We propose a framework for building such a data warehouse, structuring the data in a familiar way, for a warehouse user. We present a hierarchical way of structuring the data and the information extracted. We also propose a method of semantically enhancing the data and the information extraction process with the use of hierarchical metadata.","","Electronic:978-1-4244-8230-6; POD:978-1-4244-8228-3","10.1109/ICCP.2010.5606471","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5606471","","Biomedical imaging;Business;Data mining;Data warehouses;Multimedia communication;Streaming media;XML","data warehouses;decision making;information retrieval;meta data;multimedia databases","decision making process;hierarchical metadata;hierarchical semantically enhanced multimedia data warehouse;historical data;information extraction process;multimedia data warehouses;warehouse user","","0","","12","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"Can Motion Segmentation Improve Patch-Based Object Recognition?","A. Ulges; T. M. Breuel","German Res. Center for Artificial Intell. (DFKI), Germany","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3041","3044","Patch-based methods, which constitute the state of the art in object recognition, are often applied to video data, where motion information provides a valuable clue for separating objects of interest from the background. We show that such motion-based segmentation improves the robustness of patch-based recognition with respect to clutter. Our approach, which employs segmentation information to rule out incorrect correspondences between training and test views, is demonstrated empirically to distinctly outperform baselines operating on unsegmented images. Relative improvements reach 50% for the recognition of specific objects, and 33% for object category retrieval.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5595905","motion segmentation;object recognition","Clutter;Computer vision;Motion segmentation;Nearest neighbor searches;Object recognition;Training;Visualization","image motion analysis;image segmentation;information retrieval;object recognition;video signal processing","motion segmentation;object category retrieval;patch-based methods;patch-based object recognition;video data","","0","","18","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Bibliometric assessments of network formations by keyword-based vector space model","H. N. Su; P. C. Lee; T. Y. Chan","Science and Technology Policy Research and Information Center, National Applied Research laboratories, Taipei, Taiwan","PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH","20101014","2010","","","1","9","This study proposes an empirical way for determining probability of network tie formation between network actors. In social network analysis, it is a usually problem that information for determining whether or not a network tie should be formed is missing for some network actors, and thus network can only be partially constructed due to unavailability of information. This methodology proposed in this study is based on network actors similarities calculations by vector space model to calculate how possible network ties can be formed. Also, a threshold value of similarity for deciding whether or not a network tie should be generated is suggested in this study. Four keyword-based research networks, with journal paper or research project as network actors, constructed previously are selected as the targets of this empirical study: 1) Technology Foresight Paper Network: 181 papers and 547 keywords, 2) Regional Innovation System Paper Network: 431 papers and 1165 keywords, 3) Global Sci-Tech Policy Paper Network: 548 papers and 1705 keywords, 4) Taiwans Sci-Tech Policy Project Network: 143 research projects and 213 keywords. The four empirical investigations allow a threshold value calculated by vector space model to be suggested for deciding the formation of network ties.","2159-5100;21595100","Electronic:978-1-890843-21-2; POD:978-1-4244-8203-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603443","","Couplings;Matrix converters;Ontologies;Social network services;Technological innovation;Vocabulary","belief networks;information analysis;information retrieval;ontologies (artificial intelligence);probability;social networking (online)","Taiwans sci-tech policy project network;bibliometric assessment;global sci-tech policy paper network;keyword based research network;keyword based vector space model;network actors;network formation;network probability;regional innovation system paper network;social network analysis;technology foresight paper network","","0","","42","","","18-22 July 2010","","IEEE","IEEE Conference Publications"
"A cognitive crawler using structure pattern for incremental crawling and content extraction","S. Xi; F. Sun; J. Wang","Tsinghua University, Beijing, China","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","238","244","In this paper, we design a cognitive crawler to dramatically reduce the website crawling cost and extract useful content from web pages in an unsupervised procedure. The main idea of reducing the crawling cost is to retrieving those lately modified pages and newly added pages only. However, in reality, it is impossible for traditional crawler to judge whether a page has been modified or newly added without doing a whole crawling. We propose a method to predict those lately modified pages and newly added pages without do any actual crawling; we also find a feasible and stable feature ""structure pattern"" to better indicates the modified probability of certain page. In the meanwhile, we develop a hybrid clustering method combined with K-means and agglomerative hierarchical clustering to automatically find all the structure patterns in certain website. Using structure pattern, we developed an unsupervised algorithm to generate website's templates; using templates, crawler can extract useful information of web pages much more easily and precisely. We also introduce feasible formulas to predict pages' modified probabilities and crawling time intervals. To evaluate the performance of an incremental crawling algorithm, we proposed three new indicators. Using the algorithm proposed, we could extract content of pages with high performance. The experimental results illustrate that structure pattern is very useful and the performance of this cognitive crawler is quite promising and it can save huge amount of bandwidth and is qualified for different websites of various scales.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599733","Incremental crawler;content extraction;hybrid clustering;structure pattern;template generation","Cognitive informatics;Sun","Internet;Web sites;information retrieval;pattern clustering;unsupervised learning","Web pages;Website crawling;Website templates;agglomerative hierarchical clustering;cognitive crawler;content extraction;hybrid clustering method;incremental crawling algorithm;k-means clustering;structure pattern;unsupervised algorithm","","0","","9","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Research on a novel developing approach to open laboratory information management platform","Yong Zhou; Meichen Zhou; Jiong Yang","School of Computer Science and Technology, Soochow University, Suzhou, Jiangsu, China, 215006","2010 Second IITA International Conference on Geoscience and Remote Sensing","20101014","2010","2","","324","327","We design and implement a web-based open laboratory information management platform called WOLIMP which is an integrated portal and enables users to better understand the open laboratory's comprehensive overview, research projects and results. WOLIMP provides an effective news management, application and review issues, laboratory document management, dynamic catalog management, and user-access control management as well. WOLIMP offers a comprehensive overview of the research projects and results of laboratory. Users are able to create personal space which is autonomously managed. They are also allowed to express their options and show their academic views on academic research. By using OOAD, we design the whole system and complete UML diagrams. Finally we implement the system using J2EE and SQL Server 2005. It achieves functions such as releasing laboratory arrangements, dissemination and application information of open issues, and the display of the results. The system has a friendly interface and improves the management level of open laboratory.","","Electronic:978-1-4244-8517-8; POD:978-1-4244-8514-7","10.1109/IITA-GRS.2010.5604111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604111","J2EE;Open laboratory;information management;software architecture","Educational institutions;Laboratories;Navigation;Unified modeling language","Java;SQL;Unified Modeling Language;Web sites;information retrieval;open systems;portals","J2EE;SQL Server;UML diagram;WOLIMP;Web based open laboratory information management platform;dynamic catalog management;integrated portal;laboratory document management;news management;user access control management","","0","","9","","","28-31 Aug. 2010","","IEEE","IEEE Conference Publications"
"Survey and Analysis of CALIS Web Resources Navigation System for Major Subjects","W. Dong; S. Yuan","Libr. of JiaXing Univ., Jiaxing, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","4675","4678","Making a survey and analysis of the CALIS web resources navigation system for major subjects, from the aspects of resources quantities, resource updating, resources usage, resources organization and service function, then points out some suggestion, such as adjusting embody range, showing the specialty, authority and integrity of the resources, improving the propagandizing of the CALIS Navigation System.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590577","CALIS;subject navigatio;web resource","Book reviews;Business;Google;Libraries;Logic gates;Navigation;Programmable logic arrays","Internet;information retrieval","CALIS Web resource navigation system;service function;subject navigation","","0","","8","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Extracting Pathlets FromWeak Tracking Data","K. Streib; J. W. Davis","Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA","2010 7th IEEE International Conference on Advanced Video and Signal Based Surveillance","20101007","2010","","","353","360","We present a novel framework for extracting ""pathlets"" from tracking data. A pathlet is defined as a motion region that contains tracks having the same origin and destination in the scene and that are temporally correlated. The proposed method requires only weak tracking data (multiple fragmented tracks per target). We employ a probabilistic state space representation to construct a Markovian transition model and estimate the scene entry/exit locations. The resulting model is treated as a set of vertices in a graph and a similarity matrix is built which describes broader nonlocal relationships between states. A Spectral Clustering approach is then used to automatically extract the pathlets of the scene. We present experimental results from scenes of varying difficulty and compare against other approaches.","","Electronic:978-1-4244-8311-2; POD:978-1-4244-8310-5","10.1109/AVSS.2010.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597107","","Clustering algorithms;Feature extraction;Pixel;Probabilistic logic;Target tracking;Trajectory","Markov processes;feature extraction;graph theory;information retrieval;matrix algebra;motion estimation;pattern clustering;probability;spectral analysis","Markovian transition model;graph;pathlet extraction;probabilistic state space representation;similarity matrix;spectral clustering;tracking data","","0","","20","","","Aug. 29 2010-Sept. 1 2010","","IEEE","IEEE Conference Publications"
"Semantic History Map: Graphs Aiding Web Revisitation Support","J. ¬äimko; M. Tvarozek; M. Bielikova","Slovak Univ. of Technol., Bratislava, Slovakia","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","206","210","We present a novel approach intended to reduce user effort required to retrieve and/or revisit previously discovered information by exploiting web search and navigation history. In our approach, we collect streams of user actions during search and navigation sessions, identify individual user goals and construct and persistently store visual trees representing session history. We provide users with a History Map - a scrutable graph of semantic terms and web resources with full-text search capability over individual history entries, constructed by merging individual session history trees and the associated web resources. The Map semantically organizes a user's browsing history (with the help of the Delicious folksonomy) and enables him to quickly recall information distributed over several documents and/or sessions. We present experimental results of session identification and also evaluate our prototype over generic web pages and as well in conjunction with our personalized faceted semantic browser Factic with promising initial results.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5592075","exploratory;graphs;history;search","Browsers;Context;History;Navigation;Semantics;USA Councils;Web search","Web sites;information retrieval;online front-ends;semantic Web;tree searching;trees (mathematics)","Web resources;Web search;distributed information;full-text search;graphs aiding Web revisitation support;information retrieval;navigation history;semantic history map;user browsing history;visual tree","","0","","14","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Decoding Frequency Permutation Arrays Under Chebyshev Distance","M. Z. Shieh; S. C. Tsai","Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Information Theory","20101018","2010","56","11","5730","5737","A frequency permutation array (FPA) of length <i>n</i> = <i>m</i>Œª and distance <i>d</i> is a set of permutations on a multiset over <i>m</i> symbols, where each symbol appears exactly Œª times and the distance between any two elements in the array is at least <i>d</i>. FPA generalizes the notion of permutation array. In this paper, under the Chebyshev distance, we first prove lower and upper bounds on the size of FPA. Then we give several constructions of FPAs, and some of them come with efficient encoding and decoding capabilities. Moreover, we show one of our designs is locally decodable, i.e., we can decode a message bit by reading at most Œª+1 symbols, which has an interesting application to private information retrieval.","0018-9448;00189448","","10.1109/TIT.2010.2069253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5605363","Chebyshev distance;frequency permutation array (FPA);locally decodable code;permanent;permutation array (PA)","Ash;Chebyshev approximation;Decoding;Encoding;Information rates;Symmetric matrices;Upper bound","decoding;information retrieval;set theory","Chebyshev distance;FPA;encoding capability;frequency permutation arrays decoding capability;information retrieval;message bit decoding","","17","","21","","","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"Discriminative Basis Selection Using Non-negative Matrix Factorization","A. Jammalamadaka; S. Joshi; S. Karthikeyan; B. S. Manjunath","Dept. of Electr. & Comput. Eng., Univ. of California, Santa Barbara, CA, USA","2010 20th International Conference on Pattern Recognition","20101007","2010","","","1533","1536","Non-negative matrix factorization (NMF) has proven to be useful in image classification applications such as face recognition. We propose a novel discriminative basis selection method for classification of image categories based on the popular term frequency-inverse document frequency (TF-IDF) weight used in information retrieval. We extend the algorithm to incorporate color, and overcome the drawbacks of using unaligned images. Our method is able to choose visually significant bases which best discriminate between categories and thus prune the classification space to increase correct classifications. We apply our technique to ETH-80, a standard image classification benchmark dataset. Our results show that our algorithm outperforms other state-of-the-art techniques.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597019","feature reduction;image classification;semi-supervised learning","IEEE Computer Society;Image color analysis;Image reconstruction;Pattern recognition;Principal component analysis;Satellite broadcasting;Training","face recognition;image classification;image colour analysis;information retrieval;matrix decomposition","ETH-80;NMF;TF-IDF weight;discriminative basis selection method;face recognition;image category;image classification applications;information retrieval;nonnegative matrix factorization;standard image classification benchmark dataset;state-of-the-art techniques;term frequency-inverse document frequency weight;unaligned images","","0","","8","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A novel recommendation system with collective intelligence","J. Zhou; T. Luo; H. Lin","School of Information Science and Engineering, Graduate University of Chinese Academy of Sciences, Beijing, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","151","157","Academic resources on web include courses, educational videos, scientific literatures, experts, peers and all of the useful stuff for research. It is crucial for researchers especially freshman to access and control the academic resources when they start and conduct a research subject. This paper proposes a recommendation system suggests high-quality materials to users according to their research interest. The system makes use of an ontology which is created by domain experts to define the categories of the entire research subjects. The materials of each category are recommended by domain experts and users which are called collective intelligence. And the recommended academic resources list (RARL) is updated adaptively with the operation of the system. Based on the results of user intention detection the system assign each user to the corresponding categories and the user gets his recommendation based on the content in RARL. In the proposed system there are 15,000 education videos, 123GB related materials of 917 courses and 30,000 web pages. The experimental tests show that the system performance is well: the performance is not getting worse when there are more web pages.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607461","Academics Ontology;Adaptive;Collective Intelligence;Recommendation System;Recommended Academic Resources List (RARL);User Intention Detection","Adaptive systems;Computer architecture;Ontologies;Regression tree analysis;Videos;Web pages","Internet;educational technology;information retrieval;ontologies (artificial intelligence);recommender systems","RARL;World Wide Web;collective intelligence;ontology;recommendation system;recommended academic resources list;user intention detection","","0","","15","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"Data Leak Prevention through Named Entity Recognition","J. M. Gomez-Hidalgo; J. M. Martin-Abreu; J. Nieves; I. Santos; F. Brezo; P. G. Bringas","Optenet, Madrid, Spain","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","1129","1134","The rise of the social web has brought a series of privacy concerns and threats. In particular, data leakage is a risk that affects the privacy of not only companies but individuals. Although there are tools that can prevent data losses, they require a prior step that involves the sensitive data to be properly identified. In this paper, we propose a new automatic approach that applies Named Entity Recognition (NER) to prevent data leaks. We conduct an empirical study with real-world data and show that this NER-based approach can enhance the prevention of data losses. In addition, we present and detail the implementation of a prototype built with these techniques and show how it can be used by both particulars and companies in order to handle data losses.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590530","computer security;data leak prevention;named entity recognition;natural language processing","Accuracy;Companies;Prototypes;Security;Training;Twitter","information retrieval;security of data;social networking (online)","data leak prevention;named entity recognition;social Web","","5","","15","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Assessing the Value of Contributions in Tagging Systems","E. Santos-Neto; F. Figueiredo; J. Almeida; M. Mowbray; M. Goncalves; M. Ripeanu","Elec. & Comput. Eng. Dept., Univ. of British Columbia, Vancouver, BC, Canada","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","431","438","Assessing the value of individual users' contributions in peer-production systems is paramount to the design of mechanisms that support collaboration and improve users' experience. For instance, to incentivize contributions, file-sharing systems based on the BitTorrent protocol equate value with volume of contributed content and use a prioritization mechanism to reward users who contribute more. This approach and similar techniques used in resource-sharing systems rely on the fact that the physical resources shared among users are easily quantifiable. In contrast, information-sharing systems, like social tagging systems, lack the notion of a physical resource unit (e.g., content size, bandwidth) that facilitates the task of evaluating user contributions. For this reason, the issue of estimating the value of user contributions in information sharing systems remains largely unexplored. This paper introduces this problem and takes the first steps towards a solution. More precisely, it presents a framework to design algorithms that estimate the value of user contributions in tagging systems, proposes three complementary success criteria for potential solutions, and outlines the methodological evaluation challenges.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591289","entropy;information value;tagging systems;web","Calculators;Context;Entropy;Navigation;Production systems;Tagging","Internet;file organisation;information retrieval;peer-to-peer computing;social networking (online)","BitTorrent protocol;Web;file-sharing systems;incentivize contributions;information-sharing systems;peer-production systems;prioritization mechanism;social tagging systems","","0","","38","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Detecting Terrorism Evidence in Text Documents","P. A. R. Qureshi; N. Memon; U. K. Wiil","Maersk Mc-Kinney Moller Inst., Univ. of Southern Denmark, Odense, Denmark","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","521","527","Abstract-The paper presents a model to detect terrorism evidence in textual documents. The model pre-processes domain specific documents to extract the general patterns of text associated with the domain. The model then incorporates the Conditional Random Field (CRF) model for detection of sentences containing patterns of terrorism evidence. For incorporation of CRF model, the features are selected from generalized patterns rather than the text itself. We prepared a small data set of manually tagged instances of terrorism evidence for training and testing the model. We found that the proposed model achieves better results than other models such as Hidden Markov Model or conventional CRF which are directly applied to text. The proposed model can be applied for improvement of terrorism event extraction and ontology creation systems, especially with the focus towards their effective role in Open Source Intelligence. We describe briefly the existing systems along with possible improvements with incorporation of the presented model at different levels.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.82","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591322","","Accuracy;Adaptation model;Hidden Markov models;Mathematical model;Ontologies;Terrorism;Training","information retrieval;ontologies (artificial intelligence);random processes;terrorism;text analysis","conditional random field model;hidden Markov model;ontology creation systems;open source intelligence;pattern extraction;terrorism event extraction;terrorism evidence detection;textual documents","","1","","24","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"HMM-based Word Spotting in Handwritten Documents Using Subword Models","A. Fischer; A. Keller; V. Frinken; H. Bunke","Inst. of Comput. Sci. & Appl. Math., Univ. of Bern, Bern, Switzerland","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3416","3419","Handwritten word spotting aims at making document images amenable to browsing and searching by keyword retrieval. In this paper, we present a word spotting system based on Hidden Markov Models (HMM) that uses trained subword models to spot keywords. With the proposed method, arbitrary keywords can be spotted that do not need to be present in the training set. Also, no text line segmentation is required. On the modern IAM off-line database and the historical George Washington database we show that the proposed system outperforms a standard template matching approach based on dynamic time warping (DTW).","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597524","Handwriting recognition;Hidden Markov models","Adaptation model;Databases;Feature extraction;Handwriting recognition;Hidden Markov models;Image segmentation;Training","handwriting recognition;hidden Markov models;information retrieval;word processing","HMM-based word spotting system;IAM offline database;arbitrary keywords;dynamic time warping;handwritten documents;hidden Markov models;historical George Washington database;keyword retrieval;subword models","","46","","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"An exploratory analysis of the novelty of a news Web site","M. C. Calzarossa; D. Tessera","Dipartimento di Informatica e Sistemistica, Universit&#x00E0; di Pavia, I-27100, Italy","Performance Evaluation of Computer and Telecommunication Systems (SPECTS), 2010 International Symposium on","20101007","2010","","","399","404","The growing amount of information published on the Web, combined with its dynamic nature, opens many challenging issues dealing with management and retrieval of the information and provisioning of the underlying infrastructures. Search engines have to meet two conflicting requirements: minimize the number of downloads and provide up-to-date information. In this paper, we present the results of an exploratory analysis aimed at investigating the novelty of the content of a news Web site. We analyzed the Web site from an horizontal perspective by focusing on the content of the individual articles and from a vertical perspective by focusing on the entire collection of articles published on the site. These two perspectives allowed us to study how fast and to what extent articles were modified and to model the evolution of the Web site.","","Electronic:978-1-56555-341-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5589007","","HTML;Markov processes;Monitoring;Multimedia communication;Streaming media;Web pages","Web sites;electronic publishing;information management;information retrieval;search engines","Web site;article publishing;exploratory analysis;information retrieval;search engines","","1","","14","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"A Secure Distributed File System for Medical Image Archiving","J. Bian; R. Seker; U. Topaloglu","Res. Program, Inf. Technol., Univ. of Arkansas for Med. Sci., Little Rock, AR, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","961","966","The explosion of medical image usage in clinical and research domains brings us a great challenge of securely handling, storing, retrieving and transmitting biomedical images. Medical images are often large files and they have to be stored for a long time if they are part of a patient's medical record. As medical images usually contain Protected Health Information (PHI), such data is also subjected to various regulations such as HIPAA. Cost effective measures which provide strong security for such data are essential. Therefore, we present a secure and cost effective distributed file system, JigDFS, for archiving medical images/data.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591403","Encryption;Hashed-key Chain;IDA;Medical Image Archiving;Secure Distributed File System","DICOM;Encryption;Fault tolerance;Picture archiving and communication systems","biomedical imaging;distributed processing;file organisation;information retrieval systems;medical computing;security of data","JigDFS;medical image archiving;medical image usage;protected health information;secure distributed file system","","4","","22","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Keyword Extraction Using Word Co-occurrence","C. Wartena; R. Brussee; W. Slakhorst","Novay, Enschede, Netherlands","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","54","58","A common strategy to assign keywords to documents is to select the most appropriate words from the document text. One of the most important criteria for a word to be selected as keyword is its relevance for the text. The tf.idf score of a term is a widely used relevance measure. While easy to compute and giving quite satisfactory results, this measure does not take (semantic) relations between words into account. In this paper we study some alternative relevance measures that do use relations between words. They are computed by defining co-occurrence distributions for words and comparing these distributions with the document and the corpus distribution. We then evaluate keyword extraction algorithms defined by selecting different relevance measures. For two corpora of abstracts with manually assigned keywords, we compare manually extracted keywords with different automatically extracted ones. The results show that using word co-occurrence information can improve precision and recall over tf.idf.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5592000","co-occurrence;distributional hypothesis;extraction;term ranking","Abstracts;Context;Correlation;Feature extraction;Markov processes;Probability distribution;Semantics","information retrieval;text analysis;word processing","document text;keyword extraction algorithm;relevance measurement;word co-occurrence","","8","2","24","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Document expansion using relevant web documents for spoken document retrieval","R. Masumura; A. Ito; Y. Uno; M. Ito; S. Makino","Graduate School of Engineering, Tohoku University, Sendai, Miyagi, Japan","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","Recently, automatic indexing of a spoken document using a speech recognizer attracts attention. However, index generation from an automatic transcription has many problems because the automatic transcription has many recognition errors and Out-Of-Vocabulary words. To solve this problem, we propose a document expansion method using Web documents. To obtain important keywords which included in the spoken document but lost by recognition errors, we acquire Web documents relevant to the spoken document. Then, an index of the spoken document is generated by combining an index that generated from the automatic transcription and the Web documents. We propose a method for retrieval of relevant documents, and the experimental result shows that the retrieved Web document contained many OOV words. Next, we propose a method for combining the recognized index and the Web index. The experimental result shows that the index of the spoken document generated by the document expansion was closer to an index from the manual transcription than the index generated by the conventional method. Finally, we conducted a spoken document retrieval experiment, and the document-expansion-based index gave better retrieval precision than the conventional indexing method.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587854","","","Internet;document handling;indexing;information retrieval;speech recognition","Web document;Web index;automatic indexing;automatic transcription;document expansion;document-expansion-based index;index generation;keywords;out-of-vocabulary words;speech recognizer;spoken document retrieval precision","","1","","17","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Opinion Summarization in Bengali: A Theme Network Model","A. Das; S. Bandyopadhyay","Dept. of Comput. Sci. & Eng., Jadavpur Univ., Kolkata, India","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","675","682","Theme network is a semantic network of document specific themes. So far Natural Language Processing (NLP) research patronized much of topic based summarizer system, unable to capture thematic semantic affinity of any text i.e. a news article containing the concepts, ""gun,"" ""convenience store,"" ""demand money"" and ""make getaway"" might suggest the topics ""robbery"" and ""crime"". In this paper the development of an opinion summarization system that works on Bengali News corpus has been described. The system identifies the sentiment information in each document, aggregates them and represents the summary information in text. The present system follows a topic-sentiment model for sentiment identification and aggregation. Topic-sentiment model is designed as discourse level theme identification and the topic-sentiment aggregation is achieved by theme clustering (k-means) and Document level Theme Relational Graph representation. The Document Level Theme Relational Graph is finally used for candidate summary sentence selection by standard page rank algorithms used in Information Retrieval (IR). As Bengali is a resource constraint language, the building of annotated gold standard corpus and acquisition of linguistics tools for lexico-syntactic, syntactic and discourse level features extraction are described in this paper. The reported accuracy of the Theme detection technique is 83.60% (precision), 76.44% (recall) and 79.85% (F-measure). The summarization system has been evaluated with Precision of 72.15%, Recall of 67.32% and F-measure of 69.65%.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591520","","Clustering algorithms;Feature extraction;Frequency measurement;Gold;Machine learning;Organizations;Syntactics","information retrieval;natural language processing;semantic networks;text analysis","Bengali news corpus;NLP;discourse level feature extraction;discourse level theme identification;document level theme relational graph representation;information retrieval;lexico-syntactic level feature extraction;natural language processing;opinion summarization system;page rank algorithms;resource constraint language;semantic network;syntactic level feature extraction;thematic semantic affinity;theme clustering;theme detection technique;theme network model;topic based summarizer system;topic sentiment identification;topic-sentiment aggregation","","1","1","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Estimation of exhaust emissions of marine traffic using Automatic Identification System data (case study: Madura Strait area, Indonesia)","T. Pitana; E. Kobayashi; N. Wakabayashi","Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","OCEANS 2010 IEEE - Sydney","20101014","2010","","","1","6","The Madura Strait area is one of the busiest marine traffic regions in Indonesia. Many ships arrive, depart and travel through that area, thus influencing the air quality of the port environment. Furthermore, the Indonesian government has not yet ratified Marine Pollution (MARPOL) 73/78 Annex VI regarding the prevention of air pollution from ships and the absence of restricting regulations could have an influence on the level of air pollution. In this study, an Automatic Identification System (AIS) receiver is used to obtain ship data. AIS recognizes a vessel's Maritime Mobil Maritime Identify (MMSI), speed of ship, initial position of ship and ship type. This data is used to evaluate the marine traffic density in the Madura Strait area. Information from ship databases and AIS data are combined for retrieving gross tonnage (GT) information, which is then used to estimate the ship's air pollution emissions. Air pollution estimates also consider the ship's operation modes such as berthing, maneuvering and hotelling. The basic aims of this study are to evaluate marine traffic contributions to the nitrogen oxides (NO<sub>x</sub>), sulfur oxides (SO<sub>x</sub>), particulate matter (PM), carbon monoxide (CO) and carbon dioxide (CO<sub>2</sub>) levels in the Madura Strait area, and to evaluate the possibility of using AIS data when estimating air pollution levels. The emission quantities of NO<sub>x</sub>, SO<sub>x</sub>, PM, CO (as indicators of air pollution) and CO<sub>2</sub> (as a greenhouse gas) are shown in this paper. The process for estimating emissions using AIS is a potential decision-making tool when considering issues such as the effects of ship emissions on health is also evaluated.","","Electronic:978-1-4244-5222-4; POD:978-1-4244-5221-7","10.1109/OCEANSSYD.2010.5603866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603866","","Air pollution;Engines;Estimation;Fuels;Geographic Information Systems;Marine vehicles;Receivers","air pollution;data handling;information retrieval;marine engineering;ships","Indonesia;Madura Strait;air pollution emission;air quality;automatic identification system data;carbon dioxide;carbon monoxide;exhaust emission estimation;gross tonnage information;marine pollution 73/78;marine traffic density;maritime mobil maritime identify;nitrogen oxides;particulate matter;ship databases;sulfur oxides","","2","","16","","","24-27 May 2010","","IEEE","IEEE Conference Publications"
"Insider threat discovery using automatic detection of mission critical data based on content","J. White; B. Panda","University of Arkansas, Fayetteville, USA","2010 Sixth International Conference on Information Assurance and Security","20101014","2010","","","56","61","In this work, we design a system that can automatically detect what is critical in data systems based upon the content and context of the information. After this process has been performed, the information it provides can be used for insider threat detection. If a DBMS is used for data access, historical logs are generally kept and our method uses these logs to detect the typical level of criticality of data that each user uses during normal work conditions. If a user suddenly attempts to access data that is much more critical than was typically accessed in the past, this is a potential sign that the insider is acting maliciously. Few attempts at locating critical data exist in the computer security literature and we argue in this work that our novel design fulfills this need in a manner that is extensible and applicable to a wide range of problems. Our results show that our design requires limited computing resources, and with proper training can be very effective at locating critical data and aiding in mitigating insider threats.","","Electronic:978-1-4244-7409-7; POD:978-1-4244-7407-3","10.1109/ISIAS.2010.5604187","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604187","Critical Data;Databases;Insider Threats","Databases;Information filters;Security;Support vector machine classification;Training","computer network security;computer viruses;database management systems;information retrieval","DBMS;automatic detection;computer security;critical data;data access;data systems;historical logs;insider threat detection;malicious","","0","","15","","","23-25 Aug. 2010","","IEEE","IEEE Conference Publications"
"Density estimation-based document categorization using von Mises-Fisher kernels","A. Skabar; S. Memon","Department of Computer Science and Computer Engineering, La Trobe University, Australia","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","Although classifiers such as Support Vector Machines (SVMs) and k Nearest Neighbors (kNN) are able to achieve excellent document classification performance as measured by common information retrieval measures such as F1 score and breakeven point, they do not produce output values that can reliably be interpreted as probabilities. This means that without additional post-processing of their outputs, these classifiers are not capable of answering a question as simple as ‚ÄúTo which classes does a document belong with a minimum probability of 80%?‚Äù This paper presents a density estimation-based classification technique which outputs probabilities directly. The technique is based on estimating densities using von Mises-Fisher kernels, and combining these under Bayes' Theorem to arrive at posterior probabilities of class membership. Results of applying the technique to the Reuters-21578 dataset show that the technique is computationally feasible, that its classification performance as measured by F1 score is comparable to that of SVMs and better than that of kNN classifiers, and that the output values can be interpreted as well-calibrated probabilities.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596595","","Equations;Kernel;Mathematical model;Nearest neighbor searches;Reliability;Training;Training data","Bayes methods;document handling;information retrieval;pattern classification;probability;support vector machines","Bayes theorem;F1 score;Reuters-21578 dataset;breakeven point;class membership;density estimation;document categorization;document classification;information retrieval measures;k nearest neighbors;posterior probability;support vector machines;von Mises-Fisher kernels","","1","","13","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Contextual spatial relations based spatial modelling of vague place names","Xueying Zhang; Shaonan Zhu","Key Laboratory of Virtual Geographic Environment of Ministry of Education, Nanjing, China","2010 Second IITA International Conference on Geoscience and Remote Sensing","20101014","2010","1","","23","26","Place names have been one of the most commonly-preferred georeferencing systems used to communicate geographically-specific information in our daily lives. Gazetteers as specialized geographical information systems bridge the gap between textual place names and geospatial locations. Most place names in gazetteers are thought of as administrative regions and described with official names. However, a place name could also be a thematic region, a functional region or a cognitive region. There is hence a need to enrich gazetteers with such vague place names and extend their applications. Geospatial location and boundary of vague place names can be induced based on the descriptions of its referred geographical entities and spatial relations in context. Here an approach is proposed to approximately model vague place names based on contextual spatial relations. Computational models for qualitative spatial relations are identified to model single spatial relations and a layer-overlapping method is presented to compute composed spatial relations. A few typical examples further explore the detailed processing tasks and performance. Finally, an application case is illustrated and various aspects of the approach are discussed.","","Electronic:978-1-4244-8517-8; POD:978-1-4244-8514-7","10.1109/IITA-GRS.2010.5603125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603125","approximate modelling;gazetteer;natural language;place name;spatial relation","Cognition;Computational modeling;Computer science;Context modeling;Geospatial analysis;Google;Natural languages","cognitive systems;geographic information systems;inference mechanisms;information retrieval;natural language processing","cognitive region;contextual spatial relation;functional region;gazetteer;geographical information system;geographically specific information;geospatial location;layer overlapping method;qualitative spatial relation;spatial modelling;thematic region;vague place name","","0","","22","","","28-31 Aug. 2010","","IEEE","IEEE Conference Publications"
"A probabilistic approach to identifying technology vacuum: GTM-based patent map","C. Son; Y. Suh; Y. Lee; Y. Park","Department of Industrial Engineering, School of Engineering, Seoul National University, Seoul, Korea","PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH","20101014","2010","","","1","8","A patent map has long been considered as a useful tool to identify technology vacuum defined as an unexplored area of technologies that may deserve intensive investigation for future new technology development. However, previous studies for identifying technology vacuum on the patent map have been subjected to intuitive and manual identification of technology vacuum. In this context, this paper proposes a generative topographic mapping (GTM)-based patent map which aims to identify technology vacuum automatically. Since GTM is a probabilistic approach to map a low-dimensional latent space onto the multidimensional data space and vice versa, it contributes to the automatic identification of technology vacuum. This study consists of three stages. Firstly, text mining is executed to transform patent documents into keyword vectors as structured data. Secondly, the GTM is employed to develop the patent map with extracted keyword vectors and discover patent vacuums which are expressed as blank areas in the map. Lastly, technology vacuums are identified by inversely mapping patent vacuums in latent space into new vectors in data space. The procedure of the proposed approach is described in detail by employing a patent database.","2159-5100;21595100","Electronic:978-1-890843-21-2; POD:978-1-4244-8203-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602088","","Patents;Principal component analysis;Probabilistic logic;Space technology;Text mining;Vacuum technology","data mining;information retrieval;probability;text analysis","GTM based patent map;automatic identification;data structure;generative topographic mapping;keyword vector extraction;patent analysis;patent database;patent document;probabilistic approach;technology vacuum;text mining","","0","","33","","","18-22 July 2010","","IEEE","IEEE Conference Publications"
"Study of real time processing for geostationary satellite data applied to seismologic monitoring","Weidong Li; Xinjian Shan","Spatial Information Engineering Institute, Henan University of Technology, Zhengzhou 450001, China","2010 Second IITA International Conference on Geoscience and Remote Sensing","20101014","2010","1","","227","230","A real time auto-processing system of geostationary satellite data has been developed based on the integration of Windows NT Service and socket application, its functions include FY2C satellite data receiving, archiving, querying and issuing. A massive cloud-eliminated database and a suited imagery info database have been set up without a large number of manual operations (such as countrywide nighttime surface brightness temperature images, synthetic color daytime images and cloudless surface brightness temperature images by 5 days), IR-brightness temperature tracing for any monitored area has been implemented through the system. Through the development of this system, a lot of practical technology foundations and methods are provided for earthquake thermal infrared research.","","Electronic:978-1-4244-8517-8; POD:978-1-4244-8514-7","10.1109/IITA-GRS.2010.5603190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603190","data processing;geostationary satellite;infrared remote sensing;real time","Brightness temperature;Databases;Earthquakes;Monitoring;Real time systems;Satellite broadcasting;Satellites","data handling;database management systems;earthquakes;geophysical signal processing;information retrieval;information storage;infrared imaging;remote sensing;seismology","FY2C satellite data archiving;FY2C satellite data issuing;FY2C satellite data querying;FY2C satellite data receiving;IR brightness temperature tracing;Windows NT Service;cloud eliminated database;earthquake thermal infrared research;geostationary satellite data;real time autoprocessing system;real time data processing;seismologic monitoring;suited imagery information database","","0","","8","","","28-31 Aug. 2010","","IEEE","IEEE Conference Publications"
"I/O characterization on a parallel file system","S. Narayan; J. A. Chandy","Department of Electrical and Computer Engineering, University of Connecticut, 371 Fairfield Way U-2157, Storrs, 06269-2157, USA","Performance Evaluation of Computer and Telecommunication Systems (SPECTS), 2010 International Symposium on","20101007","2010","","","133","140","In this paper we present a study of I/O access patterns of scientific and general applications on a parallel file system. Understanding I/O access patterns is an essential condition to effectively designing a file system. Supercomputing applications running on these parallel systems make extensive use of parallel file systems taking advantage of faster data access by requesting information from multiple nodes simultaneously. However, parallel file systems can become a bottleneck if the file distribution parameters do not fit the access scheme of the applications. In our work, we examine a variety of such applications, providing measurement of inter-arrival times, I/O request size and burstiness demanded from a parallel file system. Our tests were conducted on the open source PVFS parallel file system with different configurations of metadata servers and I/O nodes. Among the findings are that the standard assumption of Poisson or random interarrival times is not justified and that access sizes are smaller than would be expected for a parallel application.","","Electronic:978-1-56555-341-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588965","","Benchmark testing;Checkpointing;Libraries;Object oriented modeling;Prefetching;Web server","information retrieval;input-output programs;meta data;parallel processing;public domain software","I/O access pattern;I/O node;I/O request size;Poisson arrival time;burstiness demand;file distribution parameter;interarrival time;metadata server;open source PVFS parallel file system;parallel file system;random inter arrival time;supercomputing","","2","","37","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Study on the Comprehensive Network-Based Service System in the Tourism Destinations for Independent Tourists","L. Tao; J. g. Gao; X. l. Min; Z. Mo","Sch. of Manage., Guangdong Univ. of Technol., Guangzhou, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","4624","4627","Tourists have been the principal parts in the value chain in tourism industry at all times. In e-tourism era, on purpose of information integration and resource optimization, which one can be the appropriate candidate to serve the ascending population of independent tourists? This paper identifies the important role of the comprehensive network-based service system in the tourism destination, sheds lights on its development model and framework from the review of relevant research and practice. Results in this study reveal that the travel service provider should dominate the e-tourism development. The service system should aim to the independent tourists' need in the aspects of information acquirement, deal conclusion, travel experiencing and its sharing, be built on the complementary ground of the Internet and mobile networks, and bring the visitors into the publication of spatio-temporal information of fine granularity. Findings of the study are expected to assist travel service providers to understand current e-tourism in China and to support their planning for future e-commerce development in China.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590602","e-commerce;independent tourist component;mobile commerce;network-based service system;tourism destination","Business;Computers;Economics;Mobile communication;Mobile computing;Presses;Travel services","electronic commerce;information resources;information retrieval;mobile computing;travel industry","China e-commerce development;comprehensive network-based service system;e-tourism development;e-tourism era;independent tourist;information acquirement;information integration;mobile network;resource optimization;spatio-temporal information;tourism destination;tourism industry;travel service provider;value chain","","0","","14","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"One-Vs-All Training of Prototype Classifier for Pattern Classification and Retrieval","C. L. Liu","Nat. Lab. of Pattern Recognition, Chinese Acad. of Sci., Beijing, China","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3328","3331","Prototype classifiers trained with multi-class classification objective are inferior in pattern retrieval and outlier rejection. To improve the binary classification (detection, verification, retrieval, outlier rejection) performance of prototype classifiers, we propose a one-vs-all training method, which enriches each prototype as a binary discriminant function with a local threshold, and optimizes both the prototype vectors and the thresholds on training data using a binary classification objective, the cross-entropy (CE). Experimental results on two OCR datasets show that prototype classifiers trained by the one-vs-all method is superior in both multi-class classification and binary classification.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597516","","Accuracy;Character recognition;Error analysis;Measurement;Prototypes;Training","image classification;information retrieval;pattern classification","OCR datasets;binary classification;binary discriminant function;cross-entropy;multiclass classification;one-vs-all training;pattern classification;pattern retrieval","","3","","13","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Identification of residential load profile in the Smart Grid context","R. A. S. Fernandes; I. N. Silva; M. Oleskovicz","Department of Electrical Engineering, USP/EESC/SEL, CP 359, CEP 13566-590, S&#x00E3;o Carlos, Brazil","IEEE PES General Meeting","20100930","2010","","","1","6","This work presents an automatic method for identification of residential load profile in the Smart Grid context. Hence, in this research were used client/server software interfaces to transmit and receive data through the Internet. In this case, the residential consumers and utility were represented by client and server software, respectively. However, to consider all the stages of this method, a database was created to store fictitious data related to consumer measurements. From these data, the utility software was able to furnish information about consumer's load profile and use this information to make decisions. The results were obtained using an experimental workbench that contains residential loads, a configurable power supply and an energy analyzer. It is show in an experimental way some benefits that can be achieved with the introduction of Smart Grid concept on distribution systems.","1932-5517;19325517","Electronic:978-1-4244-6551-4; POD:978-1-4244-6549-1; USB:978-1-4244-8357-0","10.1109/PES.2010.5589653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5589653","Artificial neural networks;harmonic components;residential loads profile;smart grid","","client-server systems;database management systems;information retrieval;power engineering computing;smart power grids;user interfaces","Internet;automatic method;client-server software interfaces;configurable power supply;data storage;distribution systems;energy analyzer;residential consumers;residential load profile;smart grid context","","9","","13","","","25-29 July 2010","","IEEE","IEEE Conference Publications"
"Mining Wikipedia Knowledge to improve document indexing and classification","R. K. Ayyasamy; B. Tahayna; S. Alhashmi; S. Eu-gene; S. Egerton","Monash University, Sunway Campus, Malaysia","10th International Conference on Information Science, Signal Processing and their Applications (ISSPA 2010)","20101018","2010","","","806","809","Weblogs are an important source of information that requires automatic techniques to categorize them into ‚Äútopic-based‚Äù content, to facilitate their future browsing and retrieval. In this paper we propose and illustrate the effectiveness of a new tf. idf measure. The proposed Conf.idf, Catf.idf measures are solely based on the mapping of terms-to-concepts-to-categories (TCONCAT) method that utilizes Wikipedia. The Knowledge base-Wikipedia is considered as a large scale Web encyclopaedia, that has high-quality and huge number of articles and categorical indexes. Using this system, our proposed framework consists of two stages to solve weblog classification problem. The first stage is to find out the terms belonging to a unique concept (article), as well as to disambiguate the terms belonging to more than one concept. The second stage is the determination of the categories to which these found concepts belong to. Experimental result confirms that, proposed system can distinguish the weblogs that belongs to more than one category efficiently and has a better performance and success than the traditional statistical Natural Language Processing-NLP approaches.","","Electronic:978-1-4244-7167-6; POD:978-1-4244-7165-2","10.1109/ISSPA.2010.5605508","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5605508","Concetps;N-grams;Text Classification;Wikipedia","Biological system modeling;Blogs;Educational institutions;Indexing;Kernel;Knowledge based systems;Organizations","Internet;Web sites;data mining;document handling;indexing;information retrieval;pattern classification","TCONCAT;Web encyclopaedia;document classification improvement;document indexing improvement;mining wikipedia knowledge;statistical natural language processing;terms-to-concepts-to-categories;weblog classification problem","","2","1","12","","","10-13 May 2010","","IEEE","IEEE Conference Publications"
"Co-construction of ontology-based knowledge base through the Web: Theory and practice","K. Zhang; Q. Fei","PLA University of Foreign Languages, Luoyang, Henan, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","6","Ontology-based knowledge base plays an increasingly important role in improving the precision and recall rate of a retrieval system. Based on Distributed Learning theory, a novel approach for the co-construction of ontology-based knowledge base is explored. Making use of the platform set up for the co-construction and sharing of domain-specific knowledge through the Web, we constructed an ontology-based knowledge base of airborne radar field. This study is expected to contribute to the effective improvement of precision and recall rate of information retrieval in the airborne radar field. Hopefully, the mode we designed and adopted for the co-construction and sharing of domain-specific knowledge base could be enlightening for other similar studies.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587804","Distributed Learning;Ontology-based knowledge base;Web-based co-construction;airborne radar ontology","Encyclopedias;Monitoring;Servers;Variable speed drives","Internet;airborne radar;information retrieval;ontologies (artificial intelligence)","Web;airborne radar field;distributed learning theory;information retrieval;ontology-based knowledge base","","0","","10","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research on Broken Mappings Detecting Method Based on Fuzzy Aggregation Operators in Deep Web Integration Environment","A. Li; J. Miao; Y. Jia","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","125","128","The deep web integration system employs a set of semantic mappings between the mediated schema and the schemas of web data sources. In this dynamic environment, sources often undergo changes that invalidate the mappings. Such continuous monitoring is extremely labor intensive, and poses a key bottleneck to the widespread deployment of web data integration systems in practice. The paper describes DBMFR (Detecting Broken Mappings Based on Fuzzy Reasoning) an automatic solution to detecting broken mappings. Fuzzy aggregation operators are leveraged to calculate the score, which implies whether the mapping is broken. The paper provides a new fuzzy reasoning algorithm based on fuzzy aggregation operators. Experiments over real-world sources demonstrate the effectiveness of our fuzzy-based approach over existing solutions, as well as the utility of our improvements.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591131","Deep Web;Fuzzy Aggregation Operators;Mapping Maintenance","Accuracy;Books;Databases;Maintenance engineering;Marketing and sales;Prediction algorithms;Training","Internet;fuzzy reasoning;information retrieval systems;information services","Web data integration system;broken mappings detecting method;continuous monitoring;data sources;deep Web integration environment;fuzzy aggregation operators;fuzzy reasoning algorithm;fuzzy-based approach;real-world sources;semantic mappings;widespread deployment","","1","","16","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Automated Inference of Socio-Cultural Information from Natural Language Conversations","R. Scherl; D. Inclezan; M. Gelfond","Dept. of Comput. Sci. & Software Eng., Monmouth Univ., West Long Branch, NJ, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","480","487","We discuss a methodology for extracting socio-cultural information from transcripts of natural language conversations. The methodology is applicable to a wide variety of languages. We use Russian and Tamil for illustration. The extracted socio-cultural information pertains to the nature of the relationship between the participants in the interaction. We concentrate on the information implicit in the use of terms that refer to people (pronouns, terms of address etc.). We have constructed an AnsProlog theory of the use of these language indicators in Russian and also in Tamil. It is this theory that looks at the usages of these indicators in the conversation in question and produces information about the relationships of the participants in the conversation.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591304","","Cognition;Construction industry;Context;Data mining;Natural languages;Pragmatics;Speech","inference mechanisms;information retrieval;natural language processing;socio-economic effects","AnsProlog theory;Russian;Tamil;natural language conversations;socio-cultural information extraction","","0","","35","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Colocation as a Service: Strategic and Operational Services for Cloud Colocation","V. Ishakian; R. Sweha; J. Londono; A. Bestavros","Comput. Sci. Dept, Boston Univ., Boston, MA, USA","2010 Ninth IEEE International Symposium on Network Computing and Applications","20101007","2010","","","76","83","By colocating with other tenants of an Infrastructure as a Service (IaaS) offering, IaaS users could reap significant cost savings by judiciously sharing their use of the fixed-size instances offered by IaaS providers. This paper presents the blueprints of a Colocation as a Service (CaaS) framework. CaaS strategic services identify coalitions of self-interested users that would benefit from colocation on shared instances. CaaS operational services provide the information necessary for, and carry out the reconfigurations mandated by strategic services. CaaS could be incorporated into an IaaS offering by providers; it could be implemented as a value-added proposition by IaaS resellers; or it could be directly leveraged in a peer-to-peer fashion by IaaS users. To establish the practicality of such offerings, this paper presents XCS - a prototype implementation of CaaS on top of the Xen hypervisor. XCS makes specific choices with respect to the various elements of the CaaS framework: it implements strategic services based on a game-theoretic formulation of colocation; it features novel concurrent migration heuristics which are shown to be efficient; and it offers monitoring and accounting services at both the hypervisor and VM layers. Extensive experimental results obtained by running PlanetLab trace-driven workloads on the XCS prototype confirm the premise of CaaS - by demonstrating the efficiency and scalability of XCS, and by quantifying the potential cost savings accrued through the use of XCS.","","Electronic:978-1-4244-7627-5; POD:978-1-4244-7628-2","10.1109/NCA.2010.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598227","","Bandwidth;Engines;Games;Memory management;Monitoring;Prototypes;Resource management","Internet;game theory;information resources;information retrieval;peer-to-peer computing","CaaS;IaaS provider;PlanetLab trace driven workload;XCS;Xen hypervisor;cloud colocation;colocation as a service;game theoretic formulation;infrastructure as a service;operational service;peer-to-peer fashion;self- interested users;strategic service;value- added proposition","","7","1","36","","","15-17 July 2010","","IEEE","IEEE Conference Publications"
"Feature selection for Chinese Text Categorization based on improved particle swarm optimization","Y. Jin; W. Xiong; C. Wang","Institute of Chinese Information Processing, Beijing Normal University 100875, CHINA","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","6","Feature selection is an important preprocessing step of Chinese Text Categorization, which reduces the high dimension and keeps the reduced results comprehensible compared to feature extraction. A novel criterion to filter features coarsely is proposed, which integrating the superiorities of term frequency-inverse document frequency as inner-class measure and CHI-square as inter-class, and a new feature selection method for Chinese text categorization based on swarm intelligence is presented, which using improved particle swarm optimization to select features fine on the results of coarse grain filtering, and utilizing support vector machine to evaluate feature subsets and taking the evaluations as the fitness of particles. The experiments on Fudan University Chinese Text Classification Corpus show a higher classification accuracy obtained by using the new criterion for features filtering and an effective feature reduction ratio attained by utilizing the novel FS method for Chinese text categorization.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587844","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587844","Feature selection;particle swarm optimization;support vector machine;text categorization;text mining","Art;Computers;Educational institutions;Military computing;Support vector machines","document handling;information retrieval;natural language processing;particle swarm optimisation;support vector machines;text analysis","CHI-square;Chinese text categorization;coarse grain filtering;feature extraction;feature selection method;frequency-inverse document frequency;particle swarm optimization;support vector machine;swarm intelligence","","3","","17","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Development of tourist information search behavior model: The case of Thailand","T. Erawan; D. Krairit; V. Esichaikul","Asian Institute of Technology, School of Management, Pathumthani, Thailand","PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH","20101014","2010","","","1","7","Information search is an important part in most consumers' buying decisions. For Thailand whose main revenues rely partly on tourism industry, one of a top industries which is significantly affected by an emergence of the Internet. Understanding tourists' information search behavior could provide useful information for both government and tourism-related businesses to plan their marketing communication and distribution strategies. The main contribution of this study is to explore and refine determinants of external information search behavior in the tourism context, the context which has not been fully explored in the literatures, and the features that could be used to characterize tourists' external information search behavior. This study utilized a so-called ‚ÄúThree-pronged approach‚Äù, an approach to cross validate among the result from literature review, expert interviews, and an exploratory field study in order to confirm and propose a reliable conceptual framework. Findings from the three-pronged approach suggested 11 components as determinants of external information search behavior and 4 features that could be used to define tourists' external information search behavior itself. Six new variables which did not exist in the literatures as determinants of external information search behavior were introduced with satisfactory validity and reliability levels.","2159-5100;21595100","Electronic:978-1-890843-21-2; POD:978-1-4244-8203-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603349","","Automobiles;Context;Data mining;Government;Industries;Internet;Interviews","Internet;decision making;information retrieval;marketing;travel industry","Internet;Thailand;consumer buying decision;marketing communication;marketing distribution;three pronged approach;tourism industry;tourist information search behavior model","","0","","45","","","18-22 July 2010","","IEEE","IEEE Conference Publications"
"Enforcing SLAs in Scientific Clouds","O. Niehorster; A. Brinkmann; G. Fels; J. Kruger; J. Simon","Paderborn Center for Parallel Comput., Univ. Paderborn, Paderborn, Germany","2010 IEEE International Conference on Cluster Computing","20101014","2010","","","178","187","Software as a Service (SaaS) providers enable the on-demand use of software, which is an intriguing concept for business and scientific applications. Typically, service level agreements (SLAs) are specified between the provider and the user, defining the required quality of service (QoS). Today SLA aware solutions only exist for business applications. We present a general SaaS architecture for scientific software that offers an easy-to-use web interface. Scientists define their problem description, the QoS requirements and can access the results through this portal. Our algorithms autonomously test the feasibility of the SLA and, if accepted, guarantee its fulfillment. This approach is independent of the underlying cloud infrastructure and successfully deals with performance fluctuations of cloud instances. Experiments are done with a scientific application in private and public clouds and we also present the implementation of a high-performance computing (HPC) cloud dedicated for scientific applications.","1552-5244;15525244","Electronic:978-0-7695-4220-1; POD:978-1-4244-8373-0","10.1109/CLUSTER.2010.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600308","","Clouds;Computer architecture;Estimation;Quality of service;Servers;Software;Virtual machine monitors","Web services;information retrieval;portals;quality of service;scientific information systems;software architecture","SLA;SaaS architecture;Web interface;business application;cloud infrastructure;high performance computing cloud;performance fluctuation;private cloud;public cloud;quality of service;scientific application;scientific cloud;scientific software;service level agreement;software as a service","","11","","20","","","20-24 Sept. 2010","","IEEE","IEEE Conference Publications"
"Design and Implementation of a Language for Web Exploring and Mashup","M. Ito; M. Suzuki","Dept. of Math. & Comput. Sci., Shimane Univ., Matsue, Japan","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","20100930","2010","","","503","508","Tools for information searching on the Internet efficiently and easily have become more important. It has become difficult to get intended information because data available on the Internet are going enormous. A technique called Mashup has become one of the most important technologies on the Internet. We propose a new language that can both explore Web information and do Mashup efficiently and easily. Features of the language include information searching utilizing the structure of html such as tables, links, and so on, and the ability to mashup information on general web pages without specific APIs from providers.","","Electronic:978-0-7695-4147-1; POD:978-1-4244-8198-9","10.1109/ICIS.2010.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590981","Mashup;Web exploring;html document;semi-structured document","Computers;Conferences;Information science","Internet;hypermedia markup languages;information resources;information retrieval","Internet;Mashup;Web exploring;Web information;html;information searching;web pages","","1","","17","","","18-20 Aug. 2010","","IEEE","IEEE Conference Publications"
"An ontology-based semantic retrieval model for Uyghur search engine","B. Ma; Y. Yang; X. Zhou; J. Zhou","Research Center for Multilingual Information, Technology, Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi, Xinjiang Province, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","191","196","In recent years, semantic search has been successfully used for information retrieval, however, it is still in the early stage, and there is not semantic search engine for minorities in China. In this paper, we propose a semantic retrieval model which is comprised of resources collection, semantic annotation, query analysis and results ranking. For semantic annotation, we use domain ontology and two bilingual dictionaries to extract keywords for annotation. For query analysis, we present a method which combines lexical relationship and semantic relationship to analyse user's query. And for results ranking, we propose a modulative method that ranks results based on how predictable a result might be for users, which is a blend of semantic and information-theoretic techniques. The preliminary experimental results show the capability of the proposed model to boost the precision and recall rates of webpage searching.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607456","Uyghur;ontology;retrieval model;semantic relationship","Analytical models;Dictionaries;Indexes;Ontologies;Search engines;Semantics;Web pages","information retrieval;ontologies (artificial intelligence);search engines;semantic Web","Uyghur search engine;bilingual dictionaries;information retrieval;information theoretic techniques;keyword extraction;lexical relationship;ontology based semantic retrieval model;query analysis;resources collection;semantic annotation;semantic relationship;webpage searching","","1","","9","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"The Effects of Documents Lineage on Use of Explanation in Document-Driven DSS","Z. Chen; H. Dong","State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China","2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics","20100930","2010","1","","243","248","In document-driven DSS, the decisions are both based on the inheritance among the documents and the acceptance of advices for users. Research in the field of DSS has shown that providing explanations may improve acceptance of decision makers. The most important part of explanations in document-driven DSS lies in tracing the contents and the classification of interrelated documents. But current document-driven DSS is lack of a mechanism to record the citation and cluster the related documents. This paper tries to find out the trace routes among documents to improve the explanations. First, a document lineage model is established to present the citation and delivery mechanism in documents. Second, the document DNA is used to build the routes of documents transferences. Third, the whole lineage in documents is integrated by routes. Finally, a system frame for explanations mechanism in document-driven DSS was described.","","Electronic:978-0-7695-4151-8; POD:978-1-4244-7869-9","10.1109/IHMSC.2010.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590681","Document lineage;Document-driven DSS;Explanation","Blood;Computers;DNA;Decision making;Decision support systems;Face","data mining;decision making;decision support systems;information retrieval;pattern clustering;text analysis","decision making;decision support system;document driven DSS;document lineage model;document transference","","0","","12","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"Study and practice for the strategy of higher education reform based on online course","H. Lihua; C. Ying; D. Juncui","College of Information Science and Technology, Shijiazhuang Tiedao University, Shijiazhuang, China","2010 5th International Conference on Computer Science & Education","20100930","2010","","","1652","1656","In this day, online course is an efficient way to help teacher changes teaching mode and it provides new ideas and methods for higher education reform. However, the effect of learning which relies solely on the online course is not very good, how can the using of online course be integrated efficiently into the daily classroom teaching in the colleges and universities? The key is the suitable instructional design and implementation of appropriate strategies and evaluation means for this hybrid learning. Taking the course Design and production of multimedia courseware which is taught by the author as an example, the paper illustrates the whole process of teaching reform of this course from the instructional design around learning tasks and learning activities, curriculum implementation and evaluation strategy. The results of questionnaire survey show that the teaching pattern based on hybrid learning can improve the learner's information accomplishment and the ability of knowledge application besides facilitating students to access knowledge actively. On the whole this practice has obtained some good effects so some experiences can be provided for other courses.","","Electronic:978-1-4244-6005-2; POD:978-1-4244-6002-1","10.1109/ICCSE.2010.5593608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593608","Higher education reform;Hybrid learning;Learning activities;Learning tasks;Online Courses","Collaboration;Courseware;Educational institutions;Multimedia communication;Production","Internet;computer science education;courseware;educational courses;further education;information retrieval;multimedia computing;teaching","daily classroom teaching;higher education reform;hybrid learning;instructional design;knowledge access;multimedia courseware;online course;questionnaire survey;teaching pattern","","0","","7","","","24-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Opinion mining of product reviews based on semantic role labeling","L. Ji; H. Shi; M. Li; M. Cai; P. Feng","School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China","2010 5th International Conference on Computer Science & Education","20100930","2010","","","1450","1453","Online product reviews are becoming increasingly available. Generally, potential customers usually wade through a lot of online reviews in order to make an informed decision. We tackle the problem of semantic understanding for consumer reviews based on semantic role labeling, which implements shallow semantic analysis. In this paper, a sentiment mining and retrieval system was proposed, which mines useful knowledge from product reviews. Furthermore, the sentiment orientation and comparison between positive and negative evaluation are presented visually in the system. Experimental results on a real-world data set have shown the system is both feasible and effective.","","Electronic:978-1-4244-6005-2; POD:978-1-4244-6002-1","10.1109/ICCSE.2010.5593740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593740","opinion mining;review analysis;semantic role labeling","Business;Cameras;Data mining;Feature extraction;Labeling;Natural language processing;Semantics","consumer behaviour;data mining;information retrieval","consumer review;knowledge mining;online product review;opinion mining;retrieval system;semantic role labeling;semantic understanding;sentiment mining;shallow semantic analysis","","1","","9","","","24-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Exploring the concepts of visualization, clustering, and re-finding in Web information gathering tasks: A survey","A. Alhenshiri; C. Watters; M. Shepherd","Dalhousie University","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","45","52","The paper explores research concerned with improving aspects of the Web information gathering task. This type of task involves finding source of information on the Web, comparing different types of information, and re-finding information for reasoning and decision making. Research in Web information retrieval has explored visualization, clustering, and re-finding for improving the effectiveness of Web search tools. Investigations concerning aspects of the Web information gathering task are discussed in this paper. In addition, the paper provides practical research recommendations for improving the design of Web information gathering tools.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607479","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607479","","Data visualization;Decision making;Navigation;Search engines;Visualization;Web search","Internet;data visualisation;information retrieval;pattern clustering","Web information gathering tasks;Web information retrieval;Web search tools;clustering concept;decision making;refinding concept;visualization concept","","1","","57","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"A High-Dimensional Access Method for Approximated Similarity Search in Text Mining","F. Artigas-Fuentes; R. Gil-Garcia; J. M. Badia-Contelles","CERPAMID, Univ. de Oriente, Santiago de Cuba, Cuba","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3155","3158","In this paper, a new access method for very high-dimensional data space is proposed. The method uses a graph structure and pivots for indexing objects, such as documents in text mining. It also applies a simple search algorithm that uses distance or similarity based functions in order to obtain the k-nearest neighbors for novel query objects. This method shows a good selectivity over very-high dimensional data spaces, and a better performance than other state-of-the-art methods. Although it is a probabilistic method, it shows a low error rate. The method is evaluated on data sets from the well-known collection Reuters corpus version 1 (RCV1-v2) and dealing with thousands of dimensions.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597302","access method;approximated search;high-dimensional spaces;similarity search;text mining","Artificial neural networks;Indexing;Search problems;Text mining;Training","data mining;graph theory;indexing;information retrieval;probability;text analysis","distance based function;document indexing;graph structure;high-dimensional access method;k-nearest neighbor;object indexing;probabilistic method;similarity based function;similarity search;text mining;very high-dimensional data space","","1","","6","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Expansion of Digital Reading Function in Library Service","B. h. Hai; L. k. Zhao","Libr. of Hebei Univ. of Eng., Handan, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","4025","4027","This article briefly expounds the conception of ‚ÄúDigital reading‚Äù,illustrates the development trends of ‚ÄúDigital reading‚Äùand how to achieve it. ‚ÄúDigital reading‚Äù is changing the trachtional model of library services. In the light of how to deal with ‚Äúdigital reading‚Äùand expand the service functions for the reader. This article discuss from digital information service, online bibliographic query, online information transvrission, online education, development of virtual resources and so on.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1010","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591585","digital reading;library;library service","Book reviews;Business;Collaboration;Education;Internet;Libraries;Presses","digital libraries;information retrieval","digital information service;digital reading function;library service;online bibliographic query;online education;online information transmission;virtual resource","","0","","7","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Authority vs Affinity: Modeling User Intent in Expert Finding","S. Budalakoti; K. S. Barber","Lab. for Intell. Processes & Syst., Univ. of Texas at Austin, Austin, TX, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","371","378","This paper considers the problem of recommending experts for a question. The problem of expert finding has been investigated in the past, within the context of information retrieval, where the focus has been on measuring expert authority. However, we treat the problem as a recommendation problem in the context of social search, that is, expert recommendations are personalized for a questioner based on his/her history. The intuition is that questioners look not only for authoritative responders, but for a combination of authority and personal trust or affinity. The significance of these factors depends on user intent in asking the question, and varies with each question, and with questioner personality. An iterative algorithm is proposed to model user intent for a question in terms of whether they are looking for authoritative experts, or individuals in their social networks, and an expert recommendation algorithm based on it is tested on data crawled from the Yahoo! Answers website.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591255","Expert Finding;Markov Chains;Question Answer Forums;Social Networks","Context;Equations;Estimation;Iterative methods;Markov processes;Mathematical model;Social network services","human computer interaction;information retrieval;iterative methods;recommender systems;social networking (online)","Yahoo! Answers Web site;expert authority;expert finding;expert recommendation algorithm;information retrieval;iterative algorithm;recommendation problem;social networks;user intent modeling","","1","","15","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Long-term prediction of industrial furnace by Extended Sequential Prediction method of LOM","M. Ogawa; Y. Yeh; S. Kawanari; H. Ogai","Information Production Systems Research Center, Waseda University, Fukuoka, Japan","Proceedings of SICE Annual Conference 2010","20101014","2010","","","1490","1493","Recently, attention has been drawn by the local modeling techniques of a new idea called ‚ÄúJust-In-Time (JIT) modeling‚Äù or ‚ÄúLazy Learning‚Äù. To apply ‚ÄúJIT modeling‚Äù to a large amount of database online, ‚ÄúLarge-scale database-based Online Modeling (LOM)‚Äù has been proposed. LOM is such a technique that makes the retrieval of ‚Äúneighboring‚Äù data more efficient by using ‚Äústepwise selection‚Äù and quantization. This paper reports an Extended Sequential Prediction (ESP) method of LOM with the local regression model. The ESP method is able to predict process variables over a long period by modeling the operator and the plant based on LOM, the approach is to repeat a process that predicts the process variables of the next step by using the predicted variables of the previous step. The method is applied to a dynamic industrial furnace with several deeply-intertwined physical phenomena; practical effectiveness of the method is verified. As a result, the method has predicted the process variables with satisfactory accuracy.","","DVD:978-4-907764-35-7; Electronic:978-4-907764-36-4; POD:978-1-4244-7642-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602285","ESP;JIT modeling;LOM;industrial furnace;operation support;sequential prediction","Accuracy;Data models;Databases;Furnaces;Input variables;Mathematical model;Predictive models","flow production systems;furnaces;information retrieval;just-in-time;learning (artificial intelligence);regression analysis","LOM;data retrieval;extended sequential prediction;industrial furnace;just in time;large scale database based online model;lazy learning;regression model","","0","","7","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Development of Retrieval Methods for RESTful Web Services Using Semantic Technologies","S. J. Cha; Y. J. Choi; K. C. Lee","Dept. of Comput. Eng., Chungnam Nat. Univ., Daejeon, South Korea","2010 IEEE/ACIS 9th International Conference on Computer and Information Science","20100930","2010","","","912","917","With the advent of Web 2.0, RESTful web services are becoming increasingly popular to emphasize the web as platform. There are already many RESTful web services and the number of services is increasing rapidly. Thus, it can be difficult to find specific services using keyword based retrieval. To solve this problem, a retrieval method was developed using semantic technologies based on RESTful web services. In order to accomplish this, first the system structure was defined and the description style was modeled based on the integrated search system for OpenAPIs; then semantic markup (tagging, semantic annotation) was added to the HTML description pages. Next, the RDF document was extracted from the HTML and stored in a service repository. Based on the keywords that are extended through ontology, the developed system provides more filtered and extended results than similarity based keyword searching systems.","","Electronic:978-0-7695-4147-1; POD:978-1-4244-8198-9","10.1109/ICIS.2010.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591055","OpenAPI;RESTful web services;retrieval method;semantic","HTML;Ontologies;Resource description framework;Semantics;Tagging;Web services;XML","Web services;feature extraction;hypermedia markup languages;information retrieval;integrated software;ontologies (artificial intelligence);semantic Web;software architecture;text analysis","HTML description page;OpenAPI;RDF document;RESTful Web service;Web 2.0;description style;integrated search system;keyword based retrieval;retrieval method;semantic markup;semantic technology;service repository;system structure","","2","","10","","","18-20 Aug. 2010","","IEEE","IEEE Conference Publications"
"Estimating Evapotranspiration Using Triangle Method with Topographic Correction from MODIS Data in Taihu Basin, China","X. Zhao; Y. Liu; D. Zhao; J. Peng","State Key Lab. of Lake Sci. & Environ., CAS, Nanjing, China","2010 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM)","20101014","2010","","","1","5","Many water resources and agricultural applications require the knowledge of evapotranspiration (ET) over a range of spatial and temporal scales. Satellite remote sensing provides an unprecedented spatial coverage of land surface and atmospheric data that are logistically and economically impossible to obtain through ground based observation networks. The surface temperature-normalized difference vegetation index (Ts-NDVI) triangle method based on remote sensing datasets was widely applied to estimate regional ET. However, little research focused on influence of topography on triangle method application in complex topographic areas. To retrieve more accurate ET, topographic correction should be employed in mountainous areas. In this study, we estimate ET by triangle method with topographic correction from MODIS datasets in Taihu Basin, China. The evaporative fraction (EF), defined as the ratio of ET and available radiant energy, was estimated by the triangle method with topographic correction. And then, spatially distributed net radiation (Rn) maps were retrieved as an estimate of available energy to get both the spatial and temporal distribution maps of ET for clear sky days. Our results indicate that topographic correction improve to determine quantitatively the dry and wet edges of Ts-NDVI triangle space in Taihu Basin, and the EF value in mountainous area become more reasonable than before correction. The Rn retrieved is in good agreement with ground-based measurements with a correlation of 0.80 on average. The ET estimated, was validated by evaporation pan measurements in Taihu Lake station, showed consistent pattern compare to measurements.","2161-9646;21619646","Electronic:978-1-4244-3707-8; POD:978-1-4244-3708-5","10.1109/WICOM.2010.5601040","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601040","","Estimation;Land surface;Land surface temperature;MODIS;Remote sensing;Satellites;Surface topography","evaporation;information retrieval;remote sensing;terrain mapping;topography (Earth);transpiration;water resources","China;ET;MODIS data;Ts-NDVI;evaporative fraction;evapotranspiration estimation;satellite remote sensing;spatially distributed net radiation;surface temperature-normalized difference vegetation index;topographic correction;triangle method;water resources","","0","","18","","","23-25 Sept. 2010","","IEEE","IEEE Conference Publications"
"A Comparison of Stylometric and Lexical Features for Web Genre Classification and Emotion Classification in Blogs","E. Lex; A. Juffinger; M. Granitzer","Know-Center GmbH, Graz, Austria","2010 Workshops on Database and Expert Systems Applications","20100930","2010","","","10","14","In the blogosphere, the amount of digital content is expanding and for search engines, new challenges have been imposed. Due to the changing information need, automatic methods are needed to support blog search users to filter information by different facets. In our work, we aim to support blog search with genre and facet information. Since we focus on the news genre, our approach is to classify blogs into news versus rest. Also, we assess the emotionality facet in news related blogs to enable users to identify people's feelings towards specific events. Our approach is to evaluate the performance of text classifiers with lexical and stylometric features to determine the best performing combination for our tasks. Our experiments on a subset of the TREC Blogs08 dataset reveal that classifiers trained on lexical features perform consistently better than classifiers trained on the best stylometric features.","1529-4188;15294188","Electronic:978-0-7695-4174-7; POD:978-1-4244-8049-4","10.1109/DEXA.2010.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591976","Data Mining;Document Classification;Features","Accuracy;Blogs;Classification algorithms;Feature extraction;Mutual information;Support vector machines;Training","Internet;Web sites;classification;data mining;information retrieval;search engines;text analysis","TREC Blogs08 dataset;Web genre classification;blog search;blogosphere;data mining;document classification;emotion classification;emotionality facet;lexical features;news genre;search engines;stylometric features;text classifiers","","1","","18","","","Aug. 30 2010-Sept. 3 2010","","IEEE","IEEE Conference Publications"
"Monitoring the key technology trends by combining chance discovery and survival analysis: Study on solar cell patent documents","M. Y. Wang; T. F. Chiu","Department of Bio-industry and Agribusiness Administration, National Chiayi University, Chiayi, Taiwan, R.O.C.","PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH","20101014","2010","","","1","7","Patents provide objective and rich information on technology, so it becomes a valuable source to monitor. The fact that the technological information in patents is almost stored in text format makes the monitoring task a hard work. The purpose of this study is to introduce a new approach which combines chance discovery, one of a text mining techniques, and survival analysis to explore the emergence of technology terms and to identify their potential. This study applies the chance discovery to extract technological terms which are important but occur infrequently. Moreover, this study conducts longitudinal analysis by employing survival analysis on the occurrence time for the extracted technological terms. The hazard rate is used as an indicator to identify the potential of the terms. This study collected solar cell patent documents from both of issued and applied databases to perform the proposed approach. The patents of 2001 to January 2005 serves as experimental sample to calculate the hazard rates of extracted technological terms and those from July 2005 to 2008 are for validity testing. The results reveal that there is a high correlation between the hazard rate and the patent numbers for extracted technological terms.","2159-5100;21595100","Electronic:978-1-890843-21-2; POD:978-1-4244-8203-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602083","","Databases;Hazards;Monitoring;Patents;Photovoltaic cells;Text mining","data mining;information retrieval;patents;solar cells;statistical analysis;text analysis","chance discovery;solar cell patent document;survival analysis;technological information;technological term extraction;text mining;validity testing","","1","","21","","","18-22 July 2010","","IEEE","IEEE Conference Publications"
"Research on the Performance Testing of the New Spatial Information Network Access G/S Mode","L. Tan; F. Miao; X. r. Guo; H. y. Shi","Key Lab. of Earth Exploration & Inf. Tech. of Minist. of Educ., Chengdu Univ. of Technol., Chengdu, China","2010 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM)","20101014","2010","","","1","5","G/S mode is a brand new spatial data access mode which is especially suitable for spatial information accessing through network. By introducing the software testing theory, a software performance testing on the spatial information network accessing was conducted between the Google Earth based on G/S mode and the Google Maps based on B/S mode. The advantages of G/S mode on the spatial information network accessing can be truly shown by comparing the testing results.","2161-9646;21619646","Electronic:978-1-4244-3707-8; POD:978-1-4244-3708-5","10.1109/WICOM.2010.5600854","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600854","","Browsers;Earth;Google;Resource management;Servers;Testing;Throughput","geographic information systems;information retrieval;program testing;search engines","B/S mode;G/S mode;Google Earth;software performance testing;software testing theory;spatial data access mode;spatial information accessing","","1","","8","","","23-25 Sept. 2010","","IEEE","IEEE Conference Publications"
"Learning Image Anchor Templates for Document Classification and Data Extraction","P. Sarkar","Perceptual Document Anal. Area, Palo Alto Res. Center, Palo Alto, CA, USA","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3428","3431","Image anchor templates are used in document image analysis for document classification, data localization, and other tasks. Current tools allow human operators to mark out small sub-images from documents to act as anchor templates. However, this requires time, and expertise because operators have to make informed decisions based on behavior of the template matching algorithms, and the expected degradations patterns in documents. We propose learning templates for a task automatically and quickly from a few training examples. Document classification or data localization can be done more robustly by combining evidence from many more discriminating templates (e.g., hundreds) than would be practicable for operators to specify.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.837","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597523","Automatic Document Recognition;Data Extraction;Document Classification;Field Localization;Forms Processing;Image Anchor Template","Degradation;Humans;NIST;Robustness;Text analysis;Training","document handling;image classification;image matching;information retrieval;object recognition","data extraction;data localization;document classification;document image analysis;image anchor templates learning;template matching algorithms","","1","","14","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Re-ranking Algorithm Based on Focused Named Entities","D. Jie","Inf. Eng. Dept., Shandong Youth Univ. of Political Sci., Jinan, China","2010 Second International Conference on Intelligent Human-Machine Systems and Cybernetics","20100930","2010","1","","187","191","This paper proposed a new method for learning to re-rank the retrieved documents based on the evaluation of the semantic relevance between named-entities in these documents and the query words, especially relevance between the query and the most topical named entities in these documents. The relevance weights used to rank documents were evaluated by analyzing the co-occurrence characters of focused named entities with respect to query. In this method, firstly, given the set of retrieved documents containing a query, the focused named entities in these documents are recognized; secondly, the relevance level of the query with respect to the focused entities in each retrieved document is estimated; thirdly, these retrieved documents are re-ranked with these relevance levels. Moreover, Experimental results on SEWM2006 test set indicate that our method can work well.","","Electronic:978-0-7695-4151-8; POD:978-1-4244-7869-9","10.1109/IHMSC.2010.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590600","Focused named entities;Ranking algorithm;Relevance levels","Classification algorithms;Feature extraction;Filtration;Frequency measurement;Machine learning;Semantic Web;Semantics","information retrieval","SEWM2006 test set;cooccurrence characters;document retrieval;focused named entities;information retrieval applications;query words;rank documents;relevance weights;reranking algorithm;semantic relevance","","0","","16","","","26-28 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research on sentiment classification of Blog based on PMI-IR","X. Duan; T. He; L. Song","Department of Computer Science, Huazhong Normal University, Wuhan, Hubei, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","6","Development of Blog texts information on the internet has brought new challenge to Chinese text classification. Aim to solving the semantics deficiency problem in traditional methods for Chinese text classification, this paper implements a text classification method on classifying a blog as joy, angry, sad or fear using a simple unsupervised learning algorithm. The classification of a blog text is predicted by the max semantic orientation (SO) of the phrases in the blog text that contains adjectives or adverbs. In this paper, the SO of a phrase is calculated as the mutual information between the given phrase and the polar words. Then the SO of the given blog text is determined by the max mutual information value. A blog text is classified as joy if the SO of its phrases is joy. Two different corpora are adopted to test our method, one is the Blog corpus collected by Monitor and Research Center for National Language Resource Network Multimedia Sub-branch Center, and the other is Chinese dataset provided by COAE2008 task. Based on the two datasets, the method respectively achieves a high improvement compared to the traditional methods.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587849","Mutual Information;PMI-IR Algorithm;Semantic Classification","Classification algorithms","Web sites;information retrieval;pattern classification;text analysis;unsupervised learning","Chinese text classification;PMI-IR algorithm;blog corpus;blog texts information;information retrieval;max semantic orientation;point-wise mutual information;sentiment classification;unsupervised learning algorithm","","1","","7","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"SERPWatcher: A Sophisticated Mining Tool Utilizing Search Engine Results Pages (SERPs) for Social Change Discovery","Y. Masunaga; K. Ito; Y. Miyama; N. Oyama; C. Watanabe; K. Tachi","Sch. of Social Inf., Aoyama Gakuin Univ., Sagamihara, Japan","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","465","472","As various individuals and organizations disseminate information on their Web pages, real-world social events and changes are considered to be reflected in Web trends. The billions of Web pages that now exist are retrieved by Web search engines which accept keywords and return a search engine results page (SERP). Since the SERP itself and the ranking order change with time reflecting the changes in society, it might be possible to accurately follow the movement of society by mining SERPs. This paper reports the design and implementation of a SERP mining tool named SERPWatcher. It provides sophisticated interfaces and functions for SERP miners in the field of social sciences to discover social changes. It could be a novel social survey method in that it totally differs from the traditional methods such as questionnaires and interviews. A research prototype of SERPWatcher is currently under operation, and its validation test shows that it has a fail-safe nature in the sense that social changes are mirrored on the changes of the SERP ranking order. Also, the testers conducting gender studies have been expressing positive opinions on the use of SERPWatcher as a novel research methodology in the field of sociology.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591298","SERP mining;SERPWatcher;Web;Web mining;search engine results page (SERP);social change discovery;social survey method","Color;Databases;Engines;Google;Robots;Search engines;Web pages","Internet;data mining;information dissemination;information retrieval;search engines;social aspects of automation","SERP mining tool;SERPWatcher;Web pages;Web search engines;search engine results pages;social change discovery;social survey method","","0","","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Marine literature categorization based on minimizing the labelled data","W. Zhang; Q. Wang; Y. Deng; R. Du","Department of Computer Science and Technology, Ocean University of China, Qing Dao, Shandong Province, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","6","In marine literature categorization, supervised machine learning method will take a lot of time for labelling the samples by hand. So we utilize Co-training method to decrease the quantities of labelled samples needed for training the classifier. In this paper, we only select features from the text details and add attribute labels to them. It can greatly boost the efficiency of text processing. For building up two views, we split features into two parts, each of which can form an independent view. One view is made up of the feature set of abstract, and the other is made up of the feature sets of title, keywords, creator and department. In experiments, the F1 value and error rate of the categorization system could reach about 0.863 and 14.26%.They are close to the performance of supervised classifier (0.902 and 9.13%), which is trained by more than 1500 labelled samples, however, the labelled samples used by Co-training categorization method to train the original classifier are only one positive sample and one negative sample. In addition we consider joining the idea of the active-learning in Co-training method.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587847","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587847","Co-training;Marine literature categorization;active-learning;two views","Manuals;Support vector machines;Variable speed drives","information retrieval;learning (artificial intelligence);literature;pattern classification;text analysis;word processing","active-learning;cotraining categorization method;labelled data minimization;marine literature categorization;supervised classifier;supervised machine learning method;text processing","","0","","18","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Homogeneity and Enrichment: Two Metrics for Web Applications Assessment","S. Valsamidis; S. Kontogiannis; A. Karakos; I. Kazanidis","Dept. of Electr. & Comput. Eng., Democritus Univ. of Thrace, Xanthi, Greece","2010 14th Panhellenic Conference on Informatics","20101021","2010","","","48","52","Earlier studies suggest that educational institutions may further benefit from Learning Management Systems (LMSs) by generating reports regarding courses. That is, with the use of tools focus to assess student's paths into course content. This paper affirms that educational meaningful information can be extracted from LMS student logged data and presents a methodology on how such findings may assist to the development of a reporting tool for educators. In the context of course assessment from student logged data, we introduce a new metric called homogeneity that extends the use of an older one, enrichment. We also propose a new algorithm that tries to qualify course content by classifying the course based on students' course paths interest. We applied our algorithm to Open eClass LMS tracking data of an academic institution and we present the results identified in 12 courses along with interest insights. We leave for future development the creation of an automated tool of our algorithm implemented for the Open eClass platform.","","Electronic:978-0-7695-4172-3; POD:978-1-4244-7838-5","10.1109/PCI.2010.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5600464","LMS courses;Web applications;algorithms;e-Learning;metrics","Classification algorithms;Clustering algorithms;Data mining;Electronic learning;Least squares approximation;Materials;Measurement","computer aided instruction;data mining;educational administrative data processing;educational courses;information retrieval;pattern classification","Open eClass platform;Web application;course assessment;course classification;educational course;learning management system;student logged data","","2","","13","","","10-12 Sept. 2010","","IEEE","IEEE Conference Publications"
"Using Term Extraction Patterns to Discover Coherent Relationships from Open Source Intelligence","W. L. Sousan; Q. Zhu; R. Gandhi; W. Mahoney; A. Sharma","Univ. of Nebraska, Omaha, NE, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","967","972","Unstructured open source information, especially the social, political, economic and cultural events described within web-based text/news articles, often contain possible motives for cyber security and trust issues. Automated processing of numerous open source intelligence sources requires the discovery of key domain terms, their conceptual hierarchies and the coherent relationships among them. A syntactic analysis of the word sequences in unstructured text documents allows for the extraction of subject-predicate-object triples, which form the basis for Term Extraction Patterns (TEP). In our research, we use TEPs to discover domain-specific multi-word entities which in turn, can be arranged in a taxonomy based on their semiotic inter-relationships. We explore the use of this method within the cyber security domain and analyze a collection of related news articles gathered from various public web sources. In this paper our initial results of term extraction and the semantic coherence derived from the TEP analyses are described. Our work extends beyond current methods, and our contribution is a novel methodology to extract semantics from unstructured text in domain specific open source information and its application to predict cyber attack outbreaks.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591400","Conceptualization;Open Source Intelligence;Semantic Relevance;Term Extraction;Term Extraction Patterns","Computer crime;Data mining;Ontologies;Pragmatics;Semantics;Taxonomy","Internet;information retrieval;security of data;text analysis","Web-based news articles;Web-based text;cyber attack;cyber security;open source intelligence;public Web sources;term extraction patterns;trust issues;unstructured text documents;word sequences","","0","","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Real-Time Search for Real-World Entities: A Survey","K. Romer; B. Ostermaier; F. Mattern; M. Fahrmair; W. Kellerer","Institute of Computer Engineering, University of L&#x00FC;beck, L&#x00FC;beck, Germany","Proceedings of the IEEE","20101018","2010","98","11","1887","1902","We are observing an increasing trend of connecting embedded sensors and sensor networks to the Internet and publishing their output on the Web. We believe that this development is a precursor of a Web of Things, which gives real-world objects and places a Web presence that not only contains a static description of these entities, but also their real-time state. Just as document searches have become one of the most popular services on the Web, we argue that the search for real-world entities (i.e., people, places, and things) will become equally important. However, in contrast to the mostly static documents on the current Web, the state of real-world entities as captured by sensors is highly dynamic. Thus, searching for real-world entities with a certain state is a challenging problem. In this paper, we define the underlying problem, outline the design space of possible solutions, and survey relevant existing approaches by classifying them according to their design space. We also present a case study of a real-world search engine called Dyser designed by the authors.","0018-9219;00189219","","10.1109/JPROC.2010.2062470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5570869","Entity discovery;Web of Things;object sensors;pervasive computing;predictive models;search engines;wireless sensor networks","IP networks;Indexes;Real time systems;Search engines;Search problems;Sensors;Substations","Internet;document handling;information retrieval;search engines","Dyser;Internet;Web of Things;embedded sensors;real-time search;real-world entities;search engine;sensor networks","","21","1","23","","20100913","Nov. 2010","","IEEE","IEEE Journals & Magazines"
"Multi-Document summarization based on improved features and clustering","Y. Xiong; H. Liu; L. Li","Beijing University of Posts and Telecommunications, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","5","Multi-Document summarization is an emerging technique for understanding the main purpose of many documents about the same topic. This paper proposes a new feature selection method to improve the summarization result. When calculating similarity, we use a modified TFIDF formula which achieves a better result. We adopt two ways for exactly extracting keywords. Experimental results demonstrate that our improved method performs better than the traditional one.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587834","Multi-document summarization;cluster;feature selection;sentence selection","Context;Telecommunications","document handling;information retrieval;pattern clustering","TFIDF formula;feature selection method;keyword extraction;multidocument summarization;sentence selection","","1","","14","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research of massive heterogeneous data integration based on Lucene and XQuery","L. Tianyuan; S. Meina; Z. Xiaoqi","School of Computer, Beijing University of Posts and Telecommunications, Beijing, China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","648","652","This paper proposes a model of massive heterogeneous data integration system based on Lucene and XQuery. This model shields distribution and heterogeneity of resources and achieves transparent access using materialized view of database. The query efficiency is increased due to the highly effective categorization algorithm to segment data as an index with open source tool Lucene. Further, the model makes full use of the advantage of XQuery, which can process not only structured data but also non-structured data so as to solve the significant difference among various data sources as well as the efficiency of massive data access.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607370","Heterogeneous Data;Lucene;Massive;XQuery","Algorithm design and analysis;Distributed databases;Indexes;Libraries;Query processing;XML","data handling;information retrieval;public domain software;query languages;search engines","XQuery;categorization algorithm;massive data access;massive heterogeneous data integration system;open source tool Lucene","","0","","7","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"Cognitive memory and its applications","B. Widrow","Dept. of Electrical Engineering, Stanford University","Cognitive Informatics (ICCI), 2010 9th IEEE International Conference on","20101011","2010","","","1","1","Regarding the workings of the human mind, memory and pattern recognition seem to be intertwined. You generally do not have one without the other. Taking inspiration from life experience, a new form of computer memory has been devised. Certain conjectures about human memory are keys to the central idea. The design of a practical and useful ‚Äúcognitive‚Äù memory system is contemplated, a memory system that may also serve as a model for many aspects of human memory. The new memory does not function like a computer memory where specific data is stored in specific numbered registers and retrieval is done by reading the contents of the specified memory register, or done by matching key words as with a document search. Incoming sensory data would be stored at the next available empty memory location, and indeed could be stored redundantly at several empty locations. The stored sensory data would neither have key words nor would it be located in known or specified memory locations. Sensory inputs concerning a single object or subject are stored together as vectors in a single ‚Äúfile folder‚Äù or ‚Äúmemory folder.‚Äù When the contents of the folder are retrieved, sights, sounds, tactile feel, smell, etc., are obtained all at the same time. Sensor fusion is a memory phenomenon. The sensory signals are not fused, but they are simply recorded together in the same folder and retrieved together. Retrieval would be initiated by a prompt signal from a current set of sensory inputs or patterns. A search through the memory would be made to locate stored data that correlates with or relates to the present real-time sensory inputs. The search would be done by a retrieval system that makes use of autoassociative artificial neural networks. Applications of cognitive memory systems have been made to visual aircraft identification, aircraft navigation, and human facial recognition. Other applications to speech recognition and control systems are being - - explored.","","Electronic:978-1-4244-8042-5; POD:978-1-4244-8041-8","10.1109/COGINF.2010.5599839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599839","","Aircraft navigation;Artificial neural networks;Computers;Electrical engineering;Humans;Medals;Registers","cognitive systems;information retrieval;sensor fusion","aircraft navigation;autoassociative artificial neural networks;cognitive memory system;computer memory;control systems;human facial recognition;human memory;memory phenomenon;memory register;retrieval system;sensor fusion;speech recognition;visual aircraft identification","","1","","","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Analyzing the Evolution of Social Groups in World of Warcraft<sup>¬Æ</sup>","C. Thurau; C. Bauckhage","Visual and Social Media Group at Fraunhofer IAIS, Sankt Augustin, Germany","Proceedings of the 2010 IEEE Conference on Computational Intelligence and Games","20100930","2010","","","170","177","This paper investigates the evolution of social structures in the game WORLD OF WARCRAFT<sup>¬Æ</sup>. We analyze 192 million recordings of 18 million characters belonging to 1.4 million teams, spanning a period of 4 years. Using a recent matrix factorization method, we extract lower dimensional data embeddings. The embeddings provide intuitively interpretable categorizations and we find a tendency towards guilds comprised of casual gamers. To our knowledge, this is the first study considering such a vast amount of data for analyzing groups in MMORPGs.","2325-4270;23254270","Electronic:978-1-4244-6297-1; POD:978-1-4244-6295-7; USB:978-1-4244-6296-4","10.1109/ITW.2010.5593358","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593358","","Ear","Internet;computer games;information retrieval;matrix decomposition;social networking (online)","World of Warcraft¬Æ game;intuitively interpretable categorization;lower dimensional data extraction;massively multiplayer online role playing game;matrix factorization method;social group","","8","","10","","","18-21 Aug. 2010","","IEEE","IEEE Conference Publications"
"Development of a High-Definition and Multispectral Image Capturing System for Digital Archiving of Early Modern Tapestries of Kyoto Gion Festival","M. Tsuchida; K. Yano; H. T. Tanaka","Commun. Sci. Lab., NTT Corp., Atsugi, Japan","2010 20th International Conference on Pattern Recognition","20101007","2010","","","2828","2831","We developed a two-shot 6-band image capturing system consisting of a large-format camera, a customized interference filter, and a scanning digital back to capture a 185-M-pixel images. The interference filter is set in front of the camera lens to obtain a 6-band image, that is, two 3-band images, one taken with the filter and the other without it. After correction of optical aberrations caused by the interference filter as well as system arrangement errors, the two images are combined into a 6-band image. The 6-band image was converted into a color-managed RGB image embedded ICC profile. In experiments, object images were captured as several divided parts and synthesized as almost 500-M-pixel image by using an image stitching technique. Resolution of the captured images is 0.02 mm/pixel. This paper discusses the camera system with its focus on some early modern tapestries used in the Kyoto Gion Festival. After the experiments, we interviewed a craftsman to assess the image's importance in archiving and analyzing fabric structures.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597051","color reproduction;digital aichive;eHeritage;multiband imaging;ultra high-definition image","Cameras;Image color analysis;Lenses;Lighting;Optical filters;Pixel;Reflectivity","fabrics;filtering theory;humanities;image colour analysis;image resolution;image sensors;information retrieval systems","Kyoto Gion Festival;camera system;color-managed RGB image;customized interference filter;digital archiving;fabric structures;image stitching technique;multispectral image capturing system;optical aberration correction","","0","","7","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Event-event relation identification: A CRF based approach","A. K. Kolya; A. Ekbal; S. Bandyopadhyay","Dept. of Computer Science and Engineering, Jadavpur University, Kolkata, India-700032","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","Temporal information extraction is a popular and interesting research field in the area of Natural Language Processing (NLP). The main tasks involve the identification of event-time, event-document creation time and event-event relations in a text. In this paper, we take up Task C that involves identification of relations between the events in adjacent sentences under the TimeML framework. We use a supervised machine learning technique, namely Conditional Random Field (CRF). Initially, a baseline system is developed by considering the most frequent temporal relation in the task's training data. For CRF, we consider only those features that are already available in the TempEval-2007 training set. Evaluation results on the Task C test set yield precision, recall and F-score values of 55.1%, 55.1% and 55.1%, respectively under the strict evaluation scheme and 56.9%, 56.9 and 56.9%, respectively under the relaxed evaluation scheme. Results also show that the proposed system performs better than the baseline system.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587774","Conditional Random Field;TempEval 2007 Task C;Temporal Relation Identification;TimeML","Accuracy;Classification algorithms;Feature extraction;Machine learning;Speech;Training;Training data","information retrieval;learning (artificial intelligence);natural language processing","TimeML framework;conditional random field;event-event relation identification;machine learning technique;natural language processing;temporal information extraction","","2","","10","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"An Information Extraction Model for Unconstrained Handwritten Documents","S. Thomas; C. Chatelain; L. Heutte; T. Paquet","LITIS, Univ. de Rouen, St. Etienne du Rouvray, France","2010 20th International Conference on Pattern Recognition","20101007","2010","","","3412","3415","In this paper, a new information extraction system by statistical shallow parsing in unconstrained handwritten documents is introduced. Unlike classical approaches found in the literature as keyword spotting or full document recognition, our approach relies on a strong and powerful global handwriting model. A entire text line is considered as an indivisible entity and is modeled with Hidden Markov Models. In this way, text line shallow parsing allows fast extraction of the relevant information in any document while rejecting at the same time irrelevant information. First results are promising and show the interest of the approach.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.833","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597527","Handwriting recognition;information extraction;shallow parsing model","Data mining;Databases;Feature extraction;Handwriting recognition;Hidden Markov models;Numerical models;Postal services","document handling;handwriting recognition;hidden Markov models;information retrieval;statistical analysis","full document recognition;hidden Markov models;information extraction model;keyword spotting;statistical shallow parsing;text line shallow parsing;unconstrained handwritten documents","","9","","11","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research on the construction and application of the generalized toponym ontology","J. Chen; H. w. Li","Geographic Information System, Institute of Surveying and Mapping, Information Engineering University, Zhengzhou, China","2010 Second IITA International Conference on Geoscience and Remote Sensing","20101014","2010","2","","590","593","In the paper, the generalized toponym ontology(GTO) is constructed and consummate d by use of the topography vocabulary and correlative nation standards. The ontology is us ed to classify and encode the generalized toponym information, spatial topology relations reasoning based on Jena and knowledge retrieval. GTO is the future development trend of the to ponym science and it will be the massy base of the intellective toponym services on the semantic web.","","Electronic:978-1-4244-8517-8; POD:978-1-4244-8514-7","10.1109/IITA-GRS.2010.5602362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602362","GTO;intellec tive retrieval;topography vocabulary","Cities and towns;Cognition;Encoding;Ontologies;Resource description framework;Topology;Vocabulary","inference mechanisms;information retrieval;ontologies (artificial intelligence);semantic Web;topology","correlative nation standard;generalized toponym ontology;information classification;information encoding;knowledge retrieval;semantic Web;spatial topology relation reasoning;topography vocabulary","","0","","24","","","28-31 Aug. 2010","","IEEE","IEEE Conference Publications"
"A semantic approach to construct a knowledge portal for e-learning using ontology","B. Saleena; M. G. Salini; S. Venkateswaran","School of Computing Science, VIT University, India","2010 4th International Conference on Distance Learning and Education","20101021","2010","","","214","217","This paper presents an architecture for the creation of a knowledge portal for e-learning based on the pedagogic domain ontology by using semantic web technologies. The knowledge portal is created by semantically relating the learning objects. A user interactive environment is created for the learners to interact with the knowledge portal to efficiently access and utilize the e-learning materials. In the existing e-learning systems that use the semantic web, the thematic knowledge is retrieved but the pre-requisites required for that content is manually grouped. This knowledge portal is designed in such a way that the thematic knowledge as well the requisites required for clearly understanding a required subject is retrieved by investigating the topic and tracking the contents based on the semantic context.","2169-1428;21691428","Electronic:978-1-4244-8752-3; POD:978-1-4244-8751-6","10.1109/ICDLE.2010.5605999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5605999","E-learning;Knowledge Portal;Semantic web;Thematic knowledge","Computers;Education;Java;Object recognition;Resource description framework;Semantics;Tutorials","computer aided instruction;information retrieval;interactive systems;ontologies (artificial intelligence);portals;semantic Web;user interfaces","e-learning;knowledge portal;pedagogic domain ontology;semantic Web;thematic knowledge retrieval;user interactive environment","","1","","12","","","3-5 Oct. 2010","","IEEE","IEEE Conference Publications"
"Improving the Effectiveness of Context-Based Prefetching with Multi-order Analysis","Y. Chen; H. Zhu; H. Jin; X. H. Sun","Comput. Sci. & Math. Div., Oak Ridge Nat. Lab., Oak Ridge, TN, USA","2010 39th International Conference on Parallel Processing Workshops","20101011","2010","","","428","435","Data prefetching is an effective way to accelerate data access in high-end computing systems and to bridge the increasing performance gap between processor and memory. In recent years, the context based data prefetching has received intensive attention because of its general applicability. In this study, we provide a preliminary analysis of the impact of orders on the effectiveness of the context-based prefetching. Motivated by the observations from the analytical results, we propose a new context-based prefetching method named Multi-Order Context-based (MOC) prefetching to adopt multi-order context analysis to increase the context-based prefetching effectiveness. We have carried out simulation testing with the SPEC-CPU2006 benchmarks via an enhanced CMP$im simulator. The simulation results show that the proposed MOC prefetching method outperforms the existing single-order prefetching and reduces the data-access latency effectively.","0190-3918;01903918","Electronic:978-0-7695-4157-0; POD:978-1-4244-7918-4","10.1109/ICPPW.2010.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599102","context-based prefetching;data prefetching;high-end computing;memory access performance","Accuracy;Benchmark testing;Context;History;Indexes;Prefetching;Radiation detectors","information retrieval;storage management","CMP$im simulator;context-based prefetching method;data prefetching;data-access latency;high-end computing systems;multiorder analysis;multiorder context-based prefetching;simulation testing;single-order prefetching","","2","","28","","","13-16 Sept. 2010","","IEEE","IEEE Conference Publications"
"Studies on multi-source image data management based on GeoRaster","J. Qin; S. Wu","Spatial Information Research Center of Fujian Province, Fuzhou University, Key Lab of Spatial Data Mining and Information Sharing, Ministry of Education, China","2010 Second IITA International Conference on Geoscience and Remote Sensing","20101014","2010","1","","487","491","On the basis of analyzing the special requirements of multi-source image data management, we proposed to store and manage image data and its metadata integratively in object-rational database. In this paper, first we studied the storage model based on GeoRaster and the key technologies about image blocking, compressing, pyramid construction and spatial indexing. Then proposed a architecture of multi-source image database system. Finally based on GDAL and GeoRaster, we implemented an image database system of Client/Server structure for storing, querying and managing Remote Sensing data.","","Electronic:978-1-4244-8517-8; POD:978-1-4244-8514-7","10.1109/IITA-GRS.2010.5602755","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5602755","GDAL;GeoRaster;image database;multi-source image data","Flowcharts;Image databases;Remote sensing;Spatial databases;Spatial indexes","data compression;data handling;geophysical image processing;indexing;information retrieval;information storage;meta data;object-oriented databases;remote sensing","GDAL;GeoRaster;client-server structure;image blocking;image compressing;image data storage;metadata;multisource image data management;object-rational database;pyramid construction;remote sensing data management;remote sensing data querying;remote sensing data storing;spatial indexing","","0","","8","","","28-31 Aug. 2010","","IEEE","IEEE Conference Publications"
"Design and implementation of discovering preferred browsing paths from Web logs algorithm","Zi-lei Jiang; Shun-lin Song","School of Computer Science and Telecommunication Engineering, Jiangsu University, Zhenjiang, China","2010 International Conference on Educational and Information Technology","20101025","2010","2","","V2-415","V2-418","This paper puts forward the algorithm of discovering preferred browsing paths from Web logs. The algorithm imports Support-preference and User access matrix which is used to reflect the frequency of visiting Web pages. After obtaining Hamming distance matrix, its element values are compared with Similarity threshold one by one, so Candidate interest sub-path 2-items set is gotten. According to Support-preference threshold, inappropriate sub-paths which belong to Sub-path set are eliminated. Finally preferred browsing paths are generated by merging sub-paths. Applying the algorithm in the experiment, its validity is proved.","","Electronic:978-1-4244-8035-7; POD:978-1-4244-8033-3","10.1109/ICEIT.2010.5607605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607605","Hamming distance;Similarity threshold;Support-preference;User access matrix;Web log mining;preferred browsing paths","Artificial intelligence","Web sites;data mining;information retrieval;matrix algebra","Web log algorithm;Web page;candidate interest;hamming distance matrix;preferred browsing path discovery;similarity threshold;support preference;user access matrix","","1","","8","","","17-19 Sept. 2010","","IEEE","IEEE Conference Publications"
"Classification of musical styles using liquid state machines","H. Ju; J. X. Xu; A. M. J. VanDongen","Program for Neuroscience and Behavioral Disorders of the Duke-NUS Graduate Medical School, Singapore","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","7","Music Information Retrieval (MIR) is an interdisciplinary field that facilitates indexing and content-based organization of music databases. Music classification and clustering is one of the major topics in MIR. Music can be defined as `organized sound'. The highly ordered temporal structure of music suggests it should be amendable to analysis by a novel spiking neural network paradigm: the liquid state machine (LSM). Unlike conventional statistical approaches that require the presence of static input data, the LSM has a unique ability to classify music in real-time, due to its dynamics and fading-memory. This paper investigates the performance of an LSM in classifying musical styles (ragtime vs. classical), as well as its ability to distinguish music from note sequences without temporal structure. The results show that the LSM performs admirably in this task.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596470","","Classification algorithms;Encoding;Information filters;Neurons;Testing;Training","content-based retrieval;finite state machines;information retrieval;music;pattern classification;pattern clustering","content-based organization;fading-memory;liquid state machine;music clustering;music database;music information retrieval;musical note sequence;musical style classification","","2","","16","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Using an opinion mining approach to exploit Web content in order to improve customer relationship management","A. Kongthon; N. Angkawattanawit; C. Sangkeettrakarn; P. Palingoon; C. Haruechaiyasak","Human Language Technology (HLT) Laboratory, National Electronics and Computer Technology Center (NECTEC), Thailand Science Park, Thailand","PICMET 2010 TECHNOLOGY MANAGEMENT FOR GLOBAL ECONOMIC GROWTH","20101014","2010","","","1","6","A traditional market survey typically seeks out customers' opinions using voluntary questionnaires or focus group interviews. The surveys' perceived and actual reliability could be limited by the number of customers who choose to respond, bias inherent in the wording of the questions or the subjects' interpretation regarding the information being sought. Online opinion resources such as review sites, forums, discussion groups and blogs are available with increasing variety and popularity. Companies can now apply information retrieval, natural language processing and machine learning techniques to automatically and more objectively identify and understand the opinions of their customers. In this paper, we present an approach to analyze customers' opinions regarding the hotels in Thailand. Such results can be used to determine public perceptions regarding selected hotels in order to allow the business to better understand customer satisfaction.","2159-5100;21595100","Electronic:978-1-890843-21-2; POD:978-1-4244-8203-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5603340","","Book reviews;Customer satisfaction;Data mining;Feature extraction;Humans;Internet","Internet;customer satisfaction;hotel industry;information retrieval;learning (artificial intelligence);market research;natural language processing;production engineering computing","Thailand;Web content;customer relationship management;customer satisfaction;customers' opinions;group interviews;hotels;information retrieval;machine learning;market survey;natural language processing;online opinion resources;opinion mining approach;public perceptions;reliability;voluntary questionnaires","","1","","18","","","18-22 July 2010","","IEEE","IEEE Conference Publications"
"Image Processing Based Approach for Retrieving Data from a Seismic Section in Bitmap Format","D. Chevion; Y. Navon; D. Ramm","IBM Res. Haifa, Haifa, Israel","2010 20th International Conference on Pattern Recognition","20101007","2010","","","4444","4447","A new method for retrieving seismic data from a seismic section provided in a bitmap format is described. The method is based on image processing techniques and includes creating a grey level image of a seismic section, processing the grey level image (by integration, filtering, etc.) and then reconstructing digitized values of individual seismic traces_ from the resulting image, thus ending with the data in standard SEG-Y format.","1051-4651;10514651","Electronic:978-1-4244-7541-4; POD:978-1-4244-7542-1","10.1109/ICPR.2010.1079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597861","Iamge Reconstruction;Image Retrieval;Image transformations;Pattern recognition systems and applications;Signal/image representation","Apertures;Geology;Image reconstruction;Pixel;Receivers;Smoothing methods","geophysics;image reconstruction;information retrieval","bitmap format;data retrieval;grey level image;image processing;image reconstruction;seismic section;standard SEG-Y format","","0","","5","","","23-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Regular expression-based reference metadata extraction from the web","X. Tang; Q. Zeng; T. Cui; Z. Wu","College of Information Science and Engineering, Shandong University of Science and Technology, No. 579 Qianwangang Road, Qingdao 266510, PR China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","346","350","Accurate reference metadata extraction becomes an intriguing task to researchers who want to collect data of scientific publications. In this paper, we introduce an approach to extracting the reference metadata based on regular expressions. A prototype system named ‚ÄúGoldrusher‚Äù is created which automatically extracts data from the website of Association for Computing Machinery (ACM). The experimental results show that, by using our regular expression-based method, we can effectively extract author names, article titles, journal titles, DIOs, etc.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607427","","Books;Crawlers;Data mining;HTML;Libraries;Machinery;Web pages","Internet;Web sites;information retrieval;meta data","Association for Computing Machinery;Goldrusher;Web site;World Wide Web;accurate reference metadata extraction;regular expression","","1","","9","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"The application and research of XOR operation on sci-tech novelty search","Huanli Pang; Lianzhe Zhou; Hanmei Liu","College of Computer Science & Engineering, Changchun University of Technology, China","2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering","20101025","2010","1","","422","424","In view of special needs with novelty search; build novelty search retrieval with XOR operation. This retrieval technique can identify the novel of the science technical contents automatically, and give preliminary conclusions. Results obtained from experiments on experiment demonstrate that the proposed algorithm performs well and fast.","2159-6026;21596026","Electronic:978-1-4244-7958-0; POD:978-1-4244-7957-3","10.1109/CMCE.2010.5610528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5610528","Sci-tech Novelty Search;XOR operation;retrieval","Barium","information retrieval;logic;scientific information systems;search problems","XOR operation;novelty search retrieval;sci-tech novelty search;science technical content","","0","","5","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"On data integration workflows for an effective Management of multidimensional petroleum digital ecosystems in Arabian gulf basins","S. L. Nimmagadda; H. Dreher; M. Nawaz; K. Laiq; A. Sabry; M. Ahmed","Curtin Business School - Information Systems, Curtin University, Perth, Western Australia","4th IEEE International Conference on Digital Ecosystems and Technologies","20101025","2010","","","513","519","Data integration of multiple heterogeneous datasets from multidimensional petroleum digital ecosystems is an effective way, for extracting information and adding value to knowledge domain from multiple producing onshore and offshore basins. At present, data from multiple basins are scattered and unusable for data integration, because of scale and format differences. Ontology based warehousing and mining modeling are recommended for resolving the issues of scaling and formatting of multidimensional datasets, in which case, seismic and well-domain datasets are described. Issues, such as semantics among different data dimensions and their associated attributes are also addressed by Ontology modeling. Intelligent relationships are built among several petroleum system domains (structure, reservoir, source and seal, for example) at global scale and facilitated the integration process among multiple dimensions in a data warehouse environment. For this purpose, integrated workflows are designed for capturing and modeling unknown relationships among petroleum system data attributes in interpretable knowledge domains. This study is an effective approach in mining and interpreting data views drawn from warehoused exploration and production metadata, with special reference to Arabian onshore and offshore basins.","2150-4938;21504938","Electronic:978-1-4244-5553-9; POD:978-1-4244-5551-5","10.1109/DEST.2010.5610599","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5610599","Arabian Gulf Basin;data integration;multidimensional data;petroleum digital ecosystems","Data mining;Data models;Data warehouses;Ecosystems;Geology;Ontologies;Petroleum","data mining;data warehouses;information retrieval;meta data;ontologies (artificial intelligence);petroleum industry","Arabian Gulf basins;data integration workflows;data mining;data warehouse environment;information extraction;multidimensional petroleum digital ecosystems;multiple heterogeneous datasets;offshore basins;onshore basins;ontology based warehousing;ontology modeling;production metadata","","1","","9","","","13-16 April 2010","","IEEE","IEEE Conference Publications"
"Neural-network based regression model with prior from ranking information","Y. Qu; B. Dai; B. Hu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","The 2010 International Joint Conference on Neural Networks (IJCNN)","20101014","2010","","","1","8","In this work, a new algorithm, which can incorporate the ranking information as prior knowledge into the regression model, is presented. Comparing with the method that treats the ranking information as hard constraints, We handle ranking reasonably by maximization of Normalized Discount Cumulative Gain (NDCG) as information retrieval (IR) evaluation measure, which is used to evaluate the performance of ranking model. In addition, an upper bound of one minus NDCG is given by weighted pairwise loss, and a connection between weighted pairwise loss and NDCG is also revealed. In this paper, RBF regression model and the pairwise shifted hinge loss and logistic loss are proposed under the suggested approach. One benefit of the proposed approach is that the weighted pairwise loss is more reasonable than the unweighted loss and all the weights are set based on the NDCG. Finally, one synthetic example shows that the method incorporated the ranking as hard constraints into regression model may cause the deteriorated results, but the good performance is shown by the proposed method. Numerical results from three existing benchmark regression problems further confirm the beneficial aspects on the proposed approach.","2161-4393;21614393","Electronic:978-1-4244-6918-5; POD:978-1-4244-6916-1","10.1109/IJCNN.2010.5596936","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596936","","Artificial neural networks;Fasteners;Knowledge engineering;Logistics;Radial basis function networks;Training;Training data","information retrieval;learning (artificial intelligence);radial basis function networks;regression analysis","RBF regression model;information retrieval;logistic loss;neural-network based regression model;normalized discount cumulative gain;pairwise shifted hinge loss;ranking information","","2","","25","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Data query using short domain question in natural language","R. Zhang; Q. Zeng; S. Feng","College of Information Science and Engineering, Shandong University of Science and Technology, Qingdao, 266510, Shandong, P.R. China","2010 IEEE 2nd Symposium on Web Society","20101021","2010","","","351","354","This paper presents the application of understanding of short domain question in natural language to data query. A domain dictionary can be obtained through extracting schema of all tables and short text data from database by ODBC API. The word segmentation tool, IK Analyzer, which is extended with the obtained domain dictionary, is used to segment the short text questions. From the segmentation results, the keywords are extracted to obtain query target and query requirement of the question and to generate a SQL statement for data query. The method proposed in this paper can be applied to question-answering system based on database.","2158-6985;21586985","Electronic:978-1-4244-6359-6; POD:978-1-4244-6356-5","10.1109/SWS.2010.5607428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5607428","","Arrays;Books;Data mining;Databases;Dictionaries;Natural languages;Vocabulary","SQL;dictionaries;information retrieval systems;natural language processing;query processing;word processing","IK analyzer;ODBC API;SQL statement;data query;domain dictionary;natural language;query requirement;query target;question-answering system;short domain question;short text questions;word segmentation tool","","0","","6","","","16-17 Aug. 2010","","IEEE","IEEE Conference Publications"
"Personalized Feed Recommendation Service for Social Networks","H. Li; Y. Tian; W. C. Lee; C. L. Giles; M. C. Chen","Dept. of Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","96","103","Social network systems (SNSs) such as Facebook and Twitter have recently attracted millions of users by providing social network based services to support easy message posting, information sharing and inter-friend communication. With the rapid growth of social networks, users of SNSs may easily get overwhelmed by the excessive volume of information feeds and felt challenging to digest and find truly valuable information. In this paper, we introduce a personalized feed recommendation service for SNS users based on user interests and social network contexts. Our approach incorporates both the topical preference and topological locality of a user in determining a feed's relevance. We propose a popularity diffusion model to propagate feeds in social networks and support our recommendation service with a set of personalized indices for feed-based information retrieval. A suite of efficient index manipulation algorithms are developed in our framework to address the need of managing the dynamics in social networks. We conduct an extensive performance evaluation to compare our proposal with alternative solutions using both real and synthetic social network data, which suggests our proposal outperforms in both efficiency and relevance.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590802","Feed Recommendation;Indexing;Personalization;Search;Social Network","Equations;Feeds;Heuristic algorithms;Indexes;Mathematical model;Social network services;Topology","information retrieval;recommender systems;social networking (online)","Facebook;Twitter;feed-based information retrieval;personalized feed recommendation service;popularity diffusion model;social network systems;user interests","","1","1","18","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Rough Set Approach to Agent Trust Management","S. Abedinzadeh; S. Sadaoui","Dept. of Comput. Sci., Univ. of Regina, Regina, SK, Canada","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","1064","1071","Trust management in Multi Agent Systems plays a key role in today's growing need for such systems. Methods of trust management try to approximate a set of best agents, in terms of some pre-defined measures. The theory of Rough Sets deals with the approximation of classifying objects in an environment for which we do not have a certain definition. In this research, we propose a new trust management approach based on the concepts of the theory of rough sets. We apply this approach on an Information Retrieval (IR) MAS. This application includes defining the attribute and their domain of values, discretizing the attribute values, collecting these values, and employing a rough set tool for analyzing them. The results of this application are presented.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590395","","Approximation methods;Fuzzy sets;Graph theory;Mathematical model;Rough sets;Search engines","information retrieval;multi-agent systems;rough set theory;security of data","information retrieval;multi agent systems;rough set theory;trust management","","0","","28","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
