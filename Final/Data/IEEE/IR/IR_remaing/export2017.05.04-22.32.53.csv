"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5756572,5759606,5756512,5759374,5669345,5567101,5754168,5661825,5752947,5754643,5752002,5752467,5750651,5750460,5750519,5750788,5750574,5750466,5750484,5747547,5749497,5747664,5749472,5743340,5742380,5742126,5742044,5741313,5740444,5738770,5738828,5738807,5738992,5738801,5645629,5738816,5738146,5735707,5738162,5635313,5557877,5734084,5734933,5734021,5734121,5730326,5730304,5729583,5729397,5729389,5724900,5723884,5723835,5722430,5723154,5722376,5722689,5723456,5720606,5720610,5721063,5467014,5718603,5716883,5718623,5716737,5718645,5718612,5718610,5718300,5718609,5718592,5718482,5718315,5716718,5719004,5716714,5718734,5718544,5714552,5715546,5714451,5715418,5715681,5714631,5714640,5715686,5716296,5714417,5715093,5714610,5715556,5716478,5560649,5713467,5713479,5712802,5713487,5713078,5711896",2017/05/04 22:32:53
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A conceptual overview of data mining","B. N. Lakshmi; G. H. Raghunandhan","Department of Computer science Engineering, Reva Institute of Technology and Management; Bangalore, Karnataka, India","2011 National Conference on Innovations in Emerging Technology","20110324","2011","","","27","32","Data mining an non-trivial extraction of novel, implicit, and actionable knowledge from large data sets is an evolving technology which is a direct result of the increasing use of computer databases in order to store and retrieve information effectively. It is also known as Knowledge Discovery in Databases (KDD) and enables data exploration, data analysis, and data visualization of huge databases at a high level of abstraction, without a specific hypothesis in mind. The working of data mining is understood by using a method called modeling with it to make predictions. Data mining techniques are results of long process of research and product development and include artificial neural networks, decision trees and genetic algorithms. This paper surveys the data mining technology, its definition, motivation, its process and architecture, kind of data mined, functionalities and classification of data mining, major issues, applications and directions for further research of data mining technology.","","Electronic:978-1-61284-810-5; POD:978-1-61284-807-5","10.1109/NCOIET.2011.5738828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738828","KDD;data mining;further research;modeling;recent techniques","Business;Classification algorithms;Data mining;Data warehouses;Spatial databases;Web sites","data analysis;data mining;data visualisation;information retrieval;very large databases","abstraction;artificial neural networks;computer databases;data analysis;data exploration;data mining;data visualization;decision trees;genetic algorithms;information retrieval;knowledge discovery in databases;large data sets;nontrivial extraction;product development","","8","","7","","","17-18 Feb. 2011","","IEEE","IEEE Conference Publications"
"Privacy preserving data mining based on association rule- a survey","S. Vijayarani; A. Tamilarasi; R. SeethaLakshmi","School of Computer Science and Engg., Bharathiar University, Coimbatore, Tamilnadu, India","2010 International Conference on Communication and Computational Intelligence (INCOCCI)","20110324","2010","","","99","103","Data mining is the process of extracting hidden information from the database. Data mining is emerging as one of the key features of many business organizations. The current trend in business collaboration shares the data and mined results to gain mutual benefit. The problem of privacy-preserving data mining has become more important in recent years because of the increasing ability to store personal data about users, and the increasing sophistication of data mining algorithms to leverage this information. Apart from classification and regression, one of the most important tasks of data mining is to find patterns in data. In particular, new advances in data mining and knowledge discovery that allow for the extraction of hidden knowledge in enormous amount of data impose new threats on the seamless integration of information. In this paper, we consider the problem of building privacy preserving algorithms for one category of data mining techniques, the association rule mining.","","Electronic:978-81-8371-369-6; POD:978-1-4577-0376-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738807","Association rule;Data Mining;Privacy Preserving Data Mining","Algorithm design and analysis;Association rules;Data privacy;Distributed databases;Itemsets","business data processing;data mining;data privacy;information retrieval;pattern classification;regression analysis","association rule mining;business collaboration;business organization;data pattern;data sharing;hidden information extraction;knowledge discovery;mutual benefit;privacy preserving data mining","","0","","12","","","27-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"From digital archives to E-business: A case study on turning “art” into “business”","R. Lin; C. L. Lin","Graduate School of Creative Industry Design, National Taiwan University of Arts, Taichung County, Taiwan","2010 International Conference on e-Business (ICE-B)","20110328","2010","","","1","8","Along with Information Technology progress, E-business is becoming a key concept in the Internet and electronic commerce world. However, in today's intensely competitive business climate, innovative products become central to E-business development. Furthermore, changes in consumer perceptions regarding innovation are also important in E-business. Recently, creative industries are continually emerging in electronic commerce and have the potential to become a key trend in E-business. Understanding the E-business models for creative industries and helping designers to design “culture” into products are important research issues, and issues not yet well covered. Therefore, this paper proposes an ABCDE approach to illustrate how to transform “Archive” into “E-business”. In order to turn “Archive” into “Business”, we first need “Creativity” and “Design” only then can we transform innovative products into “E-business.” Results presented herein create an interface for looking at the way E-business crosses over cultures, and illustrate the interwoven experience of E-business and cultural creativity in the innovation design process and electronic commerce world.","","Electronic:978-989-8425-17-1","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740444","Cross cultural product design;Cultural difference;Digital archive;e-Business","Business;Cultural differences;Databases;Industries;Product design;Solid modeling;Technological innovation","Internet;art;electronic commerce;information retrieval systems;information technology","E-business;Internet;art;digital archives;electronic commerce;information technology","","0","","30","","","26-28 July 2010","","IEEE","IEEE Conference Publications"
"User Behaviour during Web Search as Part of Information Gathering","A. Alhenshiri; C. Watters; M. Shepherd","Dalhousie Univ., Halifax, NS, Canada","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","This paper presents the results of a questionnaire on user behaviour during searching the Web as part of information gathering tasks. In this study, users' Web activities related to finding information, comparing information, managing information, and re-finding information, using different Web search and navigation tools, used for information gathering tasks are explored. The results indicate that current Web tools lack important functionalities for supporting how users find, re-find, and manage information during Web information gathering tasks. Furthermore, the results indicate that visual characteristics of search results, re-finding tools that bookmark complete and partial search sessions with user annotation, and integrated information management features may be useful in improving how users gather information on the Web.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.470","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718612","","Context;Google;Search engines;Switches;Visualization;Web pages;Web search","Internet;information retrieval;user interfaces","Web navigation tool;Web search tool;information gathering task;integrated information management features;user annotation;user behaviour","","1","","29","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Uncertainty, Affect, and Information Search","M. M. Luo; D. Nahl; S. Chea","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","Kuhlthau's Information Search Process stage (ISP) model was developed in the context of information retrieval with library users. In this model information searchers experience different stages and ultimately complete their information retrieval with end results. This study intends to understand whether Kuhlthau's ISP model can be applied in Internet search. Data collected from 30 searchers suggested that the ISP model was applicable in studying searchers' information retrieval behavior in simple tasks. However, searchers' emotional responses differed from those of the ISP model for a complex task. By testing searchers using different search strategies, results suggested that search engines with multilanguage search functions provide an advantage for bilingual searchers in the Internet's multilingual environment.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718603","","Biological system modeling;Cognition;Internet;Libraries;Search engines;Uncertainty","Internet;behavioural sciences;information retrieval;linguistics;natural language processing;search engines;social aspects of automation","Internet multilingual environment;Internet search;Kuhlthau ISP model;bilingual searcher;emotional response;information retrieval behavior;information search process;library user;multilanguage search function;search engine;search strategy","","0","","25","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"A novel audio steganography scheme using amplitude differencing","K. Shafi; A. Sankaranarayanan; G. Prashanth; A. Mohan","Amrita Vishwa Vidyapeetham Coimbatore, India","Trendz in Information Sciences & Computing(TISC2010)","20110217","2010","","","163","167","A novel method for embedding a covert message in cover audio for secure communication is proposed. The covert message to be embedded can be of any format. In this process, two cover audio files are taken and difference of the amplitude values is calculated. These differences are then classified into number of ranges and are substituted with a new value to embed the secret message. The embedded secret message can be extracted in its original format from the resulting two stego-audio files without referring the original audio files. The secret message can be encrypted for added security. Experimental results show that the technique achieves imperceptible embedding, large payload, and accurate data retrieval.","2325-5919;23255919","Electronic:978-1-4244-9009-7; POD:978-1-4244-9007-3","10.1109/TISC.2010.5714631","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714631","Audio Steganography;Data Hiding;PVD;Steganalysis","Auditory system;Data mining;Humans;Indexes;Payloads;Security;Time frequency analysis","audio signal processing;cryptography;data encapsulation;information retrieval;steganography","amplitude differencing;audio steganography scheme;cover audio;data retrieval;encryption;secure communication","","2","","7","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"A multidimensional partitioning scheme for developing English to Bangla dictionary","K. M. A. Hasan; E. Ara; F. Hoque; J. Yasmin","Department of Computer Science and Engineering (CSE), Khulna University of Engineering and Technology (KUET), 9203, Bangladesh","2010 13th International Conference on Computer and Information Technology (ICCIT)","20110303","2010","","","92","96","In this paper we describe a multidimensional implementation scheme for developing English to Bangla dictionary using multidimensional Array. We have converted the string into an integer key and partitioned the keys based on number of letters a word. Multidimensional arrays are good to store dense data. It is hard to use multidimensional array for sparse data. We have compressed the sparse multidimensional array by computing the offset value. We found good results for storage and retrieval costs. Our proposed model is explained with sufficient example and performance analysis is described with experimental results. The proposed scheme shows superiority over traditional schemes.","","Electronic:978-1-4244-8497-3; POD:978-1-4244-8496-6","10.1109/ICCITECHN.2010.5723835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723835","Bangla Dictionary;Multidimensional array;NLP;Partitioning;Storage and Retrieval cost","Arrays;Computational modeling;Computers;Dictionaries;Equations;Mathematical model;Speech","dictionaries;information retrieval;natural language processing","English to Bangla dictionary;integer key;multidimensional partitioning scheme;retrieval costs;sparse multidimensional array;storage costs","","0","","13","","","23-25 Dec. 2010","","IEEE","IEEE Conference Publications"
"Eigen-inference moments method for cognitive wireless communications","A. M. Masucci; Ø. Ryan; S. Yang; M. Debbah","","2010 Future Network & Mobile Summit","20110303","2010","","","1","8","In many situations, telecommunication engineers are faced with the problem of extracting information from the network. This corresponds in many cases to infer on functionals of spectrum of random matrices with only a limited knowledge on the statistics of the matrix entries. Here, the inference on the spectrum of random matrices is realized by moments method. In its full generality, the problem requires some sophisticated tools related to free probability theory and the explicit spectrum (complete information) can hardly be obtained (except for some trivial cases). Results in the asymptotic case and in the finite case are presented and simulations show how the moments method approach can be applied in practice. Several still open problems in this field are also presented.","","Electronic:978-1-905824-18-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5722430","","Additives;Convolution;Data mining;Deconvolution;Eigenvalues and eigenfunctions;Moment methods;Symmetric matrices","cognitive radio;eigenvalues and eigenfunctions;inference mechanisms;information retrieval;matrix algebra;method of moments;probability;radio networks","cognitive wireless communication;eigen-inference moments method;information extraction;probability theory;random matrices","","0","","9","","","16-18 June 2010","","IEEE","IEEE Conference Publications"
"Accelerating Parameter Sweep Applications Using CUDA","M. Motokubota; F. Ino; K. Hagihara","Grad. Sch. of Inf. Sci. & Technol., Osaka Univ., Suita, Japan","2011 19th International Euromicro Conference on Parallel, Distributed and Network-Based Processing","20110324","2011","","","111","118","This paper proposes a parallelization scheme for parameter sweep (PS) applications using the compute unified device architecture (CUDA). Our scheme focuses on PS applications with irregular access patterns, which usually result in lower performance on the GPU. The key idea to resolve this irregularity is to exploit the similarity of data accesses between different parameters. That is, the scheme simultaneously processes multiple parameters instead of a single parameter. This simultaneous sweep allows data accesses to be coalesced into a single access if the irregularity appears similarly at every parameter. It also reduces the amount of off-chip memory access by using fast on-chip memory for the data commonly accessed for multiple parameters. As a result, the scheme achieves up to 4.5 times higher performance than a naive scheme that processes a single parameter by a kernel invocation.","1066-6192;10666192","Electronic:978-0-7695-4328-4; POD:978-1-4244-9682-2","10.1109/PDP.2011.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738992","CUDA;GPU;acceleration;parameter sweep","Acceleration;Graphics processing unit;Instruction sets;Kernel;Memory management;Optimization","combinatorial mathematics;computer graphic equipment;coprocessors;information retrieval;optimisation;parallel architectures","CUDA;GPU;compute unified device architecture;data access;irregular access pattern;off-chip memory access;on-chip memory;parallel architecture;parameter sweep application","","0","","13","","","9-11 Feb. 2011","","IEEE","IEEE Conference Publications"
"Human Speed-Accuracy Tradeoffs in Search","C. Aperjis; B. A. Huberman; F. Wu","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","When foraging for information, users face a tradeoff between the accuracy and value of the acquired information and the time spent collecting it, a problem which also surfaces when seeking answers to a question posed to a large community. We empirically study how people behave when facing these conflicting objectives using data from Yahoo Answers, a community driven question-and-answer site. We first study how users behave when trying to maximize the amount of acquired information while minimizing the waiting time. We find that users are willing to wait longer for an additional answer if they have received a small number of answers. We then assume that users make a sequence of decisions, deciding to wait for an additional answer as long as the quality of the current answer exceeds some threshold. The resulting probability distribution for the number of answers that a question gets is an inverse Gaussian, a fact that is validated by our data.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718610","","Accuracy;Aggregates;Approximation methods;Communities;Context;Correlation;Face","Web sites;behavioural sciences;question answering (information retrieval)","Human Speed-Accuracy Tradeoffs;Yahoo Answers;inverse Gaussian;probability distribution;question-and-answer site","","0","","20","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Notice of Violation of IEEE Publication Principles<BR>Pipelined-MapReduce: An Improved MapReduce Parallel Programing Model","L. Wang; Z. Ni; Y. Zhang; Z. J. Wu; L. Tang","Sch. of Manage., Hefei Univ. of Technol., Hefei, China","2011 Fourth International Conference on Intelligent Computation Technology and Automation","20110415","2011","1","","871","874","Notice of Violation of IEEE Publication Principles<BR><BR>""Pipelined-MapReduced: An Improved MapReduce Parallel Programming Model""<BR>by Li Wang, Zhiwei Ni, Yiwen Zhang, Zhang Jun Wu, Liyang Tang<BR>in the Proceedings of the 2011 4th International Conference on Intelligent Computation Technology and Automation, March 2011, pp. 871-874<BR><BR> After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>This paper contains significant portions of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission. The lead author, Li Wang, was solely responsible for the misconduct, and submitted the paper without the knowledge or consent of the other authors.<BR><BR>Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:<BR><BR>""MapReduce Online""<BR>by Tyson Condie, Neil Conway, Peter Alvaro, Joseph M. Hellerstein<BR>in the Proceedings of the 7th USENIX Symposium on Networked Systems Design and Implementation (NSDI 2010), April 2010<BR><BR>MapReduce is a parallel programming model, and used to handle large datasets. The MapReduce program can be automatically concurrent executed in large-scale commodity machines. We proposed an improved MapReduce programming model-Pipelined-MapReduce, to solve the data intensive of information retrieval problems. Pipelined-MapReduce allows data transfer by pipeline between the operations, expanding the batched MapReduce programming model, and can reduce the completion time, and improve the system utilization rate. The experimental results demonstrate that the implementation of Pipelined-MapReduce can scale well and efficiently process large dataset- s on commodity machines.","","Electronic:978-0-7695-4353-6; POD:978-1-61284-289-9","10.1109/ICICTA.2011.593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750651","Hadoop;MapReduce;Parallel processing;Pipelined-MapReduce","Computational modeling;Fault tolerance;Fault tolerant systems;File systems;Google;Programming;Training","information retrieval;parallel programming;pipeline processing","MapReduce parallel programing model;batched MapReduce programming model;information retrieval problems;large scale commodity machines;pipelined-MapReduce","","2","","9","","","28-29 March 2011","","IEEE","IEEE Conference Publications"
"Virtual Museum Exhibition Designer Using Enhanced ARCO Standard","D. Biella; W. Luther; N. Baloian","ZIM, Univ. of Duisburg-Essen, Duisburg, Germany","2010 XXIX International Conference of the Chilean Computer Science Society","20110415","2010","","","226","235","A new Virtual Museum Exhibition Designer using an Enhanced ARCO Standard (ViMEDEAS) framework has been developed to support curators and visitors. It unifies features of a recently presented curator tool that allows exhibition planning and includes a functionality for editing existing exhibition layouts and visitors' museum tours and theReplicave2 framework that generates a Web-based virtual 3Dmuseum defined by various parameters at runtime. The framework uses the Virtual Museum and Cultural Object Exchange Format (VIMCOX), which includes new features such as room design and interactions with exhibits. VIMCOXis sufficiently flexible to gather the administrative, descriptive, technical and use metadata in a way that enables users to search the desired information and to create, display and manipulate virtual instances of artwork and whole exhibitions in a simple and intuitive way.","1522-4902;15224902","Electronic:978-0-7695-4400-7; POD:978-1-4577-0073-6","10.1109/SCCC.2010.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750519","3D Framework;Exhibition;Extended Virtual Museum Metadata Standard;Interaction types;Tour Planning","Art;Context;Cultural differences;Keyboards;Materials;Standards;Three dimensional displays","Internet;art;exhibitions;information retrieval;meta data;museums;solid modelling;virtual reality","Replicave2 framework;VIMCOX;Web based virtual 3D museum;artwork;cultural object exchange format;curator tool;enhanced ARCO standard;exhibition layout;exhibition planning;information search;metadata;virtual instances;virtual museum exhibition designer;visitor museum tour","","2","","31","","","15-19 Nov. 2010","","IEEE","IEEE Conference Publications"
"Information-Centric Multiaccess P2P Networks","O. Mammela; K. Pentikousis; P. Mannersalo","VTT Tech. Res. Centre of Finland, Oulu, Finland","2011 4th IFIP International Conference on New Technologies, Mobility and Security","20110228","2011","","","1","4","This paper explores the performance benefits of an information-centric network which capitalizes on overlapping multiaccess for content distribution. We present our architecture which uses an enhanced BitTorrent protocol, supports multiple network accesses simultaneously, and localizes information retrieval. We employ simulation to show the gains, on one hand, in individual node performance and, and on the other, in reduced load on the inter-operator traffic. Our simulation results indicate that download durations can be reduced, on median, by 33%. More importantly, upload throughput can increase significantly by 63%, on median. Finally, we show that our system can limit inter-domain traffic through hierarchical information-centric name resolution. The evidence we present indicates that an information-centric approach can be beneficial for both end users retrieving content such as files or video streaming, and for network opera-tors.","2157-4952;21574952","Electronic:978-1-4244-8704-2; POD:978-1-4244-8705-9; USB:978-1-4244-8703-5","10.1109/NTMS.2011.5720606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720606","","Internet;Logic gates;Peer to peer computing;Protocols;Throughput;Wireless LAN;Wireless communication","Internet;content management;information retrieval;peer-to-peer computing;video streaming;wireless LAN","BitTorrent protocol;content distribution;hierarchical information centric name resolution;information centric multiaccess P2P network;information retrieval;interoperator traffic;multiple network access;video streaming","","1","","18","","","7-10 Feb. 2011","","IEEE","IEEE Conference Publications"
"Design and Implementation of Electronic Medical Record Template Based on XML Schema","H. Yang","Sch. of Inf. Sci. & Eng., Lanzhou Univ. of Finance & Econ., Lanzhou, China","2010 Second World Congress on Software Engineering","20110222","2010","1","","225","228","It is critical to think of creating electronic medical record (EMR) templates for general utilization of EMR due to semi-structured features. Word processor is widely used for recording patient electronic information. However, the most weakness of these editors is that it is hard to extract medical data from text document. Also it is less flexible to present data in some other forms. This paper provides an effective solution to create EMR template and present medical data using word processor XML-Schema and XSL technologies. It has been approved that this is a practical approach to combine EMR import liberalization and structured organization using XML technology and popular word processor.","","Electronic:978-0-7695-4303-1; POD:978-1-4244-9287-9","10.1109/WCSE.2010.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718300","Electronic Medical Record Template;XML Schema;word processor","Data models;Medical diagnostic imaging;Medical services;Software;Writing;XML","XML;information retrieval;medical information systems;text analysis;word processing","EMR template;XML schema;XSL technology;electronic medical record template;import liberalization;medical data extraction;structured organization;text document;word processor","","0","","22","","","19-20 Dec. 2010","","IEEE","IEEE Conference Publications"
"An objective comparison of desktop search and visualization tools","V. L. Narasimhan; M. Lowe","Department of Computer Science, East Carolina University, Greenville, USA","Trendz in Information Sciences & Computing(TISC2010)","20110217","2010","","","206","209","Information workers deal with many types of computer information on a daily basis including documents from office productivity application suites, web sites, emails and online calendar appointments. Indexing and search packages for these types of desktop information have recently become commercially available, but they are in their infancy. This short paper provides i) an objective comparison of the approaches used by existing desktop search packages for crawling, indexing and search, and benchmark these packages against a set of metrics and ii) evaluates the potential for different visualizations of the search result items and the relationships between them.","2325-5919;23255919","Electronic:978-1-4244-9009-7; POD:978-1-4244-9007-3","10.1109/TISC.2010.5714640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714640","Desktop search engine;criteria for compariso;objective comparison;results of comparison","Electronic mail;Google;Indexing;Search engines;Search problems;Software","document handling;indexing;information retrieval;office automation;query formulation","computer information;data crawling;desktop information;desktop search packages;desktop searching;documents searching;information indexing;objective comparison;office productivity application suites;visualization tools","","0","","","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Building of the logic network of the information area of the corporation","N. Khairova; N. Sharonova","National technical university &#x201C;Kharkov Polytechnic Institute&#x201D;, Ukraine","2010 East-West Design & Test Symposium (EWDTS)","20110405","2010","","","371","373","The article describes the tasks of retrieving knowledge of corporative information systems. It has been suggested to apply math-based environment of the Intellect Theory and the groundwork of Computer Linguistics to intensify the semantic power of knowledge representation model. A mathematical relation between the local domain of manager research and reliable deep knowledge represented in the document has been modeled. A graphic realization as a logical network of personification predicate within manager knowledge domain has been carried out.","","Electronic:978-1-4244-9556-6; POD:978-1-4244-9555-9","10.1109/EWDTS.2010.5742044","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5742044","","Bipartite graph;Companies;Computational modeling;Information systems;Knowledge representation;Mathematical model;Semantics","computational linguistics;information retrieval;information systems;knowledge representation","computer linguistics;corporative information systems;graphic realization;intellect theory;knowledge representation;knowledge retrieving;logic network;semantic power","","0","","6","","","17-20 Sept. 2010","","IEEE","IEEE Conference Publications"
"Autonomous Content-Aware Multi-service Integration Technology to Achieve Timeliness in Evolving Situations","X. Lu; K. Mori","Dept. of Comput. Sci., Tokyo Inst. of Technol., Tokyo, Japan","2011 Tenth International Symposium on Autonomous Decentralized Systems","20110405","2011","","","209","215","Due to the large geographical region of business operations and external competitive pressures, information services are expected to collect, store, retrieve, integrate and distribute timely at remote and dispersed nodes. Nowadays, more and more users requests involve two or more correlated services at the same time. However, the most current information service systems for multi-service access are based on the middle process that is difficult to achieve the timeliness of users requirements. In this paper, the relationship that exists among the correlated services and the accessed contents for separate and integrated services is clarified. Based on these factors, the autonomous content-aware multi-service integration technology is proposed to achieve adaptability and timeliness of diversified interdependent requests. The simulation results show the effectiveness of proposed technology compared with the conventional systems.","1541-0056;15410056","Electronic:978-0-7695-4349-9; POD:978-1-61284-213-4","10.1109/ISADS.2011.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741313","correlated services;faded information field (FIF);integration;push/pull mobile agent (Push/Pull-MA)","Image edge detection;Information services;Joints;Magnetohydrodynamics;Mirrors;Monitoring;Servers","business data processing;information retrieval;information services;mobile agents","autonomous content aware multiservice integration technology;business operation;information service system;multiservice access;timeliness achievement;user requirement","","0","","15","","","23-27 March 2011","","IEEE","IEEE Conference Publications"
"Optimal Vendor Selection Using Fuzzy Case Based Reasoning","F. Na; W. Jinmin; L. Ping; M. Suchang","Tianjin Key Lab. of High Speed Cutting & Accurate Process Technol., Tianjin Univ. of Technol. & Educ., Tianjin, China","2011 Fourth International Conference on Intelligent Computation Technology and Automation","20110415","2011","1","","1082","1084","Vendor selection is the most important decision making process in supply chain management. To improve the vendor selection efficiency, a two level vendor selection model is proposed through case-based reasoning method. Fuzzy sets theory application is the fundamental to realize the vendor retrieval with fuzzy description of selection criteria and fuzzy similarity analysis. The optimal vendor solution is finalized using AHP after the vendor retrieval.","","Electronic:978-0-7695-4353-6; POD:978-1-61284-289-9","10.1109/ICICTA.2011.272","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750788","AHP;Vendor selection;case based reasoning;fuzzy membership;similarity analysis","Cognition;Decision making;Fuzzy sets;Materials;Mathematical model;Supply chain management;Supply chains","case-based reasoning;decision making;fuzzy reasoning;fuzzy set theory;information retrieval;supply chain management","AHP;decision making process;fuzzy case based reasoning;fuzzy description;fuzzy sets theory application;fuzzy similarity analysis;optimal vendor selection;supply chain management;vendor retrieval","","1","","7","","","28-29 March 2011","","IEEE","IEEE Conference Publications"
"Semantically-enhanced information extraction","H. Assal; J. Seng; F. Kurfess; E. Schwarz; K. Pohl","CAD Research Center, Cal Poly University, San Luis Obispo, CA, USA","2011 Aerospace Conference","20110411","2011","","","1","14","Information Extraction using Natural Language Processing (NLP) produces entities along with some of the relationships that may exist among them. To be semantically useful, however, such discrete extractions must be put into context through some form of intelligent analysis. This paper offers a two-part architecture that employs the statistical methods of traditional NLP to extract discrete information elements in a relatively domain-agnostic manner, which are then injected into an inference-enabled environment where they can be semantically analyzed. Within this semantic environment, extractions are woven into the contextual fabric of a user-provided, domain-centric ontology where users together with user-provided logic can analyze these extractions within a more contextually complete picture. Our demonstration system infers the possibility of a terrorist plot by extracting key events and relationships from a collection of news articles and intelligence reports.","1095-323X;1095323X","Electronic:978-1-4244-7351-9; POD:978-1-4244-7350-2","10.1109/AERO.2011.5747547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5747547","","Context;Data mining;Natural language processing;Ontologies;Search engines;Semantics","information retrieval;natural language processing;ontologies (artificial intelligence);statistical analysis","domain-centric ontology;inference-enabled environment;intelligent analysis;natural language processing;semantically-enhanced information extraction;statistical methods;terrorist plot;user-provided logic","","0","","21","","","5-12 March 2011","","IEEE","IEEE Conference Publications"
"Collaborative information linking: Bridging knowledge gaps between users by linking across applications","M. Waldner; D. Schmalstieg","Institute for Computer Graphics and Vision, Graz University of Technology, Austria","2011 IEEE Pacific Visualization Symposium","20110405","2011","","","115","122","Information exploration processes are often conducted in teams of experts, family members, or colleagues. These teams have to retrieve information from different sources, verify it, and finally compare and discuss their findings to find consensus. Today, support for these collaborative processes is limited and users often end up sharing either a single PC with one user taking control or using separate workstations, where support for tight collaboration is limited. In this paper, we present collaborative information linking which visually connects information across private and shared application windows to bridge knowledge gaps between users. We present the technical infrastructure for multi-user interaction and personalized meta-visualizations on large multi-projector displays, and demonstrate how personalized visual links connect information across existing applications modified in a minimally invasive manner. An observational experiment showed that information linking helps individuals to deal with large display space and teams to switch between individual information retrieval and joint verification and discussion.","2165-8765;21658765","Electronic:978-1-61284-934-8; POD:978-1-61284-935-5; USB:978-1-61284-933-1","10.1109/PACIFICVIS.2011.5742380","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5742380","Single-display groupware;collaborative information work;information linking","Browsers;Collaborative software;Collaborative work;Joining processes;Mice;Visualization","data visualisation;groupware;information analysis;information retrieval;workstation clusters","application windows;collaborative information linking;collaborative processes;information exploration processes;information retrieval;knowledge gaps;linking across applications;multiprojector displays;multiuser interaction;personalized metavisualizations;separate workstations;single PC;technical infrastructure","","3","","35","","","1-4 March 2011","","IEEE","IEEE Conference Publications"
"A Four Group Cross-Over Design for Measuring Irreversible Treatments on Web Search Tasks","L. Ma; D. Mease; D. M. Russell","Stanford Univ., Stanford, CA, USA","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","9","When trying to measure the effect of irreversible treatments such as training interventions, the choice of the experimental design can be difficult. A two group cross-over experimental design cannot be used due to longitudinal effects during the course of the experimental run, which can be especially large in dynamic web search environments. A standard case/control two group design also can be problematic because it is negatively impacted by variability among participants. Our solution uses a four group cross-over design that combines features from standard cross-over and case/control designs. We illustrate the effectiveness of this design through a case study in which participants are shown a video on how to use ""control-F"" to search for text within a web page. We quantify the improvement of our four group cross-over design compared to the standard case/control two group design with respect to measuring the effect of this video on participants. Finally, we compare the magnitude of our estimated ""control-F"" effect to similar studies on web ranking and user-interface changes, revealing that teaching this skill produces a potentially large improvement in web searchers' ability to search rapidly.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718609","","Atmospheric measurements;Data models;Google;Particle measurements;Web pages;Web search","Internet;information retrieval;search engines","Web search task;control-F;four group cross-over design;irreversible treatment;longitudinal effect","","0","","8","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Generating New Features Using Genetic Programming to Detect Link Spam","L. Shengen; N. Xiaofei; L. Peiqi; W. Lin","Sch. of Comput. Sci. & Technol., Shandong Jianzhu Univ., Jinan, China","2011 Fourth International Conference on Intelligent Computation Technology and Automation","20110415","2011","1","","135","138","Link spam techniques can enable some pages to achieve higher-than-deserved rankings in the results of a search engine. They negatively affect the quality of search results. Classification methods can detect link spam. For classification problem, features play an important role. This paper proposes to derive new features using genetic programming from existing link-based features and use the new features as the inputs to SVM and GP classifiers for the identification of link spam. Experiments on WEBSPAM-UK2006 show that the classification results of the classifiers that use 10 newly generated features are much better than those of the classifiers that use original 41 link-based features and equivalent to those of the classifiers that use 138 transformed link-based features. The newly generated features can improve the link spam classification performance.","","Electronic:978-0-7695-4353-6; POD:978-1-61284-289-9","10.1109/ICICTA.2011.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750574","Feature Generation;Genetic Programming;Link Spam","Accuracy;Binary trees;Feature extraction;Genetic programming;Support vector machines;Unsolicited electronic mail;Web pages","Internet;feature extraction;genetic algorithms;information retrieval;pattern classification;search engines;support vector machines","GP classifier;SVM;WEBSPAM-UK2006;classification method;genetic programming;link spam detection;link-based feature generation;search engine;search result quality","","4","","12","","","28-29 March 2011","","IEEE","IEEE Conference Publications"
"Secure data access in cloud computing","S. Sanka; C. Hota; M. Rajarajan","Computer Science and Information Systems Group, Birla Institute of Technology and Science-Pilani, Hyderabad Campus, Shameerpet, INDIA, 500078","2010 IEEE 4th International Conference on Internet Multimedia Services Architecture and Application","20110310","2010","","","1","6","Data security and access control is one of the most challenging ongoing research work in cloud computing, because of users outsourcing their sensitive data to cloud providers. Existing solutions that use pure cryptographic techniques to mitigate these security and access control problems suffer from heavy computational overhead on the data owner as well as the cloud service provider for key distribution and management. This paper addresses this challenging open problem using capability based access control technique that ensures only valid users will access the outsourced data. This work also proposes a modified Diffie-Hellman key exchange protocol between cloud service provider and the user for secretly sharing a symmetric key for secure data access that alleviates the problem of key distribution and management at cloud service provider. The simulation run and analysis shows that the proposed approach is highly efficient and secure under existing security models.","","Electronic:978-1-4244-7932-0; POD:978-1-4244-7930-6","10.1109/IMSAA.2010.5729397","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5729397","Access control;Capability;Cloud computing;Cryptography;Security","Access control;Cloud computing;Encryption;Public key;Servers","authorisation;cloud computing;cryptographic protocols;information retrieval;public key cryptography","Diffie-Hellman key exchange protocol;access control;cloud computing;cloud service provider;cryptographic technique;data security;key distribution;key management;outsourced data;public key encryption;secret symmetric key sharing;secure data access","","16","","22","","","15-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"A Strategy for Deploying Secure Cloud-Based Natural Language Processing Systems for Applied Research Involving Clinical Text","D. Carrell","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","11","Natural language processing (NLP) of clinical text offers great potential to expand secondary use of high-value electronic health record (EHR) data, but a barrier to adopting NLP is the high total cost of operation, driven mainly by the costs and limited availability of technical personnel in applied health research settings. To overcome this barrier we propose a cloud-based service systems model by which entire NLP systems deployed in the cloud are cloned and provided to the adopting institution for their exclusive and unlimited use. Useful algorithms that perform various information extraction and classification tasks are built in to the NLP system. A rationale and model for cloud-deployed NLP is presented and the inherent data security and patient privacy issues it raises addressed. Both technical and socio-institutional security issues are discussed in the context of the unique challenges associated with processing highly regulated clinical text in an unconventional computing environment. Results of a June 2010 survey of Institutional Review Board (IRB) managers in applied research settings are presented. Survey questions address IRB managers' readiness to approve research projects involving cloud-based NLP technologies. Useful next steps and information needs are presented in the conclusion.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718592","","Biological system modeling;Cloning;Cloud computing;Computational modeling;Fires;Security;Virtual private networks","classification;cloud computing;data privacy;information retrieval;medical information systems;natural language processing;security of data;text analysis","NLP system;classification task;clinical text;cloud-based service systems model;cloud-deployed NLP;data security;high-value electronic health record;information extraction;patient privacy;secure cloud-based natural language processing system;socio-institutional security;technical security","","2","","21","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Beats: An interactive research oriented ECG analysis system","S. C. Man; A. C. Maan; E. E. van der Wall; M. J. Schalij; C. A. Swenne","Leiden University Medical Center, The Netherlands","2010 Computing in Cardiology","20110322","2010","","","1007","1010","We developed BEATS (Beat Editing And Tracking Software), an interactive program to extract beat-to-beat information about the QRST complex. It is aimed at recordings of intermediate length, typically 20 minutes, corresponding to an average exercise ECG. BEATS accepts any 8-channel ECG recording which is then converted into a 3-channel vectorcardiographic X, Y, Z representation and the spatial velocity. After beat detection the user aids the program in determining the global positions of the onset QRS, J point and T apex at several different heart rates. From the global T apices the local T apex, the steepest slope in the descending limb of the T wave and the end of the T wave are determined. BEATS produces a file with baseline corrected signals and a file with the parameters for each QRST complex. These files can be used as input for other programs that run unattended and extract QRST features like QRS- and T-integrals, QRST angle, etc.","0276-6574;02766574","Electronic:978-1-4244-7319-9; POD:978-1-4244-7318-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738146","","Cardiology;Computers;Electrocardiography;Feature extraction;Heart rate;Lead;Software","biomechanics;electrocardiography;information retrieval systems;interactive programming;medical information systems;medical signal processing","3-channel vectorcardiography;8-channel ECG recording;BEATS software;Beat Editing And Tracking Software;ECG analysis system;QRST complex;T wave;baseline corrected signals;exercise;heart rate;information extraction;interactive program;spatial velocity","","5","","5","","","26-29 Sept. 2010","","IEEE","IEEE Conference Publications"
"Semantic service discovery based on parametric dependency relations","H. Y. Han; Y. S. Kim; K. H. Lee","Department of Computer science, Yonsei University, 134 Shinchon-dong Sudaemoon-ku Seoul, 120-749, Korea","The International Conference on Information Networking 2011 (ICOIN2011)","20110303","2011","","","530","535","As the number of Web services has increased, how to locate services becomes an important research issue. Previous works for semantic Web services discovery have been proposed. Since they lack a sophisticated scheme of specifying services' advertisements and users' requirements, they may not discover services, which satisfy the intention of service requesters. To resolve this problem, we propose a noble scheme to represent and utilize the dependency between I/O parameters. In addition to the conventional semantic matchmaking of I/O parameters, the dependency relations among them are also considered. From experimental results we can find that the proposed method based on the parametric dependency relations performs better than previous works.","1550-445X;1550445X","Electronic:978-1-61284-663-7; POD:978-1-61284-661-3","10.1109/ICOIN.2011.5723154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723154","Parametric relation;Semantic Web services;Web services discovery","Bicycles;Books;Cities and towns;Matched filters;Semantic Web;Semantics;Web services","Web services;information retrieval;semantic Web","Web services;parametric dependency relations;semantic matchmaking;semantic service discovery","","2","","16","","","26-28 Jan. 2011","","IEEE","IEEE Conference Publications"
"Application of type-2 fuzzy logic to healthcare literature search at point of care","M. Alatrash; H. Ying; P. Dews; M. Dong; W. Wu; M. Massanari","Department of Electrical and Computer Engineering, Wayne State University, Detroit, Michigan, USA","2011 Annual Meeting of the North American Fuzzy Information Processing Society","20110419","2011","","","1","5","The biomedical field publishes a huge volume of articles every year and most of them are now available online as PDF full-texts. here is still no an effective search mechanisim that could locate the full-text articles very narrowly matching the users preference quickly. Such a mechanisim can be important for many real-time applications such as information at point of care for a physician who only has a minute or two to find relevant information in the literature for his/her decision making. We explore to develop such a mechanism with the help of type-2 fuzzy sets and fuzzy logic. Our current focus is on the full-text articles in the PubMed database. We have implemented the system using Java programming language. We show the preliminary result on the usefulness of the fuzzy logic. Unlike most search engines, which are interactive in nature, our eventual system is designed to operate automatically (hence, it can be used for literature monitoring, for instance).","Pending","Electronic:978-1-61284-968-3; POD:978-1-4799-1692-4; USB:978-1-61284-967-6","10.1109/NAFIPS.2011.5752002","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5752002","Biomedicine;PDF;Text Mining;Type-2 Fuzzy Sets","Databases;Feature extraction;Fuzzy logic;Fuzzy sets;Libraries;Medical services;Search engines","Java;fuzzy logic;fuzzy set theory;health care;information retrieval;medical computing","Java programming language;biomedical field;healthcare literature search;point-of-care;search mechanism;type-2 fuzzy logic;type-2 fuzzy set","","2","","24","","","18-20 March 2011","","IEEE","IEEE Conference Publications"
"A Highly Flexible System for Smart Home Sensor Networks","J. C. Liu; K. Y. Chuang; C. F. Ye","Dept. of Comput. Sci. & Inf. Eng., Yuanpei Univ., Hsinchu, Taiwan","2010 Fourth International Conference on Genetic and Evolutionary Computing","20110217","2010","","","775","778","With the rapidly growth of wireless sensor networks (WSN), more and more services provide people up-to-date information such as weather forecast, earthquake reports, fire alarm, even for the surveillance system, and so on. The raw data are usually hard to be understood by users. We had proposed an innovated sensor observation service with web-based and GIS-based architecture, which is named WSN Application Service Platform (WASP). WASP is a data management center, which designed with the concept of Services Oriented Application (SOA) as a Cloud Service. The raw data can be transferred into add-on valued data and shown on the web pages through WASP. Users can query and obtain the valuable information and realize the meanings of these data through web-based interfaces, which is defined in Sensor Web Enablement (SWE) by Open Geospatial Consortium (OGC). Based on WASP, we propose a flexible SWE-based Data Observation and Event Notification Framework on Social Networks for smart home applications. Data can be shown immediately on social networks (i.e. Face book) via the framework. All sensors and devices provide their location information to data center and form a community. The proposed framework provides remote control functions for WSN to increase the data retrieval efficiency based on OGC SWE Sensor Observation Service (SOS), Sensor Planning Service (SPS), and Sensor Alert Service (SAS). The proposed system is helpful and efficient for user to enjoy the smart home applications.","","Electronic:978-0-7695-4281-2; POD:978-1-4244-8891-9","10.1109/ICGEC.2010.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715546","OGC;SAS;SOA;SOS;SPS;SWE;WASP;WSN","Computer architecture;Geospatial analysis;Smart homes;Social network services;Synthetic aperture sonar;Web services;Wireless sensor networks","Web services;cloud computing;computer centres;geographic information systems;home automation;information retrieval;service-oriented architecture;social networking (online);telecontrol;wireless sensor networks","WSN application service platform;cloud service;data management center;data retrieval;open geospatial consortium;sensor alert service;sensor observation service;sensor planning service;sensor web enablement;services oriented application;smart home sensor network;social networks;web page;wireless sensor network","","2","","25","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Mixing Deduplication and Compression on Active Data Sets","C. Constantinescu; J. Glider; D. Chambliss","IBM Almaden Res. Center, San Jose, CA, USA","2011 Data Compression Conference","20110411","2011","","","393","402","Many new storage systems provide some form of data reduction. We examine data reduction methods that might be suitable for emph{primary} storage systems serving active data (as contrasted with backup and archive systems), by analysis of file sets found in different active data environments. We address questions of: how effective are compression and variations of deduplication, both separately and in combination, when deduplication and compression are combined, which should be applied first, what will the tradeoff be between the different methods in their use of MIPS relative to the data reduction achieved, and what degree of data reduction should be expected for different data types.","1068-0314;10680314","Electronic:978-0-7695-4352-9; POD:978-1-61284-279-0","10.1109/DCC.2011.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5749497","data reduction;deduplication;storage systems","Algorithm design and analysis;Biomedical imaging;Databases;Image coding;Portable computers;Servers;Virtual machining","data analysis;data compression;information retrieval","MIPS;active data environment;active data sets compression;data reduction method;deduplication mixing;primary storage system","","9","2","4","","","29-31 March 2011","","IEEE","IEEE Conference Publications"
"An automatic answering system with template matching for natural language questions","T. Gunawardena; M. Lokuhetti; N. Pathirana; R. Ragel; S. Deegalla","Faculty of Engineering, University of Peradeniya, Peradeniya 20400 Sri Lanka","2010 Fifth International Conference on Information and Automation for Sustainability","20110217","2010","","","353","358","Using computers to answer natural language questions is an interesting and challenging problem. Generally such problems are handled under two categories: open domain problems and close domain problems. This paper presents a system that attempts to solve close domain problems. Typically, in a close domain, answers to questions are not available in the public domain and therefore they cannot be searched using a search engine. Hence answers have to be stored in a database by a domain expert. Then, the challenge is to understand the natural language question so that the solution could be matched to the respective answer in the database. We use a template matching technique to perform this matching. In addition, given that our target is to use this system with non-native English speakers, we developed a method to overcome the mismatches we might encounter due to spelling mistakes. The system is developed such that the questions can be asked using short messages from a mobile phone and therefore the system is designed to understand SMS language in addition to English. One of the main contributions of this paper is the outcome presented of a deployment of this system in a real environment.","2151-1802;21511802","Electronic:978-1-4244-8552-9; POD:978-1-4244-8549-9","10.1109/ICIAFS.2010.5715686","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715686","Answering System;FAQ;SMS;Template Matching","Artificial intelligence;Computers;Databases;Mobile handsets;Natural languages;Robots;Syntactics","mobile computing;natural language processing;pattern matching;question answering (information retrieval);search engines","English language;SMS language;automatic answering system;mobile phone;natural language question;search engine;short message system;template matching technique","","4","1","12","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Scalable metadata-directed search in a network of information","K. Palmskog; A. G. Prieto; C. Meirosu; R. Stadler; M. Dam","KTH Royal Institute of Technology, Lindstedtsv&#x00E4;gen 3, 10044 Stockholm, Sweden","2010 Future Network & Mobile Summit","20110303","2010","","","1","8","The information-centric paradigm has been recently proposed for the design of future networking systems. A key requirement for realising such systems is having mechanisms that provide efficient, scalable and accurate information search. In this paper, we present solutions for both one-time and continuous searches. Our solution for one-time searches is scalable for its search completion time grows sublinearly with the system size. In addition, the overhead it introduces is evenly distributed. For our solution for continuous searches, we discuss its tradeoff between load (efficiency) and timeliness (accuracy).","","Electronic:978-1-905824-18-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5722376","distributed management;information-centric networking;metadata search","Accuracy;Electronic mail;Google;IEEE Potentials;Publish-subscribe;Routing;Scalability","information networks;information retrieval","information network;information-centric paradigm;networking system;one-time search;scalable metadata-directed search;search completion time","","1","","20","","","16-18 June 2010","","IEEE","IEEE Conference Publications"
"A Dual Approach to Detect Pharming Attacks at the Client-Side","S. Gastellier-Prevost; G. Gonzalez Granadillo; M. Laurent","Inst. Telecom, Telecom SudParis, Evry, France","2011 4th IFIP International Conference on New Technologies, Mobility and Security","20110228","2011","","","1","5","Pharming attacks - a sophisticated version of phishing attacks - aim to steal users' credentials by redirecting them to a fraudulent website using DNS-based techniques. Pharming attacks can be performed at the client-side or into the Internet, using complex and well designed techniques that make the attack often imperceptible to the user. With the deployment of broadband connections for Internet access, personal networks are a privileged target for attackers. In this paper, we propose a dual approach to provide an anti-pharming protection integrated into the client's browser. Our approach combines both an IP address check as well as a webpage content analysis, using the information provided by multiple DNS servers. We present first experimental results and we discuss about future works and limitations of our approach.","2157-4952;21574952","Electronic:978-1-4244-8704-2; POD:978-1-4244-8705-9; USB:978-1-4244-8703-5","10.1109/NTMS.2011.5721063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5721063","","Browsers;Computer crime;Databases;HTML;IP networks;Internet;Servers","IP networks;Internet;Web sites;broadband networks;computer crime;computer network security;information retrieval;unsolicited e-mail","DNS server;IP address check;Internet access;Web page content analysis;antipharming protection;broadband connection;client browser;client-side;fraudulent Web site;personal network;pharming attack detection;phishing attack","","1","","13","","","7-10 Feb. 2011","","IEEE","IEEE Conference Publications"
"Collaborative e-Marketplaces Containing Clusters of SMEs: Drivers and Barriers in the Local Food Sector","A. Petrakou; P. Brandt; R. Gustavsson; P. Jokela","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","This paper explores the current context of collaboration between small local food producers. The aim is to facilitate the design and maintenance of trustworthy collaborative e-marketplaces containing clusters of SMEs. An ethnographic approach was used and data was collected through observations, interviews and questionnaires. Our findings reveal both drivers to exploit and barriers to harness enabling trustworthy collaboration. Our current test bed is based on a research and design context that lacks mechanisms for governance. To take full advantage of the drivers and to tackle the barriers in a fruitful way, there is a need for a flexible infra-structure that allow for structured requirements, contractual agreements and validation of proposed collaboration services. To address this, we take advantage of recent developments in cloud computing, more specifically the integration of Platform as a Service (PaaS) in the support system.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718482","","Business;Collaboration;Context;Driver circuits;Interviews;Joints;Production","electronic commerce;food manufacturing;groupware;marketing data processing;question answering (information retrieval);small-to-medium enterprises","SME clusters;cloud computing;collaboration service;contractual agreement;ethnographic approach;local food producer;local food sector;platform as a service;questionnaires;structured requirement;trustworthy collaborative e-marketplace","","2","","35","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Effective Web content recommendation based on consumer behavior modeling","B. Zhou; A. C. M. Fong; S. C. Hui; T. A. Do","Semantic Integration, IBM Research, China","2011 IEEE International Conference on Consumer Electronics (ICCE)","20110303","2011","","","471","472","Web surfing has become an important activity for many consumers. We propose a web recommender that models user behavior by constructing a know ledge base using temporal web access patterns as input. We apply fuzzy logic to represent real-life temp oral concepts and requested resources of periodic pattern-based web access activities. Th e fuzzy representation is used to construct a know ledge base of the user's web access behaviors, which is then used to provide timely and personalized recommendations to the user, possibly on their portable devices. Experiments conducted to e valuate the performance of the proposed approach have shown very promising results.","2158-3994;21583994","DVD:978-1-4244-8710-3; Electronic:978-1-4244-8712-7; POD:978-1-4244-8711-0","10.1109/ICCE.2011.5722689","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5722689","","Conferences;Consumer electronics","Web services;behavioural sciences computing;consumer behaviour;data mining;fuzzy logic;information retrieval;knowledge based systems;recommender systems","Web content recommendation;Web surfing;consumer behavior modeling;fuzzy logic;fuzzy representation;knowledge base;temporal Web access patterns","","0","","7","","","9-12 Jan. 2011","","IEEE","IEEE Conference Publications"
"Integrity preservation and privacy protection for medical images with histogram-based reversible data hiding","H. C. Huang; W. C. Fang","National University of Kaohsiung, Taiwan, R.O.C.","2011 IEEE/NIH Life Science Systems and Applications Workshop (LiSSA)","20110421","2011","","","108","111","For medical treatments, the integrity of the medical images, the authenticity of corresponding medical records, and the privacy of the patients are crucial requirements for the diagnosis of patient's disease. Therefore, how to retain the validity between images and medical records is an important topic for researches and real applications. In this paper, we apply the concept and implementation in digital rights management (DRM) systems, and propose a functional scheme for the above-mentioned goals. We employ the reversible data hiding scheme, a newly developed branch in DRM researches, for combating the goals. With the term of reversibility, it means that data, including patients' private information and the diagnosis data, can be hidden into the medical image by some means. Later on, the medical image containing data might be retrieved while necessary, and both the original image and the hidden data can be perfectly recovered. Data can be authenticated for enhanced privacy protection. Simulation results present the applicability of such an implementation.","","Electronic:978-1-4577-0422-2; POD:978-1-4577-0421-5","10.1109/LISSA.2011.5754168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5754168","","Data mining;Histograms;Medical diagnostic imaging;Medical services;Pixel;Watermarking","data encapsulation;data integrity;data privacy;digital rights management;information retrieval;medical information systems","authenticity;digital rights management systems;histogram-based reversible data hiding;integrity preservation;medical images;privacy protection;reversibility","","3","1","5","","","7-8 April 2011","","IEEE","IEEE Conference Publications"
"An overview of decision making in Rough Non-deterministic Information Analysis","H. Okuma; M. Nakata; D. Ślęzak; H. Sakai","Faculty of Education and Welfare Science, Oita University, Dannoharu, 870, Japan","2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)","20110217","2010","","","345","350","Rough Non-deterministic Information Analysis (RNIA) is a rough set-based data analysis framework for Non-deterministic Information Systems (NISs). RNIA-related algorithms and software tools developed so far for rule generation provide good characteristics of NISs and can be successfully applied to decision making based on non-deterministic data. This article presents a general overview of Decision Making in RNIA including both theoretical and algorithmic aspects of the theory. We mainly focused on the following aspects of RNIA: (1) a question-answering functionality that enables decision makers to analyze data gathered in NISs, (2) an automatic decision rule generation with stability factor.","","Electronic:978-1-4244-7376-2; POD:978-1-4244-7377-9","10.1109/NABIC.2010.5716296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716296","Apriori algorithm;Decision making;Incomplete information;Rough non-deterministic information analysis;Rule generation;Stability factor","","decision making;information systems;knowledge acquisition;question answering (information retrieval);rough set theory;software tools","decision making;nondeterministic information system;question answering function;rough nondeterministic information analysis;rough set based data analysis;rule generation;software tool","","1","","14","","","15-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Automating Coverage Metrics for Dynamic Web Applications","M. H. Alalfi; J. R. Cordy; T. R. Dean","Sch. of Comput., Queen's Univ., Kingston, ON, Canada","2010 14th European Conference on Software Maintenance and Reengineering","20110217","2010","","","51","60","Building comprehensive test suites for web applications poses new challenges in software testing. Coverage criteria used for traditional systems to assess the quality of test cases are simply not sufficient for complex dynamic applications. As a result, faults in web applications can often be traced to insufficient testing coverage of the complex interactions between the components. This paper presents a new set of coverage criteria for web applications, based on page access, use of server variables, and interactions with the database. Following an instrumentation transformation to insert dynamic tracking of these aspects, a static analysis is used to automatically create a coverage database by extracting and executing only the instrumentation statements of the program. The database is then updated dynamically during execution by the instrumentation calls themselves. We demonstrate the usefulness of our coverage criteria and the precision of our approach on the analysis of the popular internet bulletin board system PhpBB 2.0.","1534-5351;15345351","Electronic:978-0-7695-4321-5; POD:978-1-61284-369-8","10.1109/CSMR.2010.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714417","Enhancement;Maintenance;Reverse Engineering;Testing;Web Applications","Arrays;Databases;Grammar;Instruments;Measurement;Servers;Testing","Internet;information retrieval;program diagnostics;program testing;reverse engineering","Internet bulletin board system;PhpBB 2.0;complex dynamic application;coverage criteria;coverage metrics;dynamic Web application;dynamic tracking;instrumentation transformation;page access;server variable;software testing;static analysis;testing coverage","","3","","14","","","15-18 March 2010","","IEEE","IEEE Conference Publications"
"Oh Dear, We Bought Our Competitor: Integrating Similar Software Systems","R. Land; I. Crnkovic","M&#x0E4;lardalen University","IEEE Software","20110228","2011","28","2","75","82","A look at 10 case studies addresses the technological, personnel, and organizational challenges. The 10 cases involved seven organizations in different business sectors. Our data collection methods included our participation in projects, several rounds of interviews with project leaders and software architects, and several rounds of questionnaires with software architects and project managers, as well as project and product documentation. 2 Companies we studied included ABB, Bombardier, Ericsson, Saab, and Westinghouse. However, we can't disclose detailed information or relate case descriptions to specific companies or systems. Our observations regarding cultural influences might be skewed because all the organizations involved Sweden and other European or North American countries.","0740-7459;07407459","","10.1109/MS.2010.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467014","interoperability;process implementation;project management;software engineering","","business data processing;organisational aspects;project management;question answering (information retrieval);software architecture;system documentation","business sector;data collection method;organizational challenge;product documentation;project leader;project managers;questionnaires;software architects;software system","","0","","11","","20100520","March-April 2011","","IEEE","IEEE Journals & Magazines"
"New EPICS Channel Archiver based on MDSplus data system","G. Manduchi; A. Luchetta; C. Taliercio; A. Soppelsa; A. Barbalace","Consorzio RFX, Associazione Euratom-ENEA sulla fusione, Corso Stati Uniti, 4 - 35127 Padova - Italy","2010 17th IEEE-NPSS Real Time Conference","20110415","2010","","","1","4","The EPICS Channel Archiver is used to store data exported by EPICS I/O Controllers (IOCs). The Channel Archiver acts as a Channel Access Client (CAC) and stores recorded data, acquired via periodic scan or monitored, into indexed binary files. MDSplus is a data management system used in several Nuclear Fusion experiments to handle experimental and configuration data. A data access Application Programming Interface (API) for local and remote data access is available for several languages, namely C, C++, Fortran, Java, Python, MATLAB and H>;L, and a set of visualization tools is available for data browsing and display. The paper presents a new implementation of the EPICS Channel Archiver which uses MDSplus for data storage. In this way, it is possible to take advantage of the availability of the local and remote data access layers of MDSplus, widely used in the fusion community to handle large sets of data. A performance comparison between the original implementation and the new one is provided. In particular, the storage space requirements and the data access speed are considered.","","Electronic:978-1-4244-7110-2; POD:978-1-4244-7108-9","10.1109/RTC.2010.5750466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750466","","Data acquisition;Data visualization;Databases;Java;Monitoring;Protocols;XML","application program interfaces;data visualisation;database management systems;information retrieval systems;nuclear fusion","C language;C++ language;EPICS channel archiver;EPICS input-output controller;Fortran language;Java language;MDSplus data system;Matlab;Python language;channel access client;data access application programming interface;data management system;nuclear fusion experiments;visualization tools","","1","","8","","","24-28 May 2010","","IEEE","IEEE Conference Publications"
"Improving data accessibility in mobile ad hoc networks","R. Nandhakumar; A. Saravanan","Sree Sastha Inst. of Eng. &amp; Technol., Chennai, India","Recent Advances in Space Technology Services and Climate Change 2010 (RSTS & CC-2010)","20110214","2010","","","69","73","In mobile ad hoc networks, the networks topology changes dynamically and partition among mobile nodes occur frequently. These are due to unpredictable mobility of mobile nodes and each mobile nodes act as routers which discover and maintain routes, and forward packets to other nodes. We address the problem of replication in mobile ad hoc networks by exploring group mobility approach. Group mobility refer to the scenario where several mobile nodes are tends to move together. Group mobility approach is used to increase the data accessibility among mobile nodes through data replication and consistency group management. It also guarantees basic level of system performance, such as throughput, delay and reduces the networks traffic among mobile nodes.","","Electronic:978-1-4244-9183-4; POD:978-1-4244-9184-1","10.1109/RSTSCC.2010.5712802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5712802","","Mobile ad hoc networks;Mobile communication;Mobile computing;Resource management;Servers;Wireless communication","information retrieval;mobile ad hoc networks;telecommunication network routing;telecommunication network topology","data accessibility;forward packets;group mobility;mobile ad hoc networks;networks topology;routers","","3","","10","","","13-15 Nov. 2010","","IEEE","IEEE Conference Publications"
"Automate session setup based on machine learning","J. Putrevu; X. Wu; V. Krishnaswamy","IP Communications Department, Avaya Labs Research, Basking Ridge, NJ, USA","2010 IEEE 4th International Conference on Internet Multimedia Services Architecture and Application","20110310","2010","","","1","6","This paper proposes a system of using machine learning algorithms to extract communication session information, such as conference bridge number and participant code, from users' emails or appointments. Our system can then use the retrieved information to easily setup a communication session, for example, dialing conference bridge number and participant code, as well as popping up web conference links with simply one click. Our system can also verify the retrieved information by monitoring users' communication sessions. This paper presents the overall architecture and uses the one-click-conferencing feature as an example to illustrate our system.","","Electronic:978-1-4244-7932-0; POD:978-1-4244-7930-6","10.1109/IMSAA.2010.5729389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5729389","machine learning;one-click-conferencing","Bridges;Classification algorithms;Decision trees;Electronic mail;Machine learning;Servers;Training","Internet telephony;information retrieval;learning (artificial intelligence);teleconferencing","Web conference links;automate session setup;communication session information;machine learning;monitoring;one-click-conferencing feature","","0","","13","","","15-17 Dec. 2010","","IEEE","IEEE Conference Publications"
"Automatic Extraction of Multiword Expressions Combining Statistical and Similarity Approaches","J. Xu; J. Yu; H. Wang","Dept. of Language & Inf. Eng., Peking Univ., Beijing, China","2010 Fourth International Conference on Genetic and Evolutionary Computing","20110217","2010","","","256","259","Multiword expressions (MWEs) are important for practical applications, such as machine translation (henceforth, MT), multilingual information retrieval, data mining and other natural language processing. A method of combining similarity measure and statistical tool is proposed for automatically extracting English MWEs from the corpus of Chinese government white papers and work reports from 1991 to 2010. Statistical approach is employed to calculate the co-occurrence affinity between two words. Besides, similarity measure is harnessed to compute the semantic relations between words for improving MWE coverage, thus aiming at obtaining higher precision and recall in extracting candidate multiword expressions. Experimental results showed the proposed technique improved MWE extraction efficiently.","","Electronic:978-0-7695-4281-2; POD:978-1-4244-8891-9","10.1109/ICGEC.2010.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715418","co-occurrence affinity;multiword expressions;similarity approach;statistical tool","Computational linguistics;Conferences;Data mining;Government;Natural language processing;Pragmatics;Semantics","information retrieval;natural languages;statistical analysis;word processing","Chinese government;English;automatic extraction;multiword expression;semantic relation;similarity approach;statistical approach;white paper;work report","","0","","20","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Detection of Verbatim or Partial Duplication from Multiple Source Documents Using Data Mining Techniques and Case-Based Reasoning Methodologies","C. Chaudhuri; A. Chaudhuri","Dept. of Comput. Sci. & Eng., Jadavpur Univ., Kolkata, India","2011 Second International Conference on Emerging Applications of Information Technology","20110317","2011","","","129","132","This paper aims to specify a Case-Based Reasoning strategy for correctly classifying, storing and preventing duplication efforts of electronic text material. Preservation of complete source documents for checking similarity between them pose a daunting amount of spatial and computational complexity to researchers in this area. The problem is partially solved by applying certain preprocessing steps to reduce the volume of data handling substantially. Reduction of volume in text documents is achieved by applying some stemming algorithm and elimination of stop words from the document utilizing certain text-mining measures such as TF-IDF. A third technique involves extraction of keywords and storing them in a properly indexed base. These then can serve the dual purpose of providing solutions to Lazy Learning classification for automatic subject-wise archiving and formation of relevant word sequences for detection of plagiarism using Association Rule-mining techniques.","","Electronic:978-0-7695-4329-1; POD:978-1-4244-9683-9","10.1109/EAIT.2011.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734933","Association Rule-mining techniques;Case-BasedReasoning strategies;Plagiarism;TF-IDF","Algorithm design and analysis;Classification algorithms;Cognition;Data mining;Frequency conversion;Plagiarism;Time frequency analysis","case-based reasoning;data mining;information retrieval;learning (artificial intelligence);pattern classification;reproduction (copying);text analysis","TF-IDF;association rule mining;automatic subject wise archiving;case based reasoning;data handling;data mining;electronic text material;keyword extraction;lazy learning classification;multiple source document;partial duplication;plagiarism detection;similarity check;stemming algorithm;stopword elimination;text document;text mining measure;verbatim detection;word sequences","","0","","7","","","19-20 Feb. 2011","","IEEE","IEEE Conference Publications"
"Hypergraph Partition with Harmonic Average Top-N and PCA for Topic Detection","X. Liu; F. Ma; H. Lin; H. Shen","Sch. of Comput. Sci. & Technol., Dalian Univ. of Technol., Dalian, China","2010 3rd International Symposium on Parallel Architectures, Algorithms and Programming","20110217","2010","","","269","276","An algorithm named SMHP is proposed, which aims at improving the efficiency of Topic Detection. In SMHP, a T-MI-TFIDF model is designed by introducing mutual information (MI) and enhancing the weight of terms in the title. Then VSM is constructed according to terms' weight, and the dimension is reduced by combining H-TOPN and PCA. Then topics are grouped based on SMHP. Experiment results show the proposed methods are more suitable for clustering topics. SMHP with novel approaches can effectively solve the relationship of multiple stories problem and improve the accuracy of cluster results.","2168-3034;21683034","Electronic:978-0-7695-4312-3; POD:978-1-4244-9482-8","10.1109/PAAP.2010.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715093","","Algorithm design and analysis;Clustering algorithms;Harmonic analysis;Mutual information;Noise;Partitioning algorithms;Principal component analysis","graph theory;information retrieval;pattern clustering;principal component analysis;text analysis","H-TOPN;PCA;SMHP algorithm;T-MI-TFIDF model;VSM;clustering topics;harmonic average Top-N;hypergraph partition;multiple stories problem;mutual information;topic detection","","0","","25","","","18-20 Dec. 2010","","IEEE","IEEE Conference Publications"
"Performance analysis on ranked queries in uncertain databases","S. Selvarani; R. Janarthanan","Dept. of Comput. Sci. &amp; Eng., Jaya Eng. Coll., Chennai, India","Trendz in Information Sciences & Computing(TISC2010)","20110217","2010","","","63","67","Top-k processing in Uncertain Databases is semantically and computationally different from traditional top-k processing. The interplay between score and uncertainty information makes traditional top-k processing techniques inapplicable to uncertain databases. The existing approaches are all based on the assumption that the underlying data are exact (or certain). We construct a framework that encapsulates a novel probabilistic model and efficient query processing techniques to tackle the challenges raised by uncertain data settings. We introduce two effective pruning methods, spatial and probabilistic pruning, to help reduce the PRank search space. A special case of PRank with linear preference functions is also studied. Then, we seamlessly integrate these pruning heuristics into the PRank query procedure. And We would have propose and tackle the PRank query processing over the join of two distinct uncertain databases by means of J-Prank Query Processing. We provide efficient solutions to compute this ranking across the major models of uncertain data, such as attribute-level and tuple-level uncertainty. For an uncertain relation of N tuples, the processing cost is O(N log N)-no worse than simply sorting the relation. To demonstrate the efficiency and effectiveness of our proposed approaches in answering PRank queries, extensive experiments have been done in terms of both wall clock time and the number of candidates to be refined.","2325-5919;23255919","Electronic:978-1-4244-9009-7; POD:978-1-4244-9007-3","10.1109/TISC.2010.5714610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714610","J-Prank;Prank;Probabilistic ranked query;probabilistic ranked query on join;uncertain database","Data models;Indexes;Probabilistic logic;Query processing;Uncertainty;Upper bound","computational complexity;probability;query processing;question answering (information retrieval);search problems;uncertainty handling","J-Prank query processing;PRank query answering;PRank query processing;PRank search space;linear preference functions;performance analysis;probabilistic pruning;pruning heuristics;spatial pruning;uncertain databases","","0","","7","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Research on Data Prefetching Strategy to Support Real-time Transactions Processing in Mobile Learning Environments","Y. Du; M. Zhao","Sch. of Comput. Sci., Yangtze Univ., Jingzhou, China","2010 Fourth International Conference on Genetic and Evolutionary Computing","20110217","2010","","","814","817","In mobile environment, when downloading and opening learning resources it would need the large data communications bandwidth and strong data processing ability. Due to the intrinsic limitations of a mobile environment, there can be long time latency for a data access. Data prefetching is an approach to this problem. in this paper, a improved data prefetching strategy was proposed. based on existed research, when construcing the selected function of expected data it not only considers the time-lines for deadlines of data objects transactions but also consider the changeability, activities and priority factors of events of object datas. Therefore it could have more efficient Experiments result shows that the data prefetching strategies can reduce the deadline ratio of the mobile real-time events, and could support mobile mobile learning resource extraction effectively.","","Electronic:978-0-7695-4281-2; POD:978-1-4244-8891-9","10.1109/ICGEC.2010.206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715556","data prfetech;mobile data;mobile e-learning","Corrosion;Databases;Mobile communication;Prefetching;Real time systems;Servers;Time frequency analysis","information retrieval;learning (artificial intelligence);mobile computing;storage management;transaction processing","data access;data prefetching strategy;deadlines;mobile learning;real-time transactions processing;resource extraction;timeliness","","0","","9","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Vector logic analysis of associative matrices","V. Hahanov; W. Gharibi; S. Chumachenko; E. Litvinova","Computer Engineering Faculty, Kharkov National University of Radioelectronics, Ukraine","2010 East-West Design & Test Symposium (EWDTS)","20110405","2010","","","110","117","This article describes an infrastructure for logical analyzing associative tables (matrices), which enables to perform processing the interaction between the input vector and n-dimensional algebra-logical space, specified by using the ordered and structured tables of problem-oriented data, representing the associative behavioral models of logical objects. To estimate the interaction between vectors in algebra-logical space, the universal quality criterion is developed. It makes possible to find and evaluate the quasioptimal solution to the problems of associative logical information retrieval. Examples of the infrastructure and algebra-logical procedures, designed to solve the traditional logical analysis problems, which confirm the efficiency and practical orientation of algebraic models, are given.","","Electronic:978-1-4244-9556-6; POD:978-1-4244-9555-9","10.1109/EWDTS.2010.5742126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5742126","","Algebra;Analytical models;Arrays;Computers;Kernel;Logic arrays","information retrieval;logic analysers;matrix algebra","algebra logical space;algebraic model;associative logical information retrieval;associative matrix;associative table;problem oriented data;quasioptimal solution;vector logic analysis","","1","","16","","","17-20 Sept. 2010","","IEEE","IEEE Conference Publications"
"The Architecture and Implementation of Biodiversity Digital Library in China","Z. Xu; J. Cui; Z. Wang; F. Liu; G. Liu","Key Lab. of Biodiversity Inf., Chinese Acad. of Sci., Beijing, China","2010 Second World Congress on Software Engineering","20110222","2010","1","","291","294","Digital library is the trend of current traditional library. However, many problems, such as data collection, sharing, cooperation among different libraries and the copyright, disturb the development of digital library. Based on previous work and the cooperation with BHL (Biodiversity Heritage Library), this paper gives a description on lots of affairs in the construction of digital library in biodiversity: the hardware and software, the workflow with IA (Internet Archive), database basis, the architecture and the function. Some development works and future work are also demonstrated in the paper. The application of digital library in biodiversity will largely improve the service of related resources in traditional libraries and also have a pilot effect for many libraries in other disciplines.","","Electronic:978-0-7695-4303-1; POD:978-1-4244-9287-9","10.1109/WCSE.2010.167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718315","Biodiversity Informatics;Biodiversity heritage Library;Digital library;Scientific Community","Biodiversity;Books;Communities;Databases;Informatics;Internet;Libraries","Internet;digital libraries;information retrieval systems","China;Internet archive;biodiversity heritage library;database basis;digital library","","0","","18","","","19-20 Dec. 2010","","IEEE","IEEE Conference Publications"
"An Algorithm for Merging SMAP Radiometer and Radar Data for High-Resolution Soil-Moisture Retrieval","N. N. Das; D. Entekhabi; E. G. Njoku","Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA","IEEE Transactions on Geoscience and Remote Sensing","20110421","2011","49","5","1504","1512","A robust and simple algorithm is developed to merge L-band radiometer retrievals and L-band radar observations to obtain high-resolution (9-km) soil-moisture estimates from data of the NASA Soil Moisture Active and Passive (SMAP) mission. The algorithm exploits the established accuracy of coarse-scale radiometer soil-moisture retrievals and blends this with the fine-scale spatial heterogeneity detectable by radar observations to produce a high-resolution optimal soil-moisture estimate at 9 km. The capability of the algorithm is demonstrated by implementing the approach using the airborne Passive and Active L-band System (PALS) instrument data set from Soil Moisture Experiments 2002 (SMEX02) and a four-month synthetic data set in an Observation System Simulation Experiment (OSSE) framework. The results indicate that the algorithm has the potential to obtain better soil-moisture accuracy at a high resolution and show an improvement in root-mean-square error of 0.015-0.02-cm<sup>3</sup>/cm<sup>3</sup> volumetric soil moisture over the minimum performance taken to be retrievals based on radiometer measurements resampled to a finer scale. These results are based on PALS data from SMEX02 and a four-month OSSE data set and need to be further confirmed for different hydroclimatic regions using airborne data sets from prelaunch calibration/validation field campaigns of the SMAP mission.","0196-2892;01962892","","10.1109/TGRS.2010.2089526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661825","L-band;Soil Moisture Active and Passive (SMAP);radar;radiometer;soil moisture","Backscatter;L-band;Microwave radiometry;Radar;Soil moisture;Spatial resolution","geophysical signal processing;hydrological techniques;hydrology;information retrieval;radiometry;remote sensing by radar;soil","L-band radar observations;L-band radiometer retrievals;NASA Soil Moisture Active and Passive mission;OSSE framework;Observation System Simulation Experiment;PALS instrument data set;Passive and Active L-band System;SMAP radiometer;SMEX02;Soil Moisture Experiments 2002;airborne data sets;coarse-scale radiometer soil-moisture retrieval;data merging;fine-scale spatial heterogeneity;high-resolution soil-moisture retrieval;hydroclimatic regions;prelaunch calibration;radar data;root-mean-square error;validation field campaigns;volumetric soil moisture","","85","","14","","20101210","May 2011","","IEEE","IEEE Journals & Magazines"
"Applying machine learning algorithms for automatic Persian text classification","M. Farhoodi; A. Yari","Iran Telecommunication Research Center, Iran","2010 6th International Conference on Advanced Information Management and Service (IMS)","20110214","2010","","","318","323","Automatic document classification due to its various applications in data mining and information technology is one of the important topics in computer science. Classification plays a vital role in many information management and retrieval tasks. Document classification, also known as document categorization, is the process of assigning a document to one or more predefined category labels. Classification is often posed as a supervised learning problem in which a set of labeled data is used to train a classifier which can be applied to label future examples. Document classification includes different parts such as text processing, feature extraction, feature vector construction and final classification. Thus improvement in each part should lead to better results in document classification. In this paper, we apply machine learning methods for automatic Persian news classification. In this regard, we first try to exert some language preprocess in Hamshahri dataset, and then we extract a feature vector for each news text by using feature weighting and feature selection algorithms. After that we train our classifier by support vector machine (SVM) and K-nearest neighbor (KNN) algorithms. In Experiments, although both algorithms show acceptable results for Persian text classification, the performance of KNN is better in comparison to SVM.","","Electronic:978-89-88678-32-9; POD:978-1-4244-8599-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5713467","Hamshahri;KNN;SVM;feature selection;machine learning;text classification","Classification algorithms;Feature extraction;Kernel;Machine learning algorithms;Support vector machine classification;Text categorization","data mining;feature extraction;information retrieval;learning (artificial intelligence);natural language processing;pattern classification;support vector machines;text analysis","Hamshahri dataset;K-nearest neighbor algorithm;automatic Persian text classification;automatic document classification;data mining;document categorization;document classification;feature extraction;feature selection algorithm;feature vector construction;feature weighting;information management;information retrieval;information technology;machine learning algorithm;supervised learning problem;support vector machine;text processing","","2","","20","","","Nov. 30 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"Empirical evaluation of augmented information presentation on small form factors - navigation assistant scenario","S. Ganapathy; G. J. Anderson; I. V. Kozintsev","Intel Corporation, 5400 NE Elam Young Pkwy, Hillsboro OR 97124, USA","2011 IEEE International Symposium on VR Innovation","20110429","2011","","","75","80","Mobile Augmented Reality (MAR) enabled devices will have the capability to present a large amount of information in real time, based on sensors that determine proximity, visual reference, maps, and detailed information on the environment. This poses a challenge of presenting the information such that there is no cognitive overload for the user and the augmented information that is presented is useful and meaningful to the user. This study examined the user tolerance and identified acceptable values for the performance characteristics of the augmented information presented on - density of information, accuracy of information, delay in information presentation, and error rate. Results indicate that the amount of information presented depends on the type of activity that the user is interested in. For example, in the case of density of information - participants were interested in seeing about 7 items identified at a time. With 11 items, most were overwhelmed, but 4 items were not enough. However, desired information density depends on the information shown, and the participants wanted to control the type of information shown. The findings of the study can be used as design guidelines for MAR information overlay on small screens.","","Electronic:978-1-4577-0054-5; POD:978-1-4577-0055-2","10.1109/ISVRI.2011.5759606","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759606","Empirical Evaluation;Information Presentation;Mobile Augmented Reality;Navigation assistant","Accuracy;Augmented reality;Delay;Error analysis;Mobile communication;Navigation;Prototypes","augmented reality;information retrieval;mobile computing;navigation","MAR information overlay;augmented information presentation;information density;mobile augmented reality;navigation assistant scenario","","1","","16","","","19-20 March 2011","","IEEE","IEEE Conference Publications"
"Web spam detection based on discriminative content and link features","M. Mahmoudi; A. Yari; S. Khadivi","IT Research faculty, Iran Telecom Research Center, Tehran, Iran","2010 5th International Symposium on Telecommunications","20110317","2010","","","542","546","The problem of spam detection is a crucial task in the web information retrieval systems. The dynamic nature of information resources as well as the continuous changes in the information demands of the users makes the task of web spam detection a challenging topic. So far many different methods from researchers with different backgrounds have been proposed to tackle with spam web pages problem. In this research, we study feature space of web spam detection to recognize most effective and discriminative features. Thereafter, we design a spam detection system that employs a minimum set of features and at the same time its performance is the same or very close to a system with the complete feature set. The experimental results show that we can reduce the number of features in a clever way while the accuracy of the system is intact or even improved.","","Electronic:978-1-4244-8185-9; POD:978-1-4244-8183-5","10.1109/ISTEL.2010.5734084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734084","Search engine;classification;data mining;feature selection;web spam","Accuracy;Artificial neural networks;Classification algorithms;Feature extraction;Search engines;Support vector machines;Web pages","Internet;information retrieval systems;learning (artificial intelligence);security of data;unsolicited e-mail","Web information retrieval systems;Web spam detection;discriminative content;link features","","3","","19","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"Temporal accessibility of e-Services","R. Hellman","Karde AS, P.O. Box 69 T&#x00E5;sen, Oslo, N-0801, Norway","eChallenges e-2010 Conference","20110429","2010","","","1","8","Most European governments offer electronic self-services to citizens and businesses on a 365/7/24-basis. e-Services are available. In addition to availability, e-Services also have to be accessible in order to be successful. A number of accessibility standards and design guidelines exist and are widely applied on websites offering e-Services. Increasingly, e-Services are designed to be carried out in “batches”, within time-slots that suit the end-user. This temporal dimension plays an essential role in accessibility of e-Services. In this paper, we present seven design guidelines that will add temporal accessibility to e-Services that are being used repeatedly, over time. These are: 1. Overview and general information. 2. Targeted and relevant information. 3. Safety and trust. 4. Support to multi-channel platform and “family resemblance”. 5. Logical process and progression. 6. Storage and retrieval of information. 7. Timeline. The design objective is that it must be easy for the user to find, learn, recognise and recall e-Services as well as use-related events and transactions connected to these. We show how existing design principles from established sets of guidelines support the implementation of these principles, and thus increase the temporal accessibility of e-Services.","2166-1650;21661650","Electronic:978-1-905824-21-2; POD:978-1-4244-8390-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756572","","Europe;Government;Guidelines;Security;Standards;Usability","government data processing;handicapped aids;human computer interaction;information retrieval;information storage;security of data","European government;Websites;accessibility standards;design guidelines;e-services;electronic self-service;family resemblance;general information;information retrieval;information storage;logical process;multichannel platform support;relevant information;safety;targeted information;temporal accessibility;trust","","1","","19","","","27-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"An article retrieval support system that learns user's Kansei","Y. Murakami; S. Nakamura; S. Hashimoto","Dept. of Applied Physics, Waseda University, 3-4-1 Okubo, Shinjuku-ku, Tokyo, Japan","2010 International Conference on User Science and Engineering (i-USEr)","20110222","2010","","","32","37","Most of article retrieval systems using retrieval criteria of Kansei words have a gap between user's Kansei and system's Kansei model. Therefore, it is not always easy to retrieve the desired articles efficiently according to the user's preference. This paper proposed a system to retrieve the desired articles quickly and intuitively from the database. To achieve this aim, dimension of the retrieval space is compressed by a torus SOM (Self Organizing Maps), and a user can move in the retrieval space panoramically. A user can also choose an elimination method during search. By this method, the system estimates the significant Kansei parameters and makes the search more efficient. The system also has a function to eliminate the unselected articles and reduces the size of SOM. Additionally, the system learns the Kansei of individual user from the retrieval results by using neural networks. In evaluation experiments, we took actual painting as article, and confirmed the efficacy of the proposed method.","","Electronic:978-1-4244-9049-3; POD:978-1-4244-9048-6","10.1109/IUSER.2010.5716718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716718","Kansei;neural networks;retrieval support system;torus SOM","Artificial neural networks;Correlation;Databases;Image color analysis;Painting;Space exploration;Trajectory","information retrieval systems;self-organising feature maps;user interfaces","Kansei words;article retrieval support system;neural networks;self-organizing maps;system Kansei model;torus SOM;user Kansei model;user preference","","0","","13","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Fuzzy K- means cluster validation for institutional quality assessment","S. Prakash Kumar; K. S. Ramaswami","Department of Computer Applications, Erode Sengunthar Engineering College, Thudupathi, 57, India","2010 International Conference on Communication and Computational Intelligence (INCOCCI)","20110324","2010","","","628","635","The most important facts in educational institutional system growth lies in the quality of services rendered. (i.e., faculty profile, student performance and infrastructure requirements). The highest level of quality in educational institution can be achieved by utilizing the managerial decision makers with valuable implicit knowledge, which is currently unknown /hidden to them. The knowledge hidden among the educational data set is extractable through data mining technology. Clustering, an unsupervised learning depends on certain initiation values to define the subgroups present in a data set. Based on the features of the dataset and input parameters cluster formation may vary, which motivates the clarification of cluster validity. The proposed work presented a fuzzy k-means cluster algorithm in the formation of student, faculty and infrastructural clusters based on the performance, skill set and facilitation availability respectively. With the obtained data clusters, quality assessment is made by predictive mining using decision tree model. The cluster validation criterion is introduced to find the optimal input metrics for fuzzy k-means algorithm. Validation criteria focus on the quality metrics of the institution features for cluster formation and handle efficiently the arbitrary shaped clusters. Experimental results show improved stability and accuracy for clustering structures obtained via sub sampling, and adaptive techniques. These improvements offer insights into specific decision within the data sets. The experimental results confirm the reliability of validity index showing that it performs favorably in all cases selecting independently of clustering algorithm the scheme that best fits the data under consideration.","","Electronic:978-81-8371-369-6; POD:978-1-4577-0376-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738801","Cluster;Data Mining;Educational institution;decision tree","Classification tree analysis;Clustering algorithms;Data mining;Databases;Educational institutions;Quality assessment","data mining;decision making;decision trees;educational administrative data processing;formal verification;information retrieval;pattern clustering;quality management;unsupervised learning","adaptive technique;cluster validation criterion;clustering structure accuracy;data mining technology;decision making;decision tree model;educational data set;educational institutional system growth;fuzzy k-mean cluster algorithm;hidden knowledge;knowledge extraction;optimal input metrics;predictive mining;quality assessment;quality metrics;quality of services;subsampling technique;unsupervised learning;validity index reliability","","1","","21","","","27-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"Chasers of the Lost Data: Turning content management systems into gaming platforms","A. Hornsby; T. Aaltonen; R. Walsh","Nokia Research Center - Tampere, Finland","2010 2nd International IEEE Consumer Electronics Society's Games Innovations Conference","20110222","2010","","","1","4","This paper briefly presents our Information Retrieval and Indexing System (IRIS), and how it adapts to support game engine components. We describe a conceptual game, Chasers of the Lost Data, to demonstrate how pervasive games elements interact with content and user context detection, enabling a broad range of game applications. The presented game combines physical, sensorial and contextual information with personal content and inject this information into the game world in forms of game chases. This game allows personal content of players to be enhanced by new sets of metadata from different point of views (other players). This result in an improved content management, search and recommendation system while being more resonant fun experiences for the users.","2166-6741;21666741","Electronic:978-1-4244-7180-5; POD:978-1-4244-7178-2","10.1109/ICEGIC.2010.5716883","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716883","","Context;Engines;Games;Iris recognition;Mobile handsets;Real time systems;Sensors","computer games;indexing;information retrieval;meta data;recommender systems;ubiquitous computing","Chasers of the Lost Data;content management system;game engine components;information indexing system;information retrieval system;metadata;pervasive games elements;recommendation system;user context detection","","0","","18","","","21-23 Dec. 2010","","IEEE","IEEE Conference Publications"
"Data management and heterogeneous data integration in Grid computing environments","K. Ashok kumar; C. Chandra sekar","Computer Science & Engineering Department, Sathyabama University, India","2010 International Conference on Communication and Computational Intelligence (INCOCCI)","20110324","2010","","","437","442","Ensembles of distributed, heterogeneous resources, or Computational Grids, have emerged as popular platforms for deploying large-scale and resource-intensive applications. Large collaborative efforts are currently underway to provide the necessary software infrastructure. Grid computing raises challenging issues in many areas of computer science, bioinformatics, high energy physics and especially in the area of distributed computing, as Computational Grids cover increasingly large data, networks and span many organizations. In this paper we briefly motivate Grid computing and introduce its basic concepts. We then highlight a number of distributed computing research questions, and discuss both the relevance and the short-comings of research results when applied to Grid computing. We choose to focus on issues concerning the dissemination and retrieval of information from distributed networks and data integration on Computational Grid platforms. We feel that these issues are particularly critical at this time, and as we can point to preliminary ideas, work, and results in the Grid community and the distributed computing community. This paper is of interest to distributing computing researchers because Grid computing provides new challenges that need to be addressed, as well as actual platforms for experimentation and research.","","Electronic:978-81-8371-369-6; POD:978-1-4577-0376-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738770","Data Integration;Data management;Grid computing;Heterogeneous resources","Business;Computers;Distributed databases;Grid computing;Protocols;Software","data analysis;grid computing;information dissemination;information management;information retrieval","collaborative infrastructure;data management;distributed computing;grid computing environment;heterogeneous data integration;information dissemination;information retrieval","","0","","19","","","27-29 Dec. 2010","","IEEE","IEEE Conference Publications"
"Multi-scale Bag-Of-Features for large-size map retrieval","K. Kensuke; T. Kanji","Faculty of Engineering, University of Fukui, Japan","2010 IEEE International Conference on Robotics and Biomimetics","20110303","2010","","","961","966","Retrieving a large collection of environment maps built by mapper robots is a key problem for mobile robot self-localization. The current paper studies this map retrieval problem from a novel perspective of a multi-scale Bag-Of-Features (BOF) approach. In general, multi-scale approach is advantageous in capturing both the global structure and the local details of a given map. On the other hand, BOF map retrieval is advantageous in its compact map representation as well as efficient map retrieval using an inverted file system. Combining the advantages of both approaches is the main contribution of this paper. Our approach is based on multi-cue BOF as well as BOF dimension reduction, and achieves efficiency and compactness of the map retrieval system. Experiments on a large collection of point feature maps show promising results.","","Electronic:978-1-4244-9318-0; POD:978-1-4244-9319-7","10.1109/ROBIO.2010.5723456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723456","","Buildings;Databases;Helium;Histograms;Robots;Shape;Sparse matrices","geographic information systems;information retrieval;mobile robots","BOF;inverted file system;large size map retrieval;mapper robots;mobile robot self localization;multi scale bag-of-features","","1","","28","","","14-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Entropy-Balanced Bitmap Tree for Shape-Based Object Retrieval From Large-Scale Satellite Imagery Databases","G. J. Scott; M. N. Klaric; C. H. Davis; C. R. Shyu","Center for Geospatial Intelligence, University of Missouri, Columbia , MO, USA","IEEE Transactions on Geoscience and Remote Sensing","20110421","2011","49","5","1603","1616","In this paper, we present a novel indexing structure that was developed to efficiently and accurately perform content-based shape retrieval of objects from a large-scale satellite imagery database. Our geospatial information retrieval and indexing system, GeoIRIS, contains 45 GB of high-resolution satellite imagery. Objects of multiple scales are automatically extracted from satellite imagery and then encoded into a bitmap shape representation. This shape encoding compresses the total size of the shape descriptors to approximately 0.34% of the imagery database size. We have developed the entropy-balanced bitmap (EBB) tree, which exploits the probabilistic nature of bit values in automatically derived shape classes. The efficiency of the shape representation coupled with the EBB tree allows us to index approximately 1.3 million objects for fast content-based retrieval of objects by shape.","0196-2892;01962892","","10.1109/TGRS.2010.2088404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669345","Content-based retrieval;image databases;knowledge-based indexing;object indexing;remotesensing","Feature extraction;Geospatial analysis;Indexing;Satellites;Shape","entropy;image retrieval;information retrieval;shape recognition;visual databases","GeoIRIS;bitmap shape representation;content-based shape retrieval;entropy-balanced bitmap tree;geospatial information retrieval and indexing system;large-scale satellite imagery databases;shape-based object retrieval","","21","","38","","20101217","May 2011","","IEEE","IEEE Journals & Magazines"
"Classifying Web Pages Using Information Extraction Patterns Preliminary Results and Findings","L. K. Soon; S. H. Lee","Fac. of Inf. Technol., Multimedia Univ., Selangor, Malaysia","2010 Sixth International Conference on Signal-Image Technology and Internet Based Systems","20110217","2010","","","195","202","Web page classification plays an essential role in facilitating more efficient information retrieval and information processing. Conventionally, web text documents are represented by term frequency matrix for classification purpose. However, considering the limitations of representing documents using terms or keywords, we propose to represent web pages using information extraction patterns that are identified within the pages respectively. In this paper, we present the results as well as the findings obtained from our preliminary experiments. Our experimental results indicate that the existence of a word in different contexts has different impact to the classification task. Thus, the extraction patterns used to represent each document are more semantically meaningful and give better insight to web classification in comparison with keywords.","","Electronic:978-0-7695-4319-2; POD:978-1-4244-9527-6","10.1109/SITIS.2010.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714552","decision tree;information extraction;information gain;web classification;web mining","Bayesian methods;Classification algorithms;Computer science;Indexing;Text categorization;Web pages","Internet;classification;data mining;information retrieval;matrix algebra;text analysis","Web mining;Web page classification;Web text documents;information extraction patterns;information processing;information retrieval;term frequency matrix","","0","","20","","","15-18 Dec. 2010","","IEEE","IEEE Conference Publications"
"Resource Selection in Large-Scale Distributed System Using Dynamic Task Sharing","D. G. Kim; Z. Y. Li; S. S. Moon; H. Y. Youn","Sch. of Inf. & Commun. Eng., Sungkyunkwan Univ., Suwon, South Korea","Green Computing and Communications (GreenCom), 2010 IEEE/ACM Int'l Conference on & Int'l Conference on Cyber, Physical and Social Computing (CPSCom)","20110307","2010","","","659","665","Large-scale distributed system provides an attractive scalable infrastructure for network applications. In such environment there exist large sets of heterogeneous and geographically distributed resources. These resources can be aggregated as a virtual computing platform for executing large-scale scientific applications. Among numerous optional resources, selecting appropriate resources for applications is challenging and affected by many factors. The loosely coupled nature of large-scale distributed environment makes data access unpredictable and instability. Slow allocation process may offset the benefit obtained by running a job on a fast node. Besides, the operation condition of a resource provider changes rapidly. The status of job execution and computing capability of a resource provider need to be considered dynamically. In this paper we present an approach of dynamic task-sharing based on the record of previous data download and current execution status of resource providers to select the appropriate one or more providers to execute a job together. The proposed approach can also avoids single point failure and server overload problem.","","Electronic:978-0-7695-4331-4; POD:978-1-4244-9779-9","10.1109/GreenCom-CPSCom.2010.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5724900","Data intensive computing;large scale distributed systems;resource selection;task sharing","Distributed databases;Dynamic scheduling;Estimation;Peer to peer computing;Processor scheduling;Resource management;Servers","data analysis;distributed processing;information retrieval;resource allocation;virtual reality","data access;data intensive computing;dynamic task sharing;large scale distributed system;resource selection;server overload problem;virtual computing platform","","0","","8","","","18-20 Dec. 2010","","IEEE","IEEE Conference Publications"
"Real time monitoring system for applications performing the population of condition databases for CMS non-event data","F. Cavallari; M. de Gruttola; S. Di Guida; G. Govi; V. Innocente; G. Mazrimas; P. Paolucci; A. Pierro","CERN, Switzerland","2010 17th IEEE-NPSS Real Time Conference","20110415","2010","","","1","8","In real time systems, such as CMS Online Condition Database, monitoring and fast detecting errors is a very challenging task. To recover the system and to put it in a safe state requires spotting a faulty situation with strict timing constraints and a fast reaction. In the context of real time monitoring, this implies that the interval of time from when a faulty event occurs to when it is noticed must be minimized. In the CMS experiment, many users have access to condition data with different needs: they exploit several applications with different roles. Therefore, the system that monitors the online condition database must describe the status of the infrastructure according to the different categories of users. For example, when no errors occur, it provides simple timing information or the history of all transactions towards all the database accounts; instead, in case of faulty situations, it returns simple error messages or more complete debugging information. Hence, to classify correctly an error, once observed, the monitoring system must describe both the timing aspects of the applications that populate the Online Condition Database schemas, and the complex relationship between the components of the heterogeneous software environment. In the first part of this paper, we define the expected behaviour of the handling, the storage and the retrieval of condition data for the CMS experiment. In the second part, we describe the software components used in order to determine system failures. Finally, we will present the monitoring system used to visualize the status of the condition data infrastructure, eventually spotting all the possible combinations of error states, and how these views can be customized on the basis of the different categories of users.","","Electronic:978-1-4244-7110-2; POD:978-1-4244-7108-9","10.1109/RTC.2010.5750460","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750460","","Calibration;Databases;Detectors;History;Monitoring;Servers;Software","computer debugging;database management systems;information retrieval;monitoring;real-time systems","CMS non-event data;CMS online condition database;debugging information;real time monitoring system;software components","","3","","14","","","24-28 May 2010","","IEEE","IEEE Conference Publications"
"SCW 2009 Invited Keynote","C. Dwyer","Dept. Electr. & Comput. Eng., Duke Univ., Durham, NC, USA","2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing Systems Workshop","20110310","2010","","","xxviii","xxx","Understanding molecular scale phenomena is a critical component of many scientific disciplines. The ability to retrieve nanoscale information from inside macroscale systems is particularly useful in biological fields where the diversity of molecular components and interaction dynamics within a cell make it difficult to monitor and quantify the underlying processes. Current methods rely on custom designed molecules-called molecular probes-that alter their observable properties to acquire real-time information about nanoscale phenomena.","","Electronic:978-0-7695-4229-4; POD:978-1-4244-8684-7","10.1109/SASOW.2010.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5729583","","","biology computing;data acquisition;information retrieval;macromolecules","biological fields;custom designed molecules;interaction dynamics;macroscale systems;molecular components;molecular probes;molecular self-assembly;nanoscale information retrieval;nanoscale spatial computation","","0","","4","","","27-28 Sept. 2010","","IEEE","IEEE Conference Publications"
"Transforming IbnSina into an advanced multilingual interactive android robot","N. Mavridis; A. AlDhaheri; L. AlDhaheri; M. Khanii; N. AlDarmaki","Interactive Robots and Media Lab, United Arab Emirates University","2011 IEEE GCC Conference and Exhibition (GCC)","20110419","2011","","","120","123","IbnSina is the world's first Arabic-language conversational android robot, and is also part of an interactive theatre with multiple possibilities for human teleparticipation. In this paper, we describe extensions carried out to IbnSina's software architecture in order to enrich its capabilities in multiple ways, so that it can become an exciting educational / persuasive robot in the future. The main axis for extension were: access to online (Wikipedia) and stored (Koran database) content for dialogue generation, basic multilingual capability exploration (English and Arabic, also utilizing Google Translate), basic read-aloud-text capability (through OCR), and systematization of motor control (with higher-level API for real-time lip syncing, eye blinking, natural looking random face movements, and interpolation between facial expressions including an affective state subsystem). With such capabilities, IbnSina becomes closer to an attractive robot that can find real-world application in malls, schools, as a receptionist etc.","","Electronic:978-1-61284-119-9; POD:978-1-61284-118-2","10.1109/IEEEGCC.2011.5752467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5752467","Android;Intelligent Robots;Interactive;Multilingual;Natural Language Interfaces","Conferences","educational aids;information retrieval;intelligent robots;interactive systems;natural language processing;software architecture","Arabic language conversational android robot;Google translation;IbnSina software architecture;advanced multilingual interactive android robot;dialogue generation;educational robot;eye blinking;human teleparticipation;interactive theatre;motor control;multilingual capability exploration;natural looking random face movement;online data access;persuasive robot;read aloud text capability;real time lip syncing","","3","","21","","","19-22 Feb. 2011","","IEEE","IEEE Conference Publications"
"Tractor: A framework for soft information fusion","M. Prentice; M. Kandefer; S. C. Shapiro","Department of Computer Science and Engineering, Center for Cognitive Science, Center for Multisource Information Fusion, University at Buffalo, Buffalo, NY 14260","2010 13th International Conference on Information Fusion","20110210","2010","","","1","8","This paper presents a soft information fusion framework for creating a propositional graph from natural language messages with an emphasis on producing these graphs for fusion with other messages. The framework utilizes artificial intelligence techniques from natural language understanding, knowledge representation, and information retrieval.","","Electronic:978-0-9824438-1-1","10.1109/ICIF.2010.5711896","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5711896","context;hard/soft data fusion;ontologies;propo-sitional graphs","Agricultural machinery;Context;Logic gates;Natural languages;Ontologies;Resource description framework;Syntactics","graph theory;information retrieval;knowledge representation;natural language processing;sensor fusion","Tractor;artificial intelligence techniques;information retrieval;knowledge representation;natural language messages;natural language understanding;propositional graph;soft information fusion framework","","1","","40","","","26-29 July 2010","","IEEE","IEEE Conference Publications"
"Pareto-Based Dominant Graph: An Efficient Indexing Structure to Answer Top-K Queries","L. Zou; L. Chen","Peking University, Beijing","IEEE Transactions on Knowledge and Data Engineering","20110324","2011","23","5","727","741","Given a record set D and a query score function F, a top-k query returns k records from D, whose values of function F on their attributes are the highest. In this paper, we investigate the intrinsic connection between top-k queries and dominant relationships between records, and based on which, we propose an efficient layer-based indexing structure, Pareto-Based Dominant Graph (DG), to improve the query efficiency. Specifically, DG is built offline to express the dominant relationship between records and top-k query is implemented as a graph traversal problem, i.e., Traveler algorithm. We prove theoretically that the size of search space (that is the number of retrieved records from the record set to answer top-k query) in our algorithm is directly related to the cardinality of skyline points in the record set (see Theorem 3). Considering I/O cost, we propose cluster-based storage schema to reduce I/O cost in Traveler algorithm. We also propose the cost estimation methods in this paper. Based on cost analysis, we propose an optimization technique, pseudorecord, to further improve the search efficiency. In order to handle the top-k query in the high-dimension record set, we also propose N-Way Traveler algorithm. In order to handle DG maintenance efficiently, we propose “Insertion” and “Deletion” algorithms for DG. Finally, extensive experiments demonstrate that our proposed methods have significant improvement over its counterparts, including both classical and state art of top-k algorithms.","1041-4347;10414347","","10.1109/TKDE.2010.240","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645629","Top-k query;algorithms.;database","","graph theory;indexing;pattern clustering;query processing;question answering (information retrieval)","N-way Traveler algorithm;Pareto based dominant graph;cluster based storage schema;cost estimation method;graph traversal problem;layer based indexing structure;query optimization;record retrieval;score function;top-k query answering","","14","","25","","20101129","May 2011","","IEEE","IEEE Journals & Magazines"
"Credit scheduling and prefetching in hypervisors using Hidden Markov Models","V. Suryanarayana; A. Jasti; R. Pendse","Department of Electrical Engineering and Computer Science, Wichita State University, 1845 N Fairmount, Wichita, Kansas 67260 USA","IEEE Local Computer Network Conference","20110322","2010","","","224","227","The advances in data storage technologies like Storage Area Networking (SAN), virtualization of servers and storage, cloud computing have revolutionized the way the data is stored. A large number of business organizations, universities, hospitals, research organizations are now deploying SAN, not as a luxury but as a necessity. Scientific research organizations like NASA process terabytes of data every day. Accurate analysis and processing of the experimental data call for a need to efficiently store and retrieve the data to and from data storage media. Similarly social websites like YouTube, FaceBook handle large amounts of data every minute. So, the robust performance of any computing and retrieval applications demands a reduction in the latency of data access. Hidden Markov Models (HMM) have been successfully used by researchers to predict data patterns in the areas of speech recognition, gene prediction, cryptanalysis etc. The goal of this research is to reduce the scheduling delay in hypervisors and the latency of reading blocks of data from the disk array using Hidden Markov Models (HMM) in a server virtualized environment. HMM was implemented to identify patterns of read requests issued and exploited to reduce the overall read response time of a server. A Gaussian HMM is used to reduce the scheduling delay and a discrete HMM is used to reduce the read response time. Results observed using HMM were very promising compared to results without HMM in decreasing the overall latency in data access.","0742-1303;07421303","Electronic:978-1-4244-8389-1; POD:978-1-4244-8387-7","10.1109/LCN.2010.5735707","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5735707","Credit Scheduler;Hidden Markov Models (HMM);Hypervisor (XEN);SAN;Server Virtualization","Databases;Hidden Markov models;Prefetching;Servers;Time factors;Training;Virtual machine monitors","hidden Markov models;information retrieval systems;scheduling;storage area networks;storage management","cloud computing;credit prefetching;credit scheduling;data access;data storage;hidden Markov models;hypervisors;read response time;retrieval applications;scheduling delay;servers virtualization;storage area networking;storage virtualization","","2","","11","","","10-14 Oct. 2010","","IEEE","IEEE Conference Publications"
"Auto complete using graph mining: A different approach","N. Agrawal; M. Swain","University of South Carolina, Computer Science and Engineering, Columbia, USA","2011 Proceedings of IEEE Southeastcon","20110421","2011","","","268","271","Autocomplete feature is widely used in search interfaces to assist users in their search. Autocomplete helps users by giving list of options based on characters entered in the search field. Significant amount of work has been done in this field, but the techniques used are not efficient or relevant when it comes to search within specific content like a text file, a document or a web page. This calls for different approaches such as ours. Our proposed method is based on preprocessing, graph mining, and hashing for generating the suggestion list. The suggestion list provided by our proposed method is more relevant because the list is document specific. Test results from our proposed method show that our proposed method significantly outperforms existing document specific autocomple search techniques.","1091-0050;10910050","Electronic:978-1-61284-738-2; POD:978-1-61284-739-9","10.1109/SECON.2011.5752947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5752947","autocomplete;graph mining;hashing;pre-processing;sentence completion","Clustering algorithms;Data mining;Databases;Electronic mail;History;Program processors;Web pages","data mining;graph theory;information retrieval","autocomplete feature;document specific autocomplete search techniques;graph mining;hashing;search interfaces","","0","","9","","","17-20 March 2011","","IEEE","IEEE Conference Publications"
"Transmural exchange of cardiology related information between two academic centers and referring hospitals using XDS(-I)","A. Dijk; J. P. Busman; N. van der Putten; W. Dassen","University Medical Center Groningen, The Netherlands","2010 Computing in Cardiology","20110322","2010","","","1071","1074","More than 50% of the patient population undergoing a therapeutic invasive procedure in an Academic center has undergone diagnostic based procedures in a referring hospital. Until recently the medical documents were on paper and CD and sent by mail, fax or taxi. In this paper we describe two different IHE-XDS(-I) solutions based on a network that facilitates the transmural exchange of documents as well as images. XDS is based on medical, industrial and internet standards. Using XDS cardiologists from different centers share rather than exchange information regarding a patient, before as well as after a therapeutic invasive procedure.","0276-6574;02766574","Electronic:978-1-4244-7319-9; POD:978-1-4244-7318-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738162","","Cardiology;DICOM;Hospitals;Medical diagnostic imaging;Standards","PACS;cardiology;computer networks;hospitals;information retrieval systems;medical diagnostic computing;standards;surgery","IHE-XDS(-I) solutions;academic centers;cardiac surgeons;cardiological information;diagnostic procedures;hospital;image exchange;industrial standards;information exchange;internet standards;medical documents;medical standards;therapeutic invasive procedure;transmural exchange","","0","","4","","","26-29 Sept. 2010","","IEEE","IEEE Conference Publications"
"Using Multi Shares for Ensuring Privacy in Database-as-a-Service","M. A. ALzain; E. Pardede","Dept. of Comput. Sci. & Comput. Eng., La Trobe Univ., Bundoora, VIC, Australia","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","9","Database-as-a-service (DAAS) is a new model for data management, where a service provider offers customers software management functionalities as well as the use of expensive hardware. This service enables data integration and access on a large scale in cloud computing infrastructures. Addressing data privacy in DAAS is considered a significant issue for any organizational database. Due to the fact that data will be shared with a third party, an un-trusted server is dangerous and unsafe for the user. This paper proposes the architecture of a new model appropriate for NetDB2 architecture, known as NetDB2 Multi-Shares (NetDB2-MS). It is based on multi-service providers and a secret sharing algorithm instead of encryption, which is used by the existing NetDB2 service. The evaluation is done through simulations. It shows a significant improvement in performance for data storage and retrieval for various query types.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5719004","","Data models;Data privacy;Databases;Encryption;Servers;Software","cloud computing;data integrity;data privacy;database management systems;information retrieval;organisational aspects;software management","DAAS;NetDB2 architecture;cloud computing;data access;data integration;data management;data privacy;data retrieval;data storage;database-as-a-service;organizational database;software management","","12","","22","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Web-Scale Multimedia Analysis: Does Content Matter?","M. Slaney","Yahoo! Research and Stanford Center for Computer Research in Music and Acoustics","IEEE MultiMedia","20110421","2011","18","2","12","15","The initial success of Web-image search was based exclusively on the text around an image. Certainly we have progressed since then. But recent research results dramatically beg to differ. For example, if you want to judge the similarity of two different pieces of music, should you look at the musical notes, or should you look at what people say about the music? Similarly, how should you find the best movie to recommend to a friend? Shouldn't the genre of the movie matter? Or when tagging a photo, is it better to look at the pixels, or where the picture lives on the Internet? I want to think that content matters, but in all three cases, metadata about the content proves to be more useful. It's useful to look at several examples where content has lost out to other forms of data. These examples come from the worlds of music, movies, and images.","1070-986X;1070986X","","10.1109/MMUL.2011.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5754643","Visions and Views;content analysis;metadata;multimedia and graphics;recommendations;similarity","Electronic mail;Motion pictures;Multimedia communication;Optimization;Pixel;System-on-a-chip;Tagging","Internet;information retrieval;multimedia systems;music","Internet;Web-image search;Web-scale multimedia analysis;metadata;movies;music","","13","","5","","","Feb. 2011","","IEEE","IEEE Journals & Magazines"
"Sentiment Bias Detection in Support of News Credibility Judgment","J. Zhang; Y. Kawai; S. Nakajima; Y. Matsumoto; K. Tanaka","Kyoto Sangyo Univ., Kyoto, Japan","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","Recently, an increasing number of online news websites have come to provide news browsing and retrieval services. For certain topics, certain news websites may hold sentiment bias, and therefore select and edit information according to their own standpoints before delivering news articles. Lacking conscious awareness of websites' sentiment bias may result in blind obedience to the reported information. We focus on the sentiment aspect of news articles and develop a system which can detect and visualize sentiment tendencies of different websites. Given a topic, the system extracts relevant subtopics and presents sentiment difference between different subtopics. Once a subtopic is specified, sentiment difference between news websites is also provided. The background knowledge of sentiment difference between subtopics and between websites can assist users in judging the news credibility. In particular, the system analyzes four-dimension sentiment, which is more similar to human emotion than conventional positive-negative sentiment. Experimental evaluations show the accuracy of sentiment extraction and subtopic extraction is good, and our observation results show sentiment bias can be detected by the system.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718623","","Accuracy;Biological system modeling;Databases;Dictionaries;Economics;Knowledge engineering;Visualization","Web sites;data visualisation;information retrieval;online front-ends","Web sites;browsing services;four-dimension sentiment;human emotion;news credibility judgment;online news;retrieval services;sentiment bias detection;sentiment extraction;sentiment tendency visualization;subtopic extraction","","1","","15","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Location privacy in processing location dependent queries in mobile database systems","M. Tarafdar; M. S. Haghjoo","Department of Computer Engineering, Iran University of Science and Technology, IUST, Tehran, Iran","2010 5th International Symposium on Telecommunications","20110317","2010","","","181","186","Emergence of the mobile computing paradigm helps people to work in a much more convenient and efficient way, anywhere and anytime. Today its application areas such as traffic reports, weather forecast, bill paying and healthcare are so popular. The field of data management is also extended with such new services and applications. A mobile database system is a special heterogonous distributed system that supports mobile computing. One of the most important types of queries in mobile environments is location dependant query. Its answer is dependent to the mobile user's location. However, revealing location information raises privacy concerns. This paper concentrates on query processing in this paradigm.","","Electronic:978-1-4244-8185-9; POD:978-1-4244-8183-5","10.1109/ISTEL.2010.5734021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734021","location dependent query;location privacy;mobile computing;mobile database;query processing","Databases;GSM;Middleware;Mobile communication;Mobile computing;Radio access networks;Satellite broadcasting","data privacy;mobile computing;query processing;question answering (information retrieval)","data management;heterogenous distributed system;location dependant query;location information;location privacy;mobile computing;mobile database system;query processing","","2","","48","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"Integrating Geo-spatial Information Infrastructure into Conservation and Management of Wetlands in Ghana","W. Owusu-Banahene; I. K. Nti; P. J. Sallis","Comput. Eng. Dept., Univ. of Ghana, Accra, Ghana","2011 Second International Conference on Intelligent Systems, Modelling and Simulation","20110314","2011","","","91","94","Most data infrastructure tend to focus on data access and not particularly spatial aspects of data and services especially data relating to natural resource management. This project will conceptualise and implement a geospatial information infrastructure to facilitate conservation and management of wetlands in Ghana, where a scalable, accessible and robust solution is urgently needed. Critically, rather than relying on governmental agency as a sole means of continued and current data provision, the approach will link technical advances in mobile telephone services, global positioning systems and concepts of citizen science with advanced developments in semantics and interoperability to formalise a spatial infrastructure system capable of weighing assertion and achieving authority. This paper attempts to propose the use of the following technology in developing a Ghana Wetland Information System: remote sensed imagery plus scripting and database, e-Governance frameworks and Protégé OWL for the management of semantics.","2166-0662;21660662","Electronic:978-0-7695-4336-9; POD:978-1-4244-9809-3","10.1109/ISMS.2011.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730326","data;geospatial;informataion infrastructure;management of semantics;management of wetlands;services","Databases;Geographic Information Systems;Information systems;Internet;Monitoring;Remote sensing;Software","Global Positioning System;geophysics computing;information retrieval;mobile radio;open systems","Ghana wetland information system;data access;geospatial information infrastructure;global positioning system;interoperability service;mobile telephone service;natural resource management;wetland conservation;wetland management","","0","","10","","","25-27 Jan. 2011","","IEEE","IEEE Conference Publications"
"A supervised ranking approach for detecting relationally similar word pairs","D. Bollegala","Graduate School of Information Sciences, The University of Tokyo, 7-3-1 Hongo Bunkyo-ku, Tokyo, Japan","2010 Fifth International Conference on Information and Automation for Sustainability","20110217","2010","","","323","328","The similarity between the semantic relations that exist between two word pairs is defined as their relational similarity. For example, the semantic relation, is a large holds between the words in the word pair (lion, cat) and (ostrich, bird), because lion is a large cat, and ostrich is the largest living bird on earth. Consequently, the two word pairs, (lion, cat) and (ostrich, bird), are considered to be relationally similar. A high degree of relational similarity can be observed between analogous pairs of words. Measuring the relational similarity between word pairs is important in numerous natural language processing tasks such as solving word analogy questions, classifying noun-modifier relations and disambiguating word senses. We propose a supervised ranking-based method to detect relationally similar word pairs to a given word pair using information retrieved from a Web search engine. First, each pair of words is represented by a vector of automatically extracted lexical patterns. Then a ranking Support Vector Machine is trained to recognize word pairs with similar semantic relations to a given word pair. To train and evaluate the proposed method, we use a benchmark dataset that contains 374 SAT multiple-choice word-analogy questions. To represent the relations that exist between two word pairs, we experiment with 11 different feature functions, including both symmetric and asymmetric feature functions. Our experimental results show that the proposed ranking-based approach outperforms several previously proposed relational similarity measures on this benchmark dataset, achieving an SAT score of 46.9.","2151-1802;21511802","Electronic:978-1-4244-8552-9; POD:978-1-4244-8549-9","10.1109/ICIAFS.2010.5715681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715681","ranking SVMs;relational similarity","Birds;Kernel;Measurement;Search engines;Semantics;Support vector machines;Web search","Internet;computational linguistics;feature extraction;information retrieval;search engines;support vector machines;text analysis;word processing","Web search engine;feature function;information retrieval;lexical pattern extraction;natural language processing;noun-modifier relation;relational similarity;semantic relation;supervised ranking;support vector machine;word analogy;word pair detection;word pair recognition;word sense disambiguation","","0","","13","","","17-19 Dec. 2010","","IEEE","IEEE Conference Publications"
"Lossless Hyperspectral Image Compression System-Based on HW/SW Codesign","Y. T. Hwang; C. C. Lin; R. T. Hung","Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan","IEEE Embedded Systems Letters","20110322","2011","3","1","20","23","The design and implementation of a lossless compression system for hyperspectral images on a processor-plus-field-programmable gate array (FPGA)-based embedded platform. Software execution time of compression algorithm was profiled first to conclude the decision of accelerating the most time consuming interband prediction module by hardware realization. Efficient algorithm to hardware mapping led to a high throughput accelerator design in FPGA capable of processing 16.5 M pixels/s. A set of optimization techniques were applied systematically to enhance the overall system performance. These include a hierarchical memory access scheme to resolve the bus bandwidth limitation, DMA assisted data transfers to shorten the hardware/software (HW/SW) communication, and various coding style and compiler options to optimize the software execution. The final result shows a 21 speed-up compared to a purely software implementation and the performance was actually bounded by the software section in realizing an entropy coder. A 27 speed-up can be achieved if a simplified coder is used.","1943-0663;19430663","","10.1109/LES.2010.2092413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635313","Embedded system;field-programmable gate array (FPGA);hardware/software (HW/SW) codesign;hyperspectral images;lossless compression","Field programmable gate arrays;Hardware;Hyperspectral imaging;Image coding;Pixel;Software;Table lookup","distributed memory systems;field programmable gate arrays;hardware-software codesign;image coding;information retrieval;optimisation;program compilers","DMA;HW-SW codesign;compiler;field programmable gate array;hierarchical memory access scheme;lossless hyperspectral image compression;optimization","","9","","8","","20101115","March 2011","","IEEE","IEEE Journals & Magazines"
"Computing technology used in retrieval of patient's record","D. Prathima; B. Koushika Parvathy Devi","Sri Ramakrishna Engineering College; Coimbatore, Tamilnadu, India","2011 National Conference on Innovations in Emerging Technology","20110324","2011","","","129","132","The majority of healthcare workers in hospitals continue to record, access and update important patient information using paper charts. Disparate patient data (clinical information, laboratory results and medical imagery) is entered by different caregivers and stored at different locations around the hospital. This is a cumbersome, time consuming process that can result in critical medical errors such as documents being mislaid or prescriptions being misinterpreted due to illegible handwriting. Hospitals everywhere are moving to integrate health data sources using Electronic Health Record (EHR) systems as well as taking advantage of the flexibility and speed of wireless computing to improve the quality and reduce the cost of healthcare. We are developing a mobile application that allows doctors to efficiently access accurate real-time patient information at the point-of-care. The system can assist caregivers in automatically searching through very large repositories of previous patient cases as increasingly large hospital databases are making manual searches of such information unfeasible. The system performs computational prognosis by providing decision support for pre-screening of medical diagnosis. A presenting patient's symptoms can be input to a portable device and the application can quickly retrieve the most similar profiles with known diagnoses from large databases which can be used to compare treatments, diagnosis, test results and other information.","","Electronic:978-1-61284-810-5; POD:978-1-61284-807-5","10.1109/NCOIET.2011.5738816","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738816","","Databases;History;Hospitals;Medical diagnostic imaging;Real time systems","decision support systems;health care;information retrieval;medical diagnostic computing;medical information systems;patient diagnosis;real-time systems","computational prognosis;decision support;electronic health record system;healthcare;hospital database;medical diagnosis;patient information;patient record retrieval;wireless computing","","1","","5","","","17-18 Feb. 2011","","IEEE","IEEE Conference Publications"
"LIFT Revisited: Enhancing the Understanding of NATURAL/ADABAS Legacy Systems","K. d. S. Brito; V. C. Garcia; S. R. d. L. Meira","Exact Sci. Dept., Feira de Santana State Univ., Feira de Santana, Brazil","2010 14th European Conference on Software Maintenance and Reengineering","20110217","2010","","","272","273","LIFT (Legacy Information retrieval Tool) is a tool for reverse engineering and understanding of legacy systems, in particular NATURAL/ADABAS systems. Its provides several capabilities, such as call graphs, identification and visual representation of application tiers, the presentation of flows from screen to database entities, cluster analysis and documentation generation, among others. In this paper, we present two new functionalities of LIFT tool: the reconstruction and visualization of screen layouts, and the graphical visualization and automatic migration of ADABAS database structure.","1534-5351;15345351","Electronic:978-0-7695-4321-5; POD:978-1-61284-369-8","10.1109/CSMR.2010.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714451","Legacy systems;reverse engineering;system understanding","Business;Computer architecture;Data visualization;Reverse engineering;Software;Visual databases","data visualisation;database management systems;information retrieval;reverse engineering;software maintenance;software tools","ADABAS database structure;LIFT tool;NATURAL-ADABAS legacy systems;call graphs;cluster analysis;database entities;documentation generation;graphical visualization;legacy information retrieval tool;reverse engineering;software maintenance;visual representation","","0","","3","","","15-18 March 2010","","IEEE","IEEE Conference Publications"
"A study on web experience among visually impaired users in Malaysia","R. Bavani; Azizah Jaafar; N. F. Mohd Yatim","Faculty of Science, University of Nottingham (UNMC), Selangor, Malaysia","2010 International Conference on User Science and Engineering (i-USEr)","20110222","2010","","","11","15","This study focused on the web experience and barriers among visually impaired (VIM) users in Malaysia when accessing web pages with screen readers. In this study, eight visually impaired users were interviewed and reported major problems related to images, hyperlinks and page layout. Based on findings from qualitative survey, a comparative analysis was performed with (Web Content Accessibility Guidelines) WCAG 2.0.","","Electronic:978-1-4244-9049-3; POD:978-1-4244-9048-6","10.1109/IUSER.2010.5716714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716714","WCAG 2.0;visually impaired user;web accessibility","Guidelines;Interviews;Layout;Navigation;Usability;Web pages","Internet;handicapped aids;information retrieval","Malaysia;VIM;WCAG 2.0;Web content accessibility guidelines;Web experience;visually impaired user","","0","","17","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Automated essay scoring using Generalized Latent Semantic Analysis","M. Monjurul Islam; A. S. M. Latiful Hoque","Department of CSE, Bangladesh University of Engineering & Technology, Dhaka, Bangladesh (BUET)","2010 13th International Conference on Computer and Information Technology (ICCIT)","20110303","2010","","","358","363","Automated Essay Grading (AEG) is a very important research area in educational technology. Latent Semantic Analysis (LSA) is an information retrieval technique used for automated essay grading. LSA forms a word by document matrix and then the matrix is decomposed using Singular Value Decomposition (SVD) technique. Existing AEG systems based on LSA cannot achieve higher level of performance to be a replica of human grader. We have developed an AEG system using Generalized Latent Semantic Analysis (GLSA) which makes n-gram by document matrix instead of word by document matrix. We have evaluated this system using details representation and showed the performance of the system. Experimental results show that our system outperforms the existing system.","","Electronic:978-1-4244-8497-3; POD:978-1-4244-8496-6","10.1109/ICCITECHN.2010.5723884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723884","Automatic Essay Grading;Latent Semantic Analysis;N-gram;Singular Value Decomposition","Correlation;Humans;Matrix decomposition;Semantics;Singular value decomposition;Training","document handling;educational computing;information retrieval;singular value decomposition","automated essay grading;document matrix;educational technology;information retrieval;latent semantic analysis;matrix decomposition;n-gram;singular value decomposition","","0","","18","","","23-25 Dec. 2010","","IEEE","IEEE Conference Publications"
"Automatic Discovery of Personal Name Aliases from the Web","D. Bollegala; Y. Matsuo; M. Ishizuka","The University of Tokyo, Tokyo","IEEE Transactions on Knowledge and Data Engineering","20110421","2011","23","6","831","844","An individual is typically referred by numerous name aliases on the web. Accurate identification of aliases of a given person name is useful in various web related tasks such as information retrieval, sentiment analysis, personal name disambiguation, and relation extraction. We propose a method to extract aliases of a given personal name from the web. Given a personal name, the proposed method first extracts a set of candidate aliases. Second, we rank the extracted candidates according to the likelihood of a candidate being a correct alias of the given name. We propose a novel, automatically extracted lexical pattern-based approach to efficiently extract a large set of candidate aliases from snippets retrieved from a web search engine. We define numerous ranking scores to evaluate candidate aliases using three approaches: lexical pattern frequency, word co-occurrences in an anchor text graph, and page counts on the web. To construct a robust alias detection system, we integrate the different ranking scores into a single ranking function using ranking support vector machines. We evaluate the proposed method on three data sets: an English personal names data set, an English place names data set, and a Japanese personal names data set. The proposed method outperforms numerous baselines and previously proposed name alias extraction methods, achieving a statistically significant mean reciprocal rank (MRR) of 0.67. Experiments carried out using location names and Japanese personal names suggest the possibility of extending the proposed method to extract aliases for different types of named entities, and for different languages. Moreover, the aliases extracted using the proposed method are successfully utilized in an information retrieval task and improve recall by 20 percent in a relation-detection task.","1041-4347;10414347","","10.1109/TKDE.2010.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567101","Web mining;information extraction;web text analysis.","Data mining;Engines;Frequency measurement;Search engines;Semantics;Web search","data mining;information retrieval;search engines;support vector machines","English personal names data set;English place names data set;Japanese personal names data set;Web search engine;alias detection system;information retrieval;lexical pattern-based approach;name alias extraction methods;personal name alias discovery;personal name disambiguation;ranking support vector machines;relation extraction;sentiment analysis","","11","1","28","","20100909","June 2011","","IEEE","IEEE Journals & Magazines"
"A framework for opinion question answering","Peng Jiang; Hongping Fu; Chunxia Zhang; Zhendong Niu","School of Computer Science and Technology, Beijing Institute of Technology, 100081, China","2010 6th International Conference on Advanced Information Management and Service (IMS)","20110214","2010","","","424","427","Question answering is a useful task to help people seek the knowledge of what they want to know. Previous study mainly focuses on factoid question answering, which serves the needs to answer factual questions. Due to rapidly increasing scale of user generated contents on the Web, people are more interested in opinion questions that can reflect others' opinions. In this paper, we propose a framework for opinion question answering by combining opinion mining with traditional question answering methods. Besides, we use question-answer opinion patterns to extract and rank candidate answers from text snippets. Experimental results on TREC Blog08 dataset reveal the potential of our framework.","","Electronic:978-89-88678-32-9; POD:978-1-4244-8599-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5713487","Opinion mining;opinion pattern;opinion question answering;sentiment analysis","Blogs;Classification algorithms;Computational linguistics;Context;Natural language processing;Pattern matching;Special issues and sections","content management;data mining;question answering (information retrieval);text analysis","opinion pattern;opinion question;question answering;text snippet;user generated content","","1","","11","","","Nov. 30 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"Automated ingest of digital records from electronic records management systems","K. Aas; T. Kärberg","National Archives of Estonia, J. Liivi 4, Tartu, 50409, Estonia","eChallenges e-2010 Conference","20110429","2010","","","1","5","The amount of vital electronic records created at the agencies grows constantly, as does the need for efficient methods and tools which help to transfer records into trusted long-term repositories. This paper describes a tool called the Universal Archiving Module (UAM) which simplifies and automates the process of preparing records and their metadata for transfers into long-term repositories. Developed by the National Archives of Estonia the tool speeds up the transfer process by reusing already available records management metadata and by automating technical validation and normalisation processes.","2166-1650;21661650","Electronic:978-1-905824-21-2; POD:978-1-4244-8390-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756512","","Computers;Planets;Semantics;Software;Standards;Web services;XML","information retrieval systems;information storage;meta data;records management","National Archives of Estonia;automated ingest;digital records;electronic records management systems;long-term repositories;metadata;universal archiving module","","1","","12","","","27-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"The Knowledge Demands of Expertise Seekers in Two Different Contexts: Knowledge Allocation versus Knowledge Retrieval","D. Nevo; I. Benbasat; Y. Wand","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","This paper explores the knowledge demands of expertise seekers for the purpose of designing effective expertise locator systems. We conduct an empirical investigation, using conjoint analysis and within-subject tests, exploring the relative importance assigned to different experts' attributes under two expertise seeking contexts: knowledge allocation and knowledge retrieval. Our results show that when choosing an expert to retrieve knowledge from (knowledge retrieval), expertise seekers will assign greater importance to the person's level of expertise. When selecting an expert to transfer knowledge to (knowledge allocation), attributes representing the network ties between the expert and the seeker and the benevolence of the expert will be perceived as more important. The results are important for the design of expertise locator systems that are better customized to fit the knowledge needs of their users.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.421","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718734","","Companies;Context;Knowledge engineering;Marketing and sales;Resource management","expert systems;information retrieval;knowledge management","conjoint analysis;expertise locator systems;expertise seekers;knowledge allocation;knowledge demands;knowledge retrieval;knowledge transfer","","0","","33","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"E-Healthcare Service: An Investigation of the Antecedents, Moderating Roles, and Consequences","C. Koo; Y. Wati","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","The rapid growth of internet usage for acquiring health information has received a great deal of attention. Thus, by empirically investigating the official website of National Cancer Center of South Korea, this study adopted the concept of Elaboration Likelihood Model to examine the integration effects of website quality and perceived credibility on user satisfaction and the intention to use under an e-healthcare context. We also measured the moderating roles of self-efficacy and active control, and their consequences on both user satisfaction and intention to use. The research model was tested using Partial Least Square. The empirical results showed that both, website quality and perceived credibility, influence user satisfaction. Moreover, these three variables jointly influence intention to use. Related to the interaction effects, the results showed mixed supporting factors. In sum, our study showed that the proposed antecedents, incorporated with the moderating variables, affect the user satisfaction and intention to use.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718544","","Cancer;Computers;Context;Education;Internet;Navigation","Web sites;health care;information retrieval;least squares approximations;medical information systems","Internet usage;National Cancer Center;Website quality;active control;e-healthcare service;elaboration likelihood model;health information acquisition;partial least square;self-efficacy;user intention;user satisfaction","","0","","64","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Augmenting topic models with user relations in context based communication services","V. T. Babu; K. K. Dhara; V. Krishnaswamy","Department of Electrical Engineering, Indian Institute of Technology, Chennai, India 50036","2011 Third International Conference on Communication Systems and Networks (COMSNETS 2011)","20110217","2011","","","1","10","Context-based communication services analyze user data and offer new and novel services that enhance end user unified communication experience. These services rely on data analysis and machine learning techniques to predict user behavior. In this paper we look at topic modeling as an unsupervised learning tool to categorize user communication data for retrieval. However, modeling topics based on user communication data, such as emails, meetings, invites, etc, poses several interesting challenges. One challenge is that user communication, even for a single topic, varies with the current context of the participating users. Other challenges include low lexical content and high contextual data in communication corpus. Hence, relying primarily on lexical analysis could result in inferior topic models. In this paper, we look at this problem of modeling topics for documents based on user communication. First, we use Latent Dirichlet Allocation (LDA) for extracting topics. LDA models documents as a mixture of latent topics where each topic consists of a probabilistic distribution over words. Then we use a technique that overlays a user-relational model over the lexical topic model generated by LDA. In this paper, we present our work and discuss our results.","2155-2487;21552487","Electronic:978-1-4244-8953-4; POD:978-1-4244-8952-7; USB:978-1-4244-8951-0","10.1109/COMSNETS.2011.5716478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716478","","Analytical models;Context;Context modeling;Correlation;Data models;Electronic mail;Social network services","data analysis;document handling;information retrieval;learning (artificial intelligence);telecommunication services","context based communication services;data analysis technique;high contextual data;latent dirichlet allocation;low lexical content;machine learning technique;topic model;unsupervised learning tool;user communication data;user data;user relations","","0","","22","","","4-8 Jan. 2011","","IEEE","IEEE Conference Publications"
"FCA based concept constructing and similarity measurement algorithms","Ming Che Lee; Zhen Long Liu; Hui Hui Chen; Jian Bang Lai; Yan Tang Lin","Department of Computer and Communication Engineering, Ming Chuan University, Taoyuan, Taiwan","2010 6th International Conference on Advanced Information Management and Service (IMS)","20110214","2010","","","384","388","Traditionally information retrieval consists mainly of determining which documents of a collection contain the keywords in the user query. However, a growing number of tasks, especially those related to Semantic Web technologies and applications rely on accurately measuring the similarity between documents and online texts. Instead of giving the absolute similarity degree of two documents, this paper presents a semantic corpus and Formal Concept Analysis-based procedure to build the concept map for a given set of documents and quantify the semantic relations between the concepts. The proposed approach includes three algorithms - a) the concept lattice constructing algorithm, b) the concept similarity measure, and c) the sub-lattice similarity measure.","","Electronic:978-89-88678-32-9; POD:978-1-4244-8599-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5713479","Formal Concept Analysis;Ontology;Similarity","Algorithm design and analysis;Computers;Context;Lattices;Ontologies;Semantic Web;Semantics","formal concept analysis;information retrieval;natural language processing;semantic Web","FCA based concept construction;concept lattice constructing algorithm;concept map;formal concept analysis-based procedure;information retrieval;semantic Web technologies;semantic corpus;similarity measurement algorithms;sublattice similarity measure;user query","","1","","25","","","Nov. 30 2010-Dec. 2 2010","","IEEE","IEEE Conference Publications"
"Multi-source Spatial Data Code on the Global Partition Method","X. Xin; Z. Shengqiang; S. Zhaolin; Z. Yumei; N. Hongshan; L. Tiegen","ESSS Center, Nat. Univ. of Defense Technol., Changsha, China","2010 International Conference on Intelligent System Design and Engineering Application","20110407","2010","1","","976","979","The multi-source spatial information code is the key of spatial data organization, and the base of spatial information searching, retrieval and the data mining.In this paper, the author establish a spatial information cataloging system combined with the current characteristics and application of multi-source according to the shortage of traditional coding technology. The author also proposed a set of global partition encoding spatial information on the basis of GSM to establish a global unique identification code spatial information GeoID then realized global information sharing.","","Electronic:978-0-7695-4212-6; POD:978-1-4244-8333-4","10.1109/ISDEA.2010.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5743340","Coding;GIS;Multi-source Spatial Data;global subdivision","Data models;Distributed databases;Encoding;GSM;Intelligent systems;Object recognition;Spatial databases","cataloguing;data mining;encoding;geographic information systems;information retrieval;spatial data structures","GSM;GeoID;data mining;global partition method;global unique identification code;information sharing;multisource spatial data code;multisource spatial information code;spatial data organization;spatial information cataloging;spatial information retrieval;spatial information search","","0","","6","","","13-14 Oct. 2010","","IEEE","IEEE Conference Publications"
"Term Weighting Schemes for Question Categorization","X. Quan; L. Wenyin; B. Qiu","City University of Hong Kong, Hong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","20110322","2011","33","5","1009","1021","Term weighting has proven to be an effective way to improve the performance of text categorization. Very recently, with the development of user-interactive question answering or community question answering, there has emerged a need to accurately categorize questions into predefined categories. However, as a question is usually a piece of short text, can the existing term-weighting methods perform consistently in question categorization as they do in text categorization? The answer is not clear, since to the best of our knowledge, we have not seen any work related to this problem despite of its significance. In this study, we investigate the popular unsupervised and supervised term-weighting methods for question categorization. At the same time, we propose three new supervised term-weighting methods, namely, gf* icf, igf* gf* icf, and vrf. Comparisons of them with existing unsupervised and supervised term weighting methods are made through a series of experiments on question collections of Yahoo! Answers. The experimental results show that igf* gf* icf achieves the best performance among all term-weighting methods, while gf*icf and vrf are also competitive for question categorization. Meanwhile, tf* OR is proven to be the most significant one among existing methods. In addition, igf* gf* icf and vrf are also effective for long document categorization.","0162-8828;01628828","","10.1109/TPAMI.2010.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557877","Question answering systems;question categorization;term-weighting;text categorization.","Decision support systems","question answering (information retrieval);text analysis","community question answering;question categorization;supervised term-weighting method;term weighting schemes;text categorization;unsupervised term-weighting method;user-interactive question answering","","14","","33","","20100826","May 2011","","IEEE","IEEE Journals & Magazines"
"Design and Implementation of Campus Data Sharing Based on the Web Services Technology","S. Yang; X. Lu","Coll. of Math. & Inf. Sci., Hebei Normal Univ., Shijiazhuang, China","2010 First ACIS International Symposium on Cryptography, and Network Security, Data Mining and Knowledge Discovery, E-Commerce and Its Applications, and Embedded Systems","20110429","2010","","","217","220","This paper describes the technical background of web services. Then use web services technology to achieve the design of the campus data sharing, include the entire system analysis, design process, which introduces a data maintenance, data sharing, data access realization of three modules.","","Electronic:978-0-7695-4332-1; POD:978-1-4244-9595-5","10.1109/CDEE.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759374","campus;data;services;sharing;web","Distributed databases;Educational institutions;Maintenance engineering;Servers;Software;Web services","Web services;information retrieval","Web services;campus data sharing;data access realization;data maintenance","","0","","5","","","23-24 Oct. 2010","","IEEE","IEEE Conference Publications"
"Business intelligence from Twitter for the television media: A case study","J. Marasanapalle; T. S. Vignesh; P. K. Srinivasan; A. Saha","Computing and Decision Sciences Lab, GE - Global Research, JFWTC, Bangalore, India","2010 IEEE International Workshop on: Business Applications of Social Network Analysis (BASNA)","20110314","2010","","","1","6","Twitter, the social network service, is a rich source of information on customer response to a live event such as a television show. In this paper we present a case study where we analyzed publicly available tweets that were posted when a popular TV show was aired for the first time in a season. We use standard text-mining techniques to answer questions such as, what were the main themes during the show, what drove the popularity of the show and what were the kind of viewers who were tweeting on the show. This kind of business intelligence can be used by content producers in improving future shows, in targeted marketing to audience, in gathering competitive intelligence and many other ways.","","Electronic:978-1-4244-9000-4; POD:978-1-4244-8999-2","10.1109/BASNA.2010.5730304","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730304","Classification;Sampling;Sentiment-Mining;Text-Mining;Themes","Data mining;Interviews;Media;Motion pictures;Real time systems;TV;Twitter","competitive intelligence;data mining;multimedia systems;question answering (information retrieval);social networking (online);television applications;text analysis","TV show;business intelligence;information source;social network service;television media;text mining technique;twitter","","1","1","16","","","15-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Designing a Super-Peer semantic Network based on Hierarchical Clusters","Y. h. Tan; B. Li; X. y. Li; Y. p. Lin","Department of Information and Computing Science, Changsha University, 410003, China","2010 IEEE Youth Conference on Information, Computing and Telecommunications","20110214","2010","","","194","197","In super-peer semantic network, when a new peer joins the network, the peer will use the semantic feature of local share documents to select super-peers. In traditionally networks, client-peers use the semantic feature of clusters in peers to select the super-peers to connect. But the clusters are fixed, general, single-level, and not effective to represent the features of all documents. And, while selecting super-peers to connect, the client-peer cannot select some relative clusters in different level accord to the semantic categories of super-peers semantic group. In this paper, a Super-Peer semantic Network based on Hierarchical Clustering Tree (HCTSPN) is presented. First, an improved hierarchical clustering algorithm for organizing the share documents in a client-peer is proposed. Secondly, the method of constructing a super-peer semantic network based on hierarchical clustering tree and search mechanism are proposed. Finally, the experiments are implemented, and the results show that search efficiency and retrieval quality are improved in the network.","","Electronic:978-1-4244-8886-5; POD:978-1-4244-8883-4","10.1109/YCICT.2010.5713078","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5713078","hierarchical cluster;peer-to-peer network;semantic network;super-peer","Algorithm design and analysis;Clustering algorithms;Feature extraction;Indexes;Organizing;Peer to peer computing;Semantics","information retrieval;pattern clustering;peer-to-peer computing;semantic networks;tree searching","client-peers;hierarchical clustering tree;local share documents;retrieval quality;search mechanism;super-peer semantic network","","1","","9","","","28-30 Nov. 2010","","IEEE","IEEE Conference Publications"
"Applying Web-based tools for research, engineering and operations","W. D. Ivancic","NASA Glenn Research Center, 21000 Brookpark Road, Cleveland, OH 44135, USA","2011 Aerospace Conference","20110411","2011","","","1","8","Personnel in the NASA Glenn Research Center Network and Architectures branch have performed a variety of research related to space-based sensor webs, network centric operations, security and delay tolerant networking (DTN). Quality documentation and communications, real-time monitoring and information dissemination are critical in order to perform quality research while maintaining low cost and utilizing multiple remote systems. This has been accomplished using a variety of Internet technologies often operating simultaneously. This paper describes important features of various technologies and provides a number of real-world examples of how combining Internet technologies can enable a virtual team to act efficiently as one unit to perform advanced research in operational systems. Finally, real and potential abuses of power and manipulation of information and information access is addressed.","1095-323X;1095323X","Electronic:978-1-4244-7351-9; POD:978-1-4244-7350-2","10.1109/AERO.2011.5747664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5747664","","Electronic mail;Instant messaging;Software;Streaming media;Web server","Internet;aerospace engineering;information retrieval;virtual reality","DTN;Internet technology;NASA Glenn Research Center Network and Architectures;Web based tool;delay tolerant networking;information access;information dissemination;network centric operation;quality documentation;real time monitoring;space based sensor web;virtual team","","0","","8","","","5-12 March 2011","","IEEE","IEEE Conference Publications"
"Coverage-Aware Node-Disjoint Multipath Selection in Wireless Multimedia Sensor Networks","D. G. Costa; L. A. Guedes","Dept. of Comput. & Autom., Fed. Univ. of Rio Grande do Norte, Rio Grande, Brazil","2011 4th IFIP International Conference on New Technologies, Mobility and Security","20110228","2011","","","1","5","Typical wireless multimedia sensor networks are composed of many randomly deployed nodes which can retrieve information from the monitored field and relay packets following a hop-by-hop communication model. The transmission of packets from source nodes to the destination may flow across multiple paths, each one comprised of a number of intermediate nodes. The simple existence of a sensing unit in intermediate nodes or the estimation of cameras' Field of View over a monitoring target may turn relevant some sensors that compose a particular available path. We propose two coverage-aware node-disjoint multipath selection algorithms to distribute multimedia traffic over the available paths considering the sensing relevance of the intermediate nodes, potentially prolonging the lifetime of more relevant sensors for the application monitoring tasks.","2157-4952;21574952","Electronic:978-1-4244-8704-2; POD:978-1-4244-8705-9; USB:978-1-4244-8703-5","10.1109/NTMS.2011.5720610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720610","","Bandwidth;Multimedia communication;Sensors;Streaming media;Telecommunication traffic;Wireless communication;Wireless sensor networks","information retrieval;multimedia communication;telecommunication network management;telecommunication network routing;telecommunication traffic;wireless sensor networks","coverage awareness;hop-by-hop communication;information retrieval;multimedia traffic;node disjoint multipath selection;target monitoring;wireless sensor networks","","2","","8","","","7-10 Feb. 2011","","IEEE","IEEE Conference Publications"
"A social network-based meta search engine","M. A. Ghaderi; N. Yazdani; B. Moshiri","Central & intelligent processing center of excellence, School of ECE, University of Tehran, Iran","2010 5th International Symposium on Telecommunications","20110317","2010","","","744","749","Social networks as an application of social web have attracted many users and have became one of the most important services of Internet. Interaction of users in a social network generates huge amount of data. In this paper, a novel meta-search engine is proposed to exploit social network data to improve web search results. The system modifies meta-search engine's multi-agent based architecture by adding new agents to gather interaction data of users and process them to create user profiles based on the previous researches. These profiles are used to re-rank top search results of a web search engine and increase effectiveness of retrieval. Normalized Discounted Cumulative Gain (NDCG) measure is used to evaluate our system. Experimental results show the potential usefulness of social network data for improvement of web search effectiveness.","","Electronic:978-1-4244-8185-9; POD:978-1-4244-8183-5","10.1109/ISTEL.2010.5734121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5734121","meta search engine;social network;social search;user profiling;user social model","Engines;Facebook;Metasearch;Search engines;Web search","Internet;information retrieval;multi-agent systems;search engines;social networking (online)","Internet;meta search engine;multiagent based architecture;normalized discounted cumulative gain measure;retrieval effectiveness;social Web;social network","","0","","32","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"Tracing Opinion-Formation on Political Issues on the Internet: A Model and Methodology for Qualitative Analysis and Results","M. Kaschesky; R. Riedl","","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","Linked social information on blogs and online social networks provides a rich source of policy feedback for citizens, journalists, politicians and researchers, yet the qualitative value hidden in this information is rarely exploited. In order to address the problem, this article presents a systematic methodology for retrieving targeted information on a political issue from prominent online sources. Using news services for triangulation, the methodology enables qualitative analysis regarding the spread of political opinions on an issue across a relevant sample of linked social information on the internet. The resulting pattern informs not only about the structure and information flows across linked social information but also about sentiments and opinion adoption over time. A model of opinion formation is presented and used to apply the methodology.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718645","","Biological system modeling;Blogs;Decision making;Government;Internet;Media;Social network services","Internet;government data processing;information retrieval;politics;social networking (online)","Internet;blogs;information flow;information retrieval;linked social information;online social networks;opinion formation;policy feedback;political issue;qualitative analysis","","3","","62","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Time-critical database conditions data-handling for the CMS experiment","M. De Gruttola; S. Di Guida; V. Innocente; A. Pierro","INFN Sezione di Napoli, Naples, Italy","2010 17th IEEE-NPSS Real Time Conference","20110415","2010","","","1","4","Automatic, synchronous and of course reliable population of the condition databases is critical for the correct operation of the online selection as well as of the offline reconstruction and analysis of data. We will describe here the system put in place in the CMS experiment to automatize the processes to populate centrally the database and make condition data promptly available both online for the high-level trigger and offline for reconstruction. The data are “dropped” by the users in a dedicate service which synchronizes them and takes care of writing them into the online database. Then they are automatically streamed to the offline database hence immediately accessible offline worldwide. This mechanism was intensively used during 2008 and 2009 operation with cosmic ray challenges and first LHC collision data, and many improvements done so far. The experience of this first years of operation will be discussed in detail.","","Electronic:978-1-4244-7110-2; POD:978-1-4244-7108-9","10.1109/RTC.2010.5750484","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750484","","Calibration;Databases;Detectors;Large Hadron Collider;Monitoring;Payloads;Software","data analysis;database management systems;information retrieval systems;information services","LHC collision data;compact muon solenoid experiment;cosmic ray challenge;data analysis;data handling;offline data reconstruction;online database;time critical database condition","","0","","8","","","24-28 May 2010","","IEEE","IEEE Conference Publications"
"A Personalized Ontology Model for Web Information Gathering","X. Tao; Y. Li; N. Zhong","Queensland University of Technology, Brisbane","IEEE Transactions on Knowledge and Data Engineering","20110217","2011","23","4","496","511","As a model for knowledge description and formalization, ontologies are widely used to represent user profiles in personalized web information gathering. However, when representing user profiles, many models have utilized only knowledge from either a global knowledge base or a user local information. In this paper, a personalized ontology model is proposed for knowledge representation and reasoning over user profiles. This model learns ontological user profiles from both a world knowledge base and user local instance repositories. The ontology model is evaluated by comparing it against benchmark models in web information gathering. The results show that this ontology model is successful.","1041-4347;10414347","","10.1109/TKDE.2010.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560649","Ontology;local instance repository;personalization;semantic relations;user profiles;web information gathering.;world knowledge","","Internet;inference mechanisms;information retrieval;ontologies (artificial intelligence);user interfaces","Web information gathering;knowledge description model;knowledge formalization model;knowledge representation;personalized ontology model;user profile reasoning;user profile representation","","35","","49","","20100902","April 2011","","IEEE","IEEE Journals & Magazines"
"Design an Artificial Mirror system as an interaction method for the life logging system","Abeer Mohammed AL-Shiha; S. Dlay; W. L. Woo","Newcastle University-UK","2010 International Conference on User Science and Engineering (i-USEr)","20110222","2010","","","128","132","People are capturing and storing an ever-increasing amount of information about themselves, such as digital images. New technologies, in addition to increasing the need to store daily activities via images and for retrieval capacity, have led to the development of interaction methods for this information. Therefore, this case study suggests an Artificial Mirror interaction system to enable access of personal memories stored in digital pictures, using the eye tracking as a natural way of interacting with this system.","","Electronic:978-1-4244-9049-3; POD:978-1-4244-9048-6","10.1109/IUSER.2010.5716737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716737","Calm computing;eye tracking;life logging","Cameras;Computers;Humans;Image recognition;Mirrors;Tracking;Ubiquitous computing","artificial intelligence;computer vision;human computer interaction;information retrieval;ubiquitous computing","artificial mirror system;digital picture;eye tracking;interaction method;life logging system","","0","","18","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"The String-to-Dictionary Matching Problem","S. T. Klein; D. Shapira","Dept. of Comput. Sci., Bar Ilan Univ., Ramat Gan, Israel","2011 Data Compression Conference","20110411","2011","","","143","152","The String-to-Dictionary Matching Problem is defined, in which a string is searched for in all the possible concatenations of the elements of a given dictionary, with applications to compressed matching in variable to fixed length encodings, such as Tunstall's. An algorithm based on suffix trees is suggested and experiments on natural language text are presented suggesting that compressed search might use less comparisons for long enough patterns, in spite of a potentially large number of encodings.","1068-0314;10680314","Electronic:978-0-7695-4352-9; POD:978-1-61284-279-0","10.1109/DCC.2011.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5749472","Compressed Matching;Suffix Trees;Tunstall","Computer science;Data compression;Decoding;Dictionaries;Encoding;Indexes;Pattern matching","data compression;dictionaries;encoding;information retrieval;natural language processing;string matching","compressed matching;fixed length encoding;natural language text;string searching;string-to-dictionary matching problem","","1","","15","","","29-31 March 2011","","IEEE","IEEE Conference Publications"
