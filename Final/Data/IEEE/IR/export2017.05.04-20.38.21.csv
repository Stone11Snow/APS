"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7033048,7034845,7032948,7033482,7033049,7030113,7031196,6932449,7023587,7023972,7024623,7020593,7020630,7020773,7020463,7019378,7016857,7015074,7009919,6999268,7009714,7009717,7008013,6987314,7005959,7005997,6975165,7004500,7001512,7000176,6998359,6996185,6993462,6988094,6991398,6984710,6982639,6984893,6982864,6981017,6981009,6984844,6982404,6978954,6982067,6978944,6977273,6976084,6976114,6976083,6977237,6807734,6974639,6973603,6974832,6512497,6970221,6973991,6970168,6970188,6970174,6970257,6970223,6970164,6969063,6913297,6954237,6955352,6954255,6954221,6950655,6950705,6946276,6946767,6938715,6936538,6933026,6927558,6927573,6927557,6927528,6927626,6927526,6927562,6927669,6927604,6927097,6921722,6923242,6921690,6737290,6920736,6918273,6916462,6916598,6916189,6916796,6915399,6906262,6912118",2017/05/04 20:38:21
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Reducing Noises for Recall-Oriented Patent Retrieval","W. Lee; C. K. S. Leung; J. J. Song","Dept. of Ind. Eng., Inha Univ., Incheon, South Korea","2014 IEEE Fourth International Conference on Big Data and Cloud Computing","20150209","2014","","","579","586","Patents have been considered as key enablers for many knowledge- and information-centric companies as well as institutes. The higher the required patent capability, the more important is the need for an effective and efficient patent search system. Many conventional patent search systems produce unsatisfactory results for patent queries because the inherent search systems come from traditional keyword-based models, which inevitably lead to too many unrelated items in the search results. Consequently, these systems cost the patent experts lots of time to iteratively refine search results manually. In this paper, we propose a specialized patent-searching method, in which relationships between the keywords within each document and their implication for each patent document are investigated. With this elaborated ranking capability, keywords for valid patents are placed in higher ranks and those for noise patents are placed in sub-ranked data positions. As a benefit, our method significantly eliminates noisy data from the search results. Hence, our method is very useful for recall-oriented search for patents. Experimental results with real-life datasets show that our method outperformed many conventional patent search systems with respect to time and cost.","","Electronic:978-1-4799-6719-3; POD:978-1-4799-6720-9","10.1109/BDCloud.2014.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7034845","Social computing and networking;information retrieval;patent;recall;social computing and its applications","Equations;Mathematical model;Noise;Noise measurement;Patents;Search problems;Three-dimensional displays","patents;query processing","information-centric companies;keyword-based models;knowledge-centric companies;noise reduction;patent document;patent query;patent search system;ranking capability;recall-oriented patent retrieval;specialized patent-searching method;sub-ranked data positions","","0","","36","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Pareto-Depth for Multiple-Query Image Retrieval","K. J. Hsiao; J. Calder; A. O. Hero","WhisperText Inc., Venice, CA, USA","IEEE Transactions on Image Processing","20150108","2015","24","2","583","594","Most content-based image retrieval systems consider either one single query, or multiple queries that include the same object or represent the same semantic information. In this paper, we consider the content-based image retrieval problem for multiple query images corresponding to different image semantics. We propose a novel multiple-query information retrieval algorithm that combines the Pareto front method with efficient manifold ranking. We show that our proposed algorithm outperforms state of the art multiple-query retrieval algorithms on real-world image databases. We attribute this performance improvement to concavity properties of the Pareto fronts, and prove a theoretical result that characterizes the asymptotic concavity of the fronts.","1057-7149;10577149","","10.1109/TIP.2014.2378057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6975165","Pareto fronts;information retrieval;manifold ranking;multiple-query retrieval;multiplequery retrieval","Algorithm design and analysis;Image retrieval;Manifolds;Metasearch;Semantics","content-based retrieval;image retrieval;learning (artificial intelligence)","Pareto front method;Pareto-depth;asymptotic concavity;concavity property;content-based image retrieval systems;image semantics;manifold ranking;multiple-query image retrieval algorithm;semantic information","","2","","57","","20141204","Feb. 2015","","IEEE","IEEE Journals & Magazines"
"Fast parameterized word matching on compressed text","R. Garg; R. Prasad; S. Agarwal","Ajay Kumar Garg Engineering College, Ghaziabad, India","2014 International Conference on Computer and Communication Technology (ICCCT)","20150108","2014","","","317","321","Two strings P[1...m] and T[1...n] with m ≤ n, are said to be parameterized match (p-match), if one can be transformed into the other via some bijective mapping. It is mainly used in software maintenance, plagiarism detection and detecting isomorphism in a graph. In the compressed parameterized matching problem, our task is to find all the parameterized occurrences of a pattern in the compressed text, without decompressing it. Compressing the text before matching reduces the size and minimizes the matching time also. In this paper, we mainly focus on the parameterized word matching on the compressed text, where both patterns and text are compressed before actual matching is performed. For compressing the pattern and text, we use efficient compression code: Word Based Tagged Code (WBTC). Experimental results show that our algorithm is up to three times faster than the search on uncompressed text.","","Electronic:978-1-4799-6758-2; POD:978-1-4799-6759-9","10.1109/ICCCT.2014.7001512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7001512","Compressed parameterized matching;String matching;compressed pattern matching;information retrieval and word based tagged code","Algorithm design and analysis;Approximation algorithms;Indexes;Pattern matching;Transforms;Vocabulary","codes;data compression;pattern matching;text analysis","WBTC;bijective mapping;compressed parameterized matching problem;compression code;fast parameterized word matching;isomorphism detection;p-match;plagiarism detection;software maintenance;text compression;word based tagged code","","1","","17","","","26-28 Sept. 2014","","IEEE","IEEE Conference Publications"
"Scientific Literature Retrieval Model Based on Weighted Term Frequency","X. Q. Yang; D. Yang; M. Yuan; X. H. Lv","Sch. of Comput. Sci. & Inf. Technol., Northeast Normal Univ., Changchun, China","2014 Tenth International Conference on Intelligent Information Hiding and Multimedia Signal Processing","20141229","2014","","","427","430","Science and technology literature retrieval system is commonly used by researchers as document retrieval tools. The classic information retrieval models such as Boolean Model [1], Vector Space Model and Probabilistic model neglect the position of query words in every paper. We propose a weighted term frequency model (WTFM) based on term frequency, and through a simulated annealing algorithm to learn the weighted factor. The results of experiments show that our weighted factors model gets better performance than ordinary models.","","Electronic:978-1-4799-5390-5; POD:978-1-4799-5391-2","10.1109/IIH-MSP.2014.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6998359","information retrieval;simulated annealing","Biological system modeling;Computational modeling;Educational institutions;Information retrieval;Mathematical model;Simulated annealing;Vectors","document handling;query processing;scientific information systems;simulated annealing","WTFM;document retrieval tools;query words;scientific literature retrieval model;simulated annealing algorithm;technology literature retrieval system;weighted factor;weighted term frequency model","","0","","12","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"Content-based query for class-level tagged items via the EPC network","Z. Wang; K. Jiang; M. Du; J. Le","Donghua University, China","2014 International Conference on the Internet of Things (IOT)","20150205","2014","","","43","48","Electronic Product Code has been widely used to identify items with RFID tags. To the best of our knowledge, however, few works focus on exploring the value of textural data in the EPC Network that pertains to EPC. In this paper we propose the concept of the content-based query for tagged items by applying information retrieval method to the EPC network resources. The objective of the content-based query is to discover a set of class-level tagged items of interest which correlate with the user-specific keyword or EPC in question. Accordingly, we describe the strategies in terms of content integration, modelling and similarity measurement for the content-based queries. Our experimental results demonstrate the effectiveness of our approach.","","Electronic:978-1-4799-5154-3; POD:978-1-4799-5155-0; USB:978-1-4799-5153-6","10.1109/IOT.2014.7030113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030113","Content-based Query;EPC Information Service;Electronic Product Code;Information Retrieval;Topic Model","Heuristic algorithms;Internet of things;Patents;Product codes;Radiofrequency identification;Uniform resource locators","content-based retrieval;data integration;electronic products;network coding;radiofrequency identification","EPC network resource;RFID tags;class-level tagged items;content integration;content-based query;electronic product code;information retrieval method;textural data;user-specific keyword","","0","","19","","","6-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Design of a state machine towards efficient management of user-generated data","N. Y. Yen; R. Huang; J. Ma","School of Computer Science and Engineering, The University of Aizu, Aizu-Wakamatsu, Japan","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20141204","2014","","","700","704","Social media facilitates the process of information sharing, and meanwhile, prompts the generation of a considerable amount of data. Although the data, or user-generated contents, enrich the results for the process of information seeking, it causes the complexity to identify the value of data. Thus, an approach that achieves efficient management of user-generated data was proposed. It especially concentrates on the correlations among data and interactions with users. A state machine is designed to identify the user-generated data, and corresponding usage scenarios. The performance and feasibility can be revealed by the experiments sourced by the data collected from open social networks.","1062-922X;1062922X","Electronic:978-1-4799-3840-7; POD:978-1-4799-3841-4; USB:978-1-4799-3839-1","10.1109/SMC.2014.6973991","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973991","human-centered support;information retrieval;state machine;user-generated data","Accuracy;Artificial neural networks;Context;Niobium;Social network services;Software;Support vector machines","finite state machines;information retrieval;social networking (online)","information seeking;information sharing;open social networks;state machine design;user-generated contents;user-generated data management","","0","","15","","","5-8 Oct. 2014","","IEEE","IEEE Conference Publications"
"Word-Graph and Character-Lattice Combination for KWS in Handwritten Documents","J. Puigcerver; A. H. Toselli; E. Vidal","PRHLT Res. Center, Univ. Politec. de Valencia, Valencia, Spain","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","181","186","We present a handwritten text Keyword Spotting (KWS) approach based on the combination of KWS methods using word-graphs (WGs) and character-lattices (CLs). It aims to solve the problem that WG-based models present for out of vocabulary (OOV) keywords: since there is no available information about them in the lexicon or the language model, null scores are assigned. OOV keywords may have a significant impact on the global performance of KWS systems, as we show. By using a CL approach, which does not suffer from the previous problem, to estimate the OOV scores, we take advantage of both models, using the speed and accuracy that WGs provide for in-vocabulary keywords and the flexibility of the CL approach. This combination improves significantly both average precision and mean average precision over the two methods.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981017","character lattice;handwriting text recognition;information retrieval;out of vocabulary;spotting;word graph","Computational modeling;Decoding;Hidden Markov models;Image segmentation;Training;Viterbi algorithm;Vocabulary","handwritten character recognition;text detection","CL approach;KWS methods;OOV keywords;OOV score estimation;WG-based models;character-lattices;global performance;handwritten documents;handwritten text KWS approach;handwritten text keyword spotting approach;in-vocabulary keywords;language model;lexicon model;mean average precision;null-score assignment;out-of-vocabulary keywords;word-graphs","","3","","22","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"Reducing computational effort for plagiarism detection by using citation characteristics to limit retrieval space","N. Meuschke; B. Gipp","National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","197","200","This paper proposes a hybrid approach to plagiarism detection in academic documents that integrates detection methods using citations, semantic argument structure, and semantic word similarity with character-based methods to achieve a higher detection performance for disguised plagiarism forms. Currently available software for plagiarism detection exclusively performs text string comparisons. These systems find copies, but fail to identify disguised plagiarism, such as paraphrases, translations, or idea plagiarism. Detection approaches that consider semantic similarity on word and sentence level exist and have consistently achieved higher detection accuracy for disguised plagiarism forms compared to character-based approaches. However, the high computational effort of these semantic approaches makes them infeasible for use in real-world plagiarism detection scenarios. The proposed hybrid approach uses citation-based methods as a preliminary heuristic to reduce the retrieval space with a relatively low loss in detection accuracy. This preliminary step can then be followed by a computationally more expensive semantic and character-based analysis. We show that such a hybrid approach allows semantic plagiarism detection to become feasible even on large collections for the first time.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970168","Citation Analysis;Disguised Plagiarism;Information Retrieval;Large Scale Collections;Plagiarism Detection;Semantic Analysis","Algorithm design and analysis;Citation analysis;Couplings;Handheld computers;Plagiarism;Semantics;Text analysis","citation analysis;information retrieval;semantic Web","academic documents;character-based analysis;character-based methods;citation characteristics;citation-based methods;plagiarism detection methods;real-world plagiarism detection scenarios;retrieval space;semantic argument structure;semantic word similarity;sentence level","","1","","21","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Representing topics labels for exploring digital libraries","N. Aletras; T. Baldwin; J. H. Lau; M. Stevenson","Comput. Sci., Univ. of Sheffield, Sheffield, UK","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","239","248","Topic models have been shown to be a useful way of representing the content of large document collections, for example via visualisation interfaces (topic browsers). These systems enable users to explore collections by way of latent topics. A standard way to represent a topic is using a set of keywords, i.e. the top-n words with highest marginal probability within the topic. However, alternative topic representations have been proposed, including textual and image labels. In this paper, we compare different topic representations, i.e. sets of topic words, textual phrases and images, in a document retrieval task. We asked participants to retrieve relevant documents based on pre-defined queries within a fixed time limit, presenting topics in one of the following modalities: (1) sets of keywords, (2) textual labels, and (3) image labels. Our results show that textual labels are easier for users to interpret than keywords and image labels. Moreover, the precision of retrieved documents for textual and image labels is comparable to the precision achieved by representing topics using sets of keywords, demonstrating that labelling methods are an effective alternative topic representation.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970174","evaluation;information retrieval;topic model","Electronic publishing;Encyclopedias;Feature extraction;Internet;Labeling;Visualization","digital libraries;image retrieval;text analysis","content representation;digital libraries;document collections;document retrieval task;image labels;keyword sets;latent topics;marginal probability;query processing;textual labels;textual phrases;top-n words;topic label representation;topic models;topic words","","0","","","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A Feedback-Based Self-Organizing Query Structure Optimization Algorithm","R. Xu","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign (UIUC), Urbana, IL, USA","2014 Tenth International Conference on Computational Intelligence and Security","20150122","2014","","","80","84","Query is one of the most important factors that can directly influence the results of information retrieval (IR). However, the query is defined by the user and thus inevitably has the following two problems: (1) the user often cannot exactly represent their search intention via query terms, (2) the user cannot effectively select the weight of each query term based on its importance toward the query's meaning. The above two problems cause the two types of uncertainty of a query. In this paper, we define them as the uncertainty of the query structure and the uncertainty of the query parameter, respectively. To eliminate the above two types of uncertainty and solve the above two problems, this paper proposes a new algorithm which includes two parts: (1) a self-organizing query structure loop which expands the initial query by adding only one term within each loop based on feedback technology until it meets the terminating condition of expansion defined by the author, and (2) an optimization algorithm based on a genetic algorithm (GA) that optimizes the weights of the expanded query vector within each loop. This algorithm provides a method of finding the optimal number of query expansion terms and improving the precision and recall of the search results. The experiment results show the effectiveness of the proposed algorithm.","","CD-ROM:978-1-4799-7433-7; Electronic:978-1-4799-7434-4; POD:978-1-4799-7435-1","10.1109/CIS.2014.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016857","Information retrieval;VSM;query parameter;query structure;self-organizing;uncertainty","Genetic algorithms;Information retrieval;Optimization;Standards;Uncertainty;Vectors","feedback;genetic algorithms;query processing","GA algorithm;feedback;feedback technology;genetic algorithm;information retrieval;query parameter;query structure uncertainty;query vector;self-organizing query structure loop","","0","","16","","","15-16 Nov. 2014","","IEEE","IEEE Conference Publications"
"Modelling on classification and retrieval strategy in map-reduce based IR system","S. Gao; K. Gao","School of Information Science & Engineering, Hebei University of Science and Technology, China","Proceedings of 2014 International Conference on Modelling, Identification & Control","20150126","2014","","","322","325","Classification is essential to many web applications. Instead of the traditional segmentation as usual, this paper presents a novel non-segment classification approach, which can meet the requirement for big data classification & application. The novel algorithm removes the complicated time consuming segmentation. The experimental results and the analysis show the feasible of the approach. Based on the proposed approach, a map-reduce based distributed IR system is present.","","Electronic:978-0-9567157-4-6; POD:978-1-4799-5105-5","10.1109/ICMIC.2014.7020773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020773","classification;information retrieval;map-reduce","Analytical models;Classification algorithms;Computational modeling;Containers;Indexing;Servers;Vectors","Big Data;information retrieval;pattern classification","big data classification;information retrieval strategy;map reduce based distributed IR system;non-segment classification approach","","0","","12","","","3-5 Dec. 2014","","IEEE","IEEE Conference Publications"
"Scalable Arrow Detection in Biomedical Images","K. C. Santosh; L. Wendling; S. K. Antani; G. R. Thoma","Commun. Eng. Branch, Nat. Inst. of Health, Bethesda, MD, USA","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3257","3262","In this paper, we present a scalable arrow detection technique for biomedical images to support information retrieval systems under the purview of content-based image retrieval (CBIR) and text information retrieval (TIR). The idea primarily follows the criteria based on the geometric properties of the arrow, where we introduce signatures from key points associated with it. To handle this, images are first binarized via a fuzzy binarization tool and several regions of interest are labeled accordingly. Each region is used to generate signatures and then compared with the theoretical ones to check their similarity. Our validation over biomedical images shows the advantage of the technique over the most prominent state-of-the-art methods.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977273","Arrow detection;biomedical images;content-based image retrieval and text information retrieval","Biomedical imaging;Head;Image color analysis;Image edge detection;Information retrieval;Noise;Shape","content-based retrieval;fuzzy set theory;image retrieval;medical image processing;text analysis","CBIR;TIR;biomedical images;content-based image retrieval;fuzzy binarization tool;image binarization;information retrieval systems;regions of interest;scalable arrow detection;text information retrieval","","2","","16","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Enterprise Contextual Intelligence","G. Shroff; L. Dey; H. Ghosh","","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","2","","202","209","Information overload is an increasing challenge for the enterprise knowledge worker. Traditional information retrieval, i.e. Search-based approaches for knowledge management in the enterprise are under strain because users do not have the time to search, often they are not even aware that material relevant to they current needs exists. Neither do they have the time to track the various external news feeds that are increasingly becoming available, however personalised they might be. We submit that relevant content should be pushed to users based on detecting their current needs from the context of their current activities as sensed via their behavioural footprint, such as their posts, emails, as well as search queries. In this paper we describe a generic 'enterprise contextual intelligence' (ECI)framework based on an ontology-driven probabilistic graphical model for push-based context-aware knowledge recommendation in an enterprise. We illustrate our ECI framework with a motivating practical business example and differentiate it from other context-aware search and recommendation approaches.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927626","Contextual Intelligence;Enterprise Information retrieval","Context;Context modeling;Electronic mail;Ontologies;Probabilistic logic;Procurement;Proposals","business data processing;competitive intelligence;ontologies (artificial intelligence);recommender systems;ubiquitous computing","ECI framework;context-aware search approach;enterprise contextual intelligence;ontology-driven probabilistic graphical model;push-based context-aware knowledge recommendation","","0","1","19","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"SORM: A Social Opinion Relevance Model","A. D. S. Lima; J. S. Sichman","Lab. de Tec. Inteligentes (LTI), Univ. de Sao Paulo (USP), Sao Paulo, Brazil","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","78","85","This paper presents a generic and domain independent opinion relevance model for a Social Network user. The Social Opinion Relevance Model (SORM) is able to estimate an opinion's relevance based on twelve different parameters. Compared to other models, SORM's main distinction is its ability to provide customized results according to whom the opinion relevance is being estimated for. Due to the lack of opinion relevance corpuses able to properly test our model, we have created a new one called Social Opinion Relevance Corpus (SORC). Using SORC, we carried out some experiments on the Electronic Games domain that illustrate the importance of the customizing the opinion relevance in order to achieve better results on typical Information Retrieval metrics, such as NDCG, QMeasure and MAP. We also performed a statistical significance test that reinforces and corroborates the advantages that SORM offers.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927528","information retrieval;opinion mining;opinion relevance;social search","Books;Computational modeling;Games;Gold;Mathematical model;Social network services","computer games;information retrieval;natural language processing;social networking (online);text analysis","MAP;NDCG;QMeasure;SORC;SORM;electronic games;information retrieval metrics;opinion mining;social network;social opinion relevance corpus;social opinion relevance model;statistical significance test","","0","","23","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"A learning environment based on knowledge storage and retrieval using concept maps","R. Rudraraju; L. Najim; V. P. Gurupur; M. M. Tanik","Electrical and Computer Engineering Department, University of Alabama at Birmingham, USA","IEEE SOUTHEASTCON 2014","20141110","2014","","","1","6","In today's digital age, a plethora of websites host knowledge related to various professions. Individuals working in different professions in turn consume this knowledge either to advance their skills or to accomplish their professional responsibilities. As this knowledge is continuously evolving, both in terms of size and content, the process used for acquiring the knowledge becomes important. Concept maps are proven to explicitly facilitate meaningful learning for all age groups. In this paper we propose a new knowledge integration process, implemented using a learning environment that facilitates meaningful learning by enabling the users to make a connection between newly gained and existing knowledge using concept maps. We also discuss an algorithm to construct a meta-map in order to represent collective information related to a topic and explain the various ways to extract valuable information from it.","1091-0050;10910050","Electronic:978-1-4799-6585-4; POD:978-1-4799-6586-1","10.1109/SECON.2014.6950655","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6950655","Concept maps;bookmarks;information retrieval;recommender systems;search engines;social networking","Classification algorithms;Computers;Measurement;Multimedia communication","information retrieval;knowledge acquisition;search engines;social networking (online)","concept maps;information retrieval;knowledge acquisition;knowledge integration;knowledge storage;learning environment;search engines;social networking","","0","","14","","","13-16 March 2014","","IEEE","IEEE Conference Publications"
"On the duality of specific early and late fusion strategies","L. Kaliciak; H. Myrhaug; A. Goker; D. Song","The Robert Gordon University, Aberdeen, Scotland","17th International Conference on Information Fusion (FUSION)","20141007","2014","","","1","8","In this paper, we prove that specific early and specific late fusion strategies are interchangeable. In the case of the late fusion, we consider not only linear but also nonlinear combinations of scores. Our findings are important from both theoretical and practical (applied) perspectives. The duality of specific fusion strategies also answers the question why in the literature the experimental results for both early and late fusion are often similar. The most important aspect of our research is, however, related to the presumable drawbacks of the aforementioned fusion strategies. It is an accepted fact that the main drawback of the early fusion is the curse of dimensionality (generation of high dimensional vectors) whereas the main drawback of the late fusion is its inability to capture correlation between feature spaces1. Our proof on the interchangeability of specific fusion schemes undermines this belief. Only one of the possibilities exists: either the late fusion is capable of capturing the correlation between feature spaces or the interaction between the early fusion operators and the similarity measurements decorrelates feature spaces.","","Electronic:978-8-4901-2355-3; POD:978-1-4799-1634-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916189","Content-based Image Retrieval;Information Retrieval;Information and data fusion;Multimedia Retrieval;early fusion;late fusion;textual representation;visual representation","Educational institutions;Euclidean distance;Extraterrestrial measurements;Multimedia communication;Tensile stress;Vectors;Visualization","content-based retrieval;duality (mathematics);image fusion;image retrieval","content-based image retrieval;curse of dimensionality;duality;early fusion strategy;feature spaces;high dimensional vectors;late fusion strategy","","1","","14","","","7-10 July 2014","","IEEE","IEEE Conference Publications"
"Applications of Recurrent Neural Network Language Model in Offline Handwriting Recognition and Word Spotting","N. Li; J. Chen; H. Cao; B. Zhang; P. Natarajan","Raytheon BBN Technol., Cambridge, MA, USA","2014 14th International Conference on Frontiers in Handwriting Recognition","20141215","2014","","","134","139","The recurrent neural network language model (RNNLM) is a discriminative, non-Markovian model that can capture long-span word history in natural language. It has been proved to be successful in automatic speech recognition and machine translation. In this work, we applied RNNLM to the n-best rescoring stage of the state-of-the-art BBN Byblos OCR (optical character recognition) system for handwriting recognition.1 With RNNLM scores as additional features, our system achieved significant improvement (p <; 0.001), a 3.5% relative reduction on OCR word error rate, compared with a high baseline that uses n-gram language model for rescoring. We have also developed a novel method to integrate the OCR n-best RNNLM scores into the word posterior probabilities in OCR confusion networks, which resulted in consistent observable improvements in word spotting for OCR'ed handwritten documents, as measured by both mean average precision (MAP) and detection-error tradeoff (DET) curves.","2167-6445;21676445","Electronic:978-1-4799-4334-0; POD:978-1-4799-7892-2; USB:978-1-4799-4335-7","10.1109/ICFHR.2014.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981009","information retrieval;keyword search;optical character recognition;recurrent neural networks","Character recognition;Handwriting recognition;Hidden Markov models;Lattices;Optical character recognition software;Recurrent neural networks;Training","document image processing;handwriting recognition;language translation;optical character recognition;recurrent neural nets;word processing","BBN Byblos OCR;DET curves;MAP;OCR confusion networks;OCR handwritten documents;OCR word error rate;RNNLM scores;automatic speech recognition;detection-error tradeoff curves;long-span word history;machine translation;mean average precision;nonMarkovian model;offline handwriting recognition;optical character recognition system;recurrent neural network language model;word posterior probabilities;word spotting","","2","","36","","","1-4 Sept. 2014","","IEEE","IEEE Conference Publications"
"A study on sightseeing promotion with ICT from the viewpoint of sustainability","Y. Fudo; S. Matsumoto; T. Kashima; M. Akiyoshi","Graduate School of Science and Technology, Hiroshima Institute of Technology, 2-1-1 Miyake, Saeki-ku, 731-5193, JAPAN","2014 IEEE 7th International Workshop on Computational Intelligence and Applications (IWCIA)","20141218","2014","","","141","146","Recently, interest in Japanese domestic tour has been decreasing year by year. The number of domestic trips in one year has been decreasing from 1992 to 2012. The Tourism Agency aims to promote domestic tourism for overseas people as an issue of national priority. However in Japanese sightseeing, there has been various problem in transportation. For example, there has been few information in English about not only public transportation but also bicycle/foot. Therefore most of people gather only specific typical tourism spots and famous means of transportations, and it is the cause of overcrowding on public transportations. For local residents, public transportations are irreplaceable means to move. The tourism region should improve service quality for both tourists and local residents. Concretely, developing new tourism spots and enhancing new transportation means are required. In this paper, we propose a method to distribute tourists to various kinds of transportation means by providing new tourist spots information. We develop a mobile application to enhance foot based side trip tourism, and our work aims to provide 3 kinds of benefits for improving the sustainability in tourism region: developing new tourism spots is to support regional economy, distributing transportation means is to improve regional service, and enhancing foot based tourism is to contribute global environment. The subjects we develop are the word-of-mouth information retrieval system, a mobile application, and tourist's mobile history analysis system. Additionally in this paper, we show a tourism concierge system as the future view for wholly supporting a tourist's hospitality.","1883-3977;18833977","Electronic:978-1-4799-4770-6; POD:978-1-4799-4769-0; USB:978-1-4799-6828-2","10.1109/IWCIA.2014.6988094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6988094","Concierge;Mobile Application;Simulation;Sustainability;Tourism;Word-of-mouth Based Information Retrieval","Cities and towns;Foot;Information retrieval;Mobile communication;Mobile handsets;Navigation;Transportation","information retrieval systems;mobile computing;public transport;travel industry","ICT;Japanese domestic tour;Japanese sightseeing;domestic trips;public transportation;regional economy;sightseeing promotion;sustainability;tourism agency;tourism concierge system;tourist mobile history analysis system;word-of-mouth-based information retrieval system","","0","","12","","","7-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"Comparison of Scheduling Algorithms for Domain Specific Web Crawler","K. Filipowski","Dept. of Comput. Syst. & Networks, Wroclaw Univ. of Technol., Wroclaw, Poland","2014 European Network Intelligence Conference","20141215","2014","","","69","74","Domain-specific Web crawlers are effective tools for acquiring information from the Web. One of the most crucial factors influencing the efficiency of domain crawlers is choice of crawling strategy. This article describes and compares several strategies for domain specific Web crawling. It concentrates particularly on scheduling algorithms which determine order of crawling URLs collected by the crawler. The objective of these strategies is to download the most relevant Web pages in an early stage of the crawl. In the paper there are presented four different algorithms which are compared using several metrics.","","Electronic:978-1-4799-6914-2; POD:978-1-4799-6915-9; USB:978-1-4799-6913-5","10.1109/ENIC.2014.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984893","Best N-First Search;Best-First Search;Domain Specific Crawling;Exploration;Information Retrieval","Algorithm design and analysis;Crawlers;Internet;Search engines;Search problems;Uniform resource locators;Web pages","Internet;Web sites;information retrieval;scheduling","Web pages;domain specific Web crawler;information retrieval;scheduling algorithms","","0","","17","","","29-30 Sept. 2014","","IEEE","IEEE Conference Publications"
"Boosting Bug-Report-Oriented Fault Localization with Segmentation and Stack-Trace Analysis","C. P. Wong; Y. Xiong; H. Zhang; D. Hao; L. Zhang; H. Mei","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","181","190","To deal with post-release bugs, many software projects set up public bug repositories for users all over the world to report bugs that they have encountered. Recently, researchers have proposed various information retrieval based approaches to localizing faults based on bug reports. In these approaches, source files are processed as single units, where noise in large files may affect the accuracy of fault localization. Furthermore, bug reports often contain stack-trace information, but existing approaches often treat this information as plain text. In this paper, we propose to use segmentation and stack-trace analysis to improve the performance of bug localization. Specifically, given a bug report, we divide each source code file into a series of segments and use the segment most similar to the bug report to represent the file. We also analyze the bug report to identify possible faulty files in a stack trace and favor these files in our retrieval. According to our empirical results, our approach is able to significantly improve Bug Locator, a representative fault localization approach, on all the three software projects (i.e., Eclipse, AspectJ, and SWT) used in our empirical evaluation. Furthermore, segmentation and stack-trace analysis are complementary to each other for boosting the performance of bug-report-oriented fault localization.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976084","bug report;fault localization;feature location;information retrieval","Computer bugs;Information retrieval;Java;Logistics;Measurement;Noise;Software","fault diagnosis;information retrieval;program debugging;program diagnostics;source code (software)","AspectJ;Eclipse;SWT;boosting bug-report-oriented fault localization;bug localization;bug locator;bug reportq;faulty files;information retrieval;post-release bugs;public bug repository;representative fault localization approach;software projects;source code file;source files;stack-trace analysis;stack-trace information","","7","","46","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"NeighborNote: An Evernote Application with Capability of Suggesting Related Notes Based on User Operation History","Y. Takahashi; M. Niibori; M. Kamada","Grad. Sch. of Sci. & Eng., Ibaraki Univ., Hitachi, Japan","2014 17th International Conference on Network-Based Information Systems","20150129","2014","","","331","335","This paper presents application software named NeighborNote which extends Evernote to include the capability of suggesting related notes based on the user operation history. NeighborNote calculates the relativeness between the notes based on the idea that the notes, which the user opened at the same time or copied & pasted across, may be related to one another. NeighborNote helps users find related notes by showing other notes associated with the currently open note. We have publicly released this application software as a derivative service of Evernote and are getting feedback from its users.","2157-0418;21570418","Electronic:978-1-4799-4224-4; POD:978-1-4799-7878-6","10.1109/NBiS.2014.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023972","document management;evernote;information retrieval;user operation history","Application software;Browsers;Databases;Educational institutions;History;Measurement;Operating systems","document handling;information retrieval","Evernote application;NeighborNote;application software;document management;information retrieval;notes relativeness;open note;related notes;user operation history","","0","","12","","","10-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"An effective private data storage and retrieval system using secret sharing scheme based on secure multi-party computation","D. G. Nair; V. P. Binu; G. S. Kumar","Department of Computer Science, Cochin University, Kochi, India","2014 International Conference on Data Science & Engineering (ICDSE)","20141204","2014","","","210","214","Privacy of the outsourced data is one of the major challenge. Insecurity of the network environment and untrust-worthiness of the service providers are obstacles of making the database as a service. Privacy concerns exist wherever personally identifiable information is collected and stored. Public databases and resources are potential source of risk to user privacy. An intentional database owner can guess user details by practically monitoring their queries. Hence the major challenge here is to share the data by protecting personal information. A data retrieval scheme allowing the users to query the database with out compromising the privacy in data item is generally sought The naive solution for confidentiality is to encrypt data before outsourcing. Query execution, key management and statistical inference are major challenges in this case. The proposed system suggests a mechanism to store private information and secure retrieval of this data using secret sharing based Secure Multiparty Computation(SMC). The idea is to develop a mechanism to store private information with a highly available storage provider which could be accessed from anywhere using queries while hiding the actual data values from the storage provider. Multiparty Computation facilitates application of join functions over their private inputs and SMC performs these functions by keeping the input data private. This is achieved by making secret shares of the inputs and manipulating the shares to compute some functions.","","Electronic:978-1-4799-5460-5; POD:978-1-4799-5462-9","10.1109/ICDSE.2014.6974639","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974639","Data storage;Database;Query Processing;Secure Multi-party Computation;Shamir's Secret Sharing;private Information Retrieval","Cryptography;Indexes;Information retrieval;Protocols;Servers","cryptography;data privacy;database management systems;query processing;storage management","SMC;data confidentiality;data encryption;data retrieval scheme;database querying;key management;outsourced data privacy;personal information protection;private information storage provider;public databases;query execution;secure multiparty computation;statistical inference;user privacy","","0","","18","","","26-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Electronic resources at the University of Dubai: Information seeking behavior","A. A. El-Maamiry","Univ. of Dubai, Dubai, United Arab Emirates","The 5th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20150126","2014","","","1","4","The study investigated use of electronic resource by students of College of Business Administration and College of Information Technology. That is, it examined possible factors and problems in their searching habits, information seeking, use and retrieval in satisfying their needs. Therefore, the study focused on information seeking behaviour of students and barriers to utilizing online resources to execute academic tasks.","","Electronic:978-1-4799-6242-6; POD:978-1-4799-6243-3","10.1109/ICT4M.2014.7020593","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020593","digital library;electronic resources;information retrieval;information seeking behaviour","Decision support systems","computer aided instruction;educational institutions;information retrieval","University of Dubai;academic tasks;college of business administration;college of information technology;electronic resources;information seeking behavior;online resources;searching habits;students","","0","","14","","","17-18 Nov. 2014","","IEEE","IEEE Conference Publications"
"A new comprehensive approach for earth observation scene classification using joint image and text analysis","C. Vaduva; M. Datcu","University Politehnica of Bucharest UPB","2014 IEEE Geoscience and Remote Sensing Symposium","20141106","2014","","","1658","1661","The amount of data available on the internet provides massive additional information for the Earth Observation (EO) imagery. Periodical news, various reports and measurements, pictures or online encyclopedias are just few examples of the existent information. Occasionally, this data offers new perspectives for EO image understanding and interpretation. However, current image analysis do not benefit from the advantage given by external sources. To overcome these drawbacks, the present paper proposes an approach that goes beyond traditional information mining by using a joint image and text analysis. Fast Compression Distance (FCD) is computed to measure the similarities inside a collection of very high resolution images and text files. The main purpose is to discover common patterns within the data, without any a priori assumption, parameter-free, relying on data compression-based techniques. A hierarchical clustering is performed in order to learn about the dependencies between different types of data.","2153-6996;21536996","Electronic:978-1-4799-5775-0; POD:978-1-4799-5314-1; USB:978-1-4799-5774-3","10.1109/IGARSS.2014.6946767","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946767","Knowledge discovery;compression based algorithms;information retrieval;similarity measure","Complexity theory;Compression algorithms;Data mining;Dictionaries;Earth;Image coding;Image resolution","data compression;data mining;geophysical image processing;image classification;pattern clustering;remote sensing","Earth Observation imagery;Fast Compression Distance;data compression;hierarchical clustering;information mining;joint image-text analysis;scene classification","","0","","6","","","13-18 July 2014","","IEEE","IEEE Conference Publications"
"Automatic Population of Italian Medical Thesauri: A Morphosemantic Approach","F. Amato; A. Elia; A. Maisto; A. Mazzeo; S. Pelosi","Dept. of Electr. Eng. & Inf. Technol., Univ. of Napoli Federico II., Naples, Italy","2014 Ninth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","20150129","2014","","","432","436","In the age of Semantic Web, one of the most valuable challenges is the one connected with the information extraction from raw data. Information must be managed with sophisticated linguistic and computational architectures, which are able to approach the semantic dimension of words and sentences. In this paper we propose a morphosemantic method for the automatic creation and population of medical lexical resources. Our approach is grounded on a list of neoclassical formative elements pertaining to the medical domain an on a large sized corpus of medical diagnoses. The outcomes of this work are automatically built electronic dictionaries and thesauri and an annotated corpus for the NLP in the medical domain.","","Electronic:978-1-4799-4171-1; POD:978-1-4799-7872-4","10.1109/3PGCIC.2014.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7024623","Information Extraction;Information Retrieval","Compounds;Dictionaries;Grammar;Medical diagnostic imaging;Pragmatics;Semantics;Thesauri","information retrieval;medical administrative data processing;semantic Web;thesauri","Italian medical thesauri automatic population;NLP;computational architectures;electronic dictionaries;information extraction;information management;linguistic architectures;medical diagnoses;medical lexical resources;morphosemantic approach;neoclassical formative elements;raw data;semantic Web","","1","","36","","","8-10 Nov. 2014","","IEEE","IEEE Conference Publications"
"Cineast: A Multi-feature Sketch-Based Video Retrieval Engine","L. Rossetto; I. Giangreco; H. Schuldt","Dept. of Math. & Comput. Sci., Univ. of Basel, Basel, Switzerland","2014 IEEE International Symposium on Multimedia","20150209","2014","","","18","23","Despite the tremendous importance and availability of large video collections, support for video retrieval is still rather limited and is mostly tailored to very concrete use cases and collections. In image retrieval, for instance, standard keyword search on the basis of manual annotations and content-based image retrieval, based on the similarity to query image (s), are well established search paradigms, both in academic prototypes and in commercial search engines. Recently, with the proliferation of sketch-enabled devices, also sketch-based retrieval has received considerable attention. The latter two approaches are based on intrinsic image features and rely on the representation of the objects of a collection in the feature space. In this paper, we present Cineast, a multi-feature sketch-based video retrieval engine. The main objective of Cineast is to enable a smooth transition from content-based image retrieval to content-based video retrieval and to support powerful search paradigms in large video collections on the basis of user-provided sketches as query input. Cineast is capable of retrieving video sequences based on edge or color sketches as query input and even supports one or multiple exemplary video sequences as query input. Moreover, Cineast also supports a novel approach to sketch-based motion queries by allowing a user to specify the motion of objects within a video sequence by means of (partial) flow fields, also specified via sketches. Using an emergent combination of multiple different features, Cineast is able to universally retrieve video (sequences) without the need for prior knowledge or semantic understanding. The evaluation with a general purpose video collection has shown the effectiveness and the efficiency of the Cineast approach.","","CD-ROM:978-1-4799-4312-8; Electronic:978-1-4799-4311-1; POD:978-1-4799-4310-4","10.1109/ISM.2014.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7032948","Content-based Information Retrieval;Motion-based Video Retrieval;Video Retrieval","Feature extraction;Histograms;Image color analysis;Image edge detection;Semantics;Vectors;Video sequences","content-based retrieval;image colour analysis;image retrieval;image sequences;video retrieval","Cineast;academic prototypes;color sketches;commercial search engines;content-based image retrieval;content-based video retrieval;general purpose video collection;intrinsic image features;manual annotations;multifeature sketch-based video retrieval engine;search paradigms;sketch-enabled devices;standard keyword search;use cases;video collections;video sequences","","2","","20","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"Mixed Stereo Audio Classification Using a Stereo-Input Mixed-to-Panned Level Feature","A. Chen; M. A. Hasegawa-Johnson","Department of Electrical and Computer Engineering, Klipsch Group, Inc., Urbana, IL, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20141001","2014","22","12","2025","2033","Many past studies have been conducted on speech/music discrimination due to the potential applications for broadcast and other media; however, it remains possible to expand the experimental scope to include samples of speech with varying amounts of background music. This paper focuses on the development and evaluation of two measures of the ratio between speech energy and music energy: a reference measure called speech-to-music ratio (SMR), which is known objectively only prior to mixing, and a feature called the stereo-input mix-to-peripheral level feature (SIMPL), which is computed from the stereo mixed signal as an imprecise estimate of SMR. SIMPL is an objective signal measure calculated by taking advantage of broadcast mixing techniques in which vocals are typically placed at stereo center, unlike most instruments. Conversely, SMR is a hidden variable defined by the relationship between the powers of portions of audio attributed to speech and music. It is shown that SIMPL is predictive of SMR and can be combined with state-of-the-art features in order to improve performance. For evaluation, this new metric is applied in speech/music (binary) classification, speech/music/mixed (trinary) classification, and a new speech-to-music ratio estimation problem. Promising results are achieved, including 93.06% accuracy for trinary classification and 3.86 dB RMSE for estimation of the SMR.","2329-9290;23299290","","10.1109/TASLP.2014.2359628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6906262","Audio classification;Gaussian mixture model;audio processing;audio segmentation;classification algorithms;mel-frequency cepstral coefficients;music information retrieval;music processing;speech processing;speech/music discrimination","Accuracy;Estimation;Instruments;Multiple signal classification;Speech;Speech processing","audio signal processing;music;signal classification;speech processing","RMSE;SIMPL;SMR;background music;binary classification;broadcast mixing techniques;mixed stereo audio classification;music discrimination;music energy;objective signal measure;reference measure;speech discrimination;speech energy;speech-music classification;speech-music-mixed classification;speech-to-music ratio estimation problem;stereo-input mixed-to-panned level feature;stereo-input peripheral level feature;trinary classification","","0","","49","","20140922","Dec. 2014","","IEEE","IEEE Journals & Magazines"
"Enhanced Factored Sequence Kernel for Sentiment Classification","L. Trindade; H. Wang; W. Blackburn; P. S. Taylor","Fac. of Comp. & Eng., Univ. of Ulster, Newtownabbey, UK","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","2","","519","525","The internet and the Web 2.0 gave rise to a wide variety of user generated content. This caused a massive growth in the amount and availability of opinionated information. This collection of complex, unstructured information is often referred as Big Data. A common practical application of such Big Data is social media sentiment analysis. The general aim of sentiment analysis is to determine/extract the opinion contained within a piece of text. A very active line of work focuses on the application of existing machine learning methods to sentiment analysis problems, for example support vector machine, which is a popular kernel method for text classification. This paper focuses on sequence kernels, which have been successfully employed for various natural language processing tasks including sentiment analysis. There have been developments in advanced methods for combining multiple information sources in a single kernel function - in particular the factored sequence kernel, which is a natural fit for text classification tasks, due to each element in a piece of text having other linguistic dimensions or factors. This paper proposes an extension of the gap-weighted soft-matching factored sequence kernel that is not only proportional to the number of factors considered but also proportional to the number of total matching factors. This allows the kernel to make a stronger distinction between composite sub sequences where only a single feature is matched and where more (or all) features are matched - that is not always possible through weighting. We make use of a tridimensional representation where each sentence is a composite sequence of its words, its part-of-speech tags, and its sentiment features. We evaluate the impact of the proposed methodology on two sentiment classification tasks - subjectivity and polarity classification. We perform a series of 10 fold cross validation experiments on two publicly available corpuses. Our experimental results show that our approach- surpasses the original factored sequence kernel in almost every experiment, opening the way for future research on other extensions to the factored kernel.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.142","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927669","Data Mining;Information Retrieval;Kernel Methods;Opinion Mining;Polarity Classification;Sentiment Analysis;Sequence Kernels;Social Media","Big data;Kernel;Motion pictures;Sentiment analysis;Support vector machines;Text categorization;Vectors","Big Data;Internet;learning (artificial intelligence);natural language processing;social networking (online);support vector machines;text analysis;user interfaces","Big Data;Internet;Web 2.0;enhanced factored sequence kernel;machine learning;natural language processing;sentiment classification;single kernel function;social media sentiment analysis;support vector machine;text classification;tridimensional representation;unstructured information;user generated content","","0","","34","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Pattern discovery for text mining","V. Aswini; S. K. Lavanya","Dept. of Comput. Sci., Jerusalem Coll. of Eng., Chennai, India","2014 International Conference on Computation of Power, Energy, Information and Communication (ICCPEIC)","20141002","2014","","","412","416","Text mining can be defined as the art of extracting data from large amount of texts. It allows to structure and categorize the text contents which are initially non organized and heterogeneous. Text mining is an important data mining technique which includes the most successful technique to extract the effective patterns. The paper focuses on developing an efficient method for discovering patterns from the document. In text mining field, pattern mining techniques are used to find text patterns, such as frequent item sets, closed frequent item sets, co-occurring terms. This paper presents an innovative and effective pattern discovery technique which includes the process of pattern evolving and pattern deploying, to improve the effectiveness of using and updating discovered patterns for finding relevant and interesting information.","","CD-ROM:978-1-4799-3826-1; Electronic:978-1-4799-3827-8; POD:978-1-4799-3828-5","10.1109/ICCPEIC.2014.6915399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915399","Closed frequent mining;Information retrieval;Pattern mining;Pattern taxonomy;Sequential pattern mining;Text mining","","data mining;text analysis","data extraction;data mining technique;document;pattern deploying;pattern discovery;pattern evolving;pattern extraction;pattern mining technique;text mining","","0","","15","","","16-17 April 2014","","IEEE","IEEE Conference Publications"
"Relevant Sources of Information Are Not Necessarily Popular Ones","R. Noel; A. Pauchet; B. Grilheres; N. Malandain; L. Vercouter; S. Brunessaux","LITIS / INSA de Rouen, AIRBUS DS, Val-de-Reuil, France","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","310","317","The constant growth of the Web in recent years has made more difficult the discovery of new sources of information on a given topic. This is a prominent problem for Experts in Intelligence Analysis (EIA) who are faced to the search of pages on specific and sensitive topics. Because of their lack of popularity or because they are poorly indexed due to their sensitive content, these pages are hard-to-find with traditional search engines. In this article, we describe a new Web source discovery system called DOWSER (Discovery Of Web Sources Evaluating Relevance). The goal of this system is to provide users with new sources of information related to their needs without considering the popularity of a page unlike classic Information Retrieval tools. The expected result is a balance between relevance and originality, in the sense that the wanted pages are not necessary popular. DOWSER is based on a user profile to focus its exploration of the Web in order to collect and index only related Web documents. As requests can be insufficient to express sensitive and specific needs, the user's information needs are specified using user's interests represented by DBPedia resources [1] and keywords, both extracted from Web pages provided by the user. A series of experiments provides an empirical evaluation of DOWSER.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927558","Focused crawling;Information Retrieval;Ranking;Semantic Web;User modelling;Web source discovery","Crawlers;Electronic mail;Search engines;Vectors;Web pages","Internet;Web sites;data mining;information needs;information retrieval;search engines","DOWSER;Discovery Of Web Sources Evaluating Relevance;EIA;Web documents;Web pages;Web source discovery system;World Wide Web;information retrieval tools;information sources;intelligence analysis experts;search engines;user information needs;user interests;user profile","","1","","25","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Sharding for literature search via cutting citation graphs","H. Zhao","College of Computing & Informatics, Drexel University, Philadelphia, USA","2014 IEEE International Conference on Big Data (Big Data)","20150108","2014","","","77","79","Distributed information retrieval will be a general practice of searching in the exponentially growing scientific literature. At the core of the success for efficient and effective distributed literature search is an adequate sharding policy. This paper proposes a novel sharding policy for literature search that bases on cutting the document citation and co-citation graphs. Experiments on the iSearch test collection reveal that relevant documents for a given query distribute over the shards generated through citation graph cutting in such a pattern that a few shards becomes optimal shards thus can be leveraged in a selective search strategy, potentially leading to efficient and effective literature search solutions.","","Electronic:978-1-4799-5666-1; POD:978-1-4799-5667-8","10.1109/BigData.2014.7004500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004500","citation;distributed information retrieval;graph partition;literature search;sharding","Clustering algorithms;Conferences;Partitioning algorithms;Resource management;Search problems;Vectors","citation analysis;graph theory;query processing;scientific information systems","distributed information retrieval;distributed literature search;document co-citation graph cutting;iSearch test collection;optimal shards;query processing;scientific literature search;selective search strategy;sharding policy","","0","","7","","","27-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"Using Extended Random Set to Find Specific Patterns","M. Albathan; Y. Li; Y. Xu","Sch. of Electr. Eng. & Comput. Sci., Queensland Univ. of Technol., Brisbane, QLD, Australia","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","2","","30","37","With the overwhelming increase in the amount of data on the web and data bases, many text mining techniques have been proposed for mining useful patterns in text documents. Extracting closed sequential patterns using the Pattern Taxonomy Model (PTM) is one of the pruning methods to remove noisy, inconsistent, and redundant patterns. However, PTM model treats each extracted pattern as whole without considering included terms, which could affect the quality of extracted patterns. This paper propose an innovative and effective method that extends the random set to accurately weigh patterns based on their distribution in the documents and their terms distribution in patterns. Then, the proposed approach will find the specific closed sequential patterns (SCSP) based on the new calculated weight. The experimental results on Reuters Corpus Volume 1 (RCV1) data collection and TREC topics show that the proposed method significantly outperforms other state-of-the-art methods in different popular measures.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927604","Extended Random Set;Information retrieval;Select top-k Patterns;Specific Closed Sequential Patterns;Text mining","Feature extraction;Mathematical model;Noise measurement;Probability;Taxonomy;Text mining","data mining;text analysis","PTM;RCV1 data collection;Reuters Corpus Volume 1 data collection;SCSP;TREC topics;World Wide Web;closed sequential pattern extraction;data bases;extended random set;inconsistent pattern removal;noisy pattern removal;pattern taxonomy model;pruning methods;redundant pattern removal;specific closed sequential patterns;text documents;text mining techniques;useful pattern mining","","1","","49","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"An Unified Approach for Multimedia Document Representation and Document Similarity","P. K; A. V. S","Dept. of Inf. Technol., Nat. Inst. of Technol., Surathkal, India","2014 IEEE 17th International Conference on Computational Science and Engineering","20150129","2014","","","249","256","In the recent years, the evolution in multimedia technology has accelerated the growth of multimedia data. Even though the multimedia data are heterogeneous, the rich information they carry has made a high demand for sophisticated multimedia knowledge discovery systems. To mine the knowledge from multimedia document, each type of multimedia data has to undergo unique processing and knowledge discovery processes because of its uniqueness. However, this procedure of processing and analyzing each type of multimedia data separately may make the system more complicated in case of large databases. Alternatively, it will be more advantageous if heterogeneous objects are represented in a common domain, such that the similar processing and knowledge discovery methods can be used. Motivated by this concept, a method known as domain converter is proposed to represent the heterogeneous multimedia objects in a spatial domain. Also based on information theory, a similarity measure is proposed to find the similarity between the documents. To evaluate the proposed framework, the experiments have been conducted for the retrieval of multimedia documents. The proposed domain converter represents the multimedia document in a homogeneous domain, and with the proposed similarity measure, better document retrieval rate has been achieved.","","Electronic:978-1-4799-7981-3; POD:978-1-4799-7982-0","10.1109/CSE.2014.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7023587","Image Object;Information Retrieval;Information Theory;Multimedia;Similarity Measure","Feature extraction;Image color analysis;Media;Multimedia communication;Streaming media;Vectors","data analysis;data mining;document handling;information retrieval;information theory;multimedia computing","document similarity;domain converter;heterogeneous multimedia objects;information theory;knowledge mining;multimedia data analysis;multimedia data processing;multimedia document representation;multimedia document retrieval;multimedia knowledge discovery system;multimedia technology;spatial domain","","0","","34","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Audio Retrieval Based on Manifold Ranking","J. Qin; X. Liu; H. Lin","Coll. of Inf. Eng., Dalian Univ., Dalian, China","2014 Sixth International Symposium on Parallel Architectures, Algorithms and Programming","20141007","2014","","","187","190","This paper proposes an audio information retrieval model based on Manifold Ranking (MR) and improving ranking results by relevance feedback algorithm. Timbre component has been employed as the main feature. To compute the timbre similarity, it is necessary to extract the spectrum features for each frame. The large set of frames is clustered by a Gaussian Mixture Model (GMM) and Expectation Maximization. The typical spectra frame from GMM is drawn as the data points, manifold ranking assigns each data point a relative ranking score, which is treated as a distance instead of traditional similarity metrics based on pair-wise distance. Furthermore, manifold ranking algorithm can be easily generalized by adding these positive examples by relevance feedback algorithm, and improves the final result. Experimental results show the proposed approach is effective to improve the ranking capability of the existing distance functions.","2168-3034;21683034","Electronic:978-1-4799-3845-2; POD:978-1-4799-3846-9","10.1109/PAAP.2014.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916462","audio information retrieval;manifold ranking;relevance feedback","Clustering algorithms;Educational institutions;Feature extraction;Manifolds;Music information retrieval;Semantics;Vectors","Gaussian processes;audio signal processing;expectation-maximisation algorithm;feature extraction;learning (artificial intelligence);relevance feedback","GMM;Gaussian mixture model;MR;audio information retrieval model;distance metric;expectation maximization;manifold ranking;pairwise distance;relevance feedback algorithm;similarity metrics;spectrum feature extraction;timbre component;timbre similarity","","0","","23","","","13-15 July 2014","","IEEE","IEEE Conference Publications"
"A text mining approach to automated healthcare for the masses","V. S. Pendyala; Yi Fang; J. Holliday; A. Zalzala","Dept of Computer Eng'g, Santa Clara University, CA 95053 USA","IEEE Global Humanitarian Technology Conference (GHTC 2014)","20141204","2014","","","28","35","There is a tremendous amount of attention being focused on improving human health these days. The World Health Organization (WHO) statistics show that disease and mortality rate greatly depend on access to proper healthcare, which is not available to a vast majority of the global population. This technical paper presents our vision of automating some of the healthcare functions such as monitoring and diagnosis for mass deployment. We explain our ideas on how machines can help in this essential life supporting activity. Diagnosis part of the problem has been researched for long, so we set out working on this first, while the remaining is still in idea stage. We give insights into our work on automating medical diagnosis using text mining techniques and include some initial results.","","Electronic:978-1-4799-7193-0; POD:978-1-4799-7194-7","10.1109/GHTC.2014.6970257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970257","Information Retrieval;Machine Learning;Medical Diagnosis;Text Mining","Discharges (electric);Diseases;Medical diagnosis;Monitoring;Text mining;Vectors","data mining;health care;medical administrative data processing;text analysis","WHO;World Health Organization;health care automation;human health;mass deployment;text mining approach","","2","","31","","","10-13 Oct. 2014","","IEEE","IEEE Conference Publications"
"Indexing and Retrieving Continuations in Musical Time Series Data Using Relational Databases","A. Charapko; C. H. Chuan","Sch. of Comput., Univ. of North Florida, Jacksonville, FL, USA","2014 IEEE International Symposium on Multimedia","20150209","2014","","","341","346","This paper proposed and tested a model that provides quick search and retrieval of continuations for time series, particularly musical data, using relational databases. The model extends an existing interactive music-generation system by focusing on large input sequences. Experiments using textural and musical data provided satisfactory performance results for the model.","","CD-ROM:978-1-4799-4312-8; Electronic:978-1-4799-4311-1; POD:978-1-4799-4310-4","10.1109/ISM.2014.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033048","continuations;data sequence;database;information retrieval;music generation","Buildings;Computational modeling;Data models;Indexing;Relational databases;Time series analysis","indexing;information retrieval;music;relational databases;time series","indexing;input sequences;interactive music-generation system;musical time series data;relational databases;retrieving continuations;textural data","","1","","9","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"POS weighted TF-IDF algorithm and its application for an MOOC search engine","R. Xu","Department of Computer Science, University of Illinois at Urbana-Champaign (UIUC) Urbana, IL 61801, USA","2014 International Conference on Audio, Language and Image Processing","20150115","2014","","","868","873","Term Frequency-Inverse Document Frequency (TF-IDF) has been one of the most highly used information retrieval methods for many years. Although there are several variants of TF-IDF optimizing for solving various problems, very few of them considered the properties of the query terms themselves. We found that there could be a big potential for improvement. When people type out a query, usually the verbs and the nouns are the primary keywords that directly define the query. The adjectives and adverbs are generally the secondary keywords, which describe the query more accurately. Other terms might not be as important as the terms just mentioned and could be the tertiary keywords. Based on this fact, this paper proposes an algorithm improved upon the original TF-IDF algorithm - POS Weighted TF-IDF algorithm. This algorithm takes every query term's part of speech (POS) into account and assigns each query term frequency a different weight value according to the POS of that term. Based on the POS Weighted TF-IDF Algorithm, we developed COURSES, a massive open online courses (MOOC) search engine, and achieved very positive results, which shows the effectiveness of the proposed algorithm.","","CD-ROM:978-1-4799-3901-5; Electronic:978-1-4799-3903-9; POD:978-1-4799-3904-6","10.1109/ICALIP.2014.7009919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009919","Information Retrieval;MOOC search engine;POS Weighted;TF-IDF","Algorithm design and analysis;Information filters;Search engines;User interfaces;XML","courseware;query processing;search engines","COURSES;MOOC search engine;POS weighted TF-IDF algorithm;information retrieval methods;massive open online courses search engine;query term frequency;query term part of speech;term frequency-inverse document frequency","","1","","12","","","7-9 July 2014","","IEEE","IEEE Conference Publications"
"Learning of Legal Ontology Supporting the User Queries Satisfaction","I. B. Mezghanni; F. Gargouri","MIRACL Lab., ISIM, Sfax, Tunisia","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","414","418","In recent years, the development of legal ontologies has increased significantly with the diversity of their applications known as complicated due to the complexity of their domain. In the preliminary part of this paper, we introduce the major steps in the learning process, then we present some works interested in Arabic ontology learning. The rest of the paper serves to propose our approach for ontology learning from Tunisian Legal Texts designed for legal information retrieval. The search process that we suggest exploits the user's profile and uses a query reformulation mechanism based on the learned ontology. The purpose of the system is to satisfy a user's specific retrieval requirement by finding the best response to his request.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927573","legal information retrieval system;legal ontology learning;query reformulation mechanism","Context;Information retrieval;Law;Ontologies;Pragmatics;Semantics","learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);query formulation;query processing;user interfaces","Arabic ontology learning process;Tunisian legal texts;legal information retrieval;legal ontology;query reformulation mechanism;search process;user profile;user queries satisfaction","","1","","12","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Network of semantic wikis (Wicri) and data curation","A. Tebbakh","LORIA, University of Lorraine, 615 Rue du Jardin Botanique, 54506 Vand&#x00E6;uvre-l&#x00E8;s-Nancy France","2014 4th International Symposium ISKO-Maghreb: Concepts and Tools for knowledge Management (ISKO-Maghreb)","20150209","2014","","","1","5","This article aims at evaluating the interest of the Wicri network, a network of semantic wikis, both as a reservoir of curation rules allowing to enrich corpora metadata and as a tool for parameterizing and supporting of instructions for the creation of corpora exploration servers. Starting, from the analysis of a bibliographic corpus extracted from different documentary databases, the experiments that we have conducted in this context rely to the use of wiki technology as a central tool in a process of construction of knowledge.","","Electronic:978-1-4799-7508-2; POD:978-1-4799-7509-9","10.1109/ISKO-Maghreb.2014.7033482","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033482","data curation;eScience TEI;exploration server;information retrieval;knowledge base;metadata;semantic wikis","Context;Electronic publishing;Information services;Internet;Knowledge engineering;Semantics;Servers","Web sites;bibliographic systems;document handling;meta data","bibliographic corpus;corpora exploration servers;corpora metadata;data curation;documentary databases;semantic wiki technology","","0","","12","","","9-10 Nov. 2014","","IEEE","IEEE Conference Publications"
"A method for simplifying the submission of an online request for an E-Government service","G. N. Vo; R. Lai","Department of Computer Science and Computer Engineering, La Trobe University, Melbourne, Australia","2014 International Symposium on Technology Management and Emerging Technologies","20141027","2014","","","377","382","In recent years, to encourage citizens to use the E-Government system more widely, the number of innovative research topics in this area has grown tremendously to bridge the information gap between citizens and the government. However, recently, concerns have been increasing, especially in developing countries, as to how to simplify the submission of a request for an E-Government service and how to link these requests to build an online application without asking the citizen to input the data more than once or run around to submit their information in person. Thus, the challenge for the Government in this situation is to provide an e-system which is fast and simple for the citizen to use. This research proposes a method for simplifying the information retrieval process from the E-Government system. This method uses Natural Language Processing (NLP), concept indexing and data integration methods for data analyzing and building. To assist the retrieval of information, the government concept is used to match everyday language to the formal language which is used in the government's E-Documents. As well, the mapping is based on the enriched citizen's requests to structure a multi-layered E-Document. To demonstrate its usefulness, we applied our methodology to sample data of an online request for a vehicle registration procedure.","","CD-ROM:978-1-4799-3703-5; Electronic:978-1-4799-3704-2; POD:978-1-4799-3705-9","10.1109/ISTMET.2014.6936538","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936538","Concept Indexing;E-Document;E-Government;Information Retrieval;NLP","Electronic government;Indexing;Information retrieval;Natural language processing;Vehicles","data analysis;data integration;government data processing;indexing;information retrieval;interactive programming;natural language processing","NLP;concept indexing;data analysis;data integration;e-documents;e-government service;e-government system;information retrieval process;natural language processing;online request;vehicle registration","","0","","12","","","27-29 May 2014","","IEEE","IEEE Conference Publications"
"Choosing a profile length in the SCAP method of source code authorship attribution","M. F. Tennyson; F. J. Mitropoulos","Department of Computer Science & Information Systems, Bradley University, Peoria, IL, USA","IEEE SOUTHEASTCON 2014","20141110","2014","","","1","6","Source code authorship attribution is the task of determining the author of source code whose author is not explicitly known. One specific method of source code authorship attribution that has been shown to be extremely effective is the SCAP method. This method, however, relies on a parameter L that has heretofore been quite nebulous. In the SCAP method, each candidate author's known work is represented as a profile of that author, where the parameter L defines the profile's maximum length. In this study, alternative approaches for selecting a value for L were investigated. Several alternative approaches were found to perform better than the baseline approach used in the SCAP method. The approach that performed the best was empirically shown to improve the performance from 91.0% to 97.2% measured as a percentage of documents correctly attributed using a data set consisting of 7,231 programs written in Java and C++.","1091-0050;10910050","Electronic:978-1-4799-6585-4; POD:978-1-4799-6586-1","10.1109/SECON.2014.6950705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6950705","authorship attribution;information retrieval;plagiarism detection;software forensics","Frequency control;Frequency measurement;RNA","C++ language;Java;source code (software)","C++ language;Java language;SCAP method;data set;profile length;source code authorship attribution","","0","","8","","","13-16 March 2014","","IEEE","IEEE Conference Publications"
"Incremental solutions to online multi-unit combinatorial auctions for information feedback","S. Ramanathan; A. Kasinathan; A. K. Sen","McKinsey & Company, Chennai, India","2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)","20141016","2014","","","882","889","With the ease of carrying out an auction through internet, the electronic auction market is expanding rapidly. In online (i.e., continuous) eBay-like combinatorial auctions, bidders are allowed to join and leave the auction at any time, and in the process, bidders can repetitively bid on packages of items of their choice. In such multi-agent e-business systems, the seller is compelled to provide information feedback to the bidders after every bid on the current state of the auction to help them place more informed bids. This requires provisional winners be computed for every package of items after each bid by solving Winner Determination Problems. In multi-unit online combinatorial auctions where the number of bids can be significantly large, the paper presents for the first time dynamic programming approaches which can incrementally solve winner determination problems for every package after each new bid. We propose two dynamic programming algorithms to solve the multi-unit winner determination problem. While our first algorithm computes and stores the optimal values for all packages on arrival of a new bid traversing the packages in a reverse order, the alternative algorithm stores the optimal values only for packages that can fit into available memory but can find out the optimal solutions for every other package. We discuss the salient features of the algorithms, and demonstrate our approach through experiments. We also propose a bottom-up approach to dynamic programming for effective use of memory.","","Electronic:978-1-4799-5877-1; POD:978-1-4799-5878-8; USB:978-1-4799-5876-4","10.1109/ASONAM.2014.6921690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921690","Collaborative Information Retrieval;Dynamic Programming;E-Business;Memory-constrained;Multi-unit Combinatorial Auction;Winner Determination Problem","Companies;Conferences;Cost accounting;Dynamic programming;Heuristic algorithms;Memory management;Social network services","Internet;dynamic programming;electronic commerce","bottom-up approach;first time dynamic programming approach;incremental solutions;information feedback;multi-agent e-business systems;multiunit winner determination problem;online multiunit combinatorial auctions;winner determination problems","","0","","26","","","17-20 Aug. 2014","","IEEE","IEEE Conference Publications"
"A performance evaluation of semantic based search engines and keyword based search engines","J. A. Khan; D. Sangroha; M. Ahmad; M. T. Rahman","Dept. of Computer Science & Engineering, Ambedkar Institute of Advanced Communication Technologies & Research, GGSIP University, Delhi, India","2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom)","20150112","2014","","","168","173","Semantic based search engine are able to provide more relevant information because they understand the meaning of the term and relationship between the term and web pages but keyword based search engine not able to understand these thing. This paper evaluates the performance of Semantic web based search engine and Keyword based search engine. We selected three Semantic web based search engine (Bing, DuckDuckGo and Lexxe) and two Keyword based search engine (Google and Yahoo) to compare their search performance. We take ten queries from various topics and run on these search engines, and calculate the precision ratio for these queries. We have proposed a framework for Semantic based search engine that resolve the problem of synonyms and polysemy terms and used ontology based crawler in place of web crawler for effective precision.","","Electronic:978-1-4799-5097-3; POD:978-1-4799-5098-0","10.1109/MedCom.2014.7005997","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7005997","Evaluation;Information Retrieval;Keyword based Search Engine;Precision;Semantic-web Search Engine","Crawlers;Engines;Ontologies;Search engines;Semantic Web;Semantics","ontologies (artificial intelligence);query processing;search engines;semantic Web","keyword based search engine;ontology based crawler;performance evaluation;query processing;semantic Web based search engine","","0","","18","","","7-8 Nov. 2014","","IEEE","IEEE Conference Publications"
"Compositional Vector Space Models for Improved Bug Localization","S. Wang; D. Lo; J. Lawall","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","171","180","Software developers and maintainers often need to locate code units responsible for a particular bug. A number of Information Retrieval (IR) techniques have been proposed to map natural language bug descriptions to the associated code units. The vector space model (VSM) with the standard tf-idf weighting scheme (VSM<sub>natural</sub>), has been shown to outperform nine other state-of-the-art IR techniques. However, there are multiple VSM variants with different weighting schemes, and their relative performance differs for different software systems. Based on this observation, we propose to compose various VSM variants, modelling their composition as an optimization problem. We propose a genetic algorithm (GA) based approach to explore the space of possible compositions and output a heuristically near-optimal composite model. We have evaluated our approach against several baselines on thousands of bug reports from AspectJ, Eclipse, and SWT. On average, our approach (VSM <sub>composite</sub>) improves hit at 5 (Hit@5), mean average precision (MAP), and mean reciprocal rank (MRR) scores of VSM<sub>natural</sub> by 18.4%, 20.6%, and 10.5% respectively. We also integrate our compositional model with AmaLgam, which is a state-of-art bug localization technique. The resultant model named AmaLgam<sub>composite</sub> on average can improve Hit@5, MAP, and MRR scores of AmaLgam by 8.0%, 14.4% and 6.5% respectively.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976083","bug localization;composite model;genetic algorithm;information retrieval","Biological cells;Genetic algorithms;Sociology;Standards;Statistics;Training;Vectors","genetic algorithms;information retrieval;natural language processing;program debugging;software maintenance;vectors","AmaLgam;AspectJ;Eclipse;Hit@5;IR techniques;MAP;MRR scores;SWT;VSM variants;VSM<sub>natural</sub>;bug reports;code units;compositional model;compositional vector space model;genetic algorithm based approach;improved bug localization;information retrieval techniques;natural language bug descriptions;near-optimal composite model;optimization problem;software developers;software maintainers;software systems;standard tf-idf weighting scheme;vector space model","","9","","46","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Applying semantic similarity measures to enhance topic-specific web crawling","A. Pesaranghader; N. Mustapha; A. Pesaranghader","Fac. of Comput. Sci. & Inf. Technol., Univ. Putra Malaysia, Serdang, Malaysia","2013 13th International Conference on Intellient Systems Design and Applications","20141013","2013","","","205","212","As the Internet grows rapidly, finding desirable information becomes a tedious and time consuming task. Topic-specific web crawlers, as utopian solutions, tackle this issue through traversing the Web and collecting information related to the topic of interest. In this regard, various methods are proposed. Nevertheless, they hardly consider desired sense of the given topic which would certainly play an important role to find relevant web pages. In this paper, we attempt to improve topic-specific web crawling by disambiguating the sense of the topic. This would avoid crawling irrelevant links interlaced with other senses of the topic. For this purpose, by considering links hypertext semantic, we employ Lin semantic similarity measure in our crawler, named LinCrawler, to distinguish topic sense-related links from the others. Moreover, we compare LinCrawler against TFCrawler which only considers frequency of terms in hypertexts. Experimental results show LinCrawler outperforms TFCrawler to collect more relevant web pages.","2164-7143;21647143","Electronic:978-1-4799-3516-1; POD:978-1-4799-3517-8","10.1109/ISDA.2013.6920736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920736","Information Retrieval;Link Prediction;Semantic Web;Topic-Specific Web Crawling;Web Data Mining","Google;Internet;Iris;Search engines;Semantics;Unified modeling language;Vectors","Web sites;data mining;hypermedia;information retrieval;semantic Web","Internet;Lin semantic similarity measure;LinCrawler;TFCrawler;Web data mining;Web pages;information collection;information retrieval;links hypertext semantic;semantic Web;topic sense disambiguation;topic sense-related links;topic-specific Web crawling;utopian solutions","","0","","22","","","8-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"A New Term-Term Similarity Measure for Selecting Expansion Features in Big Data","I. Khennak; H. Drias","Lab. for Res. in Artificial Intell. Comput. Sci. Dept., USTHB, Algiers, Algeria","2014 International Conference on Advanced Networking Distributed Systems and Applications","20141201","2014","","","87","92","The massive growth of information and the exponential increase in the number of documents published and uploaded online each day have led to led to the appearance of new words in the Internet. Due to the difficulty of reaching the meanings of these new terms, which play a central role in retrieving the desired information, it becomes necessary to give more importance to the sites and topics where these new words appear, or rather, to give value to the words that occur frequently with them. For this purpose, in this paper, we propose a new term-term similarity measure based on the co-occurrence and closeness of words. It relies on searching for each query feature the locations where it appears, then selecting from these locations the words which often neighbor and co-occur with the query features, and finally used the selected words in the retrieval process. Our experiments were performed using the OHSUMED test collection and show significant performance enhancement over the state-of-the-art.","","Electronic:978-1-4799-5178-9; POD:978-1-4799-7870-0","10.1109/INDS.2014.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6969063","information retrieval;query expansion;term co-occurrence;term proximity","Dictionaries;Google;Indexing;Probabilistic logic;Q measurement;Vocabulary","Big Data;Internet;query processing","Big Data;Internet;OHSUMED test collection;expansion features;information retrieval;query feature;term-term similarity measure","","0","","20","","","17-19 June 2014","","IEEE","IEEE Conference Publications"
"Aspect-Based Similar Entity Search in Semantic Knowledge Graphs with Diversity-Awareness and Relaxation","S. Metzger; R. Schenkel; M. Sydow","Max Planck Inst. for Inf., Saarbrucken, Germany","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","60","69","Structured knowledge bases are an increasingly important way for storing and retrieving information. Within such knowledge bases, an important search task is finding similar entities based on one or more example entities. We present QBEES, a novel framework for defining entity similarity based only on structural features, so-called aspects, of the entities, that naturally model potential interest profiles of a user submitting an ambiguous query. The aspect model provides natural diversity-awareness and includes query-dependent and query-independent entity ranking components. We present evaluation results with a number of existing entity list completion benchmarks, comparing to several state-of-the-art baselines.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927526","entity similarity;information retrieval;ontology;semantic data;semantic similarity","Compounds;Computational modeling;Context;Feature extraction;Motion pictures;Ontologies;Semantics","graph theory;information storage;knowledge based systems;query processing","QBEES;ambiguous query;aspect-based similar entity search;diversity-awareness;entity list completion benchmark;entity similarity;information retrieval;information storage;query-dependent entity ranking component;query-independent entity ranking component;relaxation;search task;semantic knowledge graph;similar entity finding;structural features;structured knowledge base;user potential interest profiles","","1","","28","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Combining Retrieval Results for Balanced Effectiveness and Efficiency in the Big Data Search Environment","S. Wu; C. Huang; J. Li","Sch. of Comput. Sci. & Telecomm Eng., Jiangsu Univ., Zhenjiang, China","2014 IEEE International Conference on Computer and Information Technology","20141215","2014","","","555","560","In the big data age, we have to deal with tremendous amount of information, which is collected from various types of sources. For information retrieval systems, the collection of documents becomes larger and larger. For some query, an information retrieval system needs to retrieve a large number of documents as the result to the query. In reality, very often people mainly care about some top-ranked documents rather than the complete long list of documents. In such a situation, how to develop a retrieval system with desirable efficiency and effectiveness is a research problem. In this paper, we focus on the data fusion approach to information retrieval, in which each component retrieval system contributes a result and all the results are combined by a combination method. The goal of this research is to find a feasible combination method that is able to balance effectiveness and efficiency. Using 3 groups of historical runs from TREC for the experiment, we find that with the weights trained by weighted linear regression, the linear combination method can achieve good results in effectiveness and efficiency.","","Electronic:978-1-4799-6239-6; POD:978-1-4799-6240-2","10.1109/CIT.2014.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984710","data fusion;information retrieval;linear combination;results combination;web search","Big data;Data integration;Linear regression;Measurement;Training;Web search","Big Data;information retrieval systems;query processing;regression analysis;sensor fusion","Big Data search environment;TREC;component retrieval system;data fusion approach;effectiveness balancing;efficiency balancing;information retrieval systems;linear combination method;query;top-ranked documents;weighted linear regression","","0","","14","","","11-13 Sept. 2014","","IEEE","IEEE Conference Publications"
"Extraction of Key Expressions Indicating the Important Sentence from Article Abstracts","S. Otani; Y. Tomiura","Dept. of Libr. Sci., Kyushu Univ., Fukuoka, Japan","2014 IIAI 3rd International Conference on Advanced Applied Informatics","20141201","2014","","","216","219","In this study, we aim to extract key expressions that indicate the important sentence describing the originalities or contributions from article abstracts. The expense of searching academic information increases because of increases in the number of articles, discipline subdivisions, and promotion of interdisciplinary research. Improving the extraction and presentation of the main points from article abstracts will contribute to reducing academic information search expenses. We extracted pseudo-important sentences from each article abstract based on the ratio of the number of words in the identified sentence that appear in the article title to the number of all words in the sentence. After that, we evaluated the ratio of the number of the pseudo-important sentences including each N-gram to the number of all sentences including that N-gram. We then extracted the N-grams with a ratio as high as the key expressions.","","CD-ROM:978-1-4799-4175-9; Electronic:978-1-4799-4173-5; POD:978-1-4799-1679-5","10.1109/IIAI-AAI.2014.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913297","Information retrieval of articles;Key expression;Natural language processing;Support of Information retrieval","Abstracts;Accuracy;Data mining;Equations;Informatics;Liquids;Spectroscopy","information retrieval;natural language processing","N-gram;academic information search expenses;academic information searching;interdisciplinary research;key expression extraction;pseudoimportant sentence extraction","","0","","4","","","Aug. 31 2014-Sept. 4 2014","","IEEE","IEEE Conference Publications"
"Automated analysis and evaluation of SEC documents","Y. Zheng; H. Zhou; Z. Chen; N. N. Ekedebe","Towson University, USA","2014 IEEE/ACIS 13th International Conference on Computer and Information Science (ICIS)","20140929","2014","","","119","124","This paper presents an intelligent corporate governance analysis and rating system, called AAE System, capable of retrieving SEC required documents of public companies and performing analysis and rating in terms of recommended corporate governance practices. With Machine Learning, local knowledge bases, databases, and semantic networks, the AAE system is able to automatically evaluate the strengths, deficiencies, and risks of a company's corporate governance practices and board of directors based on the documents stored in the SEC EDGAR database[1]. The produced score reduces a complex corporate governance process and related policies into a single number which enables concerned government agencies, investors and legislators to assess the governance characteristics of individual companies.","","Electronic:978-1-4799-4860-4; POD:978-1-4799-4859-8","10.1109/ICIS.2014.6912118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6912118","Information Retrieval;Machine Learning;Semantic Net;Text Mining;knowledge Base","Companies;Databases;Industries;Java;Knowledge based systems;Semantics;Standards","business data processing;document handling;knowledge based systems;learning (artificial intelligence)","AAE system;SEC EDGAR database;SEC document;databases;intelligent corporate governance analysis;local knowledge bases;machine learning;rating system;semantic network","","0","","14","","","4-6 June 2014","","IEEE","IEEE Conference Publications"
"Advanced document management in e-Learning","Y. Abuzir","Computer Information Systems Department, Al-Quds Open University, Al-Bireh, behind Plaza Mall, P.O.Box 1804, Palestine","2014 World Congress on Computer Applications and Information Systems (WCCAIS)","20141007","2014","","","1","6","In this paper, we focus on a case concentrates on the use of email materials as supplements in the traditional classroom and in open and distance training and education. We describe how the interactive classification system based on thesaurus can simplify this task. This system provides the functions to index, classify and retrieve a collection of email messages based on user profiles. By automatically indexing the email messages using our system, Trainers and/or students can easily find their messages and find the topic. The system was evaluated. The test results showed that a good classification quality has been achieved with Precision percentage equal 77.4 and 90% for recall.","","Electronic:978-1-4799-3351-8; POD:978-1-4799-7527-3","10.1109/WCCAIS.2014.6916598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916598","e-Learning;information retrieval;student profile and classification","Education;Electronic mail;Indexing;Media;Thesauri;Three-dimensional displays","computer based training;distance learning;document handling;electronic mail;indexing;information retrieval;learning management systems;pattern classification","advanced document management;classification quality;distance education;distance training;e-learning;email message classification;email message indexing;email message retrieval;interactive classification system;open education;open training;thesaurus","","0","","15","","","17-19 Jan. 2014","","IEEE","IEEE Conference Publications"
"CoZpace: A proposal for collaborative web search for sharing search records and interactions","H. Kruajirayu; A. Tangsomboon; T. Leelanupab","Faculty of Information Technology, King Mongkuts Institute of Technology Ladkrabang (KMITL), Bangkok, Thailand. 10520","2014 Third ICT International Student Project Conference (ICT-ISPC)","20141016","2014","","","165","168","Today's search systems are mainly designed for one user to use individually. Search activities in practice can, however, be conducted by two or more users working together. This is due to the fact that information seeking tasks are complex and often requires multiple users' efforts to collaboratively assess and search for relevant information. In some tasks, there is a large amount of information to search or such information requires human intelligence to judge whether it is relevant to information needs. This paper introduces the development of collaborative search system, named “CoZpace”. CoZpace is a Web-based application, which allows a pair or a group of users to create a collaborative search task. Within the created task, a user can invite and communicate with other members in a group, share search history records, and mark search results considered relevant. We also propose a newly developed feature, called “snapboard”, to support collaborative search activities. With the snapboard, users are allowed to take a snapshot of a part of focused information in a Web site and then share it among collaborators on a display board. A user can mark it as relevant or comment it for further reviews of other collaborators.","","Electronic:978-1-4799-5573-2; POD:978-1-4799-5574-9","10.1109/ICT-ISPC.2014.6923242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6923242","CoZpace;Collaborative Search Activities;Explicit Collaboration;Information Retrieval;Synchronous and Asynchronous Collaboration","Collaboration;History;Instant messaging;Real-time systems;Servers;Web pages;Web search","Web sites;groupware;information retrieval","CoZpace;Web site;Web-based application;collaborative Web search;collaborative search activities;collaborative search system;collaborative search task;display board;information seeking tasks;search interactions;search records;snapboard;user efforts","","0","","10","","","26-27 March 2014","","IEEE","IEEE Conference Publications"
"Linking the Thesaurus for the Social Sciences to the Web of Linked Data","A. W. Alam; A. O. Kempf; B. Zapilko","GESIS - Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, 50667 Cologne, Germany","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","457","458","In this paper, we apply different methods for linking subject headings of the Thesaurus for the Social Sciences (TheSoz) to DBpedia, the nucleus of the Web of Linked Data which is derived from the structured information of Wikipedia. Our method utilizes the backlinks and outlinks within Wikipedia for link detection. We examine to what extent the linking process can be optimized with the help of a network-based similarity measure, in order to achieve a higher precision and recall. We test two baseline methods, string alignment and language property matching and compare them to our own method. Our method outperforms the F-scores of the baselines by 10 percentage points.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970223","Wikipedia;information retrieval;social sciences","Electronic publishing;Encyclopedias;Gold;Internet;Joining processes;Thesauri","Internet;Web sites;social sciences computing;string matching;thesauri","DBpedia;F-scores;Web of Linked Data;Wikipedia;backlinks;language property matching;link detection;linking process;network-based similarity measure;outlinks;string alignment;structured information;thesaurus for the social sciences","","0","","7","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"RLRAUC: Reinforcem ent learning based ranking algorithm using user clicks","V. Derhami; J. Paksima; H. Khajeh","Electrical and Computer Engineering, Dept. Yazd University Yazd, Iran","2014 4th International Conference on Computer and Knowledge Engineering (ICCKE)","20141222","2014","","","29","34","Because of great volume of web information, information retrieval process of a search engine is of great importance. For each query of user, the number of queries can reach hundred thousands, whereas a few number of the first results have the chance of being checked by user; therefore, a search engine pays attention to putting relevance results in the first ranks as a necessity. This paper introduces a reinforcement learning based ranking algorithm using user clicks, called RLRAUC, to put the relevance and favorite documents in the first ranks of query results. In the proposed algorithm, ranking system is the agent of learning system and selecting documents for displaying to user is considered as action. The reinforcement signal is calculated according to user click on documents. In this procedure, each pair of word-document in the user query is assigned a score according to the relevance of document. Documents in each repeating of learning would be sorted for next query based on changed scores and among these documents, according to document position in ranking list, random documents would be selected to be displayed to user. Learning process would be continued until it is converged to a stable ranking list. To evaluate proposed method, LETOR3 as well-known dataset has been used. Evaluation results indicate that RLRAUC is more effective than current ranking methods.","","Electronic:978-1-4799-5487-2; POD:978-1-4799-5488-9","10.1109/ICCKE.2014.6993462","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6993462","ranking;reinforcement learning;s-information retrieval;search engine;user click","Classification algorithms;Educational institutions;Learning (artificial intelligence);Learning systems;Search engines;Support vector machines;Training","Internet;document handling;learning (artificial intelligence);query processing;relevance feedback;search engines","LETOR3;RLRAUC;Web information;document relevance;favorite documents;information retrieval process;learning process;learning system;query results;random documents;ranking system;reinforcement learning based ranking algorithm;reinforcement signal;search engine;user clicks;user query;word-document","","2","","26","","","29-30 Oct. 2014","","IEEE","IEEE Conference Publications"
"LELA - a natural language processing system for Romanian tourism","B. Varga; A. D. Trambitas-Miron; A. Roth; A. Marginean; R. R. Slavescu; A. Groza","Semantic Web Department, Recognos Romania, Romania","2014 Federated Conference on Computer Science and Information Systems","20141023","2014","","","281","288","This paper presents a commercial semantic-based system for the Romanian tourism. The Lela system exploits both open linked data from Romanian and international sources, and also proprietary databases in the tourism domain. We present the process of creating the linked data set, based on: i) engineering the LELA Romanian tourism ontology, and ii) populating the ontology by linking open data. The system also provides a natural language interface for the Romanian language. The queries are automatically translated into SPARQL based on a controlled vocabulary derived from the Lela ontology.","","Electronic:978-83-60810-58-3; POD:978-1-4799-2853-8; USB:978-8-3608-1057-6","10.15439/2014F323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6933026","Linked Data;Natural language processing;Query interfaces;Semantic information retrieval;Tourism ontology","Blogs;Cities and towns;Electronic publishing;Encyclopedias;Internet;Ontologies","natural language interfaces;natural language processing;ontologies (artificial intelligence);query languages;query processing;travel industry","Lela Romanian tourism ontology;Lela system;SPARQL;commercial semantic-based system;databases;linked data set;natural language interface;natural language processing system;open linked data;query translation","","2","","22","","","7-10 Sept. 2014","","IEEE","IEEE Conference Publications"
"Searching quranic verses: A keyword based query solution using .net platform","S. Nisha; N. Ali; A. B. M. Shawkat Ali","Department of Computer Science and Information Technology School of Science and Technology The University of Fiji Lautoka, Fiji","The 5th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20150126","2014","","","1","5","Information retrieval from Islamic scriptures has greatly increased in recent years. With the fast moving life of today, there is too much to read and very little time to prepare, therefore a system is required that complies all related information from authentic electronic source files and organizes it into a standard format that could be quickly printed and taken along to be referred to during any occasion or gathering. This paper reviews existing Quaranic search engines and highlight limitations in the design as well as in its data mining ability. To overcome these limitations this paper presents a search engine (i-lab.org.au/truth-search-now) which produces better data retrieval from an ASP.Net and C sharp platform using SQL queries with table union and join operators.","","Electronic:978-1-4799-6242-6; POD:978-1-4799-6243-3","10.1109/ICT4M.2014.7020630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020630","ASP. Net;C#;SQL;aggregation functions;code behind page;information retrieval;quranic information","Decision support systems;Voltage control;Zinc","SQL;data mining;humanities;query processing;search engines","ASP.Net platform;C sharp platform;Islamic scriptures;Quranic verse search engines;SQL queries;authentic electronic source files;data mining;data retrieval;information compilation;information organization;information retrieval;join operators;keyword based query solution;standard format;table union","","0","","19","","","17-18 Nov. 2014","","IEEE","IEEE Conference Publications"
"A better indicator for genre classification: Topic word or surface text feature: A case study of recognition of brief biography","W. Xiong","National Research Center for Foreign Language Education, Beijing Foreign Studies University, Beijing 100089, China","2014 International Conference on Information Science, Electronics and Electrical Engineering","20141106","2014","3","","2015","2019","Classification based on topic (content) rather than genre (form) prevails in the text data mining and search engine circle. To simplify this work, a BOW (Bag of Words) strategy, counting topic-related words as features, is comprehensively utilized to make a final decision. Indeed, texts can be categorized by expression styles rather than their themes. Brief biography is a typical text class which differs from others in its genre. In order to differentiate biographical data from other texts quickly and effectively, we constructed two knowledge bases and compared their performances, i.e. topic keyword (content) and simple linguistic features (form). The results showed that the latter form-based approach is superior to its former counterpart. A further discussion is elaborated at the end of this paper.","","CD-ROM:978-1-4799-3195-8; Electronic:978-1-4799-3197-2; POD:978-1-4799-3198-9","10.1109/InfoSEEE.2014.6946276","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6946276","Information retrieval;discriminative analysis;genre;simple linguistic feature;text classification;topic word","Bioinformatics;Educational institutions;Knowledge based systems;Pragmatics;Resumes;Text categorization;Text recognition","biographies;classification;data mining;information retrieval;search engines;text analysis","BOW strategy;bag of words strategy;biographical data;brief biography recognition;genre classification;knowledge bases;linguistic features;search engine;surface text feature;text categorization;text class;text data mining;topic keyword;topic word;topic-related words","","0","","17","","","26-28 April 2014","","IEEE","IEEE Conference Publications"
"Ge(o)Lo(cator): Geographic Information Extraction from Unstructured Text Data and Web Documents","P. Nesi; G. Pantaleo; M. Tenti","Dept. of Inf. Eng., Univ. of Florence, Florence, Italy","2014 9th International Workshop on Semantic and Social Media Adaptation and Personalization","20141211","2014","","","60","65","The constantly growing number of websites, web pages, documents and, textual (Big) Data populating the Internet currently represents a massive resource of information and knowledge for various interests and across many different domains. However, the big amount and the complexity of unstructured, natural language textual data implies several issues and difficulties for end users to find a specific, desired pieces of information. In the era of maximum uptake of social networks and media, automatic extraction and retrieval of geographic information is becoming a field of large interest. In this paper, the GeLo system for extracting addresses and geographical coordinates of companies and organizations from their web domains is presented. The information extraction process relies on NLP techniques, specifically Part-Of-Speech-tagging, pattern recognition and annotation. The overall system performances have been manually evaluated against a consistent subset of the extracted URLs database.","","Electronic:978-1-4799-6814-5; POD:978-1-4799-6815-2","10.1109/SMAP.2014.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978954","Geocoding;Geographic Information Retrieval;Geoparsing;Web crawling;data mining","Cities and towns;Companies;Data mining;Databases;Semantics;Web pages","Big Data;Internet;Web sites;geographic information systems;information retrieval;natural language processing;text analysis","GeLo system;Internet;NLP techniques;URL database;Web domains;Web pages;Web sites;address extraction;automatic geographic information extraction;automatic geographic information retrieval;geographical coordinates;geolocator;part-of-speech-tagging;pattern annotation;pattern recognition;social media;social networks;textual big data;unstructured natural language textual data","","1","","29","","","6-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"Proposal of time series data retrieval with user feedback","C. Yin; H. Ishikawa; Y. Takama","Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan","2014 IEEE International Conference on Granular Computing (GrC)","20141215","2014","","","358","361","This paper introduces the concept of relevance feedback for retrieving time series data. Data in medical field handles various kinds of time series data, such as EHR (electronic health record) and consumer health data. Analyzing and accessing such time series data gets to be crucial for doctors to improve the quality of medical treatment. When we are going to develop an interactive interface for supporting a doctor to retrieve time series data of patients, it is supposed that similarity judgment on time series data depends on the knowledge and purpose of a doctor. Therefore, we employs relevance feedback-based retrieval system, which modifies similarity calculation based on the feedback information given by a doctor. In order to obtain enough feedback information from a doctor, we are going to employing two kinds of feedback mechanism: relevance feedback and graphical annotation-based feedback. This paper describes the concept of our relevance feedback-based retrieval system and the feedback mechanisms.","","Electronic:978-1-4799-5464-3; POD:978-1-4799-5465-0","10.1109/GRC.2014.6982864","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982864","information retrieval;interactive systems;relevance feedback;time series data","Atmospheric measurements;Data mining;Euclidean distance;Medical services;Particle measurements;Time measurement;Time series analysis","electronic health records;graphical user interfaces;relevance feedback;time series","EHR;consumer health data;electronic health record;feedback information;graphical annotation-based feedback;medical field data;medical treatment quality;relevance feedback-based retrieval system;time series data retrieval;user feedback","","0","","15","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"Are Data Sets Like Documents?: Evaluating Similarity-Based Ranked Search over Scientific Data","V. M. Megler; D. Maier","Department of Computer Science, Portland State University, Portland, OR","IEEE Transactions on Knowledge and Data Engineering","20141204","2015","27","1","32","45","The past decade has seen a dramatic increase in the amount of data captured and made available to scientists for research. This increase amplifies the difficulty scientists face in finding the data most relevant to their information needs. In prior work, we hypothesized that Information Retrieval-style ranked search can be applied to data sets to help a scientist discover the most relevant data amongst the thousands of data sets in many formats, much like text-based ranked search helps users make sense of the vast number of Internet documents. To test this hypothesis, we explored the use of ranked search for scientific data using an existing multi-terabyte observational archive as our test-bed. In this paper, we investigate whether the concept of varying relevance, and therefore ranked search, applies to numeric data-that is, are data sets are enough like documents for Information Retrieval techniques and evaluation measures to apply? We present a user study that demonstrates that data set similarity resonates with users as a basis for relevance and, therefore, for ranked search. We evaluate a prototype implementation of ranked search over data sets with a second user study and demonstrate that ranked search improves a scientist's ability to find needed data.","1041-4347;10414347","","10.1109/TKDE.2014.2320737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6807734","Scientific databases;information retrieval and relevance;similarity search","Catalogs;Geospatial analysis;Ocean temperature;Search problems;Sociology;Statistics;Temperature distribution","Internet;information needs;information retrieval;natural sciences computing;text analysis","Internet documents;data sets;information needs;information retrieval-style ranked search;multiterabyte observational archive;numeric data;scientific data;similarity-based ranked search evaluation;text-based ranked search","","1","","33","","20140429","Jan. 1 2015","","IEEE","IEEE Journals & Magazines"
"The impact of sections headings on the document retrieval","B. Abdelli; J. M. Pinon; O. Kazar","University Of Biskra","Ninth International Conference on Digital Information Management (ICDIM 2014)","20141218","2014","","","128","134","With online publications, the current Web has become the largest source of digital documents, often stored in HTML, XML, PDF or DOC. Among the features of documents, note especially their logical structure, which represents their components such as chapters, sections, paragraphs, the document title, chapter titles, sections, etc. The section headings are meaningful; they are a good indicator of the content of paragraphs. For this reason we pay particular attention to these titles during the indexing process and research. Our objective is to provide relevant access to digital documents, by the process of all sections titles to take advantage of their mining and importance in the research process. Experiments on a large corpus, INEX 2009 show effectiveness of our proposition an improvement in the precision of the results in IR.","","Electronic:978-1-4799-5421-6; POD:978-1-4799-5422-3","10.1109/ICDIM.2014.6991398","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991398","XML;information retrieval;logical structure;metadata;mining","Abstracts;Indexing;Information retrieval;Prototypes;Sections;XML","XML;electronic publishing;indexing;information retrieval;text analysis","DOC;HTML;INEX 2009;PDF;XML;chapter titles;corpus;digital documents;document mining;document retrieval;document titles;indexing process;logical structure;online publications;section headings","","0","","11","","","Sept. 29 2014-Oct. 1 2014","","IEEE","IEEE Conference Publications"
"Abnormal user detection based on instant messages","W. Dai; Y. X. Ding; C. Xue; Y. Zhang; G. Wu","Harbin Institute of Technology Shenzhen Graduate School, Shenzhen University Town, China","2014 International Conference on Machine Learning and Cybernetics","20150115","2014","2","","831","837","Instant messaging (IM) tools have been widely used in peoples' daily life. We study how to detect the identities of IM users from their chatting text. The abnormal detection model is employed to detect the identities of IM users. We use the topic model to find the relations between function words of chatting text, and extract the topic features to represent chatting text To improve the accuracy, we combine topic features with word based features to train the detection model, and achieve good experimental results.","2160-133X;2160133X","CD-ROM:978-1-4799-4217-6; Electronic:978-1-4799-4215-2; POD:978-1-4799-4214-5","10.1109/ICMLC.2014.7009717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009717","Chatting text;Information retrieval;Instant messaging;Intrusion detection;Security","Abstracts;Character recognition","electronic messaging;security of data;text analysis","IM users;abnormal user detection;chatting text;detection model;function words;instant messages;instant messaging tools;topic features","","0","","23","","","13-16 July 2014","","IEEE","IEEE Conference Publications"
"New Features Acquisition of Text with Cloud-LDA Model","M. Zhang; F. He; S. Chen","Dept. of Comput. Sci. & Technol., Central China Normal Univ., Wuhan, China","2013 International Conference on Information Science and Cloud Computing Companion","20141204","2013","","","267","272","This paper probes into how to improve Information Retrieval by changing the feature distribution of the text. It introduces Cloud Model theory into Latent Dirichlet Allocation(LDA) Model and build a new feature selection system. LDA Model is used to mine the underlying topical structure. Each topic is associated with a multinomial distribution over words which are semantic related. But there is doubt that themes are relevant with each other in the light of semantics. Based on LDA model presented probability distribution of vocabulary in text, the new system with Cloud Model theory can automatically simulate feature set whose contribution degree is high in the text. Results show this feature set has less features but higher classification accuracy, thus obviously better than currently popular feature selection methods. If the query is matched to words with high contribution degree, the more these words are, the more relevant the article searched out is with the query. NTCIR-5 (the 5th NII Test Collection for IR Systems) collections of Experiment on SLIR (Single Language IR) show that this method achieves an obvious improvement compared with some other methods in IR.","","CD-ROM:978-1-4799-1864-5; Electronic:978-1-4799-5245-8; POD:978-1-4799-5246-5","10.1109/ISCC-C.2013.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973603","Cloud Model;Information Retrieval;LDA model;feature","Computational modeling;Data models;Feature extraction;Indexes;Information retrieval;Semantics;Uncertainty","cloud computing;feature extraction;information retrieval;statistical distributions;text analysis","Information Retrieval;LDA model;NTCIR-5;SLIR;cloud model theory;cloud-LDA model;feature selection system;latent Dirichlet allocation;probability distribution;single language IR;text features acquisition","","0","","10","","","7-8 Dec. 2013","","IEEE","IEEE Conference Publications"
"Content-Based Search on Time-Series Microarray Databases","A. Hayran; H. Ogul; E. Özkoç","Dept. of Comput. Eng., Baskent Univ., Ankara, Turkey","2014 25th International Workshop on Database and Expert Systems Applications","20141204","2014","","","89","93","We study, for the first time, the problem of content-based searching of time-series microarray experiments in large-scale gene expression databases. The problem is approached as an information retrieval task where an entire ex-periment is taken as the query and searched through a collection of previous experiments. The relevant experiments are required to be retrieved based on the content similarity rather than their meta-data descriptions. A comparison of different fingerprinting and distance computation schemes is presented over a retrieval framework based on the differential expression of genes in varying time points.","1529-4188;15294188","Electronic:978-1-4799-5722-4; POD:978-1-4799-7866-3","10.1109/DEXA.2014.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974832","biological information retrieval;content-based search;gene expression database;microarray;time-course data;time-series profile","Bioinformatics;Correlation coefficient;Databases;Fingerprint recognition;Gene expression;Information retrieval;Vectors","bioinformatics;meta data;query processing;time series","content similarity;content-based search;distance computation schemes;fingerprinting computation schemes;information retrieval task;large-scale gene expression databases;meta-data descriptions;time-series microarray databases","","2","","22","","","1-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Optimized index construction for large text collections using blocked sort-based indexing","Rahevar Mrugendrasinh L; M. C. Parikh","Department of Computer Science and Engineering, Government Engineering College, Modasa, GECM, GTU, Gujarat, India","2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies","20150126","2014","","","1603","1606","Indexes are the key technology corroborate efficient text search. This paper, present an optimized index construction strategies for file system search engine. Index construction can be done in two phase: apply analyzer rule and index compression respectively. For fast index construction in-memory blocked sort-based Index partitions approach is used. Inverted index data structure used to provide efficient query evaluation. Special attention is given to a particular case of desktop search system such as Windows Desktop Search and Apple spotlight. As one of the main result of this paper demonstrate the time complexity and space complexity of indexed file.","","CD-ROM:978-1-4799-3913-8; Electronic:978-1-4799-3914-5; POD:978-1-4799-3915-2","10.1109/ICACCCT.2014.7019378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019378","File System;Index data structure;Information Retrieval;index compression","File systems;Image coding;Indexes;Information processing","computational complexity;data structures;indexing;optimisation;search engines","Apple spotlight;Windows desktop search;blocked sort-based indexing;desktop search system;file system;index compression;inverted index data structure;large text collections;optimized index construction;query evaluation;search engine;space complexity;time complexity","","0","","11","","","8-10 May 2014","","IEEE","IEEE Conference Publications"
"Harnessing Social Signals to Enhance a Search","I. Badache; M. Boughanem","Univ. of Toulouse, Toulouse, France","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","303","309","This paper describes an approach of information retrieval which takes into account social signals associated with Web resources to estimate its relevance to a query. We show how these data, which are in the form of actions within social activities (e.g. Like, tweet), can be exploited to quantify social properties such as popularity and reputation. We propose a model that combines the social relevance, estimated from these properties, with the conventional textual relevance. We evaluated the effectiveness of our approach on IMDb dataset containing 32706 resources and their social characteristics collected from several social networks. We used also the selected criteria to learn models to determine their effectiveness in information retrieval. Our experimental results are promising and show the interest of integrating social signals in retrieval model to enhance a search.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927557","Criteria Evaluation;Learning Models;Social Information Retrieval;Social Properties;Social Signals","Conferences;Intelligent agents;Joints","Internet;query processing;social networking (online)","IMDb dataset;Web resources;information retrieval;query;relevance estimation;search enhancement;social networks;social properties;social relevance;social signals;textual relevance","","0","","19","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Online PLSA: Batch Updating Techniques Including Out-of-Vocabulary Words","N. K. Bassiou; C. L. Kotropoulos","Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece","IEEE Transactions on Neural Networks and Learning Systems","20141015","2014","25","11","1953","1966","A novel method is proposed for updating an already trained asymmetric and symmetric probabilistic latent semantic analysis (PLSA) model within the context of a varying document stream. The proposed method is coined online PLSA (oPLSA). The oPLSA employs a fixed-size moving window over a document stream to incorporate new documents and at the same time to discard old ones (i.e., documents that fall outside the scope of the window). In addition, the oPLSA assimilates new words that had not been previously seen (out-of-vocabulary words), and discards the words that exclusively appear in the documents to be thrown away. To handle the new words, Good-Turing estimates for the probabilities of unseen words are exploited. The experimental results demonstrate the superiority in terms of accuracy of the oPLSA over well known PLSA updating methods, such as the PLSA folding-in (PLSA fold.), the PLSA rerun from the breakpoint, the quasi-Bayes PLSA, and the Incremental PLSA. A comparison with respect to the CPU run time reveals that the oPLSA is the second fastest method after the PLSA fold. However, the better accuracy of the oPLSA than that of the PLSA fold. pays off the longer computation time. The oPLSA and the other PLSA updating methods together with online LDA are tested for document clustering and F<sub>1</sub> scores are also reported.","2162-237X;2162237X","","10.1109/TNNLS.2014.2299806","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6737290","Document clustering;PLSA updating;document modeling;information retrieval;out-of-vocabulary (OOV) words;probabilistic latent semantic analysis (PLSA);unsupervised learning;unsupervised learning.","Computational modeling;Data models;Mathematical model;Matrix decomposition;Probabilistic logic;Semantics;Vocabulary","document handling;natural language processing;probability;vocabulary","asymmetric probabilistic latent semantic analysis model;batch updating techniques;document clustering;oPLSA;online PLSA updating method;out-of-vocabulary words;second fastest method;symmetric probabilistic latent semantic analysis","","5","","45","","20140211","Nov. 2014","","IEEE","IEEE Journals & Magazines"
"Efficiently denoising SMS text for FAQ retrieval","R. Batra; S. Sharma; A. Shrivastav; P. Goyal","Department of Computer Science and Engineering, Graphic Era University, Dehradun, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","5","Several online resources in the form of Frequently Asked Questions (FAQs) provide useful and much needed information across different domains like health, education, banking etc. Community based service has emerged as a powerful resource for information retrieval but its access is restricted to internet only.To access information without internet facility more and more people rely on Short Message Service (SMS) to get an instant answer to their query.Therefore, efforts have been put to improve the SMS based information retrieval system. The text in SMS messages are generally noisy and correcting this noisy text is one of the major challenges that affect the efficiency and accuracy of any SMS based information retrieval system. This paper provides the improvements to the existing algorithms of noise removal in SMS text to obtain better results. Experiments using different test cases show that the proposed system outperforms other methods.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954237","Algorithms;Information retrieval;Noise removal;Short Message Service (SMS);Similarity measure","Databases;Dictionaries;Noise;Noise measurement;Noise reduction;Servers","electronic messaging;query processing;text analysis","FAQ retrieval;SMS based information retrieval system;SMS messages;SMS text denoising;frequently asked questions;information access;noise removal;short message service","","1","","14","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"Increasing the visibility of library records via consortial search engine","Õ. Mets; S. Gstrein; V. Gründhammer","National Library of Estonia, T&#x00F5;nism&#x00E4;gi 2, Tallinn 15189, Estonia","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","169","172","In this paper we describe a common search engine which currently comprises the records of public domain literature from 29 libraries across Europe. These libraries offer the EOD (eBooks on Demand) digitization on request service and make digitized materials available. The search engine (http://search.books2ebooks.eu) has been developed to enable users to browse the respective content simultaneously from several library catalogues. The current case study provides a description of the search engine, statistical trends of user engagement, and their implications. Our findings show the effectiveness of such collaboration, especially in terms of increasing the visibility of data and engaging new user groups. The lessons learned are to encourage the library community, including smaller language groups, for more active cooperation.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970164","Information retrieval and browsing;consortia;evaluation;federated search;integration of datasets;library catalogues;open source software","Collaboration;Educational institutions;Electronic publishing;Europe;Google;Libraries;Search engines","electronic publishing;public libraries;relevance feedback;search engines","Europe;consortial search engine;data visibility;digitized materials;eBooks on Demand digitization;library catalogues;library community;library records;public domain literature;public libraries;statistical trends;user engagement","","0","","8","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Inside-In Search: An Alternative for Performing Ancillary Search Tasks on the Web","R. Cava; C. M. D. S. Freitas; E. Barboni; P. Palanque; M. Winckler","Inst. de Inf., Univ. Fed. do Rio Grande do Sul (UFRGS), Porto Alegre, Brazil","2014 9th Latin American Web Congress","20150108","2014","","","91","99","Some of the search tasks users perform on the Web aim at complementing the information they are currently reading in a Web page: they are ancillary search tasks. Currently, the standard way to support such ancillary searches follows an inside-out approach, which means that query results are shown in a new window/tab or as a replacement of the current page. We claim that such inside-out approach is only suitable if users really want to dissociate the search results from the Web page they were reading. In this paper we propose an alternative approach, called ""inside-in"", where query results are displayed inside the Web page next to the keyword that motivated the user to launch an ancillary search. In order to demonstrate the feasibility of our approach we have developed a tool that embeds an egocentric information visualization technique in the Web page. This tool supports nested queries and allows the display of multiple data attributes. The approach is illustrated by a case study based on ancillary searches of co authors from a digital library. The paper also reports some preliminary results obtained with an experiment conducted with remote users.","","CD-ROM:978-1-4799-6952-4; Electronic:978-1-4799-6953-1; POD:978-1-4799-6954-8","10.1109/LAWeb.2014.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000176","Visualization techniques;Web interaction techniques;Web-based user interfaces;ancillary Web queries;information retrieval","Context;Data visualization;Iris;Iris recognition;Navigation;Semantics;Web pages","Web sites;digital libraries;graphical user interfaces;query processing","Web page;ancillary Web search tasks;co-authorship;digital library;egocentric information visualization technique;inside-in search approach;keywords;multiple data attributes;nested Web queries;remote users;search result dissociation","","0","","28","","","22-24 Oct. 2014","","IEEE","IEEE Conference Publications"
"A Top-N Recommender Model with Partially Predefined Structure","E. M. Rochd; M. Quafafou","LSIS, Aix-Marseille Univ., Marseille, France","2014 IEEE 11th International Conference on e-Business Engineering","20141211","2014","","","112","119","Recommender systems can retrieve appropriate results based on users behavioral patterns and preferences. They may be built based on multi-label learning approaches, as each customer transaction may be labeled with several results that interest him/her. It is therefore useful to model the correlations between labels while controlling complexity of the learning algorithm. This paper presents a generative probabilistic model for online resources (products/URLs) recommendation, by capturing the complex local correspondence between the user's queries and the resources he/she has actually viewed. The structure of our model is partially defined and it is completed according to the observed data. Consequently, several links between observed and/or latent random variables are induced from the training dataset before starting the estimation of parameters. Experiments conducted on real data show the effectiveness of our approach.","","Electronic:978-1-4799-6563-2; POD:978-1-4799-6564-9","10.1109/ICEBE.2014.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982067","E-commerce;Information Retrieval;Local Influence;Recommendation;Topic Models;User Behavior","Context;Correlation;Data models;Mathematical model;Probabilistic logic;Testing;Training","learning (artificial intelligence);parameter estimation;probability;query processing;random processes;recommender systems","Top-N recommender model;complex local correspondence;customer transaction;generative probabilistic model;latent random variables;learning algorithm;multilabel learning approaches;online resource recommendation;parameter estimation;partially predefined structure;recommender systems;user behavioral patterns;user behavioral preferences;user queries","","0","","20","","","5-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"Feature Selection and Term Weighting","A. Algarni; N. Tairan","Coll. of Comput. Sci., King Khalid Univ., Abha, Saudi Arabia","2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20141020","2014","1","","336","339","Term-based approaches can extract many features in text documents, but most include noise. Many popular text-mining techniques have been adapted to reduce noisy information from extracted features but still contains some noises features. However, the noise features are extracted from the same training documents that good features extracted from. Therefore, the main problem is that some training documents contain large a mount of noises data. If we can reduce the noises data in the training documents that would help to reduce noises in extracted features. Moreover, we believe that remove some of training documents (documents that contains noises data more than useful data) can help to improve the effectiveness of the classifier. Using the advantages of clustering method can help to reduce the affect of noises data. The main problem of clustering is defined to be that of finding groups of similar projects in the data. In this paper we introduce the methodology that using clustering algorithm to group training data before use it. Also we tested our theory that not all training documents are useful to train the classifier.","","Electronic:978-1-4799-4143-8; POD:978-1-4799-4142-1","10.1109/WI-IAT.2014.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927562","Data mining;Information retrieval;Text mining","Feature extraction;Frequency measurement;Information retrieval;Noise;Text categorization;Training","data mining;data reduction;feature extraction;feature selection;pattern classification;pattern clustering;text analysis","classifier;clustering algorithm;feature extraction;feature selection;group training data;noise data reduction;noisy information reduction;term weighting approach;text documents;text-mining techniques;training documents","","0","","23","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Adaptive Distribution of Vocabulary Frequencies: A Novel Estimation Suitable for Social Media Corpus","R. A. Igawa; G. S. Kido; J. L. Seixas; S. Barbon","Dept. of Comput., State Univ. of Londrina, Londrina, Brazil","2014 Brazilian Conference on Intelligent Systems","20141215","2014","","","282","287","This paper aims to propose a mathematical model that evaluates the distribution of the vocabulary frequency terms in proportion to a probabilistic ideal. Once we are able to evaluate it, the main objective of this work is to use it in order to examine text demising. We propose this new metric based on the classic Zipf's law statistic method. The experimental set to test the classic Zipf's law and our developed model is based on some books of the classic literature and some tweets sets of Twitter. Thus, our main result is that the model proposed in this work is more sensitive to the presence of text noises than Zipf's law and is asymptotically quicker, suitable to corpus of social media networks.","","Electronic:978-1-4799-5618-0; POD:978-1-4799-7859-5","10.1109/BRACIS.2014.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984844","Information Retrieval;Social Media Networks;Text preprocessing;Zipfs Law","Mathematical model;Media;Noise;Noise measurement;Noise reduction;Twitter;Vocabulary","mathematical analysis;social networking (online);text analysis","Twitter;Zipf law statistic method;adaptive distribution;mathematical model;social media corpus;social media networks;text demising;text noises;tweets sets;vocabulary frequency terms","","0","","29","","","18-22 Oct. 2014","","IEEE","IEEE Conference Publications"
"A new approach to isomorphism in attributed graphs","J. Mendivelso; Y. Pinzón","Fundaci&#x00F3;n Universitaria Konrad Lorenz, Colombia","2014 9th Computing Colombian Conference (9CCC)","20141113","2014","","","231","239","Attributed graphs are widely used in many application domains, for example to model social networks. An attributed graph is a graph in which vertices and edges may have types and other attributes. Different query models have been developed to obtain information from attributed graphs. One of the most important is graph pattern matching, which is the problem of finding all the instances of the pattern graph P in the attributed graph G under graph isomorphism. A pattern graph may specify both structural requirements and predicates on attributes of the graph elements. We propose a novel technique that linearizes the pattern graph and matches such linearization against the attributed graph. We derive heuristics to produce a linearization that places selective predicates at the beginning. We implement the algorithm and our results show that our optimizations based on the attributed graph statistics are effective in querying attributed graphs.","","Electronic:978-1-4799-6717-9; POD:978-1-4799-6718-6","10.1109/ColumbianCC.2014.6955352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6955352","Databases;Information Retrieval;Semantic Web;Social Networks","Impedance matching;Pattern matching;Relational databases;Social network services;Time complexity;Topology","data structures;graph theory;pattern matching","attributed graph statistics;data structures;graph pattern matching;isomorphism;linearization algorithm;query graph","","0","","12","","","3-5 Sept. 2014","","IEEE","IEEE Conference Publications"
"Word Spotting in Bangla and English Graphical Documents","A. Tarafdar; U. Pal; J. Y. Ramel; N. Ragot; B. B. Chaudhuri","CVPR Unit, Indian Stat. Inst., Kolkata, India","2014 22nd International Conference on Pattern Recognition","20141206","2014","","","3044","3049","Word spotting in graphical documents is a very challenging task. With an increase usage of electronic media, we are in a need of searching objects in graphical documents by some labeled text. To address such scenarios we propose a word spotting system dedicated to graphical documents with Bangla and English scripts. In our proposed system, first text-graphics layers are separated using Gabor filter. In the text layer, character segmentation approach is applied using water reservoir based method to extract each character from the document. Then recognition of these isolated characters is done using rotation invariant feature, coupled with SVM classifier. Well recognized characters are then grouped based on their sizes. Initial spotting is started to find a query word among those groups of characters. In case if the system could spot a word partially due to any noise, SIFT is applied to identify missing portion of that partial spotting. Experimental results on English and Bangla script document images show that the method is feasible to spot a location in text labeled graphical documents.","1051-4651;10514651","Electronic:978-1-4799-5209-0; POD:978-1-4799-5210-6","10.1109/ICPR.2014.525","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977237","Clustering;Document Image Analysis;Gabor Filter;Graphical documents;Information Retrieval;SIFT feature;Water Reservoir Principle;Word Spotting","Character recognition;Feature extraction;Gabor filters;Graphics;Reservoirs;Support vector machines","Gabor filters;document image processing;image classification;image retrieval;image segmentation;natural language processing;optical character recognition;support vector machines;text analysis;transforms","Bangla graphical documents;Bangla scripts;English graphical documents;English scripts;Gabor filter;SIFT;SVM classifier;character segmentation approach;electronic media usage;isolated character recognition;object searching;query word;rotation invariant feature;scale invariant feature transform;support vector machine;text labeled graphical documents;text-graphics layers;word spotting system","","0","","14","","","24-28 Aug. 2014","","IEEE","IEEE Conference Publications"
"Music Genre Classification of MPEG AAC Audio Data","M. Kobayakawa; M. Hoshi; K. Yuzawa","Tokyo Metropolitan Coll. of Ind. Technol., Tokyo, Japan","2014 IEEE International Symposium on Multimedia","20150209","2014","","","347","352","In this paper, we propose a musical feature extracted from the bit stream of AAC (Advanced Audio Coding) compressed audio data without decoding to audio signals. We focus on the spectral data which are stored in the bit stream for representing the flatten MDCT (Modified Discrete Cosine Transform) of an audio signal. For computing the musical feature, we extract the spectral data and apply the Discrete Wavelet Transform (DWT) to the extracted spectral data. For musical genre classification, we use the discriminant analysis as a classifier. We experimented on 1,498 AAC compressed audio data collected from 10 musical genres and evaluated the performance of the musical feature. We got the maximum correct ratios 81.24%. The experiments showed that the musical feature based on the spectral data in the bit stream had good performance for genre classification in the MPEG-4 AAC compressed domain.","","CD-ROM:978-1-4799-4312-8; Electronic:978-1-4799-4311-1; POD:978-1-4799-4310-4","10.1109/ISM.2014.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033049","MPEG AAC audio;Music Genre Classification;music information retrieval","Data mining;Discrete wavelet transforms;Feature extraction;Music;Reliability;Transform coding;Vectors","audio coding;discrete cosine transforms;discrete wavelet transforms;feature extraction;music;signal classification;spectral analysis","AAC compressed audio data bitstream;AAC compressed audio data collection;DWT;MPEG AAC audio data;MPEG-4 AAC compressed domain;advanced audio coding;audio signal;discrete wavelet transform;discriminant analysis;flatten MDCT representation;maximum correct ratios;modified discrete cosine transform;music genre classification;musical feature extraction;musical feature performance evaluation;spectral data extraction","","0","","21","","","10-12 Dec. 2014","","IEEE","IEEE Conference Publications"
"A Chinese question answering system based on web search","Z. J. Liu; X. L. Wang; Q. C. Chen; Y. Y. Zhang; Y. Xiang","Intelligent Computing Research Center, Computer Science and Technology, Harbin Institute of Technology Shenzhen, Graduate School, China","2014 International Conference on Machine Learning and Cybernetics","20150115","2014","2","","816","820","With the rapid development of search engine technology, the massive information on the internet becomes increasingly easy to search and utilize. However, Reading a large number of web pages of search engine results is also a hard work for users. Therefore how to conveniently and directly get the answers is a recent research focus. In this paper, we put forward a Chinese question answering system which uses the real-time network information retrieved by search engines. By inputting a natural language question, users can get an accurate answer. There are three main steps to extract the answers in our system. First is the question analysis, extract keywords and type of the question. Then the second step is to retrieve relevant pages through web search engines. The last and most important step is answer extraction, evaluate all extracted candidate answers, and the final answer will be the one with highest score. In addition to the system implementation, we also evaluated the performance of our system with an artificial building question-answer dataset. And the results obviously proved the feasibility of our system.","2160-133X;2160133X","CD-ROM:978-1-4799-4217-6; Electronic:978-1-4799-4215-2; POD:978-1-4799-4214-5","10.1109/ICMLC.2014.7009714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009714","Answer extraction;Information retrieval;Named entity recognition;Question answering system","Abstracts;Engines","Internet;natural language processing;question answering (information retrieval);search engines","Chinese question answering system;Internet;Web pages;Web search;answer extraction;extract keywords;natural language question;question analysis;real-time network information;search engine technology","","1","","9","","","13-16 July 2014","","IEEE","IEEE Conference Publications"
"Similarity of Authors' Profiles and Its Usage for Reviewers' Recommendation","P. aloun; A. Ondrejka; I. Zelinka","Fac. of Electr. Eng. & Comput. Sci., VSB-Tech. Univ. of Ostrava, Ostrava, Czech Republic","2014 9th International Workshop on Semantic and Social Media Adaptation and Personalization","20141211","2014","","","3","8","This article describes an algorithm to facilitate the proper assignment of reviewers by finding an author's profile. It uses an original approach to analyzing publications published in digital libraries to get additional keywords based on NLP (natural language processing) techniques. Comparing profiles and finding similarities between them are performed afterwards in the vector space model in generally known ways. The result of our work is an algorithm to help conference organizers assign reviewers to registered publications. In many cases, the organizers have to know about the research area of all program committee members and have to select the appropriate opponent manually. The results of the algorithm functionality are verified by real data from two conferences, a local and global one.","","Electronic:978-1-4799-6814-5; POD:978-1-4799-6815-2","10.1109/SMAP.2014.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6978944","NLP;digital libraries;information retrieval;similarity profiles;text analysis","Abstracts;Computer science;Libraries;Natural language processing;Resource management;Social network services;Vectors","digital libraries;natural language processing;recommender systems;reviews;text analysis","NLP techniques;author profiles;conference organizers;digital libraries;natural language processing techniques;program committee members;reviewer assignment;reviewer recommendation;vector space model","","0","","16","","","6-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"EMR: A Scalable Graph-Based Ranking Model for Content-Based Image Retrieval","B. Xu; J. Bu; C. Chen; C. Wang; D. Cai; X. He","Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, Hangzhou, China","IEEE Transactions on Knowledge and Data Engineering","20141204","2015","27","1","102","114","Graph-based ranking models have been widely applied in information retrieval area. In this paper, we focus on a well known graph-based model - the Ranking on Data Manifold model, or Manifold Ranking (MR). Particularly, it has been successfully applied to content-based image retrieval, because of its outstanding ability to discover underlying geometrical structure of the given image database. However, manifold ranking is computationally very expensive, which significantly limits its applicability to large databases especially for the cases that the queries are out of the database (new samples). We propose a novel scalable graph-based ranking model called Efficient Manifold Ranking (EMR), trying to address the shortcomings of MR from two main perspectives: scalable graph construction and efficient ranking computation. Specifically, we build an anchor graph on the database instead of a traditional k-nearest neighbor graph, and design a new form of adjacency matrix utilized to speed up the ranking. An approximate method is adopted for efficient out-of-sample retrieval. Experimental results on some large scale image databases demonstrate that EMR is a promising method for real world retrieval applications.","1041-4347;10414347","","10.1109/TKDE.2013.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6512497","Graph-based algorithm;Information Storage and Retrieval;Information Technology and Systems;Information filtering;Retrieval models;image retrieval;out-of-sample;ranking model","Filtering theory;Graphical models;Information retrieval;Information storage;Information technology","content-based retrieval;graph theory;image classification;image retrieval","EMR;MR;adjacency matrix;content-based image retrieval;data manifold model;database anchor graph;efficient manifold ranking;image databases;out-of-sample retrieval;ranking computation;scalable graph construction;scalable graph-based ranking model","","8","","47","","20130502","Jan. 2015","","IEEE","IEEE Journals & Magazines"
"Optimized web search results through additional retrieval lists inferred using WordNet similarity measure","Saravanakumar K; A. K. Cherukuri","School of Information Technology and Engineering, Vellore Institute of Technology University, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","7","Search engines have become mandatory part in the usability of information available through Internet. They provide direct support in the growth of the World Wide Web. Today their concern is to give more importance to the precision in the top results suggested to reduce the iterative search of a concept by any user. Our main objective is to improve the efficiency of search results suggested by the search engine in response to a query. The objective is approached by constructing alternate queries for the main query given by the user. It involves the selection of contextually most similar alternate queries through the method proposed here. The coalition of results produced by the main query and the alternate queries could improve the precision in the top pages. We evaluated the proposed method and observed that the proposed method performed well in projection of some of the important links of the search results into the top few pages. Also, it is observed that the precision improved considerably.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954255","Alternate Query Formation;Information Retrieval;Re-ranking Search Results;Semantic Relatedness;Wordnet Similarity","Ontologies;Search engines;Semantics;Thesauri;Uniform resource locators;Vectors","Web sites;query processing;search engines","WordNet similarity measure;World Wide Web;additional retrieval list inference;contextually most-similar alternate query selection;information usability;iterative search reduction;optimized Web search results;precision improvement;query response;result coalition;search engines;search result efficiency improvement;top pages","","0","","25","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"A Gazetteer for Biodiversity Data as a Linked Open Data Solution","S. D. Cardoso; K. J. Serique; F. K. Amanqui; J. L. C. D. Santos; D. A. Moreira","ICMC, Univ. of Sao Paulo, Sao Carlos, Brazil","2014 IEEE 23rd International WETICE Conference","20141020","2014","","","435","440","Biodiversity studies all life forms that we find in nature. The maintenance of biological diversity is important because it is essential to life on Earth. The lack of accurate spatial geographic information in species occurrence data, especially from diversity rich regions (like the Amazon Forest), leads to problems in many conservation activities, such as systematic planning for the protection of endangered species. In this paper, we present a gazetteer (a geographical directory that associate name places to geographic coordinates) for biodiversity data that is available as an Linked Open Data resource (using a GeoSPARQL Endpoint) and show how it can be used to improve inaccurate geographic collection data. We compared the efficiency of our Gazetteer with three openly available resources, Geonames, WikiMapia and Wikipedia, and got a 10% better recall rate than these endpoints. We also used the Gazetteer to correct geographic data from a big record sample (327,000 occurrence records) from Species Link and GBIF (two big open access repositories of biodiversity occurrence data). In this data set, we were able to add geographic coordinates to around 14% of records that did not have them before.","1524-4547;15244547","Electronic:978-1-4799-4249-7; POD:978-1-4799-4248-0","10.1109/WETICE.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6927097","Biological Gazetteer;Geographic information retrieval;SPARQL and GeoSPARQL;semantic web","Accuracy;Biodiversity;Bioinformatics;Electronic publishing;Encyclopedias;Ontologies","data handling;ecology;environmental science computing","Amazon Forest;GBIF;Gazetteer;Geonames;Linked Open Data resource;Linked Open Data solution;Species Link;WikiMapia;Wikipedia;biodiversity data;biological diversity;geographic coordinates;geographical directory;spatial geographic information","","2","","14","","","23-25 June 2014","","IEEE","IEEE Conference Publications"
"AutoLeadGuitar: Automatic generation of guitar solo phrases in the tablature space","M. McVicar; S. Fukayama; M. Goto","National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan","2014 12th International Conference on Signal Processing (ICSP)","20150122","2014","","","599","604","We present AutoLeadGuitar, a system for automatically generating guitar solo tablatures from an input chord and key sequence. Our system generates solos in distinct musical phrases, and is trained using existing digital tablatures sourced from the web. When generating solos AutoLeadGuitar assigns phrase boundaries, rhythms and fretboard positions within a probabilistic framework, guided towards chord tones by two user-specified parameters (chord tone preference during and at the end of phrases). Furthermore, guitar-specific ornaments such as hammer-ons, pull-offs, slides and string bends are built directly into our model. Listening tests with our model output confirm that the inclusion of chord tone preferences, phrasing, and guitar ornaments corresponds to an increase in user satisfaction.","2164-5221;21645221","CD-ROM:978-1-4799-2187-4; Electronic:978-1-4799-2186-7; POD:978-1-4799-2189-8","10.1109/ICOSP.2014.7015074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015074","Computer generated music;Music information retrieval","Computational modeling;Data models;Genetics;Handheld computers;Markov processes","information retrieval;music;probability","AutoLeadGuitar system;chord tone preference;fretboard positions;guitar solo phrase generation;guitar solo tablature generation;guitar-specific ornaments;input chord;key sequence;listening tests;musical phrase;phrase boundaries;probabilistic framework;rhythms;tablature space;user satisfaction","","2","","27","","","19-23 Oct. 2014","","IEEE","IEEE Conference Publications"
"Learning to Rank Improves IR in SE","D. Binkley; D. Lawrie","Loyola Univ., Baltimore, MD, USA","2014 IEEE International Conference on Software Maintenance and Evolution","20141206","2014","","","441","445","Learning to Rank (LtR) encompasses a class of machine learning techniques developed to automatically learn how to better rank the documents returned for an information retrieval (IR) search. Such techniques offer great promise to software engineers because they better adapt to the wider range of differences in the documents and queries seen in software corpora. To encourage the greater use of LtR in software maintenance and evolution research, this paper explores the value that LtR brings to two common maintenance problems: feature location and traceability. When compared to the worst, median, and best models identified from among hundreds of alternative models for performing feature location, LtR ubiquitously provides a statistically significant improvement in MAP, MRR, and MnDCG scores. Looking forward a further motivation for the use of LtR is its ability to enable the development of software specific retrieval models.","1063-6773;10636773","Electronic:978-1-4799-6146-7; POD:978-1-4799-6147-4","10.1109/ICSME.2014.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976114","Information Retrieval;Software Specific Retrieval","Computational modeling;Information retrieval;Robustness;Software;Software engineering;Stability analysis;Training","document handling;information retrieval;learning (artificial intelligence);software maintenance","IR;LtR;MAP score;MRR score;MnDCG score;SE;document ranking;feature location;information retrieval;learning to rank;machine learning;software engineering;software maintenance;software specific retrieval models;traceability","","3","","20","","","Sept. 29 2014-Oct. 3 2014","","IEEE","IEEE Conference Publications"
"Effect of multi-word features on the hierarchical clustering of web documents","S. Karthick; S. M. Shalinie; A. Eswarimeena; P. Madhumitha; T. N. Abhinaya","Department of Computer Science and Engineering, Thiagarajar College of Engineering, Madurai, India","2014 International Conference on Recent Trends in Information Technology","20141229","2014","","","1","6","Contemporary search engines and other automated web tools are faced with the task of extracting relevant information from huge web archives. This is supposed to be a difficult task due to the semi-structured and unstructured nature of the web documents. Users need automated ways of organizing and cataloging the web documents so that they can be queried efficiently. Clustering is typically employed to organize web archives and to subsequently handle user queries. This paper analyzes the effect of including multi-word features on the performance of a hierarchical clustering algorithm. Noun sequences are the predominant features considered in our work, while most of the previous research uses n-grams as features. The paper also analyzes the effect of combining link and content based representations for the web documents and their inter-relationships on the clustering performance. Empirical evaluation of the hierarchical clustering engine suggests that including multi-word features enhances the performance of the hierarchical clustering algorithm with respect to precision.","","DVD:978-1-4799-4990-8; Electronic:978-1-4799-4989-2; POD:978-1-4799-7868-7","10.1109/ICRTIT.2014.6996185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996185","Clustering;Feature Extraction;Hierarchical Clustering;Information retrieval;Multi-words;Part of Speech Tagger;Web Mining","Algorithm design and analysis;Clustering algorithms;Equations;Mathematical model;Measurement;Speech;Web pages","Internet;cataloguing;pattern clustering;query processing;search engines;text analysis","Web archives;Web documents cataloging;Web documents organization;automated Web tools;clustering performance;contemporary search engines;content based representations;hierarchical clustering algorithm;hierarchical clustering engine;information extraction;link based representations;multiword features;noun sequences;user queries","","1","","16","","","10-12 April 2014","","IEEE","IEEE Conference Publications"
"Exploring relevance assessment using crowdsourcing for faceted and ambiguous queries","S. D. Ravana; P. Samimi; P. Dabir Ashtyani","Department of Information Systems, Faculty of Computer Science & Information Systems, University of Malaya, Kuala Lumpur, Malaysia","2014 Science and Information Conference","20141009","2014","","","771","776","Relevance assessment usually generated by human experts that can be a time-consuming, difficult and potentially expensive process. Recently, crowdsourcing has been presented to be a fast and cheap method to make relevance assessments in a semi-automatic way. However, previous work on the limit of crowdsourcing in IR evaluation is still inadequate and need further investigation especially for varying nature of queries used during the Web search. In this study, we have observed the responses from the crowdsourced workers and experts in assessing the judgments, compared the agreement between the relevance judgments made by an expert assessor and crowdsourced worker, and finally explored the constancy in system ranking when these two sets of relevance judgments were used to score the systems. Two commercial search engines were compared using two different types of queries namely the faceted and ambiguous queries. In general, both set of judgments ranked the systems in the same order although the absolute systems scores vary slightly. However, the findings shows that the type of query used does influence the agreement between assessors and the system performance measure.","","CD-ROM:978-0-9893-1932-4; Electronic:978-0-9893193-1-7; POD:978-1-4799-3981-7","10.1109/SAI.2014.6918273","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918273","crowdsourcing;evaluation;information retrieval;relevant assessment","Computer science;Crowdsourcing;Google;Information systems;Search engines;Web search","Internet;query processing;search engines","Web search;ambiguous queries;crowdsourcing;faceted queries;information retrieval;judgment assessment;relevance assessment;search engines","","0","","26","","","27-29 Aug. 2014","","IEEE","IEEE Conference Publications"
"What is this song about anyway?: Automatic classification of subject using user interpretations and lyrics","K. Choi; J. H. Lee; J. S. Downie","University of Illinois, Champaign, 61820, USA","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","453","454","Metadata research for music digital libraries has traditionally focused on genre. Despite its potential for improving the ability of users to better search and browse music collections, music subject metadata is an unexplored area. The objective of this study is to expand the scope of music metadata research, in particular, by exploring music subject classification based on user interpretations of music. Furthermore, we compare this previously unexplored form of user data to lyrics at subject prediction tasks. In our experiment, we use datasets consisting of 900 songs annotated with user interpretations. To determine the significance of performance differences between the two sources, we applied Friedman's ANOVA test on the classification accuracies. The results show that user-generated interpretations are significantly more useful than lyrics as classification features (p <; 0.05). The findings support the possibility of exploiting various existing sources for subject metadata enrichment in music digital libraries.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970221","Data mining;Lyrics;Metadata;Music;Music Information Retrieval;Subject;Text classification;User-generated content","Accuracy;Classification algorithms;Drugs;Educational institutions;Libraries;Music information retrieval;System-on-chip","digital libraries;information retrieval;meta data;music;pattern classification;statistical analysis","Friedman ANOVA test;automatic music subject classification;lyrics;music collections;music digital libraries;music genre;music subject metadata;user interpretations","","2","","5","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"Semantic report search engine — Questor","A. Vasilateanu; N. Goga; A. Moldoveanu","Faculty of Engineering in Foreign Languages, University Politehnica of Bucharest, Romania","2014 18th International Conference on System Theory, Control and Computing (ICSTCC)","20141215","2014","","","134","139","As ever more data is collected in the business processes of large enterprises, the decision makers need new business intelligence tools. Enterprise reporting tools have been available for some time, however, while reports aggregate business data, the large number of reports can become unmanageable. The European funded project Questor aims to create a revolutionary product that will eliminate the complexities inherent in the report management workflow. The final purpose is to make querying the report database as simple as addressing a question in natural language. This paper gives an overview over the concept of the Questor project, its software architecture, algorithms and results.","","Electronic:978-1-4799-4601-3; POD:978-1-4799-4600-6","10.1109/ICSTCC.2014.6982404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982404","business intelligence;eureka;information retrieval;semantic search engine","Crawlers;Databases;Engines;Ontologies;Resource description framework;Search engines;Semantics","business data processing;competitive intelligence;computational linguistics;search engines;semantic Web;software architecture;workflow management software","European funded project;Questor;business intelligence tools;business processes;decision makers;enterprise reporting tools;large enterprises;natural language;report management workflow;semantic report search engine;software architecture","","0","","14","","","17-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"A novel approach to personalize web search through user profiling and query reformulation","K. Makvana; P. Shah; P. Shah","Information Technology, Charusat University, Changa, India","2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)","20141113","2014","","","1","10","With a inundating of information in WWW (World Wide Web) users are often failed to retrieve search result in context of their interest through existing search engines. So the personalization of web search result has to be carryout that process user's query and re-rank retrieved results based on their interest. User have diverse background on same query, it is very difficult for some informative query to identify user's current intention. In this paper, a novel approach is proposed that personalize web search result through query reformulation and user profiling. First, a framework is proposed that identify relevant search term for particular user from previous search history by analysing web log file maintained in the server. These terms are appended to user's ambiguous query. Second, the proposed approach proceeds the user's search result and re-rank the retrieved result by identifying interest value of user on retrieved links. Proposed new approach also identify user interest on retrieved links by combing the user interest value generated from VSM (Vector Space Model) and actual rank of that link. Third, the framework also suggest some keywords that help to incorporate user's current interest. Finally, experimental result shows the effectiveness of proposed search engine with commercial search engine with different criteria.","","Electronic:978-1-4799-4674-7; POD:978-1-4799-4673-0","10.1109/ICDMIC.2014.6954221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954221","Information Retrieval;Personalized Web search;Re-Ranking Algorithm;Semantic Web Mining;User Profiling","Context;Google;History;Knowledge based systems;Search engines;Vectors;Web search","Internet;query processing;search engines;vectors","VSM;WWW users;Web log file;Web search personalization;Web server;World Wide Web;ambiguous query;query reformulation;relevant search term;search engines;user interest value;user profiling;vector space model","","1","","21","","","5-6 Sept. 2014","","IEEE","IEEE Conference Publications"
"A distributed multi-tasking job scheduling mechanism for web crawlers","C. H. Tsai; T. Ku; P. Y. Yang; M. J. Chen","Institute for Information Industry, Innovative DigiTech-Enabled Applications & Service Institute, Taipei, Taiwan, R.O.C.","2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR)","20150115","2014","","","243","248","Recently, the prosperity of social network nourished web services such as virtual community and web community. With the readily available social networking sites and the accessible internet, the interaction between people has become much frequently than before. Therefore, this research aims to provide assist to social networking sites by collecting and analyzing the enormous data on these sites. Currently there are many scholars putting effort on the research of data collection. We focus on the difficulties and challenges which web crawlers will encounterduring data collection and improve the mechanism proposed in [6]. In this paper, we will look deep in to the blocking of social networking sites and the derivative problem of idle web crawlers.","","Electronic:978-1-4799-5934-1; POD:978-1-4799-5935-8","10.1109/SOCPAR.2014.7008013","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7008013","Crawler Manager;Distributed Web Crawlers;Information Retrieval;Social Network;Web Ming","Crawlers;Data collection;Distributed databases;Schedules;Service-oriented architecture;Social network services;Uniform resource locators","Web services;scheduling;social networking (online)","Internet;Web Crawlers;Web community;Web services;distributed multitasking job scheduling mechanism;social networking sites","","0","","9","","","11-14 Aug. 2014","","IEEE","IEEE Conference Publications"
"Finding pages on the unarchived Web","H. C. Huurdeman; A. Ben-David; J. Kamps; T. Samar; A. P. de Vries","University of Amsterdam, The Netherlands","IEEE/ACM Joint Conference on Digital Libraries","20141204","2014","","","331","340","Web archives preserve the fast changing Web, yet are highly incomplete due to crawling restrictions, crawling depth and frequency, or restrictive selection policies-most of the Web is unarchived and therefore lost to posterity. In this paper, we propose an approach to recover significant parts of the unarchived Web, by reconstructing descriptions of these pages based on links and anchors in the set of crawled pages, and experiment with this approach on the DutchWeb archive. Our main findings are threefold. First, the crawled Web contains evidence of a remarkable number of unarchived pages and websites, potentially dramatically increasing the coverage of the Web archive. Second, the link and anchor descriptions have a highly skewed distribution: popular pages such as home pages have more terms, but the richness tapers off quickly. Third, the succinct representation is generally rich enough to uniquely identify pages on the unarchived Web: in a known-item search setting we can retrieve these pages within the first ranks on average.","","Electronic:978-1-4799-5569-5; POD:978-1-4799-5570-1","10.1109/JCDL.2014.6970188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6970188","Anchor text;Information retrieval;Link evidence;Web archives;Web archiving;Web crawlers","Context;Crawlers;Cultural differences;Internet;Libraries;Materials;Uniform resource locators","Web sites;information retrieval;search engines","DutchWeb archive;Web archives;Web sites;anchor descriptions;crawling depth;crawling restrictions;known-item search setting;page retrieval;restrictive selection policies;skewed distribution","","2","","28","","","8-12 Sept. 2014","","IEEE","IEEE Conference Publications"
"A Cognitive Query Model for Arabic based on probabilistic associative morpho-phonetic Sub-Networks","B. Haddad; N. El-Khalili; M. Hattab","Department of Computer Science, University of Petra, Amman, Jordan, P.O.BOX 3034, 11181","2014 5th IEEE Conference on Cognitive Infocommunications (CogInfoCom)","20150126","2014","","","25","29","This paper is discussing some novel aspects related to formalizing a Cognitive Query Model for Arabic based on constructing query associative morpho-phonetic Sub-Networks in the context of Arabic query analysis and expansion. As Humans tend to use limited number of words with possibly incomplete and ambiguous representation for requesting information, predicting the intended information conveyed in a query keywords might affect an inter-cognitive communication dramatically. Based on Associative Probabilistic Bi-directional Root-Pattern Relations introduced in APRoPAT Statistical Language Model, a cognitively motivated representation for query semantic network construction is proposed. This Model attempts to predicting the most plausible intended query information by constructing a morpho-phonetic cognitive Sub-Network based on the query terms and instantiation of the most probable query root-pattern phonetic vectors within the global Associative Network expressed by the APRoPAT Model.","","Electronic:978-1-4799-7280-7; POD:978-1-4799-7281-4; USB:978-1-4799-7279-1","10.1109/CogInfoCom.2014.7020463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020463","APRoPAT Model;Arabic Natural Language Processing;Cognitive Linguistics;Information Retrieval;Inter-Cognitive Communication;Morpho-Phonetic Network;Probabilistic Root-Pattern Relationship;Query Analysis;Query Expansion;Statistical Language Model","Analytical models;Bidirectional control;Computational modeling;Information retrieval;Probabilistic logic;Semantics;Vectors","cognition;natural language processing;probability;query processing;speech processing","APRoPAT statistical language model;Arabic query analysis;Arabic query expansion;associative morpho-phonetic sub-networks;associative probabilistic bi-directional root-pattern relations;cognitive query model;inter-cognitive communication;probabilistic associative morpho-phonetic sub-networks;query keywords;query semantic network construction;query terms","","0","","22","","","5-7 Nov. 2014","","IEEE","IEEE Conference Publications"
"Optimizing Instance Selection for Statistical Machine Translation with Feature Decay Algorithms","E. Biçici; D. Yuret","Ko&#x00E7; University, Istanbul, Turkey","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150115","2015","23","2","339","350","We introduce FDA5 for efficient parameterization, optimization, and implementation of feature decay algorithms (FDA), a class of instance selection algorithms that use feature decay. FDA increase the diversity of the selected training set by devaluing features (i.e., n-grams) that have already been included. FDA5 decides which instances to select based on three functions used for initializing and decaying feature values and scaling sentence scores controlled with five parameters. We present optimization techniques that allow FDA5 to adapt these functions to in-domain and out-of-domain translation tasks for different language pairs. In a transductive learning setting, selection of training instances relevant to the test set can improve the final translation quality. In machine translation experiments performed on the 2 million sentence English-German section of the Europarl corpus, we show that a subset of the training set selected by FDA5 can gain up to 3.22 BLEU points compared to a randomly selected subset of the same size, can gain up to 0.41 BLEU points compared to using all of the available training data using only 15% of it, and can reach within 0.5 BLEU points to the full training set result by using only 2.7% of the full training data. FDA5 peaks at around 8M words or 15% of the full training set. In an active learning setting, FDA5 minimizes the human effort by identifying the most informative sentences for translation and FDA gains up to 0.45 BLEU points using 3/5 of the available training data compared to using all of it and 1.12 BLEU points compared to random training set. In translation tasks involving English and Turkish, a morphologically rich language, FDA5 can gain up to 11.52 BLEU points compared to a randomly selected subset of the same size, can achieve the same BLEU score using as little as 4% of the data compared to random instance selection, and can exceed the full dataset result by 0.78 BLEU points. FDA5 is able to reduce the time to build a- statistical machine translation system to about half with 1M words using only 3% of the space for the phrase table and 8% of the overall space when compared with a baseline system using all of the training data available yet still obtain only 0.58 BLEU points difference with the baseline system in out-of-domain translation.","2329-9290;23299290","","10.1109/TASLP.2014.2381882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987314","Domain adaptation;information retrieval;instance selection;machine translation;transductive learning","Adaptation models;IEEE transactions;Optimization;Speech;Speech processing;Training;Training data","feature extraction;language translation;natural language processing;random processes","BLEU points;English-German section;Europarl corpus;FDA5;active learning setting;decaying feature values;feature decay algorithms;in-domain translation tasks;language pairs;machine translation experiments;out-of-domain translation tasks;random training set;sentence scores;statistical machine translation system;training data;training instance selection algorithms;transductive learning setting","","2","","","","20141218","Feb. 2015","","IEEE","IEEE Journals & Magazines"
"Comparison of two classification methods for Musical Instrument identification","Y. Takahashi; K. Kondo","Graduate School of Science and Engineering, Yamagata University, Japan","2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)","20150205","2014","","","67","68","In this paper, we compared the Linear Discriminant Analysis (LDA) with Random Forest (RF) for musical instrument identification from clips with a mixture of instruments. As the first step, monotone samples from the Musical Instrument Samples (Univ. Iowa) and RWC Music Database were used to identify the individual instruments. For the Iowa monotones, an overall instrument recognition rate of 24.8% and 82.1% was obtained using LDA and RF, respectively. However, the rate degrades to 54.9% on the RWC monotones even with RF, most likely due to insufficient number of features to cover the increase in variability of this large database.","2378-8143;23788143","Electronic:978-1-4799-5145-1; POD:978-1-4799-5146-8","10.1109/GCCE.2014.7031196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031196","Classification;Linear Discriminant Analysis;Random Forest;music information retrieval","Brightness;Feature extraction;Instruments;Radio frequency;Vegetation","information retrieval;music;musical instruments;pattern classification;statistical analysis","LDA;RF;RWC music database;classification methods;instrument recognition rate;linear discriminant analysis;monotone samples;music information retrieval;musical instrument identification;musical instrument samples;random forest","","0","","4","","","7-10 Oct. 2014","","IEEE","IEEE Conference Publications"
"Comparative analysis of Web 3.0 search engines: A survey report","R. Aravindhan; R. Shanmugalakshmi","Dept. of Computer Science and Engineering Sri Eshwar College of Engineering Coimbatore, Tamilnadu, India","2013 International Conference on Advanced Computing and Communication Systems","20141030","2013","","","1","6","The amount of information accumulated in the internet through myriad number of databases is massive. The information is searched in the internet with specialized tools known as search engine. A search engine can be viewed as a simple software program that searches for the needed information based on the keywords which the users have typed in. Usually these search and retrieval are based on syntactic analysis(Web 2.0) of keyword, but if these searches and retrieval are based on content analysis, a more meaningful result will be returned to the users. The Semantic Web (Web 3.0) is an extension of the current web in which keyword is given a well-defined meaning. Apart from that another advantage of Semantic Web is its user interface. A large number of Semantic Web search engines have emerged recently which are based on different design principles and provides different levels of support for users and/or applications. However, in spite of the benefits provided by these widely available intuition based search engine, users are reluctant in shifting towards this these sophisticated search engines. In this paper, a survey is done about the semantic search engines to reveal the promising features of the semantic search engines (SSE) and the reason behind the reluctance of the users in adopting these sophisticated search engines.","","Electronic:978-1-4799-3506-2; POD:978-1-4799-3507-9","10.1109/ICACCS.2013.6938715","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6938715","Information Retrieval;Semantic Search Engines;Semantic Web;Web 3.0;Web Crawling","Computers;Engines;Indexes;Ontologies;Search engines;Semantic Web;Semantics","content-based retrieval;search engines;semantic Web","Internet;Web 2.0;Web 3.0 search engines;content analysis;keyword syntactic analysis;keyword-based search;semantic Web search engines","","0","","16","","","19-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Wafer Map Failure Pattern Recognition and Similarity Ranking for Large-Scale Data Sets","M. J. Wu; J. S. R. Jang; J. L. Chen","Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan","IEEE Transactions on Semiconductor Manufacturing","20150130","2015","28","1","1","12","Wafer maps can exhibit specific failure patterns that provide crucial details for assisting engineers in identifying the cause of wafer pattern failures. Conventional approaches of wafer map failure pattern recognition (WMFPR) and wafer map similarity ranking (WMSR) generally involve applying raw wafer map data (i.e., without performing feature extraction). However, because increasingly more sensor data are analyzed during semiconductor fabrication, currently used approaches can be inadequate in processing large-scale data sets. Therefore, a set of novel rotation- and scale-invariant features is proposed for obtaining a reduced representation of wafer maps. Such features are crucial when employing WMFPR and WMSR to analyze large-scale data sets. To validate the performance of the proposed system, the world's largest publicly accessible data set of wafer maps was built, comprising 811 457 real-world wafer maps. The experimental results show that the proposed features and overall system can process large-scale data sets effectively and efficiently, thereby meeting the requirements of current semiconductor fabrication.","0894-6507;08946507","","10.1109/TSM.2014.2364237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6932449","Data models;data models;image recognition;information retrieval;pattern recognition;semiconductor defects","Fabrication;Feature extraction;Pattern recognition;Semiconductor device modeling;Support vector machines;Transforms","failure analysis;feature extraction;image recognition;large-scale systems;pattern recognition;semiconductor device manufacture","WMFPR;WMSR;large-scale data sets;rotation invariant features;scale invariant features;semiconductor fabrication;sensor data;wafer map data;wafer map failure pattern recognition;wafer map similarity ranking","","2","","30","","20141021","Feb. 2015","","IEEE","IEEE Journals & Magazines"
"Finding effective query strings from results of primary search","R. Teshima; M. Okabe; K. Umemura","Department of Computer Science and Engineering Toyohashi University of Technology Toyohashi, Japan","2014 International Conference of Advanced Informatics: Concept, Theory and Application (ICAICTA)","20150112","2014","","","305","308","This paper proposes a method to find query strings suitable for successive searches from primary search results. This method may be regarded as a novel kind of keyword extraction for information retrieval, where these strings are extracted from primary search results. These strings are selected depending on the following conditions: effectiveness, prevalence, and uniqueness. In addition, this method does not use any kind of dictionary, not even a Japanese morphological analyzer. The proposed procedure consists of two parts. The first part is selecting the first candidates, which are all of the keywords in primary search results. The second part is narrowing down the candidates so that the candidates form reasonable cluster of primary search results. Our main concern is whether the selected string is meaningful or understandable for people. We have found that more than 90% of the strings that satisfy the conditions above are meaningful and correct Japanese words.","","Electronic:978-1-4799-5100-0; POD:978-1-4799-5101-7","10.1109/ICAICTA.2014.7005959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7005959","information retrieval;keyword extraction","Actuators;Computers;Data mining;Dictionaries;Informatics;Robot sensing systems","pattern clustering;query processing;text analysis;word processing","information retrieval;keyword extraction;primary search results;query string finding;search results cluster","","0","","10","","","20-21 Aug. 2014","","IEEE","IEEE Conference Publications"
"Predicting Effectiveness of IR-Based Bug Localization Techniques","T. D. B. Le; F. Thung; D. Lo","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore","2014 IEEE 25th International Symposium on Software Reliability Engineering","20141215","2014","","","335","345","Recently, many information retrieval (IR) based bug localization approaches have been proposed in the literature. These approaches use information retrieval techniques to process a textual bug report and a collection of source code files to find buggy files. They output a ranked list of files sorted by their likelihood to contain the bug. Recent approaches can achieve reasonable accuracy, however, even a state-of-the-art bug localization tool outputs many ranked lists where buggy files appear very low in the lists. This potentially causes developers to distrust bug localization tools. Parnin and Orso recently conduct a user study and highlight that developers do not find an automated debugging tool useful if they do not find the root cause of a bug early in a ranked list. To address this problem, we build an oracle that can automatically predict whether a ranked list produced by an IR-based bug localization tool is likely to be effective or not. We consider a ranked list to be effective if a buggy file appears in the top-N position of the list. If a ranked list is unlikely to be effective, developers do not need to waste time in checking the recommended files one by one. In such cases, it is better for developers to use traditional debugging methods or request for further information to localize bugs. To build this oracle, our approach extracts features that can be divided into four categories: score features, textual features, topic model features, and metadata features. We build a separate prediction model for each category, and combine them to create a composite prediction model which is used as the oracle. We name our proposed approach APRILE, which stands for Automated Prediction of IR-based Bug Localization's Effectiveness. We have evaluated APRILE to predict the effectiveness of three state-of-the-art IR based bug localization tools on more than three thousands bug reports from AspectJ, Eclipse, and SWT. APRILE can achieve an average precision, recall, and - -measure of at least 70.36%, 66.94%, and 68.03%, respectively. Furthermore, APRILE outperforms a baseline approach by 84.48%, 17.74%, and 31.56% for the AspectJ, Eclipse, and SWT bug reports, respectively.","1071-9458;10719458","Electronic:978-1-4799-6033-0; POD:978-1-4799-6034-7","10.1109/ISSRE.2014.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6982639","Bug Localization;Bug Reports;Effectiveness Prediction;Information Retrieval;Text Classification","Computational modeling;Computer bugs;Debugging;Feature extraction;Predictive models;Support vector machines;Training","feature extraction;information retrieval;meta data;program debugging;source code (software)","APRILE;AspectJ;Eclipse;IR-based bug localization techniques;SWT;automated debugging tool;automated prediction of IR-based bug localization effectiveness;bug localization tool;buggy files;composite prediction model;feature extraction;information retrieval based bug localization approach;information retrieval techniques;metadata features;recommended files;score features;source code files;textual bug report;textual features;topic model features;traditional debugging method","","5","","39","","","3-6 Nov. 2014","","IEEE","IEEE Conference Publications"
"Association mining of search tags in PubMed search sessions","A. S. M. Mosa; I. Yoo","Informatics Institute, University of Missouri, Columbia, MO, USA","2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","20150115","2014","","","56","61","Background: Previous studies have shown that use of search tags in PubMed can significantly improve the performance of information retrieval. The objective of this study was to discover associations among search tags in typical PubMed search sessions. Methods: We performed session segmentation on a full-day PubMed query log, identified the search tags within those sessions, and applied association mining to identify strong associations of search tags. Results: A total of eight maximal frequent-itemsets (i.e. search tags) and 34 strong association rules from these itemsets were discovered. We also estimated that the query refinement occurs frequently (i.e. one query per minute on average) for any session length. Conclusions: The association rules consisting of PubMed search tags can be used to develop an interactive and intelligent PubMed search interface so that the users can build the search query using proper search tags and reduce the frequency of query refinement.","","Electronic:978-1-4799-5669-2; POD:978-1-4799-5670-8","10.1109/BIBM.2014.6999268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6999268","PubMed;association mining;information retrieval;query log;search session;search tag","Association rules;Educational institutions;Itemsets;Navigation;Search problems;Visualization","data mining;interactive systems;medical information systems;query processing;user interfaces","PubMed query log;PubMed search sessions;PubMed search tags;association mining;association rules;information retrieval;intelligent PubMed search interface;interactive PubMed search interface;maximal frequent-itemsets;query refinement;session segmentation","","0","","19","","","2-5 Nov. 2014","","IEEE","IEEE Conference Publications"
"Keywords extraction for automatic indexing of e-learning resources","M. Hendez; H. Achour","High Institute of Management, University of Tunis, Tunisia","2014 World Symposium on Computer Applications & Research (WSCAR)","20141007","2014","","","1","5","With the growing use of various educational web applications such as e-Learning platforms, learning portals, learning object repositories, ... as well as the increasing setting on line of learning resources, it becomes essential to index these resources in order to facilitate their searching and retrieving. In this paper, we address the problem of automatic indexing of online educational resources and we propose an approach to help the indexing operation. This approach consists in automatically extracting a set of relevant terms describing the educational content of a resource. The proposed approach is based on the TF-IDF algorithm, the usage of a domain lexicon and exploits the structure of educational documents.","","Electronic:978-1-4799-2806-4; POD:978-1-4799-2807-1","10.1109/WSCAR.2014.6916796","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916796","automatic indexation;e-Learning;information retrieval;key words extraction;learning resources","Conferences;Manuals;Programming profession;Standardization","computer aided instruction;indexing;text analysis","TFIDF algorithm;automatic indexing;domain lexicon;e-learning resources;educational content;educational documents;keywords extraction;online educational resources;term frequency inverse document frequency","","0","","11","","","18-20 Jan. 2014","","IEEE","IEEE Conference Publications"
"An ontology-based framework for Semantic Web Content Mining","S. Yasodha; S. S. Dhenakaran","Comp. Science, Govt. Arts College(W), Pudukkottai, Tamilnadu, India","2014 International Conference on Computer Communication and Informatics","20141016","2014","","","1","6","The voluminous amount of information available in the Web makes information retrieval a challenging task. Most of the surfers' time is wasted in following different links ranked by search engines. Moreover, manual integration of information available in different Web pages is difficult and inefficient. So, to ease the process of information retrieval and to provide the surfer with more relevant information, Semantic Web could be employed. The metadata information available in the Semantic Web in the form of ontology helps in the retrieval of relevant information. In this paper, an Ontology-Based framework for Semantic Web Content Mining has been proposed. This framework is a semi-automatic process which suits many application domain like Education, Medicine and Tourism. The proposed framework is implemented in JAVA and ontology engineering is done using the ontology language, RDF (Resource Description Framework). The screen shots are designed using Net Beans IDE. The efficiency of the framework is measured in terms of precision, average precision and relevance score.","","Electronic:978-1-4799-2352-6; POD:978-1-4799-2354-0","10.1109/ICCCI.2014.6921722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6921722","(RDF) Resource Description Framework;Information retrieval;Ontology;Semantic Web","Education;Informatics;Ontologies;Resource description framework;Web pages","Java;Web sites;data mining;meta data;ontologies (artificial intelligence);relevance feedback;search engines;semantic Web","JAVA;Net Beans IDE;RDF;Web information;Web pages;average precision;information retrieval;manual information integration;metadata information;ontology engineering;ontology language;ontology-based framework;relevance score;resource description framework;search engines;semantic Web content mining;semiautomatic process","","0","","16","","","3-5 Jan. 2014","","IEEE","IEEE Conference Publications"
