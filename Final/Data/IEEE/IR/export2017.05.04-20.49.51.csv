"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5645620,6018284,6035720,6103321,6102496,6100061,4021215,4021200,6100115,6100087,4021217,6088095,6093406,6093389,6088106,6083684,6079228,6025339,5999640,6062072,5582093,6047862,5611525,5728810,5611524,5601720,5710919,5620910,5989812,5735235,6045028,6041894,6032550,6032603,6040523,6032585,6032276,6021760,6019811,6014600,6015771,6008386,6006139,6005197,6002145,5995822,5984790,5977684,5977391,5974906,5974767,5967193,5963993,5966451,5959620,5948854,5945092,5948707,5946098,5946084,5946366,5936291,5929728,5888663,5888636,5876205,5882549,5873367,5873388,5873320,5777620,5768201,5768286,5767725,5229196,5475251,5763445,5763955,5438994,5754299,5482570,5374367,5724930,5723876,5416669,5720715,5720061,5719959,5716753,5716722,5718485,5714379,5713094,5708977,5701827,5698108,5689956,5688547,5690335,5487525",2017/05/04 20:49:51
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An improved method in clustering Web retrieval result based on relevance feedback","Xinye Li","Department of Electronic and Communication Engineering, North China Electric Power University, Baoding, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","3000","3003","Since the number of Web retrieval result is very large, the performance and reasonableness of clustering Web retrieval result are important. Existed methods cost much time while clustering all retrieval result and there were many unrelated document in their clustering result. To avoid the disadvantage, this paper proposed an improved k-means algorithm by using a few of related and unrelated feedback to guide clustering Web retrieval result. The improved algorithm first selected initial cluster metroid based on feedback messages, then during the clustering process, it removed large unrelated documents which increased the clustering speed and optimized the clustering result. During the clustering process, the metroids of clusters including unrelated documents needn't be modified in order to avoid noise influence. Experiment result illustrate that our algorithm is superior to the traditional k-means algorithm.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5974767","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974767","Web retrieval result;clustering;improved k-means algorithm;relevance feedback","Clustering algorithms;Computers;Information retrieval;Medical services;Ontologies;Proposals;Research and development","Internet;pattern clustering;relevance feedback","Web retrieval clustering;cluster metroid;feedback messages;k-means algorithm;relevance feedback;unrelated document;unrelated feedback","","0","","11","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Empirical Study of Chinese Text Similarity Computation Based on Machine Translation","Y. Xu; J. Liu; M. Tang; Y. Wen","Dept. of Comput. Sci. & Eng., Hunan Univ. of Sci. & Technol., Xiangtan, China","2011 Seventh International Conference on Semantics, Knowledge and Grids","20111201","2011","","","156","159","For the problems of Chinese text similarity calculation based on word frequency statistics, this paper proposed a method by using machine translation to translate Chinese text into English text, indirectly calculate similarity of given texts. This method can avoid some shortcomings of Chinese word segmentation and utilize the advantages of the natural word segmentation of English, and also can use machine translation to indirectly take the semantics of part of words into account. The experiments compared it with the way of directly using Chinese, and a detailed analysis was performed. Experiments show that this method can improve most of social texts' similarity computation as well as increase the accuracy of the computation as a whole.","","Electronic:978-0-7695-4515-8; POD:978-1-4577-1323-1","10.1109/SKG.2011.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088106","Chinese Word Segmentation;Machine Translation;Text Similarity;Word frequency statistics","Computational modeling;Computers;Google;Information processing;Information retrieval;Semantics;Vectors","language translation;natural language processing;statistical analysis;text analysis;word processing","Chinese text similarity computation;Chinese text translation;Chinese word segmentation;English text;machine translation;natural word segmentation;word frequency statistics","","0","","12","","","24-26 Oct. 2011","","IEEE","IEEE Conference Publications"
"Performance prediction using Kernel Canonical Correlation Analysis","S. Nedevschi; I. R. Peter; A. Mandrut","Technical University of Cluj-Napoca, Faculty of Automation and Computer Science, 28, Gh. Baritiu St., 400027, ROMANIA","2011 IEEE 7th International Conference on Intelligent Computer Communication and Processing","20111020","2011","","","157","162","The paper deals with the problem of anticipating performance parameters for running SPARQL queries. Canonical correlation analysis (CCA) and its kernel variant (KCCA) identify and quantify the associations between two sets of variables. It maximizes the correlation between a linear combination of the variables in one set and a linear combination of the variables in the other set. It measures the strength of association between two sets of variables. The main aspect of this maximization problem is to keep a high dimensional relationship between two sets of variables into few pairs of canonical variables.","","Electronic:978-1-4577-1481-8; POD:978-1-4577-1479-5","10.1109/ICCP.2011.6047862","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6047862","","Correlation;Databases;Feature extraction;Information retrieval;Kernel;Ontologies;Yttrium","correlation methods;optimisation;query processing","SPARQL queries;kernel canonical correlation analysis;linear variable combination;maximization problem","","0","","7","","","25-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Keyword Retrieval Technology Research of XML Document","J. x. Zhang; X. Sun","Dept. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China","2011 3rd International Workshop on Intelligent Systems and Applications","20110613","2011","","","1","3","At present many commercial database using Xpath and XQuery as XML retrieval standard, grammar about XPath and XQuery is complicated , it is difficult for general user to use. In this paper, the research work is focused on the keyword retrieval technology of XML document, designs a XML full-text information retrieval similar to HTML full-text information retrieval,proposes inverted-file retrieval method based on the Deweycoding, designs a SLCA retrieval algorithm about multi-keyword.","","Electronic:978-1-4244-9857-4; POD:978-1-4244-9855-0","10.1109/ISA.2011.5873367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5873367","","Algorithm design and analysis;Books;Indexes;Information retrieval;Sorting;XML","XML;database management systems;encoding;information retrieval;text analysis","Deweycoding;SLCA retrieval algorithm;XML document;XML full text information retrieval;XQuery;Xpath;commercial database;inverted file retrieval method;keyword retrieval technology","","0","","5","","","28-29 May 2011","","IEEE","IEEE Conference Publications"
"A discriminative model approach for accurate duplicate bug report retrieval","C. Sun; D. Lo; X. Wang; J. Jiang; S. C. Khoo","National University of Singapore","2010 ACM/IEEE 32nd International Conference on Software Engineering","20111027","2010","1","","45","54","Bug repositories are usually maintained in software projects. Testers or users submit bug reports to identify various issues with systems. Sometimes two or more bug reports correspond to the same defect. To address the problem with duplicate bug reports, a person called a triager needs to manually label these bug reports as duplicates, and link them to their ""master"" reports for subsequent maintenance work. However, in practice there are considerable duplicate bug reports sent daily; requesting triagers to manually label these bugs could be highly time consuming. To address this issue, recently, several techniques have be proposed using various similarity based metrics to detect candidate duplicate bug reports for manual verification. Automating triaging has been proved challenging as two reports of the same bug could be written in various ways. There is still much room for improvement in terms of accuracy of duplicate detection process. In this paper, we leverage recent advances on using discriminative models for information retrieval to detect duplicate bug reports more accurately. We have validated our approach on three large software bug repositories from Firefox, Eclipse, and OpenOffice. We show that our technique could result in 17-31%, 22-26%, and 35-43% relative improvement over state-of-the-art techniques in OpenOffice, Firefox, and Eclipse datasets respectively using commonly available natural language information only.","0270-5257;02705257","Electronic:978-1-60558-719-6; POD:978-1-60558-719-6","10.1145/1806799.1806811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6062072","","Feature extraction;Fires;Information retrieval;Software;Support vector machines;Training;Vectors","information retrieval;program debugging","Eclipse;Firefox;OpenOffice;bug report retrieval;discriminative model approach;information retrieval;natural language information;software bug repositories;software projects","","58","","22","","","2-8 May 2010","","IEEE","IEEE Conference Publications"
"Improving source code search with natural language phrasal representations of method signatures","E. Hill; L. Pollock; K. Vijay-Shanker","Deptartment of Computer Science, Montclair State University, NJ 07043, USA","2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)","20111212","2011","","","524","527","As software continues to grow, locating code for maintenance tasks becomes increasingly difficult. Software search tools help developers find source code relevant to their maintenance tasks. One major challenge to successful search tools is locating relevant code when the user's query contains words with multiple meanings or words that occur frequently throughout the program. Traditional search techniques, which treat each word individually, are unable to distinguish relevant and irrelevant methods under these conditions. In this paper, we present a novel search technique that uses information such as the position of the query word and its semantic role to calculate relevance. Our evaluation shows that this approach is more consistently effective than three other state of the art search techniques.","1938-4300;19384300","Electronic:978-1-4577-1639-3; POD:978-1-4577-1638-6","10.1109/ASE.2011.6100115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100115","code search;concern location;software maintenance","Equations;Head;Information retrieval;Mathematical model;Natural languages;Semantics;Software","natural languages;query processing;software maintenance;software tools;source coding","maintenance tasks;method signatures;natural language phrasal representations;query word;search techniques;software search tools;source code search improvement","","15","","8","","","6-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Reengineering legacy software products into software product line based on automatic variability analysis","Y. Xue","Sch. of Comput., Nat. Univ. of Singapore, Singapore, Singapore","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","1114","1117","In order to deliver the various and short time-to-market software products to customers, the paradigm of Software Product Line (SPL) represents a new endeavor to the software development. To migrate a family of legacy software products into SPL for effective reuse, one has to understand commonality and variability among existing products variants. The existing techniques rely on manual identification and modeling of variability, and the analysis based on those techniques is performed at several mutually independent levels of abstraction. We propose a sandwich approach that consolidates feature knowledge from top-down domain analysis with bottom-up analysis of code similarities in subject software products. Our proposed method integrates model differencing, clone detection, and information retrieval techniques, which can provide a systematic means to reengineer the legacy software products into SPL based on automatic variability analysis.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1986009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032603","legacy software;spl;variability analysis","Cloning;Cognition;Feature extraction;Information retrieval;Java;Semantics;Software","software reusability;systems re-engineering","automatic variability analysis;bottom-up domain analysis;clone detection technique;information retrieval technique;legacy software product reengineering;model differencing technique;sandwich approach;software development;software product line;software reuse;time-to-market software product;top-down domain analysis","","2","","23","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"Semantic query with stemmer for Quran documents results","M. A. Yunus; R. Zainuddin; N. Abdullah","Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia","2010 IEEE Conference on Open Systems (ICOS 2010)","20110224","2010","","","40","44","The query-based on the result is lack of limited relevant documents in retrieval results. Therefore, query performance is considered to retrieve more relevant documents across language boundaries by applying semantic and stemmers which are more significant as stemming semantic query (SSQ). Therefore, this study is conducted with the purposes to investigate the integration semantic and stemmers approach against the queries and vice versa. Furthermore, it is also conducted to investigate the performance query based on total retrieve and relevant. The retrieval however, included the irrelevant documents because of the translation polysemy. Results from the experiments suggest that SSQ is most important process in cross language information retrieval (CLIR). It also found that semantic approach with stemmers contributes to better performance in retrieving more relevant and related Quran document results.","","Electronic:978-1-4244-9192-6; POD:978-1-4244-9193-3","10.1109/ICOS.2010.5720061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720061","query;semantic;speech;stemming","Dictionaries;Information retrieval;Ontologies;Query processing;Semantic Web;Semantics;Web services","document handling;query processing","CLIR;Quran documents results;SSQ;cross language information retrieval;language boundaries;query performance;semantic query;stemming semantic query","","1","","30","","","5-7 Dec. 2010","","IEEE","IEEE Conference Publications"
"Adaptive Cluster Distance Bounding for High-Dimensional Indexing","S. Ramaswamy; K. Rose","Mayachitra Inc., Santa Barbara","IEEE Transactions on Knowledge and Data Engineering","20110421","2011","23","6","815","830","We consider approaches for similarity search in correlated, high-dimensional data sets, which are derived within a clustering framework. We note that indexing by “vector approximation” (VA-File), which was proposed as a technique to combat the “Curse of Dimensionality,” employs scalar quantization, and hence necessarily ignores dependencies across dimensions, which represents a source of suboptimality. Clustering, on the other hand, exploits interdimensional correlations and is thus a more compact representation of the data set. However, existing methods to prune irrelevant clusters are based on bounding hyperspheres and/or bounding rectangles, whose lack of tightness compromises their efficiency in exact nearest neighbor search. We propose a new cluster-adaptive distance bound based on separating hyperplane boundaries of Voronoi clusters to complement our cluster based index. This bound enables efficient spatial filtering, with a relatively small preprocessing storage overhead and is applicable to euclidean and Mahalanobis similarity measures. Experiments in exact nearest-neighbor set retrieval, conducted on real data sets, show that our indexing method is scalable with data set size and data dimensionality and outperforms several recently proposed indexes. Relative to the VA-File, over a wide range of quantization resolutions, it is able to reduce random IO accesses, given (roughly) the same amount of sequential IO operations, by factors reaching 100X and more.","1041-4347;10414347","","10.1109/TKDE.2010.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5438994","Multimedia databases;clustering;image databases.;indexing methods;similarity measures","Image databases;Image retrieval;Indexing;Information retrieval;Information systems;Multimedia databases;Nearest neighbor searches;Optical signal processing;Quantization;Space technology","indexing;pattern clustering","Mahalanobis similarity measurement;adaptive cluster distance bounding;cluster adaptive distance;clustering framework;high dimensional indexing;scalar quantization;vector approximation","","9","1","36","","20100325","June 2011","","IEEE","IEEE Journals & Magazines"
"A transformation from a singing voice to complex network using correlation coefficients of audio signals","Q. Yang; Q. Gao; R. Fan","Automation Department, Beijing Institute of Technology","2011 2nd International Conference on Intelligent Control and Information Processing","20110901","2011","2","","929","930","This paper describes a method that transforms audio signal from sing voice into complex network. First, we construct complex networks from audio signal, with each frame represented by a single node in the network. We investigate the statistical properties of these networks for different music and find that different music has very similar statistical properties. Therefore standard measures of structure in complex networks cannot be applied to distinguish different music.","","DVD:978-1-4577-0815-2; Electronic:978-1-4577-0816-9; POD:978-1-4577-0813-8","10.1109/ICICIP.2011.6008386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6008386","","Automation;Complex networks;Correlation;Fitting;Music information retrieval;Probability;Time series analysis","audio signal processing;correlation methods;signal representation","audio signals;complex network;correlation coefficients;frame representation;singing voice;single node;statistical properties","","0","","4","","","25-28 July 2011","","IEEE","IEEE Conference Publications"
"Jigsaw to save vastopolis","E. Braunstein; C. Görg; Z. Liu; J. Stasko","Mercyhurst College, USA","2011 IEEE Conference on Visual Analytics Science and Technology (VAST)","20111215","2011","","","325","326","This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw's computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.","","Electronic:978-1-4673-0014-8; POD:978-1-4673-0015-5","10.1109/VAST.2011.6102496","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6102496","Visual analytics;data ingestion;evidence marshalling;information visualization;investigative analysis","Data visualization;Electronic mail;Information retrieval;Manuals;Organizations;Text analysis;Visualization","data analysis;data visualisation;document handling","Jigsaw computational analysis capability;Jigsaw system;Jigsaw visualizations;VAST 2011 Mini Challenge 3;Vastopolis;documents","","0","","3","","","23-28 Oct. 2011","","IEEE","IEEE Conference Publications"
"Naïveté Squared: In Search of Two Taxonomies and a Mapping between Them","R. L. Glass; I. Vessey","Griffith Univ., Brisbane, QLD, Australia","IEEE Software","20110818","2011","28","5","14","15","The authors describe an issue that they think is extremely important: the relationship between applications and solutions in the software engineering and information systems fields. In particular, they believe the fields desperately need a taxonomy of application domains, a taxonomy of solution approaches, and a mapping between the two. This article has a Web extra that offers an interview with one of the article's authors, Robert L. Glass, about the ""dark side"" of this topic.","0740-7459;07407459","","10.1109/MS.2011.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984790","application domains;software solutions;taxonomy","Computer applications;Industry applications;Information retrieval;Information services;Information systems;Software development;Software engineering;Taxonomy","information systems;software engineering","information systems fields;software engineering;taxonomies","","0","2","","","","Sept.-Oct. 2011","","IEEE","IEEE Journals & Magazines"
"Research on the Chinese text retrieval method using context","J. Liu; H. Zhou","Computer Engineering Faculty, Huaiyin Institute of Technology, Huaian, China","The 2nd International Conference on Information Science and Engineering","20110117","2010","","","1475","1478","A new method to expand query words based on the context is proposed in this paper, which aims at the problem that the retrieval effect will be affected if request words used in the text retrieval can not match text words. This method does words expansion based on the context information of the query word. Additionally, the position information between the query word and the whole query sentence or the query word is considered. Experimental results show that this method greatly improves the average precision ratio.","2160-1283;21601283","DVD:978-1-4244-7617-6; Electronic:978-1-4244-7618-3; POD:978-1-4244-7616-9","10.1109/ICISE.2010.5689956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5689956","context;query expansion word;query words;text retrieval;word co-occurrence","Algorithm design and analysis;Computers;Context;Correlation;Frequency measurement;Information retrieval;Text categorization","","","","0","","8","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"Materialization and Decomposition of Dataspaces for Efficient Search","S. Song; L. Chen; M. Yuan","The Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1872","1887","Dataspaces consist of large-scale heterogeneous data. The query interface of accessing tuples should be provided as a fundamental facility by practical dataspace systems. Previously, an efficient index has been proposed for queries with keyword neighborhood over dataspaces. In this paper, we study the materialization and decomposition of dataspaces, in order to improve the query efficiency. First, we study the views of items, which are materialized in order to be reused by queries. When a set of views are materialized, it leads to select some of them as the optimal plan with the minimum query cost. Efficient algorithms are developed for query planning and view generation. Second, we study the partitions of tuples for answering top-k queries. Given a query, we can evaluate the score bounds of the tuples in partitions and prune those partitions with bounds lower than the scores of top-k answers. We also provide theoretical analysis of query cost and prove that the query efficiency cannot be improved by increasing the number of partitions. Finally, we conduct an extensive experimental evaluation to illustrate the superior performance of proposed techniques.","1041-4347;10414347","","10.1109/TKDE.2010.213","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611525","Dataspaces;decomposition.;materialization","Image color analysis;Indexes;Keyword search;Query processing;Search methods;information retrieval","data handling;query processing","dataspace decomposition;dataspace materialization;large-scale heterogeneous data;query efficiency;query interface;query planning","","5","","55","","20101028","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Empirical analysis of content-based music retrieval for music identification","Ja-Hwung Su; Cheng-Wei Wu; Shao-Yu Fu; Yu-Feng Lin; Wei-Yi Chang; I-Bin Liao; Kuo-Wei Chang; V. S. Tseng","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan, R.O.C.","2011 International Conference on Multimedia Technology","20110825","2011","","","3516","3519","Over the past few years, digitized music in forms like MP3 has made a great impact on the way of acquiring and listening to music. Due to the advanced communication tools, the consumers may search and purchase their favorite music online without going to physical music stores. Consider that a user occasionally gets an unknown and preferred music episode, but she/he has no idea on how to identify the query terms to retrieve the music using traditional textual-based search engines. Thereupon content-based music retrieval for music identification serves as an adequate solution for the users to search the targeted music effectively and conveniently. In this paper, we present several methods and similarity functions designed to achieve the effective content-based music identification. In particular, we compare the performances of various similarity functions with different musical features under real environments. The experimental results on real music datasets reveal that the Hamming Distance can bring out very robust performance for content-based music identification in terms of accuracy. In addition to music identification, this paper with detailed empirical analysis also provides the researchers with insightful ideas in other real applications such as audio monitoring, musical copyright, etc.","","Electronic:978-1-61284-774-0; POD:978-1-61284-771-9","10.1109/ICMT.2011.6002145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6002145","Content-based music retrieval;multimedia databases;music identification;query-by-example","Euclidean distance;Fingerprint recognition;Hamming distance;High definition video;Mel frequency cepstral coefficient;Music;Music information retrieval","content-based retrieval;music","MP3;audio monitoring;content-based music identification;content-based music retrieval;hamming distance;musical copyright;musical features;similarity functions;textual-based search engines","","0","","11","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Visualizing Quran documents results by stemming semantic speech query","M. A. Yunus; R. Zainuddin; N. Abdullah","Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia","2010 International Conference on User Science and Engineering (i-USEr)","20110222","2010","","","209","213","The information visualization results are retrieving lack of information to meet user's speech query even though there is presenting information and results in visualization. Hence, in this study, visualization of retrieving relevant documents through cross language information retrieval (CLIR) system needs to across language boundaries, a mechanism for query translation with semantic and stemmers are required well-known as stemming semantic query (SSQ). Therefore, this study is conducted with the purposes to investigate visualization approach against the queries and vice versa using SpaceTree. Furthermore, it is also conducted to investigate the performance of visualization to present normal listing results. The retrieval results however, focus on how SpaceTree is beneficial to represent them in a good manner. Results from the experiments suggest that SpaceTree is most friendly to display results to the users in CLIR. It also found that semantic approach with stemmers contributes to better performance in visualizing more relevant and related Quran document results.","","Electronic:978-1-4244-9049-3; POD:978-1-4244-9048-6","10.1109/IUSER.2010.5716753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716753","query;semantic;speech;stemming;visualization","Data visualization;Information retrieval;Ontologies;Semantic Web;Semantics;Speech;Visualization","data visualisation;document handling;natural language processing;query processing;speech processing","Quran documents results visualization;SpaceTree;cross language information retrieval system;information visualization;query translation;stemming semantic speech query","","1","","34","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"Semantic query for Quran documents results","M. A. Yunus; R. Zainuddin; N. Abdullah","Faculty of Computer Science and Information Technology, University of Malaya, 50603, Kuala Lumpur, Malaysia","2010 IEEE Conference on Open Systems (ICOS 2010)","20110224","2010","","","1","5","The query-based on the result is less relevant documents results. In this study, a query has been improved in order to retrieve more relevant documents across language boundaries, a mechanism for query translation with semantic which is applied on as semantic query (SQ). Therefore, this study is conducted with the purposes to investigate semantic approach against the queries and vice versa. Furthermore, it is also conducted to investigate the performance query based on total retrieve and relevant. The retrieval however, included the irrelevant documents because of the translation polysemy. Results from the experiments suggest that semantic approach is most important process in cross language information retrieval (CLIR). It also found that semantic approach contributes to better performance in retrieving more relevant and related Quran document results.","","Electronic:978-1-4244-9192-6; POD:978-1-4244-9193-3","10.1109/ICOS.2010.5719959","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5719959","query;semantic;speech","Computer science;Information retrieval;Ontologies;Presses;Query processing;Semantic Web;Semantics","document handling;natural languages;query processing;relevance feedback","CLIR;Quran document;cross language information retrieval;document retrieval;query translation;relevant document;semantic query","","3","","28","","","5-7 Dec. 2010","","IEEE","IEEE Conference Publications"
"A Framework for Integrating, Exploring, and Searching Location-Based Web Data","A. Bozzon; M. Brambilla; S. Ceri; S. Quarteroni","Politecnico di Milano","IEEE Internet Computing","20111031","2011","15","6","24","31","This article presents the adaptation of a general search computing framework for exploratory search over Web data as suggested by the specificity of location-based data services. The result is a conceptual model of geographic entities, the spatial functions operating on them, and a special-purpose exploratory interface that lets users search combinations of georeferenced objects directly on a map. Such modifications help the general framework provide ranked extraction of relevant objects and their combinations, custom ranking functions, and cost-based access to location-based services.","1089-7801;10897801","","10.1109/MIC.2011.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025339","LBS;Location-based services;exploratory search;modeling of georeferenced entities;modeling of spatial functions;ontological representation of LBSs;search computing;service integration","Computational modeling;Data models;Information retrieval;Internet;Knowledge based systems;Search methods;Search problems;Semantics;Spatial databases","Web services;geographic information systems;mobile computing;search engines;user interfaces","cost-based access;custom ranking function;exploratory search;general search computing framework;geographic entity;georeferenced object;location-based Web data searching;location-based data service;ranked extraction;search combination;spatial function;special-purpose exploratory interface","","3","","10","","20110923","Nov.-Dec. 2011","","IEEE","IEEE Journals & Magazines"
"A Service Search Engine for the Industrial Digital Ecosystems","H. Dong; F. K. Hussain; E. Chang","Digital Ecosystems and Business Intelligence Institute, Curtin University of Technology, Perth, Australia","IEEE Transactions on Industrial Electronics","20110512","2011","58","6","2183","2196","Digital ecosystem (DE) is comprised of heterogeneous and distributed species which can play the dual role of service provider and service requester. Nowadays, DE lacks semantic search support, which means it cannot provide a reliable and trustworthy link between service providers and service requesters. To solve this issue, we design a conceptual framework of a service-ontology-based semantic service search engine. Apart from the function of service search with a novel search model, this framework also provides a quality-of-services-based service evaluation and ranking methodology. To evaluate the feasibility of our framework, we implement a prototype in the transport service domain, and compare the performance of the search model with three traditional information retrieval models. The conclusion to this evaluation and suggestions for future works are provided in the final section.","0278-0046;02780046","","10.1109/TIE.2009.2031186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5229196","Digital ecosystems (DEs);quality-of-service (QoS) ranking;semantic service search;service evaluation","Ecosystems;Information retrieval;Prototypes;Quality of service;Search engines;Terminology;Transportation;Urban areas","ecology;information retrieval;ontologies (artificial intelligence);search engines;semantic Web;service-oriented architecture","distributed species;heterogeneous species;industrial digital ecosystem;information retrieval model;quality of services based service evaluation;semantic search support;service ontology based semantic service search engine;service provider;service requester;transport service domain","","16","","26","","20090901","June 2011","","IEEE","IEEE Journals & Magazines"
"Affecticon: Emotion-Based Icons for Music Retrieval","M. J. Yoo; I. K. Lee","Yonsei University","IEEE Computer Graphics and Applications","20110421","2011","31","3","89","95","Digital audio is easy to record, play, process, and manage. Its ubiquity means that devices for handling it are cheap, letting more people record and play music and speech. In addition, the Internet has improved access to re corded audio. So, the amount of recorded music that people own has rapidly increased. Most current audio players compress audio files and store them in internal memory. Because stor age costs have consistently declined, the amount of music that can be stored has rapidly increased. A player with 16 Gbytes of memory can hold ap proximately 3,200 songs if each song is stored in compressed format and occupies 5 Mbytes. Effectively organizing such large volumes of music is difficult. People often listen repeatedly to a small number of favorite songs, while others remain un justifiably neglected. We've developed Affecticon, an efficient system for managing music collections. Affecticon groups pieces of music that convey similar emotions and labels each group with a corresponding icon. These icons let listeners easily select music according to its emotional content. Experiments have demonstrated Affecticon's effectiveness.","0272-1716;02721716","","10.1109/MCG.2011.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5754299","computer graphics;graphics and multimedia;harmonograph;human-computer interaction;music emotional retrieval;music retrieval;user interfaces","Computational modeling;Emotion recognition;Image color analysis;Mood;Music information retrieval;Speech processing;System-on-a-chip","audio recording;emotion recognition;music","Internet;affecticon;audio file compression;audio players;audio recording;digital audio;emotion-based icons;music retrieval","0","1","","4","","","May-June 2011","","IEEE","IEEE Journals & Magazines"
"The improved non-negative Matrix Factorization algorithm for document clustering","W. Zhao; H. Ma; Q. He; Z. Shi","Coll. of Inf. Eng., Xiangtan Univ., Xiangtan, China","2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20110915","2011","3","","1836","1839","Non-negative Matrix Factorization (NMF) is one latest presented approach for obtaining document clusters, which aimed to provide a minimum error non-negative representation of the term-document matrix. In this paper, we have extended the classical NMF approach by imposing sparseness constraints explicitly. The new model can learn much sparser matrix factorization. Also, an objective function is defined to impose the sparseness constraint, in addition to the non-negative constraint. Experimental results on real-world document datasets show that the proposed method can treat document clustering effectively and efficiently.","","Electronic:978-1-61284-181-6; POD:978-1-61284-180-9","10.1109/FSKD.2011.6019811","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019811","","Algorithm design and analysis;Clustering algorithms;Educational institutions;Encoding;Information retrieval;Text mining","document handling;matrix algebra;pattern clustering","document clustering;minimum error nonnegative representation;nonnegative matrix factorization algorithm;real-world document datasets;term-document matrix","","0","","18","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"An Auditory Display in Playlist Generation","R. Stewart; M. Sandler","She is currently a postdoctoral researcher with the Centre for Digital Music at Queen Mary, University of London.","IEEE Signal Processing Magazine","20110616","2011","28","4","14","23","A current area of research within music information retrieval is the automatic formation of music playlists: automatically creating a meaningful arrangement of music tracks. It is an application area particularly suited for accessing music on mobile devices as music collections are becoming too large to manually navigate. The growth of music streaming services means that even more vast collections of music are accessible from a mobile device. Much energy has been spent constructing the best algorithms to create a playlist, but less has been spent on how that algorithm is presented and accessed, particularly on a mobile device.","1053-5888;10535888","","10.1109/MSP.2011.940883","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5888663","","Algorithm design and analysis;Auditory displays;Mobile communication;Mobile handsets;Music;Music information retrieval;Signal processing algorithms;Visualization","information retrieval;mobile computing;mobile handsets;music","auditory display;mobile devices;music information retrieval;music playlists;music streaming services;playlist generation","","1","1","39","","","July 2011","","IEEE","IEEE Journals & Magazines"
"Musıc tracking system for royalty rıghts management: Geometrıcal representation of musıc","E. Ünal; C. Demir; M. U. Doğan","T&#x00DC;B&#x0130;TAK B&#x0130;LGEM, Turkey","2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU)","20110623","2011","","","626","629","Representation of music with the purpose of matching queries is one of the popular sub fields of information retrieval. In this paper, studies for to the project named `Music Tracking System for Royalty Rights Management' funded by the TÜBıTAK ARDEB 3501 grant program is presented. Related to technical representation of music for music matching, the tonal music space theory and its background is explained. The short time spectral analysis features are mapped on to the three dimensional musical space for meaningful representation. The symbolic representation is then integrated into a look-up table with N-gram blocks. This process is held for each database entry. The look up table becomes an N-gram block representation of the entire database. When a match query is available, the symbolic sequence of the query is searched in the look-up table and a match result is presented to the user. In a database of ten thousand music samples, full clip and partial clip query matching results and technical details about the performance of the system is shown.","2165-0608;21650608","Electronic:978-1-4577-0463-5; POD:978-1-4577-0462-8","10.1109/SIU.2011.5929728","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929728","","Conferences;Databases;Mathematical model;Multiple signal classification;Music information retrieval;Signal processing;Spirals","geometry;information retrieval;music;table lookup","N-gram block representation;geometrıcal representation;information retrieval;look-up table;musıc tracking system;music matching;royalty rıghts management;spectral analysis features","","0","","10","","","20-22 April 2011","","IEEE","IEEE Conference Publications"
"Construct new concept lattices based on rough set theory","Qiang Li; Ling Wei; Shengnan Wang","Department of Mathematics, Northwest University, Xi'an, China","2011 International Conference on Electric Information and Control Engineering","20110527","2011","","","4052","4055","In the theory of the concept lattices, the structure of a concept lattice is the base of data analysis and is very important. This paper mainly constructs two kinds of new concept lattices using the approximation operators "" □ "" and "" ◇ "" respectively. And also studies the relations among new concept lattices, object oriented concept lattice, property-oriented concept lattice and complementary concept lattices.","","Electronic:978-1-4244-8039-5; POD:978-1-4244-8036-4","10.1109/ICEICE.2011.5777620","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5777620","Approximation operators;Concept;Concept lattices;Formal context;Rough set","Approximation methods;Data analysis;Information retrieval;Lattices;Rough sets","data analysis;lattice theory;rough set theory","approximation operators;complementary concept lattices;data analysis;object oriented concept lattice;property-oriented concept lattice;rough set theory","","0","","13","","","15-17 April 2011","","IEEE","IEEE Conference Publications"
"Finding Top-k Answers in Keyword Search over Relational Databases Using Tuple Units","J. Feng; G. Li; J. Wang","Tsinghua University, Beijing","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1781","1794","Existing studies on keyword search over relational databases usually find Steiner trees composed of connected database tuples as answers. They on-the-fly identify Steiner trees by discovering rich structural relationships between database tuples, and neglect the fact that such structural relationships can be precomputed and indexed. Recently, tuple units are proposed to improve search efficiency by indexing structural relationships, and existing methods identify a single tuple unit to answer keyword queries. However, in many cases, multiple tuple units should be integrated to answer a keyword query. Thus, these methods will involve false negatives. To address this problem, in this paper, we study how to integrate multiple related tuple units to effectively answer keyword queries. To achieve a high performance, we devise two novel indexes, single-keyword-based structure-aware index and keyword-pair-based structure-aware index, and incorporate structural relationships between different tuple units into the indexes. We use the indexes to efficiently identify the answers of integrated tuple units. We develop new ranking techniques and algorithms to progressively find the top-k answers. We have implemented our method in real database systems, and the experimental results show that our approach achieves high search efficiency and result quality, and outperforms state-of-the-art methods significantly.","1041-4347;10414347","","10.1109/TKDE.2011.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728810","Keyword search;keyword-pair-based index;relational databases;single-keyword-based index;tuple units.","Indexes;Information retrieval;Keyword search;Periodic structures;Relational databases;Steiner trees","database indexing;query processing;relational databases;trees (mathematics)","Steiner tree;connected database tuple;keyword query;keyword search;keyword-pair-based structure-aware index;ranking technique;relational database;single-keyword-based structure-aware index;top-k answer;tuple structural relationship","","3","","49","","20110310","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Anomalous Window Discovery for Linear Intersecting Paths","L. Shi; V. P. Janeja","University of Maryland, Baltimore County, Baltimore","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1857","1871","The focus of this paper is to discover anomalous windows in linear intersecting paths. Anomalous windows are the contiguous groupings of data points. A linear path refers to a path represented by a line with a single dimensional spatial coordinate marking an observation point. In this paper, we propose an approach for discovering anomalous windows using a class of algorithms based on scan statistics, specifically 1) an Order invariant algorithm using Scan Statistics for Linear Intersecting Paths (SSLIP), 2) Brute force-SSLIP (BF-SSLIP), and 3) Central Brute Force-SSLIP (CBF-SSLIP). We further present two efficient variants of SSLIP: SSLIP* which employs a upper bound on the scan window size, and SSLIP-Acc, which adopts an accelerator function to speed up the scan process. The proposed approach for discovering anomalous windows along linear paths comprises the following distinct steps: 1) Cross Path Discovery: where we identify a subset of intersecting paths to be considered, 2) Anomalous Window Discovery: where we outline the various algorithms for the traversal of the cross paths to identify varying size directional windows along the paths. For identifying an anomalous window, an unusualness metric is computed, in the form of a likelihood ratio to indicate the degree of unusualness of this window with respect to the rest of the data. We identify the window with the highest likelihood ratio as our anomalous window, and 3) Monte Carlo Simulations: to ascertain whether this window is truly anomalous and not merely random occurrence, we perform hypothesis testing by computing a p-value using Monte Carlo Simulations. We present extensive experimental results in real world accident data sets for various highways with known issues (code and data available from [32], [27]). Additionally, we also perform comparisons with current approaches [18], [34] to show the efficacy of our approach. Our results show that our approach indeed is effective in identifying anomalous traffic- - accident windows along multiple intersecting highways.","1041-4347;10414347","","10.1109/TKDE.2010.212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611524","Spatial scan statistics;anomaly detection.;linear scan statistic;spatial scan window","Correlation;Information retrieval;Monte Carlo methods;Statistical analysis","Monte Carlo methods;road safety;security of data;traffic engineering computing","Monte Carlo simulation;anomalous window discovery;brute force;cross path discovery;data point;intersecting highway;likelihood ratio;linear intersecting path;order invariant algorithm;scan statistics;single dimensional spatial coordinate;traffic accident window","","3","","40","","20101028","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Site-Based Partitioning and Repartitioning Techniques for Parallel PageRank Computation","A. Cevahir; C. Aykanat; A. Turk; B. B. Cambazoglu","Tokyo Institute of Technology, Tokyo","IEEE Transactions on Parallel and Distributed Systems","20110328","2011","22","5","786","802","The PageRank algorithm is an important component in effective web search. At the core of this algorithm are repeated sparse matrix-vector multiplications where the involved web matrices grow in parallel with the growth of the web and are stored in a distributed manner due to space limitations. Hence, the PageRank computation, which is frequently repeated, must be performed in parallel with high-efficiency and low-preprocessing overhead while considering the initial distributed nature of the web matrices. Our contributions in this work are twofold. We first investigate the application of state-of-the-art sparse matrix partitioning models in order to attain high efficiency in parallel PageRank computations with a particular focus on reducing the preprocessing overhead they introduce. For this purpose, we evaluate two different compression schemes on the web matrix using the site information inherently available in links. Second, we consider the more realistic scenario of starting with an initially distributed data and extend our algorithms to cover the repartitioning of such data for efficient PageRank computation. We report performance results using our parallelization of a state-of-the-art PageRank algorithm on two different PC clusters with 40 and 64 processors. Experiments show that the proposed techniques achieve considerably high speedups while incurring a preprocessing overhead of several iterations (for some instances even less than a single iteration) of the underlying sequential PageRank algorithm.","1045-9219;10459219","","10.1109/TPDS.2010.119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482570","PageRank;graph partitioning;hypergraph partitioning;parallelization;repartitioning.;sparse matrix partitioning;sparse matrix-vector multiplication;web search","Clustering algorithms;Concurrent computing;Convergence;Distributed computing;High performance computing;Information retrieval;Iterative algorithms;Partitioning algorithms;Sparse matrices;Web search","Internet;information retrieval;matrix multiplication;sparse matrices;vectors","Web matrices;Web search;parallel PageRank computation;repartitioning techniques;site-based partitioning technique;sparse matrix partitioning models;sparse matrix-vector multiplications","","6","","61","","20100607","May 2011","","IEEE","IEEE Journals & Magazines"
"Online Video Recommendation through Tag-Cloud Aggregation","J. Park; S. J. Lee; S. J. Lee; K. Kim; B. S. Chung; Y. K. Lee","Seoul National University","IEEE MultiMedia","20110228","2011","18","1","78","87","A framework for recommending online videos operates by constructing user profiles as an aggregate of tag clouds and generating recommendations according to similar viewing patterns.","1070-986X;1070986X","","10.1109/MMUL.2010.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416669","hybrid filtering;online videos;recommendation;social media;tag cloud similarity;tag clouds","Aggregates;Cloud computing;Information filtering;Information filters;Information resources;Information retrieval;Recommender systems;Tag clouds;User-generated content;Video recording","recommender systems;video retrieval","online video recommendation;tag-cloud aggregation;user profiles","","15","","7","","20100218","Jan. 2011","","IEEE","IEEE Journals & Magazines"
"Managing Knowledge for Organization-Wide Ad Hoc Committees","A. Sharma; L. Miller; S. Nilakanta","Dept. of Comput. Sci., Iowa State Univ. Ames, Ames, IA, USA","2011 44th Hawaii International Conference on System Sciences","20110222","2011","","","1","10","Organization and industry-wide ad hoc committees are often formed to develop solutions to crises that are ill-defined. Knowledge available to such committees is at best scattered and possibly nonexistent within the organization. The present work describes an environment created to provide the committee members with the tools to collect, organize, and utilize the knowledge for them to complete their task. The environment makes use of topic maps as the knowledge structure. A distributed system has been implemented to support the proposed environment and demonstrate feasibility.","1530-1605;15301605","Electronic:978-0-7695-4282-9; POD:978-1-4244-9618-1","10.1109/HICSS.2011.297","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5718485","","Information retrieval;Knowledge management;Memory management;Object oriented modeling;Organizations;Servers;Visualization","distributed processing;knowledge management","distributed system;industry-wide ad hoc committee;knowledge management;knowledge structure;organization-wide ad hoc committee","","1","","36","","","4-7 Jan. 2011","","IEEE","IEEE Conference Publications"
"Semantic Traffic-Aware Routing Using the LarKC Platform","E. Della Valle; I. Celino; D. Dell'Aglio; R. Grothmann; F. Steinke; V. Tresp","Politecnico di Milano","IEEE Internet Computing","20111031","2011","15","6","15","23","The popularity of location-based services and automotive navigation systems calls for a new generation of intelligent solutions to support users in mobility. This article presents a traffic-aware semantic routing service for mobile users based on the Large Knowledge Collider (LarKC) Semantic Web pluggable platform. It proposes a technique for integrating conceptual query answering with statistical learning and operations research algorithms. The presented prototype of a traffic-aware semantic routing service works efficiently with large, heterogeneous information sources and delivers value-added services to mobile users.","1089-7801;10897801","","10.1109/MIC.2011.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999640","location-based services;semantic retrieval;traffic forecasting;urban computing","Forecasting;Information retrieval;Internet;Ontologies;Recurrent neural networks;Semantics;Telecommunication traffic;Urban areas","mobile computing;query processing;road traffic;semantic Web;traffic engineering computing","LarKC platform;automotive navigation systems;conceptual query answering;large knowledge collider semantic Web pluggable platform;location-based services;mobile users;operations research algorithms;statistical learning;traffic-aware semantic routing service;value-added services","","6","","15","","20110825","Nov.-Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Observations on the connectedness between requirements-to-code traces and calling relationships for trace validation","A. Ghabi; A. Egyed","Johannes Kepler University, 4040 Linz, Austria","2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)","20111212","2011","","","416","419","Traces between requirements and code reveal where requirements are implemented. Such traces are essential for code understanding and change management. Unfortunately, the handling of traces is highly error prone, in part due to the informal nature of requirements. This paper discusses observations on the connectedness between requirements-to-code traces and calling relationships within the source code. These observations are based on the empirical evaluation of four case study systems covering 150 KLOC and 59 sample requirements. We found that certain patterns of connectedness have high or low likelihoods of occurring. These patterns can thus be used to confirm or reject existing traceability - hence they are useful for validating requirements-to-code traces.","1938-4300;19384300","Electronic:978-1-4577-1639-3; POD:978-1-4577-1638-6","10.1109/ASE.2011.6100087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100087","Requirements;Traceability;Validation","Conferences;Gold;Information retrieval;Java;Manuals;Software;Software engineering","program verification","KLOC;calling relationships;change management;error prone;requirements-to-code trace validation;source code;trace handling","","2","","14","","","6-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"A combination approach for enhancing automated traceability: (NIER track)","X. Chen; J. Hosking; J. Grundy","University of Auckland, Auckland, New Zealand","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","912","915","Tracking a variety of traceability links between artifacts assists software developers in comprehension, efficient development, and effective management of a system. Traceability systems to date based on various Information Retrieval (IR) techniques have been faced with a major open research challenge: how to extract these links with both high precision and high recall. In this paper we describe an experimental approach that combines Regular Expression, Key Phrases, and Clustering with IR techniques to enhance the performance of IR for traceability link recovery between documents and source code. Our preliminary experimental results show that our combination technique improves the performance of IR, increases the precision of retrieved links, and recovers more true links than IR alone.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985943","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032550","clustering;key phrases;regular expression;traceability","Clustering algorithms;Documentation;Information retrieval;Large scale integration;Software;Thesauri;Unified modeling language","information retrieval;program diagnostics;software engineering","automated traceability system;document clustering;information retrieval;key phrases;regular expression;traceability link recovery","","3","","12","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"E-Commerce Web Database Approximate Query Results Ranking","X. Li; J. Zhang","Comput. Center, Liaoning Univ. of Technol., Jinzhou, China","2011 International Conference on Internet Technology and Applications","20110829","2011","","","1","4","In search of e-commerce network database, users often have vague or imprecise ideas, formulation of queries can not accurately convey the intent of their query, the query to get the relevant answers to relax, to meet user needs and preferences, has become an important method. However, inquiries to relax, the user may be faced with too many answers. In response to queries from the approximate answer e-commerce Web database returns too many problems, a new method for approximate query results sorting. Based on database query history, we hypothesized that users care about each property, and the corresponding weight assigned to it. Then, depending on the property value of similarity between a query based on the results of approximate satisfaction ranking method. Secondly, satisfaction with the same tuple, each attribute value is not specified, the user's ""satisfaction"" is given a score. Proved that the method to obtain satisfactory results. Finally, preliminary experiments show its efficiency and the quality of the ranking algorithm.","","Electronic:978-1-4244-7255-0; POD:978-1-4244-7253-6","10.1109/ITAP.2011.6006139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6006139","","Data engineering;History;Image color analysis;Information retrieval;Probabilistic logic;Relational databases","Internet;database management systems;electronic commerce;query processing","approximate query results;approximate satisfaction ranking method;database query;e-commerce Web database;e-commerce network database","","0","","12","","","16-18 Aug. 2011","","IEEE","IEEE Conference Publications"
"Keyword Extraction from Documents Using a Neural Network Model","T. Jo; M. Lee; T. M. Gatton","University of Ottawa, 800 King Edward","2006 International Conference on Hybrid Information Technology","20111212","2006","2","","194","197","A document surrogate is usually represented in a list of words. Because not all words in a document reflect its content, it is necessary to select important words from the document that relate to its content. Such important words are called keywords and are selected with a particular equation based on Term Frequency (TF) and Inverted Document Frequency (IDF). Additionally, the position of each word in the document and the inclusion of the word in the title should be considered to select keywords among words contained in the text. The equation based on these factors gets too complicated to be applied to the selection of keywords. This paper proposes a neural network back propagation model in which these factors are used as the features and feature vectors are generated to select keywords. This paper will show that the proposed neural network backpropagation approach outperforms the equation in distinguishing keywords.","","POD:0-7695-2674-8","10.1109/ICHIT.2006.253612","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4021217","keyword extraction;neural networks.","Data mining;Equations;Frequency;Indexing;Information retrieval;Information technology;Natural languages;Neural networks;Text categorization;Text mining","","","","5","","13","","","9-11 Nov. 2006","","IEEE","IEEE Conference Publications"
"A Dynamic Cluster Construction Method Based on Characteristics of Query Generation in Peer-to-Peer Networks","Y. Kobayashi; T. Yoshihisa; T. Hara; S. Nishio","Dept. of Multimedia Eng., Osaka Univ., Suita, Japan","2011 IEEE Workshops of International Conference on Advanced Information Networking and Applications","20110505","2011","","","96","101","Due to the recent development of computer and network technologies, there has been increasing interest in peer-to-peer (P2P) networks. To reduce query messages for information retrieval in P2P networks, many conventional studies proposed methods that categorize similar data items and cluster peers that have data items in the same category. Some of them aim to construct clusters dynamically when the number of queries for similar data items exceeds the predetermined threshold. However, these methods have a critical problem that the threshold is fixed for any queries. The fixed threshold cannot perform cluster construction at appropriate timings since they depend on characteristics of query generation. In this paper, we propose a dynamic cluster construction method based on characteristics of query generation. Our method can reduce query messages by constructing dynamic clusters at more appropriate timings. The results of simulation experiments show that our method can reduce query messages compared with an existing method.","","Electronic:978-0-7695-4338-3; POD:978-1-61284-829-7","10.1109/WAINA.2011.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763445","P2P;clustering;query","Data models;Information retrieval;Lead;Peer to peer computing;Semantics;Timing;Tsunami","pattern clustering;peer-to-peer computing;query formulation;query processing","dynamic cluster construction method;information retrieval;peer to peer network;query generation;query message","","0","","8","","","22-25 March 2011","","IEEE","IEEE Conference Publications"
"Obtaining term similarities on concept extraction study","K. Balkan; H. Takcı","Gebze Y&#x00FC;ksek Teknoloji Enstit&#x00FC;s&#x00FC;, Turkey","National Conference on Electrical, Electronics and Computer Engineering","20110120","2010","","","578","582","Concept extraction work, promises to improve the performance of the term-based text mining which has high complexity. The first phase of the concept extraction is to detect the terms have notable frequency to represent the documents. With grouping these terms an important function will be implemented on the way conception. Transition from terms to concepts; by clustering the terms according to similarities between terms, and then by labeling these clusters with an expert. The parameters of clustering algorithm and the quality of the data set will affect the success of this process. In this study, the three methods for term similarity are examined and the the most successful one is tried to find. Study is performed on Turkish language.","","Electronic:978-605-01-0013-6; POD:978-1-4244-9588-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5698108","","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Digital signal processing;Information retrieval;Semantics;Text mining","data mining;natural language processing;pattern clustering;text analysis","Turkish language;clustering algorithm;concept extraction study;term-based text mining","","0","","10","","","2-5 Dec. 2010","","IEEE","IEEE Conference Publications"
"Know Thy Neighbor: Combining audio features and social tags for effective music similarity","A. Nanopoulos; I. Karydis","University of Hildesheim, Germany","2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20110711","2011","","","165","168","Measuring similarity of two musical pieces is an ill-defined problem for which recent research on contextual information, assigned as free-form text (tags) in social networking services, has shown to be highly effective. Nevertheless, approaches based on contextual information require adequate amount of tags per musical datum in order to be effective. In the case of the so called ""cold-start"" problem, this assumption is not valid for several music data. In this paper, we address this problem by proposing a combination of the audio and the tag feature space of musical data. The application of the proposed combination for musical data lacking contextual information is shown, through experimental results with real musical data, to evaluate more accurately their similarity than the use of solely audio-based similarity.","1520-6149;15206149","Electronic:978-1-4577-0539-7; POD:978-1-4577-0538-0; USB:978-1-4577-0537-3","10.1109/ICASSP.2011.5946366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946366","“cold-start” problem;audio similarity measurement;audio-tag feature space combination;contextual knowledge;social tags","Feature extraction;Glass;Measurement;Music information retrieval;Semantics;Training;Training data","music;social networking (online);text analysis","audio based similarity;cold start problem;contextual information;free-form text;ill-defined problem;musical data;social networking services;tag feature space","","1","2","15","","","22-27 May 2011","","IEEE","IEEE Conference Publications"
"Research on Chinese Question Classification Based on Hownet and Dependency Parsing","W. Zhang; J. Chen; Y. Niu","Inf. Center, Shanxi Med. Coll. for Continuing Educ., Taiyuan, China","2011 3rd International Workshop on Intelligent Systems and Applications","20110613","2011","","","1","4","Question classification is an important part of Chinese question answering system, and the result of question classification directly affects the quality of question answering. This paper presents a new method on feature extraction for question classification. HowNet and dependency parsing are used in this new method. The classification experimental results using SVM classifier have shown that the model proposed in the paper is effective in improving question classification accuracy.","","Electronic:978-1-4244-9857-4; POD:978-1-4244-9855-0","10.1109/ISA.2011.5873388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5873388","","Accuracy;Education;Feature extraction;Information retrieval;Semantics;Support vector machines;Syntactics","feature extraction;pattern classification;question answering (information retrieval);support vector machines;thesauri","Chinese question answering system;Chinese question classification;Hownet;SVM classifier;dependency parsing;feature extraction","","1","","6","","","28-29 May 2011","","IEEE","IEEE Conference Publications"
"Multi-document arabic text summarisation","M. El-Haj; U. Kruschwitz; C. Fox","School of Computer Science and Electronic Engineering, University of Essex, UK","2011 3rd Computer Science and Electronic Engineering Conference (CEEC)","20110822","2011","","","40","44","In this paper we present our generic extractive Arabic and English multi-document summarisers. We also describe the use of machine translation for evaluating the generated Arabic multi-document summaries using English extractive gold standards. In this work we first address the lack of Arabic multi-document corpora for summarisation and the absence of automatic and manual Arabic gold-standard summaries. These are required to evaluate any automatic Arabic summarisers. Second, we demonstrate the use of Google Translate in creating an Arabic version of the DUC-2002 dataset. The parallel Arabic/English dataset is summarised using the Arabic and English summarisation systems. The automatically generated summaries are evaluated using the ROUGE metric, as well as precision and recall. The results we achieve are compared with the top five systems in the DUC-2002 multi-document summarisation task.","","Electronic:978-1-4577-1301-9; POD:978-1-4577-1300-2","10.1109/CEEC.2011.5995822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5995822","","Conferences;Google;Humans;Information retrieval;Measurement;Redundancy;Standards","language translation;natural language processing;text analysis","DUC-2002 dataset;English extractive gold standard;Google Translate;ROUGE metric;generic extractive Arabic multidocument summariser;generic extractive English multidocument summariser;machine translation;multidocument Arabic text summarisation system","","3","","23","","","13-14 July 2011","","IEEE","IEEE Conference Publications"
"Parallel research on KMP algorithm","P. Cao; S. Wu","School of Mathematics and Computer Science, Ningxia University, Yinchuan Ningxia, China","2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)","20110516","2011","","","4252","4255","The tradition pattern matching algorithm need backtrack and compare repeatedly, so that affects efficiency of algorithm. Knuth and others put forward KMP algorithm in order to promote efficiency of the pattern matching. Paralle KMP algorithm based on MPI is provided in this paper, which can get higher efficiency.","","DVD:978-1-61284-457-2; Electronic:978-1-61284-459-6; POD:978-1-61284-458-9","10.1109/CECNET.2011.5768201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5768201","KMP;MPI;Parallel","Algorithm design and analysis;Arrays;Computer applications;Information retrieval;Parallel algorithms;Pattern matching;Process control","application program interfaces;message passing;parallel algorithms;string matching","Knuth-Morris-Pratt algorithm;MPI;message passing interface;parallel KMP algorithm;pattern matching algorithm","","1","","7","","","16-18 April 2011","","IEEE","IEEE Conference Publications"
"Model reference fuzzy-neuro text matching system","J. Osmic; E. Skejic; Z. Sehic","University of Tuzla/Faculty of electrical engineering, Tuzla, Bosnia and Herzegovina","2011 Proceedings of the 34th International Convention MIPRO","20110728","2011","","","948","952","In this paper is presented Model Reference Fuzzy-Neuro Text Matching System. By using user-friendly interface in the form of if-then rules, syntax and semantics rule base, and English word base, the input text has been transformed to an array of potentially important terms (entities). Entities, that are characterized with their names and attributes that have been extracted from the text, are inputs into the Fuzzy Inference System (FIS). The output from FIS is “term importance” for given text which is regarded as the coordinate of input text in term space. In order to simplify tuning of parameters of the FIS, FIS is transformed to neural network. Neural network parameters are adjusted offline using some reference knowledge that has been a prior given by some experts. Matching of the input text against other texts is performed using Euclidean norm in the term space. Due to the fact that output term base is organized in the term-wise form, text matching is simplified since it is performed only against those texts that the given term belongs to. By using user-friendly interface in the form of if-then rules, the overall system is open for future inclusion of new syntax and semantics rules.","","Electronic:978-953-233-059-5; POD:978-1-4577-0996-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967193","","Arrays;Engines;Indexes;Information retrieval;Mathematical model;Syntactics;Tuning","feature extraction;fuzzy neural nets;fuzzy reasoning;string matching;text analysis;user interfaces;word processing","English word base;Euclidean norm;model reference fuzzyneuro text matching;neural network parameter;semantics rule base;syntax rule;text extraction;user friendly interface","","0","","6","","","23-27 May 2011","","IEEE","IEEE Conference Publications"
"Huge Music Archives on Mobile Devices","H. Blume; B. Bischl; M. Botteck; C. Igel; R. Martin; G. Roetter; G. Rudolph; W. Theimer; I. Vatolkin; C. Weihs","Received both his Dipl. Ing. degree in electrical engineering and Ph.D. degree on nonlinear fault tolerant interpolation of intermediate images from the University of Dortmund, Germany.","IEEE Signal Processing Magazine","20110616","2011","28","4","24","39","The availability of huge nonvolatile storage capacities such as flash memory allows large music archives to be maintained even in mobile devices. With the increase in size, manual organization of these archives and manual search for specific music becomes very inconvenient. Automated dynamic organization enables an attractive new class of applications for managing ever-increasing music databases. For these types of applications, extraction of music features as well as subsequent feature processing and music classification have to be performed. However, these are computationally intensive tasks and difficult to tackle on mobile platforms. Against this background, we provided an overview of algorithms for music classification as well as their computation times and other hardware-related aspects, such as power consumption on various hardware architectures. For mobile platforms such as smartphones, a careful balance of algorithm complexity, hardware architecture, and classification accuracy has to be found to provide a high quality user experience.","1053-5888;10535888","","10.1109/MSP.2011.940880","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5888636","","Fingerprint recognition;Flash memory;Mobile communication;Mobile handsets;Multiple signal classification;Music;Music information retrieval","classification;feature extraction;flash memories;information retrieval systems;mobile computing;music;random-access storage;user interfaces","algorithm complexity;automated dynamic organization;feature processing;flash memory;hardware architecture;hardware architectures;mobile devices;music archives;music classification;music databases;music feature extraction;nonvolatile storage capacities;power consumption;smartphones","","3","","65","","","July 2011","","IEEE","IEEE Journals & Magazines"
"Study on food safety semantic retrieval system based on domain ontology","Y. Yang; J. Du; M. Liang","Beijing Key Lab of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","20111013","2011","","","40","44","From aspects of domain ontology construction, concept similarity computation based on ontology and semantic query expansion study the related technologies of information retrieval system based on ontology; establish food safety domain ontology and ontology-based concept similarity computation model, put forward a new semantic query expansion method based on concept similarity computation; design and implement food safety semantic retrieval system. The experiments show that this food safety semantic retrieval system is superior to the retrieval system based on keywords both in the recall ratio and the precision, and realize certain intelligent retrieval.","2376-5933;23765933","Electronic:978-1-61284-204-2; POD:978-1-61284-203-5","10.1109/CCIS.2011.6045028","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045028","concept similarity;domain ontology;food safety;query expansion;semantic retrieval","Certification;Computational modeling;Information retrieval;Knowledge based systems;Ontologies;Safety;Semantics","food safety;ontologies (artificial intelligence);query processing","domain ontology;food safety semantic retrieval system;information retrieval system;intelligent retrieval;semantic query expansion;similarity computation","","1","","6","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"Study on key techniques for 3G mobile learning platform based on cloud service","Q. Xue; Y. Li; L. Zhong; M. Zheng","Department of Computer Science and Technology, Nanyang Institute of Technology, Nanyang, Henan, China","2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)","20110516","2011","","","3588","3591","With the development of 3G mobile technology, the mobile learning (M-Learning) platform research becomes the demand of the Times. Based on cloud service for convenient hardware resource allocation and ontology for good individual learning, the system architecture of mobile learning platform is proposed and some key techniques are studied in this paper. Finally, a kind of M-learning platform framework is designed and realized.","","DVD:978-1-61284-457-2; Electronic:978-1-61284-459-6; POD:978-1-61284-458-9","10.1109/CECNET.2011.5768286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5768286","Cloud Service;Individualiza;M-Learning;Ontology","Cloud computing;Computer architecture;Computer science;Information retrieval;Mobile communication;Mobile computing;Ontologies","3G mobile communication;Internet;computer aided instruction;mobile computing;ontologies (artificial intelligence)","3G mobile learning platform;cloud service;hardware resource allocation;ontology;system architecture","","0","","10","","","16-18 April 2011","","IEEE","IEEE Conference Publications"
"Semantics of Ranking Queries for Probabilistic Data","J. Jestes; G. Cormode; F. Li; K. Yi","Florida State University, Tallahassee","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1903","1917","Recently, there have been several attempts to propose definitions and algorithms for ranking queries on probabilistic data. However, these lack many intuitive properties of a top-k over deterministic data. We define several fundamental properties, including exact-k, containment, unique rank, value invariance, and stability, which are satisfied by ranking queries on certain data. We argue that these properties should also be carefully studied in defining ranking queries in probabilistic data, and fulfilled by definition for ranking uncertain data for most applications. We propose an intuitive new ranking definition based on the observation that the ranks of a tuple across all possible worlds represent a well-founded rank distribution. We studied the ranking definitions based on the expectation, the median, and other statistics of this rank distribution for a tuple and derived the expected rank, median rank, and quantile rank correspondingly. We are able to prove that the expected rank, median rank, and quantile rank satisfy all these properties for a ranking query. We provide efficient solutions to compute such rankings across the major models of uncertain data, such as attribute-level and tuple-level uncertainty. Finally, a comprehensive experimental study confirms the effectiveness of our approach.","1041-4347;10414347","","10.1109/TKDE.2010.192","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601720","Probabilistic data;ranking queries;top-k queries;uncertain database.","Computational modeling;Data models;Database systems;Information retrieval;Probabilistic logic;Semantics;Uncertainty","database management systems;query processing","attribute-level uncertain data;containment property;exact-k property;expected rank;median rank;probabilistic data;quantile rank;rank distribution;ranking definition;ranking query semantics;stability property;tuple-level uncertain data;unique rank property;value invariance property","","12","","43","","20101014","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Mobile Computing: Looking to the Future","B. N. Schilit","","Computer","20110516","2011","44","5","28","29","Innovations in mobile and embedded computing are transforming the way people access information and use network services.","0018-9162;00189162","","10.1109/MC.2011.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5767725","Mobile computing","Access protocols;Embedded systems;Information retrieval;Mobile computing;Technology forecasting","embedded systems;innovation management;mobile computing","computing innovation;embedded computing;mobile computing;network services","","1","","","","","May 2011","","IEEE","IEEE Journals & Magazines"
"Towards more accurate retrieval of duplicate bug reports","C. Sun; D. Lo; S. C. Khoo; J. Jiang","School of Computing, National University of Singapore, Singapore","2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)","20111212","2011","","","253","262","In a bug tracking system, different testers or users may submit multiple reports on the same bugs, referred to as duplicates, which may cost extra maintenance efforts in triaging and fixing bugs. In order to identify such duplicates accurately, in this paper we propose a retrieval function (REP) to measure the similarity between two bug reports. It fully utilizes the information available in a bug report including not only the similarity of textual content in summary and description fields, but also similarity of non-textual fields such as product, component, version, etc. For more accurate measurement of textual similarity, we extend BM25F - an effective similarity formula in information retrieval community, specially for duplicate report retrieval. Lastly we use a two-round stochastic gradient descent to automatically optimize REP for specific bug repositories in a supervised learning manner. We have validated our technique on three large software bug repositories from Mozilla, Eclipse and OpenOffice. The experiments show 10-27% relative improvement in recall rate@k and 17-23% relative improvement in mean average precision over our previous model. We also applied our technique to a very large dataset consisting of 209,058 reports from Eclipse, resulting in a recall rate@k of 37-71% and mean average precision of 47%.","1938-4300;19384300","Electronic:978-1-4577-1639-3; POD:978-1-4577-1638-6","10.1109/ASE.2011.6100061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100061","","Accuracy;Computer bugs;Information retrieval;Software;Support vector machines;Training;Tuning","gradient methods;information retrieval;learning (artificial intelligence);program debugging","BM25F;REP;bug tracking system;duplicate bug reports;duplicate report retrieval;information retrieval community;retrieval function;software bug repositories;supervised learning;textual similarity;two-round stochastic gradient descent","","54","","24","","","6-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Evaluating spreading activation for soft information fusion","M. Kandefer; S. C. Shapiro","Department of Computer Science and Engineering and National Center for Multisource Information Fusion, State University of New York at Buffalo, 201 Bell Hall, Buffalo, New York 14260","14th International Conference on Information Fusion","20110808","2011","","","1","8","A soft-information fusion process produces refined estimates of soft-information, such as natural language messages. Information resulting from a soft-information process can be used to retrieve related, relevant information from background (a-priori) knowledge sources using contextual “cues” contained in those messages, a process we call “Context-Based Information Retrieval (CBIR)”. These retrieval results can be used to aid further understanding, and other fusion operations (e.g., data association). CBIR process performance is dependent on the choice of algorithms and parameters for those algorithms, and it is crucial that these are chosen appropriately for the problem domain the CBIR algorithm is used to aid. In this paper an f-measure evaluation of two spreading activation algorithms and their parameters is given using a soft information fusion process in a counterinsurgency domain. This evaluation takes place in two phases. The first phase executes the algorithms over a range of values in order to determine how those parameters affect the performance of the algorithms, and to set these parameters for future use. The second phase compares the results of these algorithms using the parameter settings learned from the first phase.","","Electronic:978-0-9824438-2-8; POD:978-1-4577-0267-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5977684","context exploitation;human-based sensing;soft information fusion","Algorithm design and analysis;Cognition;Context;Equations;Information retrieval;Mathematical model;Natural languages","information retrieval;natural languages;sensor fusion","context-based information retrieval;contextual cues;counterinsurgency domain;data association;f-measure evaluation;knowledge sources;natural language messages;soft information fusion;spreading activation","","1","","26","","","5-8 July 2011","","IEEE","IEEE Conference Publications"
"Document clustering and topic discovery based on semantic similarity in scientific literature","J. Jayabharathy; S. Kanmani; A. A. Parveen","Department of Computer Science & Engineering","2011 IEEE 3rd International Conference on Communication Software and Networks","20110908","2011","","","425","429","Unlabeled document collections are becoming increasingly common and mining such databases becomes a major challenge. It is a major issue to retrieve relevant documents from the larger document collection. By clustering the text documents, the documents sharing similar topics are grouped together. Incorporating semantic features will improve the accuracy of document clustering methods. In order to determine at a sight whether the content of a cluster are of user interest or not, topic discovery methods are required to tag each clusters identifying distinct and representative topic of each cluster. Most of the existing topic discovery methods often assign labels to clusters based on the terms that the clustered documents contain. In this paper a modified semantic-based model is proposed where related terms are extracted as concepts for concept-based document clustering by bisecting k-means algorithm and topic detection method for discovering meaningful labels for the document clusters based on semantic similarity by Testor theory. The proposed method is compared to the Topic Detection by Clustering Keywords method using F-measure and purity as evaluation metrics. Experimental results prove that the proposed semantic-based model outperforms the existing work.","","Electronic:978-1-61284-486-2; POD:978-1-61284-485-5","10.1109/ICCSN.2011.6014600","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6014600","Concept;Document clustering;Semantic similarity;Testor theory;Topic discovery","Data mining;Electronic publishing;Information retrieval;Information services;Internet","data mining;information retrieval;pattern clustering;text analysis","Testor theory;concept-based document clustering;database mining;distinct topic identification;k-means algorithm;representative topic identification;scientific literature;semantic similarity;text document clustering;topic detection method;topic discovery method;unlabeled document collection","","1","1","13","","","27-29 May 2011","","IEEE","IEEE Conference Publications"
"AdaGP-Rank: Applying boosting technique to genetic programming for learning to rank","Feng Wang; Xinshun Xu","School of Computer Science and Technology, Shandong University, Jinan 250101, China","2010 IEEE Youth Conference on Information, Computing and Telecommunications","20110214","2010","","","259","262","One crucial task of learning to rank in the field of information retrieval (IR) is to determine an ordering of documents according to their degree of relevance to the user given query. In this paper, a learning method is proposed named AdaGP-Rank by applying boosting techniques to genetic programming. This approach uses genetic programming to evolve ranking functions while a process inspired from AdaBoost technique helps the evolved ranking functions concentrate on the ranking of those documents associating those `hard' queries. Based on the confidence coefficients, the ranking functions obtained at each boosting round are then combined into a final strong ranker. Experiments conform that AdaGP-Rank has general better performance than several state-of-the-art ranking algorithms on the benchmark data sets.","","Electronic:978-1-4244-8886-5; POD:978-1-4244-8883-4","10.1109/YCICT.2010.5713094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5713094","AdaBoost;Genetic Programming;Learning to Rank","Boosting;Genetic programming;Information retrieval;Training;Training data;USA Councils","document handling;genetic algorithms;learning (artificial intelligence);query processing","AdaBoost technique;AdaGP-Rank;boosting technique;confidence coefficients;document ordering;genetic programming;information retrieval;learning;user given query","","2","","16","","","28-30 Nov. 2010","","IEEE","IEEE Conference Publications"
"Efficient Keyword-Based Search for Top-K Cells in Text Cube","B. Ding; B. Zhao; C. X. Lin; J. Han; C. Zhai; A. Srivastava; N. C. Oza","University of Illinois at Urbana-Champaign, Urbana","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1795","1810","Previous studies on supporting free-form keyword queries over RDBMSs provide users with linked structures (e.g., a set of joined tuples) that are relevant to a given keyword query. Most of them focus on ranking individual tuples from one table or joins of multiple tables containing a set of keywords. In this paper, we study the problem of keyword search in a data cube with text-rich dimension(s) (so-called text cube). The text cube is built on a multidimensional text database, where each row is associated with some text data (a document) and other structural dimensions (attributes). A cell in the text cube aggregates a set of documents with matching attribute values in a subset of dimensions. We define a keyword-based query language and an IR-style relevance model for scoring/ranking cells in the text cube. Given a keyword query, our goal is to find the top-k most relevant cells. We propose four approaches: inverted-index one-scan, document sorted-scan, bottom-up dynamic programming, and search-space ordering. The search-space ordering algorithm explores only a small portion of the text cube for finding the top-k answers, and enables early termination. Extensive experimental studies are conducted to verify the effectiveness and efficiency of the proposed approaches.","1041-4347;10414347","","10.1109/TKDE.2011.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710919","Keyword search;data cube.;multidimensional text data","Computational modeling;Data models;Indexes;Information retrieval;Keyword search;Portable computers;Text analysis","query languages;query processing;relational databases;text analysis","IR-style relevance model;RDBMS;bottom-up dynamic programming;document sorted-scan;free-form keyword queries;inverted-index one-scan;keyword search;keyword-based query language;keyword-based search;linked structures;multidimensional text database;search-space ordering;text cube;top-k cells","","2","1","39","","20110210","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Identifying Relevant Data for a Biological Database: Handcrafted Rules versus Machine Learning","A. K. Sehgal; S. Das; K. Noto; M. Saier; C. Elkan","Parity Computing, La Jolla","IEEE/ACM Transactions on Computational Biology and Bioinformatics","20110314","2011","8","3","851","857","With well over 1,000 specialized biological databases in use today, the task of automatically identifying novel, relevant data for such databases is increasingly important. In this paper, we describe practical machine learning approaches for identifying MEDLINE documents and Swiss-Prot/TrEMBL protein records, for incorporation into a specialized biological database of transport proteins named TCDB. We show that both learning approaches outperform rules created by hand by a human expert. As one of the first case studies involving two different approaches to updating a deployed database, both the methods compared and the results will be of interest to curators of many specialized databases.","1545-5963;15455963","","10.1109/TCBB.2009.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374367","Bioinformatics (genome or protein) databases;association rules;biomedical text classification;classification;clustering;data mining.;text mining","Association rules;Bioinformatics;Computer science;Data mining;Databases;Genomics;Humans;Information retrieval;Machine learning;Proteins","bioinformatics;data analysis;learning (artificial intelligence);molecular biophysics;proteins","MEDLINE documents;Swiss-Prot protein records;TrEMBL protein records;biological databases;data analysis;machine learning;protein sequence","Algorithms;Artificial Intelligence;Carrier Proteins;Cluster Analysis;Data Mining;Databases, Genetic;Genomics;Humans;MEDLINE;Proteins","4","","37","","20100108","May-June 2011","","IEEE","IEEE Journals & Magazines"
"A Fuzzy Logic Approach to Wrapping PDF Documents","S. Flesca; E. Masciari; A. Tagarelli","University of Calabria, Rende","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1826","1841","The PDF format represents the de facto standard for print-oriented documents. In this paper, we address the problem of wrapping PDF documents, which raises new challenges in several contexts of text data management. Our proposal is based on a novel bottom-up hierarchical wrapping approach that exploits fuzzy logic to handle the “uncertainty” which is intrinsic to the structure and presentation of PDF documents. A PDF wrapper is defined by specifying a set of group type definitions that impose a target structure to groups of tokens containing the required information. Constraints on token groupings are formulated as fuzzy conditions, which are defined on spatial and content predicates of tokens. We define a formal semantics for PDF wrappers and propose an algorithm for wrapper evaluation working in polynomial time with respect to the size of a PDF document. The proposed approach has been implemented in a wrapper generation system that offers visual capabilities to assist the designer in specifying and evaluating a PDF wrapper. Experimental results have shown good accuracy and applicability of our system to PDF documents of various domains.","1041-4347;10414347","","10.1109/TKDE.2010.220","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5620910","Adobe PDF;Information extraction;PDFWrap system.;fuzzy logic;print-oriented documents;wrapping","Data mining;Fuzzy logic;Information extraction;Information retrieval;Portable document format;Uncertainty;Visualization","electronic publishing;formal specification;fuzzy logic;printing;programming language semantics;storage management;text analysis","PDF documents wrapping;bottom-up hierarchical wrapping approach;de facto standard;formal semantics;fuzzy logic approach;polynomial time;print-oriented documents;text data management;token groupings;wrapper generation system","","2","","35","","20101109","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Dialog strategies for handling miscommunication in task-related HRI","B. Gonsior; C. Landsiedel; A. Glaser; D. Wollherr; M. Buss","Institute of Automatic Control Engineering (LSR), Technische Universit&#x00E4;t M&#x00FC;nchen, D-80290 Munich, Germany","2011 RO-MAN","20110829","2011","","","369","375","As communication quality in public spaces often is impaired by noisy environment, it is difficult for a robot to retrieve missing task-information from humans. In this paper, different dialog strategies are modeled and evaluated with respect to user experience and error handling capabilities in HRI in order to cope with erroneous speech recognition. Since correct recognition of spoken language is a bottleneck for real-world dialog systems, special emphasis is placed on the issue of adapting dialog strategies to the conditions under which the dialog is held to thereby provide for adaptability of the dialog strategy to variable speech recognition performance. Experimental evaluations are conducted in a fully automated indoor setting, and in a Wizard-of-Oz outdoor setting. Results indicate that a critical point exists, up to which the use of requests for handling miscommunication improves the user experience of a dialog strategy.","1944-9445;19449445","Electronic:978-1-4577-1573-0; POD:978-1-4577-1571-6; USB:978-1-4577-1572-3","10.1109/ROMAN.2011.6005197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005197","","Humans;Information retrieval;Mobile robots;Robot sensing systems;Speech;Speech recognition","human-robot interaction;interactive systems;natural language processing;speech recognition","Wizard-of-Oz outdoor;automated indoor setting;communication quality;dialog strategy;error handling capability;miscommunication handling;noisy environment;public space;speech recognition;spoken language recognition;task information;task-related HRI","","0","","18","","","July 31 2011-Aug. 3 2011","","IEEE","IEEE Conference Publications"
"To ‘dump’ or not to ‘dump’: Changing, supporting or distracting behavior","A. Kamaruddin; A. Dix","Universiti Putra Malaysia, Serdang, Selangor, Malaysia","2010 International Conference on User Science and Engineering (i-USEr)","20110222","2010","","","49","54","The way we manage our personal information varies considerably between users. An exploratory study was conducted to investigate the decision making process when storing new items and in particular their dumping behavior, which we define as putting in some unclassified/partially classified storage. It was found that users `dump' when unsure where to store, do not have the time to decide where to store, or not want to lose sight of data - these all have an impact on future retrieval. Understanding this behavior suggests design opportunities to support users, raising awareness of previously encountered but dumped information.","","Electronic:978-1-4244-9049-3; POD:978-1-4244-9048-6","10.1109/IUSER.2010.5716722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716722","dumping behavior;personal information management","Analytical models;Decision making;Electronic mail;Information management;Information retrieval;Organizations;Organizing","decision making;information management;personal information systems","decision making process;dumping behavior;personal information management","","0","","12","","","13-15 Dec. 2010","","IEEE","IEEE Conference Publications"
"BibPro: A Citation Parser Based on Sequence Alignment","C. C. Chen; K. H. Yang; C. L. Chen; J. M. Ho","National Taiwan University, Taipei","IEEE Transactions on Knowledge and Data Engineering","20111222","2012","24","2","236","250","Dramatic increase in the number of academic publications has led to growing demand for efficient organization of the resources to meet researchers' needs. As a result, a number of network services have compiled databases from the public resources scattered over the Internet. However, publications by different conferences and journals adopt different citation styles. It is an interesting problem to accurately extract metadata from a citation string which is formatted in one of thousands of different styles. It has attracted a great deal of attention in research in recent years. In this paper, based on the notion of sequence alignment, we present a citation parser called BibPro that extracts components of a citation string. To demonstrate the efficacy of BibPro, we conducted experiments on three benchmark data sets. The results show that BibPro achieved over 90 percent accuracy on each benchmark. Even with citations and associated metadata retrieved from the web as training data, our experiments show that BibPro still achieves a reasonable performance.","1041-4347;10414347","","10.1109/TKDE.2010.231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645620","Data integration;digital libraries;information extraction;sequence alignment.","Benchmark testing;Decision support systems;Information retrieval;Internet;Metadata;Resource management;Sequential analysis;Web and internet services","Internet;citation analysis;meta data","BibPro;Internet;World Wide Web;academic publications;citation parser;citation string;metadata extraction;public resources;sequence alignment","","2","","29","","20101129","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"A Content-Based Relevance Feedback Model for Product Review Retrieval","T. Weixin; Z. Sheng; W. Anhui","Inst. of Intell. Vision & Image Inf., China Three Gorges Univ., Yichang, China","2010 Third International Symposium on Information Science and Engineering","20110711","2010","","","236","239","Product review is a kind of useful information on the web. This paper describes a relevance feedback model based on modifying relation for that information retrieval, which utilizes the feedback information not only on the term frequency but also on the deep semantic structures. To calculate the feedback values based on semantic structures, a modifying relations knowledge base (MRKB) is used to measure the similarity between the term in relevant document and the term to be expanded. We propose a method to calculate and adjust the term weight. Experiment shows that our method got higher performance than the baseline when applying to the product review dataset.","2160-1283;21601283","Electronic:978-0-7695-4360-4; POD:978-1-61284-428-2","10.1109/ISISE.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945092","content-based;modifying relation;relevance feedback;review retrieval","Computational modeling;Information processing;Information retrieval;Knowledge based systems;Pollution;Probabilistic logic;Semantics","Internet;content-based retrieval;document handling;relevance feedback;retail data processing","MRKB;Web information;content-based relevance feedback model;information retrieval;modifying relations knowledge base;product review retrieval;semantic structure","","0","","21","","","24-26 Dec. 2010","","IEEE","IEEE Conference Publications"
"Implementation of vector-space online document retrieval system using open source technology","N. Jamil; N. A. Jamaludin; N. A. Rahman; N. Sabari","Department of Computer Science, Faculty of Computer and Mathematical Sciences, Shah Alam, Selangor, Malaysia","2011 IEEE Conference on Open Systems","20111114","2011","","","395","399","Vector-space model is one of the most popular information retrieval models and it has been successfully implemented in retrieving many textual document collections. However, not many vector-space implementations employed open source technology. This paper discusses the integration of Oracle 10g Express edition database and Java language in realizing the development of an online document retrieval system for an Archive and Museum Unit in a public university. The retrieval system is tested on thirty publication documents and natural language queries entered managed to retrieve and ranked the documents successfully.","","Electronic:978-1-61284-931-7; POD:978-1-4799-1691-7","10.1109/ICOS.2011.6079228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079228","digital archive information system;document retrieval;open source technology;vector-space model","Adaptation models;Computational modeling;Databases;Information retrieval;Materials;Mathematical model;Vectors","Java;document handling;electronic publishing;information retrieval;public domain software","Java language;Oracle 10g Express edition database;information retrieval;natural language queries;open source technology;publication documents;textual document collections;vector space implementations;vector space online document retrieval system implementation","","0","","12","","","25-28 Sept. 2011","","IEEE","IEEE Conference Publications"
"Fully-Homomorphic Encryption Based SPIR","H. Zhong; L. Yi; Y. Zhao; X. Yuan; X. Sha","Sch. of Comput. Sci. & Technol., Anhui Univ., Hefei, China","2011 7th International Conference on Wireless Communications, Networking and Mobile Computing","20111010","2011","","","1","3","The booming of the Internet and its applications, especially, the recent trend in outsourcing databases, fuels the research on symmetrically private information retrieval (SPIR) schemes. In this paper, we propose a fully homomorphic encryption based SPIR scheme in order to further improve the communication cost of SPIR from O((log n)<sup>2</sup>) to O(log n). Actually, our schemes can be directly used to implement 1-out-of-n oblivious transfer with O(1) sender-side communication complexity.","2161-9646;21619646","Electronic:978-1-4244-6252-0; POD:978-1-4244-6250-6","10.1109/wicom.2011.6040523","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040523","","Complexity theory;Encryption;Information retrieval;Noise;Protocols;Servers","Internet;computational complexity;cryptography","Internet;communication cost;fully-homomorphic encryption based SPIR;sender-side communication complexity;symmetric private information retrieval scheme","","0","","8","","","23-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"Opposite re-ranking based on relevant sub-topic dispelling","Song Hua; Yan-han Zhang; Yu Hong; Jian-min Yao; Qiao-ming Zhu","School of Computer Science and Technology, Soochow University, No.1 Shizi Street, Suzhou City, Jiangsu Province, China","The 2nd International Conference on Information Science and Engineering","20110117","2010","","","3851","3854","Opposite re-ranking is a novel strategy to personalized information retrieval, it utilizes the description structure opposed to query intention, to achieve the recognition and dispelling of obstinate-negative feedback. At present, an important problem of the research in the opposite re-ranking is how to establish the maximum discriminative and representative opposite query intention. Aiming at the problem, this paper proposes an opposite re-ranking method based on dispelling of the relevant subtopics for the optimization of result list. The experiment makes use of TDT4 corpora to test, the results present this approach improves the search performance dramatically, the MAP enhances by 16 percents, P@20 and NDCG@20 increases by 14 percents and 12 percents respectively.","2160-1283;21601283","DVD:978-1-4244-7617-6; Electronic:978-1-4244-7618-3; POD:978-1-4244-7616-9","10.1109/ICISE.2010.5688547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5688547","Clustering;Opposite intent;Re-ranking;Subtopics","Feature extraction;Information retrieval;Optimization;Presses;Semantics;Sorting;USA Councils","","","","0","","9","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"A query expansion based on sentence and vector integration strategy","M. Peng; M. Yang; S. Sun; H. Long; N. Ghani; B. Ni","Wuhan University","The 5th International Conference on New Trends in Information Science and Service Science","20111201","2011","1","","41","45","This paper proposes a novel query expansion method to improve the average precision of the original query for information retrieval. The scheme uses a graph-based ranking algorithm to choose sentences in a manner which is different from existing sentence-based query expansion methods. At the same time a synthesis strategy for sentences is also built to construct new queries. The proposed solution is analyzed using DUC09 test collection data for update summarization task. Overall evaluation results show that the proposed method improves performance by yielding more relevant information with less noise.","","Electronic:978-89-88678-50-3; POD:978-1-4577-0665-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093389","Information retrival;graph-based ranking algorithm;sentence-based query exponsion","Algorithm design and analysis;Context;Indexing;Information retrieval;Large scale integration;Semantics;Vectors","graph theory;query processing","graph-based ranking algorithm;information retrieval;query expansion;sentence integration strategy;vector integration strategy","","0","","11","","","24-26 Oct. 2011","","IEEE","IEEE Conference Publications"
"An Evaluation of the Formal Concept Analysis-Based Document Vector on Document Clustering","J. C. Jehng; S. Chou; C. Y. Cheng; J. S. Heh","Inst. of Human Resource Manage., Nat. Central Univ., Jhongli, Taiwan","2011 International Conference on Computational Science and Its Applications","20110721","2011","","","207","210","In conventional approaches, documents are represented by the vector whose dimensionalities are equivalent to the terms extracted from a document set. These approaches, called bag-of-term approaches, ignore the conceptual relationships between terms such as synonyms, hypernyms and hyponyms. In the past, researches have applied thesauri such as Word Net to solve this problem. However, thesauri such as Word Net are developed more for general purposes and are limited in specific domain. Therefore, an automatically built ontology for terms is desired. In our previous study, we proposed a method which applies formal concept analysis (FCA), an automatic ontology building method, to extract the term relationships from a document set, and then apply the extracted information as the ontology of terms to represent the documents as concept vectors. In order to evaluate the usability and effectiveness of the proposed method for information retrieval related applications, we employed the concept vectors generated for the documents to the document clustering. In this study, we apply bisecting k-means clustering and hierarchical agglomerative clustering as the platforms with which to evaluate our method.","","Electronic:978-0-7695-4404-5; POD:978-1-4577-0142-9","10.1109/ICCSA.2011.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959620","Concept vector;Document clustering;Document vector;Formal concept analysis;Term Ontology","Clustering algorithms;Context;Data mining;Information retrieval;Lattices;Ontologies;Thesauri","document handling;information retrieval;ontologies (artificial intelligence);pattern clustering;vectors","automatic ontology building method;bag-of-term approach;bisecting k-means clustering;document clustering;document vector;formal concept analysis;hierarchical agglomerative clustering;information retrieval;term relationship extraction","","1","","23","","","20-23 June 2011","","IEEE","IEEE Conference Publications"
"A new stemmer for Farsi language","S. Estahbanati; R. Javidan","Department of Computer Engineering, Islamic Azad University Science and Research Branch, Khoozestan, Iran","2011 CSI International Symposium on Computer Science and Software Engineering (CSSE)","20110728","2011","","","25","29","In this paper, we report on the design and implementation of a stemmer for the Farsi language, according to combination of Kazem Taghva's method and improved Krovetz's method. The first method removes the suffixes and prefixes according to the word's structure. And the second method is based on saving the information in a Database. This paper reports a kind of combination of these methods. The results of our evaluation on a small Farsi document collection show a significant improvement in precision/recall.","","Electronic:978-1-61284-207-3; POD:978-1-61284-206-6","10.1109/CSICSSE.2011.5963993","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963993","Farsi language;Persian Language;Stemming;algorithm","Algorithm design and analysis;Computers;Databases;Europe;Information retrieval;Internet;Morphology","document handling;natural language processing","Farsi document collection;Farsi language;Kazem Taghva method;Krovetz method;stemmer","","1","","15","","","15-16 June 2011","","IEEE","IEEE Conference Publications"
"Improved Terms Weighting Algorithm of Text","M. Zhanguo; F. Jing; H. Xiangyi; S. Yanqin; C. Liang","Dept. of Inf. Technol., Beijing Sci. & Technol. Inf. Inst., Beijing, China","2011 International Conference on Network Computing and Information Security","20110711","2011","2","","367","370","Most of traditional information retrieval and automatic text classification methods with vector space model almost need determine the weighting of the feature terms. Term weighting plays an important role to achieve high performance in information retrieval and text classification. The popular method is using term frequency (tf) and inverse document frequency (idf) for representing importance and computing weighting of terms. But the tf-idf model is not introduced class information, the important information such as title, abstract, conclusion, and the synonymous words information. This paper provides an improved method to compute weighting of the terms. The above information is involved. The experimental results show that the performance is enhanced. The role of important and representative terms is raised and the effect of the unimportant feature term to retrieval and classification is decreased. In addition, the F1 based on new algorithm is higher than based on traditional tf-idf model.","","Electronic:978-0-7695-4355-0; POD:978-1-61284-347-6","10.1109/NCIS.2011.171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948854","information tetrieval;term weighting;text classification;vector space model","Classification algorithms;Computers;Equations;Information retrieval;Mathematical model;Support vector machine classification;Text categorization","information retrieval;pattern classification;text analysis","improved terms weighting algorithm;information retrieval;inverse document frequency;term frequency;text classification;tf-idf model;vector space model","","2","","14","","","14-15 May 2011","","IEEE","IEEE Conference Publications"
"Query expansion based on Conceptual Word Cluster Space Graph","M. Peng; Q. Lin; Y. Tian; M. Yang; Y. Xiao; B. Ni","Wuhan University, Wuhan, China","The 5th International Conference on New Trends in Information Science and Service Science","20111201","2011","1","","128","133","For the information retrieval problem, the query expansion methods have been studied for a long time. However, the performance still can't meet the requirements of the users. In this paper, we present a directed graph model, named Conceptual Word Cluster Space Graph (CWCSG), which is constructed to express the semantic similarity among concepts. There are three steps to construct the CWCSG. First, the conceptual words are transformed to different terms. Then, the terms are clustered to different Conceptual Word Clusters (CWCs). After the extraction of CWCs, we calculate the co-occurrence relationship between CWCs to construct CWCSG. Based on CWCSG, user's query is extended to meet user's search requirement in a more accurate way. The experiments show that our method can provide a better performance comparing to classic synonymous dictionary of WordNet.","","Electronic:978-89-88678-50-3; POD:978-1-4577-0665-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093406","","Educational institutions;Information retrieval;Large scale integration;Natural language processing;Semantics;Training;Vectors","directed graphs;information retrieval","conceptual word cluster space graph;directed graph model;information retrieval problem;query expansion;semantic similarity","","0","","12","","","24-26 Oct. 2011","","IEEE","IEEE Conference Publications"
"Fuzzy classification by evolutionary algorithms","P. Krömer; J. Platoš; V. Snášel; A. Abraham","Faculty of Electrical Engineering and Computer Science, VSB-Technical University of Ostrava, 17. listopadu 12, Poruba, Czech Republic","2011 IEEE International Conference on Systems, Man, and Cybernetics","20111121","2011","","","313","318","Fuzzy sets and fuzzy logic can be used for efficient data classification by fuzzy rules and fuzzy classifiers. This paper presents an application of genetic programming to the evolution of fuzzy classifiers based on extended Boolean queries. Extended Boolean queries are well known concept in the area of fuzzy information retrieval. An extended Boolean query represents a complex soft search expression that defines a fuzzy set on the collection of searched documents. We interpret the data mining task as a fuzzy information retrieval problem and we apply a proven method for query induction from data to find useful fuzzy classifiers. The ability of the genetic programming to evolve useful fuzzy classifiers is demonstrated on two use cases in which we detect faulty products in a product processing plant and discover intrusions in a computer network.","1062-922X;1062922X","Electronic:978-1-4577-0653-0; POD:978-1-4577-0652-3","10.1109/ICSMC.2011.6083684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083684","data mining;evolutionary computing;fuzzy sets","Biological cells;Data mining;Genetic programming;Information retrieval;Intrusion detection;Training","data mining;document handling;fuzzy logic;fuzzy set theory;genetic algorithms;pattern classification;query processing;security of data","computer network;data classification;data mining;document retrieval;evolutionary algorithms;extended Boolean queries;fuzzy classification;fuzzy information retrieval;fuzzy logic;fuzzy rules;fuzzy sets;genetic programming;intrusion;query induction","","15","","19","","","9-12 Oct. 2011","","IEEE","IEEE Conference Publications"
"R-tfidf, a Variety of tf-idf Term Weighting Strategy in Document Categorization","D. Zhu; J. Xiao","Digital Dialogue Media Pty Ltd., Fremantle, WA, Australia","2011 Seventh International Conference on Semantics, Knowledge and Grids","20111201","2011","","","83","90","Term weighting strategy plays an essential role in the areas related to text processing such as text categorization and information retrieval. In such systems, term frequency, inverse document frequency, and document length normalization are important factors to be considered when a term weighting strategy is developed. Term length normalization is proposed to give equal opportunities to retrieve both lengthy documents and shorter ones. However, terms in very short documents that may be useless for users, especially in the scenario of Web information retrieval, could be assigned very high weights, resulting in a situation where shorter documents are ranked higher than lengthy documents that are more relevant to users information needs. In this research, a new R-tfidf term weighting strategy is proposed to alleviate the side effects of document length normalization. Experimental results demonstrate the proposed approach can to some extent improve the performance of text categorization.","","Electronic:978-0-7695-4515-8; POD:978-1-4577-1323-1","10.1109/SKG.2011.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6088095","term-weighting;text categorization;tf-idf","Frequency estimation;Information retrieval;Probabilistic logic;Support vector machine classification;Text categorization;Time frequency analysis;Training","information retrieval;text analysis","R-tfidf;document categorization;document length normalization;information retrieval;inverse document frequency;term weighting strategy;text processing","","0","","20","","","24-26 Oct. 2011","","IEEE","IEEE Conference Publications"
"Research on information tips in the search box","Xiaosheng Yu","Information Management School, Wuhan University, China","2011 International Conference on Computer Science and Service System (CSSS)","20110804","2011","","","2480","2482","With the rapid expansion of information in the network environment, it brings many challenges for information retrieval staff. It seems to be a pair of contradictions between the searchers' retrieval skill and the rapid expansion of information. On the one hand, the website developers must carefully consider arranging the retrieval key words in order to ensure the users to be able to meet their needs. On the other hand, the users should also accurately utilize retrieval key words to obtain information which they need. Frequently, after retrieval, the users have already lost the interest to the website or they have wasted a lot of precious time. According to the similar users' searching habits, information tips in the search box attempt to provide a suggestion list to the users, which can help users to ensure their own demands as soon as possible, and then help users to quickly, accurately and conveniently search the information which they want. It can not only improve the users' satisfaction, but also reduce the website developers' workload. This function can make the user interface more friendly and help users to avoid typing wrong words. In the paper, the authors discuss Ajax related technologies, and information tips in the search box model based on Ajax is established. Finally, this model is implemented by using Ajax.","","DVD:978-1-4244-9761-4; Electronic:978-1-4244-9763-8; POD:978-1-4244-9762-1","10.1109/CSSS.2011.5974906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974906","Ajax;Information Tips;PHP;Search Box","Databases;Engines;Humans;Information retrieval;Monitoring;Servers;XML","information retrieval;user interfaces","Ajax;information expansion;information retrieval staff;information tip;search box;suggestion list;user interface;user satisfaction;user searching habit","","0","","7","","","27-29 June 2011","","IEEE","IEEE Conference Publications"
"Research on Geo-event Ontology Construction Oriented Task","B. Li; L. Shi; J. Liu; T. Kunwang","Chinese Acad. of Surveying & Mapping, Beijing, China","2011 International Conference on Network Computing and Information Security","20110711","2011","1","","147","151","It is difficult to organize the spatial information according to geographic events in the existed system. And the system can't provide the users spatial information correlative to event disposal on its own initiative. Analyzing the method oriented task and centering about the task, a feasible means is introduced in this paper to be used to construct Geo-event ontology to serve the semantic retrieval, which can dispose the semantic heterology between different geographic information source, predigest the course of ontology construction and improve the efficiency of using ontology so as to redound to the distributed spatial share.","","Electronic:978-0-7695-4355-0; POD:978-1-61284-347-6","10.1109/NCIS.2011.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5948707","Geo-event ontology;model;task","Cities and towns;Earthquakes;Information retrieval;Ontologies;Roads;Semantics;Unified modeling language","geographic information systems;information retrieval;ontologies (artificial intelligence)","distributed spatial share;event disposal;geo-event ontology construction oriented task;geographic event;geographic information source;method oriented task;semantic heterology;semantic retrieval;spatial information;spatial information correlation","","0","","9","","","14-15 May 2011","","IEEE","IEEE Conference Publications"
"Automatic question answering for Turkish with pattern parsing","E. Çelebi; B. Günel; B. Şen","Department of Computer, Enginering Cyprus International University","2011 International Symposium on Innovations in Intelligent Systems and Applications","20110711","2011","","","389","393","In this study we have explained the implementation details of a Automatic Question Answering System for Turkish. Automatic Question Answering (QA) is a sub-field of information retrieval (IR) that deals with finding the answers of submitted free text questions. Automatic QA is important for daily life because, it retrieves the answers or answer sets of submitted questions without wasting time for searching the entire document corpus that include the answers. The important issue in QA systems is to extract the features of each sentence to create their semantic meaning. In this study, documents are processed with pattern matching techniques and features of documents are extracted for question answering system. We propose to categorize the questions automatically and then select the correct answer from corresponding answer set. We have used name entity recognition and pattern matching to categorize the type of questions. Additionally we have used range queries to submit the questions. Instead of using traditional distance metrics we have proposed a new approach to rank the similar documents. Each approach has been evaluated and described in this study.","","Electronic:978-1-61284-922-5; POD:978-1-61284-919-5","10.1109/INISTA.2011.5946098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946098","Automatic Question Answering;Named Entity Recognition;Pattern Matching;Turkish Stemmer","Databases;Feature extraction;Information retrieval;Organizations;Pattern matching;Semantics","document handling;pattern matching;query processing;question answering (information retrieval)","Turkey;document ranking;information retrieval;name entity recognition;pattern matching technique;pattern parsing;question answering;range query","","1","","18","","","15-18 June 2011","","IEEE","IEEE Conference Publications"
"Proximity-based ranking of biomedical texts","Rey-Long Liu; Yi-Chih Huang","Department of Medical Informatics, Tzu Chi University, Hualien, Taiwan","The 2nd International Conference on Information Science and Engineering","20110117","2010","","","2261","2264","Biomedical decision making and research often require relevant evidences in the huge and ever-growing biomedical literature. Retrieval of the evidences calls for a system that accepts a natural language query for a biomedical information need, and among the large number of texts retrieved for the query, ranks relevant texts higher for access or processing. However, state-of-the-art text rankers have a weakness in dealing with biomedical queries, which often consists of several correlating concepts and prefers those texts that talk about the concepts completely. In this paper, we present a technique PRE (Proximity-based Ranker Enhancer) that measures contextual completeness of query concepts appearing in a nearby area in the text, and based on the contextual completeness, assesses the term frequency (TF) of each term in the text. Therefore, those rankers that consider TF in ranking may be supplemented with PRE, without needing to change the algorithms and development processes of the rankers. Moreover, PRE is efficient to conduct the TF assessment, and neither training process nor training data is required. Empirical evaluation shows that PRE significantly improves several state-of-the-art rankers, and is better than several state-of-the-art techniques aiming at improving rankers.","2160-1283;21601283","DVD:978-1-4244-7617-6; Electronic:978-1-4244-7618-3; POD:978-1-4244-7616-9","10.1109/ICISE.2010.5690335","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5690335","Biomedical Query;Biomedical Text Ranking;Contextual Completeness;Supplement to Text Rankers","Biomedical measurements;Diseases;Information retrieval;Length measurement;Time frequency analysis;Training","","","","0","","18","","","4-6 Dec. 2010","","IEEE","IEEE Conference Publications"
"A Web Search Engine-Based Approach to Measure Semantic Similarity between Words","D. Bollegala; Y. Matsuo; M. Ishizuka","The University of Tokyo, Tokyo","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","7","977","990","Measuring the semantic similarity between words is an important component in various tasks on the web such as relation extraction, community mining, document clustering, and automatic metadata extraction. Despite the usefulness of semantic similarity measures in these applications, accurately measuring semantic similarity between two words (or entities) remains a challenging task. We propose an empirical method to estimate semantic similarity using page counts and text snippets retrieved from a web search engine for two words. Specifically, we define various word co-occurrence measures using page counts and integrate those with lexical patterns extracted from text snippets. To identify the numerous semantic relations that exist between two given words, we propose a novel pattern extraction algorithm and a pattern clustering algorithm. The optimal combination of page counts-based co-occurrence measures and lexical pattern clusters is learned using support vector machines. The proposed method outperforms various baselines and previously proposed web-based semantic similarity measures on three benchmark data sets showing a high correlation with human ratings. Moreover, the proposed method significantly improves the accuracy in a community mining task.","1041-4347;10414347","","10.1109/TKDE.2010.172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582093","Web mining;information extraction;web text analysis.","Context;Data mining;Information retrieval;Search engines;Semantics;Support vector machines;Text processing;Web search","Internet;data mining;information retrieval;pattern clustering;search engines;support vector machines;text analysis","Web search engine;Web-based semantic similarity measures;benchmark data sets;community mining task;lexical pattern clusters;lexical patterns;numerous semantic relations;optimal combination;page counts-based co-occurrence measures;pattern clustering algorithm;pattern extraction algorithm;semantic similarity between words;support vector machines;text snippets;word co-occurrence measures","","67","","47","","20100923","July 2011","","IEEE","IEEE Journals & Magazines"
"Furniture Models Learned from the WWW","O. M. Mozos; Z. C. Marton; M. Beetz","Human-Symbiotic Intelligent Robots Lab, Kyushu University, Fukuoka, Japan.","IEEE Robotics & Automation Magazine","20110616","2011","18","2","22","32","In this article, we investigate how autonomous robots can exploit the high quality information already available from the WWW concerning 3-D models of office furniture. Apart from the hobbyist effort in Google 3-D Warehouse, many companies providing office furnishings already have the models for considerable portions of the objects found in our workplaces and homes. In particular, we present an approach that allows a robot to learn generic models of typical office furniture using examples found in the Web. These generic models are then used by the robot to locate and categorize unknown furniture in real indoor environments.","1070-9932;10709932","","10.1109/MRA.2011.940996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5876205","","Design automation;Information retrieval;Marketing and sales;Online services;Robot programmig;Shape measurement;Solid modeling;World Wide Web","Internet;control engineering computing;furniture;mobile robots;office automation;solid modelling","3D model;WWW;World Wide Web;autonomous robot;office furniture model","","14","","35","","","June 2011","","IEEE","IEEE Journals & Magazines"
"Improving Query Suggestion for Digital Libraries","L. Chao; Y. Zhang; C. Xing","Res. Inst. of Inf. Technol., Tsinghua Univ., Beijing, China","2011 IEEE 35th Annual Computer Software and Applications Conference Workshops","20111003","2011","","","428","434","The users of a digital library often have difficulty in formulating query expression that could represent his or her information requirements exactly. Query suggestion can provide some recommended query expression and help the user build a proper expression. Query suggestion for digital libraries requires higher precision ratio and novelty ratio than that of web search engines. Based on case studies, we found that there are four main types of query suggestion within digital library environments, namely spelling suggestion, hot keyword suggestion, personalized suggestion and semantic suggestion. These approaches are, however, hardly to ensure high precision ratio and novelty ratio expected by digital library users to date. The paper proposed an improved query suggestion approach for digital library and its main advantages lie in computing semantic relations, finding hot concepts and ranking candidate concepts. Semantic similarity between user's input and a candidate keyword is calculated by Relative Information Loss (RIL). Hot keywords are indentified by a new algorithm, which involving clicked time, novelty clicked time, result record number, novelty result record. The rank degree of a keyword is evaluated by its RIL and hot degree. Finally, a software component that takes advantage of DBpedia Ontology, Jena, Ajax and SPARQL in align with these new improvements is developed and deployed on a digital library named iDLib. Better user experience with our new query suggestion software component proves the feasibility and efficiency of the improvement.","","Electronic:978-07695-4459-5; POD:978-1-4577-0980-7","10.1109/COMPSACW.2011.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032276","Digital Library;Keyword Suggestion;Query Suggestions;Semantic Suggestion;iDlib","Databases;Information retrieval;Libraries;OWL;Ontologies;Semantics;Software","digital libraries;query formulation;recommender systems","Ajax;DBpedia Ontology;Jena;SPARQL;Web search engines;digital libraries;hot keyword suggestion;iDLib;personalized suggestion;query expression formulation;query suggestion software component;relative information loss;semantic suggestion","","0","","21","","","18-22 July 2011","","IEEE","IEEE Conference Publications"
"Tiny Videos: A Large Data Set for Nonparametric Video Retrieval and Frame Classification","A. Karpenko; P. Aarabi","University of Toronto, Toronto","IEEE Transactions on Pattern Analysis and Machine Intelligence","20110117","2011","33","3","618","630","In this paper, we present a large database of over 50,000 user-labeled videos collected from YouTube. We develop a compact representation called “tiny videos” that achieves high video compression rates while retaining the overall visual appearance of the video as it varies over time. We show that frame sampling using affinity propagation - an exemplar-based clustering algorithm - achieves the best trade-off between compression and video recall. We use this large collection of user-labeled videos in conjunction with simple data mining techniques to perform related video retrieval, as well as classification of images and video frames. The classification results achieved by tiny videos are compared with the tiny images framework for a variety of recognition tasks. The tiny images data set consists of 80 million images collected from the Internet. These are the largest labeled research data sets of videos and images available to date. We show that tiny videos are better suited for classifying scenery and sports activities, while tiny images perform better at recognizing objects. Furthermore, we demonstrate that combining the tiny images and tiny videos data sets improves classification precision in a wider range of categories.","0162-8828;01628828","","10.1109/TPAMI.2010.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487525","Image classification;content-based retrieval;data mining;nearest-neighbor methods.;tiny images;tiny videos","Clustering algorithms;Data mining;Image coding;Image recognition;Image retrieval;Image sampling;Information retrieval;Video compression;Visual databases;YouTube","data compression;data mining;image classification;image representation;pattern clustering;sampling methods;video coding;video retrieval","Internet;YouTube;affinity propagation;data mining techniques;exemplar based clustering algorithm;frame sampling;high video compression rates;nonparametric video retrieval;tiny videos;user labeled videos;video frames classification;video recall;visual appearance","Algorithms;Artificial Intelligence;Cluster Analysis;Database Management Systems;Databases, Factual;Fractals;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Internet;Pattern Recognition, Automated;Video Recording;Videotape Recording","19","","27","","20100617","March 2011","","IEEE","IEEE Journals & Magazines"
"Query Expansion for UMLS Metathesaurus Disambiguation Based on Automatic Corpus Extraction","A. J. Yepes; A. R. Aronson","Nat. Libr. of Med., Bethesda, MD, USA","2010 Ninth International Conference on Machine Learning and Applications","20110204","2010","","","965","968","Word sense disambiguation (WSD) is an intermediate task within information retrieval and information extraction, which attempts selecting the proper sense of ambiguous terms. In the biomedical domain, general WSD has not received much attention compared to the disambiguation of specific categories of entities like proteins and genes or diseases. Statistical learning approaches have achieved better performance compared to other methods. On the other hand, manually annotated data is limited, and covering all the ambiguous cases of a large resource like the UMLS is infeasible. Knowledge-based approaches using the UMLS and MEDLINE citations have achieved good performance but below that of statistical learning approaches. Our best knowledge-based result has been obtained by training a Naïve Bayes algorithm on an automatically extracted MEDLINE corpus. In this work, we extend on previous methods to enhance the quality of an automatically extracted corpus using related terms obtained from MEDLINE without manually annotated training data. We have focused on the extraction of collocations which might be used in combination with one of the senses of the ambiguous terms. We find that left side collocations have the largest improvement in accuracy with an improvement of 4%. In addition, the combination of different types of collocations and post-filtering of retrieved citations achieves an improvement of almost 9% in accuracy.","","Electronic:978-0-7695-4300-0; POD:978-1-4244-9211-4","10.1109/ICMLA.2010.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708977","Collocation extraction;Combination of approaches;Text categorization;UMLS;Word Sense Disambiguation","Accuracy;Data mining;Feature extraction;Information retrieval;Knowledge based systems;Semantics;Unified modeling language","learning (artificial intelligence);query processing;text analysis;thesauri","UMLS metathesaurus disambiguation;automatic corpus extraction;information extraction;information retrieval;knowledge-based approaches;naïve Bayes algorithm;query expansion;statistical learning;word sense disambiguation","","3","","10","","","12-14 Dec. 2010","","IEEE","IEEE Conference Publications"
"Notice of Violation of IEEE Publication Principles<BR>A Study on Secure Multiparty Computation Problems and Their Relevance","Z. Shaikh; D. K. Mishra","Master of Comput. Applic., Acropolis Inst. of Technol. & Res., Indore, India","2010 Second International Conference on Computational Intelligence, Modelling and Simulation","20110128","2010","","","95","99","Notice of Violation of IEEE Publication Principles<BR><BR>""A Study on Secure Multiparty Computation Problems and Their Relevance""<BR>by Shaikh, Z., Mishra, D.K<BR>published in the 2010 Second International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM), 2010, pp.95-99<BR><BR>After careful and considered review of the content and authorship of this paper by a duly constituted expert committee this paper has been found to be in violation of IEEE's Publication Principles. The committee has found Z. Shaikh to be the sole offending author and that D.K. Mishra was not involved in the offense.<BR><BR>This paper contains significant portions of original text from the paper cited below. The original text was copied with insufficient attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<BR><BR>Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:<BR><BR>""Secure multi-party computation problems and their applications: a review and open problems""<BR>by Wenliang Du and Mikhail J. Atallah<BR>published in the Proceedings of the 2001 workshop on New security paradigms (NSPW '01), 2001, pp. 13 - 23 <BR><BR>The growth of the Internet has prompted tremendous opportunities for cooperative computation, where people are jointly conducting computation tasks based on the private inputs they each supplies. These computations can occur between mutually untrusted parties, or even between competitors. For example, customers might send to a remote database queries that contain private information, two competing financial organizations might jointly invest in a project that must satisfy both organizations private and valuable constraints, and so on. Today, to conduct such computations, one entity must usually know the inputs from all the participants, however if nobody can be trust- d enough to know all the inputs, privacy will become a primary concern. This problem is referred to as Secure Multi-party Computation Problem (SMC) in the literature. Research in the SMC area has been focusing on only a limited set of specific SMC problems, while privacy concerned cooperative computations call for SMC studies in a variety of computation domains. Before we can study the problems, we need to identify and define the specific SMC problems for those computation domains. We have developed a scaffold to facilitate this problem-discovery task. Based on our framework, we have identified and defined a number of SMC problems for a range of computation domains. The goal of this paper is not only to present our results, but also to serve as a guideline so other people can identify useful SMC problems in their own computation fields. During computation of inputs, we had also considered the factor, what if trusted third parties are malicious? Considering different probabilities for the malicious users, we have tried to find out the correctness of the result and percentage of system acceptability. We then tried to increase the number of TTP's in order to get the accuracy of the result. The aim of our proposed work is to identify what probability of malicious users will lead to the system in an unacce- table state.","2166-8523;21668523","Electronic:978-0-7695-4262-1; POD:978-1-4244-8652-6","10.1109/CIMSiM.2010.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5701827","Privacy;Trusted Third Party;secure multi-party computation","Data mining;Databases;Equations;Information retrieval;Mathematical model;Privacy;Protocols","Internet;data privacy","Internet;malicious user probability;privacy concerned cooperative computations;problem-discovery task;secure multiparty computation problem;trusted third party","","0","","14","","","28-30 Sept. 2010","","IEEE","IEEE Conference Publications"
"Returning Clustered Results for Keyword Search on XML Documents","X. Liu; C. Wan; L. Chen","Jiangxi University of Finance and Economics, Nanchang","IEEE Transactions on Knowledge and Data Engineering","20111020","2011","23","12","1811","1825","Keyword search is an effective paradigm for information discovery and has been introduced recently to query XML documents. In this paper, we address the problem of returning clustered results for keyword search on XML documents. We first propose a novel semantics for answers to an XML keyword query. The core of the semantics is the conceptually related relationship between keyword matches, which is based on the conceptual relationship between nodes in XML trees. Then, we propose a new clustering methodology for XML search results, which clusters results according to the way they match the given query. Two approaches to implement the methodology are discussed. The first approach is a conventional one which does clustering after search results are retrieved; the second one clusters search results actively, which has characteristics of clustering on the fly. The generated clusters are then organized into a cluster hierarchy with different granularities to enable users locate the results of interest easily and precisely. Experimental results demonstrate the meaningfulness of the proposed semantics as well as the efficiency of the proposed methods.","1041-4347;10414347","","10.1109/TKDE.2011.183","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989812","XML keyword search;cluster hierarchy.;search results clustering","Cloud computing;Clustering algorithms;Databases;Keyword search;Pattern matching;Search methods;Semantics;XML;information retrieval","XML;query processing","XML document query;XML keyword query;XML trees;eXtensible Markup Language;information discovery;keyword search","","5","","31","","20110818","Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Music genre recognition using spectrograms","Y. M. G. Costa; L. S. Oliveira; A. L. Koericb; F. Gouyon","State University of Maringa, Maringa, Brazil","2011 18th International Conference on Systems, Signals and Image Processing","20110808","2011","","","1","4","In this paper we present an alternative approach for music genre classification which converts the audio signal into spectrograms and then extracts features from this visual representation. The idea is that treating the time-frequency representation as a texture image we can extract features to build reliable music genre classification systems. The proposed approach also takes into account a zoning mechanism to perform local feature extraction, which has been proved to be quite efficient. On a very challenging dataset of 900 music pieces divided among 10 music genres, we have demonstrated that the classifier trained with texture compares similarly to the literature. Besides, when it was combined with other classifiers trained with short-term, low-level characteristics of the music audio signal we got an improvement of about 7 percentage points in the recognition rate.","2157-8672;21578672","Electronic:978-9958-9966-1-0; POD:978-1-4577-0074-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5977391","","Databases;Feature extraction;Multiple signal classification;Music information retrieval;Spectrogram;Support vector machines;Training","audio signal processing;feature extraction;music;signal classification;signal representation;visual perception","local feature extraction;music audio signal;music genre classification;music genre recognition;spectrograms;texture image;time-frequency representation;visual representation;zoning mechanism","","5","","13","","","16-18 June 2011","","IEEE","IEEE Conference Publications"
"Don't Read Books","N. Serrano; J. Campos-Capelastegui","University of Navarra","IEEE Software","20110228","2011","28","2","92","94","Reading is a critical habit to learn and keeping current. But books aren't the only thing available to read. The articles discuss pros and cons of articles related to books and how to organize and choose your readings. Reading articles is a good source of knowledge and will help you to read better, read better books, and even read more books.","0740-7459;07407459","","10.1109/MS.2011.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720715","articles;book;career development;continuous training;reading","Books;Electronic mail;Electronic publishing;Information resources;Information retrieval","","","","0","","","","","March-April 2011","","IEEE","IEEE Journals & Magazines"
"Dimensionality Reduction for Data Visualization [Applications Corner]","S. Kaski; J. Peltonen","A professor of computer science at Aalto University and director of the Helsinki Institute for Information Technology (HIIT).","IEEE Signal Processing Magazine","20110217","2011","28","2","100","104","Dimensionality reduction is one of the basic operations in the toolbox of data analysts and designers of machine learning and pattern recognition systems. Given a large set of measured variables but few observations, an obvious idea is to reduce the degrees of freedom in the measurements by rep resenting them with a smaller set of more ""condensed"" variables. Another reason for reducing the dimensionality is to reduce computational load in further processing. A third reason is visualization.","1053-5888;10535888","","10.1109/MSP.2010.940003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714379","","Data models;Data visualization;Information retrieval;Machine learning;Manifolds;Probabilistic logic;Visualization","data visualisation;learning (artificial intelligence);pattern recognition","data visualization;dimensionality reduction;machine learning;pattern recognition systems","","9","","17","","","March 2011","","IEEE","IEEE Journals & Magazines"
"Multimodal image collection summarization using non-negative matrix factorization","J. E. Camargo; F. A. González","Bioingenium Research Group, Universidad Nacional de Colombia","2011 6th Colombian Computing Congress (CCC)","20110630","2011","","","1","6","The huge amount of biomedical images that are produced every day require of suitable methods to access them in an efficient and effective way. Although there has been an important development in methods to search large information repositories, these methods have been mainly focused on text data, and less work has been devoted to non-text data such as images and video. This paper presents a new method that combines text and visual information in the same latent representation space in which images and text are jointly represented. We also investigate how to select the most representative elements of the collection to build an image collection summary. The proposed method was applied to a collection of histological images and the results where evaluated both qualitatively and quantitatively by an expert. The initial results show that the proposed method is able to build a meaningful summary that can be integrated in an image collection exploration system.","","Electronic:978-1-4577-0286-0; POD:978-1-4577-0285-3","10.1109/COLOMCC.2011.5936291","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5936291","CBIR;multimodal image retrieval;summarization","Biomedical imaging;Image retrieval;Information retrieval;Kidney;Matrix decomposition;Semantics;Visualization","image representation;image retrieval;matrix decomposition;medical image processing;text analysis","biomedical images;histological images;image collection exploration system;information repositories;multimodal image collection summarization;nonnegative matrix factorization;text information;visual information","","1","","18","","","4-6 May 2011","","IEEE","IEEE Conference Publications"
"Good to be Bad? Distinguishing between Positive and Negative Citations in Scientific Impact","D. C. Cavalcanti; R. B. C. Prudêncio; S. S. Pradhan; J. Y. Shah; R. S. Pietrobon","Centro de Inf., Univ. Fed. de Pernambuco, Recife, Brazil","2011 IEEE 23rd International Conference on Tools with Artificial Intelligence","20111215","2011","","","156","162","The impact of a publication is often measured by the number of citations it received, this number being taken as a proxy for the relevance of published work. However, a higher citation index does not necessarily mean that a publication necessarily had a positive feedback from citing authors, as a citation can represent a negative criticism. In order to overcome this limitation, we used sentiment analysis to rate citations as positive, neutral or negative. Adjectives are initially extracted from the citations, with the SentiWordNet lexicon being used to rate the degree of positivity and negativity for each adjective. Relevance scores were then computed to rank citations according to the sentiment expressed in the text corresponding to each citation. As expected for accurate information retrieval systems, higher precision rates were observed in the initial points of the curve. The SRC (0.6728) computed using number of raw citations is lower than the SRC (0.7397) observed by the ranking generated using sentiment scores (Table 3). Conclusion: This result indicates that child articles with higher values of relevance score were in general the ones expressing positive opinion about their parents. Therefore, the ranking generated by sentiment scores had an improved accuracy.","1082-3409;10823409","Electronic:978-0-7695-4956-7; POD:978-1-4577-2068-0","10.1109/ICTAI.2011.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103321","Impact Factor;SentiWordNet;Sentiment Analysis;Spearman Ranking Correlation","Bibliometrics;Cancer;Equations;Google;Information retrieval;Mathematical model;Position measurement","citation analysis;indexing","SentiWordNet lexicon;adjective;citation index;citation ranking;citing authors;information retrieval system;negative citation;negative criticism;neutral citation;positive citation;positive feedback;relevance scores;scientific impact;sentiment analysis;sentiment scores","","3","","25","","","7-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"Analysis of preprocessing methods on classification of Turkish texts","D. Torunoğlu; E. Çakirman; M. C. Ganiz; S. Akyokuş; M. Z. Gürbüz","Department of Computer Engineering, Do&#x011F;u&#x015F; University, Istanbul, Turkey","2011 International Symposium on Innovations in Intelligent Systems and Applications","20110711","2011","","","112","117","Preprocessing is an important task and critical step in information retrieval and text mining. The objective of this study is to analyze the effect of preprocessing methods in text classification on Turkish texts. We compiled two large datasets from Turkish newspapers using a crawler. On these compiled data sets and using two additional datasets, we perform a detailed analysis of preprocessing methods such as stemming, stopword filtering and word weighting for Turkish text classification on several different Turkish datasets. We report the results of extensive experiments.","","Electronic:978-1-61284-922-5; POD:978-1-61284-919-5","10.1109/INISTA.2011.5946084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5946084","Data preprocessing;Text Classification;Turkish Text Classification;stemming;stopword removal","Classification algorithms;Filtering;Information retrieval;Support vector machines;Text categorization;Text mining;Training","classification;data mining;information retrieval;text analysis","Turkish newspapers;Turkish text classification;crawler;information retrieval;stemming;stopword filtering;text mining;word weighting","","8","","26","","","15-18 June 2011","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Key technologies of New Event Detection in emergency management","Huang Rui; Liu Lihua","School of Economics and Management, Beihang University, BUAA, Beijing, China","2011 2nd IEEE International Conference on Emergency Management and Management Sciences","20110908","2011","","","673","675","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>New Event Detection is very important in emergency management. This paper introduced key technologies in NED and analyzed the advantages and disadvantages of these technologies. And future works have been proposed.","","Electronic:978-1-4244-9666-2; POD:978-1-4244-9665-5","10.1109/ICEMMS.2011.6015771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6015771","New Event Detection;emergency management;key technologies","Clustering algorithms;Computational modeling;Economics;Educational institutions;Event detection;Information retrieval;Numerical models","emergency services;information retrieval","NED;emergency management;event detection","","0","","5","","","8-10 Aug. 2011","","IEEE","IEEE Conference Publications"
"Locality-Sensitive Hashing for Chi2 Distance","D. Gorisse; M. Cord; F. Precioso","ETIS, Cergy-Pontoise","IEEE Transactions on Pattern Analysis and Machine Intelligence","20111219","2012","34","2","402","409","In the past 10 years, new powerful algorithms based on efficient data structures have been proposed to solve the problem of Nearest Neighbors search (or Approximate Nearest Neighbors search). If the Euclidean Locality Sensitive Hashing algorithm, which provides approximate nearest neighbors in a euclidean space with sublinear complexity, is probably the most popular, the euclidean metric does not always provide as accurate and as relevant results when considering similarity measure as the Earth-Mover Distance and χ<sup>2</sup> distances. In this paper, we present a new LSH scheme adapted to χ<sup>2</sup> distance for approximate nearest neighbors search in high-dimensional spaces. We define the specific hashing functions, we prove their local-sensitivity, and compare, through experiments, our method with the Euclidean Locality Sensitive Hashing algorithm in the context of image retrieval on real image databases. The results prove the relevance of such a new LSH scheme either providing far better accuracy in the context of image retrieval than euclidean scheme for an equivalent speed, or providing an equivalent accuracy but with a high gain in terms of processing speed.","0162-8828;01628828","","10.1109/TPAMI.2011.193","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035720","Sublinear algorithm;approximate nearest neighbors;chi2 distance;image retrieval.;locality sensitive hashing","Approximation algorithms;Approximation methods;Databases;Histograms;Information retrieval;Measurement;Semantics","approximation theory;data structures;image retrieval;pattern classification;visual databases","Chi2 distance;Euclidean locality sensitive hashing algorithm;data structures;earth mover distance;euclidean metric;euclidean space;image databases;image retrieval;nearest neighbors approximation;nearest neighbors search","","18","","21","","20111006","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"CodeTopics: which topic am I coding now?","M. Gethers; T. Savage; M. Di Penta; R. Oliveto; D. Poshyvanyk; A. De Lucia","College of William and Mary, Williamsburg, VA, USA","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","1034","1036","Recent studies indicated that showing the similarity between the source code being developed and related high-level artifacts (HLAs), such as requirements, helps developers improve the quality of source code identifiers. In this paper, we present CodeTopics, an Eclipse plug-in that in addition to showing the similarity between source code and HLAs also highlights to what extent the code under development covers topics described in HLAs. Such views complement information derived by showing only the similarity between source code and HLAs helping (i) developers to identify functionality that are not implemented yet or (ii) newcomers to comprehend source code artifacts by showing them the topics that these artifacts relate to.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985988","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032585","program comprehension;source code lexicon;traceability","Educational institutions;Games;Information retrieval;Java;Monopoly;Object oriented modeling;Software","reverse engineering;software quality;software tools","CodeTopics;Eclipse plug-in;high-level artifacts;source code artifacts comprehension;source code identifier quality","","7","","9","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"Generalization bounds for ranking algorithms via almost everywhere stability","Tianwei Xu; Jianhou Gan; Yungang Zhang; Wei Gao","Department of Information, Yunnan Normal University, Kunming, 650092, China","2011 3rd International Conference on Computer Research and Development","20110505","2011","4","","500","503","The goal of ranking is to learn a real-valued ranking function that induces a ranking or ordering over an instance space. A learning algorithm is stable if the algorithm satisfies the hypothesis that the output of the algorithm varies in a limited way in response to small changes made to the training set. This paper studies the `almost everywhere' stability of ranking algorithms, notions of strong stability and weak stability for ranking algorithms are defined, and the generalization bounds of stable ranking algorithms are obtained. In particular, the relationship between strong (weak) loss stability and strong (weak) score stability is also discussed.","","Electronic:978-1-61284-840-2; POD:978-1-61284-839-6","10.1109/ICCRD.2011.5763955","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763955","algorithmic stability;generalization bounds;ranking;strong stability;weak stability","Algorithm design and analysis;Information retrieval;Machine learning;Machine learning algorithms;Silicon;Stability analysis;Training","learning (artificial intelligence);stability","almost everywhere stability;generalization bounds;learning algorithm;real-valued ranking function;stable ranking algorithm","","0","","12","","","11-13 March 2011","","IEEE","IEEE Conference Publications"
"Developing an efficient search suggestion generator, ignoring spelling error for high speed data retrieval using Double Metaphone Algorithm","Ashis Kumar Mandal; Md. Delowar Hossain; Md. Nadim","Department of CEN, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh","2010 13th International Conference on Computer and Information Technology (ICCIT)","20110303","2010","","","317","320","Finding desire information from a large text database is one of the most important issues of modern information processing systems. In this regard different types of searching techniques are used. Though some of them are vary useful, they frequently fail to show appropriate performance when a user enters misspelled data as searching keyword. In this paper we have developed an efficient search suggestion generator using Phonetic algorithm namely, Double Metaphone Algorithm. Here we use a technique to reduce total searching comparisons by creating an index on a specific field, we have defined it as keyCode field, in a table of our database where all of the values of Code field are produced by that algorithm acted on records. Results show that generator not only quickly finds the required information but provides possible search suggestion avoiding the misspelled words entered as search key.","","Electronic:978-1-4244-8497-3; POD:978-1-4244-8496-6","10.1109/ICCITECHN.2010.5723876","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723876","Double Metaphone Algorithm;Indexing;Phonetic algorithm;Search Comparisons","Books;Data structures;Encoding;Generators;Indexing;Information retrieval","database indexing;information retrieval","double metaphone algorithm;high-speed data retrieval;information processing systems;keycode field;phonetic algorithm;search suggestion generator;text database","","0","","8","","","23-25 Dec. 2010","","IEEE","IEEE Conference Publications"
"n-Keyword based Automatic Query Generation","H. Ryu; G. Kim; K. Yoo; S. Ha","School of Engineering, ICU","2006 International Conference on Hybrid Information Technology","20111212","2006","2","","90","96","In the information retrieval process, the selection of keywords and the generation of queries are very critical for the efficient retrieval. However, users experience the difficulties of selecting major keywords without being aware of the domain context. This paper proposes an automatic query generation method using n-Keyword expansion model, which consists of keyword extraction, keyword expansion and query generation. This method uses context model, semantic thesaurus and ontology. The keyword extraction is for finding document annotation data and document instances that are inferred from ontology and making the list of document keyword. n- Keyword, keywords expanded from the user input keyword, is constructed by selecting candidate keywords and assigning weight value to each candidate keyword from semantic thesaurus and document keyword list after consideration of context models. The query generation expands and generates the query using weighted keywords and query patterns. In retrieval for documents, n-Keyword using semantic thesaurus makes more useful query than users' keyword.","","POD:0-7695-2674-8","10.1109/ICHIT.2006.253595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4021200","","Context awareness;Context modeling;Data mining;Decision making;Information retrieval;Information systems;Ontologies;Project management;Research and development;Thesauri","","","","0","","8","","","9-11 Nov. 2006","","IEEE","IEEE Conference Publications"
"The Research of Ship Scheduling Model in Bulk Port Based on Multi-Agent","X. Song; L. Li","Sch. of Econ. & Manage., Beijing Jiaotong Univ., Beijing, China","2011 3rd International Workshop on Intelligent Systems and Applications","20110613","2011","","","1","4","With the development of China's economy and the growing demand for energy and raw materials, ship scheduling of bulk port has received extensive attention. This paper studies ship scheduling in bulk port business process and introduces Multi-Agent technology into ship scheduling, upon which the ship scheduling framework in bulk port based on multi-Agent technology is established. The structure of each agent and its conflict coordination mechanism are analyzed as well.","","Electronic:978-1-4244-9857-4; POD:978-1-4244-9855-0","10.1109/ISA.2011.5873320","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5873320","","Cognition;Information retrieval;Job shop scheduling;Marine vehicles;Multiagent systems;Real time systems","logistics;multi-agent systems;scheduling;shipbuilding industry","bulk port;multi-agent conflict coordination mechanism;multi-agent technology;ship scheduling model","","1","","4","","","28-29 May 2011","","IEEE","IEEE Conference Publications"
"Evaluation of the Impact of User-Cognitive Styles on the Assessment of Text Summarization","H. Nguyen; E. Santos; J. Russell","Department of Mathematical and Computer Sciences, University of Wisconsin&#x2013;Whitewater , Whitewater, WI, USA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20111017","2011","41","6","1038","1051","Text summarization techniques have been found to be effective with regard to helping users find relevant information faster. The effectiveness and efficiency of a user's performance in an information-seeking task can greatly be improved if he/she needs to only look at a summary that includes the relevant information presented in his/her preferred manner. On the other hand, if the main idea is misrepresented and/or omitted altogether from a summary, it may take users more time to solve a target problem or, even worse, lead users to make incorrect decisions. There is an important need to design a personalized text summarization system that takes into account both what a user is currently interested in and how a user perceives information. The latter factor is referred to as a user's cognitive styles. Although there are some existing approaches that have employed a user's interests to help in the design of a personalized text summarization system, there has been inadequate focus on exploring cognitive styles. This paper aims at studying the impact of a user's cognitive styles when assessing multidocument summaries. In particular, we choose two dimensions of a user's cognitive style - the analytic/wholist and verbal/imagery dimensions - and study their impacts on how a user assesses a summary that was generated from a set of documents. In particular, the type of a document set refers to whether the set's content is loosely or closely related. We use a document set type to explore if there are any differences in the users' assessments of summaries that were generated from sets of different types. The results of this paper show that different users have different assessments with regard to information coverage and the way that information is presented in both loosely and closely related document sets. In addition, we found that the coherency ratings that were given to summaries from the two types of document sets were significantly different between the analytic a- d wholist groups. This result leads us to investigate the impact of a user's cognitive styles and the following two factors that directly relate to the coherence of a summary: 1) graph entropy and 2) the percentage of stand-alone concepts. We found that these two factors and a user's cognitive styles affect a user's ratings on the coherency of a summary.","1083-4427;10834427","","10.1109/TSMCA.2011.2116001","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5735235","Cognitive styles;text summarization;user study;wholist/analytic","Coherence;Human factors;Information filtering;Information retrieval;Modeling;Text analysis","entropy;graph theory;text analysis;user centred design","document sets;graph entropy;information seeking task;multidocument summaries;personalized text summarization system;stand alone concepts;user cognitive styles","","9","","52","","20110322","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"A Statistical Approach for Automatic Text Summarization by Extraction","M. Chandra; V. Gupta; S. K. Paul","Sch. of Eng., DIT, Noida, India","2011 International Conference on Communication Systems and Network Technologies","20110728","2011","","","268","271","Automatic Document Summarization is a highly interdisciplinary research area related with computer science as well as cognitive psychology. This Summarization is to compress an original document into a summarized version by extracting almost all of the essential concepts with text mining techniques. This research focuses on developing a statistical automatic text summarization approach, Kmixture probabilistic model, to enhancing the quality of summaries. KSRS employs the K-mixture probabilistic model to establish term weights in a statistical sense, and further identifies the term relationships to derive the semantic relationship significance (SRS) of nouns. Sentences are ranked and extracted based on their semantic relationship significance values. The objective of this research is thus to propose a statistical approach to text summarization. We propose a K-mixture semantic relationship significance (KSRS) approach to enhancing the quality of document summary results. The K-mixture probabilistic model is used to determine the term weights. Term relationships are then investigated to develop the semantic relationship of nouns that manifests sentence semantics. Sentences with significant semantic relationship, nouns are extracted to form the summary accordingly.","","Electronic:978-0-7695-4437-3; POD:978-1-4577-0543-4","10.1109/CSNT.2011.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5966451","extraction;semantic relationship significance;statistical approach","Computer science;Information retrieval;Pragmatics;Probabilistic logic;Semantics;Text categorization","data mining;statistical analysis;text analysis","automatic document summarization;cognitive psychology;computer science;k-mixture probabilistic model;k-mixture semantic relationship significance;semantic relationship significance;statistical automatic text summarization;text mining techniques","","2","","13","","","3-5 June 2011","","IEEE","IEEE Conference Publications"
"Skolem preprocessing using WordNet and lexicon in building effective knowledge representation","K. D. Varathan; T. M. T. Sembok; R. A. Kadir; N. Omar","Fac. of Inf. Sci. &amp; Technol., Nat. Univ. of Malaysia, Bangi, Malaysia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","5","We are in the information intensive environment in which various forms of digital contents have been growing exponentially. In this era of digital data, knowledge representation has been considered as a crucial component of any information retrieval system. It is also considered as a major problem especially in representing the content of unstructured text in an effective way. Although the mission remains impossible to achieve 100% accuracy, many researchers are indulging themselves in documenting these data in many different techniques so that it can be communicated effectively and easily. Indexing is an important element that determines the success of retrieval. Since we are dealing with multiple documents, preprocessing of data is needed before the data gets indexed. Thus, this paper presents an approach on the preprocessing technique. The semantic data which have been represented in skolem clauses will be preprocessed with the help of automatic lexicon generator output and WordNet. This preprocessing plays an important role in getting rid of redundant data before it gets indexed into the semantic matrix. Besides redundancy, it also helps in dealing with common problem that exists in indexing multiple documents in which similar sentences with more or less the same meaning but have been constructed by using different sets of words. As a conclusion, the integration of WordNet and lexicon leads to better result in terms of building effective knowledge representation.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021760","indexing;lexicon;preprocessing;skolem","Generators;Indexing;Information retrieval;Knowledge representation;Redundancy;Semantics","indexing;information retrieval;knowledge representation;word processing","Skolem preprocessing;WordNet;automatic lexicon generator;digital data;indexing;information retrieval system;knowledge representation;semantic matrix","","0","","15","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"Focused Crawling for Automatic Service Discovery, Annotation, and Classification in Industrial Digital Ecosystems","H. Dong; F. K. Hussain","Digital Ecosystems and Business Intelligence Institute, Curtin University of Technology, Bentley, Australia","IEEE Transactions on Industrial Electronics","20110512","2011","58","6","2106","2116","Digital Ecosystems make use of Service Factories for service entities' publishing, classification, and management. However, before the emergence of Digital Ecosystems, there existed ubiquitous and heterogeneous service information in the Business Ecosystems environment. Therefore, dealing with the preexisting service information becomes a crucial issue in Digital Ecosystems. This issue has not been addressed previously in the literature. In order to resolve this issue, in this paper, we present a conceptual framework for a semantic focused crawler, with the purpose of automatically discovering, annotating, and classifying the service information with the Semantic Web technologies. The technical and evaluation details of the framework are also presented and discussed in this paper.","0278-0046;02780046","","10.1109/TIE.2010.2050754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5475251","Digital Ecosystems;semantic focused crawler;service annotation;service classification;service discovery;service ontologies","Crawlers;Ecosystems;Information retrieval;OWL;Ontologies;Permission;Production facilities;Publishing;Resource description framework;Semantic Web","business process re-engineering;ecology;electronic publishing;semantic Web;ubiquitous computing","annotation;automatic service discovery;business ecosystems environment;classification;heterogeneous service information;industrial digital ecosystems;publishing;semantic Web technologies;service entities;service factories;ubiquitous service information","","18","","27","","20100601","June 2011","","IEEE","IEEE Journals & Magazines"
"Representative melodies retrieval using digital signal processing of audio","M. b. Chung; I. j. Ko","Soongsil University","2006 International Conference on Hybrid Information Technology","20111212","2006","2","","185","190","Extracting a melody to have representativeness of music so that contents-based music information retrieval system lets recently reduce response time about a search of a user, and be indexes do, and used this to a search. A way the existing study used MIDI data, and was proposed to extract a representative melody. However, there is a disadvantage limited to MIDI data. Therefore these papers propose the representative melody search way how application is possible to all audios file format as using a digital signal process technique of audio data. A representative melody is a section each audio data showing characteristics most conspicuous. This is the section where appeal is largest to persons listening to audio data and we was able to find from pieces having the maximum during wave forms of total data. Have got a node of audio data and tempos, and measure the frequency that high value (value more than 90% of a wave form highest of data) appears of a wave form from each nodes from node information got for representative melody searches. At this time a 8 node interval is representative melody scope of audio data from the scopes where high values was gathering most around of wave forms. Selected 1000 pieces of guns, and by 250 pieces by genres represented audio data of four kinds of Ballad, Dance, Hip-hop, Rock by experiment to verify effectiveness of a proposal way, and extracted a melody, and therefore showed Ballad 79.6%, Dance 83%, Hip-hop 89%, precision of Rock 62.8%.","","POD:0-7695-2674-8","10.1109/ICHIT.2006.253610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4021215","","Content based retrieval;Data mining;Delay;Digital signal processing;Information analysis;Information retrieval;Multiple signal classification;Music information retrieval;Proposals;Signal processing","","","","0","","12","","","9-11 Nov. 2006","","IEEE","IEEE Conference Publications"
"Automatic text categorization based on Jensen-Shannon Divergence","X. Li; D. Sun; L. H. Wuhan","The School of Information Management, Wuhan University, Wuhan 430072, China","2011 International Conference on E-Business and E-Government (ICEE)","20110616","2011","","","1","4","This paper studies the principle of text categorization in which Jensen-Shannon Divergence is used to calculate text similarity, comparing its accuracy of classification and time taking to the traditional Cosine Similarity algorithm. Experimental research shows that Jensen-Shannon Divergence algorithm will reach better results when test materials remain unchanged.","","Electronic:978-1-4244-8694-6; POD:978-1-4244-8691-5","10.1109/ICEBEG.2011.5882549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5882549","Jensen-Shannon divergence;KNN algorithm;cosine similarity;text categorization","Classification algorithms;Information retrieval;Libraries;Publishing;Research and development;Sun;Text categorization","","","","0","","12","","","6-8 May 2011","","IEEE","IEEE Conference Publications"
"Search Results Clustering Based on Suffix Array and VSM","S. Bai; W. Zhu; B. Zhang; J. Ma","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","Green Computing and Communications (GreenCom), 2010 IEEE/ACM Int'l Conference on & Int'l Conference on Cyber, Physical and Social Computing (CPSCom)","20110307","2010","","","852","857","With the rapid growth of web pages, search engines will usually present a long ranked list of documents. The users must sift through the list with ""title"" and ""snippet"" (a short description of the document) to find the desired document. This method may be good for some simple and specific tasks but less effective and efficient for ambiguous queries such as ""apple"" or ""jaguar"". To improve the effect and efficiency of information retrieval, an alternative method is to automatically organize retrieval results into clusters. This paper presents an improved Lingo algorithm named Suffix Array Similarity Clustering (SASC) for clustering web search results. This method creates the clusters by adopting improved suffix array, which ignores the redundant suffixes, and computing document similarity based on the title and short document snippets returned by Web search engines. Experiments show that the SASC algorithm has not only a better performance in time-consuming than Lingo but also in cluster description quality and precision than Suffix Tree Clustering.","","Electronic:978-0-7695-4331-4; POD:978-1-4244-9779-9","10.1109/GreenCom-CPSCom.2010.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5724930","Lingo;STC;Suffix Array;Suffix Tree;search results clustering","Algorithm design and analysis;Arrays;Clustering algorithms;Information retrieval;Matrix decomposition;Software;Software algorithms","Internet;information retrieval;pattern clustering;search engines","Lingo algorithm;SASC;VSM;Web search engines;ambiguous queries;clustering web search;information retrieval;search results clustering;suffix array;suffix array similarity clustering","","0","","8","","","18-20 Dec. 2010","","IEEE","IEEE Conference Publications"
"Interactive Spoken Document Retrieval With Suggested Key Terms Ranked by a Markov Decision Process","Y. C. Pan; H. Y. Lee; L. S. Lee","","IEEE Transactions on Audio, Speech, and Language Processing","20111219","2012","20","2","632","645","Interaction with users is a powerful strategy that potentially yields better information retrieval for all types of media, including text, images, and videos. While spoken document retrieval (SDR) is a crucial technology for multimedia access in the network era, it is also more challenging than text information retrieval because of the inevitable recognition errors. It is therefore reasonable to consider interactive functionalities for SDR systems. We propose an interactive SDR approach in which given the user's query, the system returns not only the retrieval results but also a short list of key terms describing distinct topics. The user selects these key terms to expand the query if the retrieval results are not satisfactory. The entire retrieval process is organized around a hierarchy of key terms that define the allowable state transitions; this is modeled by a Markov decision process, which is popularly used in spoken dialogue systems. By reinforcement learning with simulated users, the key terms on the short list are properly ranked such that the retrieval success rate is maximized while the number of interactive steps is minimized. Significant improvements over existing approaches were observed in preliminary experiments performed on information needs provided by real users. A prototype system was also implemented.","1558-7916;15587916","","10.1109/TASL.2011.2163512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6018284","Spoken document retrieval (SDR);dialogue system","Economics;Information retrieval;Markov processes;Navigation;Prototypes;Speech;Videos","Markov processes;information needs;information retrieval;interactive systems;learning (artificial intelligence);multimedia computing;text analysis","Markov decision process;SDR system;inevitable recognition error;information needs;interactive functionality;interactive spoken document retrieval success rate;multimedia access;reinforcement learning;spoken dialogue system;text information retrieval process;user query","","10","","49","","20110915","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Self-Regulated Trade-Off among Timeliness, Messages and Accuracy for Approximate Queries in Large-Scale Information Aggregation","R. Brunner; F. Freitag; L. Navarro","Comput. Archit. Dept., Tech. Univ. of Catalonia, Barcelona, Spain","2011 14th International Conference on Network-Based Information Systems","20111013","2011","","","258","267","In data management for large-scale applications such as Peer-to-Peer networks, and Grid and Cloud Computing arise challenges in regard to the decentralization of the application and in regard to an increasing number of failures. A consequence of these conditions is an increasing retrieval time, inaccurate results and higher network consumption. A solution to restrain an increasing retrieval time and an increasing number of messages is the introduction of approximate queries. The introduction of approximate queries limits the querying of all nodes of a network to a subset of nodes in the cost of the results' accuracy. Thus, a conflict to provide a large-scalability lies in guaranteeing accurate data, in the provision of fast results and in a low consumption of network bandwidth. Therefore, we propose an information aggregation that is based on an analytic hierarchical process (AHP) to find a trade-off among the unpredictable factors of time, messages and accuracy. After a user defines the preferences for the retrieval process, the AHP-based algorithm makes autonomous decisions on each node. The algorithm decides autonomously about pruning the approximate queries to reach an optimal trade-off from a global perspective. Applying the self-regulated pruning of the approximate queries allows reducing the messages from an exponential in crease to a constant factor. At the same time, the retrieval time is reduced from a linear increase to a constant factor in regard to an increasing number of nodes. At the same time of reducing the retrieval time and network bandwidth, the AHP-based self-regulation guarantees certain level of accuracy.","2157-0418;21570418","CD-ROM:978-0-7695-4458-8; CD-ROM:978-07695-4580-6; Electronic:978-0-7695-4458-8; POD:978-1-4577-0789-6","10.1109/NBiS.2011.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041894","Approximate Queries;Autonomic Management;Computational Grids and Clouds;Large-scale Information Aggregation","Accuracy;Approximation algorithms;Approximation methods;Bandwidth;Delay;Information retrieval;Peer to peer computing","cloud computing;data handling;decision making;grid computing;peer-to-peer computing;query processing","analytic hierarchical process;approximate query pruning;cloud computing;data management;grid computing;large scale information aggregation;peer-to-peer networks;self regulated pruning;self regulated trade off","","0","","27","","","7-9 Sept. 2011","","IEEE","IEEE Conference Publications"
