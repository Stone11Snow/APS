"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6042787,6041712,6042678,6042630,6045051,6041935,6042799,6042674,6045022,6041962,6037753,6040860,6040877,6040719,6040852,6036404,6040511,6038700,6040882,6038210,6032511,6037717,6040859,6040743,6040764,6041259,6040819,6040517,6036755,6036806,6040782,6038089,6040583,6040801,6040837,6038706,6032457,6036591,6041220,6038155,6040879,6040842,6032450,6041234,6040657,6040492,6039731,6037083,6037649,6040864,6037328,6040466,6040505,6040494,6040826,6032607,6034654,6035037,6034836,6033242,6034257,6032861,6033316,6034370,6032408,6033374,6030227,6030578,6030361,6030249,6030043,6030262,6031262,6028577,6028748,6028845,6028622,6028895,5986637,6028881,6027352,6025814,6024651,6026722,6025660,6025634,5601726,6025602,6024661,6022500,6023787,6023915,6022090,6021626,6021743,6022956,6021827,6021634,6022545,6023963",2017/05/04 22:30:26
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Care pathway records and variance data: Enabling research through the use of ontologies","M. Olive; A. Lashwood; T. Solomonides","CSCT, University of the West of England, Bristol, UK","2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)","20111013","2010","","","144","149","Integrated care pathways (ICPs), a fine-grained form of medical guideline including the explicit recording of any deviation, or `variance', could serve as a rich source of data for research. Not only do they incorporate a wealth of operational knowledge, but feeding the results of the analysis of variance into the development of a pathway could be an effective way of capturing evidence from practice. In our principal case study we propose a system for extracting data from care pathways with the aid of ontologies, and a method for inferring ICPs from other patient records, combining these with data collected for retrospective and prospective studies in preimplantation genetic diagnosis (PGD) for assisted reproduction.","1063-7125;10637125","Electronic:978-1-4244-9168-1; POD:978-1-4244-9167-4","10.1109/CBMS.2010.6042630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042630","","Drugs;Embryo;Guidelines;Iterative closest point algorithm;Ontologies;Pediatrics","data handling;information retrieval;medical information systems;ontologies (artificial intelligence)","care pathway records;data extraction;evidence capture;integrated care pathways;medical guideline;ontologies;operational knowledge;patient records;preimplantation genetic diagnosis;variance data","","1","","9","","","12-15 Oct. 2010","","IEEE","IEEE Conference Publications"
"Paragraph act based pragmatic information extraction in question answering","S. Liu; F. Ren","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","20111013","2011","","","153","157","In Question Answering System the greatest hardship is crossing the gap between the questions and corpus to find the appropriate answers. The questions and corpus are in different context, to find the answers the inference whether one candidate sentence fits the user's request is necessary. Pragmatic is concerned with inference about the utterances and user. It is a bridge across the gap of questions and corpus. In this paper we analyze the elements of pragmatic and extract the pragmatic information from the corpus based on the paragraph act. The pragmatic information is also well organized. And the experiments show that the appended pragmatic information significantly improves the performance of the Question Answering System either the precision, recall or F score especially in the condition that the quantity of answer is restricted.","2376-5933;23765933","Electronic:978-1-61284-204-2; POD:978-1-61284-203-5","10.1109/CCIS.2011.6045051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045051","Question Answering;information extraction;paragraph act;pragmatic information","Bridges;Context;Data mining;Educational institutions;Kernel;Pragmatics;Semantics","question answering (information retrieval)","paragraph act based pragmatic information extraction;question answering system;user request","","0","","12","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"Notice of Violation of IEEE Publication Principles<BR>Privacy protection in outsourced database services","Y. Yu; W. Bai","Sch. of Manage. Sci. & Eng., Anhui Univ. of Finance & Econ., Bengbu, China","2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)","20110922","2011","","","1726","1731","Notice of Violation of IEEE Publication Principles<BR><BR> ""Privacy Protection in Outsourced Database Services""<BR> by Yonghong Yu and Wenyang Bai<BR> in the Proceedings of the International Conference on Mechatronic Science, Electric Engineering<BR> and Computer, August 2011, pp. 1726-1731<BR><BR> After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR> This paper contains substantial duplication of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<BR><BR> Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:<BR><BR> ""Enforcing Confidentiality Constraints on Sensitive Databases with Lightweight Trusted Clients""<BR> by Valentina Ciriani, Sabrina De Capitani di Vimercati, Sara Foresti, Sushil Jajodia, Stefano Paraboschi, and Pierangela Samarati<BR> in the Proceedings of the 23rd Annula IFIP WG 11.3 Working Conference on Data and Applications<BR> Security (DBSec), July 2009<BR><BR> ""Fragmentation and Encryption to Enforce Privacy in Data Storage""<BR> by Valentina Ciriani, Sabrina De Capitani di Vimercati, Sara Foresti, Sushil Jajodia, Stefano Paraboschi, and Pierangela Samarati<BR> in the Proceedings of the 12th European Symposium on Research in Computer Security (ESORICS), September 2007<BR><BR> ""Fragmentation Design for Efficient Query Execution over Sensitive Distributed Databases""<BR> by Valentina Ciriani, Sabrina De Capitani di Vimercati, Sara Foresti, Sushil Jajodia, Stefano Paraboschi, and Pierangela Samarati<BR> in the Proceedings of the 29th International Conference on Distributed Computing Systems (ICDCS), June 2009<BR><BR>Technical consideratio- s and many significant commercial and legal regulations demand that privacy guarantees be provided whenever sensitive information is stored, processed, or communicated to external partied. In this paper, we propose a solution to enforce data confidentiality, data privacy and accountable user privacy in outsourced database services. The approach starts from a flexible definition of privacy constraints, applies encryption on information in a parsimonious way and mostly relies on attribute partition to protect sensitive information. Based on the approximation algorithm for the minimal encryption attribute partition, the approach allows storing the outsourced data on un-trusted database server and minimizing the amount of encrypted data. By combining cryptographic with auxiliary random server, the approach can reduce the computational and communication complexity of private information retrieval to provide user privacy protection. By introducing verifiable encryption and revocation of decryption based on event capsule, the approach obtains accountability when the user misbehaves. The theoretical analysis shows that our new approach can provide efficient data privacy, efficient accountable user privacy protection with lower computational complexity and not increase the cost of communication complexity simultaneously.","","Electronic:978-1-61284-722-1; POD:978-1-61284-719-1","10.1109/MEC.2011.6025814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025814","accountability;cryptgraphic;data privacy;outsourced database services;user privacy","Data privacy;Databases;Encryption;Privacy;Protocols;Servers","computational complexity;cryptography;data privacy;database management systems;information retrieval;information services;outsourcing","approximation algorithm;auxiliary random server;communication complexity;computational complexity;data encryption;data privacy;database server;information retrieval;outsourced database services;sensitive information","","0","","18","","","19-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"The design of smart home platform based on Cloud Computing","H. Gu; Y. Diao; W. Liu; X. Zhang","Dept. of Commun. Eng., Jilin Univ., Changchun, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","8","","3919","3922","The smart home is a concept of the pervasive computing, and it gradually becomes significant for the people living in the high technology area. For numerous data and complex control bring about a much heavy burden on the local computers, and it is difficult for the users to obtain the information of the smart home. In this paper, we propose the smart home structure based on Cloud Computing, which helps to reduce local workload and the users obtain the real time information through Web browser directly. In addition, we build the experimental platform to validate the structure of smart home based on Cloud Computing, the experimental results show that the proposed structure of smart home is more convenient, flexible, high efficiency and low cost. Though experiment, we find that the structure based on Cloud Computing is available and has a widespread scope of applications. Furthermore, the Cloud Computing provides plentiful network resource, and guarantees the users data security.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6023915","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023915","Cloud Computing;Google App Engine;Java Servlet;smart home","Cloud computing;Google;Java;Protocols;Smart homes;Zigbee","cloud computing;computer network security;home automation;information retrieval;online front-ends;ubiquitous computing","Web browser;cloud computing;complex control;information retrieval;local workload reduction;pervasive computing;real time information;smart home platform design;user data security","","11","","13","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"The research on user satisfaction of easy teaching Web of Taipei assessed via information quality, system quality, and Technology Acceptance Model","C. Y. Dai; M. T. Kao; C. T. Harn; Y. H. Yuan; W. F. Chen","Dept. of Appl. Electron. Technol., Taiwan Normal Univ., Taipei, Taiwan","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","758","762","In the digital era, using information technology to search valuable information is one of the important skills. Taipei City Government set up Easy Teaching Web of Taipei, integrates scattered knowledge in the field of education and human resources, and build a knowledge-sharing platform for teachers. However, it is still important to understand how to improve the usage of Easy Teaching Web of Taipei to teachers. This research applied the Technology Acceptance Model as research foundation, and the Information Systems Success Model was also considered as impact factor in this research, to understand the teachers to the satisfaction of the digital platform. There are 318 valid samples by random selected from members to fill out a developed pencil-paper questionnaire. The multiple-regression was used for data analysis, the empirical results lead to four conclusions. First, Information Quality (IQ) can predict Perceived Usefulness (PU) and Perceived Ease of Use (PEOU). Second, System Quality (SQ) can predict PU and PEOU. Third, PEOU can predict PU and Attitude toward using (ATU). Fourth, ATU can predict User Satisfaction (US). According to research finding that Easy Teaching Web can promote the user satisfaction by improve easy use of the system.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028748","ET Web;IS Success Model;TAM","Correlation;Educational institutions;Information systems;Internet;Mathematical model;Reliability","Internet;data analysis;human resource management;information systems;information technology;question answering (information retrieval);regression analysis;technology management","Taipei city government set up easy teaching Web;data analysis;digital era;digital platform;human resource;information quality;information system success model;information technology;knowledge sharing platform;multiple regression;pencil-paper questionnaire;technology acceptance model;user satisfaction","","2","","13","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Neural pre-coding increases the pattern retrieval capacity of Hopfield and Bidirectional Associative Memories","Amir Hesam Salavati; K. Raj Kumar; A. Shokrollahi; W. Gerstnery","Laboratoire d'algorithmique, Ecole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne (EPFL), 1015, Switzerland","2011 IEEE International Symposium on Information Theory Proceedings","20111003","2011","","","850","854","We consider the problem of neural association, which deals with the retrieval of a previously memorized pattern from its noisy version. The performance of various neural networks developed for this task may be judged in terms of their pattern retrieval capacities (the number of patterns that can be stored), and their error-correction (noise tolerance) capabilities. While significant progress has been made, most prior works in this area show poor performance with regard to pattern retrieval capacity and/or error correction. In this paper, we propose two new methods to significantly increase the pattern retrieval capacity of the Hopfield and Bidirectional Associative Memories (BAM). The main idea is to store patterns drawn from a family of low correlation sequences, similar to those used in Code Division Multiple Access (CDMA) communications, instead of storing purely random patterns as in prior works. These low correlation patterns can be obtained from random sequences by pre-coding the original sequences via simple operations that both real and artificial neurons are capable of accomplishing.","2157-8095;21578095","Electronic:978-1-4577-0595-3; POD:978-1-4577-0596-0; USB:978-1-4577-0594-6","10.1109/ISIT.2011.6034257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034257","","Associative memory;Biological neural networks;Correlation;Error correction;Gold;Neurons;Noise","Hopfield neural nets;code division multiple access;content-addressable storage;error correction;information retrieval;pattern recognition;precoding","CDMA communications;Hopfield associative memories;bidirectional associative memories;code division multiple access;error correction;neural networks;neural precoding;pattern retrieval","","4","","11","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Automatic Annotation of Non-English Web Content","J. evcech; M. Bielikov´","Inst. of Inf. & Software Eng., Slovak Univ. of Technol. in Bratislava, Bratislava, Slovakia","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","281","284","Nowadays we are facing the daily information overload. It is thus difficult to get exactly the information we need. It often happens that while reading, we find a word we do not understand and we would need an explanation or some additional information about this word. For this purpose annotations in the Web environment are created and attached to such words. In this paper we propose a method for an automatic extension of the content available on the Web by adding annotations to selected terms (keywords) in the text. The method is designed to be able to insert annotations into the text written in Slovak with a potential to be language independent. Annotations themselves are obtained through publicly available services providing information retrieval. We adapt created annotations taking into account implicit feedback from users in form of click through data. We evaluate the proposed method in the environment of an educational web-based system.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040860","Web annotation;adaptive annotations;keywords;keywords mapping","Dictionaries;Encyclopedias;Internet;Shape;Web pages","computer aided instruction;information retrieval;natural language processing;text analysis","Slovak text;Web content automatic extension;click through data;educational Web-based system;implicit feedback;information overload;information retrieval;language independent;nonEnglish Web content automatic annotation","","0","","11","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Experiences with text mining large collections of unstructured systems development artifacts at jpl","D. Port; A. Nikora; J. Hihn; L. Huang","University of Hawaii, Honolulu, HI, USA","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","701","710","Often repositories of systems engineering artifacts at NASA's Jet Propulsion Laboratory (JPL) are so large and poorly structured that they have outgrown our capability to effectively manually process their contents to extract useful information. Sophisticated text mining methods and tools seem a quick, low-effort approach to automating our limited manual efforts. Our experiences of exploring such methods mainly in three areas including historical risk analysis, defect identification based on requirements analysis, and over-time analysis of system anomalies at JPL, have shown that obtaining useful results requires substantial unanticipated efforts - from preprocessing the data to transforming the output for practical applications. We have not observed any quick 'wins' or realized benefit from short-term effort avoidance through automation in this area. Surprisingly we have realized a number of unexpected long-term benefits from the process of applying text mining to our repositories. This paper elaborates some of these benefits and our important lessons learned from the process of preparing and applying text mining to large unstructured system artifacts at JPL aiming to benefit future TM applications in similar problem domains and also in hope for being extended to broader areas of applications.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985891","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032511","assurance;experience;requirements assurance;risk;risk assurance;system repository mining;systems development artifact;text mining","Association rules;Manuals;Risk management;Software;Text mining","aerospace industry;data mining;formal verification;information retrieval;systems analysis;text analysis","JPL;Jet Propulsion Laboratory;NASA;defect identification;historical risk analysis;information extraction;large collections;requirements analysis;sophisticated text mining methods;system anomaly over-time analysis;systems engineering artifacts;unstructured systems development artifacts","","2","","41","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"e-health for improving community healthcare: Encouraging clinical experience of simple e-prescription system and m-health system development for mother and childcare","S. Soegijoko; I. M. Puspitasari; A. Aridarma; I. D. Jani","Sch. of Electr. Eng. &amp; Inf., Inst. Teknol. Bandung, Bandung, Indonesia","2011 IEEE 13th International Conference on e-Health Networking, Applications and Services","20110922","2011","","","102","105","In this paper, we describe the eleven month encouraging clinical implementation experience of our e-prescription system in a community health center and further development activities of a mobile e-health system for mother and childcare. The e-prescription system has been developed for supporting the patient and medicine data recording, retrieving and reporting systems, as well as for minimizing the possible medication errors through improving the prescribing process. Several months of clinical experience have been used to enhance further development activities in our m-health system dedicated for supporting mother and childcare (especially the safe motherhood program). The m-health system consists of an SMS (short messaging system) manager module which is responsible for sending short messages with four different operating modes.","","Electronic:978-1-61284-697-2; POD:978-1-61284-695-8; USB:978-1-61284-696-5","10.1109/HEALTH.2011.6026722","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6026722","community healthcare;e-health;e-prescription;m-health","Communities;Drugs;Mobile communication;Pediatrics;Software;Training","data recording;electronic messaging;health care;information retrieval systems;medical computing;medical information systems;mobile computing","SMS manager module;clinical implementation experience;community health center;community healthcare improvement;e-prescription system;m-health system development;medicine data recording;mobile e-health system;patient data recording;reporting systems;retrieving systems;short messaging system","","0","","6","","","13-15 June 2011","","IEEE","IEEE Conference Publications"
"A framework to the development of Islamic ontology: Symbiosis of thesaurus and domain expert in ontology development","J. Salim; Siti Farhana Mohamad Hashim; S. A. M. Noah","Centre for Artificial Intell. Technol., Univ. Kebangsaan Malaysia, Bangi, Malaysia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","6","This paper discusses the conceptual and vocabulary problems users faced when searching the web. It will show how a well structured thesaurus can be used as knowledge base for an interface that can assist user with search topic clarification. The first part of the paper covers thesaurus structure needed to support these functions. Several thesaurus samples are presented to illustrate these principles. Thesauri contain structured vocabularies that provide knowledge based support for end user searching. However, if we want to create a knowledge-rich description of for example an (image of an) art object, medical, business, crime etc. such as required by the “semantic web”, thesauri turn out to provide only part of the knowledge needed. The aim of this research is to explore how ontology and semantic web technology be applied as solutions to problems in retrieving Islamic resources. This research emphasizes on semantic web technologies and the development of ontology using symbiotic approach involving thesaurus and other reference sources as the basis for implementing novel mechanism for retrieving Islamic web in 3 different languages simultaneously. In this research, existing knowledge sources such as documents, reports, etc. are mapped into the domain ontology and semantically enriched. As a result, we developed a framework for the development of Islamic ontology that advocates the symbiosis of thesaurus and domain expert. This semantically enriched information enables better knowledge indexing and searching process, not only improve precision but also search time and implicitly a better management of knowledge.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021626","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021626","Islamic retrieval system;multilingual ontology;ontology development;thesaurus","Indexes;Knowledge based systems;Libraries;Ontologies;Semantic Web;Thesauri;Vocabulary","humanities;indexing;information retrieval;knowledge based systems;ontologies (artificial intelligence);semantic Web","Islamic Web retrieval;Islamic ontology;Web searching;end user searching;knowledge based support;knowledge indexing;knowledge rich description;ontology development domain expert;search topic clarification;semantic Web;thesaurus symbiosis;vocabulary problems","","0","","9","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"Implement of communication between configuration software and OPC server based on Modbus/TCP","Li Dongjiang; Sun Ruiqi","School of Control and Computer Engineering, North China Electric Power University, Beijing 102206, China","IEEE 2011 10th International Conference on Electronic Measurement & Instruments","20111010","2011","1","","218","221","Introduces the communication among a variety of Industrial Ethernet based on OPC industry standard, and details the entire process developing OPC data access server in the visual studio 2008 development environment with the example of Modbus/TCP. It takes Siemens WinCC 6.0 as OPC client in a FPCB (Flexible Printed Circuit Board) film production system in this paper to test and achieve the normal communication between configuration software WinCC and OPC data access server. It is convenient to achieve a variety of system integration of Industrial Ethernet, by adding other Industrial Ethernet protocol analysis module to this OPC server.","","Electronic:978-1-4244-8161-3; POD:978-1-4244-8158-3","10.1109/ICEMI.2011.6037717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037717","Modbus/TCP;OPC;WinCC","Educational institutions;Films;Production systems;Protocols;Servers;Software;Temperature measurement","application program interfaces;client-server systems;field buses;information retrieval;local area networks;printed circuits;production engineering computing;transport protocols","FPCB film production system;Modbus/TCP;OPC client;OPC data access server;OPC industry standard;OPC server;Siemens WinCC 6.0;configuration software;flexible printed circuit board;industrial Ethernet protocol analysis module;visual studio 2008 development environment","","2","","8","","","16-19 Aug. 2011","","IEEE","IEEE Conference Publications"
"Content-Based Privacy Management on the Social Web","M. Jakob; Z. Moler; M. Pechoucek; R. Vaculin","Dept. of Cybern., Czech Tech. Univ., Prague, Czech Republic","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","277","280","Protection of privacy is a major concern for users of social web applications, including social networks. Although most online social networks now offer fine-grained controls of information sharing, these are rarely used, both because their use imposes additional burden on the user and because they are too complex for an average user to handle. To mitigate the problem, we propose an intelligent privacy manager that automates the assignment of sharing permissions, taking into account the content of the published information and user's high-level sharing policies. At the core of our contribution is a novel privacy policy language which explicitly accounts for social web concepts and which balances the expressive power with representation complexity. The manager employs named entity recognition algorithms to annotate sensitive parts of published information and an answer set programming system to evaluate user's privacy policies and determine the list of safe recipients. We implemented a prototype of the manager on the Face book platform. On a small test scenario, the manager reached the F-measure value of 0.831 in correctly recommending safe recipients.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040859","Facebook;information extraction;policies;privacy protection;social web","Context;Data privacy;Facebook;Privacy;Prototypes;Vocabulary","content management;information retrieval;security of data;social networking (online)","Facebook platform;answer set programming system;content-based privacy management;intelligent privacy manager;named entity recognition algorithms;novel privacy policy language;online social networks;social Web","","3","","10","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Expertise Prediction for Social Network Platforms to Encourage Knowledge Sharing","N. Raj; L. Dey; B. Gaonkar","TCS Innovation Labs. Delhi, Delhi, India","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","380","383","Knowledge sharing social platforms where users mutually benefit through question-answering are gaining popularity. The success of these platforms on the web has led to their adoption within the firewalls of enterprises also. In this paper we have presented some in-depth study about two such platforms -- one open on the web and one which is within an enterprise to identify the similarities and dissimilarities of user behavior in the two platforms. We have proposed an algorithm to predict experts to improve the effectiveness of such platforms.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040743","Attrition rate;Expertise prediction;Hubs;Propensity to answer","Communities;Conferences;Correlation;Data mining;Knowledge engineering;Social network services;Uninterruptible power systems","authorisation;knowledge management;question answering (information retrieval);social networking (online)","firewalls;knowledge sharing social platform;question-answering;social network;user behavior","","1","","6","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Email Social Network Extraction and Search","M. Laclavik; . Dlugolinsky; M. Kvassay; L. Hluchy","Inst. of Inf., Slovak Acad. of Sci., Slovakia","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","373","376","The article discusses our email search prototype, which exploits social networks hidden in email archives and the spread of activation algorithm. The prototype offers new way of searching email archives as knowledge repository. The prototype was partially evaluated on the Enron email corpus.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040882","email search;information extraction;social networks","Data mining;Electronic mail;Prototypes;Search problems;Social network services;Time factors;User interfaces","electronic mail;information retrieval;information retrieval systems;knowledge acquisition;social networking (online)","Enron email corpus;activation algorithm;email archives;email communication analysis;email search prototype;email social network extraction;email social network search;knowledge repository","","1","1","8","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Traffic Condition Information Extraction & Visualization from Social Media Twitter for Android Mobile Application","S. K. Endarnoto; S. Pradipta; A. S. Nugroho; J. Purnama","Fac. of Inf. Technol., Swiss German Univ., Tangerang, Indonesia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","4","Traffic jam in Jakarta, Indonesia has become a crucial problem for the society. A Traffic Management Center has been built by the police, in this case Polda Metro Jaya to help people to get the latest information regarding traffic jam. Twitter has been used by TMC Polda Metro Jaya to spread the news of traffic. With its limitations, Twitter doesn't provide good user interface in the case of traffic condition. In this paper, information extraction technique is used to get the data of traffic, so that the traffic information can be presented in map view as a mobile application of Android. Natural Language Processing can be used to extract information from a tweet. A tweet will be tokenized, then each of the token will be assigned to a particular part-of-speech tag while analyzing the sentence by using rule based approach. Based on the rules, information of traffic can be extracted in the form of template which consist of time, origin, destination and condition. By using Google Map, the extracted information will be presented in 3 different colors for 3 different levels of traffic condition. Early experiment with limited vocabulary and rules has showed promising result.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021743","Information extraction;Natural Language Processing;mobile application","Androids;Data mining;Databases;Humanoid robots;Jamming;Mobile communication;Twitter","data mining;data visualisation;geographic information systems;information retrieval;knowledge based systems;mobile computing;natural language processing;social networking (online);traffic information systems","Android mobile application;Google Map;Indonesia;Jakarta;TMC Polda Metro Jaya;information visualization;natural language processing;part-of-speech tag;police;rule based approach;social media Twitter;traffic condition;traffic condition information extraction;traffic jam;traffic management center;user interface;vocabulary","","13","","6","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"Strategic Behavior in Interaction Selection and Contact Selection","B. O. Hartmann; K. Bohm; C. Hutter","Karlsruhe Inst. of Technol., Karlsruhe, Germany","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","2","","117","124","Social search platforms like Aardvark or Yahoo Answers have attracted a lot of attention lately. In principle, participants have two strategic dimensions in social search systems: (1) Interaction selection, i.e., forwarding/processing incoming requests (or not), and (2) contact selection, i.e., adding or dropping contacts. In systems with these strategic dimensions, it is unclear whether nodes cooperate, and if they form efficient network structures. To shed light on this fundamental question, we have conducted a study to investigate human behavior in interaction selection and to investigate the ability of humans to form efficient networks. In order to limit the degree of problem understanding necessary by the study participants, we have introduced the problem as an online game. 193 subjects joined the study that was online for 67 days. One result is that subjects choose contacts strategically and that they use strategies that lead to cooperative and almost efficient systems. Surprisingly, subjects tend to overestimate the value of cooperative contacts and keep cooperative but costly contacts. This observation is important: Assisting agents that help subjects to avoid this behavior might yield more efficiency.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040764","contact selection;economics;experimentation;human factors;interaction selection","Analytical models;Economics;Electronic mail;Games;Humans;Tin;User interfaces","behavioural sciences computing;human computer interaction;information retrieval;social networking (online)","Aardvark;Yahoo Answers;contact selection;human behavior;interaction selection;online game;social networks;social search platforms;social search systems;strategic behavior","","0","","23","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Improving question retrieval in community question answering with label ranking","W. Wang; B. Li; I. King","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","349","356","Community question answering services (CQA), which provides a platform for people with diverse backgrounds to share information and knowledge, has become an increasingly popular research topic recently as made popular by sites such as Yahoo! Answers<sup>1</sup>, answerbag<sup>2</sup>, zhidao<sup>3</sup>, etc. Question retrieval (QR) in CQA can automatically find the most relevant and recent questions that have been solved by other users. Current QR approaches typically consider using diverse retrieval models, but they fail to analyze users' intention. User intentions such as finding facts, interacting with others, seeking reasons, etc. reflect what the users really want to know. Hence, we propose to integrate user intention analysis into QR. Firstly, we classify questions into different and multiple types of users' intentions. Another practical problem is that there naturally exist some preferences among the possible questions types. The more relevant type should be ranked higher than types which are not so relevant. Therefore, we propose to utilize a novel label ranking method, which is a machine learning algorithm that aims to predict a ranking among all the possible labels, to perform question classification. Secondly, based on the result of question classification, we integrate user intentions with translation-based language models to explore whether a user's intention does help to improve the performance. We conduct a series of experiments with Yahoo data, and the experimental results demonstrate that our proposed improved question retrieval can indeed enhance the performance of traditional question retrieval model.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033242","","Data models;History;Machine learning algorithms;Prediction algorithms;Support vector machines;Training;Training data","Internet;information retrieval;learning (artificial intelligence)","CQA;QR;Yahoo data;community question answering services;label ranking method;machine learning algorithm;question classification;question retrieval improvement;user intention analysis","","1","","21","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Integrating Living Labs with Future Internet experimental platforms for co-creating services within Smart Cities","H. Schaffers; A. Sällström; M. Pallot; J. M. Hernández-Muñoz; R. Santoro; B. Trousse","ESoCE Net, Rome, Italy","2011 17th International Conference on Concurrent Enterprising","20111010","2011","","","1","11","This paper examines the potential integration of Living Labs concepts of open and user driven innovation with Future Internet experimentally driven research approaches, in order to accelerate the user-driven development of Future Internet enabled services towards Smart Cities. Two key issues are underlying this integration: strengthening user involvement in experimental Internet research, and providing access to common resources such as testbed facilities and living lab resources. To explore the opportunities for such integration, three case studies from current FP7-ICT projects are discussed: SmartSantander, TEFIS and ELLIOT. A framework is proposed facilitating the sharing of resources offered by existing Smart City platforms, testbeds and living labs facilities as a basis for partnership agreements implementing open innovation approaches for Smart Cities.","","Electronic:978-3-943024-05-0; POD:978-1-4577-0772-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041259","Experimental Facilities;Experimentation;Future Internet;Internet of Things;Living Labs;Smart Cities","Cities and towns;Communities;Finite impulse response filter;Fires;Ice;Internet;Technological innovation","Internet;information retrieval","ELLIOT;FP7-ICT project;Future Internet experimental platform;Internet research;Living Labs concept;Smart Cities;SmartSantander;TEFIS;open innovation approach;partnership agreement;resource access;resource sharing;service cocreation;testbed facilities;user driven innovation;user involvement;user-driven development","","5","","9","","","20-22 June 2011","","IEEE","IEEE Conference Publications"
"Web-Based Verification on the Representativeness of Terms Extracted from Single Short Documents","J. H. Wang","Nat. Taipei Univ. of Technol., Taipei, Taiwan","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","114","117","Single document summarization is useful for extracting the major ideas from huge amount of daily information. However, it's a challenge to distinguish the relative importance among terms. In this paper, we propose a Web-based approach to term verification. Search-results of extracted terms are utilized as their expanded representation, and their similarity with the original document are calculated as an estimate of term representative ness. We experimented with term extraction methods on multilingual news extracts and compared the effectiveness of term verification with various Jaccard similarity measures. The experimental results show the feasibility of Web-based verification on the representativeness of extracted terms.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040819","Web mining;short text;term verification","Artificial intelligence;Conferences;Data mining;Estimation;Feature extraction;Google;Search engines","Internet;document handling;formal verification;information retrieval;linguistics","Jaccard similarity measures;Web-based verification;multilingual news extraction;single short document summarization;term extraction methods;term representativeness estimation;term verification","","0","","12","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Contrastive Reasoning with Inconsistent Ontologies","J. Fang; Z. Huang; F. van Harmelen","Sch. of Autom., Northwestern Polytech. Univ., Xi'an, China","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","191","194","In this paper we present a framework for answering queries over inconsistent ontologies by using contrastive reasoning, the reasoning of contrasts which are expressed as contrary conjunctions like the word ""but"" in natural language. We argue that contrastive answers are more informative for reasoning with inconsistent ontologies, as compared with the usual simple boolean answer, i.e., either ""yes"" or ""no"". We propose a general framework for contrastive reasoning with inconsistent ontologies. The proposed approach has been implemented in the system CRION (Contrastive Reasoning with Inconsistent Ontologies) as a reasoning plug-in in the LarKC (Large Knowledge Collider) platform. We report several experiments in which we apply the CRION system to some realistic ontologies. This evaluation shows that contrastive reasoning is a useful extension to the existing approaches of reasoning with inconsistent ontologies.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040517","clarification formula;contrastive answer;contrastive formula;contrastive reasoning;inconsistent ontology","Cognition;Knowledge based systems;Maintenance engineering;Mesons;Ontologies;Prototypes;Transportation","inference mechanisms;ontologies (artificial intelligence);question answering (information retrieval)","CRION system;LarKC;boolean answer;contrastive reasoning;inconsistent ontologies;large knowledge collider platform;natural language;plug-in reasoning;queries answering","","0","1","6","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Revealing Associations between Events and Their Characteristic Items","S. y. Sato; M. Takahashi; T. Nakamura; M. Matsuo","NTT Network Innovation Labs., Musashino, Japan","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","243","248","We pose a new problem of discovering associations between events in our daily lives and their characteristic items, such as (Halloween, pumpkin) and (Christmas, chimney). To solve the problem, we dopted an approach similar to that of existing research on event detection, which tries to discover events by detecting bursts of occurrence frequency of a relevant term in a document stream, where the term (item) is associated with the discovered event. We extracted events from blog entries available on the Web, while the previous studies mostly used news articles as document streams. Blog entries are shown to have quite different characteristics to news articles. Considering this fact, we developed a method for discovering the associations by integrating existing techniques that can handle and take advantage of the characteristics of blog data. We verified through experiments using actual data that the proposed approach works quite well.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6036755","burst detection;community detection;event extraction","Batteries;Blogs;Communities;Context;Data mining;IP networks;Typhoons","Web sites;document handling;information retrieval","Christmas;Halloween;association discovery problem;blog entries;characteristic items;chimney;community detection;document streams;event detection;event extraction;news articles;pumpkin","","0","","7","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Towards large scale modeling and realization of SNOMED CT in OWL-DL","L. Q. A. Michael; A. W. Tiong; R. Kanagasabai","Data Mining Department - Institute for Infocomm Research, A&#x2217;STAR Singapore","2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)","20111013","2010","","","401","407","SNOMED CT is a comprehensive medical terminology used for standardizing storage, retrieval and exchange of electronic health data. Towards more expressive knowledge representation, recent efforts have attempted to model SNOMED CT using OWL, but have often been stymied due to its size and complexity. This paper proposes a new approach to model and realize SNOMED<sup>1</sup> as an OWL ontology on large-scale. Rather than constructing raw owl files, we exploit a framework based on a triplestore-powered semantic backend that is interfaced through web services. With this framework, we show that almost the whole of the core tables of SNOMED including concepts, descriptions and relationships can be loaded into an OWL ontology, which can be queried in real-time. As part of the OWL modeling, we also propose a new strategy to model role groups via n-ary relationship ontology patterns. Through experiments on several use cases, we demonstrate that ours is a promising approach for modeling and realizing SNOMED in OWL.","1063-7125;10637125","Electronic:978-1-4244-9168-1; POD:978-1-4244-9167-4","10.1109/CBMS.2010.6042678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042678","","Load modeling;Medical services;OWL;Ontologies;Semantics;Servers;Web services","electronic data interchange;information retrieval;knowledge representation languages;medical information systems;ontologies (artificial intelligence);storage management","OWL-DL;SNOMED CT;electronic health data;information exchange;information retrieval;information storage;knowledge representation;large scale modeling;n-ary relationship ontology patterns;web services","","3","","13","","","12-15 Oct. 2010","","IEEE","IEEE Conference Publications"
"Ranking documents using similarity-based PageRanks","S. Hatakenaka; T. Miura","Dept. of Elect. and Elect. Engineering, HOSEI University, Kajinocho 3-7-2, Koganei, Tokyo, Japan","Proceedings of 2011 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing","20111003","2011","","","19","24","In this investigation we propose a new ranking algorithm for documents based on popularity. Considering similarity as virtual links, we introduce structural aspects among documents. Then, by means of authoritative importance or popularity, we obtain ranking scheme based on PageRank algorithm. We discuss experimental results to examine the effectiveness and some applications.","1555-5798;15555798","Electronic:978-1-4577-0253-2; POD:978-1-4577-0252-5; USB:978-1-4577-0251-8","10.1109/PACRIM.2011.6032861","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032861","Document Ranking;PageRank;Similarity;TF∗IDF Querying Documents using Similarity-based Ranks","Algorithm design and analysis;Equations;Games;Mathematical model;Stochastic processes;Symmetric matrices;Web pages","document handling;information retrieval","document ranking;similarity-based PageRanks;virtual links","","3","","5","","","23-26 Aug. 2011","","IEEE","IEEE Conference Publications"
"ICTs based crime control model: An application based study of Gilgit-Baltistan, Pakistan","S. Rahim; Sun Tie; A. Begum; B. Naz","School of Automation and Electrical Engineering, USTB 100083, China","IEEE 2011 10th International Conference on Electronic Measurement & Instruments","20111010","2011","2","","1","6","Information and communication technology involves all those kinds of services which receive, manipulate, store, retrieve and transmit information in digital form [18]. Example is the personal computers, email, robots and digital television. In this research, the Authors have proposed a GIS based system for crime monitoring and information retrieval for Gilgit City. This web based GIS application provides information and monitoring facilities in crimes control. This system enables for retrieval of various analytical information relating to Geography, report for crime location and indicate crime occurrence scene, information about Law Enforcement Agencies, and the services area like educational, health, parking areas, communication, Banks, community centers, shopping Malls, NGO office, hostels, Bus and vagan stations and Apartments etc. The system enables building the maps dynamically at different levels like Mohallas (Towns) and shows the security cameras which mounte in different areas. This system also stores the relevant information in database such as postgresql/postgis and mapserver and publishes online for public.","","Electronic:978-1-4244-8161-3; POD:978-1-4244-8158-3","10.1109/ICEMI.2011.6037753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037753","GIS;MS4W;MapServer;gmap;postgis;postgresql","Cities and towns;Geographic Information Systems;Law enforcement;Monitoring;Security;Spatial databases","Internet;geographic information systems;information retrieval;police data processing","GIS based system;Gilgit City;ICTs based crime control model;Web based GIS application;crime location;crime monitoring;crime occurrence scene;digital form;digital television;email;information and communication technology;information retrieval;law enforcement agency;mapserver;personal computer;robot;security camera","","0","","26","","","16-19 Aug. 2011","","IEEE","IEEE Conference Publications"
"Greedy and Randomized Feature Selection for Web Search Ranking","F. Pan; T. Converse; D. Ahn; F. Salvetti; G. Donato","Bing SF, Microsoft Corp., San Francisco, CA, USA","2011 IEEE 11th International Conference on Computer and Information Technology","20111010","2011","","","436","442","Modern search engines have to be fast to satisfy users, so there are hard back-end latency requirements. The set of features useful for search ranking functions, though, continues to grow, making feature computation a latency bottleneck. As a result, not all available features can be used for ranking, and in fact, much of the time only a small percentage of these features can be used. Thus, it is crucial to have a feature selection mechanism that can find a subset of features that both meets latency requirements and achieves high relevance. To this end, we explore different feature selection methods using boosted regression trees, including both greedy approaches (i.e., selecting the features with the highest relative influence as computed by boosted trees, discounting importance by feature similarity) and randomized approaches (i.e., best-only genetic algorithm, a proposed more efficient randomized method with feature-importance-based backward elimination). We evaluate and compare these approaches using two data sets, one from a commercial Wikipedia search engine and the other from a commercial Web search engine. The experimental results show that the greedy approach that selects top features with the highest relative influence performs close to the full-feature model, and the randomized feature selection with feature-importance-based backward elimination outperforms all other randomized and greedy approaches, especially on the Wikipedia data.","","Electronic:978-0-7695-4388-8; POD:978-1-4577-0383-6","10.1109/CIT.2011.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6036806","Feature Selection;Learning to Rank;Web Search","Data models;Electronic publishing;Encyclopedias;Feature extraction;Genetic algorithms;Internet","Web sites;greedy algorithms;information retrieval;random processes;regression analysis;search engines;tree data structures","Web search engine;Wikipedia;backend latency requirements;boosted regression trees;data sets;full-feature model;greedy approach;random feature selection;search ranking functions","","1","","17","","","Aug. 31 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"A Web-Based Framework for User-Centred Evaluation of End-User Experience in Adaptive and Personalized E-Learning Systems","C. Mulwa; S. Lawless; M. Sharp; V. Wade","Centre for Next Generation Localisation, Trinity Coll. Dublin, Dublin, Ireland","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","351","356","The evaluation of interactive adaptive and personalised systems has long been acknowledged as a difficult, complicated and very demanding Endeavour due to the complex nature of these systems. This paper describes a web-based framework for the evaluation of end-user experience in adaptive and personalised e-Learning systems. The benefits of the framework include: i) the provision of an interactive reference and recommendation tool to encourage the evaluation of systems that fulfil certain methodological requirements, ii) the collaborative nature of the framework facilitates the sharing of information among researchers from the information technology, adaptive hypermedia, information retrieval and e-Learning communities, iii) the identification of pitfalls in the evaluation planning process as well as in data analysis, and iv) the translation of presented information into users language of choice. This paper also presents a review of User-Centred Evaluation approaches, methodologies and techniques adopted by current systems and frameworks. The results of this review are analysed. From these results, an architectural design for the framework was specified.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040877","Personalised e-Learning;User-centred Evaluation;adaptive hypermedia;personalisation","Adaptation models;Adaptive systems;Analytical models;Context modeling;Data models;Electronic learning;Object oriented modeling","Internet;adaptive systems;computer aided instruction;data analysis;human computer interaction;hypermedia;information retrieval;planning (artificial intelligence);recommender systems","Web-based framework;adaptive hypermedia;architectural design;data analysis;end-user experience;evaluation planning process;information retrieval;information technology;interactive adaptive e-learning systems;interactive personalized e-learning systems;interactive recommendation tool;interactive reference tool;user-centred evaluation","","3","","33","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Alleviating information overload caused by volumes of numerical web data: the concept and development process","S. C. Hu; I. C. Chen","Department of Computer Science & Communication Engineering, Providence University, No. 200, Chung-Chi Road, Shalu, Taichung 43301, Taiwan","IET Software","20111010","2011","5","5","445","453","The really simple syndication (RSS), a popular information dissemination mechanism, to some extent, eases the overloaded users on the Web. However, because of the limitation in its original design, currently available RSS applications cannot salvage overloaded information consumers from volumes of numerical Web data. The present work aims to change the working pattern of users who rely on processing numerical Web data to accomplish their tasks and correspondingly to improve their productivity. An extended schema was developed for formally representing numerical data items in RSS documents, and thus data providers can distribute numerical data and textual messages to subscribers. A client-side productive tool was designed to support retrieval and manipulation of numerical data from RSS feeds, its prototype was developed to realise the proposed idea and demonstrate its usefulness. Based on the observation of actual usage, the foreseeable effect of this kind of applications is reducing users' time spent on surfing, collecting, calculating and tracking numerical data on the Web. To make the present work more versatile and serve diverse users, it is rational to augment the prototyped tool as a general-purpose computing platform.","1751-8806;17518806","","10.1049/iet-sen.2010.0099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6036404","","","Internet;human computer interaction;information dissemination;information retrieval;text analysis","RSS documents;client-side productive tool;concept process;development process;general-purpose computing platform;information dissemination mechanism;information overload;numerical Web data;numerical data manipulation;numerical data retrieval;really simple syndication;textual messages","","1","","","","","Oct. 2011","","IET","IET Journals & Magazines"
"Principles and Properties of a MAS Learning Algorithm: A Comparison with Standard Learning Algorithms Applied to Implicit Feedback Assessment","S. Lemouzy; V. Camps; P. Glize","IRIT, Univ. Paul Sabatier, Toulouse, France","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","2","","228","235","The purpose of this paper is to present a new learning algorithm based on an adaptive multi-agent system and to compare it with classical learning algorithms such as the Multi-Layer Perceptron (MLP), the Support Vector Machine (SVM), and the Decision Tree (DT). This comparison is made using data extracted from logs of a local citizen information search engine, called iSAC. It is based on the learning and the inference of the assessment of a real user with regard to the documents provided by iSAC in response to his request. The experimental evaluations show that our algorithm provides results at least as good as those achieved with classical learning approaches, in addition to its capability to function in dynamic and time constrained environments.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040782","Implicit assessment of user's feedback;Multi-agent learning;Personalization;Self-adaptive systems;Self-organization","Algorithm design and analysis;Artificial neural networks;Data mining;Decision trees;Heuristic algorithms;Real time systems;Support vector machines","decision trees;document handling;feedback;inference mechanisms;information retrieval;learning (artificial intelligence);multi-agent systems;multilayer perceptrons;search engines;support vector machines","MAS learning algorithm;adaptive multi-agent system;data extraction;decision tree;document handling;feedback assessment;iSAC;inference mechanism;information search engine;multilayer perceptron;standard learning algorithms;support vector machine","","9","","17","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Automated question answering for customer helpdesk applications","L. Samarakoon; S. Kumarawadu; K. Pulasinghe","Department of Electrical Engineering, University of Moratuwa, Sri Lanka","2011 6th International Conference on Industrial and Information Systems","20111010","2011","","","328","333","This paper describes a closed domain question answering system which can be used as the first step in automating a customer helpdesk of a commercial organization. Even though there has been an increasing interest in data-driven methods over the past decade to achieve more natural human-machine interactions, such methods require a large amount of manually labeled representative data on how user converses with a machine. However, this is a strong requirement that is difficult to be satisfied in the early phase of system development. The knowledge-based approach that we present here is aimed at maximally making use of the user experience available with the customer services representatives (CSRs) in the organization and hence not relying on application data. The approach takes into account the syntactic, lexical, and morphological variations, as well as a way of synonym transduction that is allowed to vary over the systems knowledgebase. The query understanding method, which is based on a ranking algorithm and a pattern writing process, takes into account the intent, context, and content components of natural language meaning as well as the word order. A genetic algorithm-based method is presented for regularly updating the ranking parameters to adapt to changes in the nature of users' queries over time. We present an evaluation of our system deployed in a real-world enterprise helpdesk environment at Exetel Pty Ltd., Australia.","2164-7011;21647011","Electronic:978-1-4577-0035-4; POD:978-1-4577-0032-3","10.1109/ICIINFS.2011.6038089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038089","Automated Helpdesk;Question Answering;Vector Space Model","Boosting;Context;Genetic algorithms;Indexes;Optimization;Writing","customer services;genetic algorithms;human computer interaction;knowledge based systems;natural language processing;question answering (information retrieval);technical support services","Australia;Exetel Pty Ltd.;automatic closed domain question answering system;commercial organization;customer helpdesk applications;customer services representatives;data-driven methods;genetic algorithm-based method;knowledge-based approach;natural language meaning;natural machine interactions;pattern writing process;ranking algorithm;real-world enterprise helpdesk environment;synonym transduction;system development","","1","","15","","","16-19 Aug. 2011","","IEEE","IEEE Conference Publications"
"An automatic approach to extracting review link from Chinese news pages","W. Liu","Inf. Source Center, Inst. of Sci. &amp; Tech. Inf. of China, Beijing, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","2","","411","415","Review links are widely used in some special kinds of web pages, especially news pages. They are very useful pieces of information in many applications, such as hot topic discovery and public opinion monitoring. Unfortunately, extracting review links manually from news pages is time-consuming and error-prone. Though lots of works on web data extraction have been developed, we argue that this is still not a trivial problem due to the diversity on both DOM tree structure and visual presentation. In this paper, a novel approach is proposed for automatically extracting the review links from web pages. This approach consists of two steps: first segment each news page into a set of blocks, and then identify the block(s) that contain the review link using a machine learning technique. Experimental results over a large number of Chinese news pages indicate that this approach is highly accurate.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030361","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030361","Machine learning;Review link;Visual feature;Web data extraction","Data mining;Decision trees;Feature extraction;HTML;Training;Visualization;Web pages","Internet;information retrieval;learning (artificial intelligence);reviews;tree data structures","Chinese news pages;DOM tree structure;Web data extraction;Web pages;machine learning technique;review link extraction;visual presentation","","0","","16","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"A Semi-Markov Survivability Evaluation Model for Intrusion Tolerant Real-Time Database Systems","C. Chen; W. Wu; H. Zhou; G. Shen","Huazhong Univ. of Sci. & Technol., Wuhan, China","2011 7th International Conference on Wireless Communications, Networking and Mobile Computing","20111010","2011","","","1","4","With the application of real-time databases and the intrusion of malicious transactions, it has become increasingly important to model the ability of real-time database intrusion tolerance and effectively evaluate its survivability. Based on the features of transaction and data for real-time database system, an intrusion tolerant architecture has been proposed for real-time database system. Considering factors such as intrusion detection latency and a variety of parameters for real-time, Semi-Markov evaluation model for survival assessment is established. Based on this model, relevant quantitative criteria are made to define the important indicators of survivability, such as integrity and availability, so as to validate intrusion detection capability and the survivability of real-time database. The three important factors of false alarm, detection rate and the intensity of attack are analyzed in detail by the TPC-C benchmark. Experiments show that the model can accurately predict the behavior of real-time database. The real-time database following the model can still provide essential services when facing attacks and the basic survival characteristics will not be seriously affected.","2161-9646;21619646","Electronic:978-1-4244-6252-0; POD:978-1-4244-6250-6","10.1109/wicom.2011.6040583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040583","","Database systems;Maintenance engineering;Markov processes;Mathematical model;Real time systems;Steady-state","information retrieval systems;information services;safety systems;security of data;telecommunication network reliability","TPC-C benchmark;essential services;false alarm;intrusion tolerant real-time database system;quantitative criteria;real-time database intrusion tolerance;semiMarkov survivability evaluation model;survivability","","0","","8","","","23-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"DEH: A Ubiquitous Heritage Exploring System Using the LBS Mechanism","C. M. Huang; S. C. Lu","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","2011 14th International Conference on Network-Based Information Systems","20111013","2011","","","310","317","This paper proposes a concept of providing a theme tour in which people can deeply experience heritage in a main topic using handheld devices. Based on the concept, a Demodulating and Encoding Heritage (DEH) heritage exploring system is developed using a Location Based Service (LBS) mechanism. In order to fulfill the LBS-based heritage touring experience, a metadata element set has been defined to describe the heritage content. Additionally, there are some technical issues that need to be resolved in the LBS mechanism, i.e., how to retrieve content efficiently and provide appropriate contents to a user according the user location? In this study, we propose (1) a hierarchical content retrieving method to retrieve content efficiently and (2) a content cache and arrangement method to provide appropriate contents to users, and (3) a triggering of content presentation method to present the corresponding contents in the right time instant. To verify our DEH heritage exploring system, we also had a case usage and then had the questionnaire about the using experience.","2157-0418;21570418","CD-ROM:978-0-7695-4458-8; CD-ROM:978-07695-4580-6; Electronic:978-0-7695-4458-8; POD:978-1-4577-0789-6","10.1109/NBiS.2011.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041935","Heritage exploring system;LBS content retrieving;Location-based services;touring system","Blogs;Cities and towns;Communities;Context;Databases;Handheld computers;Mobile communication","content management;encoding;information retrieval;meta data;ubiquitous computing","DEH heritage exploring system;LBS mechanism;content arrangement method;content cache;content presentation method;content retrieving method;demodulating and encoding heritage exploring system;handheld device;location based service mechanism;metadata element;ubiquitous heritage exploring system;user location","","1","","7","","","7-9 Sept. 2011","","IEEE","IEEE Conference Publications"
"A music question answering system enhanced with dialogue management","Z. Xingtao","Dept. of Security, Chinese People's Public Security Univ., Beijing, China","2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)","20110922","2011","","","1105","1109","The main challenge of question answering is that the lack of task structure prohibits the use of simplified assumptions as in task-oriented dialogue systems. This problem was tackled by integrating a dialogue management environment into a question answering system. Firstly, Wizard of Oz studies were conducted to discover how users describe their music information needs in contextual situations as well as single standalone questions. Subsequently, the system was constructed and enhanced with the ability to use the dialogue context and the Web to answer more extended questions about artists, songs, albums, tours, et cetera. Finally, the system was successfully tested on 120 dialogues with 10 users. The evaluation was reported on three variants of this system, and the results were promising with good levels of both task completion and user preferences.","","Electronic:978-1-61284-722-1; POD:978-1-61284-719-1","10.1109/MEC.2011.6025660","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025660","Wizard of Oz;dialogue management;music domain;question answering","Computer architecture;Context;Databases;Humans;Internet;Natural languages;Pragmatics","Internet;information needs;interactive systems;question answering (information retrieval)","Wizard of Oz studies;dialogue management environment;music information needs;music question answering system;task-oriented dialogue systems","","0","","8","","","19-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Application of CBR on viral fever detection system(VFDS)","S. Deyashi; D. Banerjee; B. Chakraborty; D. Ghosh; J. Debnath","National Institute of Technology, Durgapur, West Bengal, India","2011 9th IEEE International Conference on Industrial Informatics","20111006","2011","","","660","665","In this paper an approach for developing knowledge-based viral fever detection system based on the methodology of case-based reasoning (CBR) is described. CBR is an approach for solving problems based on solutions of similar past case. Cases are stored in a database of cases called a case base (CB). To solve an actual problem a notation of similarities between problems is used to retrieve similar cases from the case base. The solutions of these similar cases are then used as starting points for solving the actual problem. This paper discusses on a viral fever detection system (VFDS) which helps the hospital or medical centre to detect the type of disease the patient is suffering from after being affected by some particular viral fever with its respective symptoms.","1935-4576;19354576","Electronic:978-1-4577-0434-5; POD:978-1-4577-0435-2; USB:978-1-4577-0433-8","10.1109/INDIN.2011.6035037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035037","","Cognition;Diseases;Equations;Mathematical model;Pediatrics;Temperature measurement;Temperature sensors","bio-optics;biomedical measurement;biothermics;case-based reasoning;diseases;information retrieval systems;infrared detectors;knowledge based systems;medical diagnostic computing;microorganisms;thermometers","case based reasoning;case retrieval;disease;hospital;knowledge based system;medical centre;viral fever detection system","","2","","27","","","26-29 July 2011","","IEEE","IEEE Conference Publications"
"Geometric identification of search states on (F, F)-information","Y. Li; L. Zhang; S. Zhang; Q. Ruan","Dept. of Comput. &amp; Inf. Eng., Ningde Normal Univ., Ningde, China","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","1189","1193","Using P-sets, the concepts of (F̅, F)-information, (F̅, F)-search scale and (F̅, F)-search circle are proposed. Meanwhile, this paper give the search principle of (F̅, F)-information, the sequence theorem of (F̅, F)-search scale, the internal-outer point theorem of the unit discrete interval on (F̅, F)-search scale, and the position theorem of (F̅, F)-search circle. (F̅, F)-search circle is a series of concentric circles. The geometric identification theorem and the identification criterion of the search states on (F̅, F)-information are given by (F̅, F)-search circle. This paper also provides the application of identifying the search states on (F̅, F)-information. The geometric identification of the search states on (F̅, F)-information can enhance the geometry intuitive characteristic of the search states as well as (F̅, F)-information size in information systems. The geometric identification of the search states on (F̅, F)-information provides a new visualization method for information systems' search states.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028845","(F, F)-information;(F, F)-search circle;P-sets;geometric identification;identification criterion","Computers;Educational institutions;Finite element methods;Information systems;Marine vehicles;Typhoons;Visualization","geometry;information retrieval;information systems;set theory","P-sets;concentric circles;geometric identification theorem;geometry intuitive characteristic;identification criterion;information size;information systems search states;internal-outer point theorem;position theorem;search circle;search principle;search scale;sequence theorem;unit discrete interval;visualization method","","1","","12","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Chinese calligraphy system in CADAL","K. Yu; B. Hu; M. Ye; Z. Yuan","Sch. of Inf. Sci. &amp; Eng., Hangzhou Normal Univ., Hangzhou, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","1","","377","380","In this paper, a novel Chinese calligraphy system is presented and implemented. It is designed as a new version of the calligraphy system in CADAL, and will be online in several months instead of the current version developed some years ago. In this system, users can browse and retrieve the calligraphy books, calligraphy works and calligraphy characters, user can generate a calligraphy tablet, a user can write one or more characters with common-used input devices and render them with the strokes of a specific calligrapher and a user can view the writing process of some calligraphy characters. Many latest technologies are integrated in the proposed system. The key technologies are shape based calligraphy character retrieval, style-consistent calligraphy character synthesis and calligraphy tablet generation, calligraphy character rendering, and calligraphy character writing process simulation. The system is well designed and all the subsystems work well in our experiments.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6022956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022956","CADAL;Chinese calligraphy system;calligraphy rendering;calligraphy retrieval;calligraphy synthesis;writing process simulation","Brushes;Databases;Educational institutions;Rendering (computer graphics);Shape;Skeleton;Writing","art;digital simulation;information retrieval;rendering (computer graphics)","CADAL;Chinese calligraphy system;calligraphy books;calligraphy character rendering;calligraphy character retrieval;calligraphy character writing process simulation;calligraphy tablet generation;calligraphy works;style consistent calligraphy character synthesis","","0","","12","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"An adaptive projection strategy and its implementation in column stores","X. Ding; W. Yu; J. Le","Sch. of Comput. Sci. &amp; Theor., Donghua Univ., Shanghai, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","1","","468","473","Tuple reconstruction is an important component in column-stores. Some well-known column-stores, such as C-Store, employ projection to support tuple reconstruction. This paper proposes an adaptive projection strategy and an implementation method for projection. The proposed strategy employs association analysis to a considerable amount of query accesses submitted by users to group attributes of a relation into various projections. The strategy makes selections of projections adaptive to usage behaviors of users. This paper implements projections using main indexes and jointing address mapping indexes. The main index stores all columns of a projection, therefore, the proposed storage pattern is a compromise pattern rather than pure column store. But, with the proposed storage structure, the system not only avoids reading unnecessary attribute columns to answer query, but also does tuple reconstruction. The address mapping index is used to locate fast tuples. Finally, the experimental results on benchmark data set SSB show that the proposed strategy and implementation method can improve significantly the performance of multicolumn queries.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030249","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030249","address mapping index;association analysis;column-store;projection;tuple reconstruction","Amplitude modulation;Clustering algorithms;Correlation;Data mining;Distributed databases;Engines;Indexes","indexing;query processing;question answering (information retrieval)","C-Store;adaptive projection strategy;address mapping indexes;association analysis;column stores;multicolumn queries;query answering;storage pattern;support tuple reconstruction","","1","","14","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Semantic Negotiation-Based Service Framework in an M2M Environment","P. B. Jeon; J. Kim; S. Lee; C. Lee; D. K. Baik","Intell. Comput. Lab., Samsung Electron., Yongin, South Korea","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","2","","337","340","In this paper, we propose a semantic negotiation based service framework for the extraction of optimized service information without user intervention in intelligent Machine to Machine (M2M) environment. Proposed semantic negotiation procedure is used for a machine in order to interact with another encountered heterogeneous machine. Through the proposed semantic negotiation procedure, each machine can understand the messages thoroughly sent by the corresponding machine and exchange necessary information.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040801","M2M;agent;ontology;semantic negotiation","Cognition;Data mining;Mobile handsets;Ontologies;Semantics;Sensors;Servers","human computer interaction;information retrieval;mobile computing;multi-agent systems;ontologies (artificial intelligence);optimisation","M2M environment;intelligent machine to machine environment;ontology;optimized service information extraction;semantic negotiation-based service framework","","3","","8","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Optimizing User Guidance during Decision-Making","A. Nohrer; A. Egyed","Inst. for Syst. Eng. &amp; Autom. (SEA), Johannes Kepler Univ., Linz, Austria","2011 15th International Software Product Line Conference","20110929","2011","","","25","34","The configuration of a product from a product line is a decision-making process that requires humans to answer questions. However, questions and their choices tend to affect one another (e. g., one feature depending on another) and decisions on how questions are answered may render other questions obsolete or reduce their choices. There is thus an ideal order in which questions should be answered to minimize the number of questions that need answering to completely configure a product. Unfortunately, this ideal order differs depending on the product -- which cannot be known a priori. Decision-making is thus characterized by either imposing a predefined order on how questions must be answered (usually done manually by product line engineers) or not imposing any order. Both situations have downsides and this paper thus proposes an alternative: an incremental algorithm and tool-support for automatically optimizing the order of questions with every answer. We evaluated our approach on six models, the largest with over 280 questions, and found that the approach is 78-99% optimal and significantly reduces the number of questions that need to be answered manually. For the creators of product line models, this implies savings in not having to predefine the optimal order which is exponentially complex. For the configurator (decision maker) this implies more freedom in the order in which to answer questions while still benefiting from guidance.","","Electronic:978-0-7695-4487-8; POD:978-1-4577-1029-2","10.1109/SPLC.2011.45","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030043","Formal Reasoning;Product Line Engineering;User Guidance","Cognition;Databases;Decision making;Engines;Portable computers;Software","decision making;human computer interaction;inference mechanisms;optimisation;question answering (information retrieval);software development management","automatic optimization tool support;decision making process;formal reasoning;incremental algorithm;product line engineering;question answering;user guidance optimization","","3","","15","","","22-26 Aug. 2011","","IEEE","IEEE Conference Publications"
"RCBA: An Efficient Annotation Tool for Community E-Learning","F. Lu; X. Li","Coll. of Comput. Sci., Yangtze Univ., Jingzhou, China","2011 Fifth International Conference on Genetic and Evolutionary Computing","20111013","2011","","","353","356","The topic of webpage content annotation has been an important research area in the field of human computer interaction. Annotation tools enable ""value-adding"" info to digital resources, by adding additional data in the form of provenances, understandings, references, comments and other types of remarks. They facilitate learners' and reviewers' understanding and remembering of information accessible over the Web, and make the collaborative learning easier. This paper describes an efficient annotation tool RCBA (Role Control Based Annotator), that we have developed which uses RBAC (Role Based Access Control) theory to identify and authenticate users and restrict their access to annotations stored on the database server, and enhance the knowledge sharing and reuse in communities' E-learning.","","Electronic:978-0-7695-4449-6; POD:978-1-4577-0817-6","10.1109/ICGEC.2011.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042799","RCBA;annotation;relational database;role control","Browsers;Communities;Databases;Electronic learning;HTML;Servers;User interfaces","authorisation;computer aided instruction;content management;human computer interaction;information retrieval;relational databases","RBAC;RCBA;Web page content annotation tools;collaborative learning;database server;digital resources;e-learning;human computer interaction;knowledge sharing;role based access control theory;role control based annotator;user authentication;user identification","","0","","6","","","Aug. 29 2011-Sept. 1 2011","","IEEE","IEEE Conference Publications"
"Ontology-Based Feature Extraction","C. Vicient; D. S´nchez; A. Moreno","Dept. d'Eng. Inf. i Mat., Univ. Rovira i Virgili, Tarragona, Spain","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","189","192","Knowledge-based data mining and classification algorithms require of systems that are able to extract textual attributes contained in raw text documents, and map them to structured knowledge sources (e.g. ontologies) so that they can be semantically analyzed. The system presented in this paper performs this tasks in an automatic way, relying on a predefined ontology which states the concepts in this the posterior data analysis will be focused. As features, our system focuses on extracting relevant Named Entities from textual resources describing a particular entity. Those are evaluated by means of linguistic and Web-based co-occurrence analyses to map them to ontological concepts, thereby discovering relevant features of the object. The system has been preliminary tested with tourist destinations and Wikipedia textual resources, showing promising results.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040837","Information Extraction;Linguistic Patterns;Ontologies;Web-based statistics","Data mining;Electronic publishing;Feature extraction;Information services;Internet;Ontologies;Semantics","data analysis;data mining;information retrieval;knowledge based systems;ontologies (artificial intelligence);pattern classification;text analysis","Web-based co-occurrence analysis;Wikipedia textual resources;classification algorithms;data analysis;knowledge sources;knowledge-based data mining;linguistic analysis;named entities;ontology-based feature extraction;text documents;textual attributes extraction;tourist destinations","","3","","16","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Throughput per Pass for Data Aggregation from a Wireless Sensor Network via a UAV","A. Giorgetti; M. Lucchi; M. Chiani; M. Z. Win","University of Bologna","IEEE Transactions on Aerospace and Electronic Systems","20111006","2011","47","4","2610","2626","Data retrieval from a sensor field by means of unmanned aerial vehicle (UAV) has increasing interests for both commercial, military, and homeland security applications. In these situations, the design of energy-efficient communication links between sensor field and UAV is crucial, owing to battery powered sensor nodes. We propose an energy-efficient cooperative transmission scheme for wireless sensor networks (WSNs) where data gathered by sensor nodes need to be collected into a far receiver. In particular, we consider a network composed of sensor nodes that share a common message that has to be transmitted asynchronously toward a fusion center onboard a UAV. We consider that the communication channels between the nodes and the fusion center are subject to fading and noise. Due to the far communication distance and energy constraint at each node, the fusion center must be able to reliably receive the weak and noisy signals. In our approach the fusion center consists of a Rake receiver capable of collecting multiple replicas of the same information from the nodes in the WSN. The performance of the proposed cooperative diversity scheme is then studied in terms of throughput, bit error probability, and energy efficiency. The results obtained show that, as the number of nodes increases, the proposed approach increases network lifetime, communication reliability, and throughput.","0018-9251;00189251","","10.1109/TAES.2011.6034654","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034654","","Fading channles;Multipath channels;Mutual information;Receivers;Throughput;Unmanned aerial vehicles;Wireless sensor networks","cooperative communication;diversity reception;error statistics;information retrieval;radio receivers;remotely operated vehicles;sensor fusion;space vehicles;telecommunication channels;telecommunication links;telecommunication network reliability;wireless sensor networks","Rake receiver;UAV;WSN;battery powered sensor nodes;bit error probability;communication channels;communication distance;communication reliability;cooperative diversity scheme;data aggregation;data retrieval;energy constraint;energy efficiency;energy-efficient communication links;energy-efficient cooperative transmission scheme;fusion center;network lifetime;noisy signals;sensor field;unmanned aerial vehicle;wireless sensor network","","20","","40","","","OCTOBER 2011","","IEEE","IEEE Journals & Magazines"
"Proposal for semantic metric to assess the quality of ontologies","D. Sathya; K. R. Uthayan","Dept. of Inf. Technol., SSN Coll. of Eng., Chennai, India","2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies","20110922","2011","","","754","756","Existing web retrieve the relevant information based on its syntactic nature. But the information retrieval is not that much efficient. Semantic Web, the extension of current web is providing a solution to this problem. The semantic web depends on Ontology which provides an efficient meaning based search and information retrieval available through the web. Ontology is a test bed of semantic web, capturing knowledge about a certain area via providing relevant concepts and relations between them. Since the Semantic Web is heavily relies on Ontology we have to evaluate the quality of Ontology. Quality metrics are essential to evaluate the quality. Metrics are based on structure and the semantic level. At present the Ontology evolution is based only on structural metrics, which has not been very appropriate in providing desired results. This proposal concentrates on identifying the ontology, which ensures high accuracy. So the main aim is to design a Web interface for evaluating the quality of ontology by new semantic metric.","","Electronic:978-1-61284-653-8; POD:978-1-61284-654-5","10.1109/ICSCCN.2011.6024651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024651","Inheritance;Ontology;Relationships;Semantic Metric;Semantic Web","Gears;Measurement;Ontologies;Proposals;Semantic Web;Semantics;Vehicles","information retrieval;ontologies (artificial intelligence);semantic Web","Web interface;information retrieval;meaning based search;ontology evolution;quality metrics;semantic Web;semantic metric","","1","","12","","","21-22 July 2011","","IEEE","IEEE Conference Publications"
"Developing local languages repository system using semantic web technology","W. D. Sunindyo; A. Mulyanto; Y. Widyani; T. E. Widagdo","Sch. of Electr. Eng. &amp; Inf., Inst. of Technol. Bandung, Bandung, Indonesia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","6","A language contains complex history and knowledge of human kinds. Hence, we have to conserve the language in order to conserve the history and knowledge of our ancestors to the next generation. Currently, there are a lot of local languages that are endangered due to the extensive use of national language in daily practices. This could make us losing of historical and knowledge richness from our local ancestors. One way to conserve the local language is by learning and making research on that language. However, current approaches for learning and making research on local language is hard and time-consuming, due to the limitation of domain experts. Current method to learn and research on local language is based on offline media, e.g., books, that have limitation on access and distribution. To solve these problems, we proposed a language repository system based on semantic web technology. We created LangIT, a language intelligent repository system to facilitate the users to learn and conduct research on a local language. LangIT is developed by using semantic web technology to enable a faster, easier, and more efficient data access compared to the traditional approach. We used Sundanese language as case for our system. Major result shows that LangIT is very useful for learning and researching Indonesian local language and extendable for other purposes on using the local languages.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021827","Semantic web technology;ontology;repository system","Databases;Engines;Ontologies;Pragmatics;Resource description framework;Vocabulary","information retrieval;natural language processing;semantic Web","LangIT;Sundanese language;data access;domain experts;local language repository system;national language;offline media;semantic Web technology","","0","","11","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"A Text Similarity Meta-Search Engine Based on Document Fingerprints and Search Results Records","F. Bravo-Marquez; G. L'Huillier; S. A. Rios; J. D. Vel´squez","Dept. of Ind. Eng., Univ. of Chile, Santiago, Chile","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","146","153","The retrieval of similar documents from the Web using documents as input instead of key-term queries is not currently supported by traditional Web search engines. One approach for solving the problem consists of fingerprint the document's content into a set of queries that are submitted to a list of Web search engines. Afterward, results are merged, their URLs are fetched and their content is compared with the given document using text comparison algorithms. However, the action of requesting results to multiple web servers could take a significant amount of time and effort. In this work, a similarity function between the given document and retrieved results is estimated. The function uses as variables features that come from information provided by search engine results records, like rankings, titles and snippets. Avoiding therefore, the bottleneck of requesting external Web Servers. We created a collection of around 10,000 search engine results by generating queries from 2,000 crawled Web documents. Then we fitted the similarity function using the cosine similarity between the input and results content as the target variable. The execution time between the exact and approximated solution was compared. Results obtained for our approximated solution showed a reduction of computational time of 86% at an acceptable level of precision with respect to the exact solution of the web document retrieval problem.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040511","Document Fingerprinting;Meta-Search Engine;Query Generation;Ranking Fusion;Similar Document Retrieval","Engines;Feature extraction;Fingerprint recognition;Metasearch;Search engines;Web search;Web servers","document handling;file servers;information retrieval;records management;search engines;text analysis","URL;Web document retrieval;Web search engines;Web server;document fingerprint;search result record;text comparison algorithm;text similarity meta search engine","","3","","22","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Detecting Intent of Web Queries Using Questions and Answers in CQA Corpus","S. Yoon; A. Jatowt; K. Tanaka","Grad. Sch. of Inf., Kyoto Univ., Kyoto, Japan","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","352","355","Detecting intent in Web search activity is important task for finding relevant Web information. However extracting intents from users' queries is difficult as users express their intent by issuing short and often ambiguous queries, yet at the same time it is crucial factor for enhancing user satisfaction. Showing the variety of candidate intents behind a query could help users choose correct intent expressions and improve the Web search. In this paper, we propose the methodology for detecting intent of Web queries using Community Question-Answer (CQA)information. Our assumption is that questions and its answers in CQA corpus reflect intents of questioners. To detect these intents, we use the semantic connections between questions and its answers. We categorize questions to find the connections of features within a question and its answers, detect intent words in answers by calculating supports of concerned CQA contents, and cluster questions and their answers by these intent words. Experimental results show that the variety of Web query intents can be found with satisfactory performance.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038706","Community Question-Answer corpus;Query Intent","Data mining;Feature extraction;Knowledge engineering;Semantics;Web pages;Web search;World Wide Web","Internet;query formulation;query processing;question answering (information retrieval)","CQA corpus;Web information;Web query;Web search activity;community question-answer information;intent detection;user satisfaction","","0","1","20","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Methods for greyscale representation of HEp-2 colour images","E. Cordelli; P. Soda","Integrated Research Centre, Universit&#x00E0; Campus Bio-Medico di Roma, Roma, Italy, Via Alvaro del Portillo 21, 00128 Roma, Italy","2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)","20111013","2010","","","383","388","Detection of antibodies via indirect immunofluorescence (IIF) is a common marker in patients with suspected connective tissue diseases. IIF readings are affected by several issues limiting their reproducibility and reliability: hence, the development of a computer-aided diagnosis (CAD) tool supporting IIF diagnostic procedure would be beneficial in many respects. Although some works in the literature use greyscale cooled cameras for IIF image acquisition, recent research as well as commercial CAD solution use colour cameras. Indeed, colour cameras are cheaper than greyscale cameras and have adequate performance for the needs of IIF image acquisition. However, their application asks for studying how to extract useful information from colour images for CAD development. This paper presents an experimental comparison between four different methods converting a colour image into a greyscale one. This analysis has been carried out testing different popular classification paradigms on an annotated IIF image dataset, and also performing pre-clinical tests. Results show that a conversion method based on information derived from RGB primary components outperforms the others relying on different colour models.","1063-7125;10637125","Electronic:978-1-4244-9168-1; POD:978-1-4244-9167-4","10.1109/CBMS.2010.6042674","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042674","","Accuracy;Cameras;Design automation;Feature extraction;Humans;Image color analysis;Medical services","biological tissues;biomedical optical imaging;diseases;fluorescence;image colour analysis;image representation;image sensors;information retrieval;medical image processing","CAD development;HEp-2 colour images;IIF diagnostic procedure;IIF image acquisition;IIF readings;RGB primary components;antibodies detection;colour cameras;computer-aided diagnosis tool;greyscale representation;indirect immunofluorescence;suspected connective tissue diseases","","2","","24","","","12-15 Oct. 2010","","IEEE","IEEE Conference Publications"
"Information extraction from scientific paper using rhetorical classifier","M. L. Khodra; D. H. Widyantoro; E. A. Aziz; R. T. Bambang","Sch. of Electr. Eng., Bandung Inst. of Technol., Bandung, Indonesia","Proceedings of the 2011 International Conference on Electrical Engineering and Informatics","20110919","2011","","","1","5","Time constraints often lead a reader of scientific paper to read only the title and abstract of the paper, but reading these parts is often ineffective. This study aims to extract information automatically in order to help the readers get structured information from a scientific paper. The information extraction is done by rhetorical classification of each sentence in a scientific paper. Rhetoric information is the intention to be conveyed to the reader by the author of the paper. This research used corpus-based approach to build rhetorical classifier. Since there was a lack of rethorical corpus, we constructed our own corpus, which is a collection of sentences that have been labeled with rhetorical information. Each sentence represented as a vector of content, location, citation, and meta-discourses features. This collection of feature vectors is used to build rhetorical classifiers by using machine learning techniques. Experiments were conducted to select the best learning techniques for rhetorical classifier. Training set consists of 7239 labeled sentences, and the testing set consists of 3638 labeled sentences. We used WEKA (Waikato Environment for Knowledge Analysis) and LibSVM libraries. Learning techniques being considered were Naive Bayes, C4.5, Logistic, Multi-Layer Perceptron, PART, Instance-based Learning, and Support Vector Machines (SVM). The best performers are the SVM and Logistic classifier with accuracy of 0.51. By applying one-against-all strategy, the SVM accuracy can be improved to 0.60.","2155-6822;21556822","Electronic:978-1-4577-0752-0; POD:978-1-4577-0753-7","10.1109/ICEEI.2011.6021634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6021634","SVM classifier;information extraction;rhetorical classifier;rhetorical corpus;scientific paper","Accuracy;Data mining;Feature extraction;Logistics;Machine learning;Support vector machines;Training","Bayes methods;information retrieval;learning (artificial intelligence);multilayer perceptrons;pattern classification;support vector machines","C4.5 learning technique;LibSVM libraries;PART;Waikato environment for knowledge analysis;corpus-based approach;feature vectors;information extraction;instance-based learning;logistic learning technique;machine learning techniques;multilayer perceptron;naive Bayes;rhetoric information;rhetorical classifier;scientific paper;sentence rhetorical classification;support vector machines","","1","","24","","","17-19 July 2011","","IEEE","IEEE Conference Publications"
"Music retrieval method based on filter-bank feature and earth mover's distance","Q. Xiao; S. Tsuge; K. Kita","Univ. of Tokushima, Tokushima, Japan","2011 Seventh International Conference on Natural Computation","20110919","2011","4","","1845","1849","In this paper, we propose a novel music retrieval method using a filter bank feature and earth mover's distance (EMD). In the proposed method, we use MFCCs for acoustic features and EMD for a distance measurement. Evaluation experimental results show that the accuracy of the proposed method achieves 96.73%.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022545","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022545","earth mover's distance;filter bank feature;music retrieval","Accuracy;Bit rate;Databases;Earth;Feature extraction;Filter banks;Fingerprint recognition","acoustic signal processing;audio signal processing;cepstral analysis;channel bank filters;information retrieval;music;probability","MFCC;acoustic features;distance measurement;earth mover distance;filter-bank feature;mel-frequency cepstral coefficients;music retrieval method","","0","","9","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Mining Fuzzy Domain Ontology Based on Concept Vector from Wikipedia Category Network","C. Y. Lu; S. W. Ho; J. M. Chung; F. Y. Hsu; H. M. Lee; J. M. Ho","Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","249","252","Ontology is essential in the formalization of domain knowledge for effective human-computer interactions (i.e., expert-finding). Many researchers have proposed approaches to measure the similarity between concepts by accessing fuzzy domain ontology. However, engineering of the construction of domain ontologies turns out to be labor intensive and tedious. In this paper, we propose an approach to mine domain concepts from Wikipedia Category Network, and to generate the fuzzy relation based on a concept vector extraction method to measure the relatedness between a single term and a concept. Our methodology can conceptualize domain knowledge by mining Wikipedia Category Network. An empirical experiment is conducted to evaluate the robustness by using TREC dataset. Experiment results show the constructed fuzzy domain ontology derived by proposed approach can discover robust fuzzy domain ontology with satisfactory accuracy in information retrieval tasks.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040852","Concept Vector;Domain Ontology;Expert-finding;Reviewer Classification;Wikipedia Mining","Electronic publishing;Encyclopedias;Internet;Ontologies;Semantics","data mining;human computer interaction;information retrieval;ontologies (artificial intelligence);search engines","TREC dataset;Wikipedia category network;concept vector extraction method;domain knowledge formalization;expert-finding;fuzzy domain ontology mining;fuzzy relation;human-computer interactions;information retrieval tasks;similarity measurement","","0","","4","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"On-demand feature recommendations derived from mining public product descriptions","H. Dumitru; M. Gibiec; N. Hariri; J. Cleland-Huang; B. Mobasher; C. Castro-Herrera; M. Mirakhorli","DePaul University, Chicago, IL, USA","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","181","190","We present a recommender system that models and recommends product features for a given domain. Our approach mines product descriptions from publicly available online specifications, utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain-specific features, generates a probabilistic feature model that represents commonalities, variants, and cross-category features, and then uses association rule mining and the k-Nearest-Neighbor machine learning strategy to generate product specific feature recommendations. Our recommender system supports the relatively labor-intensive task of domain analysis, potentially increasing opportunities for re-use, reducing time-to-market, and delivering more competitive software products. The approach is empirically validated against 20 different product categories using thousands of product descriptions mined from a repository of free software applications.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985819","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032457","clustering;domain analysis;recommender systems","Algorithm design and analysis;Association rules;Clustering algorithms;Feature extraction;Recommender systems;Software;Viruses (medical)","data mining;information retrieval;learning (artificial intelligence);probability;recommender systems","association rule mining;domain analysis;domain-specific feature;incremental diffusive clustering algorithm;k-nearest-neighbor machine learning;ondemand feature recommendation;online specification;probabilistic feature model;public product description mining;recommender system;text mining","","19","1","33","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"Study on the personalized retrieval model of BP neural network","S. Wang; K. Xu; J. Li","Sch. of Manage., Jilin Univ., Changchun, China","2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)","20110922","2011","","","1002","1005","In this paper, a new method of personalized retrieval based on algorithm of BP(Back Propagation) Neural Networks is establish to meet the growing demand for search. The method which can make search engines more intelligent and more personalized tries to provide the best search results.","","Electronic:978-1-61284-722-1; POD:978-1-61284-719-1","10.1109/MEC.2011.6025634","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025634","BP Neural Networks;Personalized Retrieval;User Profiles","Accuracy;Arrays;Biological neural networks;Databases;Educational institutions;Information services;Training","backpropagation;information retrieval;neural nets;search engines","BP neural network;backpropagation;personalized retrieval model;search engine","","0","","5","","","19-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Experiences with Complex User Profiles for Approximate P2P Community Matching","P. Dazzi; M. Mordacchini; F. Baglini","ISTI-CNR, Pisa, Italy","2011 IEEE 11th International Conference on Computer and Information Technology","20111010","2011","","","53","58","The problem of defining P2P overlays where peers characterized by similar interests are directly connected is currently an important research issue. We have recently proposed a two layer P2P architecture where the first layer exploits a gossip algorithm for the detection of communities of peers characterized by similar interests, while the second layer defines a DHT storing the profiles of the communities detected in the first layer. The DHT is exploited by peers joining the system to find out a community matching its interests. This paper investigates a DHT based approach supporting a similarity based search of user profiles. Our approach exploits Locality Sensitive Hashing to support the similarity indexing. The paper investigates several types of profiles to model user interests and evaluates the indexing mechanisms of the DHT with respect to the different types. Experimental evaluation has been conducted by considering a real data set.","","Electronic:978-0-7695-4388-8; POD:978-1-4577-0383-6","10.1109/CIT.2011.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6036591","distributed clustering;peer-to-peer;user profiles","Bandwidth;Communities;Indexing;Measurement;Peer to peer computing;Symmetric matrices","file organisation;indexing;information retrieval;peer-to-peer computing;user modelling","DHT;P2P overlays;approximate P2P community matching;community detection;distributed hash table;gossip algorithm;locality sensitive hashing;similarity indexing;two layer P2P architecture;user interest model;user profile","","1","2","13","","","Aug. 31 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"A solution based on intelligent software agents to improve the data searching in the contact centers","C. I. Popirlan","Fac. of Math. &amp; Comput. Sci., Univ. of Craiova, Craiova, Romania","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","2","","1","5","Many companies have been collecting customer-related data for years, this was normally for administration rather than customer management. In last year's contact centers become more complex in their function and organization so that the data searching become more formal to ensure consistency and efficiency. This paper suggests a multi-agent approach for distributed data searching in context of contact centers to advance and frame future discussion of this knowledge intensive environments. We prove the efficiency of data search using intelligent software agents for contact centers with distributed data bases, considering an adequate case study and presenting experimental results.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030262","JADE;contact center;data searching;intelligent agents;mobile agent;multi-agent system;software agent","Computer architecture;Context;Distributed databases;Mobile agents;Multiagent systems;Software agents","Java;call centres;customer relationship management;distributed databases;information retrieval;mobile agents;multi-agent systems","JADE;contact centers;customer-related data;distributed data searching;distributed databases;intelligent software agents;multiagent approach","","0","","16","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"A semantic journey to discover research and innovation opportunities in Europe","P. Furrer; C. Höllmüller; F. Kienzle; O. Küttel; N. Gamard; S. Gamard","Euresearch, Effingerstrasse 19, 3008 Bern, Switzerland","2011 17th International Conference on Concurrent Enterprising","20111010","2011","","","1","7","As the amount of information which becomes available to users grows, finding condensed sets of useful information becomes more difficult. The manual evaluation and discovery for content valuable to individual users needs thus grows in conjunction with the size of the dataset. Ideally, providing as condensed set of accurate information as possible results in a significant increase in user productivity and with decreased mental effort. While this concept of information foraging has been in the literature since the 1990's, its application to specific information domains has proven to be of a continual challenge. In this paper we examine the process of global matchmaking across the whole spectrum of activities between research development, innovation. As a concrete example, we investigate the European Research Area and introduce a three tiered search approach embedded in a tool called The Opportunity Finder, which increases the ease of finding matches in a user friendly and intuitive manner.","","Electronic:978-3-943024-05-0; POD:978-1-4577-0772-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041220","European Research Innovation;Information Foraging;Scientific and Technological Cooperation;Semantic Web","Companies;Context;Databases;Europe;Ice;Semantics;Technological innovation","information retrieval","European Research Area;content discovery;content evaluation;information foraging concept;innovation opportunity;research opportunity;the opportunity finder tool;user productivity","","0","","9","","","20-22 June 2011","","IEEE","IEEE Conference Publications"
"An Interactive Way to Acquire Internet Documents for Language Model Adaptation of Speech Recognition Systems","H. Zhang; X. Wang; Y. Qian; S. Lin","Inst. of Comput. Technol., Chinese Acad. of Sci., Beijing, China","2011 Third International Conference on Intelligent Human-Machine Systems and Cybernetics","20111010","2011","1","","97","100","In this paper, a new method for language model adaptation based on users' feedback in the field of speech recognition is described. Different from other methods, the proposed method conducts corpus collection and language model adaptation in an interactive way. The user can input a small quantity of texts to describe the topic or the basic idea of the speech and evaluate some of the obtained texts as ""good"" or ""useless"". The system can learn from the interaction information and acquire textual corpus which is more relevant to the topic of the speech. Experimental results show that for a given speech recognition system using this approach the recognition accuracy is increased by 7 percentage points compared to the same system using traditional adaptation method without interaction.","","Electronic:978-0-7695-4444-1; POD:978-1-4577-0676-9","10.1109/IHMSC.2011.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038155","corpus acquiring;feedback;language model adaptation;speech recognition;users","Accuracy;Adaptation models;Computational modeling;Indexes;Internet;Speech;Speech recognition","Internet;information retrieval;interactive systems;speech recognition;text analysis","Internet document acquisition;corpus collection;interactive way;language model adaptation;recognition accuracy;speech recognition systems;textual corpus;users feedback","","0","","11","","","26-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"The design and research of Literary retrieval system based on Lucene","W. Zhao","Dept. of Comput. Sci., Weinan Teachers Univ., Weinan, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","8","","4146","4148","A general search engine oriented to academic field only need to modify the vocabulary libraries in its field for adapting to the Varity of the application field. The search engine system based on Lucene building proposed in this paper consists of the seven modules in which index module and retrieval module are the core parts. In this paper, the overall structure is discussed, the index and retrieval modules are analyzed and the system efficiency is improved through specific index and retrieval technology.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6023963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023963","Lucene retrieval;search engine index","Computers;Data processing;Indexing;Libraries;Search engines","academic libraries;information retrieval;search engines;vocabulary","Lucene building;academic field;literary retrieval system;search engine;search engine system;specific index technology;vocabulary libraries","","0","","7","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"Question classification oriented Chinese Framenet feature selection","G. Yan; W. Wenjing","Dept. of Inf. Eng., Shanxi Univ., Taiyuan, China","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","222","225","For feature selection of the classification in Restricted-domain Question Answering System, Chinese Net framework full advantage of this Chinese characteristics in terms of semantic expression, this paper presents feature selection called strong class information words (SCIW). First, selecting five kinds of Chinese Framenet features, and using SCIW to select features. According to each category's classification precision of features, sorts them. Through the experiment of the combination of the features, we select the combination of features. It improved the accuracy of classification, reaching the feature reduction.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028622","Chinese framenet;feature selection;question classification","Accuracy;Computers;Educational institutions;Feature extraction;Iron;Semantics;Syntactics","classification;natural language processing;question answering (information retrieval);semantic Web","Chinese Net framework;Chinese characteristics;Chinese framenet features;SCIW;category classification precision;classification accuracy;feature reduction;question classification oriented Chinese framenet feature selection;restricted-domain question answering system;semantic expression;strong class information words","","0","","6","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Topic-special information extraction of online store","Z. Siting; Z. Ning; Y. Fan","Sch. of Inf. Sci. &amp; Technol., Xiamen Univ., Xiamen, China","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","1416","1420","Taobao is the most representative transaction platform in C2C industry in China. It was taken as an example. This paper designed the extracting flow of the online store information automatically, and realized the automatic online store information collection and its structured output by Python language.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028895","Python;information extraction;online store;regular expression;topic-special crawler","Crawlers;Data mining;Feature extraction;HTML;Indexes;Information filters","Internet;information retrieval;retail data processing","C2C industry;Python language;Taobao;information extraction;online store information;topic-special crawler","","0","","13","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"The MovieOracle - Content Based Movie Recommendations","J. Nessel; B. Cimpa","EdgeWorks Software Ltd. Ho Chi Minh City, Ho Chi Minh City, Vietnam","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","361","364","""What movies do you like?"" Everyone has had to answer this question at least once. And the answer is often given by means of examples: ""I like Star Wars."" Often an examples explains a lot more than trying to characterize movies by other means, like giving a category like ""Science Fiction"" or providing actor or director names. The Movie Oracle recommends movies by comparing examples provided by the user to movie contents, which the Movie-Oracle derives from the movie dialogues gathered from movie subtitle files, without using any human generated meta-data.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040879","content based prediction;inductive learning","Books;Humans;Internet;Motion pictures;Prediction algorithms;Prototypes;Servers","meta data;question answering (information retrieval);recommender systems","MovieOracle;Science Fiction;content based movie recommendation;human generated metadata;movie content;question answering","","1","","17","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"When You Doubt, Abstain: From Misclassification to Epoché in Automatic Text Categorisation","A. Locoro; D. Grignani; V. Mascardi","Comput. Sci. Dept., Univ. of Genova, Genova, Italy","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","209","212","This paper describes how natural language processing and ontologies are exploited for automatic text categorisation. The approach introduced is part of the MANENT system, an infrastructure for integrating, structuring and searching Digital Libraries. The procedure of structural information extraction, and of the automatic classification of the records according to natural language understanding and the WordNet Domains taxonomy is discussed. A comparison between two versions of the classification algorithm is conducted and the improvements of the new approach are articulated. In particular, using semantic connections between words refines the classification results while reducing misclassification to no classification.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040842","automatic text categorisation;natural language processing;semantic digital libraries;wordnet domains","Educational institutions;Frequency domain analysis;Humans;Libraries;Ontologies;Semantics;Tagging","classification;digital libraries;information retrieval;natural language processing;ontologies (artificial intelligence);text analysis","MANENT system;WordNet domain taxonomy;automatic text categorisation;digital libraries;natural language processing;natural language understanding;ontologies;record automatic classification;structural information extraction","","0","","9","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"User interest modeling by labeled LDA with topic features","W. Li; X. Wang; R. Hu; J. Tian","Center of Intelligent Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China","2011 IEEE International Conference on Cloud Computing and Intelligence Systems","20111013","2011","","","6","11","As well known, the user interest is carried in the user's web browsing history that can be mined out. This paper presents an innovative method to extract user's inter.ests from his/her web browsing history. We first apply an efficient algorithm to extract useful texts from the web pages in user's browsed URL sequence. We then proposed a Labeled Latent Dirichlet Allocation with Topic Feature (LLDA-TF) to mine user's interests from the texts. Unlike other works that need a lot of training data to train a model to adopt supervised information, we directly introduce the raw supervised information to the procedure of LLDA-TF. As shown in the experimental results, results given by LLDA-TF fit predefined categories well. Furthermore, LLDA-TF model can name the user interests by category words as well as a keyword list for each category.","2376-5933;23765933","Electronic:978-1-61284-204-2; POD:978-1-61284-203-5","10.1109/CCIS.2011.6045022","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6045022","Labeled Latent Dirichlet Allocation with topic Feature (LLDA-TF);browsing history;topic feature;topic model;user interest model","Data models;Encyclopedias;Feature extraction;Internet;Training;Web pages","Internet;human computer interaction;information retrieval;text analysis;unsupervised learning;user modelling","LLDA-TF model;Web browsing history;Web pages;innovative method;labeled LDA;latent Dirichlet allocation;text extraction;topic features;unsupervised model;user interest extraction;user interest modeling","","1","","8","","","15-17 Sept. 2011","","IEEE","IEEE Conference Publications"
"Data structuring and effective retrieval in the mining of web sequential characteristic","Z. Ou","Heilongjiang Univ., Harbin, China","Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology","20110919","2011","7","","3551","3554","The Web data mining based on sequential characteristics is a mining technology focusing on text data on Web pages and link structure and combing sequential characteristics on the basis of the mining of Web structure and Web contents. A huge number of data information is carried on Web, and it is increased at a geometric speed every day. As time goes by, the effectiveness of a great number of data is continuously reduced, and they even become completely useless. How to clean these useless data, find out hidden regular contents among a great number of data, and solve the quality problem of data application has become the research hotspot in the Web data mining technology at present. All the information objects on Web can be generally divided into two categories: Structured data and semi-structured data. Those that can be expressed in database structure are called structured data; those expressed in various forms with text as representative are called semi-structured data. The greatest feature of Web data is semi-structuring. Such kind of semi-structured data are relevant to time sequence, meanwhile, time effect of data is also related to time sequence. In the article, discussion is made about how to use the sequential characteristic in the course of Web data mining to carry out structural transfer of semi-structured data based on time effect of data, that is the structuring of Web data, and solve the problem about effectiveness in retrieval accordingly.","","DVD:978-1-61284-086-4; Electronic:978-1-61284-088-8; POD:978-1-61284-087-1","10.1109/EMEIT.2011.6023787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023787","B-Tree;Data time effect;Sequential characteristic;semi-structuring Web data","Data mining;Data models;Data warehouses;Databases;Educational institutions;Feature extraction;Web pages","Internet;data mining;data structures;information retrieval;text analysis","Web contents;Web data mining;Web pages;Web sequential characteristics mining;Web structure mining;data information;data retrieval;data structure;database structure;link structure;semistructured data;text data mining;time sequence","","0","","8","","","12-14 Aug. 2011","","IEEE","IEEE Conference Publications"
"Portfolio: finding relevant functions and their usage","C. McMillan; M. Grechanik; D. Poshyvanyk; Q. Xie; C. Fu","College of William &#x0026; Mary, Williamsburg, VA, USA","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","111","120","Different studies show that programmers are more interested in finding definitions of functions and their uses than variables, statements, or arbitrary code fragments [30, 29, 31]. Therefore, programmers require support in finding relevant functions and determining how those functions are used. Unfortunately, existing code search engines do not provide enough of this support to developers, thus reducing the effectiveness of code reuse. We provide this support to programmers in a code search system called Portfolio that retrieves and visualizes relevant functions and their usages. We have built Portfolio using a combination of models that address surfing behavior of programmer and sharing Related concepts among functions. We conducted an experiment with 49 professional programmers to compare Portfolio to Google Code Search and Koders using a standard methodology. The results show with strong statistical significance that users find more relevant functions with higher precision with Portfolio than with Google Code Search and Koders.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1985809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032450","code search;function call graph;pagerank;portfolio;ranking","Google;Navigation;Portfolios;Search engines;Storage area networks;Visualization","data visualisation;information retrieval;search engines;statistical analysis","Google code search;Koders;Portfolio code search system;Portfolio function;Portfolio usage;code reuse;code search engine;function retrieval;function visualization;statistical significance","","44","3","38","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"A Vertical Search Engine for Energy Conservation and Environmental Protection","C. Wang; L. Jin; N. Zhou","Sch. of Inf. Sci. & Eng., Northeastern Univ., Shenyang, China","2011 Fifth International Conference on Genetic and Evolutionary Computing","20111013","2011","","","307","310","For most of the current search engines, the difference of their returned results are only because of the different keywords, i.e. for the same keywords used for searching, the same results will be returned. In fact, different users may have different search purposes even if they use the same keywords. In this paper, we propose a vertical search engine in the domain of energy conservation and environmental protection. We construct the vertical search engine based on the special domain models and the user motivation models, so that the efficiency and accuracy rate of information retrieval can be improved. Experiments show that the returned results by the vertical search engine can better meet the requirements of the users.","","Electronic:978-0-7695-4449-6; POD:978-1-4577-0817-6","10.1109/ICGEC.2011.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042787","Search Engine;Specific Domain Model;User Motivation model;Vertical Search Engine","Accuracy;Computer architecture;Energy conservation;Google;Indexes;Search engines;Web pages","environmental science computing;information retrieval;search engines","energy conservation;environmental protection;information retrieval;special domain models;user motivation models;vertical search engine","","0","","5","","","Aug. 29 2011-Sept. 1 2011","","IEEE","IEEE Conference Publications"
"GeoSpatial-temporal analytics to gain insight from linked open data","M. Donovang-Kuhlisch; M. Small","IBM Deutschland GmbH, Gorch-Fock-Str. 4, 53229 Bonn, Germany","2011 17th International Conference on Concurrent Enterprising","20111010","2011","","","1","12","Collective endeavours, operating in an environment of efficient collaboration and informed decision making in a value network, bear the only effective way to meet the challenges and threats we face in this modern, interconnected world. Enhanced inter-agency and inter-company communication and collaboration has been defined as the capability to deliver information superiority when required to enable agile and informed decision making to underpin effects-based operations: delivering the right effect, at the right time, to achieve the outcome required. Challenges and threats in our modern world are global and multi-faceted requiring complex responses: governments and corporations buoyed by the realization that the interests of both are mutually engage, are pursuing joint corporate social responsibility to make life and business conduct safe and sustainable. One outcome is increasing openness: organisations increasingly publish data and knowledge in open formats and open spaces and (others) provide tools to gain insight from this open and accessible data. This case study summarizes the technological state-of-the-art and points the way how value networks can benefit from these digital society trends.","","Electronic:978-3-943024-05-0; POD:978-1-4577-0772-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041234","Corporate Social Responsibility;Linked Open Data;Smarter Planet;Visual Analytics","Cities and towns;Decision making;Europe;Government;Ice;Planets","data analysis;data visualisation;decision making;geographic information systems;government;information retrieval;organisational aspects;publishing","corporate social responsibility;data access;data publishing;decision making;digital society trend;geospatial temporal analytics;information superiority;intercompany communication;linked open data;multifaceted requiring complex response;underpin effects-based operation","","0","","12","","","20-22 June 2011","","IEEE","IEEE Conference Publications"
"Babouk: Focused Web Crawling for Corpus Compilation and Automatic Terminology Extraction","C. de Groc","Syllabs, Univ. Paris Sud, Paris, France","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","497","498","The use of the World Wide Web as a free source for large linguistic resources is a well-established idea. Such resources are keystones to domains such as lexicon-based categorization, information retrieval, machine translation and information extraction. In this paper, we present an industrial focused web crawler for the automatic compilation of specialized corpora from the web. This application, created within the framework of the TTC project, is used daily by several linguists to bootstrap large thematic corpora which are then used to automatically generate bilingual terminologies.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040719","focused crawling;resources bootstrapping;web-as-corpus","Computer networks;Crawlers;HTML;Pragmatics;Terminology;Upper bound;Web sites","Internet;feature extraction;information retrieval;language translation","Babouk;TTC project;Web crawling;World Wide Web;automatic compilation;automatic terminology extraction;corpus compilation;information extraction;information retrieval;lexicon-based categorization;linguistic resource;machine translation","","1","","6","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Adaptive VoIP Steganography for Information Hiding within Network Audio Streams","E. Xu; B. Liu; L. Xu; Z. Wei; B. Zhao; J. Su","Sch. of Comput. Sci., Nat. Univ. of Defense Technol., Changsha, China","2011 14th International Conference on Network-Based Information Systems","20111013","2011","","","612","617","With the rapid development of the Internet, steganography on Voice over IP (VoIP) has been attracted a lot of research efforts. To date, existing VoIP steganography research commonly focus on information hiding in the LSB bits of Network Audio Streams, yet, we found this approach may raise serious security threat, where the hidden information may be easily removed, detected and attacked. Towards this issue, in this paper, we propose AVIS, a novel Adaptive VoIP steganography approach to hide information within Network Audio Streams. AVIS consists of two parts, named VAMI and VADDI. VAMI works by dynamically select multiple bits based on the VoIP vector value, while VADDI dynamically changes embedding intervals to avoid detection and attacking. We also implemented AVIS and conducted extensive experiments in real systems. Experimental results demonstrate the effectiveness of our proposed AVIS scheme.","2157-0418;21570418","CD-ROM:978-0-7695-4458-8; CD-ROM:978-07695-4580-6; Electronic:978-0-7695-4458-8; POD:978-1-4577-0789-6","10.1109/NBiS.2011.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041962","Information Hiding;Internet;Steganography;VoIP","Audio systems;Bandwidth;Codecs;Humans;Internet;Receivers;Speech","Internet telephony;audio streaming;computer network security;information retrieval;steganography","AVIS;Internet;LSB bits;VADDI;VAMI;adaptive VoIP steganography;hidden information removal;information hiding;network audio streams;security threat;voice over IP","","4","","10","","","7-9 Sept. 2011","","IEEE","IEEE Conference Publications"
"Learning Room Enquiry System Based on Social Networking Service","J. Hu; T. Gou; W. Yu","Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China","2011 7th International Conference on Wireless Communications, Networking and Mobile Computing","20111010","2011","","","1","4","Most of universities put out classroom information on WEB convenient for students learning. Existing Learning Room Enquiry Systems simply extract such information from Teaching Affairs Office and publish it at Head End. Thus, they only have the single way to get classrooms not in use and can't dynamically provide exact information of available seats in them. This article introduces the state of the art of Social Networking Services for both domestic and overseas, analyzes the functional requirement of this system, and proposes its designs. The target system utilizes user-updating mode to effectively collect and integrate separated information, at the same time, to improve utilization rate of information and classroom resources. The target system also emphasizes user experience, thus designs best-choice algorithm on available seats, evaluation algorithm on user credibility, and algorithm on self-recognition of user credibility.","2161-9646;21619646","Electronic:978-1-4244-6252-0; POD:978-1-4244-6250-6","10.1109/wicom.2011.6040657","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040657","","Algorithm design and analysis;Buildings;Educational institutions;Facebook;Internet;Servers","Internet;computer aided instruction;educational institutions;electronic publishing;information retrieval;social networking (online);teaching","Web based learning;best-choice algorithm;classroom information;classroom resource;evaluation algorithm;information extraction;learning room enquiry system;self-recognition algorithm;social networking service;student learning;teaching affairs office;universities;user credibility;user-updating mode","","0","","5","","","23-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"A Fundamental Study on Harmony between Colors and Fragrances","M. Fukumoto; H. Kuroda; K. Nakamura","Fac. of Inf. Eng., Fukuoka Inst. of Technol., Fukuoka, Japan","2011 International Conference on Biometrics and Kansei Engineering","20110929","2011","","","118","123","Recent development of information technology enables us to use fragrance as media content. The additional use of fragrance to information of sight will achieve higher effects in Web browsing than ever. Referring to the previous studies, this study fundamentally investigated the relationship between color and fragrance. Ten subjects participated in two experiments. In the experiment 1, impressions and preference for each six color and each twelve fragrance were obtained. The experiment 2 investigated the harmony of color and fragrance based on the results of experiment 1. With correlation analysis, relationship between impression distance of color and fragrance and their harmony was investigated. Tendency of the impressions and preference for colors and fragrances were different. Especially, fragrance elicited larger variance in preference than that in color. Furthermore, some combination of color and fragrance elicited positive and negative harmony. However, through the correlation analysis, obvious relationship between the impression distance and the harmony was not observed.","","Electronic:978-0-7695-4512-7; POD:978-1-4577-1356-9","10.1109/ICBAKE.2011.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6031262","color;correlation;fragrance;harmony;impression","Color;Concrete;Correlation;Evolutionary computation;Image color analysis;Media;Web pages","Internet;information retrieval;online front-ends","Web browsing;color impression distance;correlation analysis;fragrance impression distance;information technology;media content","","0","","15","","","19-22 Sept. 2011","","IEEE","IEEE Conference Publications"
"Wrapper Generation for Overlapping Web Sources","M. Bronzi; V. Crescenzi; P. Merialdo; P. Papotti","Dipt. di Inf. ed Autom., Univ. degli Studi Roma Tre, Rome, Italy","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","32","35","Exploiting the huge amount of data available on the Web involves the generation of wrappers to extract data from web pages. We argue that existing approaches for web data extraction from data-intensive websites miss the opportunities related to the presence of redundant information on the Web. We propose an innovative approach that aims at pushing further the level of automation of existing wrapper generation systems by leveraging the redundancy of data on the Web. An experimental evaluation of the proposed solution shows a relevant improvement for the precision of the extracted data, without a significant loss in the recall.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040492","web data extraction;wrapper generation","Crawlers;Data mining;Feature extraction;Generators;HTML;Measurement;Redundancy","Web sites;data mining;information retrieval","Web data extraction;Web sources;data-intensive Websites;wrapper generation","","1","","8","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"ELIAS: An Efficient Storage Underlay for Mobile Peer-to-Peer Systems","K. Kim; T. Xu; Y. Cai","Dept. of Comput. Sci., Iowa State Univ., Ames, IA, USA","IEEE Transactions on Parallel and Distributed Systems","20110926","2011","22","11","1851","1861","Our physical environment is a natural storage where we can store and share information. For instance, a stop sign is a piece of information implanted in a particular location. In this paper, we propose a storage underlay platform called “ELIAS” (Every Location Is A Storage) for a mobile peer-to-peer system. ELIAS enables user applications to transparently save/retrieve data items to/from a location without concerning with low-level detailed implementation. The underlying platform chooses appropriate mobile nodes to store/retrieve data items. We discuss an efficient implementation of ELIAS, and present a detailed analytical model that is validated by simulation. Finally, we show results of sensitivity analysis on a variety of factors that impact the performance of ELIAS.","1045-9219;10459219","","10.1109/TPDS.2011.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5986637","Mobile peer-to-peer systems;service lookup;spatial messaging.;storage management","Analytical models;Data models;Indexes;Loading;Mobile communication;Mobile computing;Peer to peer computing","information retrieval;peer-to-peer computing","ELIAS;Every Location Is A Storage;data item retrieval;data item storage;efficient storage underlay;mobile nodes;mobile peer-to-peer systems;peer-to-peer system;physical environment;share information;storage information;storage underlay platform","","2","","35","","20110818","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"Making fault data and non-SCADA data accessible for predictive analysis in data historians","D. Toporek; A. Hutchings","Georgia Power, 1650 Mooregate Court, Marietta, GA 30062","2011 IEEE Power and Energy Society General Meeting","20111010","2011","","","1","4","Southern Company consists of four electric utilities; Alabama Power, Georgia Power, Gulf Power and Mississippi Power. In these four states, Southern Company has 120,000 square mile of service territory and approximately 3400 substations. Analyzing power system disturbances is a critically important task for any electrical utility, especially Southern Company. When a power system event occurs, such as an outage, Southern Company needs a clear picture of the root cause of the event in order to take the optimal corrective action. Appropriate responses to system events will allow the utility to improve grid reliability, safety, profitability and to increase customer satisfaction. Smart relays have been widely deployed by electrical utilities to protect the power system. Smart relays usually contain SCADA data, non-SCADA data (useful real-time data not collected by SCADA system) and fault files which capture detailed information about power system disturbance and assist utilities in determining the root cause of the disturbance. But often the valuable non-SCADA data and fault files are not collected, as they require costly time and labor expenses to manually retrieve this additional information from each relay. This collection is time consuming, and delays the utility's ability to respond quickly to system events. Collecting this information is further complicated by the many different relay vendors and product models. These differences include determining when a fault file is available, knowing how to collect this fault file from the device and deciphering the format of the fault file. As a result, Southern Company has sought a solution that not only centrally archives non-SCADA data, but also fault file data in a data historian. The solution provides archiving of non-SCADA data by directly interfacing with the data historian. Archiving of fault file data, however, requires secure automated collection of fault files from numerous smart relays into a centralized corpora- - tely-accessible location. Centrally storing these files in a common location provides for system-wide review of disturbance data. The centralized location contains event viewing tools for authenticated users to analyze the fault files. Additionally, the system extrapolates the key time series data from the fault files, performs calculations (for example; breaker analytics) and sends all data (extrapolated and calculated) to the data historian for further historical analysis. Historical analysis on both the fault data and non-SCADA data allows Southern Company to perform predictive maintenance, event analysis, load contingency studies, reliability improvement studies, substation transformer life studies, power quality studies and much more. Overall, Southern Company's expected results from this initiative are to better prioritize money, prioritize labor resources and improve system reliability. The paper outlines the process for automated fault file collection highlighting the importance and benefits that a company can receive by archiving both fault file data and non-SCADA data in a data historian.","1932-5517;19325517","Electronic:978-1-4577-1002-5; POD:978-1-4577-1000-1; USB:978-1-4577-1001-8","10.1109/PES.2011.6039731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6039731","","Companies;Maintenance engineering;Monitoring;Relays;Substations;Temperature sensors","SCADA systems;authorisation;customer satisfaction;data analysis;electrical maintenance;electrical safety;electricity supply industry;information retrieval;power grids;power supply quality;power system protection;profitability;relay protection;substation automation;time series;transformer substations","Alabama power utility;Georgia power utility;Gulf power utility;Mississippi power utility;SCADA data;Southern electric utility company;automated fault file collection;customer satisfaction;data historian;event analysis;fault data accessible;fault file data;grid reliability;grid safety;load contingency;nonSCADA data access;power quality;power system disturbances;power system protection;predictive data analysis;predictive maintenance;profitability;reliability improvement;smart relays;substation transformer life;supervisory control and data acquisition;time series data extrapolation;user authentication","","0","","1","","","24-29 July 2011","","IEEE","IEEE Conference Publications"
"A new approach for noisy iris database indexing based on color information","Q. Zhao","Dept. of Comput. Eng., Taiyuan Univ., Taiyuan, China","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","28","31","Iris indexing is one of the hot topics in the research on iris recognition. Effective indexing method will both reduce the computational complexity and enhance the matching accuracy of iris recognition systems. In this paper, a new noisy iris indexing approach based on iris color information is proposed. After color correction, this method utilizes normalized color components to index the noisy iris images. Hit rate and penetration rate are used to measure the indexing and retrieval performance of the proposed method. The effectiveness evaluation is performed based on the UBIRIS.v2 database, and the results are analyzed and discussed.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028577","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028577","Iris indexing;color correction;normalized color components","Image color analysis;Image segmentation;Indexing;Iris;Iris recognition;Noise measurement","computational complexity;database indexing;image colour analysis;image matching;information retrieval;iris recognition","color correction;computational complexity;hit rate;iris color information;iris recognition;matching accuracy;noisy iris database indexing;penetration rate","","1","","17","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Deep into web general vs vertical search engine design based on secure and QoS","Wang Da-quan; Wang Tian; Zhang Lin; Wu Ai-ping; Zhou Qi-li; Wu Xiao-kai","Computer College, Hangzhou Dianzi University, Zhejiang, 310018, China","Proceedings of 2011 Cross Strait Quad-Regional Radio Science and Wireless Technology Conference","20111010","2011","1","","847","851","Vertical search engines are targeted to specific areas of the network information of the coverage is relatively high, with a reliable technical and information resources and support, with clear targeting search effectively compensate for a comprehensive search engine on a specific topic areas of expertise and information coverage too low. Mainly by the vertical search engine focused crawler module, the index module, search module, user interface components such as 4, it is the first to use the module from the specified URL reptiles seed starts to crawl, to crawl down the web page content analysis, determine the required after the extraction of information for the structured data, and then the data on the structure of Chinese words segmentation and indexing, and generate an index database, and finally create web pages for users to query the module to search. Database storage is a prerequisite for building the search. Foreground is the search engine system with the user interface.","","Electronic:978-1-4244-9793-5; POD:978-1-4244-9792-8","10.1109/CSQRWC.2011.6037083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037083","Web;crawling;database;engine;index","Economics;HTML;Indexing;Information filters;Message systems","Internet;Web sites;indexing;information retrieval;natural language processing;quality of service;search engines","Chinese words segmentation;QoS;URL reptiles;Web general search engine design;Web page content analysis;Web pages;Web vertical search engine design;clear targeting search;crawler module;index database;indexing;information extraction;information resources;network information;search engine system;structured data;user interface","","0","","8","","","26-30 July 2011","","IEEE","IEEE Conference Publications"
"Model based building height retrieval from single SAR images","L. b. Jiang; Z. Wang; W. x. Yu","ATR Key Lab., Nat. Univ. of Defense Technol., Changsha, China","2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference","20110929","2011","1","","379","384","With the improvements of spaceborne and airborne SAR system resolution, the applications of radar remote sensing has been extended to building 3D geometric information retrieval and reconstruction from urban SAR images, which is the foundation of build-up areas reconstruction and urban analysis. This paper mainly focuses on the problem of building height estimation from a single high resolution (HR) SAR image of urban scenes. A model based method combined with image segmentation framework of building height estimation is proposed. This method optimizes a new likelihood measure between the projection image from 3D geometric model of the buildings and the observed image over the heights hypothesis space. With assumption of the parallelepiped shapes, the SAR building area is partitioned into several regions. The new likelihood criterion then measures both the inner homogeneity of partitioned regions as well as their inter heterogeneity to achieve robust height hypothesis test. The optimization is done by simulated annealing in order to avoid local optimum. The experimental results performed on simulated SAR image data set valid the proposed method.","","Electronic:978-1-4244-8625-0; POD:978-1-4244-8622-9","10.1109/ITAIC.2011.6030227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030227","HR SAR;building height retrieval;likelihood criterion;projection model;simulated annealing;urban","Buildings;Estimation;Geometry;Reflection;Simulated annealing;Solid modeling;Three dimensional displays","airborne radar;image reconstruction;image resolution;image retrieval;image segmentation;information retrieval;natural scenes;radar imaging;remote sensing by radar;simulated annealing;spaceborne radar;synthetic aperture radar","3D geometric information retrieval;SAR image;airborne;building height estimation;image reconstruction;image resolution;image retrieval;image segmentation;likelihood criterion;optimization;parallelepiped shapes;radar remote sensing;simulated annealing;spaceborne;urban scenes","","0","","14","","","20-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"DIGO: An Open Data Architecture for e-Government","A. L. Machado; J. M. Parente de Oliveira","Divisao de Ciencia da Computacao (IEC), Instituto Tecnologico de Aeronautica (ITA), Sao Jose dos Campos, Brazil","2011 IEEE 15th International Enterprise Distributed Object Computing Conference Workshops","20111010","2011","","","448","456","Currently most governing bodies publish their data on the World Wide Web (WWW). These data are available on e-Government Web Portals in unstructured formats using current Web languages, making them difficult to reuse and to generate new information. In this context, access to relevant, accurate public information, and possible reuse by other applications become increasingly complex. Open Government Data (OGD) means the publication of data in open raw formats (open data). There are tools to put open data on the WWW. However, this tools doesn't work with an architecture covering all aspects of data reuse. The aim of this paper is to show an architecture called Delivering Information of Government (DIGO) to allow access to primary data by machines in open data so that citizens interested in doing so can combine them (linked open data) and produce new information and mashup applications, consequently, enabling OGD and data fusion on the Linking Open Data (LOD) cloud.","2325-6583;23256583","Electronic:978-0-7695-4426-7; POD:978-1-4577-0869-5","10.1109/EDOCW.2011.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037649","e-Government;linked open data;ontologies;open data;open government data","Context;Data mining;Electronic government;Portals;Resource description framework;Semantics","Internet;cloud computing;data structures;government data processing;information retrieval;portals;sensor fusion","DIGO;Web languages;World Wide Web;data fusion;delivering information of government;e-government Web portals;linking open data cloud;open data architecture;open government data","","4","","24","","","Aug. 29 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"Utilizing Hubel Wiesel models for semantic associations and topics extraction from unstructured text","S. Tiwari; K. Ramanathan","Singapore MIT Alliance, Singapore","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","892","898","There is a desire to extract and make better use of unstructured textual information available on the web. Semantic cognition opens new avenues in the utilization of this information. In this research, we extended the Hubel Wiesel model of hierarchical visual representation to extract semantic information from text. The unstructured text was preprocessed to a suitable input for Hubel Wiesel model. The threshold at each layer for neuronal growth was chosen as a ramp function of the level. Probabilistic approach was used for all post processing steps like prediction, word association, labeling, gist extraction etc. Equivalence with the Topics model was used to arrive at conditional probabilities in our model. We validated our model on three datasets and the model generated reasonable semantic associations. We evaluated the model based on top level clustering, label generation and word association.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033316","Hubel Wiesel Model;Semantic Cognition;Text Mining;Topics and Semantic Association","Electronic publishing;Encyclopedias;Firing;Internet;Neurons;Semantics","Internet;cognition;data mining;information retrieval;pattern clustering;probability;text analysis","Hubel Wiesel model;Web;gist extraction;hierarchical visual representation;label generation;labeling;prediction;probabilistic approach;semantic association extraction;semantic cognition;semantic information extraction;semantic topic extraction;text mining;top level clustering;topics model;unstructured text;word association","","1","","19","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Personalized recommendation using implicit interaction information","L. Nancheng; Q. Jiang; H. Chen; B. Wang","Software Sch., Xiamen Univ., Xiamen, China","2011 6th International Conference on Computer Science & Education (ICCSE)","20110926","2011","","","1340","1345","Currently, the information in the internet is becoming explosive. In order to help the users searching the items they are interested in, such as, the news, the books, in this paper, we propose an automatic personalized recommendation algorithm by constructing the social graph resting on the users' implicit interaction information. We at first introduce a metric to measure the users' affinity based on their implicit interaction information to construct a social graph, and then categorize the users into different clusters within which they will have similar tastes, finally, we use a personalized recommendation algorithm to recommend the items shared in the same cluster to the users. The experiments on a book data set are performed to demonstrate that our proposed method can well generate the recommendations which users will be interested in with high accuracy and efficiency.","","Electronic:978-1-4244-9718-8; POD:978-1-4244-9717-1","10.1109/ICCSE.2011.6028881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6028881","implicit interaction information;personalized recommendation;social graph","Clustering algorithms;Educational institutions;Internet;Measurement;Recommender systems;Social network services","Internet;graph theory;information retrieval;personal information systems;recommender systems","Internet;book data set;implicit interaction information;personalized recommendation;social graph","","0","","16","","","3-5 Aug. 2011","","IEEE","IEEE Conference Publications"
"Unsupervised language model adaptation using n-gram weighting","M. A. Haidar; D. O'Shaughnessy","INRS-EMT, Montreal, QC, Canada","2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE)","20110929","2011","","","000857","000860","In this paper, we introduce the weighting of topic models in mixture language model adaptation using n-grams of the topic models. Topic clusters are formed by using a hard-clustering method assigning one topic to one document based on the maximum number of words chosen from a topic for that document in Latent Dirichlet Allocation (LDA) analysis. The n-grams of the topic generated by hard-clustering are used to compute the mixture weights of the component topic models. Instead of using all the words of the training vocabulary, selected words are used for LDA analysis, which are chosen by incorporating some information retrieval techniques. The proposed n-gram weighting approach shows significant reduction in perplexity and word error rate (WER) against a unigram weighting approach used in the literature.","0840-7789;08407789","Electronic:978-1-4244-9789-8; POD:978-1-4244-9788-1; USB:978-1-4244-9787-4","10.1109/CCECE.2011.6030578","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030578","Mixture models;language model adaptation;latent Dirichlet allocation;speech recognition","Adaptation models;Computational modeling;Mathematical model;Probabilistic logic;Semantics;Training;Vocabulary","information retrieval;pattern clustering;statistical analysis;text analysis;unsupervised learning","LDA analysis;component topic models;hard clustering method;information retrieval;latent Dirichlet allocation analysis;mixture language model adaptation;mixture weights;n-gram weighting approach;training vocabulary;unsupervised language model adaptation;word error rate","","4","","17","","","8-11 May 2011","","IEEE","IEEE Conference Publications"
"""Read"" More from Business Cards: Toward a Smart Social Contact Management System","B. Guo; D. Zhang; D. Yang","Telecom SudParis, Inst. Telecom, Evry, France","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","384","387","The ability to leverage the power of a network of social contacts is important to get things done. However, as the number of contacts increases, people often find it difficult to maintain their contact network by using merely memory, and are frequently encompassed with questions like ""who is that person, I met him in Tokyo last year"". Existing contact tools make up for the shortage of unreliable human memory by storing contact information in the digital format, but laying much burden on users on manually inputting contact data. This paper, however, presents a social contact management system called SCM, which supports the auto-collection of rich contact data by exploring the aggregated power of pervasive sensing and Web intelligence techniques. Regarding that people often need to leverage several associated things (e.g., meeting location) to fetch other information about a contact (e.g., his name), we also develop an associative contact retrieval method. The effectiveness and runtime performance of our system is validated through a set of experiments.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038700","HCI;Information Integration;Pervasive Computing;Social Contact Management;Web Intelligence","Business;Context;Data mining;Feature extraction;Humans;Sensors;Web pages","Internet;content management;information retrieval;social networking (online);ubiquitous computing","Web intelligence technique;associative contact retrieval method;business cards;contact information storage;contact tools;pervasive sensing technique;smart social contact management system","","2","","6","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Sailing the corpus sea: Visual exploration of news stories","I. Subašić; B. Berendt; D. Trümper","K.U. Leuven, Belgium","2011 IEEE 9th International Symposium on Intelligent Systems and Informatics","20111003","2011","","","447","452","Rich information spaces like blogs or news are full of “stories”: sets of statements that evolve over time, made in fast-growing streams of documents. Even if one reads a specific source every day and/or subscribes to a selection of feeds, one may easily lose track; in addition, it is difficult to reconstruct a story already in the past. In this paper, we present the STORIES methods and tool for (a) learning an abstracted story representation from a collection of time-indexed documents; (b) visualizing it in a way that encourages users to interact and explore in order to discover temporal “story stages” depending on their interests; (c) supporting the search for documents and facts that pertain to the user-constructed story stages; (d) discovering the most important facts in the corpora; and (e) navigating in document space along multiple meaningful dimensions of document similarity and relatedness. This combination provides users with more control, progressing from “surfing” the Web to “sailing” selected corpora of it, semantically in story space as well as between the underlying documents. An evaluation demonstrates that machine learning and interaction lead to representations that serve to retrieve coherent and relevant document subsets and that help users learn facts about the story.","1949-047X;1949047X","Electronic:978-1-4577-1974-5; POD:978-1-4577-1975-2","10.1109/SISY.2011.6034370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034370","","Google;Navigation;Semantics;Text mining;USA Councils;Visualization","Web sites;classification;data mining;data visualisation;information retrieval;learning (artificial intelligence);text analysis","STORIES method;abstracted story representation;blogs;document similarity;machine learning;news stories;story tracking;time-indexed document;visual exploration","","1","","15","","","8-10 Sept. 2011","","IEEE","IEEE Conference Publications"
"A detection method of FAQ matching inquiry e-mails by automatic generation of characteristic word groups on past inquiry e-mails","Y. Sakumichi; M. Akiyoshi; M. Samejima; H. Oka","Osaka University","2011 9th IEEE International Conference on Industrial Informatics","20111006","2011","","","53","56","This paper discusses how to detect the inquiry e-mails corresponding to pre-defined FAQs(Frequently Asked Questions). Web-based interaction such as orders and registration form on a web page is usually provided with its FAQ page for helping a user, however, most users submit their inquiry e-mails without checking such pages. Help desk operators must spend lots of time on replying to process lots of e-mails even if some contents match to FAQs, we propose the automatic detection method of such e-mails based on SVM (Support Vector Machine) and specific Jaccard coefficient with positive and negative instances. Experimental results show that the proposed method can improve the recall rate to 50% and the precision rate to 91%.","1935-4576;19354576","Electronic:978-1-4577-0434-5; POD:978-1-4577-0435-2; USB:978-1-4577-0433-8","10.1109/INDIN.2011.6034836","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034836","","Accuracy;Companies;Electronic mail;Feature extraction;Servers;Support vector machines;Web pages","Internet;Web sites;electronic mail;pattern matching;query processing;question answering (information retrieval);support vector machines","FAQ matching;Jaccard coefficient;Web page;Web-based interaction;automatic detection method;automatic generation;characteristic word group;help desk operator;inquiry e-mail;registration form;support vector machine","","0","","6","","","26-29 July 2011","","IEEE","IEEE Conference Publications"
"Supporting Search Result Browsing and Exploration via Cluster-Based Views and Zoom-Based Navigation","K. R´stocny; M. Tvarozek; M. Bielikov´","Inst. of Inf. & Software Eng., Slovak Univ. of Technol. in Bratislava, Bratislava, Slovakia","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","297","300","The difficulty of finding relevant information in the Web is increasing as web repositories grow in size. We propose a novel approach for navigation in the Semantic Web, which helps users find relevant information and enables them to browse similar and/or related resources. We achieve this via view-based search using navigation in a two-dimensional graph, which has the advantage of visualizing dependencies between results. We address problems with readability and understandability via adaptive views, result clustering, facet marking, next action recommendation and zoom-based navigation.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040864","Semantic Web;adaptive views;graph visualization;navigation;results clustering","Browsers;Conferences;Navigation;Prototypes;Resource description framework;Visualization","information retrieval;pattern clustering;semantic Web","Web repositories;adaptive views;cluster-based views;dependency visualization;facet marking;next action recommendation;result clustering;search result browsing;search result exploration;semantic Web navigation;two-dimensional graph;view-based search;zoom-based navigation","","3","","14","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Towards using prosody to scaffold lexical meaning in robots","J. Saunders; H. Lehmann; Y. Sato; C. L. Nehaniv","Adaptive Systems Research Group, School of Computer Science, University of Hertfordshire, Hatfield, UK, AL10 9AB","2011 IEEE International Conference on Development and Learning (ICDL)","20111010","2011","2","","1","7","We present a case-study analysing the prosodic contours and salient word markers of a small corpus of robot-directed speech where the human participants had been asked to talk to a socially interactive robot as if it were a child. We assess whether such contours and salience characteristics could be used to extract relevant information for the subsequent learning and scaffolding of meaning in robots. The study uses measures of pitch, energy and word duration from the participants speech and exploits Pierrehumbert and Hirschberg's theory of the meaning of intonational contours which may provide information on shared belief between speaker and listener. The results indicate that 1) participants use a high number of contours which provide new information markers to the robot, 2) that prosodic question contours reduce as the interactions proceed and 3) that pitch, energy and duration features can provide strong markers for relevant words and 4) there was little evidence that participants altered their prosodic contours in recognition of shared belief. A description and verification of our software which allows the semi-automatic marking of prosodic phrases is also described.","2161-9476;21619476","Electronic:978-1-61284-990-4; POD:978-1-61284-989-8","10.1109/DEVLRN.2011.6037328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037328","","Fires;Humans;Manuals;Robot sensing systems;Speech","control engineering computing;formal verification;humanoid robots;information retrieval;interactive systems;learning (artificial intelligence);natural language processing;speech processing","Hirschberg theory;Pierrehumbert theory;human participants;information extraction;intonational contours;learning;prosodic contours;robot-directed speech;salient word markers;scaffold lexical meaning;scaffolding;semi-automatic marking;socially interactive robot;software verification","","3","","34","","","24-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Study of Optimizing the Merging Results of Multiple Resource Retrieval Systems by a Particle Swarm Algorithm","X. Xie; G. Zhang","Dept. of Autom., Univ. of Sci. & Technol. of China, Hefei, China","2011 Third International Conference on Intelligent Human-Machine Systems and Cybernetics","20111010","2011","2","","39","42","The result merging for multiple independent resource retrieval systems (IRRSs), which is a key component in developing the metasearch engine, is a difficult problem that still not effectively solved in distributed information retrieving areas. After investigating a variety of existing result merging algorithms for combination multiple IRRS results, we proposed a Discrete Particle Swarm Algorithm (DPSA) that is able to further coalesce and optimize a group of merging results produced by other existing result merging algorithms. The experimental results show that: the DPSA, not only can overall outperform all the other result merging algorithms it employed, but also has better adaptability in application for unnecessarily taking into account the usefulness weights of IRRS results and the overlap rate among different IRRS results with respect to concrete query.","","Electronic:978-0-7695-4444-1; POD:978-1-4577-0676-9","10.1109/IHMSC.2011.80","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6038210","DPSA;IRRS;Metasearch engine;Result merging","Algorithm design and analysis;Bayesian methods;Engines;Merging;Metasearch;Particle swarm optimization;Silicon","information retrieval;merging;particle swarm optimisation;search engines","discrete particle swarm algorithm;distributed information retrieving area;independent resource retrieval system;merging result optimization;metasearch engine;multiple resource retrieval systems","","0","","11","","","26-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"A Large Scale Domains Resolving System","X. Liu","Sch. of Software Eng., Huazhong Univ. of Sci. & Technol., Wuhan, China","2011 7th International Conference on Wireless Communications, Networking and Mobile Computing","20111010","2011","","","1","4","Efficient domain resolving is essential for large scale Web crawl. Based on batch processing and caching, data structures and algorithms are presented for maintaining domains and addresses in crawling, and their performances are analyzed mathematically. Large scale domain resolving system is designed with proposed data structure. The theoretical analysis and experiments show that the speed of several thousand links per second for billions of links or hundreds of millions hosts can be achieved on one common personal computer.","2161-9646;21619646","Electronic:978-1-4244-6252-0; POD:978-1-4244-6250-6","10.1109/wicom.2011.6040466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040466","","Algorithm design and analysis;Crawlers;Data structures;Maintenance engineering;Merging;Random access memory;Web sites","information retrieval;mathematical analysis","Web crawl;data structures;large scale domain resolving system;mathematical analysis;personal computer","","0","","8","","","23-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"Provenance Based Retrieval: File Retrieval System Using History of Moving and Editing in User Experience","K. Yamamoto; T. Kuriyama; H. Shigemori; I. Kuramoto; Y. Tsujino; M. Minakuchi","Grad. Sch. of Sci. & Technol., Kyoto Inst. of Technol., Kyoto, Japan","2011 IEEE 35th Annual Computer Software and Applications Conference","20111003","2011","","","618","625","Most of traditional retrieval keys are the place (folder), name and content of desired files. If a user does not remember these keys, it is difficult for him or her to access desired files. In order to solve this problem, we propose a file retrieval system that is based on provenance. In this paper, provenance means the history of the file's moving and editing that a user has experienced. By recording how and from where a user gets the file, the system enables the user to query, for example, ""which files did I get from my teacher yesterday?"", ""which files did I download from the web page of my college last month?"", and ""which files did I edit by MS Word last week?"" We present a model of provenance and describe how to use provenance as the keys of retrieval and how the system is constructed.","0730-3157;07303157","Electronic:978-0-7695-4439-7; POD:978-1-4577-0544-1","10.1109/COMPSAC.2011.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032408","Provenance;Retrieval models;User experience;User-centered design","Data mining;Educational institutions;Electronic mail;Error analysis;History;Media;Postal services","file organisation;information retrieval","MS Word;file retrieval system;provenance based retrieval;user experience","","0","","13","","","18-22 July 2011","","IEEE","IEEE Conference Publications"
"Informative Polythetic Hierarchical Ephemeral Clustering","G. Dias; G. Cleuziou; D. Machado","HULTIG, Univ. of Beira Interior, Covilha, Portugal","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","104","111","Ephemeral clustering has been studied for more than a decade, although with low user acceptance. According to us, this situation is mainly due to (1) an excessive number of generated clusters, which makes browsing difficult and (2) low quality labeling, which introduces imprecision within the search process. In this paper, our motivation is twofold. First, we propose to reduce the number of clusters of Web page results, but keeping all different query meanings. For that purpose, we propose a new polythetic methodology based on an informative similarity measure, the InfoSimba, and a new hierarchical clustering algorithm, the HISGK-means. Second, a theoretical background is proposed to define meaningful cluster labels embedded in the definition of the HISGK-means algorithm, which may elect as best label, words outside the given cluster. To confirm our intuitions, we propose a new evaluation framework, which shows that we are able to extract most of the important query meanings but generating much less clusters than state-of-the-art systems.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040505","Automatic Cluster and Label Evaluation;Hierarchical Ephemeral Clustering;Informative Similarity Measure;Polythetic Web Snippet Representation","Clustering algorithms;Context;Convergence;Equations;Partitioning algorithms;Taxonomy;Web pages","information retrieval;pattern clustering","HISGK-means algorithm;InfoSimba;Web page results;cluster number reduction;evaluation framework;informative polythetic hierarchical ephemeral clustering;informative similarity measure;query meanings","","0","","21","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Approximate Aggregations in Structured P2P Networks","D. Sun; S. Wu; S. Jiang; J. Li","Harbin Institute of Technology, Harbin","IEEE Transactions on Knowledge and Data Engineering","20110922","2011","23","11","1748","1752","In corporate networks, daily business data are generated in gigabytes or even terabytes. It is costly to process aggregate queries in those systems. In this paper, we propose PACA, a probably approximately correct aggregate query processing scheme, for answering aggregate queries in structured Peer-to-Peer (P2P) network. PACA retrieves random samples from peers' databases and applies the samples to process queries. Instead of scanning the entire database of each peer, PACA only accesses a small random number of data. Moreover, based on the query distribution,PACA publishes a precomputed synopsis and uses the synopsis to answer future queries. Most queries are expected to be answered by the precomputed synopsis partially or fully. And the synopsis is adaptively tuned to follow the query distribution. Experiments on the PlanetLab show the effectiveness of the approach.","1041-4347;10414347","","10.1109/TKDE.2010.198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601726","BATON;Peer-to-Peer;approximate query processing.","Aggregates;Estimation;Indexes;Peer to peer computing;Query processing;Servers","business data processing;distributed databases;peer-to-peer computing;query processing;question answering (information retrieval)","P2P network;PACA;PlanetLab;aggregate query answering;business data;corporate networks;peer database;probably approximately correct aggregate query processing;query distribution;sample retrieval;structured peer-to-peer network","","1","","14","","20101014","Nov. 2011","","IEEE","IEEE Journals & Magazines"
"On designing and realization of professional teaching evaluation system based on Internet of Things","H. Haiyan; S. Chang","Dept. of Inf. Eng., Jilin Bus. &amp; Technol. Coll., Changchun, China","2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)","20110922","2011","","","872","875","Based on the initial achievements made in Internet of Things, the hierarchical model of learning assessment will be constructed, applying both quantitative and non-quantitative evaluation standards, extracting key information that influences learning efficiency through data mining technique, formulating the weight of evaluation standards through analytic hierarchy process, diminishing the anthropogenic factors, so that a comprehensive, integrated and objective evaluation result of students' learning can be concluded by way of analytic hierarchy process.","","Electronic:978-1-61284-722-1; POD:978-1-61284-719-1","10.1109/MEC.2011.6025602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025602","Analytic Hierarchy Process;Data Mining;Internet of Things;Teaching Evaluation;Weighted Average Method","Data mining;Education;Indexes;Inspection;Internet;Radiofrequency identification;Testing","Internet;computer aided instruction;data mining;decision making;educational administrative data processing;information retrieval;teaching","Internet of things;analytic hierarchy process;anthropogenic factors;data mining technique;evaluation standards;key information extraction;learning assessment;learning efficiency;professional teaching evaluation system","","0","","4","","","19-22 Aug. 2011","","IEEE","IEEE Conference Publications"
"Measuring Comprehensibility of Web Pages Based on Link Analysis","K. Akamatsu; N. Pattanasri; A. Jatowt; K. Tanaka","Dept. of Social Inf., Kyoto Univ., Kyoto, Japan","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","1","","40","46","We put forward a hypothesis that if there is a link from one page to another, it is likely that comprehensibility of the two pages is similar. To investigate whether this hypothesis is true or not, we conduct experiments using existing readability measures. We investigate the relationship between links and readability of text extracted from web pages for two datasets, set of English and Japanese pages. We could find that links and readability of text extracted from web pages are correlated. Based on the hypothesis, we propose a link analysis algorithm to measure comprehensibility of web pages. Our method is based on the Trust Rank algorithm which is originally used for combating web spam. We use link structure to propagate readability scores from source pages selected based on their comprehensibility. The results of experimental evaluation demonstrate that our method could improve estimation of comprehensibility of pages.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040494","comprehensibility;link analysis;readability","Algorithm design and analysis;Complexity theory;Educational institutions;Search engines;Vocabulary;Web pages;Web search","Web services;information retrieval;search engines;text analysis;unsolicited e-mail","English;Japanese pages;TrustRank algorithm;Web pages;Web spam;comprehensibility;extracted text readability;link analysis","","1","","14","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Merging and Re-ranking Answers from Distributed Multiple Web Sources","H. J. Oh; J. Hur; C. H. Lee; P. M. Ryu; Y. C. Yoon; H. Kim","Knowledge Min. Res. Team, Electron. & Telecommun. Res. Inst. (ETRI), Daejeon, South Korea","2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","20111010","2011","3","","143","146","Depending on questions, various answering methods and answer sources can be used. In this paper, we build a distributed QA system to handle different types of questions and web sources. When a user question is entered, the broker distributes the question over multiple sub-QAs according to question types. The selected sub-QAs find local optimal candidate answers, and then they are collected in to the answer manager. The merged candidates are re-ranked by adjusting confidence weights based on the question analysis result. The re-ranking algorithm aims to find global optimal answers. We borrow the concept from the margin and slack variables in SVM, and modify to project confidence weights into the same boundary by training. Several experimental results prove reliability of our proposed QA model.","","Electronic:978-0-7695-4513-4; POD:978-1-4577-1373-6","10.1109/WI-IAT.2011.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6040826","Answer Selection;Question Answering;Re-ranking","Blogs;Classification algorithms;Encyclopedias;Games;Internet;Support vector machines;Training","distributed processing;question answering (information retrieval);support vector machines","SVM;answer merging;answer reranking algorithm;answer sources;answering methods;confidence weight adjustment;distributed QA system;distributed multiple Web sources;local optimal candidate answers;subQA","","0","","13","","","22-27 Aug. 2011","","IEEE","IEEE Conference Publications"
"Tracing architecturally significant requirements: a decision-centric approach","M. Mirakhorli","DePaul University, Chicago, IL, USA","2011 33rd International Conference on Software Engineering (ICSE)","20111010","2011","","","1126","1127","This thesis describes a Decision-Centric traceability framework that supports software engineering activities such as architectural preservation, impact analysis, and visualization of design intent. We present a set of traceability patterns, derived from studying real-world architectural designs in high-assurance and high-performance systems. We further present a trace-retrieval approach that reverse engineers design decisions and their associated traceability links by training a classifier to recognize fragments of design decisions and then using the traceability patterns to reconstitute the decisions from their individual parts.","0270-5257;02705257","Electronic:978-1-4503-0445-0; POD:978-1-4503-0445-0","10.1145/1985793.1986014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6032607","architectural preservation;architecturally significant requirements;design rationale;software traceability","Discrete cosine transforms;Software architecture;Software reliability;Software systems","information retrieval;software architecture","architectural preservation;architecturally significant requirements;decision-centric traceability framework;design intent;high-assurance systems;high-performance systems;impact analysis;real-world architectural designs;software engineering activities;trace-retrieval approach;traceability links","","2","","8","","","21-28 May 2011","","IEEE","IEEE Conference Publications"
"Development Prior-art Data Search (PDS) system","K. S. Chari; R. Bansal","Semicond. IC Layout Design Registry, Gov. of India, New Delhi, India","2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies","20110922","2011","","","806","811","In research and development works, prior-art, that is the present knowledge in the field plays a crucial role in taking various decisions and approaches in handling the problem on hand; and this is especially of value in allowing or disallowing claims on intellectual property creations by the authors and permitting their registrations in respective countries or globally. Since the prior-art information are reported in various sources and is usually a huge data spread in various formats and forms, physically accessing the data and making determinations on deciding on eligibility of submitted works for awarding Intellectual Property (IP) certification by concerned IP offices and utilization of developments made ( at users and industries) becomes very cumbersome, time consuming and could in some cases nearly difficult to achieve with reliable picture on status of prior-art, the new works generated and the differentiators in these. Such scenarios arise in cases of Patent and Integrated Circuit (IC) Layout Design (LD) filings, deciding and fighting infringements/piracy and catching the violators etc. The disadvantages cited in lack of coherent data as a one stop source make it imperative for developing tools and technologies at the places of IP offices and creators of IP works that can substantially aid in evaluating the various development works submitted and also on utilization of the knowledge generated, the matters of protection of created works, possible commercialization and other steps etc.","","Electronic:978-1-61284-653-8; POD:978-1-61284-654-5","10.1109/ICSCCN.2011.6024661","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6024661","GUI;IC LD;IP;PDS;SQL Backend;application setting prior-art data and search","Databases;Graphical user interfaces;Handheld computers;IP networks;Integrated circuits;Layout;Servers","client-server systems;information retrieval;integrated circuit layout;patents","IP offices;client-server based prior-art data search system;integrated circuit layout design filings;intellectual property certification;patents;semiconductor integrated circuits layout design registry","","0","","6","","","21-22 July 2011","","IEEE","IEEE Conference Publications"
"Application Research of Aerobics Internet Course among University Student","Y. X. Jun; J. H. Gang","Sports Sect. Acad., Harbin Normal Univ., Harbin, China","2011 International Conference on Future Computer Science and Education","20111013","2011","","","266","269","This paper aims to analysis the application effect of the internet courses of aerobics for the universities students through information retrieval, mathematical statistics, survey method and experimental method, and the writer designed and developed the internet courses of aerobics for the universities students.","","Electronic:978-0-7695-4533-2; POD:978-1-4577-1562-4","10.1109/ICFCSE.2011.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6041712","aerobics;implementation;the internet courses","Databases;Educational institutions;Internet;Interviews;Multimedia communication;Navigation","Internet;computer aided instruction;educational courses;information retrieval;social sciences computing","aerobics Internet course;experimental method;information retrieval;mathematical statistics;survey method;university student","","0","","8","","","20-21 Aug. 2011","","IEEE","IEEE Conference Publications"
"Image-based vehicle indexing for a seaport transportation surveillance system","D. A. Sadlier; P. Ferguson; C. Ó. Conaire; N. E. O'Connor; K. Doyle","Centre for Sensor Web Technol., Dublin City Univ., Dublin, Ireland","2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","20110926","2011","","","367","372","In this paper we describe and evaluate two methods underpinning a surveillance-based content management system, designed for monitoring and profiling freight-based vehicular traffic in a seaport environment. The `InSPeCT' system captures video footage of passing vehicles, and uses tailored optical character recognition (OCR) to index the footage according to vehicle license-plates and freight codes. The system provides advanced search techniques for the efficient retrieval of records, where each captured vehicle is profiled according to captured imagery and its associated interpretations. Underpinning this system is a method for detecting the boundaries of individual transits within sustained traffic flow. Considering it desirable to extend the indexing functionality of the system beyond OCR, a colour-based vehicle indexing approach is proposed and evaluated. All evaluations take place in the context of a system deployed in a busy national seaport.","","Electronic:978-1-4577-0845-9; POD:978-1-4577-0844-2; USB:978-1-4577-0843-5","10.1109/AVSS.2011.6027352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6027352","","Accuracy;Cameras;Image color analysis;Indexing;Optical character recognition software;Support vector machines;Vehicles","content management;indexing;information retrieval;marine engineering;marine systems;optical character recognition;video surveillance","InSPeCT system;OCR;freight based vehicular traffic monitoring;freight based vehicular traffic profiling;freight codes;image based vehicle indexing;optical character recognition;record retrieval;seaport transportation surveillance system;surveillance based content management system;vehicle license plates;video footage","","0","","15","","","Aug. 30 2011-Sept. 2 2011","","IEEE","IEEE Conference Publications"
"Melody retrieval by self-organizing map with refractoriness which has robustness for fluctuation of key input","A. Cho; Y. Osana","School of Computer Sciences, Tokyo University of Technology, 1404-1 Katakura Hachioji, Japan","The 2011 International Joint Conference on Neural Networks","20111003","2011","","","1300","1307","In this research, we propose a melody retrieval system by self-organizing map with refractoriness which has robustness for fluctuation of key input. In the self-organizing map with refractoriness, the plural neurons in the Map Layer corresponding to the input can fire sequentially because of the refractoriness. The proposed melody retrieval system using the self-organizing map with refractoriness makes use of this property in order to retrieve plural similar melodies. In this melody retrieval system, as the melody features, rhythm, tone and keyword (genre of music) are employed. We carried out a series of computer experiments and confirmed that the effectiveness of the proposed system even when the key input includes fluctuation.","2161-4393;21614393","Electronic:978-1-4244-9637-2; POD:978-1-4244-9635-8","10.1109/IJCNN.2011.6033374","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033374","","Neurons;Robustness","information retrieval systems;music;self-organising feature maps","key input fluctuation;keyword;map layer;melody features;melody retrieval system;music genre;plural neurons;refractoriness;rhythm;selforganizing map;tone","","0","","7","","","July 31 2011-Aug. 5 2011","","IEEE","IEEE Conference Publications"
"Structure analysis of Chinese Peking Opera","Z. Zhang; X. Wang","Dept. of Comput. Sci., East China Normal Univ., Shanghai, China","2011 Seventh International Conference on Natural Computation","20110919","2011","1","","237","241","Automatic processing of Chinese Peking Opera becomes more important than ever before. This paper presents a multistage system for structure analysis of Chinese Peking Opera. Taking advantage of opera theory, all procedures fits human's usual practice appropriately. Especially, a clustering technique is employed for collecting all concrete timbre types. The bottom-top strategy is also presented to reconstruct the structure which discriminates components of Peking Opera. Firstly timbre information sequence is obtained using Viterbi algorithm. There will be coherences or abrupt changes in this sequence generally. Then we gather component information of opera via Forward algorithm in a series of well-trained HMM. Finally, another Viterbi algorithm revised by greedy theory is applied to eliminate petty slices that smoothes the sequence and gets rid of possible errors. The proposed system has been tested on various Peking Opera recordings. These results are shown to demonstrate the performance of this system.","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022090","HMM;Hierarchical;Peking Opera;Structure Analysis;Viterbi","Feature extraction;Hidden Markov models;Mel frequency cepstral coefficient;Probability distribution;Timbre;Viterbi algorithm","audio signal processing;greedy algorithms;hidden Markov models;information retrieval;maximum likelihood estimation;music;pattern clustering","Chinese Peking Opera;Viterbi algorithm;clustering technique;forward algorithm;greedy theory;hidden Markov model;information retrieval;multistage system;structure analysis;timbre information sequence;well-trained HMM","","1","","12","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
"Automatic singer identification based on auditory features","W. Cai; Q. Li; X. Guan","Sch. of Electron. &amp; Inf. Eng., Tianjin Univ., Tianjin, China","2011 Seventh International Conference on Natural Computation","20110919","2011","3","","1624","1628","The paper describes a method of identifying singers' voice from the monophonic music including sounds of various musical instruments based on auditory features. In this system, there are four problems to solve, vocal segment detection, feature extraction, modeling of the singing voice and identification. For a song to be identified, the vocal/nonvocal segment is detected via a new classifier - Sparse Representation-based Classification (SRC). The feature extraction is of the most importance. Human ear can distinguish among different types of sounds, so auditory features to describe the singer's voice are important. To describe the auditory features, we calculate features of each frame including Mel-frequency Cepstral Coefficient (MFCC), Liner Prediction Mel-frequency Cepstral Coefficient (LPMCC) and Gammatone Cepstral Coefficient (GTCC). Finally, we introduce the Gaussian Mixture Model (GMM) to model the singers' voice. This system is demonstrated to improve the performance of an automatic singer identification system in Music Information Retrieval (MIR).","2157-9555;21579555","Electronic:978-1-4244-9953-3; POD:978-1-4244-9950-2","10.1109/ICNC.2011.6022500","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022500","GMM;Gammatone Cepstrum Coefficient;SRC;auditory feature;singer identification;singing voice detection","Feature extraction;Filter banks;Humans;Low pass filters;Mel frequency cepstral coefficient","Gaussian processes;cepstral analysis;feature extraction;information retrieval;musical instruments;signal classification;speaker recognition","GMM;Gaussian mixture model;LPMCC;MFCC;auditory feature extraction;automatic singer identification;human ear;liner prediction Mel-frequency cepstral coefficient;monophonic music;music information retrieval;musical instruments;nonvocal segment detection;singer voice identification;singing voice modeling;sparse representation-based classification;vocal segment detection","","2","","28","","","26-28 July 2011","","IEEE","IEEE Conference Publications"
