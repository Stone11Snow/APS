"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5459655,5462196,5460725,5461576,5459905,5459359,5459467,5461643,5458859,5462355,5461799,5459466,5459368,5461512,5458619,5461819,5460024,5461304,5460586,5462438,5461774,5459428,5459132,5459447,5459813,5458784,5460567,5462386,5457528,5457346,5457724,5457663,5457691,5457682,5455699,5454599,5455289,5455626,5455721,5454518,5454708,5455519,5454885,5454846,5454917,5455236,5454639,5455305,5454707,5455618,5454139,5455338,5455566,5455670,5454972,5455568,5454105,5455680,5452700,5452706,5452524,5452727,5452498,5452730,5452546,5452519,5452770,5452538,5453468,5452772,5452634,5452451,5453695,5453473,5452733,5452771,5453471,5453813,5452618,5452697,5453502,5452758,5452548,5453828,5453273,5452563,5452454,5451344,5451952,5451965,5452008,5451204,5451718,5451940,5451390,5452084,5451664,5451992,5451751,5451529",2017/05/04 20:52:46
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Towards a Research Agenda for Recommendation Systems in Requirements Engineering","W. Maalej; A. K. Thurimella","Tech. Univ. Munchen, Munich, Germany","2009 Second International Workshop on Managing Requirements Knowledge","20100503","2009","","","32","39","To push the right information to the right person at the right time, classical work on recommendation systems focuses on optimizing the rating of recommended items. Recent research on context-awareness and knowledge exchange shows potentials of recommendation systems in engineering work. Requirements engineering can also profit from recommendation systems in several scenarios, including maintaining requirements, sharing collaboration information and reusing templates. By describing these scenarios and identifying key realization challenges, this paper presents a vision on recommendation systems in requirements engineering.","","Electronic:978-0-7695-4099-3; POD:978-1-4244-7694-7","10.1109/MARK.2009.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457346","","Automotive engineering;Collaboration;Collaborative work;Design engineering;Explosions;Information retrieval;Knowledge engineering;Machine vision;Maintenance engineering;Systems engineering and theory","formal specification;formal verification;recommender systems;research and development;systems analysis","collaboration information;context-awareness;knowledge exchange;recommendation systems;requirements engineering;research agenda;template reuse","","7","","28","","","1-1 Sept. 2009","","IEEE","IEEE Conference Publications"
"Summarizing ontology-based schemas in PDMS","C. E. Pires; P. Sousa; Z. Kedad; A. C. Salgado","Computer Science Department, Federal University of Campina Grande (UFCG) Av. Apr&#237;gio Veloso, 882, Bodocong&#243; - 58109-970 - Campina Grande - PB - Brazil","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","239","244","Quickly understanding the content of a data source is very useful in several contexts. In a Peer Data Management System (PDMS), peers can be semantically clustered, each cluster being represented by a schema obtained by merging the local schemas of the peers in this cluster. In this paper, we present a process for summarizing schemas of peers participating in a PDMS. We assume that all the schemas are represented by ontologies and we propose a summarization algorithm which produces a summary containing the maximum number of relevant concepts and the minimum number of non-relevant concepts of the initial ontology. The relevance of a concept is determined using the notions of centrality and frequency. Since several possible candidate summaries can be identified during the summarization process, classical Information Retrieval metrics are employed to determine the best summary.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452706","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452706","","Clustering algorithms;Computer science;Content management;Databases;Frequency;Informatics;Information retrieval;Large scale integration;Merging;Ontologies","database management systems;information retrieval;ontologies (artificial intelligence)","centrality notion;frequency notion;information retrieval metrics;ontology-based schemas;peer data management system;summarization algorithm","","1","","17","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Three Dimension Wind Retrieval of Single-Doppler Radar Data with Improved VVP Method","M. Wei; N. Li","Key Lab. of Meteorol. Disaster of Minist. of Educ., Nanjing Univ. of Inf. Sci. &Technol., Nanjing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","5276","5278","Theoretically, three dimension (3D) wind field and the other kinematical parameters could be retrieved by the volume velocity processing (VVP) method using single-Doppler weather radar volume data. However, ever since the theory was brought forward, it has never been fully and truly applied to practice due to the large vertical speed error. This research has found that the ill coefficient matrix of the linear equations is the key obstacle in retrieving the vertical speed field and other parameters. Based on the numerical analysis theory, the feasible algorithm has also been studied as an attempt to solve the ill matrix problem in linear equations. Numerical experiments have also been conducted with single-Doppler radar data, and the retrieval results are verified with dual-Doppler radar data observed in HUBEX_IOP. The research results show that the better retrieval of three dimension wind field can be obtained with the improved VVP method. Especially, the retrieval of vertical speed is obviously much better than that of the previous studies, and consistent with the real vertical wind speed of severe weather.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455236","","Data engineering;Doppler radar;Equations;Information retrieval;Information science;Meteorological radar;Numerical analysis;Radar measurements;Radar remote sensing;Wind speed","Doppler radar;atmospheric techniques;numerical analysis;wind","HUBEX_IOP;VVP method;dual-Doppler radar data;ill coefficient matrix;linear equations;numerical analysis theory;single-Doppler weather radar volume data;three dimension wind field;three dimension wind retrieval;vertical speed error;vertical speed field;volume velocity processing method","","0","","7","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Practical Approach to Modeling and Extracting Information from Semantic Web Based on Microformats","J. G. Ramos; R. A. Sol√≠s; H. Oceguera; J. Silva","Dept. de Sist. y Comput., Inst. Tecnol. de La Piedad, La Piedad, Mexico","2009 Mexican International Conference on Computer Science","20100422","2009","","","65","74","The lowercase semantic web consists of web pages enriched with semantic special tags which are called microformats, and it is considered a pragmatic path to the Semantic Web. In this work, we present a practical approach for modeling (microformat based) semantic relations between web pages by means of classical graph like data structures, such as semantic networks. In order to provide categorization into the semantic network we implement the special set of entrance points to the semantic network, which are so-called, semantic indexes. Then we present an agent software approach to retrieve semantically related information between web pages, we describe the main modules and data structures of the process and finally we present snapshots of the tool.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452498","lowercase semantic web;microformats;semantic network","Computer science;Data mining;Data structures;Information retrieval;Resource description framework;Semantic Web;Software agents;Web pages;Web sites;XML","Web sites;data structures;graph theory;information retrieval;semantic Web;semantic networks;software agents","Web pages;agent software approach;graph like data structures;information extraction;information retrieval;microformats;semantic Web;semantic indexes;semantic networks;semantic special tags","","0","","19","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"A New Conceptual Approach to Document Indexing","S. Barresi; S. Nefti-Meziani; Y. Rezgui","Inf. Res. Inst., Univ. of Salford, Salford, UK","2009 Mexican International Conference on Computer Science","20100422","2009","","","360","366","This paper presents a new conceptual indexing technique intended to overcome the major problems resulting from the use of Term Frequency (TF) based approaches. To resolve the semantic problems related to TF approaches, the proposed technique disambiguates the words contained in a document and creates a list of super ordinates based on an external knowledge source. In order to reduce the dimension of the document vector, the final set of index values is created by extracting a set of common concepts, shared by multiple related words, from the list of hypernyms. Subsequently, a weight is assigned to each concept index by considering its position in the knowledge source's hierarchical tree (i.e. distance from the substituted words) and its number of occurrences. By applying the proposed technique, we were able to disambiguate words within different contexts, extrapolate concepts from documents, assigning appropriate normalised weights, and significantly reduce the vector dimension.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452538","","Computational efficiency;Computer science;Data analysis;Extrapolation;Frequency;Indexing;Informatics;Information analysis;Information retrieval;Ontologies","indexing;knowledge acquisition;natural language processing;query processing;semantic Web;text analysis;vocabulary;word processing","TF;Term Frequency;common concepts extraction;conceptual indexing technique;document indexing;document vector dimension;external knowledge source;hierarchical tree;hypernyms;multiple related words;semantic problems;super ordinates list","","1","","16","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Individual Image Retrieval Based on User Interest Model","F. Fujuan; Q. Zhaowen","Coll. of Life Sci., Northeast Forestry Univ., Harbin, China","2010 Second International Workshop on Education Technology and Computer Science","20100506","2010","3","","392","395","There exists a semantic gap between low-level visual feature and high-level semantics feature, and the accuracy of image semantics annotation depends greatly on the description of low-level visual feature. Taking this into consideration, user interest model is proposed in this paper, syncretizing color feature and texture feature into eigenvector, labeling image semantics information by using user interest model. Experiments show that user interest model can be successfully used in image semantics annotation and individual image retrieval.","","Electronic:978-1-4244-6389-3; POD:978-1-4244-6388-6","10.1109/ETCS.2010.443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459655","Image retrieval;Semantic gap;Semantics annotation;User interest model","Computer science education;Data mining;Feature extraction;Forestry;Humans;Image retrieval;Information retrieval;Labeling;Layout;Shape","eigenvalues and eigenfunctions;image retrieval","eigenvector;high level semantics feature;image retrieval;image semantics annotation;low level visual feature;user interest model","","0","","10","","","6-7 March 2010","","IEEE","IEEE Conference Publications"
"Validation of MODIS Aerosol Optical Depth Retrievals in Anhui Province","X. Deng; D. He; W. Deng; Y. Zhao","Anhui Inst. of Meteorol. AIM, Hefei, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","5283","5286","MODIS aerosol retrievals onboard Terra and ground truth data obtained from AERONET (Aerosol Robotic Network) solar direct radiance measurements are collocated to evaluate the quality of the former in Anhui. The validation results show that the MODIS Collection 005 aerosol optical thickness (AOT) has a good relationship with AERONET AOT and their correlation coefficient is larger than 0.8 in Anhui. MODIS Collection 005 AOT correspond with the error standard of NASA and most of its error can be controlled under √Ç¬± 0.05 √Ç¬± 0.15 √Ç¬ø, so MODIS Collection 005 AOT is creditable in Anhui for science research.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1332","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454708","","Aerosols;Area measurement;Error correction;Information retrieval;Information science;MODIS;Meteorology;Pixel;Pollution measurement;Satellites","aerosols;geophysics computing;information retrieval;optical images;optical instruments","AERONET;Anhui Province;MODIS aerosol optical depth retrieval validation;aerosol optical thickness;aerosol robotic network;correlation coefficient;ground truth data;solar direct radiance measurements","","0","","6","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Maximizing visibility of objects","M. Miah; G. Das","University of Texas at Arlington Arlington, TX, USA","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","289","292","In recent years, there has been significant interest in the development of ranking functions and efficient top-k retrieval algorithms to help users in ad-hoc search and retrieval in databases (e.g., buyers searching for products in a catalog). We introduce a complementary problem: how to guide a seller in selecting the best attributes of a new tuple (e.g., a new product) to highlight so that it stands out in the crowd of existing competitive products and is widely visible to the pool of potential buyers. We refer this problem as ""attributes selection"" problem. Package design based on user input is a problem that has also attracted recent interest. Given a set of elements, and a set of user preferences (where each preference is a conjunction of positive or negative preferences for individual elements), we investigate the problem of designing the most ""popular package"", i.e., a subset of the elements that maximizes the number of satisfied users. Numerous instances of this problem occur in practice. We refer this later problem as ""package design"" problem. We develop several formulations of both the problems. Even for the NP-complete problems, we give several exact (optimal) and approximation algorithms that work well in practice. Our experimental evaluation on real and synthetic datasets shows that the optimal and approximate algorithms are efficient for moderate and large datasets respectively, and also that the approximate algorithms have small approximation error.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452730","","Algorithm design and analysis;Automobiles;Business;Catalogs;Costs;Information retrieval;Manufacturing;Marketing and sales;Relational databases;Spatial databases","database management systems;information retrieval;optimisation;user centred design","NP-complete problems;ad-hoc retrieval;ad-hoc search;approximation algorithms;approximation error;attributes selection problem;databases;object visibility maximization;package design;ranking functions;top-k retrieval algorithms;user preferences","","0","","10","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Shape Recognition Using Vector Quantization","A. D. Lillo; G. Motta; J. A. Storer","Brandeis Univ., Waltham, MA, USA","2010 Data Compression Conference","20100422","2010","","","484","493","We present a framework to recognize objects in images based on their silhouettes. In previous work we developed translation and rotation invariant classification algorithms for textures based on Fourier transforms in the polar space followed by dimensionality reduction. Here we present a new approach to recognizing shapes by following a similar classification step with a ""soft"" retrieval algorithm where the search of a shape database is based on the VQ centroids found by the classification step. Experiments presented on the MPEG-7 CE-Shape 1 database show significant gains in retrieval accuracy over previous work. An interesting aspect of this recognition algorithm is that the first phase of classification seems to be a powerful tool for both texture and shape recognition.","1068-0314;10680314","Electronic:978-1-4244-6426-5; POD:978-1-4244-6425-8","10.1109/DCC.2010.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453468","MPEG7;recognition;shape;vector quantization","Cascading style sheets;Feature extraction;Image databases;Image recognition;Image segmentation;Information retrieval;MPEG 7 Standard;Shape measurement;Spatial databases;Vector quantization","Fourier transforms;image coding;image retrieval;image texture;object recognition;pattern classification;shape recognition;vector quantisation","Fourier transforms;MPEG-7 CE-Shape 1 database;image textures;object recognition;polar space;rotation invariant classification;shape recognition;silhouettes;soft retrieval algorithm;vector quantization","","0","","11","","","24-26 March 2010","","IEEE","IEEE Conference Publications"
"LiterMiner: A Literature Visual Analytic System","B. Wu; L. Suo","Beijing Key Lab. of Intell. Telecommun. Software & Multimedia, Beijing Univ. of Posts & Telecommun., Beijing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","891","894","The data set of scientific literature contains abundant knowledge. Currently, most bibliography search engines provide only keyword search or similarity search functions for retrieving information directly stored in the database but neglect mining hidden information. In this article, we design a visual analytic tool called LiterMiner to extract entities such as article, author, affiliation, and keyword from these literature records, establish the relationships among them and display them to help analyst understand them effectively. Especially, LiterMiner uses community detection algorithm to explore academic teams. Our tool has three principle features. First, a sophisticated data clean process is designed for integration of many different formatted literature records. Second, LiterMiner can find academic teams and analyze the resume of an academic team. Third, an interactive and cooperate visualization solution is used to display the analysis result, which help user understand the result better.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454639","","Bibliographies;Data mining;Detection algorithms;Displays;Information retrieval;Keyword search;Process design;Search engines;Visual analytics;Visual databases","bibliographic systems;data mining;data visualisation;search engines","LiterMiner;abundant knowledge;cooperate visualization solution;keyword search;literature records;literature visual analytic system;mining hidden information;retrieving information;scientific literature;search engines;search functions","","0","","10","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"3D action matching with key-pose detection","J. Kilner; J. Y. Guillemaut; A. Hilton","Center for Vision, Speech and Signal Processing, University of Surrey, Guildford, United Kingdom","2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","20100503","2009","","","1","8","This paper addresses the problem of human action matching in outdoor sports broadcast environments, by analysing 3D data from a recorded human activity and retrieving the most appropriate proxy action from a motion capture library. Typically pose recognition is carried out using images from a single camera, however this approach is sensitive to occlusions and restricted fields of view, both of which are common in the outdoor sports environment. This paper presents a novel technique for the automatic matching of human activities which operates on the 3D data available in a multi-camera broadcast environment. Shape is retrieved using multi-camera techniques to generate a 3D representation of the scene. Use of 3D data renders the system camera-pose-invariant and allows it to work while cameras are moving and zooming. By comparing the reconstructions to an appropriate 3D library, action matching can be achieved in the presence of significant calibration and matting errors which cause traditional pose detection schemes to fail. An appropriate feature descriptor and distance metric are presented as well as a technique to use these features for key-pose detection and action matching. The technique is then applied to real footage captured at an outdoor sporting event.","","Electronic:978-1-4244-4124-2; Electronic:978-1-4244-4441-0; POD:978-1-4244-4442-7","10.1109/ICCVW.2009.5457724","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457724","","Broadcasting;Cameras;Data analysis;Humans;Image motion analysis;Image recognition;Information retrieval;Libraries;Motion analysis;Shape","feature extraction;image matching;image motion analysis;image reconstruction;pose estimation;shape recognition","3D action matching;3D representation;feature descriptor;human action matching;key pose detection;motion capture library;multicamera broadcast environment;outdoor sports broadcast environments;shape retrieval","","12","2","25","","","Sept. 27 2009-Oct. 4 2009","","IEEE","IEEE Conference Publications"
"Ageing Management System of the Steam Generator of the Nuclear Power Plant","J. Guo; Y. Liu; K. Gu; M. Wu; P. Liu; L. Zhou; J. Jiang; Y. Wang","Sch. of Power & Mech. Eng., Wuhan Univ., Wuhan, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","2266","2269","Steam generator (SG) is one of the key important equipments to safety of nuclear power plant (NPP), its reliability is the one vital weakness of nuclear steam supply system (NSSS), so it is necessary for ageing management (AM) to increase its reliability for safety operation. However the SG AM data has not always been readily available, thus the Ageing Management Database of the Steam Generator of nuclear power plant (AMDSG) was developed to integrate decentralized information and provide a valuable data center that the data needed could be easily and quickly retrieved, and can serve as the basis platform for optimizing SG ageing evaluation and management. AMDSG is an online interactive integrated knowledge management system. Some modern information technologies are applied, especially real-time data acquisition and virtual reality technology. It not only contains all equipment condition information and important operation data that are needed based on data warehouse technology, but also provides fundamental online monitoring, analysis, assessment functions and basis data management functions.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455305","","Aging;Databases;Distributed power generation;Energy management;Information retrieval;Nuclear power generation;Power generation;Power system management;Power system reliability;Safety devices","ageing;boilers;data acquisition;data warehouses;nuclear power stations;power system management;power system reliability;virtual reality","ageing management system;data warehouse technology;modern information technologies;nuclear power plant;nuclear steam supply system;online interactive integrated knowledge management system;online monitoring;real-time data acquisition;steam generator;virtual reality technology","","1","","9","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Automated Event Log File Recovery Based on Content Characters and Internal Structure","Y. Lou; P. Wang; M. Xu; N. Zheng","Comput. & Software Inst., Hangzhou Dianzi Univ., Hangzhou, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","4778","4781","Rapidly retrieving valuable information is vital in computer forensic, especially information with respect to the computer system itself. Attentions on the system information such as registry and event log have increasingly promoted the forensic researches. Event log is a very import file in computer, which contains a large amount of available information about what happened on the system observed, but current forensic tool on event log only can repair corrupted log files and has no effect on the situation that event log file has been fragmented. To address this problem, this paper presents an algorithm which allows search for windows event log file data fragments based solely on their data contents, without the need of any meta data. The algorithm is based on searching the signature in log file combining with computing the entropy difference between neighboring clusters. A tool was developed to automate recovery and parse of Windows NT5 (XP and 2003) event logs for computer forensic. This tool automates repair of multiple event logs and parse the recovered files without user intervention. The evaluation of this method shows an average accuracy of 82.5%, with lower false positive.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.351","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454707","","Clustering algorithms;Content based retrieval;Digital forensics;Entropy;File systems;Image analysis;Image retrieval;Information retrieval;Information science;Software","computer forensics;operating systems (computers);system recovery","Windows NT5;automated event log file recovery;computer forensic;computer system;content character;entropy difference;forensic tool;import file;internal structure;log file signature;neighboring cluster;parse;system information","","0","","9","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Automated scientific document retrieval","J. Kaur; M. Yusof; P. Boursier; J. M. Ogier","Faculty of Information Technology & Multimedia Communications, Open University Malaysia, 50480 Kuala Lumpur, Malaysia","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","5","","732","736","Internet has revolutionized knowledge acquisition. Scientific knowledge in books, journals, and conference proceedings are available in digital libraries online. Current digital library end users are not adequately equipped with the technological know-how on information retrieval. While these systems normally retrieve documents based on keywords, users normally have a more abstract perception what information they require. Semantic gap, which is the disparity between user's request and query results, has been identified as a challenging issue. In this paper, we are interested in scientific document indexing for retrieval. Knowing the structure of such a document is helpful to the retrieval process, as the document is decomposed into different elements and specific indexing methods are applied to the different element types. Also, as the document is viewed as a composition of many elements, query responses may return some of the elements instead of the entire document. Therefore the aim of this paper is to present a novel approach to information retrieval from scientific documents, combining text mining with image mining.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451344","Digital Libraries;Document Retrieval;Text and Image mining","Books;Conference proceedings;Data mining;Image retrieval;Indexing;Information retrieval;Internet;Knowledge acquisition;Software libraries;Text mining","digital libraries;information retrieval;knowledge acquisition;scientific information systems","Internet;automated scientific document retrieval;digital library end users;image mining;information retrieval;knowledge acquisition;text mining","","0","","15","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"XML Element Recommendation by Semantic Ranking","S. Vacharaskunee; S. Intakosum","Software Systems Engineering Laboratory, Department of Mathematics and Computer Science, Faculty of Science, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","3","","244","248","From the strong point of XML that allows document owners to describe their documents in their own format, it is difficult to search information if those XML documents use different formats. Moreover, users might not retrieve all relevant information from differently formatted XML documents. To allow users to retrieve all relevant results, users need to have as many as queries for all possible formats. SXER (Semantic Ranking for XML Element Recommendation) is an idea to make XML documents easier for searching. It receives XML document as an input, checks all possible semantics for each element, and checks those semantic elements to find which element (word) should be used. The output is a recommendation for each element of input XML document.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451204","Semantic Ranking for XML Element Recommendation;WordCount;WordNet;XML","Computer science;Database languages;Information retrieval;Keyword search;Laboratories;Markup languages;Mathematics;Software systems;Systems engineering and theory;XML","XML;query processing","XML document;XML element recommendation;information retrieval;query;searching;semantic element;semantic ranking","","1","","24","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Purifying Sets of Matched Features through RANSAC for Image Retrieval","W. Xu; K. Fang; X. Liu","Coll. of Inf. Sci. & Eng., Wuhan Univ. of Sci. & Technol., Wuhan, China","2010 International Conference on Measuring Technology and Mechatronics Automation","20100506","2010","2","","952","955","An image is often represented by a set of local invariant features for many computer vision tasks such as object recognition and content-based image retrieval (CBIR), in which correct and reliable feature matching is an essential and challenging issue. Aiming at the problem of the existence of the false matches in CBIR system, we put forward a post-verification method in this paper where RANSAC algorithm is adopted to verify the primary retrieved images on global geometric consensus with the query image so that the false matches are discarded as outliers and only the correct ones are remained as inliers. Experiments show that RANSAC algorithm used in this context can improve the reliability of CBIR systems efficiently.","2157-1473;21571473","Electronic:978-1-4244-5739-7; POD:978-1-4244-5001-5","10.1109/ICMTMA.2010.726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459905","CBIR;RANSAC algorithm;image matching;local invariant features","Automation;Computer vision;Content based retrieval;Image matching;Image retrieval;Information retrieval;Iterative algorithms;Mechatronics;Object recognition;Parameter estimation","computer vision;content-based retrieval;image matching;image retrieval","CBIR system;RANSAC algorithm;computer vision;content-based image retrieval;image retrieval;object recognition;post-verification method;query image","","0","","7","","","13-14 March 2010","","IEEE","IEEE Conference Publications"
"Negotiation-Based Trust Establishment for Shibboleth","H. Wang; F. Shen","Dept. of Comput. Sci., East China Normal Univ., Shanghai, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","1773","1776","In frameworks of Shibboleth, if the identity provider (IdP) receives a request from the service provider (SP), before sending back the response, it must verify the SP's identity by its metadata file. The same as in SP. However, these metadata files are stored in local and if the metadata file is modified hostilely, the trust establishment will be damaged. We focus on Shibboleth and propose a solution of trust establishment between an IdP and a SP for Shibboleth. While in the conventional framework of Shibboleth trust establishment is done by local metadata file, in our solution trust establishment is done by negotiation, an SP or IdP requests the discovery service (DS) whether the provider is trusty, then the DS returns either ""true"" or ""false"" to the SP or IdP.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455618","","Access control;Authentication;Authorization;Computer architecture;Computer science;Information retrieval;Information science;Information security;Protection;Service oriented architecture","Internet;authorisation","IdP request;SP request;Shibboleth system;Web single sign-on;discovery service;identity provider;metadata file;negotiation-based trust establishment;service provider","","0","","10","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Detecting objects in large image collections and videos by efficient subimage retrieval","C. H. Lampert","Max Planck Institute for Biological Cybernetics, T&#252;bingen, Germany","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","987","994","We study the task of detecting the occurrence of objects in large image collections or in videos, a problem that combines aspects of content based image retrieval and object localization. While most previous approaches are either limited to special kinds of queries, or do not scale to large image sets, we propose a new method, efficient subimage retrieval (ESR), that is at the same time very flexible and very efficient. Relying on a two-layered branch-and-bound setup, ESR performs object-based image retrieval in sets of 100,000 or more images within seconds. An extensive evaluation on several datasets shows that ESR is not only very fast, but it also achieves excellent detection accuracies thereby improving over previous systems for object-based image retrieval.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459359","","Content based retrieval;Cybernetics;Electronic switching systems;Image databases;Image representation;Image retrieval;Information retrieval;Object detection;Paramagnetic resonance;Videos","content-based retrieval;object detection;video retrieval","content based image retrieval;efficient subimage retrieval;object detection;object localization;object-based image retrieval;two-layered branch-and-bound setup;video retrieval","","35","","23","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"Human action recognition from a single clip per action","Weilong Yang; Yang Wang; G. Mori","School of Computing Science, Simon Fraser University, Burnaby, BC, Canada","2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","20100503","2009","","","482","489","Learning-based approaches for human action recognition often rely on large training sets. Most of these approaches do not perform well when only a few training samples are available. In this paper, we consider the problem of human action recognition from a single clip per action. Each clip contains at most 25 frames. Using a patch based motion descriptor and matching scheme, we can achieve promising results on three different action datasets with a single clip as the template. Our results are comparable to previously published results using much larger training sets. We also present a method for learning a transferable distance function for these patches. The transferable distance function learning extracts generic knowledge of patch weighting from previous training sets, and can be applied to videos of new actions without further learning. Our experimental results show that the transferable distance function learning not only improves the recognition accuracy of the single clip action recognition, but also significantly enhances the efficiency of the matching scheme.","","Electronic:978-1-4244-4124-2; Electronic:978-1-4244-4441-0; POD:978-1-4244-4442-7","10.1109/ICCVW.2009.5457663","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457663","","Biological system modeling;Biomedical optical imaging;Computer vision;Humans;Image motion analysis;Information retrieval;Optical filters;Surveillance;Training data;Videos","feature extraction;image matching;image motion analysis;image recognition;video signal processing","human action recognition;learning based approaches;matching scheme;motion descriptor;single clip per action;transferable distance function learning","","7","","26","","","Sept. 27 2009-Oct. 4 2009","","IEEE","IEEE Conference Publications"
"Efficient k-nearest neighbor queries with the Signature Quadratic Form Distance","C. Beecks; M. S. Uysal; T. Seidl","Data Management and Data Exploration Group RWTH Aachen University, Germany","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","10","15","A frequently encountered query type in multimedia databases is the k-nearest neighbor query which finds the k-nearest neighbors of a given query. To speed up such queries and to meet the user requirements in low response time, approximation techniques play an important role. In this paper, we present an efficient approximation technique applicable to distance measures defined over flexible feature representations, i.e. feature signatures. We apply our approximation technique to the recently proposed Signature Quadratic Form Distance applicable to feature signatures. We performed our experiments on numerous image databases, gathering k-nearest neighbor query rankings in significantly low computation time with an average speed-up factor of 13.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452772","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452772","","Audio databases;Data mining;Delay;Histograms;Image databases;Image retrieval;Information retrieval;Multimedia databases;Spatial databases;Videos","multimedia databases;query processing","efficient approximation technique;efficient k-nearest neighbor queries;multimedia databases;signature quadratic form distance","","3","1","15","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Facebrowsing: Search and navigation through comparisons","D. Tschopp; S. Diggavi","School of Computer and Communication Sciences, Ecole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), 1015 Lausanne, Switzerland","2010 Information Theory and Applications Workshop (ITA)","20100426","2010","","","1","10","This paper addresses the problem of finding the nearest neighbor (or one of the R-nearest neighbors) of a query object in a database which is only accessible through a comparison oracle. The comparison oracle, given two reference objects and a query object, returns the reference object closest to the query object. The oracle attempts to model the behavior of human users, capable of making statements about similarity, but not of assigning meaningful numerical values to distances between objects. We develop nearest-neighbor search algorithms and analyze its performance for such an oracles. Using such a comparison oracle, the best we can hope for is to obtain, for every object in the database, a ranking of the other objects according to their distance to it. The difficulty of searching using such an oracle depends on the non-homogeneities of the underlying space. We introduce the new idea of a rank-sensitive hash (RSH) function which gives same hash value for ¬ø¬øsimilar¬ø¬ø objects based on the rank-value of the objects obtained from the similarity oracle. As one application of RSH, we demonstrate that, we can retrieve one of the (1 + ¬ø¬ø)r-nearest neighbor of a query point in time-complexity depending on an underlying property (termed rank-distortion) of the search space. We use this idea to implement a navigation system for an image database of human faces. In particular, we design a database for images that is organized adaptively based on both baseline comparisons using eigenfaces and refined using selected human input. We present a preliminary implementation of this system which seeks to minimize the number of questions asked to a (human) oracle.","","Electronic:978-1-4244-7014-3; POD:978-1-4244-7012-9","10.1109/ITA.2010.5454139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454139","","Algorithm design and analysis;Extraterrestrial measurements;Face;Feature extraction;Humans;Image databases;Information retrieval;Navigation;Nearest neighbor searches;Performance analysis","computational complexity;face recognition;query processing;search problems;visual databases","RSH function;comparison oracle;eigenface;facebrowsing;human face;human user behaviour;image database;navigation system;nearest-neighbor search algorithm;query object;rank value;rank-distortion;rank-sensitive hash;reference object;searching;time-complexity","","2","","20","","","Jan. 31 2010-Feb. 5 2010","","IEEE","IEEE Conference Publications"
"Fuzzy Keyword Search over Encrypted Data in Cloud Computing","J. Li; Q. Wang; C. Wang; N. Cao; K. Ren; W. Lou","Dept. of ECE, Illinois Inst. of Technol., Chicago, IL, USA","2010 Proceedings IEEE INFOCOM","20100506","2010","","","1","5","As Cloud Computing becomes prevalent, more and more sensitive information are being centralized into the cloud. For the protection of data privacy, sensitive data usually have to be encrypted before outsourcing, which makes effective data utilization a very challenging task. Although traditional searchable encryption schemes allow a user to securely search over encrypted data through keywords and selectively retrieve files of interest, these techniques support only exact keyword search. That is, there is no tolerance of minor typos and format inconsistencies which, on the other hand, are typical user searching behavior and happen very frequently. This significant drawback makes existing techniques unsuitable in Cloud Computing as it greatly affects system usability, rendering user searching experiences very frustrating and system efficacy very low. In this paper, for the first time we formalize and solve the problem of effective fuzzy keyword search over encrypted cloud data while maintaining keyword privacy. Fuzzy keyword search greatly enhances system usability by returning the matching files when users' searching inputs exactly match the predefined keywords or the closest possible matching files based on keyword similarity semantics, when exact match fails. In our solution, we exploit edit distance to quantify keywords similarity and develop an advanced technique on constructing fuzzy keyword sets, which greatly reduces the storage and representation overheads. Through rigorous security analysis, we show that our proposed solution is secure and privacy-preserving, while correctly realizing the goal of fuzzy keyword search.","0743-166X;0743166X","Electronic:978-1-4244-5838-7; POD:978-1-4244-5836-3","10.1109/INFCOM.2010.5462196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5462196","","Cloud computing;Cryptography;Data privacy;Fuzzy systems;Impedance matching;Information retrieval;Keyword search;Outsourcing;Protection;Usability","Internet;cryptography;data privacy;fuzzy set theory;information retrieval","cloud computing;data privacy;data protection;encrypted data;files matching;fuzzy keyword search;user searching behavior","","169","1","16","","","14-19 March 2010","","IEEE","IEEE Conference Publications"
"A framework for visual saliency detection with applications to image thumbnailing","L. Marchesotti; C. Cifarelli; G. Csurka","Textual and Visual Pattern Analysis (TVPA), Xerox Research Centre Europe (XRCE), France","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","2232","2239","We propose a novel framework for visual saliency detection based on a simple principle: images sharing their global visual appearances are likely to share similar salience. Assuming that an annotated image database is available, we first retrieve the most similar images to the target image; secondly, we build a simple classifier and we use it to generate saliency maps. Finally, we refine the maps and we extract thumbnails. We show that in spite of its simplicity, our framework outperforms state-of-the-art approaches. Another advantage is its ability to deal with visual pop-up and application/task-driven saliency, if appropriately annotated images are available.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459467","","Detectors;Europe;Face detection;Humans;Image databases;Image retrieval;Information retrieval;Layout;Object detection;Pattern analysis","object detection;visual databases","annotated image database;application-task-driven saliency;image thumbnailing;thumbnail extraction;visual pop-up;visual saliency detection","","81","2","34","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"An Architecture for Asynchronous Indexing of Media Assets","J. M. Espinosa Carl√≠n; D. L. Cheng Abusabal","Commun. & Distrib. Syst., KWTH Aachen Univ., Aachen, Germany","2009 Mexican International Conference on Computer Science","20100422","2009","","","75","85","Multimedia documents, though rich in content, generally lack structured and descriptive metadata that would allow indexing, searching, and cross-linking. Since the field of Multimedia Information Retrieval has been working on solving the problem of multimedia content analyzing and indexing for a number of years, several existing components could be integrated into a final solution, as well as incorporating new techniques from current research results. Hence, a multimedia indexing system must not only face the challenge of a providing scalability and performance, but should also allow for interoperability with legacy code and integration of new processes. With these goals in mind, this paper presents a loosely coupled, asynchronous, distributed event-based SOA media indexing system, making use of Web services and Enterprise Service Bus technologies and contrasts it with different application distribution approaches, with regards to the throughput, scalability, and response time when executing the tasks required for analyzing and indexing of large media document collections.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452524","","Content based retrieval;Delay;Indexing;Information analysis;Information retrieval;Multimedia systems;Scalability;Service oriented architecture;Throughput;Web services","Web services;document handling;indexing;information retrieval;multimedia computing","Web services;application distribution approach;asynchronous indexing;distributed event based SOA media indexing system;enterprise service bus technologies;media assets;multimedia documents;multimedia indexing system;multimedia information retrieval","","0","","13","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Rules and Scripts Based Dynamic Spatial Data Catalogue Technique Study and Its Application","F. Fang; M. Hu; B. Wan; L. Yang","Facuity of Inf. Eng., China Univ. of Geosci.(Wuhan), Wuhan, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","2172","2176","Catalogue technology has been widely used in spatial information organization, management and retrieval; it also plays vital effect in geography information system in organizing distributed and various spatial data resources. However, recent ways to describe catalogue tree, such as xml or database tables, lead fixed structure which is difficult to change, reuse and extend when facing masses of real-time spatial data. The directory service (OpenGIS Catalogue Services) standard developed by OGC (OpenGIS Consortium) only defines the directory service interoperable interface specifications but lacks of organizations and technology to implement. Thus, it is indispensable to develop a new method to manage masses of spatial data in spatial data warehouse or spatial data center systems in a facile, flexible and real-time way. Through analyzing common methods of representing and building catalogue system, this paper presents the novel concept of dynamic spatial data catalogue (DSDC) based upon these traditional model. Firstly, DSDC builds up a highly abstracted catalogue model for general directory description. Then, combining with the requirements of GIS application system, it developed a dynamic spatial data catalogue technique and mechanism using rules and scripts to produce the dynamic effect of catalogue representation. It detailedly introduced the key approach of the implementation using XML as the define language of rule, and using python as the script language. In this way, the catalog system will meet the requirements of faster development, easier extension, heterogeneous spatial data resource integration and real time reaction in a flexible way. DSDC technology is also an approach to build or integrate with any GIS systems rapidly. This paper discusses some applications of DSDC in various appropriate occasions, illustrates the integration of DSDC with MapGIS data center platform, and gives the application of DSDC in specific GIS application development and building- - process. The DSDC technology has been implemented and used in managing national 1:50000 basic geographic database resource and weather spatial data of Wuhan dynamically. Experiments prove that dynamic spatial data catalogue using rules and scripts has obvious advantages and will have huge potential in GIS applications.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454518","","Geographic Information Systems;Geography;Information management;Information retrieval;Management information systems;Organizing;Real time systems;Resource management;Spatial databases;Technology management","cataloguing;geographic information systems;spatial data structures;visual databases","MapGIS data center platform;OpenGIS catalogue services;directory service standard;dynamic spatial data catalogue;dynamic spatial data catalogue technique;geographic database resource;geography information system;python script language;spatial data warehouse;spatial information organization","","1","","8","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Schemas Extraction for XML Documents by XML Element Sequence Patterns","H. Zhang; X. Yuan","Coll. of Inf. Tech. Sci., Nankai Univ., Tianjin, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","5096","5099","XML is the de facto standard format for data exchange manipulation of structured documents. XML schema provides important structural information of XML documents. Unfortunately, much XML data does not have XML schema or is not accompanied by its XML schema. In order to take advantage of having XML schema in XML documents, XML schema of the XML document is significant to be extracted. This paper will present a model named XML Element Sequence Patterns (XESP) for XML documents to extract XML schemas from documents without schemas. XESPs will be built based on paths of XML elements, and represented by a sequence of XML elements with relations. Experimental results show that extracting XML schemas by XESPs will occupy less time and memory and bring more precision than traditional methods based on ECMs and EPMs.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455519","","Brushless DC motors;Data engineering;Data mining;Databases;Educational institutions;Electrochemical machining;Information retrieval;Information science;XML","XML;electronic data interchange;information retrieval","XML document;XML element sequence patterns;XML schema;data exchange manipulation;extensible markup language","","4","","12","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Text clustering based on term weights automatic partition","Yu Yonghong; Bai Wenyang","Department of Computer Science, Anhui University of Finance & Economics, Bengbu, China","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","3","","373","377","Text clustering is becoming more and more popular due to the increasing of texts on Web and the requirements in real application. This paper introduces a novel automatic text clustering method, in which the genetic algorithm is first applied to the global optimal and high searching efficient term selection to achieve dimensionality reduction, and then appropriate number of partitions of document set are created according to the different combinations of term weights, and each document partition is clustered into an initial clusters based on dynamic programming technique, and last all initial clusters are clustered using the same method to final text clusters. It also provides analysis and theorem proof that the algorithm can provide higher performance in computational complexity, clustering effect and high dimensional data clustering.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451390","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451390","genetic algorithm;term selection;term weight partition;text clustering","Clustering algorithms;Clustering methods;Computer science;Data mining;Finance;Genetic algorithms;Information analysis;Information retrieval;Machine learning;Partitioning algorithms","computational complexity;dynamic programming;genetic algorithms;pattern clustering;text analysis;theorem proving","automatic text clustering method;computational complexity;data clustering;dynamic programming technique;genetic algorithm;global optimal searching;theorem proof;weights automatic partition","","0","","20","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Secure P2P File Sharing System Based on Full-Text Retrieval","L. Wang; Z. Wan","Sch. of Comput. Sci. & Software, Tianjin Polytech. Univ., Tianjin, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","380","383","Apache Lucene is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search. Using Apache Lucene and Remote Method Invocation (RMI), we have designed and completed a secure P2P File Sharing System based on Full-Text Retrieval. This system could find and locate the keywords which users interested in scientifically and efficiently. Besides the function of full-text retrieval, this system also contains ID Authentication, this ensures the safety of the share resources. In the end, we prove that our system is more efficient than the P2P File Sharing Systems based on Full-Text Travel in the aspect of finding and locating specified keywords.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455338","","Authentication;Computer science;Encapsulation;Information retrieval;Java;Libraries;Peer to peer computing;Search engines;Skeleton;Software","computer network security;digital signatures;full-text databases;peer-to-peer computing;remote procedure calls","Apache Lucene;ID authentication;full-featured text search engine library;full-text retrieval;remote method invocation;secure P2P file sharing system","","0","1","6","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"The big pileup","N. Mitchell","IBM, USA","2010 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS)","20100419","2010","","","1","1","Programmers no longer write monolithic applications, they assemble code from a sea of reusable libraries and frameworks. This layered process of construction has a magnifying effect on local coding decisions. Piece by innocent piece, seemingly harmless constant factors pile up. They become part of an interstitial excess, marbled throughout the code and APIs, and difficult to remove. It is not uncommon for large applications to miss their performance targets by an order of magnitude. We commonly see web requests create objects and invoke methods by the hundreds of thousands to retrieve and format a few database records. Current Java optimizers and garbage collectors don't address many of these systemic problems. This talk discusses these issues, via many examples, with a goal of motivating research on the programming of large-scale artifacts in a way that local, often ad hoc, decisions can be unwound, rather then pile up, in the large.","","Electronic:978-1-4244-6024-3; POD:978-1-4244-6023-6","10.1109/ISPASS.2010.5452084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452084","","Assembly;Databases;Information retrieval;Java;Large-scale systems;Libraries;Programming profession;Scalability;Systems engineering and theory;Visualization","programming;software tools","Java optimizers;database records;garbage collectors;large-scale artifacts programming;local coding decisions;pileup;reusable libraries","","0","","","","","28-30 March 2010","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Webpage Development for Genome Compression Technique","M. S. M. Hossein; A. Mukherjee; S. Ghosh","Dept. of CST, ICV Polytech., Jhgargram, India","2010 Second International Conference on Machine Learning and Computing","20100506","2010","","","282","287","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>This is web based project which mainly deals with GENOMIC COMPRESSION. Here we have used several compression techniques i,e Huffman Compression Techniques, Four base to single base compression techniques..etc for compressing Nucleotide sequence of huge size. There are two phases one is ADMINISTRATOR and another NORMAL USER. ADMINISTRATOR handles the data and maintains the database. Initially our aim to generate the encoded file for a particular file at runtime and the signature of that particular file are stored in another file to identify that particular file while decoding but we were not able to generate at runtime but rather we store the encoded file along with signature file in the database and while retrieving decoded data from encoded data we use encoded data file along with the signature file. The DNA sequences storing and transmitting them may require a huge amount of space. This web page are help to reduce the space for storing and transmitting data, also introduce one new techniques along with exiting Huffman Technique of compression routine. DNA and RNA sequences can be considered as tests over a four letter alphabet, namely {a, t, g and c}. This algorithm can approach a compression rate of 2.1 bits /base and even lower. We tested the program on standard benchmark data used. The greatest advantage of this program is fast execution, small memory occupation and easy implementation.","","Electronic:978-1-4244-6007-6; POD:978-1-4244-6006-9","10.1109/ICMLC.2010.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5460725","Biology and genetics;Data Compression;Data Decompression","Bioinformatics;DNA;Databases;Decoding;Genomics;Information retrieval;Runtime;Sequences;Testing;Web pages","Internet;biocomputing;data compression;digital signatures;encoding;genomics;information retrieval","DNA sequences;Huffman Technique;RNA sequences;Webpage development;database;decoded data retrieval;encoded data file;genome compression technique;nucleotide sequence;signature file","","0","","11","","","9-11 Feb. 2010","","IEEE","IEEE Conference Publications"
"Enterprise Storage Architecture for Optimal Business Continuity","R. Singhal; S. Bokare; P. Pawar","CNIE Dept, C-DAC, Mumbai, India","2010 International Conference on Data Storage and Data Engineering","20100422","2010","","","73","77","This paper presents a solution for optimal business continuity, with storage architecture for enterprise applications, which shall ensure negligible data loss and quick recovery. The solution makes use of IP SAN, which are used for data management without burdening the application server, as well as replication techniques to replicate data to remote disaster recovery site. We have presented the design using open source database Postgres to prove our point for optimal business continuity. The theoretical presentation is also given for the same.","","Electronic:978-1-4244-5679-6; POD:978-1-4244-5678-9","10.1109/DSDE.2010.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452634","Business continuity;Database;Disaster Recovery;IPSAN","Application software;Business continuity;Costs;Data engineering;Databases;Disaster management;Information retrieval;Memory;Protection;Storage area networks","IP networks;business continuity;business data processing;storage area networks","IP SAN;Postgres open source database;application server;data management;enterprise storage architecture;negligible data loss;optimal business continuity;remote disaster recovery site;replication technique","","1","","16","","","9-10 Feb. 2010","","IEEE","IEEE Conference Publications"
"Multihypothesis Viterbi Data Association: Algorithm Development and Assessment","G. W. Pulford; B. F. La Scala","QinetiQ, UK","IEEE Transactions on Aerospace and Electronic Systems","20100506","2010","46","2","583","609","Two algorithms for tracking in clutter, based on the Viterbi algorithm are presented: single-target Viterbi data association (ST-VDA) and multihypothesis VDA (MH-VDA). MH-VDA is designed specifically for multiple-target tracking (MTT), although ST-VDA still achieves good performance on MTT problems. The basic philosophy of both methods is to set up an optimisation problem for the sequence of measurement-to-target associations rather than directly seeking the target state estimates. The joint optimisation problem for the data association sequence is decomposed into a sequence of scalar optimisation problems by means of an approximate forward dynamic programming recursion to which the Viterbi algorithm is applicable. Once the data association problem is solved, the target state estimates can be retrieved by backtracking. The operation of the algorithms is easily visualised as a search on a trellis for the optimal path. For ST-VDA, nodes in the trellis correspond to measurements. For MH-VDA, nodes correspond to multitarget data association hypotheses. Conventional measurement gating is extended to work within this context. Results from simulations that compare the performance of ST-VDA and MH-VDA with four, standard, zero-scan-back tracking approaches are given. The performance assessment includes metrics for track loss and track swaps in a multiple crossing target context. The Viterbi data association (VDA) algorithms are shown to outperform the alternative algorithms. In particular the ST-VDA is found to have the best track swap performance, while MH-VDA has the lowest track loss figure. Average state estimation errors for both VDA algorithms are only about 10% larger than a Kalman filter with known data associations. While both variants of VDA are essentially batch processing approaches, the simulation results indicate that the algorithms can be implemented with a fixed processing lag of only a few scans without significant loss in performance.","0018-9251;00189251","","10.1109/TAES.2010.5461643","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461643","","Australia;Dynamic programming;Information retrieval;Optimization methods;Particle filters;Performance loss;State estimation;Target tracking;Visualization;Viterbi algorithm","Viterbi detection;dynamic programming;radar detection;radar tracking;sensor fusion;target tracking","Kalman filter;approximate forward dynamic programming recursion;batch processing;measurement-to-target associations;multihypothesis VDA;multiple target tracking;optimisation problem;single-target Viterbi data association;target state estimates;track loss figure;track swaps;zero-scan-backtracking","","13","","70","","","April 2010","","IEEE","IEEE Journals & Magazines"
"Scalability Issues for Self Similarity Join in Distributed Systems","C. Gennaro; F. Rabitti","ISTI-CNR, Pisa, Italy","2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing","20100422","2010","","","309","316","Efficient processing of similarity joins is important for a large class of data analysis and data-mining applications. This primitive finds all pairs of records within a predefined distance threshold of each other. However, most of the existing approaches have been based on spatial join techniques designed primarily for data in a vector space. Treating data collections as metric objects brings a great advantage in generality, because a single metric technique can be applied to many specific search problems quite different in nature. In this paper, we concentrate our attention on a special form of join, the Self Similarity Join, which retrieves pairs from the same dataset. In particular, we consider the case in which the dataset is split into subsets that are searched for self similarity join independently (e. g, as in a distributed computing environment). To this end, we formalize the abstract concept of √Ç¬ø-Cover, prove its correctness, and demonstrate its effectiveness by applying it to two real implementations on a real-life large dataset.","1066-6192;10666192","Electronic:978-1-4244-5673-4; POD:978-1-4244-5672-7","10.1109/PDP.2010.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452451","","Cleaning;Clustering algorithms;Data analysis;Data mining;Databases;Distributed computing;Information retrieval;Scalability;Search problems;Time series analysis","data mining;set theory;software metrics","data analysis;data-mining applications;distributed computing environment;distributed systems;real-life large dataset;spatial join techniques;subsets","","0","","29","","","17-19 Feb. 2010","","IEEE","IEEE Conference Publications"
"Automatic Summarization for Chinese Text Based on Combined Words Recognition and Paragraph Clustering","C. j. Jiang; H. Peng; Q. l. Ma; J. c. Chen","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China","2010 Third International Symposium on Intelligent Information Technology and Security Informatics","20100422","2010","","","591","594","With the tremendous amount of information available electronically, there is an increasing requirement for automatic text summarization systems. An extractive summarization method is represented. The weight of a Chinese word/phrase is computed based on its frequency, part of speech, position and length. The weight of a Chinese sentence is computed by its content, position, length and cue words in it. The adjacent paragraphs are clustered into same cluster or different clusters according to their similarity. The experiment results show that the proposed algorithm has a significantly better performance compared with the traditional automated summarization algorithms based on TF-ISF method.","","Electronic:978-1-4244-6743-3; POD:978-1-4244-6730-3","10.1109/IITSI.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453695","Chinese combined word;automatic summarization;paragraph clustering;weight computation","Artificial intelligence;Clustering algorithms;Data mining;Dictionaries;Frequency;Information retrieval;Information technology;Natural languages;Speech;Text recognition","pattern clustering;text analysis","Chinese phrase computation;Chinese sentence computation;Chinese word computation;TF-ISF method;automatic Chinese text summarization systems;combined words recognition;extractive summarization method;paragraph clustering","","1","","9","","","2-4 April 2010","","IEEE","IEEE Conference Publications"
"Blocking Wavelet-Histogram Image Retrieval by Adaptive Particle Swarm Optimization","T. Luo; Y. Bing; T. Li","Dept. of Comput. & Inf. Eng., Wuhan Polytech. Univ., Wuhan, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","3985","3988","There exist numerous image retrieval systems perform a fast similarity search in the image databases, but the quality of the outcomes provided by color histogram-based image search is usually rather limited. In this paper, an innovative approach based on blocking wavelet-histogram image similarity retrieval method and particle swam optimization (PSO), which is proposed as a solution to the problem of intelligent retrieval of images in large image databases. The problem is recast to a discrete optimization one, where a suitable speed and position of particle is defined through a customized PSO. Farther on, in virtue of the new computation model, a fitness function which combines blocking wavelet transformation information and the Euclidean distance of color histogram is constructed. The experimental results show that the proposed algorithm is feasible and effective to the similarity search in images database.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455289","","Content based retrieval;Data engineering;Euclidean distance;Histograms;Image databases;Image retrieval;Information retrieval;Iterative algorithms;Optimization methods;Particle swarm optimization","image colour analysis;image retrieval;particle swarm optimisation;wavelet transforms","Euclidean distance;adaptive particle swarm optimization;blocking wavelet transformation;blocking wavelet-histogram image similarity retrieval;color histogram;customized PSO;discrete optimization;fitness function;image retrieval system;image search;intelligent image retrieval;large image database;similarity search","","0","","7","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"The Architecture of Centralized Access Control Proxy Server Based on NETCONF","F. Wang; B. Zhang; G. Li; J. Guo; Y. Li; X. Gao","Pattern Recognition & Intell. Syst. Lab., Beijing Univ. of Post & Telecommun., Beijing, China","2010 International Conference on Measuring Technology and Mechatronics Automation","20100506","2010","3","","810","813","NETCONF is a new protocol as the network becomes more and more complexity, which has a better capability administering lots of devices. However, the large scale network brings some trouble for implementing access control especially when administers need to deploy or update policies on each devices. In this regard, the architecture of centralized access control proxy server based on NETCONF is focused, which realizes policies management and authorization centralized and raises administration efficiency. In order to figure it out absolutely, we present the basic theory giving the detailed illustration about components of the architecture. Finally, we describe how dose the architecture work based on NETCONF.","2157-1473;21571473","Electronic:978-1-4244-5739-7; POD:978-1-4244-5001-5","10.1109/ICMTMA.2010.533","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5458859","Access Control;Architecture;Centralized;NETCONF","Access control;Access protocols;Authentication;Authorization;Automation;Certification;Information retrieval;Mechatronics;Network servers;Transport protocols","access control;access protocols;telecommunication security","NETCONF;centralized access control;proxy server","","0","","6","","","13-14 March 2010","","IEEE","IEEE Conference Publications"
"Modelling Parallel Texts for Boosting Compression","J. Adiego; M. A. Mart√≠nez-Prieto; J. E. Hoyos-Tor√≠o; F. S√°nchez-Mart√≠nez","Dept. de Inf., Univ. de Valladolid, Valladolid, Spain","2010 Data Compression Conference","20100422","2010","","","517","517","Bilingual parallel corpora, also known as bitexts, convey the same information in two different languages. This implies that to model a bitext we can take advantage of the translation relationship that exists between the two texts; the text alignment task makes it possible to establish such a translation relationship. A biword is defined as a pair of words, each from a different text, that are mutual translations in the bitext; the use of biwords allows both texts in the bitext to be represented on a single model. Several biword-based schemes have been proposed leading to good compression ratios. Bearing in mind Melamed's affirmation which states that ""the translation of a text into another language can be viewed as a detailed annotation of what that text means"", we propose a new model for bitexts in agreement with this affirmation, dubbed MAR. The idea is to represent the words in the right text with respect to the preceding word in the left text; thus, a first-order model based on alignment relationships is proposed.","1068-0314;10680314","Electronic:978-1-4244-6426-5; POD:978-1-4244-6425-8","10.1109/DCC.2010.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453473","Bitext Compression;Compression Boosting;PPM","Boosting;Data compression;Dictionaries;Information retrieval","data compression;text analysis","bilingual parallel corpora;bitext;biword-based scheme;boosting compression;parallel text;text alignment task","","0","","2","","","24-26 March 2010","","IEEE","IEEE Conference Publications"
"Text Clustering Based on Key Phrases","A. Wang; Y. Li; W. Wang","Key Lab. of Complex Syst. & Intell. Sci., Chinese Acad. of Sci., Beijing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","986","989","Text clustering is a hot and essential topic in data mining and information retrieval. This paper proposed a KP-FCM clustering method, which used the key phrases as text features and applied the Fuzzy c-means (FCM) as clustering algorithm. In this method, key phrases were extracted by an algorithm based on suffix array. Experimental results on two standard text clustering benchmark corpuses, OHSUMED (English) and the SOGOU corpus (Chinese) showed that this KP-FCM algorithm outperformed STC-10, Lingo in terms of overall precision, overall recall and overall F-Measure. This indicated that the approach is very effective both in English and Chinese environments. And what's more, since this method was based on key phrases, it could get a readable label of each cluster, which would make the users browse online web search results or volume files more conveniently.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1163","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455626","","Clustering algorithms;Clustering methods;Data engineering;Data mining;Information retrieval;Information science;Intelligent systems;Laboratories;Natural languages;Web search","Internet;fuzzy set theory;pattern clustering;text analysis","KP-FCM clustering method;OHSUMED;SOGOU corpus;data mining;fuzzy c-means;information retrieval;online Web search;suffix array;text clustering;text features","","1","","7","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Database Management and Data Processes of Environmental Observations","D. An","Key Lab. of MOE for Geomechanics & Embankment Eng., Hohai Univ., Nanjing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","4819","4822","It has become increasingly pressing to build a database managing environmental observations for common media, e.g., water, soil and waste streams. Such management enables samples collected in a single domain and characterized in a succinct and straightforward means. An MS-Access based database is described in this paper to demonstrate a robust manner informatively managing environmental observations. The database includes typical functions that a database processes, e.g., data entering, browsing, and filtering, and spans a range of analytes which are regulated in common environmental regulations. The database forms a platform featuring the storage, retrieval, input & output of environmental observations. Besides the data management, processes of observation data are presented as well, including the data characteristics, distributions, challenges and methods. Many illustrations are presented to depict the database uses and data processes. The contents help build a prospective tool kit favoring regulatory authorities, env-statisticians, characterization and remediation professionals in environmental communities. Use of the tool kit would eventually improve the regulatory compliance procedure and environmental impact assessment of any environmental medium, and thus play a role in decision-making about the medium's destination.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.450","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455566","","Decision making;Environmental management;Filtering;Information retrieval;Pressing;Robustness;Soil;Spatial databases;Streaming media;Waste management","database management systems;decision making;environmental engineering","MS-Access based database;database management;database processes;decision making;environmental regulations;regulatory authorities;statistics","","0","","5","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"A novel MIR framework and application with automatic voice processing, database construction and fuzzy matching","Peng Li; Xuesong Wang; Nansha Li; Xiaofeng Wang; Lizhi Xie; Mingquan Zhou","Virtual Reality and Visualization Technology Institute, Beijing Normal University, China","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","1","","20","24","In this paper, we present a music information retrieval system which enables users to retrieve music by vocal query. Three essential components are query processing, database construction by MIDI and an approximate search engine. For query processing, we have achieved a real-time and robust voice-to- melody converter. For database construction, proposed MIDI analysis methods to obtain music melody features from MIDI files automatically. In order to match query with melodies in database, we extend an existing search engine into a fast approximate melodic matching engine. We have carried out extensive experiments on the prototype system to evaluate the performance. The results show that the proposed three components are achieving good performance.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5452008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452008","‚ÄúCabinet‚Äù Post-treatment;MIR;Melodic Matching;Pitch Extraction;Vocal Query","Content based retrieval;Educational institutions;Educational technology;Frequency;Information science;Matched filters;Music information retrieval;Query processing;Search engines;Spatial databases","audio databases;fuzzy set theory;music;query processing;speech processing","MIDI;MIR application;MIR framework;automatic voice processing;database construction;fuzzy matching;information retrieval system;query processing;robust voice-to- melody converter;search engine","","0","","30","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Cleansing uncertain databases leveraging aggregate constraints","H. Chen; W. S. Ku; H. Wang","Dept. of Computer Science and Software Engineering, Auburn University, USA","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","128","135","Emerging uncertain database applications often involve the cleansing (conditioning) of uncertain databases using additional information as new evidence for reducing the uncertainty. However, past researches on conditioning probabilistic databases, unfortunately, only focus on functional dependency. In real world applications, most additional information on uncertain data sets can be acquired in the form of aggregate constraints (e.g., the aggregate results are published online for various statistical purposes). Therefore, if these aggregate constraints can be taken into account, uncertainty in data sets can be largely reduced. However, finding a practical method to exploit aggregate constraints to decrease uncertainty is a very challenging problem. In this paper, we present three approaches to cleanse (condition) uncertain databases by employing aggregate constraints. Because the problem is NP-hard, we focus on the two approximation strategies by modeling the problem as a nonlinear optimization problem and then utilizing Simulated Annealing (SA) and Evolutionary Algorithm (EA) to sample from the entire solution space of possible worlds. In order to favor those possible worlds holding higher probabilities and satisfying all the constraints at the same time, we define Satisfaction Degree Functions (SDF) and then construct the objective function accordingly. Subsequently, based on the sample result, we remove duplicates, re-normalize the probabilities of all the qualified possible worlds, and derive the posterior probabilistic database. Our experiments verify the efficiency and effectiveness of our algorithms and show that our approximate approaches scale well to large-sized databases.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452733","","Aggregates;Application software;Asia;Computer science;Databases;Equations;Information retrieval;Remuneration;Software engineering;Uncertainty","computational complexity;evolutionary computation;simulated annealing;statistical databases;uncertainty handling","NP hard problem;aggregate constraints;evolutionary algorithm;nonlinear optimization problem;objective function;satisfaction degree functions;simulated annealing;uncertain databases cleansing","","0","","20","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Subspace similarity search using the ideas of ranking and top-k retrieval","T. Bernecker; T. Emrich; F. Graf; H. P. Kriegel; P. Kr√∂ger; M. Renz; E. Schubert; A. Zimek","Institut f&#252;r Informatik, Ludwig-Maximilians Universit&#228;t M&#252;nchen","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","4","9","There are abundant scenarios for applications of similarity search in databases where the similarity of objects is defined for a subset of attributes, i.e., in a subspace, only. While much research has been done in efficient support of single column similarity queries or of similarity queries in the full space, scarcely any support of similarity search in subspaces has been provided so far. The three existing approaches are variations of the sequential scan. Here, we propose the first index-based solution to subspace similarity search in arbitrary subspaces which is based on the concepts of nearest neighbor ranking and top-k retrieval.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452771","","Acceleration;Clustering algorithms;Data structures;Image databases;Information retrieval;Nearest neighbor searches;Particle measurements;Shape","database management systems;indexing;query formulation","databases;index-based solution;nearest neighbor ranking;single column similarity query;subspace similarity search;top-k retrieval","","3","","19","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Optimization of Overlapped Tiling for Efficient 3D Image Retrieval","Z. Fan; A. Ortega","Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","2010 Data Compression Conference","20100422","2010","","","494","503","Remote visualization of an arbitrary 2-D planar ""cut"" from a large volumetric dataset with random access has both gained importance and posed significant challenges over the past few years in industrial and medical applications. In this paper, a prediction model is presented that relates transmission efficiency to voxel coverage statistics for a fast random 2-D image retrieval system. This model can be for parameter selection and also provides insights that lead us to propose a new 3D rectangular tiling scheme, which achieves an additional 10% - 30% reduction in average transmission rate as compared to our previously proposed technique, e.g.,a nearly 30%/45% reduction in the average transmission rate at the cost of a factor of ten/fifteen in storage overhead compared to traditional cubic tiling. Furthermore, this approach leads to improved random access, with less storage and run-time memory required at the client.","1068-0314;10680314","Electronic:978-1-4244-6426-5; POD:978-1-4244-6425-8","10.1109/DCC.2010.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453471","","Biomedical imaging;Data compression;Data visualization;Image retrieval;Information retrieval;Predictive models;Runtime;Signal processing;Three dimensional displays;Tiles","data visualisation;image retrieval;optimisation","3D image retrieval;arbitrary 2-D planar cut;average transmission rate;datasets;overlapped tiling optimization;prediction model;remote visualization;transmission efficiency;volumetric dataset","","2","","11","","","24-26 March 2010","","IEEE","IEEE Conference Publications"
"Condensed semantic tree model for image category representation","Mianshu Chen; Ping Fu; Yong Li; Huiyuan Tan","School of Communication Engineering, Jilin University, Changchun, China","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","4","","358","362","This paper presents a condensed semantic tree model for representing image category. For a specific application area, a semantic concept space is defined. According to the annotation for an image, a real-value semantic vector is gained that describes the content of it. In order to represent image category, condensed semantic tree model is introduced. It is a triple level structure. The bottom level is a semantic concept mask, which selects those concepts relevant to semantic category. The middle level is composed of three semantic modules, which extract high-level semantic of an image. The top level analyzes the probability that an image is belong to a specific image category. Every semantic category has different model configuration. The experimental results illustrate that the effectiveness of the proposed condensed semantic tree model is good.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451664","image category;semantic tree model;semantic vector","Content based retrieval;Image analysis;Image databases;Image retrieval;Information retrieval;Labeling;Ontologies;Probability;Statistical learning;Support vector machines","image representation;trees (mathematics)","condensed semantic tree model;high-level semantic;image annotation;image category representation;real-value semantic vector;semantic concept mask;semantic concept space","","1","","8","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Using content based image retrieval techniques for the indexing and retrieval of Thai handwritten documents","S. Sangsawad; Chun Che Fung","School of Information Technology, Murdoch University, Perth, Australia","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","1","","98","101","This paper proposes the use of content base image retrieval (CBIR) techniques for indexing and retrieval of handwritten documents in Thai language. Issues associated with Thai handwritten documents are the lack of spacing between words, multi-level alphabets and different writing styles. This causes low recognition rate based on automated techniques such as Optical Character Recognition (OCR). This paper also examined off-line signature recognition techniques in order to adapt to Thai handwriting system for matching data. The objective of the proposal is to develop a semiautomated method to index and retrieve Thai handwritten documents based on sampled keywords by combining CBIR and signature recognition techniques.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451992","CBIR;Thai handwritten document;sampled keywords;signture recognition","Character recognition;Content based retrieval;Handwriting recognition;Image retrieval;Image segmentation;Indexing;Information retrieval;Information technology;Optical character recognition software;Writing","content-based retrieval;document image processing;image retrieval;natural language processing;optical character recognition","Thai handwritten documents;Thai language;content based image retrieval;indexing;multilevel alphabets;off-line signature recognition;optical character recognition;writing styles","","0","","21","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"On Web Page extraction based on position of DIV","Xunhua Liu; Hui Li; Dan Wu; Jiaqing Huang; Wei Wang; Li Yu; Ye Wu; Hengjun Xie","Key Laboratory of Integrated Microsystem Science and Engineering Applications, Shenzhen Graduate School of Peking University, 518055 China","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","4","","144","147","For the popular DIV page layout in Web Pages, this paper presents a method based on the position of DIV to extract main text from the body of Web pages by reconstructing, remaining atomic DIV and analyzing DIV position. Experiments showed that the accuracy rate of extraction can reach more than 90%, with a high versatility and accuracy.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451751","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451751","DIV position analysis;main text of web page;web information extraction","Cascading style sheets;Containers;Data mining;HTML;Information analysis;Information retrieval;Microelectronics;Standards publication;Telecommunications;Web pages","Internet;information filtering;text analysis","DIV page layout;Web page extraction;text extraction","","2","","10","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"An integrated method for video shot boundary detection","L. Zhu; J. Qu; M. A. Rahman; W. Hong","College of Information and Mathematical Sciences, Clayton State University 2000 Clayton State Blvd, Morrow, GA 30260, U.S.A.","Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon)","20100422","2010","","","151","154","Video shot boundary detection, which segments a video by detecting boundaries between camera shots, is usually the first and important step for content-based video retrieval. This paper investigates methods which are effective in detecting abrupt transitions and gradual transitions, respectively, and proposes an integration scheme to combine their results, aiming to detect both types of transitions.","1091-0050;10910050","Electronic:978-1-4244-5853-0; POD:978-1-4244-5854-7","10.1109/SECON.2010.5453813","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453813","abrupt transitions;cuts;dissolves;fades;gradual transitions;video shot boundary detection;wipes","Cameras;Content based retrieval;Gunshot detection systems;Histograms;Humans;Image segmentation;Information retrieval;Layout;Video sharing;YouTube","video retrieval","camera shots;content-based video retrieval;video shot boundary detection","","3","","11","","","18-21 March 2010","","IEEE","IEEE Conference Publications"
"Dynamic regulation of index implementation for flash memory storages","Rize Jin; Tae-Sun Chung","College of Information Technology, Ajou University, Suwon, Republic of Korea","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","2","","325","328","Hard disk is gradually replaced by flash memory for its mechanical constraints. And with increase of capacity of flash memory, a large-scale database is able to run it. But the frequent changes of index structure can degrade the performance of flash memory and reduction of service life. Most previous works considered the characteristics of flash memory and improved the performance to some extent. In this paper, we first analyze two representative mechanisms which are suitable to write-oriented and read-oriented workload, respectively. And we pointed out the drawbacks of them. Then we propose a dynamic regulation algorithm for utilizing the superiority of both two mechanisms. With simulation, we can see that the proposed methodology could significantly enhance the efficiency of using index on flash memory storages.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451529","R-tree;dynamic regulation;embedded systems;flash memory;index structure","Earth;Electric shock;Energy consumption;Flash memory;Hard disks;Heuristic algorithms;Indexes;Information retrieval;Large-scale systems;Spatial databases","flash memories","dynamic regulation algorithm;flash memory storages;hard disk;index structure;large-scale database;read-oriented workload;service life","","0","","10","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"The Animation and Comics Content Retrieval Model Based on Analysis of Clustered Group","X. Lu; M. Q. Zhang","Sch. of Comput. Sci. & Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","2010 International Conference on Biomedical Engineering and Computer Science","20100506","2010","","","1","4","In content-based multimedia data retrieval model, relying solely on cluster analysis blind search retrieval model has poor robustness, low recall rate problems. In order to address these problems, this paper proposed a new retrieval model for multimedia material. Combining with the features of animation and comics material, the model introduces a clustered group analyzing method which obeys the instruction of background-knowledge. Utilizing the clustered group, we can extract the effective semantic character of objective image. It aims to realize robustness, low-dimension and rapidly-converging so as to achieve high-quality retrieval.","2165-9192;21659192","Electronic:978-1-4244-5316-0; POD:978-1-4244-5315-3","10.1109/ICBECS.2010.5462355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5462355","","Animation;Clustering methods;Computer science;Content based retrieval;Eyes;Image databases;Information retrieval;Materials science and technology;Robustness;Spatial databases","computer animation;content-based retrieval;feature extraction;image retrieval;multimedia systems","animation;background-knowledge;clustered group;comics;content-based multimedia data retrieval model;high-quality retrieval;multimedia material;objective image;semantic character extraction","","1","","7","","","23-25 April 2010","","IEEE","IEEE Conference Publications"
"A statistical approach on Persian word sense disambiguation","M. Soltani; H. Faili","Department of ECE, University of Tehran, Tehran, Iran","2010 The 7th International Conference on Informatics and Systems (INFOS)","20100506","2010","","","1","6","This article studies different aspect of a new approach for resolving lexical ambiguities using statistical information gained from a monolingual corpus. The proposed approach resolves the problem of target word selection in an machine translation system. This Method is an unsupervised graph-based approach which uses a bilingual dictionary to find all possible translations of each ambiguous word in the source sentence (English) and then chooses the most appropriate alternative regarding the statistical information gathered from target language (Persian) corpora. Also, two new methods to measure the semantic similarity based on source and target language corpora are introduced. The experiments show that the unsupervised graph-based WSD which uses the proposed semantic similarity measures in the dependency graph outperforms all other methods on WSD for translating English to Persian words, significantly.","","Electronic:978-977-403-396-4; POD:978-1-4244-5828-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461799","Centrality Algorithms;Mutual Information;Persian Language;Word Sense Disambiguation;graph","Bioinformatics;Computational linguistics;Dictionaries;Humans;Information retrieval;Mutual information;Natural language processing;Natural languages;Semantic Web;Text mining","language translation;natural language processing;statistical analysis","Persian word sense disambiguation;bilingual dictionary;machine translation system;monolingual corpus;semantic similarity;statistical approach;target language corpora;unsupervised graph-based approach","","0","","15","","","28-30 March 2010","","IEEE","IEEE Conference Publications"
"Kernelized locality-sensitive hashing for scalable image search","B. Kulis; K. Grauman","UC Berkeley EECS and ICSI, CA 94720, USA","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","2130","2137","Fast retrieval methods are critical for large-scale and data-driven vision applications. Recent work has explored ways to embed high-dimensional features or complex distance functions into a low-dimensional Hamming space where items can be efficiently searched. However, existing methods do not apply for high-dimensional kernelized data when the underlying feature embedding for the kernel is unknown. We show how to generalize locality-sensitive hashing to accommodate arbitrary kernel functions, making it possible to preserve the algorithm's sub-linear time similarity search guarantees for a wide class of useful similarity functions. Since a number of successful image-based kernels have unknown or incomputable embeddings, this is especially valuable for image retrieval tasks. We validate our technique on several large-scale datasets, and show that it enables accurate and fast performance for example-based object classification, feature matching, and content-based retrieval.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459466","","Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;Kernel;Large-scale systems;Object recognition;Spatial databases;Visual databases","file organisation;image classification;image retrieval","data driven vision application;example based object classification;fast retrieval method;generalize locality sensitive hashing;high dimensional kernelized data;image retrieval;kernelized locality sensitive hashing;low dimensional Hamming space;scalable image search;sublinear time similarity search","","211","7","34","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"Learning actions from the Web","N. Ikizler-Cinbis; R. Gokberk Cinbis; S. Sclaroff","Computer Science Department, Boston University, MA, USA","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","995","1002","This paper proposes a generic method for action recognition in uncontrolled videos. The idea is to use images collected from the Web to learn representations of actions and use this knowledge to automatically annotate actions in videos. Our approach is unsupervised in the sense that it requires no human intervention other than the text querying. Its benefits are two-fold: (1) we can improve retrieval of action images, and (2) we can collect a large generic database of action poses, which can then be used in tagging videos. We present experimental evidence that using action images collected from the Web, annotating actions is possible.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459368","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459368","","Computer science;Humans;Image recognition;Image retrieval;Information retrieval;Legged locomotion;Search engines;Videos;Vocabulary;YouTube","Internet;image recognition;image retrieval;learning (artificial intelligence)","Web;action images retrieval;action representations;generic database;generic method;human action recognition;human intervention;text querying;uncontrolled videos;unsupervised learning;video tagging","","36","5","28","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"A Personalized Search Engine Using Ontology-Based Fuzzy Concept Networks","F. Akhlaghian; B. Arzanian; P. Moradi","Dept. of Electr. Eng., Univ. of Kurdistan, Sanandaj, Iran","2010 International Conference on Data Storage and Data Engineering","20100422","2010","","","137","141","Nowadays, personalization of search engines as the only web search tools plays important role in increasing the speed of access to web information. Since the users may have diverse backgrounds and expectations for a given query, personalization of search engines results based on user's profile can help to better match the overall interests of an individual user. In this paper we personalize the search engine results using the automatic fuzzy concept networks. Our main idea is to employ the concepts of ontology in order to enrich the common fuzzy concept networks built based on user's profile. Experimental results indicate improvement in personalized search engine results using enriched fuzzy concept networks comparing to common fuzzy concept networks.","","Electronic:978-1-4244-5679-6; POD:978-1-4244-5678-9","10.1109/DSDE.2010.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452618","Fuzzy Concept Networks;Ontolgy;Search Engine;User Profiles;Web Personalization","Boolean functions;Fuzzy logic;Fuzzy set theory;Fuzzy systems;Information retrieval;Memory;Ontologies;Query processing;Search engines;Web search","fuzzy set theory;ontologies (artificial intelligence);query processing;search engines","Web information;Web search tools;fuzzy set theory;ontology based automatic fuzzy concept networks;personalized search engine;query processing;user profiles","","4","","12","","","9-10 Feb. 2010","","IEEE","IEEE Conference Publications"
"Semantic domain specific search engine","B. H. Chandrashekar; G. Shobha.","Department of Master of Computer Applications, R.V.College of Engineering, Bangalore 560059, India","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","2","","669","672","The World-Wide-Web (WWW) is growing exponentially and has become increasingly difficult to retrieve relevant information on the web. The rapid growth of the WWW poses unprecedented scaling challenges for general purpose crawlers and search engines. In this paper we describe a new hypertext resource discovery system called topic specific crawler. The goal of this crawler is to selectively seek out pages that are relevant to a predefined set of topics, rather than collecting and indexing all accessible web documents to be able to answer all possible ad-hoc queries. A topic specific crawler analyses its crawl boundary to find the links that are likely to be most relevant for the crawl. This leads to significant savings in hardware and network resources, and helps keep the crawl more up-to-date.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451718","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451718","Internet;WebCrawler;domain;lexicon;webpage","Computer applications;Computer science;Crawlers;Hardware;Indexing;Information retrieval;Internet;Search engines;Uniform resource locators;World Wide Web","Internet;information retrieval;online front-ends;search engines","WebCrawler;World-Wide-Web;crawl boundary;hypertext resource discovery system;semantic domain specific search engine;topic specific crawler","","1","","9","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"A novel approach to solve the sparsity problem in collaborative filtering","J. Zhou; T. Luo","","2010 International Conference on Networking, Sensing and Control (ICNSC)","20100506","2010","","","165","170","Collaborative Filtering (CF) is the most successful approach of Recommender System. Although it has made significant progress over the last decade, the current CF method is stressed by the sparsity problem. In this paper we propose a novel approach to address this issue. Multiple Imputation (MI) is a useful statistic strategy for dealing with data sets with missing values and replace each missing value with a set of plausible values that represent the uncertainty about the right value. In our approach we apply MI technique in the data processing procedure to turn the original sparse data into dense data. And then we use the dense data and the original data in the following CF progress separately. We compare their performance both in cosine-based and correlation-based similarity measures. We conduct a 10-fold cross validation and take the MAE as the evaluation metrics. Our experimental results show that our approach can efficiently solve the extreme sparsity problem, and provide better recommendation results than traditional CF method.","","Electronic:978-1-4244-6453-1; POD:978-1-4244-6450-0","10.1109/ICNSC.2010.5461512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461512","Collaborative Filetring;Mutiple Imputaion;Recommender Systems","Books;Collaboration;Collaborative work;Data processing;Information filtering;Information filters;Information retrieval;Recommender systems;Statistics;Uncertainty","information filtering;recommender systems;statistical analysis","collaborative filtering;correlation-based similarity measures;cosine-based similarity measures;data processing procedure;multiple imputation statistic strategy;recommender system;sparsity problem solving","","2","","22","","","10-12 April 2010","","IEEE","IEEE Conference Publications"
"A Survey Analysis of the Employment Situation and Intentions of E-Commerce Graduates","Y. Wang; A. Chen; X. Wang","Sch. of Traffic & Transp., Beijing Jiaotong Univ., Beijing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","2833","2836","The paper analyses the employment situation of domestic E-Commerce (EC) graduates, especially the EC graduates between 2005 and 2008 in Beijing Jiaotong University, through researching the available literature, questionnaire, interview and mathematical statistics. It also includes a survey covers the EC undergraduates in Beijing Jiaotong University ranging from the class of 2005 to the class of 2007, while mainly focus on employment objectives, ideal salary and required qualities. Meanwhile, after an exhaustive analysis of the problems exposed from that survey, the paper also provides some suggestions concerning how to promote the employment.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.190","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455670","","Databases;Educational institutions;Employment;Information analysis;Information retrieval;Information science;Personnel;Remuneration;Statistical analysis;Transportation","computer science education;electronic commerce;employment;salaries","Beijing Jiaotong University;e-commerce graduates;employment situation;mathematical statistics;survey analysis","","0","","7","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Bibliometric Study Based on ESI: Taking Material Science as Example","J. Qiu; R. Yang","Center for Studies of Inf. Resources, Wuhan Univ., Wuhan, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","4626","4630","This paper makes a bibliometric study of the articles on material science in ESI with a special emphasis on the distribution of countries, institutions, journals and scientists of high productivity and impact. It also analyzes the journals and scientists with highly cited papers and hot papers on material science. Finally, the co-citation analysis on the highly cited authors is conducted by SPSS so as to provide the hotspots and scientists' clusters on material science in recent 11 years. And some conclusions are got in this study.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454972","","Bibliometrics;Data engineering;Information analysis;Information resources;Information retrieval;Information science;Materials science and technology;Productivity;Visual databases;Visualization","information analysis","ESI;SPSS;bibliometric study;cocitation analysis;material science","","0","","6","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Hybrid text mining model for document classification","K. A. Vidhya; G. Aghila","Department of Computer Science, Pondicherry University, India","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","1","","210","214","This work proposes a hybrid model for text document classification for information retrieval using Naive Bayes and Rough set theory. Rough set theory is used for feature reduction and Naive Bayes theorem is used for classification of documents into the predefined categories by means of the probabilistic values. The deployment of the proposed model is planned through an enhanced method of the utilization of the Naive Bayes approach and rough set theory to overcome the imprecision and vagueness in data set thus improving the classification accuracy. In Naive Bayes model, the word probabilities for a class are estimated by calculating the likelihood in the entire training documents where the training and test data are split randomly into k-subsets like 2/3 for training and 1/3 for test data. In addition, it also utilizes two level hierarchy structures for training documents like features from title, keywords and content with the predefined knowledge available. The rough set model includes the feature reduction technique through which the number of features for classification is reduced aiming at an optimal classification of text document.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451965","Feature Reduction;Feature Selection;Na√Øve Bayes;Rough sets;Text Mining","Computer science;Data mining;Information retrieval;Machine learning;Machine learning algorithms;Probability;Rough sets;Set theory;Testing;Text mining","Bayes methods;classification;data mining;information retrieval;probability;rough set theory;text analysis","feature reduction;hybrid text mining model;information retrieval;naive Bayes;probabilistic value;rough set theory;text document classification;training document;word probability","","2","","22","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Feature Selection with Maximum Information Metric in Text Categorization","H. Wang; L. Han; X. Zeng; Z. Zhen","Dept. of Math., Tonghua Normal Univ., Tonghua, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","857","860","Text categorization usually suffers from a huge-scale number of features. Most of those are irrelevant and noise which could mislead the classifier. In order to improve the efficiency and effectiveness for text categorization, feature selection is often performed. In this paper, a novel feature selection approach for dealing with text categorization, called Maximum Information Metric (MIM), is proposed to get good quality terms of documents. This method exploits the weight of term and document frequency to construct the correlation between a term and each class. It aims to maximize the differences of term over each class based on information theory. We design a better evaluation function to yield a kind of ranking of the features. Experimental results on the standard Reuters-21578 and 20-Newsgroups corpus show that the new feature selection approach outperforms the classic methods including Information Gain (IG), Chi-square statistic (CHI) in a context of text categorization.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454885","","Computer science;Educational institutions;Information filtering;Information filters;Information retrieval;Information science;Information theory;Mathematics;Statistics;Text categorization","document handling;feature extraction;information retrieval;information theory;text analysis","20-Newsgroups corpus;Chi-square statistic;Information Gain;classifier;document frequency;evaluation function;feature selection;huge-scale number;information theory;maximum information metric;standard Reuters-21578;term weight;text categorization","","1","","18","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Query an Image Database by Segmentation and Content","E. Castillo Ju√°rez; I. H. Pineda Torres; M. J. Somodevilla; M. Mart√≠n Ort√≠z","Fac. de Cienc. de la Comput., Univ. Autonoma de Puebla (BUAP), Puebla, Mexico","2009 Mexican International Conference on Computer Science","20100422","2009","","","127","134","The Recent advances on image databases have been developed and most of them consider several methods to query image, the amount of information stored is so big that it is a must to use a combination of different techniques such as image segmentation in order to reduce the dimensionality of the search space. Taking advantage of an image pictographic expressiveness together with the soundness of image segmentation methods, it is possible to rely on an efficient method to query an image database. In this work, it is proposed a new method of image segmentation, indexation and retrieval by content. In this paper an image is not considered as a set of objects, is considered as a feature vector where its components represent a segment of color. Color is treated in another color space rather than to work on RGB space. For each image a fuzzy histogram is obtained in order to get for each image its own signature together whit its own feature vector. Fuzzy theory is applied to solve color uncertainty, which it comes from color quantification and human perception of colors. The whole set of images, which are in RGB representation are transformed to LAB model, obtaining better color representation in order to obtain a feature vector together with wavelet coefficients.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452546","","Color;Content based retrieval;Data mining;Histograms;Humans;Image databases;Image retrieval;Image segmentation;Information retrieval;Space technology","fuzzy set theory;image colour analysis;image segmentation;visual databases;wavelet transforms","LAB model;RGB representation;RGB space;color quantification;fuzzy histogram;fuzzy theory;image database;image segmentation;pictographic expressiveness","","0","","11","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Keyword based search over semantic data in polynomial time","P. Cappellari; R. De Virgilio; A. Maccioni; M. Miscione","Department of Computing Science, University of Alberta, Canada","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","203","208","In pursuing the development of Yanii, a novel keyword based search system on graph structures, in this paper we present the computational complexity study of the approach, highlighting a comparative study with actual PTIME state-of-the-art solutions. The comparative study focuses on a theoretical analysis of different frameworks to define complexity ranges, which they correspond to, in the polynomial time class. We characterize such systems in terms of general measures, which give a general description of the behavior of these frameworks according to different aspects that are more general and informative than mere benchmark tests on a few test cases. We show that Yanii holds better performance than others, confirming itself as a promising approach deserving further practical investigation and improvement.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452697","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452697","","Benchmark testing;Buildings;Computational complexity;Database languages;Database systems;Information retrieval;Polynomials;System testing;Tree graphs;XML","computational complexity;data handling;graph theory;polynomials","graph structures;keyword based search system;polynomial time;semantic data","","2","","9","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Noise removing from Web pages using neural network","T. Htwe; K. H. S. Hla","University of Computer Studies, Yangon, Myanmar","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","1","","281","285","With the exponentially growing amount of information available on the Internet, an effective technique for users to discern the useful information from the unnecessary information is urgently required. Cleaning web pages for web data extraction becomes critical for improving performance of information retrieval and information extraction. So, we investigate to remove various noise patterns in Web pages instead of extracting relevant content from Web pages to get main content information. In this paper, we propose an approach that detect multiple noise patterns and remove these noise patterns from Web pages of any Web sites. The method first build DOM tree for any Web page. Our approach is based on the basic idea of Case-Based Reasoning (CBR) to find noise pattern in current Web page by matching similar noise pattern kept in Case-Based. We also apply a back propagation neural network algorithm to classify the stored various noise patterns by matching similar noise data in current Web page. We have implemented our method on several commercial Web sites and News Web sites to evaluate the performance and improvement of our approach. Experiments show that results leads to a more accurate and effectiveness of the approach.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451952","DOM;Noise detection;information extraction;neural network;noise elimination","Cleaning;Computer networks;Content based retrieval;Data mining;IP networks;Information retrieval;Navigation;Neural networks;Pattern matching;Web pages","Internet;backpropagation;case-based reasoning;information retrieval;interference suppression;neural nets","DOM tree;Internet;Web data extraction;Web pages noise removing;Web sites;back propagation neural network algorithm;multiple noise pattern detection;noise case based reasoning","","1","","14","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Inverted Index Compression for Scalable Image Matching","D. M. Chen; S. S. Tsai; V. Chandrasekhar; G. Takacs; R. Vedantham; R. Grzeszczuk; B. Girod","Dept. of Electr. Eng., Stanford Univ., Stanford, CA, USA","2010 Data Compression Conference","20100422","2010","","","525","525","In this paper, they address a key challenge for scaling image search up to larger databases: the amount of memory consumed by the inverted index. In a VT-based image retrieval system, the most memory-intensive structure is the inverted index. For example, in a database of one million images where each image contains hundreds of features, the inverted index consumes 2.5 GB of RAM. Such large memory usage limits the ability to run other concurrent processes on the same server, such as recognition systems for other databases. A memory-congested server can exhibit swapping between main and virtual memory, which significantly slows down all processes.","1068-0314;10680314","Electronic:978-1-4244-6426-5; POD:978-1-4244-6425-8","10.1109/DCC.2010.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453502","entropy coding;image retrieval;inverted index;local features;vocabulary tree","Decoding;Delay;Image coding;Image databases;Image matching;Indexes;Information retrieval;Intrusion detection;Random access memory;Spatial databases","data compression;image coding;image matching;image retrieval;visual databases","RAM;databases;image retrieval system;inverted index compression;main memory;memory-congested server;memory-intensive structure;recognition systems;scalable image matching;virtual memory;vocabulary tree","","23","1","","","","24-26 March 2010","","IEEE","IEEE Conference Publications"
"Midas for government: Integration of government spending data on Hadoop","A. Sala; C. Lin; H. Ho","University of Modena and Reggio Emilia, Via Vignolese 905, 41100 Modena, Italy","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","163","166","We describe our experience in developing a Hadoop based integration flow to collect and integrate publicly available government datasets related to government spending. The objective is to enable users, U.S. taxpayers in this case, to easily access the data their government discloses on the web in different websites. We also provide users with easy-to-use tools to query and explore this data to gather information from the integrated data that allows for evaluation of how tax money is spent.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452758","","Aggregates;Contracts;Data mining;Database languages;File systems;Information retrieval;Libraries;US Government;User interfaces;Web pages","Web sites;government data processing","Hadoop based integration flow;Midas;Web sites;World Wide Web;data query;government datasets;government spending data;tax money","","1","","9","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Meaningful Interrelated Object Tree for XML keyword search","U. Supasitthimethee; M. Yoshikawa; T. Shimizu; K. Porkaew","School of Information Technology, King Mongkut's University of Technology Thonburi, Thailand","2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)","20100419","2010","1","","339","344","In the research field of XML retrieval with keyword-based approach, a variant of Lowest Common Ancestors (LCAs) have been widely accepted to provide how keywords are connected by ancestor relationship. However, returning a whole subtree or a partial subtree based on LCA nodes is insufficient for identifying how subtrees are conceptually related under different tree structure such as ID/IDREF. On the other hand, storing XML documents in the graph model can define richer relationships that the tree model cannot but the cost of enumerating result is very high. In this paper, we propose a novel Smallest Lowest Object Tree (SLOT) which keywords are connected through physical connections. In addition, to capture conceptual connections, we also propose the Smallest Interrelated Object Tree (SIOT) which extends ID/IDREF relationships based on SLOT. Finally, our experiment indicates that the proposed approach returns more effective and more semantic results for users.","","Electronic:978-1-4244-5586-7; POD:978-1-4244-5569-0","10.1109/ICCAE.2010.5451940","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5451940","LCA;SIOT;SLOT;XML;interrelated object tree;keyword search","Costs;Database languages;Informatics;Information retrieval;Information technology;Keyword search;Solids;Tree data structures;Tree graphs;XML","XML;information retrieval;tree data structures","ID-IDREF;XML documents;XML keyword search;XML retrieval;graph model;lowest common ancestors;meaningful interrelated object tree;smallest interrelated object tree;smallest lowest object tree","","0","","21","","","26-28 Feb. 2010","","IEEE","IEEE Conference Publications"
"Query Optimization Using Case-Based Reasoning in Ubiquitous Environments","L. A. Mart√≠nez-Medina; C. Bibineau; J. L. Zechinelli-Martini","Res. Center in Inf. & Autom. Technol. CENTA, UDLA-P, Puebla, Mexico","2009 Mexican International Conference on Computer Science","20100422","2009","","","107","118","Query optimization is a widely studied problem, a variety of query optimization techniques have been suggested. These approaches are presented in the framework of classical query evaluation procedures that rely upon cost models heavily dependent on metadata (e.g. statistics and cardinality estimates) and that typically are restricted to execution time estimation. There are computational environments where metadata acquisition and support is very expensive. Additionally, execution time is not the only optimization objective of interest. A ubiquitous computing environment is an appropriate example where classical query optimization techniques are not useful any more. In order to solve this problem, this article presents a query optimization technique based on learning, particularly on case-based reasoning. Given a query, the knowledge acquired from previous experiences is exploited in order to propose reasonable solutions. It is possible to learn from each new experience in order to suggest better solutions to solve future queries.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452548","case-based reasoning;classical query optimization techniques;learning;metadata;similarity function;ubiquitous computing environment","Automation;Costs;Energy consumption;Energy storage;Information retrieval;Personal digital assistants;Pervasive computing;Query processing;Statistics;Ubiquitous computing","case-based reasoning;learning (artificial intelligence);meta data;query processing;ubiquitous computing","case-based reasoning;learning;metadata;query evaluation;query optimization;ubiquitous environment","","0","5","15","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Realization of Extended Functions of SIP-Based IP-PBX","J. Zhu; Z. Li; Y. Ma; Y. Huang","Dept. Comput. Sci. & Technol., Qiongzhou Univ., Sanya, China","2010 Second International Workshop on Education Technology and Computer Science","20100506","2010","3","","488","490","IP-PBX from SETA Company in Japan which is an IP phone switch system based on SIP (Session Initial Protocol), has realized both phone call and other related extensions. At the same time, kinds of incompatible problems concerning SIP phone on their extended functions exist, such as call hold while developing this IP-PBX. The characteristics of both IP-PBX call hold function and other kind of SIP phone is analyzed in details. A new solution is proposed through combining both SIP and its extended protocol, which is also realized functions of call hold and its retrieve, call park and its retrieve on kinds of SIP phone successfully.","","Electronic:978-1-4244-6389-3; POD:978-1-4244-6388-6","10.1109/ETCS.2010.384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5458619","IP-PBX;SIP;SIP phone;call hold;call park","Communications technology;Computer science;Computer science education;Educational technology;Mobile handsets;Multiaccess communication;Music information retrieval;Pressing;Protocols;Switches","Internet telephony;private telephone exchanges;signalling protocols","IP phone switch;IP-PBX;SIP phone;call hold function;call park;extended functions;session initial protocol","","0","","6","","","6-7 March 2010","","IEEE","IEEE Conference Publications"
"Effective XML Keyword Search Algorithm for Meaningful Return Information","H. Wu; Z. Tang","Sch. of Comput. Sci. & Technol., Nanjing Univ. of Sci. & Technol., Nanjing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","841","844","With the XML becomes a de-facto standard for exchanging and presenting information, the study on XML keyword search has become the focus of information retrieval. Several recent studies have finished the effective XML keyword search, but not all approach is effective in identifying return information, not all search result is satisfactory to user. In order to reduce the burden of user and satisfy user's requirement, in this paper, we construct a kind of specific data indexes, and propose an effective XML keyword search algorithm which is designed for meaningful and useful return information. A large number of experiments show that the algorithm is efficient and effective.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.530","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455699","","Algorithm design and analysis;Computer science;Data models;Database languages;Electronic mail;Information retrieval;Information science;Keyword search;Load management;XML","XML;information retrieval","XML keyword search algorithm;information retrieval;meaningful return information;specific data indexes","","0","","9","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Improving product search with economic theory","L. Beibei; P. G. Ipeirotis; A. Ghose","Department of Information, Operations & Management Sciences, Stern School of Business, New York University, 44 West 4th street, New York, NY 10012, USA","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","293","296","With the growing pervasiveness of the Internet, online search for commercial goods and services is constantly increasing, as more and more people search and purchase goods from the Internet. Most of the current algorithms for product search are based on adaptations of theoretical models devised for √Ç¬øclassic√Ç¬ø information retrieval. However, the decision mechanism that underlies the process of buying a product is different than the process of judging a document as relevant or not. So, applying theories of relevance for the task of product search may not be the best approach. We propose a theory model for product search based on expected utility theory from economics. Specifically, we propose a ranking technique in which we rank highest the products that generate the highest consumer surplus after the purchase. In a sense, we rank highest the products that are the √Ç¬øbest value for money√Ç¬ø for a specific user. Our approach naturally builds on decades of research in the field of economics and presents a solid theoretical foundation in which further research can build on. We instantiate our research by building a search engine for hotels, and show how we can build algorithms that naturally take into account consumer demographics, heterogeneity of consumer preferences, and also account for the varying price of the hotel rooms. Our extensive user studies demonstrate an overwhelming preference for the rankings generated by our techniques, compared to a large number of existing strong baselines.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452727","","Adaptation model;Business;Demography;Information management;Information retrieval;Multidimensional systems;Predictive models;Recommender systems;Search engines;Web and internet services","Internet;electronic commerce;information retrieval;purchasing","Internet;commercial goods;commercial services;economic theory;information retrieval;online search;product search improvement","","0","","11","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"An ontology-based retrieval system using semantic indexing","S. Kara; √ñ. Alan; O. Sabuncu; S. Akpinar; N. K. √ái√ßekli; F. N. Alpaslan","Orbim Corp. METU Technopolis, Ankara, Turkey","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","197","202","In this paper, we present an ontology-based information extraction and retrieval system and its application to soccer domain. In general, we deal with three issues in semantic search, namely, usability, scalability and retrieval performance. We propose a keyword-based semantic retrieval approach. The performance of the system is improved considerably using domain-specific information extraction, inference and rules. Scalability is achieved by adapting a semantic indexing approach. We implement the system using the state-of-the-art technologies in Semantic Web and evaluate the performance against traditional systems. Further detailed evaluation is provided to observe the performance gain due to domain-specific information extraction and inference.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452700","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452700","","Data mining;Database languages;Indexing;Information retrieval;Knowledge representation;Ontologies;Resource description framework;Scalability;Semantic Web;Usability","indexing;information retrieval;ontologies (artificial intelligence);semantic Web","domain-specific information extraction;inference;information retrieval system;keyword-based semantic retrieval;ontology-based information extraction;ontology-based retrieval system;retrieval performance;scalability;semantic Web;semantic indexing;semantic search;soccer domain;usability","","2","","17","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Securely Coordinating Services Using Contracts","J. A. Espinosa-Oviedo; G. Vargas-Solar; J. L. Zechinelli-Martini; C. Collet","French Mexican Lab. of Inf. & Autom. Control, San Andres Cholula, Mexico","2009 Mexican International Conference on Computer Science","20100422","2009","","","307","314","Along with the emergence of Web 2.0 there is a need for accessing information in a continues and secure way using whatever device available for doing so. In such a context, access to information resources must be done in a secure and robust way through services that come up as a new paradigm for programming and organizing operations. This paper presents an approach for retrieving critical and non critical data with different security constraints by coordinating services. Thanks to contracts describing the logic of a services based application running in a dynamic environment, it is possible to associate a personalized secure behavior in an orthogonal way. Contracts ensure, for example, integrity and authentication of services at execution time in the presence of exceptions and make applications aware of their execution context.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452519","Contract;Non-Functional Properties;Services Coordination","Authentication;Context-aware services;Contracts;Data security;Information resources;Information retrieval;Information security;Logic programming;Organizing;Robustness","Internet;information resources;information retrieval;message authentication","Web 2.0;contracts;coordinating services security;data retrieval;information resources;security constraints;service authentication","","0","","9","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"An evaluation of Protocol Buffer","G. Kaur; M. M. Fuad","Department of Computer Science Winston-Salem State University Winston-Salem, NC 27110, USA","Proceedings of the IEEE SoutheastCon 2010 (SoutheastCon)","20100422","2010","","","459","462","World is shrinking each day through the use of Internet and people are communicating better than before in this widely distributed network. There is a great need to manage this communication over various networks supporting different specifications. One of the widely used techniques for this type of data management is XML data interchange format. Google developers recently introduced Protocol Buffer as an alternative to XML claiming that it overcomes the shortcomings suffered by XML. This paper compares XML and Protocol Buffer data formats by extensive analysis of the two. The paper evaluates the claims made by Google by developing an algorithm to map an existing XML to Protocol Buffer format and drawing any conclusion on the efficiency and effectiveness of this format as compared to XML. It can be hoped that this work will contribute to the upcoming research in this field as people are looking for more robust data interchange format for the future of the Internet.","1091-0050;10910050","Electronic:978-1-4244-5853-0; POD:978-1-4244-5854-7","10.1109/SECON.2010.5453828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453828","","Application software;Buffer storage;Computer science;Encoding;IP networks;Information retrieval;Internet;Java;Protocols;XML","XML;data analysis;document handling;electronic data interchange","Internet;XML data interchange format;data interchange format;data management;protocol buffer format","","2","4","7","","","18-21 March 2010","","IEEE","IEEE Conference Publications"
"Naive Bayes Classifier based Arabic document categorization","H. M. Noaman; S. Elmougy; A. Ghoneim; T. Hamza","Faculty of Computers and Information Sciences, Mansoura University, Mansoura 35517, Egypt","2010 The 7th International Conference on Informatics and Systems (INFOS)","20100506","2010","","","1","5","Text Categorization aims to assign an electronic document to one or more categories based on its contents. Due to the rapid growth of the number of online Arabic documents, the information libraries and Arabic document corpus, automatic Arabic document classification becomes an important task. This paper suggests the use of rooting algorithm with Nai√Ç¬øve Bayes Classifier to the problem of document categorization of Arabic language and reports the algorithm performance in terms of error rate, accuracy, and micro-average recall measures. Our experimental study shows that using rooting algorithm with Nai√Ç¬øve Bayes (NB) Classifier gives ~62.23% average accuracy and decreases the dimensionality of the training documents.","","Electronic:978-977-403-396-4; POD:978-1-4244-5828-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461819","Na√Øve Bayes classifier;document categorization;machine learning;natural language processing for Arabic language","Classification tree analysis;Inference algorithms;Information filtering;Information filters;Information retrieval;Machine learning;Machine learning algorithms;Niobium;Support vector machines;Text categorization","belief networks;natural language processing;text analysis","Arabic document categorization;electronic document;naive Bayes classifier;rooting algorithm;text categorization","","2","","28","","","28-30 March 2010","","IEEE","IEEE Conference Publications"
"Scenario Elicitation from Natural Language Requirements","X. Liu","Coll. of Inf. Sci. & Technol., Jinan Univ., Guangzhou, China","2010 Second International Workshop on Education Technology and Computer Science","20100506","2010","2","","252","255","Scenarios are critical for requirement analysis and system design. In this paper, we present a lightweight framework for scenario elicitation from natural language requirements. First, the events are elicited from sentences using event templates. Then the elicited events are associated with event tree to constitute scenarios.","","Electronic:978-1-4244-6389-3; POD:978-1-4244-6388-6","10.1109/ETCS.2010.137","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5460024","Event template;NLR analysis;Scenario elicitation;component","Computer science;Computer science education;Educational institutions;Educational technology;Information analysis;Information retrieval;Information science;Natural languages;System analysis and design;Text analysis","fault trees;formal specification;knowledge acquisition;natural language processing;systems analysis","event elicitation;event tree;natural language requirements;requirement analysis;scenario elicitation;system design","","2","","10","","","6-7 March 2010","","IEEE","IEEE Conference Publications"
"Robots asking for directions ‚Äî The willingness of passers-by to support robots","A. Weiss; J. Igelsb√∂ck; M. Tscheligi; A. Bauer; K. K√ºhnlenz; D. Wollherr; M. Buss","ICT&S Center, University of Salzburg, Salzburg, Austria","2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","20100422","2010","","","23","30","This paper reports about a human-robot interaction field trial conducted with the autonomous mobile robot ACE (Autonomous City Explorer) in a public place, where the ACE robot needs the support of human passers-by to find its way to a target location. Since the robot does not possess any prior map knowledge or GPS support, it has to acquire missing information through interaction with humans. The robot thus has to initiate communication by asking for the way, and retrieves information from passers-by showing the way by gestures (pointing) and marking goal positions on a still image on the touch screen of the robot. The aims of the field trial where threefold: (1) Investigating the aptitude of the navigation architecture, (2) Evaluating the intuitiveness of the interaction concept for the passers-by, (3) Assessing people's willingness to support the ACE robot in its task, i.e. assessing the social acceptability. The field trial demonstrates that the architecture enables successful autonomous path finding without any prior map knowledge just by route directions given by passers-by. An additional street survey and observational data moreover attests the intuitiveness of the interaction paradigm and the high acceptability of the ACE robot in the public place.","2167-2121;21672121","Electronic:978-1-4244-4893-7; POD:978-1-4244-4892-0","10.1109/HRI.2010.5453273","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453273","autonomous mobile robot;field trial;human-robot interaction;social acceptance","Automatic control;Cities and towns;Global Positioning System;Human robot interaction;Humanoid robots;Information retrieval;Mobile robots;Navigation;Orbital robotics;Robotics and automation","human-robot interaction;mobile robots;path planning;social aspects of automation;telerobotics","autonomous city explorer;autonomous mobile robot;autonomous path finding;human passers-by;human-robot interaction;interaction intuitiveness;interaction paradigm;navigation architecture;social acceptability","","2","","30","","","2-5 March 2010","","IEEE","IEEE Conference Publications"
"A case-based reasoning system for enterprise informalization: Development and management","L. Hua; W. Li-ping; C. Hong","College of Business Administration, Zhejiang University of Technology, Hangzhou 310023, China","2010 International Conference on Logistics Systems and Intelligent Management (ICLSIM)","20100506","2010","3","","1887","1891","In order to decrease the hardship of the knowledge transferring and sharing between enterprises. We designed a Case-based reasoning mechanism for enterprise informalization projects. After an intensive survey of enterprise informalization we defined the case hierarchical representation in detail to enable project managers to describe project requirements adequately. Furthermore, we proposed a combination method of subjective and objective weights to the nearest neighbor algorithm for enterprise informalization case retrieval, which can facilitate users to get more comfortable. In addition, a framework of enterprise informalization project system based on CBR was built and the portion functions of the system were designed. Finally, an example was given for describing the CBR system.","","Electronic:978-1-4244-7330-4; POD:978-1-4244-7331-1","10.1109/ICLSIM.2010.5461304","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461304","Case Representation;Case Retrieval;Case-based Reasoning;Enterprise Informalization","Database systems;Decision making;Educational institutions;Enterprise resource planning;Information analysis;Information retrieval;Knowledge management;Knowledge transfer;Nearest neighbor searches;Project management","case-based reasoning;enterprise resource planning;knowledge management;project management","case hierarchical representation;case-based reasoning system;enterprise informalization case retrieval;enterprise informalization projects;knowledge sharing;knowledge transferring;nearest neighbor algorithm;project managers;project requirements","","1","","13","","","9-10 Jan. 2010","","IEEE","IEEE Conference Publications"
"Image Retrieval Using DCT Coefficients of Pixel Distribution and Average Value of Row and Column Vector","N. S. T. Sai; R. C. Patil","Tech Mahindra, Mumbai, India","2010 International Conference on Recent Trends in Information, Telecommunication and Computing","20100506","2010","","","375","377","Retrieving image from large & varied collections using image content (such as color, shape, texture) as a key is challenging & important problem . This paper describes a two approaches to content based image retrieval (CBIR) that represent each image in database by a vector of feature values called √Ç¬øImage Retrieval using DCT coefficients of pixel distribution & average value of row & column vector√Ç¬ø. Here we propose simple approaches that can be easily implemented in a programming language. In this paper we apply DCT on average value of row and column vector and DCT on pixel distribution of row and column vector. Feature vector each image is DCT coefficients. Here DCT coefficients are calculated by using two techniques. These two techniques are compared using precision and recall of each class by using each method. This classifiers is well suitable for features extracted and fast in computation for CBIR systems. We use simple Euclidean distance to compute the similarity measures of images for Content Based Image Retrieval application. This technique gives acceptable results in a simple and fast way.","","Electronic:978-1-4244-5957-5; POD:978-1-4244-5956-8","10.1109/ITC.2010.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5460586","BTC;CBIR;DCT;Precision;Recall","Computer languages;Content based retrieval;Discrete cosine transforms;Feature extraction;Image databases;Image retrieval;Information retrieval;Pixel;Shape;Spatial databases","content-based retrieval;discrete cosine transforms;feature extraction;image colour analysis;image representation;image retrieval;image texture;vectors","DCT coefficients;Euclidean distance;column vector;content based image retrieval;database;feature extraction;image color;image representation;image shape;image texture;pixel distribution;programming language;row vector","","0","","16","","","12-13 March 2010","","IEEE","IEEE Conference Publications"
"On novelty in publish/subscribe delivery","D. Souravlias; M. Drosou; K. Stefanidis; E. Pitoura","Computer Science Department, University of Ioannina, Greece","2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)","20100422","2010","","","20","22","In publish/subscribe systems, users express their interests in specific items of information and get notified when relevant data items are produced. Such systems allow users to stay informed without the need of going through huge amounts of data. However, as the volume of data being created increases, some form of ranking of matched events is needed to avoid overwhelming the users. In this work-in-progress paper, we explore novelty as a ranking criterion. An event is considered novel, if it matches a subscription that has rarely been matched in the past.","","Electronic:978-1-4244-6523-1; POD:978-1-4244-6522-4; USB:978-1-4244-6521-7","10.1109/ICDEW.2010.5452770","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452770","","Computer science;Explosions;Feeds;Gain measurement;Information retrieval;Motion pictures;Social network services;Subscriptions","content-based retrieval;information retrieval;middleware","content-based model;matched event ranking;publish-subscribe delivery","","0","2","12","","","1-6 March 2010","","IEEE","IEEE Conference Publications"
"Study and Implementation of Image Retrieval for Teaching Resources","X. j. Wang; L. h. Han","Comput. & Inf. Eng. Dept., Shijiazhuang Railway Inst., Shijiazhuang, China","2010 International Conference on Biomedical Engineering and Computer Science","20100506","2010","","","1","4","Teaching resources are usually massive, complex, hybrid and distributed. In order to search and utilize images from teaching resources with high efficiency, this paper introduced how to use CBIR (Content-based Image Retrieval) to search images from teaching resources, and design a image retrieval system for Teaching resources, it emphasizes on the analysis of relevance feedback algorithm based on SVM (support vector machines) as well as its' application in the image retrieval of the Teaching Resources. The experiments indicate that this method can accurately and effectively find out the images which are required by user, and improve the image retrieval efficiency effectively.","2165-9192;21659192","Electronic:978-1-4244-5316-0; POD:978-1-4244-5315-3","10.1109/ICBECS.2010.5462438","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5462438","","Content based retrieval;Education;Feature extraction;Feedback;Image databases;Image retrieval;Information retrieval;Spatial databases;Support vector machines;Visual databases","content-based retrieval;educational computing;image retrieval;relevance feedback;support vector machines","CBIR;SVM;content-based image retrieval;image searching;relevance feedback algorithm;support vector machines;teaching resources","","0","","10","","","23-25 April 2010","","IEEE","IEEE Conference Publications"
"Toward enhanced Natural Language Processing to databases: Building a specific domain Ontology derived from database conceptual model","R. Khamis; S. Shatnawi","University of Bahrain, Applied Studies College","2010 The 7th International Conference on Informatics and Systems (INFOS)","20100506","2010","","","1","8","Natural Language Interface to database NLIDB applications achieve great success when dealing with simple user requests, however most of NLIDB applications fail dramatically when users issue indirect or sophisticated requests. One modern approach to enhance NLIDB is using Ontology. Ontologies are very helpful when used with Natural Language Processing applications for supporting extraction of relevant elements from databases. This paper proposes a framework and a semi automatic procedure for building domain specific Ontology by using data conceptual model and general purpose Ontology such as WordNet. The aim is to help NLIDB understanding and simplifying indirect users data requests.","","Electronic:978-977-403-396-4; POD:978-1-4244-5828-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461774","","Application software;Artificial intelligence;Buildings;Databases;Educational institutions;Information retrieval;Natural language processing;Natural languages;Ontologies;Vocabulary","database management systems;natural language interfaces;natural language processing;ontologies (artificial intelligence)","WordNet;database conceptual model;general purpose ontology;natural language interface to databases;natural language processing;specific domain ontology","","2","","28","","","28-30 March 2010","","IEEE","IEEE Conference Publications"
"Ground truth dataset and baseline evaluations for intrinsic image algorithms","R. Grosse; M. K. Johnson; E. H. Adelson; W. T. Freeman","Massachusetts Institute of Technology, Cambridge, 02139, USA","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","2335","2342","The intrinsic image decomposition aims to retrieve ‚Äúintrinsic‚Äù properties of an image, such as shading and reflectance. To make it possible to quantitatively compare different approaches to this problem in realistic settings, we present a ground-truth dataset of intrinsic image decompositions for a variety of real-world objects. For each object, we separate an image of it into three components: Lambertian shading, reflectance, and specularities. We use our dataset to quantitatively compare several existing algorithms; we hope that this dataset will serve as a means for evaluating future work on intrinsic images.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459428","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459428","","Computer vision;Geometry;Image decomposition;Image retrieval;Information retrieval;Layout;Light sources;Lighting;Reflectivity;Shape","image processing","Lambertian shading;ground truth dataset;ground-truth dataset;intrinsic image algorithms;intrinsic image decompositions","","82","3","16","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"Ontology based P2P Semantic Search Routing Algorithm","C. Xu; Y. Zhang","College of Computer Science of Chongqing University in China","2010 International Conference on Networking, Sensing and Control (ICNSC)","20100506","2010","","","689","692","Aiming at existing deficiencies such as low text semantic relevance degree in P2P context search, an Ontology-based P2P Content Semantic Search Routing Algorithm is developed. In this algorithm, texts are described as ontology and concepts are mapped from K- High Frequency Term. Concept Similarity is calculated by semantic distance between concepts to from concept relevance overlay and locate semantic peers. Based on the concept relevance overlay, search requests are routed to the semantic peers firstly in order to search more semantic relevance resource by less time and network traffic. Finally, the experiment was done to validate the efficiency and validity of Ontology based P2P Content Semantic Search Routing Algorithm, in which the result had shown that the algorithm is much better than Simple Flooding in semantic relevance degree of text.","","Electronic:978-1-4244-6453-1; POD:978-1-4244-6450-0","10.1109/ICNSC.2010.5461576","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5461576","","Computer science;Floods;Frequency;Information retrieval;Information technology;Ontologies;Resource description framework;Routing;Semantic Web;Telecommunication traffic","information retrieval;ontologies (artificial intelligence);peer-to-peer computing;text analysis","concept relevance overlay;concept similarity;k-high frequency term;ontology based P2P semantic search routing algorithm;simple flooding;text semantic relevance degree","","1","","15","","","10-12 April 2010","","IEEE","IEEE Conference Publications"
"Efficient retrieval of deformable shape classes using local self-similarities","K. Chatfield; J. Philbin; A. Zisserman","Dept. of Engineering Science, University of Oxford, UK","2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","20100503","2009","","","264","271","We present an efficient object retrieval system based on the identification of abstract deformable `shape' classes using the self-similarity descriptor of Shechtman and Irani. Given a user-specified query object, we retrieve other images which share a common `shape' even if their appearance differs greatly in terms of colour, texture, edges and other common photometric properties. In order to use the self-similarity descriptor for efficient retrieval we make three contributions: (i) we sparsify the descriptor points by locating discriminative regions within each image, thus reducing the computational expense of shape matching; (ii) we extend to enable matching despite changes in scale; and (iii) we show that vector quantizing the descriptor does not inhibit performance, thus providing the basis of a large-scale shape-based retrieval system using a bag-of-visual-words approach. Performance is demonstrated on the challenging ETHZ deformable shape dataset and a full episode from the television series Lost, and is shown to be superior to appearance-based approaches for matching non-rigid shape classes.","","Electronic:978-1-4244-4124-2; Electronic:978-1-4244-4441-0; POD:978-1-4244-4442-7","10.1109/ICCVW.2009.5457691","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457691","","Cows;Deformable models;Heart;Image retrieval;Information retrieval;Large-scale systems;Pattern matching;Photometry;Shape;TV","image colour analysis;image matching;image retrieval;image texture;photometry;vector quantisation","bag-of-visual-words approach;deformable shape class retrieval;discriminative regions;image colour;image texture;large-scale shape-based retrieval system;local self-similarities;nonrigid shape classes;object retrieval system;photometric properties;shape matching;vector quantization","","20","","15","","","Sept. 27 2009-Oct. 4 2009","","IEEE","IEEE Conference Publications"
"High-Dimensional Approximate Nearest Neighbor Query Based on Fuzzy Control and Genetic Algorithm","W. Yan; Z. Liu; Y. Wang; D. Chen; Z. Wang","Sch. of Comput. Sci. & Technol., Xidian Univ., Xi'an, China","2010 Second International Workshop on Education Technology and Computer Science","20100506","2010","1","","264","267","Recently, with the constant development of application of high-dimensional data query, the index-based nearest neighbor retrieval has greatly improved the efficiency and accuracy of retrieval. The approximate nearest neighbor query is proposed and applied to get high performance to ease the curse of dimensionality to a certain extent. However, the heuristic pruning method may prune many local optimal solutions so that it is impossible to make sure to what extent the final results meet users' needs. With the nearest neighbor as input, this paper proposes a method to get extent how the input meets user's need based on fuzzy control, and then determines whether or not the input will be an approximate optimal solution with a comparison between the extent and threshold value. At the same time, the genetic algorithm is used to complete the adaptive study process of the threshold value to reflect users' approximate needs.","","Electronic:978-1-4244-6389-3; POD:978-1-4244-6388-6","10.1109/ETCS.2010.383","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459132","Demand Degree;Fuzzy Control;Genetic Algorithm;Pruning;Rule Base","Application software;Computer science;Computer science education;Databases;Educational technology;Fuzzy control;Genetic algorithms;Information retrieval;Nearest neighbor searches;Probability","fuzzy control;genetic algorithms;heuristic programming;indexing;query processing","fuzzy control;genetic algorithm;heuristic pruning method;high-dimensional approximate neighbor query;index-based nearest neighbor retrieval","","1","","5","","","6-7 March 2010","","IEEE","IEEE Conference Publications"
"Image annotation using multi-label correlated Green's function","Hua Wang; Heng Huang; C. Ding","Computer Science and Engineering Department, University of Texas at Arlington, USA","2009 IEEE 12th International Conference on Computer Vision","20100506","2009","","","2029","2034","Image annotation has been an active research topic in the recent years due to its potentially large impact on both image understanding and web/database image search. In this paper, we target at solving the automatic image annotation problem in a novel semi-supervised learning framework. A novel multi-label correlated Green's function approach is proposed to annotate images over a graph. The correlations among labels are integrated into the objective function which improves the performance significantly. We also propose a new adaptive decision boundary method for multi-label assignment to deal with the difficulty of label assignment in most of the existing rank-based multi-label classification algorithms. Instead of setting the threshold heuristically or by experience, our method principally compute it upon the prior knowledge in the training data. We perform our methods on three commonly used image annotation testing data sets. Experimental results show significant improvements on classification performance over four other state-of-the-art methods. As a general semi-supervised learning framework, other local feature based image annotation methods could be easily incorporated into our framework to improve the performance.","1550-5499;15505499","Electronic:978-1-4244-4419-9; POD:978-1-4244-4420-5","10.1109/ICCV.2009.5459447","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459447","","Computer science;Computer vision;Content based retrieval;Data engineering;Green's function methods;Image retrieval;Information retrieval;Pairwise error probability;Semisupervised learning;Training data","Green's function methods;graph theory;image classification;image retrieval;learning (artificial intelligence);query formulation","Web/database image search;adaptive decision boundary method;graph;image annotation;image understanding;multi-label classification algorithms;multi-label correlated Green function;semi-supervised learning","","14","","24","","","Sept. 29 2009-Oct. 2 2009","","IEEE","IEEE Conference Publications"
"Records Retention in Relational Database Systems: Bridging the Gap between Laws and Enforcement Actions","A. A. Ataullah; F. W. Tompa","David R. Cheriton Sch. of Comput. Sci., Univ. of Waterloo, Waterloo, ON, Canada","2009 Second International Workshop on Requirements Engineering and Law","20100506","2009","","","15","16","Relational databases contain a large number intertwined transaction level facts that can collectively (or independently) represent innumerable business records. In this paper we present a framework for defining business records contained in a database system as queries and then specifying retention policies over them. We also highlight several key issues for both policy makers and database administrators to consider when designing and implementing records retention policies over relationally stored records.","","Electronic:978-0-7695-4102-0; POD:978-1-4244-7696-1","10.1109/RELAW.2009.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5459813","","Business;Computer science;Database languages;Database systems;Forensics;Information retrieval;Law;Legal factors;Relational databases;Transaction databases","law;records management;relational databases","business records;enforcement actions;laws;relational database;retention policies","","1","","2","","","1-1 Sept. 2009","","IEEE","IEEE Conference Publications"
"Research on Locating Video Format and Its Retrieving Method","Y. Wu; X. Liu; H. Zhao; M. Wang","Key Lab. of Virtual Geographic Environ. (MOE), Nanjing Normal Univ., Nanjing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","2153","2156","This paper proposes a new video file format, which can integrate video information, audio information, as well as the spatial positioning information into a whole file. Based on this video format, the TMS320DM642 video processing platform is adopted to carry out embedded program. Then the method and workflow which employs RF5 (Reference Framework level 5) structure in real-time collecting locating video files are introduced. Given that the video frames have their corresponding spatial positioning information, we put forward a location-based information retrieval algorithm and the rapid and efficient retrieval of the video clips in the chosen region from an electronic map can be realized.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.962","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454599","","Cities and towns;Digital cameras;Educational institutions;Geographic Information Systems;Global Positioning System;Information retrieval;Information science;Manufacturing;Paper technology;Videoconference","file organisation;video retrieval;video signal processing","TMS320DM642 video processing platform;audio information;electronic map;location-based information retrieval algorithm;reference framework level 5 structure;spatial positioning information;video file format location;video information;video retrieving method","","0","","10","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Shape Google: a computer vision approach to isometry invariant shape retrieval","M. Ovsjanikov; A. M. Bronstein; M. M. Bronstein; L. J. Guibas","ICME, Stanford University, USA","2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","20100503","2009","","","320","327","Feature-based methods have recently gained popularity in computer vision and pattern recognition communities, in applications such as object recognition and image retrieval. In this paper, we explore analogous approaches in the 3D world applied to the problem of non-rigid shape search and retrieval in large databases.","","Electronic:978-1-4244-4124-2; Electronic:978-1-4244-4441-0; POD:978-1-4244-4442-7","10.1109/ICCVW.2009.5457682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457682","","Computer science;Computer vision;Image databases;Image retrieval;Information retrieval;Object recognition;Pattern recognition;Robustness;Shape;Spatial databases","computer graphics;computer vision;image retrieval;pattern recognition;search engines;shape recognition","3D world application;computer vision;computer vision approach;feature based methods;image retrieval;isometry invariant shape retrieval;object recognition;pattern recognition;shape Google","","25","","32","","","Sept. 27 2009-Oct. 4 2009","","IEEE","IEEE Conference Publications"
"Learning to rank images from eye movements","K. Pasupa; C. J. Saunders; S. Szedmak; A. Klami; S. Kaski; S. R. Gunn","School of Electronics & Computer Science, University of Southampton, SO17 1BJ, United Kingdom","2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops","20100503","2009","","","2009","2016","Combining multiple information sources can improve the accuracy of search in information retrieval. This paper presents a new image search strategy which combines image features together with implicit feedback from users' eye movements, using them to rank images. In order to better deal with larger data sets, we present a perceptron formulation of the Ranking Support Vector Machine algorithm. We present initial results on inferring the rank of images presented in a page based on simple image features and implicit feedback of users. The results show that the perceptron algorithm improves the results, and that fusing eye movements and image histograms gives better rankings to images than either of these features alone.","","Electronic:978-1-4244-4124-2; Electronic:978-1-4244-4441-0; POD:978-1-4244-4442-7","10.1109/ICCVW.2009.5457528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457528","","Conferences;Feedback;Focusing;Histograms;Human computer interaction;Information retrieval;Machine learning algorithms;Navigation;Support vector machines;Writing","eye;feedback;image retrieval;learning (artificial intelligence);perceptrons;support vector machines","eye movements;feedback;image features;image histograms;image ranking learning;image search strategy;information retrieval;multiple information sources;perceptron algorithm;perceptron formulation;ranking support vector machine algorithm","","1","","16","","","Sept. 27 2009-Oct. 4 2009","","IEEE","IEEE Conference Publications"
"EM Frequency Domain Correlation Analysis on Cipher Chips","P. Zhang; G. Deng; Q. Zhao; K. Chen","Dept. of Comput. Eng., Mech. Eng. Coll., Shijiazhuang, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","1729","1732","Inserting random time delay into cipher device's running process is a general countermeasure against time domain correlation side channel attacks. In which way the interesting intermediate operations will occur at different time in different runs of the cipher. To break this countermeasure, based on the property that the data dependence of the electromagnetic (EM) signals emitted from the cipher chips can remain when they are transformed from time domain to frequency domain, and power spectrum density will not be affected by inserting random delays into time domain signals, this paper presents a new EM frequency domain correlation analysis. Experiments of EM frequency domain correlation analysis on a micro-controller implemented AES show that the genuine key of AES can still be revealed after inserting random delays in source code, while correlation analysis in time domain is invalid.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.542","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455568","","Delay effects;Electromagnetic analysis;Electromagnetic modeling;Fourier transforms;Frequency domain analysis;Information analysis;Information retrieval;Signal analysis;Signal processing;Time domain analysis","correlation methods;frequency-domain analysis;time-domain analysis","AES;EM frequency domain correlation analysis;cipher chips;cipher device;electromagnetic signals;power spectrum density;random time delay;time domain correlation side channel attacks;time domain signals","","2","","14","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Statistical modeling and analysis of content identification","P. Moulin","University of Illinois, Beckman Inst., Coord. Sci. Lab., & ECE Dept., 405 N. Mathews Ave., Urbana, IL 61801, USA","2010 Information Theory and Applications Workshop (ITA)","20100426","2010","","","1","5","A number of hash-based algorithms for audio and video identification (ID) have been studied in recent literature, and some have been deployed as mobile phone applications and on file sharing sites. A fundamental question is what is the relationship between database size, hash length, and robustness, that any reliable content ID system should satisfy. This paper presents some answers under a simple statistical model for the signals of interest.","","Electronic:978-1-4244-7014-3; POD:978-1-4244-7012-9","10.1109/ITA.2010.5454105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454105","Content identification;audio;capacity;decoding;error exponents;fingerprinting;hashing;strong converse;video","Content based retrieval;Databases;Decoding;Fingerprint recognition;Information retrieval;Peer to peer computing;Probes;Robustness;Signal processing algorithms;Video sharing","content-based retrieval;cryptography;fingerprint identification;statistical analysis","audio identification;content ID system;content identification;database size;hash length;hash-based algorithm;robustness;statistical modeling;video identification","","14","","9","","","Jan. 31 2010-Feb. 5 2010","","IEEE","IEEE Conference Publications"
"Extracting Domain-Specific Concepts to Enhance Search Accuracy","J. Gong; L. Liu","Inf. Syst. Dept., Beihang Univ., Beijing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","849","851","Many users often perform searches in unfamiliar domains and these search experiences are often unsatisfactory since the users are lack of domain-specific knowledge. In this paper, we present a concept based retrieval method to deal with domain-specific searches. Three groups of domain-specific concepts are extracted from the online resource. The following experiments on three domain-specific test collections show that this approach is effective in improving domain-specific search accuracy.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.576","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454846","","Computer science;Data mining;Diseases;Information retrieval;Information science;Information systems;Knowledge engineering;Ontologies;Search engines;Testing","Internet;information retrieval","concept based retrieval method;domain-specific concept extraction;domain-specific knowledge;domain-specific searches;domain-specific test collections;online resource;search accuracy enhancement","","0","","16","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"A New Document Retrieval Model Using Dempster-Shafer Theory of Evidence","C. Shi; J. Zhang; B. Deng","Dept. of Electron. Eng., Tsinghua Univ., Beijing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","746","749","Vector space model is a widely used conventional document retrieval model. It judges the relevance between a query and a document by calculating the similarity between them. However, vector space model is not satisfactory in recall and precision. In this paper, we propose a new document retrieval model using Dempster-Shafer theory of evidence. Documents are segmented into sentences firstly. Then similarities between a query and every sentence are calculated. As our model is within Dempster-Shafer theory of evidence, the combination rule of the theory is utilized to calculate the similarity between a query and a document. To evaluate our model, experiments are carried out and the results show that the model outperforms vector space model in recall and precision.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455721","","Application software;Frequency measurement;Hardware;Indexing;Information retrieval;Information science;Music information retrieval;Q measurement;Software measurement;Uncertainty","document handling;inference mechanisms;information retrieval","Dempster-Shafer evidence theory;document retrieval model;vector space model","","0","","11","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Key Frame Extraction Based on Connectivity Clustering","Y. Xiao; L. Xia","Sch. of Inf. Sci. & Eng., Central South Univ., Changsha, China","2010 Second International Workshop on Education Technology and Computer Science","20100506","2010","1","","174","177","Key frames play a very important role in video retrieval. In this paper, we introduce a novel method to extract key frames to represent video shot based on connectivity clustering. Compared with other methods, the proposed method can dynamically divide the frames into clusters depending on the content of shot, and then the frame closest to the cluster centroid is chosen as the key frame for the video shot. Experimental results and the comparisons with other methods on various types of video sequences illustrate the high performance of the proposed method.","","Electronic:978-1-4244-6389-3; POD:978-1-4244-6388-6","10.1109/ETCS.2010.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5458784","connectivity clustering;key frame;shot;video retrieval","Clustering algorithms;Computer science;Computer science education;Data mining;Educational technology;Information management;Information retrieval;Information science;Pattern recognition;Video sequences","image sequences;pattern clustering;video retrieval","connectivity clustering;key frame extraction;video retrieval;video shot","","0","","12","","","6-7 March 2010","","IEEE","IEEE Conference Publications"
"An Algorithm to Tackle the Name Authority Control Problem Using Semantic Information","A. Ch√°vez-Arag√≥n; J. F. Ramirez Cruz; O. F. Reyes-Galaviz; H. Ayanegui-Santiago; A. Portilla","Fac. de Cienc. Basicas, Ing. y Tecnol., Univ. Autonoma de Tlaxcala, Tlaxcala, Mexico","2009 Mexican International Conference on Computer Science","20100422","2009","","","176","179","Name disambiguation is a focal point on realworld information integration, analysis, and data mining. This problem, also known as the classical name authority control problem, consists in ""same authors with different spellings"" or ""different authors with the same spelling"". The problem is augmented in large data repositories where information changes and grows over time (e.g., DBLP, CiteSeer). In particular, we are mainly interested in DBLP because we use this database to discover the publishing movement among Mexican researchers. In this paper, we propose an algorithm that solves the name authority control problem. Our approach aims to improve the identity author tracking by using semantic information about authors, even thought they use different name varieties to sign their research work over time.","","Electronic:978-0-7695-3882-2; POD:978-1-4244-5258-3","10.1109/ENC.2009.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452563","Name disambiguation;identity uncertainty;name authority control problem;semantic information","Bibliographies;Computer science;Data analysis;Data mining;Databases;Informatics;Information analysis;Information retrieval;Laboratories;Publishing","bibliographic systems;data mining;database management systems","DBLP;digital bibliography-library project;identity author tracking;name authority control;name disambiguation;semantic information","","0","","14","","","21-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Tamper Detection in Multi-format Image Databases Using Fragile Watermarking","V. P. Kumari; K. S. Easwarakumar","Tek-Tools Software Inc., Chennai, India","2010 International Conference on Recent Trends in Information, Telecommunication and Computing","20100506","2010","","","308","310","Storing and using multimedia data for various commercial usages has increased enormously, which in turn needs a way to secure data from intentional attacks. Watermarking is one of the securing methods that can wrap any content and detect the attack, if any on decoding. This paper proposes a watermarking technique for image databasses that might contain images in any format like JPEG, BMP, PNG, etc. We propose to store image data in encoded form and compare the content against the watermarked for its authenticity.","","Electronic:978-1-4244-5957-5; POD:978-1-4244-5956-8","10.1109/ITC.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5460567","Authenticity;Encoding;Image Databases;Watermarking","Data security;Decoding;Image coding;Image databases;Image retrieval;Information retrieval;Multimedia databases;Multimedia systems;Robustness;Watermarking","image coding;security of data;visual databases;watermarking","BMP;JPEG;PNG;fragile watermarking;intentional attacks;multiformat image database;multimedia data;secure data;tamper detection","","0","","9","","","12-13 March 2010","","IEEE","IEEE Conference Publications"
"DataCube: A P2P Persistent Data Storage Architecture Based on Hybrid Redundancy Schema","H. B. Ribeiro; E. Anceaume","IRISA/INRIA Rennes Bretagne-Atlantique, Rennes, France","2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing","20100422","2010","","","302","306","This paper presents the design of a P2P data persistent platform. Durable access and integrity of the data are ensured despite massive attacks. This platform, named DataCube, exploits the properties of cluster-based peer-to-peer substrates to implement a compound of full replication and rateless erasure codes. DataCube guarantees durable access and integrity of data despite adversarial attacks. In particular, the recovery of damaged data is achieved through the retrieval of coded blocks whose integrity is checked on the fly.","1066-6192;10666192","Electronic:978-1-4244-5673-4; POD:978-1-4244-5672-7","10.1109/PDP.2010.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452454","Byzantine failure model;Peer-to-peer;availability","Algorithm design and analysis;Information retrieval;Logic testing;Memory;Open systems;Peer to peer computing;Redundancy;Robustness;System testing;Topology","data integrity;peer-to-peer computing","DataCube;P2P persistent data storage architecture;damaged data recovery;data integrity;hybrid redundancy schema","","6","","18","","","17-19 Feb. 2010","","IEEE","IEEE Conference Publications"
"The Research and Design of Information Sharing of GIS Based on RESTful Web Service","H. Wang; H. Fan","LIESMARS, Wuhan Univ., Wuhan, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","2225","2228","The model of Web Service and Geographic Information Services Specification of the OGC is introduced in this paper firstly; then the difference of the RPC and ROA is analyzed, the properties of the REST and the detail of the Restlet architecture are expounded. The detail of the advantages of GIS information sharing which used the REST design principles is indicated. Finally, the design process which used the REST design principles is described.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.1260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5455680","","Computer displays;Design engineering;Geographic Information Systems;Information retrieval;Information science;Programming profession;Uniform resource locators;Web and internet services;Web services;XML","Web services;geographic information systems;peer-to-peer computing","GIS;Restlet architecture;geographic information services specification;restful Web service","","1","","9","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Approach Based on Reverse Hidden Markov Model for Audio Classification","X. He; Y. Shi; X. Zhou","Sch. of Autom., Nanjing Univ. of Sci. & Technol., Nanjing, China","2009 First International Conference on Information Science and Engineering","20100426","2009","","","481","484","In recent years, with more and more multimedia data being captured and stored, the searching and indexing techniques for multimedia data are getting more attention in the area of multimedia databases. As many research works were done on the content-based retrieval of image and video data, less attention was received to the content-based retrieval of audio data. As one of important parts in audio retrieval, audio classification is discussed in this paper. The reverse Hidden Markov Model is introduced and an approach based on reverse Hidden Markov Model for audio classification is presented. Experiments show that this method is effective.","2160-1283;21601283","Electronic:978-1-4244-5728-1; POD:978-1-4244-4909-5","10.1109/ICISE.2009.238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5454917","","Content based retrieval;Data engineering;Feature extraction;Hidden Markov models;Image retrieval;Independent component analysis;Indexing;Information retrieval;Multimedia databases;Vectors","audio signal processing;hidden Markov models;independent component analysis;indexing;information retrieval;signal classification","audio classification;audio retrieval;content-based image retrieval;content-based video data retrieval;independent component analysis;multimedia data indexing technique;multimedia databases;reverse hidden Markov model","","0","","6","","","26-28 Dec. 2009","","IEEE","IEEE Conference Publications"
"Clinical Data Management System","L. Fu; S. Ding; T. Chen","Inst. of Comput. Sci. & Software, Hebei Univ. of Technol., Tianjin, China","2010 International Conference on Biomedical Engineering and Computer Science","20100506","2010","","","1","4","Reference clinical data interchange standards defined by CDISC (Clinical Data Interchange Standards Consortium), we developed clinical data management system with distributed system architecture which can be executed on different platforms for high performance. This system consists mainly of study management module, data capture module, data management module and security module. Besides, web-based approach changes the traditional client/server design pattern for case report form which will becomes more convenient and intuitive. Although there have some features should be improved in later, clinical data management system has been proven to be very helpful in efficiency and effectiveness improvement.","2165-9192;21659192","Electronic:978-1-4244-5316-0; POD:978-1-4244-5315-3","10.1109/ICBECS.2010.5462386","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5462386","","Business;Clinical trials;Data models;Information retrieval;Protocols;Quality management;Relational databases;Software standards;Standards development;XML","Internet;client-server systems;distributed databases;electronic data interchange;medical information systems","Web-based approach;client-server design pattern;clinical data interchange standards;clinical data management system;data capture module;data management module;distributed system architecture;security module;study management module","","1","","7","","","23-25 April 2010","","IEEE","IEEE Conference Publications"
