"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5588744,5590817,5587860,5593618,5590962,5592885,5588761,5587775,5591526,5588758,5592949,5586167,5587011,5587013,5586938,5585940,5586527,5586016,5581285,5583899,5582014,5583009,5584815,5581378,5581384,5583243,5583740,5584863,5581615,5584115,5581367,5583953,5583565,5582967,5581590,5583207,5581286,5580675,5580683,5580295,5580902,5581026,5580678,5580664,5580677,5580733,5573411,5579014,5580680,5579321,5579518,5579353,5572266,5578130,5577901,5575982,5578505,5575467,5576882,5575555,5578421,5575518,5575852,5575650,5576015,5576554,5577850,5577937,5578160,5575757,5572397,5575632,5575603,5571760,5575684,5578415,5571505,5578027,5577955,5577868,5573864,5575630,5571211,5570002,5571261,5569977,5571201,5571117,5569971,5567476,5567595,5569075,5566476,5568850,5569330,5567805,5568585,5569522,5569682,5567300",2017/05/04 22:35:58
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Using the format concept analysis to construct the tourism information ontology","S. Tang; Z. Cai","School of Information Science and Engineering, Central South University, Changsha 410083 China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","6","","2941","2944","Ontology is playing an increasingly important role in knowledge management and the Semantic Web. The tourism information ontology is becoming a core research field in the realm of information retrieval. The objective of this study is to explore the potential role of Formal Concept Analysis (FCA) in a web-based ontology construction support system in a tourism domain. An ontology construction method known as TOCM (Tourism Ontology Construction Method) that can generate an ontology based on Formal Concept Analysis theory is proposed. Under the framework of our ontology construction method, the knowledge engineers could reach a new ontology of tourism information that was demonstrated as useful to support their ontology construction tasks.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569075","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569075","format concept analysis;ontology construction;tourism information","Construction industry;Context;Intelligent systems;Ontologies;Pragmatics","electronic data interchange;information retrieval;knowledge management;knowledge representation languages;semantic Web;travel industry;vocabulary","TOCM;format concept analysis;information retrieval;knowledge management;semantic Web;tourism information ontology;tourism ontology construction method;web-based ontology construction support system","","0","","17","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Internet information extraction & evaluation of mineral resources based on WebGIS","Liu xing; Wu Shouliang","Faculty of earth and enviroment, Anhui university of sciences and technology, Huainan, China","2010 The 2nd Conference on Environmental Science and Information Application Technology","20100909","2010","2","","150","153","At present, the application of WebGIS is mostly limited to data sharing and distribution, while the professional mineral resources evaluation WebGIS needs stronger functions of information extraction, data integration and thematic mapping and so on. This paper provided a set of solution to mineral resources evaluation analysis system based on MapGIS-IMS, introducing system build-up, the process of data organizing, and detailed description to realize professional extension module by secondary development. This paper also provides a sample reference for networking of mineral resources evaluation and building up professional WEBGIS website for specialized department.","","Electronic:978-1-4244-7390-8; POD:978-1-4244-7387-8","10.1109/ESIAT.2010.5567300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567300","Evaluation & Predication of Mineral Resources;Information Extraction;Thematic Mapping;WebGIS Extension","Field-flow fractionation;Geology","Internet;data integrity;geographic information systems;information retrieval;minerals;natural resources","Internet;MapGIS-IMS;WebGIS;data distribution;data integration;data sharing;information extraction;mineral resources;thematic mapping","","0","","11","","","17-18 July 2010","","IEEE","IEEE Conference Publications"
"Towards Automated Processing of the Right of Access in Inter-organizational Web Service Compositions","R. Herkenhöner; H. de Meer; M. Jensen; H. C. Pöhls","Comput. Networks & Commun., Univ. of Passau, Passau, Germany","2010 6th World Congress on Services","20100916","2010","","","645","652","Enforcing the right of access to personal data usually is a long-running process between a data subject and an organization that processes personal data. As of today, this task is commonly realized using a manual process based on postal communication or personal attendance and ends up conflicting with trade secret protection. In this paper, we present an automated architecture to enable exercising the right of access in the domain of inter-organizational business processes based on Web Services technology. Deriving its requirements from the legal, economical, and technical obligations, we show the architecture's overall approach solving the conflict between trade secret and exercising the right of access.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575518","Web Services;legal compliance;privacy;right of access;trade secret","Companies;Correlation;Law;Roads;Web services","Web services;authorisation;business data processing;digital rights management;information retrieval;law administration","automated architecture;automated processing;economical obligation;interorganizational Web service composition;interorganizational business processes;legal obligation;personal data access;postal communication;right of access;technical obligation","","3","","15","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Intelligent Information Technology Based Drug Knowledge Platform","C. Li; Z. Zhong; H. Dai","Sch. of Comput. Eng., Huaihai Inst. of Technol., Lianyungang, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","In this paper, a drug knowledge platform based on intelligent information technology is constructed. Unlike the traditional virtual drug compound library which focus on the patents of drug only, the aim of the new platform is to design a system including information retrieval, information extraction, construction of drug compound and drug ontology, structure based virtual screening, and text classification. It is clear that such an novel system will improve the effectiveness of new drug discovery and development.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566476","","Compounds;Drugs;Feature extraction;Ontologies;Support vector machines","data mining;drugs;information retrieval;information technology;ontologies (artificial intelligence);patents;pattern classification;text analysis","drug knowledge platform;drug ontology;drug patents;information extraction;information retrieval;intelligent information technology;text classification;virtual drug compound library;virtual screening","","0","","11","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Extracting and Clustering Method of Web Bipartite Cores","N. Yang; H. Ding; Y. Liu","Inf. Sch., Rennin Univ. of China, Beijing, China","2010 Seventh Web Information Systems and Applications Conference","20100923","2010","","","29","34","The paper focuses on some key problems in Web communities' discovery. Based on topic-oriented communities discovery, we analyze some insufficiencies of CBG (complete bipartite graph) in trawling method. The conception of x-core-set is introduced, instead of CBG, it is more reasonable as a signature of core of community. We construct a bipartite graph from a node x and then (i, j)pruning the graph to obtain x-cores-set. By scanning topic subgraph, we can extract a set of x-cores-sets. Finally, a hierarchal clustering algorithm is applied to these x-cores-sets and the dendrogram of community is formed. We proved that x-cores-set, consisted of x-cores, can be calculated by a bipartite graph collected from x and (i, j)pruning. The experiment is set up on the dataset that is same as that in HITS method, except for returned pages are integrated from 4 search engines. The result shows that our algorithm is effective and efficient.","","Electronic:978-0-7695-4193-8; POD:978-1-4244-8440-9","10.1109/WISA.2010.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581378","bipartite cores;hiearachical clustering;web communities","Algorithm design and analysis;Bipartite graph;Clustering algorithms;Communities;Earth Observing System;Fans;Search engines","Internet;graph theory;information retrieval;pattern clustering;search engines","HITS method;Web bipartite cores;Web communities discovery;clustering algorithm;clustering method;complete bipartite graph;extracting method;search engines;topic-oriented communities discovery;trawling method;x-core-set","","0","","11","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"The GPU-based String Matching System in Advanced AC Algorithm","J. Peng; H. Chen; S. Shi","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1158","1163","As one of the most pervasive problems in computer science, string matching is the kernel algorithm in many applications,which especially within the communities of information retrieval and computational biology. Meanwhile, the CPU+GPU heterogeneous parallel platform becomes more and more popular in solving computing intensive applications. This paper implements the webpage matching system with GPU-based advanced AC algorithm, G-AC, which is almost 28 times peak performance to the original AC algorithm which is referred from Snort.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577901","AC algorithm;CUDA;GPU;parallel multi-string matching;webpage matching system","Algorithm design and analysis;Automata;Data structures;Graphics processing unit;Instruction sets;Memory management;Pattern matching","Web services;computer graphic equipment;coprocessors;information retrieval;string matching","GPU;adavanced AC algorithm;computational biology;information retrieval;kernel algorithm;string matching system;webpage matching system","","8","","16","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"A fuzzy model of the MSCI EURO index based on content analysis of European Central Bank statements","V. Milea; R. J. Almeida; U. Kaymak; F. Frasincar","Econometric Institute, Erasmus School of Economics, Erasmus University Rotterdam, P.O. Box 1738, 3000 DR, Rotterdam, the Netherlands","International Conference on Fuzzy Systems","20100923","2010","","","1","7","In this paper we investigate whether the MSCI EURO index can be predicted based on the content of European Central Bank (ECB) statements. We propose a new model to retrieve information from free text and transform it into a quantitative output. For this purpose, we first identify all adjectives in an ECB statement by using the Stanford Part-of-Speech Tagger and feed these to the General Inquirer (GI) content analysis tool. From GI we obtain a matrix that provides for each document and for each content category the percentage of words in the document that fall under each category. After normalizing the data, we develop a Takagi-Sugeno (TS) fuzzy model using fuzzy c-means clustering. The TS fuzzy system is used to model the levels of the MSCI EURO index. To determine the performance of the model, we focus on the accuracy of predicting upward or downward movement in the index, and obtain, on average, an accuracy of 66%, that corresponds to an improvement of 16% over a random classifier.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584815","","Accuracy;Biological system modeling;Economics;Fuzzy systems;Indexes;Predictive models;Training","banking;fuzzy set theory;indexing;information retrieval;natural language processing;pattern clustering","ECB statement;European central bank statements;GI content analysis tool;MSCI EURO index;Stanford part-of-speech tagger;Takagi-Sugeno fuzzy model;content analysis;fuzzy c-means clustering;fuzzy model;general inquirer content analysis tool;information retrieval;random classifier","","2","","21","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"An overview of search methodologies in Semantic Web","T. Slimani; B. Ben Yaghlane","LARODEC Laboratory, ISG de Tunis, Cit&#x00E9; Bouchoucha 2000, Tunisia","ACS/IEEE International Conference on Computer Systems and Applications - AICCSA 2010","20100927","2010","","","1","8","Several researches in Semantic Web are based on information search centered meaning. The common purpose of these researches is to improve current information search and retrieval methods. The last few years have seen a various number of developed semantic search systems. The requirement of a complete survey in this field is one of the main purpose of this paper. The approaches, methodologies and objectives of some recognized projects and their corresponding practical systems are exploited to constitute this overall view of semantic search. In this paper, we present and compare various research directions in semantic search. Further, we give discussion with regards to future research in this area.","2161-5322;21615322","Electronic:978-1-4244-7717-3; POD:978-1-4244-7716-6","10.1109/AICCSA.2010.5587013","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587013","","Database languages;Feature extraction;Ontologies;Resource description framework;Semantics;Syntactics","information retrieval;semantic Web","information retrieval;information search;search methodologies;semantic Web;semantic search systems","","0","","57","","","16-19 May 2010","","IEEE","IEEE Conference Publications"
"Phase retrieval based on an Evolutionary Multicriterion Optimisation method","S. Watanabe; H. Shioya; K. Gohara","Division of Information and Electronic Engineering at Muroran Institute of Technology, 27-1, Mizumoto-cho, Muroran 050-8585, Japan","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Phase problems arise from lost phase information in measurement of diffraction waves. The missing phase should be retrieved to reconstruct an object image from the diffraction pattern. This paper proposes a hybrid type approach, Evolutionary-based GS (E-GS), based on the Gerchberg - Saxton algorithm (GS algorithm) and Evolutionary Multicriterion Optimisation (EMO). There are three main aims of E-GS: (1) to reduce the dependence on initial conditions, (2) to obtain some candidate solutions with various features in one trial and (3) to achieve algorithmic parallelism. In E-GS, the phase retrieval problem is formulated as a two-objective optimisation problem, and the EMO and GS algorithm are used as the framework of multiobjective optimisation and local search, respectively. E-GS deals directly with phase as an optimisation parameter and embeds original genetic operations based on frequency characteristics. In this paper, the characteristics and effectiveness of the proposed approach are discussed by comparison of the performance with that of the GS algorithm. Through numerical examples, it was demonstrated that E-GS could derive good results and the difference of search transition between GS algorithm and E-GS was clarified.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5585940","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5585940","","Diffraction;Erbium;Fourier transforms;Genetics;Materials;Noise;Optimization","evolutionary computation;image reconstruction;image retrieval;information retrieval;optimisation;search problems","Gerchberg-Saxton algorithm;algorithmic parallelism;diffraction pattern;diffraction wave;evolutionary multicriterion optimisation method;object image reconstruction;phase retrieval;search transition","","0","","8","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"DESP: An Automatic Data Extractor on Deep Web Pages","J. Ma; D. Shen; T. Nie","Dept. of Comput. Sci. & Eng., Northeastern Univ., Shenyang, China","2010 Seventh Web Information Systems and Applications Conference","20100923","2010","","","132","136","We present DESP, an automatic data extractor on Deep Web pages for book domain, which can extract data items and label attributes at the same time. The case of DESP is to extract books' information such as title, author, price and publisher from result pages returned from bookstore web sites. Although DESP is for a specific domain, the method used by DESP is highly adaptive and can suit other domains. The system consists of two parts, one is Data Record Locater, the Modified Data Locating algorithm used by it overcomes the shortcoming of the MDR algorithm, the other is Attribute Labeler, and the Detect Combine algorithm makes the data item have a more explicit meaning.","","Electronic:978-0-7695-4193-8; POD:978-1-4244-8440-9","10.1109/WISA.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581384","Web;edit distance;string similarity algorithm","Data mining;HTML;Hidden Markov models;Labeling;USA Councils;Web pages","Internet;Web sites;information retrieval","DESP;attribute labeler;automatic data extractor;book domain;books information extracttion;bookstore Web sites;data record locater;deep Web pages;detect combine algorithm;modified data locating algorithm","","0","","13","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Ecosystems Monitoring: An Information Extraction and Event Processing Scientific Workflow","A. A. Hamed; B. S. Lee; A. E. Thessen","Dept. of Comput. Sci., Univ. of Vermont UVM, Burlington, VT, USA","2010 6th World Congress on Services","20100916","2010","","","302","305","This paper presents a novel architecture that brings together Information Extraction (IE) with Event Processing (EP)research areas to globally monitor human activities and biodiversity dynamics and measure their impact on ecosystems. The two areas (IE and EP) are rich on their own and we believe their integration will achieve a much more comprehensive solution to ecosystems monitoring. The integration is based on a closed loop mechanism that guarantees the communication and the evolution of the overall architecture. While we use Microblogging communities (e.g., Twitter) as a news producing tool, we keep track of the vulnerable ecosystems using a GIS tracking database. We also make use of Google Map/Earth API capabilities to dynamically update the GIS database. After a complete cycle, the architecture produces a list of vulnerable ecosystems. This architecture leverages the rich research in Scientific Workflows to achieve the integration and communication of the various components. We are in the process of developing a system that can be used by conservationists and decision makers to efficiently allocate their time and limited resources in response to ecosystems perturbation.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575852","biodiversity;ecosystem monitoring;event processing;information extraction;scientific workflow;tweet monitoring","Biodiversity;Biomedical monitoring;Data mining;Databases;Ecosystems;Geographic Information Systems;Monitoring","Web sites;application program interfaces;biology computing;decision making;ecology;geographic information systems;information retrieval;knowledge acquisition;monitoring","GIS;Google Map;biodiversity dynamics;closed-loop mechanism;decision making;earth API;ecosystems monitoring;event processing scientific workflow;human activities;information extraction;tracking database","","1","","33","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Semantic Retrieval Based on SPARQL and Fuzzy Ontology for Electronic Commerce","J. Zhai; Y. Song","Sch. of Manage., Dalian Maritime Univ., Dalian, China","2010 International Conference of Information Science and Management Engineering","20100916","2010","1","","399","402","Information retrieval is the important work for Electronic Commerce. Ontology-based semantic retrieval is a hotspot of current research. In order to achieve fuzzy semantic retrieval, this paper proposes an approach using Resource Description Framework (RDF) and fuzzy ontology. First, we apply RDF data model to represent e-commerce information on the Semantic Web. Then, introducing new data type referred as fuzzy linguistic variables to RDF data model, the semantic query expansion in SPARQL query language is constructed by order relation, equivalence relation and inclusion relation between fuzzy concepts defined in linguistic variable ontologies. Examples show that this research facilitates the semantic retrieval through fuzzy concepts for Electronic Commerce on the Semantic Web.","","Electronic:978-1-4244-7670-1; POD:978-1-4244-7669-5","10.1109/ISME.2010.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572266","Electronic Commerce;SPARQL;fuzzy ontology;semantic retrieval;the Semantic Web","Data models;Electronic commerce;Ontologies;Pragmatics;Resource description framework;Semantics","computational linguistics;data models;electronic commerce;fuzzy set theory;information retrieval;ontologies (artificial intelligence);query languages;semantic Web","RDF data model;SPARQL;e-commerce;electronic commerce;fuzzy ontology;information retrieval;linguistic variable ontologies;query language;resource description framework;semantic Web;semantic retrieval","","0","","16","","","7-8 Aug. 2010","","IEEE","IEEE Conference Publications"
"Influence of music representation on compression-based clustering","A. González-Pardo; A. Granados; D. Camacho; F. de Borja Rodríguez","Escuela Polit&#x00E9;cnica Superior, Universidad Aut&#x00F3;noma de Madrid, Madrid, Spain","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","Multimedia Information Retrieval is currently a hot research topic due the popularity of the World Wide Web and the huge amount of multimedia data available. There exists an increasing interest to design and develop new methods and techniques to represent and classify this kind of information. Among the different sources of multimedia information currently available, we have decided to work with music audio files. Three different music representations (binary code, wave information, and SAX) have been used to study how the selection of a particular representation could affect a clustering process based on a set of similarity clusters. Two different algorithms (a hierarchical clustering method based on the quartet tree method and a genetic algorithm) have been applied to automatically perform the clustering. A compression distance, the Normalized Compression Distance (NCD), has been used to generate the similarities among the music files. This distance is parameter-free and widely applicable so we can use it directly with different formats and representations. The paper shows some experimental results using these representations and compares the behavior of both clustering methods.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586167","","Binary codes;Clustering algorithms;Clustering methods;Compression algorithms;Compressors;Measurement;Multimedia communication","Internet;audio signal processing;data compression;information retrieval;multimedia computing;music;pattern clustering","World Wide Web;compression based clustering;multimedia information retrieval;music audio file;music representation;normalized compression distance","","1","","28","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Chinese question classification based on mining association rules","Y. L. Sun","School of Computer and Communication Engineering, Weifang University, Weifang 261061, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","1","","413","416","In this paper, a method of Chinese question classification based on the mining association rules is proposed. Words and Bi-gram are extracted from question as classific features. The method can mine the association rules between the type of the question and its classific features, to construct an association rules - based database. At last the type of the question is marked by choosing the type which the most association rules define. Experimental results show that the proposed method is feasible and can achieve good performance.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5581026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581026","Association rules;Nature Language Processing;Question classification","Association rules;Classification algorithms;Databases;Feature extraction;Machine learning;Taxonomy;Training","data mining;information retrieval;natural language processing","Chinese question classification;association rules mining;natural language processing","","3","","13","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Enriching music mood annotation by semantic association reasoning","J. Wang; X. Anguera; X. Chen; D. Yang","Institute of Computer Science and Technology, Peking University, Beijing, P.R. China 100871","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","1445","1450","Mood annotation of music is challenging as it concerns not only audio content but also extra-musical information. It is a representative research topic about how to traverse the well-known semantic gap. In this paper, we propose a new music-mood-specific ontology. Novel ontology-based semantic reasoning methods are applied to effectively bridge content-based information with web-based resources. Also, the system can automatically discover closely relevant semantics for music mood and thus a novel weighting method is proposed for mood propagation. Experiments show that the proposed method outperforms purely content-based methods and significantly enhances the mood prediction accuracy. Furthermore, evaluations show the system's accuracy could be promisingly increased with the enrichment of metadata.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583243","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583243","Social music;annotation;mood;ontology;semantic reasoning","Accuracy;Cognition;Mood;Music;Ontologies;Psychoacoustic models;Semantics","information retrieval;meta data;music;ontologies (artificial intelligence)","Web-based resources;audio content;content-based information;extra-musical information;metadata;music mood annotation;music-mood-specific ontology;ontology-based semantic reasoning methods;semantic association reasoning","","2","","20","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"The GIS system for the Yunnan soil quality data management and analysis","Liu Liu; Yufeng Zhang; Panhua Ma; Sicong Liu; Wen Lu","Electronic Engineering Department, School of Information Science and Engineering, Yunnan University, Kunming, China, 650091","2010 The 2nd Conference on Environmental Science and Information Application Technology","20100909","2010","2","","768","771","Soil is one of the fundamental elements of human life. However, the growing situation of soil pollution has threatened the ecological balance of terrestrial animals and plants. In order to protect the soil environment, Yunnan Province launched a province-wide soil pollution survey. Until now the statistics and evaluation procession of the sample data has been implemented and a series of valuable results have been obtained. Based on Visual Studio as development platform, ArcEngine as embedded development component, C# as the developing language, SQL Server 2005 as the database, a system is set up to reveal the spatial relationship, distribution patterns and development trends among these results. It provides the functions of information input, maintenance, retrieval, spatial analysis, thematic mapping, etc... By using this system, the integrated management and correlation between the spatial and attribute information are demonstrated in visualization method.","","Electronic:978-1-4244-7390-8; POD:978-1-4244-7387-8","10.1109/ESIAT.2010.5568850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568850","ArcEngine;Data Management and Analysis;embedded components;soil pollution","","data analysis;geographic information systems;information retrieval;soil pollution;visual databases","C# language;GIS system;SQL server;Yunnan soil quality data management;data analysis;ecological balance;embedded development component;evaluation procession;information input function;information retrieval;province-wide soil pollution;spatial analysis;spatial distribution patterns;terrestrial animal;visual studio","","1","","10","","","17-18 July 2010","","IEEE","IEEE Conference Publications"
"Opinion retrieval based on mutual reinforcement between opinon analysis and relavence estimation","R. F. Xu; C. Y. Kit","Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen Postgraduate School, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3347","3352","Different from most existing opinion retrieval systems separately process opinion analysis and relevance estimation as two one-step classification, this paper proposes a coarse-fine multi-pass opinion retrieval system incorporating mutual reinforcement between opinion analysis and relevance estimation. Based on linguistic observation on the opinion expression, some inner-and inter-sentence features are discovered. A multi-pass opinion retrieval system is then designed. Firstly, by using inner-sentence features, two base classifiers corresponding to opinion analysis and relevance estimation tasks, respectively, analyze the opinion and relevance of each sentence in the document. The inter-sentence features, including neighboring sentence-level, paragraph-level and document-level features, are obtained based on coarse analysis results. Secondly, both inner-sentence and inter-sentence features are incorporated the improved classifiers to refine the sentence analysis results and then update the inter-sentence features. Considering the strong association between opinionated sentences and topic-relevance sentences, the individual analysis results are refined following a mutual reinforcement mechanism. The updated features are then feed back to the improved classifier to further refine the sentence analysis results. Such circles terminate until the analysis results converge. Evaluations on NTCIR-7 MOAT dataset show that the proposed system achieved promising results. It shows that the proposed opinion retrieval system integrating coarse-fine analysis strategy and mutual reinforcement mechanism between opinion analysis and relevance estimation are effective.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580678","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580678","Mutual reinforcement;Opinion analysis;Opinion retrieval;Relevance estimation","Context;Cybernetics;DNA;Estimation;Machine learning;Support vector machines;Training","information retrieval;linguistics;pattern classification","NTCIR-7 MOAT dataset;classifiers;coarse fine multipass opinion retrieval;linguistic observation;mutual reinforcement mechanism;opinon analysis;relavence estimation","","0","","14","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"LifeSocial.KOM: A P2P-Based Platform for Secure Online Social Networks","K. Graffi; C. Gross; P. Mukherjee; A. Kovacevic; R. Steinmetz","Multimedia Commun. Lab. (KOM), Tech. Univ. Darmstadt, Darmstadt, Germany","2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P)","20100913","2010","","","1","2","Online social networks with millions of users are very popular nowadays. They provide a platform for the users to present themselves and to interact with each other. In this paper, we present a totally distributed platform for social online networks based on the p2p paradigm, called LifeSocial.KOM. It provides the same functionality as common online social networks, while distributing the operational load on all participating nodes. LifeSocial.KOM is plugin-based and extendible, provides secure communication and user-based data access control and integrates a monitoring component which allows the users and operators to observe the quality of the distributed system.","2161-3559;21613559","Electronic:978-1-4244-7141-6; POD:978-1-4244-7140-9","10.1109/P2P.2010.5569977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569977","","Distributed databases;Graphical user interfaces;Monitoring;Multimedia communication;Peer to peer computing;Security;Social network services","authorisation;computer network security;information retrieval;peer-to-peer computing;social networking (online);software quality","LifeSocial.KOM;P2P-based platform;distributed system quality;monitoring component;participating nodes;plugin-based communication;secure communication;secure online social networks;user-based data access control","","8","","5","","","25-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Chinese text categorization study based on CBM learning","Y. Zhan; H. Chen","Key Lab. of Machine Learning and Computational Intelligence, College of Mathematics and Computer Science, Hebei University, Baoding, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1511","1514","Text Categorization (TC) is an important component in many information organization and information management tasks. In many TC applications, the case-base grows at a fast rate and this causes inefficiency in the case retrieval process. Using Case-Base Maintenance learning via the GC (Generalization Capability) algorithm, which can reduce the case number into KNN algorithm, can improve efficiency when indexing near neighbor in K-Nearest Neighbor algorithm. The numerical experiments prove the validity of this learning algorithm. Since K-NN algorithm is used extensively to a variety of areas, we can improve classification performance further in TC.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569330","CBM;K-NN;Text Categorization","Accuracy;Algorithm design and analysis;Classification algorithms;Databases;Machine learning;Text categorization;Training data","case-based reasoning;information retrieval;learning (artificial intelligence);pattern clustering;statistical analysis;text analysis","CBM learning;Chinese text categorization;K-NN algorithm;case base maintenance learning;generalization capability algorithm;information management;information retrieval process;k-nearest neighbor","","0","","9","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Concentric Layout, a New Scientific Data Distribution Scheme in Hadoop File System","L. Cheng; P. Shang; S. Sehrish; G. Mackey; J. Wang","Univ. of Central Florida, Orlando, FL, USA","2010 IEEE Fifth International Conference on Networking, Architecture, and Storage","20100916","2010","","","231","239","The data generated by scientific simulation, sensor, monitor or optical telescope has increased with dramatic speed. In order to analyze the raw data fast and space efficiently, data pre-process operation is needed to achieve better performance in data analysis phase. Current research shows an increasing tread of adopting MapReduce framework for large scale data processing. However, the data access patterns which generally applied to scientific data set are not supported by current MapReduce framework directly. The gap between the requirement from analytics application and the property of MapReduce framework motivates us to provide support for these data access patterns in MapReduce framework. In our work, we studied the data access patterns in matrix files and proposed a new concentric data layout solution to facilitate matrix data access and analysis in MapReduce framework. Concentric data layout is a hierarchical data layout which maintains the dimensional property in large data sets. Contrary to the continuous data layout adopted in current Hadoop framework, concentric data layout stores the data from the same sub-matrix into one chunk, and then stores chunks symmetrically in a higher level. This matches well with the matrix like computation. The concentric data layout preprocesses the data beforehand, and optimizes the afterward run of MapReduce application. The experiments show that the concentric data layout improves the overall performance, reduces the execution time by about 38% when reading a 64 GB file. It also mitigates the unused data read overhead and increases the useful data efficiency by 32% on average.","","Electronic:978-0-7695-4134-1; POD:978-1-4244-8133-0","10.1109/NAS.2010.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575650","","Analytical models;Arrays;Computational modeling;Data models;Distributed databases;File systems;Layout","data analysis;distributed processing;file organisation;information retrieval;matrix algebra","Hadoop file system;MapReduce framework;concentric data layout solution;data access pattern;data analysis;data pre-process operation;large scientific data set;matrix data access;matrix files;optical telescope;scientific data distribution scheme;scientific simulation","","0","","9","","","15-17 July 2010","","IEEE","IEEE Conference Publications"
"From Tinnitus Data to Action Rules and Tinnitus Treatment","X. Zhang; Z. W. Ras; P. J. Jastreboff; P. L. Thompson","Dept. of Math. & Comput. Sci., Univ. of North Carolina, Pembroke, NC, USA","2010 IEEE International Conference on Granular Computing","20100916","2010","","","620","625","Medical records contain feature values on specific dates, which brings very unstable sampling rate. Therefore popular temporal features, which have been successfully applied to sound data, failed to fully describe the vita behaviors of features and factors of patient and treatment. The authors developed a flexible temporal feature retrieval system based on grouping of similar visiting patterns with connection to an action-rules engine and observed interesting and useful results about how the changes of treatment factors affects the changes of recover.","","Electronic:978-0-7695-4161-7; POD:978-1-4244-7964-1","10.1109/GrC.2010.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5576015","action rules;decision support system;knowledge discovery;tinnitus","Databases;Decision trees;Ear;Feature extraction;Instruments;Medical treatment","decision trees;feature extraction;information retrieval;medical information systems;patient treatment;pattern classification","action rule engine;decision tree;flexible temporal feature retrieval system;tinnitus data;tinnitus treatment","","4","","10","","","14-16 Aug. 2010","","IEEE","IEEE Conference Publications"
"Homogeneous segmentation and classifier ensemble for audio tag annotation and retrieval","H. Y. Lo; J. C. Wang; H. M. Wang","Institute of Information Science, Academia Sinica, Taipei, Taiwan","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","304","309","Audio tags describe different types of musical information such as genre, mood, and instrument. This paper aims to automatically annotate audio clips with tags and retrieve relevant clips from a music database by tags. Given an audio clip, we divide it into several homogeneous segments by using an audio novelty curve, and then extract audio features from each segment with respect to various musical information, such as dynamics, rhythm, timbre, pitch, and tonality. The features in frame-based feature vector sequence format are further represented by their mean and standard deviation such that they can be combined with other segment-based features to form a fixed-dimensional feature vector for a segment. We train an ensemble classifier, which consists of SVM and AdaBoost classifiers, for each tag. For the audio annotation task, the individual classifier outputs are transformed into calibrated probability scores such that probability ensemble can be employed. For the audio retrieval task, we propose using ranking ensemble. We participated in the MIREX 2009 audio tag classification task and our system was ranked first in terms of F-measure and the area under the ROC curve given a tag.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583009","audio segmentation;audio tag annotation;audio tag retrieval;ensemble method","Accuracy;Classification algorithms;Feature extraction;Measurement;Support vector machine classification;Training","audio signal processing;feature extraction;information retrieval;probability;signal classification;support vector machines","AdaBoost classifier;F-measure;MIREX 2009 audio tag classification task;ROC curve;SVM classifier;audio feature extraction;audio novelty curve;audio tag annotation;audio tag retrieval;calibrated probability scores;classifier ensemble;ensemble classifier;frame-based feature vector sequence format;homogeneous segmentation;music database;probability ensemble;ranking ensemble","","4","","14","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"Autonomous Decentralized Community Construction and Reconstruction Technology for Service Assurance","R. Sakamoto; K. Mahmood; Y. Kanamaru; X. Lu; K. Mori","Dept. of Comput. Sci., Tokyo Inst. of Technol., Tokyo, Japan","2010 6th World Congress on Services","20100916","2010","","","485","490","Recent headway in the domains of mobile communication and ubiquitous computing has given surge of interest to mobile commerce applications. Current information systems promote concept of information service provision to anyone, anytime and anywhere. Autonomous Decentralized Community System has been proposed to meet the varying requirements of users. In this paper, the decentralized search service is taken up as an application. This retrieves service in which the service offer end time has been decided beforehand. Needs of this application are the accuracy, the adaptability, and the improvement of the assurance is requested. There are two requirements in this service. First, it is to prevent the network being crowded with the request message from the node where SP that can enjoy serving doesn't exist. And, it is to prevent the stability of the entire system from decreasing to update cash information. To solve these, it proposed the Autonomous Construction Technology and the Autonomous Change Adjustment Technology. Simulation results demonstrate the effectiveness of proposed technology in terms of improvement in service assurance and confirms the trade-off between accuracy and system stability.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575555","accuracy;adaptability;assurance;autonomous decentralized community system;construction and reconstruction","Accuracy;Base stations;Communities;Computer architecture;Construction industry;Mobile communication;Stability analysis","electronic commerce;information retrieval;information services;mobile communication;mobile computing","autonomous change adjustment technology;autonomous construction technology;autonomous decentralized community system;decentralized search service;information retrieval;mobile commerce application;mobile communication;service assurance;ubiquitous computing","","0","","17","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Research on Chinese Natural Language Understanding and Question-Answering System Based on Agent","Y. Zhang; N. Wang; C. Wang; C. Wu","Coll. of Eng. Technol., Northeast Forestry Univ., Harbin, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","4","This paper applies the agent technology and the natural language understanding technology into the question-answering system. Firstly, it introduces the agent technology and the natural language understanding technology; and then a new design method is proposed and system's model including the problem analysis agent model and corpus and search algorithm is constructed. It has solved the problem of computer understanding Chinese, as well as improved the search efficiency and accuracy ratio of question-answering system; at last these methods are applied into the domain of forestry pests and diseases and receive better effect.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5576554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5576554","","Artificial intelligence;Computers;Forestry;Indexes;Natural languages;Vocabulary","information retrieval;natural language processing;software agents","Chinese natural language understanding;agent technology;corpus-and-search algorithm;problem analysis agent model;question-answering system","","1","","8","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Complementary Classification Techniques based Personalized Software Requirements Retrieval with Semantic Ontology and User Feedback","T. Zhang; B. Lee","Sch. of Comput. Sci., Univ. of Seoul, Seoul, South Korea","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1358","1363","Requirements engineering is an important research area in software engineering. Recent years, with the exponentially growing amount of software developed, it is necessary to elicit appropriate software requirements at an early phase of software development. We provide the complementary classification techniques that combine folksonomy, keyword and facet-based retrieval methods to retrieve software requirements related to users' interests. We add semantic ontology and users' feedback to obtain better software requirements that satisfy users' preferences to enhance software requirements retrieval performance. Finally, we demonstrate the feasibility of the method we proposed in software requirements retrieval using an experiment.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.243","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577850","feedback;folksonomy;semantic ontology;software requirement","Computer architecture;Databases;Dictionaries;Ontologies;Semantics;Software;Software engineering","formal specification;information retrieval;ontologies (artificial intelligence)","complementary classification technique;facet-based retrieval;folksonomy-based retrieval;keyword-based retrieval;personalized software requirement retrieval;requirements engineering;semantic ontology;user feedback","","1","","15","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Term Weighting Approaches for Mining Significant Locations from Personal Location Logs","Z. Qiu; C. Gurrin; A. R. Doherty; A. F. Smeaton","CLARITY: Centre for Sensor Web Technol., Dublin City Univ., Dublin, Ireland","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","20","25","In this paper, we describe experiments into the application of term weighting techniques from text retrieval to support the automatic identification of significant locations from a large location log, which we consider to be important for supporting many location-based social network applications. We identify the fact that the distribution of locations follows a similar shaped distribution to that of terms in a language and in so doing motivate our use of term weighting techniques. Using this information we then show that these proven techniques can be used to automatically identify social visits and “pass through” locations, as well as standard home and work locations. We also suggest that it is possible to classify whether an extended segment of personal location data may be a tourist trip, business trip or a typical working (at home) period of time.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578421","GPS;Location;Power-law distribution;important locations;text retrieval","Buildings;Frequency measurement;Global Positioning System;IEEE 802.11 Standards;Mobile communication;Mobile handsets;Social network services","data mining;information retrieval;mobile computing;social networking (online);text analysis","automatic location identification;business trip;home location;location distribution;location-based social network application;pass through location;personal location data;personal location log;segment classification;shaped distribution;significant location mining;social visit;term weighting;text retrieval;tourist trip;work location","","0","","9","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Exploiting Context in Location-Based Information Systems","C. Mettouris; G. A. Papadopoulos","Dept. of Comput. Sci., Univ. of Cyprus, Nicosia, Cyprus","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1593","1598","The area of mobile location-based information systems enumerates many systems that enable their users to digitally annotate physical locations, providing in this way information to others about these locations, communicating with other people in the proximity and publicly expressing their opinions and thoughts. However, no attempts have been made to facilitate the user in describing important situations through annotations and further on, to analyze the textual data provided in the annotations, in order to extract useful information and exploit this information for the benefit of others. We argue that these annotations could be proved critical, as long as the system exploits their content and the context. In this work we propose a mobile location-based annotation system with enhanced context-aware functionality, which enables users to textually annotate public spaces, mainly streets and squares, in order to inform users and authorities about hazardous circumstances, public issues and other important information.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.282","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577937","annotation content;context-awareness;keyword matching;location-based systems;mobile applications;ontology-based methods;ubiquitous systems","Cities and towns;Cognition;Context;Information systems;Mobile communication;Object oriented modeling;Roads","data analysis;information retrieval systems;mobile computing;text analysis","annotation content;context awareness;location-based information systems;mobile location;textual data analysis","","0","","10","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"A framework of ontological semantic knowledge tree for vertical search engine","P. Lu; L. Chen; Y. Gao; Y. Yang","Dept. of Integration Information System and Research Center, Institute of Automation Chinese Academy of Sciences, Beijing, China","2010 Sixth International Conference on Natural Computation","20100923","2010","7","","3682","3686","Search engine is becoming more and more important in our life. Traditional search technologies, however, cannot provide the required information for the users. Future search engine must be intelligent and semantic. We develop a vertical search engine based on ontological semantic knowledge tree model. In this model, concept is regarded as the basic knowledge representation unit. And attribute, relation and behavior describe concept. On the basis of characteristics of Chinese, concept is divided into primitive concept, semantic binding concept, semantic state concept and semantic logical concept. Then these concepts are organized by tree hierarchical structure to describe a specific domain. And this model has been proved successfully to many domains such knowledge reasoning of agriculture and knowledge service of automobile etc. Subsequently, the architecture of search engine are described, especially, semantic classification has been proved practical. Finally, because this tree is expansible, vertical search engine can be built on any domain.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5583740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583740","Ontology;Semantic Knowledge Tree;Vertical Search Engine","Indexing;Industries;Natural languages;Ontologies;Search engines;Semantics","inference mechanisms;information retrieval;ontologies (artificial intelligence);search engines;trees (mathematics)","knowledge reasoning;knowledge representation unit;knowledge service;ontological semantic knowledge tree;search technology;semantic binding concept;semantic logical concept;semantic state concept;tree hierarchical structure;vertical search engine","","0","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Web information processing and extracting","K. Gao; B. Q. Zong; X. L. Yang","Department of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhuang 050018, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","5","","2350","2355","With the rapid growth of the web, search engine has been an important tool to retrieve relevant information from the Internet. Due to the limited bandwidth, storage and some other limitations, the general search engine is not suitable for some situations. A topical search engine which is focused on collecting domain-specific issues by focused crawling is needed. It can provide higher accuracy than general search because of the lack of irrelevant information on the domain collection, so the web information processing and extracting is necessary. This paper presents some strategies on web information processing, together with analyzing and extracting based on data content mining. The experimental result validates the suitable of the approach, and some problems are also present in the end.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580664","Crawling;Information extracting;Information processing;Topical search","Accuracy;Data mining;Databases;Materials;Noise;Web pages","Internet;data mining;information retrieval;search engines","Web information extracting;Web information processing;data content mining;search engine","","1","","12","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"An Extraction Method of Moving Object Based on Visual Cognition Mechanism","M. Li; H. Wang; X. Yan; L. Xu","Coll. of Comput. & Inf., Hohai Univ., Nanjing, China","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","544","551","Reichardt motion detector is the most basic mechanism of motion perception of biological vision system. But because of the aperture problem and the dependence of scene pattern, the detected motion information is always ambiguity. However, the vision cognition mechanism shows that: the motion perception of vision system doesn't only detect motion velocity, but also supplies the temporal feature to assist object recognition. Thus this paper puts emphasis on the contribution of temporal features to the moving object recognition and extraction, rather than the accuracy of motion estimation. A spatial-temporal iterative feed forward method was proposed to identify the moving objects. The common motion information is propagated along the similar spatial features; the temporal synchrony binds spatial features of the same object. By the interactive process, the moving object will be recognized and extracted by the bound spatial feature, and the ambiguity motion information will be corrected. The proposed method can overcome error motion information caused by noise, camera-self oscillation and poor luminance.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578160","Reichardt motion detector;object extraction;object recognition;vision congition","Biology;Cognition;Detectors;Feature extraction;Object recognition;Pixel","cognition;feature extraction;feedforward neural nets;information retrieval;object recognition;visual perception","Reichardt motion detector;ambiguity motion information;biological vision system;bound spatial feature;camera self oscillation;error motion information;interactive process;motion perception;motion velocity;moving object extraction;object recognition;spatial-temporal iterative feed forward method;temporal feature;visual cognition mechanism","","0","","13","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Causality and imperfect causality from texts: A frame for causality in social sciences","A. Sobrino; J. A. Olivas; C. Puente","Faculty of Philosophy, University of Santiago de Compostela, La Coru&#x00F1;a, Spain","International Conference on Fuzzy Systems","20100923","2010","","","1","8","The focus of this paper is the study of causality in both its crisp and approximate forms. Crisp causality is characterized by some properties and modalities and is related to semantic implications. This paper presents a program that extracts causal and conditional sentences with causal content from several texts. The examples extracted show that, even in scientific texts, causality can be imprecise or imperfect, as shown by the linguistic modifiers or the fuzzy quantifiers embedded in them. Quantum mechanics introduces imprecision in physics, but social sciences are the disciplines that show more circumstantial and imperfect links between cause and effect. In social sciences, there are two theoretical paradigms to understanding imperfect causality: (i) cause as an `ideal type', from Weber, (ii) cause as a `family resemblance predicate', from Anscombe, a follower of Wittgenstein's philosophy. Our work provides two short exemplifications of these paradigms using the causal or conditional sentences retrieved from texts of different genres.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584863","","Accidents;Context;Law;Materials;Prototypes;Quantum mechanics","causality;computational linguistics;content management;information retrieval;knowledge acquisition;philosophical aspects;physics;quantum theory;scientific information systems;social sciences;text analysis","Anscombe;Crisp causality;Weber;Wittgenstein philosophy;causal extraction;conditional sentence;family resemblance predicate;fuzzy quantifier;imperfect causality;linguistic modifier;physics;quantum mechanics;scientific text;semantic implication;sentence retrieval;social science","","1","","25","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Online topic detection and tracking of financial news based on hierarchical clustering","X. Y. Dai; Q. C. Chen; X. L. Wang; J. Xu","Intelligence Computing Research Center, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen 518055, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3341","3346","In this paper, we apply TDT technology to the vertical search engine in the financial field. The returned results are grouped into several topics with the stock as the unit. Then we show the topics to the users in time series order. As a result, users can easily learn about the important events which belong to a stock. Moreover, the causes and the effects of these events can also be found out easily. We improve the common agglomerative hierarchical clustering algorithm based on average-link method, which is then used to implement the retrospective topic detection and the online topic detection of news stories of the stocks. Additionally, the improved single pass clustering algorithm is employed to accomplish topic tracking. We consider that the feature terms which occur in the title of a news story contribute more during the similarity calculation and increase their corresponding weights. Experiments are performed on two datasets which are annotated by human judgment. The results show that the proposed method can effectively detect and track the online financial topics.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580677","Agglomerative Hierarchical Clustering;Topic Detection and Tracking;Vector Space Model","Clustering algorithms;Clustering methods;Computational modeling;Cybernetics;Machine learning;Measurement;Web pages","information retrieval;pattern clustering;portals;search engines;stock markets;text analysis;time series","TDT technology;agglomerative hierarchical clustering algorithm;average-link method;financial news;online topic detection;online topic tracking;retrospective topic detection;single pass clustering algorithm;stock news;time series;topic tracking;vertical search engine","","17","","11","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Content Retrieval Delay Driven by Caching Policy and Source Selection","M. Bjorkqvist; L. Y. Chen","IBM Res. Zurich Lab., Ru&#x0308;schlikon, Switzerland","2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems","20100923","2010","","","397","399","In this paper we study the content retrieval delay in a hybrid content distribution system, e.g., emerging content clouds [1], where a requested content item can be vertically retrieved from the central server and horizontally retrieved from network nodes. The content retrieval delay depends on the load intensities of the retrieval sources, which have asymmetric system properties such as bandwidth and cache capacity. The retrieval traffic arises due to heterogeneous content availability, i.e., content diffusion resulting from the applied caching policies, and the selection of retrieval sources. To optimize the retrieval delay, the advantages of the network nodes should be utilized while also leveraging the caching and retrieval capacity of the server. The traffic loads and latency of a given combination of source selection and caching policy is derived based on the content diffusion and distribution in the entire system. The simulation and analytical results show that satisfactory content retrieval delay is achieved when the retrieval selection is load aware and the caching policies can effectively utilize the cache storage and retrieval capacity of both the network nodes and the server.","1526-7539;15267539","Electronic:978-0-7695-4197-6; POD:978-1-4244-8181-1","10.1109/MASCOTS.2010.50","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581615","","Analytical models;Bandwidth;Delay;Peer to peer computing;Scalability;Servers;Silver","cache storage;content management;information retrieval;network servers","asymmetric system;caching policy;content diffusion;content distribution;content retrieval;delay driven;heterogeneous content availability;hybrid content distribution system;load intensity;network nodes;network server;retrieval source;source selection","","2","","9","","","17-19 Aug. 2010","","IEEE","IEEE Conference Publications"
"Improving diversity in Web search results re-ranking using absorbing random walks","G. L. Lin; H. Peng; Q. L. Ma; J. Wei; J. W. Qin","School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","5","","2116","2421","Search result diversification has become important for improving Web search effectiveness and user satisfaction, as redundancy in top ranking results often disappoints users. To solve this problem, many techniques have been proposed to make a tradeoff between the relevance and diversity. Among them, GRASSHOPPER which utilizes the framework of absorbing random walks has shown good performance. In this paper, we propose a novel algorithm named DATAR with a new ranking strategy, which improves the diversification ability of GRASSHOPPER. Also, we make a discussion on the reason why DATAR is better. We evaluated the proposed algorithm with a public dataset ODP239 and a real search result dataset collected from Google. The experiment results show that the proposed DATAR algorithm outperforms GRASSHOPPER in improving diversity in Web search results re-ranking.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580733","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580733","Absorbing random walks;Ranking with diversity;Search result diversification;Web search","Absorption;Cybernetics;Diversity reception;Google;Machine learning;Markov processes;Web search","Internet;information retrieval;search engines","DATAR algorithm;GRASSHOPPER;Google;Web search;absorbing random walks;public dataset ODP239;user satisfaction","","0","","14","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Availability and Redundancy in Harmony: Measuring Retrieval Times in P2P Storage Systems","L. Pamies-Juarez; P. Garcia-Lopez; M. Sanchez-Artigas","Univ. Rovira i Virgili, Tarragona, Spain","2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P)","20100913","2010","","","1","10","Peer-to-peer (P2P) storage systems are strongly affected by churn - temporal and permanent peer failures. Because of this churn, the main requirement of such systems is to guarantee that stored objects can always be retrieved. This requirement is specially needed in two main situations: when users want to access the stored objects or when data maintenance processes have to repair lost information. To meet this requirement, exiting P2P storage systems introduce large amounts of redundancy that maintain data availability close to 100%. Unfortunately, these large amounts of redundancy increase the storage costs, either by reducing the overall net capacity or by increasing the communication required for data maintenance. In order to minimize storage costs, P2P storage systems can reduce data redundancy. However, less redundancy means lower data availability, which leads to increase object retrieval times. Unfortunately, longer retrieval times could compromise data maintenance processes and could penalize user's retrieval times. It is crucial then for P2P storage systems to predict the effects of a redundancy reduction. In order to provide this information, we present a novel analytical framework to measure object retrieval times under different redundancy and churn circumstances. Our framework can be directly used by backup applications aiming to maintain durability at the lower cost, or by data sharing applications that seek to reduce costs by penalizing user retrieval times. We validate our framework by simulation using real P2P traces (Skype and eMule's KAD).","2161-3559;21613559","Electronic:978-1-4244-7141-6; POD:978-1-4244-7140-9","10.1109/P2P.2010.5570002","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5570002","","Availability;Book reviews;IEEE Communications Society;Maintenance engineering;Peer to peer computing;Redundancy;Stochastic processes","information retrieval;information storage;peer-to-peer computing;redundancy;reliability;storage allocation","P2P storage system;data availability;data maintenance process;data sharing application;object retrieval times measurement;peer-to-peer storage system","","5","","26","","","25-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Features extraction in the copper futures market of China based on DIV clustering method of interval data","J. Meng","School of Statistics, Central University of Finance and Economics, Beijing 100081, China","Proceedings of the 29th Chinese Control Conference","20100920","2010","","","5555","5558","In futures market, daily trading records of numerous contracts compose a large scale database. How to integrate the mass data, extract the general features, and find out the underlying operational regularity of the market are significant to instruct the sound development of the market. For that research motivation, this paper utilizes the symbolic data analysis (SDA) methodology to model on the large scale database of the copper futures contracts in Shanghai Futures Exchange (SHFE). First, classify the mass and complex time-series trading records in the temporal dimension as their residual time to maturity, so that the original data set of single-values is transformed into the high-level structure of symbolic interval data which greatly reduces the dimension scale of the sample space. Based on that, symbolic DIV clustering method is applied to the interval data and three clusters partitioned by the size of trading volume are obtained. Moreover, ZoomStar graphs of the three clusters are also clearly illustrated the variation features of the copper futures. The results of the empirical study indicate that in the whole valid period of transaction, speculations present a “less-more-less” quantity in trading volume and open interest, and the tradings in two and three months to maturity are especially more active than in the other time. The application research also verifies the validity and practicability of SDA in integrating complex system, effectively modeling and information mining.","1934-1768;19341768","Electronic:978-7-8946-3104-6; POD:978-1-4244-6263-6","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573411","Clustering;DIV;Futures Market;Interval Data;Symbolic Data Analysis","Clustering methods;Contracts;Copper;Data analysis;Data mining;Feature extraction;Principal component analysis","commodity trading;copper;data analysis;data mining;graph theory;information retrieval;pattern classification;pattern clustering;symbol manipulation;time series","China;DIV clustering;Shanghai Futures Exchange;ZoomStar graph;copper futures contract;features extraction;futures market;information mining;large scale database;symbolic data analysis;symbolic interval data;time-series;trading records","","0","","9","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"Towards a multi-agent based architecture to simulate the reality of a stock exchange market","S. Mellouli; F. Bouslama","Management Information Systems Departement, Faculty of Business School, Laval University, Quebec, Canada","ACS/IEEE International Conference on Computer Systems and Applications - AICCSA 2010","20100927","2010","","","1","8","In this paper, the initial steps of the development process of an agent-based architecture used to simulate the reality of a stock exchange market are provided. This architecture includes a representation of all market participants from investors to floor traders. There are five main modules in the proposed architecture: an information retrieval and ontology module which extracts online market news and data, a knowledge base which includes portfolios compositions, a strategy and planning module used as an analysis tool, a learning module based on market historical data where agents learn market behavior and tendencies, and finally a decision making module with which agents make decisions on buying and selling of stocks. The information retrieval and ontology module is then detailed to show the proposed ontology representing the financial news. This architecture can be used to develop simulation platforms for stock markets.","2161-5322;21615322","Electronic:978-1-4244-7717-3; POD:978-1-4244-7716-6","10.1109/AICCSA.2010.5587011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587011","","","decision making;information retrieval;multi-agent systems;ontologies (artificial intelligence);software architecture;stock markets","decision making module;financial news;floor trader;information retrieval;investor;knowledge base;learning module;market behavior;market historical data;market participant;market tendency;multiagent based architecture;online market data;online market news;ontology;planning module;portfolio composition;stock buying;stock exchange market;stock selling;strategy module","","0","","20","","","16-19 May 2010","","IEEE","IEEE Conference Publications"
"Extraction, analysis and representation of imperfect conditional and causal sentences by means of a semi-automatic process","C. Puente; A. Sobrino; J. A. Olivas; R. Merlo","Advanced Technical Faculty of Engineering ICAI, Pontificia Comillas University, Madrid, Spain","International Conference on Fuzzy Systems","20100923","2010","","","1","8","Causality is not only a matter of causal statements, but also of conditional sentences. In conditional statements, causality generally emerges from the entailment relationship between the antecedent and the consequence. This entailment is frequently vague and uncertain in nature. In this article, we present a method of retrieving crisp and imperfect conditional and causal sentences identified by some linguistic patterns. These sentences are pre-processed to obtain both single cause-effect structures and causal chains. The result is displayed automatically in an imperfect causal graph by means of a Java application. The causal graph shows the strenght of the causal link labelling it with a fuzzy quantifier and the intensity of the cause or effect nodes with linguistics hedges. The knowledge base used to provide automatic information based on causal relations was some medical texts, suited for the described process.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5584115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584115","","Artificial neural networks;Cancer;Data mining;Databases;Knowledge based systems;Lungs;Pragmatics","Java;causality;computational linguistics;information retrieval;knowledge representation;linguistics;text analysis","Java application;causal graph;causal statements;causality;cause-effect structure;conditional sentence;fuzzy quantifier;linguistic pattern","","4","","30","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Efficient Optimization of H.264 Decoder on PAC Duo SoC Platform","K. C. Liu; S. Y. Tseng; W. S. Wang; J. K. Yang; W. C. Su","SoC Technol. Center, Ind. Technol. Res. Inst., Hsinchu, Taiwan","2010 5th International Conference on Embedded and Multimedia Computing","20100916","2010","","","1","4","H.264 has become a popular video compression standard for years; however, the complexity of computation and huge amount of external data access are still the main problems. In this paper, we will propose two mechanisms to fulfill high performance H.264 baseline profile decoder on PAC Duo SOC platform. To reduce the complexity of computation, in addition to algorithm optimization, we use parallelizing method by partitioning the process of the independent data into two processor clusters of PACDSP so that they can be processed in parallel. To reduce the waiting time caused by the latency of external data access, we employ the overlapping approach so that the PACDSP always processes the data without referring to the being transferred external data According to the experimental result of eight baseline CIF sequences, the performance of H.264 decoder software utilizing the mentioned mechanisms is higher than 59.8 frames per second, in average, when runs in one PACDSP in the PAC Duo platform.","2159-1520;21591520","Electronic:978-1-4244-7713-5; POD:978-1-4244-7710-4","10.1109/EMC.2010.5575757","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575757","","Complexity theory;Decoding;Multimedia communication;Optimization;Software;System-on-a-chip;Video coding","computational complexity;data compression;decoding;information retrieval;optimisation;parallel processing;video coding","H.264 decoder algorithm optimization;PAC Duo SoC platform;computation complexity;data access;eight baseline CIF sequences;independent data process;parallelizing method;processor clusters;video compression standard","","0","","9","","","11-13 Aug. 2010","","IEEE","IEEE Conference Publications"
"Musical perceptual similarity estimation using interactive genetic algorithm","S. Wang; H. Zhu","Key Lab of Computing and Communicating Software of Anhui Province, School of Computer Science and Technology, University of Science and Technology of China","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","7","This paper proposes a new approach to estimate the emotional perceptual similarity of music using interactive genetic algorithm. Different combinations of measure function and feature weights construct the searching space, and users' subjective similarity evaluations of musical pieces are used as the fitness. The approach tries to search for the optimal combination of measure function and feature weights to better reflect human's perception. A comparative emotion detection experiment is designed to explore the effectiveness of our approach in our MIDI database. The one is the simple K-Nearest Neighbor (KNN) and the other is the modified KNN using the optimal combination obtained. Experimental results show that our method outperforms the simple KNN classifier, which confirms its usefulness of better reflecting human's perception.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586527","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586527","","Biological cells;Encoding;Humans;Phase measurement;Training;Weight measurement","audio databases;behavioural sciences;genetic algorithms;information retrieval;music;signal classification","K-nearest neighbor;KNN classifier;MIDI database;emotion detection;emotional perceptual similarity estimation;feature weight;human perception;interactive genetic algorithm;measure function;musical perceptual similarity estimation;musical piece;searching space;subjective similarity evaluation","","1","","12","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"Towards comprehensive integration management of business continuity, records and knowledge","X. An; W. Wang","Key Laboratory of Data Engineering and Knowledge Engineering of the Ministry of Education, Renmin University of China, Beijing 100872, China","The 6th International Conference on Networked Computing and Advanced Information Management","20100916","2010","","","5","10","Many of management systems for business continuity, records and knowledge (BRK) are standalone. Connections and networks of business continuity management systems (BCMS), records management systems (RMS) and knowledge management systems (KMS) are expected to study for facing challenges from evidence-based collaborations in a networked working environment, in terms of control of documented information for business efficiency; guarantee of evidentiality and quality of documented information for organizational effectiveness; and sharing, protecting and increasing values of records as business and knowledge assets for knowledge economy. Based on review of ideas of integration management thinking, best practice frameworks of business continuity management, records management and knowledge management, management models of BCMS, RMS and KMS, an architecture framework towards comprehensive integration management of BRK is proposed by vertical integration design and crosswise integration operations. Case studies demonstrate that such architecture framework has implications to enhance controls of efficiency, effectiveness, and economy of organizational resources and assets adaptable to complex global competition; to improve quality assurance of documented information for supporting evidence-based governance adaptable to dynamic changing of information and communication technologies; to consistent accumulation, sharing and exchanging evidence, memory and knowledge along e-business processes to promote collaboration, optimization and innovation of BCMS, RMS and KMS.","","Electronic:978-89-88678-26-8; POD:978-1-4244-7671-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5572397","Business continuity management;Comprehensive integration management framework;Knowledge management;Records management","Adaptation model;Biological system modeling;Business;Communities;Knowledge engineering;Optimization;Process control","business continuity;business data processing;information retrieval systems;knowledge management;optimisation;organisational aspects;records management","BCMS;KMS;RMS;business continuity management systems;document information;e-business processes;evidence-based collaboration;integration management framework;knowledge economy;knowledge management systems;optimization;organizational resource;records management systems","","0","","31","","","16-18 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Ciphertext Retrieval Model for Encrypted XML Database with Bucket Management Algorithm","X. m. Lu; J. You; Y. j. Zhou","Sch. of Electron. & Inf., Northwestern Polytech. Univ., Xi'an, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","4","To resolve the problems of security and ciphertext query efficiency for the XML database, a ciphertext retrieval model is presented in this paper. In this model, the value index and structure index in the encrypted XML database are established and the entrance addresses are recorded with the bucket management algorithm to realize the rapid retrieval for encrypted XML data. Experiments results show that this model not only has high security and improved ciphertext retrieval efficiency, but also supports the range query and easy to update.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5575632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575632","","Algorithm design and analysis;Encryption;Indexes;XML","XML;cryptography;information retrieval;security of data","bucket management algorithm;ciphertext retrieval model;encrypted XML database;security;structure index;value index","","2","","8","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Efficient algorithm for handling dangling pages using hypothetical node","A. K. Singh; P. Ravi Kumar; A. G. Kwang Leng","Department of Electrical and Computer Engineering, Curtin University of Technology, Miri, Malaysia","6th International Conference on Digital Content, Multimedia Technology and its Applications","20100909","2010","","","44","49","Dangling pages are one of the major drawbacks of page rank algorithm which is used by different search engines to calculate the page rank. The number of these pages increasing with web as the source of knowledge. However search engines are the main tools used in knowledge extraction or Information retrieval from the Web. We proposed an algorithm to handle these pages using a hypothetical node and comparing it with page rank algorithm.","","Electronic:978-8-9886-7827-5; POD:978-1-4244-7607-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568585","Dangling Pages;Link rot;PageRank;Penalty Pages;zero-one-gap","Robots","Internet;information retrieval;search engines","Web;dangling pages;hypothetical node;information retrieval;knowledge extraction;page rank algorithm;search engines","","0","","14","","","16-18 Aug. 2010","","IEEE","IEEE Conference Publications"
"Database Narratives: Conceptualising Digital Heritage Databases in Remote Aboriginal Communities","H. Cohen; R. Morley; P. Dallow; L. Kaufmann","Sch. of Commun. Arts, Univ. of Western Sydney, Sydney, NSW, Australia","2010 14th International Conference Information Visualisation","20100913","2010","","","422","427","Interactive web-based resources are significant to the mediation of culture in that they act as an interface (Newton: 2003) between communities and information structures. The focus of this paper is on the use of digital media arts and user-centered technologies to develop a digital heritage resource to revitalize a community's cultural capital. The paper addresses the creation and use of an interactive database that forms the portal to a digital repository of archival media. The database supports and extends an Australian classic memoir, Journey to Horseshoe Bend by TGH Strehlow. Journey to Horseshoe Bend is a vivid ethno-historiographic account of the Aboriginal (Arrernte/Arrarnta), settler and Lutheran communities of Central Australia in the 1920's. The Journey to Horseshoe Bend database draws on a broad range of visual representations (including images, maps, concept diagrams, text and other media resources), and through hyperlinks connects these media to specific annotated points in an electronic version of the book. The paper focuses on the book's use as a digital heritage resource and explores the link between information architectures and knowledge practices in particular contexts to address the following question: How can a digital heritage resource be conceived as a sustainable emerging “thing-in-the-making” to reflect community, cultural and knowledge interests? Background resources: http://bugs.commarts.uws.edu.au/cocoon/jhsb/item/69994/ and project website: http://www.commarts.uws.edu.au/jthb/.","1550-6037;15506037","Electronic:978-0-7695-4165-5; POD:978-1-4244-7846-0","10.1109/IV.2010.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571201","Aboriginal;Strehlow;database;digital;heritage","Australia;Communities;Context;Cultural differences;Databases;Global communication;Visualization","Internet;database management systems;humanities;information retrieval systems;interactive systems;portals","Australian classic memoir;Journey to Horseshoe Bend database;archival media;database narratives;digital heritage databases;digital media arts;ethno-historiographic account;interactive Web-based resources;remote aboriginal communities;user-centered technologies","","0","","17","","","26-29 July 2010","","IEEE","IEEE Conference Publications"
"Crawling Result Pages for Data Extraction Based on URL Classification","T. Nie; Z. Wang; Y. Kou; R. Zhang","Key Lab. of Med. Image Comput., Northeastern Univ., Shenyang, China","2010 Seventh Web Information Systems and Applications Conference","20100923","2010","","","79","84","In Web database integration, crawling data pages is important for data extraction. The fact that data are contained by multiple result pages increases the difficulty of accessing data for integration. Thus, it is necessary to accurately and automatically crawl query result pages from Web database. To address this problem, we propose a novel approach based on URL classification to effectively identify result pages. In our approach, we compute the similarity between URLs of hyperlinks in result pages and classify them into four categories. Each category maps to a set of similar web pages, which separate result pages from others. Then, we use the page probing method to verify the correctness of classification and improve the accuracy of crawled result pages. The experimental result demonstrates that our approach is effective for identifying the collection of result pages in Web database, and can improve the quality and efficiency of data extraction.","","Electronic:978-0-7695-4193-8; POD:978-1-4244-8440-9","10.1109/WISA.2010.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581367","URL;classification;component;data extraction;result pages","Accuracy;Classification algorithms;Clustering algorithms;Data mining;Databases;Web pages","Web sites;information retrieval;online front-ends","URL classification;Web database;Web pages;category map;crawling data pages;crawling result pages;data extraction;hyperlinks","","0","","9","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"An ontological fuzzy Smith-Waterman with applications to patient retrieval in Electronic Medical Records","M. Popescu","University of Missouri Informatics Institute, Columbia, MO 65211 USA","International Conference on Fuzzy Systems","20100923","2010","","","1","6","With the introduction of Electronic Medical Records (EMR) systems in health care institutions, a huge data repository has been created. By employing computational intelligence (CI) techniques, this data repository can be used to address important health care issues such as improving quality and reducing medical errors. In this paper, we introduce a general word sequence alignment method based on a fuzzy version of the Smith-Waterman (SW) dynamic programming algorithm. The word similarity matrix used in computing the sequence alignment is calculated based on a domain ontology (taxonomy). The fuzzy version of the SW algorithm is designed to accommodate words not present in the initial dictionary used to precompute the similarity matrix, hence avoiding its recalculation. We apply the developed algorithm for patient retrieval in an EMR. Each patient is described by an ordered sequence of ICD9 diagnoses. We analyze various properties of the proposed algorithm on a patient dataset that contains 107 patients described by ICD9 diagnose sequences.","1098-7584;10987584","Electronic:978-1-4244-6921-5; POD:978-1-4244-6919-2","10.1109/FUZZY.2010.5583953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583953","","Algorithm design and analysis;Bioinformatics;Drugs;Medical diagnostic imaging;Neodymium;Ontologies","dynamic programming;fuzzy set theory;health care;information retrieval;medical information systems;ontologies (artificial intelligence)","computational intelligence techniques;dynamic programming algorithm;electronic medical records;general word sequence alignment method;health care institution;ontological fuzzy Smith-Waterman;patient retrieval","","2","1","20","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A Case Retrieval Algorithm Based on Bayesian Estimation","Y. Xiao; X. Zhou; K. Wu","Sch. of Manage. & Eng., Nanjing Univ., Nanjing, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","5","Implementing knowledge engineering in DSS has brought a problem of inefficient reasoning due to huge searching space. The use of case-based reasoning technique has ameliorated the situation. The validity of case retrieval directly influences the effect of case-based reasoning, and the key is to measure the similarity between cases. In this paper, an algorithm for cases similarity computation based on Bayesian Estimation is proposed. First, we designate the priori distribution parameters by the semantic distance-based similarity algorithm, and then calculate the posteriori encountering probability using Bayesian Estimation, thereby, the cases semantic similarity integrating the subjective experience with the objective statistic is acquired. This approach can effectively improve the success rate of case retrieval in the situation of incomplete sample information.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5576882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5576882","","Algorithm design and analysis;Bayesian methods;Cognition;Nearest neighbor searches;Ontologies;Semantics","Bayes methods;case-based reasoning;decision support systems;information retrieval;probability","Bayesian estimation;DSS;case retrieval algorithm;case-based reasoning;cases similarity computation;knowledge engineering;objective statistic;posteriori encountering probability;priori distribution parameters;semantic distance based similarity algorithm","","0","","15","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"MAuth: A Fine-Grained and User-centric Permission Delegation Framework for Multi-mashup Web Services","M. Alam; X. Zhang; M. Nauman; S. Khan; Q. Alam","Security Eng. Res. Group, Inst. of Manage. Sci., Peshawar, Pakistan","2010 6th World Congress on Services","20100916","2010","","","56","63","Mashups are a new breed of interactive web applications that aggregate and stitch together data retrieved from one or more sources to create an entirely new and innovative set of services. The paradigm is not limited to social networks and many enterprises are redesigning their business processes to create interactive systems in the form of mashups. However, protecting users' private data from unauthorized access in mashups is a challenging security problem. Existing solutions for addressing the various authorization problems are limited due to all-or-nothing policy, third party dependence and scalability issues. In this paper, we present a general permission delegation model for mashups that is fine-grained, user centric and scalable. This contribution has the following objectives: We formally specify the dependency relationships among multiple web applications. Dependency relationships are categorized on the basis of specific data items. We present an extensible reference architecture for configuring multiple web applications and a session management protocol.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575603","Access Control;Mashup;Permission Delegation;Security","Authorization;Google;Mashups;Protocols;Social network services","Web services;authorisation;information retrieval;software architecture","MAuth;authorization problems;business processes;extensible reference architecture;multimashup Web services;session management protocol;social networks;unauthorized access;user-centric permission delegation framework","","1","","22","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"An information extraction of title panel in engineering drawings and automatic generation system of three statistical tables","Z. Jiang; X. Feng; Xianzhang Feng; Yuanpeng Liu","School of Mechatronics Engineering, Zhengzhou Institute of Aeronautical Industry Management, 450015, China","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","1","","V1-297","V1-301","The title panel information in engineering drawings is the important data source for product data management (PDM). Firstly, the data structure of title panel and bill of material (BOM) information in engineering drawing was analyzed, and the collected concourse based on the describing information cell was put forward. Then the text-objects and line-objects within the collection concourse were handled to get the information of the text objects and its position by information cell recognition and format recognition. And also, the data concerning the extracted information was written into the database. Finally, the development and implement of the TST compilation and the generation system automatically based on the bill of material (BOM), bills of standard (BOS) and bills of purchase (BOP) (i.e. TST) was accomplished. The info consistency between the engineering drafting and the compilation of TST was assured by using the software package based on this method in practical project, and the designing efficiency was enhanced in favor of the implement of CAPP.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579014","Attribute of component and part;Automatic generation system;Information extraction;Result buffer;Three statistical tables (TST);Title panel","","bills of materials;information retrieval;product life cycle management;production engineering computing","bill of material;bills of purchase;bills of standard;engineering drawings;information extraction;product data management;statistical table generation system;title panel information","","0","","19","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Relationship extraction from biomedical literature using Maximum Entropy based on rich features","L. Yao; C. J. Sun; X. L. Wang; X. Wang","Department of Computer Science, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3358","3361","Relation extraction is the detection and classification of interactions between named entities. Recently, a lot of studies have focused on the relation extraction from biomedical literatures. Although various approaches have been applied on this area, most methods are either pre-requires biomedical lexicons or parsing templates which are not suitable for complexities of biomedical literatures. In this paper, applying existing lexicons, we propose a Maximum Entropy method based on rich features to extract the interactions between the disease and treatment. This task is a multi-class biomedical relationship extraction. Experiment results show that the proposed method can achieve a comparable performance with the state-of-the-art generative biomedical relation extraction methods on multi-class disease-treatment interaction extraction.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580680","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580680","Biomedical relation extraction;Disease-treatment interaction;Maximum entropy model;Supervised learning","Artificial neural networks;Data mining;Diseases;Entropy;Feature extraction;Proteins;Semantics","grammars;information retrieval;maximum entropy methods;medical computing;patient treatment","biomedical lexicons;biomedical literature;maximum entropy;multiclass biomedical relationship extraction;multiclass disease-treatment interaction extraction;parsing templates;rich features","","1","","16","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"One-class classification models for financial industry information recommendation","J. Xu; Q. C. Chen; X. L. Wang; Z. Y. Wei","Department of Computer Science and Technology, Key Laboratory of Network Oriented Intelligent Computation, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518055, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3329","3334","In finance domain, the acquisition of in-time and comprehensive intra-industry information is important for decision-makers and stock investors to maximize their investment profits. But there are following problems in the retrieval and recommendation of financial industry information. (1) Unlike the concrete conceptions, industry could not be perfectly delineated with keywords. (2) It's difficult to calculate the relevance between document and industry. (3)The massive search results confused the user as a result of the information overload. In this paper, this problem is treated as a classification of relevance. The one-class classification model is adopted to calculate the relevance between document and industry since the lack of well sampled non-relevant documents. Based on selected industry-specific description terms, three different one-class classifiers k-means, one-class SVM and language model algorithm are trained with only relevant (positive) documents to help making recommendation decisions. The experimental results show that the proposed methods perform well with high micro-average F1 and macro-average F1 both up to the 80%. We also perform experiments to verify the relationship between parameters and performance.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580675","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580675","Finance Text Analysis;Language Model;One-class Classification;One-class SVM;k-Means","Banking;Computational modeling;Transportation","classification;information retrieval;investment;pattern classification;recommender systems;support vector machines","comprehensive intra-industry information acquisition;decision-makers;financial industry information recommendation;financial industry information retrieval;investment profits;language model algorithm;one-class SVM;one-class classification models;one-class classifiers k-means;recommendation decisions;relevance classification;stock investors","","0","","20","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Comparison of Performance in Automatic Classification between Chinese and Western Musical Instruments","J. Liu; L. Xie","Commun. Acoust. Lab., Commun. Univ. of China, Beijing, China","2010 WASE International Conference on Information Engineering","20100916","2010","1","","3","6","Classification of musical instrument is resulted from musicology. Thus, automatic identification of instrument families not only benefits the study in musicology, but also worth of attention in MIR. Based on a database consists of 2177 clips from Chinese and Western instrumental music, the experiments provided in this paper evaluate the ability of automatic Chinese and Western instrument identification by confusion matrices. Regarding various features and classifiers, the experiment results revealed the similarity and difference between Chinese and western instrumental music, which produce new possibilities for the study in identifying and classifying Chinese and Western instrument families.","","Electronic:978-1-4244-7507-0; POD:978-1-4244-7506-3","10.1109/ICIE.2010.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571760","Confusion Matrix;Instrument Identification;MIR","Accuracy;Classification algorithms;Feature extraction;Instruments;Mel frequency cepstral coefficient;Support vector machines;Training","database management systems;information retrieval;music;musical instruments;pattern classification","MIR;automatic instrument identification;automatic musical instrument classification;chinese musical instrument;confusion matrices;instrumental music;musicology;western musical instrument","","2","","14","","","14-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic Annotation for the Generation of Extraction Rules","Y. Shi; R. Chen","Coll. of Informational Sci. & Technol., Dalian Maritime Univ., Dalian, China","2010 International Conference on Management and Service Science","20100916","2010","","","1","5","Current Web information extraction systems are supervised systems which require manual annotation of training instances in order to learn extraction rules. The annotation is tedious and subject to changes when Web sites upgrade. In this paper, we present a finite-state-transducer-based method of automatic annotation, which can deal with pages with missing attributes, multiple-valued attributes, multi-ordering attributes. Moreover, we also argument it with probability theory to reduce the uncertainty of the state machine. The experimental results show that our algorithm can annotate Web pages efficiently and accurately and thus speed-up extraction rules learning in Web information extraction systems.","","Electronic:978-1-4244-5326-9; POD:978-1-4244-5325-2","10.1109/ICMSS.2010.5575684","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575684","","Books;Data mining;Logic gates;Particle separators;Training;Transducers;Web pages","Web sites;data mining;finite state machines;information retrieval systems;learning (artificial intelligence);probability;uncertainty handling","Web information extraction system;Website;automatic annotation;extraction rules generation;extraction rules learning;finite state transducer based method;probability theory;state machine;supervised system","","0","","11","","","24-26 Aug. 2010","","IEEE","IEEE Conference Publications"
"Modelling semantic context for novelty detection in wildlife scenes","S. P. Yong; J. D. Deng; M. K. Purvis","Dept. of Information Science, University of Otago, PO Box 56, Dunedin, New Zealand","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","1254","1259","Novelty detection is an important functionality that has found many applications in information retrieval and processing. In this paper we propose a novel framework that deals with novelty detection for multiple-scene image sets. Working with wildlife image data, the framework starts with image segmentation, followed by feature extraction and classification of the image blocks extracted from image segments. The labelled image blocks are then scanned through to generate a co-occurrence matrix of object labels, representing the semantic context within the scene. The semantic co-occurrence matrices then undergo binarization and principal component analysis for dimension reduction, forming the basis for constructing one-class models for each scene category. An algorithm for outlier detection that employs multiple one-class models is proposed. An advantage of our approach is that it can be used for scene classification and novelty detection at the same time. Our experiments show that the proposed approach algorithm gives favourable performance for the task of detecting novel wildlife scenes, and binarization of the label co-occurrence matrices helps to significantly increase the robustness in dealing with the variation of scene statistics.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583899","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583899","co-occurrence matrix;context;multi-class;novel image;semantics","Context;Feature extraction;Image color analysis;Image segmentation;Semantics;Training;Wildlife","feature extraction;image classification;image segmentation;information retrieval;matrix algebra;principal component analysis","binarization;cooccurrence matrix;feature extraction;image blocks classification;image segmentation;information processing;information retrieval;novelty detection;object labels;outlier detection;principal component analysis;semantic context modelling;wildlife scenes","","4","","27","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"A Study on XML and Ontology-based Web Data Integration","L. Yan-heng; Z. Jin; P. YIng","Coll. of Inf. Sci. Technol., Dalian Maritime Univ., Dalian, China","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","2914","2919","With the rapid development of Internet technology, web information system has achieved great development, and XML, as the new carrier and standard of information exchanging and calculating on the internet, has been widely used as well. While providing a uniform syntax and semi-structured data model, XML does not express semantics but only structure. This paper combines the web data integration problem and a XML and ontology-based data integration framework, including three main layers: distributed heterogeneous data sources layer, intermediary layer and application layer. Ontology is introduced as a tool in this framework. The experiment results verify the effectiveness of the proposed integration framework.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578415","Data Integration;Ontology;Ontology Mapping;Semantic Heterogeneity;XML","Data models;Distributed databases;Middleware;Ontologies;Semantics;XML","Web services;XML;electronic data interchange;information retrieval systems;ontologies (artificial intelligence)","Internet;Web data integration;XML;information exchange;ontology;web information system","","0","","12","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Research on ontology semantic retrieval for enterprise metadata","J. Yang; C. Huang","Information Engineering School, Jiangxi University of Science and Technology, Ganzhou, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2050","2053","This paper introduces the basic conceptions of metadata and ontology, analyzes process and relations between them. By employing the semantic logic ability of ontology to the enterprise metadata information system, it indicates ontology dominance in mutual operational of metadata. On the basis of establishing enterprise metadata information resource domain ontology, the author elaborates idea of metadata semantics retrieval at ontology environment, and through a prototype system, it is applied to the enterprise metadata manage systems to demonstrate the feasibility and the validity of the semantic inquiry.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569682","inquiry;metadata;ontology;semantic","Cognition;Construction industry;Information services;Information systems;OWL;Ontologies;Semantics","business data processing;information retrieval;information systems;meta data;ontologies (artificial intelligence)","domain ontology;enterprise metadata;information system;ontology dominance;ontology semantic retrieval;semantic logic ability","","0","","10","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Small-worlds clustering applied to documents re-ranking","M. Khazri; M. Tmar; M. Abid","National Ingeneering School, 4 Road of Soukra, 3038 Sfax, Tunisia","ACS/IEEE International Conference on Computer Systems and Applications - AICCSA 2010","20100927","2010","","","1","6","We propose in this paper an approach for document clustering. It consists on representing the corpus as a document graph, where links are defined by some criteria. These links are quantified by similarity measures. We aim to join this context with clustering to build small-world networks of homogeneous documents. The homogeneity of the clusters is measured according to the properties of small-worlds networks. The clusters, as well as their properties, allow to re-rank search results. Some experiments have been undertaken into a corpus provided by TREC and the obtained results show the contribution of small-worlds properties and analysis in information retrieval and document re-ranking.","2161-5322;21615322","Electronic:978-1-4244-7717-3; POD:978-1-4244-7716-6","10.1109/AICCSA.2010.5586938","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586938","","","document handling;graph theory;information retrieval;pattern clustering","document clustering;document graph;document re-ranking;homogeneous document;information retrieval;re-rank search;small-worlds clustering","","0","","12","","","16-19 May 2010","","IEEE","IEEE Conference Publications"
"Usage of tagging for research paper recommendation","W. Choochaiwattana","Faculty of Information Technology, Dhurakij Pundit University, Bangkok, Thailand","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","2","","V2-439","V2-442","Tagging has become a common service on Web2.0 application. This kind of service allows users to share and annotate interesting web resources. CiteULike is an example of Web2.0 application that allows its users to share research papers based on their interest. It also allows the users to create annotations or tags attached to the research papers. This paper examined the use of tagging for research paper recommendation. A research paper recommendation mechanism based on tagging was proposed. This mechanism recommends a research paper according a set of tags they have created. The result suggested that tags created by each user could be used as a user individual profile. The profile then compared with research paper index to compute a similarity score. The result of experiment showed that the accuracy of the proposed research paper recommendation is 79% with f-measure value at 82%.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579321","recommender system;tag-based recommendation;tagging","Computers;Information filters;Tagging","information retrieval;recommender systems;user interfaces","CiteULike application;Web2.0 application;research paper recommendation mechanism;tagging usage;user individual profile","","1","","30","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Discrete Particle Swarm Optimization Algorithm for Domain Independent Linear Text Segmentation","J. W. Wu; J. C. R. Tseng; W. N. Tsai","Dept. of Comput. Sci., Nat. Chiao Tung Univ., Hsinchu, Taiwan","2010 IEEE International Conference on Granular Computing","20100916","2010","","","519","524","Linear text segmentation has been used in several natural language processing tasks, such as information retrieval and text summarization. It has been proven that linear text segmentation is beneficial to these tasks. To improve the performance of linear text segmentation, a novel domain independent linear text segmentation algorithm, called DPSO-SEG, is proposed in this paper. DPSO-SEG applies the Discrete Particle Swarm Optimization (DPSO) algorithm to find the optimal topical segments. The performance of DPSO-SEG is compared with some state-of-the-art linear text segmentation algorithms. The experimental results show that DPSO-SEG is advantageous in its controllable time complexity and its promising accuracy, especially when the segment size is consistent.","","Electronic:978-0-7695-4161-7; POD:978-1-4244-7964-1","10.1109/GrC.2010.146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575982","Discrete Particle Swarm Optimization;Linear text segmentation","Complexity theory;Convergence;Dynamic programming;Heuristic algorithms;Optimization;Particle swarm optimization;Semantics","information retrieval;natural language processing;particle swarm optimisation;text analysis","DPSO-SEG;discrete particle swarm optimization algorithm;domain independent linear text segmentation;information retrieval;natural language processing;text summarization","","3","","20","","","14-16 Aug. 2010","","IEEE","IEEE Conference Publications"
"User Centred Mobile Aided Learning System: Student Response System (SRS)","J. Lu; R. P. Pein; G. Hansen; K. L. Nielsen; J. B. Stav","Dept. of Inf., Univ. of Huddersfield, Huddersfield, UK","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","2970","2975","This research develops a new system based on the user centred concepts and applied on the latest mobile devices. XML, database, information retrieval and object oriented technologies are embedded into the system. It is found that the system demonstrates a strong impact on teaching and learning in class activities in comparison with traditional learning environments. Also, the system has achieved that It can be self independent as well as integrated with other learning management environments, such as blackboard, Smartboard as well as subject oriented learning management systems, which makes an additional contribution to the modern pedagogical applications, such as activity based learning.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.499","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578505","iPod/iPhone;mobile aided learning;student response system","Education;Mobile communication;Mobile handsets;Portable media players;Portals;Software;Testing","XML;computer aided instruction;database management systems;information retrieval;mobile computing;mobile radio;object-oriented methods;teaching;user centred design","XML;activity based learning;blackboard;class activity;database;information retrieval;learning management environment;mobile device;object oriented technology;pedagogical application;smartboard;student response system;subject oriented learning management system;teaching;user centred mobile aided learning system","","4","","19","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Touch me interaction paradigm for physically browsing personal learning spaces","A. M. Rahman; A. E. Saddik","Multimedia Communications Research Lab, University of Ottawa, Ottawa","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","436","441","The prevalent visions of ambient intelligence leverage natural interaction between user and available services in a learning space. In this pursuit, we present a framework for augmenting physical objects with annotated information in order to improve physical browsing. The proposed system incorporates an intuitive camera based annotation scheme to catalog and author information about the physical learning objects in an environment. Each annotated data is encoded in such a way that they provide access points for available information or services about the physical objects. The system uses adequate visual cues and provides tactile feedback in order to leverage the touch-based interactions with the objects. These real world interaction techniques with the physical environment and seamless virtual learning information acquisition make the system transparent from the young learners and help them to become engaged in their learning activities.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583565","Indoor position;Mobile interaction;physical browsing;physical mobile interaction;physical object annotation","Cameras;Mobile communication;Mobile handsets;Radiofrequency identification;Tagging;Usability;Visualization","computer aided instruction;information retrieval;interactive programming;user interfaces;virtual reality","ambient intelligence;information acquisition;natural interaction;personal learning spaces;physical browsing;seamless virtual learning;touch me interaction paradigm","","0","","24","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"A Chinese word segmentation algorithm based on maximum entropy","L. Y. Zhang; M. Qin; X. M. Zhang; H. X. Ma","Institute of Information, Heibei University of Science and Technology, Shijiazhuang, Hebei 050018, China","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","3","","1264","1267","Automatic word segmentation technology is an important component part of modern Chinese information processing. It is the key technology of the Chinese full-text retrieval. This paper presents a Chinese word segmentation algorithm based on maximum entropy. It uses of part-of-speech tagging and word frequency tagging of corpus to establish maximum entropy model based on mutual information as a word segmentation language model to make word segmentation. At last, the binary model was used to test whether the expansion of the training corpus may impact the word segmentation accuracy, and the relationship curves between the expansion of training corpus and the word segmentation accuracy was obtained.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580902","Chinese full text retrieval;Maximum entropy;Word segmentation algorithm","Accuracy;Computational modeling;Context;Entropy;Mathematical model;Probability;Training","entropy;information retrieval;text analysis;word processing","Chinese full-text retrieval;Chinese information processing;Chinese word segmentation algorithm;binary model;maximum entropy model;part-of-speech tagging;word frequency tagging;word segmentation language model","","2","","5","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"Similarity-based hierarchical structured trust and reputation model in peer-to-peer networks","Ting Zhong; Xiaojuan Liao; Ji Geng","School of Computer Science & Engineering/University of Electronic Science and Technology of China/Chengdu, Sichuan, China","2010 International Conference on Communications, Circuits and Systems (ICCCAS)","20100923","2010","","","221","225","Trust and reputation system has been a key component in P2P networks since all peers are intellectual and autonomous. Previous researches either ignore particular peer's needs or sacrifice efficiency in storage and retrieval to adapt to diversity of peer's preferences. This paper aims to propose a scheme achieving quicker access and more precise calculation of reputation data. This system utilizes peer's self estimation in calculation and provides a hierarchical structure for retrieving information.","","Electronic:978-1-4244-8225-2; POD:978-1-4244-8224-5","10.1109/ICCCAS.2010.5582014","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582014","","Receivers","information retrieval;peer-to-peer computing","information retrieval;peer-to-peer networks;reputation model;similarity based hierarchical structured trust model","","0","","14","","","28-30 July 2010","","IEEE","IEEE Conference Publications"
"A Bully Strategy for Progressive Mobile Map Generation","N. Jabeur","Comput. Sci. Dept., Dhofar Univ., Salalah, Oman","2010 First International Conference on Integrated Intelligent Computing","20100916","2010","","","73","78","In this paper, we address the process of generating cartographic maps on-the-fly. Despite the existence of intensive research works, this process is still characterized by its complexity, time-consuming processing, and lack of flexibility. While web users are having an improved access to spatial data, mobile users are still facing problems in getting personalized maps that fit their limited display screens and do not penalize them due to low transfer rates. In order to provide the mobile users with the right data and avoid cluttering their screens with useless data, we propose to progressively generate, transmit, and display spatial objects according to a decreasing order of their importance. The approach is based upon software agents that compete for the occupation of the limited display space. This competition is driven by a bully approach that privileges the processing of objects with higher importance. In order to illustrate our solution, we apply it in the context of tourist mobile mapping applications.","","Electronic:978-0-7695-4152-5; POD:978-1-4244-7963-4","10.1109/ICIIC.2010.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571505","bully strategy;mobile map;multiagent systems;progressive approach","Context;Mobile communication;Multiagent systems;Roads;Semantics;Software agents;Spatial databases","Internet;cartography;information retrieval;mobile computing","World Wide Web;bully strategy;cartographic maps;data access;progressive mobile map generation;spatial data;tourist mobile mapping","","0","","24","","","5-7 Aug. 2010","","IEEE","IEEE Conference Publications"
"New GML Storage Schema Models for Spatial and Non-spatial Information","Y. k. Kim; H. k. Yoo; J. w. Chang","Dept. of Comput. Eng., Chonbuk Nat. Univ., Chonju, South Korea","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","620","626","GML (Geographic Markup Language) is a markup language presented as exchange standard for geographic information by the OGC (Open GIS Consortium). In spatial network databases, studies on GML can be divided into parsing, storing and retrieval of GML documents. Among them, the storage of GML documents is essential for their efficient retrieval. However, there is little research on storing GML documents, whereas there have been a lot of research on the storing of XML documents. The storage schema models designed for XML documents are not appropriate for geographic information because they store duplicate data and need to search many tables for obtaining elements. In order to solve the problem, we, in this paper, propose new storage schema models for GML documents including spatial and non-spatial information. In addition, we implement a storage manager which can store GML documents by using our GML storage schema models.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578130","GML document;LBS;Storage Manager;Storage Schema","Cities and towns;Data models;Pediatrics;Redundancy;Spatial databases;XML","XML;geographic information systems;information retrieval;visual databases","GML documents parsing;GML documents retrieval;GML documents storing;Geographic Markup Language storage schema model;Open GIS Consortium;XML documents;geographic information;spatial network databases","","0","","14","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Web page repetitive structure and URL feature based Deep Web data extraction","Xingyi Li; Yanyan Kong; Huaji Shi","School of Computer Science and Telecommunication Engineering, Jiangsu University, Zhenjiang, China","2010 Second International Conference on Communication Systems, Networks and Applications","20100930","2010","1","","361","364","Noise interference in web pages and the demand for multiple sample pages are the key issues of Deep Web data extraction. In this paper, we propose a novel web page repetitive structure and URL feature based approach for Deep Web data extraction. It employs continuous repetitive tag region and similar URL to partition the sample page into blocks, locate the data region and extract specific URL template, which is further exploited to quickly identify the data region and the boundary of data records in similar pages. Experimental results show that our approach is highly effective for Deep Web data extraction.","","Electronic:978-1-4244-7478-3; POD:978-1-4244-7475-2","10.1109/ICCSNA.2010.5588744","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588744","Deep Web;data extraction;similar URL;web page repetitive structure","Accuracy;Data mining;Educational institutions;Feature extraction","Internet;Web sites;information retrieval","Deep Web data extraction;URL feature;Web page repetitive structure;noise interference","","0","","10","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Finding Overlapping Communities in Social Networks","M. Goldberg; S. Kelley; M. Magdon-Ismail; K. Mertsalov; A. Wallace","Dept. of Comput. Sci., Rensselaer Polytech. Inst., Troy, NY, USA","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","104","113","Increasingly, methods to identify community structure in networks have been proposed which allow groups to overlap. These methods have taken a variety of forms, resulting in a lack of consensus as to what characteristics overlapping communities should have. Furthermore, overlapping community detection algorithms have been justified using intuitive arguments, rather than quantitative observations. This lack of consensus and empirical justification has limited the adoption of methods which identify overlapping communities. In this text, we distil from previous literature a minimal set of axioms which overlapping communities should satisfy. Additionally, we modify a previously published algorithm, Iterative Scan, to ensure that these properties are met. By analyzing the community structure of a large blog network, we present both structural and attribute based verification that overlapping communities naturally and frequently occur.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590817","community detection;overlapping groups;social network analysis","Algorithm design and analysis;Communities;Information services;Internet;Measurement;Partitioning algorithms;Social network services","information retrieval;social networking (online)","attribute based verification;blog network;intuitive arguments;iterative scan;overlapping community detection algorithms;social network analysis","","17","","22","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"A novel redundant attribute reduction method","E. Xu; Liangshan Shao; Wenge Ma; H. Wu; Tao Qu","Electronic & Information Engineering College, Liaoning University of Technology, Jinzhou 121001, China","2010 Sixth International Conference on Natural Computation","20100923","2010","1","","36","40","Attribute reduction is an important problem in an information system. The paper proposed a novel method to reduce the redudant attributes in an incomplete information system based on rough set theory. The method introduce the concepts such as upper-approximate relationship and lower-approximate relationship, equivalence relationship, tolerance relationship, attribute significance and so on, to calculate the core attributes and use the attribute significance as heuristic knowledge to reduce attributes set according to dependence between the conditonal attributes and decision attributes in the information system. Experiment results show that the algorithm is simple and effective.","2157-9555;21579555","Electronic:978-1-4244-5961-2; POD:978-1-4244-5958-2","10.1109/ICNC.2010.5582967","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582967","attributes reduction;core attributes;information system;rough set;similar matrix","Algorithm design and analysis;Approximation methods;Arrays;Complexity theory;Information systems;Rough sets","data handling;information retrieval systems;rough set theory","heuristic knowledge;information system;redundant attribute reduction method;rough set theory","","0","","24","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Extraction of purpose data using surface text patterns","P. Kiran Mayee; R. Sangal; S. Paul","Language Technologies Research Centre, International Institute of Information Technology, Hyderabad, Andhra Pradesh, India","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","7","This paper presents the concept of surface text patterns for extracting purpose data from the web. In order to obtain an optimal set of patterns, we have developed a method for learning purpose patterns automatically. A corpus was downloaded from the Internet using bootstrapping by providing a few hand-crafted examples of each purpose pattern to a generic search engine. This corpus was then tagged and patterns were extracted from the returned documents by automated means and standardized. The precision of each pattern and the average precision for each group were computed. The extracted patterns were then used to extract purpose data. The results for extraction from the web have been reported.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587860","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587860","Information Extraction;Surface Text Patterns","Data mining;Encyclopedias;Google;Internet;Pattern matching;Search engines;Surface morphology","Internet;information retrieval;learning (artificial intelligence);search engines;text analysis","Internet;World Wide Web;bootstrapping;generic search engine;learning purpose pattern;purpose data extraction;surface text pattern","","0","","15","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic translation for Chinese mathematical Braille code","Z. Liu; W. Su; L. Li; Y. Chen; Y. Peng","School of Information Science & Engineering, Lanzhou University, Lanzhou, P. R. China","2010 5th International Conference on Computer Science & Education","20100930","2010","","","340","345","Mathematics accessibility for the blind attracts more and more attention in recent years. It aims to make mathematical documents and information accessible to the blind via computer and Internet. Several projects have made considerable progress in meeting the challenges in mathematics accessibility. One of the remaining challenges is the translation between mathematical formats used by sighted individuals and mathematical Braille codes used by blind individuals. We concentrate on the automatic translation of Chinese mathematical Braille code and develop an automatic translation middleware to implement the inter-translation between Chinese mathematical Braille code and any format of MathML, LaTex and OpenMath using XSLT stylesheets. The automatic translation middleware has higher flexibility, scalability and portability, easy to transplant, modify and upgrade.","","Electronic:978-1-4244-6005-2; POD:978-1-4244-6002-1","10.1109/ICCSE.2010.5593618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593618","Braille;MathML;blind person;mathematical expression;translation","Computers;Encoding;Mathematical model;Middleware;Writing;XML","Internet;document handling;handicapped aids;information retrieval;language translation;mathematics computing;middleware","Chinese mathematical Braille code;Internet;LaTex;MathML;OpenMath;XSLT stylesheet;automatic translation middleware;blind individual;information access;mathematical document;mathematical format","","1","","21","","","24-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"A new indexing strategy for XML keyword search","Y. Xiang; Z. Deng; H. Yu; S. Wang; N. Gao","Key Laboratory of Machine Perception (Ministry of Education), School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2412","2416","With the rapid increase of XML documents on the web, how to index, store and retrieve these documents has become a very popular and valuable problem. At present, there are two normal ways of retrieving XML documents. One is structure-based retrieval; the other is keyword-based retrieval. However, XML keyword search is becoming more and more popular because it is easy to master and manipulate. In XML keyword search system, a key problem is how to store the structure information into XML indices efficiently. At present, Dewey numbers are often used to label XML nodes in XML indices. However, Dewey numbers may lead to redundancy in XML indices. In this paper, we propose a new labeling method called LAF numbers for XML indices and we device a new indexing structure called Two-Layer index for XML keyword retrieval systems. At last, we have conducted an extensive experimental study and the experimental results show that our indexing method achieves better space efficiency than prevailing Dewey-number-based indexing method.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569522","Dewey numbers;Indexing;LAF numbers;Two-Layer;XML keyword Search","Encoding;Indexing;Keyword search;Labeling;Redundancy;XML","XML;digital arithmetic;indexing;information retrieval systems;redundancy;semantic Web","Dewey numbers;LAF numbers;XML documents;document retrieval;indexing;keyword retrieval systems;keyword search system;redundancy;structure based retrieval;two-layer index;web","","2","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Performance of Quantized Congestion Notification in TCP Incast Scenarios of Data Centers","P. Devkota; A. L. N. Reddy","Dept. of Electr. & Comput. Eng., Texas A&M Univ., College Station, TX, USA","2010 IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems","20100923","2010","","","235","243","This paper analyzes the performance of Ethernet layer congestion control mechanism Quantized Congestion Notification (QCN) during data access from clustered servers in data centers. We analyze the reasons why QCN does not perform adequately in these situations and propose several modifications to the protocol to improve its performance in these scenarios. We trace the causes of QCN performance degradation to flow rate variability, and show that adaptive sampling at the switch and adaptive self-increase of flow rates at the rate limiter improve performance in a TCP In cast setup significantly. We compare the performance of QCN against TCP modifications in a heterogeneous environment, and show that modifications to QCN yield better performance.","1526-7539;15267539","Electronic:978-0-7695-4197-6; POD:978-1-4244-8181-1","10.1109/MASCOTS.2010.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581590","","Bandwidth;Ethernet networks;Negative feedback;Protocols;Servers;Switches;Synchronization","computer centres;data handling;information retrieval;local area networks;telecommunication congestion control;transport protocols","Ethernet layer congestion control mechanism;QCN;TCP incast scenarios;TCP modifications;adaptive sampling;clustered servers;data access;data centers;flow rate variability;heterogeneous environment;quantized congestion notification","","15","7","21","","","17-19 Aug. 2010","","IEEE","IEEE Conference Publications"
"Research on Unified interface of Heterogeneous database","B. He; Y. Tang","Sch. of Comput. Sci. & Eng., South China Univ. of Technol., Guangzhou, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","4513","4517","At present, different technologies were used to handle heterogeneous database in system development. It's easy for the application developers to access single database, however, the technology and code complexity make a big challenge to handle data of systems which obtain multiple data sources, no matter what the application patterns base on C/S B/S or the mixture of both. This paper offers a perspective on the framework and its realization of handling multiple data sources under a unified way based on the years of application system development experience. To achieve purpose of accessing multiple data sources with unified messages, some specific types of messages for operating heterogeneous database were defined by XML language, and other relevant technologies were introduced to implement this framework.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590962","Data Access;Heterogeneous data sources;Web Services;XML","Databases;SGML;Servers;Service oriented architecture;XML","Web services;XML;distributed databases;information retrieval","XML language;code complexity;data access;data sources;heterogeneous database;system development;unified messages","","0","","7","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"An Efficient Search Mechanism in Unstructured P2P Networks Based on Semantic Group","W. Shen; S. Su; K. Shuang; F. Yang; J. Xia","State Key Lab. of Networking & Switching Technol., Beijing Univ. of Posts & Telecommun., Beijing, China","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","2982","2986","Recently among various searching techniques, semantic-based searching has drawn significant attention. In this paper, we propose a novel and efficient search mechanism BF-SKIP (Biased walk, Flooding and Search with K-Iteration Preference). We use Vector Space Model (VSM) and relevance ranking algorithms to construct the overlay network. In BF-SKIP system, the search mechanism is divided into three stages (A, B and C). It significantly reduces the number of redundant messages and the number of visited nodes. Our analysis and simulation results show that the BF-SKIP scheme can outperform GES in terms of higher precision and lower search cost.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.497","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578027","BF-SKIP;GES;K-Iteration;P2P networks;Preference","Bandwidth;Floods;Maintenance engineering;Peer to peer computing;Query processing;Semantics;Topology","information retrieval;peer-to-peer computing","BF-SKIP system;Biased walk Flooding and Search with K-Iteration Preference;overlay network;relevance ranking algorithm;search mechanism;semantic based searching;semantic group;unstructured p2p network;vector space model","","2","","7","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Analysis of Prerequisite for Experts Acquiring and Reporting Informatively","G. Lu; G. Li","Sch. of Manage., Anhui Inst. of Archit. & Ind., Hefei, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","5094","5097","This paper is concerned with the problem of strategic information acquisition and information transmission. In our model, a decision maker delegates multiple experts to acquire information concerning a binary decision under uncertainty. The decision maker and experts have different utility functions with respect to the decision problem, which are their private information. We derive the optimal number of experts which the decision maker should delegate providing that all experts acquire information and report sincerely. Then we identify the prerequisite for all experts gathering and reporting informatively. We show that every expert's strategy for information acquisition and transmission when he is one of multiple information senders is generally different from that when he is the only one. And every expert's pivotal probability for the final decision, which is evaluated based on the probability distribution of the decision maker's threshold of doubt, is not equal to his pivotal probability under the majoritarian decision rule with a quota being the expected threshold of doubt of the decision maker.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1278","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5592885","decision;incentive compatibility;information acquisition;information transmission;preference","Biological system modeling;Economics;Equations;Games;Industries;Nash equilibrium;Organizations","decision making;information retrieval;statistical distributions","analysis of prerequisite;decision making;information acquisition;information transmission;probability distribution","","0","","16","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"Using Web Services as Functional-Level Plug Ins for Interactive 3D Medical Visualisation","T. Wang; Y. Zhao; E. Liu; G. J. Clapworthy; X. Zhao; H. Wei; F. Dong","Dept. of Comput. Sci. & Technol., Univ. of Bedfordshire, Luton, UK","2010 14th International Conference Information Visualisation","20100913","2010","","","617","622","Web services provide remote access to distributed resources and processes through uniform interfaces. However, the latency associated with data transmission has meant that they are generally applied to non-interactive data processing. Interactive applications, in which many more user interactions and data transmissions are involved, are difficult to adapt to web service based frameworks, particularly if the interactive investigation involves large datasets. In medical imaging and visualisation, user interactions are generally a prerequisite for the detailed study and manipulation of data. As a result of major scientific initiatives, such as the Virtual Physiological Human, in which large data repositories are being set up at a variety of sites, it is becoming increasingly common for the data being investigated to be stored on a remote server. Consequently, it is now highly desirable to develop a means by which web service based interactive visualisation can be applied to distributed medical data access and clinical collaboration. This paper presents a functional-level plug-in based architecture for interactive data visualisation via web services which is being implemented within the EC-funded ContraCancrum project.","1550-6037;15506037","Electronic:978-0-7695-4165-5; POD:978-1-4244-7846-0","10.1109/IV.2010.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571117","Virtual Physiological Human;data-preview service;functional-level plug in;interactive visualisation;mesh simplification;web service","Biomedical imaging;Data models;Data visualization;Rendering (computer graphics);Solid modeling;Three dimensional displays;Web services","Web services;computer graphics;data visualisation;information retrieval;medical computing;user interfaces","EC-funded ContraCancrum project;Web services;clinical collaboration;data manipulation;data repository;data transmission;distributed medical data access;distributed resources;functional-level plug-in based architecture;interactive 3D medical visualisation;interactive data visualisation;medical imaging;noninteractive data processing;remote server;user interactions;virtual physiological human","","2","","26","","","26-29 July 2010","","IEEE","IEEE Conference Publications"
"LOG4SWS.KOM: Self-Adapting Semantic Web Service Discovery for SAWSDL","S. Schulte; U. Lampe; J. Eckert; R. Steinmetz","Multimedia Commun. Lab., Tech. Univ., Darmstadt, Germany","2010 6th World Congress on Services","20100916","2010","","","511","518","In recent years, a number of approaches to semantic Web service matchmaking have been proposed. Most of these proposals are based on discrete and thus relatively coarse Degrees of Match (DoMs). However, different basic assumptions regarding the generalization and specialization of semantic concepts in ontologies and their subsequent rating in matchmaking exist. Hence, most matchmakers are only properly suitable if these assumptions are met. In this paper, we present an approach for mapping subsumption reasoning-based DoMs to a continuous scale. Instead of determining the numerical equivalents of the formerly discrete DoMs manually, these values are automatically derived using a linear regression model. This permits not only easy combination with other numerical similarity measures, but also allows to adapt matchmaking to different basic assumptions. These notions are implemented and tested in LOG4SWS.KOM-a matchmaker for SAWSDL that provides very good evaluation results with respect to Information Retrieval metrics such as precision and recall.","2378-3818;23783818","Electronic:978-0-7695-4129-7; POD:978-1-4244-8199-6","10.1109/SERVICES.2010.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575467","SAWSDL;Semantic Web Services;Service Discovery;Service Matchmaking","Bipartite graph;Length measurement;Ontologies;Semantic Web;Semantics;Web services;XML","information retrieval;ontologies (artificial intelligence);regression analysis;semantic Web","SAWSDL;degrees of match;information retrieval;linear regression model;ontologies;self adapting semantic Web service","","2","","19","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Design and implement web services for sharing standardized medication information between enterprises","Ying-Ting Wang; Der-Ming Liou","Institute of Biomedical Informatics, National Yang-Ming University, Taipei, Taiwan","2010 Second International Conference on Communication Systems, Networks and Applications","20100930","2010","1","","101","104","Duplicate medication between enterprises not only wastes medical resources, but also endangers a patient's safety. However, medication information may come from different medical institutes and use different terminologies. The majority of patients do not know the names of these drugs; and for other doctors, they may also not understand medication information content. In order to avoid duplicate medication, drug allergy or other drug incidents, this study hope to implement web services for sharing medication information between enterprises base on IHE Cross-Enterprise Document Sharing (XDS) and RxNorm, making the medication information correspond to standardization. Through the consistency of these standards, the doctor could refer to a complete medication record of the patient in the past when prescribing in order to avoid the duplication of a drug. Because patients in recent years care more about their own health management consciousness, this service also provides automatic duplicate medication check.","","Electronic:978-1-4244-7478-3; POD:978-1-4244-7475-2","10.1109/ICCSNA.2010.5588761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588761","IHE XDS;RxNorm","Unified modeling language","Web services;document handling;information retrieval;medical computing","IHE cross-enterprise document sharing;RxNorm;Web service;automatic duplicate medication check;standardized medication information sharing","","0","","11","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Algorithms for Data Retrieval from Online Social Network Graphs","R. Abdulrahman; S. Alim; D. Neagu; M. Ridley","Dept. of Comput., Univ. of Bradford, Bradford, UK","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1660","1666","In the last few years, data extraction from online social networks (OSNs) has become more automated. The aim of this study was to extract all friends from MySpace profiles in order to generate a friendship graph. The graph would be analysed to investigate and apply node vulnerability metrics. This research is an extension of our previous work which concentrated on the extraction of top friends but did not investigate the graph or node vulnerability. The graph was generated from the friendship links that were extracted and placed into a repository. From the graph structure and profiles' personal details, vulnerability was calculated to find the most vulnerable node. Results were promising and provided interesting findings. Metric validation highlighted that the graph can be used to infer information that may not be present on the profile. The number of neighbours and the clustering coefficient were two main factors that affect the vulnerability of nodes.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577955","Automated Data Extraction;Online Social Network Graphs;Vulnerability","Data privacy;Measurement;Media;MySpace;Privacy","graph theory;information retrieval;social networking (online)","MySpace profiles;data extraction;data retrieval;friendship graph;graph structure;online social network graphs","","1","","23","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Web-based technical term translation pairs mining for patent document translation","F. Ren; J. Zhu; H. Wang","Northeastern University, Shenyang, China","Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)","20100930","2010","","","1","8","This paper proposes a simple but powerful approach for obtaining technical term translation pairs in patent domain from Web automatically. First, several technical terms are used as seed queries and submitted to search engineering. Secondly, an extraction algorithm is proposed to extract some key word translation pairs from the returned web pages. Finally, a multi-feature based evaluation method is proposed to pick up those translation pairs that are true technical term translation pairs in patent domain. With this method, we obtain about 8,890,000 key word translation pairs which can be used to translate the technical terms in patent documents. And experimental results show that the precision of these translation pairs are more than 99%, and the coverage of these translation pairs for the technical terms in patent documents are more than 84%.","","Electronic:978-1-4244-6899-7; POD:978-1-4244-6896-6","10.1109/NLPKE.2010.5587775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587775","Term translation;key word extraction;key word selection;machine translation;patent document translation;web-based","Chemistry;Patents","Internet;data mining;document handling;information retrieval;natural language processing;patents","Web-based technical term translation;extraction algorithm;multifeature based evaluation method;patent document translation;seed queries","","1","","16","","","21-23 Aug. 2010","","IEEE","IEEE Conference Publications"
"Noise Robustness Evaluation of Audio Features in Segment Search","M. Kuwabara; M. Sugiyama","Sch. of Comput. Sci. & Eng., Univ. of Aizu, Aizu-Wakamatsu, Japan","2010 10th IEEE International Conference on Computer and Information Technology","20100916","2010","","","1285","1291","This paper evaluates the noise robustness of audio features in segment search. Active Search is well-known as a fast segment search algorithm, and it has been successfully applied to locate music or video segments (intervals) in huge databases. The noise is generated by MP3 encoding/decoding. The search accuracy is evaluated using F-measure, which is calculated precision and recall. The experiment results show that mel-scaled spectral features are better and have a broader range of search thresholds than linear-scaled features. The low analysis order of the mel-scaled audio features has a search speed that is about 12 times faster, with quite reasonable search accuracy.","","Electronic:978-1-4244-7548-3; POD:978-1-4244-7547-6","10.1109/CIT.2010.232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5577868","Audio Features;Noise Robustness;Segment Search","Accuracy;Cepstrum;Databases;Digital audio players;Mel frequency cepstral coefficient;Multiple signal classification;Noise","audio signal processing;information retrieval;spectral analysis","F-measure;MP3 decoding;MP3 encoding;active search;audio features;linear-scaled feature;mel-scaled audio feature;mel-scaled spectral features;music segment;noise robustness evaluation;search accuracy;search threshold;segment search;video segment","","0","","9","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"INSPIRE: A New Method of Mapping Information Spaces","R. A. Ruddle","Sch. of Comput., Univ. of Leeds, Leeds, UK","2010 14th International Conference Information Visualisation","20100913","2010","","","273","279","Information spaces such the WWW are the most challenging type of space that many people navigate during everyday life. Unlike the real world, there are no effective maps of information spaces, so people are forced to rely on search engines which are only suited to some types of retrieval task. This paper describes a new method for creating maps of information spaces, called INSPIRE. The INSPIRE engine is a tree drawing algorithm that uses a city metaphor, comprised of streets and buildings, and generates maps entirely automatically from webcrawl data. A technical evaluation was carried out using data from 112 universities, which had up to 485, 775 pages on their websites. Although they take longer to compute than radial layouts (e.g., the Bubble Tree), INSPIRE maps are much more compact. INSPIRE maps also have desirable aesthetic properties of being orthogonal, preserving symmetry between identical subtrees and being planar.","1550-6037;15506037","Electronic:978-0-7695-4165-5; POD:978-1-4244-7846-0","10.1109/IV.2010.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571261","","Buildings;Cities and towns;Grammar;Layout;Pediatrics;Shape;Visualization","Web sites;cartography;computer graphics;information retrieval;search engines","INSPIRE engine;INSPIRE maps;Web crawl data;Web sites;information spaces;retrieval task;search engines;tree drawing algorithm","","1","","20","","","26-29 July 2010","","IEEE","IEEE Conference Publications"
"COBS: A tool for collaborative browsing and search on the web","C. von der Weth; A. Datta; S. A. Nanyang","Technological University (NTU), Singapore","2010 IEEE International Conference on Multimedia and Expo","20100923","2010","","","272","273","User-generated content in the spirit of Web 2.0 is a promising means to improve the search for relevant information on the web, particularly multimedia content. The idea is that user col-laboratively search or browse for information, either directly by communicating or indirectly by adding meta information (e.g., tags) to web pages. However, current solutions are bound to specific web sites providing such features. To overcome this limitation we introduce COBS, making Web 2.0 features available also for the 'old' web. In this demo we present the front-end, a browser add-on that enables users to tag, rate or comment arbitrary web pages and to communicate with others in both a synchronous and asynchronous manner.","1945-7871;19457871","Electronic:978-1-4244-7493-6; POD:978-1-4244-7491-2","10.1109/ICME.2010.5583207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583207","Web 2.0;browser add-on;collaborative browsing and searching;social networking","Browsers;Collaboration;Data privacy;History;Social network services;Web pages","Internet;information retrieval;online front-ends","COBS tool;Web 2.0;Web search tool;collaborative browsing tool;multimedia content;user-generated content","","2","","4","","","19-23 July 2010","","IEEE","IEEE Conference Publications"
"Media Monitoring Using Social Networks","T. White; W. Chu; A. Salehi-Abari","Carleton Univ., Ottawa, ON, Canada","2010 IEEE Second International Conference on Social Computing","20100930","2010","","","661","668","With the rapid rise in the number of weblogs, or blogs, on the World Wide Web (WWW), there is a growing need to be able to quickly search for discussion on specific topics. While keyword searches using tools such as Google or Technorati can yield useful results, we run into the problem of having to enter contextualizing keywords to filter out unwanted and irrelevant search results. This has the unfortunate consequence of making the search process more complicated and possibly filtering out search hits that we would typically want. This paper outlines an approach to narrow search results to only relevant hits, while allowing for general keyword queries. Since the blogosphere constitutes a social network, the solution, BlogCrawler, attempts to use the properties of social networks to narrow the focus of search queries to only those blogs that the user is interested in. This paper presents an algorithm and empirical evaluation that exploits the social network implicit in blogs found on the WWW for the purpose of improving search on the Web.","","Electronic:978-0-7695-4211-9; POD:978-1-4244-8439-3","10.1109/SocialCom.2010.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5591526","Blogs;Internet Search;Social Networks","Blogs;Crawlers;Indexes;Keyword search;Search engines;Social network services;Web sites","Internet;information retrieval;social networking (online)","BlogCrawler;Google;Technorati;Weblogs;World Wide Web;blogosphere;keyword searches;media monitoring;social networks","","0","1","21","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"The Research of Hybrid Scheduling Model in AS/RS Based on Multi-agent System and Petri Net","Y. Wei; Q. Xiaohong; W. Haigang","Mech. & Electr. Eng. Coll., Shaanxi Univ. of Sci. & Technol., Xi'an, China","2010 International Conference of Information Science and Management Engineering","20100916","2010","2","","120","124","This paper studies the problem of loading/unloading scheduling in AR/SR (Automated Storage/Retrieval System) and establishes a hybrid scheduling model which takes advantage of pure centralized and distributed structure. The scheduling model based on multi-Agent and Petri Net is proposed, and the structure of the physical layer, control layer and management layer of the model is detailed described. The distributed sub Agent in the bottom level uses AHP (analytic hierarchy process) to assign weights to the scheduling rules and also uses Genetic Algorithm and Petri Net to optimize the rules. The centralized main Agent in the upper level mainly uses improved Hungarian Algorithm to assign tasks. Loading/unloading scheduling in AR/SR is controlled by making use of collaborative communication of the Agents. JADE is used as the development platform to resolve tasks in/output decision problems of AS/RS. It shows that the hybrid scheduling model is effective according to the simulation example.","","Electronic:978-1-4244-7670-1; POD:978-1-4244-7669-5","10.1109/ISME.2010.115","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5573864","AS/RS;Petri Net;multi-Agent system;scheduling","Buffer storage;Indexes;Job shop scheduling;Load modeling;Loading;Physical layer","Petri nets;genetic algorithms;information retrieval;multi-agent systems;scheduling","AHP;Petri net;analytic hierarchy process;automated storage;genetic algorithm;hybrid scheduling model research;multiagent system;retrieval system;unloading scheduling","","0","","10","","","7-8 Aug. 2010","","IEEE","IEEE Conference Publications"
"Data Mining in Personalized Travel Information System","L. F. Hsu; C. C. Hsu; T. D. Lin","Dept. of Inf. Manage., Hwh Hsia Inst. of Technol., Taipei, Taiwan","2010 2nd International Conference on Information Technology Convergence and Services","20100923","2010","","","1","4","Information retrieval is the most popular database technology, which is focusing on data analysis, association rules, pattern discovery and so on. It is critical to find efficient ways of mining large data sets. In this paper we present a Personalized Travel Information System, called PTIS. PTIS can automatically link to the travel sites to collect information, and then create new data rules. According the rules to provides valuable information for tourism to make travel plan. In addition, we also evaluate the impact of parameters on the algorithm.","","Electronic:978-1-4244-7585-8; POD:978-1-4244-7583-4","10.1109/ITCS.2010.5581285","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581285","","Airplanes;Association rules;Business;Clustering algorithms;Information systems;Web sites","data analysis;data mining;information retrieval;pattern clustering;personal information systems;travel industry","association rule;data analysis;data mining;database technology;information retrieval;pattern discovery;personalized travel information system;tourism;travel site","","0","","12","","","11-13 Aug. 2010","","IEEE","IEEE Conference Publications"
"Web document clustering based on a new niching Memetic Algorithm, Term-Document Matrix and Bayesian Information Criterion","C. Cobos; C. Montealegre; M. F. Mejía; M. Mendoza; E. León","University of Cauca","IEEE Congress on Evolutionary Computation","20100927","2010","","","1","8","This paper introduces a new description-centric algorithm for web document clustering based on Memetic Algorithms with Niching Methods, Term-Document Matrix and Bayesian Information Criterion. The algorithm defines the number of clusters automatically. The Memetic Algorithm provides a combined global and local strategy for a search in the solution space and the Niching methods to promote diversity in the population and prevent the population from converging too quickly (based on restricted competition replacement and restrictive mating). The Memetic Algorithm uses the K-means algorithm to find the optimum value in a local search space. Bayesian Information Criterion is used as a fitness function, while FP-Growth is used to reduce the high dimensionality in the vocabulary. This resulting algorithm, called WDC-NMA, was tested with data sets based on Reuters-21578 and DMOZ, obtaining promising results (better precision results than a Singular Value Decomposition algorithm). Also, it was also then initially evaluated by a group of users.","1089-778X;1089778X","Electronic:978-1-4244-6911-6; POD:978-1-4244-6909-3","10.1109/CEC.2010.5586016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586016","","Algorithm design and analysis;Classification algorithms;Clustering algorithms;Complexity theory;Heuristic algorithms;Memetics;Partitioning algorithms","Bayes methods;Internet;document handling;genetic algorithms;information retrieval;matrix algebra;singular value decomposition;vocabulary","Bayesian information criterion;DMOZ;FP-growth;Reuters-21578;WDC-NMA;Web document clustering;description-centric algorithm;fitness function;k-means algorithm;niching memetic algorithm;niching methods;search space;singular value decomposition algorithm;term-document matrix;vocabulary","","4","","35","","","18-23 July 2010","","IEEE","IEEE Conference Publications"
"A High Effective Indexing and Retrieval Method Providing Block-Level Timely Recovery to Any Point-in-Time","Y. Sheng; D. Xu; D. Wang","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2010 IEEE Fifth International Conference on Networking, Architecture, and Storage","20100916","2010","","","41","50","Block-level continuous data protection (CDP) logs every disk write operation so that the disk can be rolled back to any arbitrary point-in-time within a time window. For each update operation is time stamped and logged, the indexing for such huge amounts of records is an important and challenging problem. Unfortunately, the conventional indexing methods can not efficiently record large numbers of versions and support instant “time-travel” types of queries in CDP. In this paper, we present an effective indexing method providing timely recovery to any point-in-time in comprehensive versioning systems, called the Hierarchical Spatial-Temporal Indexing Method (HSTIM). The basic principle of HSTIM is to partition the time domain and the production storage LBAs into time slice and segments respectively according to update frequency of disk IOs, and build separate index file for each segment. In order to meet the demands of instant view of history data, the metadata of production storage is independently indexed. For long-time history data retrieval requirements, index snapshot is introduced in HSTIM to reduce the retrieval time. Another distinctive feature of HSTIM is its incremental retrieval method, which achieves high query performance at time point t + t if neighboring time point t is queried previously. The paper compares HSTIM with traditional B+-tree and multi-version B-tree (MVBT) index in many aspects. Experiments with real workload IO trace files show that HSTIM can locate history data within 8.05 seconds for recovery point of 48 hours, while B+-tree consumes 24.04 seconds. If the index snapshot is applied, HSTIM can reduce such retrieval time within 3 seconds.","","Electronic:978-0-7695-4134-1; POD:978-1-4244-8133-0","10.1109/NAS.2010.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575630","CDP;Recovery;data protection;index;storage","History;Image restoration;Indexing;Partitioning algorithms;Production;Time domain analysis","indexing;information retrieval;security of data","B+ tree;CDP logs;block-level continuous data protection;disk write operation;hierarchical spatial-temporal indexing method;incremental retrieval method;index snapshot;indexing method;multiversion B-tree;point-in-time recovery;production storage metadata;retrieval method;time window","","0","","32","","","15-17 July 2010","","IEEE","IEEE Conference Publications"
"Local Access to Sparse and Large Global Information in P2P Networks: A Case for Compressive Sensing","R. Gaeta; M. Grangetto; M. Sereno","Dipt. di Inf., Univ. degli Studi di Torino, Torino, Italy","2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P)","20100913","2010","","","1","10","In this paper we face the following problem: how to provide each peer local access to the full information (not just a summary) that is distributed over all emph{edges} of an overlay network? How can this be done if local access is performed at a given rate? We focus on emph{large and sparse} information and we propose to exploit the compressive sensing (CS) theory to efficiently collect and pro-actively disseminate this information across a large overlay network. We devise an approach based on random walks (RW) to spread CS random combinations to participants in a random peer-to-peer (P2P) overlay network. CS allows the peer to compress the RW payload in a distributed fashion: given a constraint on the RW size, e.g., the maximum UDP packet payload size, this amounts to being able to distribute larger information and to guarantee that a large fraction of the global information is obtained by each peer. We analyze the performance of the proposed method by means of a simple (yet accurate) analytical model describing the structure of the so called CS sensing matrix in presence of peer dynamics and communication link failures. We validate our model predictions against a simulator of the system at the peer and network level on different models of random overlay networks. The model we developed can be exploited to select the parameters of the RW and the criteria to build the sensing matrix in order to achieve successful information recovery. Finally, a prototype has been developed and deployed over the PlanetLab network to prove the feasibility of the proposed approach in a realistic environment. Our analysis reveals that the method we propose is feasible, accurate and robust to peer and information dynamics. We also argue that centralized and other distributed approaches, i.e., flooding and gossiping, are unfit in the context we consider.","2161-3559;21613559","Electronic:978-1-4244-7141-6; POD:978-1-4244-7140-9","10.1109/P2P.2010.5569971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569971","","Analytical models;Book reviews;Mathematical model;Peer to peer computing;Probability distribution;Sensors;Sparse matrices","information retrieval;peer-to-peer computing","CS sensing matrix;PlanetLab network;compressive sensing theory;information recovery;maximum UDP packet payload size;peer-to-peer networks;random overlay networks;random walks","","5","","17","","","25-27 Aug. 2010","","IEEE","IEEE Conference Publications"
"Optimal pattern search for sequence databases","V. R. Krishna; P. V. Kumar","Department of CSE, BITS, Narsampet, Warangal, A.P, India","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","2","","V2-654","V2-658","Many time series database applications require processing and analyzing database sequences where the focus is on finding the patterns and trends in sequence data. In this paper, we propose a new approach based on the observation that finding sequential patterns in databases is somehow similar to searching for a phrase in the text. However instead of searching for sequence of letters usually from finite alphabet, we search for sequence of tuple with rich structure and infinite possibilities. We take the text search algorithm of Boyer-Moore and generalize it to search for complex sequence patterns of interest in a given database by exploiting the logical interdependencies between the elements of a sequential pattern.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579518","Time series;database query languages;sequence pattern;sequences","Ice;Manganese","database management systems;information retrieval;time series","Boyer-Moore algorithm;optimal pattern search;sequence databases;sequential database patterns;time series database;tuple sequence","","0","","11","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Deployment and performance issues of an Integrated Wireless Sensor Network and Wireless mesh campus network","M. Hassan; R. Stewart; E. Brito; J. Allen","School of Engineering, Athlone Institute of Technology, Co.Westmeath, Ireland","2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010)","20100920","2010","","","890","895","Empirical results from a performance study of an Integrated Wireless Sensor Network (WSN) and Wireless Local Area Network (WLAN) are presented in this paper. Integration of heterogeneous wireless technologies using different modulation techniques such as direct-sequence spread spectrum (DSSS) and orthogonal frequency division multiplexing (OFDM) require careful deployment planning and configuration if network performance is to be optimized. The impact on network performance of the WLAN and WSN is investigated through a series of experiments on the Athlone Institute of Technology (AIT) campus network under realistic load conditions. Novel software tools from Motorola are used in this research for fast efficient deployment of WLAN's. These software tools utilize satellite maps of the deployment area to predict coverage and range. Combined with management tools for integrated channel assignment, this should provide performance enhancement capabilities. Our findings show that at least more than four channels of WSN were under interference when WSN and WLAN coexisted. The expression for a channel assignment model is adapted from Chowdhury et al . The reference power variables were taken from IEEE802.11g under real traffic loading with eight channels being considered. Achieving effective channel allocation for WSNs offers better performance due to less retransmission and inherently reduces energy consumption. This paper will be of interest to organisations where critical information retrieval over wide area networks in hostile environments (such as disaster recovery situations) is required as well as traditional network deployments.","","Electronic:978-1-86135-369-6; POD:978-1-4244-8858-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580295","","Interference;Load modeling;Sensors;Throughput;Wireless LAN;Wireless communication;Wireless sensor networks","OFDM modulation;channel allocation;information retrieval;software tools;telecommunication computing;telecommunication network planning;wide area networks;wireless LAN;wireless mesh networks;wireless sensor networks","Athlone Institute of Technology;DSSS;IEEE802.11g;Motorola;OFDM;WLAN;WSN;channel allocation;deployment planning;direct-sequence spread spectrum;heterogeneous wireless technologies;information retrieval;integrated channel assignment;integrated wireless sensor network;management tools;modulation techniques;network deployments;orthogonal frequency division multiplexing;real traffic loading;satellite maps;software tools;wide area networks;wireless local area network;wireless mesh campus network","","0","","18","","","21-23 July 2010","","IEEE","IEEE Conference Publications"
"Implementing an image information sharing system based on IHE XDS-I profile and ontology","Jian-Wu Lin; Der-Ming Liou","Institute of Biomedical Informatics, National Yang-Ming University, Taipei City 112, Taiwan (R.O.C.)","2010 Second International Conference on Communication Systems, Networks and Applications","20100930","2010","1","","109","111","The Integrating the Healthcare Enterprise (IHE) provided a series profiles for decreasing costs and integrating different healthcare enterprises. In IHE Cross-Enterprise Document Sharing for Image (XDS-I), it provides a web service and Web Access to Digital Imaging and Communication in Medicine Persistent Objects (WADO) service, to access DICOM objects. This paper analyzes the operational specifications of the WADO service and extends the access capability of WADO service to get other related documents and/or reports based on IHE XDS-I profile. And then we re-design an ontology following the Unified Medical Language System (UMLS) for use in the relationship between Structure Reports (SR). By analyzing the SR to retrieve key words and using an ontology to search, we can retrieve the other related reports and/or images. This research wants to find the related medical image documents when getting a SR or DICOM image from a patient or other Enterprises. It can reduce the time for searching and improve the diagnostic accuracy, when radiologist write or read reports and images.","","Electronic:978-1-4244-7478-3; POD:978-1-4244-7475-2","10.1109/ICCSNA.2010.5588758","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5588758","DICOM SR;IHE;UMLS;WADO","DICOM;HTML;Medical diagnostic imaging;Ontologies;Picture archiving and communication systems","Web services;health care;information retrieval;medical computing;ontologies (artificial intelligence)","DICOM image;IHE XDS-I profile;WADO service;Web access;Web service;cross enterprise document sharing;digital imaging;healthcare enterprise;image information sharing system;key word retrieval;medical image document;medicine persistent object;ontology;radiologist;structure report;unified medical language system","","0","","13","","","June 29 2010-July 1 2010","","IEEE","IEEE Conference Publications"
"Study on the Evaluation System of Basic Research Projects Outputs","R. Lei; J. Lv","Coll. of Inf. & Software, South China Agric. Univ., Guangzhou, China","2010 International Conference on E-Business and E-Government","20100930","2010","","","5523","5526","With the rapid development of social economy and increasing Capital Input of the Chinese government to basic scientific research, the evaluation of basic research projects outputs will be an important part of performance evaluation. Uncertainty and backwardness of value affirmation are the characteristics of basic research outputs, whose evaluation needs diversified participates, opening of evaluate process and becoming integrated part of normal work. The computer network and its related information technologies enable the development of information system of evaluation of the results of basic research projects. Information system of evaluation of basic research outputs based on internet can not only improve working efficiency, but also make the evaluation process fair, just and open. Based on the analysis of characteristics of basic research and review of existing works of the basic research outputs, we analyze the feasibility and necessity of informationizing of evaluation. The paper proposes the framework of a web-based evaluation system of basic research outputs.","","Electronic:978-1-4244-6647-4; POD:978-1-4244-6646-7","10.1109/ICEE.2010.1382","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5592949","basic science research;evaluation;information system","Book reviews;Complexity theory;Databases;Information systems;Internet;Servers","Internet;government data processing;information retrieval;public information systems","Chinese government;Web-based evaluation system;basic research projects outputs;computer network;information technologies;performance evaluation system;social economy","","0","","7","","","7-9 May 2010","","IEEE","IEEE Conference Publications"
"A folksonomy-ontology-based digital gazetteer service","X. Peng; R. Chen; C. Cheng; X. Yan","Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences, Beijing, China","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","6","At present, many digital gazetteer systems manage names and types of places. However, information of names and types is just a part of geographical knowledge, and types are relative nonflexible. Meanwhile, as free-tagging classification is widely used in web 2.0 implementations, folksonomy has raised various issues regarding information retrieval, though some management problems emerge when the quantity of inorganized tags raise to be large. In this paper, we describe an approach that embeds folksonomy and ontology into Digital Gazetteer Service in order to give a smarter Digital Gazetteer Service (FODGS), and to enrich geographical information retrieval capabilities. To present relations between tags and avoid problems raised by inorganized free-tagging, we develop a new method to manager those tags - we write a set of modular ontologies. For the purpose of make queries over all the data above, we store the data in a triple-store, which offers SPARQL support. Finally, this paper also introduces an application implementation - a prototype system of FODGS was built with a XML-based interface.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567595","digital gazetteer;folksonomy;geographical knowledge;ontology;tagging","Ontologies;Resource description framework;Semantics;Spatial databases;Tagging;Web sites","geographic information systems;information retrieval;ontologies (artificial intelligence);pattern classification","SPARQL support;XML-based interface;digital gazetteer service;folksonomy ontology;free-tagging classification;geographical information retrieval capability;geographical knowledge;inorganized tags;modular ontologies","","0","","8","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"1:10000 Scale urban navigation electronic map production based on provincial foundation surveying and mapping 3D products","D. Wang; Y. Gu; D. Yang","Department of Civil Engineering, Shandong Jiaotong University, Jinan, China","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","5","Navigation electronic map, one of the electronic maps or databases which contain spatial position geographical coordinates can be combined with spatial positioning system and guide man or means of transportation accurately to arrive from place of departure to place of destination with spatial information service function of location-based services and internet application. With the ever-increasing expansion of urban size, road construction has witnessed changes with each passing day, thus actual environment requires urban navigation electronic map strengthening geographical coverage and the accuracy of the information points. Urban navigation electronic map must possess very high accuracy, including the precision of geographic position data and accuracy of the actual ground features information. Various elements of urban navigation electronic map should also have correct topological relationships and overall connectivity, which enables each ground feature to correctly map the actual world in logic and in semantic. Urban navigation electronic map must provide complete ground features attribute information to satisfy the objective and actual requirements of searching and retrieval and navigation applications. Provincial foundation surveying and mapping is a basic and early phase project the provincial government has established with investment and with established updating mechanism. Provincial foundation surveying and mapping 3D products refer to the 1:10000 scale digital mapping products DLG, DEM, DOM. Digital line graphic (DLG) is the dataset vector of tiered storage of basic geographical elements of existing topographic maps, not only includes spatial information but also includes attribute information. Digital elevation model (DEM) is the digital collection which express ground surface relief by elevation. Digital orthoimage map (DOM) is the orthoimage data which applies digital elevation models to correct and inlay digital images, according to map sheet, clippin- - g and generating. Provincial foundation surveying and mapping DLG adopts ArcGIS Shapefile data format, with similar scale and data format to 1:10000 scale urban navigation electronic map, which can provide vector data for navigation electronic map production to ensure the consistency of the size, layer, classification and coding, properties of the map symbol. DEM, DOM can provide data base for three-dimensional navigation digital map production. High precision, high reliability, total factors of information and updating mode of provincial foundation surveying and mapping products just meet the requirement of the accuracy, information-richness and feasibility for urban navigation electronic map. Provincial foundation surveying and mapping 3D products, being used in urban navigation electronic map production, is a direct, economical, and efficient service mode. This paper describes the control and surveying of photograph, photograph annotation, and DLG, DEM, DOM data production process of provincial foundation surveying and mapping. Road annotation, production process, topology relation and geometric expression, coordinate transformation and data format of 1:10000 scale urban navigation electronic map are also dwelt on in the paper.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567476","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567476","3D products;DEM;DLG;DOM;GPS;navigation electronic map;provincial foundation surveying and mapping;urban","Belts;Bridges;Navigation;Roads;Three dimensional displays","Global Positioning System;computerised navigation;digital elevation models;geographic information systems;information retrieval;terrain mapping;transportation","1:10000 scale;3D product mapping;GIS;GPS;digital elevation model;digital line graphic;digital ortho image map;geographical coordinate;information retrieval;location based service;provincial foundation survey;spatial positioning system;urban navigation electronic map","","3","","5","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"Extracting Search Intentions from Web Search Logs","K. Park; T. Lee; S. Jung; S. Nam; H. Lim","Dept. Comput. Sci. Educ., Korea Univ., Seoul, South Korea","2010 2nd International Conference on Information Technology Convergence and Services","20100923","2010","","","1","6","Web search users complain of inaccurate results of the current search engines. Most of inaccurate results are from failing to understand user's search goal. This paper proposes a method to mine user's intentions and to build an intention map representing their information needs. It selects intention features from search logs obtained from previous search sessions on a given query and extracts user's intentions by using clustering and labeling algorithms. The mined user's intentions on the query are represented in an intention map. For the efficiency analysis of intention maps, we extracted user intentions using 2,600 search log data of a current domestic commercial web search engine. The experimental results using a web search engine with the intention maps show statistically significant improvements in user satisfaction scores.","","Electronic:978-1-4244-7585-8; POD:978-1-4244-7583-4","10.1109/ITCS.2010.5581286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5581286","","Classification algorithms;Clustering algorithms;Data mining;Engines;Feature extraction;Partitioning algorithms;Web search","Internet;information needs;information retrieval;pattern clustering;search engines","Web search engine;Web search logs;clustering algorithm;information needs;intention map;labeling algorithms;search intention extraction;user intention mining","","1","","16","","","11-13 Aug. 2010","","IEEE","IEEE Conference Publications"
"Study on Wikipedia for translation mining for CLIR","J. M. Yao; C. L. Sun; Y. Hong; Y. D. Ge; Q. M. Zhu","Suzhou University, Jiangsu Province, Key Laboratory of Computer Information Processing, Suzhou 215006","2010 International Conference on Machine Learning and Cybernetics","20100920","2010","6","","3374","3379","The query translation of Out of Vocabulary (OOV) is one of the key factors that affect the performance of Cross-Language Information Retrieval (CLIR). Based on Wikipedia data structure and language features, the paper divides translation environment into target-existence and target-deficit environment. To overcome the difficulty of translation mining in the target-deficit environment, the frequency change information and adjacency information is used to realize the extraction of candidate units, and establish the strategy of mixed translation mining based on the frequency-distance model, surface pattern matching model and summary-score model. Search engine based OOV translation mining is taken as baseline to test the performance on TOP1 results. It is verified that the mixed translation mining method based on Wikipedia can achieve the precision rate of 0.6279, and the improvement is 6.98% better than the baseline.","2160-133X;2160133X","Electronic:978-1-4244-6527-9; POD:978-1-4244-6526-2","10.1109/ICMLC.2010.5580683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5580683","","Data mining;Electronic publishing;Encyclopedias;Equations;Internet;Mathematical model","computational linguistics;data mining;information retrieval;search engines","CLIR;OOV;Wikipedia data structure;cross-language information retrieval;frequency adjacency information;frequency change information;frequency-distance model;language features;mixed translation mining;out of vocabulary;search engine;summary-score model;surface pattern matching model","","0","","16","","","11-14 July 2010","","IEEE","IEEE Conference Publications"
"An evidence-based approach for Toponym Disambiguation","X. Wang; Y. Zhang; M. Chen; X. Lin; H. Yu; Y. Liu","Institute of Remote Sensing and Geographical Information Systems, Peking University, Beijing, China 100871","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","7","Toponym Disambiguation (TD) in Geographic Information Retrieval (GIR) systems is a crucial technique, which makes a direct impact on the quality of subsequent assignment of geographic focus to a document and that of establishment of spatial index as well as the effectiveness of the entire retrieval model as a whole. We explore the mechanism for human beings' dealing with the problem of TD. Human's way of TD follows some linguistic rules since that documents are organized according to these rules. From a linguistic perspective, involved rules fall into three categories: semantic rules, syntactic rules and pragmatic rules. In this paper we set our focus on semantic rules. Moreover, co-occurring toponyms without any ambiguity in the same context of document can be regarded as evidences or clues to support the process of TD. The candidate referent of a toponym that has the closest semantic relationship with the referent of co-occurring toponym as evidence in context is chosen as the intended one. To achieve this goal, the strength of semantic relationships among co-occurring toponyms is required to be computed properly. In response to this requirement, a model is proposed in this paper for the needed calculation. Combining the evidential effects of toponyms as evidences is essential when there are multiple of them in context. In this paper, we propose an evidence-based approach to fulfill the task of TD in two main steps: 1) calculate the semantic relationships between any two geographical referents based on a computing model of semantic relations among them; 2) use Dempster-Shafer (D-S) theory of evidence to combine multiple co-occurring toponyms as evidences. Finally, case studies are presented to evaluate the effectiveness of our approach.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567805","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567805","D-S theory;Evidence;Semantic relations;Toponym Disambiguation","Cities and towns;Computational modeling;Context;Mathematical model;Measurement;Pragmatics;Semantics","case-based reasoning;document handling;geographic information systems;inference mechanisms;information retrieval;linguistics","Dempster Shafer evidence theory;document;evidence based approach;geographic information retrieval systems;linguistic rules;toponym disambiguation","","1","","28","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"Multi-Type Web Relation Extraction Based on Bootstrapping","X. Liu; N. Yu","MOE-MS KeyLab of MCC, Univ. of Sci. & Technol. of China, Hefei, China","2010 WASE International Conference on Information Engineering","20100916","2010","2","","24","27","Web-scale relation extraction is crucial to building the Web people search engines. Previous extraction models, such as Snowball, focus only on single type extraction, while the real applications always require as many as possible types of relation. In this paper, we propose a novel Web-scale relation extraction framework Multi-Type Snowball (MultiSnowball). MultiSnowball targets at extracting multiple types of relation simultaneously while starts with one pattern. By adopting the general bootstrapping framework, MultiSnowball not only iteratively finds new relation tuples and extraction patterns, but also iteratively identifies new relation types. Patterns are shared during the simultaneous extraction process among all the types to get more relation tuple extractions. Empirical studies on real Web-scale data set show the effectiveness of MultiSnowball over the baseline and Snowball and the ability to identify accurate relation types.","","Electronic:978-1-4244-7507-0; POD:978-1-4244-7506-3","10.1109/ICIE.2010.365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5571211","bootstrapping;people search;relation extraction","Data mining;Electronic publishing;Encyclopedias;Organizations;Pattern matching;Search engines;Web pages","Internet;computer bootstrapping;information retrieval;search engines","Web people search engines;Web-scale data set;general bootstrapping framework;multitype Snowball extraction models;multitype Web relation extraction;simultaneous extraction process;single type extraction","","0","","4","","","14-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"Management information system for documents archiving and organization security","A. Nadeem; Muhammad Haroon Yousaf; Hafiz Adnan Habib","Department of Computer Engineering, University of Engineering and Technology, Taxila, Pakistan","2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE)","20100920","2010","6","","V6-1","V6-4","This paper presents multi-user desktop application which can be implemented in any academic institution to record and manage all sort of permanent and day to day statistical data of students and staff. Other than this data, the paper also presents the computerized solution to save all the necessary documents/letters/certificates in the database through multi page high speed scanning system which can be retrieved and reproduced through a powerful query system. This process also helps to reduce the fatigue of physical handling and storing the documents in the files and piling up all this stuff in a store of the institution. The application also has the provision to create and print the Bar Code on the Identity cards which can be detected through any bar code reader to improve the institutional security. It helps to retrieve and view the personal data, very quickly. OCR feature implementation on the scanned forms helps to extract basic data through this technique and save it in the database automatically, thus automate the document archiving system by reducing the man power and labour cost involved in this activity.","2154-7491;21547491","Electronic:978-1-4244-6542-2; POD:978-1-4244-6539-2","10.1109/ICACTE.2010.5579353","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5579353","Documents Archiving;Management Information System;OCR;Organizational Security","Databases;Lead;Security","database management systems;educational institutions;image scanners;information retrieval systems;management information systems;mark scanning equipment;optical character recognition;query processing;records management;security of data;statistical analysis","OCR feature implementation;academic institution;bar code reader;document archiving system;document storage;documents archiving;identity cards;institutional security;management information system;multipage high speed scanning system;multiuser desktop application;organization security;personal data;physical handling;powerful query system;scanned forms;statistical data","","0","","5","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
