"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5567583,5566433,5568702,5564283,5566301,5569709,5568893,5568927,5569630,5566569,5569377,5568598,5566448,5566554,5566633,5569791,5567695,5569794,5569528,5565256,5569298,5564174,5569673,5564016,5565018,5563808,5563598,5564100,5563625,5563653,5564459,5563818,5563638,5563924,5563057,5563410,5564530,5563526,5562786,5564723,5563061,5563787,5563743,5563359,5564098,5564125,5561360,5559696,5561330,5561454,5561603,5561533,5559693,5561334,5561027,5561354,5559739,5559853,5561537,5561588,5558004,5558962,5557335,5557361,5557336,5558956,5558658,5558911,5558905,5557168,5558016,5555313,5553112,5553378,5556472,5473200,5555537,5556569,5554125,5556657,5555396,5555788,5555619,5552413,5552343,5551343,5374412,5551706,5437175,5549699,5547964,5223698,5550041,5543536,5546440,5546792,5543924,5540938,5543020,5543921",2017/05/04 22:36:26
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"GDAL-based extend ArcGIS Engine's support for HDF file format","S. Zhao; T. Yu; Q. Meng; Q. Zhou; F. Wang; L. Wang; Y. Hu","College of Informatics, South China Agriculture University, Guangzhou, China","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","3","ArcGIS Engine can access HDF files with only one dataset, but can not access HDF files with multiple datasets. To Make ArcGIS Engine have the ability to access HDF files with multiple datasets, this article studies the data model of GDAL, and uses the API of GDAL to read HDF files into memory, then uses the programming interface of ArcGIS Engine to convert the data in memory to raster datasets that ArcGIS Engine can access. With this method, ArcGIS Engine will have the ability to access HDF files with multiple datasets.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567583","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567583","ArGIS;GDAL;HDF;precipitation raster","Engines;Image resolution;Libraries;Pixel;Software;Spatial databases;Transforms","application program interfaces;electronic data interchange;geographic information systems;information retrieval","API;ArcGIS engine;GDAL;HDF flie access;data conversion;multiple datasets;programming interface","","1","","7","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"Research of Real-Time WLAN MAC Protocol","X. y. Shuai; H. s. Huang; D. b. Lian","Dept. of Comput. Sci., Chizhou Coll., Chizhou, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","Proposed a modified WLAN MAC protocol, to lower real-time data access delay of control system. Data transported through the control system of WLAN included: burst real-time data (BRD), periodical real-time date (PRD) and non-real-time data (NRD). Priority ranged from the high level to the low level and distinguished them by different inter frame space (IFS). Presents boundary backoff and polling algorithm to avoid collide of real-time data, which guaranteed the bound of real-time access delay. Simulation and analysis show the performance of the modified MAC excels the standard MAC in real-time access delay.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566433","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566433","","Delay;Gallium nitride;IEEE 802.11 Standards;Media Access Protocol;Real time systems;Wireless LAN","access protocols;information retrieval;real-time systems;wireless LAN","burst real-time data;inter frame space;nonreal-time data;periodical real-time date;real-time WLAN MAC protocol;real-time data access delay","","0","","12","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Study on IT-based teaching evaluation","S. y. Li; X. g. Liang; Z. Han","Department of Education Technology, Handan College, China","2010 International Conference On Computer Design and Applications","20100809","2010","5","","V5-408","V5-410","It is the focus of common concern that whether reform can succeed and achieve the desired purpose. Evaluation of IT-based teaching, which is one of the important means of evaluation on curriculum reform effect, worths an in-depth study. The elementary education curriculum reform has undergone tremendous changes in all aspects of basic education. Firstly, this thesis retrieval research on the IT-based teaching evaluation in five years. Secondly, the author uses the method of content analysis to analyze, classify and sum up these papers, finds the current situation and problems of IT-based teaching evaluation. Lastly, the author analyzes the problem and proposes corresponding strategies to solve it. This thesis attempts to provide basis and foundation for the construction of IT-based teaching evaluation system.","","Electronic:978-1-4244-7164-5; POD:978-1-4244-7162-1","10.1109/ICCDA.2010.5540938","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5540938","E-learning;IT-based teaching;Information technology;development;teaching evaluation","Cities and towns;Computer science education;Content based retrieval;Councils;Educational institutions;Educational technology;Electronic learning;Information analysis;Information technology;Information theory","computer aided instruction;content management;information retrieval;teaching","IT-based teaching evaluation;basic education;content analysis;curriculum reform effect;e-learning;elementary education curriculum reform;in-depth study;thesis retrieval research","","0","","4","","","25-27 June 2010","","IEEE","IEEE Conference Publications"
"Application of blog for setting metadata of digital archives- a value added aspect","Z. P. Ho; Huei-Ju Lee","Digital Group, Taichung Division, The Society of Wilderness, Taiwan","6th International Conference on Digital Content, Multimedia Technology and its Applications","20100909","2010","","","217","220","A digital archive is a digital database, which is built by the internet, websites' culture and information techniques. In digital archives, there's a high correlation between documental connotation and information techniques, especially in historically cultural information. Numerous institutions archives are going digitalized. People are able to access digital archives information, even if seldom people could access the original. However, on the current artificial intelligence methodology, it is still a hard problem to describe a story for humans after computer reading mass information. At this moment, if we can gather a lot of friends from the internet, discussing valuable photos, articles or videos from blogs, then, it would form a popular approach to set up a metadata. This paper offers this new concept to illustrate the new ideas, hoping that it can reduce the gap between current techniques and a willingness to create new ones. It also could create new meanings of knowledge management and cultural development.","","Electronic:978-8-9886-7827-5; POD:978-1-4244-7607-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568702","blog;digital archive;digital library;knowledge management;metadata","Blogs;Couplings;Photonics","Internet;Web sites;digital libraries;information retrieval systems;meta data","Internet;blog;digital archive;digital database;documental connotation;information techniques;metadata","","0","","26","","","16-18 Aug. 2010","","IEEE","IEEE Conference Publications"
"Workload analysis of SPECmail2009","H. Oi; S. Niboshi","Computer Architecture and Operating Systems Group, The University of Aizu Aizu-Wakamatsu, Japan","2010 International Symposium on Information Technology","20100902","2010","2","","672","677","SPECmail2009 is a new benchmark suite for measuring the performance of corporate mail servers. It assumes the IMAP4 protocol for retrieving messages and a large fraction of transactions are for manipulating hierarchical messages and mail folders from the users connected via high-speed networks. In this paper, we present a performance analysis of SPECmail2009, including disk I/O behavior, quality of service metrics, and CPU time breakdown. The IMAP4's capability of directly manipulating the messages on the server makes SPECmail2009 a highly I/O-bound workload. Our experiments show that a combination of a small but fast access SCSI drive for indexing messages and larger but slower SATA drives for message files can be an option for building a cost-effective mail storage. Both of multiprocessing and multithreading are quite effective for SPECmail2009 especially in the user mode execution.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561533","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561533","Mail server;disk I/O;performance analysis","Benchmark testing;HTML;Postal services;Protocols;Servers","Internet;electronic mail;indexing;information retrieval;performance evaluation;protocols","IMAP4 protocol;SATA drives;SPECmail2009;disk I/O;indexing messages;mail servers;message retrieval;messages manipulation;performance analysis;workload analysis","","0","","15","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"How to get a good digital library","Y. Mao; J. Wang","School of Computer, China University of Mining and Technology, Xuzhou Jiangsu 221116 China","2010 International Conference on Intelligent Control and Information Processing","20100909","2010","","","240","243","Digital libraries are information collections that have associated services delivered to user communities using a variety of technologies. In this paper we present 8Qual, a tool which provides ways to perform automatic and configurable evaluations of some of the most important DL components-digital objects, metadata, and services. And we propose a fuzzy linguistic recommender system to achieve major advances in the activities of DL in order to improve their performance.","","Electronic:978-1-4244-7050-1; POD:978-1-4244-7047-1","10.1109/ICICIP.2010.5564283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564283","","Books;Communities;Libraries;Pragmatics;Recommender systems;Resource management;XML","digital libraries;information retrieval;meta data","8Qual;digital library;digital objects;fuzzy linguistic recommender system;information collections;metadata;user communities","","0","","15","","","13-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"Methodology for developing web-based applications from reusable components using open-source tools","H. Krawczyk; A. Rek","Department of Computer Architecture, Gdansk University of Technology, Poland","2010 2nd International Conference on Information Technology, (2010 ICIT)","20100823","2010","","","117","120","A global network provides new opportunities for IT designers. It allows building applications from many pieces, known as components, distributed in different network locations. This methodology describes how to build all system elements; business logic, data access and a presentation layer from the coarse-grained components. Such a possibility gives us the Java programming language and related open source technologies: Enterprise JavaBeans (EJB) for creating business components and Java Portlets for creating interface components. The presented approach shows how to manage relationships between components and their versions. It describes methods to ensure reliable and fast communication between them. The authors present platforms for building and testing automation of component based applications and explain how the component based approach could help to speed up the team work.","","Electronic:978-83-60779-02-6; POD:978-1-4244-8182-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5553378","Java;Web application;component;open source;portlet","World Wide Web","Java;Web services;information retrieval;public domain software;software reusability","Enterprise JavaBeans;IT designer;Java portlets;Java programming language;Web based application;automation testing;business logic;coarse grained component;data access;open source tool;presentation layer;reusable component","","0","","20","","","28-30 June 2010","","IEEE","IEEE Conference Publications"
"VLIW architecture optimization for an efficient computation of stereoscopic video applications","G. Payá-Vayá; J. Martín-Langerwerf; C. Banz; F. Giesemann; P. Pirsch; H. Blume","Institute of Microelectronic Systems, Leibniz Universit&#x00E4;t Hannover (Germany)","The 2010 International Conference on Green Circuits and Systems","20100809","2010","","","457","462","This paper presents two new architecture optimizations to improve the processing performance of video applications with a high degree of data parallelism in VLIW processors. On the one hand, a new register file access mechanism, called X4 operation mode, allows to access wide operands made up of several consecutive registers in the register file, while keeping its normal functionality (i.e. single read/write register access). On the other hand, a new functional unit is proposed to efficiently process a typical stereoscopic video application based on a rank transformation and a semi-global-matching algorithm. An evaluation of those enhanced mechanisms is performed using a generic VLIW architecture and the resulting VLIW processor is compared with other CPU/GPU and FPGA implementations. The proposed architecture provides the full flexibility of a programmable processor, while processing 640×480 stereo video sequences under real-time conditions, what is not possible with the compared CPUs or GPUs.","","Electronic:978-1-4244-6878-2; POD:978-1-4244-6876-8; USB:978-1-4244-6877-5","10.1109/ICGCS.2010.5543020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5543020","","Computer architecture;Data mining;Embedded system;Field programmable gate arrays;Hardware;Machine vision;Microelectronics;Registers;VLIW;Vehicle detection","image matching;image sequences;information retrieval;multiprocessing systems;optimisation;program processors;stereo image processing","VLIW architecture;X4 operation mode;data parallelism;optimization;programmable processor;rank transformation algorithm;register file access mechanism;semi-global matching algorithm;stereoscopic video;video sequences","","8","","19","","","21-23 June 2010","","IEEE","IEEE Conference Publications"
"A Program-and-User Based File Access Prediction Model","H. Hu; D. Qian","Sch. of Comput. Sci., Beihang Univ., Beijing, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","Abstract-In the research on external storage file access prediction algorithms, how to improve the predictive hit ratio and the degree of applicability becomes the major issue. This paper discusses several current prediction models including Program-based Last Successor (PLS) model, User-based Last Successor (ULS) model and Program-and User-based Last Successor (PULS) model, which both use program or user information to improve the predictive hit ratio, but all three models need a lot of file access history information which requires a long time to accumulate and have poor applicability. This paper presents a Program-and User-based Buffer Window (PUBW) model, which not only uses program and user information to improve the prediction hit ratio, but also uses the buffering mechanisms to improve its applicability. Our simulation results show that PUBW model achieves higher predictive hit ratio compared with the PLS and ULS model and has almost the same high degree of applicability as the Last Successor (LS) model. Our experiments show that the PUBW model is a useful and efficient file access prediction model.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566301","","Analytical models;Computational modeling;Computer science;Computers;Markov processes;Predictive models;Prefetching","buffer storage;information retrieval;prediction theory","PLS model;PUBW model;ULS model;buffering mechanism;file access history information;predictive hit ratio;program and user based buffer window;program and user based file access prediction model;program based last successor model;user based last successor model","","0","","9","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Zycox: File analyzer on the web","K. Sukhija","Qualcomm Incorporated, San Diego, California, USA","2010 International Conference on Electronics and Information Engineering","20100902","2010","1","","V1-548","V1-551","This paper includes the details on the implementation of the Zycox (Document Analyzer). It analyses the complete document by making permutation & combination of words and sentences which are further searched on the different search engines to find their relevant URL's and thus gives the complete statistical analyses on the document with its originality and percentage of document copied from the web.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559693","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559693","Document Parsing;File Analyzing;Intelligent Editors;Porter Algorithm","Algorithm design and analysis;Data mining;Hard disks;Internet;Privacy;Search engines","information retrieval;search engines;statistical analysis;text analysis","URL;Web document;Zycox;document analyses;file analysis;file analyzer;search engines;statistical analysis","","0","","6","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Dynamic and Task-Oriented Social Network Extraction System Based on Analyzing Personal Social Data","K. Y. Wang; I. H. Ting; H. J. Wu; P. S. Chang","Dept. of Marketing, Int. Bus. & Strategy, Brock Univ., St. Catharines, ON, Canada","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","464","469","Large amount of social (communication) data have been generated in many applications for personal communication purpose. However, these data have not been used well currently. In this paper, we will introduce a methodology to collect and analyze those personal data, and by this for extracting social networks from the data. A system architecture will also be presented and implemented to show how the data can be collected, pre-processed, analyzed, which can also be used for personal decision support.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.47","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563057","E-mail;Instant Messenger;Social Network Analysis;Social Networking;Visualization","Construction industry;Data mining;Data visualization;Electronic mail;Engines;History;Social network services","data analysis;information retrieval;object-oriented methods;social networking (online);software architecture","data analysis;social network;system architecture;task-oriented extraction system","","2","","28","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Model based detection of implied scenarios in multi agent systems","M. Moshirpour; A. Mousavi; B. H. Far","Department of Electrical and Computer Engineering, University of Calgary, Canada","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","63","68","Multi-agent systems (MAS) are efficient solutions for commercial applications such as information retrieval and search. In a MAS, agents are usually designed with distribution of functionality and control. Lack of central control implies that the quality of service of MAS may be degraded because of possible unwanted behavior at the runtime, commonly known as emergent behavior. Detecting and removing emergent behavior during the design phase of MAS will lead to huge savings in deployment costs of such systems. An effective approach for the MAS design is to describe system requirements using scenarios. A scenario, commonly known as a message sequence chart or a sequence diagram, is a temporal sequence of messages sent between agents. In this paper a method for detecting emergent behavior of MAS by detecting incompleteness and partial description of scenarios is proposed. The method is explained along with a prototype MAS for semantic search that blends the search and ontological concept learning.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558962","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558962","annotation;emergent behaviour;message sequence chart;multiagent system;semantic search","Automata;Buildings;Finite element methods;Multiagent systems;Ontologies;Semantics;Spirals","emergent phenomena;information retrieval;multi-agent systems","MAS;information retrieval;message sequence chart;model based detection;multiagent systems;ontological concept learning;sequence diagram;temporal sequence","","5","","21","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"Assessing Concurrent Think-Aloud Protocol as a Usability Test Method: A Technical Communication Approach","L. Cooke","English Department, West Chester University of Pennsylvania, West Chester","IEEE Transactions on Professional Communication","20100823","2010","53","3","202","215","Concurrent think-aloud protocol (CTA) is often used in usability test settings to gain insight into participants' thoughts during their task performances. This study adds to a growing body of research within technical communication that addresses the use of think-aloud protocols in usability test settings. The eye movements and verbalizations of 10 participants were recorded as they searched for information on a website. The analysis of transcripts and real-time eye movement showed that CTA is an accurate data-collection method. The researcher found that the majority of user verbalizations in the study included words, phrases, and sentences that users read from the screen. Silence and verbal fillers that occurred during CTA enabled users to assess and process information during their searches. This study demonstrates the value technical communicators add to the study of usability test methods, and the paper recommends future avenues of research.","0361-1434;03611434","","10.1109/TPC.2010.2052859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556472","Cognitive psychology;communication;technical communication","Human computer interaction;Mice;Professional communication;Protocols;Psychology;Testing;Usability","Web sites;cognition;eye;human computer interaction;information retrieval systems;protocols;psychology","concurrent think-aloud protocol;data-collection method;information search;participant thoughts;real-time eye movement;task performances;technical communication approach;technical communicators;transcripts analysis;usability test method;verbal fillers;verbalizations;website","","17","","53","","","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"A re-examination of ranking metrics for Learning Object repository","N. Y. Yen; Ying-Hong Wang; Qun Jin; D. J. T. Yang","Dept. of Human Informatics and Cognitive Sciences, Waseda University, Japan","2010 3rd IEEE International Conference on Ubi-Media Computing","20100809","2010","","","91","94","In line with the popularity of Internet and the development of search engine, users request information through Web-based services. Although general purpose searching such as one provided by Google is powerful, searching mechanism for specific purposes could rely on metadata. We followed SCORM and CORDRA specifications to develop a registry system, called the MINE Registry, for storing and sharing 20,738 Learning Objects created in the past five years. As a contribution, we propose the concept of “Reusability Tree” to represent the relationships among relevant Learning Objects and to enhance CORDRA. We further collect relevant information while users are utilizing Learning Objects, such as citations and time period persisted. The feedbacks from community users are also considered as critical elements for evaluating significance degree of Learning Objects. Through these factors, we propose a mechanism to weight and rank Learning Objects in the MINE Registry, in addition to other external learning objects repositories.","","Electronic:978-1-4244-6709-9; POD:978-1-4244-6708-2","10.1109/UMEDIA.2010.5543921","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5543921","","Cloud computing;Computer aided instruction;Computer science;Courseware;Feedback;Grid computing;Humans;Informatics;Search engines;Web and internet services","Internet;information retrieval;learning (artificial intelligence);meta data;search engines","CORDRA specification;Internet;MINE registry;SCORM specification;Web based service;general purpose searching;learning object repository;metadata;ranking metrics re-examination;reusability tree;search engine;users request information","","0","","13","","","5-6 July 2010","","IEEE","IEEE Conference Publications"
"Performance issues of hospital system using MySQL","N. Kohli; N. K. Verma","Electrical Engineering Department, Indian Institute of Technology, Kanpur, India","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","6","","497","501","To provide the better treatment in the hospitals, it is required to integrate all the hospitals of the country via internet. While visiting to hospital for treatment, a smart card with 10 digit unique patient-ID with his personal information is issued to the patient from the administrator of the hospital. As per unique patient-ID, all the doctor prescriptions, test reports, MRI, CT-scan images are stored in the database of the local server of the hospital and main centralized server of all the hospitals. Application of the smart card based on line hospital system has been developed as front end in .Net and back end in MySQL. In the development of application, all kinds of optimization have been covered at application level, database design level, memory utilization and optimization of queries for accessing the database. In this paper, some performance issues have been proposed for fast retrieval of patient data.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564100","Hospital;MySQL;patient;smart card","Databases","Internet;SQL;hospitals;information retrieval;medical information systems;optimisation;patient treatment;personal information systems;smart cards;software performance evaluation",".Net;CT-scan image;Internet;MRI report;MySQL;doctor prescription;hospital centralized server;hospital system;patient data retrieval;patient test report;patient-ID;personal information;smart card","","0","","11","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"DRWSC — To simplify dynamic invocation for RESTful Web services","Y. Chen; J. Li; Y. Lv; H. Qin; L. Zhang","School of Computer Science, Fudan University, Shanghai 200433, China","2010 IEEE International Conference on Software Engineering and Service Sciences","20100819","2010","","","226","229","Dynamic invocation has always been a hot issue in Web services in order to take full advantage of the flexibility of services computing. One key underlying enabling technology is a self-descriptive contact between the service consumer and provider. In the SOAP-based environment, WSDL has been proven a successful description language which is widely accepted. But for many years, we cannot get the equivalent in the RESTful, another dominant style of Web services. Thanks for the announcement of WSDL 2.0 which has been designed with RESTful Web service in mind and became a recommend in 2007, developers can use it as the APIs for RESTful Web services which are attracting more and more attention of Web applications all over the world. Unfortunately, the vision is almost unfulfilled due to rare reference implementations. To fill the gap between the vision and practice, we present a useful tool for dynamically invoking RESTful Web services based on the information extracted from WSDL 2.0. Our implementation demonstrates the feasibility that dynamic invocations in general RESTful Web services can be done as easy as in SOAP-based ones.","2327-0586;23270586","Electronic:978-1-4244-6055-7; POD:978-1-4244-6054-0","10.1109/ICSESS.2010.5552413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5552413","RESTful;SOAP;WSDL 2.0;Web service;dynamic invocation","Data mining;Graphical user interfaces;Service oriented architecture;Simple object access protocol;Web sites","Web services;information retrieval;software architecture","DRWSC;RESTful Web service;REpresentational State Transfer;SOAP based environment;description language;dynamic invocation;information extraction;service consumer;service provider;services computing","","1","","13","","","16-18 July 2010","","IEEE","IEEE Conference Publications"
"Improving the index structure with hierarchical techniques in time-series databases","T. Sun; J. Liu; L. Feng","School of Innovation Experiment, Dalian University of Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2089","2094","The R*-tree, as a state-of-the-art spatial index, has already been applied in many fields. But in high-dimensional space its performance is not better than sequential scan algorithm. To solve time-series retrieval problem, we introduce a new index structure - Hierarchical Index Tree. Each time-series of database is divided into several segments with same length, each segment of which corresponds to a cell-tree similar to R*-Tree. Based on the proposed structure, we introduce the corresponding insertion and retrieval algorithm respectively. And we prove no false dismissals for the algorithms. Extensive experiments reveal that Hierarchical Index Tree is superior to the traditional retrieval methods when the dimension of time-series is high.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569709","Data mining;Hierarchical Index Tree;Similar research;Time-series","Algorithm design and analysis;Indexes;Pediatrics;Robustness;Temperature measurement;Tin","database indexing;information retrieval;time series;trees (mathematics)","R*-tree;hierarchical index tree;index structure;spatial index;time-series databases;time-series retrieval problem","","0","","14","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Incremental Embedding and Learning in the Local Discriminant Subspace With Application to Face Recognition","M. Cheng; B. Fang; Y. Y. Tang; T. Zhang; J. Wen","Dept. of Comput. Sci., Chongqing Univ., Chongqing, China","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","20100816","2010","40","5","580","591","Dimensionality reduction and incremental learning have recently received broad attention in many applications of data mining, pattern recognition, and information retrieval. Inspired by the concept of manifold learning, many discriminant embedding techniques have been introduced to seek low-dimensional discriminative manifold structure in the high-dimensional space for feature reduction and classification. However, such graph-embedding framework-based subspace methods usually confront two limitations: (1) since there is no available updating rule for local discriminant analysis with the additive data, it is difficult to design incremental learning algorithm and (2) the small sample size (SSS) problem usually occurs if the original data exist in very high-dimensional space. To overcome these problems, this paper devises a supervised learning method, called local discriminant subspace embedding (LDSE), to extract discriminative features. Then, the incremental-mode algorithm, incremental LDSE (ILDSE), is proposed to learn the local discriminant subspace with the newly inserted data, which applies incremental learning extension to the batch LDSE algorithm by employing the idea of singular value-decomposition (SVD) updating algorithm. Furthermore, the SSS problem is avoided in our method for the high-dimensional data and the benchmark incremental learning experiments on face recognition show that ILDSE bears much less computational cost compared with the batch algorithm.","1094-6977;10946977","","10.1109/TSMCC.2010.2043529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5437175","Dimensionality reduction;discriminant embedding;face recognition;incremental learning;manifold learning;singular value decomposition (SVD);small sample size (SSS) problem","","data mining;feature extraction;graph theory;information retrieval;learning (artificial intelligence);pattern classification;singular value decomposition","batch algorithm;data mining;dimensionality reduction;face recognition;feature classification;feature extraction;feature reduction;graph-embedding framework;high-dimensional space;incremental learning;information retrieval;local discriminant subspace;manifold learning;singular value-decomposition;supervised learning","","15","","56","","20100322","Sept. 2010","","IEEE","IEEE Journals & Magazines"
"Evaluating the accessibility and visibility of Quran websites","A. B. A. Bakar","Dept. of Libr. &amp; Inf. Sci., Int. Islamic Univ. Malaysia, Kuala Lumpur, Malaysia","2010 International Symposium on Information Technology","20100902","2010","1","","1","4","With the introduction of the World Wide Web and graphical browsers in the 1990s the Internet has become widely accessible and many people have grabbed the idea of using it for their multifarious purposes and agenda. They have established all types of websites to foster their mission and visions. They recognize that Internet can enhance their scale of communication through the websites as the Internet is capable of delivering large quantities of information in a speedy manner to the public. It is not surprising therefore that Muslims believe that the websites are the most useful platform to disseminate Islamic knowledge and information. The most important website that Muslims interact with is the Holy Quran website. Higher quality websites tend to attract more links and rendered those websites as highly visible. Using a software, Alexa, it is possible to gauge the volume of web traffic in order to determine the visibility of the website. In this paper Alexa is applied to study the visibility of Quranic websites. Nine quranic websites were investigated. It was found that the website, almushaf.com is the most visible website. It is futile to have a website that is difficult to access by users owing to non compliance with the accessibility guidelines. To check whether a particular Al-Quran website conforms or not to the accessible guidelines a software, A-Prompt could be used. The A-Prompt is able to examine the Al-Quran websites for barriers to accessibility, and at the same time is able to perform automatic repairs of the respective websites. Applying A-Prompt it was found that the most inaccessible website is the qurancomplex.org.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561334","Quran;accessibility;software;visibility;websites","Couplings;Guidelines;Internet;Printing;Software;Web pages","Web sites;humanities;information dissemination;information retrieval;online front-ends","A-Prompt;Al-Quran Website;Alexa software;Internet;Islamic knowledge dissemination;Muslim;Web traffic;World Wide Web;graphical browser;information accessibility;information dissemination;information visibility","","1","","4","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"An internet based interactive telemedicine system for remote healthcare","N. Celik; J. Baker; H. Youn; M. F. Iskander","Hawaii Center for Advanced Communications, Honolulu, HI, 96822","2010 IEEE Antennas and Propagation Society International Symposium","20100902","2010","","","1","4","To enable remote monitoring and diagnosis of patients located far from medical facilities, a prototype Internet based telemedicine system is developed. The developed telemedicine system establishes an audio-visual connection as well as a data path from the patient's home to the medical personnel's office through a web browser interface. A remote controlled wireless camera installed on the patient side can be tilted, zoomed, and panned by the doctor, at the medical facility, to examine different parts of the patient's body through the web interface. Unlike many of the existing systems, the established data path enables additional diagnosis functions such as electrocardiogram, blood pressure, respiration, temperature, and stethoscope. Results from laboratory and field testing of the developed system are presented and avenues for broader implementation in integrated facilities using low cost wireless networks will be discussed.","1522-3965;15223965","Electronic:978-1-4244-4968-2; POD:978-1-4244-4967-5","10.1109/APS.2010.5561027","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561027","","Cameras;Medical diagnostic imaging;Medical services;Software;Telemedicine;Temperature sensors","Internet;health care;information retrieval;monitoring;patient diagnosis;telemedicine;user interfaces","Internet;Web browser interface;audio-visual connection;interactive telemedicine system;patient diagnosis;remote healthcare;remote monitoring;wireless networks","","4","","7","","","11-17 July 2010","","IEEE","IEEE Conference Publications"
"The research on double-base state model with amendments","Liu Xiaosheng; Ren Xueshen","School of Architectural and Surveying Engineering, Jiangxi University of Science and Technology, Ganzhou, 341000, China","2010 The 2nd Conference on Environmental Science and Information Application Technology","20100909","2010","1","","470","473","Based on the characteristics of land-use change, a model of double-base state with amendments is proposed with the analysis of existing ground-state correction model, including the model design idea and conceptual model, spatio-temporal data structure and spatio-temporal data retrieval mechanism. This double-base state model with amendment has solved problems of a duplicate retrieval of historical data and retrieval inefficiencies, and it runs with a high speed of data retrieval speed and the other advantages.","","Electronic:978-1-4244-7390-8; POD:978-1-4244-7387-8","10.1109/ESIAT.2010.5568893","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568893","Double-base state with amendments;Land Use;Raster Data;Spatial-temporal Data;component","Databases;Gallium nitride;Real time systems","geographic information systems;information retrieval;land use planning","amendments;double-base state model;ground-state correction model;land-use change;spatio-temporal data retrieval mechanism;spatio-temporal data structure","","0","","4","","","17-18 July 2010","","IEEE","IEEE Conference Publications"
"An intelligent model to construct specialized domain ontologies","A. Mooman; O. Basir; A. Younes","Dept. of Electrical and Computer Engineering, University of Waterloo, Canada","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","5","","696","702","Search engines and information retrieval (IR) systems provide a mechanism for users to access large amounts of information available through the Internet. However, in order to find the desired information, the user has to go through a staggering amount of information retrieved from highly dynamic resources. Experimental results show that the approach proposed for constructing specialized domains improves the precision of information retrieval. Our approach involves enriching the user's query with related linguistic semantic and statistical semantic related concept terms. We employ natural language process (NLP) techniques such as WordNet engine to enrich the user's query with semantic lexical synonymous terms and a probabilistic topic model such as latent dirichet allocation (LDA) to extract highly ranked topic from a query's retrieved information. Furthermore, an intelligent learning algorithm, reinforcement learning (RL) is integrated into the design to assist end users in selecting the concept domains that are most relevant to their needs.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564016","","Ontologies;Variable speed drives","information retrieval;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);probability;statistical analysis","LDA;NLP technique;WordNet engine;domain ontology;information retrieval;intelligent learning model;latent Dirichet allocation;linguistic semantic;natural language process;probabilistic topic model;reinforcement learning;search engine;semantic lexical synonymous term;statistical semantic","","0","","27","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Web Content Extraction based on Webpage Layout Analysis","L. Fu; Y. Meng; Y. Xia; H. Yu","Fujitsu R&D Center CO., Ltd., Beijing, China","2010 Second International Conference on Information Technology and Computer Science","20100826","2010","","","40","43","For web content extraction task, researchers have proposed many different methods, such as wrapper-based method, DOM tree rule-based method, machine learning-based method and so on. To some extent, all these methods ignore the layout information of the webpage, although the layout information such as the spatial and visual cues often plays a very important role in the process of locating the main content of the webpage when browsing. As a consequence, these methods often throw part of the main content away when extracting content from the webpage. In this paper, we present a method which combines webpage layout analysis with DOM tree rule-base method, it can make full use of the advantages of the two methods. It uses the layout information to guide the extraction work with a global view and can gain a better performance than the traditional methods.","","Electronic:978-1-4244-7294-9; POD:978-1-4244-7293-2","10.1109/ITCS.2010.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557336","DOM tree rule-based method;web content extraction;webpage layout analysis","Algorithm design and analysis;Bismuth;Data mining;HTML;Layout;Learning systems;Particle separators","Web design;information retrieval;knowledge based systems;learning (artificial intelligence);trees (mathematics)","DOM tree rule-based method;Web content extraction task;Webpage layout analysis;document object model;layout information;machine learning-based method;wrapper-based method","","7","","16","","","24-25 July 2010","","IEEE","IEEE Conference Publications"
"MediaTable: Interactive Categorization of Multimedia Collections","O. Rooij; J. van Wijk; M. Worring","University of Amsterdam","IEEE Computer Graphics and Applications","20100823","2010","30","5","42","51","Many multimedia collections include only metadata such as date created and file size and remain largely unannotated. So, browsing them is cumbersome. Automatic content-analysis techniques yield metadata in the form of high-level content-based descriptors. However, these techniques' accuracy is insufficient to automate collection categorization. A human is essential to validate and organize automated techniques' results. MediaTable helps users efficiently categorize an image or video collection. A tabular interface gives an overview of multimedia items and associated metadata, and a bucket list lets users quickly categorize materials. MediaTable uses familiar interface techniques for sorting, filtering, selection, and visualization. Evaluations with expert and nonexpert users indicate that MediaTable supports efficient categorization and provides valuable insight into the collection.","0272-1716;02721716","","10.1109/MCG.2010.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473200","computer graphics;graphics and multimedia;image and video search systems;interactive multimedia retrieval;multimedia collection categorization;table-based browsing","Digital multimedia broadcasting;Forensics;Humans;Multimedia communication;Multimedia systems;Search engines;Sorting;Telephony;Videos;YouTube","content management;information retrieval;interactive systems;meta data;multimedia computing;sorting","automatic content-analysis techniques;high-level content-based descriptors;image collection;interactive categorization;mediatable;metadata;multimedia collections;tabular interface;video collection","","9","","3","","20100527","Sept.-Oct. 2010","","IEEE","IEEE Journals & Magazines"
"Experiment on video watermark detection system using degraded original images","T. Yamada; Yoshiyasu Takahashi; Ryu Ebisawa; I. Echizen; H. Yoshiura","1 Hitachi, Ltd., Japan","2010 8th IEEE International Conference on Industrial Informatics","20100816","2010","","","454","459","Watermarks often have to be detected from videos that have experienced such severe image processing as combinations of re-encoding and resizing in real applications. To improve watermark detection performance, this paper proposes a new method consisting of the following four steps: (a) estimate the image processing the watermarked images experienced, (b) apply the estimated image processing to the original images, (c) subtract the degraded original images from the watermarked images, and (d) detect watermarks from the difference images. Under the redistributing threat model, experimental evaluations show that the proposed method yields a detection ratio 34.4-percentage points higher than that yielded by the conventional method M1, which does not use original images.","1935-4576;19354576","Electronic:978-1-4244-7300-7; POD:978-1-4244-7298-7","10.1109/INDIN.2010.5549699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5549699","","Cameras;Data security;Degradation;Image processing;Informatics;Pixel;Signal processing;Surveillance;Video sharing;Watermarking","information retrieval systems;video signal processing;watermarking","degraded original images;image processing;redistributing threat model;video archive;video watermark detection system","","0","","13","","","13-16 July 2010","","IEEE","IEEE Conference Publications"
"A study of on-demand service for spatial data system","Yi Zeng; Baoguo Wu; Guoqing Li","School of Information Technology and Science, Beijing Forestry University, China","2010 The 2nd Conference on Environmental Science and Information Application Technology","20100909","2010","3","","98","101","Data services offered by the traditional spatial data system always can not meet the final customer needs. Scientists often spend a lot of time on data preprocessing according to specific application targets. In this paper we formulate the problem and study on the on-demand service model for spatial data. The objective is to integrate a large number of fundamental data pre-processing tasks into data access procedure, and minimize the time cost. The research based on OGC WCS standards, and the data system can provide high level spatial data products to meet applications requests. We use this on-demand data service model in Spatial Information Grid platform for case study, and conducted close examination of comparison study with traditional methods.","","Electronic:978-1-4244-7390-8; POD:978-1-4244-7387-8","10.1109/ESIAT.2010.5568927","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568927","WCS;data grid;service on-demand;spatial data service","Geospatial analysis;Image coding","data handling;information retrieval;meta data;visual databases","OGC WCS standard;data access;data preprocessing;on-demand data service;spatial data system;spatial information grid","","1","","6","","","17-18 July 2010","","IEEE","IEEE Conference Publications"
"Extracting relational network from the online forums: Methods and applications","Tian Zhu; Bin Wu; Bai Wang","Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, 100876, China","2010 IEEE International Conference on Emergency Management and Management Sciences","20100907","2010","","","424","427","We study the problem of automatically extracting semantic information network and social network from the online forum. We describe an efficient system called INEOF which is capable of processing millions of forum posts in a few hours. We also introduce some applications, including topic detection and opinion leader detection based on social network analysis techniques after building the two type of relational networks. Experiments based on real forum data are given, and the results prove the effectiveness and efficiency of our methodology.","","Electronic:978-1-4244-6065-6; POD:978-1-4244-6064-9","10.1109/ICEMMS.2010.5563410","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563410","online forum;opinion leader;processing;social network;topic detection","Book reviews;Lead","Internet;computer mediated communication;information retrieval;semantic networks;social networking (online)","INEOF;online forums;opinion leader detection;relational network extraction;semantic information network extraction;social network analysis techniques;topic detection","","0","","13","","","8-10 Aug. 2010","","IEEE","IEEE Conference Publications"
"A medical image archive solution in the cloud","C. C. Teng; J. Mitchell; C. Walker; A. Swan; C. Davila; D. Howard; T. Needham","School of Technology, Brigham Young University, Provo, UT, USA","2010 IEEE International Conference on Software Engineering and Service Sciences","20100819","2010","","","431","434","Growing long-term cost of managing an onsite medical imaging archive has been a subject which the health care industry struggles with. Based on the current trend, it is estimated that over 1 billion diagnostic imaging procedures will be performed in the United States during year 2014, generating about 100 Petabytes of data. The high volume of medical images is leading to scalability and maintenance issues with healthcare providers' onsite picture archiving and communication system (PACS) and network. Cloud computing promises lower cost, high scalability, availability and disaster recoverability which can be a natural solution some of the problems we faced for long-term medical image archive. A prototype system was implemented to study such as solution on one of the industry leading cloud computing platform, Microsoft Windows Azure. It includes a Digital Imaging and Communications in Medicine (DICOM) server which handles standard store/query/retrieve requests; a DICOM image indexer that parses the metadata and store them in a SQL Azure database; and a web UI for searching and viewing archived images based on patient and image attributes. The comprehensive tools and functionality of Windows Azure made it an ideal platform to develop and deploy this kind of service oriented applications.","2327-0586;23270586","Electronic:978-1-4244-6055-7; POD:978-1-4244-6054-0","10.1109/ICSESS.2010.5552343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5552343","DICOM;PACS;cloud computing;medical imaging","Cloud computing;Clouds;DICOM;Medical diagnostic imaging;Medical services;Servers","Internet;SQL;biomedical imaging;health care;information retrieval systems;medical computing;query processing;software architecture","Microsoft Windows Azure;SQL Azure database;Web UI;cloud computing;digital imaging and communications in medicine;health care industry;medical imaging archive;picture archiving and communication system;service oriented applications","","19","2","19","","","16-18 July 2010","","IEEE","IEEE Conference Publications"
"Cloud Computing: A Digital Libraries Perspective","P. Teregowda; B. Urgaonkar; C. L. Giles","Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA, USA","2010 IEEE 3rd International Conference on Cloud Computing","20100826","2010","","","115","122","Provisioning and maintenance of infrastructure for Web based digital library search engines such as CiteSeer<sup>x</sup> present several challenges. CiteSeer<sup>x</sup> provides autonomous citation indexing, full text indexing, and extensive document metadata from document scrawled from the web across computer and information sciences and related fields. Infrastructure virtualization and cloud computing are particularly attractive choices for CiteSeer<sup>x</sup>, which is challenged by both growth in the size of the indexed document collection, new features and most prominently usage. In this paper, we discuss constraints and choices faced by information retrieval systems like CiteSeer<sup>x</sup> by exploring in detail aspects of placing CiteSeer<sup>x</sup> into current cloud infrastructure offerings. We also implement an ad-hoc virtualized storage system for experimenting with adoption of cloud infrastructure services. Our results show that a cloud implementation of CiteSeer<sup>x</sup> may be a feasible alternative for its continued operation and growth.","2159-6182;21596182","Electronic:978-0-7695-4130-3; POD:978-1-4244-8207-8","10.1109/CLOUD.2010.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558004","CiteSeer;Cloud Computing;Digital Libraries;Economics;SeerSuite;Virtualization","Cloud computing;Clouds;Crawlers;Engines;Indexes;Maintenance engineering","Internet;citation analysis;digital libraries;indexing;information retrieval;meta data;search engines;virtual storage","CiteSeer;Cloud computing;Web based digital library search engines;ad-hoc virtualized storage system;autonomous citation indexing;cloud infrastructure services;extensive document metadata;full text indexing;information retrieval systems;infrastructure virtualization","","12","","23","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"The extended TAM on keyword searching for internet users","W. Y. Tsao; H. J. Yang","Department of Information Management, National Chin-Yi University of Technology, Taiwan, R. O. C.","2010 2nd International Conference on Signal Processing Systems","20100823","2010","1","","V1-469","V1-473","A model of the precursors of intention to use in online keyword searching is presented and empirically tested with data collection. Analysis of the data 331 participants, utilizing structural equation model (SEM), supported most of the predictions. Language anxiety, perceived ease of use, perceived usefulness, perceived playfulness and attitude have impact on intention to use. Future researches and implications are applied.","","Electronic:978-1-4244-6893-5; POD:978-1-4244-6892-8","10.1109/ICSPS.2010.5555537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555537","Keyword Searching;Language Anxiety;Perceived Playfulness;TAM","Computers;Internet;Keyword search;Mathematical model;Predictive models;Signal processing;World Wide Web","Internet;behavioural sciences computing;data analysis;information retrieval;search problems;user interfaces","Internet;TAM;data analysis;keyword searching;language anxiety;perceived attitude;perceived playfulness;perceived usefulness;structural equation model;technology acceptance model","","0","","36","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"Research on mixed model-based Chinese relation extraction","Ruqi Lin; Jinxiu Chen; Xiaofang Yang; Honglei Xu","Cognitive Science Department, Xiamen University, Fujian Key Laboratory of the Brain-like Intelligent Systems (Xiamen University), China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","1","","687","691","Relation Extraction is an important research field in Information Extraction. In this paper, we present a novel mixed model to extract relation between named entities in Chinese, which combines the merits of both feature based method and tree kernel based method. Feature based method captures the language information of the text, while, the tree kernel based method shows the structured information of the text. We evaluate the proposed model on the ACE (Automatic Content Extraction) 2005 corpus. The experiments show that our model can identify the majority of the non-relational instances and also has a good precision and recall rate on the identification of various relation types.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564530","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564530","Feature;Relation Extraction;Tree Kernel","Artificial neural networks;Business;Data mining;Employment;Feature extraction;Kernel;Logic gates","information retrieval;natural language processing","automatic content extraction;feature based method;information extraction;mixed model-based Chinese relation extraction;tree kernel based method","","1","","15","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A tank fish recognition and tracking system using computer vision techniques","Jia-Hong Lee; Mei-Yi Wu; Zhi-Cheng Guo","Dept. of Information Management, National Kaohsiung First University of Science and Technology, Taiwan, R.O.C. China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","4","","528","532","Aquarium usually provides the visitors with pictures and some description of the fishes in the exhibition tank. In this paper, an intelligent fish recognition system using computer vision is proposed to help aquarium to educate people about the fishes in the tank. The designed system provides a convenient and friendly interface to help the users to retrieve the related fish information they are interested. The system includes three sub-systems: (1) fish object detection system (2) fish object tracking system (3) fish object recognition system. Two types of fish indexing system (offline and real time) have been designed and implemented.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563625","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563625","Tank fish recognition;computer vision;object detection;object tracking","Artificial neural networks;Databases;IEC;ISO;Marine animals","aquaculture;computer vision;indexing;information retrieval;object detection;object recognition;tracking;user interfaces","aquarium;computer vision;indexing system;information retrieval;object detection;object recognition;object tracking;tank fish recognition;tracking system;user interface","","1","","16","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Algorithm of XML document information hiding based on equal element","Yang Jie","Department of Communication Engineering, Nanjing Institute of Technology, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","3","","250","253","Information hiding can hide secret messages inside of image, video, audio, document, and other digital objects. The messages are invisible to general observers. Information hiding has become a new research hotspot of information security and copyright protection of digital multimedia recently. XML document is used as cover-media in XML document information hiding algorithms. A new algorithm of XML document information hiding based on equal element is presented, which overcomes the shortcoming of imperceptibility, robustness and hiding capacity of traditional XML document information hiding algorithms. According to the embedded rule, firstly, the algorithm turns secret message to a decimal integer, and then created equal element through sub-elements' permutation and combination. According to mapping function between integer and equal element, the integer is embedded into the XML document by replacing the element with its equal element. The experimental results show that the algorithm does not change the size of XML document, and has good imperceptibility and robustness. The embedding capacity of the algorithm gets better increase than traditional XML document information hiding algorithms. So the algorithm could be used to covert communication and protect the content of XML documents.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563526","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563526","XML;equal element;information hiding;subelement","Algorithm design and analysis;Mobile communication;XML","XML;copy protection;copyright;data encapsulation;information retrieval;message authentication;multimedia computing","XML;copyright protection;digital multimedia;document information hiding;equal element algorithm;mapping function;message hiding;sub-element permutation and combination","","1","","10","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A genetic fuzzy expert system for stock price forecasting","E. Hadavandi; H. Shavandi; A. Ghanbari","Department of Industrial Engineering, Sharif University of Technology, Tehran, Iran, P.O. Box: 11365-9466","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","1","","41","44","Forecasting stock price time series is very important and challenging in the real world because they are affected by many highly interrelated economic, social, political and even psychological factors, and these factors interact with each other in a very complicated manner. This article presents an approach based on Genetic Fuzzy Systems (GFS) for constructing a stock price forecasting expert system. We use a GFS model with the ability of rule base extraction and data base tuning for next day stock price prediction to extract useful patterns of information with a descriptive rule induction approach. We evaluate capability of the proposed approach by applying it on stock price forecasting case study of International Business Machines Corporation (IBM), and compare the outcomes with previous stock price forecasting methods using mean absolute percentage error (MAPE). Results show that the proposed approach is able to cope with the fluctuation of stock price values and it also yields good prediction accuracy in short term stock price forecasting.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569630","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569630","Expert systems;Genetic Fuzzy systems;Stock Price Forecasting","Expert systems;Forecasting;Fuzzy systems;Genetics;Hidden Markov models;Predictive models;Stock markets","data mining;expert systems;forecasting theory;fuzzy set theory;genetic algorithms;information retrieval;pricing;stock markets","IBM;International Business Machines Corporation;database tuning;descriptive rule induction approach;genetic fuzzy expert system;information extraction;mean absolute percentage error;rule base extraction;stock price forecasting;time series","","0","","15","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Visualization of All the IP Addresses That Host a Publicly Accessible Web Server","D. Benoit; A. Trudel","Jodrey Sch. of Comput. Sci., Acadia Univ., Wolfville, NS, Canada","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","5","Every valid IP address was checked for the presence of a publicly accessible web server on port 80. To better understand the distribution of web servers across the available address space, we map the results to a 2-dimentional Cartesian plane. The resulting graph is presented and discussed.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566569","","Companies;IP networks;Pixel;Resource management;Web server","IP networks;Web services;data visualisation;information retrieval","2-dimensional cartesian plane;IP addresses;data visualisation;publicly accessible Web server","","0","","11","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Modulization approach & application of OSGi -based RFID middleware persistence Layer","F. Liu; P. Yang; W. Shen; Y. Lin; Y. Zhang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2010 International Conference on Anti-Counterfeiting, Security and Identification","20100819","2010","","","293","297","The enterprise-class RFID Middleware demands the flexibility to switch its data access strategies on the persistence layer; however, the traditional frameworks of persistence layer such as Hibernate, iBatis, etc. are seldom of dynamic switching characteristic which makes them incapable to cater for the enterprise-class RFID Middleware on its persistence layer. This paper begins with the analysis of the traditional data access strategies of persistence layer. With the foundation of in-depth studying OSGi, Spring and current mainstream frameworks of persistence layer, it points out a feasible method to implement dynamic switching by CBSD. Hence, the SpringDM-based modularization of Hibernate, an open source persistence layer framework, is firstly proposed. With further insight and development, a dynamic model based on SpringDM is put forward which achieves the flexibility to switch the data access strategies effortlessly at will. It could also be regarded as the general form of deploying the J2EE persistence frameworks to OSGi to provide support for the OSGi-ized multi-frameworks and realize the applications of RFID Middleware's persistence layer.","2163-5048;21635048","Electronic:978-1-4244-6734-1; POD:978-1-4244-6731-0","10.1109/ICASID.2010.5551343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551343","OSGI;Persistence Layer Framework;RFID Middleware;SpringDM","Data models;Databases;Middleware;Production facilities;Radiofrequency identification;Springs;Switches","information retrieval;middleware;radiofrequency identification","OSGi application;RFID middleware persistence layer;data access strategies;dynamic switching characteristic;modulization approach","","0","","9","","","18-20 July 2010","","IEEE","IEEE Conference Publications"
"Implementation of BIM/RFID in computer-aided design-manufacturing-installation process","Haiyan Xie; Wei Shi; R. R. A. Issa","Department of Construction Management, College of Engineering and Information Technology, University of Arkansas at Little Rock, USA","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","2","","107","111","In this paper, the authors discussed in detail about the framework of integrating Radio Frequency Identification (RFID) with Building Information Modeling (BIM) technologies. The proposed framework can be used in the computer-aided design, manufacturing, engineering, and installation processes. In specific, this paper explained how to use RFID technology for structural steel components, such as a steel beam or column. The paper discussed the framework of the decision support system to transmit data read from RFID, retrieve the requested information, integrate the information in analysis process, and update the BIM project model when a decision is reached. The suggested result would have great potential of saving installation time, decrease cost, improve safety record, or achieve better quality in the end of the construction process.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563653","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563653","building information modeling;computer-aided design and manufacturing;radio frequency identification","Analytical models;Biological system modeling;Computational modeling;Databases;Manufacturing;Steel;Synchronization","CAD/CAM;computer aided engineering;construction;decision support systems;information retrieval;radiofrequency identification;structural engineering computing","BIM project model;RFID;building information modeling;computer-aided design-manufacturing-installation process;computer-aided engineering;construction process;decision support system;information retrieval;integrating radio frequency identification;structural steel component","","0","","4","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A supervised machine learning approach of extracting coexpression relationship among genes from literature","R. Tiwari; C. Zhang; T. Solorio","Department of Computer and Information Sciences, The University of Alabama at Birmingham, USA","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","98","103","It is vital to develop automatic information extraction systems to help researchers cope up with the vast amount of data available on the Internet. In this paper, we describe a framework to extract precise information about coexpression relationship among genes, from published literature using a supervised machine learning approach. We use a graphical model, Dynamic Conditional Random Fields (DCRFs), for training our classifier. Our approach is based on semantic analysis of text to classify the predicates describing coexpression relationship rather than detecting the presence of keywords. We compared our results of sentence classification with the baseline technique of word matching and a Naïve Bayes classification algorithm. Our framework outperformed the baseline by almost 45%, with DCRFs showing superior performance to Naïve Bayes.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558956","Dynamic Conditional Random Fields;Gene coexpression;Machine learning;Relationship extraction","Classification algorithms;Data mining;Feature extraction;Hidden Markov models;Machine learning;Testing;Training","Bayes methods;information retrieval;knowledge acquisition;learning (artificial intelligence);medical administrative data processing;pattern classification;random functions;text analysis","Naive Bayes classification;coexpression relationship extraction;dynamic conditional random field;gene information;published literature;supervised machine learning;text analysis;word matching","","0","2","13","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"Logical analysis of information in tabular form","H. Vladimir; C. Svetlana; L. Eugenia","Computer Engineering Faculty, Kharkov National University of Radioelectronics, Lenin Ave. 14, Kharkov, Ukraine, 61166","2010 IEEE Region 8 International Conference on Computational Technologies in Electrical and Electronics Engineering (SIBIRCON)","20100823","2010","","","72","79","This article describes algebra for logical analyzing of vector and tabular forms of information representation to solve the problems of information retrieval, diagnosis, pattern recognition and decision-making in the vector discrete Boolean space. The high-speed models and methods for concurrent vector logical analysis of information, which completely exclude the use of arithmetic operations, including the calculation of the solution quality criterion that uses logic operations only, are proposed.","","Electronic:978-1-4244-7626-8; POD:978-1-4244-7625-1","10.1109/SIBIRCON.2010.5555313","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555313","","Algebra;Analytical models;Arrays;Computers;Kernel;Region 8","Boolean algebra;decision making;information retrieval;pattern recognition","algebra;concurrent vector logical analysis;decision making;high-speed models;information logical analysis;information representation;information retrieval;pattern recognition;quality criterion;tabular forms;vector discrete Boolean space;vector forms","","0","","16","","","11-15 July 2010","","IEEE","IEEE Conference Publications"
"Implementation of interactive database system for STEP-geometric data from EXPRESS entities","Chinta Someswara Rao; Adavi Balakrishna; G. V. Padma Raju; K. Suresh Babu; D. Nageswara Rao","Computer Science and Engineering, SRKR Engineering College, Bhimavaram, Andhra Pradesh, INDIA","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","3","","285","289","Today information systems have become the key factor of current computer based engineering applications. So database are designed to support data storage, processing, and retrieval activities related to data management, and they are the key to implementing engineering information models. However, the current mainstream databases are mainly used for business applications, some new engineering requirements challenge today's database technologies and promote their evolvement. The main focus of this paper is to determining the requirements of a database for STEP-Geometry entities that supports integrity validation of versioned design artifacts through effective management of evolving constraints. In this paper develop a tool for separate and store the geometric data from STEP file using EXPRESS entities. Finally this tool operates around a version model that uses a well-defined configuration management strategy to manage and storage of geometric data.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563598","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563598","Database;EXPRESS entity;Geometric Data;STEP","Data models;Wire","computer aided engineering;configuration management;data analysis;database management systems;engineering information systems;information retrieval;interactive systems;storage management","EXPRESS entity;STEP-geometric data;STEP-geometry entity;business applications;computer based engineering applications;data management;data processing;data retrieval activity;data storage;database technology;engineering information models;information systems;interactive database system;mainstream databases;well-defined configuration management strategy","","0","","16","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Google's powermeter IET conference, 2 March 2010","J. Redmer","Google Inc, USA","IET Seminar on Smart Metering 2010: Delivering a Smart UK","20100826","2010","","","1","15","Presents a collection of slides covering the following topics: Google powermeter; home energy monitoring; realtime electricity usage information and home energy management.","","Electronic:978-1-84919-253-8","10.1049/ic.2010.0054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558658","","","information networks;information retrieval;power meters;power system analysis computing","Google powermeter;home energy management;home energy monitoring;realtime electricity usage information","","0","","","","","2-2 March 2010","","IET","IET Conference Publications"
"The research of information extraction based on knowledge engineering","W. l. Gao; L. Zhu","The Chinese Department of Hunan International Economics University, Changsha, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","4","","1657","1661","The system of arms information extraction based on the ontology, consists of two parts: knowledge base, processing program. It realizes the arms category determination based on text categorization, and realizes the arms object determination based on named entity recognition. It realizes the information extraction according to information extraction rules based on syntax and semantic constraint. It realizes the information integration in semantic level to some extent based on the ontology.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569377","Information Extraction;Information Integration;Knowledge Engineering;Ontology","Classification algorithms;Data mining;Databases;Dictionaries;Ontologies;Semantics","Internet;constraint handling;information retrieval;ontologies (artificial intelligence)","arms category determination;arms information extraction;arms object determination;information integration;knowledge engineering;named entity recognition;semantic constraint;syntax constraint;text categorization","","0","","9","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Application of Genetic Algorithms to the Identification of Website Link Structure","M. R. M. Torres; B. Palacios; S. L. Toral; F. Barrero","Dept. of Bus. Adm. & Marketing, Univ. of Seville, Seville, Spain","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","88","95","This paper explores website link structure considering websites as interconnected graphs and analyzing their features as a social network. Factor Analysis provides the statistical methodology to adequately extract the main website profiles in terms of their internal structure. However, due to the large number of indicators, a genetic search of their optimum number is proposed, and applied to a case study based on 80 Spanish University websites. Results provide coherent and relevant website profiles, and highlight the possibilities of Genetic Algorithms as a tool for discovering new knowledge related to website link structures.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5562786","Factor Analysis;Genetic Algorithms;Link Analysis;Website structure","Biological cells;Correlation;Feature extraction;Genetics;Loading;Social network services;Web sites","directed graphs;genetic algorithms;information retrieval;search problems;social networking (online);statistical analysis","Website;Website link structure;factor analysis;genetic algorithm;genetic search;interconnected graph;social network","","0","","22","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Extracting information from continuous naturalistic driving data: sample applications","M. A. Perez; Z. R. Doerzaph; C. K. Gaylord; J. M. Hankey","Scientist with the Virginia Tech Transportation Institute, 3500 Transportation Research Plaza, Blacksburg, 24061 USA","2010 IEEE Intelligent Vehicles Symposium","20100816","2010","","","1201","1208","The technology and tools used for naturalistic driving data collection have evolved greatly in recent years. Data collection efforts that required a trunk full of equipment and days of installation can now be achieved with data acquisition systems that are about the size of a deck of cards and can be installed in minutes. This evolution has made possible large-scale driving data collection efforts, such as the upcoming Second Safety Highway Research Program Naturalistic Driving Study (SHRP2 NDS). Data from naturalistic studies allow for an unparalleled breadth and depth of driver behavior analysis that goes beyond the quantification and description of driver distraction into a deeper understanding of how drivers interact with their vehicles. This paper describes key aspects of how such studies are designed and executed, and provides some examples of how common types of data are extracted from these naturalistic driving datasets. Specifically, the use of RADAR and speed data are discussed in detail. In addition, a sample architecture for the storage of and access to these vast quantities of driving data and video is provided. Naturalistic driving data have allowed for a transformation in the understanding of driver behavior and, as datasets are expanded to include diverse populations, they will help researchers and automotive engineers in developing novel ways to mitigate and prevent vehicular crashes and their consequences.","1931-0587;19310587","Electronic:978-1-4244-7868-2; POD:978-1-4244-7866-8","10.1109/IVS.2010.5547964","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5547964","","Automotive engineering;Data acquisition;Data engineering;Data mining;Large-scale systems;Radar;Road safety;Road transportation;Vehicle crash testing;Vehicle driving","behavioural sciences computing;driver information systems;information retrieval;road safety;road vehicle radar","RADAR;continuous naturalistic driving data;driver behavior analysis;information extraction;speed data;vehicular crashes","","1","","6","","","21-24 June 2010","","IEEE","IEEE Conference Publications"
"Online academic databases use in Croatian higher education","D. Dukić","Josip Juraj Strossmayer University of Osijek, Department of Physics, Trg Ljudevita Gaja 6, 31000, Croatia","Proceedings of the ITI 2010, 32nd International Conference on Information Technology Interfaces","20100812","2010","","","349","354","The development of information and communication technologies has facilitated access to a range of scientific and professional content for academic community. Resulting from this process, online academic databases over the last decade have become an indispensable source of recent and relevant information in all areas of human activity. The paper presents the results of the research that endeavored to establish how far Croatian university teachers rely on such databases, and the way they perceive certain aspects of their usage. The research was conducted on a sample consisting of respondents employed at the Josip Juraj Strossmayer University in Osijek. The analysis of the data collected in the survey indicates that the respondents highly value online academic database usefulness; however, there are certain constraints in their usage.","1330-1012;13301012","Electronic:978-1-4244-5733-5; POD:978-1-4244-5732-8","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546440","Croatian higher education;Online academic databases;users' perception","Communities;Computers;Databases;Education;Investments;Libraries;Medical services","database management systems;educational institutions;further education;information retrieval systems","Croatian higher education;Croatian university teachers;Osijek Josip Juraj Strossmayer University;information and communication technologies;online academic databases","","0","","10","","","21-24 June 2010","","IEEE","IEEE Conference Publications"
"Keep It Simple with Time: A Reexamination of Probabilistic Topic Detection Models","Q. He; K. Chang; E. P. Lim; A. Banerjee","Pennsylvania State University, State College","IEEE Transactions on Pattern Analysis and Machine Intelligence","20100819","2010","32","10","1795","1808","Topic detection (TD) is a fundamental research issue in the Topic Detection and Tracking (TDT) community with practical implications; TD helps analysts to separate the wheat from the chaff among the thousands of incoming news streams. In this paper, we propose a simple and effective topic detection model called the temporal Discriminative Probabilistic Model (DPM), which is shown to be theoretically equivalent to the classic vector space model with feature selection and temporally discriminative weights. We compare DPM to its various probabilistic cousins, ranging from mixture models like von-Mises Fisher (vMF) to mixed membership models like Latent Dirichlet Allocation (LDA). Benchmark results on the TDT3 data set show that sophisticated models, such as vMF and LDA, do not necessarily lead to better results; in the case of LDA, notably worst performance was obtained under variational inference, which is likely due to the significantly large number of LDA model parameters involved for document-level topic detection. On the contrary, using a relatively simple time-aware probabilistic model such as DPM suffices for both offline and online topic detection tasks, making DPM a theoretically elegant and effective model for practical topic detection.","0162-8828;01628828","","10.1109/TPAMI.2009.203","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374412","DPM;TFIDF.;Topic detection;bursty feature;online;probabilistic model;time-aware","Character generation;Data mining;Event detection;Finance;Frequency;Helium;Hurricanes;Linear discriminant analysis;Mathematical model;Nominations and elections","document handling;information retrieval;probability","TDT3 data set;feature selection;latent dirichlet allocation;news streams;probabilistic topic detection models;temporal discriminative probabilistic model;topic detection and tracking;vMF","","29","","44","","20100108","Oct. 2010","","IEEE","IEEE Journals & Magazines"
"Summarizing Similar Questions for Chinese Community Question Answering Portals","Y. Tang; F. Li; M. Huang; X. Zhu","Dept. of Comput. Sci. & Tech., Tsinghua Univ., Beijing, China","2010 Second International Conference on Information Technology and Computer Science","20100826","2010","","","36","39","As online community question answering (cQA) portals like Yahoo! Answers and Baidu Zhidao have attracted over hundreds of millions of questions, how to utilize these questions and accordant answers becomes increasingly important for cQA websites. Prior approaches focus on using information retrieval techniques to provide a ranked list of questions based on their similarities to the query. Due to the high variance of question quality and answer quality, users have to spend lots of time on finding the truly best answers from retrieved results. In this paper, we develop an answer retrieval and summarization system which directly provides an accurate and comprehensive answer summary instead of a list of similar questions to user's query. To fully explore the information of relations between queries and questions, between questions and answers, and between answers and sentences, we propose a new probabilistic scoring model to distinguish high-quality answers from low-quality answers. By fully exploiting these relations, we summarize answers using a maximum coverage model. Experiment results on the data extracted from Chinese cQA websites demonstrate the efficacy of our proposed method.","","Electronic:978-1-4244-7294-9; POD:978-1-4244-7293-2","10.1109/ITCS.2010.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557335","Answer Summarization;Sentence Scoring;cQA","Brain modeling;Computational modeling;Conferences;Internet;Laboratories;Probabilistic logic;Redundancy","Web sites;information retrieval systems;portals;query processing;statistical analysis","Chinese community;answer quality;answer retrieval system;answer summarization system;cQA Web sites;maximum coverage model;online community question answering portal;probabilistic scoring model;question quality;user query","","0","","11","","","24-25 July 2010","","IEEE","IEEE Conference Publications"
"Providing relevant health information to patient-centered healthcare","J. Puustjärvi; L. Puustjärvi","Department of Computer Science and Engineering, Helsinki University of Technology, Finland","The 12th IEEE International Conference on e-Health Networking, Applications and Services","20100823","2010","","","215","220","Patient-centric healthcare is an emerging healthcare model that optimizes the healthcare system to focus on patient experience and outcomes for better health and well-being. It requires that patients as well as physicians should have the ability to obtain and understand health information, and make appropriate health decisions. A problem is how such health information should be gathered from a variety of heterogeneous data sources, and how patient and physicians should access such information. Our argument is that the gathered information should not be presented as a collection of XML-documents but rather the information should be stored in an ontology based data store (knowledge base), which provides sophisticated features for accessing health information. How this kind of solution can be implemented by exploiting ontology languages RDF and OWL is the topic of this paper.","","Electronic:978-1-4244-6376-3; POD:978-1-4244-6374-9","10.1109/HEALTH.2010.5556569","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556569","HL7 RIM;information based medicine;information therapy;interoperability;ontologies;personal health records","Hospitals;OWL;Ontologies;Security;Surges;XML","health care;information retrieval;knowledge representation languages;medical information systems;ontologies (artificial intelligence)","OWL;RDF;XML documents;health information;healthcare system;information access;ontology languages;patient experience;patient-centered healthcare","","1","","27","","","1-3 July 2010","","IEEE","IEEE Conference Publications"
"SMS-based final exam retrieval system on mobile phones","R. Ahmad; A. Sarlan; K. A. A. Maulod; E. M. Mazlan; R. Kasbon","Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, Bandar Seri Iskandar, 31750 Tronoh, Perak, Malaysia","2010 International Symposium on Information Technology","20100902","2010","1","","1","5","Due to the wide usage of mobile phones, many software developers have make use of the device to be the platform for their applications. This move is especially crucial when the applications are to be made available anytime, anywhere. In this paper the development of a mobile application for administering the final examination exercise of a Malaysian private university using mobile phones is presented. Problems such as change of venue or time of the exams at the last minutes that cause confusion to both students and invigilators warrant the development of Final Exam Timetable Information Retrieval System (FETIDS) that can be accessible anytime and anywhere. The results from user evaluations after the completion of FETIDS show that the system is acceptable by users. Hence, the framework and development process of the application can be adapted when developing other similar type of mobile applications.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561330","mobile application;mobile device;retrieval system;sms-based system","Conferences;Databases;Mobile communication;Mobile handsets;Servers;Wireless application protocol;XML","educational administrative data processing;educational institutions;information retrieval;mobile computing;mobile handsets","FETIDS;Malaysian private university;SMS-based final exam retrieval system;final exam timetable information retrieval system;mobile phones;software developers","","1","","14","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"A comparative study of topic models for topic clustering of Chinese web news","Yonghui Wu; Yuxin Ding; X. Wang; Jun Xu","Harbin Institute of Technology, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","5","","236","240","Topic model is an increasing useful tool to analyze the semantic level meanings and capture the topical features. However, there is few research about the comparative study of the topic models. In this paper, we describe our comparative study of three topic models in the extrinsic application of topic clustering. The topic model distance is defined on the converged parameters of topic models, which is used in the topic clustering. Then, the topic models are compared using the clustering result of the corresponding topic distance matrix. A series of comparative experiments are carried on a corpus containing 5033 web news from 30 topics using the cosine distance as the base-line. Web page collections with different number of topics and documents are used in experiments. The experiment results show that topic clustering using topic distance achieves a better precision and recall in the data set containing related topics. The topic clustering using topic distance benefits from the topic features captured by topic models. The complex topic model does provide further help than the simple topic model in topic clustering.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564723","clustering;comparative study;distance measure;topic model","Artificial neural networks","Internet;information retrieval;pattern clustering;search engines","Chinese Web news;Web page collections;cosine distance;data set;semantic level meanings;topic clustering;topic distance matrix;topic features;topic models","","1","","14","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Extractive Speech Summarization Using Shallow Rhetorical Structure Modeling","J. J. Zhang; R. H. Y. Chan; P. Fung","Dept. of Electron. & Comput. Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China","IEEE Transactions on Audio, Speech, and Language Processing","20100816","2010","18","6","1147","1157","We propose an extractive summarization approach with a novel shallow rhetorical structure learning framework for speech summarization. One of the most under-utilized features in extractive summarization is hierarchical structure information-semantically cohesive units that are hidden in spoken documents. We first present empirical evidence that rhetorical structure is the underlying semantic information, which is rendered in linguistic and acoustic/prosodic forms in lecture speech. A segmental summarization method, where the document is partitioned into rhetorical units by K-means clustering, is first proposed to test this hypothesis. We show that this system produces summaries at 67.36% ROUGE-L F-measure, a 4.29% absolute increase in performance compared with that of the baseline system. We then propose Rhetorical-State Hidden Markov Models (RSHMMs) to automatically decode the underlying hierarchical rhetorical structure in speech. Tenfold cross validation experiments are carried out on conference speeches. We show that system based on RSHMMs gives a 71.31% ROUGE-L F-measure, a 8.24% absolute increase in lecture speech summarization performance compared with the baseline system without using RSHMM. Our method equally outperforms the baseline with a conventional discourse feature. We also present a thorough investigation of the relative contribution of different features and show that, for lecture speech, speaker-normalized acoustic features give the most contribution at 68.5% ROUGE-L F-measure, compared to 62.9% ROUGE-L F-measure for linguistic features, and 59.2% ROUGE-L F-measure for un-normalized acoustic features. This shows that the individual speaking style of each speaker is highly relevant to the summarization.","1558-7916;15587916","","10.1109/TASL.2009.2030951","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5223698","Extractive speech summarization;lecture speech;rhetorical information","","document handling;hidden Markov models;information retrieval;pattern clustering;speech processing","K-means clustering;ROUGE-L F-measure;acoustic forms;extractive speech summarization;hierarchical structure information;lecture speech summarization;prosodic forms;rhetorical-state hidden Markov models;segmental summarization method;shallow rhetorical structure learning framework;speaker-normalized acoustic features;spoken document summarization","","9","","34","","20090825","Aug. 2010","","IEEE","IEEE Journals & Magazines"
"Sentence based semantic similarity measure for blog-posts","M. Aziz; M. Rafi","Computer Science Department, National University of Computer & Emerging Sciences, Karachi Campus, Pakistan","6th International Conference on Digital Content, Multimedia Technology and its Applications","20100909","2010","","","69","74","Blogs-Online digital diary like application on web 2.0 has opened new and easy way to voice opinion, thoughts, and like-dislike of every Internet user to the World. Blogosphere has no doubt the largest user-generated content repository full of knowledge. The potential of this knowledge is still to be explored. Knowledge discovery from this new genre is quite difficult and challenging as it is totally different from other popular genre of web-applications like World Wide Web (WWW). Blog-posts unlike web documents are small in size, thus lack in context and contain relaxed grammatical structures. Hence, standard text similarity measure fails to provide good results. In this paper, specialized requirements for comparing a pair of blog-posts is thoroughly investigated. Based on this we proposed a novel algorithm for sentence oriented semantic similarity measure of a pair of blog-posts. We applied this algorithm on a subset of political blogosphere of Pakistan, to cluster the blogs on different issues of political realm and to identify the influential bloggers.","","Electronic:978-8-9886-7827-5; POD:978-1-4244-7607-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5568598","algorithm;semantic similarity;text mining","Atmospheric measurements;Dictionaries;Particle measurements;World Wide Web","Internet;Web sites;data mining;information retrieval;text analysis","Internet user;Web 2.0;World Wide Web;blog post;knowledge discovery;online digital diary;political blogosphere;sentence based semantic similarity measurement;user generated content repository","","1","","13","","","16-18 Aug. 2010","","IEEE","IEEE Conference Publications"
"A fast convergent ant colony algorithm for optimization automated warehouse problem","Gang Wang; Meijuan Li; Xuebo Chen","Department of Computer, Anshan Normal University, Liaoning, China","2010 8th World Congress on Intelligent Control and Automation","20100823","2010","","","867","872","Automated warehouse is one kind of modern warehouse with automatic storage/retrieval system(AS/RS) and a product of highly integration of modern logistics technology, warehousing technology, automation technology and computer technology. The working characteristics of each storage/retrieval machine serving multi-aisles are analyzed in automated storage and retrieval system. A mathematic model on path planning problem is constructed, a kind of new fast and improved ant colony algorithm for the order picking problem is presented. Three improvements are adopted: awaiting nodes set, selection operator and dynamic change on algorithm parameters. The performance of ant colony algorithm is greatly improved. Computer simulations show that the improved algorithm has the ability of better overall search and quickly astringency, satisfying the demands of medium or large scale work. The approach is an effective solution to order picking problem.","","DVD:978-1-4244-6711-2; Electronic:978-1-4244-6712-9; POD:978-1-4244-6710-5","10.1109/WCICA.2010.5554125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5554125","NP-hard problem;automated storage and retrieval system;improved ant colony algorithm;order picking problem","Computer simulation;Computers;Heuristic algorithms;NP-hard problem;Storage automation;Yttrium","data warehouses;information retrieval systems;optimisation;path planning","automatic storage-retrieval system;awaiting nodes set;fast convergent ant colony algorithm;modern logistics technology;optimization automated warehouse problem;order picking problem;path planning problem;selection operator;storage-retrieval machine serving multi-aisles","","0","","10","","","7-9 July 2010","","IEEE","IEEE Conference Publications"
"Building a knowledge repository of educational resources using dynamic harvesting","M. Prashant; D. Ankit; S. M. Kumar; A. Kumar; M. Sasikumar","C-DAC Mumbai, India","2010 International Conference on Technology for Education","20100816","2010","","","157","163","World Wide Web is hosting huge information regarding lots of areas and education is not an exception. Given the huge amount of data, searching for any educational resource manually is very difficult. To overcome this, an intelligent repository of educational resources that helps to decide among the available resources is needed. This paper discusses an attempt to build such repository. This will help users to decide among the available solutions for their needs by providing a comparative analysis among the solutions. The user will also be provided with user experience of the solutions. As the content over the web changes regularly and also new resources get added to the web, the repository will be updated dynamically. And all these tasks are done automatically as far as possible. This work uses crawling, classification, and information extraction techniques for the task of identifying the softwares/tools for education from the web. Our implementation focuses on the free open source softwares (FOSS) for education domain. The final framework of this system would be generic so that it can be extended to any other domain.","","Electronic:978-1-4244-7361-8; POD:978-1-4244-7362-5","10.1109/T4E.2010.5550041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5550041","document classification;document filtering;information extraction;knowledge repository","Blogs;Computer science education;Content management;Data mining;Educational technology;Information filtering;Information filters;Open source software;Software tools;Web sites","Internet;classification;computer aided instruction;educational aids;information resources;information retrieval;public domain software","FOSS;World Wide Web;classification;crawling;dynamic harvesting;educational resources;free open source softwares;information extraction techniques;intelligent repository;knowledge repository","","0","","15","","","1-3 July 2010","","IEEE","IEEE Conference Publications"
"Automatic extraction and representation of geographic entities in eGovernment","M. Rodrigues; G. P. Dias; A. Teixeira","Polytech. Sch. Techn. & Manag. /IEETA, University of Aveiro, Aveiro, Portugal","5th Iberian Conference on Information Systems and Technologies","20100823","2010","","","1","4","In this paper we present a system that automatically extracts and geocodes named entities from unstructured, natural language textual documents. The system uses the Geo-Net-PT ontology and Google maps as auxiliary data sources. This type of system is particularly useful to automate the geocoding of existing information in e-government applications, which usually requires human intervention. Within the paper we introduce the relevant human language technologies, describe the system that was developed, present and discuss the preliminary results and draw the relevant conclusions and future work.","2166-0727;21660727","Electronic:978-989-96247-3-3; POD:978-1-4244-7227-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5556657","e-government;geographic information systems;human language technology","Cities and towns;Databases;Electronic government;Google;Humans;Ontologies;Web server","cartography;geographic information systems;government data processing;information retrieval;natural language processing;ontologies (artificial intelligence);text analysis","Geo-Net-PT ontology;Google map;auxiliary data sources;egovernment;geocoding;geographic entities extraction;geographic entities representation;human language technology;natural language textual document","","1","","18","","","16-19 June 2010","","IEEE","IEEE Conference Publications"
"Application of clickstream analysis as Web page importance metric in parallel crawlers","A. Selamat; F. Ahmadi-Abkenari","Intelligent Software Engineering Laboratory, Faculty of Computer Science & Information Systems, Universiti Teknologi Malaysia, 81310 UTM Skudai, Johor, Malaysia","2010 International Symposium on Information Technology","20100902","2010","1","","1","6","Employing a parallel crawler as a multi processes crawler causes different issues of concern in comparison to applying a single-process crawler. These issues impact on achieving the results with higher or even the same quality from a parallel crawler in comparison to a centralized one. Existed parallel crawlers' architectures employ link dependant metrics - such as Backlink count or PageRank - for URL importance determination in order to prioritize the queue of each process. Then the specific number of the most important pages is sent to the index section of the crawler for further processing on their content. Application of metrics with link dependent nature causes considerable overhead on the overall parallel crawler resulted from the link information exchange among different processes. In this paper we propose the application of clickstream analysis as a link independent Web page importance metric in a parallel crawler. Our approach includes proposing an algorithm for a balanced performance of different processes within a parallel crawler which results in the discovery of higher quality pages by the overall parallel crawler with less overhead in comparison to a centralized crawler which employs link dependant metrics of importance.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561354","Clickstream analysis;Parallel crawlers;Web data management;Web page Importance metrics","Crawlers;Equations;Fires;Mathematical model;Measurement;Web pages","Web sites;information filters;information retrieval","Backlink count;PageRank;URL importance determination;Web page importance metric;clickstream analysis;link dependant metrics;multi processes crawler;parallel crawlers","","5","","10","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Development of a web-based telemedicien system for remote ENT diagnoses","Chung-Hsien Kuo; Jung-Jie Liu","Department of Electrical Engineering, National Taiwan University of Science and Technology, 106 Taipei, China","2010 International Conference on System Science and Engineering","20100819","2010","","","565","570","This paper presents an asynchronous web-based ear-nose-throat (ENT) diagnosis system to carry out location independent diagnoses. The proposed diagnosis model provides a medical service process for patients who may ask for diagnosis at a distance location instead of going to hospitals directly. Based on the web-based ENT diagnosis system, patients are able to submit their physiological signals and multimedia data to the virtual hospital server through the internet. Meanwhile, ENT physicians may process the diagnoses through the internet via accessing the data and files in the virtual hospital server. Especially, the quality of multimedia data transmissions can be guaranteed by using an asynchronous communication mechanism. Tentative diagnostic reports are used to suggest the requested patients for further face-to-face diagnoses at appropriate clinics, local hospitals, general hospitals, or medical centers. Therefore, the nation's medical resources can be well arranged. As a consequence, a system prototype with self-modified hardware devices and software components had been implemented in our laboratory. Finally, several experimental results are demonstrated to verify our approaches.","2325-0909;23250909","Electronic:978-1-4244-6474-6; POD:978-1-4244-6472-2","10.1109/ICSSE.2010.5551706","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551706","ear-nose-throat diagnosis;telemedicine;virtual hospital;web-based diagnosis","Browsers;HTML;Hospitals;Laboratories;Medical diagnostic imaging;Web server","Web services;data communication;file servers;hospitals;information retrieval;medical diagnostic computing;patient care;patient diagnosis;telemedicine","Internet;Web based ear-nose-throat diagnosis system;Web based telemedicine system;asynchronous communication mechanism;data access;face-to-face diagnosis;location independent diagnosis;medical center;medical resource;medical service process;multimedia data transmission;patient physiological signal;remote ENT diagnosis;tentative diagnostic report;virtual hospital server","","0","","10","","","1-3 July 2010","","IEEE","IEEE Conference Publications"
"Behavior checking of web applications after testing","M. Jiang; Z. Ding; Q. Ge","Center of Math Computing and Software Engineering, Zhejiang Sci-Tech University, Hangzhou, China","2010 International Conference on Electronics and Information Engineering","20100902","2010","2","","V2-163","V2-167","Testing is the last step to check the correctness of a software system. However, due to its incompleteness, we still do not know if the implementation behavior matches the design behavior. In this paper, we provide a new solution for web applications. Since web application has special navigation character, we can get rich information in the log file after testing. From such log file, we extract the Petri net based behavior of the web application. The behavior is then checked by SPIN. Market Information System has been adopted as the case study.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559739","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559739","Behavior checking;Petri net;SPIN;Web navigation","Analytical models;Browsers;Mice;Navigation;Testing;Unified modeling language;Web pages","Internet;Petri nets;information retrieval","Petri net;SPIN;Web application;behavior checking;log file;market information system","","0","","7","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"News clustering system based on text mining","J. R. Li; K. Yang","Information Engineer Department, Henan Vocational and Technical Institute, Zhengzhou, China","2010 IEEE International Conference on Advanced Management Science(ICAMS 2010)","20100823","2010","1","","540","543","Clustering displaying about News articles and summaries is the final result in automatical retrieve of news information. News clustering related to the automatic capture of news content, information processing and extraction, automatic classification, cluster analysis and display, etc. This paper presents the news clustering system to solve a number of issues which show in the current information retrieval involved in the Chinese word search, and uses a number of improved algorithms in system module.","","Electronic:978-1-4244-6932-1; POD:978-1-4244-6931-4","10.1109/ICAMS.2010.5553112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5553112","Information classification;Text clustering;the participle;tract Data","","information resources;information retrieval;natural language processing;text analysis","Chinese word search;information retrieval;news articles;news clustering;text mining","","4","","4","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Flight connections multi-leg searching by adopting Partial Constraint Satisfaction","S. Z. M. Yusof; V. S. Asirvadam; M. F. Hassan","Computer and Information Sciences Department, Universiti Teknologi PETRONAS (UTP), Bandar Seri Iskandar, Tronoh, Perak, Malaysia","2010 International Symposium on Information Technology","20100902","2010","1","","1","4","This research explores the development of flight connections multi-leg searching. It applies the concept of graph theory and Partial Constraint Satisfaction Problem (Partial CSP). Current practices of information retrieval for flight connections usually provide the users with only one-leg of network which restricts the scope of information that users could retrieve in planning their flight itinerary. This research is aimed at developing a flight connections searching system that is able to give suggestion to users of broader destination network for their itinerary. The suggested destinations are selected based on Partial CSP technique. Instead of using Constraint Satisfaction technique, Partial CSP has been proposed to be implemented in this research as its approach could solve over-constrained problem. A web-based prototype has been developed to explain the concept of multi-leg searching. The development will be continued by adopting Partial CSP in future works.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561360","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561360","Constraint Satisfaction Problem (CSP);Graph Theory;Itinerary;Partial Constraint Satisfaction (Partial CSP)","Artificial intelligence;Fires;Graph theory;Industries;Leg;Planning;Prototypes","constraint theory;graph theory;information retrieval;operations research","broader destination network;flight connections multi-leg searching;flight itinerary;graph theory;information retrieval;partial constraint satisfaction","","0","","10","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Chinese Automatic Documents Classification System","J. R. Li; K. Yang","Information Engineer Department, Henan Vocational and Technical Institute, Zhengzhou , China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","5","","324","327","Chinese Web Automatic Document Classification is one of the core technologies in Chinese information retrieval. Web Spider technology is the key in Chinese WEB document automatic classification. this issue surrounds WEB information explore which is this cutting-edge research, combined with the overall requirements of the Chinese WEB Document Classification System Framework, achieving roaming of the network spiders on the Internet, and applying to improved algorithm of network spider which mainly solutes some of the problems encountered in the Chinese word search in the current information retrieval.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5565018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5565018","Chinese Automatic Classification;Link Tracking Method;Web Spider","Bayesian methods;Feature extraction;HTML","Internet;document handling;information retrieval;natural language processing;pattern classification","Chinese Web automatic document classification;Chinese information retrieval;Chinese word search;Internet;Web spider technology","","1","","4","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A new digital library retrieval model based on Wiki technology","Wu Jianjun; Wang Shiming; Lu Rongshuang","Library of Jiangxi University of Science and Technology, China","2010 International Conference on Computer and Communication Technologies in Agriculture Engineering","20100812","2010","2","","404","407","Wiki technology is one of the hottest research domains nowadays. The idea of integrating Wiki with digital library brings us new way to improve the quality of information retrieval and service in digital library. This paper presents a new retrieval model based on Wiki technology in literature retrieval system. Experiments designed show that the recall and precision of the new system are much better than the traditional ones.","2161-1092;21611092","Electronic:978-1-4244-6947-5; POD:978-1-4244-6944-4","10.1109/CCTAE.2010.5543536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5543536","Digital Library;Retrieval Model;Wiki Technology","Libraries","data mining;digital libraries;information retrieval","Wiki technology;digital library retrieval model;information retrieval;literature retrieval system","","0","","6","","","12-13 June 2010","","IEEE","IEEE Conference Publications"
"The Change of Learning Mode Based on New Internet Technology","X. Fang; Z. Lin","Dept. of Educ. Technol., Ningbo Univ., Ningbo, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","The new internet technologies open a new era of efficient, personalized and intelligent network in the Web3.0 times, and provides a new technical support for e-learning under internet environment.The present study summarized the new trends to information acquisition and transmission based on new internet technologies, analyzed the impact on the changes of learning conception and learning ability arising from new internet technologies development. Furthermore, some trends and developments of learning modes transformation were analysed from the Web3.0 internet technology.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566448","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566448","","Computers;Digital audio broadcasting;Electronic learning;Information systems;Intelligent networks;Internet","Internet;computer aided instruction;information retrieval","Internet technology;Web3.0;e-learning;information acquisition;information transmission;learning mode","","0","","6","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Web classification using extraction and machine learning techniques","L. M. Yusuf; M. S. Othman; J. Salim","Fac. of Comput. Sci. &amp; Inf. Syst., Univ. Teknol. Malaysia, Skudai, Malaysia","2010 International Symposium on Information Technology","20100902","2010","2","","765","770","Internet services that has become easier to access has contributed to the drastic increase in the number of web pages. This phenomenon has created new difficulties to internet users about retrieving the latest, relevant and excellent web information. This is due to the enormous contents of web information that have caused problems in the restructuring of web information. Thus, in order to ensure the latest, quality and relevant web information is optimally retrievable, it is necessary to undertake the task of web document classification. This paper discusses the result of classifying web document using the extraction and machine learning techniques. Four types of kernels namely the Radial Basis Function (RBF), linear, polynomial and sigmoid are applied to test the accuracy of the classification. The results show that the accuracy percentage of web document classification will increase whenever more web document is used. The results also show that linear kernel technique is the best in web document classification compared to RBF, polynomial and sigmoid.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561603","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561603","Extraction;Machine Learning;Web Classification;Web Document","Accuracy;Astronomy;Biology;Europe;Finance;HTML;Testing","Internet;document handling;information retrieval;learning (artificial intelligence);pattern classification;radial basis function networks","Internet services;Web document classification;Web information retrieval;Web pages;extraction technique;linear kernel;machine learning technique;polynomial kernel;radial basis function;sigmoid kernel","","0","","19","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Discipline-Ontology Based Learning Resources Semantic Retrieval Algorithm","Q. Yang; J. Xiao","Sch. of Comput. Sci. & Technol., Wuhan Univ. of Technol., Wuhan, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","5","There is much difference among learners and learning resource providers when the semantic of learning resources is understood and expressed, and it is the important reason which causes lower accuracy in learning resources retrieval. In order to resolve the problem above, three mechanisms are applied as follows: 1) Discipline Ontology is constructed, which is the formalization for concepts and the relationships between concepts existing in some discipline domain. OWL is adopted as Discipline Ontology description language; 2) Inference rules are defined on the basis of Discipline Ontology. Semantic extension on keyword from user is performed by using Jena inference engine and inference rules , so as to better interpret and describe the requirement; 3) Learning resource metadata is extracted and defined by following Learning Resource Meta-data Specification, so as to provide formal description for learning resources. A semantic retrieval framework for learning resources is presented, and the process of learning resource semantic retrieval algorithm is discussed in detail. Firstly, the semantic extension on inquiry keyword from user is performed on the basis of Discipline Ontology; secondly, by using the improved similarity calculating formula, the keywords produced by semantic extension are sequenced. A set of keywords which have higher similarity with inquiry keyword are sorted out, and are used as inquiry keywords; then, search is performed on the basis of inquiry keywords and learning resource metadata. A set of descriptions for learning resources, which probably meet the requirement of user, is sent to user. The algorithm provides an approach for learning resource retrieval, and is able to support the effective access on learning resources.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566554","","Educational institutions;Electronic learning;Java;OWL;Ontologies;Semantics","inference mechanisms;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);semantic Web","Jena inference engine;OWL;discipline ontology description language;formal description;learning resources semantic retrieval algorithm;meta data specification","","0","","5","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"A Chinese fuzzy autocompletion approach","Y. Feng; H. Chen; H. Sheng","Zhejiang University, China","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","355","358","Autocompeltion is a feature for predicting a word or phrase that the user wants to type in without actually typing it completely. Fuzzy autocompletion technologies have been presented recently to deal with the typing error. However, they do not perform well in Chinese circumstance. In the paper, it extends autocompletion by (1) supporting Chinese character fuzzy match (2) considering phonetic similarity and shape similarity of Chinese characters(3) allowing infix match as well as prefix match. When typing a Chinese character string, minor mistakes are tolerated and expected autocompletion strings are presented to user. Our empirical evaltuation demonstrates that our autocompletion algorithm has high-real-time performance to meet the demand of user interaction. We have developed a autocompletion framework using this algorithm and has been used in a Traditional Chinese medicine (TCM) application.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558911","Autocompletion;Chinese character;Fuzzy match","Algorithm design and analysis;Biomedical imaging;Computational linguistics;Data structures;Heuristic algorithms;Pediatrics;Shape","fuzzy set theory;information retrieval;trees (mathematics)","Chinese character fuzzy match;Chinese fuzzy autocompletion approach;infix match;phonetic similarity;prefix match;shape similarity","","0","","10","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"Automatic Detection of Social Tag Spams Using a Text Mining Approach","H. C. Yang; C. H. Lee","Dept. of Inf. Manage., Nat. Univ. of Kaohsiung, Kaohsiung, Taiwan","2010 International Conference on Advances in Social Networks Analysis and Mining","20100907","2010","","","441","445","Social tags are annotations for Web pages collaboratively added by users. It will be much easier to understand the meaning of Web pages and classify them according to their tags. The precision in retrieving Web pages may also increase using such tags. Nowadays social tags are mostly annotated manually by users via social bookmarking Web sites. Such manual annotation process may produce diverse, redundant, and inconsistent tags. Besides, many tags which are inconsistent with their annotated Web pages exist and deteriorate the feasibility of social tags. In this work we will develop an automatic scheme to discover the associations between Web pages and social tags and apply such associations on applications of social tag spam detection. We applied a text mining approach based on self-organizing maps to find the relationships between Web pages and social tags. The disadvantages of manual annotation will be remedied through such relationships. The discovered associations were then used to identify social tag spams. Preliminary experiments show that the quality and usability of social tags were improved through this method.","","Electronic:978-0-7695-4138-9; POD:978-1-4244-7787-6","10.1109/ASONAM.2010.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563061","","Labeling;Neurons;Phase change materials;Semantics;Training;Web pages","Web sites;data mining;information retrieval;text analysis","Web pages;Web sites bookmarking;automatic detection;social tag spam detection;social tag spams;text mining approach","","0","","17","","","9-11 Aug. 2010","","IEEE","IEEE Conference Publications"
"Improved Humming Music Retrieval Method Based on Wavelet Transformation and Dynamic Time Warping","F. Zhang; S. Dong; G. Teng; J. Yao","Sch. of Inf. Sci. & Technol., Agric. Univ. of Hebei, Baoding, China","2010 International Conference on Internet Technology and Applications","20100909","2010","","","1","4","This paper proposes a method, which makes use of the band-pass property of the wavelet transform, combining the wavelet analysis with autocorrelation function to extract melody characters from the humming signal. After the wavelet transform, the humming signal is weighed, and then combined with auto-correlation function for signal analysis. The weighted factors in the design, gives full consideration about that the sound of men and women with different frequency range. This paper adopts the improved DTW algorithm to match melodies, and presents one kind of music melody representation irrespective with tone. While carrying through the DTW algorithm, it can avoid the up and down transition of tone and also reduce the calculation of melody matching.","","Electronic:978-1-4244-5143-2; POD:978-1-4244-5142-5","10.1109/ITAPP.2010.5566633","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5566633","","Databases;Feature extraction;Libraries;Smoothing methods;Wavelet analysis;Wavelet transforms","discrete wavelet transforms;information retrieval;music","autocorrelation function;dynamic time warping;humming signal;improved DTW algorithm;improved humming music retrieval method;melody characters extraction;melody matching;music melody representation;signal analysis;wavelet transformation","","0","","15","","","20-22 Aug. 2010","","IEEE","IEEE Conference Publications"
"Web information classifying and navigation based on neural network","Q. Meng; C. Gong","Library, Shenyang Aerospace University, Shenyang, China","2010 2nd International Conference on Signal Processing Systems","20100823","2010","2","","V2-431","V2-433","A quantum neural network classifier is presented, which can classify chinese Web information into each subject. Based on this quantum neural network classifier, a framework of chinese Web information navigation is proposed. We choose keywords of Web document as inputs of quantum neural network classifier, and choose subjects code as outputs of quantum neural network classifier. In order to evaluate the neural network classifier, we use 2000 Web pages for training and 1000 Web pages for testing. The test result shows that the average system performance of our chinese Web information classifier is about 86.7%.","","Electronic:978-1-4244-6893-5; POD:978-1-4244-6892-8","10.1109/ICSPS.2010.5555396","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555396","classifying;neural network;web information","Artificial neural networks;Indexing;Navigation;Search engines;Testing;Web pages","Web services;information retrieval;learning (artificial intelligence);neural nets;pattern classification;vocabulary","Chinese Web information;Web document;document keyword;information navigation;quantum neural network classifier;subject code","","0","","9","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"A context-aware proactive source code search and Retrieval Tool","E. C. R. Santos; F. C. de Almeida; E. S. de Almeida; S. R. de Lemos Meira","Federal University of Pernambuco, Federal University of Bahia, Reuse in Software Engineering (RiSE), Brazil","2010 IEEE International Conference on Information Reuse & Integration","20100826","2010","","","380","381","Software reuse is considered as a prominent strategy for software development productivity improvement. However, there are many cases of software reuse adoption failure. One of the main factors for software reuse failure is the “no attempt to reuse” issue, which is highly influenced by the effort needed to find reusable artifacts. In this sense, this paper presents the definition, the implementation and a case study of a proactive search system called BART (Basic Asset Retrieval Tool) created to improve the reusable artifacts search activity without increasing the user effort.","","Electronic:978-1-4244-8099-9; POD:978-1-4244-8097-5","10.1109/IRI.2010.5558905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558905","proactive search;software reuse;source code search","Companies;Context;Documentation;Java;Programming;Software;Software engineering","information retrieval;software reusability;ubiquitous computing","basic asset retrieval tool;context-aware proactive source code search tool;proactive search system;reusable artifacts search activity;software development productivity improvement;software reuse failure","","0","","8","","","4-6 Aug. 2010","","IEEE","IEEE Conference Publications"
"A CRF-based approach for web object extraction","Rui Liu; Rui Xiong; Kun Gao","State Key Lab of Software Development Environment, Beihang University, No.37 Xueyuan Road, Haidian District, Beijing, 100191, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","4","","483","487","A method for extracting Web object is presented in this paper. Firstly, Web object blocks are obtained by blocking the web page and calculating the information entropy of it. Then it uses Conditional Random Field model as a probability and statistics model, and builds a series of feature templates according to the characteristics of objects themselves. Feature functions are generated based on the result of Chinese word segmentation and feature templates. It uses a limited memory BFGS algorithm to estimate parameters of the model, and labels property sequences of Web object blocks by Viterbi algorithm. Experiment result shows that the proposed method is an effective way to extract science data.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563787","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563787","Conditional Random Field;Information Extraction;Machine Learning;Web Object","Feature extraction;Laboratories;Viterbi algorithm","Internet;Viterbi detection;entropy;information retrieval;object detection;random processes;word processing","Chinese word segmentation;Viterbi algorithm;Web object extraction;conditional random field model;feature templates;information entropy","","0","","12","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Trust management in privacy — Preserving information system","Kun Peng; Feng Bao","Institute for Infocomm Research, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","7","","1","4","In many information management applications, sensitive information must be stored as a record and be retrieved when necessary. When the record is stored in a distributed way in multiple databases and shared by multiple users with different trust levels and accessing privileges, the trust management model is called M-to-M model. In this model, on one hand the record is stored in a distributed way; one the other hand every user obtains a different version of the record in their retrieving operations according to their different trust levels and access privileges. A scheme is proposed in this paper to specify M-to-M trust management. The new scheme not only realizes privacy-preserving information storage and sharing in a multi-level-trust environment, but also achieves robustness through information redundancy. The new technique is quite simple and does not need any cryptographic operation like encryption, digital signature or hash function, so its security is unconditional and does not depend on any computational assumption.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564459","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564459","","Computational modeling;Cryptography;Information systems","cryptography;data privacy;distributed databases;information retrieval;records management","M-to-M model;M-to-M trust management;cryptography;digital signature;encryption;hash function;information management application;information redundancy;information retrieval;information storage;multilevel trust environment;privacy preserving information system","","0","","8","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A method of 3D CAD model retrieval based on genetic algorithm","B. Xiaoliang; Z. Shusheng; Z. Kaixing","Key Laboratory of Contemporary Design and integrated, Manufacturing Technology of the Ministry of Education, Northwestern Polytechnical University, Xi'an, China","2010 International Conference on Electronics and Information Engineering","20100902","2010","1","","V1-562","V1-565","A new method of 3D CAD model retrieval based on genetic algorithm is proposed. By extracting B-Rep information of CAD models, the models are represented by the AAG (attribute adjacent graph). Next, genetic algorithm is used to detect the common sub-graph of AAG and then obtain the similar sub-parts. The similarity of the CAD models is evaluated by comparing the similar sub-parts. Experimental results show that this method can achieve 3D CAD model retrieval and the retrieval performance is higher than the common retrieval algorithms and can achieve the reuse of design and manufacture.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559696","Attribute Adjacent Graph;Common Sub-graph;Genetic Algorithm","Algorithm design and analysis;Design automation;Feature extraction;Harmonic analysis;Shape;Solid modeling;Three dimensional displays","CAD;genetic algorithms;graph theory;information retrieval","3D CAD model retrieval;CAD models B-Rep information;attribute adjacent graph;genetic algorithm","","0","","5","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>Research and application of functional ontology in household appliances domain","Liu Yong; Deng Yongjing","Qingdao University of Science and Technology, College of Information Science and Technology, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","8","","513","517","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>To improve sharing and reusability of designing knowledge in domestic enterprises, a proposal of sharing of knowledge based on functional ontology was proposed. By using bases of knowledge of functional ontology, the mapping of structure-to-function has been realized. On basis of comprehensively understanding original functional model, through changing way of function achievement to obtain new functional model of product, an innovation of product was accomplished. Function decomposition tree describes a functional model about specific device, which includes functional designing principle. This paper designed a software platform based on functional decomposition tree, which can achieve retrieval of functional knowledge and draw out a function decomposition tree of refrigerator.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563743","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563743","function decomposition tree;functional ontology;knowledge retrieval;knowledge sharing","Context;Context modeling;Ontologies","domestic appliances;information retrieval;knowledge based systems;ontologies (artificial intelligence);product design;refrigerators","domestic enterprises;function decomposition tree;functional knowledge retrieval;functional ontology;household appliances domain;knowledge reusability design;knowledge sharing design;product innovation;refrigerator;software platform;structure-to-function mapping","","0","","10","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Sequencing Strategy with Learning Portfolio Analysis for Personalized English Reading","T. T. Wu; T. W. Sung; Y. M. Huang; H. C. Chao; J. H. Park; C. S. Yang","Dept. of Eng. Sci., Nat. Cheng Kung Univ., Tainan, Taiwan","2010 3rd International Conference on Human-Centric Computing","20100907","2010","","","1","6","Learning English is extremely popular in non-native English speaking countries, thus, the development of useful computer assisted learning programs and tools to support effective English learning are a critical issue in the educational field of learning the English-language. With the rapid growth of Internet technologies and easy access to information, the field of digital learning has stimulated innovation and diversified developments, and the emergence of guidance systems provide learners with adaptive learning paths that promote learning performance during learning processes. However, most guidance systems neglect to consider the level of difficulty, and recommended materials are proprietary in nature, and thus, do not fully utilize portfolio features of learners incorporated into personalized learning services when implementing personalized guidance. Therefore, this study proposed a guidance mechanism which utilizes the data of a learning portfolio to evaluate guidance parameters, and simultaneously considers information regarding the degree of relational reading, reading difficulty, and the average ability of learners, which can be entered into a genetic algorithm to construct a near optimal reading sequence during learning activities. Experiments were conducted to compare the free browsing reading mode without the guidance of a personalized reading path, as in most present systems. Based on the experimental results, this proposed guidance mechanism generates a high quality and concise learning path for individual learners, and the reading learning system results in an efficient and effective learning performance to promote learning motivation through appropriate learning paths.","","Electronic:978-1-4244-7570-4; POD:978-1-4244-7567-4","10.1109/HUMANCOM.2010.5563359","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563359","","Adaptive systems;Biological cells;Education;Learning systems;Materials;Portfolios;Vocabulary","Internet;computer aided instruction;information retrieval;natural languages","English language;English learning;English speaking countries;Internet;digital learning;guidance system;learning portfolio analysis;optimal reading sequence;personalized English reading;sequencing strategy","","0","","23","","","11-13 Aug. 2010","","IEEE","IEEE Conference Publications"
"Keyword weight adjusting schema based on Domain Repository","Jie Xiao; Liang He","Instituation of Computer Application, East China Normal University, Shanghai, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","1","","221","225","Webpage keyword is widely used in personalized search and recommendations. The accuracy of keyword is significant to the quality of search and recommendation result. Current keyword extraction methods' accuracy is not high. In order to make up for the shortage of present technology, a new keyword weight adjusting schema based on Domain Repository has been proposed in this paper. Three steps: 1) Extract original keywords by word frequency statistics. 2) Match original keywords with concepts in Domain Repository in this page's field. 3) Increase the weight of words more related to this field then abstract its meaning to build the weighted keywords. Extensive experiments show that this method has better resource description accuracy than traditional statistical keyword extracting method.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564098","Domain Repository;Ontology;WordNet;keyword;weight","Filling;HTML","Internet;information retrieval;ontologies (artificial intelligence)","Web page keyword;domain repository;keyword extraction methods;keyword weight adjusting schema;ontology;statistical keyword extracting method;word frequency statistics","","0","","13","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"M-Logger","A. Dash; S. Bali; S. Chugh","Department of Electronics and Communication, Maharishi Dayanand University Lingaya's Institute of Management and Technology, Faridabad, New Delhi India","2010 International Conference on Electronics and Information Engineering","20100902","2010","1","","V1-389","V1-394","The goal of this paper is to propose and describe the development of an actual unified messaging and mailing solution, which is a mobile-based universal inbox application for Symbian Sixty Series phones, integrating access to all previous and new Short Message Service, Multimedia Message Service, and email messages. The general aim of the application is to intensify the message access capabilities of Series sixty phones by maximizing convenience and flexibility for its users. This is achieved by maintaining a back up database of all the sent and received messages on a remote server and accessing it when needed. The M-Logger inbox was primarily developed on the Java Two Micro Edition platforms. However, it also employs Symbian application program interfaces by communicating with a peer Symbian C++ application for crucial operations such as monitoring a mobile phone's normal inbox. The main features of the application include accessing, replying to and sending messages, keeping a back up of all messages, as well as configuring settings for email retrieval using Post Office Protocol and Internet Message Access Protocol.","","Electronic:978-1-4244-7681-7; POD:978-1-4244-7679-4","10.1109/ICEIE.2010.5559853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559853","M-Logger inbox;Unified messaging;message holder;message log;mobile applications","Electronic mail;Internet;Java;Mobile communication;Mobile handsets;Protocols;Servers","C++ language;Java;application program interfaces;electronic mail;electronic messaging;information retrieval;mobile computing;multimedia systems","Internet message access protocol;Java two micro edition platforms;M-Logger;Short Message Service;Symbian C++ application;Symbian application program interfaces;Symbian sixty series phones;email messages;mobile-based universal inbox application;multimedia message service;post office protocol","","0","","3","","","1-3 Aug. 2010","","IEEE","IEEE Conference Publications"
"Entity answer extraction of web table","Y. Xu; Z. Yu; C. Mao; Y. Wang; J. Guo","The School of Information Engineering and Automation, Kunming University of Science and Technology, China, 650051","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2465","2468","This paper presents an entity answer extraction method based on list web table. Firstly, extract table from page using the features of web page table and label, segment the table that includes the potential entity answers by calculating the relevance of web table's title and query context, merge the table elements of each column according to table properties, and merge the web table's title with the merged elements of column again. Secondly, using merged passage as context of entity recognition, and recognize the entity for each element of the table, thus get the probability of the column elements belongs to the same type of entity answer, and locate the passages of entity answers and the entity answers. Finally, we conduct the experiment in the task of Entity Track of TREC2009. It turns out that the proposed method shows a very good result, the accuracy of entity answer extraction for web table has achieved 99.08%.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569791","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569791","list answers;table NER;table entity answer extraction;table passage segment;web table","Accuracy;Context;Data mining;Feature extraction;Machine learning;Text recognition;Web pages","Web sites;information retrieval","Web page table;Web table title;entity answer extraction;entity recognition;query context","","0","","9","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Ontology of programming resources for semantic searching of programming related materials on the Web","S. N. M. Using; R. Ahmad; S. M. Taib","Computer and Information Science Department, University Teknologi PETRONAS (UTP), Perak, Malaysia","2010 International Symposium on Information Technology","20100902","2010","2","","698","703","This paper discusses about the development of ontology for semantic searching of programming related materials on the Web. As today, more and more businesses as well as organizations have become computerized, thus programming or system development knowledge is becoming an added advantage for job seekers to have. However, teaching and learning programming has always been a challenge. Since programming need more practical aptitude rather than theoretical, classroom learning is not enough to groom good programmers. Hence, supplementary materials would need to be explored by students and one common source of these materials is the Internet. However, looking for suitable materials among the abundance information on the Internet is not that easy especially to novice users. Therefore, this research explores the concept of Semantic Web in assisting user search. In this research, ontology will be developed along with a website to help students and lecturers to find online information and materials related to programming.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561537","ontology;programming;semantic web;software development (key words)","OWL;Ontologies;Semantics","Web sites;computer science education;information retrieval;ontologies (artificial intelligence);programming;semantic Web","Web sites;World Wide Web;learning programming;online information;online materials;ontology;programming knowledge;programming related materials;programming resources;semantic Web;semantic searching;system development knowledge;teaching programming","","0","","37","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Design and Realization of Equipment's Archives Management System Based on Struts2 and Hibernate","Y. Guigui; C. Gengguo; B. Kaomin; W. Li","Coll. of Inf. Sci. & Eng., Wuhan Univ. of Sci. & Technol., Wuhan, China","2010 Second International Conference on Information Technology and Computer Science","20100826","2010","","","466","469","This paper introduced three excellent web frameworks-Struts2, Hibernate and Site Mesh. It discussed the integration solution of the three frameworks and a method of page display based on Bridge mode, with the help of which we designed and realized the manage system of equipment's archives. The results showed that on one hand, this mode can lower the degree of coupling in layers and improve the development efficiency and shorten the development cycle of Web application; on another hand, the system built by this technique had an excellent maintainability and an expansibility.","","Electronic:978-1-4244-7294-9; POD:978-1-4244-7293-2","10.1109/ITCS.2010.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557168","Bridge Mode;Hibernate;Page Display;SiteMesh;Struts2","Bridges;Business;Databases;Information filters;Maintenance engineering;Servers","Java;Web sites;information retrieval systems;records management","Bridge mode;Hibernate;Site Mesh;Struts2;equipment archive management system;page display;web framework","","0","","5","","","24-25 July 2010","","IEEE","IEEE Conference Publications"
"Evaluating the datamining techniques and their roles in increasing the search speed data in web","O. Panah; A. Panah; A. Panah","Computer Department, Islamic Azad University-AyatollahAmoli Branch, Amol, Iran","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","9","","806","809","In this article, data mining which is a new method in retrieving the high amount of information has been introduced. Data mining nowadays plays an important role in searching the information on the web that include a high variety data types. For reaching this goal, datamining techniques for automatic discovering and extracting the web based information has been used as webmining.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563818","search speed;web content mining;web mining;web structure mining;web usage mining","World Wide Web","data mining;information retrieval","Web;Web mining;data mining techniques;information retrieval;search speed data","","1","","11","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"The extraction of water information based on SPOT5 image using object-oriented method","Y. Yue; J. Gong; D. Wang","State Key Lab of Remote Sensing Science, Institute of Remote Sensing Applications, Chinese Academy of Sciences, Beijing, China","2010 18th International Conference on Geoinformatics","20100909","2010","","","1","5","The paper realizes water body extraction well using object-oriented classification method based on SPOT5 image. Firstly, segment image according to multi-scale image segmentation method based on edge-detection algorithm. Secondly, determine various characteristic parameters in land surface features according to object characteristics such as spectrum, shape and texture. And thirdly, use SVM (Support Vector Machine) method to achieve object classification through the establishment of the sample rules, and extract water body successfully. It takes SPOT5 image in Xiaojiaqiao section of Chaping River in Anxian County, Mianyang City, Sichuan Province, China as a case study. The results show that, compared with pixel-oriented supervised classification method, object-oriented classification method applied in water information extraction is more effective and its classification accuracy is higher.","2161-024X;2161024X","Electronic:978-1-4244-7303-8; POD:978-1-4244-7301-4","10.1109/GEOINFORMATICS.2010.5567695","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567695","Object-oriented classification method;SPOT5 image;Water extractiong","Accuracy;Classification algorithms;Data mining;Image resolution;Image segmentation;Remote sensing;Rivers","edge detection;feature extraction;geographic information systems;image classification;image segmentation;information retrieval;object-oriented methods;support vector machines;water","SPOT5 image;SVM;edge detection;image segment;land surface features;object characteristics;object classification;object-oriented classification method;support vector machine;water information extraction","","0","","11","","","18-20 June 2010","","IEEE","IEEE Conference Publications"
"The research and application of the Chinese machinery word segmentation algorithm based on improved PATRICIA tree dictionary","Y. Abudoulikemu","Information and Construction College of Urumqi Vocational University","2010 2nd International Conference on Signal Processing Systems","20100823","2010","3","","V3-341","V3-345","Chinese mechanical word segmentation is divided into word segmentation and dictionary segmentation in accordance with segmentation approach. Word segmentation is simple but large redundant degree. However, dictionary segmentation is accurate but complex structure. In this paper, the Chinese word segmentation mechanical dictionary algorithm and the dictionary's mechanism has been conducted the thorough research, proposed the improvement PATRICIA tree dictionary mechanical algorithm, which is combined of the word segmentation and word segmentation, and design the participle system is realized and applied in the emergency management platform full text retrieval system. Full text retrieval in emergency management platform requires a higher speed of word segmentation. Therefore, the establishment of rapid and efficient word segmentation dictionary and use a good word segmentation method has significant practical significance.","","Electronic:978-1-4244-6893-5; POD:978-1-4244-6892-8","10.1109/ICSPS.2010.5555788","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555788","Chinese mechanical word segmentation algorithm;PATRICIA tree improvement;full text retrieval;word segmentation dictionary","Algorithm design and analysis;Complexity theory;Dictionaries;Information processing;Information science;Machine learning algorithms;Signal processing algorithms","information retrieval;natural language processing;text analysis","Chinese machinery word segmentation algorithm;PATRICIA tree dictionary;emergency management platform;full text retrieval system","","1","","10","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"Parameter learning for multi-factors of entity answer extracting","H. Zong; Z. Yu; C. Mao; J. Zou; J. Guo","The School of Information Engineering and Automation, Kunming University of Science and Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2478","2482","Entity extraction involves multi-factors, and the different factor has an impact on the answer in varying degrees, this paper presents a machine learning approach to parameter learning for entity answer. Firstly, in view of characteristics of the Question Answering System (QA), we define three elements of the text score, passage score and entity score which influenced the answer extraction, also give the relevant computational method about them. Then collect 400 entity answers of product, person, and organization according to TREC2009 entity task requirements. With the help of search engines, retrieve related pages and calculate the score of the various factors related to the answer respectively. Thereafter compute the score of entity answers according to a linear combination of the various factors. Define an initial score to extract the entity answer and get a sorted list of answers. Finally, mark these entities answer to obtain the correct marked answers corpus, then build parameter learning model by the EM algorithm iterate gradually to find the optimal answer weight of different factors that influenced the answer extraction. We carried on the experiment in the TREC2009 entity task; it shows very good results for this method. The accuracy of entity answer has achieved 88.93%.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569794","EM algorithm;entity answer extraction;entity relevance;parameter estimation;passage relevance;text relevance","Accuracy;Algorithm design and analysis;Context;Data mining;Machine learning;Parameter estimation;Training","information retrieval;learning (artificial intelligence)","TREC2009 entity task requirements;answer extraction;entity answer extraction;entity score;machine learning;parameter learning;passage score;question answering system;relevant computational method;search engines;text score","","1","","8","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"Sentiment analysis of online product reviews with Semi-supervised topic sentiment mixture model","W. Wang","Key Laboratory for Ferrous Metallurgy and Resources Utilization of Ministry of Education, Wuhan University of Science and Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2385","2389","Analysis the positive and negative sentiments about each topic of the product are very useful to the customers and manufacturers. In this paper we propose a new topic sentiment mixture model which we call Semi-supervised Co-LDA model to obtain the positive and negative opinions from the reviews about each product. The Semi-supervised Co-LDA can model the topic and sentiment of the product reviews simultaneously. The Semi-supervised Co-LDA model we proposed is a semi-supervised model, which utilizes the well-written expert reviews as labeled data. The Co-LDA model has an additional advantage that can integrate expert opinions and ordinary opinions. Empirical experiments on the online reviews datasets from CNET show that this approach is effective for topic sentiment analysis of the product. The Co-LDA model is quite general, which can be applied to many fields such as modeling opinions in weblogs, user behavior prediction.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569528","LDA;Sentiment mining;Topic model;Web mining","Analytical models;Data mining;Data models;Feature extraction;Internet;Probabilistic logic;Web sites","Internet;Web sites;data mining;information retrieval","Weblogs;online product reviews;semi-supervised Co-LDA model;semi-supervised topic sentiment mixture model;sentiment analysis;user behavior prediction","","3","3","36","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"An approach for mulit-label music mood classification","E. E. P. Myint; M. Pwint","University of Computer Studies, Yangon Myanmar","2010 2nd International Conference on Signal Processing Systems","20100823","2010","1","","V1-290","V1-294","Music can express emotion in succinctly but in an effective way. Peoples select different music at different time concordance with listening time's mood and objectives. Music classification and retrieval by perceived emotion is natural and functionally powerful. Since, human perception of music mood varies individual to individual; multi-label music mood classification has become a challenging problem. Because music mood may well change one or more times in an entire music clip, an exact song may offer more than one music taste to the music listener. Therefore, tracking mood changes in an entire music clip is given precedence in multi-label music mood classification tasks. This paper presents self-colored music mood segmentation and a hierarchical framework based on new mood taxonomy model to automate the task of multi-label music mood classification. The proposed mood taxonomy model combines Thayer's 2 Dimension (2D) model and Schubert's Updated Hevner adjective Model (UHM) to mitigate the probability of error causing by classifying upon maximally 4 class classification from 9. The verse and chorus parts approximately 50 to 110 sec of the whole songs is exerted manually as input music trims in this system. Consecutive self-colored mood is segmented by the image region growing method. The extracted feature sets from these segmented music pieces are ready to inject the Fuzzy Support Vector Machine (FSVM) for classification. One-against-one (O-A-O) multi-class classification method are used, for 9 class classification upon updated Hevner labeling. The hierarchical framework with new mood taxonomy model has the advantage of reducing computational complexity due to the number of classifiers employed for O-A-O approach as only 19 instead of 36 classifiers.","","Electronic:978-1-4244-6893-5; POD:978-1-4244-6892-8","10.1109/ICSPS.2010.5555619","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555619","music emotion;music mood;self-colored music mood segmentation","Accuracy;Feature extraction;Image segmentation;Mood;Music;Support vector machines;Taxonomy","computational complexity;fuzzy set theory;information retrieval;music;pattern classification;support vector machines","O-A-O approach;Schubert updated Hevner adjective model;Thayer 2D model;computational complexity reduction;error probability;feature extraction;fuzzy support vector machine;human perception;mood taxonomy model;multilabel music mood classification approach;music retrieval;one-against-one multiclass classification method;selfcolored music mood segmentation","","1","","14","","","5-7 July 2010","","IEEE","IEEE Conference Publications"
"An adaptive service for objects re-ranking in u-learning environment","N. Y. Yen; S. Y. Kuo; J. J. Huang; H. P. Chang","Dept. of Human Informatics and Cognitive Sciences, Waseda University, Japan","2010 3rd IEEE International Conference on Ubi-Media Computing","20100809","2010","","","58","63","Ubiquitous Learning (U-Learning), as an emerging learning paradigm, makes it possible for learners to carry out the learning activities at any places and at anytime. With the advantages of the devices, learners can obtain a variety of supplementary materials from the internet. In the scope of distance learning, LOR (Learning Object Repository) stands for managing and sharing of these kinds of materials which also be named as learning objects. However, some challenges raise while performing these activities. For instance, a huge amount of learning objects may appear while learners utilize the search service provided by the system. Learners have to spend time on collecting relevant resources for specific purposes. This situation may discourage the reusability of learning objects especially in a ubiquitous environment. In this paper, based on systematic re-examination of reuse scenarios, a resource retrieval mechanism, as a search middleware, was proposed to assist learners in obtaining relevant objects. The achievement of proposed mechanism can re-rank the search results in order of relevant degree based on the combination of learners' geographical information and input query. It may make resource retrieval more efficient in u-learning environment.","","Electronic:978-1-4244-6709-9; POD:978-1-4244-6708-2","10.1109/UMEDIA.2010.5543924","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5543924","","Computer aided instruction;Computer science;Electronic learning;Hardware;Humans;Informatics;Internet;Libraries;Middleware;Radiofrequency identification","Internet;computer aided instruction;distance learning;information retrieval;ubiquitous computing","Internet;distance learning;learning objects;objects re-ranking;resource retrieval mechanism;ubiquitous learning","","0","","16","","","5-6 July 2010","","IEEE","IEEE Conference Publications"
"A framework for building multilingual ontologies for Islamic portal","J. Salim; S. F. M. Hashim; A. Aris","Information Science Department, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia","2010 International Symposium on Information Technology","20100902","2010","3","","1302","1307","In recent years, there were a variety of difficulties that users have to face in searching for information through Internet. Past research had shown that in performing searches, users use query terms that consist of “everyday language, technical terms (with or without knowledge of underlying concepts) and various explanatory model, all influenced by psychosocial and cultural variations. Semantically annotated documents provide several advantages. One advantage is document specific representations no longer affect the search. This is extremely important in the case of multilingual representations. Keywords of several languages are mapped to the same concept in an ontology and are therefore given the same meaning. Multilingual search portal can be established to produce the same results, no matter which language is used for retrieval. This research aim to identify and analyze ontology that relates to Islam to enhance the use of exact vocabularies and to develop an ontology based Islamic semantic retrieval that can retrieve Islamic web in 3 different languages simultaneously through a multilingual search portal. This research emphasizes on semantic web technologies and the development of ontology using thesaurus such as Library Congress Subject Heading and other reference sources such as Index Islamicus, thesaurus, encyclopaedia, biographies etc. as the basis for implementing novel mechanism for retrieving Islamic web in 3 different languages simultaneously. In this research, existing knowledge sources such as documents, reports, etc. are mapped into the domain ontology and semantically enriched. This semantically enriched information enables better knowledge indexing and searching process and implicitly a better management of knowledge.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561454","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561454","islami c extraction system;islamic retrieval system;multilingual ontology","","information retrieval;natural language processing;ontologies (artificial intelligence);portals;semantic Web;thesauri","Internet;Islamic Web;Islamic portal;Islamic semantic retrieval;multilingual ontologies;multilingual search portal;semantic Web technology;thesaurus","","1","","16","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Synchronizing web browsing data with Browserver","L. G. de Carvalho; R. F. do Valle; A. Passito; E. S. Mota; E. S. Mota; R. Novellino; A. G. Penaranda","Comput. Sci. Dept., Fed. Univ. of Amazonas, Manaus, Brazil","The IEEE symposium on Computers and Communications","20100812","2010","","","738","743","People spend a lot of time navigating on the web. When moving from one computer device to another, it would be useful to have access to the navigation data produced in the previous web session. In this article, a synchronization service of navigation data, called Browserver, is presented. It is responsible for keeping user navigation information (tabs, history, forms, cookies, etc.) so that it can be recovered from any device connected to the Internet. Finally, Browserver performance is compared to a similar service, according to hardware and network consumption metrics.","1530-1346;15301346","Electronic:978-1-4244-7755-5; POD:978-1-4244-7754-8","10.1109/ISCC.2010.5546792","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5546792","Browser;browsing data synchronization;web session migration","Browsers;Hardware;History;IEEE Journals and Transactions On-LINE - OpeRA;Navigation;Servers;Synchronization","Internet;information retrieval;synchronisation","Browserver;Internet;Web browsing data synchronization;Web navigation;Web session;computer device;hardware consumption metrics;network consumption metrics;synchronization service","","2","31","13","","","22-25 June 2010","","IEEE","IEEE Conference Publications"
"Realizing XML driven design activity for mold & die design","Shuangrong Yang; Mingyue Huang; Sha Hu; Jianjun Li","State Key Laboratory of Material Processing and Die & Mould Technology, Huazhong University of Science and Technology, Wuhan 430074, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","2","","205","211","To improve design quality and efficiency, many studies have been conducted around design reuse and design information integration. One of the methods is to make records of design activities and reuse them. Traditional methods, e.g. design reports, minutes and records, all use design-record mechanism to record the design activities, where the records information are often in weakly structured form, partially, personal errors or mixture with useless data, and therefore lack good mechanisms for information retrieval and unable to really realize design reuse. This paper presents a framework to realize XML driven design activity to support design reuse for mold & die design, which draws on the successful experience of Business Process Execute Language. The proposed framework builds design activity templates and makes XML file to drive the design activities, like business activities driven by Business Process Execute Language files, and very different from the design-record systems. Thus the design process is recorded in a more structured, complete and computer-interpretable form with less human error which makes the design XML file easier to reuse. An illustrative example is included for demonstrating the usefulness of the proposed XML driven design activity framework. The framework explores a new approach to research the reuse of design.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563808","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563808","Design reuse;Mould & die design;XML driven design","Business;Design automation","XML;design engineering;dies (machine tools);information retrieval;moulding;production engineering computing","XML driven design activity;XML file;business process execute language;computer-interpretable form;design information integration;design quality;design-record mechanism;human error;information retrieval","","0","","26","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Retrieving the GPS information of telephone based on Symbian OS","Jia Liu; Weiyao Lan","Department of Automation, Xiamen University, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","8","","145","147","With the popularity of smart phones, GPS is used more and more in the cell phone. The location information in the GPS is very significant for evidence-gaining. This paper researched and realized the operations under Symbian OS such as GPS-related applications. Firstly I introduced the concept of GPS and GPS-related knowledge in the mobile phone. Secondly I programmed cell phone GPS detection and extracted the GPS information from Nokia N95.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563638","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563638","GPS;information extraction;symbian","Distance measurement;Flowcharts;Servers;World Wide Web","Global Positioning System;information retrieval;mobile handsets;mobile satellite communication;operating systems (computers)","GPS detection;GPS information retrieval;Symbian OS;cell phones;evidence gaining;location information;smart phones","","0","","7","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A solution for invalid source link in anti-plagiarism system based on web archive","H. Fu; S. Wu; X. Ren; L. Peng; Y. Shen","School of Information Management of Wuhan University, Hubei 430072 China","2010 International Conference on Intelligent Control and Information Processing","20100909","2010","","","455","459","Invalid web links exert a profound negative influence both on detection effect and support evidence of anti-plagiarism system based on the network information resources. For this reason, we utilize the self-developed software ROST CM to detect 57662 academic keyword links of 30 hot research issues from 6 popular subjects in 3 large academic fields, 29057 through telecommunication network and 28605 through education network. After that, we got the link failure rate of major subjects through different networks, and proposed the original idea of storage priority level to effectively establish the web archive of anti-plagiarism system. On this basis, we propose the solution to link failure and make detailed descriptions of its key technology - the evaluating method of storage priority of web archives. The framework and implementation of this solution are described in detail and the problem which needs further study is put forward in the end.","","Electronic:978-1-4244-7050-1; POD:978-1-4244-7047-1","10.1109/ICICIP.2010.5565256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5565256","","Communications technology;Databases;Education;Libraries;Plagiarism;Servers;Software","Internet;information retrieval systems","Web archive;Web links;antiplagiarism system;detection effect;invalid source link;self-developed software ROST CM;telecommunication network","","0","","9","","","13-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"The development of hashing indexing technique in case retrieval","M. F. M. Mohsin; N. M. Norwawi; M. B. Manaf; M. H. A. Wahab","UUM College of Arts & Sciences, Universiti Utara Malaysia, Kedah, Malaysia","2010 International Symposium on Information Technology","20100902","2010","2","","1045","1050","Case-based reasoning (CBR) considers previous experience in form of cases to overcome new problems. It requires many solved cases in case base in order to produce a quality decision. Since today, database technology has allowed CBR to use a huge case storage therefore the case retrieval process also reflects the final decision in CBR. Traditionally, sequential indexing method has been applied to search for possible cases in case base. This technique is worked fast when the number of cases is small but it consumes more time to retrieve when the number of data grows in case base. To overcome the weakness, this study researches the nonsequential indexing called hashing as an alternative to mine large cases and faster the retrieval time in CBR. Hashing indexing searches a record by determines the index using only an entry's search key without traveling to all records. This paper presents the review of a literature and early stages of the integration hashing indexing method in CBR. The concept of hashing indexing in case retrieving process, the model development, and the preliminary algorithm testing result will be discussed in this paper.","2155-8973;21558973","Electronic:978-1-4244-6718-1; POD:978-1-4244-6715-0","10.1109/ITSIM.2010.5561588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5561588","case retrieval;hashing indexing;sequential indexing;temporal data","Accuracy;Indexing;Logic gates","case-based reasoning;database management systems;indexing;information retrieval","case retrieval process;case-based reasoning;database technology;hashing indexing;nonsequential indexing","","0","","14","","","15-17 June 2010","","IEEE","IEEE Conference Publications"
"Deployment of neutrosophic technology to retrieve answer for queries posed in natural language","M. Arora; R. Biswas","CSE Department, JSS Academy of Technical Education, Noida, INDIA","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","3","","435","439","In this paper, we have we have introduced a new intelligent soft-computing method of neutrosophic search with ranks and a new neutrosophic rank sets for neutrosophic relational data model (NRDM). Essentially the data and documents on the Web are heterogeneous; inconsistency is unavoidable in Web mining. Using the presentation and reasoning method of our data model, it is easier to capture imperfect information on the Web which will provide more potentially valued-added information. In Bio-informatics there is a proliferation of data sources. Each research group and each new experimental technique seems to generate yet another source of valuable data. But these data can be incomplete and imprecise, and even inconsistent. We could not simply throw away one data in favor of other data. So now we can represent and extract useful information from these data as a challenge. Thus it is a kind of an intelligent search for match in order to answer imprecise queries of the lay users. Our method, being an intelligent soft-computing method, will support the users to make and find the answers to their queries without iteratively refining them by trial and error. This important issue of closeness cannot be addressed with the crisp mathematics. That is why we have used the Neutrosophic tools. Neutrosophic-search method could be easily incorporated in the existing commercial query languages of DBMS to serve the lay users better. So in this Paper Authors are suggesting NRDM and Rank Sets to solve the imprecise query based on Rank Neutrosophic search which is a combination - Neutrosophic Proximity search and α-Neutrosophic-equality Search.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5564125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564125","α-Neutrosophic-equality Search;Neutrosophic relation;Neutrosophic relational data model;Rank Neutrosophic search;Rank neutrosophic sets;proximity search","Ear","Web services;bioinformatics;data mining;database management systems;fuzzy logic;fuzzy set theory;information retrieval;medical information systems;natural languages;query languages","α-neutrosophic-equality search;DBMS;Web document;Web mining;answer retrieval;bioinformatics;intelligent soft-computing method;natural language;neutrosophic proximity search;neutrosophic rank set;neutrosophic relational data model;neutrosophic-search method;query language","","3","","8","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"A study of features on Primary Question detection in Chinese online forums","L. Sun; B. Liu; B. Wang; D. Zhang; X. Wang","MOE-MS Key Laboratory of Natural Language Processing and Speech, Harbin Institute of Technology, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2422","2427","Primary Question detection in online forum is a subtask of extracting question-answer pairs. In this paper, by surveying the forms of questions in Chinese online forums, a combination of textual and N-gram features achieved via feature selection is adopted to help detecting primary questions. By viewing primary question detection a binary classification problem, decision tree classifier C4.5 and support vector machine are introduced to distinguish questions from non-questions separately. Experimental results across multiple datasets demonstrate that the mixture of textual and N-gram features performs better than using each of them separately under both C4.5 and support vector machine. By computing the weight of each feature in the two classifiers, the top 6 features are found the very same except for a little adjustment of order, showing that the combination of textual and N-gram features is universal and effective in detecting primary questions.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569298","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569298","N-gram feature;classification;information extraction;primary question detection;textual feature","Classification tree analysis;Electronic mail;Feature extraction;Speech;Support vector machines","classification;decision trees;information retrieval;natural language processing;support vector machines","Chinese online forums;N-gram features;binary classification;decision tree classifier;feature selection;primary question detection;question-answer pairs;support vector machine;textual features","","0","","18","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
"The Study and Design on Data Security System of E-government Intranet","J. h. Zhu; D. z. Han; R. q. Zhong","Sch. of Inf. Sci. & Technol., Univ. of Foreign Studies, P. R. China, Guangzhou, China","2010 Third International Symposium on Electronic Commerce and Security","20100826","2010","","","398","402","To deal with the data security problems in the storage system for the E-government intranet, an integrated data security defense system, which incorporates information isolation, access control, virus detection, content filtering, real time backup and rapid information retrieval, has been designed and implemented. The result on trial displays that this system can ensure the data security of storage system for E-government intranet, with few side effects on the I/O performance of the network.","","Electronic:978-0-7695-4219-5; POD:978-1-4244-8231-3","10.1109/ISECS.2010.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557361","content filtration and detection;multi - protocol file system;security system of E-government intranet","Data security;Electronic government;Information security;Servers;Software","authorisation;government data processing;information retrieval systems;intranets","access control;content filtering;e-government Intranet;information isolation;integrated data security defense system;real time backup;storage system;virus detection","","0","","17","","","29-31 July 2010","","IEEE","IEEE Conference Publications"
"Distributed situation assessment for traffic emergent events","H. Wang; G. Tan; Y. Wang; G. Wang","Dalian University of Technology, Liaoning China","2010 International Conference on Intelligent Control and Information Processing","20100909","2010","","","623","628","The concept of the Internet of Things provides a new model to access the information of the objective world. A new approach based on the Internet of Things for traffic emergent events is proposed. The network architecture entails a hierarchy of capability, information and control, where nodes in the network expected to possess resources for networking and computing and presume autonomy through multi-functional modules for sensory processing and situation assessment. For the data fusion of multi-sensor device, the paper puts forward three different methods of date fusion according to different integrality levels of raw information. Finally, Bayesian network method is used to get situational assessment of the fused data. Comprehensive experiments on urban traffic emergent events of Dalian and comparisons with several other methods show that the Bayesian network combined with the Internet of Things is a very promising and effective approach for traffic emergent events' situation assessment modeling and forecasting, both for complete data and incomplete data.","","Electronic:978-1-4244-7050-1; POD:978-1-4244-7047-1","10.1109/ICICIP.2010.5564174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564174","","Bayesian methods;Internet;Joints;Probability distribution;Sensor fusion;Vehicles","Bayes methods;Internet;information retrieval;sensor fusion;traffic information systems","Bayesian network;Internet;data fusion;distributed situation assessment;information access;traffic emergent events;urban traffic","","0","","16","","","13-15 Aug. 2010","","IEEE","IEEE Conference Publications"
"An Architecture for Public and Open Submission Systems in the Cloud","M. Azambuja; R. Pereira; K. Breitman; M. Endler","WebMedia, Globo.com, Rio de Janeiro, Brazil","2010 IEEE 3rd International Conference on Cloud Computing","20100826","2010","","","513","517","The advent of the Internet poses great challenges to the design of public submission systems as it eliminates traditional barriers, such as geographical location and costs associated to physical media and mailing, that helped keeping the number of submissions at bay. With open global access, it is very hard to estimate storage space and processing power required by this class of applications. In this paper we argue in favor of a Cloud Computing solution, and propose a general architecture in which to build open access, public submission systems. Furthermore, we demonstrate the feasibility of our approach with a real video submission application, where candidates that want to take part in a nationwide reality show can register by submitting a personal video clip.","2159-6182;21596182","Electronic:978-0-7695-4130-3; POD:978-1-4244-8207-8","10.1109/CLOUD.2010.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558016","Cloud Computing;Service Orientation;Storage;User Generated Content;Video Encoding","Cloud computing;Clouds;Computer architecture;Servers;Streaming media;Transcoding;User-generated content","Internet;information retrieval systems","Internet;cloud computing;open access submission systems;public submission systems;video submission application","","0","","17","","","5-10 July 2010","","IEEE","IEEE Conference Publications"
"Semi-automatically building ontologies from relational databases","Shihan Yang; Ying Zheng; Xuehui Yang","Chengdu Branch of the National Science Library, Chinese Academy of Sciences, China","2010 3rd International Conference on Computer Science and Information Technology","20100907","2010","1","","150","154","Semantic Web applications meet a serious problem in practice: the shortage of semantic data (ontologies). Since the vast majority of data are still stored in relational databases, they are unavailable for the most next generation Web applications, such as Semantic Digital Libraries. Therefore, it becomes one of core challenges of Semantic Web whether applications can automatically retrieve semantic information from existed relational databases. This paper proposes a middle graph-based formal model language, W-graph, to help retrieve an ontology from existed relational database instances. The main idea is to execute SQL procedures to retrieve the semantic information of the database instances, transform semi-automatically the result sets into the medium model, then transform the model into the ontology complete automatically. This method not only maps schemata to the middle model, but also populates the model with data stored in databases.","","Electronic:978-1-4244-5540-9; POD:978-1-4244-5537-9","10.1109/ICCSIT.2010.5563924","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5563924","OWL ontology;Semantic Web;W-graph;data retrieving;interoperability;relational databases","Artificial neural networks;Context;Databases;OWL","SQL;formal languages;graph theory;information retrieval;ontologies (artificial intelligence);relational databases;semantic Web","SQL;W-graph;graph-based formal model language;relational database;semantic Web application;semantic information retrieval;semiautomatically building ontologies","","0","","10","","","9-11 July 2010","","IEEE","IEEE Conference Publications"
"Non-wood forest information extraction based on ALOS data","E. Yan; H. Lin; D. Mo; L. Bai; H. Sun","Research Center of Forest Remote Sensing & Information Engineering, Central South University of Forestry & Technology, Changsha, Hunan, China","2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery","20100909","2010","5","","2037","2041","Non-wood forest is a kind of important forest resource. This paper focused on the information extraction of non-wood forest based on Advanced Land Observation Satellite (ALOS) data. Band characteristics were analyzed to get understanding of this data wholly by information content, correlation coefficient and Optimum Index Factor (OIF). A new set of data with eight bands were obtained by the fusion of Normalized Difference Vegetation Index (NDVI), the first three components of Principal Component Analysis (PCA1, PCA2, PCA3) and the four bands of ALOS data. Various kinds of vegetations, especially non-wood forest was analyzed through the Spectral Feature Model (SFM) and Maximum Likelihood (ML) with association of topographical map and field investigation data. Results show that NDVI and PCA can improve the extraction accuracy of non-wood forest. In addition, SFM reduces the phenomenon of mixed classification and improves the information extraction accuracy of non-wood forest, which will provide reference for the classification of vegetation.","","Electronic:978-1-4244-5934-6; POD:978-1-4244-5931-5","10.1109/FSKD.2010.5569673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5569673","ALOS data;information extraction;non-wood forest;remote sensing","Accuracy;Correlation;Data mining;Feature extraction;Presses;Remote sensing;Vegetation mapping","classification;correlation methods;forestry;geographic information systems;geophysical signal processing;information retrieval;maximum likelihood estimation;principal component analysis;spectral analysis;vegetation mapping","ALOS data;Advanced Land Observation Satellite;band characteristics;correlation coefficient;field investigation data;forest resource;information content;maximum likelihood;nonwood forest information extraction;normalized difference vegetation index;optimum index factor;principal component analysis;remote sensing;spectral feature model;topographical map;vegetation classification","","0","","18","","","10-12 Aug. 2010","","IEEE","IEEE Conference Publications"
