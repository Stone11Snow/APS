"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6128052,6128247,6127956,6128279,6128389,6128180,6126671,6128268,6127957,6128293,6128274,6128130,5959154,6126238,5983479,6123504,6123508,6123519,6030867,6123386,6123494,6123403,6122559,6122827,6122608,6122587,6119026,6121640,6118910,6121499,6121786,6113311,6120750,6120981,6120984,6120723,6121741,6121828,6113152,6113318,6118700,6118853,6118965,6120545,6120630,6118868,6121007,6118887,6120300,6121784,6119089,6121602,6121839,6118933,6119029,6120666,6121301,6119064,6121515,6113239,6120964,6120400,6118945,6121624,6121694,6113187,6117428,6112917,6113434,6114927,6117996,6112910,6115483,6116134,6113392,6114039,6116416,6115484,6112954,6112920,6116617,6112503,6111993,6112547,5871604,6112433,5645628,6108154,6108597,6108899,6108518,6107361,6106954,6106400,6107368,6106983,6107367,6106519,6106922,6107944",2017/05/04 22:28:57
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Web-based Medical Image Archiving and Communication System for Teleimaging","P. Suapang; S. Yimmun; A. Puditkanawat","Biomedical Instrumentation Program, Department of Physics, Rangsit University, Pathumthani, 12000, Thailand","2011 11th International Conference on Control, Automation and Systems","20111219","2011","","","172","177","The design and implementation of Web-based Medical Image Archiving and Communication System for Teleimaging which was developed using software such as Borland C++ Builder 5.0, MyDAC, PHP, Apache and MySQL for image acquisition system, image viewer and web-based information system. The system provides the following facilities: (1) Image acquisition system can connect and display medical image signal from endoscope in real-time and it can save single frame in .bmp, .jpg, .jpg2, .avi and .dcm file format into database system. (2) Image viewer is developed for DICOM viewing and image processing based on local contrast enhancement, adaptive interpolation technique, colour transformation and cine loop. (3) Web-based information system developed under a cooperation effort between Rangsit University and Hospital. It presents a set of tools that allow physician to manipulate and annotate images. The results shown that the system enables physician to store, display, retrieve and transmit medical images throughout interfaces that are used to present data to the user via a choice of viewing tools.","2093-7121;20937121","Electronic:978-89-93215-03-8; POD:978-1-4577-0835-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106400","Image Archiving;Teleimaging;Web-based Medical Information System","DICOM;Image coding;Medical diagnostic imaging;Medical services;Servers;Transform coding","Internet;endoscopes;image colour analysis;image enhancement;image retrieval;information retrieval systems;information storage;interpolation;medical image processing;medical information systems;telemedicine;visual communication;visual databases",".avi file format;.bmp file format;.dcm file format;.jpg2 file format;DICOM viewing;Web-based information system;Web-based medical image archiving;Web-based medical image communication system;adaptive interpolation technique;cine loop;colour transformation;database system;endoscope;image acquisition system;image annotation;image manipulation;image processing;image viewer;local contrast enhancement;medical image retrieval;medical image signal;medical image storage;medical image transmission;teleimaging","","0","","20","","","26-29 Oct. 2011","","IEEE","IEEE Conference Publications"
"Mining Parallel Data from Comparable Corpora via Triangulation","T. N. D. Do; E. Castelli; L. Besacier","MICA Center, Grenoble INP, Hanoi, Vietnam","2011 International Conference on Asian Language Processing","20120102","2011","","","185","188","This paper improves an unsupervised method for extracting parallel sentence pairs from a comparable corpus by using the triangulation through a third language. Before, an unsupervised method for extracting parallel sentence pairs from a comparable corpus has been proposed. This method is based on technique of cross-language information retrieval with iterative process and requires no more additional parallel data. The method has been validated on the Vietnamese-French and Vietnamese-English bilingual data. In this paper, we address the problem of using triangulation through a third language to improve the parallel data mining processes: English is used in the Vietnamese-French parallel data mining process, and French is used in the Vietnamese-English parallel data mining process. The experiments conducted show that using triangulation can improve the quality of the extracted data and the quality of the translation system as well.","","Electronic:978-0-7695-4554-7; POD:978-1-4577-1733-8","10.1109/IALP.2011.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121499","comparable corpus;extracting parallel sentence pairs;triangulation method;unsupervised method","Computational linguistics;Data mining;Information filters;Noise measurement;Training","data mining;information retrieval;iterative methods;language translation;natural language processing","Vietnamese-English bilingual data;Vietnamese-French bilingual data;comparable corpora;cross-language information retrieval;iterative process;machine translation;parallel data mining;parallel sentence pair extraction;translation system quality;triangulation;unsupervised method","","1","","16","","","15-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"An immune system approach to personalize search results","H. Rastegari; S. M. Shamsuddin","Faculty of Computer Science and Information System University Technology Malaysia","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","112","117","Since dawn of the World Wide Web, the retrieval of relevant information has been a major problem for search engines. Current Web search engines use search algorithms to generate results that are suitable for discovering relevant pages to a query, but in doing so they do not consider the user who requested the query. A personalization system helps users to find interesting documents based on their preferences. The issue in this field is low accuracy in retrieved relevant information for particular user. This article proposed a novel technique to personalize the search results. We utilize artificial immune system (AIS) as a successful intelligent technique to find relevant pages in the search results based on user preferences. According to the obtain result, the proposed algorithm based on the AIS improved accuracy in retrieval of relevant information in the Web search results.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121640","Affinity Function;Artificial Immune System;Clonal Selection;Personalization of Web Search;Search Result","Conferences;Decision support systems;Helium;Intelligent systems","Internet;artificial immune systems;document handling;information retrieval;search engines","AIS;World Wide Web;artificial immune system;document handling;immune system approach;information retrieval;intelligent technique;personalize search results;search engines","","0","","25","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"The Research of Soft Component Library Based on Cloud Computing","H. Zhao; Y. Zhang; J. Liu","Dept. of Comput. Sci. & Technol., Taiyuan Univ. of Sci. & Technol., Taiyuan, China","2011 First International Conference on Robot, Vision and Signal Processing","20111229","2011","","","154","157","Aimed at the problems that have appeared in the component library (CL) development at present, this paper introduces a distributed CL system based on cloud computing technology. The architecture and retrieval model of this system are also introduced. It can nicely meet the need of component retrieval for component requester through many distributed component base.","2376-9793;23769793","Electronic:978-0-7695-4581-3; POD:978-1-4577-1881-6","10.1109/RVSP.2011.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114927","cloud computing;component library;software reuse;virtual resource pool","Cloud computing;Computational modeling;Computer architecture;Industries;Libraries;Protocols","cloud computing;distributed processing;information retrieval;object-oriented programming;software libraries;software reusability","architecture model;cloud computing technology;component-based software development;distributed CL system;retrieval model;soft component library development;software reuse","","2","","8","","","21-23 Nov. 2011","","IEEE","IEEE Conference Publications"
"Measuring Semantic Relatedness between Words Using Lexical Context","W. He; X. Yang; D. Huang","Sch. of Inf., Renmin Univ. of China, Beijing, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","1316","1320","Semantic relatedness measurement between words is always a hot issue interested by many researchers. It can be applied to various tasks of NLP and IR with a big challenge. We propose a method for measuring semantic relatedness between words using lexical context in this paper. The method can mainly be divided into two steps. Firstly, for each word of a word-pair, a lexical context is generated exploiting search engine with WordNet, which is constituted by the words highly related to the target word. Secondly, semantic relatedness between words is measured by considering semantic relatedness between a word and lexical context of another word for an original word-pair. Experimental results on Miller-Charles benchmark dataset show our proposed method outperforms all other state of the art related approaches, achieving a Pearson correlation coefficient of 0.912. It shows more competitive than other methods.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128247","lexical context;relatedness measurement;semantic relatedness","Context;Correlation;Electronic publishing;Encyclopedias;Internet;Semantics","information retrieval;natural language processing","IR;Miller-Charles benchmark dataset;NLP;Pearson correlation coefficient;WordNet;lexical context;word pair;word semantic relatedness measurement","","1","","20","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"Exchanging Data Agreements in the DaaS Model","H. L. Truong; S. Dustdar; J. Gotze; T. Fleuren; P. Muller; S. E. Tbahriti; M. Mrissa; C. Ghedira","Distrib. Syst. Group, Vienna Univ. of Technol., Vienna, Austria","2011 IEEE Asia-Pacific Services Computing Conference","20120112","2011","","","153","160","Rich types of data offered by data as a service(DaaS) in the cloud are typically associated with different and complex data concerns that DaaS service providers, data providers and data consumers must carefully examine and agree with before passing and utilizing data. Unlike service agreements, data agreements, reflecting conditions established on the basis of data concerns, between relevant stakeholders have got little attention. However, as data concerns are complex and contextual, given the trend of mixing data sources by automated techniques, such as data mash up, data agreements must be associated with data discovery, retrieval and utilization. Unfortunately, exchanging data agreements so far has not been automated and incorporated into service and data discovery and composition. In this paper, we analyze possible steps and propose interactions among data consumers, DaaS service providers and data providers in exchanging data agreements. Based on that, we present a novel service for composing, managing, analyzing data agreements for DaaS in cloud environments and data marketplaces.","","Electronic:978-0-7695-4624-7; POD:978-1-4673-0206-7","10.1109/APSCC.2011.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6127956","","Couplings;Data models;Data privacy;Data structures;Joining processes;Law enforcement;Licenses","cloud computing;electronic data interchange;information retrieval","DaaS service provider;cloud environment;data agreement exchange;data as a service;data composition;data concern;data consumer;data discovery;data marketplace;data retrieval;data source mixing;data utilization","","6","","10","","","12-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"Functional semantic retrieval for effects knowledge base","H. Wu; J. Zhang; J. Ma; R. Tan","School of Computer Science & Software, Hebei University of Technology, Tianjin, China","2011 IEEE International Conference on Industrial Engineering and Engineering Management","20111229","2011","","","644","648","Effects, which are knowledge of scientific principles, can be used to transform inputs to outputs and achieve corresponding functions. To resolve a technical problem in innovative design, designers usually try to find the appropriate effects relevant to the required function. So it is very important to retrieve effect in terms of its function. This paper explores ontology-based functional semantic retrieval for effects knowledge base. To enhance the reasoning ability, the functional semantics of effects is represented as <;input flow list, action verb, output flow list>; in this paper. And functional ontology is used to expand the functional keywords in order to provide a variety of retrieval cues and trigger design inspiration. Using the functional semantic retrieval, designers obtain the lists of effects and/or chains of effects relevant to the required function, which greatly widen the solution space and increase opportunities for product innovation.","2157-3611;21573611","Electronic:978-1-4577-0739-1; POD:978-1-4577-0740-7; USB:978-1-4577-0738-4","10.1109/IEEM.2011.6117996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6117996","effects knowledge base;functional semantic retrieval;innovative design;ontology reasoning","Cognition;Educational institutions;Knowledge based systems;Ontologies;Product design;Semantics;Technological innovation","information retrieval;knowledge based systems;ontologies (artificial intelligence)","functional ontology;knowledge base;ontology-based functional semantic retrieval;product innovation","","0","","38","","","6-9 Dec. 2011","","IEEE","IEEE Conference Publications"
"Infrastructure for sharing standardized clinical brain scans across hospitals","T. G. M. van Erp; A. L. Chervenak; C. Kesselman; M. D'Arcy; J. Sobell; D. Keator; L. Dahm; J. Murry; M. Law; A. Hasso; J. Ames; F. Macciardi; S. G. Potkin","Department of Psychiatry and Human Behavior, University of California, Irvine, Irvine, CA, USA","2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20111226","2011","","","1026","1028","Progress in our understanding of brain disorders increasingly relies on costly collection of large standardized brain magnetic resonance imaging (MRI) data sets. Moreover, clinical interpretations of brain scans benefit from compare and contrast analyses of scans from patients with similar, and sometimes rare, demographic, diagnostic, and treatment status. A solution to both needs is to acquire standardized, research-ready clinical brain scans and to build the information technology infrastructure to share such scans, along with other pertinent information, across hospitals. The resulting research-ready brain imaging resource would provide a wealth of accessible standardized brain imaging data relevant to patient care and research. This paper describes a pilot project that develops such a brain resource, including the rationale, the short imaging protocol, the access to patient data, and the system architecture. This pilot project is a joined effort by researchers from the Clinical Translational Science Institutes (CTSIs) at the University of California Irvine (UCI) and University of Southern California (USC) with strong support from the Biomedical Informatics Research Network (BIRN). The pilot system developed enables capture and sharing of standardized, de-identified clinical brain images across institutions via a federated database system.","","Electronic:978-1-4577-1613-3; POD:978-1-4577-1612-6","10.1109/BIBMW.2011.6112547","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112547","MRI;architecture;brain;de-identification;federation;health;hospitals;imaging;infrastructure;open source;pilot;protocol;sharing;standardizatoin","DICOM;Databases;Educational institutions;Hospitals;Logic gates;Protocols","biomedical MRI;brain;information networks;information resources;information retrieval;medical information systems;standardisation;visual databases","BIRN;Biomedical Informatics Research Network;Clinical Translational Science Institute;University of California Irvine;University of Southern California;brain disorders;federated database system;information technology infrastructure;magnetic resonance imaging;patient data access;research ready brain imaging resource;research ready clinical brain scans;standardized brain MRI data sets;standardized clinical brain scan sharing infrastructure;standardized clinical brain scans;system architecture","","1","","15","","","12-15 Nov. 2011","","IEEE","IEEE Conference Publications"
"Performance Analysis of the Single Pattern Matching Algorithm Based on Prefix Searching","W. Xi-hong","Sch. of Comput. Sci., Jiaying Univ., Meizhou, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","1024","1027","Intrusion Detection System has become the important part of the computer and network security because it can effectively compensate for the lack of network security measures. However, the intrusion detection technology relies heavily on pattern matching algorithms, as the choice of pattern matching algorithms directly affect the detection rate, so it is more important. First the paper is detailed analysis the characteristics of the four kinds of single pattern matching which based on prefix search, and then it tests by the number of different pattern strings. The experimental results show that the KMP algorithm can improve effectively the speed of pattern matching. So the application of KMP algorithm can improve the efficiency of intrusion detection.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128279","KMP algorithm;network security;prefix searching;single pattern matching algorithm","Algorithm design and analysis;Arrays;Classification algorithms;Complexity theory;Intrusion detection;Pattern matching","computer network security;information retrieval;string matching","IDS;KMP algorithm;computer security;intrusion detection system;network security;pattern strings;performance analysis;prefix searching;single pattern matching algorithm","","0","","8","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"An LIRS-Based Replica Replacement Strategy for Data-Intensive Applications","W. Liu; F. Shi; W. Du","Coll. of Comput. Sci. & Technol, Wuhan Univ. of Technol., Wuhan, China","2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications","20120102","2011","","","1381","1386","Data Replication, creating identical copies of data on different sites geographically, is one of the effective optimization techniques for reducing data access costs and improving load balance among sites in data-intensive computing. However, due to the limitation of storage capacity of each site, an efficient replica replacement can make a significant difference in the performance and efficiency of replication technologies. In this paper, for the inability of LRU to cope with access patterns with weak locality, a novel replacement strategy called Low Inter- reference Recency Set (LIRS) was applied into replica replacement during data replication. And then, OptorSim was extended, and LIRS replica replacement algorithm was implemented. Finally, LIRS replacement strategy was comprehensively compared with other algorithms including LRU, MRU LFU and MFU by use of different scheduling algorithms and file access patterns, and the results show that LIRS replacement algorithm can improve the performance of the data access, especially under access pattern with weak locality.","2324-898X;2324898X","Electronic:978-0-7695-4600-1; POD:978-1-4577-2135-9","10.1109/TrustCom.2011.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120984","LIRS;LRU;OptorSim;resource replacement","Algorithm design and analysis;Educational institutions;History;Optimization;Prediction algorithms;Scheduling;Scheduling algorithm","cost reduction;file organisation;information retrieval;optimisation;replicated databases;resource allocation","LIRS-based replica replacement strategy;data access costs;data replication;data-intensive computing;file access pattern;load balance;low interreference recency set;optimization;replication technology;storage capacity","","1","","18","","","16-18 Nov. 2011","","IEEE","IEEE Conference Publications"
"Delegation-Based I/O Mechanism for High Performance Computing Systems","A. Nisar; W. k. Liao; A. Choudhary","University of California Santa Cruz, Santa Cruz","IEEE Transactions on Parallel and Distributed Systems","20111226","2012","23","2","271","279","Massively parallel applications often require periodic data checkpointing for program restart and post-run data analysis. Although high performance computing systems provide massive parallelism and computing power to fulfill the crucial requirements of the scientific applications, the I/O tasks of high-end applications do not scale. Strict data consistency semantics adopted from traditional file systems are inadequate for homogeneous parallel computing platforms. For high performance parallel applications independent I/O is critical, particularly if checkpointing data are dynamically created or irregularly partitioned. In particular, parallel programs generating a large number of unrelated I/O accesses on large-scale systems often face serious I/O serializations introduced by lock contention and conflicts at file system layer. As these applications may not be able to utilize the I/O optimizations requiring process synchronization, they pose a great challenge for parallel I/O architecture and software designs. We propose an I/O mechanism to bridge the gap between scientific applications and parallel storage systems. A static file domain partitioning method is developed to align the I/O requests and produce a client-server mapping that minimizes the file lock acquisition costs and eliminates the lock contention. Our performance evaluations of production application I/O kernels demonstrate scalable performance and achieve high I/O bandwidths.","1045-9219;10459219","","10.1109/TPDS.2011.166","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5871604","I/O delegation;MPI-IO;Parallel I/O;collaborative caching;file locking.;non collective I/O;parallel file systems","Bandwidth;Benchmark testing;Kernel;Multicore processing;Optimization;Performance evaluation;Servers","client-server systems;data analysis;data integrity;file organisation;information retrieval;input-output programs;optimisation;parallel architectures;parallel programming;performance evaluation;software architecture","I-O optimization;I-O request;I-O serialization;client-server mapping;delegation-based I-O mechanism;file lock acquisition cost;file system layer;high I-O bandwidth;high end application;high performance computing system;high performance parallel application;homogeneous parallel computing platform;large scale system;lock contention;parallel I-O architecture;parallel program;parallel storage system;performance evaluation;periodic data checkpointing;post-run data analysis;process synchronization;production application I-O kernel;software design;static file domain partitioning method;strict data consistency semantics;unrelated I-O access","","5","1","19","","20110609","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"A fuzzy-based recommender approach for learning objects management systems","F. P. Romero; M. Ferreira-Satler; J. A. Olivas; M. E. Prieto-Mendez; V. H. Menendez-Dominguez","Department of Information Systems and Technologies, University of Castilla-La Mancha, Ciudad Real, Spain","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","984","989","This paper shows how some fuzzy logic tecniques applied to a recommender engine can be used in a Learning Object Repository. A Fuzzy Linguistic model based on three dimensions: structural, contextual, personal is proposed. The contextual and personal dimensions are modelled using domain ontologies and a automatically built fuzzy ontology, respectively. The experiment results indicate that the presented approach is useful and warrants further research in recommending and retrieval information.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121786","Fuzzy Logic;Fuzzy Ontology;Learning Object;Recommender Systems","Context;Context modeling;Electronic learning;Ontologies;Pragmatics;Proposals;Recommender systems","computer aided instruction;fuzzy logic;information retrieval;ontologies (artificial intelligence);recommender systems","domain ontologies;fuzzy based recommender approach;fuzzy linguistic model;fuzzy logic tecniques;fuzzy ontology;learning object repository;learning objects management systems;recommender engine;recommending information;retrieval information","","1","","30","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"Information Extraction Using Web Usage Mining, Web Scrapping and Semantic Annotation","S. K. Malik; S. Rizvi","Univ. Sch. of Inf. Technol., GGS Indraprastha Univ., New Delhi, India","2011 International Conference on Computational Intelligence and Communication Networks","20111229","2011","","","465","469","Extracting useful information from the web is the most significant issue of concern for the realization of semantic web. This may be achieved by several ways among which Web Usage Mining, Web Scrapping and Semantic Annotation plays an important role. Web mining enables to find out the relevant results from the web and is used to extract meaningful information from the discovery patterns kept back in the servers. Web usage mining is a type of web mining which mines the information of access routes/manners of users visiting the web sites. Web scraping, another technique, is a process of extracting useful information from HTML pages which may be implemented using a scripting language known as Prolog Server Pages(PSP) based on Prolog. Third, Semantic annotation is a technique which makes it possible to add semantics and a formal structure to unstructured textual documents, an important aspect in semantic information extraction which may be performed by a tool known as KIM(Knowledge Information Management). In this paper, we revisit, explore and discuss some information extraction techniques on web like web usage mining, web scrapping and semantic annotation for a better or efficient information extraction on the web illustrated with examples.","","Electronic:978-0-7695-4587-5; POD:978-1-4577-2033-8","10.1109/CICN.2011.97","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112910","KIM;Prolog;Prolog Server Pages;Semantic Web;Text Grepping;Web Log Analyzer;Web Mining;Web Scrapping;Web Usage Mining;knowledge management;semantic annotation","Browsers;HTML;Semantics;Web mining;Web servers","PROLOG;Web sites;authoring languages;data mining;hypermedia markup languages;information retrieval;semantic Web;text analysis","HTML pages;Prolog Server Pages;Web scrapping;Web sites;Web usage mining;access routes;scripting language;semantic Web;semantic annotation;semantic information extraction;unstructured textual documents","","1","","14","","","7-9 Oct. 2011","","IEEE","IEEE Conference Publications"
"Instrumenting and monitoring the LarKC reasearch infrastructure","R. Krummenacher; I. Toma; D. Fensel; R. Brehar; S. Nedevschi","Semantic Technology Institute, University of Innsbruck, Technikerstr. 21a, A-6020, Austria","2011 IST-Africa Conference Proceedings","20111219","2011","","","1","8","Reasoning is central to the idea of the Semantic Web and ontologies, however, the fundamental principles of reasoning - soundness and completeness - do not match the reality of the (Semantic) Web that is ruled by contradicting and incomplete data and claims. Furthermore, logical reasoning is strong for rather small numbers of axioms and facts, while the Web is growing at an impressive speed and hence offering tremendous amounts of data. `Reasearch' is a novel idea of combining reasoning with information retrieval methods (search) in order to respond to the requirements and constraints implied by reasoning on the Semantic Web. The Large Knowledge Collider is a modular reasoning platform that allows for reasearching with Web-scale data, and instrumenting and monitoring the platform is essential for verifying and assuring high performance, adaptability and well-functioning. These aspects are vital for experiments running on the platform.","","Electronic:978-1-905824-26-7; POD:978-1-4577-1077-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107361","Instrumentation and Monitoring;Reasoning;Semantic Web","Cognition;Instruments;Knowledge engineering;Measurement;Monitoring;Semantic Web;Semantics","inference mechanisms;information retrieval;ontologies (artificial intelligence);semantic Web","LarKC reasearch infrastructure;Web-scale data;completeness reasoning principle;information retrieval methods;large knowledge collider;logical reasoning;ontologies;semantic Web;soundness reasoning principle","","0","","14","","","11-13 May 2011","","IEEE","IEEE Conference Publications"
"Knowledge Discovery in Text Mining Technique Using Association Rules Extraction","V. Bhujade; N. J. Janwe","","2011 International Conference on Computational Intelligence and Communication Networks","20111229","2011","","","498","502","This paper describes text mining technique for automatically extracting association rules from collections of textual documents. The technique called, Extracting Association Rules from Text (EART). It depends on keyword features for discover association rules amongst keywords labeling the documents. EART system ignores the order in which the words occur, but instead focusing on the words and their statistical distributions in documents. The system based on Information Retrieval scheme (TF-IDF) for selecting most important keywords for association rules generation. It consists of three phases: Text Preprocessing phase (transformation, filtration, stemming and indexing of the documents), Association Rule Mining (ARM) phase (applying our designed algorithm for Generating Association Rules based on Weighting scheme GARW) and Visualization phase (visualization of results). Experiments applied on Online WebPages related to the cryptography. The extracted association rules contain important features.","","Electronic:978-0-7695-4587-5; POD:978-1-4577-2033-8","10.1109/CICN.2011.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112917","Association Rules;Data Mining;Knowledge Discovery;Text Mining","Communication systems;Computational intelligence","cryptography;data mining;data visualisation;information retrieval;statistical distributions;text analysis","Online WebPages;association rule mining phase;association rules extraction;cryptography;information retrieval scheme;knowledge discovery;statistical distribution;text mining;text preprocessing phase;visualization phase","","1","","16","","","7-9 Oct. 2011","","IEEE","IEEE Conference Publications"
"Earth Observation and Environmental Modelling for the Mitigation of Health Risks such as cholera, cardio-vascular and respiratory diseases","I. Simonis; M. Van Der Merwe","Open Geospatial Consortium (Europe) Ltd., 8 Coldbath Square, London, EC1R 5HL, UK","2011 IST-Africa Conference Proceedings","20111219","2011","","","1","8","Despite many national and international initiatives and research projects that started in the past, the complex relationships between environmental factors and their impact on human health still bear numerous unsolved challenges and unknown links. In addition, natural as well as human introduced changes to the environment lead to continuously changing framework conditions, which itself cause new obstacles and challenges for the earth observation and health research communities. Key to a resource-efficient and cost effective research of cross-community correlations is the easy access to data sets and processing capacities, which are ideally based on common modelling approaches and representation models. This paper illustrates the recent results of the African-European integrated research project called EO2HEAVEN that tackles the questions of integrated research using state-of-the art internet technologies, applications, and architectural principles to shed more light on the complex correlations of environmental factors and health aspects such as cholera and cardio-vascular diseases.","","Electronic:978-1-905824-26-7; POD:978-1-4577-1077-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107368","Earth Observation;Health;Spatial Data Infrastructure;eInfrastructures","Africa;Communities;Correlation;Diseases;Earth;Environmental factors;Humans","Internet;cardiovascular system;diseases;environmental factors;health care;information retrieval;medical computing","African-European integrated research project;EO2HEAVEN;Earth observation;Internet technology;cardiovascular disease;cholera;cross-community correlations;data access;environmental factors;environmental impact;environmental modelling;health research communities;health risk mitigation;representation model;resource-efficient research;respiratory diseases","","0","","12","","","11-13 May 2011","","IEEE","IEEE Conference Publications"
"Sentiment Value Propagation for an Integral Sentiment Dictionary Based on Commonsense Knowledge","H. H. Wu; A. C. R. Tsai; R. T. H. Tsai; J. Y. j. Hsu","Dept. of CSIE, Nat. Taiwan Univ., Taipei, Taiwan","2011 International Conference on Technologies and Applications of Artificial Intelligence","20120102","2011","","","75","81","With the rise of social media, sentiment analysis has become a popular research field in recent years. A sentiment dictionary plays an important role in sentiment analysis. To remedy the lack of Chinese sentiment dictionary, researches translate English sentiment dictionaries to Chinese before using them in their applications. However, cultural difference often causes such translations inaccurate. Moreover, some of the dictionaries have small vocabulary size and some of the dictionaries have only polarity labels or even no label instead of value labels. In the first part of the paper, we integrated several common sentiment dictionaries to get the sentiment seeds. Then, we proposed a self-training sentiment spreading activation to expand the sentiment values on Chinese Concept Net. Finally, we derived iSentiDictionary, a Chinese sentiment dictionary with 28,248 concepts and corresponding sentiment values.","2376-6816;23766816","Electronic:978-0-7695-4601-8; POD:978-1-4577-2174-8","10.1109/TAAI.2011.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120723","Commonsense Knowledge;Sentiment Analysis;Sentiment Dictionary","Accuracy;Dictionaries;Educational institutions;Google;Semantics;Vectors;Vocabulary","common-sense reasoning;data mining;dictionaries;emotion recognition;information retrieval;social sciences computing","Chinese ConceptNet;Chinese sentiment dictionary;commonsense knowledge;iSentiDictionary;self-training sentiment;sentiment analysis;sentiment value propagation;social media","","2","","20","","","11-13 Nov. 2011","","IEEE","IEEE Conference Publications"
"A shared context approach for supporting experts in data ETL (Extraction, Transformation and Loading) processes","H. Tahir; P. Brézillon","Laboratory of Computer Science-Paris 6 (LIP6), University Pierre and Marie Curie (UPMC), Paris, France","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","720","725","Many experts in data integration often use standard procedures to accomplish the process of extracting data from the existing source systems in order to be transformed and loaded into new target systems such as a data warehouse or ERP (Enterprise Resource Planning) applications. The process is called ETL (Extraction, Transformation and Loading) process. There are different ways of applying such a process by different actors because they do not have the same viewpoints in the contexts in which the process occurs. To create an effective strategy and minimize risks, actors need to devote their efforts to develop new practices to meet the current business and IT needs, and mainly use past expert experience. The paper presents how to contextualize ETL processes based on different expert viewpoints. We show how making shared context explicit can help to improve the ETL process and, thus, avoid conflicts between experts having different viewpoints. We illustrate our proposal by using a software tool called Contextual Graphs (CxGs). The paper is intended to provide the basis for the development of an experience base that will be used by a support system for data migration experts.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121741","Contextual Graph;Data Integration;ETL;Experience base;Practice;Procedure;Shared Context;Support system;Viewpoint","Business;Context;Context modeling;Data mining;Databases;Intelligent systems;Loading","data integration;graph theory;information retrieval;software tools","ETL;contextual graphs;data extracting process;data integration;data loading process;data migration expert;data transformation;information technology;shared context approach;software tool","","1","","21","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"The Application Study about Lucene in Document Retrieval for Office","D. Wu","Coll. of Media Eng., Weinan Normal Univ., Weinan, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","1554","1556","In order to meet the requirement of quickly retrieving offices' documents for staffs in offices. The article studied and implemented One Full-Text Retrieval system based on Lucene which catered to massive document data retrieval. This system can retrieve lots of frequently-used documents' format. Such as doc, xls, pdf and so on. The application result in actual offices proved that it is provided with high retrieval performance, recall rate and precision rate. It can be satisfied with the requirement of quickly retrieving offices' documents for staffs in offices. If extended, it can be used for the application in C/S or B/S environment, thus it will have wider application perspective.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128389","Full-Text Retrieval;Index;Retrieval;document;office","Engines;Indexing;Portable document format;Text analysis","document handling;information retrieval;office automation","Lucene;document retrieval;frequently-used documents;full-text retrieval system;massive document data retrieval;office documents","","0","","7","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"An iterative strategy for feature construction on a fuzzy rule-based learning algorithm","D. García; A. González; R. Pérez","Departamento de Ciencias de la Computati&#x00F3;n e LA., CITIC-UGR University of Granada (Spain)","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","1235","1240","This paper presents a proposal for using feature construction in a fuzzy rule-based learning algorithm as a method to avoid working with a fixed set of features to describe a particular problem. The main purpose is to increase the amount of information extracted from initial variables to construct a model that has better prediction capability. This approach iteratively looks for the function that obtains the best adaptation level to the examples covered by a rule. If exists, this function is added both to the antecedent of the rule and to a specific structure called catalog of functions in order to be considered by the learning algorithm. For that, a model of rule is used in order to represent this kind of knowledge in combination with the catalog, which helps us to manage the functions that have ever been considered during the learning process. Finally, a comparative study of the results obtained with this approach is presented.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121828","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121828","Classification;Feature Construction;Genetic Fuzzy Systems;Iterative Learning Approach","Catalogs;Databases;Genetic algorithms;Genetics;Input variables;Pragmatics;Training","data mining;feature extraction;fuzzy set theory;information retrieval;iterative methods;learning (artificial intelligence)","catalog of functions;feature construction;fuzzy rule-based learning algorithm;information extraction;iterative strategy;learning process;prediction capability","","0","","23","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"Emotions in Product Reviews--Empirics and Models","D. Garcia; F. Schweitzer","Dept. of Syst. Design, ETH Zurich, Zurich, Switzerland","2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing","20120102","2011","","","483","488","Online communities provide Internet users with means to overcome some information barriers and constraints, such as the difficulty to gather independent information about products and firms. Product review communities allow customers to share their opinions and emotions after the purchase of a product. We introduce a new dataset of product reviews from Amazon.com, with emotional information extracted by sentiment detection tools. Our statistical analysis of this data provides evidence for the existence of polemic reviews, as well as for the coexistence of positive and negative emotions inside reviews. We find a strong bias towards large values in the expression of positive emotions, while negative ones are more evenly distributed. We identified different time dynamics of the creation of reviews dependent on the presence of marketing and word of mouth effects. We define an agent-based model of the users of product review communities using a modeling framework for online emotions. This model can reproduce the scenarios of response to external influences, as well as some properties of the distributions of positive and negative emotions expressed in product reviews. This analysis and model can provide guidelines to manufacturers on how to increase customer satisfaction and how to measure the emotional impact of marketing campaigns through reviews data.","","Electronic:978-0-7695-4578-3; POD:978-1-4577-1931-8","10.1109/PASSAT/SocialCom.2011.219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113152","agent-based modeling;emotions;product reviews","Biological system modeling;Communities;Correlation;Equations;Internet;Mathematical model;Media","Internet;Web sites;customer satisfaction;electronic commerce;information retrieval;multi-agent systems;purchasing;statistical analysis","Amazon.com;Internet users;agent-based model;customer satisfaction;data reviews;emotional impact;emotional information extraction;independent information;information barriers;information constraints;marketing campaigns;modeling framework;negative emotions;online community;online emotions;polemic reviews;positive emotions;product purchase;product review community;product reviews;sentiment detection tools;statistical analysis;time dynamics;word of mouth effects","","4","","15","","","9-11 Oct. 2011","","IEEE","IEEE Conference Publications"
"Social Objects Description and Recommendation in Multidimensional Social Networks: OCSO Ontology and Semantic Spreading Activation","N. Marie; F. Gandon","Alcatel-Lucent Bell Labs., INRIA Villarceaux, Sophia-Antipolis, France","2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing","20120102","2011","","","1415","1420","Two strong tendencies in social networks today are their growing multidimensionality and the key role of social objects around which they crystallize. Growing heterogeneity and amount of social objects start to be an issue for some popular social platforms. Users need more efficient ways to access and navigate information. To achieve this challenge we define OCSO as semantic web schema to describe finely these social objects and their afferent social activity. Then we defend the use of spreading activation algorithms to simulate user interest and perform complex recommendation in multidimensional social networks. A possible approach to what we call semantic spreading activation is introduced in order to exploit, among others, the OCSO model.","","Electronic:978-0-7695-4578-3; POD:978-1-4577-1931-8","10.1109/PASSAT/SocialCom.2011.242","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113318","OCSO;mutidimensional social network;object centered sociality;ontology;semantic spreading activation;semantic web;social object;social semantic web;spreading activation","Conferences;Privacy;Security;Social network services","authorisation;information retrieval;ontologies (artificial intelligence);recommender systems;semantic Web;social networking (online)","OCSO ontology;complex recommendation;multidimensional social networks;semantic Web schema;semantic spreading activation;semantic spreading activation algorithm;social activity;social object description;social object recommendation;user interest","","0","1","23","","","9-11 Oct. 2011","","IEEE","IEEE Conference Publications"
"A Rule-Based Framework of Metadata Extraction from Scientific Papers","Z. Guo; H. Jin","Cluster & Grid Comput. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2011 10th International Symposium on Distributed Computing and Applications to Business, Engineering and Science","20120102","2011","","","400","404","Most scientific documents on the web are unstructured or semi-structured, and the automatic document metadata extraction process becomes an important task. This paper describes a framework for automatic metadata extraction from scientific papers. Based on a spatial and visual knowledge principle, our system can extract title, authors and abstract from scientific papers. We utilize format information such as font size and position to guide the metadata extraction process. The experiment results show that our system achieves a high accuracy in header metadata extraction which can effectively assist the automatic index creation for digital libraries.","","Electronic:978-0-7695-4415-1; POD:978-1-4577-0327-0","10.1109/DCABES.2011.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118700","document metadata;information extraction;rule-based approach","Accuracy;Data mining;Layout;Libraries;Portable document format;Semantics;XML","Internet;digital libraries;document handling;indexing;information retrieval;knowledge based systems;meta data;natural sciences computing","Web;automatic document metadata extraction;automatic index creation;digital libraries;header metadata extraction;rule-based framework;scientific documents;scientific papers;spatial knowledge principle;visual knowledge principle","","1","","12","","","14-17 Oct. 2011","","IEEE","IEEE Conference Publications"
"Building transparent data access for ocean observatories: Coordination of U.S. IOOS DMAC with NSF's OOI Cyberinfrastructure","M. Arrott; C. Alexander; J. Graybeal; C. Mueller; R. Signell; J. de La Beaujardiere; A. Taylor; J. Wilkin; B. Powell; J. Orcutt","Calit2, University of California at San Diego, La Jolla, CA, USA","OCEANS'11 MTS/IEEE KONA","20111219","2011","","","1","9","The NOAA-led U.S. Integrated Ocean Observing System (IOOS) and the National Science Foundation's Ocean Observatories Initiative (OOI) have been collaborating since 2007 on advanced tools and technologies that ensure open access to ocean observations and models. Initial collaboration focused on serving ocean data via cloud computing - a key component of the OOI cyberinfrastructure (CI) architecture. As the OOI transitioned from planning to execution in the Fall of 2009, an OOI/IOOS team developed a customer-based “use case” to align more closely with the emerging objectives of OOI-CI team's first software release scheduled for Summer 2011 and provide a quantitative capacity for stress-testing these tools and protocols. A requirements process was initiated with coastal modelers, focusing on improved workflows to deliver ocean observation data. Accomplishments to date include the documentation and assessment of scientific workflows for two “early adopter” modeling teams from IOOS Regional partners (Rutgers - the State University of New Jersey and University of Hawaii's School of Ocean and Earth Science and Technology) to enable full understanding of data sources and needs; generation of all-inclusive lists of the data sets required and those obtainable through IOOS; a more complete understanding of areas where IOOS can expand data access capabilities to better serve the needs of the modeling community; and development of “data set agents” (software) to facilitate data acquisition from numerous data providers and conversions of the data format to the OOI-CI canonical form.","0197-7385;01977385","Electronic:978-0-933957-39-8; Paper:978-1-4577-1427-6","10.23919/OCEANS.2011.6106983","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106983","DMAC;OOI;U.S. IOOS;coastal modelers;cyberinfrastructure;data access;ocean observatories","Collaboration;Communities;Data models;Educational institutions;Observatories;Oceans;Sea measurements","cloud computing;geophysics computing;information networks;information resources;information retrieval;oceanographic techniques","NS OOI cyberinfrastructure;National Science Foundation;OOI cyberinfrastructure architecture;Ocean Observatories Initiative;School of Ocean and Earth Science and Technology;State University of New Jersey;US IOOS DMAC;US Integrated Ocean Observing System;University of Hawaii's;cloud computing;coastal modelers;customer based use case;data set agents;data sources;ocean data;ocean observation data delivery;ocean observatories;open access;transparent data access","","0","","14","","","19-22 Sept. 2011","","IEEE","IEEE Conference Publications"
"An Automated Approach to Web Service Classification Based on Semantic","Z. Song; X. Tang","Software Coll., Shanghai Jiao Tong Univ., Shanghai, China","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","1207","1210","Web Service classification becomes more essential with the increasing number of Web Services. The current practical approach for management and discovery is based on keyword search techniques. In this paper, we present an approach based on semantic reasoning and ontology techniques in order to organize web services automatically and accurately. And we will verify our approach by comparing with METEOR-S's classification results.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118853","Web Service;Web Service classification;ontology;semantic","Educational institutions;Meteorology;OWL;Ontologies;Semantics;Web services","Web services;inference mechanisms;information retrieval;ontologies (artificial intelligence);pattern classification","Web service classification;automated approach;keyword search techniques;semantic ontology;semantic reasoning","","4","","12","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Reference metadata extraction from scientific papers","Z. Guo; H. Jin","Cluster & Grid Comput. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies","20120102","2011","","","45","49","Bibliographical information of scientific papers is of great value since the Science Citation Index is introduced to measure research impact. Most scientific documents available on the web are unstructured or semi-structured, and the automatic reference metadata extraction process becomes an important task. This paper describes a framework for automatic reference metadata extraction from scientific papers. Our system can extract title, author, journal, volume, year, and page from scientific papers in PDF. We utilize a document metadata knowledge base to guide the reference metadata extraction process. The experiment results show that our system achieves a high accuracy.","2379-5352;23795352","Electronic:978-0-7695-4564-6; POD:978-1-4577-1807-6","10.1109/PDCAT.2011.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118965","metadata extraction;reference;rule-based approach","Accuracy;Data mining;Hidden Markov models;Knowledge based systems;Libraries;Portable document format;Semantics","Internet;citation analysis;document handling;information retrieval;knowledge based systems;meta data;natural sciences computing","Bibliographical Information;Web;automatic reference metadata extraction process;document metadata knowledge base;science citation index;scientific documents;scientific papers;semistructured metadata extraction process;unstructured metadata extraction process","","0","","13","","","20-22 Oct. 2011","","IEEE","IEEE Conference Publications"
"A Multidimensional Sequence Approach to Measuring Tree Similarity","Z. Lin; H. Wang; S. McClean","University of Ulster at Jordanstown, United Kingdom","IEEE Transactions on Knowledge and Data Engineering","20111222","2012","24","2","197","208","Tree is one of the most common and well-studied data structures in computer science. Measuring the similarity of such structures is key to analyzing this type of data. However, measuring tree similarity is not trivial due to the inherent complexity of trees and the ensuing large search space. Tree kernel, a state of the art similarity measurement of trees, represents trees as vectors in a feature space and measures similarity in this space. When different features are used, different algorithms are required. Tree edit distance is another widely used similarity measurement of trees. It measures similarity through edit operations needed to transform one tree to another. Without any restrictions on edit operations, the computation cost is too high to be applicable to large volume of data. To improve efficiency of tree edit distance, some approximations were introduced into tree edit distance. However, their effectiveness can be compromised. In this paper, a novel approach to measuring tree similarity is presented. Trees are represented as multidimensional sequences and their similarity is measured on the basis of their sequence representations. Multidimensional sequences have their sequential dimensions and spatial dimensions. We measure the sequential similarity by the all common subsequences sequence similarity measurement or the longest common subsequence measurement, and measure the spatial similarity by dynamic time warping. Then we combine them to give a measure of tree similarity. A brute force algorithm to calculate the similarity will have high computational cost. In the spirit of dynamic programming two efficient algorithms are designed for calculating the similarity, which have quadratic time complexity. The new measurements are evaluated in terms of classification accuracy in two popular classifiers (k-nearest neighbor and support vector machine) and in terms of search effectiveness and efficiency in k-nearest neighbor similarity search, using three differ- nt data sets from natural language processing and information retrieval. Experimental results show that the new measurements outperform the benchmark measures consistently and significantly.","1041-4347;10414347","","10.1109/TKDE.2010.239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645628","All common subsequences;approximate tree edit distance;dynamic time warping;the longest common subsequence;tree edit distance;tree kernel;tree similarity.","Algorithm design and analysis;Approximation methods;Complexity theory;Heuristic algorithms;Kernel;Natural language processing;Time measurement","information retrieval;natural language processing;support vector machines;tree data structures","art similarity measurement;brute force algorithm;data structure;dynamic time warping;edit operation;information retrieval;k-nearest neighbor similarity search;multidimensional sequence approach;natural language processing;quadratic time complexity;sequence representation;sequential dimension;sequential similarity;spatial dimension;support vector machine;tree edit distance;tree kernel;tree similarity","","7","","44","","20101129","Feb. 2012","","IEEE","IEEE Journals & Magazines"
"Extracting biomedical concepts from fulltext by relative importance in a graph model","M. Song; S. Bleik; H. Yu; W. S. Han","Information, Systems, New Jersey, Institute of Technology","2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20111226","2011","","","586","593","Extracting concepts from fulltext data collections is a daunting task in that many different concepts and themes are intertwined and ample term variation exists in fulltext. Concepts represent topics or themes of a article and are helpful means of managing and searching large document collections. In addition, automatically extracting and assigning concepts play a pivotal role in indexing electronic documents and building digital libraries. In this paper we propose a novel approach to biomedical concept extraction by adopting a ranking algorithm of relative importance in concept graphs. The proposed consists of two major steps: First, we represent full-text documents by graphs whose nodes and edges are determined by named entity recognition and UMLS Semantic Network. Second, we rank concepts with relative importance algorithms. We evaluate our technique with a set of biomedical full-texts and compare it to various different key-phrase extraction and graph ranking techniques. The experimental results show that our technique achieves the best performance over other compared algorithms.","","Electronic:978-1-4577-1613-3; POD:978-1-4577-1612-6","10.1109/BIBMW.2011.6112433","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112433","","Algorithm design and analysis;Data mining;Feature extraction;Libraries;Markov processes;Semantics;Unified modeling language","document handling;indexing;information retrieval;medical computing;semantic networks","UMLS semantic network;biomedical concept extraction;digital libraries;electronic document indexing;full text data collections;full text documents;graph model;graph ranking techniques;key phrase extraction;large document collections;named entity recognition;ranking algorithm","","0","","40","","","12-15 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Web Text Extraction Method Based on Regular Expressions and Text Density","F. Li","Public Manage. Sch., Fuzhou Univ., Fuzhou, China","2011 International Conference on Information Management, Innovation Management and Industrial Engineering","20111229","2011","1","","287","290","With the advantages of some current web text extraction algorithms, this paper puts forward a new method based on the combination of the regular expressions and density of page text, the method firstly uses the regular expressions to clear the html tags by the characteristics of the web page source code, and then extracts the main text of page with the distribution density of text. The algorithm is simple and efficient and the method proves to have higher accuracy for extraction after tests.","2155-1456;21551456","Electronic:978-1-61284-453-4; POD:978-1-61284-450-3","10.1109/ICIII.2011.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6115483","Regular expressions;Text density;Text extraction;Web page","Accuracy;Algorithm design and analysis;Data mining;Feature extraction;HTML;Noise;Web pages","Internet;hypermedia markup languages;information retrieval;text analysis","HTML tags;Web page source code;Web text extraction method;regular expressions;text density","","0","","6","","","26-27 Nov. 2011","","IEEE","IEEE Conference Publications"
"LetSurf -- Implementing Collaborative Surfing","M. Bedekar; B. A. Rao; P. Gupta; S. Chatterjee","","2011 Fourth International Conference on Emerging Trends in Engineering & Technology","20120102","2011","","","8","11","Collaborative caching and browsing allow a group of users to utilize internet bandwidth in an optimal manner by minimizing outgoing requests and allowing cooperation during web research activities. Let Surf allows a group of clients to retrieve cached materials from within the group while collaborating through a user interface to access items indicative of group behavior, such as the most recent links visited by peer users and the most popular links visited. An implementation of the system is presented and evaluated in terms of latency in loading a sample set of web elements.","2157-0477;21570477","Electronic:978-0-7695-4561-5; POD:978-1-4577-1847-2","10.1109/ICETET.2011.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120545","Caching;Collaboration;Distributed Computing;Human-Computer Interaction","Collaboration;Databases;IP networks;Internet;Peer to peer computing;Servers;User interfaces","Internet;groupware;human computer interaction;information retrieval;online front-ends;user interfaces","Internet bandwidth;LetSurf;Web element;Web research activity;cached material retrieval;collaborative browsing;collaborative caching;collaborative surfing;group behavior;user interface","","0","","12","","","18-20 Nov. 2011","","IEEE","IEEE Conference Publications"
"Browsing catalogue graphs: Content caching supercharged!!","J. Chakareski","Signal Processing Laboratory - LTS4, Ecole Polytechnique F&#x00E9;d&#x00E9;rale de Lausanne (EPFL), Lausanne, Switzerland","2011 18th IEEE International Conference on Image Processing","20111229","2011","","","2429","2432","We consider a generic scenario of content browsing where a client is presented with a catalogue of items of interest. Upon the selection of an item from a page of the catalogue, the client can choose the next item to browse from a list of related items presented on the same page. The system has limited resources to have all items available for immediate access by the browsing client. Therefore, it pays a penalty when the client selects an unavailable item. Conversely, there is a reward that the system gains when the client selects an immediately available item. We formulate the optimization problem of selecting the subset of items that the system should have for immediate access such that its profit is maximized, for the given system resources. We design two techniques for solving the optimization problem in linear time, as a function of the catalogue size. We examine their performance via numerical simulations that reveal their core properties. We also study their operation on actual YouTube data and compare their efficiency relative to conventional solutions. Substantial performance gains are demonstrated, due to accounting for the content graph imposed by the catalogue of items.","1522-4880;15224880","Electronic:978-1-4577-1303-3; POD:978-1-4577-1304-0; USB:978-1-4577-1302-6","10.1109/ICIP.2011.6116134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6116134","","Complexity theory;Conferences;Image processing;Optimized production technology;Videos;YouTube","cataloguing;graphs;information retrieval;optimisation;social networking (online)","YouTube data;browsing client;content browsing catalogue graph;content caching supercharge;conventional solution;numerical simulation;optimization problem;performance gain","","1","","7","","","11-14 Sept. 2011","","IEEE","IEEE Conference Publications"
"Architecture for Component Library Retrieval on the Cloud","G. Junwei; T. Cong; F. Yiqiu","Libr. of Chongqing Univ. of Posts & Telecommun., Chongqing, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","536","539","The Component Library(CL)is the key to realize software reuse, the CL available on the network is decentralized, independent, not easy to access at present and existing component libraries face infrastructure supply and maintenance challenges. The authors use cloud computing model, which contribute to resolve the issues of visiting different component libraries and the scalability of component library resources. In this paper, we discuss the plan that placed the CL in the cloud infrastructure and put forward a hierarchical organizational model of component resources based on cloud storage to achieve component integration services. We also explore the component library retrieval framework in the cloud and verify the cloud model applied to component library retrieval based on the Hadoop platform can improve the system performance and achieve the scalability of the computing power.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128180","MapReduce;cloud computing;component storage;library;retrieval architecture","Cloud computing;Computational modeling;Computer architecture;Indexes;Libraries;XML","cloud computing;information retrieval;software architecture;software libraries;software maintenance;software performance evaluation;software reusability","Hadoop platform;cloud computing model;cloud infrastructure;component integration services;component library resources;component library retrieval;hierarchical organizational model;infrastructure supply;maintenance challenges;software reuse;system performance improvement","","0","","12","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"CHANET: A content-centric architecture for IEEE 802.11 MANETs","M. Amadeo; A. Molinaro","University &#x201C;Mediterranea&#x201D; of Reggio Calabria - DIMET Department, Italy","2011 International Conference on the Network of the Future","20120112","2011","","","122","127","Content-centric networking is a new communication paradigm conceived for Future Internet architectures. It supports content search and delivery without any reference to the location where data can be retrieved from. It also exploits in-network caching to provide fast delivery and distribute the network load. This communication model is promising for mobile wireless networks with intermittent connectivity, like MANETs. In this paper, we present CHANET, a content-centric MANET that is built on a connectionless layer designed on top of legacy IEEE 802.11 protocols to provide content-based routing and transport functionality without relying on the TCP/IP protocol suite.","","Electronic:978-1-4577-1607-2; POD:978-1-4577-1605-8","10.1109/NOF.2011.6126671","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126671","Content Centric Networking;Future Internet;Mobile Ad-hoc Networks","Ad hoc networks;IEEE 802.11 Standards;IP networks;Internet;Mobile communication;Mobile computing;Protocols","Internet;content management;information retrieval;mobile ad hoc networks;telecommunication network routing;transport protocols;wireless LAN","CHANET;IEEE 802.11 MANET;TCP-IP protocol;connectionless layer design;content search;content-based routing;content-based transport;content-centric architecture;data retrieval;future Internet architecture;in-network caching;intermittent connectivity;mobile wireless network;network load distribution","","12","2","17","","","28-30 Nov. 2011","","IEEE","IEEE Conference Publications"
"Implementing ITS 3.0 Applications by Integrating Ruby on Rails, Sesame and Protegè Technologies","A. Faro; C. Spampinato","Dept. of Electr., Electron. & Comput. Eng., Univ. of Catania, Catania, Italy","2011 Seventh International Conference on Signal Image Technology & Internet-Based Systems","20120102","2011","","","62","68","As known, the new generation of Intelligent Transportation Systems (ITSs) is evolving towards a geo-referenced semantic system, denoted in the paper as ITS 3.0, highly permeated by the Web 3.0 technology. More explicitly, ITS 3.0 is a set of databases dealing with geospatial, administrative and business information to be interconnected by a standard data scheme to allow mobile users to access the relevant ITS information through a suitable geo-referenced semantic interface. Although many models have been proposed for semantically structuring the main location based services by means of conceptual taxonomies or entity relations, few real ITSs work in this way. Thus, aim of the paper is to discuss how effective semantic ITSs can be implemented in practice by three technologies: the first devoted to implement user centered processes (Ruby on Rails), the second aiming at integrating the disparate data sources featuring the ITS applications by a suitable data ontology (Protegè), the third to provide the user processes with the needed data (Sesame). Both theoretical considerations and practical issues will be taken into account to build safe and live ITS applications that meet the user practices.","","Electronic:978-0-7695-4635-3; POD:978-1-4673-0431-3","10.1109/SITIS.2011.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120630","Applications of Semantic-Driven Approaches;On-tology based Systems;Semantic Services for Mobile Users","Databases;Mobile communication;OWL;Ontologies;Resource description framework;Semantics;Servers","automated highways;geographic information systems;information retrieval;mobile computing;ontologies (artificial intelligence);semantic Web","ITS 3.0;Web 3.0 technology;administrative information processing;business information processing;conceptual taxonomy;geo-referenced semantic interface;geospatial information;information access;intelligent transportation systems;location based services;mobile users;ontology;semantic Web;user centered processes","","3","","35","","","Nov. 28 2011-Dec. 1 2011","","IEEE","IEEE Conference Publications"
"MERLINGO - the adaptation and accessible distribution of study materials on the basis of rich-media for the support of the learning process in students with special needs","I. Martiník","Faculty of Economics V&#x0160;B-Technical University of Ostrava, Sokolsk&#x00E1; Street 33, 701 21, Czech Republic","2011 IST-Africa Conference Proceedings","20111219","2011","","","1","7","MERLINGO (MEdia-rich Repository of LearnING Objects) project based on the rich-media technologies application in the eLearning environment is aimed at the building of the central repository of multimedia learning objects in the distributed environment containing teachers' presentations accessible on-line and on-demand within the national academic computer network CESNET2. The article presents integration of its services with the chosen Accordent Media Management System programming system and the possibilities of this new technology. The support of integration of students with special needs into a learning system is a brand new aspect of MERLINGO project activities being currently aimed at the area of the methodology development enabling the adaptation of study materials developed by rich-media technologies, their accessible distribution for students with specials needs and pilot implementation of those adapted study materials, expansion of services of the central repository MERLINGO by a possibility of the indexation and browsing in audio records, the introduction of accessible multi-channel audio-visual communication service and finally, the expansion and improvement of services provided by support centers for students with special needs across participating universities.","","Electronic:978-1-905824-26-7; POD:978-1-4577-1077-3","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107367","Accordent;CESNET2;MERLINGO;eLearning;handicapped students;rich-media","Educational institutions;Handicapped aids;Media;Multimedia communication;Servers","audio-visual systems;computer aided instruction;distributed processing;indexing;information retrieval;multimedia communication","Accordent media management system;CESNET2;MERLINGO project;accessible multichannel audio-visual communication service;accessible study material distribution;audio record browsing;audio record indexation;distributed environment;eLearning environment;learning process support;media-rich repository of learning objects;multimedia learning objects;national academic computer network;on-line accessible teacher presentations;rich-media technologies application;special need students;students support centers","","0","","17","","","11-13 May 2011","","IEEE","IEEE Conference Publications"
"On Data Staging Strategies for Mobile Accesses to Cloud Services","Y. Wang; B. Veeravalli; C. K. Tham","Dept. of Electr. & Comput. Eng., Nat. Univ. of Singapore, Singapore, Singapore","2011 Fourth IEEE International Conference on Utility and Cloud Computing","20120109","2011","","","245","252","In this paper, we design and develop time-efficient algorithms that identify vantage locations to stage a shared data item for the ease of mobile accesses. As mobile users will be charged on the use of communication bandwidth as well as on the fraction of the time the storage resources are kept busy on their respective data, we aim to provide such access for a class of mobile users using Cloud services with minimum total cost. To this end, we adopt a homogeneous cost model and network model used in [1], and consider this problem under a practical restriction that the maximum number of instant copies is bounded by a given constant k. We first study this optimal problem without constraints and then investigate the constrained version by limiting the relationship between the communication cost C and caching (storage) cost S of a copy of the requested data and point out the limitation of this method. For arbitrary C and S, we propose three heuristic algorithms to this problem. All the proposed algorithms are built upon the optimal solution (using dynamic programming (DP)) without constraints on the number of copies, but leverage different strategies to respect the constraint while minimizing the cost. We shown that they have the same time complexity but exhibit different actual performance in different situations. We validate our findings via extensive simulation studies.","","Electronic:978-0-7695-4592-9; POD:978-1-4577-2116-8","10.1109/UCC.2011.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123504","Cloud;data staging and caching;mobile access;resource constraints","Algorithm design and analysis;Complexity theory;Heuristic algorithms;Measurement;Mobile communication;Nickel;Schedules","cache storage;cloud computing;computational complexity;information retrieval;mobile computing;service-oriented architecture","caching cost;cloud service;communication bandwidth;communication cost;data staging strategy;homogeneous cost model;mobile access;network model;storage resource;time complexity;time-efficient algorithm;vantage location","","0","","12","","","5-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"The Dynamic Retrieval Tree Menu Based on Dojo","X. Zhang; Y. Cao; X. Mu","Transp. Manage. Coll., Dalian Maritime Univ., Dalian, China","2011 International Conference of Information Technology, Computer Engineering and Management Sciences","20111229","2011","1","","202","205","In order to offer correct and perfect classification design for users to find what they need quickly and conveniently, a tree menu with classification and level division for some objects is used in this paper. By introducing Dojo widget, JSON format and Ajax technology can solve the classified and level divisive problem with different categories of objects. For illustration, a dynamic retrieval tree menu is utilized to show the classification and level division. The practice results show that the Dojo widget with modular JavaScript library will be used as the appropriate selection in solving the classified and level divisive problem. The dynamic retrieval tree menu based on Dojo can realize the directory structure which is similar to the using in files directory management, and with a retrieval function, this tree menu makes maintenance more convinient.","","Electronic:978-0-7695-4522-6; POD:978-1-4577-1419-1","10.1109/ICM.2011.116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113392","Dojo;Dynamic;Retrieval Function;Tree Menu","Arrays;Blogs;Browsers;Data models;Databases;Vegetation;XML","Java;information retrieval;pattern classification;software libraries;tree data structures;user interfaces","Ajax technology;Dojo widget;JSON format;classification design;directory structure;dynamic retrieval tree menu;file directory management;level divisive problem;modular JavaScript library","","0","","11","","","24-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"Statistical estimation of emotions in speech notes by featured term analogy","K. K. Sita; S. Suhasini; Z. P. Shaik Mohd.","Department of Information Technology, V. R. Siddhartha Engineering College, Vijayawada, A.P., INDIA","2011 International Conference on Image Information Processing","20111222","2011","","","1","6","Human Being is the only creature in the World who can express his emotions in various forms. Capturing the extent of emotions in a particular speech notes through quantification of verbal expressions is undoubtedly a challenging area to study. Either positive or negative, whatever be the emotions are in the notes, if we succeed in assessing the degree of positiveness or negativeness, the impact of the notes while addressing to the intended people can be pre-estimated easily. This paper presents a brief idea of how we can statistically estimate the emotional characteristics of a speech notes by analyzing the content in the speech notes through Information Extraction. Since it is mandatory for any sentence to have atleast a verb, we primarily concentrate on the verbs as featured terms in each sentence and there by statistically estimate the rigorousness of the verb on the entire speech note. The strength of the verb in its severity can be measured by comparing it with strong, medium, light corpus of emotions developed specially. This enables to judge the effectiveness of a speech notes in various emotions.","","Electronic:978-1-61284-861-7; POD:978-1-61284-859-4","10.1109/ICIIP.2011.6108899","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6108899","Emotion Estimator;Feature Term Identification (FTI);Inflectional morphemes;Normalization;POSTagging;Term Weight;Word Segmentation","Encoding;Estimation;Feature extraction;Information processing;Speech;Speech processing;Tagging","emotion recognition;information retrieval;natural language processing;statistical analysis;word processing","information extraction;speech note;statistical emotion estimation;term analogy feature;verb;verbal expression quantification","","0","","13","","","3-5 Nov. 2011","","IEEE","IEEE Conference Publications"
"Extracting Opinions from Topic-Based Events in the Blogosphere","C. M. Wu; T. Ku","Enabled Applic. & Service Inst., Inst. for Inf. Ind. Innovative DigiTech, Taipei, Taiwan","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","1025","1030","With the rapid development of information technologies in recent years, people can now easily publish their opinions on the Internet. On the other hand, people can also obtain various opinions from others in a few seconds even though they do not know each other. A typical approach to obtain required information is to use a search engine with some relevant keywords. Nevertheless, it is a time-consuming process when looking for opinions of other individuals. Usually, the retrieved opinions are not the latest and single-sided. On the other hand, it is noted that people can have their own blog sites as a platform to publish personal thoughts, ideas or comments easily. We thus take the blogosphere as our major data source and aim at discovering opinions efficiently and effectively in this work. Moreover, two crucial issues are carefully addressed in this work. First, the opinion diversity is addressed by providing various opinions from multiple aspects. Second, we conduct sentiment analysis on opinions against some topic-based events in different time spans to address the opinion dynamics. Empirical studies show that the proposed scheme can help users to obtain opinions of some topic-based events in both an efficient and an effective way.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118868","blogosphere;opinion extraction;sentiment analysis","Blogs;Databases;Feeds;Google;Internet;Search engines;Time factors","Internet;Web sites;information retrieval;search engines","Internet;blog sites;blogosphere;information technologies;opinion diversity;opinion dynamics;opinion extraction;opinion retrieval;search engine;sentiment analysis;topic-based events","","0","","15","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Proxy Re-encryption with Keyword Search from Anonymous Conditional Proxy Re-encryption","W. Zhong; X. A. Wang; Z. Wang; Y. Ding","Eng. Coll., Chinese Armed Police Force, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","969","973","Proxy re-encryption (PRE) allows a proxy to transform a cipher text for Alice (delegator) to be the one which can be decrypted by Bob (delegatee). Since it is introduced by Blaze et al. in 1998, many variants of PRE have been proposed. In this paper, we concentrate on two of them: anonymous conditional proxy re-encryption (ACPRE) and constrained proxy re-encryption with keyword search (PRES). Conditional proxy re-encryption (CPRE) is a primitive which only allows those cipher texts satisfying the condition can be re-encrypted correctly by the proxy. Anonymous conditional proxy re-encryption (ACPRE) requires the proxy not knowing which condition the cipher text associated with. PRES is a primitive which allows the proxy simultaneously re-encrypt and search the delegator's cipher text. Based on the PRES proposed by Shao et al., We show the definition of constrained proxy re-encryption with keyword search (CPRES), give its security models and discuss its potential applications. At last, based on a concrete ACPRE scheme, we construct a concrete CPRES scheme.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128268","","Concrete;Encryption;Keyword search;Public key;Testing","cryptography;information retrieval","PRES;anonymous conditional proxy reencryption;delegator cipher text;proxy reencryption with keyword search","","1","","20","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"The Hot Keyphrase Extraction Based on TF*PDF","Y. Gao; J. Liu; P. Ma","Coll. of Inf. Sci. & Eng., Central South Univ., Changsha, China","2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications","20120102","2011","","","1524","1528","Keyphrase consisting of several words is viewed as the phrase that represent the topic and the content of the whole text. Extracting keyphrase is a good way to detect hot topics and tracking topics from news report. In this paper, a two-step keyphrase extraction method based on TF*PDF is proposed. In the first step, the position-weighted IT*PDF algorithm is proposed to obtain candidate hot term list and the bursty value of term is used to filter the noise in the list. In the second step, a phrase identification process combines hot terms into phrases using position information, frequency information etc. At last the position-weighted TF*PDF algorithm are also used to weight the phrase, and the top k phrases are chosen as hot keyphrases. The experiments on the real web data indicate that our extraction method provides solutions with improved quality.","2324-898X;2324898X","Electronic:978-0-7695-4600-1; POD:978-1-4577-2135-9","10.1109/TrustCom.2011.211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121007","TDT;TF*PDF;bursty value;keyphrase extraction","Conferences;Data mining;Event detection;Feature extraction;Internet;Noise;Presses","Internet;information retrieval;text analysis","TF-PDF algorithm;hot keyphrase extraction;hot topic detection;inverse document frequency;news report;phrase identification process;position-weighted IT-PDF algorithm;term frequency;tracking topic detection;two-step keyphrase extraction method","","1","","32","","","16-18 Nov. 2011","","IEEE","IEEE Conference Publications"
"A comparative study of text classification approaches for personalized retrieval in PubMed","S. Pitigala; C. Li; S. Seo","Dept of Computer Science, Middle Tenn State Uni.","2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)","20111226","2011","","","919","921","Retrieval of the information relevant to one's need from PubMed is becoming increasingly challenging due to its large volume and rapid growth. The traditional information search techniques based on keyword matching are insufficient for large databases such as PubMed. A personalized article retrieval system that is tailored to individual researcher's specific interests and selects only highly relevant articles can be a helpful tool in the field of Bioinformatics. The text classification methods developed in the text mining community have shown good results in differentiating relevant articles from the irrelevant ones. This study compares two text classification methods, Naïve Bayes and Support Vector Machines, in order to study the effectiveness of the two methods on classifying full text articles in the case when only a small set of training data is available. The comparison results show that the Naïve Bayes method is a better choice than Support Vector Machines in building a personalized article retrieval system which can learn (train) from a small set of full text articles.","","Electronic:978-1-4577-1613-3; POD:978-1-4577-1612-6","10.1109/BIBMW.2011.6112503","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112503","","Accuracy;Bioinformatics;Kernel;Support vector machine classification;Text categorization;Training","Bayes methods;bioinformatics;classification;data mining;information retrieval;medical information systems;support vector machines;text analysis;very large databases","PubMed;bioinformatics;information search techniques;keyword matching;large databases;naïve Bayes;personalized article retrieval system;personalized retrieval;relevant articles;relevant information retrieval;support vector machines;text classification approaches;text classification methods;text mining community","","1","","8","","","12-15 Nov. 2011","","IEEE","IEEE Conference Publications"
"Information security awareness in university: Maintaining learnability, performance and adaptability through roles of responsibility","A. R. Ahlan; M. Lubis","Information Technology Division (ITD), International Islamic University of Malaysia (IIUM), Selangor, Malaysia","2011 7th International Conference on Information Assurance and Security (IAS)","20120105","2011","","","246","250","As the 21<sup>st</sup> century approached, the current trend of technology product besides deliver the benefit on availability and accessibility on information, problem emerged regard information security. In order to analyze on how technology introduces new risks, it is necessary to discuss the technology lifecycle. Consider for instance the life cycle of technology as the diffusion of an innovation. Since technological innovations or IT solutions are being adopted to support business processes, the need to protect those IT solutions arises with its adoption. Accordingly, two important factors need much consideration in raising awareness are how organization influences significantly of end user's attitude and how the organization has the regular assessment or evaluation to measure the effectiveness of IS awareness policy inside the organization.","","Electronic:978-1-4577-2155-7; POD:978-1-4577-2154-0","10.1109/ISIAS.2011.6122827","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122827","adaptability;information security awareness;learnability;performance;roles of responsibility","Educational institutions;Human factors;Humans;Information security;Organizations;Training","educational institutions;information retrieval;innovation management;life cycle costing;security of data","IS awareness policy;IT solutions;adaptability;business processes;end user attitude;information accessibility;information availability;information security awareness;learnability;technological innovations;technology lifecycle;university","","2","","16","","","5-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"Credibility Assessment Using Wikipedia for Messages on Social Network Services","Y. Suzuki; A. Nadamoto","Inf. Technol. Center, Nagoya Univ. Furo, Nagoya, Japan","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","887","894","We propose methods for calculating credibility values of messages in Social Network Services (SNSs), such as Linked In and Face book. Many users post messages on SNSs, however, not all of these messages are credible. Our method is based on two assumptions: an SNS message is credible (1) if the SNS message is similar to information from other resources and (2) if the information is confirmed as credible. For assumption (1), we developed a method to retrieve similar descriptions from Wikipedia articles. For assumption (2), we developed a method for assessing Wikipedia articles using the edit history. Using these two methods, we can calculate accurate credibility values for SNS messages. In an experiment, we confirmed that our method can calculate appropriate credibility values for SNS messages if Wikipedia has credible articles related to the SNS messages.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118887","Social Network Service;Wikipedia;credibility","Electronic publishing;Encyclopedias;History;Internet;Mathematical model;Message systems","electronic messaging;information retrieval;social networking (online)","Facebook;Linkedln;SNS message;Wikipedia articles;edit history;message credibility assessment;social network services","","1","","13","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Caching, replication strategy and implementions of directories in DHT-based filesystem","X. Zhan; X. Wang; H. Hong","School of Computer Science and Technology, Beijing University of Posts and Telecommunications, 100876, China","2011 6th International Conference on Pervasive Computing and Applications","20111219","2011","","","287","292","Recently, most of the traffic on the existing networks is occupied by the content distribution and retrieval. The existing technologies such as the P2P technology and DHT technology although have evolved the scalability, robust, effective of the content distribution, there are some problems existing. P2P technology has been implemented to store and deliver the content stored in the P2P overlay, while DHT technology improves the search performance by indexing the stored and requested contents. Many infrastructure and implementations of the file systems have been proposed by combining the P2P technology and DHT technology, maybe some other technology also be included such as CDN. In this paper, we proposed the caching and replication strategy and corresponding implementations of the directories in the DHT-based filesystems.","","Electronic:978-1-4577-0208-2; POD:978-1-4577-0209-9","10.1109/ICPCA.2011.6106519","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106519","CDN;DHT-based filesystem;P2P Techonology","Educational institutions","cache storage;indexing;information retrieval;peer-to-peer computing","DHT-based filesystem;P2P technology;caching strategy;content distribution;content retrieval;indexing;replication strategy;search performance","","1","","9","","","26-28 Oct. 2011","","IEEE","IEEE Conference Publications"
"Scheduling for data center interactive services","Y. He; S. Elnikety","Microsoft Research","2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","20120102","2011","","","1170","1181","To service requests with high quality, web search servers keep average server utilization low. As servers become busy, queuing delays increase, and requests miss their deadlines, resulting in degraded quality of service with poor user experience and potential revenue loss. In this paper, we propose a group of scheduling algorithms that can produce partial answers during overload. One of their key features is assigning processing time to each request based on system load with the objective of maximizing overall quality of responses. We propose three scheduling algorithms - offline, online clairvoyant and online nonclairvoyant. For applications with concave quality profile, we prove that the offline algorithm is optimal. We show the effectiveness of the online algorithms by conducting a simulation study modeling a web search engine. Simulation results show a significant improvement compared to traditional scheduling models with respect to average response quality.","","Electronic:978-1-4577-1818-2; POD:978-1-4577-1817-5","10.1109/Allerton.2011.6120300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120300","VOD bandwidth allocation;best-effort applications;interactive services;offline;online clairvoyant;online nonclairvoyant;partial results;quality profile;scheduling;web search engine","Indexes;Optimal scheduling;Optimized production technology;Schedules;Scheduling algorithm;Servers;Web search","Internet;computer centres;information retrieval;interactive systems;search engines","Web search engine;Web search servers;concave quality profile;data center interactive services scheduling;offline scheduling algorithm;online nonclairvoyant scheduling algorithm;processing time assignment;quality of service;queuing delays;revenue loss;server utilization;user experience","","1","","21","","","28-30 Sept. 2011","","IEEE","IEEE Conference Publications"
"Class Tag Clustering Algorithm of Clustering Search Engine","H. Zhou; D. h. Zhu; B. w. Liu","Sch. of Inf. Sci. & Technol., Beijing Wuzi Univ., Beijing, China","2011 International Conference of Information Technology, Computer Engineering and Management Sciences","20111229","2011","1","","371","374","In order to solve the problems including semantic search, label cluster, theme-related difference of search engines especially under the Chinese environment, this paper aimed to construct a cluster search engine retrieval model suitable for semantic search environment for Chinese through introducing ontology and class label mechanism. Based on the improvement of traditional STC algorithm as well as ontology library and suffix array, this paper studied the class label extraction method of cluster research engine, and put forward related arithmetic of label cluster. The study of cluster research engine label cluster broke through the bottleneck of the semantic research of research engine and information resource management, and solved the single on-line research problem of metasearch and robot engine.","","Electronic:978-0-7695-4522-6; POD:978-1-4577-1419-1","10.1109/ICM.2011.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113434","STC;class tag;clustering search engine;ontology","Clustering algorithms;Databases;Engines;Ontologies;Prototypes;Search engines;Semantics","information resources;information retrieval;ontologies (artificial intelligence);search engines","Chinese environment;STC algorithm;class label extraction method;class label mechanism;class tag clustering algorithm;cluster research engine;cluster search engine retrieval model;clustering search engine;information resource management;label cluster;metasearch;ontology library;related arithmetic;robot engine;search engines;semantic research;semantic search environment;single on-line research problem;suffix array;theme-related difference","","0","","9","","","24-25 Sept. 2011","","IEEE","IEEE Conference Publications"
"PyBot: An Algorithm for Web Crawling","A. G. K. Leng; R. Kumar P; A. K. Singh; R. K. Dash","Dept. of Electr. & Comput. Eng., Curtin Univ., Miri, Malaysia","2011 International Conference on Nanoscience, Technology and Societal Implications","20111226","2011","","","1","6","PyBot is a Web Crawler developed in Python to crawl the Web using Breadth First Search (BFS). The success of the World Wide Web (WWW), which itself built on the open internet, has changed the way how human share and exchange information and ideas. With the explosive growth of the dynamic Web, users have to spend much time just to retrieve a small portion of the information from the Web. The birth of the search engines have made human lives easier by simply taking them to the resources they want. Web crawler is a program used by search engines to retrieve information from the World Wide Web in an automated manner.","","Electronic:978-1-4577-2037-6; POD:978-1-4577-2035-2","10.1109/NSTSI.2011.6111993","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111993","","Crawlers;Engines;Indexes;Robots;Search engines;Web pages","Internet;information retrieval;search engines","PyBot;Python;Web crawler;World Wide Web;breadth first search;information retrieval;open Internet;search engines","","1","","24","","","8-10 Dec. 2011","","IEEE","IEEE Conference Publications"
"UWB radar sensor to monitor heart physiology","A. Boryssenko; E. Boryssenko","A&E Partnership Belchertown MA USA","2011 Loughborough Antennas & Propagation Conference","20111229","2011","","","1","4","Feasibility for noncontact monitoring of major cardiovascular physiology using ultra-wideband radar sensors is studied in computer simulations. A full-wave electromagnetic model of a human chest with a heart of variable blood filling volume is developed. The model is then simulated for several discrete volumes of heart blood filling. Computed subsequent radar returns are modulated by heart motions at different cardiac phases but heavily masked by background scattering. The recorded radar returns are processed using the developed algorithm to extract physiological information that can be linked to ventricle heart blood volume and heart electrical activity associated with ECG.","","Electronic:978-1-4577-1016-2; POD:978-1-4577-1014-8; USB:978-1-4577-1015-5","10.1109/LAPC.2011.6114039","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114039","","Blood;Electrocardiography;Heart;Radar;Radar antennas;Solid modeling;Time domain analysis","cardiovascular system;electrocardiography;haemodynamics;information retrieval;medical signal processing;patient monitoring;sensors;ultra wideband radar","ECG;UWB radar sensor;background scattering;full-wave electromagnetic model;heart electrical activity;heart physiology monitoring;human chest;human heart;noncontact cardiovascular physiology monitoring;physiological information extraction;radar returns;ultra wideband radar sensor;variable blood filling volume;ventricle heart blood volume","","0","","9","","","14-15 Nov. 2011","","IEEE","IEEE Conference Publications"
"Making United States Integrated Ocean Observing System (U.S. IOOS) inclusive of marine biological resources","H. Moustahfid; J. Potemra; P. Goldstein; R. Mendelssohn; A. DesRochers","NOAA/U.S. Integrated Ocean Observing System, Silver Spring, MD, USA","OCEANS'11 MTS/IEEE KONA","20111219","2011","","","1","9","An important Data Management and Communication (DMAC) goal is to enable a multi-disciplinary view of the ocean environment by facilitating discovery and integration of data from various sources, projects and scientific domains. United States Integrated Ocean Observing System (U.S. IOOS) DMAC functional requirements are based upon guidelines for standardized data access services, data formats, metadata, controlled vocabularies, and other conventions. So far, the data integration effort has focused on geophysical U.S. IOOS core variables such as temperature, salinity, ocean currents, etc. The IOOS Biological Observations Project is addressing the DMAC requirements that pertain to biological observations standards and interoperability applicable to U.S. IOOS and to various observing systems. Biological observations are highly heterogeneous and the variety of formats, logical structures, and sampling methods create significant challenges. Here we describe an informatics framework for biological observing data (e.g. species presence/absence and abundance data) that will expand information content and reconcile standards for the representation and integration of these biological observations for users to maximize the value of these observing data. We further propose that the approach described can be applied to other datasets generated in scientific observing surveys and will provide a vehicle for wider dissemination of biological observing data. We propose to employ data definition conventions that are well understood in U.S. IOOS and to combine these with ratified terminologies, policies and guidelines.","0197-7385;01977385","Electronic:978-0-933957-39-8; Paper:978-1-4577-1427-6","10.23919/OCEANS.2011.6106922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106922","Bioinformatics;Biological observations;Observing Systems","Biology;Databases;Oceans;Standards;Terminology;US Government agencies;XML","data integration;data mining;geophysics computing;information retrieval;meta data;oceanographic techniques;vocabulary","IOOS Biological Observations Project;US IOOS DMAC functional requirements;United States Integrated Ocean Observing System;biological observing data;controlled vocabularies;data discovery;data formats;data integration;data management and communication;informatics framework;marine biological resources;metadata;ocean environment;species absence;species abundance data;species presence;standardized data access services","","0","","12","","","19-22 Sept. 2011","","IEEE","IEEE Conference Publications"
"Measurement for Improving the Design of Commodity Archival Storage Tiers","D. Lee; M. O'Sullivan; C. Walker","Dept. of Eng. Sci., Univ. of Auckland, Auckland, New Zealand","2011 Fourth IEEE International Conference on Utility and Cloud Computing","20120109","2011","","","275","280","Archival data storage plays a critical role in data preservation as almost all current data will eventually be archived. In addition, the demands placed on archival storage tiers are growing because of large regularly-scheduled backups. Archival storage tiers usually consist of tape-based devices with a large storage capacity, but limited I/O performance for retrieving data, especially when multiple retrieval requests are made simultaneously. The cost of disk-based devices continues to decrease while the capacity of individual disks increases so that disk-based systems are a realistic option for enterprise archival storage tiers. Optimization approaches can design archival storage systems with the best mix of small, low-cost machines and larger, expensive machines, but only if various metrics of the candidate machines are well-understood. This paper investigates the measurement of different classes of enterprise servers when utilized by a distributed file system. Our study primarily concerns the possible use of these servers within a disk-based archival storage system and produces measurements suitable for immediate use in the optimization-driven design of archival storage. Observing patterns from these measurements also enables us to predict metrics for other enterprise servers and then incorporate these alternative servers in the design process. We combine our measurements and predictions with an optimization engine to discover an ideal building block for a 500TB archival storage system.","","Electronic:978-0-7695-4592-9; POD:978-1-4577-2116-8","10.1109/UCC.2011.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123508","Archival;Benchmark;Commodity;Components;Experimentation;Performance;Power Consumption;Storage System","Benchmark testing;Power demand;Power measurement;Random access memory;Robustness;Servers","distributed databases;information retrieval;input-output programs;optimisation;storage management","I/O performance;archival data storage;archival storage tiers;data preservation;data retrieval;design of commodity;distributed file system;optimization","","0","","23","","","5-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"Domain Concept Extraction Model Based on Folksonomy","W. Pan; S. Chen; Z. Feng","Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China","2011 IEEE Asia-Pacific Services Computing Conference","20120112","2011","","","161","165","Social annotation provides a convenient way to annotate shared content by allowing users to use any tag or keyword. While free folksonomy is widely used in social software implementations and especially in web services, it will play an important role in the semantic web services. However, such tags cannot offer the expressivity of ontologies, and the respective tags often lack context-independent and explicit semantic. In this paper, we describe a model to extract domain concept from social tags. The model mainly includes three modules: a) Detecting the noun terminology through mutual information, b) Applying semantic dictionary to disambiguate between tags, c) Filtering the domain concept via domain relevance and consensus. Finally, experimental results on real world data sets show that the model can effectively learn the domain concept from social tags, and the concept also has a high degree of generality and applicability.","","Electronic:978-0-7695-4624-7; POD:978-1-4673-0206-7","10.1109/APSCC.2011.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6127957","domain concept;folksonomy;ontology;tag;web service","Compounds;Educational institutions;Ontologies;Semantics;Tagging;Terminology;Web services","Web services;information retrieval;ontologies (artificial intelligence);semantic Web","Web services;domain concept extraction model;folksonomy;ontologies;semantic Web services;social software implementations;social tags","","1","","19","","","12-15 Dec. 2011","","IEEE","IEEE Conference Publications"
"Comparing Social Tags to Microblogs","V. Lai; C. Rajashekar; W. Rand","Center for Complexity in Bus., Univ. of Maryland, College Park, MD, USA","2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing","20120102","2011","","","1380","1383","As Internet usage and e-commerce grow, online social media serve as popular outlets for consumers to express sentiments about products. On Amazon, users can tag an album with a keyword, while tweets on Twitter represent a more natural conversation. The differing natures of these media make them difficult to compare. This project collects and analyzes social media data for newly released music albums and develops new methods of comparing a product's social tags to its microblogging data. It explores information retrieval and rank correlation measures as similarity measures, as well as term frequency-inverse document frequency (tf-idf) processing. We conclude that with sufficient Twitter activity about an album, social tags do represent the most frequent conversations occurring on Twitter. These results imply that managers can collect and analyze tags and use them as a proxy for most common consumer feedback from microblogging, which is more difficult to collect.","","Electronic:978-0-7695-4578-3; POD:978-1-4577-1931-8","10.1109/PASSAT/SocialCom.2011.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113311","Amazon;Twitter;comparison;microblogging;music albums;similarity;social media;tagging","Correlation;Frequency measurement;Media;Noise measurement;Tagging;Twitter","electronic commerce;information retrieval;music;social networking (online)","Internet usage;Twitter;e-commerce;information retrieval;microblog;music album;online social media;rank correlation measures;similarity measure;social tags;term frequency-inverse document frequency","","2","","11","","","9-11 Oct. 2011","","IEEE","IEEE Conference Publications"
"Association rule mining using a multi-objective grammar-based ant programming algorithm","J. L. Olmo; J. M. Luna; J. R. Romero; S. Ventura","Department of Computer Science & Numerical Analysis, University of Cordoba, Cordoba, Spain","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","971","977","This paper presents a method for extracting association rules by means of a multi-objective grammar guided ant programming algorithm. Solution construction is guided by a context-free grammar specifically suited for association rule mining, which defines the search space of all possible expressions or programs. Evaluation of individuals is considered from a Pareto-based point of view, measuring support and confidence of rules mined, and assigning them a ranking fitness. The proposed algorithm is verified over 10 varied data sets and compared to other association rule mining algorithms from several paradigms such as exhaustive search, genetic algorithms and genetic programming, showing that ant programming is a good technique at addressing the association task of data mining as well.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121784","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121784","Association rule mining (ARM);ant colony optimization (ACO);ant programming (AP);data mining (DM)","Algorithm design and analysis;Association rules;Grammar;Machine learning algorithms;Measurement;Software algorithms","ant colony optimisation;context-free grammars;data mining;information retrieval","ant colony optimization;ant programming;association rule mining;context-free grammar;data extraction;multi-objective grammar;search space","","2","","22","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"Design and implementation of web based application for relational data maintenance in an university environment","S. Jeyalatha; B. Vijayakumar; G. Singh","BITS Pilani Dubai, UAE","The 2011 International Conference and Workshop on Current Trends in Information Technology (CTIT 11)","20111219","2011","","","105","112","The present work deals with designing and creating a Academic Search Web Application that provides the user with a range of options. It also discusses the ways in which the files are accessed from the MySQL database. The implementation has been carried out in PHP and MySQL and the test scenario has been presented. The present work will assist in organized search and downloading academic related web pages for various users in an University environment.","2377-5327;23775327","Electronic:978-1-4673-0098-8; POD:978-1-4673-0097-1","10.1109/CTIT.2011.6107944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6107944","Academic Search;Web Log file;Website Navigation Menu","","SQL;educational administrative data processing;information retrieval;relational databases","MySQL database;PHP;academic search Web application;relational data maintenance;university environment","","0","","10","","","26-27 Oct. 2011","","IEEE","IEEE Conference Publications"
"Personalized Searching for Web Service Using User Interests","R. Hu; W. Dou; X. F. Liu; J. Liu","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","156","163","Users usually have different prospective even they input a same keyword to search Web services. It is a challenge to personalize web service search engine as more and more keyword-like Web services becoming available on Internet. User interest plays an important role in personalizing search result. Therefore, through interest extraction, Web service search engine is personalized. At last, an experiment is presented to demonstrate the feasibility of the method.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6119089","TF/IDF;User Interests;Web service search engine;personalize","Computers;Data mining;Feature extraction;Search engines;Vectors;Web services","Web services;information retrieval;search engines","Internet;Web service;personalized searching system;search engine","","2","","36","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Cybercomputer for information space analysis","V. Hahanov; W. Gharibi; Dong Won Park; E. Litvinova","Computer Engineering Faculty, Kharkov National University of Radioelectronics, Ukraine","2011 9th East-West Design & Test Symposium (EWDTS)","20111229","2011","","","66","71","This article describes an infrastructure and technologies for analyzing information space, based on virtual cybercomputer. A model and metrics for cyberspace, where subjects are the interacting processes or phenomena with the physical carrier in the form of computer systems and networks, are proposed. The structural model of high-speed multimatrix processor designed for fast and accurate search of information objects in cyberspace is described.","","Electronic:978-1-4577-1958-5; POD:978-1-4577-1957-8","10.1109/EWDTS.2011.6116416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6116416","","Computers;Cyberspace;Educational institutions;Engines;Libraries;Measurement;Vectors","information analysis;information retrieval systems","Cybercomputer;computer networks;computer systems;information objects;information space analysis;interacting processes;multimatrix processor","","0","","13","","","9-12 Sept. 2011","","IEEE","IEEE Conference Publications"
"Model Interactive Search between User and Associated Link Networks","B. Zhu; X. Luo; Y. Liu; X. He; L. Xu","High Performance Comput. Center, Shanghai Univ., Shanghai, China","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","729","736","Web search is a key information retrieval method for human beings in current society, both in the fields of academic and commercial activities. Due to ""one-size-fits-all"" approach limit to search results obtainment, there are still challenges to give personalized web service with high precision in traditional web search process. Herein, a new framework is proposed to advance traditional search process into a new paradigm, i.e. interactive search. First, a cognitive model of interaction process about one search step is developed by the imitation of human search behaviors. Then based on the theory of interactive computing, an interactive search model is introduced to formalize successive search sessions which include several search steps. Third, based on human's cognitive mechanism such as the spreading activation model and user memory theory, a user model is designed to capture user's search activities which can aid the interactive search process effectively. Last, by the help of Associated Link Network, an information gradient based rank algorithm is proposed aiming at maximizing the quantity of web information supply. The efficiency of our proposed interactive search service is verified by the experimental results.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118910","cognitive mechanism;interactive computing;interactive search;user model","Algorithm design and analysis;Computational modeling;History;Humans;Knowledge engineering;Search engines;Semantics","Internet;cognition;gradient methods;information retrieval;interactive systems","Web information supply;Web search process;associated link network;human cognitive mechanism;human search behaviors;information gradient based rank algorithm;information retrieval method;interaction process;interactive computing;interactive search model;spreading activation model;user memory theory;user model;user search activities","","1","","19","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Demanding Affecting Factors Analysis for Personal Financial Management Business: An Empirical Approach Based on Factor Analysis Model","J. Peng; D. Lu","Sch. of Econ. & Manage., Northwest A& F Univ., Yanling, China","2011 International Conference on Information Management, Innovation Management and Industrial Engineering","20111229","2011","1","","291","294","This paper analyzes the demanding affecting factors for financial management business by using factor analysis model and logistic regression through the data obtained from the survey questionnaires. It is found that the main factors that affecting financial management business are the special life cycle stages the residents are in and the external information environment for residents to purchase financial products. Bank creditworthiness, residents risk preference attributes, financial product characteristics have certain influence on the behaviors of residents. But residents' perceptions of the risk on financial products have no significant effect on their financial behaviors.","2155-1456;21551456","Electronic:978-1-61284-453-4; POD:978-1-61284-450-3","10.1109/ICIII.2011.74","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6115484","Affecting Factors;Factors Analysis Model;Logistic Regression;Personal Financial Management","Analytical models;Banking;Education;Financial management;Logistics;Mathematical model","bank data processing;life cycle costing;logistics data processing;purchasing;question answering (information retrieval);regression analysis;risk management","bank creditworthiness;external information environment;factor analysis model;financial product characteristics;financial product purchase;financial product risk;logistic regression;personal financial management business;questionnaire;resident risk preference attribute","","0","","5","","","26-27 Nov. 2011","","IEEE","IEEE Conference Publications"
"Histogram Based Reflection Detection","A. Ahmadi; S. Ahani; H. Khalilian; I. Gholampour","Electr. Res. Inst., Sharif Univ. of Technol., Tehran, Iran","2011 7th Iranian Conference on Machine Vision and Image Processing","20120102","2011","","","1","5","Reflection appears as a layer that partly covers the original image. This phenomenon may cause failure in extracting information from images of reflecting objects. This work presents an automated technique for determining of reflection area as well as its severity to define reliability of extracted information. This is done by analyzing histogram and objects found in the image. We present a strong detector based on combining the results of these two procedures. We presented new reflection detection algorithm and a new method to find a good threshold value for converting any image into a binary image. The average reflection detection accuracy of the proposed algorithm is more than 95% for different types of reflection.","2166-6776;21666776","Electronic:978-1-4577-1535-8; POD:978-1-4577-1533-4","10.1109/IranianMVIP.2011.6121602","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121602","","Accuracy;Algorithm design and analysis;Data mining;Feature extraction;Histograms;Reflection;Vectors","image enhancement;information retrieval;object detection","automated technique;binary image;histogram based reflection detection;information extraction","","0","","14","","","16-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"A study on different backward feature selection criteria over high-dimensional databases","P. Bermejo; L. de La Ossa; J. A. Gamez; J. M. Puerta","Computings Systems Department, University of Castilla-La Mancha, Albacete, Spain","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","1300","1305","Feature subset selection has become an expensive process due to the relatively recent appearance of high-dimensional databases. Thus, not only the need has arisen for reducing the dimensionality of these datasets, but also for doing it in an efficient way. We propose a new backward search, where attributes are removed given several smart criteria found in the literature and, besides, it is guided using a heuristic which reduces the cost and needed number of evaluations commonly expected from a backward search. Besides, we do not only propose the design of a new forward-backward algorithm but we also provide an experimental study of different criteria to decide the removal of attributes. The result is a very competitive algorithm which does not exceed the in-practice linear complexity while obtaining selected subsets of features with lower cardinality than other state-of-the-art algorithms.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121839","feature;high-dimensional;hybrid;selection;sequential","Algorithm design and analysis;Complexity theory;Databases;Frequency selective surfaces;Measurement;Proposals;Signal processing algorithms","classification;computational complexity;database management systems;information retrieval","backward feature selection criteria;backward search;cardinality;competitive algorithm;dimensionality;feature subset selection;forward-backward algorithm;high-dimensional databases;in-practice linear complexity;state-of-the-art algorithms","","0","","14","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"Entropy simulation of digital information sources and the effect on information source rates","E. F. Armay; I. Wahid","Electrical Engineering Department, State Islamic University of Sultan Syarif Kasim Riau, Pekanbaru, Indonesia","2011 2nd International Conference on Instrumentation, Communications, Information Technology, and Biomedical Engineering","20111222","2011","","","74","78","Entropy is defined as a measure of how much information can be retrieved from a message or information sources. In data communications, entropy from information sources is described in the form of bits and closely related to the probability of arriving message to receiver and depends on the period of light spectrum, therefore information source rates affected. The problem faced is how to describe it in visual form. Here the entropy simulation was programmed by using Matlab GUI. The design of entropy simulation program consists of two types. The first type is entropy simulation program of text information as input. The second type is entropy simulation program of voice information as input. The results of both simulation program show that entropy value influenced information source rates. In other words, information source rates will increase with the increasing of entropy value.","","Electronic:978-1-4577-1166-4; POD:978-1-4577-1167-1","10.1109/ICICI-BME.2011.6108597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6108597","average information;entropy;source rate","Computational modeling;Computers;Entropy;Image color analysis;Quantization;Simulation;Time frequency analysis","data communication;digital simulation;entropy;graphical user interfaces;information retrieval;mathematics computing","Matlab GUI;data communications;digital information sources;entropy simulation;information retrieval;information source;information source rates;text information","","0","","5","","","8-9 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Study on Relationship Migration among Social Networking Providers","S. Li; L. Wang; Z. Qin; Z. Ming; L. Shu","Sch. of Software, Dalian Univ. of Technol., Dalian, China","2011 Seventh International Conference on Mobile Ad-hoc and Sensor Networks","20111229","2011","","","303","309","User profiles backup and migration among social networking providers have become more urgent after the conflict between Tencent, the largest Instant Messaging(IM) service provider in China, and Qihu360, the largest antivirus company in China. So far, exchanging contact list among emails has been wildly used. Mainstream email service providers commonly make use of Comma Separated Value (CSV) files to export/import contact lists. Meanwhile, XML format is popular to transfer information among different platforms due to its rich hierarchical data structures. By using CSV files and XML files, we propose a new method to do relationship migration among social networking providers, which consists of three stages: 1) information retrieval from original social networking provider, 2) information storage and re-processing, and 3) relationship migration and recovery in the target provider. In order to evaluate our solution, we have designed and implemented a real experiment to test the migration from RenRen (the largest social network in China) to my Elgg (our test bed server).","","Electronic:978-0-7695-4610-0; POD:978-1-4577-2178-6","10.1109/MSN.2011.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6117428","","Blogs;Crawlers;Electronic mail;Google;Social network services;Software;XML","XML;computer viruses;data structures;electronic data interchange;electronic messaging;information retrieval;social networking (online)","CSV files;China;Elgg;Qihu360;RenRen;Tencent;XML files;XML format;antivirus company;comma separated value files;hierarchical data structures;information re-processing;information retrieval;information storage;instant messaging service provider;relationship migration;relationship recovery;social networking providers;user profiles backup;user profiles migration","","0","","25","","","16-18 Dec. 2011","","IEEE","IEEE Conference Publications"
"Adaptive Metadata Management and Flexible Consistency in a Distributed In-memory File-System","K. T. Rehmann; S. Dere; M. Schoettner","Inst. fur Inf., Heinrich-Heine-Univ. Dusseldorf, Dusseldorf, Germany","2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies","20120102","2011","","","201","206","Distributed file-systems are a popular storage abstraction for cloud-computing applications. They provide generic data access for different applications in order to pass information between computing nodes and to save computation results persistently. The performance of distributed applications depends on data-consistency protocols and meta-data management, but these factors of influence are often statically configured in distributed file-systems. In this paper, we describe EFS, an in-memory file-system that manages meta-data and consistency by flexibly adapting to file-access patterns.","2379-5352;23795352","Electronic:978-0-7695-4564-6; POD:978-1-4577-1807-6","10.1109/PDCAT.2011.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118933","distributed computing;distributed file system;distributed transactional memory;false sharing;in-memory storage","Distributed computing","cloud computing;data integrity;distributed memory systems;file organisation;information retrieval;meta data;protocols","adaptive metadata management;cloud computing application;data consistency protocols;distributed application;distributed in-memory file system;file-access pattern;flexible consistency;generic data access;storage abstraction","","0","","15","","","20-22 Oct. 2011","","IEEE","IEEE Conference Publications"
"Guidelines on accessible web portal design","D. Radosav; D. Karuovic; B. Markoski; Z. Ivankovic","University of Novi Sad, Technical Faculty &#x201C;Mihajlo Pupin&#x201D;, Zrenjanin, Serbia","2011 IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI)","20111222","2011","","","297","302","WWW (World Wide Web) as a basic Internet service has an important role in almost every aspect of life. The goal of the message sent from one Web page is to attract temporary and future clients i.e. visitors, and to inform them about products, services and to stimulate them to buy and use them. Therefore, the authors of Web pages have to consider different abilities possibilities and conditions of using. Each attempt which makes accessibility easier is useful for people with disabilities. The authors of these paper present guidelines which should be considered in web portals design, in order to make them accessible to people with disabilities. The problem of adjustment of web pages to people with disabilities is analyzed in more details.","","Electronic:978-1-4577-0045-3; POD:978-1-4577-0044-6","10.1109/CINTI.2011.6108518","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6108518","Internet;Web;accessibility;color discrimination","Color;Guidelines;Image color analysis;Internet;Software;Visualization;Web pages","Internet;Web design;information retrieval;portals","Internet service;WWW;Web page;World Wide Web;accessible Web portal design","","1","","11","","","21-22 Nov. 2011","","IEEE","IEEE Conference Publications"
"A Secure Storage Service in the Hybrid Cloud","S. Nepal; C. Friedrich; L. Henry; S. Chen","Inf. Eng. Lab., CSIRO ICT Centre, Canberra, ACT, Australia","2011 Fourth IEEE International Conference on Utility and Cloud Computing","20120109","2011","","","334","335","Cloud storage services are not secure by nature. There is an inherent risk of (a) data exposure (confidentiality), (b) data tampering (integrity) and (c) denial of access to data (availability). We provide a service-oriented solution for provisioning secure storage service in the hybrid cloud environment, called Trust Store. The system is suitable to facilitate individual as well as collaborative data storage and access. In this demonstration, we show how Trust Store can be used to store and retrieve files securely in the hybrid cloud environments.","","Electronic:978-0-7695-4592-9; POD:978-1-4577-2116-8","10.1109/UCC.2011.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123519","cloud computing;secure storage;storage service","Availability;Cloud computing;Collaboration;Computer architecture;Cryptography;Secure storage","cloud computing;data privacy;groupware;information retrieval;information storage;security of data;service-oriented architecture","Trust Store;cloud storage service;collaborative data access;collaborative data storage;data access denial;data availability;data confidentiality;data exposure;data integrity;data tampering;file storage;files retrieval;hybrid cloud environment;secure storage service;service-oriented","","2","","3","","","5-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"A Workflow-Based Cooperative Project Management System","Y. Chen; K. Hou; R. Wang","Coll. of Comput. & Inf. Eng., Beijing Technol. & Bus. Univ., Beijing, China","2011 10th International Symposium on Distributed Computing and Applications to Business, Engineering and Science","20120102","2011","","","69","73","In modern large enterprises, a complex project is usually composed of a series of processes and needs many persons with different roles cooperating with each other within limited time and investment. A workflow-based cooperative project management system (CPMS) that can support multi-user working is presented in this paper. The system is based on Browser/Server architecture that contains User Interface, Business Logic and Data Access three layers in which the core is an XPDL-based workflow engine. A series of cooperative mechanisms such as inclusive gateway, exclusive gateway and parallel gateway are designed to achieve the definition, configuration, and control of the workflow, the assignment, submission and approval of project tasks, the allocation and configuration of project resource. The version control techniques for workflow designs, project plans and project documents are also presented. CPMS has been used in an international enterprise that needs to manage thousands of projects each year. The application result demonstrates that the system can satisfy the needs of cooperative project management.","","Electronic:978-0-7695-4415-1; POD:978-1-4577-0327-0","10.1109/DCABES.2011.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6119029","Cooperative work;Project management;Visualization;Workflow","Collaborative work;Databases;Decision making;Engines;Logic gates;Project management;Visualization","configuration management;file servers;groupware;information retrieval;project management;user interfaces;workflow management software","XPDL-based workflow engine;browser-server architecture;business logic;cooperative mechanisms;data access;exclusive gateway;inclusive gateway;international enterprises;modern large enterprises;multiuser working;parallel gateway;project resource;user interface;version control techniques;workflow-based cooperative project management system","","1","1","8","","","14-17 Oct. 2011","","IEEE","IEEE Conference Publications"
"Data mining and its applications in bioinformatics: Techniques and methods","X. Hu","College of Information Science and Technology, Drexel University, Philadelphia, PA, 19104, USA","2011 IEEE International Conference on Granular Computing","20120105","2011","","","3","3","In this talk, I will discuss some of the latest data mining techniques and methods and their applications in bioinformatics study, focusing on data integration, text mining and graph-based data mining in bioinformatics research. In data integration, I will present a semantic-based approach for multi source bioinformatics data integration. In our approach, a metamodel is utilized to represent the master search schema, and an effective interface extraction algorithm based on the hierarchical structure of the web and pattern is developed to capture the rich semantic relationships of the online bioinformatics data sources. Our final goal is to develop a meta-search interface for biologists as a single point of access to multiple online bioinformatics databases. In text mining, some of the challenging issues in mining and searching the biomedical literature are addressed, and I will present a unified architecture Bio-SET-DM (Biomedical Literature Searching, Extraction and Text Data Mining), discuss some novel algorithms such as semantic-based language model for literature retrieval, semi-supervised pattern learning for information extraction of biological relationships from biomedical literature. In the third part, graph-based data mining, the focus is on graph-based mining in biological networks. I will discuss how to apply graph-based mining techniques and algorithms in the analysis of modular and hierarchical structure of biological networks, how to identify and evaluate the subnetworks from complicated biological networks, and present the experimental results. To put these pieces together, a unified framework is introduced to integrate the three parts (data integration, text mining and graph-based data mining) in the bioinformatics data mining procedure.","","Electronic:978-1-4577-0371-3; POD:978-1-4577-0372-0","10.1109/GRC.2011.6122559","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122559","","Awards activities;Bioinformatics;Biology;Conferences;Data mining;Educational institutions;Intelligent systems","Internet;bioinformatics;data mining;graph theory;information retrieval;learning (artificial intelligence);literature;pattern clustering;text analysis;user interfaces","Bio-SET-DM;bioinformatic research;biological networks;biomedical literature searching;graph based data mining;hierarchical structure;information extraction;interface extraction algorithm;literature retrieval;master search schema;metamodel;metasearch interface;modular structure;multisource bioinformatic data integration;online bioinformatic data sources;online bioinformatic databases;semantic based language model;semantic relationships;semisupervised pattern learning;text data mining","","0","","","","","8-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Enabling Web Services to Consume and Produce Large Datasets","S. Koulouzis; R. Cushing; K. Karasavvas; A. Belloum; M. Bubak","University of Amsterdam","IEEE Internet Computing","20120109","2012","16","1","52","60","Service-oriented architectures and Web services are well-established paradigms for developing distributed applications. However, Web services face problems when accessing, moving, and processing large datasets. To address this problem, the authors present ProxyWS, which uses myriad protocols to transport large amounts of data. ProxyWS undertakes data transfers on behalf of legacy Web services and can serve as an interface for developing new Web services that can stream data. Experiments show how this approach facilitates scalable data transports for two data-intensive applications.","1089-7801;10897801","","10.1109/MIC.2011.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030867","SOA;Web services;data transfers;data-intensive applications;distributed indexing.","Distributed databases;Indexing;Internet;Service oriented architecture;Simple object access protocol;Web and internet services","Web services;data communication;information retrieval;protocols;service-oriented architecture;user interfaces","ProxyWS;data intensive applications;data streaming;data transfer;dataset accessing;dataset processing;distributed application;legacy Web services;myriad protocols;scalable data transports;service oriented architecture","","6","","11","","20110929","Jan.-Feb. 2012","","IEEE","IEEE Journals & Magazines"
"3D Object Retrieval Using a Global-Partial Analogy and the Bayesian Approach","L. Moumoun; M. Chahhou; M. El Far; A. Haqiq; T. Gadi","Dept. Math. & Comput. Sci., Hassan 1st Univ., Settat, Morocco","2011 Seventh International Conference on Signal Image Technology & Internet-Based Systems","20120102","2011","","","314","321","3D retrieval has become an important field for applications that require 3D databases. Several descriptors have been defined in the past, most of them are based on the global geometric signature of the 3D objects and only a few of them allow a partial matching using segments of a 3D object as queries. In this paper, we propose to improve the results of global indexing by combining the partial signatures of the segments of a 3D object and its global descriptor using the Bayesian framework. The proposed approach improves significantly the results of global indexing and allows the retrieval of similar objects with different poses.","","Electronic:978-0-7695-4635-3; POD:978-1-4673-0431-3","10.1109/SITIS.2011.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120666","3D mesh;3D retrieval;3D segmentation;Bayesian framework;partial matching;shape descriptor;shape index","Bayesian methods;Humans;Indexes;Shape;Solid modeling;Three dimensional displays","Bayes methods;computational geometry;image segmentation;indexing;information retrieval;solid modelling;visual databases","3D database;3D object retrieval;3D object segment;Bayesian approach;global geometric signature;global indexing;global-partial analogy;partial matching;partial signature","","2","","28","","","Nov. 28 2011-Dec. 1 2011","","IEEE","IEEE Conference Publications"
"Lonestar: An Energy-Aware Disk Based Long-Term Archival Storage System","M. Grawinkel; M. Pargmann; H. Domer; A. Brinkmann","Paderborn Center for Parallel Comput. PC2, Univ. of Paderborn, Paderborn, Germany","2011 IEEE 17th International Conference on Parallel and Distributed Systems","20120102","2011","","","380","387","We present the architecture for an disk based archival storage system and propose a new RAID scheme that is designed for ""write once, read sometimes"" workloads. By intertwining parity groups into a multi-dimensional RAID and improving the single disk reliability with intra-disk redundancy, the system achieves an elastic fault tolerance that can at least recover from all 3-disk failures. We do not stripe data to multiple disks and store related information to the same disks. Typically, all disks of the RAID are powered off, and for a read request, only a single disk has to be spun up, while write and rebuild processes require multiple disks. We analyzed our RAID scheme and showed that it provides a MTTDL that is orders of magnitudes higher than a set of RAID6 systems with a similar amount of disk drives. We also present and evaluate our prototype and show that it is well suited for archival scenarios.","1521-9097;15219097","Electronic:978-0-7695-4576-9; POD:978-1-4577-1875-5","10.1109/ICPADS.2011.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121301","RAID;archival;disk;energy-aware;reliability;storage","Arrays;Energy consumption;Fault tolerant systems;Redundancy;Servers","RAID;disc drives;fault tolerance;information retrieval systems;power aware computing;records management;system recovery","Lonestar;RAID scheme;RAID6 systems;disk based archival storage system;disk drives;disk failure recovery;elastic fault tolerance;energy-aware disk based long-term archival storage system;intra-disk redundancy;multidimensional RAID;single disk reliability","","2","","23","","","7-9 Dec. 2011","","IEEE","IEEE Conference Publications"
"Classification of PICO elements by text features systematically extracted from PubMed abstracts","K. C. Huang; C. C. H. Liu; S. S. Yang; F. Xiao; J. M. Wong; C. C. Liao; I. J. Chiang","Graduate Institute of Biomedical Engineering, National Taiwan University, Taipei, Taiwan","2011 IEEE International Conference on Granular Computing","20120105","2011","","","279","283","We propose and evaluate a systematic approach to detect and classify Patient/Problem, Intervention, Comparison and Outcome (PICO) from the medical literature. The training and test corpora were generated systematically and automatically from structured PubMed abstracts. 23,472 sentences by exact pattern match of head words of P-I-O categories. Afterward, the terms with top frequencies were used as the features of Naïve Bayesian classifier. This approach achieves F-measure values of 0.91 for Patient/Problem, 0.75 for Intervention and 0.88 for Outcome, comparable to previous studied based on mixed textural, paragraphical, and semantic features. In conclusion, we show that by stricter pattern matching criteria of training set, detection and classification of PICO elements can be reproducible with minimal expert intervention. The results of this work are higher than previous studies.","","Electronic:978-1-4577-0371-3; POD:978-1-4577-0372-0","10.1109/GRC.2011.6122608","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122608","information extraction;natural language processing;question answering;text mining","Abstracts;Bayesian methods;Informatics;Knowledge based systems;Pattern matching;Testing;Training","belief networks;information retrieval;pattern classification;pattern matching;text analysis","F-measure values;Naïve Bayesian classifier;P-I-O categories;PICO element classification;medical literature;mixed textural feature;paragraphical feature;patient-problem-intervention-comparison outcome;pattern matching criteria;semantic features;structured PubMed abstracts;test corpora;training corpora;training set","","1","","10","","","8-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Construction of a Bilingual Cognitive Property Knowledgebase","B. Li; H. Kuang; X. Chen; X. Tang; C. Chen","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","1100","1103","Every language has its own culture background, thus it is difficult to translate or retrieve figurative expressions across languages. Based on the metaphoric cognition and feature analysis theory, we collect data from the web to construct the Chinese-English bilingual lexical cognitive property knowledgebase linked to ""HowNet"". By comparing the differences of the cognitive property, we get some answers to the core linguistic problem ""is the metaphor universal?"" Then, we put forward a novel method to gain the metaphoric property of a word by its translation in another language. The paper lays a solid foundation for semantic analysis and computing of lexical cognitive property.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.244","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128293","cognitive property;lexical semantics;linguistic knowledgebase;metaphor","Contracts;Educational institutions;Presses;Search engines;Semantics;Software;Vehicles","information retrieval;language translation;natural language processing;semantic Web","Chinese-English bilingual lexical cognitive property knowledgebase;HowNet;Web;feature analysis theory;figurative expression retrieval;figurative expression translation;linguistic problem;metaphoric cognition;metaphoric property;semantic analysis","","1","","9","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"An Access Control Mode Based on Information Flow Graph","W. Chao; C. X. Yuan; L. Na","ZhengZhou Inf. Sci. & Technol. Inst., Zhengzhou, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","998","1000","Due to different class systems make access decision independently, in the cross class information system (Cross-Class-IS), the privilege may be out of control and the security policies may not be coincident. It is huge risk especially to the higher class system. Now, the system normally checks the security of the access between subject and object. But it cannot protect the indirect information caused by access cross class and domain. This article proposes an access control model, which can be used to analyze the security in Cross-Class-IS.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128274","Access control model;Cross-Class-IS;Information flow graph","Access control;Analytical models;Computational modeling;Computers;Flow graphs;Mathematical model","authorisation;decision making;flow graphs;information retrieval","access control mode;access decision;cross class IS;cross class information system;information flow graph;security policies","","1","","9","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"Theme-Based Mobile Social Network System","J. Tang; S. Kim","Sch. of Eng. & Comput. Sci., Kyungpook Nat. Univ., Daegu, South Korea","2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","20120102","2011","","","1089","1095","With the rapid development of mobile device and wireless network, mobile device becomes an excellent choice for people to access social life here and there all around the clock. However, most of widely used mobile social network systems cannot make the best of mobile device's features and hardly satisfied persons' demands in dynamic realistic social network. So this paper proposes a Theme-based Mobile Social Network System to assist in accessing the realistic social network. Theme-based Mobile Social Network System supports to automatically detect surrounding social networks and intelligently recommend optimal activities to users, and also provides convenient interactive ways to help people take an active part in realistic social activities. The aim of this proposed system is helping users discover nearby social activities or social relations, which they may have interests in attending or visiting or connecting.","","Electronic:978-0-7695-4612-4; POD:978-1-4673-0006-3","10.1109/DASC.2011.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6119064","Context-awareness;Location-based Service;Mobile Social Network;Theme;Theme-awareness","Business;History;Mobile communication;Mobile computing;Mobile handsets;Servers;Social network services","human computer interaction;information retrieval;interactive devices;mobile computing;radio networks;social aspects of automation;social networking (online)","dynamic realistic social network;interactive ways;mobile device;social activities;social life access;social relations;theme-based mobile social network system;wireless network","","3","","9","","","12-14 Dec. 2011","","IEEE","IEEE Conference Publications"
"Enhancing Local Binary Patterns Distinctiveness for Face Representation","M. Ghahramani; W. Y. Yau; E. K. Teoh","Dept. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2011 IEEE International Symposium on Multimedia","20120109","2011","","","440","445","The Local Binary pattern (LBP) is a well-known feature and has been widely used for human identification. However, the amount of information extracted is limited which reduces the LBP discriminative power. Recently, some enhancements have been proposed by adding preprocessing stages or considering more neighbor pixels to enrich the extracted feature. In this paper, we propose Uniformly-sampled Thresholds for LBP (UTLBP) operator that increases the richness of information derived from the LBP feature. It outperforms other features in various probe sets of the large CAS-PEAL database for face recognition. Moreover, we collected a database of 25 families to verify the superiority of the proposed feature in the family verification. Results show that using the UTLBP, the total error in face recognition and family verification is reduced up to 8% and 3% respectively comparing to the state of the art LBP. It improves the missing family member verification performance up to 3% where, contrary to expectation, increasing the LBP operator radius worsens the performance by 2%.","","Electronic:978-0-7695-4589-9; POD:978-1-4577-2015-4","10.1109/ISM.2011.78","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123386","LBP modification;family verification;feature","Databases;Face;Face recognition;Feature extraction;Lighting;Probes;Training","face recognition;feature extraction;image segmentation;information retrieval;visual databases","CAS-PEAL database;LBP feature extraction;UTLBP operator;face recognition;human identification;information extraction;local binary pattern;missing family member verification performance;uniformly sampled threshold for LBP","","1","","17","","","5-7 Dec. 2011","","IEEE","IEEE Conference Publications"
"Using HTML Tags to Improve Parallel Resources Extraction","Y. Feng; Y. Hong; W. Tang; J. Yao; Q. Zhu","Sch. of Comput. Sci. & Technol., Soochow Univ., Suzhou, China","2011 International Conference on Asian Language Processing","20120102","2011","","","255","259","This paper proposes a new approach to extract parallel resources (including bilingual sentences and bilingual terms) from bilingual web pages, which have a primary language and a secondary language (the second language is often the translation to primary language). Our method is composed of four tasks: 1) parsing the web page into a DOM tree and segmenting inner texts of each node into series of monolingual snippets; 2) selecting adjacent snippet pairs in different languages and with higher translation scores as seeds for the next task; 3) constructing comprehensive wrappers from selected seeds, which save both HTML and surface formatting styles; 4) mining candidate instances and selecting good instances by their similarities with seeds. In this paper, we first propose to segment text by HTML tags, and select potential parallel resources by ranking all extracted candidates. According to the experimental results, our method can be applied to bilingual pages written in any other pair of languages. Experimental results also show that our approaches are effective in improving the parallel resources extraction.","","Electronic:978-0-7695-4554-7; POD:978-1-4577-1733-8","10.1109/IALP.2011.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121515","Bilingual Resource;HTML Tags;Web Data Mining","Computational linguistics;Data mining;HTML;Noise measurement;Web pages","Internet;data mining;information retrieval;natural language processing;text analysis","DOM tree;HTML tags;Web page parsing;bilingual Web page;bilingual sentence;bilingual term;comprehensive wrapper;instance mining;monolingual snippets;parallel resource extraction;primary language;secondary language;text segmentation;translation score","","2","","18","","","15-17 Nov. 2011","","IEEE","IEEE Conference Publications"
"Security System for Migrating Crawlers","A. Dixit; A. K. Sharma","Dept. of Comput. Eng., YMCA Univ. of Sci. & Technol., Faridabad, India","2011 International Conference on Computational Intelligence and Communication Networks","20111229","2011","","","667","671","Owing to their inherent security problems, migrants have limited applications especially when they are more prone to misuse by some other applications, resulting in increase in the scale of threats. Nevertheless migrants are potential contributors for implementation of migrating crawlers because of their capability to move to the information resource itself. In this paper, general security objectives for migrants are identified and corresponding mechanisms for facing the identified threats have been designed.","","Electronic:978-0-7695-4587-5; POD:978-1-4577-2033-8","10.1109/CICN.2011.145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112954","Crawler;Information Security;Migrating Crawler;Search engine","Computer crime;Crawlers;Encryption;Image restoration;Monitoring","information retrieval;search engines;security of data","crawler migration;information resource;security system","","1","","9","","","7-9 Oct. 2011","","IEEE","IEEE Conference Publications"
"A Web Page Classification Algorithm Based on Link Information","Z. Xu; F. Yan; J. Qin; H. Zhu","Sch. of Comput., Wuhan Univ. of Technol., Wuhan, China","2011 10th International Symposium on Distributed Computing and Applications to Business, Engineering and Science","20120102","2011","","","82","86","Effective classification of web pages can improve the quality of information retrieval. The traditional classification algorithms are basically based on the analysis of Web content, but the content of the web page is complicated, filled with a large number of false, erroneous information, has seriously affected the accuracy of the classification of network information. To solve this problem, this paper presents a web page classification algorithm, Link Information Categorization(LIC). Based on the K nearest neighbor method, it combines information on the website features, to implement the Web page link to information classification. Experiments show that the algorithm can get higher efficiency and accuracy on the Web page classification.","","Electronic:978-0-7695-4415-1; POD:978-1-4577-0327-0","10.1109/DCABES.2011.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6119026","Link Information;Link Information Categorization;Web Page Classification","Accuracy;Algorithm design and analysis;Classification algorithms;Internet;Support vector machines;Text categorization;Web pages","Web sites;information retrieval;pattern classification","K nearest neighbor method;Web content analysis;Web page classification algorithm;Web page link;Web site features;information retrieval;link information categorization;network information classification","","3","","8","","","14-17 Oct. 2011","","IEEE","IEEE Conference Publications"
"Characterizing E-Science File Access Behavior via Latent Dirichlet Allocation","Y. Kim; C. Germain-Renaud","LRI, Univ. Paris-Sud 11, Orsay, France","2011 Fourth IEEE International Conference on Utility and Cloud Computing","20120109","2011","","","162","169","E-science is moving from grids to clouds. Getting the best of both worlds needs to build on the experience gained by the steady operation of production grids since some years. We propose a new approach for analyzing behavioral traces: as most of them are indeed text documents, state of the art techniques in text mining, and specifically latent Dirichlet allocation, can be exploited. The advantages are twofold: providing some level of explanation inferred from the data, and a relatively scalable way to capture the temporal variability of the behavior of interest, while retaining the full dimensionality of the problem at hand. We experiment the text mining analogy by characterizing file access behavior on data from the steady operation of the largest production grid. We validate the resulting probabilistic model by showing that it is capable of generating synthetic traces statistically consistent with the real ones. The approach would equally apply to wider contexts such as social networks activity or web access.","","Electronic:978-0-7695-4592-9; POD:978-1-4577-2116-8","10.1109/UCC.2011.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123494","Graphical Models;Trace Analysis;e-science infrastructures","Correlation;Joints;Maximum likelihood estimation;Measurement;Probabilistic logic;Text mining;Vectors","cloud computing;data mining;grid computing;information retrieval;natural sciences computing;social networking (online);text analysis","Web access;behavioral trace analysis;cloud computing;e-science file access behavior characterization;grid computing;latent Dirichlet allocation;probabilistic model;production grid;social network activity;text document;text mining","","0","","19","","","5-8 Dec. 2011","","IEEE","IEEE Conference Publications"
"Search Engine Optimization Based on Algorithm of BP Neural Networks","S. Wang; K. Xu; Y. Zhang; F. Li","Sch. of Vocational Educ., Jilin Teachers' Inst. of Eng. & Technol., Changchun, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","390","394","Every user has a distinct background and a specific goal when searching for information on the Web. The goal of Web search personalization is to tailor search results to a particular user based on that user's interests and preferences. This paper presents an approach of search engine optimization based on algorithm of BP neural networks aiming at meeting the increasing requirements of modern people to Internet information retrieval. The method makes the search engine more intelligent and personalized, which strives for providing optimum retrieval result to the users.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128052","BP Neural Networks;Implicit Feedback;Personalized search engine","Arrays;Artificial neural networks;Biological neural networks;Databases;Educational institutions;Search engines;Training","Internet;backpropagation;information retrieval;neural nets;search engines","BP neural network algorithm;Internet information retrieval;Web search personalization;search engine optimization;user interests;user preferences","","5","","13","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"Not All Is Gold That Glitters: Response Time & Satisfaction Rates in Yahoo! Answers","A. Rechavi; S. Rafaeli","Sagy Center for Internet Res., Univ. of Haifa, Haifa, Israel","2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing","20120102","2011","","","904","909","This study investigates two questions concerning question-and-answer sites. We analyzed data from ""Yahoo! Answers"", including 19 months and over 20 million interactions per month. The first question investigates the differences in response time and in the average number of answers between an asker's ranking of ""Best Answer"" (BA) and the community's BA. The second question concerns the impact of an explicit network on several implicit network activities. The results imply that askers use response time as a parameter to choose the BA, whereas the community chooses the BA with no regard to Answer Response Time (ART). Another finding implies that if the answerer is not listed in the asker's ""explicit network, "" it might result in longer ranking (award) time and in a slightly decreased number of answer stars (satisfaction-rate indicator). And yet, one result might be surprising. Being a ""fan"" of the asker implies a long response time to the question. This finding might contradict the intuition that our friends are the first to provide answers to our questions. Several explanations of this result from different research fields are suggested in the discussion.","","Electronic:978-0-7695-4578-3; POD:978-1-4577-1931-8","10.1109/PASSAT/SocialCom.2011.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113239","Response time;Satisfaction rates;Wisdom of the crowds;Yahoo! Answers","Awards activities;Barium;Communities;Internet;Social network services;Subspace constraints;Time factors","Web sites;question answering (information retrieval)","Yahoo;answer response time;answer stars;long response time;network activity;question-and-answer site;ranking time","","5","","39","","","9-11 Oct. 2011","","IEEE","IEEE Conference Publications"
"Efficient Fully Homomorphic Encryption from (Standard) LWE","Z. Brakerski; V. Vaikuntanathan","","2011 IEEE 52nd Annual Symposium on Foundations of Computer Science","20111222","2011","","","97","106","We present a fully homomorphic encryption scheme that is based solely on the (standard) learning with errors (LWE) assumption. Applying known results on LWE, the security of our scheme is based on the worst-case hardness of ""short vector problems"" on arbitrary lattices. Our construction improves on previous works in two aspects: 1) We show that ""somewhat homomorphic"" encryption can be based on LWE, using a new re-linearization technique. In contrast, all previous schemes relied on complexity assumptions related to ideals in various rings. 2) We deviate from the ""squashing paradigm"" used in all previous works. We introduce a new dimension-modulus reduction technique, which shortens the ciphertexts and reduces the decryption complexity of our scheme, without introducing additional assumptions. Our scheme has very short ciphertexts and we therefore use it to construct an asymptotically efficient LWE-based single-server private information retrieval (PIR) protocol. The communication complexity of our protocol (in the public-key model) is k · polylog(k) + log |DB| bits per single-bit query (here, A; is a security parameter).","0272-5428;02725428","Electronic:978-0-7695-4571-4; POD:978-1-4577-1843-4","10.1109/FOCS.2011.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6108154","Fully Homomorphic Encryption;Lattices;Learning with Errors","Complexity theory;Databases;Encryption;Lattices;Protocols","communication complexity;cryptographic protocols;data privacy;information retrieval;public key cryptography","LWE based single server private information retrieval protocol;ciphertext;communication complexity;decryption complexity;dimension modulus reduction technique;fully homomorphic encryption scheme;learning with error assumption;public key model;relinearization technique;short vector problem;somewhat homomorphic encryption;squashing paradigm;worst case hardness","","107","","38","","","22-25 Oct. 2011","","IEEE","IEEE Conference Publications"
"Research of Rapid Attention-Information Extraction in Human-Robot Interaction","G. Fei; X. Lun; L. Nan; W. Zhi-Liang","Sch. of Comput. & Commun. Eng., Univ. of Sci. & Technol. Beijing, Beijing, China","2011 Seventh International Conference on Computational Intelligence and Security","20120112","2011","","","316","320","In the human-robot interactions, it is an important research on the artificial intelligence that robots catch the human's attention information. This process has a significant impact on robot intelligence. In this paper, a system for extracting human's attention-information from interaction has been designed. On the basis of face detection and eye-area location, an algorithm, combined with ant colony algorithm(ACA) eye edge extracting, curve fitting and eye-model 3D reconstruction, has been designed to achieve attention information successfully by using an ordinary web cam and a low requirement hardware system. There is a significant help on real-time and applicability for human-robot visual interaction.","","Electronic:978-0-7695-4584-4; POD:978-1-4577-2008-6","10.1109/CIS.2011.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6128130","3D reconstruction;Ant Colony Al-gorithm (ACA);Attention;Edge Detection;Human-Robot Interaction","Algorithm design and analysis;Face detection;Feature extraction;Humans;Image edge detection;Iris;Three dimensional displays","ant colony optimisation;artificial intelligence;curve fitting;edge detection;face recognition;human-robot interaction;image reconstruction;information retrieval;intelligent robots;robot vision;solid modelling","ACA;ant colony algorithm;artificial intelligence;curve fitting;eye area location;eye edge extraction;eye model 3D reconstruction;face detection;human attention information extraction;human robot visual interaction;low requirement hardware system;robot intelligence;webcam","","0","","20","","","3-4 Dec. 2011","","IEEE","IEEE Conference Publications"
"An Advanced and Effective Literature Search Algorithm Based on Analytic Hierarchy Process","Q. Wang; C. Liu; Z. Wang","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications","20120102","2011","","","1264","1270","Currently, electronic literature becomes increasing common for its convenient and informative features, however, the sharp increase in the number of literature has brought certain difficulties for the users to manage and access to such literatures. This demand is satisfied to some extent by the literature search engines on some existing well-known websites. But such literature search does not take into account various elements thus the access efficiency is far from the expectation. To address this issue, this paper, combining with the demands of research institutes, teams and other small groups, has developed a literature search algorithm based on AHP (Analytic Hierarchy Process). This system fully considers all the aspects of elements and improves the literature search algorithm by applying analytic hierarchy model, thus enables the ranking of literature search results to be much more valuable and beneficial to the users. Research and testing have shown that, compared with Google Scholar, the proposed algorithm in this paper is more accurate, advanced and effective in accessing and managing literatures for the researchers in academic institutes.","2324-898X;2324898X","Electronic:978-0-7695-4600-1; POD:978-1-4577-2135-9","10.1109/TrustCom.2011.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120964","AHP;Literature search;ranking","Algorithm design and analysis;Analytical models;Eigenvalues and eigenfunctions;Indexes;Libraries;Search engines;Vectors","Web sites;content management;decision making;information retrieval;literature;search engines","AHP;Web sites;access efficiency;analytic hierarchy process;electronic literature;literature access;literature search algorithm;literature search engines","","0","","7","","","16-18 Nov. 2011","","IEEE","IEEE Conference Publications"
"Construction of tagged corpus for Nanodevices development papers","T. M. Dieb; M. Yoshioka; S. Hara","Graduate School of IST, Hokkaido University, Sapporo, Japan","2011 IEEE International Conference on Granular Computing","20120105","2011","","","167","170","Nanodevices development process is not well systematized. In order to support this development process, we have been working on an experimental record management system that aims at analyzing previous manufacturing experiments to provide an insight on future manufacturing. However, we found that experimental records do not have enough information for detailed analysis. In this paper, we propose an approach to extract extra information (metadata) from Nanodevices development papers that can enhance the analysis of experimental results.","","Electronic:978-1-4577-0371-3; POD:978-1-4577-0372-0","10.1109/GRC.2011.6122587","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122587","information extraction;nanodevice;tagged corpus","Color;Data mining;Educational institutions;Guidelines;Manufacturing;Nanoscale devices;Reliability","information retrieval;nanotechnology;records management","nanodevice development papers;nanodevice development process;record management system;tagged corpus","","1","","8","","","8-10 Nov. 2011","","IEEE","IEEE Conference Publications"
"Meta Search Engine Based on Prioritizor","B. K. Chaurasia; S. K. Gupta; R. Soni","ITM Univ., Gwalior, India","2011 International Conference on Computational Intelligence and Communication Networks","20111229","2011","","","512","514","Meta search engine searches information using multiple independent search engines. World wide web has been developed to a distributed information space nearly more than 800 million working stations and several billion pages, which brings the people great trouble in finding needed information although huge amount of information available on webs. The focus of this paper is to design and implementation of a meta search engine. The work is to develop prioritizor based and profile assisted meta search engine for merging the results extracted from two or more search engines. The results and analysis show that the improved the search quality to the specific specialty.","","Electronic:978-0-7695-4587-5; POD:978-1-4577-2033-8","10.1109/CICN.2011.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112920","Crawler;Meta-search engine;Prioritizor","Communication systems;Computational intelligence","Internet;information retrieval;search engines","World Wide Web;distributed information space;multiple independent search engines;prioritizor;profile assisted meta search engine","","0","","11","","","7-9 Oct. 2011","","IEEE","IEEE Conference Publications"
"Inferring Functional Groups from Microbial Gene Catalogue with Probabilistic Topic Models","X. Chen; T. T. He; X. Hu; Y. An; X. Wu","Coll. of Inf. Sci. & Technol., Drexel Univ., Philadelphia, PA, USA","2011 IEEE International Conference on Bioinformatics and Biomedicine","20120102","2011","","","3","9","In this paper, based on the functional elements derived from non-redundant CDs catalogue, we show that the configuration of functional groups in meta-genome samples can be inferred by probabilistic topic modeling. The probabilistic topic modeling is a Bayesian method that is able to extract useful topical information from unlabeled data. When used to study microbial samples (assuming that relative abundance of functional elements is already obtained by a homology-based approach), each sample can be considered as a 'document', which has a mixture of functional groups, while each functional group (also known as a 'latent topic') is a weight mixture of functional elements (including taxonomic levels, and indicators of gene orthologous groups and KEGG pathway mappings). The functional elements bear an analogy with 'words'. Estimating the probabilistic topic model can uncover the configuration of functional groups (the latent topic) in each sample. The experimental results demonstrate the effectiveness of our proposed method.","","Electronic:978-0-7695-4574-5; POD:978-1-4577-1799-4","10.1109/BIBM.2011.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120400","Bioinformatics databases;Biological data mining;Metagenomics;Probabilistic topic model","Bioinformatics;Biological system modeling;Data models;Databases;Genomics;Probabilistic logic;Vocabulary","Bayes methods;bioinformatics;genetics;information retrieval","Bayesian method;KEGG pathway mappings;functional groups;gene orthologous groups;homology-based approach;information extraction;latent topic;microbial gene catalogue;probabilistic topic models;taxonomic levels;topical information extraction;unlabeled data","","3","","16","","","12-15 Nov. 2011","","IEEE","IEEE Conference Publications"
"Finding Mutual Benefit between Subjectivity Analysis and Information Extraction","J. Wiebe; E. Riloff","University of Pittsburgh, Pittsburgh","IEEE Transactions on Affective Computing","20120112","2011","2","4","175","191","""Subjectivity analysis” systems automatically identify and extract information relating to attitudes, opinions, and sentiments from text. As more and more people make their opinions available on the Internet and as people increasingly consult the Internet to ascertain other people's opinions about products, political issues, and so on, the demand for effective subjectivity analysis systems continues to grow. Information extraction systems, which automatically identify and extract factual information relating to events of interest, remain critically important in this day and age of increasingly vast amounts of text available online. In this work, we discover that these research areas are mutually beneficial. Information extraction techniques may be used to learn informative clues of subjectivity. Then, by bootstrapping from a lexicon of subjectivity clues, we can build a subjective-objective sentence classifier that does not require annotated data as input. This classifier may then be used to improve information extraction performance, on data which have not been annotated for subjectivity, by improving precision.","1949-3045;19493045","","10.1109/T-AFFC.2011.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959154","Natural language processing;text analysis.","Algorithm design and analysis;Context modeling;Data mining;Feature extraction;Information analysis;Semantics;Syntactics","Internet;information retrieval;natural language processing;text analysis","Internet;bootstrapping;information extraction;information identification;mutual benefit;subjective-objective sentence classifier;subjectivity analysis system;subjectivity clue","","9","","75","","20110721","Oct.-Dec. 2011","","IEEE","IEEE Journals & Magazines"
"Performance Analysis and Improvement of Turkish Broadcast News Retrieval","S. Parlak; M. Saraclar","Department of Electrical and Computer Engineering, Rutgers University, Piscataway, NJ, USA","IEEE Transactions on Audio, Speech, and Language Processing","20120109","2012","20","3","731","741","This paper presents our work on the retrieval of spoken information in Turkish. Traditional speech retrieval systems perform indexing and retrieval over automatic speech recognition (ASR) transcripts, which include errors either because of out-of-vocabulary (OOV) words or ASR inaccuracy. We use subword units as recognition and indexing units to reduce the OOV rate and index alternative recognition hypotheses to handle ASR errors. Performance of such methods is evaluated on our Turkish Broadcast News Corpus with two types of speech retrieval systems: a spoken term detection (STD) and a spoken document retrieval (SDR) system. To evaluate the SDR system, we also build a spoken information retrieval (IR) collection, which is the first for Turkish. Experiments showed that word segmentation algorithms are quite useful for both tasks. SDR performance is observed to be less dependent on the ASR component, whereas any performance change in ASR directly affects STD. We also present extensive analysis of retrieval performance depending on query length, and propose length-based index combination and thresholding strategies for the STD task. Finally, a new approach, which depends on the detection of stems instead of complete terms, is tried for STD and observed to give promising results. Although evaluations were performed in Turkish, we expect the proposed methods to be effective for similar languages as well.","1558-7916;15587916","","10.1109/TASL.2011.2164531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5983479","Automatic speech recognition (ASR);speech retrieval;spoken document retrieval;spoken term detection","Indexing;Lattices;Materials;Speech;Speech recognition","indexing;information resources;information retrieval;speech recognition","Turkish broadcast news corpus;Turkish broadcast news retrieval;automatic speech recognition transcripts;index alternative recognition hypothesis;indexing unit;length-based index combination;out-of-vocabulary words;performance analysis;query length;speech retrieval system;spoken document retrieval system;spoken information retrieval collection;spoken term detection;word segmentation algorithm","","10","","49","","20110818","March 2012","","IEEE","IEEE Journals & Magazines"
"Birdlets: Subordinate categorization using volumetric primitives and pose-normalized appearance","R. Farrell; O. Oza; Ning Zhang; V. I. Morariu; T. Darrell; L. S. Davis","University of Maryland, College Park, USA","2011 International Conference on Computer Vision","20120112","2011","","","161","168","Subordinate-level categorization typically rests on establishing salient distinctions between part-level characteristics of objects, in contrast to basic-level categorization, where the presence or absence of parts is determinative. We develop an approach for subordinate categorization in vision, focusing on an avian domain due to the fine-grained structure of the category taxonomy for this domain. We explore a pose-normalized appearance model based on a volumetric poselet scheme. The variation in shape and appearance properties of these parts across a taxonomy provides the cues needed for subordinate categorization. Training pose detectors requires a relatively large amount of training data per category when done from scratch; using a subordinate-level approach, we exploit a pose classifier trained at the basic-level, and extract part appearance and shape information to build subordinate-level models. Our model associates the underlying image pattern parameters used for detection with corresponding volumetric part location, scale and orientation parameters. These parameters implicitly define a mapping from the image pixels into a pose-normalized appearance space, removing view and pose dependencies, facilitating fine-grained categorization from relatively few training examples.","1550-5499;15505499","Electronic:978-1-4577-1102-2; POD:978-1-4577-1101-5","10.1109/ICCV.2011.6126238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126238","","Birds;Ellipsoids;Feature extraction;Shape;Taxonomy;Training;Visualization","computer vision;image resolution;information retrieval;object detection;pose estimation","Birdlets;category taxonomy;computer vision;image pixels;part appearance extraction;pose detectors;pose-normalized appearance model;salient distinctions;shape information extraction;subordinate-level categorization;subordinate-level models;volumetric poselet scheme;volumetric primitives","","74","","50","","","6-13 Nov. 2011","","IEEE","IEEE Conference Publications"
"Grid Based Analysis Toolkit for Partial Wave Analysis","Z. Yang; R. T. Jones; C. Yin","Coll. of Software Eng., Tongji Univ., Shanghai, China","2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies","20120102","2011","","","161","166","To get the physics out of the data, GlueX relies entirely on an amplitude-based analysis-PWA (Partial Wave Analysis). We build a grid test platform to verify how computational and data grid can be used to process large scale dataset in PWA, and make PWA toolkit to be grid-enable. The work we did has demonstrated that grid is a promising computing architecture for PWA in GlueX project. We setup grid computational platform, which consists of three clusters. We also setup data grid platform using dCache and evaluate the file access performance of dCache. A new Condor wrapper for Open MPI is presented in this grid platform. Through revising ruby-PWA package, we parallel ruby-PWA in grid environment. We run some scaling test benchmarks, and the results show grid-enabled ruby-PWA gets high performance in multi-node amplitude analysis.","2379-5352;23795352","Electronic:978-0-7695-4564-6; POD:978-1-4577-1807-6","10.1109/PDCAT.2011.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6118945","Grid;MPI;Partial Wave Analysis;framework","Collaboration;Computer architecture;Educational institutions;Memory;Mesons;Physics;Security","application program interfaces;benchmark testing;grid computing;information retrieval;message passing;open systems;quantum computing","Condor wrapper;GlueX project;PWA toolkit;amplitude-based analysis;computational platform;dCache;data grid platform;file access performance;grid based analysis toolkit;grid test platform;large scale dataset;multinode amplitude analysis;parallel ruby-PWA package;partial wave analysis;scaling test benchmark","","0","","14","","","20-22 Oct. 2011","","IEEE","IEEE Conference Publications"
"ViPLab - A Virtual Programming Laboratory for Mathematics and Engineering","T. Richter; S. Rudlof; B. Adjibadji; H. Berlohr; C. Gruninger; C. D. Munz; C. Rohde; R. Helmig","Univ. of Stuttgart, Stuttgart, Germany","2011 IEEE International Symposium on Multimedia","20120109","2011","","","537","542","In the process of the implementation of the eBologna program of the European states and the recent change of the German university system from the Diploma to the Bachelor/Master system, studies at German universities have been redesigned, courses have been condensed and learning content has been re-structured into granular ""modules"", each of which requires an evaluation at the end of the semester. Simultaneously, the skills required for working as an engineer changed as well, handling of computer software, knowledge of mathematical or numerical algorithms and programming skills play an increasingly important role in the daily job routine of the working engineer. To support the learning by practical exercises, engineering faculties, mathematics and physics, and the Computing Center of the University of Stuttgart setup a project for implementing an online programming lab for teaching the required skills. The focus of this project is to provide easy access to the necessary software tools, avoid the overhead of installation and maintenance, and seamlessly integrate these tools into the eLearning infrastructure of the university. This paper describes the motivation and backgrounds, the software infrastructure and early results of this project.","","Electronic:978-0-7695-4589-9; POD:978-1-4577-2015-4","10.1109/ISM.2011.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6123403","eLearning;numerical mathematics;programming;virtual lab","Computers;Data visualization;Educational institutions;Electronic learning;Java;Programming;Software","Internet;computer science education;courseware;educational institutions;engineering education;information retrieval;interactive programming;mathematics computing;teaching","Computing Center;European states;German university system;University of Stuttgart;ViPLab;computer software;e-learning infrastructure;eBologna program;engineering faculties;granular module;learning content;mathematical algorithm;numerical algorithm;online programming lab;programming skills;software infrastructure;software tools;teaching;virtual programming laboratory","","0","","17","","","5-7 Dec. 2011","","IEEE","IEEE Conference Publications"
"Classification and Evaluation of Online Indexing Strategies","R. Hu; X. Zhang; P. Wang","Coll. of Software Eng., Southeast Univ., Nanjing, China","2011 International Conference on Technologies and Applications of Artificial Intelligence","20120102","2011","","","233","238","Most search engines have to face the dynamic nature of the web, and it becomes a big problem that how to offer near real-time query service while the underlying document collection increases dramatically every day. As a result, the online indexing approaches become one of the kernel research problems of information retrieval. In this paper, we first present a detailed classification of various online indexing strategies, from the classics to the state-of-the-arts. We then perform an evaluation on selected strategies. A new evaluation metric is introduced in this paper to characterize the dynamic performance when queries interact with online indexing concurrently. Evaluation results characterize the performance differences among strategies and indicate the future improvements on update and query performance.","2376-6816;23766816","Electronic:978-0-7695-4601-8; POD:978-1-4577-2174-8","10.1109/TAAI.2011.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120750","Massive Text Data;Merge;Online Index;Query","Educational institutions;HTML;Indexing;Internet;Merging;Partitioning algorithms","Internet;document handling;indexing;information retrieval;pattern classification;search engines","Web;classification;document collection;information retrieval;kernel research problems;online indexing strategies;real-time query service;search engines","","0","","21","","","11-13 Nov. 2011","","IEEE","IEEE Conference Publications"
"An architecture for web information agents","H. A. Sleiman; R. Corchuelo","University of Seville, ETSI Inform&#x00E1;tica, Sevilla E-41012, Spain","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","18","23","Many authors are researching on information extraction techniques to transform the semi-structured information in typical web pages into structured information. When a researcher devises a new technique, he or she has to validate it, which requires implementing it, experimenting, gathering precision and recall results, comparing it to others, and drawing conclusions. This involves an array of details that are specific to this technique, but many others that are actually shared with other proposals. Unfortunately, the literature does not provide a single up-to-date platform to guide software engineers and researches in the design and implementation of information extractors. In this paper, we present a platform to design and implement learners of information extraction rules. Due to space constraints, we focus on the class of learners that learn hierarchical transducers. We have implemented our platform, and we have validated it by means of three case studies.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121624","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121624","Information extraction;learning rules","Data mining;Indexes;Particle separators;Proposals;Software;Transducers;Web pages","Internet;information retrieval;learning (artificial intelligence);software agents;software engineering","Web information agents;Web pages;hierarchical transducers;information extraction techniques;learning;semi-structured information;software engineers","","3","","25","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"The XML hydrographic metadata system and the hydrographic survey metadata data base (HSMDB)","D. Neumann","National Oceanic and Atmospheric Administration, 1315 East0-West Highway, Station 6715, Silver Spring, Maryland 20910 USA","OCEANS'11 MTS/IEEE KONA","20111219","2011","","","1","5","Metadata is crucial for the efficient archiving and retrieval of hydrographic survey data. Currently, hydrographic metadata is created in multiple formats and housed in manually populated databases. NOAA's Office of Cost Survey (OCS) is developing tools, using eXtensible Markup Language (XML), to enable NOAA to provide structured XML packaging of information that will allow metadata to be constrained and parsed more efficiently for multiple outputs. When completed, this will support a more efficient, semi-automated workflow for capturing metadata throughout the hydrographic survey lifecycle. This lifecycle is from initial project instructions to final descriptive reports and other supporting documents. Part of the improved workflow is eliminating the manual input of metadata to the authoritative HSMDB at the National Geophysical Data Center (NGDC). Timely automated update will free Hydrographic survey Division (HSD) data control resources to focus on HSMDB population of archived hydrographic surveys. This will in turn enable different user communities to easily query and harvest more historic hydrographic survey information. This paper will first offer an overview of the current status and proposed end product of the XML system. Secondly, the interaction of this XML as an extract and insert tool for the HSMDB will be explored stressing the notion that “enter once, use multiple times” approach greatly reduces errors, while also increasing efficiency and usability.","0197-7385;01977385","Electronic:978-0-933957-39-8; Paper:978-1-4577-1427-6","10.23919/OCEANS.2011.6106954","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106954","","Aggregates;Databases;Marine vehicles;Tides;US Government agencies;XML","XML;geophysics computing;information retrieval;meta data","NOAA Office of Cost Survey;National Geophysical Data Center;National Oceanic and Atmospheric Administration;XML hydrographic metadata system;extensible markup language;hydrographic survey data archiving;hydrographic survey data retrieval;hydrographic survey metadata database","","0","","6","","","19-22 Sept. 2011","","IEEE","IEEE Conference Publications"
"Mapping data on a rotated grid in high-dimensions for lossless compression","Z. Fan; A. Ortega","Signal and Image Processing Institute, Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA","2011 18th IEEE International Conference on Image Processing","20111229","2011","","","585","588","Interactive navigation of large high-dimensional media datasets aims at allowing viewers to freely navigate content, selecting a subset of the high-dimensional visual data of interest for display. An example application would be remote visualization of an arbitrary 2-D planar cut from a large volumetric dataset with random access. In our previous work, we proposed a server-client based data representation and retrieval system using overlapping rotated tiles to represent the dataset, which lower the bandwidth required for accessing a random plane from large volume data. This leads to the question of how best to represent these rotated tiles for compression. In this paper we present a non-interpolated symmetric mapping algorithm, which maps each voxel in the original image to a rotated Cartesian grid point. We will show that this approach outperforms tile representation methods based on interpolation and non-symmetric mapping. In particular, the lack of interpolation means that complexity is significantly lower. Moreover, especially at high rates, remapping without interpolation will be shown to lead to overall better RD performance and the more symmetric the mapping is, the better RD performance will be achieved. Furthermore, a metric is proposed for automatically checking the mapping symmetry and measuring the percentage of the non-symmetric mapped points in the non-symmetric mapping algorithms.","1522-4880;15224880","Electronic:978-1-4577-1303-3; POD:978-1-4577-1304-0; USB:978-1-4577-1302-6","10.1109/ICIP.2011.6116617","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6116617","image retrieval;mapping;random access;tiling","Image coding;Interpolation;Measurement;Three dimensional displays;Tiles;Vectors","data compression;data structures;data visualisation;grid computing;image retrieval;information retrieval systems;interactive systems","RD performance;arbitrary 2D planar cut;automatic mapping symmetry checking;high-dimensional media dataset;high-dimensional visual data;interactive navigation;interpolation based tile representation method;interpolation mapping;lossless compression;mapping data;noninterpolated symmetric mapping algorithm;nonsymmetric mapping;random access;remote visualization;rotated Cartesian grid point;rotated grid;server-client based data representation;server-client based data retrieval system","","0","","12","","","11-14 Sept. 2011","","IEEE","IEEE Conference Publications"
"Mining answers for causal questions in a medical example","A. Sobrino; J. A. Olivas; C. Puente","Faculty of Philosophy University of Santiago de Compostela Santiago de Compostela, Spain","2011 11th International Conference on Intelligent Systems Design and Applications","20120102","2011","","","432","437","The aim of this paper is to approach causal questions in a medical domain. Causal questions par excellence are what, how and why-questions. The `pyramid of questions' shows this. At the top, why-questions are the prototype of causal questions. Usually why-questions are related to scientific explanations. Although cover law explanation is characteristically of physical sciences, it is less common in biological or medical knowledge. In medicine, laws applied to all cases are rare. It seems that doctors express their knowledge using mechanisms instead of natural laws. In this paper we will approach causal questions with the aim of: (1) answering what-questions as identifying the cause of an effect; (2) answering how-questions as selecting an appropriate part of a mechanism that relates pairs of cause-effect (3) answering why-questions as identifying ultimate causes in the answers of how-questions. In this task, we hypothesize that why-questions are related to scientific explanations in a negative and a positive note: (i) as previously said, scientific explanations in biology are based on mechanisms instead of natural laws; (ii) scientific explanations are generally concerned with deepening, providing explanations as detailed as possible. Thus, we conjecture that answers to why-questions have to find the ultimate causes in a mechanism and link them to the prior cause summarizing the intermediate nodes in order to provide a comprehensible answer. The Mackie's INUS causality offers a theoretical support for this solution.","2164-7143;21647143","Electronic:978-1-4577-1676-8; POD:978-1-4799-1697-9","10.1109/ISDA.2011.6121694","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6121694","answering causal questions;causal questions;imperfect causality;mechanisms","Blood;Cancer;Databases;Intelligent systems;Joining processes;Lungs;Materials","causality;cause-effect analysis;data mining;medical computing;medicine;question answering (information retrieval)","Mackie's INUS causality;biological knowledge;causal questions par excellence;cause-effect answering why-questions;cover law explanation;how-questions answering;intermediate nodes;medical domain;medical example;medical knowledge;medicine;mining answers;natural laws;what-questions","","0","","9","","","22-24 Nov. 2011","","IEEE","IEEE Conference Publications"
"Coalescing Twitter Trends: The Under-Utilization of Machine Learning in Social Media","M. Brennan; R. Greenstadt","Dept. of Comput. Sci., Drexel Univ., Philadelphia, PA, USA","2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing","20120102","2011","","","641","646","We demonstrate the effectiveness that machine learning can bring to improving social media platforms through a case study on Twitter trending topics. Social media relies heavily on tagging and often does not take advantage of machine learning advances. Twitter is no exception. Individual tweets are identified as being part of a trending discussion topic by the presence of a tagged keyword. Relying solely on this keyword, however, may be inadequate for identifying all the discussion associated with a trend. Our research demonstrates that machine learning techniques can be used identify the top trend a tweet belongs to with up to 85% precision without using the identifying keyword as a feature. This can aid in improving the quality of topic categorization by ensuring on-topic tweets that are missing the trend keyword are included, as well as suggest keywords to include in new tweets.","","Electronic:978-0-7695-4578-3; POD:978-1-4577-1931-8","10.1109/PASSAT/SocialCom.2011.160","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113187","machine learning;social media;twitter","Accuracy;Bayesian methods;Machine learning;Media;Support vector machines;Training;Twitter","information retrieval;learning (artificial intelligence);social networking (online)","Twitter trends;machine learning;social media;topic categorization","","0","","13","","","9-11 Oct. 2011","","IEEE","IEEE Conference Publications"
"Object-Level Data Model for Keyword Search over Relational Databases","J. Zhang; R. Shao","Sch. of Inf. Sci. & Technol., Dalian Maritime Univ., Dalian, China","2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications","20120102","2011","","","1361","1366","Keyword Search Over Relational Databases(KSORD) has been widely studied in recent years. However, existing KSORD methods are usually based on schema graph or data graph and they are actually tuple-level methods. That is, the retrieved objects are direct tuple-level relational data, and the retrieval results are tuple-connected trees which are difficult to be understood by end-users. There are still much work to do to further improve the effectiveness and efficiency of existing KSORD methods. The essential cause is that an entity is usually divided into some parts stored in different tables due to normalized relational database design. In fact, the relational data model is storage-oriented rather than end-user-oriented. Therefore, a novel method called Object-level Keyword Search Over Relational Databases(OKSORD) is proposed in this paper. In OKSORD method, relational data are modeled as an object- level data graph, in which each node may consist of several tuples to present the complete information of an entity. There are two key issues in OKSORD method, one is object-level data modeling for relational databases, the other is object-level searching and ranking based on object-level data graph. This paper mainly addresses the first issues. The main contributions are as follows. Firstly, the concept of OKSORD is introduced for the first time. Secondly, an algorithm for classifying relation schemas is proposed to partition relations into four categories: primary relations, secondary relations, linked relations and coding relations. Finally, an object-level data model for relational data is defined and the algorithm for generating corresponding object-level data graph is proposed.","2324-898X;2324898X","Electronic:978-0-7695-4600-1; POD:978-1-4577-2135-9","10.1109/TrustCom.2011.185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6120981","Object-Level Data Model;Relational Databases;Search","Classification algorithms;Data models;Encoding;Keyword search;Relational databases;Search problems","graph theory;information retrieval;pattern classification;relational databases;search problems;trees (mathematics)","OKSORD method;coding relations;direct tuple-level relational data model;object retrieval;object-level data graph;object-level data modeling;object-level keyword search;object-level searching;relation schemas;relational database;schema graph;tuple-connected tree;tuple-level method","","0","","19","","","16-18 Nov. 2011","","IEEE","IEEE Conference Publications"
