"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7832261,7828376,7832921,7829914,7833376,7832919,7831344,7830234,7832905,7830805,7830324,7829790,7829774,7832928,7831698,7829895,7779069,7731596,7820882,7819679,7823952,7821000,7824831,7819694,7823673,7821669,7824800,7820436,7823792,7816458,7814910,7814891,7816459,7814462,7817098,7810828,7816844,7817107,7815160,7814468,7817103,7817125,7816883,7811572,7815082,7810887,7817113,7813655,7814688,7815098,7817102,7813711,7817070,7816945,7816939,7817131,7817112,7813067,7814877,7816492,7812938,7814728,7814872,7817066,7817119,7816874,7723822,7809713,7809769,7811106,7811047,7807870,7809910,7808176,7811116,7809391,7809397,7810123,7805064,7806258,7805760,7807184,7804437,7806725,7805073,7803105,7802961,7803013,7803008,7801717,7800549,7800504,7801412,7801723,7801773,7765033,7796718,7795502,7796634,7797046",2017/05/04 22:08:38
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Research on Metadata Management Scheme of Distributed File System","L. Huo; R. Yi","Coll. of Comput. & Electron. Inf., Guangxi Univ., Nanning, China","2015 International Conference on Computer Science and Applications (CSA)","20170116","2015","","","37","41","Traditional distributed file system in availability, scalability, and data access performance has been difficult to meet the growing demand for data storage. This paper proposes a Metadata Server (MDS) Cluster scheme based on two-server high availability. On this basis, use a combination of a directory subtree partitioning and improved consistency hash algorithm divides the metadata, ensure the cluster load balancing and adapted to the change of the size of the cluster. For the load imbalance caused by the difference of data access during operation, propose a dynamic load balancing algorithm to adjust the load balance of cluster. Finally, the experimental results show that the scheme has good effect on the availability, access performance, load balance.","","CD:978-1-4799-9960-6; Electronic:978-1-4799-9961-3; POD:978-1-4799-9962-0","10.1109/CSA.2015.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810828","Consistent hash;Distributed file system;load balancing;metadata","Clustering algorithms;Delays;File systems;Heuristic algorithms;Metadata;Partitioning algorithms;Servers","distributed databases;information retrieval;meta data;resource allocation;storage management;trees (mathematics)","MDS;cluster load balancing;data access;data storage;directory subtree partitioning;distributed file system;metadata management scheme;metadata server;two-server high availability","","","","","","","20-22 Nov. 2015","","IEEE","IEEE Conference Publications"
"Application of Bloom Filter for Duplicate URL Detection in a Web Crawler","A. Kapoor; V. Arora","Comput. Sci. & Eng. Dept., Thapar Univ., Patiala, India","2016 IEEE 2nd International Conference on Collaboration and Internet Computing (CIC)","20170109","2016","","","246","255","A web crawler is an important component for web based information retrieval system. In this paper, a detailed study of an open-source map-reduce based web crawler, Apache Nutch has been done. In addition, the bloom filter methodology for de-duplicated URL list generation and updating in each iteration of the crawl, has been implemented. The bloom based approach is compared with the existing URL fetch-time approach (inherent to Nutch) in terms of time. Further, two types of hashes-jenkins hash and murmur hash have been used in the bloom filter; their performance in terms of time, false positive has been compared with each other. It has also been shown that the usage of this additional data structure, bloom filter in the proposed approach is memory-efficient. The paper is an attempt to improve upon the time-efficiency of a map-reduce based crawler. Using bloom filter, based upon comparison against different parameters our results indicate the efficiency and effectiveness of the proposed approach.","","Electronic:978-1-5090-4607-2; POD:978-1-5090-4608-9","10.1109/CIC.2016.042","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809713","Apache Nutch;Bloom Filter;Hashing;Search Engine;Web Crawling;Web Graph","Computer architecture;Computer science;Crawlers;Databases;Electronic mail;Search engines;Uniform resource locators","Internet;data structures;information retrieval;public domain software;search engines","Apache Nutch;Bloom Filter application;URL fetch-time approach;URL list generation;Web Crawler;bloom filter methodology;duplicate URL detection;hashes-jenkins hash;information retrieval system;murmur hash;open source map","","","","","","","1-3 Nov. 2016","","IEEE","IEEE Conference Publications"
"Relation extraction using dependency tree kernel for Bahasa Indonesia","D. S. Esperanti; A. Purwarianti","School of Electronic Engineering and Informatics, Institute Technology Bandung, Indonesia","2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA)","20170102","2016","","","1","6","Most studies on relation extraction for Bahasa Indonesia were usually done by using string matching method. This approach lacked the syntactical information of the original text data. This paper offers an alternative approach of tree kernel method having advantage of preserving the sentence structure. Each sentence from the text is represented as a dependency parse tree. The tree kernel will calculate the similarity between the trees. Intuitively, the use of dependency structure would yield more accurate result since the related entities would closely connected to each other. Here, we compared our work with bag of word method. In the bag of word method, each pair of possibly related entities within the sentence, the shortest sub sentence containing both entities will be transformed into a feature vector. The similarity between two feature vectors will be calculated using a dot product. The experiments showed that the tree kernel method outperformed the bag of words method. On average, the tree kernel method yielded 77.3% on accuracy while the best bag of words method only had 71.8%. As a trade off, this method runs slower about ~50x longer than the bag of words method. At the final method, we tried the combined kernel and held the best result with 78.7% accuracy.","","Electronic:978-1-5090-1636-5; POD:978-1-5090-1637-2","10.1109/ICAICTA.2016.7803105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803105","Bahasa Indonesia;Dependency Tree Kernel;Relation Extraction","Convolution;Indexes;Kernel;Natural language processing;Runtime","information retrieval;natural language processing;text analysis;trees (mathematics);vectors","Bahasa Indonesia;dependency parse tree;dependency structure;dot product;feature vector;relation extraction;sentence structure;shortest sub sentence;string matching;tree kernel","","","","","","","16-19 Aug. 2016","","IEEE","IEEE Conference Publications"
"Understanding Question Quality through Affective Aspect in Q&A Site","J. Jiarpakdee; A. Ihara; K. I. Matsumoto","Grad. Sch. of Inf. Sci., Nara Inst. of Sci. & Technol., Ikoma, Japan","2016 IEEE/ACM 1st International Workshop on Emotional Awareness in Software Engineering (SEmotion)","20161229","2016","","","12","17","Ever since the Internet has become widely available, question and answer sites have been used as a knowledge sharing service. Users ask the community about how to solve problems, hoping that there will be someone to provide a solution. However, not every question is answered. Eric Raymond claimed that how an user asks a question is important. Existing studies have presented ways to study the question quality by textual, community-based or affective features. In this paper, we investigated how affective features are related to the question quality, and we found that using affective features improves the prediction of question quality. Moreover, Favorite Vote Count feature has the highest influence on our prediction models.","","Electronic:978-1-4503-4169-1; POD:978-1-5090-2212-0","10.1109/SEmotion.2016.012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801412","Affective Aspect;Sentimental Analysis;Stack Overflow","Analytical models;Computational modeling;Data analysis;Data mining;Data models;Feature extraction;Internet","Internet;question answering (information retrieval)","Favorite Vote Count feature;Internet;Q&A site;affective aspect;community-based features;knowledge sharing service;prediction models;question quality;textual features","","","","","","","17-17 May 2016","","IEEE","IEEE Conference Publications"
"Social Influence Analysis in Social Networking Big Data: Opportunities and Challenges","S. Peng; G. Wang; D. Xie","Guangdong Univ. of Foreign Studies, Guangzhou, China","IEEE Network","20170120","2017","31","1","11","17","Social influence analysis has become one of the most important technologies in modern information and service industries. It will definitely become an essential mechanism to perform complex analysis in social networking big data. It is attracting an increasing amount of research ranging from popular topics extraction to social influence analysis, including analysis and processing of big data, social influence evaluation, influential users identification, and information diffusion modeling. We provide a comprehensive investigation of social influence analysis, and discuss the characteristics of social influence and the architecture of social influence analysis based on social networking big data. The relationship between big data and social influence analysis is also discussed. In addition, research challenges relevant to real-world issues based on social networking big data in social influence analysis are discussed, focusing on research issues such as scalability, data collection, dynamic evolution, causal relationships, network heterogeneity, evaluation metrics, and effective mechanisms. Our goal is to provide a broad research guideline of existing and ongoing efforts via social influence analysis in large-scale social networks, and to help researchers better understand the existing work, and design new algorithms and methods for social influence analysis.","0890-8044;08908044","","10.1109/MNET.2016.1500104NM","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7731596","","Algorithm design and analysis;Analytical models;Big data;Mathematical model;Measurement;Social network services","Big Data;Internet;data analysis;information retrieval;social networking (online)","Web 2.0 technology;social influence analysis;social networking Big Data;topic extraction","","","","","","20161103","January/February 2017","","IEEE","IEEE Journals & Magazines"
"Evolving Requirements-to-Code Trace Links across Versions of a Software System","M. Rahimi; W. Goss; J. Cleland-Huang","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, South Bend, IN, USA","2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20170116","2016","","","99","109","Trace links provide critical support for numerous software engineering activities including safety analysis, compliance verification, test-case selection, and impact prediction. However, as the system evolves over time, there is a tendency for the quality of trace links to degrade into a tangle of inaccurate and untrusted links. This is especially true with the links between source-code and upstream artifacts such as requirements - because developers frequently refactor and change code without updating the links. We present TLE (Trace Link Evolver), a solution for automating the evolution of trace links as changes are introduced to source code. We use a set of heuristics, open source tools, and information retrieval methods to detect common change scenarios across different versions of software. Each change scenario is then associated with a set of link evolution heuristics which are used to evolve trace links. We evaluate our approach through a controlled experiment and also through applying it across 27 releases of the Cassandra Database System. Results show that the trace links evolved using our approach are significantly more accurate than those generated using information retrieval alone.","","Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7","10.1109/ICSME.2016.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816458","Evolution;Maintenance;Traceability","Computer science;Conferences;Crawlers;Feature extraction;Software systems","formal specification;formal verification;information retrieval;program diagnostics;public domain software;software tools;source code (software);systems analysis","TLE;information retrieval;open source tool;requirements-to-code trace link;software engineering;software system version;source code;trace link evolver;traceability;upstream artifact","","","","","","","2-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Early Warning of City-Scale Unusual Social Event on Public Transportation Smartcard Data","H. Wang; X. Chen; S. Qiang; H. Zhang; Y. Wang; J. Shi; Y. Jin","State Key Lab. of Adv. Opt. Commun. Syst. & Network, Shanghai Jiao Tong Univ., Shanghai, China","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","188","195","A sudden social crowd event is serious to public safety as it usually triggers huge number of people who are overwhelming to existing public facilities. Detection, early warning of such social crowd events is very important to the city administration but a very challenging problem in research. In this paper, we aim to solve this problem by using the non-sensitive data from public transportation smartcard. We make a detailed analysis of the traffic of people from smartcard data,, we find a 'two-peak' pattern of human flow before, after a social crowd event happening. Motivated by this finding, we propose a framework for early detection of unusual social crowd events by exploiting time series analysis, machine learning technology. We evaluate our model on the real world public transportation data of the biggest metropolitan of China, validate our model with social crowd event data retrieved from the Internet. The evaluation result shows the effectiveness of our model.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816844","crowd behavior;early warning;public transportation;smartcard;social event","Data models;Hidden Markov models;History;Mobile handsets;Public transportation;Urban areas","Internet;data analysis;information retrieval;intelligent transportation systems;learning (artificial intelligence);public transport;smart cards;time series","Internet;data retrieval;early warning;machine learning;public safety;public transportation smart card data;social event detection;time series analysis;traffic analysis;two-peak pattern","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"On the Correctness of a Two-Round Multi-Keyword Top-k Ciphertext Retrieval","X. Ding; X. Wang; Y. Shao","Dept. of Imformation Manage., Sichuan Univ., Chengdu, China","2017 9th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)","20170126","2017","","","377","379","Yu et al. proposed a two-round multi-keyword ciphertext retrieval TRMCR) scheme by employing a vector space model and homomorphic encryption. A distinctive feature is to support top-k multi-keyword retrieval and hence TRMCR is an excellent choice for searching encrypted data over cloud with a desirable property of data privacy-preserving. Correct decryption is one of the fundamental requirements for the ciphertext retrieval. In this paper, we find that TRMCR can not achieve correct decryption, as we find that the underlying modified fully homomorphic encryption will result in a decryption error due to the growth of exponential noise. To solve the problem of incorrect decryption, we amend the original TRMCR by adjusting the parameter setup.","","Electronic:978-1-5090-4868-7; POD:978-1-5090-4869-4","10.1109/ICMTMA.2017.0098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832261","ciphertext retrieval;cloud computing;correct decryption;homomorphic encryption","Cloud computing;Encryption;Indexes;Privacy;Servers","cloud computing;cryptography;data privacy;information retrieval","TRMCR scheme;data privacy-preserving;decryption error;encrypted data searching;exponential noise growth;incorrect decryption problem;modified fully homomorphic encryption;two-round multikeyword top-k ciphertext retrieval scheme;vector space model","","","","","","","14-15 Jan. 2017","","IEEE","IEEE Conference Publications"
"Evaluating L2 Phrases from Google Translation and L1-L2 Dictionaries Using Google Search","T. D. Dang; K. G. D. Thi","Fac. of Inf. Technol., HCMC Univ. of Technol. & Educ., Ho Chi Minh City, Vietnam","2016 3rd International Conference on Green Technology and Sustainable Development (GTSD)","20161226","2016","","","132","134","The L1-L2 dictionaries (e.g. Chinese-English dictionaries for Chinese users) and translation tools (e.g. Google Translation) play an important role in sca ffolding L2 writers (e.g. Chinese people who write in English as a second/foreign language) in solving lexical problems in the L2 writing process. However, these tools lack a validation mechanism to support users to validate the returned L2 entries, and to incorporate chosen items into continuous text following accepted collocations. As a result, users face difficulties in choosing appropriate word(s) to convey the intended meaning, leading wrong or inappropriate use of words or phrases for given contexts. This paper proposes a Google Search based model for evaluating L2 phrases/words returned by the L1-L2 dictionaries or translation tools. A pilot experiment was conducted to evaluate the model. The preliminary results show that the model is reliable.","","Electronic:978-1-5090-3638-7; POD:978-1-5090-3639-4","10.1109/GTSD.2016.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796634","Google Translation;L1-L2 dictionaries;L2 writing;crowdsourcing;word retrieval","Dictionaries;Encyclopedias;Google;Production;Reliability","dictionaries;information retrieval;language translation;search engines;text analysis","Chinese-English dictionaries;Google search;Google translation;L1-L2 dictionaries;L2 phrases;L2 words;L2 writing process;lexical problems;translation tools;word retrieval","","","","","","","24-25 Nov. 2016","","IEEE","IEEE Conference Publications"
"Leveraging Large Corpora Using Internet Search for Question Answering","S. Gallagher; W. Zadrozny","Coll. of Comput. & Inf., Univ. of North Carolina at Charlotte, Charlotte, NC, USA","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","532","535","In this experiment, we measure the potential contribution of internet search to question answering. The task is to correctly answer Jeopardy! questions, and for doing so we use our existing question answering system, ""Watsonsim"", the architecture of which follows the original IBM Watson. We compare the answering precision and recall with and without internet search data from Microsoft's Bing. To accommodate the new sources we included several additional procedures, in particular merging candidate answers with similar meaning, and removing any candidate answers which are forbidden. The experiments show the potential of the internet search to improve question answering in terms of both the accuracy and recall: the top rank accuracy increased by around 14%, reaching 20% precision, compared to only 6% precision when using local search, and the recall improved by 20%, reaching 52%, up from 32% using only local search engines. Tweaks to better handle web results later raised top-rank accuracy an additional 21%, reaching 41% precision, and raised recall by another 19%, to reach 71% recall. The overall conclusion of our experiments was to show that in question answering, a network enabled system can compensate for a smaller corpus and provide reasonably good answers.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817107","question answering;search engine","Computer architecture;Encyclopedias;Internet;Knowledge discovery;Merging;Pipelines","question answering (information retrieval);search engines","Internet search;Microsoft Bing;Watsonsim system;question answering;search engines","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Memory-Based Data Management for Large-Scale Distributed Rendering","R. Zheng; J. Jia; H. Jin; X. Lv; S. Yang","Services Comput. Technol. & Syst. Lab., Huazhong Univ. of Sci. & Technol., Wuhan, China","2016 IEEE 13th International Conference on e-Business Engineering (ICEBE)","20170109","2016","","","123","128","With the increasing requirements of large-scale animation rendering, I/O congestion has become one of the main bottlenecks to constrain the whole performance seriously. What's worse, frequent rendering data access in remote storages brings a heavy burden of storage and delay of data access. Distributed Memory caching System for Rendering (RenDMS) is proposed to alleviate I/O congestion and improve data access performance. Rendering data is accessed from memories but not remote storages to reduce the overhead of data access and transmission. The concept of rendering unit is put forward to cluster rendering nodes, and MPI-based RPC, two-level data management, and dynamic adaptive placement are proposed to make rendering performance much better. Experiments have demonstrated the effectiveness of RenDMS. Compared with direct remote disk access, parallel rendering with RenDMS can not only shorten data access time more than 40%, but also speedup the execution of rendering applications efficiently.","","Electronic:978-1-5090-6119-8; POD:978-1-5090-6120-4","10.1109/ICEBE.2016.029","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809910","","Animation;Data communication;Distributed databases;Engines;Lenses;Memory management;Rendering (computer graphics)","computer animation;data handling;information retrieval;rendering (computer graphics);storage management","I/O congestion;MPI-based RPC;RenDMS;data access performance improvement;data transmission;distributed memory caching system for rendering;dynamic adaptive placement;frequent rendering data access;large-scale animation rendering;large-scale distributed rendering;memory-based data management;parallel rendering;remote storages;rendering node clustering;two-level data management","","","","","","","4-6 Nov. 2016","","IEEE","IEEE Conference Publications"
"Centrality-based caching for privacy in Information-Centric Networks","N. Abani; M. Gerla","University of California, Los Angeles, USA","MILCOM 2016 - 2016 IEEE Military Communications Conference","20161226","2016","","","1249","1254","Information Centric Networking (ICN) is a proposal for a future network architecture that shifts from the current end-to-end host based TCP/IP internet architecture by prioritizing content rather than hosts. To this end, ICN relies on in-network caching where routers cache content they have seen with the hope of satisfying future requests for the same content and relieving the original data servers. While in-network caching proved beneficial for a more efficient retrieval of content, it has also caused the emergence of several privacy risks. Timing attacks are one such privacy breach where attackers use timing analysis of data retrievals to analyze users' interests in particular content. In this paper, we propose centrality-based caching to mitigate such attacks and use the anonymity set privacy metric to show that our strategy does provide privacy guarantees. Moreover, our simulations show that we can still achieve high hit rates and low delays while alleviating the network's vulnerability to timing attacks.","","Electronic:978-1-5090-3781-0; POD:978-1-5090-3782-7","10.1109/MILCOM.2016.7795502","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795502","","Computer security;Delays;Privacy;Probes;Servers","Internet;cache storage;computer network security;data privacy;information retrieval;network servers;transport protocols","ICN;anonymity set privacy metric;centrality-based caching;data retrievals;data servers;end-to-end host based TCP-IP Internet architecture;future network architecture;in-network caching;information-centric network privacy;network vulnerability;privacy breach;privacy risks;timing attacks","","","","","","","1-3 Nov. 2016","","IEEE","IEEE Conference Publications"
"Reduction in web latency through novel prefetching techniques","T. M. V. G. Swamy; G. T. Raju","Department of ISE, GM Institute of Technology, Davanagere, Visvesvaraya Technological University, Karnataka","2016 IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","20170109","2016","","","1946","1949","The internet play an vital role in accumulating the Data, even from different location, easily available to all users all over the world. However, the majority of this data are not of much concern to most of the web users as their interest vary over the time. Nowadays there exists more than a billion web sites providing necessary information to users with precise data within fewer page access delay. But the traffic on the internet has increased considerably and the network resources will be full of activity all the time due to this, delay increases, by this it degrades the efficiency of the web site. Hence there is a considerable need to lessen the web page access delay, which increases the performance of the web site. In order to decrease the web page access delay, knowing the user interest is most significant to handle the web page in a cache memory. The goal of this research is to minimize the web latency by using FSPs, to identifying Most Promising Pages, which are to be brought to the cache Memory.","","Electronic:978-1-5090-0774-5; POD:978-1-5090-0775-2","10.1109/RTEICT.2016.7808176","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7808176","Prefetching;Sequential patterns;Web usage mining","Conferences;Data mining;Delays;Market research;Prefetching;Web pages","Web sites;information retrieval;storage management","FSPs;Internet traffic;Web latency minimization;Web page access delay;Web sites information;Web user interest;cache memory;prefetching techniques","","","","","","","20-21 May 2016","","IEEE","IEEE Conference Publications"
"Using Collaborative Based Algorithm for Efficient Management of Limited Resources on Social Networks","V. Xhafa; K. Rrmoku; B. Rexha","Fac. of Electr. & Comput. Eng., Univ. of Prishtina, Prishina, Kosovo","2016 Third International Conference on Mathematics and Computers in Sciences and in Industry (MCSI)","20170116","2016","","","289","295","With all features and resources, such as: social actors, social relations, content, communication, and ratings that todays' social networks like Facebook, LinkedIn, Twitter, Google+, etc. offer to users, it still appears that at given point we have to refine and optimize our own accounts within the limits of a certain social network. In line with this trend, in this paper we present a model for efficient management of friends list in Facebook, as one of the limited resource in this social network. In order to get users data from Facebook, a web scraping technique combined with reverse image search has been adopted to ensure users authenticity. The activity between nodes (friends) on a social network is calculated based on their interactions in terms of likes, comments, shares and posts between each other. This approach led us into designing and implementing an algorithm based in these collaborative metrics, named ""weight of relationship"". This algorithm calculates weights between friends on a network, and the results are evaluated by comparing these weights with respondent answers, conducted through personalized questionnaire. Consequently, this methodology brings feasible results, with an average accuracy of 71% on recommending which friends should be removed, thus releasing the space for incoming new friends. An app named RateMyFriends is developed based on presented approach.","","Electronic:978-1-5090-0973-2; POD:978-1-5090-0974-9","10.1109/MCSI.2016.060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815160","Social networks;Web scraping;algorithm;application;efficiency","Algorithm design and analysis;Collaboration;Facebook;HTML;Internet;Privacy","Internet;data handling;information retrieval;social networking (online)","Facebook user data;RateMyFriends app;Web scraping technique;collaborative based algorithm;friends list efficient management;resource management;reverse image search;social actors;social network interactions;social relations;weight of relationship","","","","","","","27-29 Aug. 2016","","IEEE","IEEE Conference Publications"
"Simple Interrogative Sentence Analysis Based on CRF","W. Zheng; Z. Lijun; X. Shuo; Z. Ning; Y. Yingying; L. Weifeng","Inst. of Sci. & Tech. Inf. of China, Beijing, China","2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW)","20170116","2016","","","21","24","[Objective] This paper intends to enhance the simple interrogative sentence analysis , which leads question answering system to understand ”What is this question asking?”. [ Methods] Under the condition that simple interrogative sentence analysis is regarded as a sequence labelling problems, Conditional Random Field (CRF) model can process it well. [Results] Few manual label can lead to promoted result. [Limitations] For non-factual problems processing needs exceed the defined label system support.[Conclusions] Using Conditional Random Field model to process question analysis problem, which is regarded as a sequential labelling problem, can improve handling capacity with relatively little cost.","","Electronic:978-1-5090-4771-0; POD:978-1-5090-4772-7","10.1109/WIW.2016.018","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814468","Cognitive Law;Conditional Random Fields;Interrogative sentence Analysis;Question Answering System;Sequential Labelling","Analytical models;Complexity theory;Databases;Feature extraction;Knowledge based systems;Knowledge discovery;Labeling","natural language processing;question answering (information retrieval);statistical analysis","CRF model;NLP-based application;conditional random field model;defined label system support;handling capacity improvement;question analysis problem;question answering system;sequence labelling problems;sequential labelling problem;simple interrogative sentence analysis","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Augmented Reality Solution for Retail Using Visual Commerce Engine","M. A. Kodandarama; S. Chandrashekar","Preksh Innovations Pvt. Ltd., Bangalore, India","2016 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)","20170119","2016","","","173","175","Currently, the e-commerce platforms or websites are designed such that users search for products and they are not ""store centric"" rather product centric. Browsing products over such websites does not add any value to the stores. The below abstract shows the method and system of a Visual Commerce Engine. In this system, stores can come online and showcase their products and improve their branding in the marketplace. This system works best for stores where visual appeal plays a vital role. We are bridging the gap of a faraway shopper with the store, where the shopper can visit the store online, view the products (as if in store) and buy them on the spot in the high quality 360° virtual tour. We have added many shopping features (built using our software toolsets) which will give the shopper an interactive real experience in the store.","","Electronic:978-1-5090-4573-0; POD:978-1-5090-4574-7","10.1109/CCEM.2016.041","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819694","Augmented reality for retail;Customer Engagement;Virtual guided tour for retail shopping;Visual Commerce","Art;Augmented reality;Business;Electronic commerce;Engines;Standards;Visualization","Internet;Web sites;augmented reality;electronic commerce;information retrieval;retail data processing","augmented reality;e-commerce Websites;e-commerce platforms;online store;product centric search;retail;software toolsets;visual commerce engine","","","","","","","19-21 Oct. 2016","","IEEE","IEEE Conference Publications"
"Applying Community Detection Methods to Cluster Tags in Multimedia Search Results","T. Bracamonte; A. Hogan; B. Poblete","Dept. of Comput. Sci., Univ. of Chile, Santiago, Chile","2016 IEEE International Symposium on Multimedia (ISM)","20170119","2016","","","467","474","Multimedia searches often return items that can be categorized into several ""topics"", allowing users to disambiguate and explore answers more efficiently. In this paper we investigate methods for clustering tags associated with multimedia search results, where each resulting cluster represents a topic computed online for that particular search. We specifically investigate the applicability of community detection algorithms to the tag graph induced from the search results. This type of approach allows us to exploit tag similarity and create ad-hoc topics for each search, without specify the number and sizes of clusters a priori. In this work we experiment with well-known algorithms in this field and propose two new methods based on adaptive island cuts. Using the Social20 dataset (a collection gathered from Flickr) we evaluate several community detection methods, with quantitative analysis of each algorithm in terms of the relative number of communities (which we interpret as topics) that they produce and their sizes, as well as qualitative analysis of topics per human judgement. Our evaluation shows that it is possible to extract ad-hoc topics for search results using community detection, but that different community detection methods produce very different results. In particular, our proposed methods produce more compact and less noisy clusters as well as less relative recall when compared to methods that produce much larger clusters.","","Electronic:978-1-5090-4571-6; POD:978-1-5090-4572-3","10.1109/ISM.2016.0106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823673","community detection;multimedia retrieval;tag clustering;topic detection","Clustering algorithms;Detection algorithms;Image edge detection;Multimedia communication;Search engines;Search problems;Taxonomy","information retrieval;multimedia systems;pattern clustering;social networking (online)","Social20 dataset;ad-hoc topic extraction;adaptive island cuts;community detection;multimedia search results;quantitative analysis;tag clustering;tag similarity","","","","","","","11-13 Dec. 2016","","IEEE","IEEE Conference Publications"
"Development and Evaluation of an Operational Service Robot Using Wikipedia-Based and Domain Ontologies","H. Asano; T. Morita; T. Yamaguchi","Keio Univ., Yokohama, Japan","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","511","514","Recently, the use of service robots has increased considerably and their social contribution is expected. It is desirable that a robot, as a provider of operational information, can answer questions in both the open domain and intended operations, to respond to questions in a manner that satisfies users. This paper proposes a question answering system that can respond to questions in both intended operations and open domain by linking an ontology, which is semi-automatically built from Wikipedia (Wikipedia-based ontology), with a domain ontology.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0086","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817103","Domain Ontology;Question Answering;Robot;Wikipedia-based Ontology","Electronic publishing;Encyclopedias;Internet;Knowledge discovery;Ontologies;Service robots","Web sites;control engineering computing;ontologies (artificial intelligence);question answering (information retrieval);service robots","Wikipedia-based ontology;domain ontology;open domain;operational service robot;question answering system;social contribution","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Handicraft Women Recommendation Approach Based on User's Social Tagging Operations","S. Kichou; H. Mellah; O. Boussaid; A. Meziane","DSISM, CERIST, Algiers, Algeria","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","618","621","Recommendation predicts which items the user might be interested in, and aims to help users finding the adequate element. Such as movies, music and commercial products, persons may be also recommended. In the case of handicraft women, we propose a recommendation approach based on extracted user's interest using his/her social tagging operations to improve business activities of the handicrafts women, the approach is applied with preliminary tests.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817125","Recommendation;User interest;handicraft woman;social tagging;user profile","Business;Ceramics;Collaboration;Context;Recommender systems;Tagging","information retrieval;recommender systems","handicraft women recommendation approach;social tagging operations","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Topic Cohesion Preserving Requirements Clustering","J. Misra; S. Sengupta; S. Podder","Accenture Technol. Labs., Bangalore, India","2016 IEEE/ACM 5th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE)","20170109","2016","","","22","28","This paper focuses on the problem of generating human interpretable clusters of semantically related plain-text requirements. Presented approach applies techniques from information retrieval, natural language processing, network analysis, and machine learning for identifying semantically central terms as themes and clustering requirements into semantically coherent groups together with meaningful explanatory themes associated with the clusters to assist in user comprehension of the clusters. Presented approach is generic in nature and can be used for other phases of SDLC (Software Development Life Cycle) including code-comprehension and architectural discovery. Suggested approach is particularly suitable for developing automated tool support for requirements management and analysis.","","Electronic:978-1-4503-4165-3; POD:978-1-5090-0132-3","10.1109/RAISE.2016.012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809769","Requirements Management; Requirements Analysis; Latent Semantic Analysis; Requirements Clustering; Network Centrality; Theme Mining; Clustering Interpretation Problem","Context;Data mining;Natural languages;Requirements management;Semantics;Software;Tagging","information retrieval;learning (artificial intelligence);natural language processing;pattern clustering;systems analysis","SDLC;architectural discovery;code-comprehension;information retrieval;machine learning;natural language processing;network analysis;requirements management;software development life cycle;topic cohesion preserving requirements clustering","","","","","","","17-17 May 2016","","IEEE","IEEE Conference Publications"
"A System for Facilitating Discussion in Business Simulation Exercises Based on the Dual-Advising Model","R. Kurita; M. Darai; M. Kusano; M. Kiuchi; C. S. Aie","Facul. Bus. Adm., Josai Univ. Sakado, Saitama, Japan","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","489","495","The aim of this study has been to develop a system for facilitating practical discussions in business simulation exercises with a focus on discussion processes. This system provides the total environment to enable automatic advice provision in real time, proper guidance by a teacher based on understanding of specific circumstances. We initially propose a mechanism for presenting the details of discussions to teachers so that they can easily understand each situation during an exercise. Our system records detailed conversations during discussions by each student group until the group's decision-making is completed. The system then presents the recorded conversations to teachers in an easily understandable manner. Moreover, our system is equipped with functions for commenting, question-and-answer sessions. These functions enable teachers to provide real-time guidance through careful monitoring of the exercise situations. Next, we carefully analyzed actual discussion data. On the basis of this analysis, we constructed a case-base for automatically generating advice, designed a way to present this advice to students. This paper also describes the development of a prototype system based on the above methods. The features of our system are discussed based on a practical experiment.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816883","PBL;business simulation exercise;discussion process;discussion support system;dual-advising model","Computational modeling;Decision making;Monitoring;Real-time systems;Speech;Training","commerce;decision making;question answering (information retrieval);simulation","automatic advice provision;business simulation;decision making;dual-advising model;question-and-answer sessions","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"Advances in real-time indexing models and techniques for the web of things","C. Manta-Caro; J. M. Fernández-Luna","Department of Computer Science and AI, University of Granada, Granada, 18071, Spain","2016 8th IEEE Latin-American Conference on Communications (LATINCOM)","20170116","2016","","","1","6","Real-time indexing is a core component in retrieval systems and search services of any type in complex domains ranging from analytics to the Web of Things. As greatest challenges, the efficiency, scalability, and performance are central factors to consider at any level when designing or building an index. The multidimensional characteristics of data exposed by smart things interacting with the World concerning volume, velocity, variety, and volatility (4V) leverage advances and research in models and techniques for the indexing process. We present a state-of-the-art regarding them focusing on the Web of Things and related research areas such as Big data. Furthermore, we propose a methodology for comparing them and some guidelines for designing real-time indexes for the Web of Things. Our novel approach brings together the recent advances in traditional domains and adjusts models and techniques for the emerging Web of Things.","","Electronic:978-1-5090-5137-3; POD:978-1-5090-5138-0; USB:978-1-5090-4758-1","10.1109/LATINCOM.2016.7811572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811572","","Big data;Cloud computing;Data models;Data structures;Indexing;Real-time systems","Internet;Internet of Things;indexing;information retrieval","4V model;Web of Things;multidimensional characteristics;real-time indexing;retrieval systems;search services;smart things;volume-velocity-variety-volatility model","","","","","","","15-17 Nov. 2016","","IEEE","IEEE Conference Publications"
"Proposal of the review recommendation system using the concurrent network","R. Shiraishi; K. Otake; T. Namatame","Graduate School of Science and Engineering, Chuo University 1-13-27, Kasuga, Bunkyo-ku, Tokyo 112-8551, Japan","2016 Future Technologies Conference (FTC)","20170119","2016","","","616","621","Recently, reviews of goods are one of the important factors which have an influence on the consumer's buying behavior. Under the situation, information aggregation of reviews has attracted much attention in electronic commerce (EC) site. In this study we propose a review recommendation system target on golf EC site. In our proposal system, reviews are scored by the evaluation of characteristic words which were obtained by TF-IDF and reputation analysis. Moreover, our proposal system visualize concurrent network using concurrent relations between the characteristic words. In order to verify the effectiveness of our proposal system, we conducted an experimental evaluation. In the experimental evaluation, we compared our proposal reviews with other review (selected randomly, recently date and reference counts). As the result, it was found that the result score of our proposed reviews were almost the same as the result score of reference count. Moreover, we received positive evaluation about concurrent network. Through these experimental evaluate, we consider that the effectiveness of this system was successfully verified.","","Electronic:978-1-5090-4171-8; POD:978-1-5090-4172-5","10.1109/FTC.2016.7821669","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821669","EC site;Recommendation;Review","Electronic mail;Internet;Media;Proposals;Shafts;Trajectory;Visualization","consumer behaviour;data visualisation;electronic commerce;information retrieval;network theory (graphs);recommender systems;text analysis","TF-IDF analysis;characteristic word evaluation;concurrent network;consumer buying behavior;electronic commerce site;golf EC site;information aggregation;recommendation system;reputation analysis;visualization networks","","","","","","","6-7 Dec. 2016","","IEEE","IEEE Conference Publications"
"An empirical study on mood classification in music through computational approaches","H. Shahmansouri; J. Z. Zhang","Department of Mathematics and Computer Science, University of Lethbridge, Lethbridge, Albert, Canada","2016 3rd International Conference on Systems and Informatics (ICSAI)","20170109","2016","","","1050","1055","Music Information Retrieval aims computational approaches that can be used to facilitate managing, e.g., indexing, retrieving, storing, etc., music data in large-volume music datasets. In this study, we empirically explore different classification schemes on the mood classification problems in music data. It is long recognized that using mood to classify music data is subjective and ambiguous. Through comprehensive empirical experiments, we demonstrate that the current classification schemes are not sufficient to conduct music classification through mood. Various issues, such as feature selection, feature discretization, etc., are analyzed and discussed. The main purposes of this study is to find through empirical experiments what combinations of classifiers and feature selection techniques work better to classify moods in music data and in the meanwhile, analyze and discuss various issues related to the mood classification problem.","","Electronic:978-1-5090-5521-0; POD:978-1-5090-5522-7; USB:978-1-5090-5520-3","10.1109/ICSAI.2016.7811106","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811106","","Benchmark testing;Feature extraction;Mood;Music;Principal component analysis;Support vector machines","feature selection;information retrieval;music;pattern classification","computational approaches;feature discretization;feature selection;mood classification;music data classification;music datasets;music information retrieval","","","","","","","19-21 Nov. 2016","","IEEE","IEEE Conference Publications"
"Automatic Question Answering Based on Single Document","X. Wang; B. Xu; H. Zhuge","Key Lab. of Intell. Inf. Process., Inst. of Comput. Technol., Beijing, China","2016 12th International Conference on Semantics, Knowledge and Grids (SKG)","20170116","2016","","","90","96","This paper proposes an approach to finding answers within single text for a given question through extracting a network of categories from Wikipedia as background knowledge to support matching between question and answer. Experiments show that the approach is effective for keyword-based QA.","","Electronic:978-1-5090-4795-6; POD:978-1-5090-4796-3","10.1109/SKG.2016.021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815082","Question answering;Wikipedia;category","Electronic publishing;Encyclopedias;Internet;Ontologies;Semantics","Web sites;question answering (information retrieval)","Wikipedia;automatic question answering system;keyword-based QA system;single document","","","","","","","15-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Research on Replica Strategy in Cloud Storage System","L. Huo; R. Yi","Coll. of Comput. & Electron. Inf., Guangxi Univ., Nanning, China","2015 International Conference on Computer Science and Applications (CSA)","20170116","2015","","","313","317","Most cloud storage system uses replica technology to ensure data reliability and improve data access efficiency. But in current file system, there are some problems such as the fixed number of replica and replica placement may cause load imbalance. In order to solve these problems, introducing a dynamic replica adjustment strategy and replica placement algorithm, this strategy can dynamic adjust the number of replica along with the change of heat of access and access response time. When placing a replica, in order to make the access efficiency is the highest, propose a replica placement algorithm based on transmission cost, which is select the best place of access efficient is most in placement a replica. Finally, experimental results show the effectiveness of the strategy.","","CD:978-1-4799-9960-6; Electronic:978-1-4799-9961-3; POD:978-1-4799-9962-0","10.1109/CSA.2015.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810887","cloud storage;file access heat;replica;replica placement algorithm","File systems;Heuristic algorithms;Indexes;Reliability;Space heating;Time factors","cloud computing;information retrieval;storage management","access response time;cloud storage system;data access efficiency;data reliability;dynamic replica adjustment strategy;file system;replica placement algorithm;replica strategy;replica technology;transmission cost","","","","","","","20-22 Nov. 2015","","IEEE","IEEE Conference Publications"
"Practical Web Data Extraction: Are We There Yet? - A Short Survey","A. Schulz; J. Lässig; M. Gaedke","Dept. of Comput. Sci., Univ. of Appl. Sci. Zittau/Gorlitz, Gorlitz, Germany","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","562","567","The number of web documents as well as the inherent data and information is growing at a rapid pace. The interest in extracting and utilizing this data is rising likewise. The prospects that are unlocked by Web Data Extraction to its users are as broad as the extensiveness of topics and fields on the Web. The major obstacle is to utilize the available data, contents and processes. Several, mostly older survey papers have already shown developments and approaches to solve Web Data Extraction tasks, but there is a need for a more up-to-date review, showing the latest developments. Additionally when looking from the user perspective, there is still a gap between research results and practical applicability. Available solutions, including research results, commercial products and open source solutions lack certain capabilities or suffer from severe usability issues. This paper therefore gives a short review of the state of the art in Web Data Extraction and relates this to the practical application of these technologies.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817113","Web Data Extraction;Web Mining;Wrapper Induction","Data mining;Feature extraction;HTML;Ontologies;Proposals;Usability;Web pages","Internet;document handling;information retrieval","Web data extraction;Web documents","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Redundancy-Based Trust in Question-Answering Systems","J. Atkinson; A. Maurelia","Universidad Adolfo Iba&#x00F1;ez","Computer","20170105","2017","50","1","58","65","By combining user preferences, redundancy analysis, and trust-network inference, the proposed trust model can augment candidate answers with information about target sources on the basis of connections with other web users and sources. Experiments show that the model is more effective overall than trust analyses based on inference alone.","0018-9162;00189162","","10.1109/MC.2017.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807184","question-answering systems;redundancy analysis;search efficiency;search engines;search results accuracy;trust metrics;trust models;trust networks;trust systems;web data","Analytical models;Computational modeling;Context awareness;Search engines;Trust management;Web and internet searches","Web sites;inference mechanisms;question answering (information retrieval);redundancy;trusted computing","Web sources;Web users;inference based trust analysis;question-answering systems;redundancy analysis;redundancy-based trust;trust-network inference;user preferences","","","","","","","Jan. 2017","","IEEE","IEEE Journals & Magazines"
"Exploiting topological structures for graph compression based on quadtrees","A. Chatterjee; M. Levan; C. Lanham; M. Zerrudo; M. Nelson; S. Radhakrishnan","Department of Computer Science, California State University Dominguez Hills, Carson, CA USA","2016 Second International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN)","20170116","2016","","","192","197","In the age of big data, the need for efficient data processing and computation has been in the forefront of research endeavors. The process of extracting information from huge data sets require novel storage techniques to aid the computing devices to perform necessary computation. With pervasive use of heterogeneous systems and advent of non-traditional computing units like GPUs, with limited memory, it has become relevant to underline the relevance of data storage, especially to utilize such computing devices. Graphs contain a plethora of information, and also can be used to represent data from a broad range of domains; real-world big data sets are effectively represented by graphs. Efficient graph compression is therefore essential for performing computations on large data sets. Quadtrees, generally used to represent images, can be used as an effective technique to perform compression. Using additional topological information that depict certain patterns for the data sets, further improvements can be made to the space complexity of storing graph data. In this paper we describe algorithms that take into consideration the properties of graphs, and perform compression based on quadtrees. The introduced techniques achieve up to 70% compression as compared to adjacency matrix representation; when compared to existing quadtree based compression method, the proposed algorithms achieve an additional 50% improvement. Techniques to both compress data and also perform queries on the compressed data itself are introduced and discussed in detail.","","CD:978-1-5090-1045-5; Electronic:978-1-5090-1047-9; POD:978-1-5090-1048-6; USB:978-1-5090-1046-2","10.1109/ICRCICN.2016.7813655","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813655","Graph compression;Online Social Networks;Quadtrees","Big data;Complexity theory;Computer science;Data structures;Image coding;Performance evaluation;Social network services","Big Data;data compression;data structures;information retrieval;quadtrees;social networking (online)","Big Data;data representation;graph compression;information extraction;online social network;quadtree;topological structure","","","","","","","23-25 Sept. 2016","","IEEE","IEEE Conference Publications"
"SelQA: A New Benchmark for Selection-Based Question Answering","T. Jurczyk; M. Zhai; J. D. Choi","Math. & Comput. Sci., Emory Univ., Atlanta, GA, USA","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","820","827","This paper presents a new selection-based question answering dataset, SelQA. The dataset consists of questions generated through crowdsourcing and sentence length answers that are drawn from the ten most prevalent topics in the English Wikipedia. We introduce a corpus annotation scheme that enhances the generation of large, diverse, and challenging datasets by explicitly aiming to reduce word co-occurrences between the question and answers. Our annotation scheme is composed of a series of crowdsourcing tasks with a view to more effectively utilize crowdsourcing in the creation of question answering datasets in various domains. Several systems are compared on the tasks of answer sentence selection and answer triggering, providing strong baseline results for future work to improve upon.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814688","data set;framework;machine reading;natural language processing;neural networks;question answering","Context;Electronic publishing;Encyclopedias;Internet;Knowledge discovery;Neural networks","question answering (information retrieval);search engines","English Wikipedia;SelQA;annotation scheme;crowdsourcing tasks;selection-based question answering","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"Music Recommendation System Improvement Using Distributed Genetic Algorithm","M. Inoue; H. Takenouchi; M. Tokumaru","Grad. Sch., Kansai Univ., Suita, Japan","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","20161229","2016","","","627","630","Existing music recommendation systems don't suit user subjectivity and are not naturally intuitive. We previously proposed a music recommendation system to address these problems. Our music recommendation system uses Kansei agents and a Kansei retrieval system. The Kansei agents employ a Kansei model and are characterized by a three-layered neural network. Music fluctuation properties are defined as inputs to the neural networks of the Kansei agents. Our previously proposed system returns recommendations based on user subjectivity. However, this system incurs significant user evaluation load. In this study, we introduce a distributed genetic algorithm (DGA) as an optimization method to address this problem. We compare the proposed DGA method to our previous method by simulation. The simulation results indicate that the proposed DGA method significantly outperforms previous method.","","Electronic:978-1-5090-2678-4; POD:978-1-5090-2679-1","10.1109/SCIS-ISIS.2016.0136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801723","Distributed genetic algorithm;Kansei retrieval;Music recommendation system;Neural network","Convergence;Genetic algorithms;Load modeling;Neural networks;Optimization;Recommender systems;Simulation","genetic algorithms;information retrieval;music;neural nets;recommender systems","Kansei agents;Kansei retrieval system;distributed genetic algorithm;music fluctuation;music recommendation system;three-layered neural network","","","","","","","25-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"Predicting the Bursts of Data Access Streams by Filtering Correlated I/Os","L. Huang; Y. Deng; C. Hu; Y. Zhou; R. Yang; R. Liu","Dept. of Comput. Sci., Jinan Univ., Guangzhou, China","2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","20170126","2016","","","174","181","Bursty behavior normally indicates that the workload generated by data accesses happens in short time, uneven spurts. In order to handle the bursts, the physical resources of IT devices have to be configured to offer capability which goes far beyond the average resource utilization, thus satisfying the performance. However, this kind of fat provisioning incurs wasting resources when the system does not experience peak workloads. If the bursts can be predicted in advance, thin provision will save a lot of resources in contrast to the fat provision. However, the bursty data access involves both correlated I/Os and non-correlated I/Os which are mixed together. Therefore, it has long been a challenge to effectively predict the bursts. By analyzing real traces, this paper observes that the non-correlated block I/Os dominate bursts across I/O workloads. Based on this observation, SAW-Apriori algorithm is proposed in this paper to mine the frequent and correlated I/Os by enhancing the temporal locality of traditionl Apriori algorithm. Furthermore, this paper proposes to predict the bursts by filtering those frequent and correlated I/Os. Experimental results demonstrate that the proposed approach significantly outperforms the traditional time series method when predicting the bursts.","","Electronic:978-1-5090-4297-5; POD:978-1-5090-4298-2","10.1109/HPCC-SmartCity-DSS.2016.0035","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828376","Storage I/O;association mining;bursty access;prediction;strengthened association window","Algorithm design and analysis;Conferences;Correlation;Data mining;Mathematical model;Prediction algorithms;Time series analysis","information retrieval;input-output programs","Apriori algorithm temporal locality;SAW-Apriori algorithm;bursty data access;correlated I/Os filtering;data access stream burst prediction;fat provisioning;noncorrelated block I/Os","","","","","","","12-14 Dec. 2016","","IEEE","IEEE Conference Publications"
"Document image retrieval based on texture features and similarity fusion","F. Alaei; A. Alaei; M. Blumenstein; U. Pal","School of ICT, Griffith University, Australia","2016 International Conference on Image and Vision Computing New Zealand (IVCNZ)","20170105","2016","","","1","6","In this paper we investigate the usefulness of two different texture features along with classification fusion for document image retrieval. A local binary texture method, as a statistical approach, and a wavelet analysis technique, as a transform-based approach, are used for feature extraction and two feature vectors are obtained for every document image. The similarity distances between each of the two feature vectors extracted for a given query and the feature vectors extracted from the document images in the training step are computed separately. In order to use the properties of both features, a classifier fusion technique is then employed using a weighted average fusion of distance measures obtained in relation to each feature vector. The document images are finally ranked based on the greatest visual similarity to the query obtained from the fusion similarity measures. The Media Team Document Database, which provides a great variety of page layouts and contents, is considered for evaluating the proposed method. The results obtained from the experiments demonstrate a correct document retrieval of 65.4% and 91.8% in the Top-1 and Top-10 ranked document list, respectively.","","Electronic:978-1-5090-2748-4; POD:978-1-5090-2749-1; USB:978-1-5090-2747-7","10.1109/IVCNZ.2016.7804437","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804437","Classifier fusion;Document image retrieval;Local binary pattern;Texture features;Wavelet transform","Feature extraction;Image retrieval;Training;Visualization;Wavelet analysis;Wavelet transforms","document image processing;feature extraction;image texture;information retrieval;pattern classification;sensor fusion;statistical analysis;vectors;wavelet transforms","classification fusion;classifier fusion technique;distance measure weighted average fusion;document image retrieval based;feature extraction;feature vector extraction;local binary texture method;media team document database;similarity fusion;statistical approach;texture features;transform-based approach;wavelet analysis technique","","","","","","","21-22 Nov. 2016","","IEEE","IEEE Conference Publications"
"How can we predict the new products and services by using the trademark information and the patent information?","T. Inui; Y. Tanaka","IPNJ Patent Attorneys Office, Shibuya-ku, Tokyo, Japan","2016 Portland International Conference on Management of Engineering and Technology (PICMET)","20170105","2016","","","1478","1486","The purpose of this research is to examine the new product prediction by using the trademark information and the patent information. We have focused on the adding goods and services, and the suggestive trademark. The additional goods and services are added by the applicant. The additional goods and services are expected to include the information about the type of the new product. The suggestive trademark is expected to contain the information about function and effect of the new product. We analyzed the additional goods and services, and the suggestive trademark. As a result, it was found that the information useful in new product predicted can be extracted from the trademark information. In addition, we examined how to search for patents related to new products by using the trademark information. The information extracted from the trademark information can be expected to be utilized as a keyword. Furthermore, designated goods and services were found to be converted to IPC information. Consequently, it was found that keyword and IPC search using the information extracted from the trademark information is possible. By using the trademark information and patent information, it is expected that it is possible to highly accurate new products prediction.","","POD:978-1-5090-3595-3","10.1109/PICMET.2016.7806725","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7806725","","Patents;Search problems;Technological innovation;Technology management;Trademarks","information retrieval;innovation management;patents;trademarks","IPC information;IPC search;information extraction;keyword search;new product prediction;patent information;trademark information","","","","","","","4-8 Sept. 2016","","IEEE","IEEE Conference Publications"
"Recognizing Gender of Stack Overflow Users","B. Lin; A. Serebrenik","Eindhoven Univ. of Technol., Eindhoven, Netherlands","2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)","20170126","2016","","","425","429","Software development remains a predominantly male activity, despite coordinated efforts from research, industry, and policy makers. This gender imbalance is most visible in social programming, on platforms such as Stack Overflow. To better understand the reasons behind this disparity, and offer support for (corrective) decision making, we and others have been engaged in large-scale empirical studies of activity in these online platforms, in which gender is one of the variables of interest. However, since gender is not explicitly recorded, it is typically inferred by automatic “gender guessers”, based on cues derived from an individual's online presence, such as their name and profile picture. As opposed to self-reporting, used in earlier studies, gender guessers scale better, but their accuracy depends on the quantity and quality of data available in one's online profile. In this paper we evaluate the applicability of different gender guessing approaches on several datasets derived from Stack Overflow. Our results suggest that the approaches combining different data sources perform the best.","","Electronic:978-1-4503-4186-8; POD:978-1-5090-2242-7","10.1109/MSR.2016.050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832921","Stack Overflow;gender identification","Electronic mail;Facebook;Image processing;Measurement;Programming;Software","Web sites;decision making;gender issues;question answering (information retrieval);software engineering","Stack Overflow users;automatic gender guessers;data quality;data quantity;decision making;gender imbalance;gender recognition;online platforms;online presence;profile picture;social programming;software development","","","","","","","14-15 May 2016","","IEEE","IEEE Conference Publications"
"A novel paragraph embedding method for spoken document summarization","K. Y. Chen; S. H. Liu; B. Chen; H. M. Wang","Academia Sinica, Taiwan","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","20170119","2016","","","1","6","Representation learning has emerged as a newly active research subject in many machine learning applications because of its excellent performance. In the context of natural language processing, paragraph (or sentence and document) embedding learning is more suitable/reasonable for some tasks, such as information retrieval and document summarization. However, as far as we are aware, there is only a dearth of research focusing on launching paragraph embedding methods. Extractive spoken document summarization, which can help us browse and digest multimedia data efficiently, aims at selecting a set of indicative sentences from a source document to express the most important theme of the document. A general consensus is that relevance and redundancy are both critical issues in a realistic summarization scenario. However, most of the existing methods focus on determining only the relevance degree between a pair of sentence and document. Motivated by these observations, three major contributions are proposed in this paper. First, we propose a novel unsupervised paragraph embedding method, named the essence vector model, which aims at not only distilling the most representative information from a paragraph but also getting rid of the general background information to produce a more informative low-dimensional vector representation. Second, we incorporate the deduced essence vectors with a density peaks clustering summarization method, which can take both relevance and redundancy information into account simultaneously, to enhance the spoken document summarization performance. Third, the effectiveness of our proposed methods over several well-practiced and state-of-the-art methods is confirmed by extensive spoken document summarization experiments.","","Electronic:978-9-8814-7682-1; POD:978-1-5090-2401-8","10.1109/APSIPA.2016.7820882","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820882","","Artificial neural networks;Context;Context modeling;Multimedia communication;Redundancy;Streaming media","document handling;information retrieval;natural language processing;speech processing;unsupervised learning;vectors","deduced essence vectors;density peaks clustering summarization method;essence vector model;information retrieval;low-dimensional vector representation;machine learning applications;multimedia data;natural language processing;novel unsupervised paragraph embedding method;representation learning;spoken document summarization","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Resource Space Extension Model","J. Wu; B. Xu","Nanjing Univ. of Posts & Telecommun., Nanjing, China","2016 12th International Conference on Semantics, Knowledge and Grids (SKG)","20170116","2016","","","170","173","Resource Space Model (RSM) is a semantic data model for specifying, storing, managing, and locating versatile resources based on multi-dimensional categorization. However, the structure of the model needs to be extended for managing and searching contents. This paper proposes an extensive model of RSM to solve the problem by building a new layer of RSM to store, manage and search the meaning units of text content, which includes definition meaning unit, cause and effect meaning unit, demonstration meaning unit.","","Electronic:978-1-5090-4795-6; POD:978-1-5090-4796-3","10.1109/SKG.2016.037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815098","Definition extraction;Meaning unit;Resource Space Model;Term Recognition","Data mining;Data models;Pattern matching;Semantics;Standards;Terminology;XML","content management;data models;information retrieval;pattern classification;text analysis","RSM model;cause-and-effect meaning unit;classification-based semantic data model;definition meaning unit;demonstration meaning unit;resource space extension model;text content management;text content search;versatile resource location;versatile resource management;versatile resource specification;versatile resource storage","","","","","","","15-17 Aug. 2016","","IEEE","IEEE Conference Publications"
"Novel Audio Steganography Technique for ECG Signals in Point of Care Systems (NASTPOCS)","A. Devi; K. B. ShivaKumar","Sri Siddhartha Acad. of Higher Educ., Tumakuru, India","2016 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM)","20170119","2016","","","101","106","Point of care testing (POCT) in patients with ischemic heart disease is impelled by the time critical need for quick, specific and accurate results for initiation of therapy instantly. The driving force behind POCT using ECG signals is to provide test immediately and conveniently to cardiac patients. This will intensify the probability of patient, physician and care team receiving the results faster, which facilitate immediate clinical management decisions to be taken. In wireless communication the biomedical data may be susceptible to potential attacks leading to following security challenges. To safeguard the privacy and integrity of biomedical data. To make sure that only authorized people can have the access to secret information. This paper proposes a five level wavelet decomposition based steganography technique applied to ECG signals along with RSA encryption and scrambling matrix based encoding technique to protect confidential information related to patient hidden inside ECG signals. To assess the efficiency of the proposed algorithm on the patient ECG signal, the two distortion measurement metrics like percentage RMSE difference (PRD) and PSNR(peak signal to noise ratio) have been compared with existing algorithm results and energy of watermarked ECG signal is compared with original ECG for Coiflet, Bioorthogonal and symlet wavelets. It is found that the proposed algorithm provides very high security protection for information related to patient and as well as with very less distortion of ECG signal, so that it remains diagnosable even after retrieval of patient related secret information.","","Electronic:978-1-5090-4573-0; POD:978-1-5090-4574-7","10.1109/CCEM.2016.026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819679","Bioorthogonal;Coiflet;ECG;POCT;PRD;PSNR;RSA;Steganography;Symlet","Distortion;Electrocardiography;Encryption;Matrix decomposition;Medical diagnostic imaging","audio watermarking;biomedical communication;data integrity;data protection;diseases;electrocardiography;encoding;information retrieval;medical information systems;medical signal processing;public key cryptography;steganography;wavelet transforms","Coiflet wavelet;PSNR;RSA encryption;audio steganography technique;biomedical data integrity;biomedical data privacy;bioorthogonal wavelet;cardiac patients;clinical management decisions;confidential information protection;distortion measurement metrics;five level wavelet decomposition based steganography technique;ischemic heart disease;patient ECG signal;patient related secret information retrieval;peak signal-to-noise ratio;percentage RMSE difference;point-of-care systems;point-of-care testing;scrambling matrix based encoding technique;symlet wavelet;watermarked ECG signal energy;wireless communication","","","","","","","19-21 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Research on Sentence Similarity for Question Answering System Based on Multi-feature Fusion","H. Ruan; Y. Li; Q. Wang; Y. Liu","Sch. of Autom., Beijing Inst. of Technol., Beijing, China","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","507","510","If just consider one feature of sentences to calculate sentences similarity, the performance of system is difficult to reach a satisfactory level. This paper presents a method of combining the features of semantic and structural to compute sentences similarity. It first discusses the methods of calculating the semantic similarity of sentences through word embedding and Tongyici Cilin. Next, it discusses the methods of calculating the morphological similarity and order similarity of sentences, and then combines the features through the neutral network to calculate the total similarity of the sentences. We include results from an evaluation of the system's performance and show that a combination of the features works better than any single approach.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817102","neural network;semantic similarity;sentence similarity;structural similarity;word embedding","Automation;Biological neural networks;Knowledge discovery;Measurement;Semantics;System performance","neural nets;question answering (information retrieval);sensor fusion","Tongyici Cilin;morphological similarity;multifeature fusion;neutral network;order similarity;question answering system;satisfactory level;semantic features;sentence similarity;structural features;system performance evaluation;word embedding","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Bridging the Gap between bdME and OntoME","R. G. Martini; P. R. Henriques","Dept. of Inf., Univ. of Minho, Braga, Portugal","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","487","491","The Semantic Web aims at building a Web where data is enriched with meaningful annotations. In other words, data is semantically organized in such a way that both human and machine can understand and query it, aiming at the creation of dynamic Web pages. Ontologies, as a keystone of the Semantic Web, have gained an ample acceptance as an information model, which can be used for several purposes, such as information retrieval in the Web. However, data is normally stored in databases, which present various problems in the Semantic Web context, because data is not semantically annotated. Aiming at retrieving rich results in the sense of meaning, several ways of relating databases with ontologies have emerged. This paper presents a mapping - with the aid of a framework called Ontop - as a solution for the communication problem between the relational database of the Emigration Museum of Fafe (EMF) and the ontology of the Emigration Museum (OntoME), which describes the Cultural Heritage domain. This mapping will be used to realize the CaVa architecture, aiming at the creation of dynamic Web pages as virtual Learning Spaces. Real examples of the mapping process are presented.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817098","","Context;Cultural differences;Databases;Ontologies;Semantic Web;Vocabulary;Web pages","history;information retrieval;museums;ontologies (artificial intelligence);relational databases;semantic Web","CaVa architecture;EMF;Emigration Museum;Emigration Museum of Fafe;OntoME;Ontop;bdME;cultural heritage domain;dynamic Web pages;information model;ontologies;relational database;semantic Web;virtual learning spaces","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"User preference based page ranking algorithm","D. Gupta; D. Singh","Department of Computer Science and Engineering, Delhi Technological University, Delhi, India","2016 International Conference on Computing, Communication and Automation (ICCCA)","20170116","2016","","","166","171","World Wide Web has become the major source of information dissemination. Due to its vast expansion and heterogeneity, users faces difficulty in finding relevant results quickly. Ranking is an important application of web mining which is based on the structure, content and usage. Many algorithms exist for web page ranking and these algorithms are based upon one or more parameters such as forward links, backward links, contents and user interaction time. The efficiency of an algorithm may be based upon the parameters that are applied to determine the ranking of the page. In this paper some important page ranking algorithms are discussed and a new page ranking algorithm is proposed named as User Preference Based Page Ranking. The proposed algorithm is efficient in terms of relevancy because it uses agents to determine pages content relevancy and user behavior is also considered while ranking the web pages. Hence User Preference Based Page Ranking make users search result navigation easier and more satisfactory to find the desired information.","","Electronic:978-1-5090-1666-2; POD:978-1-5090-1667-9","10.1109/CCAA.2016.7813711","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813711","Inbound Link;Outbound Link;Page Ranking Algorithms;WWW;Web Crawling;Web Mining","Algorithm design and analysis;Crawlers;Mathematical model;Search engines;Web mining;Web pages","Internet;human factors;information retrieval","Web mining;Web pages;backward links parameter;contents parameter;forward links parameter;information dissemination;page ranking algorithm;user interaction time parameter;user preference","","","","","","","29-30 April 2016","","IEEE","IEEE Conference Publications"
"A trust-aware recommender algorithm based on users overlapping community structure","P. Moradi; F. Rezaimehr; S. Ahmadian; M. Jalili","Department of Computer Engineering, University of Kurdistan, Sanandaj, Iran","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","162","167","Retrieving items in online e-commerce systems with abundance of products is time consuming for users. To deal with this issue, recommender systems (RS) aims to help users by suggesting their interested items in the presence of thousands of products. Generally, RS algorithms are constructed based on similarity between users and/or items (e.g., a user is likely to purchase the same items as his/her most similar users). In this paper, we introduce a novel time-aware recommendation algorithm that is based on overlapping community structure between users. Users' interests might change over time, and thus accurate modelling of dynamic users' tastes is a challenging issue in designing efficient recommendation systems. The users-items interaction network is often highly sparse in real systems, for which many recommenders fail to provide accurate predictions. We apply the proposed algorithm on a benchmark dataset. Our proposed recommendation algorithm overcomes these challenges and show better precision as compared to the state-of-the-art recommenders.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829914","Recommender algorithms;network science;overlapping community structure;reliability;social networks;trust","Algorithm design and analysis;Clustering algorithms;Collaboration;Heuristic algorithms;Prediction algorithms;Recommender systems;Reliability","electronic commerce;information retrieval;purchasing;recommender systems;social networking (online);trusted computing","dynamic user taste modelling;item retrieval;online e-commerce systems;time-aware recommendation;trust-aware recommender algorithm;user interests;user overlapping community structure;user-item interaction network","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"Design of Chinese intelligent question answering system of the online learning platform","L. Jiang; Z. Jia; S. Hu","Software College, Northeastern University, Shenyang, China","2016 3rd International Conference on Systems and Informatics (ICSAI)","20170109","2016","","","1106","1111","With the rapid development of the online learning platform in China, there is no doubt that the Chinese question answering system will play an extremely important role in the online learning platform. The Intelligent Question Answering System will relieve teachers of piles of questions and help them make dynamic adjustment to their teaching focus based on the analysis of students' questions. The expected educative effects of the system shall be no less than that of traditional face-to-face teaching method. This paper will provide a practical scheme on the design of the Chinese Intelligent Question Answering System of the online learning platform, as well as discussion about the key algorithms such as Chinese Word Segmentation, Similarity Computation and Text Clustering which are deployed in our system. After evaluation, we found this design scheme worthy of promotion.","","Electronic:978-1-5090-5521-0; POD:978-1-5090-5522-7; USB:978-1-5090-5520-3","10.1109/ICSAI.2016.7811116","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811116","Chinese word segment;Question Answering System;Similarity Computation;Text Clustering","Algorithm design and analysis;Data warehouses;Dictionaries;Education;Electronic mail;Indexes;Knowledge discovery","computer aided instruction;pattern clustering;question answering (information retrieval);teaching;text analysis","China;Chinese intelligent question answering system;face-to-face teaching method;online learning platform;similarity computation;text clustering","","","","","","","19-21 Nov. 2016","","IEEE","IEEE Conference Publications"
"A New Approach to Ontology-Based Semantic Modelling for Opinion Mining","R. Alfrjani; T. Osman; G. Cosma","Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK","2016 UKSim-AMSS 18th International Conference on Computer Modelling and Simulation (UKSim)","20161226","2016","","","267","272","With the fast growth of World Wide Web 2.0, a great number of opinions about a variety of products have been published in blogs, forums, and social networks. Opinion mining tools are needed to enable users to efficiently process a large number of reviews found online, in order to determine the underlying opinions. This paper presents a new methodology for semantic modelling of the domain knowledge for opinion mining. In particular, the new methodology focuses on modelling the domain knowledge in such a way that it can be translated to a formal ontology, which can then be automatically enriched with ground facts obtained from public Linked Open Data resources. The methodology also considers procedures to link between the formal ontology and Natural Language Processing. Our approach successfully enriches the ontology with the relevant ground facts. This ontology can then be used to perform a variety of data mining tasks including sentiment analysis and information retrieval.","","CD:978-1-5090-0887-2; Electronic:978-1-5090-0888-9; POD:978-1-5090-0889-6","10.1109/UKSim.2016.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7796718","Knowledge Base;Ontology;Opinion Mining;Semantic Modelling","Computational modeling;Data mining;Data models;Feature extraction;Motion pictures;Ontologies;Semantics","Internet;Web sites;data mining;information retrieval;ontologies (artificial intelligence);sentiment analysis","World Wide Web 2.0;data mining;domain knowledge modelling;formal ontology;information retrieval;natural language processing;ontology-based semantic modelling;opinion mining;public Linked Open Data resources;sentiment analysis","","","","","","","6-8 April 2016","","IEEE","IEEE Conference Publications"
"Proposing scalable method for music genre classification","V. V. Palkar; P. Joeg","Dept of Computer Science and Engineering, Vishwakarma Institute of Technology, Pune, India","2016 International Conference on Inventive Computation Technologies (ICICT)","20170119","2016","2","","1","6","Music, a vital part of our lives from long time. It is a one of the type of multimedia and much online music content distribution vendors are providing very large database of musical libraries for streaming and downloading services. Classification of audio files by genres have a significant role in management of music. Music genre classification helps in organizing, searching and retrieving musical content. It is also used for music recommendation system. In this paper, music genre classification using serial execution and parallel execution is implemented. For both serial and parallel execution, feature vector is extracted from mel-frequency cepstral coefficients (MFCC) and some other features and support vector machine (SVM) is used for genre classification. The classification accuracy of the proposed single-node system is 88.40%. The paper mainly focuses on multi-node system and how it can be useful to improve performance of large musical database. Apache Spark enables fast processing of data in hadoop clusters. It also allows to persist data in memory. Spark have support of machine learning, graph processing and SQL queries.","","DVD:978-1-5090-1283-1; Electronic:978-1-5090-1285-5; POD:978-1-5090-1286-2","10.1109/INVENTIVE.2016.7824800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7824800","Apache Spark;MFCC;RDD;SVM","Databases;Feature extraction;Mel frequency cepstral coefficient;Music;Sparks;Support vector machines;Training","feature extraction;information retrieval;music;parallel processing;pattern classification;support vector machines;very large databases","Hadoop clusters;MFCC;SQL queries;SVM;Spark;audio file classification;downloading services;feature vector extraction;graph processing;machine learning;mel-frequency cepstral coefficients;multinode system;music content organization;music genre classification;music management;musical content retrievaal;musical libraries;online music content distribution vendors;parallel execution;serial execution;streaming services;support vector machine;very large musical database","","","","","","","26-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"Predicting Questions' Scores on Stack Overflow","H. Alharthi; D. Outioua; O. Baysal","Sch. of Inf. Technol. & Eng., Univ. of Ottawa, Ottawa, ON, Canada","2016 IEEE/ACM 3rd International Workshop on CrowdSourcing in Software Engineering (CSI-SE)","20170109","2016","","","1","7","Developer support forums are becoming more popular than ever. Crowdsourced knowledge is an essential resource for many developers yet it can raise concerns about the quality of the shared content. Most existing research efforts address the quality of answers posted by Q&A community members. In this paper, we explore the quality of questions and propose a method of predicting the score of questions on Stack Overflow based on sixteen factors related to questions' format, content and interactions that occur in the post. We performed an extensive investigation to understand the relationship between the factors and the scores of questions. The multiple regression analysis shows that the question's length of the code, accepted answer score, number of tags and the count of views, comments and answers are statistically significantly associated with the scores of questions. Our findings can offer insights to community-based Q&A sites for improving the content of the shared knowledge.","","Electronic:978-1-4503-4158-5; POD:978-1-5090-2201-4","10.1109/CSI-SE.2016.009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809391","Crowdsourced knowledge; content quality; questions; pre- diction model; regression analysis","Analytical models;Conferences;Correlation;Data analysis;Predictive models;Regression analysis;XML","human computer interaction;knowledge management;question answering (information retrieval);regression analysis","community-based Q&A;questions scores prediction;regression analysis;shared knowledge content;stack overflow","","","","","","","16-16 May 2016","","IEEE","IEEE Conference Publications"
"Performance evaluation of search result diversification methods and their stability","C. Xu; T. Chen; S. Wu","School of Computer Science and Telecommunication Engineering, Jiangsu University, Zhenjiang, Jiangsu Province, China","2016 3rd International Conference on Systems and Informatics (ICSAI)","20170109","2016","","","721","726","Recently search result diversification has attracted a lot of attention in the information retrieval and Web search research community. Although quite a few result diversification algorithms have been proposed, it lacks in comparative study on those algorithms. In this paper, we compare four explicit result diversification algorithms. Three of them are representative explicit result diversification methods xQuAD, PM2 and IA-SELECT. The fourth, CombSumDiv, is presented in this paper. The experiments are carried out with 4 data sets used in the web track of TREC. The experimental results show that the proposed method CombSumDiv is as good as xQuAD, while PM2 and IA-SELECT are not as good as the other two. Stability of the four algorithms are also tested in a variety of situations. Experiments show that all four result diversification methods have very good stability when the search condition is not ideal.","","Electronic:978-1-5090-5521-0; POD:978-1-5090-5522-7; USB:978-1-5090-5520-3","10.1109/ICSAI.2016.7811047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811047","Data fusion;Retrieval evaluation;Search result diversification;Web search","Greedy algorithms;Informatics;Measurement;Stability analysis;Web search;Web sites","Internet;information retrieval;performance evaluation","CombSumDiv;IA-SELECT;PM2;TREC Web track;Web search research community;information retrieval;performance evaluation;representative explicit result diversification;search result diversification methods;xQuAD","","","","","","","19-21 Nov. 2016","","IEEE","IEEE Conference Publications"
"Hashing with Non-Linear Manifold Learning","Y. Liu; X. Bai; C. Yan; J. Wang; J. Zhou","","2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","20161226","2016","","","1","8","The amount of data is exploding with the development of Internet and multimedia technology. Rapid retrieval of mass data is becoming more and more important. To meet the demand of the rapid retrieval, many approximate nearest neighobor methods have been proposed to accelerate the exhaustive search process. Hashing is such an example with great balance of time and accuracy. Hashing methods achieve quick retrieval by converting the high-dimensional raw data into a binary hash code, keeping the similarity of original data in mapped hash codes. Many hashing approaches use the Euclidean distance as similarity measurement. However, data in many datasets are distributed on a non-linear manifold, such that geodesic distance on manifold can represents the semantic similarity of original data points more accurately than the Euclidean distance. This enables better preservation of the sematic similarity in the hash code when mapping the original dataset to low- dimensional space. In this paper, we propose to use Isometric Mapping (ISOMAP) for dimensional reduction and utilize iterative quantization to reduce quantization loss during hashing process. The experiments show that our manifold learning method outperforms several alternative hashing methods. The retrieval performance is further boosted after iterative quantization process is added to the Diffusion Hashing (DH) and Spectral Hashing.","","Electronic:978-1-5090-2896-2; POD:978-1-5090-2897-9","10.1109/DICTA.2016.7797046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797046","","Binary codes;Eigenvalues and eigenfunctions;Euclidean distance;Kernel;Learning systems;Manifolds;Quantization (signal)","differential geometry;file organisation;information retrieval;learning (artificial intelligence)","DH;Euclidean distance;ISOMAP;Internet;approximate nearest neighbor methods;binary hash code;diffusion hashing;dimensional reduction;exhaustive search process;geodesic distance;hashing method;high-dimensional raw data;isometric mapping;iterative quantization process;mapped hash codes;mass data retrieval;multimedia technology;nonlinear manifold learning;original data points semantic similarity;quantization loss reduction;sematic similarity;similarity measurement;spectral hashing","","","","","","","Nov. 30 2016-Dec. 2 2016","","IEEE","IEEE Conference Publications"
"New algorithms for composite retrieval","E. Feuerstein; J. A. Knebel; I. Méndez-Díaz; A. Stein; P. Zabala","Departamento de Computaci&#x00F3;n, FCEyN, UBA, Buenos Aires, Argentina","2016 XLII Latin American Computing Conference (CLEI)","20170126","2016","","","1","9","Internet users constantly make searches to find objects or results of their interest, generally through terms or phrases. Traditional search offers only solutions that take into account just the individual characteristics of the results, and not the relations they have with the rest of the universe. Typically, we are given an ordered list of the results related to the search criterion, which implies the need of changing several times the terms of the query to get to a solution that is more adequate to the intended search goal. As a solution to this problem, Composite Retrieval proposes that the results to a query may be grouped in sets of items (bundles), related through some similarity criterion, but at the same time are complementary. In this work we propose heuristic algorithms for Composite Retrieval which are evaluated experimentally, showing performance improvements over the previous results presented in the literature.","","Electronic:978-1-5090-1633-4; POD:978-1-5090-1634-1","10.1109/CLEI.2016.7833376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833376","Composite retrieval;Heuristics","Australia;Heuristic algorithms;Indexes;Oceans;Rocks;Search problems;Silicon","Internet;information retrieval","Internet;composite retrieval","","","","","","","10-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"Personalised PageRank as a Method of Exploiting Heterogeneous Network for Counter Terrorism and Homeland Security","A. Anil; S. R. Singh; R. Sarmah","Comput. Sci. & Eng., Indian Inst. of Technol., Guwahati, Guwahati, India","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","327","334","Majority of the social network analysis studies for counter-terrorism and homeland security consider homogeneous network. However, a terrorist activity (attack) is often defined by several attributes such as terrorist organisation, time, place, attack type etc. To capture inherent dependency between the attributes, we need to adopt a network which is capable of capturing the dependency between the attributes. In this paper, we define a heterogeneous network to represent a collection of terrorist activities. Further, we propose personalised PageRank (PPR) as a method capable of performing various analytical operations over heterogeneous network just by changing model parameters without changing the underlying model. Using global terrorist data (GTD), behavioural network, and news discussion network, we show various applications of PPR for counter-terrorism over heterogeneous network just by changing the model parameter. In addition we propose heterogeneous version of four local proximity based link prediction methods, namely, Common Neighbour, Adamic-Adar, Jaccard Coefficient, and Resource Allocation.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817070","Heterogeneous network;Personalised PageRank;Terrorist Networks","Computer science;Heterogeneous networks;Matrices;Prediction methods;Radiation detectors;Social network services;Terrorism","information retrieval;social sciences computing;terrorism","Adamic-Adar method;Jaccard coefficient method;PPR method;common neighbour method;counter terrorism;heterogeneous network;homeland security;personalised PageRank method;proximity based link prediction methods;resource allocation method;social network analysis;terrorist activity","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Semantic Word Rank Algorithm Based on the Relation Degree of the Words","H. Han; K. Fu; X. Sun; Z. Li","Shandong Prov. Key Lab. of Digital Media Technol., Shandong Univ. of Finance & Econ., Jinan, China","2016 12th International Conference on Computational Intelligence and Security (CIS)","20170119","2016","","","161","164","With the continuous development of the Internet, the volume of data is soaring sharply, the question answering system plays an increasingly important role in our lives. The current question answering system knowledge base is mainly constructed manually, costing a lot of manpower and material resources, hindering the expansion of application of question answering system from a single field to the whole field. Therefore, based on previous research results, this paper focused on the construction of domain lexicon and knowledge base, proposed semantic word rank (SWR) algorithm based on the relation degree of the words. By extracting the subject words and characteristic words of the paragraph, a knowledge base which is marked by the subject words and characteristic words is constructed automatically. The experimental results show that the SWR algorithm can effectively improve the accuracy of the extraction of subject words and characteristic words, the construction of knowledge base is more scientific and reasonable.","","Electronic:978-1-5090-4840-3; POD:978-1-5090-4841-0","10.1109/CIS.2016.0045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820436","Characteristic words;Knowledge base;SWR algorithm;Subject words","Computers;Economics;Finance;Knowledge based systems;Knowledge discovery;Media;Semantics","Internet;question answering (information retrieval);text analysis","Internet;SWR algorithm;accuracy improvement;characteristic word extraction;domain lexicon construction;knowledge base;material resources;question answering system;semantic word rank algorithm;subject word extraction","","","","","","","16-19 Dec. 2016","","IEEE","IEEE Conference Publications"
"Investigation of adaptive local threshold segmentation in context of 3D-handwriting forensics","M. Kalbitz; T. Scheidat; C. Vielhauer","University of Applied Sciences Brandenburg, Department of Informatics and Media, Magdeburger Str. 50, 14770 Brandenburg an der Havel, Germany","2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)","20170119","2016","","","1","6","Image segmentation plays an important role in digitized crime scene forensics. Particularly in context of modern high resolution contact-less and non-destructive acquisition and analysis of handwriting impression traces by means of 3D sensors, one main challenge is the separation of writing trace areas and non-traces by image segmentation. In earlier work authors have presented the general, yet qualitative feasibility to do so by an initial processing pipeline based on data acquisition, pre-processing and a global segmentation approach. However, quantitative measurements with regards to the segmentation quality have not been studied yet, as well as the discussion of alternative strategies for 3D image segmentation in this scenario. In this paper, we extent the earlier work by introducing a concept for benchmarking segmentation accuracy for 3D handwriting traces. Further we present results with regards to the initial approach as well as a new, adaptive local threshold segmentation. The benchmarking is based on ground truth data, determined using data of handwriting traces acquired by a high-quality flatbed scanner and segmentation information retrieved from those by means of an Otsu operator. This ground truth allows for calculation of true positive, true negative, false positive and false negative error rates as quality measurement. The practical impact of the suggested benchmarking is shown by comparison of experimental results based on initial segmentation approach and new adaptive approach. Experiments are based on ten handwriting traces each of eleven persons. The comparison of results indicates that the best parameter set of the adaptive thresholding leads to an quality increase of 12.1% in terms of precision for writing trace and decrease of 1.4% in terms of precission for background.","","Electronic:978-1-4673-8910-5; POD:978-1-4673-8911-2","10.1109/IPTA.2016.7821000","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821000","Image and 3D processing applications;handwriting forensics;intended writing;pattern recognition;questioned documents;segmentation","Benchmark testing;Forensics;Image segmentation;MATLAB;Sensors;Three-dimensional displays;Writing","data acquisition;document image processing;handwriting recognition;image forensics;image scanners;image segmentation;information retrieval;sensors;stereo image processing","3D handwriting forensics;3D image segmentation;3D sensors;Otsu operator;adaptive local threshold segmentation;data acquisition;digitized crime scene forensics;handwriting impression;high quality flatbed scanner;segmentation information retrieval","","","","","","","12-15 Dec. 2016","","IEEE","IEEE Conference Publications"
"Eliminating Unanswered Questions from Question Answering System for Khulafaa Al-Rashidin History","M. Z. Naf’An; D. E. Mahmudah; S. J. Putra; A. F. Firmansyah","Dept. of Inf., ST3 Telkom, Purwokerto, Indonesia","2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20170116","2016","","","140","143","This paper discusses some attempts conducted to improve performance of Question Answering System for Khulafaa Al-Rashidin (Caliphs) history (called as QAKH). Experiments done on QAKH in 2012 showed that only 61,67% questions got a correct answer. The one contributed in this achievement was lack of Indonesian stemming process that implemented by utilizing Lucene library. It was found that Lucene did over stemming on some Indonesian word in indexing phase, so that it was delivered impacts on passage retrieval and answer extraction as well. We tried to implement two approaches in order to solve that problem. As the first, we used other library for doing stemming process for Indonesian words that developed by Information Retrieval laboratorium in University of Indonesia. In any case if there is no answer delivered, we shifted to the second approach where there is no stemming process applied. Result of evaluation demonstrated a better achievement where we got 66,67% correct answers. Analysis of each fold of experiments also discussed.","","Electronic:978-1-5090-4521-1; POD:978-1-5090-4522-8","10.1109/ICT4M.2016.038","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814891","eliminating unanswered question;khulafaa al-rashidin history;question answering system","History;Indexing;Knowledge discovery;Libraries;Search engines","history;indexing;libraries;question answering (information retrieval)","Caliphs history;Indonesia university;Indonesian stemming process;Indonesian words;Khulafaa Al-Rashidin history;Lucene library utilization;QAKH;answer extraction;indexing phase;information retrieval laboratorium;passage retrieval;question answering system","","","","","","","22-24 Nov. 2016","","IEEE","IEEE Conference Publications"
"Using domain knowledge and bilingual resources for addressing community question answering for Arabic","Y. El Adlouni; I. Lahbari; H. Rodríguez; M. Meknassi; S. O. El Alaoui; N. Ennahnahi","Laboratoire Informatique et Mod&#x00E9;lisation (LIM), Facult&#x00E9; des Sciences, Dhar El Mahraz (FSDM), Universit&#x00E9; Sidi Mohammed Ben Abdellah, (USMBA), Fes, Morocco","2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)","20170105","2016","","","368","373","This paper presents a description of the approach of the UPC-USMBA team for addressing Community Question Answering, for the Arabic language on the medical domain. Our approach for addressing the task is based on combining the use of original Arabic texts with English translations over which supervised Machine Learning techniques are applied. Our system perform on four steps: A preliminary step, aiming to collect domain resources, a learning step, for getting two models, one over Arabic texts and the other on English texts, a classification step, for applying them to the test datasets, and, finally a combination step over the results of the two classifiers.","","Electronic:978-1-5090-0751-6; POD:978-1-5090-0752-3","10.1109/CIST.2016.7805073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805073","","Drugs;Feature extraction;Knowledge discovery;Message systems;Pragmatics;Terminology;Training","learning (artificial intelligence);pattern classification;question answering (information retrieval);text analysis","Arabic language;Arabic texts;English translations;UPC-USMBA team;bilingual resources;community question answering;domain knowledge;supervised machine learning","","","","","","","24-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"Mining Duplicate Questions of Stack Overflow","M. Ahasanuzzaman; M. Asaduzzaman; C. K. Roy; K. A. Schneider","","2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)","20170126","2016","","","402","412","Stack Overflow is a popular question answering site that is focused on programming problems. Despite efforts to prevent asking questions that have already been answered, the site contains duplicate questions. This may cause developers to unnecessarily wait for a question to be answered when it has already been asked and answered. The site currently depends on its moderators and users with high reputation to manually mark those questions as duplicates, which not only results in delayed responses but also requires additional efforts. In this paper, we first perform a manual investigation to understand why users submit duplicate questions in Stack Overflow. Based on our manual investigation we propose a classification technique that uses a number of carefully chosen features to identify duplicate questions. Evaluation using a large number of questions shows that our technique can detect duplicate questions with reasonable accuracy. We also compare our technique with DupPredictor, a state-of-the-art technique for detecting duplicate questions, and we found that our proposed technique has a better recall rate than that technique.","","Electronic:978-1-4503-4186-8; POD:978-1-5090-2242-7","10.1109/MSR.2016.048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832919","Stack Overflow;discriminative classifier;duplicate questions","Computer bugs;Data mining;Databases;Knowledge discovery;Manuals;Mars;Software","classification;data mining;question answering (information retrieval)","Stack Overflow;classification technique;duplicate question identification;duplicate question mining;programming problems;question answering site","","","","","","","14-15 May 2016","","IEEE","IEEE Conference Publications"
"Data storage in big data context: A survey","A. Elomari; A. Maizate; L. Hassouni","RITM-ESTC / CED-ENSEM, University Hassan II, Km 7, Eljadida Street, B.P. 8012 Oasis, Casablanca, Morocco","2016 Third International Conference on Systems of Collaboration (SysCo)","20170126","2016","","","1","4","As data volumes to be processed in all domains; scientific, professional, social...etc., are increasing at a high speed, their management and storage raises more and more challenges. The emergence of highly scalable infrastructures has contributed to the evolution of storage management technologies. However, numerous problems have emerged such as consistency and availability of data, scalability of environments or yet the competitive access to data. The objective of this paper is to review, discuss and compare the main characteristics of some major technological orientations existing on the market, such as Google File System (GFS) and IBM General Parallel File System (GPFS) or yet on the open source systems such as Hadoop Distributed File System (HDFS), Blobseer and Andrew File System (AFS), in order to understand the needs and constraints that led to these orientations. For each case, we will discuss a set of major problems of big data storage management, and how they were addressed in order to provide the best storage services.","","Electronic:978-1-5090-4926-4; POD:978-1-5090-4927-1","10.1109/SYSCO.2016.7831344","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7831344","AFS;Big Data;Blobs;Blobseer;Data Storage;GFS;GPFS;HDFS","Big data;Distributed databases;File systems;Google;Metadata;Scalability;Servers","Big Data;information retrieval;public domain software;storage management","AFS;Andrew file system;Big Data storage management;Blobseer;GFS;Google File System;HDFS;Hadoop distributed file system;IBM GPFS;IBM general parallel file system;competitive data access;data availability;open source systems","","","","","","","28-29 Nov. 2016","","IEEE","IEEE Conference Publications"
"Inferring Links between Concerns and Methods with Multi-abstraction Vector Space Model","Y. Zhang; D. Lo; X. Xia; T. D. B. Le; G. Scanniello; J. Sun","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20170116","2016","","","110","121","Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that are relevant to the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose a multi-abstraction concern localization technique named MULAB. MULAB represents a code unit and a textual description at multiple abstraction levels. Similarity of a textual description and a code unit is now made by considering all these abstraction levels. We combine a vector space model and multiple topic models to compute the similarity and apply a genetic algorithm to infer semi-optimal topic model configurations. We have evaluated our solution on 136 concerns from 8 open source Java software systems. The experimental results show that MULAB outperforms the state-of-art baseline PR, which is proposed by Scanniello et al. in terms of effectiveness and rank.","","Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7","10.1109/ICSME.2016.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816459","Concern Localization;Multi-Abstraction;Text Retrieval;Topic Modeling","Computational modeling;Computer bugs;Genetic algorithms;Java;Sociology;Software systems;Statistics","Java;genetic algorithms;inference mechanisms;information retrieval;pattern matching;public domain software;software maintenance;source code (software);text analysis;vectors","IR;MULAB;code unit location;concern localization;genetic algorithm;information retrieval;link inference;multiabstraction vector space model;open source Java software system;software maintenance;textual description matching;topic model configuration inference","","1","","","","","2-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Extraction of behavioral patterns from pre-processed web usage data for web personalization","B. J. Doddegowda; G. T. Raju; S. K. S. Manvi","Reva University, Asso. Prof., Dept. of CSE, AMCEC, Bengaluru, VTU, Karnataka","2016 IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","20170109","2016","","","494","498","Data on World Wide Web has been growing in an exponential manner. This raises a severe concern on information overload challenges for the users. Retrieving the most relevant information from the web as per the user requirement has become hard because of the large collection of heterogeneous documents. One approach to overcome this is to personalize the information available on the Web according to user requirements. This is called Web Personalization process that adjusts information/services delivered by a Web to the needs of each user or group of users, taking their behavioral patterns. Frequent Sequential Patterns (FSPs) that are extracted from Web Usage Data (WUD) are very important for analyzing and understanding users' behavior to improve the quality of services offered by the World Wide Web (WWW). User behavioral patterns are required to build profiles of each user, using which Personalization of website is made.","","Electronic:978-1-5090-0774-5; POD:978-1-5090-0775-2","10.1109/RTEICT.2016.7807870","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807870","sequential patterns;web personalization;web usage data","Algorithm design and analysis;Communications technology;Conferences;Data mining;Databases;Market research;Web pages","Internet;data handling;data mining;information retrieval;pattern classification","FSP;WUD;WWW data;Web personalization;Web usage data;World Wide Web data;behavioral pattern extraction;frequent sequential patterns;heterogeneous document collection;information personalization;information retrieval;user requirements","","","","","","","20-21 May 2016","","IEEE","IEEE Conference Publications"
"A similar trademark retrieval system based on rotation invariant local features","T. Toriu; M. Miyazaki; K. Miyazaki; K. Toda; H. Hama","Graduate School of Engineering, Osaka City University, Japan","2016 2nd International Conference on Frontiers of Signal Processing (ICFSP)","20170102","2016","","","81","86","This paper describes a new method to extract rotation invariant local features. The features are invariant not only to a global rotation but also to a local rotation. In addition, a similar trademark retrieval system is proposed, which is based on the rotation invariant local features. By experiment, it is shown that we can find the similar trademark with high probability by checking only higher ranked trademarks.","","CD:978-1-5090-3813-8; Electronic:978-1-5090-3815-2; POD:978-1-5090-3816-9; Paper:978-1-5090-3814-5","10.1109/ICFSP.2016.7802961","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7802961","content based image retrievale;rotation invarianc;similar trademarl retrieval;trademark","Feature extraction;Manganese;Trademarks","information retrieval;probability;trademarks","global rotation;probability;rotation invariant local features;trademark retrieval system","","","","","","","15-17 Oct. 2016","","IEEE","IEEE Conference Publications"
"A Policy-Driven Framework for Document Classification and Enterprise Security","E. Nwafor; P. Chowdhary; A. Chandra","Dept. of Comput. Sci., Howard Univ., Washington, DC, USA","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","949","953","In an enterprise, accessing data on the go using several ubiquitous devices is fast becoming the norm. This brings its own set of challenges when dealing with access to sensitive resources. The pervasive nature of these devices makes them ideal candidates for cyber-attacks. The challenge arises in ensuring that devices conform to proper access control requirements. Due to the nature of the cyber-attacks on ubiquitous devices, there is a need to provide dynamic access control to enterprise resources. A system that automatically classifies documents by sensitivity level would be essential to every enterprise. This helps reduce manual document classification that might be prone to errors. To this effect, we propose a framework that automates the security profile detection, access pattern of enterprise resources using text mining, user context, enterprise policies. We also develop a prototype system to elevate the effectiveness of our framework.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816945","Context-aware security;Data classification;Enterprise data security;Pervasive computing","Algorithm design and analysis;Context;Dictionaries;Engines;Permission;Sensitivity","access control;data mining;information retrieval;mobile computing;pattern classification;security of data;text analysis","cyber-attacks;data accessing;document automatically classification;enterprise policies;enterprise resource access pattern;enterprise resource dynamic access control;enterprise security;enterprise sensitivity level;manual document classification reduction;pervasive devices;policy-driven framework;security profile detection;sensitive resource access;text mining;ubiquitous devices;user context","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"Client-Side Partial File Caching for Cloud-Based Systems","I. A. Ridhawi; N. Mostafa; W. Masri","Coll. of Eng. & Technol., American Univ. of the Middle East, Egaila, Kuwait","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","909","914","Distributed cloud applications acquire, generate tremendous amounts of stored information. The data associated with such applications are distributed widely in geographical terms. Replication services are designed to facilitate, support such cloud applications. A replication service aims to replicate data, select the most appropriate data replica from those available in order to minimize application access time. Current replica services can also exhibit an increase in data acquisition by clients resulting in slower data access. This paper proposes a Partial File Cache (PFC) strategy that minimizes the volume of data transfers under a limited cache space, provides faster data access simultaneously. Traditional caching approaches work well on networks with high latency, however, they can be expensive if an application only requires access to a small part of a large file. To improve cache utilization, our solution makes use of different techniques when caching, such as caching sections or parts of files. The system identifies user hotspots so that fit clients are selected for partial data caching to assist third party cloud storage sites. Results show significant improvement over traditional caching techniques when implemented in geographically spatial cloud environments.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816939","Cloud;Data Replication;File Caching;Mobility","Bandwidth;Cloud computing;Mobile nodes;Predictive models;Quality of service","cache storage;cloud computing;distributed processing;information retrieval;information storage;sensor fusion","PFC strategy;cache utilization;client-side partial file caching;cloud-based systems;data access;data association;distributed cloud applications;geographically spatial cloud environments;information storage","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"Cloud based privacy preserving secure health data storage and retrieval system","S. J. Nadaf; R. Patil","Gogte Institute of Technology, Belagavi","2016 International Conference on Inventive Computation Technologies (ICICT)","20170119","2016","2","","1","6","Data sharing is an important functionality in cloud environment. The system proposes to build privacy into e-healthcare system with the help of private cloud. Privacy of the stored health data can be achieved by encrypting the data before storing it on cloud server. By doing this we can limit the user access for keyword search. Since one cannot perform plaintext search over encrypted content. But again it is necessary to provide keyword search mechanism to identify the encrypted source file. The salient features of the system are efficient key management, privacy preserving data storage and retrieval. The implemented scheme provides the platform for user to store and retrieve the health information securely on cloud storage by encrypting the health data before storing it on cloud server. The system also provides user to search for appropriate file by using keyword search mechanism.","","DVD:978-1-5090-1283-1; Electronic:978-1-5090-1285-5; POD:978-1-5090-1286-2","10.1109/INVENTIVE.2016.7824831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7824831","cloud storage;data confidentiality;e-healthcare;keyword search","Cloud computing;Data privacy;Encryption;Postal services;Privacy;Servers","cloud computing;cryptography;data privacy;health care;information retrieval;medical computing;storage management","cloud based privacy preserving secure health data storage-and-retrieval system;cloud server;e-healthcare system;encrypted content;encrypted source file;health information;keyword search;plaintext search;private cloud","","","","","","","26-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"High Throughput Log-Based Replication for Many Small In-Memory Objects","K. Beineke; S. Nothaas; M. Schoettner","Inst. fur Inf., Heinrich-Heine-Univ. Dusseldorf, Dusseldorf, Germany","2016 IEEE 22nd International Conference on Parallel and Distributed Systems (ICPADS)","20170119","2016","","","535","544","Online graph analytics and large-scale interactive applications such as social media networks require low-latency data access to billions of small data objects. These applications have mostly irregular access patterns making caching insufficient. Hence, more and more distributed in-memory systems are proposed keeping all data always in memory. These in-memory systems are typically not optimized for the sheer amount of small data objects, which demands new concepts regarding the local and global data management and also the fault-tolerance mechanisms required to mask node failures and power outages. In this paper we propose a novel two-level logging architecture with backup-side version control enabling parallel recovery of in-memory objects after node failures. The presented fault-tolerance approach provides high throughput and minimal memory overhead when working with many small objects. We also present a highly concurrent log cleaning approach to keep logs compact. All proposed concepts have been implemented within the DXRAM system and have been evaluated using two benchmarks: The Yahoo! Cloud Serving Benchmark and RAMCloud's Log Cleaner benchmark. The experiments show that our proposed approach has less memory overhead and outperforms state-of-the-art in-memory systems for the target application domains, including RAMCloud, Redis, and Aerospike.","1521-9097;15219097","Electronic:978-1-5090-4457-3; POD:978-1-5090-5382-7","10.1109/ICPADS.2016.0077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823792","B-trees;Buffering;Cloud computing;Data centers;Flash memory;Graph-based database models;Main memory;Reliability;Remote replication;Secondary storage","Distributed databases;Fault tolerance;Java;Memory management;Peer-to-peer computing;Random access memory;Throughput","DRAM chips;benchmark testing;cache storage;cloud computing;configuration management;distributed memory systems;fault tolerant computing;graph theory;information retrieval;replicated databases","Aerospike;DXRAM system;RAMCloud Log Cleaner benchmark;Redis;Yahoo! Cloud Serving Benchmark;access patterns;backup-side version control;concurrent log cleaning approach;distributed in-memory systems;fault-tolerance mechanisms;global data management;high throughput log-based replication;in-memory objects;large-scale interactive applications;local data management;low-latency data access;node failures;online graph analytics;parallel recovery;small data objects;two-level logging architecture","","","","","","","13-16 Dec. 2016","","IEEE","IEEE Conference Publications"
"Toward Microtask Crowdsourcing Software Design Work","E. R. Q. Weidema; C. López; S. Nayebaziz; F. Spanghero; A. van der Hoek","Grad. Sch. of Inf. Sci., VU Univ. Amsterdam, Amsterdam, Netherlands","2016 IEEE/ACM 3rd International Workshop on CrowdSourcing in Software Engineering (CSI-SE)","20170109","2016","","","41","44","The use of crowdsourcing as an approach for performing software engineering work is slowly but surely gaining foothold. Different models of crowdsourcing, however, have had varying levels of success to date. This paper contributes to the discussion a preliminary exploration of microtask crowdsourcing and its potential to generate design solutions. We specifically report on an experiment with Amazon Mechanical Turk workers, who each provided one or more solution alternatives to a small, partial user interface design problem. Early analysis of the results indicates that: (1) it is feasible for a crowd to generate a broad range of alternative solutions, (2) quality of those solutions varies considerably, and (3) the task, despite being small, is seen as difficult by many workers.","","Electronic:978-1-4503-4158-5; POD:978-1-5090-2201-4","10.1109/CSI-SE.2016.015","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809397","Crowdsourcing;alternatives;microtasks;software design","Conferences;Crowdsourcing;Qualifications;Software design;Software engineering;User interfaces","information retrieval;software engineering","Amazon Mechanical Turk;microtask crowdsourcing software design work;software engineering work;user interface design problem","","","","","","","16-16 May 2016","","IEEE","IEEE Conference Publications"
"Performance optimisation of web applications using In-memory caching and asynchronous job queues","S. S. Prakash; B. C. Kovoor","Software Systems Department of Information Technology, School of Engineering, CUSAT, Kochi, India","2016 International Conference on Inventive Computation Technologies (ICICT)","20170126","2016","3","","1","5","Web applications are an integral part of the internet domain. They provide services to the clients from a remote Web server and hence the quality of the service to the clients depends on its performance such as speed and response time. This paper presents two specific ways to boost the performance of a web application from two entirely different perspectives. First method utilises in-memory caching, which aims to improve the speed of database retrieval process using a cached data set. In the second method, the user perceived delay is decreased by pushing the heavy time consuming tasks to the background from the main user interface thread. The paper evaluates the performance of in-memory caching and asynchronous job queues in different scenarios using statistical analysis tools.","","DVD:978-1-5090-1283-1; Electronic:978-1-5090-1285-5; POD:978-1-5090-1286-2","10.1109/INVENTIVE.2016.7830234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830234","Asynchronous job queue;In-memory caching;Statistical analysis;Web application","Benchmark testing;Concurrent computing;Databases;Delays;User interfaces;Web servers","Internet;cache storage;database management systems;information retrieval","Internet domain;Web applications;asynchronous job queues;cached data set;database retrieval process;in-memory caching;performance optimisation;quality of service;remote Web server;statistical analysis tools;user interface thread;user perceived delay","","","","","","","26-27 Aug. 2016","","IEEE","IEEE Conference Publications"
"A Journey of Bounty Hunters: Analyzing the Influence of Reward Systems on StackOverflow Question Response Times","P. Berger; P. Hennig; T. Bocklisch; T. Herold; C. Meinel","Hasso-Plattner-Inst., Univ. of Potsdam, Potsdam, Germany","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","644","649","Question and Answering (Q&A) platforms are an important source for information and a first place to go when searching for help. Q&A sites, like StackOverflow (SO), use reward systems to incentivize users to answer fast and accurately. In this paper we study and predict the response time for those questions on StackOverflow, that benefit from an additional incentive through so called bounties. Shaped by different motivations and rules these questions perform unlike regular questions. As our key finding we note that topic related factors provide a much stronger evidence than previously found factors for these questions. Finally, we compare models based on these features predicting the response time in the context of bounty questions.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817131","bounty;prediction;question answering;response times;stackoverflow","C# languages;Correlation;Focusing;Indexes;Pragmatics;Predictive models;Time factors","information resources;question answering (information retrieval)","Q&A platforms;StackOverflow;bounty hunters;information source;question and answering platforms;question response times;reward systems","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Context Free Frequently Asked Questions Detection Using Machine Learning Techniques","F. Razzaghi; H. Minaee; A. A. Ghorbani","Fac. of Comput. Sci., Univ. of New Brunswick, Fredericton, NB, Canada","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","558","561","FAQs are the lists of common questions and answers on particular topics. Today one can find them in almost all web sites on the internet and they can be a great tool to give information to the users. Questions in FAQs are usually identified by the site administrators on the basis of the questions that are asked by their users. While such questions can respond to required information about a service, topic, or particular subject, they can not easily be distinguished from non-FAQ questions. This paper describes machine learning based parsing and question classification for FAQs. We demonstrate that questions for FAQs can be distinguished from other types of questions. Identification of specific features is the key to obtaining an accurate FAQ classifier. We propose a simple yet effective feature set including bag of words, lexical, syntactical, and semantic features. To evaluate our proposed methods, we gathered a large data set of FAQs in three different contexts, which were labeled by humans from real data. We showed that the SVM and Naive Bayes reach the accuracy of 80.3%, which is an outstanding result for the early stage research on FAQ classification. Experimental results show that the proposed approach can be a practical tool for question answering systems. To evaluate the accuracy of our classifier we have conducted an evaluation process and built the questionnaire. Therefore, we compared our classifier ranked questions with user rates and almost 81% similarity of the question ratings gives some confidence.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817112","FAQ Generation;FAQ identification;Frequently Asked Questions;Question Answering;Question classification","Context;Feature extraction;Internet;Knowledge discovery;Niobium;Semantics;Support vector machines","Internet;Web sites;context-free grammars;information retrieval;learning (artificial intelligence);support vector machines","FAQ;Internet;Naive Bayes;SVM;Web sites;answers;bag of words;context free frequently asked questions detection;lexical;machine learning;machine learning techniques;question answering systems;question classification;questions;semantic features;site administrators;syntactical","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Partial Similarity of 3D Shapes Using Cross Recurrence Plot","R. U. Nakanishi; J. P. Ono; P. Pagliosa; L. G. Nonato; A. Paiva","","2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20170116","2016","","","448","454","This paper presents a novel 3D partial shape retrieval algorithm based on time-series analysis. Given a piece of a 3D shape, the proposed method encodes the shape descriptor given by the Heat Kernel Signature (HKS) as a time-series, where the time is considered an ordered sequence of vertices provided by the Fiedler vector. Finally, a similarity metric is created using a well-known tool in time-series analysis called Cross Recurrence Plot (CRP). The good performance of our method is also attested in a large collection of shape models.","","Electronic:978-1-5090-3568-7; POD:978-1-5090-3569-4","10.1109/SIBGRAPI.2016.068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813067","Cross Recurrence Plot;Fiedler Vector;Geometry Processing;Heat Kernel Signature;Partial Shape Retrieval;Time-Series Analysis","Eigenvalues and eigenfunctions;Heating;Kernel;Shape;Solid modeling;Space vehicles;Three-dimensional displays","information retrieval;solid modelling;time series","3D partial shape retrieval algorithm;CRP;Fiedler vector;HKS;cross recurrence plot;heat kernel signature;shape models;similarity metric;time-series analysis","","","","","","","4-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"SAO Extraction on Patent Discovery System Development for Islamic Finance and Banking","R. Othman; M. F. Noordin; R. H. Gusmita; T. M. T. Sembok; Z. Zulkifli","Semantic Body of Knowledge & Technol. Lab., Int. Islamic Univ. Malaysia, Kuala Lumpur, Malaysia","2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20170116","2016","","","59","63","This paper presents our work on Subject-Action-Object (SAO) extraction as one component needed on patent discovery system development for Islamic Finance and Banking. There are some processes done in order to conduct SAO extraction. They are covering retrieving patents and transforming patents into structured data. We used several patent databases such as USPTO, MyIPO, WIPO, and EPO to collect patents. In patent searching, we used keywords, which were derived from Islamic Finance and Banking phrase, book's title, of which its content is related to Islamic Finance and Banking, and all concepts on Islamic Finance and Banking ontology. Result on SAO extraction will be utilized on the next component on the system i.e. analyzing patents trend using TRIZ evolution trend model.","","Electronic:978-1-5090-4521-1; POD:978-1-5090-4522-8","10.1109/ICT4M.2016.024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814877","Islamic Finance and Banking;SAO extraction;patent discovery system","Banking;Cost accounting;Databases;Finance;Market research;Patents;Semantics","bank data processing;database management systems;information retrieval;patents","Islamic finance and banking;SAO extraction;patent database;patent discovery system development;patent searching;subject-action-object extraction","","","","","","","22-24 Nov. 2016","","IEEE","IEEE Conference Publications"
"Ontology-based indexing method for engineering documents retrieval","W. Fang; Y. Guo; W. Liao","College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, 210016, China","2016 IEEE International Conference on Knowledge Engineering and Applications (ICKEA)","20170102","2016","","","172","176","Engineering documents are valued resources in the reuse of engineering knowledge and effective reuse of these documents depends on efficient retrieval. A semantic indexing method, which accomplished by utilizing state-of-the-art ontology technologies of Semantic Web, is proposed in this paper to handle the issues in engineering documents retrieval. Firstly, in order to represent the semantics embedded in design documents, a domain ontology is constructed by concepts hierarchy and ontology population. Secondly, ontology inference service is presented to fulfill keywords semantic extension. Combining with Lucene mechanism, the extended document index is constructed for retrieval application. Finally, the classical matching and ranking approaches are adopted to develop a prototype domain knowledge retrieval system.","","CD:978-1-5090-3469-7; Electronic:978-1-5090-3471-0; POD:978-1-5090-3472-7; Paper:978-1-5090-3470-3","10.1109/ICKEA.2016.7803013","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803013","engineering documents;knowledge inference;ontology construction;semantic indexing","Indexing;Integrated circuit modeling;Microwave circuits;Microwave integrated circuits","document handling;indexing;inference mechanisms;information retrieval;ontologies (artificial intelligence);pattern matching;semantic Web","Lucene mechanism;concepts hierarchy;domain ontology construction;engineering document retrieval;matching approach;ontology inference service;ontology population;ontology-based indexing method;ranking approach;semantic Web;semantic indexing method","","","","","","","28-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"Performance Evaluation of a Kansei Retrieval Agent Model with Neural Networks","H. Takenouchi; M. Tokumaru","Fukuoka Inst. of Technol., Fukuoka, Japan","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","20161229","2016","","","857","861","We describe the effectiveness of a Kansei Retrieval Agent (KRA) model with Neural Network (NN) for retrieving user preference data. Our system evaluates KRAs using the user's evaluation and optimizes the KRA parameters using an evolutionary computation approach. While our previous study involved Kansei retrieval systems for T-shirts or music, the basic optimization performance of a KRA with NN was not examined. Therefore, in the present study, we investigate the effectiveness of the KRA model with an NN using numerical simulations. The simulation uses a pseudo user that imitates user preferences. We examine the quantization of evaluation values by the user and KRAs and compares the performances obtained using the particle swarm optimization and genetic algorithm methods. The simulation results show that the KRA model can learn user preferences.","","Electronic:978-1-5090-2678-4; POD:978-1-5090-2679-1","10.1109/SCIS-ISIS.2016.0186","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801773","Interactive Evolutionary Computation;Kansei Retrieval Agent;Particle Swarm Optimization","Artificial neural networks;Computational modeling;Data models;Load modeling;Numerical models;Numerical simulation;Optimization","genetic algorithms;information retrieval;neural nets;particle swarm optimisation","KRA model;Kansei retrieval agent model;basic optimization performance;evolutionary computation approach;genetic algorithm methods;neural network;numerical simulations;particle swarm optimization","","","","","","","25-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"A comparative study of classifiers for music genre classification based on feature extractors","D. P. Kumar; B. J. Sowmya; Chetan; K. G. Srinivasa","Department of CSE, M S Ramaiah Institute of Technology, Bangalore, India","2016 IEEE Distributed Computing, VLSI, Electrical Circuits and Robotics (DISCOVER)","20170105","2016","","","190","194","The objective of this paper is to do a comparative study to detect and classify music files automatically based on its genre by using various classification algorithms. Music genre classification is a popular problem in the domain of Music Information Retrieval (MIR) used in many music streaming platforms such as Pandora which is a automated music recommendation service based on the Music Genome Project, that suggests songs to users based on similarity of songs that the user is interested in. In this paper we have done a comparative study using various machine learning classification algorithms to classify music file based on its genre. We have used both Fast Fourier Transform (FFT) and Mel Frequency Cepstral Coefficients (MFCC) to featurize our data, the latter out of which was recommended in a previous study.","","Electronic:978-1-5090-1623-5; POD:978-1-5090-1624-2","10.1109/DISCOVER.2016.7806258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7806258","Decision trees;Fast Fourier Transform;Support vector machine;kth nearest neighbour;logistic regression;mel Frequency Cepstrum;recurrent neural networks","Algorithm design and analysis;Classification algorithms;Decision trees;Logistics;Mel frequency cepstral coefficient;Recurrent neural networks;Support vector machines","classification;fast Fourier transforms;feature extraction;information retrieval;learning (artificial intelligence);music;recommender systems","FFT;MFCC;MIR;automated music recommendation service;fast Fourier transform;feature extractors;machine learning classification algorithms;mel frequency cepstral coefficients;music genome project;music genre classification;music information retrieval;music streaming platforms","","","","","","","13-14 Aug. 2016","","IEEE","IEEE Conference Publications"
"On Mining Crowd-Based Speech Documentation","P. Moslehi; B. Adams; J. Rilling","Concordia Univ., Montreal, QC, Canada","2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)","20170126","2016","","","259","268","Despite the globalization of software development, relevant documentation of a project, such as requirements and design documents, often still is missing, incomplete or outdated. However, parts of that documentation can be found outside the project, where it is fragmented across hundreds of textual web documents like blog posts, email messages and forum posts, as well as multimedia documents such as screencasts and podcasts. Since dissecting and filtering multimedia information based on its relevancy to a given project is an inherently difficult task, it is necessary to provide an automated approach for mining this crowd-based documentation. In this paper, we are interested in mining the speech part of YouTube screencasts, since this part typically contains the rationale and insights of a screencast. We introduce a methodology that transcribes and analyzes the transcribed text using various Information Extraction (IE) techniques, and present a case study to illustrate the applicability of our mining methodology. In this case study, we extract use case scenarios from WordPress tutorial videos and show how their content can supplement existing documentation. We then evaluate how well existing rankings of video content are able to pinpoint the most relevant videos for a given scenario.","","Electronic:978-1-4503-4186-8; POD:978-1-5090-2242-7","10.1109/MSR.2016.034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832905","Crowd-based documentation; mining video content; speech analysis; Information Extraction; software documentation","Blogs;Data mining;Documentation;Internet;Software;Speech;Videos","data mining;document handling;information retrieval","IE techniques;WordPress tutorial videos;YouTube screencasts;crowd-based speech documentation mining;information extraction techniques;multimedia documents;multimedia information;project documentation;software development;textual Web documents;use case scenario","","","","","","","14-15 May 2016","","IEEE","IEEE Conference Publications"
"DisITQ: A Distributed Iterative Quantization Hashing Learning Algorithm","Q. Chen; B. Lang; X. Liu; Z. Gu","State Key Lab. of Software Dev. Environ., Beihang Univ., Beijing, China","2016 9th International Symposium on Computational Intelligence and Design (ISCID)","20170126","2016","2","","118","123","In the field of big data retrieval, hashing based approximate nearest neighbors (ANN) search has attracted many attentions. However, most existing hashing algorithms are learned from the centralized settings and based on small scale datasets, or in other words, they are single machine approaches which load the training data into memory to get models. For big data processing, models learned from large scale datasets which have the properties of big data such as variety often have better performance. However, there are two critical problems when training datasets are in very large size. First, a single compute node can't load all the data into memory to train hashing models. Second, in real-word applications, the data is often stored or even collected in a distributed manner, and it's infeasible to gather all data into a fusion center because of the prohibitively expensive communication and computation overhead. In this article, we present a distributed learning algorithm which is based on MapReduce and Iterative Quantization (ITQ) to train hashing functions. The proposed method, named as distributed iterative quantization hashing (DisITQ), can not only be performed on large scale datasets, but can also be applied to distributed data storing scenarios. Massive experiments carried out on large scale datasets demonstrate the time efficiency and the accuracy advantages of the method we proposed in comparison with the state-of-the-art hashing algorithms.","","Electronic:978-1-5090-3558-8; POD:978-1-5090-3559-5","10.1109/ISCID.2016.2036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830805","MapReduce;big data;distributed hashing","","Big Data;file organisation;information retrieval;learning (artificial intelligence);parallel processing","ANN search;DisITQ;MapReduce;approximate nearest neighbor search;big data processing;big data retrieval;distributed data storing scenarios;distributed iterative quantization hashing learning algorithm;fusion center;single machine approaches","","","","","","","10-11 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Validity Analysis of a User Model Employed in a Research Activity Support System","D. Kitakoshi; S. Toda; M. Suzuki","Dept. of Comput. Sci., Nat. Inst. of Technol., Hachioji, Japan","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","20161229","2016","","","591","597","Many students in higher education are required to complete graduate work while learning state-of-the-art technologies and theories in their laboratories. To obtain their objectives efficiently, although it is important that students accumulate, share, and apply ""research know-how"", these are generally tough tasks because most students graduate without conveying their know-how to juniors. Inspired by the concepts of Knowledge Management (KM) and Human-Agent Interaction (HAI), we previously proposed a system to support the research activity of students. It presents appropriate know-how based on two types of model: the first expresses relationships between tagged information, the second represents features and trends of information retrieved and evaluated by the students. In this paper, we conducted several experiments using the prototype of our developed system: (i) to evaluate the validity of the user model constructed for respective users (students) based on their usage history of the prototype system, and (ii) to discuss whether the user model adequately estimates users' trends in terms of know-how retrieval/evaluation.","","Electronic:978-1-5090-2678-4; POD:978-1-5090-2679-1","10.1109/SCIS-ISIS.2016.0130","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801717","Human-agent interaction;Knowledge management;Research activity support;Research know-how","Analytical models;Computational modeling;History;Knowledge management;Laboratories;Market research;Prototypes","further education;information retrieval;knowledge management","HAI;KM;higher education;human-agent interaction;information retrieval;knowledge management;research activity support system","","","","","","","25-28 Aug. 2016","","IEEE","IEEE Conference Publications"
"On the Vocabulary Agreement in Software Issue Descriptions","O. Chaparro; J. M. Florez; A. Marcus","Univ. of Texas at Dallas, Richardson, TX, USA","2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20170116","2016","","","448","452","Many software comprehension tasks depend on how stakeholders textually describe their problems. These textual descriptions are leveraged by Text Retrieval (TR)-based solutions to more than 20 software engineering tasks, such as duplicate issue detection. The common assumption of such methods is that text describing the same issue in multiple places will have a common vocabulary. This paper presents an empirical study aimed at verifying this assumption and discusses the impact of the common vocabulary on duplicate issue detection. The study investigated 13K+ pairs of duplicate bug reports and Stack Overflow (SO) questions. We found that on average, more than 12.2% of the duplicate pairs do not have common terms. The other duplicate issue descriptions share, on average, 30% of their vocabulary. The good news is that these duplicates have significantly more terms in common than the non-duplicates. We also found that the difference between the lexical agreement of duplicate and non-duplicate pairs is a good predictor for the performance of TR-based duplicate detection.","","Electronic:978-1-5090-3806-0; POD:978-1-5090-3807-7","10.1109/ICSME.2016.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816492","","Computer bugs;Context;Java;Software engineering;Software maintenance;Vocabulary","information retrieval;program debugging;vocabulary","TR-based solutions;duplicate bug reports;duplicate issue detection;software comprehension tasks;software engineering tasks;software issue descriptions;stack overflow;text retrieval;textual descriptions;vocabulary agreement","","","","","","","2-7 Oct. 2016","","IEEE","IEEE Conference Publications"
"Content pollution mitigation for Content-Centric Networking","I. Ribeiro; A. Rocha; C. Albuquerque; F. Guimarães","Computing Institute, Fluminense Federal University, Brazil","2016 7th International Conference on the Network of the Future (NOF)","20170109","2016","","","1","5","Content-Centric Networking - CCN is a prominent architectural proposal for the future Internet. Even though CCN design includes a set of security mechanisms in order to to ensure authenticity, integrity and confidentiality of contents, some security threats still exists. One of these threats is content pollution, where malicious users cause legitimate users to retrieve incorrect contents, what, in the worst scenario, can lead to a denial of service attack. To mitigate this problem it was proposed CCNCheck, a mechanism that makes all routers in the network to check the signature of contents according to the same probability, which makes the mechanism's efficiency very topology-dependent. In this paper we propose two different deployment approaches to CCNCheck. The first one splits the network routers into two groups: border router and core routers. These two groups were associated with two different verification probabilities. In the second approach, we let the verification probability in the border routers to vary dynamically, according to the pollution level perceived by the router. We have shown through simulation experiments that these approaches reduce topology dependency, allow users to retrieve the majority of requested contents and reduces the number of polluted messages forwarded in the network core.","","Electronic:978-1-5090-4671-3; POD:978-1-5090-4672-0","10.1109/NOF.2016.7810123","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7810123","","Computer crime;Internet;Network topology;Pollution;Proposals;Topology","Internet;computer network security;data integrity;digital signatures;information retrieval;probability","CCN design;CCNCheck;Internet;border router;content authenticity;content confidentiality;content integrity;content pollution mitigation;content-centric networking;core routers;denial of service attack;malicious users;network routers;security mechanisms;security threats;topology-dependent mechanism efficiency;verification probability","","","","","","","16-18 Nov. 2016","","IEEE","IEEE Conference Publications"
"On the Development of Advanced Parental Control Tools","W. Fuertes; K. Quimbiulco; F. Galárraga; J. L. García-Dorado","Univ. de las Fuerzas Armadas ESPE, Sangolqui&#x0301;, Ecuador","2015 1st International Conference on Software Security and Assurance (ICSSA)","20170116","2015","","","1","6","Given the lack of completeness of the current implementations of parental control software along with the novel characteristics parents demand on these pieces of software, this paper presents the design decisions and implementation of parental control mechanisms that both register and avoid inappropriate content accesses by children and teenagers through the Internet. We first evaluated the state-of-the-art tools assessing their functionality, efficiency, usability, security, and accuracy. Then, we conducted an exploratory study spanning surveys of a representative sample of children, parents and network administrators to determine the baseline and the main requirements this sort of software must fulfil. With such foundations, we have implemented an application and front-end interface following criteria as relevance and internal consistency. As development method, we have applied Object Oriented Hypermedia Design combined with Natural Language Processing that uses the Boolean Retrieval Model by means of string searching algorithms as Boyer-Moore and fuzzy string search. The results show that not only inappropriate content accesses through the Internet have been blocked, but also that the proposal provides parents with mechanisms to control and measure their children's Internet use as a fundamental mean in the process of prevention and awareness among the young population.","","Electronic:978-1-5090-1078-3; POD:978-1-5090-1079-0","10.1109/ICSSA.2015.011","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7812938","Cybersecurity;Natural Language Processing;OOHDM;Parental Control","Design methodology;Internet;Natural language processing;Object oriented modeling;Proposals;Security;Software","Internet;authorisation;fuzzy set theory;hypermedia;information retrieval;natural language processing;object-oriented programming;search problems;software tools;user interfaces","Boolean retrieval model;Boyer-Moore search;Internet;application interface;content access;front-end interface;fuzzy string search;natural language processing;object oriented hypermedia design;parental control software;parental control tool;string searching algorithm","","","","","","","27-27 July 2015","","IEEE","IEEE Conference Publications"
"A recommendation system of grants to acquire external funds","S. Kamada; T. Ichimura; T. Watanabe","Dept. of Intelligent Systems, Graduate School of Information Sciences, Hiroshima City University, 3-4-1, Ozuka-Higashi, Asa-Minami-ku Hiroshima, 731-3194, Japan","2016 IEEE 9th International Workshop on Computational Intelligence and Applications (IWCIA)","20170105","2016","","","125","130","The recommendation system of the competitive grants to university researchers by using the Grants-in-Aid for Scientific Research (KAKEN) keywords has been developed. The system can determine the recommendation order of researchers to each grant by the using the association rules between KAKEN application and various information from the web site of the corresponding grant. However, our developed previous system has some fatal errors in the retrieval algorithm. We modify the algorithm and extend the retrieval data for web mining. If the grant information is not enough to determine the relation, the system investigates the past KAKEN records in the database for the researcher who acquired the past grant. Moreover, the system retrieves the papers of the researchers to search their interests. As a result, the agreement degree of the researcher's interest to the grant increases. This paper discusses some simulation results.","","Electronic:978-1-5090-2775-0; POD:978-1-5090-2776-7","10.1109/IWCIA.2016.7805760","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805760","Association Analysis;Grants-in-Aid;Recommendation System;TF-IDF;Web Intelligence","Data mining;Databases;Informatics;Knowledge acquisition;Neural networks;Organizations;Web sites","data mining;information retrieval;recommender systems;research initiatives","KAKEN application;KAKEN database records;Web mining;Web site;association rules;competitive grants;external fund acquisition;grant information;grants-in-aid for scientific research;keywords;recommendation system;retrieval algorithm errors;university researchers","","","","","","","5-5 Nov. 2016","","IEEE","IEEE Conference Publications"
"I Know What You Want to Express: Sentence Element Inference by Incorporating External Knowledge Base","X. Wei; H. Huang; L. Nie; H. Zhang; X. L. Mao; T. S. Chua","Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, School of Computer, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","20170110","2017","29","2","344","358","Sentence auto-completion is an important feature that saves users many keystrokes in typing the entire sentence by providing suggestions as they type. Despite its value, the existing sentence auto-completion methods, such as query completion models, can hardly be applied to solving the object completion problem in sentences with the form of (subject, verb, object), due to the complex natural language description and the data deficiency problem. Towards this goal, we treat an SVO sentence as a three-element triple (subject, sentence pattern, object), and cast the sentence object completion problem as an element inference problem. These elements in all triples are encoded into a unified low-dimensional embedding space by our proposed TRANSFER model, which leverages the external knowledge base to strengthen the representation learning performance. With such representations, we can provide reliable candidates for the desired missing element by a linear model. Extensive experiments on a real-world dataset have well-validated our model. Meanwhile, we have successfully applied our proposed model to factoid question answering systems for answer candidate selection, which further demonstrates the applicability of the TRANSFER model.","1041-4347;10414347","","10.1109/TKDE.2016.2622705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723822","Representation learning;external knowledge base;sentence modeling","Encyclopedias;Face;Internet;Knowledge based systems;Knowledge discovery;Natural languages;Semantics","inference mechanisms;knowledge based systems;learning (artificial intelligence);natural language processing;question answering (information retrieval)","SVO sentence;TRANSFER model;answer candidate selection;complex natural language description;data deficiency problem;element inference problem;external knowledge base;factoid question answering systems;linear model;query completion models;representation learning performance;sentence autocompletion methods;sentence element inference;sentence object completion problem;three-element triple;unified low-dimensional embedding space","","","","","","20161027","Feb. 1 2017","","IEEE","IEEE Journals & Magazines"
"Rewriting Minimisations for Efficient Ontology-Based Query Answering","T. Venetis; G. Stoilos; V. Vassalos","Dept. of Inf., Athens Univ. of Econ. & Bus., Athens, Greece","2016 IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)","20170116","2016","","","1095","1102","Computing a (Union of Conjunctive Queries - UCQ) rewriting R for an input query and ontology and evaluating it over the given dataset is a prominent approach to query answering over ontologies. However, R can be large and complex in structure hence additional techniques, like query subsumption and data constraints, need to be employed in order to minimise Rew and lead to an efficient evaluation. Although sound in theory, how to efficiently and effectively implement many of these techniques in practice could be challenging. For example, many systems do not implement query subsumption. In the current paper we present several practical techniques for UCQ rewriting minimisation. First, we present an optimised algorithm for eliminating redundant (w.r.t. subsumption) queries as well as a novel framework for rewriting minimisation using data constraints. Second, we show how these techniques can also be used to speed up the computation of R in the first place. Third, we integrated all our techniques in our query rewriting system IQAROS and conducted an extensive experimental evaluation using many artificial as well as challenging real-world ontologies obtaining encouraging results as, in the vast majority of cases, our system is more efficient compared to the two most popular state-of-the-art systems.","","Electronic:978-1-5090-4459-7; POD:978-1-5090-4460-3","10.1109/ICTAI.2016.0168","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814728","Ontology Based Data Access;Optimization;Query Answering;Query Rewriting","Business;Economics;Electronic mail;Informatics;Minimization;OWL;Ontologies","ontologies (artificial intelligence);question answering (information retrieval);rewriting systems","IQAROS;data constraints;ontology-based query answering;query rewriting system;query subsumption;rewriting minimisations","","","","","","","6-8 Nov. 2016","","IEEE","IEEE Conference Publications"
"QoI-Aware Unified Framework for Node Classification and Self-Reconfiguration Within Heterogeneous Visual Sensor Networks","A. Amjad; A. Griffiths; M. Patwary","Faculty of Computing, Engineering and Sciences, Staffordshire University, Stoke-on-Trent, U.K.","IEEE Access","20170123","2016","4","","9027","9042","Due to energy and throughput constraints of visual sensing nodes, in-node energy conservation is one of the prime concerns in visual sensor networks (VSNs) with wireless transceiving capability. To cope with these constraints, the energy efficiency of a VSN for a given level of reliability can be enhanced by reconfiguring its nodes dynamically to achieve optimal configurations. In this paper, a unified framework for node classification and dynamic self-reconfiguration in VSNs is proposed. The proposed framework incorporates quality-of-information (QoI) awareness using peak signal-to-noise ratio-based representative metric to support a diverse range of applications. First, for a given application, the proposed framework provides a feasible solution for the classification of visual sensing nodes based on their field-of-view by exploiting the heterogeneity of the targeted QoI within the sensing region. Second, with the dynamic realization of QoI, a strategy is devised for selecting suitable configurations of visual sensing nodes to reduce redundant visual content prior to transmission without sacrificing the expected information retrieval reliability. The robustness of the proposed framework is evaluated under various scenarios by considering: 1) target QoI thresholds; 2) degree of heterogeneity; and 3) compression schemes. From the simulation results, it is observed that for the second degree of heterogeneity in targeted QoI, the unified framework outperforms its existing counterparts and results in up to 72% energy savings with as low as 94% reliability.","2169-3536;21693536","","10.1109/ACCESS.2016.2635941","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779069","3D field-of-view modelling;dynamic reconfiguration;energy optimization;node classification;quality-of-information;reliability analysis;visual sensor networks","Energy management;Node classification;Optimization;Reliability;Sensors;Solid modeling;Three-dimensional displays;Visual analytics;Visualization","information retrieval;radio transceivers;telecommunication computing;telecommunication network reliability;wireless sensor networks","QoI-aware unified framework;VSN;compression scheme;dynamic realization;dynamic self-reconfiguration;energy efficiency;heterogeneity degree;heterogeneous visual sensor networks;in-node energy conservation;information retrieval reliability;node classification;peak signal-to-noise ratio-based representative metric;quality-of-information;target QoI thresholds;visual sensing nodes;wireless transceiving capability","","","","","","20161209","2016","","IEEE","IEEE Journals & Magazines"
"enGeno: Towards enabling a medical genogram library for supporting home-visit patient diagnosis","M. Boonnavasin; P. Rattanatamrong","Department of Computer Science, Faculty of Science and Technology, Thammasat University, Pathum Thani, Thailand","2016 IEEE 5th Global Conference on Consumer Electronics","20161229","2016","","","1","4","A genogram refers to a family tree used for medical purposes. It is a useful diagnosis tool for physicians to understand patients' family information. There are many programs that attempt to support genogram creation, but each has its own limitation. For examples, some programs require users to pay usage fee and to install them in computers in order to view and edit genograms. While free Web-based genogram tools offer more economical alternatives to the formers, their users usually cannot save genograms for later edition. Moreover, it is not possible to integrate and reuse functionalities from these existing programs in users' own systems. Therefore, we propose a JavaScript library, called ""enGeno"", to address the above issues. From our performance evaluation, the enGeno library can efficiently provide physicians capabilities to store and retrieve information about their patients.","","Electronic:978-1-5090-2333-2; POD:978-1-5090-2334-9","10.1109/GCCE.2016.7800549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800549","Genogram;JavaScript library;diagnosis tool;medical diagram","Complexity theory;Conferences;Consumer electronics;Diseases;Libraries;Medical diagnostic imaging","Java;information retrieval;medical computing;patient diagnosis","JavaScript library;Web-based genogram tools;diagnosis tool;enGeno library;genogram creation;home-visit patient diagnosis;information retrieval;medical genogram library;patient family information;physician capabilities","","","","","","","11-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"An Efficient Association Mining Method via Matrix Compression","Y. Zhong; D. Liu","Res. Inst. of Electron. Sci. & Technol., Univ. of Electron. Sci. Technol. of China, Chengdu, China","2016 9th International Symposium on Computational Intelligence and Design (ISCID)","20170126","2016","1","","188","192","With the development of computer network technology and popularization, and the technology of data acquisition, data management and data query develop rapidly. People who is in the surging ""data ocean"", need an intelligent technology badly, to ""explore"" more valuable ""oil ""from the ""data ocean"",so the data mining technology which has been successfully used in commercial, medical, financial, and other fields, emerges. The primary technology of data mining is classification analysis, cluster analysis, Association Rule analysis, and etc. Association Rule analysis is an important branch of data mining, which can extract the valuable associations or rules people want to know from data warehouse. Based on the background of ""data platform for public petition"", it aims to study how to combine the Association Rule analysis technology with the current massive government-data, extracting association information from the massive hidden government-data, which can provide userful and valuable information according to the practical significance of the associations for system managers and decision makers. This paper study the classic Association Rule algorithm Apriori, propose the improved Apriori algorithm based on matrix com-pression. Based on this improved Apriori algorithm, develop the module of the analysis of cases evaluation, which can associate the cases and case handlers according to the information of cases and case handlers fistly, and then get the practical significance from the association result analysis, which can provide help to the managers and decision makers.","","Electronic:978-1-5090-3558-8; POD:978-1-5090-3559-5","10.1109/ISCID.2016.1050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7830324","Analysis of cases evaluation;Apriori algorithm;Association Rule analysis;Compression Matrix;government-data","Algorithm design and analysis;Data mining;Government;Itemsets;Oceans","data mining;information retrieval;matrix algebra","association information extraction;association rule analysis;classification analysis;cluster analysis;computer network technology;data acquisition;data management;data mining;data query;intelligent technology;massive hidden government-data;matrix compression","","","","","","","10-11 Dec. 2016","","IEEE","IEEE Conference Publications"
"A Comprehensive Knowledge Management Process Framework for Healthcare Information Systems in Healthcare Industry of Pakistan","A. Arshad; M. F. Bin Noordin; R. B. Othman","Dept. of Inf. Syst. Kulliyah of Inf. & Commun., Technol. Int. Islamic Univ., Kuala Lumpur, Malaysia","2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20170116","2016","","","30","35","The major challenge in the existing healthcare industry of Pakistan is that despite the presence of extensive data and related information, there is no solid Knowledge Management (KM) process or framework for controlling and catering the diversified nature of knowledge creation for effective decision making resulting in ineffective and inefficient organization and utilization of various important resources being used during the decision making operations [12] [13]. In this study, we present and suggest a comprehensive and phased knowledge management process framework that integrates and streamlines varied and multiple processes in a phased manner to collect, analyze and manage knowledge and the knowledge creation process for supporting the effective decision making in healthcare information systems related to healthcare industry of Pakistan. This KM process framework will help identify the information needs and provide decision makers with useful step-by-step recommendations and guidelines based upon the integrated knowledge and past experience.","","Electronic:978-1-5090-4521-1; POD:978-1-5090-4522-8","10.1109/ICT4M.2016.019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814872","Decision Making;Healthcare Information System;Integrated Knowledge;Knowledge Management;Knowledge creation;Process Framework","Industries;Information and communication technology;Information systems;Knowledge management;Medical services;Organizations;Technological innovation","decision making;decision support systems;health care;information needs;information retrieval;knowledge management;medical information systems;recommender systems","Pakistan;comprehensive knowledge management process framework;decision making operation;effective decision making;healthcare industry;healthcare information systems;information needs identification;knowledge analysis;knowledge collection;knowledge creation;phased knowledge management process framework;resource utilization;step-by-step recommendation","","","","","","","22-24 Nov. 2016","","IEEE","IEEE Conference Publications"
"Exploiting response patterns for identifying topical experts in StackOverflow","M. Bhanu; J. Chandra","Department of Computer Science & Engineering, Indian Institute of Technology, Patna","2016 Eleventh International Conference on Digital Information Management (ICDIM)","20170126","2016","","","139","144","The popularity of community question answer (CQA) forums like Stack Overflow, Yahoo Answers and Quora is increasing tremendously with thousands of questions being posted each day and about thrice the number of responses being provided. With such query explosion, users participating in these forums receive a huge number of postings that adversely affects their responsiveness and also the quality of the responses. Hence, identifying topical experts is necessary to improve the efficacy of these systems in terms of both response time and quality. Although expert detection in CQA forums has traditionally been a topic of wide interest, however, many of the proposed techniques use features set that reflect the popularity of the responses of the responder rather than the difficulty level of the questions being responded. In this paper we provide measures of labeling difficult questions and use the number of difficult questions responded by a user combined with other user interaction parameters in identifying potential topical experts. Using a random forest classifier with the proposed feature set on Stack Overflow data, we obtain an improvement in accuracy of 5-16% over existing techniques, in detecting topical experts.","","Electronic:978-1-5090-2641-8; POD:978-1-5090-2642-5","10.1109/ICDIM.2016.7829790","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829790","","Computer science;Electronic mail;Explosions;Feature extraction;Labeling;Standards;Time factors","Web sites;learning (artificial intelligence);pattern classification;question answering (information retrieval);user interfaces","CQA forums;Quora;StackOverflow;Yahoo Answers;community question answer forums;feature set;random forest classifier;response patterns;response quality;response time;topical experts identification;user interaction parameters","","","","","","","19-21 Sept. 2016","","IEEE","IEEE Conference Publications"
"Joint Model of Topics, Expertises, Activities and Trends for Question Answering Web Applications","Z. Meng; F. Gandon; C. F. Zucker","INRIA SAM, France","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","296","303","Users in question-answer sites generate huge amounts of high quality and highly reusable information. This information can be categorized by topics but since users' interests change with time, uncovering the temporal patterns and trends in their activity is of prime interest to detect their current expertize. These temporal variations have long remained unexplored in question-answer sites while detecting them enables us to improve tasks such as: question routing, expert recommending and community life-cycle management. In this paper, we propose a generative model of such a community and its dynamics, and we perform experiments with real-world data extracted from the StackOverflow website to confirm the effectiveness of our model to study the users' behaviors and topics dynamics.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817066","Community Question Answering;Probabilistic graphical model;Question routing;Temporal analysis;Topic modeling","Data mining;Data models;Databases;Feature extraction;Market research;Routing;Training data","Internet;Web sites;question answering (information retrieval)","StackOverflow Website;Web applications;data extraction;joint model;question answering;topics dynamics;user behaviors","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Improved Combination of Multiple Retrieval Systems Using a Dynamic Combinatorial Fusion Algorithm","H. Liu; Z. Wu; D. F. Hsu; B. S. Kristal","Sch. of Software & Microelectron., Peking Univ., Beijing, China","2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)","20170116","2016","","","592","596","A combination of multiple retrieval systems can outperform its individual component systems, but it remains a challenging problem to predict whether two systems can be beneficially combined and, if so, the optimal means by which they should be merged. The performance of combined systems is affected by many factors, including the performance of individual systems, the diversity between a pair of systems, and the method for combination. In this paper, we undertake the study of these issues using combinatorial fusion algorithm (CFA) utilizing the rank-score characteristic (RSC) function and the notion of a weighted cognitive diversity. Using the selected eight TREC datasets, we demonstrated that: (a) the combination of two retrieval systems performs better than each individual system only when the individual systems have relatively good performance and they are diverse, (b) a dynamic combination method, using rank vs. score combination based on cognitive diversity which does not display a tight correlation with other statistical diversity measures, can improve the performance of the combined system, even when performance of each individual system is not known or in the context of an unsupervised learning environment. Within the TREC datasets, the proposed dynamic approach offers a potential for substantial improvement with no significant risk. Our results provide a new paradigm of dynamic fusion to the study of the combination of multiple retrieval systems.","","Electronic:978-1-5090-4470-2; POD:978-1-5090-4471-9","10.1109/WI.2016.0102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817119","cognitive diversity;combinatorial fusion;multiple retrieval systems;rank-score characteristic (RSC) function","","combinatorial mathematics;information retrieval;learning (artificial intelligence);statistical analysis","TREC datasets;dynamic combinatorial fusion algorithm;multiple retrieval system;rank-score characteristic function;statistical diversity;unsupervised learning environment;weighted cognitive diversity","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Estimating the Structural Segmentation of Popular Music Pieces Under Regularity Constraints","G. Sargent; F. Bimbot; E. Vincent","Institut de Recherche en Informatique et Syst&#232;mes Al&#233;atoires, Rennes, France","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20161226","2017","25","2","344","358","Music structure estimation has recently emerged as a central topic within the field of music information retrieval. Indeed, as music is a highly structured information stream, knowledge of how a music piece is organized represents a key challenge to enhance the management and exploitation of large music collections. This paper focuses on the benefits that can be expected from a regularity constraint on the structural segmentation of popular music pieces. Specifically, here, we study how a constraint that favors structural segments of comparable size provides a better conditioning of the boundary estimation process. First, we propose a formulation of the structural segmentation task as an optimization process, which separates the contribution from the audio features and the one from the constraint. We illustrate how the corresponding cost function can be minimized using a Viterbi algorithm. We present briefly its implementation and results in three systems designed for and submitted to the MIREX 2010, 2011, and 2012 evaluation campaigns. Then, we explore the benefits of the regularity constraint as an efficient mean for combining the outputs of a selection of systems presented at MIREX between 2010 and 2015, yielding a level of performance competitive to that of the state-of-the-art on the “MIREX10” dataset (100 J-Pop songs from the RWC database).","2329-9290;23299290","","10.1109/TASLP.2016.2635031","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7765033","Fusion;MIREX evaluation campaign;Viterbi algorithm;multi criteria approach;music structure estimation;optimization;regularity constraint;structural segmentation","Estimation;Music;Periodic structures;Semiotics;Speech;Speech processing;Viterbi algorithm","Viterbi detection;audio signal processing;information retrieval;music","MIREX10 dataset;Viterbi algorithm;audio features;boundary estimation process;cost function;music collections;music information retrieval;music pieces;music structure estimation;optimization process;regularity constraints;structural segmentation","","","","","","20161202","Feb. 2017","","IEEE","IEEE Journals & Magazines"
"Examination of effective features for CRF-based bibliography extraction from reference strings","D. Matsuoka; M. Ohta; A. Takasu; J. Adachi","Okayama University, Okayama, Japan","2016 Eleventh International Conference on Digital Information Management (ICDIM)","20170126","2016","","","243","248","Metadata such as bibliographic information about documents are indispensable in the effective use of digital libraries. In particular, the reference fields of academic papers contain much bibliographic information such as authors' names and document titles. We are therefore developing a method for automatically extracting bibliographic information from reference strings using a conditional random field (CRF). The features used by the CRF determine the accuracy of this method. We examine effective features for accurate extraction by experimentally changing the features used. The experiments showed that lexical features were quite effective in accurate extraction and augmenting lexicons properly could lead to further improvements in accuracy.","","Electronic:978-1-5090-2641-8; POD:978-1-5090-2642-5","10.1109/ICDIM.2016.7829774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829774","","Bibliographies;Data mining;Electronic mail;Feature extraction;Libraries;Uniform resource locators","bibliographic systems;digital libraries;feature extraction;information retrieval;random processes;string matching;text analysis","CRF-based bibliography extraction;author names;automatic bibliographic information extraction;bibliographic information;conditional random field;digital libraries;document titles;lexical features;metadata;reference strings","","","","","","","19-21 Sept. 2016","","IEEE","IEEE Conference Publications"
"Multi-extract and Multi-level Dataset of Mozilla Issue Tracking History","J. Zhu; M. Zhou; H. Mei","Key Lab. of High Confidence Software Technol., Peking Univ., Beijing, China","2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)","20170126","2016","","","472","475","Many studies analyze issue tracking repositories to understand and support software development. To facilitate the analyses, we share a Mozilla issue tracking dataset covering a 15-year history. The dataset includes three extracts and multiple levels for each extract. The three extracts were retrieved through two channels, a front-end (web user interface (UI)), and a back-end (official database dump) of Mozilla Bugzilla at three different times. The variations (dynamics) among extracts provide space for researchers to reproduce and validate their studies, while revealing potential opportunities for studies that otherwise could not be conducted. We provide different data levels for each extract ranging from raw data to standardized data as well as to the calculated data level for targeting specific research questions. Data retrieving and processing scripts related to each data level are offered too. By employing the multi-level structure, analysts can more efficiently start an inquiry from the standardized level and easily trace the data chain when necessary (e.g., to verify if a phenomenon reflected by the data is an actual event). We applied this dataset to several published studies and intend to expand the multi-level and multi-extract feature to other software engineering datasets.","","Electronic:978-1-4503-4186-8; POD:978-1-5090-2242-7","10.1109/MSR.2016.057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832928","","Computer bugs;Data mining;Databases;History;Security;Software;Target tracking","Internet;data analysis;information retrieval;software engineering;user interfaces","Mozilla Bugzilla;Mozilla issue tracking dataset;Mozilla issue tracking repositories;Web user interface;back-end channels;data chain trace;data processing scripts;data retrieval;front-end channels;multilevel multiextract feature;multilevel structure;official database dump;software development;software engineering datasets","","","","","","","14-15 May 2016","","IEEE","IEEE Conference Publications"
"Distributed Coverage of Ego Networks in F2F Online Social Networks","A. D. Salve; B. Guidi; P. Mori; L. Ricci","Dipt. di Inf., Univ. di Pisa, Pisa, Italy","2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)","20170116","2016","","","423","431","Although most online social networks rely on a centralized infrastructure, several proposals of Distributed Online Social Networks (DOSNs) have been recently presented. Since in DOSNs user profiles are stored on the peers of the users belonging to the network, one of the main challenges comes from guaranteeing the profile availability when the owner of the data is not online. In this paper, we propose a DOSN based on a friend-to-friend P2P overlay where the user's data is stored only on friend peers. Our approach is based on the ego-network concept, which models the social network from the local point of view of a single user. We propose a distributed algorithm which is based on the notion of coverage of the ego-network, assures that users store their data only on the peers of their friends,, that each online user can retrieve the private data of its offline friends through a common online friend. We formalize this as a Neighbour Dominating Set problem. A set of experimental results conducted on real Facebook dataset show the effectiveness of our approach.","","Electronic:978-1-5090-2771-2; POD:978-1-5090-2772-9","10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0078","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816874","Data Availability;Distributed Online Social Networks;P2P;friend-to-friend networks","Cryptography;Data privacy;Distributed databases;Peer-to-peer computing;Privacy;Servers;Social network services","information retrieval;security of data;social networking (online)","DOSN user profiles;F2F online social networks;distributed coverage;distributed online social networks;ego networks;friend-to-friend P2P;neighbour dominating set problem;online user;private data;user data","","","","","","","18-21 July 2016","","IEEE","IEEE Conference Publications"
"Improve the data retrieval time and security through fragmentation and replication in the cloud","W. Delishiya Moral; B. M. Kumar","Department of Computer Science and Engineering, Syed Ammal Engineering College, Ramanathapuram","2016 International Conference on Advanced Communication Control and Computing Technologies (ICACCCT)","20170126","2016","","","539","545","Cloud computing being promising and emerging technology for the next generation of IT applications which provides the storage and supports for outsourcing of data without having the native copy of data or files. Cloud computing service providers require a system which can handle a large number of requests at a time and is needed to be highly available. Major issue faces in cloud computing is Security and data retrieval. In data security an important problem is to prevent illegal modifications and data loss. But, for this it requires either data replication or on-demand computation of a function over the entire contract out data. Generally system keeps multiple copies of the blocks of data on different nodes by replication. Another issue is retrieval of data, whereas in the cloud computing environment it becomes particularly serious because the data is located in different places even in the entire globe. Load on system may increase when there is high demand of a data. In this, the main focus is on the problems of security, replication and availability of data. The proposed system use a fragmentation and sole replication (FASR) concept in the cloud to improve the security and data retrieval time rather than using traditional cryptographic techniques. It fragments the file, place every single fragment in distinct node and perform sole replication that is every fragment is replicated only once, to provide security. Particularly selection of primary node is done through hotbed measure, selection of node and placement of other fragments is done through T-coloring technique, which limits tampering of data. Thereby improve retrieval time for easy accessing of the fragments for reconstruction of original file on user request. In this user can download, update and upload the file again. User can also request for required fragments and can update, upload it to cloud. Another automatic updating technique is proposed which allow uploading of only updated fragment in the cloud - ode. FASR concept provides security; save time and automatic updating technique reduce the resource utilized. Non-cryptographic nature makes the system even faster.","","CD:978-1-4673-9544-1; Electronic:978-1-4673-9545-8; POD:978-1-4673-9546-5","10.1109/ICACCCT.2016.7831698","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7831698","Automatic updating technique;Sole replication data retrieval time;T-coloring;node Selection","Cloud computing;Computers;Cryptography;Reliability;Servers;Virtualization","cloud computing;graph theory;information retrieval;outsourcing;security of data","FASR;T-coloring;cloud computing;data outsourcing;data retrieval time;data security;fragmentation and sole replication;node selection","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Permanent participatory data security in a cloud computing environment","S. I. El Ahrache; H. Badir; P. Ghodous; A. Sbihi","LABTIC, National School of Applied Sciences, Tangier, Morocco","2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)","20170105","2016","","","320","324","Recently, there has been increasing confidence for a favorable usage of big data drawn out from the huge amount of information deposited in a cloud computing system. Data kept on such systems can be retrieved through the network at the user's convenience. However, the data that users send include private information, and therefore, information leakage from these data is now a major social problem. The usage of secret sharing schemes for cloud computing have lately been approved to be relevant in which users deal out their data to several servers. Notably, in a (k, n) threshold scheme, data security is assured if and only if all through the whole life of the secret the opponent cannot compromise more than k of the n servers. In fact, a number of secret sharing algorithms have been suggested to deal with these security issues. However, a limitation of these methods is that first they do not consider long term data storage and second they assume that data tempering only occurs at retrieval time, after the distribution of the shares has been correctly done. In this paper we address these two problems by presenting a novel scheme to ensure a perpetual secure data storage and retrieval.","","Electronic:978-1-5090-0751-6; POD:978-1-5090-0752-3","10.1109/CIST.2016.7805064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7805064","blinding;cloud computing;data security;secret sharing;treshold cryptography","Cloud computing;Cryptography;Distributed databases;Memory;Servers","Big Data;cloud computing;cryptography;information retrieval;storage management","Big Data;cloud computing;data retrieval security;data tempering;information leakage;long term data storage security;permanent participatory data security;secret sharing;share distribution","","","","","","","24-26 Oct. 2016","","IEEE","IEEE Conference Publications"
"A method to extract essential keywords from a tweet using NLP tools","T. Weerasooriya; N. Perera; S. R. Liyanage","Department of Statistics & Computer Science, University of Kelaniya, Sri Lanka","2016 Sixteenth International Conference on Advances in ICT for Emerging Regions (ICTer)","20170126","2016","","","29","34","A tweet is an authentic use of Natural Language where the user has to deliver the message in 140 characters or less. According to previous researchers, this restriction increases the possible ambiguity of a tweet making it difficult for traditional Natural Language Processing (NLP) tools to analyze it. This research enhances the machine learning based Stanford CoreNLP Part-of-Speech (POS) tagger with the Twitter model to extract essential keywords from a tweet. The system was enhanced using two rule-based parsers and a corpus. The research was conducted using tweets of customer service requests sent to a telecommunication company. A domain specific corpus was compiled after analyzing the tweets. The POS tagger extracted the keywords while the parsers removed any possible noise and extracted any other keywords missed by the POS tagger. The evaluation of the system was done using the Turing Test. The proposed system was tested and compared against the Stanford CoreNLP. The testing was conducted using 6 test cases, each consisting of a human keyword generator and a supervisor. In order to ensure the impartiality and intellectual diversity, the response generators and supervisors were representatives of 6 different fields. As a result of the enhancements, the Turing Test score of the system increased from 50.00% to 83.33%. The accuracy of the system could be further improved by using a complete domain specific corpus. Since the approach used theoretical linguistic features of a sentence, the same method could be employed for other NLP tools.","","CD:978-1-5090-6076-4; Electronic:978-1-5090-6078-8; POD:978-1-5090-6079-5; Paper:978-1-5090-6077-1","10.1109/ICTER.2016.7829895","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829895","Keyword Extraction;Natural Language Processing;Turing Test;Tweet Analysis","Customer services;Feature extraction;Natural language processing;Pragmatics;Syntactics;Tagging;Twitter","customer services;grammars;information retrieval;knowledge based systems;learning (artificial intelligence);natural language processing;social networking (online);telecommunication industry","NLP tools;POS tagger;Turing test score;Twitter model;customer service requests;domain specific corpus;essential keyword extraction;machine learning based Stanford CoreNLP part-of-speech tagger;natural language processing tools;rule-based parsers;telecommunication company;tweets analysis","","","","","","","1-3 Sept. 2016","","IEEE","IEEE Conference Publications"
"KMS with hierarchical administrative architecture: A knowledge administrator perspective","T. I. Ghosh; S. S. Chatterjee; B. Chakraborty","InMobi, Bangalore, India","2016 IEEE International Conference on Knowledge Engineering and Applications (ICKEA)","20170102","2016","","","144","149","A Knowledge Management System (KMS) refers to a system for managing knowledge in organizations, supporting creation, capture, storage and dissemination of information. KMS is viewed as an essential tool to extract tacit knowledge from data, convert it to explicit knowledge and preserve the same for future utilization. The system involves creation of a knowledge repository using the extracted knowledge and disseminating it in the form of query response systems. In this work, we have proposed the architecture for an administrator-centric KMS which revolves around the concept of Knowledge Administrator (KA) with a Knowledge Worker (KW) standard. KA is responsible for maintenance as well as security and efficiency of the framework which are essential for a reliable KMS. In this system, the Knowledge Worker (KW) structure is hierarchical which provides scope for building a knowledge repository which is often encountered to be critical in some of its applications. The Knowledge Base (KB) is built on tag extraction based on inverted indexing. The system was a learning automation which used the available client feedback in response to the query answered from the knowledge base. The knowledge repository interacted with data using a framework created based on inverted indexing. A salient feature of the architecture is the notion of Probabilistic Optimum Performance (POP) factor used for rating KWs. The rating which is determined by past performance and client feedback acts as a driving force for a more comprehensive KB as its interaction with its environment increases.","","CD:978-1-5090-3469-7; Electronic:978-1-5090-3471-0; POD:978-1-5090-3472-7; Paper:978-1-5090-3470-3","10.1109/ICKEA.2016.7803008","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803008","KMS architecture;Knowledge management system;POP factor;client feedback;knowledge administrator","Indexes;Probabilistic logic","information dissemination;information retrieval;knowledge based systems;knowledge management;probability","KA;KB;KMS;KW;POP factor;hierarchical administrative architecture;knowledge administrator;knowledge base;knowledge dissemination;knowledge management system;knowledge repository;knowledge worker;probabilistic optimum performance factor;tacit knowledge extraction","","","","","","","28-30 Sept. 2016","","IEEE","IEEE Conference Publications"
"Tutorials [2 abstracts]","Yong Zheng; R. Girardi","Illinois Inst. of Technol., Chicago, IL, USA","2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW)","20170116","2016","","","xix","xx","Describes Tutorial I: ""Context-Awareness in Information Retrieval and Recommender Systems"" (Presented by Yong Zheng) and Tutorial II: ""Ontology Learning and Population from Text Background"" (Presented by Rosario Girardi); Ontology Learning and Population from Text Background.","","Electronic:978-1-5090-4771-0; POD:978-1-5090-4772-7","10.1109/WIW.2016.012","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814462","","Context;Knowledge based systems;Motion pictures;Ontologies;Recommender systems;Tutorials","information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);recommender systems;text analysis","IR;RS;context-awareness;information retrieval;ontology learning;recommender systems","","","","","","","13-16 Oct. 2016","","IEEE","IEEE Conference Publications"
"Research field analysis using linked data of I-Scover","T. Wakahara; T. Maki; K. Takahashi","Intelligent Information System Engineering, Fukuoka Institute of Technology, FIT, Fukuoka, Japan","2016 IEEE 5th Global Conference on Consumer Electronics","20161229","2016","","","1","2","This paper presents the research field analysis method using the Linked Data of I-Scover [1]. I-Scover is the article retrieval system of the Institute of Electronics, Information and Communication Engineers (IEICE). This system manages the article metadata by Linked Data format. The research field analysis of the articles is important, and the effective article classification is desired for faceted navigation. The simulation results of the proposed analysis method show the good performance and the validity of this method is confirmed.","","Electronic:978-1-5090-2333-2; POD:978-1-5090-2334-9","10.1109/GCCE.2016.7800504","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7800504","Article Retrieval;Classification;I-Scover;Linked Data;Research Field Analysis","Analytical models;Conferences;Global Positioning System;Information systems;Metadata;Peer-to-peer computing;Simulation","Linked Data;information retrieval","I-Scover;IEICE;Institute of Electronics, Information and Communication Engineers;Linked Data;article metadata;article retrieval system;effective article classification;research field analysis method","","","","","","","11-14 Oct. 2016","","IEEE","IEEE Conference Publications"
"Apriori algorithm for association rule mining in high dimensional data","S. Harikumar; D. U. Dilipkumar","Department of Computer Science and Engineering, Amrita School of Engineering, Amritapuri, Amrita Vishwa Vidyapeetham, Amrita University, India","2016 International Conference on Data Science and Engineering (ICDSE)","20170119","2016","","","1","6","Apriori is one of the best algorithms for learning association rules. Due to the explosion of data, the storage and retrieval mechanisms in various database paradigms have revolutionized the technologies and methodologies used in the architecture. As a result, the database is not only utilized for mere information retrieval but also to infer the analytical aspect of data. Therefore it is essential to find association rules from high dimensional data because the correlation amongst the attributes can help in gaining deeper insight into the data and help in decision making, recommendations as well as reorganizing the data for effective retrieval. The traditional Apriori algorithm is computationally expensive and infeasible with high dimensional datasets. Hence we propose a variant of Apriori algorithm using the concept of QR decomposition for reducing the dimensions thereby reducing the complexity of the traditional Apriori algorithm.","","Electronic:978-1-5090-1281-7; POD:978-1-5090-1282-4","10.1109/ICDSE.2016.7823952","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823952","Apriori;Association Rule Mining;QR decomposition","Algorithm design and analysis;Conferences;Correlation;Data mining;Itemsets;Organizations","data mining;information retrieval","QR decomposition;apriori algorithm;association rule mining;high dimensional data;information retrieval","","","","","","","23-25 Aug. 2016","","IEEE","IEEE Conference Publications"
"Time Aware Recommendation","A. Sara; Y. E. B. El Idrissi; R. Ajhoun","ENSIAS, Univ. Mohamed V, Rabat, Morocco","2016 6th International Conference on Information and Communication Technology for The Muslim World (ICT4M)","20170116","2016","","","244","247","The overload of information can become a significant challenge in relation to information retrieval systems. Often users will need to carry out extensive research to get the information they desire. This issue will only become more challenging as the quantity of data available on the internet increases. This increase shows no signs of slowing down and inevitably demands better solutions. One such solution proposed in this paper will look at the quality of the service discovery, such as adaptation customizing recommendation. In our project we considered ways to customize the contextual recommendation by creating a time awareness system.","","Electronic:978-1-5090-4521-1; POD:978-1-5090-4522-8","10.1109/ICT4M.2016.057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814910","Recommendation; context; profile; time; intention","Collaboration;Computers;Context;Internet;Media;Recommender systems","Internet;information retrieval;recommender systems","Internet;adaptation customizing recommendation;contextual recommendation;information overload;information retrieval systems;service discovery;time aware recommendation;time awareness system","","","","","","","22-24 Nov. 2016","","IEEE","IEEE Conference Publications"
