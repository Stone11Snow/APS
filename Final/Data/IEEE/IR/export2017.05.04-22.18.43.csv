"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6840465,6836639,6838004,6839927,6839275,6835701,6839264,6838389,6835565,6835555,6835644,6838164,6838268,6838561,6836569,6837642,6835627,6836633,6832329,6832348,6834627,6832332,6830993,6830590,6832880,6831409,6831981,6831933,6830471,6831411,6830971,6831136,6831393,6830184,6828144,6831005,6832010,6828170,6830551,6828149,6826018,6825669,6826167,6824595,6826165,6825065,6816015,6823955,6823528,6822242,6822222,6823554,6268270,6821420,6821465,6822768,6822131,6822431,6821440,6822424,6821677,6821498,6822349,6819953,6821437,6820309,6821015,6821052,6820968,6820463,6820469,6820609,6820317,6819679,6819197,6819235,6816543,6816418,6816610,6816667,6816608,6818079,6816607,6816352,6816567,6816307,6816671,6816316,6818307,6816660,6816736,6818331,6816644,6816717,6816737,6816536,6816741,6816597,6816651,6750756",2017/05/04 22:18:43
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Cognitive-Based Multi-document Summarization Approach","J. Chen; W. Li","Key Lab. of Intell. Inf. Process., Inst. of Comput. Technol., Beijing, China","2013 Ninth International Conference on Semantics, Knowledge and Grids","20140519","2013","","","214","217","Automatic text summarization is an important and useful research area in natural language processing and information retrieval. Most of current approaches for text summarization do not make full use of human reading process. This paper proposes a multi-document scanning mechanism by simulating human reading process. The mechanism simulates human memory of words, association between words and three cognitive processes invoked when reading. Changes of human memory of topic words in reading process are used to denote sentences' significance, based on which sentences are then ordered and extracted to form a summary. Experiments on DUC2007 test data show that our proposing method is efficient and outperforms two baseline methods.","","Electronic:978-1-4799-3012-8; POD:978-1-4799-3013-5","10.1109/SKG.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816610","cognitive;human reading process;summarization","Artificial intelligence;Computational linguistics;Computational modeling;Equations;Mathematical model;Natural language processing;Semantics","information retrieval;natural language processing;text analysis","automatic text summarization;cognitive-based multidocument summarization approach;human reading process;information retrieval;multidocument scanning mechanism;natural language processing","","0","","30","","","3-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"A crowdsourced SkyMap","B. Ko≈üucu; B. Arnrich; C. Ersoy","","2014 22nd Signal Processing and Communications Applications Conference (SIU)","20140612","2014","","","1283","1286","Weather reports are an integral part of almost any modern newscast service. Concise weather reports, which are often found in mobile applications, consist of logos for indicating sunshine, cloudiness, fog or rain. The weather information is usually obtained from professional weather stations. SkyMap aims to create mobile weather reports based on crowd sourcing of images that contain regions of the sky. The main motivation behind is that observing the sky gives us an intuitive understanding about the weather situation. SkyMap intends to enable sky observations from everywhere. The main working principle is to gather geo-tagged photos taken from mobile/smartphones with the help of crowdsourcing and to present the relevant sky regions on a map. We have developed mobile phone clients for Android and iOS and a server infrastructure that manages the crowd sourcing. We present the overall system design and we show the results of several feasibility studies.","2165-0608;21650608","Electronic:978-1-4799-4874-1; POD:978-1-4799-4873-4","10.1109/SIU.2014.6830471","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830471","crowdsourcing;mobile sensing;weather status reporting","Conferences;Google;Meteorology;Mobile communication;Sensors;Signal processing;Smart phones","Android (operating system);geophysics computing;iOS (operating system);information retrieval;mobile computing;weather forecasting","Android;SkyMap;cloudiness;crowdsourced skymap;crowdsourcing;fog;iOS;logos;mobile applications;mobile weather reports;rain;server infrastructure;sky observations;sunshine;weather information;weather situation","","0","","12","","","23-25 April 2014","","IEEE","IEEE Conference Publications"
"Ontology Population from the Web: An Inductive Logic Programming-Based Approach","R. Lima; B. Espinasse; H. Oliveira; F. Freitas","Inf. Center, Fed. Univ. of Pernambuco, Recife, Brazil","2014 11th International Conference on Information Technology: New Generations","20140602","2014","","","473","478","The rapid growth of the Web and the information overload problem demand the development of practical information extraction (IE) solutions for web content processing. Ontology Population (OP) concerns both the extraction and classification of instances of the concepts and relations defined by an ontology. Developing IE rules for OP is an intensive and time-consuming process. Thus, an automated mechanism, based on machine-learning techniques, able to convert textual data from web pages into ontology instances may be a crucial path. This paper presents an inductive logic programming-based method that automatic induces symbolic extraction rules, which are used for populating a domain ontology with instances of entity classes. This method uses domain-independent linguistic patterns for retrieving candidate instances from web pages, and a WordNet semantic similarity measure as background knowledge to be used as input by a generic inductive logic programming system. Experiments were conducted concerning both the instance classification problem and a comparison with other popular machine learning algorithms, with encouraging results.","","Electronic:978-1-4799-3188-0; POD:978-1-4799-3189-7","10.1109/ITNG.2014.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822242","Inductive Logic Programming;Information Extraction;Ontology Population;Pattern Learning","Feature extraction;Logic programming;Ontologies;Semantics;Sociology;Statistics","Internet;information retrieval;learning (artificial intelligence);logic programming;ontologies (artificial intelligence);pattern classification","IE solutions;OP;Web content processing;Web pages;WordNet semantic similarity measure;background knowledge;candidate instances retrieval;domain-independent linguistic patterns;entity classes;generic inductive logic programming system;information extraction;information overload problem;instance classification problem;machine-learning techniques;ontology population;symbolic extraction rules;textual data","","0","","24","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Exploring the Role of Haptic Feedback in Enabling Implicit HCI-Based Bookmarking","M. K. X. J. Pan; J. McGrenere; E. A. Croft; K. E. MacLean","Department of Mechanical Engineering, University of British Columbia, 6250 Applied Science Lane, Vancouver, Canada","IEEE Transactions on Haptics","20140516","2014","7","1","24","36","We examine how haptic feedback could enable an implicit human-computer interaction, in the context of an audio stream listening use case where a device monitors a user's electrodermal activity for orienting responses to external interruptions. When such a response is detected, our previously developed system automatically places a bookmark in the audio stream for later resumption of listening. Here, we investigate two uses of haptic feedback to support this implicit interaction and mitigate effects of noisy (false-positive) bookmarking: (a) low-attention notification when a bookmark is placed, and (b) focused-attention display of bookmarks during resumptive navigation. Results show that haptic notification of bookmark placement, when paired with visual display of bookmark location, significant improves navigation time. Solely visual or haptic display of bookmarks elicited equivalent navigation time; however, only the inclusion of haptic display significantly increased accuracy. Participants preferred haptic notification over no notification at interruption time, and combined haptic and visual display of bookmarks to support navigation to their interrupted location at resumption time. Our contributions include an approach to handling noisy data in implicit HCI, an implementation of haptic notifications that signal implicit system behavior, and discussion of user mental models that may be active in this context.","1939-1412;19391412","","10.1109/TOH.2014.2309124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6750756","Haptic I/O;browsing;human-centered computing;low-attention interfaces;multimodal user interfaces;notifications;user/machine systems","Context;Haptic interfaces;Human computer interaction;Navigation;Noise measurement;Physiology;Visualization","audio streaming;haptic interfaces;human computer interaction;information retrieval","audio stream listening use case;bookmark location;bookmark placement;electrodermal activity monitoring;focused-attention display;haptic display;haptic feedback;haptic notification;implicit HCI-based bookmarking;implicit human-computer interaction;implicit interaction;low-attention notification;noisy bookmarking;resumptive navigation;user mental models;visual display","0","0","","59","","20140228","Jan.-March 2014","","IEEE","IEEE Journals & Magazines"
"An Incremental Weibo-Oriented Method for Unknown Word and Topic Extraction","Q. Liu; L. Wang","Sch. of Inf. & Commun. Eng., Beijing Univ. of Posts & Telecommun., Beijing, China","2013 Ninth International Conference on Semantics, Knowledge and Grids","20140519","2013","","","206","209","Due to the great flexibility in wording and highly correlation between unknown words and unpredictable topics, which are exhibited in Chinese twitter (i.e. weibo) messages, it proposed a weibo-oriented method to detect unknown words and topics simultaneously. The method is efficient and precise, however, because of the adopted classical K-means algorithm, it cannot deal with weibo corpus with increasing size. In this paper, a modified version is presented to eliminate the limitation by incorporating incremental clustering mechanism. Based on the weibo characteristics, a new similarity measure is introduced, which takes into considerations the relevance of the recently identified unknown words. With this measure, the categories evolution is reasonably carried out in the process of incremental clustering to ensure the balance between the consistency and timeliness of the method. Experiments show that unknown words and topics can be effectively detected and tracked.","","Electronic:978-1-4799-3012-8; POD:978-1-4799-3013-5","10.1109/SKG.2013.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816608","Categories merge;Cosine similarity;Incremental k-means;Unknown words extraction","Clustering algorithms;Correlation;Data mining;Dictionaries;Educational institutions;Semantics;Telecommunications","information retrieval;learning (artificial intelligence);pattern clustering;social networking (online)","Chinese twitter message;K-means algorithm;incremental Weibo-oriented method;incremental clustering mechanism;similarity measure;topic extraction;unknown word extraction","","0","","6","","","3-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"An evolutionary approach to automatic Chinese text segmentation","D. Zhang","Fac. of Arts, Comput., Eng. & Sci., Sheffield Hallam Univ., Sheffield, UK","2013 Ninth International Conference on Natural Computation (ICNC)","20140519","2013","","","771","776","Textual information written in Chinese now represents a huge knowledge repository. The first step of managing and processing information in written Chinese text is segmentation. A new method for automatic Chinese text segmentation using evolutionary algorithms and Web search statistical data is outlined. This proposed method considers Web text a de facto corpus that updates automatically, thus eliminating the need for statistics training. It treats the segmentation as a process that finds out the best probability of how individual characters are combined into sentences, paragraphs, and articles, thus producing segmentation results that are tailored to the text in question and are independent of segmentation standards.","2157-9555;21579555","Electronic:978-1-4673-4714-3; POD:978-1-4673-4712-9","10.1109/ICNC.2013.6818079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818079","Chinese information processing;Chinese text segmentation;genetic algorithm;n-best segmentations;statistical segmentation","Biological cells;Genetic algorithms;Pragmatics;Probability;Standards;Training data;Web search","Internet;evolutionary computation;information retrieval;natural language processing;probability;text analysis","Web search statistical data;articles;automatic Chinese text segmentation;de facto corpus;evolutionary algorithms;evolutionary approach;knowledge repository;paragraphs;probability;segmentation standards;sentences;textual information","","0","","17","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"Feature Selection Algorithm for Improving the Performance of Classification: A Survey","K. Naidu; A. Dhenge; K. Wankhade","Dept. of IT, G.H. Raisoni Coll. of Eng., Nagpur, India","2014 Fourth International Conference on Communication Systems and Network Technologies","20140529","2014","","","468","471","With the rapid development of the Computer Science and Technology, It has become a major problem for the users that how to quickly find useful or needed information. Data mining can be seen as an area of artificial intelligence that seeks to extract information or patterns from large amounts of data stored in databases. Recent researches on feature selection have been conducted in an attempt to find efficient methods for selection of relevant features. Feature selection generally involves a combination of search and attributes utility estimation plus evaluation with respect to specific learning schemes. There are several methods to select features in ensembles systems and genetic algorithms (GA) are one of the most used methods. This paper gives overview of feature selection Algorithm which searches the feature space using the idea of evolutionary computation, in order to find the optimal feature subset.","","Electronic:978-1-4799-3070-8; POD:978-1-4799-3071-5","10.1109/CSNT.2014.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821440","Data mining;feature selection;genetic algorithm","Algorithm design and analysis;Classification algorithms;Conferences;Data mining;Filtering algorithms;Genetic algorithms;Genetics","data mining;feature selection;genetic algorithms;information retrieval;learning (artificial intelligence);pattern classification","artificial intelligence;attribute utility estimation;classification performance;data mining;databases;ensemble systems;evolutionary computation;feature selection algorithm;feature space;genetic algorithms;information extraction;learning schemes;optimal feature subset;pattern extraction","","2","","23","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Intelligent searching using delay semantic network","S. Dvor≈°ƒç√°k; K. Machov√°","Dept. of Cybern. & Artificial Intell., FEI TU of Kosice, Kosice, Slovakia","2014 IEEE 12th International Symposium on Applied Machine Intelligence and Informatics (SAMI)","20140529","2014","","","291","294","Article introduces different way how to implement semantic search, using semantic search agent over information obtained directly from web. The paper describes time delay form of semantic network, which we have used for providing of semantic search. Using of time-delay aspect inside semantic network has positive impact in several ways. It provides way how to represent knowledges dependent on time via semantic network, but also how to optimize a process of inference. That is all realized for Wikipedia articles in the form of search engine. The core's implementation is realized in way of massive multithread inference mechanism for massive semantic network.","","Electronic:978-1-4799-3442-3; POD:978-1-4799-3443-0; USB:978-1-4799-3440-9","10.1109/SAMI.2014.6822424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822424","","Electronic publishing;Encyclopedias;Engines;Internet;Knowledge engineering;Semantics","Web sites;delays;inference mechanisms;information retrieval;search engines;semantic Web;semantic networks","Web information;Wikipedia articles;delay semantic network;inference optimization;intelligent searching;knowledge representation;massive multithread inference mechanism;massive semantic network;search engine;semantic search agent;time delay","","0","","6","","","23-25 Jan. 2014","","IEEE","IEEE Conference Publications"
"Exhaustive Exploration of Ajax Web Applications with Selective Jumping","S. Hall√©; G. L. Breton; F. Maronnaud; A. B. Mass√©; S. Gaboury","Dept. d'Inf. et de Math., Univ. du Quebec a Chicoutimi, Chicoutimi, QC, Canada","2014 IEEE Seventh International Conference on Software Testing, Verification and Validation Workshops","20140605","2014","","","243","252","Exploring modern web applications is a difficult task with the presence of client-side JavaScript code, as a crawler cannot jump or backtrack arbitrarily inside applications that maintain a state. In this paper, we present Web Mole, an automated crawler that implements a formal framework for web exploration that generalizes existing approaches. Web Mole uses an algorithm that explores an application without the need for arbitrary backtracking, it intercepts HTTP requests called from client-side code, and uses that information to perform selectively jump to pages while preserving the client-server state relationship. Comparisons with existing crawlers on various classes of graphs show that this strategy incurs a lower exploration cost.","","Electronic:978-1-4799-5790-3; POD:978-1-4799-5791-0","10.1109/ICSTW.2014.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6825669","web crawler","Browsers;Color;Crawlers;HTML;History;Navigation;Servers","Internet;Java;client-server systems;hypermedia;information retrieval;search engines","Ajax Web applications;HTTP request interception;Web Mole;automated crawler;client-server state;client-side JavaScript code;formal framework;selective jumping","","2","","27","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Rule Based Faceted Navigation on Semantic Link Network","B. Xu; H. Zhuge","Nanjing Univ. of Posts & Telecommun., Nanjing, China","2013 Ninth International Conference on Semantics, Knowledge and Grids","20140519","2013","","","202","205","Semantic link network is a model which can represent resources in cyber space, physical space and social space. It pursues semantic richness rather than correctness. So the scale of SLN becomes larger and larger which renders hard browsing. Faceted navigation is a feasible and efficient way to browse a large scale SLN if it can comprehensively consider properties of resources and semantic links between them. This paper proposes a mechanism that provides rule based faceted navigation for users to freely browse resources in different facets from an SLN. Besides properties of resources, the model deals with semantic links as well. A user can set personalized rules to generate their desired facets. Several interfaces are designed for users to operate the process of faceted navigation.","","Electronic:978-1-4799-3012-8; POD:978-1-4799-3013-5","10.1109/SKG.2013.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816607","Faceted navigation;Rule based;Semantic link network","Algorithm design and analysis;Birds;Insects;Mice;Navigation;Rabbits;Semantics","information networks;information retrieval;knowledge based systems","SLN;cyber space;personalized rules;physical space;rule based faceted navigation;semantic link network;social space","","0","","8","","","3-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"Text lines and PAWs segmentation of handwritten Arabic document by two hybrid methods","S. S. Maddouri; F. Ghazouani; F. B. Samoud","Hnayka Community Fac., Taiba Univ., Saudi Arabia","2014 1st International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)","20140616","2014","","","310","315","We present in this paper two hybrid segmentation methods of handwritten Arabic script. Both methods allow the segmentation of Arabic document in text lines and the segmentation of the text line into Pieces of Arabic Words (PAWs) respectively. The particularity of these two methods is that both use a combination with Mathematical Morphology (MM). The first method uses the (MM) in the first hand and the algorithm of construction of the Outer Isothetic Cover of a digital object (OIC) named MM-OIC in the second hand. The second method combines Hough Transform (HT) and MM called HT-MM. The two proposed methods are evaluated to the three databases : IFN/ENIT-database, BSB and KSU online databases. The impact of the MM on the two proposed methods is then discussed.","","Electronic:978-1-4799-4888-8; POD:978-1-4799-4887-1","10.1109/ATSIP.2014.6834627","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834627","","Databases;Educational institutions;Extremities;Image color analysis;Image segmentation;Labeling;Libraries","Hough transforms;document image processing;handwritten character recognition;image segmentation;information retrieval systems;mathematical morphology;text analysis;visual databases;word processing","BSB online databases;HT-MM;Hough transform;IFN-ENIT-database;KSU online databases;MM-OIC;PAW segmentation;digital object outer isothetic cover;handwritten Arabic document segmentation;handwritten Arabic script;hybrid segmentation methods;mathematical morphology;pieces of Arabic words;text line segmentation","","1","","15","","","17-19 March 2014","","IEEE","IEEE Conference Publications"
"Automatic Personalized Marathi Content Generation","S. R. Vispute; S. Kanthekar; A. Kadam; C. Kunte; P. Kadam","Dept. of Comput. Eng., PCCOE, Pune, India","2014 International Conference on Circuits, Systems, Communication and Information Technology Applications (CSCITA)","20140619","2014","","","294","299","The purpose of the present work is to create a system to retrieve personalized documents in Marathi Language. The system mainly focuses on providing personalized documents to the end user by analyzing the browsing history and user profile of the user in Marathi language. The system also provides manual bookmark facility to the end user as per the user interest. This paper provides personalization of Marathi text documents by using Label Induction Grouping [LINGO] Algorithm based on Vector Space Model [VSM]. This paper presents the automatic personalization of Marathi documents and literature survey of the related work done in automatic categorization of Marathi text documents. Several learning techniques exist for the classification of text documents like Decision Trees, Support Vector Machine, NaiÃàve Bayes, etc. Several clustering techniques are available for text categorization namely K-means, Suffix Tree Clustering, Label Induction Grouping Algorithm, etc. With the help of literature survey, it is found that Vector Space Model [VSM] gives better accuracy than other models.","","Electronic:978-1-4799-2494-3; POD:978-1-4799-2495-0","10.1109/CSCITA.2014.6839275","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839275","Automatic Personalization;Bookmark Facility;Browsing History;Categorization;Clustering","Classification algorithms;Clustering algorithms;History;Information technology;Matrix decomposition;Search engines;Text categorization","information retrieval;learning (artificial intelligence);natural language processing;pattern classification;pattern clustering;text analysis","LINGO algorithm;Marathi language;Marathi text document personalization;NaiÃàve Bayes classification;VSM;automatic categorization;automatic personalized Marathi content generation;bookmark facility;browsing history analysis;clustering techniques;decision trees;k-means clustering;label induction grouping algorithm;learning techniques;personalized document retrieval;suffix tree clustering;support vector machine;text categorization;text document classification;user profile;vector space model","","2","","14","","","4-5 April 2014","","IEEE","IEEE Conference Publications"
"Hot topic detection based on complex networks","Jingwei Deng; Kaiying Deng; Yongsheng Li; Yingxing Li","Sch. of Math. & Comput. Sci., Northwest Univ. for Nat., Lanzhou, China","2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20140519","2013","","","1055","1059","The hot topic has become a key part of social information. Recognizing and detecting hot topics can help people to be aware of the focus of the community in the period and discover public opinions. The improved model can dynamically adjust the cluster to more accurately match document. Moreover, it lays the foundation for further study on the evolution of the hot topics in complex networks. For verifying the feasibility and validity of the model, the experiments are performed and the experimental results show that the proposed method works well on large-scale WebPage dataset.","","Electronic:978-1-4673-5253-6; POD:978-1-4673-5251-2","10.1109/FSKD.2013.6816352","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816352","clustering;complex network;hot topic detection;random walk model","Complex networks;Computational modeling;Educational institutions;Hidden Markov models;Market research;Text mining;Vectors","information retrieval;text analysis","complex networks;hot topic detection;hot topic recognition;large-scale WebPage dataset;social information","","0","","29","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"RankAOH: Context-driven similarity-based retrieval of experiences in cyber analysis","C. Zhong; D. Samuel; J. Yen; P. Liu; R. Erbacher; S. Hutchinson; R. Etoty; H. Cam; W. Glodek","Pennsylvania State Univ., State College, PA, USA","2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)","20140519","2014","","","230","236","In cyber analysis, it is highly desirable to support the analysis of junior analysts by leveraging the experiences of experts. But, there are two major challenges to achieve this goal. First, it is very costly to capture the experience of experts for the complex task of cyber analysis using traditional approaches such as protocol analysis. Second, it is difficult to identify previous experiences of experts that are relevant to the dynamic context of an analyst's cyber analysis task. To address the first challenge, a system has been developed to capture non-intrusively the analytical reasoning processes of analysts. To tackle the second challenge, this paper presents an effective and efficient approach for retrieving relevant experiences based on the dynamically changing context of cyber analysis. We define an experience as a process of analytical reasoning and adopt an Action-Observation-Hypothesis (A-O-H) model to represent the processes in cyber analysis. Based on this model, a tool for capturing and supporting the analytical reasoning processes is shown to be able to support the elusive cognitive process in dynamic cyber situations. The experience retrieval approach of this paper supports the efficient experience retrieval, and dynamically updates the results as the context of analysis evolves. The experience retrieval approach is evaluated, based on the precision and recall with respect to the ground truth. The evaluation results suggest that the proposed approach supports significantly the analytical reasoning of analysts by leveraging the experiences of experts.","2379-1667;23791667","CD-ROM:978-1-4799-3563-5; Electronic:978-1-4799-3564-2; POD:978-1-4799-3565-9","10.1109/CogSIMA.2014.6816567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816567","Context-based retrieval;Decision support;Intrusion detection;Knowledge management","Analytical models;Cognition;Context;IP networks;Indexing;Servers","information retrieval;security of data","RankAOH;action-observation-hypothesis model;analyst analytical reasoning process;cyber analysis;dynamic cyber situations;elusive cognitive process;experience context-driven similarity-based retrieval;protocol analysis","","2","","6","","","3-6 March 2014","","IEEE","IEEE Conference Publications"
"A Method on Extracting Registry Information from Windows CE Memory Images","S. Yang; L. Wang; S. Zhang; J. Liu","Shandong Comput. Sci. Center, Shandong Provincial Key Lab. of Comput. Network, Jinan, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","728","732","The Windows CE registry plays a very important role from physical memory and contains lots of important information that are of potential evidential value in forensic analysis. Memory acquisition and analysis is the most important in Windows CE devices forensic. The paper introduces physical memory acquisition and analysis methods in Windows environment and the procedure of memory analysis on the different kernels of windows CE device. The algorithm for extracting the registry information from the physics memory is presented and mainly composed of the following steps: judging the version of operating system, locating the ROMHDR structure, File structure and Module structure, lpszFileName traversal until to find the file name whose Suffix is. Rgu and. hv, locating the ulLoadOffset and nFileSize to find the entry address and the size of registry file. The method is proved to be effective and reliable in extracting registry file from physical memory on Windows mobile6.5 operating system.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.175","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835701","forensic analysis;physical memory;registry information extraction;windows CE forensics;windows CE kernel;windows CE registry;windows mobile device forensics","Computers;Data mining;Forensics;Kernel;Mobile communication;Mobile handsets","database management systems;digital forensics;information retrieval;operating system kernels","ROMHDR structure location;Windows CE device;Windows CE memory images;Windows CE registry;Windows mobile 6.5 operating system;file structure location;forensic analysis;kernels;lpszFileName traversal;module structure location;nFileSize location;operating system version;physical memory acquisition;physical memory analysis;registry information extraction;ulLoadOffset location","","0","","10","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Structural fusion of heterogeneous visual-auditory features for multimedia analysis","Hong Zhang; Jiamei Nie; Li Chen","Coll. of Comput. Sci. & Technol., Wuhan Univ. of Sci. & Technol., Wuhan, China","2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20140519","2013","","","821","825","It is interesting and challenging to learn underlying semantics from multimodal data of different modalities, which carry their own contribution to high-level semantics. However, multimodal data are usually represented with heterogeneous features. It is difficult to learn a semantic subspace where multimodal correlation is learned and preserved. In this paper, we analyze sparse canonical correlation for multimodal data in heterogeneous feature dimension reduction; moreover, we propose subspace optimization strategy with structural multi-feature fusion, which fuse structural content correlation learning result and graph-based semantic correlation learning result into an objective function. Our algorithm has been applied to content based multimedia applications, including image classification and multimedia retrieval. Comprehensive experiments have demonstrated the superiority of our method over several existing algorithms.","","Electronic:978-1-4673-5253-6; POD:978-1-4673-5251-2","10.1109/FSKD.2013.6816307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816307","multimodal semantics;structural correlation analysis;weighted graph","Correlation;Image classification;Image retrieval;Linear programming;Multimedia communication;Semantics;Vectors","image classification;information retrieval;learning (artificial intelligence);multimedia systems;optimisation;sensor fusion","graph-based semantic correlation learning;heterogeneous visual-auditory features;high-level semantics;image classification;multimedia analysis;multimedia retrieval;multimodal data;structural content correlation learning;structural multifeature fusion;subspace optimization","","0","","18","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"Reconfigurable hardware architecture for music generation using cellular automata","H. Din√° Bezerra; N. Nedjah; L. de Macedo Mourelle","Dept. of Electron. Eng. & Telecommun., State Univ. of Rio de Janeiro, Rio de Janeiro, Brazil","2014 IEEE 5th Latin American Symposium on Circuits and Systems","20140526","2014","","","1","4","This paper proposes a hardware architecture to generate harmonized music, which is composed by melodic intervals determined from the association of cellular automata in accordance to standard MIDI protocol. The implementation of the architecture is implemented in FPGA aiming at designing an alternative efficient tool for the study and research related to the field of random music. To this end, the architecture includes four kind of cellular automata, developed through four neighborhood models with a radius of 1. The proposed architecture allows 16 possible combinations of cellular automata models. to maximize the applicability potential of the architecture, the configuration data that influence the generated music product is performed almost in entirety by the user, with no virtual limit of the number of possible melodic combinations generated by the hardware. In order to validate the effectiveness as well as efficiency of the architecture, we present some results about the generated melodies. The results were extracted by means of known musical information retrieval techniques.","","CD-ROM:978-1-4799-2506-3; Electronic:978-1-4799-2507-0; POD:978-1-4799-2508-7","10.1109/LASCAS.2014.6820309","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820309","","Automata;Computer architecture;Hardware;Instruments;Microprocessors;Protocols;Standards","cellular automata;electronic music;information retrieval;music;reconfigurable architectures","FPGA;cellular automata models;harmonized music;music generation;musical information retrieval techniques;reconfigurable hardware architecture;standard MIDI protocol","","0","","8","","","25-28 Feb. 2014","","IEEE","IEEE Conference Publications"
"An Effective Forum Crawler","Sreeja S R; S. Chaudhari","Dept. of Comput. Sci. & Eng., A.C. Patil Coll. of Eng., Navi Mumbai, India","2014 International Conference on Circuits, Systems, Communication and Information Technology Applications (CSCITA)","20140619","2014","","","230","234","Web Forums or Internet Forums provide a space for users to share, discuss and request information. Web Forums are sources of huge amount of structured information that is rapidly changing. So crawling Web Forums require special softwares. A Generic Deep Web Crawler or a Focused Crawler cannot be used for this purpose. In this paper, we propose an effective Web Crawler especially for Internet Forums. This Forum Crawler overcomes the drawbacks of many of the existing Forum Crawlers. It has the ability to detect the Entry URL of a Forum site, given any page of it. Crawling process starting from Entry URL increases the coverage. Different URLs in the Web Forums are classified into four categories and our Forum Crawler is capable of detecting these URLs even if they are JavaScript-based which most of the existing Forum Crawlers cannot do. The entire process is divided into learning part and online crawling part. The learning part classifies different URLs in the forum site into four categories: Index URL, Thread URL, Index-Page-Turning URL and Thread-Page-Turning URL. This Forum Crawler uses a Freshness First Strategy rather than the BFS (Breadth First Strategy) for performing online crawling which is advantageous in situations where there are limited system resources available.","","Electronic:978-1-4799-2494-3; POD:978-1-4799-2495-0","10.1109/CSCITA.2014.6839264","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839264","JavaScript-based URLs;URL type;crawling strategy;forum crawling;page classification","Crawlers;Indexes;Information technology;Internet;Kernel;Web pages","Internet;Web sites;information retrieval;tree searching","BFS;Entry URL;Internet forum crawler;JavaScript-based URLs;Web Forum crawling;Web forum crawler;breadth first strategy;focused crawler;forum site;freshness first strategy;generic deep Web crawler;index URL;index-page-turning URL;information requesting;information sharing;online crawling;thread URL;thread-page-turning URL","","0","","14","","","4-5 April 2014","","IEEE","IEEE Conference Publications"
"An On-demand Multi-Path Interest Forwarding strategy for content retrievals in CCN","A. Udugama; X. Zhang; K. Kuladinithi; C. Goerg","Univ. of Bremen, Bremen, Germany","2014 IEEE Network Operations and Management Symposium (NOMS)","20140619","2014","","","1","6","Content Centric Networking (CCN) is a new paradigm in networking and a future Internet architecture. Performance evaluations show that conventional CCN forwarding strategies which use replication of Interests (standard) or the shortest path (best-face) do not perform well under high bandwidth requirements and loaded networks. We have designed and evaluated the performance of an On-demand Multi-Path Interest Forwarding (OMP-IF) strategy which identifies a set of paths based on the disjointness of paths to content locations. Then, the discovered paths are used simultaneously to distribute (split) Interests based on the characteristics of the paths. We have evaluated OMP-IF strategy using a simulator with a large scale network scenario and a realistic traffic generation model. The results show improved performance in CCN networks considering download time, load balancing, content hit ratios, and others.","1542-1201;15421201","Electronic:978-1-4799-0913-1; POD:978-1-4799-0911-7; USB:978-1-4799-0912-4","10.1109/NOMS.2014.6838389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838389","","Delays;IP networks;Load management;Load modeling;Probes;Standards;Topology","Internet;information retrieval","CCN forwarding strategies;Internet architecture;OMP-IF strategy;bandwidth requirements;content centric networking;content hit ratio;content retrievals;download time;load balancing;network scenario;networking paradigm;on-demand multipath interest forwarding strategy;traffic generation model","","4","","21","","","5-9 May 2014","","IEEE","IEEE Conference Publications"
"A lexiconizing framework of feature-based opinion mining in tourism industry","A. Muangon; S. Thammaboosadee; C. Haruechaiyasak","Technol. of Inf. Syst. Manage. Div., Mahidol Univ., Nakhonpathom, Thailand","2014 Fourth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","20140529","2014","","","169","173","Among of the travel agency business in Thailand, Agoda (www.agoda.com) has boomed in recent years with the number of online agents offering for hotels booking. When customers need to make decision, they typically explore by investigating the opinions attached with each hotel in online agent. This paper proposes a framework of feature-based opinion mining by using scores which essentially relies on the usage of two main lexiconizing levels, features and polar words. An approach for extracting features and polar words from textual opinion is based on syntactic pattern analysis. The evaluation is performed with existing opinions and compared the statistical resulted scores with the existing scores of each hotel. The proposed scoring method is proven for the effectiveness of the score from Agoda and could facilitate the further text retrieval application development for the benefit of automatic customer's opinion detection.","","CD-ROM:978-1-4799-3723-3; Electronic:978-1-4799-3724-0; POD:978-1-4799-3725-7","10.1109/DICTAP.2014.6821677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821677","Hotel Agency;Lexiconizing;Opinion Mining;Text Mining;Travel Agency","Cities and towns;Data mining;Dictionaries;Feature extraction;Industries;Standards;Statistical analysis","data mining;feature extraction;hotel industry;information retrieval;text analysis;travel industry","Agoda;Thailand;automatic customer opinion detection;feature extraction;feature-based opinion mining;hotels booking;lexiconizing framework;online agents;polar words;scoring method;syntactic pattern analysis;text retrieval application development;textual opinion;tourism industry;travel agency business","","0","","13","","","6-8 May 2014","","IEEE","IEEE Conference Publications"
"Toponym recognition on Turkish tweets","K. Dilek Onal; P. Karag√∂z; R. √áakƒ±cƒ±","Bilgisayar Muhendisligi Bolumu, Orta Dogu Teknik Univ., Ankara, Turkey","2014 22nd Signal Processing and Communications Applications Conference (SIU)","20140612","2014","","","1758","1761","In recent years, Twitter has become a popular platform for following and spreading trends, news and ideas all over the world. Geographical scope of tweets is crucial to many tasks like disaster management, event tracking and information retrieval. First step for assigning a geographical location to a tweet is toponym recognition. Toponym Recognition (Geoparsing) is identification of toponyms (place names) in a text. In this study, we investigated performance of three existing approaches for toponym recognition on Turkish tweets. We conducted experiments for measuring performance of the existing approaches on a sample data set. Best results have been obtained with the NER algorithm by KuÃà√ßuÃàk et.al. However, we observed that existing NER algorithms for Turkish neglect the syntactic and semantic features of text.","2165-0608;21650608","Electronic:978-1-4799-4874-1; POD:978-1-4799-4873-4","10.1109/SIU.2014.6830590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830590","Twitter;geoparsing;toponym recognition","Computational linguistics;Conferences;Reactive power;Signal processing;Text recognition;Twitter;Web sites","grammars;information retrieval;natural language processing;social networking (online)","disaster management;event tracking;geographical scope;geoparsing;information retrieval;toponym recognition","","0","","10","","","23-25 April 2014","","IEEE","IEEE Conference Publications"
"Design and Implementation of On-Line Answering System for Visually Impaired College Students","D. Xu; C. Yu","Sch. of Electron. & Inf. Eng., Changchun Univ., Changchun, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","142","145","Due to the visually impaired student's own physical characteristics, within a specified time to reach the designated location with the teacher to discuss issues, there are some difficulties to eliminate doubts. Developing a network for the visually impaired students answering exchange platform for the visually impaired students of particular significance. In this paper, ASP.NET technology to achieve a visually impaired students online answering system, and elaborates on the main system design process. The system of special education in the field of information accessibility has certain application value.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835565","FAQ;Information Accessibility;Visually Impaired","Computers","computer aided instruction;further education;handicapped aids;human computer interaction;question answering (information retrieval)","ASP.NET technology;answering exchange platform;information accessibility;on-line answering system;special education;system design process;visually impaired college students","","0","","6","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Efficient methodologies to optimize Website for link structure based search engines","P. R. Kumar; A. K. Singh; A. Mohan","Department of Electrical and Computer Engineering, Curtin University, Miri, Sarawak, Malaysia","2013 International Conference on Green Computing, Communication and Conservation of Energy (ICGCE)","20140602","2013","","","719","724","As more and more e-commerce companies are mushrooming on the Internet, the competition becomes very high for those sites to be appeared on the top of Search Engine Results Pages (SERPs). With the massive growth of Internet, the dependability of Search Engines for Information Retrieval (IR) becomes a mandatory. This paper provides an introduction to link structure base search engine ranking algorithms and efficient methodologies to optimize Websites for link structure based ranking algorithms.","","DVD:978-1-4673-6125-5; Electronic:978-1-4673-6126-2; POD:978-1-4673-6124-8","10.1109/ICGCE.2013.6823528","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823528","Black hat;Link Structure;Off-Site ranking factors and e-Commerce;On-Site ranking factors;Organic Search;PageRank;Search Engine Optimization;Website Optimization;White hat","Algorithm design and analysis;Companies;Google;HTML;Internet;Optimization;Search engines","Internet;Web sites;information retrieval;optimisation;search engines","IR;Internet;SERP;Web site optimisation;e-commerce companies;information retrieval;link structure;search engine results pages","","1","","26","","","12-14 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Performance Analysis of MapReduce Task with Large Number of Files Dataset in Big Data Using Hadoop","A. Pal; K. Jain; P. Agrawal; S. Agrawal","Dept. of Comput. Eng. & Applic., Nat. Inst. of Tech. Teachers' Training & Res., Bhopal, India","2014 Fourth International Conference on Communication Systems and Network Technologies","20140529","2014","","","587","591","Big Data is a huge amount of data that cannot be managed by the traditional data management system. Hadoop is a technological answer to Big Data. Hadoop Distributed File System (HDFS) and MapReduce programming model is used for storage and retrieval of the big data. The Tera Bytes size file can be easily stored on the HDFS and can be analyzed with MapReduce. This paper provides introduction to Hadoop HDFS and MapReduce for storing large number of files and retrieve information from these files. In this paper we present our experimental work done on Hadoop by applying a number of files as input to the system and then analyzing the performance of the Hadoop system. We have studied the amount of bytes written and read by the system and by the MapReduce. We have analyzed the behavior of the map method and the reduce method with increasing number of files and the amount of bytes written and read by these tasks.","","Electronic:978-1-4799-3070-8; POD:978-1-4799-3071-5","10.1109/CSNT.2014.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821465","Data Node;HDFS;Hadoop;Job Tracker;MapReduce;Name Node;Secondary Name Node;Task Tracker;Teragen;Terasort;Teravalidate","Computers;Distributed databases;File systems;Google;Programming;Training","Big Data;distributed databases;information retrieval;storage management","Hadoop HDFS;Hadoop distributed file system;MapReduce programming model;big data retrieval;big data storage;data management system;files dataset;information retrieval;performance analysis","","0","","9","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Integer linear programming for transforming pairwise based results to the original ratings","Ping Ji; Jian Jin","Dept. of Ind. & Syst. Eng., Hong Kong Polytech. Univ., Hong Kong, China","11th International Symposium on Operations Research and its Applications in Engineering, Technology and Management 2013 (ISORA 2013)","20140529","2013","","","1","6","Many pairwise models are proposed for ranking problems in the field of information retrieval. Classification problems in the field of data mining also use pairwise comparison. However, conventionally, these pairwise approaches are evaluated based evaluation metrics. The original rating for a single document or instance is not explained faithfully, which makes these algorithms cannot be evaluated by standard evaluation metrics, such as Mean Average Precision and Normalized Discounted Cumulative Gain for ranking models. In this research, the focus is on how to transform pairwise based results to the original ratings. Particularly, an integer linear programming model is formulated for this problem. In this algorithm, the objective is to minimize the number of conflicts for the predicted pairwise based relationship between instances by the assignment of rating values. An example is presented in order to clarify the proposed integer linear programming method. It validates the possibility to transform pairwise based results to the original ratings, which make them to be evaluated by standard evaluation metrics.","","Electronic:978-1-84919-713-7","10.1049/cp.2013.2257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822768","integer linear programming;optimization;pairwise","","data mining;information retrieval;integer programming;linear programming;pattern classification","classification problems;data mining;document rating;information retrieval;instance rating;integer linear programming model;original rating;pairwise comparison;pairwise-based relationship prediction;pairwise-based result transformation;ranking problems","","0","","","","","23-25 Aug. 2013","","IET","IET Conference Publications"
"Cognitive Knowledge Representation for Examination Questions Specification Analysis","F. Yaakob; N. H. I. Teo; N. A. S. Abdullah","Dept. of Comput. Sci., Univ. Teknol. MARA, Shah Alam, Malaysia","2013 International Conference on Advanced Computer Science Applications and Technologies","20140619","2013","","","530","533","The quality of education is relatively important to improve the quality of teaching. The quality of teaching is reflected on the quality of examination paper. A quality examination paper can be measured against the specification stated in Test Specification Table (JSU). In order to reduce the subjectivity and randomness of the evaluation on examination paper, this paper demonstrates a representation model, which assists the educators to analyze the percentage of accuracy between examination paper specification (EPS) and JSU. The parameters used are cognitive level and score. Keyword extraction and classification approach based on Information Retrieval has been implemented to yield the analysis. In addition, the analysis provides the error percentage between EPS and JSU. The specification analysis gives high impact to educational sectors by ensuring quality standard of assessment mechanism. It can be used by all tertiary level of education to evaluate the quality of examination question paper.","","Electronic:978-1-4799-2758-6; POD:978-1-4799-2759-3","10.1109/ACSAT.2013.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6836639","OBE;Test Specification Table;examination question;keyword extraction","Cognition;Data mining;Education;Error analysis;Linear programming;Prototypes;Taxonomy","cognition;computer aided instruction;information retrieval;knowledge representation;teaching;text analysis","EPS;JSU;assessment mechanism;cognitive knowledge representation;cognitive level;education quality;educational sectors;examination paper specification;examination question paper;examination questions specification analysis;information retrieval;keyword classification approach;keyword extraction;quality standard;teaching quality;test specification table","","0","","6","","","23-24 Dec. 2013","","IEEE","IEEE Conference Publications"
"Decoupling Identity Resolution from the Maintenance of Identity Information","F. Kobayashi; J. R. Talburt","Dept. of Inf. Sci., Univ. of Arkansas at Little Rock, Little Rock, AR, USA","2014 11th International Conference on Information Technology: New Generations","20140602","2014","","","349","354","The EIIM model for ER allows for creation and maintenance of persistent entity identity structures. It accomplishes this through a collection of batch configurations that allow updates and asserted fixes to be made to the Identity knowledgebase (IKB). The model also provides a batch IR configuration that provides no maintenance activity but instead allows access to the identity information. This batch IR configuration is limited in a few ways. It is driven by the same rules used for maintaining the IKB, has no inherent method to identity ""close"" matches, and can only identify and return the positive matches. Through the decoupling of this configuration and its movements into an interactive role under the umbrella of an Identity Management Service, a more robust access method can be provided for the use of identity information. This more robust access to the information improved the quality of the information along multiple Information Quality dimensions.","","Electronic:978-1-4799-3188-0; POD:978-1-4799-3189-7","10.1109/ITNG.2014.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822222","Entity Resolution;Identity Life Cycle Management;Identity Management Service;Information Quality;Interactive Identity Resolution","Context;Erbium;Maintenance engineering;Organizations;Robustness;Synchronization","information retrieval;knowledge based systems;quality management","EIIM model;ER;IKB;batch IR configuration;decoupling identity resolution;entity identity structures;identity information;identity knowledge base;identity management service;information quality;robust information access","","0","","15","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Type Based Keyword Search for Securing Big Data","Y. Yang; X. Zheng; B. Lin","Coll. of Math. & Comput. Sci., Fuzhou Univ., Fuzhou, China","2013 International Conference on Cloud Computing and Big Data","20140526","2013","","","354","359","Big data is an up-to-date attractive research topic and also full of challenges. Sharing massive sensitive personal data in public cloud will arouse large-scale privacy concerns. Data encryption is a widely accepted way to prevent information leakage. However, it is difficult for the users to retrieve desired information from encrypted big data. In this paper, we provide a novel keyword search method to enable customers easily searching keywords from encryption-protection data. Moreover, the encrypted big data could be managed by different type that was assigned by data owner. Moreover, the access right can be delegated to others according to the user's willingness. Security and efficiency analysis are provided to prove the security and efficiency of the scheme.","","Electronic:978-1-4799-2830-9; POD:978-1-4799-2831-6","10.1109/CLOUDCOM-ASIA.2013.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821015","big data;keyword search;proxy re-encryption;type based","Encryption;Keyword search;Public key;Servers","cloud computing;cryptography;information retrieval","big data security;data encryption;encryption-protection data;information leakage prevention;information retrieval;large-scale privacy concerns;massive sensitive personal data sharing;public cloud;type based keyword search","","0","","18","","","16-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"A mashup ecosystem for network management situations","O. M. C. Rendon; F. Estrada-Solano; L. Z. Granville","Comput. Networks Group, Univ. Fed. do Rio Grande do Sul, Porto Alegre, Brazil","2013 IEEE Global Communications Conference (GLOBECOM)","20140612","2013","","","2249","2255","Current network management approaches and their implementations are not intended to address dynamic situations that need rapid delivery of good-enough and comprehensive solutions. In this paper, we introduce a novel mashup ecosystem, called Mashment Ecosystem, that allows Network Administrators to conduct on a Mashment Maker the activities and interactions necessary to provide Mashments. Mashments are mashups aimed to tackle network management situations. We evaluate the Mashment Ecoystem by estimating with the Keystroke-Level Model and measuring in a test scenario the time that Network Administrators take to perform the activities of creating, launching, and publishing Mashments. Similarly, we evaluate the time for retrieving information about a network management situation by using or not Mashments. The evaluation results corroborated that Network Administrators, in our ecosystem, need short-time to deal with network management situations.","1930-529X;1930529X","Electronic:978-1-4799-1353-4; POD:978-1-4799-1351-0; USB:978-1-4799-1352-7","10.1109/GLOCOM.2013.6831409","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831409","","Ecosystems;Engines;Mashups;Monitoring;Nuclear magnetic resonance;Visualization","information retrieval;telecommunication network management","Mashment Ecoystem;Mashment maker;information retrieval;keystroke-level model;mashup ecosystem;network administrators;network management situations","","2","","21","","","9-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"Not So Cooperative Caching in Named Data Networking","Xiaoyan Hu; C. Papadopoulos; J. Gong; D. Massey","Sch. of Comput. Sci. & Eng., Southeast Univ., Nanjing, China","2013 IEEE Global Communications Conference (GLOBECOM)","20140612","2013","","","2263","2268","This work designs and implements a Not So Cooperative Caching system for Information Centric Networking (ICN). We consider a network comprised of selfish nodes; each is with caching capability and an objective of reducing its own access cost by fetching data from its local cache or from neighboring caches. These nodes would cooperate in caching and sharing content if and only if they each benefit. The challenges are to determine what objects to cache at each node and to implement the system in the context of Named Data Networking (NDN), a large effort that exemplifies ICN. Our results include both a solution for the Not So Cooperative Caching problem and an NDN design and implementation. We evaluate our approach by deploying the system we developed on PlanetLab and show that it improves the content hit ratio by up to 13%.","1930-529X;1930529X","Electronic:978-1-4799-1353-4; POD:978-1-4799-1351-0; USB:978-1-4799-1352-7","10.1109/GLOCOM.2013.6831411","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831411","","Cooperative caching;Logic gates;Next generation networking;Organizations;Radiation detectors;Servers;Synchronization","cache storage;cooperative communication;information networks;information retrieval","information centric networking;named data networking;not-so-cooperative caching system","","1","","16","","","9-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic generation of question answer pairs from noisy case logs","J. Ajmera; S. Joshi; A. Verma; A. Mittal","IBM India Res. Lab., New Delhi, India","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","436","447","In a customer support scenario, a lot of valuable information is recorded in the form of `case logs'. Case logs are primarily written for future references or manual inspections and therefore are written in a hasty manner and are very noisy. In this paper, we propose techniques that exploit these case logs to mine real customer concerns or problems and then map them to well written knowledge articles for that enterprise. This mapping results into generation of question-answer (QA) pairs. These QA pairs can be used for a variety of applications such as dynamically updating the frequently-asked-questions (FAQs), updating the knowledge repository etc. In this paper we show the utility of these discovered QA pairs as training data for a question-answering system. Our approach for mining the case logs is based on a composite model consisting of two generative models, viz, hidden Markov model (HMM) and latent Dirichlet allocation (LDA) model. The LDA model explains the long-range dependencies across words due to their semantic similarity and HMM models the sequential patterns present in these case logs. Such processing results in crisp `problem statement' segments which are indicative of the real customer concerns. Our experiments show that this approach finds crisp problem-statements in 56% of the cases and outperforms other alternate methods for segmentation such as HMM, LDA and conditional random field (CRF). After finding these crisp problem-statements, appropriate answers are looked up from an existing knowledge repository index forming candidate QA pairs. We show that considering only the problemstatement segments for which the answers can be found further improves the segmentation performance to 82%. Finally, we show that when these QA pairs are used as training data, the performance of a question-answering system can be improved significantly.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816671","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816671","","Context;Hidden Markov models;Noise measurement;Semantics;Syntactics;Training;Viterbi algorithm","data mining;hidden Markov models;question answering (information retrieval)","FAQ;HMM;LDA model;QA pairs discovery;case logs mining;conditional random field;frequently-asked-questions;hidden Markov model;knowledge repository;latent Dirichlet allocation model;problem statement segments;question answer pairs;question-answering system;segmentation performance;semantic similarity","","0","","15","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Crowdsourcing for public safety","A. Goncalves; C. Silva; P. Morreale; J. Bonafide","Comput. Sci. Dept., Kean Univ., Union, NJ, USA","2014 IEEE International Systems Conference Proceedings","20140522","2014","","","50","56","With advances in mobile technology, the ability to get real-time geographically accurate data, including photos and videos, becomes integrated into daily activities. Businesses use this technology edge to stay ahead of their competitors. Social media has made photo and video sharing a widely accepted and adopted behavior. This real-time data and information exchange, crowdsourcing, can be used to help first responders and personnel in emergency situations caused by extreme weather such as earthquakes, hurricanes, floods, and snow storms. Using smartphones, civilians can contribute data and images to the recovery process and make it more efficient, which can ultimately save lives and decrease the economic impact caused by extreme weather conditions.","","CD-ROM:978-1-4799-2087-7; Electronic:978-1-4799-2086-0; POD:978-1-4799-2089-1","10.1109/SysCon.2014.6819235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819235","crowdsourcing;extreme weather;public safety;real-time network data","Companies;Hurricanes;Maintenance engineering;Meteorology;Real-time systems;Smart phones","emergency management;information retrieval;mobile computing;smart phones","crowdsourcing;data exchange;earthquakes;emergency situations;extreme weather conditions;floods;geographically accurate data;hurricanes;information exchange;mobile technology;public safety;smart phones;snow storms;social media","","3","","11","","","March 31 2014-April 3 2014","","IEEE","IEEE Conference Publications"
"Information Service Platform of China Human Resources in Science and Technology Based on WEBGIS","Q. Guo; D. Zhou","Beijing Inst. of Technol. Beijing, Beijing, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","98","101","This paper proposes the solution of information service platform of China human resources in science and technology based on WEBGIS. The platform and the technical standards of information service and supervision for China human resources in science and technology are developed. The platform is consisted of the five parts, i.e. the Information Infrastructure Network (IIN), the Data Collection System (DCS), the Data Processing System (DPS), the Data Warehouse (DW) and the Information Service and Supervision System (I3S) based on WEBGIS. It can provide the following main functions, such as (1) on-line information search for China human resources in science and technology, (2) on-line information collection of China human resources in science and technology, (3) information processing and analysis of China human resources in science and technology, (4) on-line information update of China human resources in science and technology, (5) on-line information service and supervision of China human resources in science and technology based on WEBGIS.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835555","Human Resources;Information Service;Information Supervision;Science and Technology;WEBGIS","Data collection;Data warehouses;Databases;Information services;Service-oriented architecture","Internet;data analysis;data warehouses;geographic information systems;human resource management;information retrieval;management information systems","China human resources;DCS;DPS;DW;I3S;IIN;WEBGIS;data collection system;data processing system;data warehouse;information analysis;information infrastructure network;information processing;information service and supervision system;information service platform;on-line information collection;on-line information search;on-line information service;on-line information supervision;on-line information update;science and technology","","0","","7","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Effective Search Results Semantic Optimization Clustering Method for XML Fragments","Z. Minjuan","Sch. of Inf. Technol., Jiangxi Univ. of Finance & Econ., Nanchang, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","479","482","With the emergence of more and more XML documents, the clustering of XML documents has become an active research area. However, it is more significance of XML element clustering than whole document due to the more focused and specific amount of information, especially to some application domain. Therefore, in this paper, we study the xml element clustering, in which the latent semantic indexing model is used to obtain the semantic relationship between terms firstly, and then a evaluation function for k-mediod is presented to automatic generate the optimal cluster number. In addition, information gain, for evaluating clustering quality is introduced. Experiment results show that the proposed semantic clustering optimization method outperforms the traditional method (No_optimization) in information gain and produces better clustering quality.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835644","Evaluation Function;Optimal Cluster Number;Search Results Clustering;XML Fragments","Clustering algorithms;Indexing;Mathematical model;Optimization methods;Semantics;XML","XML;document handling;indexing;information retrieval;pattern clustering","XML documents;XML fragments;clustering quality;document clustering;evaluation function;k-mediod;latent semantic indexing model;search results;semantic optimization clustering method","","0","","13","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Civil Transportation Event Extraction from Chinese Microblog","J. Xiong; Y. Hao; Z. Huang","Dept. of Inf. Security & Eng., Shanghai Jiaotong Univ., Shanghai, China","2013 International Conference on Cloud Computing and Big Data","20140526","2013","","","577","582","People produce hundreds of millions of microblogs everyday. With its 140-character message, Microblog has yielded an enormous corpus of information, which is noisy but informative in some way. However, previous work with standard NLP tools of event extraction performs poorly on Microblog. In this paper, we adopt a series of methods to extract events from Chinese microblogs. In particular, we grab the chatters from Sina Weibo to extract civil transportation information. We eliminate buzz in Weibo, use CRF methods to filter microblogs so as to focus on transportation, and we also use CRF to recognize named entities and to extract events.","","Electronic:978-1-4799-2830-9; POD:978-1-4799-2831-6","10.1109/CLOUDCOM-ASIA.2013.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821052","CRF;Chinese Microblog;Event Extraction;NER;NLP","Data mining;Noise;Standardization;Tagging;Testing;Training;Transportation","information retrieval;social networking (online)","CRF methods;Chinese microblog;NLP tools;Sina Weibo;civil transportation event extraction;conditional random fields;named entity recognition;natural language processing","","0","","12","","","16-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Context Based Text Summarization System","R. Ferreira; F. Freitas; L. d. S. Cabral; R. D. Lins; R. Lima; G. Fran√ßa; S. J. Simske; L. Favaro","Inf. Center, Fed. Univ. of Pernambuco, Recife, Brazil","2014 11th IAPR International Workshop on Document Analysis Systems","20140612","2014","","","66","70","Text summarization is the process of creating a shorter version of one or more text documents. Automatic text summarization has become an important way of finding relevant information in large text libraries or in the Internet. Extractive text summarization techniques select entire sentences from documents according to some criteria to form a summary. Sentence scoring is the technique most used for extractive text summarization, today. Depending on the context, however, some techniques may yield better results than some others. This paper advocates the thesis that the quality of the summary obtained with combinations of sentence scoring methods depend on text subject. Such hypothesis is evaluated using three different contexts: news, blogs and articles. The results obtained show the validity of the hypothesis formulated and point at which techniques are more effective in each of those contexts studied.","","Electronic:978-1-4799-3243-6; POD:978-1-4799-1663-4","10.1109/DAS.2014.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830971","Document Engineering;Text Summarization;Text Summarization Evaluation","Abstracts;Algorithm design and analysis;Blogs;Context;Educational institutions;Gold;Standards","information retrieval;text analysis","Internet;automatic text summarization;context based text summarization system;extractive text summarization techniques;large text libraries;sentence scoring;text documents","","6","","9","","","7-10 April 2014","","IEEE","IEEE Conference Publications"
"Community-aware data replication in sparse vehicular networks","Zhenni Feng; Yanmin Zhu; Ruobing Jiang; B. Li","Dept. of Comput. Sci. & Eng., Shanghai Jiao Tong Univ., Shanghai, China","2013 IEEE Global Communications Conference (GLOBECOM)","20140612","2013","","","593","598","Vehicular networks have become a promising platform for large-scale urban sensing. On-demand data retrieval is a crucial operation for many applications of vehicular networks. It is particularly challenging, however, to achieve high performance of on-demand data retrieval in sparse vehicular networks. Data replication based on random linear network coding can solve the coupon collection problem but suffers the problem of unnecessary data replications which waste the precious communication opportunities of sparse vehicular networks. With real traces we reveal the existence of community structures in vehicular networks, which causes excessive linearly correlated blocks. Motivated by the important observation, we propose a community-aware data replication scheme based on random linear network coding. To reduce the excessive correlated coded blocks because of community structures, we make probabilistic control on the data replication phase, taking the community structures into account. It is demonstrated through extensive simulations that the community-aware scheme can effectively save up to 50% communication opportunities whiling achieving high performance of on-demand data retrieval.","1930-529X;1930529X","Electronic:978-1-4799-1353-4; POD:978-1-4799-1351-0; USB:978-1-4799-1352-7","10.1109/GLOCOM.2013.6831136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831136","Community-aware;Data Replication;Network Coding;Sparse Vehicular Networks","Ad hoc networks;Communities;Decoding;Delays;Network coding;Probabilistic logic;Vehicles","information retrieval;linear codes;network coding;probability;replicated databases","communication opportunities;community structures;community-aware data replication;coupon collection problem;data replication phase;excessive correlated coded blocks;large-scale urban sensing;linearly correlated blocks;on-demand data retrieval;probabilistic control;random linear network coding;sparse vehicular networks","","0","","14","","","9-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"A bibliometric description and content analysis of mega-project characteristics","X. Peng; W. Che; Y. Shou","Sch. of Manage., Zhejiang Univ., Hangzhou, China","2012 IEEE International Conference on Industrial Engineering and Engineering Management","20140619","2012","","","2331","2336","With the rapid development of project management practice, mega-project management has become a hot research topic in the field of project management. At present, researchers hold different understandings of the characteristics of mega-projects, thus it is of theoretical significance to study this issue. By collecting the academic papers relevant to mega-projects published from 1998 to 2011 in the Web of Science, we made a bibliometric description of the retrieval results and summarized the status quo of mega-project management. The content analysis method was employed in this megaproject characteristics study. Using a category system, we found four significant factors including time constraint, stakeholders, impact of external environment, and risk.","2157-3611;21573611","Electronic:978-1-4673-2945-3; POD:978-1-4673-2946-0","10.1109/IEEM.2012.6838164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838164","Mega-project;characteristic;content analysis","Bibliometrics;Complexity theory;Educational institutions;Encoding;Investment;Project management;Time factors","construction industry;information analysis;information retrieval;project management","Web of science;bibliometric description;category system;content analysis;external environment;mega-project characteristics;mega-project management;project management practice;retrieval results;time constraint","","0","","21","","","10-13 Dec. 2012","","IEEE","IEEE Conference Publications"
"Integration of heterogeneous data for real world domain","J. L. Hong","Sch. of Comput. & IT, Taylor's Univ., Subang Jaya, Malaysia","2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20140519","2013","","","868","872","There are a large number of companies that have abundant amount of data presented in unstructured forms. For example, accounting firms and banking sectors have clients who may provide financial data for them. However, these clients have data which is of diverse nature. To make this data presentable in a meaningful way, companies usually use their employees to key in data manually to their own systems. This approach is tedious and labor intensive. To facilitate the data processing, these companies normally prefer to have automated softwares that can easily recognize the different formats of data, process and present them in a usable form suitable for further processing. However, there are currently no automated software tools which can perform this task. In this paper, we propose a novel ontological tool in this study to extract data from heterogeneous sources. Our tool will be able to analyze the semantic properties of the various data.","","Electronic:978-1-4673-5253-6; POD:978-1-4673-5251-2","10.1109/FSKD.2013.6816316","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816316","Data Integration;Heterogeneous Data;Ontology","Companies;Data integration;Data mining;Internet;Ontologies;Semantics;Visualization","data analysis;data integration;information retrieval;ontologies (artificial intelligence)","data extraction;data processing;data semantic property analysis;heterogeneous data integration;heterogeneous data sources;ontological tool;real world domain","","0","","23","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"An improved method for measuring concept semantic similarity combining multiple metrics","K. Sun; Y. Ji; L. Rui; X. Qiu","Beijing Univ. of Posts & Telecommun., Beijing, China","2013 5th IEEE International Conference on Broadband Network & Multimedia Technology","20140602","2013","","","268","272","Ontology-based semantic similarity measures the similarity between the concepts, which is widely used in information retrieval and semantic web service fields. Existing studies of semantic similarity matching algorithm are mainly focused on computing the semantic distance between concepts, the notion of information content or the overlap of concept attributes. But most of these algorithms calculate semantic similarity in their own way without taking other factors into account. This paper proposes a novel algorithm which combines three factors mentioned above. To avoid unreasonable artificial weight setting, the principal component analysis is used to weigh each factor's contribution to the semantic similarity. The experimental evaluations using WordNet proves that the algorithm presented in this paper improves the accuracy of semantic similarity and the results are more close to human judgment.","","Electronic:978-1-4799-0095-4; POD:978-1-4799-0096-1","10.1109/ICBNMT.2013.6823955","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823955","Ontology;Principal component analysis;Semantic similarity;WordNet","Accuracy;Algorithm design and analysis;Correlation;Integrated circuits;Measurement;Principal component analysis;Semantics","Web services;information retrieval;ontologies (artificial intelligence);principal component analysis;semantic Web;software metrics","WordNet;artificial weight setting;information content;information retrieval;measuring concept semantic similarity;multiple metrics;ontology;principal component analysis;semantic Web service fields;semantic distance;semantic similarity matching algorithm","","0","","11","","","17-19 Nov. 2013","","IEEE","IEEE Conference Publications"
"Leveraging metadata for identifying local, robust multi-variate temporal (RMT) features","X. Wang; K. S. Candan; M. L. Sapino","Arizona State Univ., Tempe, AZ, USA","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","388","399","Many applications generate and/or consume multi-variate temporal data, yet experts often lack the means to adequately and systematically search for and interpret multi-variate observations. In this paper, we first observe that multi-variate time series often carry localized multi-variate temporal features that are robust against noise. We then argue that these multi-variate temporal features can be extracted by simultaneously considering, at multiple scales, temporal characteristics of the time-series along with external knowledge, including variate relationships, known a priori. Relying on these observations, we develop algorithms to detect robust multi-variate temporal (RMT) features which can be indexed for efficient and accurate retrieval and can be used for supporting analysis tasks, such as classification. Experiments confirm that the proposed RMT algorithm is highly effective and efficient in identifying robust multi-scale temporal features of multi-variate time series.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816667","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816667","","Correlation;Data models;Feature extraction;Robustness;Smoothing methods;Tensile stress;Time series analysis","feature extraction;indexing;information retrieval;meta data;pattern classification;time series","RMT features;classification task;external knowledge;information retrieval;local multivariate temporal features;meta data;multivariate observations;multivariate time series;robust multivariate temporal features;variate relationships","","1","","27","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Comparative analysis of similarity measures in document clustering","Kavitha Karun A; M. Philip; K. Lubna","Dept. of Comput. Sci. & Eng., Rajagiri Sch. of Eng. & Technol., Kochi, India","2013 International Conference on Green Computing, Communication and Conservation of Energy (ICGCE)","20140602","2013","","","857","860","Rapid breakthrough in science and technology paved way for the accumulation of bulk of data. Extracting useful and meaningful data from this gargantuan amount of data is a tedious process. This has resulted in the development of efficient Data mining methods to discover interesting unknown knowledge from a large amount of data. Document mining or Text mining refers to data mining techniques to extract interesting and nontrivial information and knowledge from unstructured text. Document clustering is an effective Text mining method which classifies similar documents in to a group. Similarity measures play a key role in clustering documents. In this, a comparative study on the effect of various similarity measures in clustering documents in the same data set is done.","","DVD:978-1-4673-6125-5; Electronic:978-1-4673-6126-2; POD:978-1-4673-6124-8","10.1109/ICGCE.2013.6823554","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823554","Clusters;Document Clustering;similarity measures","Clustering algorithms;Computational modeling;Correlation coefficient;Euclidean distance;Text mining;Vectors","data mining;information retrieval;pattern classification;pattern clustering;text analysis","comparative analysis;data mining methods;document clustering;document mining;information extraction;similarity measures;text mining","","1","","8","","","12-14 Dec. 2013","","IEEE","IEEE Conference Publications"
"Improvement of retrieval in case-based reasoning for system design","T. Coudert; E. Vareilles; L. Geneste; M. Aldanondo","Lab. Genie de Production, Univ. of Toulouse, Tarbes, France","2012 IEEE International Conference on Industrial Engineering and Engineering Management","20140619","2012","","","1538","1542","The problematic addressed in this article is dealing with the improvement of retrieval in Case-Based Reasoning for system design. The retrieval activity is based on the evaluation of similarities between requirements (target) and the solutions (sources). However, similarities between features is often a subjective kind of knowledge difficult to formalize within companies. Based on an ontology of domain, the approach permits to retrieve compatible solutions rather than similar ones using a model of designer preferences. The requirements are modeled by means of constraints. When constraints are confronted to solutions in order to evaluate a compatibility measure, missing information within solutions with regard to requirements are taken into account using semantic similarities between concepts. A case study validates the proposals.","2157-3611;21573611","Electronic:978-1-4673-2945-3; POD:978-1-4673-2946-0","10.1109/IEEM.2012.6838004","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838004","Case-Based Reasoning;Ontology;Preference modeling;System design;semantic similarity","Abstracts;Cognition;Equations;Metals;Ontologies;System analysis and design;System-on-chip","case-based reasoning;information retrieval;ontologies (artificial intelligence);systems analysis","case-based reasoning retrieval;compatibility measure;ontology;semantic similarity;system design","","0","","10","","","10-13 Dec. 2012","","IEEE","IEEE Conference Publications"
"Web accessibility evaluation of massive open online courses on Geographical Information Systems","T. Calle-Jimenez; S. Sanchez-Gordon; S. Luj√°n-Mora","Dept. of Inf. & Comput. Sci., Nat. Polytech. Sch., Quito, Ecuador","2014 IEEE Global Engineering Education Conference (EDUCON)","20140605","2014","","","680","686","This paper describes some of the challenges that exist to make accessible massive open online courses (MOOCs) on Geographical Information Systems (GIS). These courses are known by the generic name of Geo-MOOCs. A MOOC is an online course that is open to the general public for free, which causes a massive registration. A GIS is a computer application that acquire, manipulate, manage, model and visualize geo-referenced data. The goal of a Geo-MOOC is to expand the culture of spatial thinking and the use of geographic information, enabling geospatial web technologies for widespread use. However, the Geo-MOOCs, by nature, have inherent problems of accessibility. The Convention on the Rights of Persons with Disabilities (CRPD), Article 24, recognize the right of persons with disabilities to education. ‚ÄúStates Parties must ensure that persons with disabilities are able to access general tertiary education, vocational training, adult education and lifelong learning without discrimination and on an equal basis with others‚Äù [1]. Therefore, it is important to have accessible Geo-MOOCs. In this paper, we present the results of the evaluation of a Geo-MOOC called ‚ÄúMaps and the Geospatial Revolution‚Äù using three tools available for free on the Internet: Chrome Developer Tools - Accessibility Audit, eXaminator and WAVE; and included a selection of web content and geographical data representative of the course. This provided feedback for establishing recommendations to improve the accessibility of the analyzed course. Other Geo-MOOCs can also benefit from these recommendations.","2165-9559;21659559","Electronic:978-1-4799-3191-0; POD:978-1-4799-3192-7; USB:978-1-4799-3190-3","10.1109/EDUCON.2014.6826167","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6826167","Automatic Accessibility Evaluation Tools;Chrome Accessibility Audit;Geo-MOOC;Geographical Information Systems;Massive Open Online Courses;WAVE;Web Accessibility;eXaminator","Cascading style sheets;Geospatial analysis;Image color analysis;Internet;Vectors;Web pages","Internet;computer aided instruction;educational courses;geographic information systems;information retrieval;interactive programming","Accessibility Audit;CRPD;Chrome Developer Tools;Convention on the Rights of Persons with Disabilities;GIS;Geo-MOOC;Internet;WAVE;Web accessibility evaluation;eXaminator;geographical information systems;massive open online courses","","7","","20","","","3-5 April 2014","","IEEE","IEEE Conference Publications"
"NDNBench: A benchmark for Named Data Networking lookup","Ting Zhang; Y. Wang; Tong Yang; Jianyuan Lu; B. Liu","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing, China","2013 IEEE Global Communications Conference (GLOBECOM)","20140612","2013","","","2152","2157","Content-centric Networking (CCN) and the later proposed Named Data Networking (NDN) have attracted wide attention in both academia and industry, as the clean slate future Internet architecture. Wire speed name lookup for packet forwarding is one of the most challenging tasks in CCN/NDN. As a promising technology, its feasibilities including reachable speed, scalability, and update performance are imperative to be deeply evaluated. However, CCN/NDN is currently on its initial stage and no actual network is deployed, which means no real name routing tables and NDN traffic are available. In order to fulfill performance comparisons among various innovative name lookup solutions and facilitate future name lookup researches, we present NDNBench, a publicly available platform for evaluation, comparison and experiments with different name lookup approaches. NDNBench can generate various Forwarding Information Bases (FIBs), traces with structure and size diversity to conduct the tests thoroughly by adjusting the parameters. NDNBench provides a simulation package tool with flexibility to evaluate various name lookup approaches. Furthermore, in order to verify the effectiveness of NDNBench, we benchmark some existing name lookup schemes and the results are very supportive. NDNBench has been applied to recent work and is publicly available at the following site: http://s-router.cs.tsinghua.edu.cn/~zhangting/.","1930-529X;1930529X","Electronic:978-1-4799-1353-4; POD:978-1-4799-1351-0; USB:978-1-4799-1352-7","10.1109/GLOCOM.2013.6831393","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831393","","Generators;IP networks;Internet;Measurement;Routing;Scalability;Throughput","Internet;computer networks;information retrieval;table lookup;telecommunication network routing","NDNBench;content centric networking;forwarding information base;future name lookup research;named data networking lookup benchmark;packet forwarding;routing tables","","2","","17","","","9-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"Hybridsourcing: A novel work allocation mechanism to provide controlled autonomy to workers","P. S. Hotkar; S. Agarwal; S. Mhaskar","Dept. of Manage. Studies, Indian Inst. of Technol., Chennai, Chennai, India","2014 IEEE Network Operations and Management Symposium (NOMS)","20140619","2014","","","1","8","Workforce management is a growing concern in people intensive service organizations like IT service delivery. The knowledge workers tend to get de-motivated due to the mundane nature of maintenance tasks assigned to them. To tackle this problem, many organizations are willing to experiment with novel methods of work allocation that provide certain amount of autonomy to the knowledge workers by enabling them to choose what they want to work on. In this paper, we propose a method of work allocation that provides opportunities to employees to choose their work without the organization having to compromise on the regular business tasks. The idea is to use crowdsourcing concepts for the tasks that will enable employees to showcase their skills and talent. We have modeled crowdsourced cum managerial assignments , which we call Hybridsourcing, as an auction mechanism and use game theoretic analysis for studying the competition among players and the tradeoffs for the organization. As part of the auction mechanism for carrying out Hybridsourcing, two games have been formulated based on: 1) players have common knowledge about the operation costs and 2) operation costs are a private information. We show the existence and uniqueness of a Nash equilibrium (NE) in both the cases and provide an algorithm bounded by polynomial complexity in order to compute the NE. The outcome of the mechanism is defined by the unique NE. Furthermore, we study the pros and cons of our mechanism vis-a-vis the popular auction based mechanisms like VCG and few others. We also show that the mechanism allows for flexible autonomy making it very practical.","1542-1201;15421201","Electronic:978-1-4799-0913-1; POD:978-1-4799-0911-7; USB:978-1-4799-0912-4","10.1109/NOMS.2014.6838268","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838268","Crowdsourcing;Nash Equilibrium;Tullock Auction;Work Allocation;Workforce Management","Crowdsourcing;Equations;Games;Mathematical model;Nash equilibrium;Organizations;Resource management","computational complexity;game theory;human resource management;information retrieval","IT service delivery;Nash equilibrium;auction mechanism;controlled autonomy;crowdsourcing concepts;game theoretic analysis;hybridsourcing mechanism;information technology;knowledge workers;managerial assignments;operation costs;people intensive service organizations;polynomial complexity;work allocation mechanism;workforce management","","0","","23","","","5-9 May 2014","","IEEE","IEEE Conference Publications"
"GOSCL as facet-like structures","P. Butka; J. P√≥csova; J. P√≥cs","Dept. of Cybern. & Artificial Intell., Tech. Univ. of Kosice, Kosice, Slovakia","2014 IEEE 12th International Symposium on Applied Machine Intelligence and Informatics (SAMI)","20140529","2014","","","321","326","In this paper we describe Generalized One-sided Concept Lattices (GOSCL) as facet-like structures. Facet-like structures occur in many computer science disciplines as some hierarchical structures. GOSCL constitute from (objects, properties) pairs known as the formal concepts. The hierarchical structure of formal concepts, ordered by the generalization and specialization among the concepts, forms a concept lattice, which represents a concept hierarchy where each node represents a subset of objects with the corresponding set of properties. The paper focus on GOSCL model for facets and discusses some graphical representations of faceted systems based on this model.","","Electronic:978-1-4799-3442-3; POD:978-1-4799-3443-0; USB:978-1-4799-3440-9","10.1109/SAMI.2014.6822431","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822431","","Computer science;Context;Educational institutions;Informatics;Lattices;Machine intelligence;Mathematical model","formal concept analysis;fuzzy set theory;generalisation (artificial intelligence);information retrieval systems","GOSCL model;concept hierarchy;facet-like structures;formal concepts;generalized one-sided concept lattices;hierarchical structures;information retrieval systems","","0","","17","","","23-25 Jan. 2014","","IEEE","IEEE Conference Publications"
"Semantic relation extraction by Conditional Random Fields from Turkish Wikipedia pages","C. Girgin; B. Diri","Bilisim ve Bugi Guvenligi Ileri Teknolojiler Arastirma, Merkezi - TUBITAK, Kocaeli, Turkey","2014 22nd Signal Processing and Communications Applications Conference (SIU)","20140612","2014","","","136","139","Relations between entities constitute the most important fundamental parts of semantic search technologies. The products that use semantic search technologies include datastores which keep relations between entities in their infrastructures. Various Relation Extraction applications are done in the extraction of the relations between entities. In this study, Conditional Random Fields has been used to extract extract relations between entities from Turkish Wikipedia pages.","2165-0608;21650608","Electronic:978-1-4799-4874-1; POD:978-1-4799-4873-4","10.1109/SIU.2014.6830184","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830184","conditional random fields;natural language processing;relation extraction;semantic search;wikipedia","Conferences;Electronic publishing;Encyclopedias;Internet;Semantics;Signal processing","Web sites;information retrieval;statistical analysis","Turkish Wikipedia pages;conditional random fields;data stores;entity relations;semantic relation extraction;semantic search technologies","","0","","7","","","23-25 April 2014","","IEEE","IEEE Conference Publications"
"A tool for personal data extraction","D. Vianna; A. M. Yong; C. Xia; A. Marian; T. Nguyen","Department of Computer Science Rutgers University, Piscataway, NJ 08854-8019","2014 IEEE 30th International Conference on Data Engineering Workshops","20140519","2014","","","80","83","Digital storage now acts as an archive of the memories of users worldwide, keeping record of data as well as the context in which the data was acquired. The massive amount of data available and the fact that it is fragmented across many services (e.g., Facebook) and devices (e.g., laptop) make it very difficult for users to find specific pieces of information that they remember having stored or accessed. Unifying this fragmented data into a single data set that includes contextual information would allow for much better indexing and searching of personal information. Thus, we have developed a personal data extraction tool as a first step toward this vision. In this paper, we present this extraction tool, along with some preliminary statistics about personal data gathered by the tool for several users. The goal of the data analysis is to give a glimpse of what the digital life of a person may look like, and how it is currently partitioned across many different services; moreover, it reinforces the fact that it is not possible for users to manually retrieve, store and access their extensive digital data without the support of a personalized information management tool.","","Electronic:978-1-4799-3481-2; POD:978-1-4799-3482-9","10.1109/ICDEW.2014.6818307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818307","","Data mining;Data models;Databases;Electronic mail;Facebook;Google;Knowledge discovery","data handling;information retrieval;storage management","Facebook;contextual information;data record;digital storage;personal data extraction;personal information indexing;personal information searching;personalized information management tool","","1","","7","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Load balancing for resource provisioning using Batch Mode Heuristic Priority in Round Robin (P<inf>B</inf>RR) Scheduling","G. Raj; D. Singh; A. Bansal","Punjab Tech. Univ., Jalandhar, India","Confluence 2013: The Next Generation Information Technology Summit (4th International Conference)","20140616","2013","","","308","314","Number of users, now a days tries to access the data in different type of online services like shopping, gaming, learning etc., which tends to increase the computing as well as storing/fetching load if we use single server. Increase of load on a server results in reduction of throughput and it leads to a strong need of developing and maintaining an efficient system with an appropriate load balancing algorithm that will be used to retrieve the important information with a reasonable response time. The main objective of our study is to propose an new approach for load balancing which can balance the incoming requests from global users which reside in different geographical locations to retrieve the information from a distributed data sources using effective scheduling and virtualization techniques. We are utilizing the combination of Batch Mode Heuristic Priority and Round Robin Scheduling for reducing the load on server. This paper provide good results as we compare Batch mode and Online Mode priority, and conclude with suggestion to use Batch Mode in place of Online mode for better load balancing.","","Electronic:978-1-84919-846-2","10.1049/cp.2013.2333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832348","Batch Mode and Online Mode Priority Scheduling;Cloud computing;distributed database;load balancing;virtualization","","cloud computing;distributed databases;information retrieval;processor scheduling;resource allocation;virtualisation","P<sub>B</sub>RR scheduling;batch mode heuristic priority;cloud computing;data access;distributed data sources;geographical locations;information retrieval;load balancing algorithm;load reduction;online services;resource provisioning;round robin scheduling;throughput reduction;virtualization techniques","","0","","","","","26-27 Sept. 2013","","IET","IET Conference Publications"
"Semantic Stability and Implicit Consensus in Social Tagging Streams","C. Wagner; P. Singer; M. Strohmaier; B. Huberman","Univ. of Koblenz, Koblenz, Germany","IEEE Transactions on Computational Social Systems","20140603","2014","1","1","108","120","One potential disadvantage of social tagging systems is that due to the lack of a centralized vocabulary, a crowd of users may never manage to reach a consensus on the description of resources (e.g., books, images, users, or songs) on the Web. Yet, previous research has provided interesting evidence that the tag distributions of resources in social tagging systems may become semantically stable over time, as more and more users tag them and implicitly agree on the relative importance of tags for a resource. At the same time, previous work has raised an array of new questions such as: 1) how can we assess semantic stability in a robust and methodical way? 2) does the semantic stabilization varies across different social tagging systems and ultimately, and 3) what are the factors that can explain semantic stabilization in such systems? In this work, we tackle these questions by: 1) presenting a novel and robust method, which overcomes a number of limitations in existing methods; 2) empirically investigating semantic stabilization in different social tagging systems with distinct domains and properties; and 3) detecting potential causes of stabilization and implicit consensus, specifically imitation behavior, shared background knowledge and intrinsic properties of natural language. Our results show that tagging streams that are generated by a combination of imitation dynamics and shared background knowledge exhibit faster and higher semantic stability than tagging streams that are generated via imitation dynamics or natural language phenomena alone.","2329-924X;2329924X","","10.1109/TCSS.2014.2307455","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816015","Distributional semantics;emergent semantics;social semantics;social tagging;stabilization process","Natural languages;Robustness;Semantics;Stability analysis;Tagging;Twitter;Vocabulary","information retrieval;natural language processing","centralized vocabulary;imitation dynamics;implicit consensus;natural language phenomena;semantic stability;semantic stabilization;social tagging systems","","0","","34","","20140516","March 2014","","IEEE","IEEE Journals & Magazines"
"Fast incremental SimRank on link-evolving graphs","W. Yu; X. Lin; W. Zhang","Univ. of New South Wales, Sydney, NSW, Australia","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","304","315","SimRank is an arresting measure of node-pair similarity based on hyperlinks. It iteratively follows the concept that 2 nodes are similar if they are referenced by similar nodes. Real graphs are often large, and links constantly evolve with small changes over time. This paper considers fast incremental computations of SimRank on link-evolving graphs. The prior approach [12] to this issue factorizes the graph via a singular value decomposition (SVD) first, and then incrementally maintains this factorization for link updates at the expense of exactness. Consequently, all node-pair similarities are estimated in O(r<sup>4</sup>n<sup>2</sup>) time on a graph of n nodes, where r is the target rank of the low-rank approximation, which is not negligibly small in practice. In this paper, we propose a novel fast incremental paradigm. (1) We characterize the SimRank update matrix ŒîS, in response to every link update, via a rank-one Sylvester matrix equation. By virtue of this, we devise a fast incremental algorithm computing similarities of n<sup>2</sup> node-pairs in O(Kn<sup>2</sup>) time for K iterations. (2) We also propose an effective pruning technique capturing the ‚Äúaffected areas‚Äù of ŒîS to skip unnecessary computations, without loss of exactness. This can further accelerate the incremental SimRank computation to O(K(nd+|AFF|)) time, where d is the average in-degree of the old graph, and |AFF| (‚â§ n<sup>2</sup>) is the size of ‚Äúaffected areas‚Äù in ŒîS, and in practice, |AFF| ‚â™ n<sup>2</sup>. Our empirical evaluations verify that our algorithm (a) outperforms the best known link-update algorithm [12], and (b) runs much faster than its batch counterpart when link updates are small.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816660","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816660","","Accuracy;Approximation methods;Equations;Heuristic algorithms;Matrix converters;Matrix decomposition;Vectors","approximation theory;computational complexity;graph theory;information retrieval;learning (artificial intelligence);singular value decomposition","O(Kn<sup>2</sup>) time;O(r<sup>4</sup>n<sup>2</sup>) time estimation;SVD;SimRank update matrix;fast incremental SimRank;fast incremental algorithm;fast incremental paradigm;graph factorization;hyperlinks;link updates;link-evolving graphs;link-update algorithm;low-rank approximation;node-pair similarities;node-pair similarity measure;pruning technique;rank-one Sylvester matrix equation;singular value decomposition","","2","","21","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Parallel Approach and Platform for Large-Scale WEB Data Extraction","S. Yi; S. Shi; H. Wang; W. Wei; C. Yuan; Y. Huang","Dept. of Comput. Sci. & Technol., Nanjing Univ., Nanjing, China","2013 International Conference on Advanced Cloud and Big Data","20140605","2013","","","192","196","As the most popular information publishing platform, the Web contains a lot of valued information of interests to users or applications. Although a lot of data extraction techniques have been studied in the last decade, it is still far away from meeting the need of real data extraction. On the one hand, most of them cannot support the whole web information extraction process involving three stages: web page navigation, data extraction and data integration, On the other hand, they cannot support parallel data extraction process for large-scale web pages. In this paper, we propose a parallel approach and platform based on the Hadoop MapReduce for large-scale web data extraction. Our approach can perform the whole three-stage web data extraction process in parallel. Experimental results show that our approach is efficient and can achieve linear speedup.","","CD-ROM:978-1-4799-3260-3; Electronic:978-1-4799-3261-0; POD:978-1-4799-3262-7","10.1109/CBD.2013.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824595","Large-scale web data extraction;Parallel platform;Parallel web data extraction;Web data integration;Web page navigation","Data integration;Data mining;Data models;Knowledge engineering;Navigation;Web pages","Internet;Web sites;information retrieval;parallel processing","Hadoop MapReduce;Web information extraction process;Web page navigation;data integration;information publishing platform;large-scale Web data extraction;parallel approach;parallel data extraction process","","0","","17","","","13-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Secure and Efficient Search Technique in Cloud Computing","A. D. Kapse; P. K. Ingole","Dept. of C.S.E., G.H.R.C.E., Nagpur, India","2014 Fourth International Conference on Communication Systems and Network Technologies","20140529","2014","","","743","747","Cloud computing is nowadays widely used technology. Various advanced technologies in the world are taking cloud computing very seriously as the new era for mobile as well as a steady computing environment. In cloud computing the data privacy and its security is highly recommended, that's why the data which have to be stored on the cloud server database requires encryption. This results into complex utilization of cloud data access. So, it is highly recommended to improve the trust on cloud server as well as not to make its utilization a complex task for computation. This process should not increase the burden on overall system. This paper represents brief review of various methodologies which helps user for secured storage and efficient access to the data. Later a very secure and efficient system has been proposed to reduce the burden of the system thus to decrease complexity and to improve performance of overall system.","","Electronic:978-1-4799-3070-8; POD:978-1-4799-3071-5","10.1109/CSNT.2014.156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821498","cloud computing;data encryption;keyword search;ranked search","Cloud computing;Elliptic curve cryptography;Encryption;Indexes;Servers","cloud computing;cryptography;data privacy;file servers;information retrieval;mobile computing;search problems","cloud computing;cloud data access;cloud server;cloud server database;data privacy;encryption;secure search technique;steady computing environment","","0","","17","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"A Generic, Scalable and Fine-Grained Data Access System for Sharing Digital Objects in Honest but Curious Cloud Environments","I. M. Ibrahim; S. H. N. El-Din; R. Elgohary; H. Faheem; M. G. M. Mostafa","Inf. Technol. Ind. Dev. Agency (ITIDA), Giza, Egypt","2013 International Conference on Cloud Computing and Big Data","20140526","2013","","","15","22","This paper presents a generic, scalable and fine-grained data access system that realizes the main challenges which hinder the growth of using storage-as-a-service for sharing digital objects offered by honest but curious cloud environments. These main challenges are maintaining data confidentiality, enforcing fine-grained data access control, applying efficient user revocation mechanism, preventing the collusion between users to access unauthorized digital objects, achieving scalability and possessing generic construction desirable feature. In addition, the proposed system avails digital passport which is presented by the user to be granted access to any digital object in the cloud environment. The usage of digital passport minimizes the number of transactions needed to authenticate the specified user. Moreover, the digital passport simplifies the data management for users since the user has to keep his passport only to use it to access the cloud. Furthermore, the digital passport prevents a rejoined user who possesses different attributes to access his previously authorized data. Additionally, the digital passport prohibits the collusion between an authorized user and a revoked one to own the access privileges once assigned to the revoked user. The proposed system exploits public key infrastructure (PKI) to capitalize the usage of offline operations to enhance system performance and to secure the transmission of private data as well as defending man in the middle attack. It should be noted that the implementation of the proposed system has showed the system computational validity.","","Electronic:978-1-4799-2830-9; POD:978-1-4799-2831-6","10.1109/CLOUDCOM-ASIA.2013.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820968","Attribute Based Encryption;Cloud Computing;Proxy Re-encryption;Public Key Infrastructure","Access control;Cloud computing;Encryption;Public key;Scalability;System performance","authorisation;cloud computing;digital signatures;information retrieval;public key cryptography","PKI;cloud environments;data confidentiality;digital object sharing;digital passport;fine-grained data access control;fine-grained data access system;generic data access system;public key infrastructure;scalable data access system;storage-as-a-service","","0","","36","","","16-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"An efficient and optimized recommendation system using social network knowledge base","M. Z. Ashraf; Dheeraj Kumar Chouwdhary; Rohan Lal Das; P. Ghosal","Dept. of IT, Bengal Eng. & Sci. Univ., Howrah, India","2014 International Conference on Advances in Electrical Engineering (ICAEE)","20140619","2014","","","1","4","With the advent of e-commerce in the current market a large number of companies e.g. Flipkart, eBay, infibeam, amazon etc. have come up with a huge range of products on a single platform to the users. These products are recommended to the users based on certain parameters related to the user. Moreover, in order to refine the recommendation these e-commerce based websites have started using social networking sites to access information pertaining to the user in order to improve their recommendation. In this paper we present a novel recommendation system for e-commerce websites using social network knowledge base that uses certain parameters provided by users viz. age group, gender, location etc. and based on these criteria best recommendation is provided by our proposed method using Analytical Hierarchy Process, Merge-and-Sort, and Sort-and-Count algorithms within a wrapper to optimize. User preferences are taken from Facebook whereas Flipkart is chosen as the e-commerce website for illustration of our proposed method.","","Electronic:978-1-4799-3543-7; POD:978-1-4799-3236-8","10.1109/ICAEE.2014.6838561","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6838561","Analytical Hierarchy Process;Merge-and-Sort algorithm;Sort-and-Count algorithm;e-commerce websites;recommendation system;social networks","Analytic hierarchy process;Data mining;Educational institutions;Facebook;History","analytic hierarchy process;electronic commerce;information retrieval;knowledge based systems;merging;recommender systems;social networking (online);sorting","Facebook;Flipkart;analytical hierarchy process;e-commerce based Web sites;information access;merge-and-sort algorithms;optimized recommendation system;social network knowledge base;social networking sites;sort-and-count algorithms;user preferences","","0","","12","","","9-11 Jan. 2014","","IEEE","IEEE Conference Publications"
"Web-Based Semantic Web Retrieval Service for Law Ontology","D. W. Jo; M. H. Kim","Dept. of Comput. Sci. & Eng., Soongsil Univ., Seoul, South Korea","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","20140612","2013","","","666","673","Law grows in volume and complexity in the process of enactment and amendment, it could happen that yesterday's law is applied differently today. In this circumstance, law search service is necessary so as to appropriately recognize and find law which gets bigger in size and changes continuously. This study aims at providing a general user with easy and convenient service to access professional information such as law. To accomplish an easy and convenient service from user's perspective, this paper attempts to take diverse technical approaches as follows: (1) construct ontology on professional knowledge area, especially law, (2) access via web which ensures easy access to constructed information, and (3) visualization technology which allows the users to retrieve data conveniently. This service allows the user to check the data with visualized presentation of ontology information and to navigate the information. Those functions indicate that this service focuses on enhancing user convenience from the viewpoint of users in retrieving professional information which might be hard to find and deal with for the general users.","","Electronic:978-0-7695-5088-6; POD:978-1-4799-0973-5","10.1109/HPCC.and.EUC.2013.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831981","Law;Ontology;RDF;Semantic Web;Web","Engines;Law;Ontologies;Resource description framework;Semantics","data visualisation;information retrieval;law;ontologies (artificial intelligence);semantic Web","Web access;Web-based semantic Web retrieval service;data retrieval;information navigation;law amendment;law enactment;law ontology;law search service;ontology construction;ontology information;professional information access;professional information retrieval;professional knowledge area;visualization technology;visualized presentation","","0","","20","","","13-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Hybrid cognitive model for semantic discovery and selection of services","S. Sharma; J. S. Lather; M. Dave","Dept. of Comput. Applic., Nat. Inst. of Technol., Kurukshetra, India","2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)","20140519","2014","","","73","78","Lack of (semi)automatic mechanisms for service classification in the Universal Description Discovery and Integration repositories and non utilization of explicit or implicit semantic information of a service during its publishing are the two major challenges in the area of web service discovery and selection. We propose a semantic model of human-machine collaboration for the classification, discovery and selection of web services that integrates the semantic as well as syntactic data of the web services to achieve the hybrid cognition. This proposed cognitive approach uses the principals from the machine learning, measures of semantic relatedness and information retrieval where the cognitive information from the WordNet based Omiotis measure of semantic relatedness is merged with the syntactic service profiles and further these semantically enriched service vectors are passed to the supervised learning algorithms to achieve the decision support for the discovery and selection of relevant services. Empirical evaluation of the proposed approach implemented on OWL-X data set has been presented and a comparison of two different supervised classifiers has been made.","2379-1667;23791667","CD-ROM:978-1-4799-3563-5; Electronic:978-1-4799-3564-2; POD:978-1-4799-3565-9","10.1109/CogSIMA.2014.6816543","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816543","Machine learning;Measures of Semantic Relatedness;OWL-S;Semantic Web Service Discovery;Text Mining","Conferences;Decision support systems","Web services;cognitive systems;information retrieval;knowledge representation languages;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;semantic Web","OWL-X data set;Universal Description Discovery and Integration repositories;Web service discovery;Web service selection;WordNet based Omiotis measure;cognitive approach;cognitive information;decision support;explicit semantic information;human-machine collaboration;hybrid cognition;hybrid cognitive model;implicit semantic information;information retrieval;machine learning;semantic model;semantic relatedness;semantic service discovery;semantically enriched service vectors;service classification;supervised classifier comparison;supervised learning algorithm;syntactic data;syntactic service profile","","1","","27","","","3-6 March 2014","","IEEE","IEEE Conference Publications"
"CrowdCleaner: Data cleaning for multi-version data on the web via crowdsourcing","Y. Tong; C. C. Cao; C. J. Zhang; Y. Li; L. Chen","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","1182","1185","Multi-version data is often one of the most concerned information on the Web since this type of data is usually updated frequently. Even though there exist some Web information integration systems that try to maintain the latest update version, the maintained multi-version data usually includes inaccurate and invalid information due to the data integration or update delay errors. In this demo, we present CrowdCleaner, a smart data cleaning system for cleaning multi-version data on the Web, which utilizes crowdsourcing-based approaches for detecting and repairing errors that usually cannot be solved by traditional data integration and cleaning techniques. In particular, CrowdCleaner blends active and passive crowdsourcing methods together for rectifying errors for multi-version data. We demonstrate the following four facilities provided by CrowdCleaner: (1) an error-monitor to find out which items (e.g., submission date, price of real estate, etc.) are wrong versions according to the reports from the crowds, which belongs to a passive crowdsourcing strategy; (2) a task-manager to allocate the tasks to human workers intelligently; (3) a smart-decision-maker to identify which answer from the crowds is correct with active crowdsourcing methods; and (4) a whom-to-ask-finder to discover which users (or human workers) should be the most credible according to their answer records.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816736","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816736","","Cleaning;Data integration;Delays;Entropy;Maintenance engineering;Monitoring;Uncertainty","Internet;data integration;information retrieval","CrowdCleaner;Web information integration systems;crowdsourcing methods;crowdsourcing-based approach;data integration error;error-monitor facility;multiversion data;passive crowdsourcing strategy;smart data cleaning system;smart-decision-maker facility;task-manager facility;update delay error;whom-to-ask-finder facility","","14","","11","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Knowledge Management Strategy and Structure in Service Sector","V. P. Gulati; S. Srivastava","Tata Consultancy Services, Hyderabad, India","2014 International Conference on Computational Science and Computational Intelligence","20140529","2014","1","","334","338","A dominant, fast growing chunk of global GDP, the service sector is unique marked by intangibility, simultaneous production and consumption of the ""product"" and reliance on employee skills. Talent and skills are the base for this sector and the challenge lies in knowledge retention and management. particularly, IT services. Four types of IT employees are identified -- knowledge absorbers, knowledge retainers, knowledge sharers and knowledge gurus. Attrition of knowledge sharers and gurus means extensive knowledge loss. Knowledge management strategy and structure are critical. The paper presents the evolution of collaborative KM hinging on change management processes, in a large Indian IT multinational. The paper also recommends implementation of a ""Data Index"" to facilitate easy and efficient information management and retrieval.","","Electronic:978-1-4799-3010-4; POD:978-1-4799-3011-1; USB:978-1-4799-3009-8","10.1109/CSCI.2014.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822131","Data Index;Knowledge Management;Service Sector","Collaboration;Companies;Indexes;Industries;Knowledge management","information management;information retrieval;knowledge management;personnel;service industries","GDP;Gross Domestic Product;IT employees;Indian IT multinational;change management process;collaborative KM;data index;employee skills;information management;information retrieval;information technology;knowledge absorbers;knowledge gurus;knowledge loss;knowledge management strategy;knowledge management structure;knowledge retainers;knowledge retention;knowledge sharers;product consumption;product production;service sector","","0","","6","","","10-13 March 2014","","IEEE","IEEE Conference Publications"
"Integration of semantic search technique and pervasive computing","A. Chopra; S. Tokas; S. Sinha; V. K. Panchal","IITM, GGSIP Univ., Delhi, India","2014 International Conference on Computing for Sustainable Global Development (INDIACom)","20140612","2014","","","283","285","The main goal of pervasive computing is to provide services that can be used by the user in the given context with minimal user intervention. To support such an environment services or the applications in the environment should be able to interact seamlessly, with the other devices or applications present in the environment, to gather relevant information in current context. Main challenge is devices are resource constrained. To support such systems, so that they can utilize resources of other sensor nodes/mobile devices, I propose a system that integrates semantic search in pervasive computing. Information associated with mobile devices and sensor nodes is used in a way that results in minimal inexact matching, efficient and improved service discovery.","","CD-ROM:978-93-80544-11-3; Electronic:978-93-80544-12-0; POD:978-1-4799-2278-9","10.1109/IndiaCom.2014.6828144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6828144","RDF;pervasive computing;semantic search;service discovery","Context;Decision support systems;Mobile handsets;Pervasive computing;Resource description framework;Semantics;Wireless sensor networks","information retrieval;ubiquitous computing","information gathering;mobile devices;pervasive computing;resource utilization;semantic search technique;sensor nodes;service discovery;user intervention","","0","","7","","","5-7 March 2014","","IEEE","IEEE Conference Publications"
"Ground-Truth Production in the Transcriptorium Project","B. Gatos; G. Louloudis; T. Causer; K. Grint; V. Romero; J. A. S√°nchez; A. H. Toselli; E. Vidal","Inst. of Inf. & Telecommun., Nat. Centre for Sci. Res. Demokritos, Athens, Greece","2014 11th IAPR International Workshop on Document Analysis Systems","20140612","2014","","","237","241","Tran Scriptorium is a 3-years project that aims to develop innovative, cost-effective solutions for the indexing, search and full transcription of historical handwritten document images, using Handwritten Text Recognition (HTR) technology. The production of ground-truth (GT) of a dataset of handwritten document images is among the first tasks. We address novel approaches for the faster production of this GT based on crowd-sourcing and on prior-knowledge methods. We also address here a novel low-cost semi-supervised procedure for obtaining pairs of correct line-level aligned detected/extracted text line images and text line transcripts, specially suitable for training models of the HTR technology employed in Tran Scriptorium.","","Electronic:978-1-4799-3243-6; POD:978-1-4799-1663-4","10.1109/DAS.2014.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831005","Document Image Processing;Handwritten Text Recognition Technology;alignment between ground-truth transcripts and text line images;tranScriptorium Union Europe Project","Hidden Markov models;Image segmentation;Layout;Production;Standards;Training","document image processing;handwritten character recognition;indexing;information retrieval","HTR technology;Transcriptorium Project;crowd-sourcing;ground-truth production;handwritten text recognition;historical handwritten document image full transcription;historical handwritten document image indexing;historical handwritten document image searching;text line image detection;text line image extraction;text line transcripts","","2","","12","","","7-10 April 2014","","IEEE","IEEE Conference Publications"
"Benchmarking cloud-based tagging services","T. Malik; K. Chard; I. Foster","Argonne Nat. Lab., Univ. of Chicago, Chicago, IL, USA","2014 IEEE 30th International Conference on Data Engineering Workshops","20140519","2014","","","231","238","Tagging services have emerged as a useful and popular way to organize data resources. Despite popular interest, an efficient implementation of tagging services is a challenge since highly dynamic schemas and sparse, heterogeneous attributes must be supported within a shared, openly writable database. NoSQL databases support dynamic schemas and sparse data but lack efficient native support for joins that are inherent to query and search functionality in tagging services. Relational databases provide sufficient support for joins, but offer a multitude of options to manifest dynamic schemas and tune sparse data models, making evaluation of a tagging service time consuming and painful. In this case-study paper, we describe a benchmark for tagging services, and propose benchmarking modules that can be used to evaluate the suitability of a database for workloads generated from tagging services. We have incorporated our modules as part of OLTP-Bench, a cloud-based benchmarking infrastructure, to understand performance characteristics of tagging systems on several relational DBMSs and cloud-based database-as-a-service (DBaaS) offerings.","","Electronic:978-1-4799-3481-2; POD:978-1-4799-3482-9","10.1109/ICDEW.2014.6818331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818331","","Benchmark testing;Data models;Indexes;Mathematical model;Relational databases;Tagging","SQL;cloud computing;information retrieval;relational databases","NoSQL databases;OLTP-Bench;benchmarking cloud-based tagging services;cloud-based database-as-a-service;data resources;heterogeneous attributes;relational DBMS;relational databases","","4","","19","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Incremental discovery of prominent situational facts","A. Sultana; N. Hassan; C. Li; J. Yang; C. Yu","Univ. of Texas at Arlington, Arlington, TX, USA","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","112","123","We study the novel problem of finding new, prominent situational facts, which are emerging statements about objects that stand out within certain contexts. Many such facts are newsworthy-e.g., an athlete's outstanding performance in a game, or a viral video's impressive popularity. Effective and efficient identification of these facts assists journalists in reporting, one of the main goals of computational journalism. Technically, we consider an ever-growing table of objects with dimension and measure attributes. A situational fact is a ‚Äúcontextual‚Äù skyline tuple that stands out against historical tuples in a context, specified by a conjunctive constraint involving dimension attributes, when a set of measure attributes are compared. New tuples are constantly added to the table, reflecting events happening in the real world. Our goal is to discover constraint-measure pairs that qualify a new tuple as a contextual skyline tuple, and discover them quickly before the event becomes yesterday's news. A brute-force approach requires exhaustive comparison with every tuple, under every constraint, and in every measure subspace. We design algorithms in response to these challenges using three corresponding ideas-tuple reduction, constraint pruning, and sharing computation across measure subspaces. We also adopt a simple prominence measure to rank the discovered facts when they are numerous. Experiments over two real datasets validate the effectiveness and efficiency of our techniques.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816644","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816644","","Algorithm design and analysis;Context;Databases;Extraterrestrial measurements;Games;Lattices;Media","data mining;information retrieval;learning (artificial intelligence)","brute-force approach;computational journalism;conjunctive constraint;constraint pruning;constraint-measure pairs;contextual skyline tuple;dimension attributes;fact identification;historical tuple;incremental discovery;measure attributes;prominent situational facts;sharing computation;tuple reduction","","1","","14","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Handoff prediction for data caching in mobile Content Centric Network","Pengcheng Jiang; Yuehui Jin; Tan Yang; J. Geurts; Yaning Liu; J. C. Point","State Key Lab. of Network & Switching Technol., Beijing Univ. of Posts & Telecommun., Beijing, China","2013 15th IEEE International Conference on Communication Technology","20140526","2013","","","691","696","As real-time mobile multimedia becomes more and more popular in modern life, Quality of Service (QoS) has drawn more and more attention. IEEE 802.11 has been widely deployed to provide broadband wireless network access due to its low cost, simplicity and high bandwidth capacity. However, its poor network availability and frequent network disconnection in a mobile scenario challenge real-time services. This paper presents a caching and pre-fetching mechanism based on the usage of Content Centric Network (CCN) in mobile environments. The idea is to anticipate disconnections and prefetch the content that a user is expected to access in the near future. Hence, when to trigger the caching and pre-fetching module is an essential part of the objective. This paper focuses on the design and implementation of a disconnection predictor algorithm. The method is to predict the time before a terminal disconnects from an Access Point (AP) by monitoring Received Signal Strength Indicator (RSSI). This paper evaluates and compares the used algorithms by experiments.","","Electronic:978-1-4799-0077-0; POD:978-1-4799-0076-3","10.1109/ICCT.2013.6820463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820463","CCN;DASH;Quality of Service;RSSI;caching;prediction","IEEE 802.11 Standards;Mathematical model;Mobile communication;Mobile computing;Predictive models;Time series analysis;Wavelet transforms","broadband networks;cache storage;information retrieval;mobility management (mobile radio);multimedia communication;quality of service;radio access networks;telecommunication network reliability;wireless LAN","IEEE 802.11;QoS;RSSI monitoring;access point;broadband wireless network access;content data prefetching mechanism;data caching;disconnection predictor algorithm;frequent network disconnection;handoff prediction;mobile content centric network;network availability;quality of service;real-time mobile multimedia;real-time services;received signal strength indicator;terminal disconnection","","0","","14","","","17-19 Nov. 2013","","IEEE","IEEE Conference Publications"
"Combining information extraction and human computing for crowdsourced knowledge acquisition","S. K. Kondreddi; P. Triantafillou; G. Weikum","Database & Inf. Syst. Group, Max Planck Inst. for Inf., Saarbrucken, Germany","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","988","999","Automatic information extraction (IE) enables the construction of very large knowledge bases (KBs), with relational facts on millions of entities from text corpora and Web sources. However, such KBs contain errors and they are far from being complete. This motivates the need for exploiting human intelligence and knowledge using crowd-based human computing (HC) for assessing the validity of facts and for gathering additional knowledge. This paper presents a novel system architecture, called Higgins, which shows how to effectively integrate an IE engine and a HC engine. Higgins generates game questions where players choose or fill in missing relations for subject-relation-object triples. For generating multiple-choice answer candidates, we have constructed a large dictionary of entity names and relational phrases, and have developed specifically designed statistical language models for phrase relatedness. To this end, we combine semantic resources like WordNet, ConceptNet, and others with statistics derived from a large Web corpus. We demonstrate the effectiveness of Higgins for knowledge acquisition by crowdsourced gathering of relationships between characters in narrative descriptions of movies and books.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816717","","Context;Dictionaries;Encyclopedias;Engines;Games;Motion pictures;Semantics","computational linguistics;human factors;information retrieval;knowledge acquisition;semantic networks;very large databases","HC;Higgins system architecture;IE;KBs;automatic information extraction;crowd-based human computing;crowdsourced knowledge acquisition;entity names;multiple-choice answer candidate generation;phrase relatedness;relational phrases;semantic resources;statistical language models;subject-relation-object triples;very large knowledge bases","","5","","55","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Hybrid Multi-cloud Data Security (HMCDS) Model and Data Classification","M. A. Zardari; L. T. Jung; M. N. B. Zakaria","CIS Dept., Univ. Teknolo gi PETRONAS, Tronoh, Malaysia","2013 International Conference on Advanced Computer Science Applications and Technologies","20140619","2013","","","166","171","Cloud computing is one of the most exciting paradigm shifts in distributed computing. Cloud computing is being widely used due to its readily available services at low cost. When the number of cloud users increase this may subsequently lead to data security and privacy threats. Data confidentiality and efficient data retrieval are major issues which block users to adopt cloud computing. The focus of this paper is data confidentiality and efficient data retrieval issues in cloud computing. The data classification and cloud model are proposed to overcome data confidentiality and efficient data retrieval issues. In this paper we propose a new cloud model, i.e., the Hybrid Multi-Cloud Data Security (HMCDS) model with data classification. The model is based on multi-cloud, different clusters and data classification. Two levels of security are considered, i.e., model and data classification based levels.","","Electronic:978-1-4799-2758-6; POD:978-1-4799-2759-3","10.1109/ACSAT.2013.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6836569","Cloud Computing;Data Classification;Data Security;Hybrid Multi-cloud;Multi-Cloud","Computer science","cloud computing;data privacy;information retrieval;pattern classification;security of data","HMCDS model;cloud computing;data classification;data confidentiality;data privacy;data retrieval;data security;distributed computing;hybrid multicloud data security","","1","","26","","","23-24 Dec. 2013","","IEEE","IEEE Conference Publications"
"Protecting Outsourced Data Privacy with Lifelong Policy Carrying","X. Wang; Q. Yong; Y. Dai; J. Ren; Z. Hang","Dept. of Comput. Sci., Xi'an Jiaotong Univ., Xi'an, China","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","20140612","2013","","","896","905","The lack of remote data access control capability and the loss of remote data access trail make data owners hesitate when they have to outsource their sensitive data to remote third party platform. The data owners have no choice but to trust the remote third party software before they ship their data to the remote environment. In this paper we propose a new set of guiding principles for protecting outsourced data with data owner specified policy. Compared with traditional access control mechanism equipped by service providers, which can be regarded as the first layer of confinement, we aim to provide data owner a second layer of confinement on data propagation and access without modifying existing data-access applications. This is achieved by two critical techniques: (1) a policy-carrying data model that binds customer data with logical data access policy, and (2) a remote application running environment which acts as data access verifier and propagation controller. To demonstrate the feasibility of this approach, we build the logical data propagation and access control (LDPAC) system, in which a human-readable policy abstract is provided to formulate data propagation and access. When policy-carrying data is shipped to remote service provider, the per-node LDPAC verifier module conducts the logical proof checking to mediate sensitive data access. Meanwhile, the authorized application which intends to access sensitive data is forced to run in an application container, in order to prevent sensitive data leakage through in-memory data breaches. Our evaluation shows that LDPAC system adds reasonable performance overhead for the remote sensitive data access and propagation mediation, while preserving the original service deployment.","","Electronic:978-0-7695-5088-6; POD:978-1-4799-0973-5","10.1109/HPCC.and.EUC.2013.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832010","access and propagation control;data outsourcing;data privacy;policy-carrying data model","Access control;Containers;Data models;History;Servers;Software","data protection;information retrieval;outsourcing;theorem proving;trusted computing","LDPAC system;access control mechanism;data owner specified policy;human-readable policy abstract;in-memory data breaches;lifelong policy carrying;logical data propagation and access control system;logical proof checking;outsourced data privacy protection;per-node LDPAC verifier module;policy-carrying data;policy-carrying data model;remote data access control capability;remote sensitive data access and propagation mediation;remote service provider;remote third party platform;remote third party software","","2","","29","","","13-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Analyzing the Political Landscape of 2012 Korean Presidential Election in Twitter","M. Song; M. C. Kim; Y. K. Jeong","","IEEE Intelligent Systems","20140612","2014","29","2","18","26","Social media is changing existing information behavior by giving users access to real-time online information channels without the constraints of time and space. Social media, therefore, has created an enormous data analysis challenge for scientists trying to keep pace with developments in their field. Most previous studies have adopted broad-brush approaches that typically result in limited analysis possibilities. To address this problem, we applied text-mining techniques to Twitter data related to the 2012 Korean presidential election. We use three primary techniques: topic modeling to track changes in topical trends, mention-direction-based user network analysis, and term co-occurrence retrieval for further content analysis. Our study reveals that Twitter could be a useful way to detect and trace the advent of and changes in social issues, while analyzing mention-based user networks could show different aspects of user behaviors.","1541-1672;15411672","","10.1109/MIS.2014.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832880","2012 Korean presidential election;Big Data;database management;intelligent systems;mention-based network analysis;real-time Twitter trend mining;social media mining;temporal topic modeling;text mining","Data mining;Market research;Media;Moon;Nominations and elections;Real-time systems;Twitter","data mining;information retrieval;politics;social networking (online);text analysis","2012 Korean Presidential Election;Twitter;content analysis;mention-direction-based user network analysis;political landscape;real-time online information channel;social media;term cooccurrence retrieval;text-mining technique;topic modeling;topical trends","","5","","18","","","Mar.-Apr. 2014","","IEEE","IEEE Journals & Magazines"
"Answering Why-Not Questions on Top-K Queries","Z. He; E. Lo","Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong","IEEE Transactions on Knowledge and Data Engineering","20140602","2014","26","6","1300","1315","After decades of effort working on database performance, the quality and the usability of database systems have received more attention in recent years. In particular, the feature of explaining missing tuples in a query result, or the so-called ‚Äúwhy-not‚Äù questions, has recently become an active topic. In this paper, we study the problem of answering why-not questions on top-k queries. Our motivation is that we know many users love to pose those kinds of queries when they are making multi-criteria decisions. However, they would also want to know why if their expected answers do not show up in the query results. In this paper, we develop algorithms to answer such why-not questions efficiently. Case studies and experimental results show that our algorithms are able to return high quality explanations efficiently.","1041-4347;10414347","","10.1109/TKDE.2012.158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268270","Database Usability;Dominating Query;Top-k Query;Why-Not;Why-Not Questions;dominating;top-k;usability","Algorithm design and analysis;Database systems;Quadratic programming;Usability","decision making;query processing;question answering (information retrieval)","database performance;database systems;multicriteria decision making;top-K queries;why-not question answering","","3","","22","","20120814","June 2014","","IEEE","IEEE Journals & Magazines"
"A Digital Archive Data Preservation Management System Using IRODS Architecture","T. s. Hsu; H. W. Wei; Y. P. Huang; T. Y. Chen; T. T. Yeh; M. J. Sun; Y. C. Cheng; W. K. Shih","Inf. Sci. Acad. Sinica, Taiwan","2014 International Conference on Computational Science and Computational Intelligence","20140529","2014","2","","281","284","Currently, the amount of data is huge. Not only is the quantity of data growing in size, it is also becoming much more diverse and complex, significantly complicating the issues around its creation. It is increasingly important to improve and maintain infrastructure services for a long time. Therefore, this study uses an automated approach in which digital policies and strategies are represented as rules, which are implemented in data grids that use iRODS middleware. The attempt of using iRODS in this study is to discover the Sinica Data Preservation System (SIDPS) architecture. The SIDPS management platform using iRODS architecture offers better control of the environment and helps to deal with systematic crises, increases efficiency and allows more effective use of systematic resources.","","Electronic:978-1-4799-3010-4; POD:978-1-4799-3011-1; USB:978-1-4799-3009-8","10.1109/CSCI.2014.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822349","Data Preservation Management;Data grid;iRODS","Computer architecture;Computers;Distributed databases;Educational institutions;Monitoring;Organizations;Synchronization","digital preservation;grid computing;information retrieval systems;middleware;storage management","SIDPS architecture;SIDPS management platform;Sinica data preservation system architecture;automated approach;data grids;digital archive data preservation management system;digital policies;digital strategies;iRODS architecture;iRODS middleware;infrastructure services","","0","","12","","","10-13 March 2014","","IEEE","IEEE Conference Publications"
"The research on topic detection of microblog based on TC-LDA","Gaofei Ge; Liping Chen; Junping Du","Beijing Univ. of Posts & Telecommun., Beijing, China","2013 15th IEEE International Conference on Communication Technology","20140526","2013","","","722","727","With the rapid development of microblog, the research of topic detection has been paid more attention, which has begun to transfer from the traditional news media to microblog. However, compared with the traditional fields where topic detection applied, the microblogging data is written informally and the structure of that is not rigorous, which will bring great difficulties. In the process of topic detection, there will be lots of noise information extracted as the topics if using the traditional methods. Therefore, based on the Latent Dirichlet Allocation (LDA) model, the Topic-Coreterms Latent Dirichlet Allocation (TC-LDA) model for topic detection is proposed. With considering the microblogging features, the model increases a layer of background model to reduce the noise in microblogging data. The experiment shows that through the method of extending, the model can obtain good results and improve the generalization performance in the same environment.","","Electronic:978-1-4799-0077-0; POD:978-1-4799-0076-3","10.1109/ICCT.2013.6820469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820469","LDA;Microblog;Noise;Topic detection","Computational modeling;Equations;Feature extraction;Mathematical model;Noise;Probability distribution;Training","Web sites;information retrieval","TC-LDA;Topic-Coreterms Latent Dirichlet Allocation model;microblogging data;noise information extraction;topic detection","","0","","17","","","17-19 Nov. 2013","","IEEE","IEEE Conference Publications"
"An efficient massive evidence storage and retrieval scheme in encrypted database","Ruoqing-Zhang; Zehui-Li; Yatao-Yang; Zichen-Li","Commun. Eng. Inst., Xidian Univ., Xian, China","2013 International Conference on Information and Network Security (ICINS 2013)","20140605","2013","","","1","6","In this paper, the problem is described which of storing massive digital evidence and preventing potential information leaks in forensics. The strategy of cloud encrypted database is therefore to be proposed. Existing encrypted database frameworks and solutions do not provide a satisfactory result to solve the problem. They either cause potential information leaks or have unacceptable data redundancy. We propose an efficient encrypted database model adopting initialization vector transfer and numerical order replacement. Experimental results show that the ciphertext retrieval speed can be significantly matched with what of plaintext.","","Electronic:978-1-84919-729-8","10.1049/cp.2013.2469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6826018","Digital forensics;ciphertext retrieval;cloud storage;encrypted database","","cloud computing;cryptography;database management systems;digital forensics;information retrieval;information storage;vectors","ciphertext retrieval speed;cloud encrypted database;data redundancy;forensics;initialization vector transfer;massive digital evidence storage;numerical order replacement;potential information leaks","","0","","","","","22-24 Nov. 2013","","IET","IET Conference Publications"
"Efficient search on encrypted data using bloom filter","S. K. Pal; P. Sardana; A. Sardana","SAG-Sci. Anal. Group, Defence R & D Organ., Delhi, India","2014 International Conference on Computing for Sustainable Global Development (INDIACom)","20140612","2014","","","412","416","Efficient and secure search on encrypted data is an important problem in computer science. Users having large amount of data or information in multiple documents face problems with their storage and security. Cloud services have also become popular due to reduction in cost of storage and flexibility of use. But there is risk of data loss, misuse and theft. Reliability and security of data stored in the cloud is a matter of concern, specifically for critical applications and ones for which security and privacy of the data is important. Cryptographic techniques provide solutions for preserving the confidentiality of data but make the data unusable for many applications. In this paper we report a novel approach to securely store the data on a remote location and perform search in constant time without the need for decryption of documents. We use bloom filters to perform simple as well advanced search operations like case sensitive search, sentence search and approximate search.","","CD-ROM:978-93-80544-11-3; Electronic:978-93-80544-12-0; POD:978-1-4799-2278-9","10.1109/IndiaCom.2014.6828170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6828170","Approximate Search and Bloom Filter;Cloud Computing;Encrypted Search","Cloud computing;Cryptography;Filtering algorithms;Indexes;Information filters;Servers","cloud computing;cost reduction;cryptography;data structures;document handling;information retrieval","Bloom filter;approximate search;case sensitive search;cloud services;computer science;cryptographic techniques;data loss;data misuse;data theft;document decryption;efficient encrypted data search;search operations;sentence search;storage cost reduction","","1","","38","","","5-7 March 2014","","IEEE","IEEE Conference Publications"
"iTag: Incentive-based tagging","S. Lei; X. S. Yang; L. Mo; S. Maniu; R. Cheng","Dept. of Comput. Sci., Univ. of Hong Kong, Hong Kong, China","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","1186","1189","In social tagging systems, such as Delicious<sup>1</sup> and Flickr<sup>2</sup>, users are allowed to annotate resources (e.g., Web URLs and images) with textual descriptions called tags. Tags have proven to be invaluable building blocks in algorithms for searching, mining and recommending resources. In practice, however, not all resources receive the same attention from users, and as a result, most tags are added to the few highly-popular resources, while most of the resources receive few tags. Crucially, this incomplete tagging on resources can severely affect the effectiveness of all tagging applications. We present iTag, an incentive-based tagging system, which aims at improving tagging quality of resources, by incentivizing taggers under budget constraints. Our system is built upon traditional crowdsourcing systems such as Amazon Mechanical Turk (MTurk). In our demonstration, we will show how our system allows users to use simple but powerful strategies to significantly improve the tagging quality of resources.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816737","","Collaboration;Facebook;Monitoring;Noise measurement;Real-time systems;Resource management;Tagging","information retrieval systems","Amazon Mechanical Turk;Delicious;Flickr;MTurk;crowdsourcing systems;iTag system;incentive-based tagging system;resource annotation;resource mining;resource quality;resource recommendation;resource searching;social tagging systems;textual descriptions","","0","","6","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Boosting audio chord estimation using multiple classifiers","M. Pesek; A. Leonardis; M. Marolt","Lab. for Comput. Graphics & Multimedia, Univ. of Ljubljana, Ljubljana, Slovenia","IWSSIP 2014 Proceedings","20140619","2014","","","107","110","The paper addresses the task of automatic audio chord estimation using stacked generalization of multiple classifiers over Hidden Markov model (HMM) estimators. We evaluated two feature types for chord estimation: a new compositional hierarchical model and standard chroma feature vectors. The compositional hierarchical model is presented as an alternative deep learning approach. Both feature types are further modelled with two separate Hidden Markov models (HMMs) in order to estimate chords in music recordings. Further, a binary decision tree and support vector machine are proposed binding the HMM estimations into a new feature vector. The additional stacking of the classifiers provides a classification boost by 17.55% with a binary decision tree and and 21.96% using the support vector machine.","2157-8672;21578672","Electronic:978-953-184-191-7; POD:978-1-4799-2602-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6837642","audio chord estimation;compositional hierarchical model;deep learning;stacking generalization","Estimation;Hidden Markov models;Silicon carbide","audio signal processing;decision trees;hidden Markov models;information retrieval;learning (artificial intelligence);music;signal classification;support vector machines","HMM estimators;alternative deep learning approach;audio chord estimation;binary decision tree;boosting;classification boost;classifier stacking;compositional hierarchical model;hidden Markov model;multiple classifiers;music recordings;standard chroma feature vectors;support vector machine","","0","","13","","","12-15 May 2014","","IEEE","IEEE Conference Publications"
"An Automatic Tag Recommendation Algorithm for Micro-blogging Users","X. Wang; S. Li; X. Zou; R. Chen; B. Zhou","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","398","401","Online social networks such as Sina Weibo micro-blogging website allow user to annotate himself (or herself) using tags, which describe the characteristics of the user. Many researches have been done on photos, films, commodities but rare researches on users. In this paper, we try to recommend tags for users who can communicate directly with other users. Our method is based on interactive relations between users and is low cost. We present and evaluate tag recommendation method to support the user self-annotation task by recommending a set of tags for users. Experiment evaluations on real and large Sina Weibo dataset which contains more than 140 million users and distributed processing framework Hadoop shows that our method can effectively recommend relevant tags to users.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835627","Micro-blogging;Social Network;Tag Recommendation;User Tags","Collaboration;Computers;Equations;Mathematical model;Social network services;Tagging;Web sites","information retrieval;social networking (online)","Sina Weibo microblogging Web site;automatic tag recommendation algorithm;distributed processing framework Hadoop;online social network;user self-annotation task","","0","","12","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Recommending Items via Interest-Similar Cluster Identification in Online Social Networks","J. Ma; H. Chen; H. xu","Sci. & Technol. on Inf. Syst. Eng. Lab., Nat. Univ. of Defense Technol., Changsha, China","2013 Third International Conference on Instrumentation, Measurement, Computer, Communication and Control","20140623","2013","","","331","334","Social network has played a more and more important role in recommender system as users are strongly influenced by their friends. But the friend lists of a user are always hidden for privacy concern. Even her friend lists are accessible, there still exist many potential friends who have similar interest with her but she doesn't know. How to predict the friendship she knows and does not know when the friend lists are hidden? How to identify her interest? To address the above questions, we first propose a Friendship prediction approach mainly based on the analysis of her group information. Secondly, we propose a graph model which simultaneously models user's friendship and interest. Then we propose an unbiased random walk strategy for item recommendation via the graph model. Finally, we evaluate our approach on large scale real world data from Cite Like and last.fm data set, the results show that the performance of our algorithms is very good in implementation.","","Electronic:978-0-7695-5122-7; POD:978-1-4799-1393-0","10.1109/IMCCC.2013.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840465","Friendship Prediction;Interest-similar Cluster;Online Social Network;Recommender System","Collaboration;Data mining;Educational institutions;Prediction algorithms;Recommender systems;Social network services","graph theory;information retrieval;pattern clustering;random processes;recommender systems;social networking (online)","Cite Like;friend lists;friendship prediction;graph model;group information analysis;interest-similar cluster identification;item recommendation;large scale real world data;last.fm data set;online social networks;privacy concern;recommender system;unbiased random walk strategy;user friendship modeling;user interest modeling","","0","","17","","","21-23 Sept. 2013","","IEEE","IEEE Conference Publications"
"Mobile game recommendation using touch gestures","H. T. Yang; D. Y. Chen; Y. X. Hong; K. T. Chen","Inst. of Inf. Sci., Acad. Sinica, Taipei, Taiwan","2013 12th Annual Workshop on Network and Systems Support for Games (NetGames)","20140526","2013","","","1","6","Today, any Internet user can find out and download more than one hundred thousands of games on mobile app marketplaces; nevertheless, how to pick the best games out of the large pool without spending much time on tryout is very challenging. The common rank list and social recommendation approaches for discovering new games do not work well when a player wants to search for games with a particular gameplay, or he may want to find out all the slow-paced games suitable for his grandparents. There is currently no feasible way to do that because these requirements cannot be formulated in a proper text search query. In this paper, we propose a scheme that can discover mobile games with similar gameplay based on players' touch gestures while playing a game. We select 22 mobile games from 5 genres and recorded 94 touch gesture traces from 5 subjects. The evaluation results show that 1) touch gestures can serve robust signatures of gameplay as the key traits of the touch gestures from different subjects remain consistent; 2) our scheme can give reasonably accurate recommendations of similar games simply based on touch gestures.","2156-8138;21568138","Electronic:978-1-4799-2961-0; POD:978-1-4799-2962-7","10.1109/NetGames.2013.6820609","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820609","","Feature extraction;Games;Land mobile radio;Presses;Rhythm;Robustness;Tiles","computer games;gesture recognition;haptic interfaces;information retrieval;mobile computing;recommender systems","game searching;gameplay signature;mobile app marketplace;mobile game discovery;mobile game recommendation;new game discovery;player touch gestures;rank list;social recommendation;touch gesture traces","","0","","13","","","9-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"Truth, lies, and data: Credibility representation in data analysis","J. Schaffer; T. Abdelzaher; D. Jones; T. H√∂llerer; C. Gonzalez; J. Harman; J. O'Donovan","Dept. of Comput. Sci., Univ. of California Santa Barbara, Santa Barbara, CA, USA","2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)","20140519","2014","","","28","34","The web has evolved in a scale free manner, with available information about different entities developing in different forms, different locations, and at massive scales. This paper addresses the cognitive limitations that information analysts typically experience as they approach the boundaries where automated analysis algorithms are sorely needed. An experiment is conducted to explore information analysts' interactions with recommendations from an automated fact-finder algorithm during the task of answering questions in a fictional humanitarian aid delivery scenario. An experiment (N=285) is performed using three increasingly complex user interfaces, with and without the presence of the automated recommendations. Results show that in the best performing group, interaction with the fact-finder recommendations was 47 percent greater than the worst performing group.","2379-1667;23791667","CD-ROM:978-1-4799-3563-5; Electronic:978-1-4799-3564-2; POD:978-1-4799-3565-9","10.1109/CogSIMA.2014.6816536","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816536","","Algorithm design and analysis;Complexity theory;Computational modeling;Conferences;Reliability;User interfaces;Visualization","Internet;data analysis;data mining;information retrieval;recommender systems","World Wide Web;automated analysis algorithm;automated fact-finder algorithm;cognitive limitation;credibility representation;data analysis;fictional humanitarian aid delivery;user interface","","0","","19","","","3-6 March 2014","","IEEE","IEEE Conference Publications"
"Kondenzer: Exploration and visualization of archived social media","O. Alonso; K. Khandelwal","Microsoft Corp., Mountain View, CA, USA","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","1202","1205","Modern social networks such as Twitter provide a platform for people to express their opinions on a variety of topics ranging from personal to global. While the factual part of this information and the opinions of various experts are archived by sources such as Wikipedia and reputable news articles, the opinion of the general public is drowned out in a sea of noise and ‚Äúun-interesting‚Äù information. In this demo we present Kondenzer - an offline system for condensing, archiving and visualizing social data. Specifically, we create digests of social data using a combination of filtering, duplicate removal and efficient clustering. This gives a condensed set of high quality data which is used to generate facets and create a collection that can be visualized using the PivotViewer control.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816741","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816741","","Companies;Data visualization;Feature extraction;Media;Noise;Twitter","data visualisation;information retrieval systems;social networking (online)","Kondenzer;PivotViewer control;archived social media exploration;archived social media visualization;duplicate removal;efficient clustering;high quality data;social data archiving;social data condensing;social data visualization;social networks","","0","","6","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Information Mining on the Web: E-business Application","H. Taherdoost; J. Hosseinkhani","Adv. Inf. Sch., Univ. Teknol. Malaysia, Kuala Lumpur, Malaysia","2013 International Conference on Advanced Computer Science Applications and Technologies","20140619","2013","","","500","503","At the recent development in the application of Information Communication Technologies (ICT), Internet has been at the forefront. Since, people have been becoming more interested in the Internet and Electronic Businesses (e-business), a growing number of organizations have been already entered or planning to move into e-business. In e-business environment, search engines play an important role because they are efficient methods for customers to find their required and requested products quick. This paper aims to propose a framework to extract the useful information from the business related websites contents that can support search engines to find appropriate services and products.","","Electronic:978-1-4799-2758-6; POD:978-1-4799-2759-3","10.1109/ACSAT.2013.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6836633","Application;Crowler;E-business;Framework;Information Mining;Search Engine;Web Mining","Business;Crawlers;Data models;Internet;Search engines;Web mining","Internet;Web sites;data mining;electronic commerce;information retrieval;search engines","ICT;Information Communication Technologies;Internet;Web;business related Website contents;e-business application;electronic business;information extraction;information mining;search engines","","0","","24","","","23-24 Dec. 2013","","IEEE","IEEE Conference Publications"
"Extracting important tweets of a user: A rough set approach","A. K. Singh; D. Bansal; I. Bansal; S. Chakraverty","Netaji Subhas Inst. of Technol., Univ. of Delhi, New Delhi, India","Confluence 2013: The Next Generation Information Technology Summit (4th International Conference)","20140616","2013","","","209","215","Microblogs such as Twitter are user driven content generation systems that allow users to share short text messages on a variety of topics such as daily conversations, news, personal updates and URLs of interest. As users continue to post, their past tweets generate a history of the shared events, opinions and reactions. Some of these tweets convey information that are of mass appeal and evoke more discussion. These tweets have a stronger social impact and may be considered to be more important than others from the authors' perspective. Authors will be greatly benefitted if an automated mechanism is developed to categorize their posted tweets and extract the most important ones. In this paper, we identify the parameters that reflect the impact of a tweet for example, the length of time during which it sustained listeners' interest (time impact). We employ topic detection techniques to determine the semantic interrelationships between tweets and retrieve the underlying theme in the thread of discussion. We propose a Rough Set based rules generation technique to sieve out important tweets along a user's timeline and demonstrate the results.","","Electronic:978-1-84919-846-2","10.1049/cp.2013.2317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832332","Importance of Tweet;Lexical Semantics;Retweet;Rough Sets;Twitter","","information retrieval;knowledge acquisition;learning (artificial intelligence);rough set theory;social networking (online)","Twitter;URLs;microblogs;rough set approach;rough set based rules generation technique;short text messages;topic detection techniques;tweet extraction;user driven content generation systems","","0","","","","","26-27 Sept. 2013","","IET","IET Conference Publications"
"An arabic ontology-based learning system for children with intellectual challenges","Abdel Ghani Karkar; M. Saleh; S. Saad; J. M. Al Ja'am","Dept. of Comput. Sci. & Eng., Qatar Univ., Doha, Qatar","2014 IEEE Global Engineering Education Conference (EDUCON)","20140605","2014","","","670","675","Children with intellectual challenges (IC) are growing up with extensive exposure to computer technology. Computer software and assistive devices have the potential to help these children in education, career development, and independent living. However, most of the software, tools and web sites that these children interact with are designed without consideration of their special needs, making these elements less effective or completely inaccessible for them. This paper proposes an assistive education system that dynamically generates multimedia tutorials for children with IC in the state of Qatar. We use several techniques to generate the tutorials which include: Arabic text processing, entities relationship extraction, multimedia-based ontology, and online retrieval of multimedia contents. The main aim of our system is to enhance those children learning capabilities, understanding, communications, thinking and memorization skills through multimedia.","2165-9559;21659559","Electronic:978-1-4799-3191-0; POD:978-1-4799-3192-7; USB:978-1-4799-3190-3","10.1109/EDUCON.2014.6826165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6826165","Accessibility;Intellectual Challenges;Learning;Multimedia Tutorials;Ontology;Special Education","Computers;Integrated circuits;Multimedia communication;Ontologies;Servers;Software;Tutorials","Web sites;computer aided instruction;handicapped aids;information retrieval;multimedia computing;natural language processing;ontologies (artificial intelligence);text analysis","Arabic ontology-based learning system;Arabic text processing;Qatar;Web sites;assistive devices;assistive education system;children learning capability;computer software;computer technology;entities relationship extraction;intellectual challenges;memorization skills;multimedia content;multimedia tutorials;multimedia-based ontology;online retrieval;thinking skills","","0","","17","","","3-5 April 2014","","IEEE","IEEE Conference Publications"
"Rule-based focus extraction in Turkish question answering systems","C. Derici; K. √áelik; A. √ñzg√ºr; T. G√ºng√∂r; E. Kutbay; Y. Aydƒ±n; G. Kartal","","2014 22nd Signal Processing and Communications Applications Conference (SIU)","20140612","2014","","","1604","1607","This study describes a rule-based approach that is employed in the question analysis module of the Turkish question answering system we design for high-school students to assist their education. The technique is used to extract parts of the question (the focus) that indicate the type and the character of the answer. Evaluation is performed on a set of geography question data that are collected and annontated by human experts, and the results are provided. Manually tailored rules are based on general Turkish question patterns, thereby not dependent on the domain. Therefore, this technique can be used by any Turkish question answering system, regardless of the domain. Both the source codes and the annontated data set are electronically provided for both reproducability and future work.","2165-0608;21650608","Electronic:978-1-4799-4874-1; POD:978-1-4799-4873-4","10.1109/SIU.2014.6830551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830551","focus;question analysis;question answering systems;rule-based information extraction","Art;Computer applications;Conferences;Education;Hidden Markov models;Knowledge discovery;Signal processing","data analysis;question answering (information retrieval);source code (software)","Turkish question answering systems;annontated data set;general Turkish question patterns;geography question data;high-school students;human experts;question analysis module;rule-based focus extraction;source codes","","0","","11","","","23-25 April 2014","","IEEE","IEEE Conference Publications"
"Egovernment and web accessibility in South America","S. Luj√°n-Mora; R. Navarrete; M. Pe√±afiel","Dept. of Software & Comput. Syst., Univ. of Alicante, Alicante, Spain","2014 First International Conference on eDemocracy & eGovernment (ICEDEG)","20140529","2014","","","77","82","The number of e-government websites has increased greatly in recent years. Many countries have laws to ensure that e-government sites satisfy web accessibility requirements. The objective of web accessibility is to ensure that people with disabilities can access websites just like everyone else. However, laws that enforce web accessibility do not automatically guarantee compliance: e-government websites are not always prepared to provide a correct service to persons with disabilities. This paper analyses the accessibility of a group of e-government websites of all South American countries and Spain. Three official websites from each country has been analysed: the government, the Parliament and the Senate websites. Different automatic evaluation tools have been used to perform the analysis. The preliminary results of our research show that the majority of e-government websites do not provide adequate levels of web accessibility.","","Electronic:978-3-907589-17-5; POD:978-1-4799-5108-6","10.1109/ICEDEG.2014.6819953","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819953","e-government e-participation;e-inclusion;universal access;web accessibility","Cascading style sheets;Color;Electronic government;Guidelines;HTML;Web pages","Web sites;government data processing;handicapped aids;information retrieval","Parliament Websites;Senate Websites;South American countries;Spain;Web accessibility requirements;automatic evaluation tools;disabilities;e-government Websites;laws","","2","","29","","","24-25 April 2014","","IEEE","IEEE Conference Publications"
"Arbor: Efficient Large-Scale Graph Data Computing Model","W. Zhou; B. Li; J. Han; Z. Xu","Inst. of Inf. Eng., Beijing, China","2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing","20140612","2013","","","300","307","Graph data is the default data organization mechanism used in large-scale Social Network Service (SNS) applications. Traditional graph data computing models are used to dig out useful hidden information inside the data. However, the ever growing data volume is adding more and more pressures. To retrieve and discover the information, the system has to introduce a larger number of data iterations. This makes the data analysis operations becoming slower. To speed up these operations on large-scale graph data, recent research works focus on developing efficient parallel iteration processing strategies. However, the synchronization requirements between successive iterations can severely jeopardize the effectiveness of parallel operations. In this paper, we propose a novel large-scale graph data processing model, Arbor, to address these issues. Arbor substitutes time-constrained synchronization operations with nontime-constrained control message transmissions to increase the degree of parallelism. Furthermore, it develops a new graph data organization format, which can not only save storage space, but also accelerate graph data processing operations. We compare Arbor with other graph processing models using a large-scale experimental graph data, and the results show that it outperforms the state-of-the-art systems.","","Electronic:978-0-7695-5088-6; POD:978-1-4799-0973-5","10.1109/HPCC.and.EUC.2013.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6831933","graph aggregation;graph analysis;graph data;graph data processing;graph query","Computational modeling;Data analysis;Data models;Organizations;Synchronization;Time factors","data encapsulation;graph theory;information retrieval;iterative methods;parallel processing;social networking (online);synchronisation","Arbor;SNS;data analysis;data hiding;data organization mechanism;efficient large-scale graph data computing model;information discovery;information retrieval;large-scale graph data processing model;large-scale social network service;nontime-constrained control message transmissions;parallel iteration processing strategy;storage space;successive iterations;synchronization requirements;time-constrained synchronization operations","","1","","25","","","13-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Semantic-Synaptic Web Mining: A Novel Model for Improving the Web Mining","H. K. Azad; K. Abhishek","Dept. of CSE, NIT Patna, Patna, India","2014 Fourth International Conference on Communication Systems and Network Technologies","20140529","2014","","","454","457","Web mining is the application of data mining technique to automatically discover and gathered information from web documents and services which can be in structured, unstructured or semi-structured form. It is used to understand user behaviour, evaluate the effectiveness of a particular web and find out the relevant and efficient results from the web. Accuracy and relevance of information extracting from the web is the most significant issue of concern for the realization of web mining. The idea is to improve the accuracy and relevance of information extracting from the web. This paper proposes a novel model for improving the web mining, we hypothesize that web mining is Semantic-Synaptic web mining. Semantic-Synaptic web Mining interlinks the web of data to different data sources at low entropy (Information Theory). This paper combines the best ideas from the semantic web and synaptic web at low entropy and constructs the architecture of Semantic-Synaptic web mining.","","Electronic:978-1-4799-3070-8; POD:978-1-4799-3071-5","10.1109/CSNT.2014.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821437","SemanticWeb Mining;Synaptic web;Synaptic web Mining;Web mining","Entropy;Semantic Web;Semantics;Service-oriented architecture;Web mining;Web sites","data mining;information retrieval;semantic Web","Web documents;data mining technique;information extraction;semantic-synaptic Web mining","","3","","20","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Device-to-device data storage for mobile cellular systems","J. P√§√§kk√∂nen; C. Hollanti; O. Tirkkonen","Dept. of Commun. & Networking, Aalto Univ., Espoo, Finland","2013 IEEE Globecom Workshops (GC Wkshps)","20140605","2013","","","671","676","As an alternative to downloading content from a cellular access network, mobile devices could be used to store data files and distribute them through device-to-device (D2D) communication. We consider a D2D-based storage community that is comprised of mobile users. Assuming that transmitting data from a base station to a mobile user consumes more energy than transmitting data between two mobile users, we show that it can be beneficial to use redundant storage to ensure that data files stay available to the community even if some of the storing users leave the network. We derive a tractable closed-form equation stating when redundancy should be used in order to minimize the expected energy consumption of data retrieval. We find that replication is the preferred method of adding redundancy as opposed to regenerating codes. Our findings are verified by computer simulations.","2166-0077;21660077","Electronic:978-1-4799-2851-4; POD:978-1-4799-2852-1; USB:978-1-4799-2850-7","10.1109/GLOCOMW.2013.6825065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6825065","","Bandwidth;Base stations;Communities;Conferences;Maintenance engineering;Mobile communication;Redundancy","cache storage;cellular radio;information retrieval;redundancy;storage allocation","D2D communication;D2D-based storage community;base station;cellular access network;data files;data retrieval;device-to-device communication;energy consumption;mobile cellular systems;mobile devices;mobile users;redundant storage;replication;tractable closed-form equation","","12","","14","","","9-13 Dec. 2013","","IEEE","IEEE Conference Publications"
"Efficient way of searching data in MapReduce paradigm","G. Shah; Annappa; K. C. Shet","","2014 International Conference on Computing for Sustainable Global Development (INDIACom)","20140612","2014","","","305","310","Cloud computing has emerged as an effective solution in the computing world. When the cloud is used for large amounts of data storage, searching for any required data takes lots of time. A framework is required to distribute the work of searching and fetching from thousands of computers. The data in Hadoop Distributed File System is scattered and needs lots of time to retrieve. MapReduce function on data sets of key & value pair is the programming paradigm of large distributed operation. The proposed work aims to minimize the data retrieval time taken by the MapReduce program in the cloud. The major idea is to design a web server in the map phase using the jetty web server which shall give a fast and efficient way of searching data in MapReduce paradigm. For real time processing on Hadoop, a search mechanism is implemented in HDFS. The load balancer is used to balance the workload across servers to improve its availability, performance and scalability.","","CD-ROM:978-93-80544-11-3; Electronic:978-93-80544-12-0; POD:978-1-4799-2278-9","10.1109/IndiaCom.2014.6828149","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6828149","Hadoop;MapReduce;indexing;jetty server;load balancing","Cloud computing;Computer architecture;Distributed databases;File systems;Indexes;Web servers","cloud computing;information retrieval;parallel programming;resource allocation","Hadoop distributed file system;MapReduce paradigm;Web server;cloud computing;data fetching;data retrieval time;data search;data storage;load balancer;programming paradigm","","0","","14","","","5-7 March 2014","","IEEE","IEEE Conference Publications"
"Microblogging as a social sensing tool","H. Liu; Z. Dong; H. Gu","Sch. of Eng. & Comput. Sci., New York Inst. of Technol., New York, NY, USA","Proceedings of the 11th IEEE International Conference on Networking, Sensing and Control","20140522","2014","","","513","517","Microblogging has become a popular communication tool among Internet users. Millions of users retrieve information and share opinions on different aspects of their daily lives using this platform. This paper presents the development of an online microblog collection and analysis tool that automatically collects public tweets from Chinese microblogging site - Sina Weibo and employs the data processing techniques from Hadoop platform to perform linguistic analysis of the collected data (Chinese characters). We show examples and procedures to use our tool on Chinese posting with GBK and UTF-8 encodings. We demonstrate the tool as a social sensing tool by providing geographical locations on air pollution topic in Sina Weibo. The proposed techniques can be used to analyze online posts in other languages and can be used for online social behavior study.","","Electronic:978-1-4799-3106-4; POD:978-1-4799-3107-1","10.1109/ICNSC.2014.6819679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819679","Hadoop;Sina Weibo;Social sensing;microblogs;natural language processing","Birds;Data mining;Educational institutions;Meteorology;Rail to rail inputs;Silicon","data handling;information analysis;information retrieval;parallel programming;social networking (online);social sciences computing","Chinese characters;GBK encodings;Hadoop platform;Internet users;Sina Weibo;UTF-8 encodings;air pollution topic;data processing techniques;geographical locations;information retrieval;linguistic analysis;microblogging;online microblog analysis tool;online microblog collection tool;online social behavior study;opinion sharing;social sensing tool","","2","","25","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
"Sentimental Space Based Analysis of User Personalized Sentiments","X. Wang; X. Luo","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2013 Ninth International Conference on Semantics, Knowledge and Grids","20140519","2013","","","151","156","With the development of social media, online documents such as the comments of news articles, blogs and microblogs have received great attention, and the sentiment analysis via online documents has become one popular research area. This paper focuses on establishing user sentimental space obtained from online documents to analyze user's personalized sentiments, which aims to identify user's sentimental feature. Affection, sentiment and attributes of user are firstly employed to build user's personalized sentimental space. Then, the general constrains of user sentiments space are proposed to calculate user's personality. And finally we seek out sentimental leaders who paly pivotal role in the leading public opinions. Our works can give some suggestions for decision makers when urgent event happen.","","Electronic:978-1-4799-3012-8; POD:978-1-4799-3013-5","10.1109/SKG.2013.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816597","big data;personalized sentiment model component;sentiment analysis","Aerospace electronics;Asymptotic stability;Controllability;Feature extraction;Fluctuations;Stability analysis;Vectors","information retrieval;natural language processing;social networking (online);text analysis","microblogs;news articles;online documents;sentimental information extraction;sentimental space based analysis;social media;user affection;user attributes;user personality calculation;user personalized sentiment analysis","","3","","18","","","3-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"Efficient top-k closeness centrality search","P. W. Olsen; A. G. Labouseur; J. H. Hwang","Dept. of Comput. Sci., State Univ. of New York, Albany, NY, USA","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","196","207","Many of today's applications can benefit from the discovery of the most central entities in real-world networks. This paper presents a new technique that efficiently finds the k most central entities in terms of closeness centrality. Instead of computing the centrality of each entity independently, our technique shares intermediate results between centrality computations. Since the cost of each centrality computation may vary substantially depending on the choice of the previous computation, our technique schedules centrality computations in a manner that minimizes the estimated completion time. This technique also updates, with negligible overhead, an upper bound on the centrality of every entity. Using this information, our technique proactively skips entities that cannot belong to the final answer. This paper presents evaluation results for actual networks to demonstrate the benefits of our technique.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816651","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816651","","Approximation methods;Educational institutions;Equations;Heuristic algorithms;Measurement;Schedules;Upper bound","information retrieval;network theory (graphs);scheduling","centrality computations;real-world networks;top-k closeness centrality search;upper bound","","5","","34","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Lab-on-Phone: A Participatory Sensing system","J. M. G. Rey; J. M. S. Valencia; A. G. Rozo; F. Segura-Quijano","Dept. de Ing. Electr. y Electron., Univ. de los Andes, Bogota&#x0301;, Colombia","2014 IEEE 5th Latin American Symposium on Circuits and Systems","20140526","2014","","","1","5","This paper presents a novel approach defined as laboratory on phone ‚ÄúLab-on-Phone‚Äù which include the main features of ‚ÄúHuman Centric Sensing‚Äù, ‚ÄúParticipatory Sensing‚Äù and ‚ÄúUbiquitous Computing‚Äù paradigms in a multiuser and multipurpose acquisition, processing, storage and analysis chain infrastructure. Lab-On-Phone includes a generic sensing module which shares data with a Smartphone via Near Field Communication (NFC). The sensor measurements are processed and displayed by an Android application running in the same Smartphone, a web server stores the measured information sent by multiple Smartphones, considering privacy and security. Lab-on-Phone also uses a set of web applications which allow accessing data from many different places and in any platform with Internet access.","","CD-ROM:978-1-4799-2506-3; Electronic:978-1-4799-2507-0; POD:978-1-4799-2508-7","10.1109/LASCAS.2014.6820317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820317","Human centric sensing;Participatory Sensing;Ubiquitous Sensing","ISO standards;Microcontrollers;Protocols;Sensors;Web servers;Wireless sensor networks","Android (operating system);Internet;data acquisition;data privacy;information retrieval;near-field communication;smart phones;storage management;ubiquitous computing","Android application;Internet access;NFC;Web application;Web server;chain infrastructure analysis;data access;data privacy;data security;data sharing;generic sensing module;human centric sensing;lab-on-phone;measured information storage;multipurpose acquisition;multiuser acquisition;near field communication;participatory sensing system;sensor measurements;smart phone;ubiquitous computing","","0","","15","","","25-28 Feb. 2014","","IEEE","IEEE Conference Publications"
"Word-Graph Based Handwriting Key-Word Spotting: Impact of Word-Graph Size on Performance","A. H. Toselli; E. Vidal","Univ. Politec. de Valencia, Valencia, Spain","2014 11th IAPR International Workshop on Document Analysis Systems","20140612","2014","","","176","180","Key-Word Spotting (KWS) in handwritten documents is approached here by means of Word Graphs (WG) obtained using segmentation-free handwritten text recognition technology based on N-gram Language Models and Hidden Markov Models. Linguistic context significantly boost KWS performance with respect to methods which ignore word contexts and/or rely on image-matching with pre-segmented isolated words. On the other hand, WG-based KWS can be significantly faster than other KWS approaches which directly work on the original images where, in general, computational demands are exceedingly high. A large WG contains most of the relevant information of the original text (line) image needed for KWS but, if it is too large, the computational advantages over traditional, image matching-based KWS become diminished. Conversely, if it is too small, relevant information may be lost, leading to degraded KWS precision/recall performance. We study the trade off between WG size and KWS information retrieval performance. Results show that small, computationally cheap WGs can be used without loosing the excellent KWS performance achieved with huge WGs.","","Electronic:978-1-4799-3243-6; POD:978-1-4799-1663-4","10.1109/DAS.2014.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830993","KWS performence effect;Word-Graph size;word-graph generation cost","Decoding;Hidden Markov models;Image segmentation;Training;Vectors;Viterbi algorithm;Vocabulary","computational linguistics;data structures;document image processing;handwritten character recognition;hidden Markov models;image matching;image segmentation;information retrieval;text analysis","KWS information retrieval performance;N-gram language models;WG-based KWS;handwritten documents;hidden Markov models;image matching-based KWS;linguistic context;presegmented isolated words;segmentation-free handwritten text recognition technology;text image;word-graph based handwriting key-word spotting;word-graph size","","3","","19","","","7-10 April 2014","","IEEE","IEEE Conference Publications"
"Decision mining for multi choice workflow patterns","R. Sarno; P. L. I. Sari; H. Ginardi; D. Sunaryono; I. Mukhlash","Inf. Dept., Inst. Teknol. Sepuluh Nopember, Surabaya, Indonesia","2013 International Conference on Computer, Control, Informatics and Its Applications (IC3INA)","20140522","2013","","","337","342","Decision mining is combination of process mining and machine learning technique to retrieve information about how an attribute in a business process affects a case's route choice. It identifies decision point by looking for XOR-splits in petri-net workflow model and analyzing rules for each choice based on available attributes using decision tree. Problem emerges when decision mining technique is used on a workflow that does not use either XOR or AND splits, for example OR-split gateway logic. OR-split does not have explicit representation in petri nets and it makes decision mining algorithm cannot find its decision point. Workflow pattern that uses OR-split as its splitting logic is multi choice. Multi choice does not have its own explicit representation in form of petri net and it is problematic to apply decision mining to this workflow pattern. To make multi choice can be analyzed by decision miner some modification needs to be applied to the petri net representation of this pattern. This paper proposes modification of OR-split gateway representation in petri net. The new representation of OR-split uses combination the existing XOR-split and AND-split to make the model easier to be analyzed using decision miner. The proposed modification do not affect the conformance of event log and process model, but will allow each choice branch to be checked by decision miner.","","CD-ROM:978-1-4799-1076-2; Electronic:978-1-4799-1078-6; POD:978-1-4799-1077-9","10.1109/IC3INA.2013.6819197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819197","decision mining;decision tree;multi choice;process mining;workflow pattern","Analytical models;Companies;Decision trees;Logic gates;PROM;Routing","Petri nets;business data processing;data mining;decision trees;information retrieval;learning (artificial intelligence)","OR-split gateway representation;Petri net representation;Petri-net workflow model;XOR-splits;business process;decision mining;decision tree;information retrieval;machine learning technique;multi choice workflow patterns;process mining","","4","","16","","","19-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"Architecture of web services interface for a Home Energy Management system","M. M. Rahman; M. Kuzlu; M. Pipattanasomporn; S. Rahman","Virginia Tech - Advanced Research Institute, Arlington, 22203, USA","ISGT 2014","20140519","2014","","","1","5","This paper proposes a web-based architecture to enable information retrieval and appliance management for a Home Energy Management (HEM) system. With the proposed architecture, homeowners can monitor their basic energy usage information, and can perform necessary appliance management based on their pre-defined load priority, preferences, and comfort settings. The proposed architecture is designed based on the Standard Energy Usage Information (PAP10), which ensures interoperability among smart grid equipment. It is also designed with comprehensive security measures. It is expected that the proposed architecture can serve as a reference model for custom hardware designs and implementation of a real time, lightweight and reliable embedded web server for HEM applications in the smart grid environment.","","Electronic:978-1-4799-3653-3; POD:978-1-4799-3654-0; USB:978-1-4799-3652-6","10.1109/ISGT.2014.6816418","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816418","Smart grid;ZigBee communications and Home Energy Management;smart appliance interface","Energy management;Home appliances;Logic gates;Protocols;Standards;Web services;Zigbee","Web services;domestic appliances;energy management systems;information retrieval;smart power grids","Web services interface;appliance management;home energy management system;information retrieval;smart grid equipment;standard energy usage information","","3","","16","","","19-22 Feb. 2014","","IEEE","IEEE Conference Publications"
"Information-Centric Networks: Categorizations, challenges, and classifications","M. S. Akbar; K. A. Khaliq; R. N. B. Rais; A. Qayyum","Center of Res. in Networks & Telecommun. (CoReNeT), M.A. Jinnah Univ. Islamabad, Islamabad, Pakistan","2014 23rd Wireless and Optical Communication Conference (WOCC)","20140619","2014","","","1","5","Information-Centric Networking (ICN) emerges as a promising approach for content dissemination and retrieval with a number of advantages including efficient content delivery, better bandwidth utilization and improved mobility support. In past few years, several ICN architectures have been proposed offering different set of features and characteristics, which makes it difficult to choose a particular architecture, given some network conditions and characteristics at hand. These characteristics include IP compatibility, and choice of naming structures etc. Besides, there is a little focus on a number of challenging areas including congestion control, availability, sporadic behavior, multi-source multi-destination and security etc. Moreover, it is not clear how ICN approaches behave with different emerging network environments such as user-centric networking, object-centric networking, Software-Defined networking and Cloud Computing. In this paper, we target all these issues together. First, we attempt to categorize different ICN architectures based on some common characteristics. Second, we identify a number of research challenges in the ICN domain and provide suggestions on mapping them to different ICN approaches. At the end, we bisect ICN approaches based on their characteristics and classify them on the basis of usability which helps a user choose a particular ICN approach given network requirements at hand.","2379-1268;23791268","Electronic:978-1-4799-5249-6; POD:978-1-4799-5250-2","10.1109/WOCC.2014.6839927","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839927","Categorization of ICN;Classification;Cloud Computing;Content-Centric Networking;Information-Centric Networking","Availability;Cloud computing;Computer architecture;IP networks;Routing;Security","IP networks;cloud computing;computer network security;information retrieval;telecommunication congestion control","ICN architectures;IP compatibility;bandwidth utilization;cloud computing;congestion control;content dissemination;content retrieval;information-centric networks;mobility support;multisource multidestination;object-centric networking;software-defined networking;sporadic behavior;user-centric networking","","0","","39","","","9-10 May 2014","","IEEE","IEEE Conference Publications"
"Customized trust based search on expert and knowledge users two sided service systems","K. Sridharan; M. Chitra","Dept. of Comput. Sci. & Eng., Anna Univ., Chennai, India","Confluence 2013: The Next Generation Information Technology Summit (4th International Conference)","20140616","2013","","","180","186","In Collaborations of Web service and processes in business environments, SOA and web services are the most hunted technology. But due to increase in complexity of services there is requirement for dynamic interaction models. In two sided service-oriented systems, both human provided services and software services are combined together to provide a single service. For a two sided service system to work properly we need a context-sensitive trust based on our modified trust algorithm which process exact skill matching and retrieval of Information based on proper content rank. Our contribution to this system is this new modified trust algorithm which process to evaluate trust based on the expert rank and their content quality of their resources provided. We also make the system available for public use and available for two sided markets, hence effectively reduces complexity in combining HPS and software services and provides superior exploration designed for knowledgeable users.","","Electronic:978-1-84919-846-2","10.1049/cp.2013.2314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6832329","Human provided services;Metric calculation;dynamic trust calculation;expert ranking;trust emergence","","Web services;computational complexity;content management;expert systems;groupware;information retrieval;pattern matching;service-oriented architecture;trusted computing","HPS;SOA;Web service collaboration;business environments;content quality;content rank;context sensitive trust;customized trust based search;dynamic interaction model;expert rank;expert system;exploration design;human provided services;information retrieval;knowledge users two sided service system;modified trust algorithm;service-oriented systems;services complexity;skill matching;software service;two sided markets","","0","","","","","26-27 Sept. 2013","","IET","IET Conference Publications"
"Research on Novel Methodology for Documentation Taxonomy for English IDIOLECT to GAIN Lesser Ambiguity Results","S. A. Lohi; A. Motwani","","2014 Fourth International Conference on Communication Systems and Network Technologies","20140529","2014","","","369","372","Information in the form of textual documents would have a huge growth due to the factors like digitization of libraries, exponential rise in internet usage, use of e-mail for various reasons, acceptability of soft copies for many works even critical financial work and other things. In view of these reasons, this paper discusses a new approach for Documentation Taxonomy (DT) based on combining efficient algorithms to be used for english language. The important aspect of automatically classifying and providing taxonomy to a set of documents into any taxonomical structure with the help of predefined categories is termed as Documentation Taxonomy. Automated Documentation Taxonomy is gaining prominence since it frees organizations from the frantic and time consuming need of manually organizing documents. This manual process can be expensive and given the time constraints of the application or the number of documents involved, simply not feasible. In terms of accuracy, modern documentation taxonomy systems proves better than that of trained human professionals, which is made possible by a combination of information retrieval technology and machine learning technology. This research put forwards a mechanism that shows that the use of combination of different algorithms brings down the ambiguity in taxonomical issues. There are numerable useful applications of this approach spanning various scientific and general fields of work.","","Electronic:978-1-4799-3070-8; POD:978-1-4799-3071-5","10.1109/CSNT.2014.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821420","Deductive Inference;Documentation Taxonomy;Lazy Evaluation Method (Fast-KNN);Space Reduction;pair-relation","Communication systems","inference mechanisms;information retrieval;learning (artificial intelligence);natural language processing;pattern classification;text analysis","English idiolect;English language;Internet usage;deductive inference;document classification;document organization;documentation taxonomy;e-mail;information retrieval technology;library digitization;machine learning technology;taxonomical structure;textual documents","","0","","12","","","7-9 April 2014","","IEEE","IEEE Conference Publications"
