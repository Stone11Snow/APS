"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4740578,4740539,4739723,4740821,4740548,4740570,4736952,4740781,4737054,4740777,4740426,4739592,4740790,4737719,4740458,4739597,4740866,4740820,4740546,4740483,4740502,4740567,4739556,4736899,4740125,4740048,4740450,4739958,4736814,4740869,4739775,4740537,4739744,4739878,4740467,4740024,4736801,4737127,4740524,4736990,4737533,4739743,4739927,4739703,4740293,4736555,4740456,4740753,4740542,4736557,4739841,4740461,4740468,4739720,4740371,4737076,4739613,4736804,4738444,4736991,4740482,4736526,4740394,4739046,4740535,4740558,4740478,4740021,4737105,4736843,4599572,4740840,4737037,4732009,4732936,4732851,4730939,4731396,4730586,4730996,4731670,4736401,4730333,4733957,4731986,4732844,4730947,4731504,4730469,4731602,4732935,4732793,4734014,4732826,4731975,4731540,4730461,4731726,4731486,4735717",2017/05/04 21:05:18
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A Representation Model for Reusable Assets to Support User Context","H. B. Hadji; S. K. Kim; H. J. Choi","Sch. of Eng., Inf. & Commun. Univ., South Korea","2008 IEEE International Symposium on Service-Oriented System Engineering","20081230","2008","","","91","96","In the field of software reuse, methods for storage and retrieval of software assets abound. However, these methods have limitations and fail to find the suitable reusable components or software assets that satisfy the requirements of a particular software system. We identify two problems to be the leading cause of this situation. One is the lack of accurate semantics for describing software assets. The other is the ignorance of user context in the query. In this paper we present an XML-based asset representation model which incorporates the user contextual information into the description of software assets that can be reused in the software development process. The proposed model provides semantic metadata for the user context in the asset description in order to build the foundation for semantic reasoning in the retrieval process.","","CD-ROM:978-0-7695-3499-2","10.1109/SOSE.2008.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730469","semantic retrieval;software reuse;user context","Communication system software;Context modeling;Context-aware services;Information retrieval;Productivity;Programming;Software quality;Software reusability;Software systems;Systems engineering and theory","XML;programming language semantics;software reusability","XML;query;representation model;retrieval process;reusable assets;semantic metadata;semantic reasoning;semantics;software assets;software development;software reuse;user context","","2","","14","","","18-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Adding Content-based 3D Model retrieval to semantic web","Huang Shiguo; Zhou Mingquan; Geng Guohua; Ning Zhengyuan; Wang Kegang","Computer & Information College, Fujian Agriculture and Forestry University, Fuzhou, 35002, China","2008 3rd International Conference on Intelligent System and Knowledge Engineering","20081230","2008","1","","313","318","The goal of adding content-based 3d model retrieval to semantic web is to develop a rich set of 3d model semantic representation to enable both humans and machines to generate and understand model descriptions and processing which can be used to enable fast efficient retrieval from model collections. The purpose of Ontology for Content-based 3d Model retrieval is intended to describe model information regardless of storage, feature extraction, creation. In our research, the ontology includes the information on media features, low level visual descriptors and their relationship and non media features of 3d model. It is represented in RDF Schema and implemented in protege.","","POD:978-1-4244-2196-1","10.1109/ISKE.2008.4730947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730947","","Content based retrieval;Educational institutions;Humans;Information retrieval;Intelligent systems;Knowledge engineering;Ontologies;Search engines;Semantic Web;Shape","content-based retrieval;ontologies (artificial intelligence);semantic Web","content-based 3D model retrieval;ontology;semantic Web;semantic representation","","0","","35","","","17-19 Nov. 2008","","IEEE","IEEE Conference Publications"
"Image Retrieval Based on Clustering of Salient Points","M. Jian; S. Chen","Sch. of Space Sci. & Phys., Shandong Univ. at Weihai, Weihai, China","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","347","351","In content-based image retrieval, how to representation of local properties in an image is one of the most active research issues. In certain circumstance, however, users concern more about objects of their interest and only wish to retrieve images containing relevant objects, while ignoring irrelevant image areas (such as the background). Previous work on represent of local properties normally requires complicated segmentation of the object from the background. In this paper, we propose an improved salient points detector based on wavelet transform; it can extract salient points in an image more accurately. Then salient points are clustered into different salient regions according to their spatial distribution. It takes not only local image features into account, but also the spatial distribution information of the salient regions. We have tested the proposed scheme using a wide range of image samples from the Corel Image Library for content-based image retrieval. The experiments indicate that the method has produced promising results.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.524","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739592","","Content based retrieval;Detectors;Feature extraction;Humans;Image retrieval;Image segmentation;Information retrieval;Shape;Signal resolution;Wavelet transforms","content-based retrieval;feature extraction;image representation;image retrieval;object detection;pattern clustering;wavelet transforms","Corel Image Library;content-based image retrieval;feature extraction;image representation;object segmentation;salient point clustering;salient point detector;spatial distribution;wavelet transform","","2","","22","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Unified Framework for Opinion Retrieval","Q. Miao; Q. Li; R. Dai","Lab. of Complex Syst. & Intell. Sci., Inst. of Autom. Chinese Acad. of Sci., Beijing","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","739","742","The popularity of Web 2.0 has promoted the Web to be a valuable source for accessing opinions. Unfortunately, due to the large number of user generated content, it is difficult to access and utilize the opinion resource efficiently. Developing an opinion retrieval system is a promising way to overcome the problem of overloaded opinion information. In this paper, we propose a unified framework for opinion retrieval, which is based on generative model and opinion mining technologies. Within this framework, relevance, quality and temporal dimension information of user generated content are incorporated in a unified language model, and on the top of which an opinion summary is proposed. We have developed an opinion retrieval system, (ORS), to retrieve opinions in customer review domain. Our evaluation on a real-world data set shows that ORS can effectively retrieve, summarize and visualize customer opinions.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740539","","Automation;Data mining;Feature extraction;Information retrieval;Intelligent agent;Intelligent systems;Laboratories;Unified modeling language;User-generated content;Visualization","Internet;Unified Modeling Language;data mining;information retrieval;search engines","Web 2.0;customer opinion visualization;opinion mining technology;opinion retrieval system;real-world data set;search engine;temporal dimension information;unified language model framework;user generated content","","2","2","17","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Exploiting Hyponymy in Extracting Relations and Enhancing Ontologies","B. Mandhani; S. Soderland","Dept. of Comput. Sci., Univ. of Washington, Seattle, WA","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","325","329","Relation extraction systems typically rely on local lexical and syntactic features as evidence. Recent work suggests that for a given relation, there might exist certain patterns which, if present in the graph of relationships between objects, provide additional evidence for that relation. While these relational patterns can be very useful, obtaining them on a per-relation basis can be difficult. We propose template relational patterns based on the hyponymy relation. These patterns are applicable for all relations. Existing resources like WordNet are a rich and reliable source of hyponymy relationships between entities. We present techniques for making use of these template patterns for extracting relationships and incorporating them into the ontology. Our experiments show performance improvements in both tasks.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740790","","Buildings;Computer science;Data mining;Fires;Information retrieval;Intelligent agent;Ontologies;Probabilistic logic;Taxonomy;USA Councils","computational linguistics;information retrieval;ontologies (artificial intelligence)","graph theory;hyponymy relation;local lexical feature;ontology;syntactic feature;template relation pattern extraction system","","0","","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Establishment and Management of the English-Chinese Ontology based on the Bilingual Corpus","X. Huang; J. Xiong","Sch. of Comput. Sci. & Eng., Shandong Economic Univ., Jinan","2008 International Conference on Information Management, Innovation Management and Industrial Engineering","20090106","2008","3","","27","30","English-Chinese ontology is of great importance to such fields as CLIR, machine aided translation and language learning et al. Now, there are some perfect kinds of English ontology in Foreign and some mature bilingual corpus in civil, which can be used to build a new kind of english-chinese ontology. The word translation probabilities was calculated by 4 common co-occurrence models in bilingual corpus, and the translation equivalences was extracted according to translation probabilities. The English ontology described by OWL was analyzed by Jena, and MySQL database is used to store ontology resource.","2155-1456;21551456","POD:978-0-7695-3435-0","10.1109/ICIII.2008.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737719","Jena;OWL;ontology","Computer science;Databases;Frequency;Information retrieval;Innovation management;Natural languages;OWL;Ontologies;Probability;Semantic Web","information retrieval;language translation;natural language processing;ontologies (artificial intelligence);probability;semantic Web","English-Chinese ontology management;Jena;MySQL database;Web ontology language;bilingual corpus;common co-occurrence model;word translation probability","","1","","9","","","19-21 Dec. 2008","","IEEE","IEEE Conference Publications"
"Chinese Partial Parsing with Modal Finite-State Approach","Y. Zhao; J. Zeng; Y. Yang","Res. Center of Integrated Inf. Syst., Chinese Acad. of Sci., Beijing, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","2","","729","733","A novel finite-state approach with the practical use of modal operators for Chinese partial parsing is presented in this paper. The traditional rule-based partial parsing approaches make use of regular grammar to approximate the context free or simplified context sensitive grammar with some loss of descriptive ability. Until now, how to solve the non-categorical problem within rule-based paradigm has not been reported, except for adding probability to grammars. In the approach presented in this paper, basic modal operators, necessity and possibility, are introduced into classic regular grammar. The technique of using such grammar to partially parse the free Chinese text is also discussed in detail. The experimental results suggest that the proposed approach can achieve Chinese partial parsing well and give a considerable performance improvement compared to traditional finite-state approach. A new application in natural language processing of modal logic is revealed through this paper.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731726","Chinese;finite-state approach;modal;partial parsing","Automation;Computer science;Hidden Markov models;Information analysis;Information retrieval;Information systems;Logic;Machine learning algorithms;Natural language processing;Natural languages","context-free grammars;context-sensitive grammars;natural language processing","Chinese partial parsing;context free grammar;free Chinese text;modal finite-state approach;modal logic;modal operators;natural language processing;noncategorical problem;rule-based paradigm;rule-based partial parsing;simplified context sensitive grammar","","1","","24","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Rough Concept Lattice Model of Variable Precision","Y. Li; Y. Sheng; S. Tian; L. Luan","Inst. of Inf. Eng., Yangzhou Univ., Yangzhou","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","162","166","Classical formal concept analysis can't deal with rough and uncertain information, so the research on rough concept lattice and information express has important significance. There is an interesting relationship between approximate space and concept lattice in the rough set theory. The upper-lower approximation and variable precision in rough set theory are introduced into concept lattice, this paper proposes a rough concept lattice model of variable precision. Two parameters beta<sub>1</sub> and beta<sub>2</sub> are adopted to represent the roughness of the objects and attributes respectively in a rough concept and the approximate mapping between objected set and attribute set is defined by changing the traditional Galois connection. According to the different parameter beta<sub>1</sub> and beta<sub>2</sub> given by user, the rough concept lattice with different roughness can be obtained.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.225","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739556","Rough Concept Lattice;Variable Precision","Engineering management;Information analysis;Information retrieval;Information technology;Knowledge management;Knowledge representation;Lattices;Object oriented modeling;Set theory;Uncertainty","approximation theory;data mining;knowledge representation;rough set theory","data mining;knowledge representation;rough concept lattice model;rough set theory;traditional Galois connection;upper-lower approximation;variable precision","","0","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Rethinking Metadata Creation and Management in a Data-Driven Research World","A. Treloar; R. Wilkinson","Australian Nat. Data Service Establ. Project, Monash Univ., Clayton, VIC, Australia","2008 IEEE Fourth International Conference on eScience","20090106","2008","","","782","789","Research data collections are tremendously important and thus need good curation. However data collections are significantly different to publication repositories and so we need to ensure that these differences are taken into account when managing research data. We believe that a good way of approaching this problem is to articulate the needs of research data stakeholders - particularly users and creators. Consequently we have described an analysis of these needs and then examined costs in the light of these varying needs - it is important to note that costs are often incurred by different people to the beneficiaries. We finish the paper by showing practically how incurring software costs can provide valuable savings for both data creators and data managers.","","CD-ROM:978-0-7695-3535-7; POD:978-1-4244-3380-3","10.1109/eScience.2008.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736899","Data Curation;Data Management;Information Needs;Metadata;e-Research","Australia;Conference management;Costs;History;Humans;Information retrieval;Instruments;Ontologies;Project management;Sensor phenomena and characterization","data acquisition;meta data;software cost estimation","data creator;data manager;data-driven research world;metadata creation;metadata management;research data collection;research data stakeholder;software cost","","4","","20","","","7-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"The Research of Subtitles Regional Location Algorithm Based on Video Caption Frames","X. Wang","Coll. of Math. & Comput. Sci., Hebei Univ., Baoding","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","886","889","There are still some shortcomings in the existing traditional location algorithm, so we focus on the improvement of the algorithm through the unique characteristics of video images, like edge, gradient, etc. First, we can determine which are the caption frames according to the region gradient value, then use the method of re-projection to locate the subtitles region on the basis of caption frames. The judgment of the caption frames of the video effectively reduces the complexity of the text recognition. The method of re-projection can avoid the false text region between the two lines of subtitles regions. It suits each kind of video images. The experiment indicates this method could locate the video image subtitles region well. Comparing with the other methods, it had great improving and provided a convenience for the next recognition.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740125","Caption frames;False text region;Re-projection;Sobel operator","Application software;Computer science;Educational institutions;Filters;Image edge detection;Image recognition;Information retrieval;Information technology;Mathematics;Text recognition","image recognition;video signal processing","re-projection method;subtitle regional location algorithm;text recognition complexity;video caption frames;video images","","1","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Trackback-Rank: An Effective Ranking Algorithm for the Blog Search","J. H. Kim; T. B. Yoon; K. S. Kim; J. H. Lee","Dept. of Electr. & Comput. Eng., Sungkyunkwan Univ., Suwon","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","503","507","Today, most Web pages are being created in the blog space or evolving into the blog space. A major problem is that a blog entry (blog page) includes non-traditional features of Web pages. Those are trackback links, bloggers' authority, tags, and userspsila responses. Thus, the traditional rank algorithms are not proper to evaluate blog entries because those algorithms do not consider the blog specific features. In this paper, we propose a new algorithm called ""trackback-rank"" that ranks blog entries by calculating the reputation scores of bloggers, trackback scores, and comment scores based on the features of the blog entries. We apply this algorithm to searching for information related to the userspsila queries in the blog space. The experiment shows that our algorithm finds the much more relevant information than the traditional ranking algorithms.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.541","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740048","Blog;Link-analysis;Ranking;Search engine;Tag;Trackback;Weblog","Application software;Information retrieval;Information services;Information technology;Internet;Publishing;Web pages;Web search;Web sites","Web sites","Web pages;blog search;blog space;comment scores;ranking algorithm;trackback links;trackback-rank;user queries","","3","","11","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"RATE: A Review of Reviewers in a Manuscript Review Process","W. Wei; K. T. Chan; I. King; J. H. M. Lee","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Hong Kong","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","204","207","In this paper, we propose a novel approach called, Reviewers Authority Testing and Evaluation (RATE), to improve the effectiveness of a manuscript review process. In the proposed RATE approach, we define a RATE model to express a manuscript review process mathematically. We then design a RATE algorithm to rank the authority of each reviewer in the RATE model and consequently calculate the quality score for each manuscript. The experimental results demonstrate that the performance of the RATE algorithm is superior to existing approaches. Furthermore, the experiments on testing algorithm's parameter settings also demonstrate that the proposed RATE algorithm behaves effectively and stably.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740450","","Algorithm design and analysis;Computer science;Electronic learning;Information retrieval;Intelligent agent;Mathematical model;Testing","data analysis;information analysis","manuscript review process;quality score;reviewers authority testing","","0","","7","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Multi-taxonomy: Determining Perceived Brand Characteristics from Web Data","S. Spangler; L. Proctor; Y. Chen","","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","258","264","A strong brand is a major asset to any corporation. Traditional brand image and reputation tracking is limited to news wires and contact centers analysis. However, with the emergence of Web, consumer generated media (CGM), such as blogs, news forums, message boards, and web pages/sites, is rapidly transforming the way companies analyze their brand perceptions. This paper describes the next generation COBRA (Corporate Brand and Reputation Analysis) approach to mining a wide range of CGM content to discover how the social media-based community perceives the brand. The solution processes a diverse set of structured and unstructured information and mines CGM content by generating multiple taxonomies from the data. These taxonomies are then used singly and in combination to better understand important brand characteristics and hence enhance marketing and strategic decision making. We illustrate our approach with a real-world case study involving the Kraft Foodspsila Vegemite brand.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740458","clustering;discovery;sentiment;taxonomy","Blogs;Data mining;Information analysis;Information filtering;Information filters;Information retrieval;Intelligent agent;Taxonomy;Text mining;User-generated content","Web sites;data mining;decision making;information retrieval;marketing data processing","Kraft Foods Vegemite brand;Web data;Web pages;Web sites;consumer generated media;message boards;news forums;next generation COBRA;reputation tracking;social media-based community;strategic decision making;traditional brand image","","1","3","16","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Efficient Algorithm of Gray Projection Cyclostyle Matching to Image Retrieval","L. Junjuan; T. Guoxin; G. Xinru; L. Bo","Eng. Res. Center for Educ. Inf. Technol., Huazhong Normal Univ., Wuhan","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","57","60","This paper presents an improved image retrieval algorithm which based on the gray projection cyclostyle matching to overcome the shortcomings of conventional content-based image retrieval methods. The algorithm based on the analysis that gray scale projection curves of horizontal and vertical direction of the images fully reflects the feature of gray distribution in the corresponding direction, then compares with them if it's not homology. The experimental results show that the presented algorithm can preferably meet the requirements of image retrieval and greatly decrease the amount of calculation.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.549","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739958","Content-based Image Retrieval;Cyclostyle Matching;Gray scale projection","Algorithm design and analysis;Content based retrieval;Digital images;Educational technology;Histograms;Image analysis;Image retrieval;Information retrieval;Information technology;Partitioning algorithms","content-based retrieval;image matching;image retrieval","content-based image retrieval methods;gray distribution feature;gray projection cyclostyle matching","","0","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Single Chinese News Article Summarization Based on Ranking Propagation","M. Liu; Y. Liu; L. Xiang; X. Chen; Q. Yang","Nat. Lab. of Pattern Recognition, Chinese Acad. of Sci., Beijing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","779","783","This paper proposes a news summarization system called NewsSum for simultaneous key entities and sentences extraction from single Chinese news article. NewsSum can provide both query-independent and query-specific news summarization. In this study, NewsSum is implemented by firstly parsing the news text in the preprocessing stage and building a news document graph, then exploiting the ranking propagation algorithm on the graph to extract key entities and sentences from the text as its summary. Furthermore, the quality of NewsSum is compared with state-of-the-art summarization approaches through a user survey.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732935","","Automation;Data mining;Information retrieval;Internet;Knowledge acquisition;Laboratories;Machine learning;Natural language processing;Pattern recognition;Web search","grammars;information retrieval;natural language processing;search engines;text analysis","NewsSum system;document graph;key entity extraction;parsing;query-independent news summarization;query-specific news summarization;ranking propagation;sentence extraction;single Chinese news article summarization;text analysis","","0","","8","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Performance Comparison between Color and Spatial Segmentation for Image Retrieval and Its Parallel System Implementation","G. Pengdong; L. Yongquan; Q. Chu; L. Nan; Y. Wenhua; L. Rui","High Performance Comput. Center, Commun. Univ. of China, Beijing, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","1","","539","543","In this paper segmentation on both color and spatial space is implemented to compare their influence to the performance of content-based image retrieval (CBIR) system. Firstly, images are converted from RGB color space to HSV space. And then cumulative histograms on H component are extracted from four segmented blocks as one color feature of the image. At the same time, the HSV color space is further divided into H2SV space. Local accumulative histograms on H1 and H2 components are sequentially extracted as the other color feature of the image. Finally, both color features combined with the texture feature are taken to evaluate their performance of retrieving images. In addition, some parallel techniques are applied to construct an image retrieval system based on the cluster architecture. Experimental results have demonstrated that spatial segmentation has done more influence on the performance of CBIR system. And the parallel techniques can improve the retrieval efficiency significantly.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731486","H2SV color space;content-based image retrieval;local accumulative histogram;parallel technique","Computer science;Concurrent computing;Content based retrieval;Feature extraction;High performance computing;Histograms;Image retrieval;Image segmentation;Information retrieval;Space technology","content-based retrieval;feature extraction;image colour analysis;image retrieval;image segmentation;image sequences;image texture;parallel processing;pattern clustering;visual databases","H2SV color space;RGB color space;cluster architecture;content-based image retrieval system;feature extraction;image colour analysis;image texture;parallel system implementation;performance comparison;spatial segmentation","","2","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Replica Aware Reliable File Transfer Service for the Data Grid","Y. Lee; E. Kim; H. Y. Yeom","Sch. of Comput. Sci. & Eng., Seoul Nat. Univ., Seoul, South Korea","2008 IEEE Fourth International Conference on eScience","20090106","2008","","","396","397","We focus on faster and more reliable third-party transfer in the data Grid with extending existing service - reliable file transfer service.","","CD-ROM:978-0-7695-3535-7; POD:978-1-4244-3380-3","10.1109/eScience.2008.117","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736814","RFT;replica;third-party transfer","Computer science;Data engineering;Databases;File servers;Information retrieval;Network servers;Reliability engineering;Testing;Throughput","computer communications software;data handling;grid computing","Globus Toolkit version 4;data grid;replica aware reliable file transfer service;transient transfer failures","","0","","3","","","7-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Variable Threshold Based Reversible Watermarking: Hiding Depth Maps","A. Khan; A. Ali; M. T. Mahmood; I. Usman; T. S. Choi","","2008 IEEE/ASME International Conference on Mechtronic and Embedded Systems and Applications","20081230","2008","","","59","64","This paper presents a lossless data hiding approach based on integer wavelet transform and variable threshold for a novel application of watermarking. In this novel application, a depth map of an object obtained from sequence of 2D images is secretly embedded in one of the 2-D images for subsequent 3-D analysis after transmission. Additionally, for efficient generation of the depth map, we also propose a new focus measure based on discrete cosine transform (DCT) and principal component analysis. The proposed approach is able not only in extracting the depth map, but also recovers the cover image. Experimental results show the capability of the proposed approach of secretly transmitting and retrieving the depth information. The employment of this novel idea of hiding depth maps in corresponding 2-D cover images could be helpful in medical and military image processing, security based stickers, mobile advertizing, image vision, law enforcement, etc. Additionally, if the depth map is generated through a standard approach, it could also help in the authentication related applications of the cover image.","","POD:978-1-4244-2367-5","10.1109/MESA.2008.4735717","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4735717","","Data encapsulation;Data mining;Discrete cosine transforms;Image analysis;Image sequence analysis;Information retrieval;Principal component analysis;Two dimensional displays;Watermarking;Wavelet transforms","data encapsulation;discrete cosine transforms;feature extraction;image coding;image segmentation;image sequences;principal component analysis;watermarking;wavelet transforms","2D image sequence;3D analysis;authentication related applications;cover image recovery;depth map extraction;depth map hiding;discrete cosine transform;integer wavelet transform;lossless data hiding approach;principal component analysis;reversible watermarking;variable threshold","","0","","28","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Ranking Web Pages Using Machine Learning Approaches","S. L. Yong; M. Hagenbuchner; A. C. Tsoi","Univ. of Wollongong, Wollongong, NSW","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","677","680","One of the key components which ensures the acceptance of web search service is the web page ranker - a component which is said to have been the main contributing factor to the early successes of Google. It is well established that a machine learning method such as the Graph Neural Network (GNN) is able to learn and estimate Google's page ranking algorithm. This paper shows that the GNN can successfully learn many other Web page ranking methods e.g. TrustRank, HITS and OPIC. Experimental results show that GNN may be suitable to learn any arbitrary web page ranking scheme, and hence, may be more flexible than any other existing web page ranking scheme. The significance of this observation lies in the fact that it is possible to learn ranking schemes for which no algorithmic solution exists or is known.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740869","Machine learning;Web page ranking","Computer architecture;Information retrieval;Intelligent agent;Learning systems;Machine learning;Neural networks;Neurons;Web pages;Web search;World Wide Web","Web services;Web sites;graph theory;learning (artificial intelligence);neural nets;search engines","Google;HITS;OPIC;TrustRank;Web page ranking;graph neural network;machine learning method;web search service","","3","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Trademark Image Retrieval Using Region Zernike Moments","L. Li; D. Wang; G. Cui","Dept. of Comput. Eng., Henan Polytech. Inst., Nanyang","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","301","305","To solve the problems on the invariance property under translation, rotation, scale and the starting point existing in the shape features of trademarks, a new trademark image retrieval method based on region Zernike moments to extract the shape feature of images is presented. First, the object region of an image is extracted according to the circumcircle of object pixels. Then, the object is plotted out based on the concentric circles to produce a series of sub-images. Furthermore, the Zernike moments of sub-images are computed, and they are constructed into a feature vector for describing the shape of the trademark image. Finally, the similarity comparison between the images is drawn according to the Euclidean distance. Experiment results demonstrate that this method has good invariant property under translation, rotation and scale, and is insensitive to noise.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.330","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739775","Zernike moment;image retrieval;trademark","Application software;Educational institutions;Image retrieval;Information retrieval;Information technology;Noise shaping;Pixel;Polynomials;Shape;Trademarks","edge detection;feature extraction;image retrieval","Euclidean distance;feature vector;invariance property;object pixels;region Zernike moments;shape feature extraction;trademark image retrieval method","","0","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"TheHotMap.com: Enabling Flexible Interaction in Next-Generation Web Search Interfaces","O. Hoeber; M. Brooks; D. Schroeder; X. D. Yang","Dept. of Comput. Sci., Memorial Univ. of Newfoundland, St. John's, NL","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","730","734","TheHotMap.com is an example of a next-generation Web search interface, wherein users are able to take an active role in the Web search process. Information that can assist searchers in their Web search tasks is presented in a visual manner. The system supports user interaction both during the query refinement process, as well as the search results exploration process. This paper describes the features of TheHotMap.com; usage log analysis illustrates the benefits of supporting flexible interaction within a single unified Web search interface.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.150","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740537","Web search;interface;usage log analysis;visualization","Computer science;Frequency;Histograms;Information retrieval;Intelligent agent;Prototypes;Search engines;User interfaces;Web search","Internet;human computer interaction;query processing;user interfaces","TheHotMap.com;log analysis;next-generation Web search interface;query refinement process;user interaction;visual manner","","1","","16","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"The design of electric power equipment information search system","Ping Yu; Hui Yuan; Zhenbing Zhao","Department of Electronic and Communication Engineering, North China Electric Power University, Baoding, China","2008 9th International Conference on Computer-Aided Industrial Design and Conceptual Design","20081230","2008","","","349","353","Starting with the current situation and development of electric power equipment information administration, structured a networked electric power equipment images management information system that is safe, reliable and efficient to run. System is on basic of B/S structure, realizes dynamic interactive Web application based on MVC frame, adopting SIFT algorithm to carry out fast matching, realize retrieval and classification for equipment photographs in image database, program execution of BLOB interface aiming at JDBC achieved storage, display for equipment photograph and relevant information. In addition, malfunction administration module is able to add abnormal equipment information such ad exceed the time limit with the service life or consumer thinks false to abnormal form, warn of operators at the regular time.","","CD-ROM:978-1-4244-3291-2; POD:978-1-4244-3290-5","10.1109/CAIDCD.2008.4730586","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730586","BLOB Interface;Database Linking Pool;Information Search;MVC Frame;Photograph Classify","Computational Intelligence Society;Displays;Energy management;Image databases;Image storage;Information retrieval;Internet;Logic;Power system management;Power system reliability","Internet;Java;image classification;image matching;image retrieval;information retrieval systems;interactive systems;object-oriented programming;power apparatus;power engineering computing","BLOB interface;JDBC;MVC frame;SIFT algorithm;abnormal equipment information;browser-server structure;dynamic interactive Web application;electric power equipment information administration;electric power equipment information search system design;image classification;image database;image matching;image retrieval;malfunction administration module;networked electric power equipment photographic image management system","","0","","6","","","22-25 Nov. 2008","","IEEE","IEEE Conference Publications"
"Semantic-Based Image Retrieval Using Fuzzy Domain Ontology","Y. Ren; X. Cheng","Dept. of Comput. Eng., Henan Polytech. Inst., Nanyang","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","141","145","For solving ""semantic gap"" which exists between the low-features and the high-level semantic features and the fuzziness of users' comprehension, combining Ontology and Fuzzy sets, an universal image semantic description model based on fuzzy domain ontology (SDMFDO) is constructed. Ontology is a kind of model that is used to describe the concepts and the relations of them, and fuzzy set theory can make image retrieval apart from precision of calculating. By adding fuzzy membership to the concepts and the relations of them in the domain ontology, we get a fuzzy domain ontology (FDO) which can be used to describe the semantic features of an image in a way catering for human's fuzzy thoughts. Then the mapping from low-features to high-level semantic features realizes using FSVMs. Finally, the simulation experiments on images provided by Corel are performed to confirm that this method has effectively improved the retrieval performance.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739744","Concept semantic;Domain ontology;Fuzzy set;Image retrieval","Application software;Content based retrieval;Fuzzy set theory;Fuzzy sets;Image retrieval;Information retrieval;Information technology;Ontologies;Telecommunication computing;Vocabulary","fuzzy set theory;image retrieval;ontologies (artificial intelligence);support vector machines","fuzzy domain ontology;fuzzy membership;fuzzy sets;semantic gap;semantic-based image retrieval;support vector machine","","2","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Knowledge Management Technologies in Education","W. Kebao; D. Junxun","Econ. & Manage. Sch., Wuhan Univ., Wuhan","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","93","97","Nowadays, students are learning in a knowledge society, and they have to master some new skills to meet the needs of knowledge society. In this paper, we will discuss what knowledge is, what is knowledge management and what are knowledge management technologies. Then we will analyze how knowledge management technologies have changed the traditional modes of education and whether knowledge management technologies have important effect on education. By analyzing, we find that knowledge management technologies such as data mining, case-based reasoning, information retrieval, topic maps, weblogs, e-Portfolio, are playing important roles in education.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732793","education;knowledge;knowledge management technologies","Computer science education;Data mining;Educational technology;Information analysis;Information retrieval;Knowledge acquisition;Knowledge management;Performance analysis;TV;Technology management","educational administrative data processing;knowledge management","education traditional mode;knowledge management technology;knowledge society","","2","","16","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Learning to rank with voted multiple hyperplanes for documents retrieval","He-li Sun; Bo-qin Feng; Jian-bin Huang","Department of Computer Science & Technology, Xi&#191;an Jiaotong Univ., 710049, China","2008 3rd International Conference on Intelligent System and Knowledge Engineering","20081230","2008","1","","572","577","The central problem for many applications in Information retrieval is ranking. Learning to rank has been considered as a promising approach for addressing the issue. In this paper, we focus on applying learning to rank to document retrieval, particularly the approach of using multiple hyperplanes to perform the task. Ranking SVM (RSVM) is a typical method of learning to rank. We point out that although RSVM is advantageous, it still has shortcomings. RSVM employs a single hyperplane in the feature space as the model for ranking, which is too simple to tackle complex ranking problems. In this paper, we look at an alternative approach to RSVM, which we call ¿¿multiple vote ranker¿¿ (MVR), and make comparisons between the two approaches. MVR employs several base rankers and uses the vote strategy for final ranking. We study the performance of the two methods with respect to several evaluation criteria, and the experimental results on the OHSUMED dataset show that MVR outperforms RSVM, both in terms of quality of results and in terms of efficiency.","","POD:978-1-4244-2196-1","10.1109/ISKE.2008.4730996","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730996","Document retrieval;Learning to rank;Multiple vote ranker;Ranking SVM","Information retrieval;Intelligent systems;Knowledge engineering;Machine learning;Sun;Support vector machine classification;Support vector machines;Testing;Training data;Voting","information retrieval;support vector machines","documents retrieval;information retrieval;multiple vote ranker;ranking SVM;voted multiple hyperplanes","","0","","21","","","17-19 Nov. 2008","","IEEE","IEEE Conference Publications"
"An Agent-Based Security Business Data Integration Middleware for Heterogeneous Enterprise Legacy systems","B. Xu","Coll. of Comput. & Inf. Eng., ZheJiang GongShang Univ., Hangzhou","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","819","823","Business data integration is very important for the enterprises with several distributed departments and heterogeneous legacy business systems. Due to the different functionalities of the different business departments, the access authority to the business data is different. This paper suggests yet a new method to establish a security business data integration framework among heterogeneous legacy business systems.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.355","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739878","Agent-based Middleware;Enterprise Legacy systems;Secure Business Data Integration","Communication system security;Data security;Humans;Information filtering;Information filters;Information retrieval;Information security;Intelligent agent;Middleware;Protocols","business data processing;middleware;security of data;software maintenance","agent-based security;business data integration middleware;heterogeneous enterprise legacy systems","","0","","15","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Enriching Multilingual Language Resources by Discovering Missing Cross-Language Links in Wikipedia","J. H. Oh; D. Kawahara; K. Uchimoto; J. Kazama; K. Torisawa","Nat. Inst. of Inf. & Commun. Technol. (NICT), Seika","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","322","328","We present a novel method for discovering missing cross-language links between English and Japanese Wikipedia articles. We collect candidates of missing cross-language links -- a pair of English and Japanese Wikipedia articles, which could be connected by cross-language links. Then we select the correct cross-language links among the candidates by using a classifier trained with various types of features. Our method has three desirable characteristics for discovering missing links. First, our method can discover cross-language links with high accuracy (92% precision with 78% recall rates). Second, the features used in a classifier are language-independent. Third, without relying on any external knowledge, we generate the features based on resources automatically obtained from Wikipedia. In this work, we discover approximately $10^5$ missing cross-language links from Wikipedia, which are almost two-thirds as many as the existing cross-language links in Wikipedia.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740467","Cross-Language Links;Language Resource;Web mining;Wikipedia","Communications technology;Dictionaries;Encyclopedias;Information retrieval;Intelligent agent;Natural languages;Statistics;Wikipedia","Web sites;classification;natural language processing","English Wikipedia articles;Japanese Wikipedia articles;classification;cross-language links;multilingual language resources","","4","","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"The Opportunities and Challenges of Information Extraction","Q. Zhu; X. Cheng","Sch. of Comput. Sci. & Telecommun. Eng., Jiangsu Univ., Zhenjiang","2008 International Symposium on Intelligent Information Technology Application Workshops","20081230","2008","","","597","600","The purpose of information extraction (IE) is to extract appointed information. It breaks through the limitation that the work of reading, comprehending, IE must all been done by people in information retrieval (IR), and can automatically retrieve, comprehend and extract information. After analyzed the difficulty that WWW encountered, the paper presents the opportunities and challenges of IE.","","POD:978-0-7695-3505-0","10.1109/IITA.Workshops.2008.165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732009","Information Extraction;WWW;the related conceptions about Information Extraction","Application software;Computer science;Data mining;IP networks;Information retrieval;Information technology;Internet;Isolation technology;Search engines;World Wide Web","feature extraction;information retrieval","WWW;information extraction;information retrieval","","3","","10","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Object Based Image Retrieval","Y. Zhang; J. Yang","Dept. of Comput. Sci., YunNan Normal Univ., Kunming","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","385","388","An object based image retrieval scheme is described. In this scheme, to get objects in an image is the first step, which indeed is an image split and merge process. To control image segmentation, definition of LPD is given. After the split, merge the sub-blocks to get some homogeneous regions called objects. In objects detection, the concepts of inside block and outside block are proposed, a method to choose the seed of regions and proper growth criterion is also presented. Based on the objects get from the image, some important features can be extracted to measure similarity between images.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740024","","Computer science;Content based retrieval;Data mining;Feature extraction;Histograms;Image analysis;Image retrieval;Image segmentation;Information retrieval;Pixel","feature extraction;image retrieval;image segmentation;object detection","feature extraction;image segmentation;image split-merge process;object based image retrieval scheme;object detection","","0","","6","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Word Alignment Based on Multi-Grain Model","Y. He; Y. Zhou; C. Zong","Inst. of Autom., Chinese Acad. of Sci., Beijing, China","2008 6th International Symposium on Chinese Spoken Language Processing","20081230","2008","","","1","4","Word alignment plays a critical role in statistical machine translation (SMT) and cross-language information retrieval. Until now, most existing methods get the word alignment within the whole range of the sentence length. The alignment quality is unsatisfactory. In this paper, we propose a novel approach to word alignment based on multi-grain model (WAMG). We split a parallel sentence pair into blocks in different grain and get the word alignments within each corresponding block. Our approach is able to restrict the search space of word alignment in the relatively accurate local range and reduce the mapping error. The experiments have shown that our approach outperforms the traditional word alignment algorithm relatively by about 12% in AER and improves the performance of Chinese-to-English translation system relatively by about 2.8% in BLEU.","","CD-ROM:978-1-4244-2943-1; POD: 978-1-4244-2942-4","10.1109/CHINSL.2008.ECP.79","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730333","","Automation;Entropy;Helium;Hidden Markov models;Information retrieval;Merging;Natural languages;Neural networks;Surface-mount technology","information retrieval;language translation;word processing","Chinese-to-English translation system;cross-language information retrieval;multi-grain model;statistical machine translation;word alignment","","1","","13","","","16-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Supervised Textual Document Classification Using Neuronal Group Learning","M. Pryczek; P. S. Szczepaniak","Inst. of Comput. Sci., Tech. Univ. of Lodz, Lodz","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","780","784","Together with fast development of different areas of pattern analysis, an increasing demand on new models and techniques is observed. Especially new information retrieval tasks, oriented on data meaning rather than layout, prove to be demanding for most known techniques. neuronal group learning concept presented in this article, together with prototype implementation gives flexibility of utilization of any kind of expert knowledge about the problem to ease classifier inference process. It can also be used to acquire structural knowledge about an object, which can later be used for solving a segmentation problem-often addressed in semantics-oriented text and image processing.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740548","neural networks;pattern classification;pattern recognition;structural pattern recognition","Active contours;Computer science;Image processing;Image segmentation;Inference algorithms;Information retrieval;Intelligent agent;Kernel;Pattern analysis;Prototypes","information retrieval;learning (artificial intelligence);pattern classification;text analysis","expert knowledge;image processing;information retrieval tasks;neuronal group learning;pattern analysis;supervised textual document classification","","0","","15","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"OGSA-DWC: A Middleware for Deep Web Crawling Using the Grid","J. Song; D. H. Choi; Y. J. Lee","Div. of Comput. Sci., KAIST, Daejeon, South Korea","2008 IEEE Fourth International Conference on eScience","20090106","2008","","","370","371","Conventional search engines generally cannot find information from the Deep Web because they use hyper link-based crawling techniques to visit Web pages. Recently, lots of research efforts are being tried to crawl the Deep Web. One of the obstacles for crawling the Deep Web is the requirement of huge computing resources, but most of search engine companies hardly meet the needs. We, therefore, propose the design of the Grid-based middleware, OGSA-DWC for crawling the Deep Web. With our middleware, developers will easily implement a Grid-based Deep Web crawling system although they do not have much knowledge about how to use idle and distributed computing resources.","","CD-ROM:978-0-7695-3535-7; POD:978-1-4244-3380-3","10.1109/eScience.2008.118","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736801","Deep Web;Grid;OGSA;crawling;middleware","Computer science;Crawlers;Databases;Distributed computing;Grid computing;Information retrieval;Middleware;Production facilities;Search engines;Web pages","Web sites;grid computing;middleware;open systems;search engines;software architecture","Deep Web crawling system;Web page;distributed computing resources;grid-based middleware;open grid services architecture;search engine","","1","","10","","","7-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Spatial On-line Analytical Processing (SOLAP): Overview and Current Trends","T. O. Ahmed","Fac. of Sci., Aljabal Algharby Univ., Libya","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","1095","1099","Geographic information systems (GIS) have shown their power when dealing with information that is tied to places. However their analytical functionalities are oriented towards the management of data not towards their effective analysis. On the other hand OLAP technology on which decision support systems (DSS) are based, provide powerful, user-friendly tools that help in the decision making process. The coupling GIS and OLAP has lead to the concept of SOLAP (spatial OLAP) where GIS provides the cartographic representation and OLAP provides multidimensional perspective of data and. In this paper, we present a review of literature of SOLAP, some of the open research issues which are under investigation. We also present some trends in SOLAP such as continuous SOLAP, near real time SOLAP applications, Web based interfaces, and so on.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737127","","Data analysis;Data warehouses;Decision support systems;Geographic Information Systems;Information analysis;Information retrieval;Multidimensional systems;Power engineering and energy;Power engineering computing;Spatial databases","data mining;geographic information systems","GIS;SOLAP;decision support system;geographic information system;spatial OLAP;spatial online analytical processing","","0","","20","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"The Metadata Triumvirate: Social Annotations, Anchor Texts and Search Queries","M. G. Noll; C. Meinel","Hasso-Plattner-Inst. an der Univ. Potsdam, Potsdam","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","640","647","In this paper, we study and compare three different but related types of metadata about Web documents: social annotations provided by readers of Web documents, hyperlink anchor text provided by authors of Web documents, and search queries of users trying to find Web documents. We introduce a large research data set called CABS120k, which we have created for this study from a variety of information sources such as AOL500k, the Open Directory Project, del.icio.us/Yahoo!, Google and the WWW in general. We use this data set to investigate several characteristics of said metadata including length, novelty, diversity, and similarity and discuss theoretical and practical implications.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.341","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740524","anchor text;aol500k;cabs120k08;comparison;del.icio.us;delicious;google;metadata;open directory;pagerank;search query;social web;study;tagging;tags","Data mining;Indexing;Information resources;Information retrieval;Intelligent agent;Privacy;Sampling methods;Search engines;Tagging;World Wide Web","document handling;meta data;query processing;text analysis","Open Directory Project;Web documents;hyperlink anchor text;metadata triumvirate;search queries;social annotations","","7","5","29","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Formal Concepts and Maximal Compatibility Blocks","W. L. Chen","Dept. of Comput. & Inf. Eng., Anhui Inst. of Architechure & Ind., Hefei","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","403","407","An alternative perspective of formal concept is presented. Given the finite formal context, the incidence relation is seen as the universe of discourse since it is a subset of the Cartesian product from objects set to attributes set, and then the compatibility relation on the universe is induced. It is proved that formal concepts are precisely maximal compatibility blocks with respect to the induced compatibility relation. Some properties of formal concept are also discussed in terms of maximal compatibility blocks.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736990","compatibility relation;concept;formal concept analysis","Computer industry;Computer science;Data mining;Database systems;Delta modulation;Industrial relations;Information retrieval;Lattices;Particle separators;Software engineering","data analysis;graph theory","Cartesian product;formal concept analysis;maximal compatibility block","","0","","20","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Research on Case Representation and Case Retrieval Algorithm for Stamping Die","W. Deng; X. Wang; H. Zhao; X. Yang; P. He","Software Inst., Dalian Jiaotong Univ., Dalian","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","370","374","In allusion to the traditional case retrieval technology disadvantage of die design, a rough set-based case retrieval method is presented in the die design. To analyze and deal with die case database using rough set theory, and use a method by using grade classification and decision attributes supporting degree to discretize the quantitative features. It confirms the important degree of all types of characteristic attributes. To aim to build up a retrieval method based on case's key attributes. It uses the similarity method to carry on the similarity degree, retrieve the closest design the case from the case database to take the design case reference. The proposed method is also demonstrated by an application example. The technology guarantees the validity of case retrieval reduces system dependence and improves efficiency of case retrieval.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739597","","Application software;Decision making;Design methodology;Information retrieval;Information systems;Information technology;Knowledge representation;Set theory;Software algorithms;Spatial databases","database management systems;dies (machine tools);information retrieval;pattern classification;product design;rough set theory","case retrieval algorithm;decision attribute;die case database;grade classification;rough set theory;similarity method;stamping die case representation;stamping die design","","0","","14","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Comparative Study of the Innovation Ability Based on the Maintenance Status of Domestic and Foreign Patents","Y. Qiao","Sch. of Politics & Public Affairs, Southwest Univ. of Political Sci. & Law, Chongqing","2008 International Conference on Information Management, Innovation Management and Industrial Engineering","20090106","2008","1","","224","227","The relevant data of 3838 domestic and foreign patents, which were granted by SIPO in 1994, are comparatively analyzed using SPSS software, and fund that the maintenance rate, the maintenance time, the average number of claims and the examination time of domestic patents are significantly less than foreign patents. In the maintained patents, foreign patents focus on high-tech fields; domestic patents focus on traditional technologies fields. From the perspective of the maintenance status of patents, the innovation ability of domestic patentee is less than that of foreign patentee.","2155-1456;21551456","POD:978-0-7695-3435-0","10.1109/ICIII.2008.51","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737533","Comparative study;Innovation ability;Maintenance status of patents","Databases;Industrial engineering;Information management;Information retrieval;Innovation management;Intellectual property;Law;Legal factors;Software maintenance;Technological innovation","innovation management;patents","SPSS software;domestic patents maintenance status;foreign patents maintenance status;innovation ability","","0","","8","","","19-21 Dec. 2008","","IEEE","IEEE Conference Publications"
"Algorithm of Relational Back in Image Retrieval Using SPA","C. Xian-yi; Z. Yan; S. Lanshui","Coll. of Comput. Sci. & Telecommun. Eng., Jiangsu Univ., Zhenjiang","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","136","140","Arming at the problem that the features of the trademark still keep invariant after rotation, scaling and changing of the initial point, an algorithm of relational back in image retrieval using SPA was presented in this paper. The algorithm first extracts five features, and initialized the weight of each feature, then modifies the weight until the feedback from users is over. Finally, a comparison between the algorithm presented in this paper and the algorithm using Hu moment as the feature vectors was made. The experiment indicates that the new algorithm has a good invariant property under translation scale and rotation and strong noise resistance.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.93","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739743","","Application software;Computer science;Content based retrieval;Educational institutions;Feedback;Image retrieval;Information retrieval;Information technology;Shape measurement;Uncertainty","feature extraction;image retrieval","Hu moment;image retrieval;relational back;translation scale","","0","","5","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Improving Keyphrase Extraction Using Wikipedia Semantics","T. Shi; S. Jiao; J. Hou; M. Li","Dept. of Comput. Sci., Shanghai Jiao Tong Univ., Shanghai","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","42","46","Keyphrase extraction plays a key role in various fields such as information retrieval, text classification etc. However, most traditional keyphrase extraction methods relies on word frequency and position instead of document inherent semantic information, often results in inaccurate output. In this paper, we propose a novel automatic keyphrase extraction algorithm using semantic features mined from online Wikipedia. This algorithm first identifies candidate keyphrases based on lexical methods, and then a semantic graph which connects candidate keyphrases with document topics is constructed. Afterwards, a link analysis algorithm is applied to assign semantic feature weight to the candidate keyphrases. Finally, several statistical and semantic features are assembled by a regression model to predict the quality of candidates. Encouraging results are achieved in our experiments which show the effectiveness of our method.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.211","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739723","keyphrase extraction;wikipedia","Algorithm design and analysis;Application software;Data mining;Information retrieval;Information technology;Search engines;Taxonomy;Text categorization;Thesauri;Wikipedia","Web sites;graph theory;information retrieval;pattern classification;text analysis","Wikipedia semantics;information retrieval;keyphrase extraction;lexical methods;semantic graph;text classification","","1","","12","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Standards-Based Coastal Sensor Web","S. S. Durbha; R. L. King; N. H. Younan; S. A. Rajender; S. Bheemireddy","Dept. of Electr. & Comput. Eng., Mississippi State Univ., Starkville, MS","2008 IEEE International Conference on Data Mining Workshops","20081230","2008","","","369","374","Coastal buoys and stations provide frequent, high quality marine observations for oceanographic study, weather service, atmospheric and public safety. Sharing of the generated data sets requires tremendous efforts and coordination among the different sensor network agencies to come to a shared understanding and for dissemination in a uniform way. Syntactic standardization provides data description models that are agreed upon by all the stakeholders. In addition, there is a need for semantic enrichment of the information sources which would help to understand the context of the data and helps to resolve the meaning, interpretation or usage of the same or related data. The standardized data models facilitate improved information retrieval on a variety of Spatiotemporal scales. In this paper we describe the mining of these information sources through a Web services based framework. The sensor observation service component of this framework allows operations such as spatial, temporal subsetting, filtering etc. Further, the terminology involved in the coastal domain is being conceptualized in the form of Ontology. The knowledgebase being developed using this ontological model is amenable to querying using SPARQL which is a standardized RDF query language. The knowledge-enabled client being developed will allow to process queries on the coastal sensors networks that goes beyond the prevalent key words based searches.","2375-9232;23759232","CD-ROM:978-0-7695-3503-6","10.1109/ICDMW.2008.131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4733957","Buoys;Semantics;Sensor Web;Services Oriented Architecture","Atmospheric modeling;Data models;Filtering;Information retrieval;Marine safety;Ontologies;Sea measurements;Spatiotemporal phenomena;Standardization;Web services","Web services;marine engineering;marine safety;marine systems;ontologies (artificial intelligence)","Web services based framework;atmospheric safety;coastal buoys;coastal domain;coastal sensor network;data description model;information retrieval;knowledge-enabled client;marine observations;oceanographic study;ontological model;ontology;public safety;sensor observation service component;spatiotemporal scales;standardized RDF query language;standardized data model;standards-based coastal sensor Web;syntactic standardization;weather service","","1","","16","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Matching and Ranking with Hidden Topics towards Online Contextual Advertising","D. T. Le; C. T. Nguyen; Q. T. Ha; X. H. Phan; S. Horiguchi","Coltech, Vietnam Nat. Univ., Hanoi","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","888","891","In online contextual advertising, ad messages are displayed related to the content of the target Web page. It leads to the problem in information retrieval community: how to select the most relevant ad messages given the content of a page. To deal with this problem, we propose a framework that takes advantage of large scale external datasets. This framework provides a mechanism to discover the semantic relations between Web pages and ad messages by analyzing topics for them. This helps overcome the problem of mismatch due to unimportant words and the difference in vocabularies between Web pages and ad messages. The framework has been evaluated through a number of experiments. It shows a significant improvement in accuracy over word/lexicon-based matching and ranking methods.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.180","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740570","Contextual Advertising;Topic analysis","Advertising;Content based retrieval;Information retrieval;Intelligent agent;Internet;Large-scale systems;Linear discriminant analysis;Taxonomy;Vocabulary;Web pages","Internet;advertising data processing;information retrieval;pattern matching;vocabulary","Web advertising;Web page;advertisement message;hidden topic matching;hidden topic ranking;information retrieval community;online contextual advertising;semantic relation;vocabulary","","2","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Watershed-Based Texture Image Retrieval","X. Lin; X. Wen","Sch. of Continuing Educ., Beijing Univ. of Posts & Telecommun., Beijing","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","1073","1077","The content-based image retrieval (CBIR) is a hot topic recently. In this paper, a novel algorithm, namely a watershed-based texture image retrieval algorithm, is proposed. The algorithm mainly consists of three parts. Firstly, after reduced the noise by the open-closing by reconstruction, the image is segmented into regions by an improved watershed transformation. Secondly, the segmentation regions are re-arrayed from big to small under pixel number, and selected from number one to number T-1. The remaining regions are combined to generate the region of order T. After above optimizing, the textural features regions are extracted to compose a feature vector of image based on color co-occurrence matrix. Finally, the similarity of two images will be determined by the similarity between texture feature vectors. Experiment results show that the proposed algorithm is efficient.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.285","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739927","Co-occurrence matrices;Content-based image retrieval;Mathematical morphology;Texture;Watershed Transformation","Color;Content based retrieval;Continuing education;Feature extraction;Image reconstruction;Image retrieval;Image segmentation;Information retrieval;Information technology;Noise reduction","content-based retrieval;feature extraction;image colour analysis;image reconstruction;image retrieval;image segmentation;image texture;matrix algebra","color co-occurrence matrix;content-based image retrieval;feature vector extraction;image reconstruction;image segmentation;pixel number;watershed transformation;watershed-based texture image retrieval algorithm","","0","","14","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"The Determination of Semantic Dimension in Social Tagging System Based on SOM Model","B. Li; Q. Zhu","Econ. & Manage. Sch., Jiangsu Univ. of Sci. & Technol., Zhenjiang","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","909","913","It is the social tagging that users tag the networked information resources from bottom to up. Different from the traditional experts classification, the semantic classification of tags formed by social tagging has some self-organizing characteristics. We try to use the self-organizing characteristics of SOM neural networks to classify the popular tags in ""Del.icio.us"" website, to determine the tags semantic dimension in social tagging system, and to provide semantics references for information users to use tags.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739703","SOM Neural Network;Semantic Classification;Semantic Dimension;Social Tags","Frequency;Information resources;Information retrieval;Neural networks;Neurons;Resource management;Statistical analysis;Tagging;Technology management;Thesauri","Web sites;information networks;self-organising feature maps;social sciences computing","Del.icio.us website;SOM model;SOM neural networks;networked information resources;self-organizing characteristics;social tagging system","","3","","8","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Scalable Lightweight Distributed Crawler for Crawling with Limited Resources","M. Kc; M. Hagenbuchner; A. C. Tsoi","Univ. of Wollongong, Wollongong, NSW","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","663","666","Web page crawlers are an essential component in a number of Web applications. The sheer size of the Internet can pose problems in the design of Web crawlers. All currently known crawlers implement approximations or have limitations so as to maximize the throughput of the crawl, and hence, maximize the number of pages that can be retrieved within a given time frame. This paper proposes a distributed crawling concept which is designed to avoid approximations, to limit the network overhead, and to run on relatively inexpensive hardware. A set of experiments, and comparisons highlight the effectiveness of the proposed approach.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740866","Distributed Crawler;Web crawler;complete crawl","Australia;Bandwidth;Crawlers;Hardware;Information retrieval;Intelligent agent;Internet;Throughput;Web pages;Web search","Internet;Web sites;information retrieval","Internet;Web page crawlers;distributed crawling concept;limited resources;network overhead;scalable lightweight distributed crawler","","3","","6","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Effective Ranking and Recommendation on Web Page Retrieval by Integrating Association Mining and PageRank","J. H. Su; B. W. Wang; V. S. Tseng","Dept. of Comput. Sci. & Inf. Eng., Nat. ChengKung Univ., Tainan","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","455","458","Nowadays, the well-known search engines, such as Google, Yahoo, MSN, etc, have provided the users with good search results based on special search strategies. However there still exist some problems unsolved for traditional search engines, including: (1) the gap between userpsilas intention and searched results is not easy to narrow down under the global search space, and (2) userpsilas interested pages hidden in the local website are not associated with the search results. To deal with such problems, in this paper, we propose a novel approach for personalized page ranking and recommendation by integrating association mining and PageRank so as to meet userpsilas search goals. Moreover, by mining the userspsila browsing behaviors, we can successfully bridge the gap between global search results and local preferences. The effectiveness of our proposed approach was verified through experimental evaluations.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740820","","Bridges;Computer science;Information retrieval;Intelligent agent;Internet;Itemsets;Joining processes;Search engines;Web mining;Web pages","Web sites;data mining;information retrieval;search engines","PageRank;Web page retrieval;association mining;browsing behaviors;global search space;local Website;personalized page ranking;recommendation;search engines;search strategies","","1","1","8","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Semantic Concept Learning through Massive Internet Video Mining","P. Yuan; B. Zhang; J. Li","Dept. of Comput. Sci. & Technol., Tsinghua Univ., Beijing","2008 IEEE International Conference on Data Mining Workshops","20081230","2008","","","847","853","Semantic concept learning is one of the most challenging problems in video retrieval. The key barrier for semantic concept learning is lack of annotated training data. Internet videos are different from ordinary videos: massive, rich information, customized, non-uniform format, uneven quality, little descriptive text, only a few shots with limited length etc. Therefore, Internet is a potential repository to provide a reliable source for concept learning. In this paper, we focus on the semantic concept learning through known Internet video sources mining. Starting from the video-sharing websites, an automatical graph model generator for concepts relationship learning based on known ontology such as LSCOM, WordNet and ConceptNet is discussed. An automated source discovery method is addressed which prove to be useful in concept detection from the massive Internet videos. Experimental results prove that the addressed method is effective and efficient in semantic concept detection and learning through massive Internet video mining.","2375-9232;23759232","CD-ROM:978-0-7695-3503-6","10.1109/ICDMW.2008.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4734014","Semantic concept learning;automatical graph model generator;video mining","Conferences;Content based retrieval;Data mining;Information retrieval;Internet;Laboratories;Learning systems;Video on demand;Video sharing;YouTube","Internet;Web sites;learning (artificial intelligence);ontologies (artificial intelligence);video retrieval","ConceptNet;LSCOM;Web sites;WordNet;annotated training data;automated source discovery;massive Internet video mining;ontology;semantic concept learning;video retrieval","","4","","32","","","15-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Advanced user interfaces in traffic information systems","C. Wutiwiwatchai; S. Jiwasurat; S. Saychum; C. Sangkeettrakarn; J. Sumanon","National Electronics and Computer Technology Center, under the National Science and Technology Development Agency, the Ministry of Science and Technology, Pathumthani 12120 Thailand","2008 8th International Conference on ITS Telecommunications","20090106","2008","","","396","399","This article summarizes recent works on two advanced user interfaces for traffic information systems, which are expected to support the future amount of users accessing daily for the information. Natural language processing technology has been applied in two ways. First, automatic speech recognition and text-to-speech synthesis are integrated in a telephone call center in order to automatically retrieve call voices and provide voice information over telephones. Second, a question-answering system, developed on the widely-used instant messenger, is applied to provide traffic information over the computer network. Case studies in deploying the systems during traffic-congested occasions are also briefly reported.","","CD-ROM:978-1-4244-2858-8; POD:978-1-4244-2857-1","10.1109/ITST.2008.4740293","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740293","","Automatic speech recognition;Computer networks;Information retrieval;Information systems;Natural language processing;Network synthesis;Speech synthesis;Telecommunication traffic;Telephony;User interfaces","natural language processing;speech recognition;speech synthesis;traffic information systems;user interfaces","automatic speech recognition;computer network;natural language processing technology;text-to-speech synthesis;traffic information systems;user interfaces;widely-used instant messenger","","2","","15","","","24-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"Information embedding with reversible stegotext","O. Sumszyk; Y. Steinberg","Department of Electrical Engineering, Technion - IIT, Haifa 32000, Israel","2008 IEEE 25th Convention of Electrical and Electronics Engineers in Israel","20090106","2008","","","394","395","Information embedding is the transmission of an independent data embedded into a host signal via a host dependent channel. Reversible information embedding (RIE) extends this model by adding the requirement of decoding the host signal. In some applications however, this requirement is too strong. For example if the user is interested in decoding the data and further transmitting the stegotext, i.e. the result of the embedding of the independent data into the host. This work expands the study of information embedding channels by adding the requirement of retrieving the stegotext at the destination. A single-letter characterization of the achievable rate is developed. In particular, it is shown that this rate is higher than the achievable rate in the RIE problem.","","CD-ROM:978-1-4244-2482-5; POD:978-1-4244-2481-8","10.1109/EEEI.2008.4736555","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736555","Stegotext reversibility;information embedding;state dependent channels","Communication channels;Costs;Decoding;Digital signal processing;Distortion measurement;Entropy;Information retrieval;Memoryless systems;Signal analysis;Tin","encoding;steganography","host signal decoding;information embedding;single-letter characterization;state dependent channels;stegotext reversibility","","1","","3","","","3-5 Dec. 2008","","IEEE","IEEE Conference Publications"
"Tag Normalization and Prediction for Effective Social Media Retrieval","M. H. Hsu; H. H. Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","770","774","In this paper, we propose a tag normalization algorithm to unify the userspsila annotations. Meanwhile, we explore some general phenomena in a social annotation system and propose a supervised tag prediction model to predict the stabilized tag set of a resource, with feedback of a small amount of user annotation records. The experiments show that a large potion of the stabilized tag set is predicted, and it is feasible to reduce the requirement of sufficient user annotations in the applications of social annotations.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.92","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740546","prediction;social annotation;social media;tag normalization","Application software;Computer science;Feedback;Frequency;Information retrieval;Intelligent agent;Power engineering and energy;Power system modeling;Predictive models;Uniform resource locators","Web services;information retrieval","social annotation system;social media retrieval;supervised tag prediction model;tag normalization algorithm","","3","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Restrain the Linkage to Malicious Web Pages though Negative Link Weight","J. Luo; C. Zhu; W. Zhang; Z. Liu; J. Huang","","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","262","267","Currently, the search engine is mainly based on the Web content-identifying technique to deal with malicious Web pages. As long as the malicious content is identified, it is common to simply filter out the malicious pages or give some security warnings. They donpsilat distinguish the linkage to malicious pages from others during the pagepsilas rank. This paper mainly researches on the impact of the malicious Web pages on userpsilas surfing action and present a new surfing action model. Under the new surfing model, we put forward a new page rank algorithm with negative link weight penalty to restrain the linkage to malicious pages, in which the Web pages which link to malicious pages are punished. Subsidiary nodes are introduced to ensure the correctness and effectiveness of the algorithm under different conditions. Both theoretic analysis and simulation result show authority values of the pages linking to malicious pages will be reduced. It effectively restrains the linkage to malicious Web pages from the perspective of link analysis.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732826","Markov process;malicious webpage;negative link weight penalty;subsidiary node","Algorithm design and analysis;Analytical models;Couplings;Filters;Information retrieval;Joining processes;Knowledge acquisition;National security;Search engines;Web pages","Internet;information retrieval;search engines;security of data","Web content-identifying technique;malicious Web pages;negative link weight penalty;page rank algorithm;search engine;surfing action model","","0","","16","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Conceptual Framework of Information Retrieve and Reuse in Construction Projects","W. Hu","Sch. of Econ. & Manage., Tongji Univ., Shanghai, China","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","735","739","Information is an asset of organizations, proper reuse of information could reduce project time and cost, and improve management performance. Though information is more crucial than ever in construction project management, construction information is scattered in construction projects and each construction project is managed independently and separately, and construction information is usually lost in each phase of projects. Neither construction engineers nor organizations accumulate construction information and experiences systematically. In order to retrieve valuable information and reuse it in construction projects, a conceptual framework of information retrieve and reuse in projects is developed with construction information management and technology. The problem of information loss, which is barriers to improve project management performance,could be solved through efficient information retrieve and reuse in construction project lifecycle. And a web based construction information management system is suggested to facilitate information retrieve and reuse for the project participants.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.98","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737054","Project information;construction project;information retrieve;information reuse","Asset management;Conference management;Contracts;Costs;Engineering management;Environmental management;Information management;Information retrieval;Project management;Scattering","construction;information retrieval;project management","conceptual framework;construction project lifecycle management;information retrieval;information reuse","","2","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"From Web to Map: Exploring the World of Music","O. Goussevskaia; M. Kuhn; M. Lorenzi; R. Wattenhofer","ETH Zurich, Zurich","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","242","248","Ever growing music collections ask for novel ways of organization. The traditional browsing of folder hierarchies or search by title and album tends to be insufficient to maintain an overview of a collection of orders of thousands of tracks. Methods based on song similarity offer an alternative to keyword-based search. In this work we propose to use a high-dimensional map of the ""world of music"" as a data structure for music retrieval and exploration of personal collections. Our approach does not require expensive analysis of audio signals and scales to hundreds of thousands of tracks. The techniques presented in this work can be used in a variety of applications, ranging from automatic DJs to file sharing on mobile devices. As a concrete example, we have developed a Web-application that allows users to visualize and navigate through their music collections and create playlists by specifying trajectories.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740456","collaborative filtering;embedding;graph;high-dimensional space;music;music similarity;playlist;visualization","Collaboration;Concrete;Data structures;Information analysis;Information filtering;Information filters;Intelligent agent;Music information retrieval;Navigation;Visualization","data visualisation;mobile computing;online front-ends","Web-application;audio signals;data structure;high-dimensional map;keyword-based search;mobile devices;music retrieval;world of music","","3","","26","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Approach to Extracting Central URLs on Catalog Page","H. Bai; J. Wang; Y. Li","Nat. Network New Media Eng. Res. Center, Chinese Acad. of Sci., Beijing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","388","392","Catalog pages construct the intermediate layer in architecture of a standard Web site; therefore research on information retrieval for this kind of pages can be beneficial to improve Web crawler's efficiency. A page is called ""catalog-style"" if its main body is displayed as a sequence of regular entries, and the central link in each entry apparently contains the pagepsilas major information. Here, we propose a central-URL extraction approach, which can automatically recognize effective information from the main segmentation on catalog-page. Our approach combines machine learning classification and DOM (document object model) tree based analysis. For one page, we represent each block node, mainly DIV and table, by a set of content-based and structure-based features, which can be used as the input of support vector machine to determine whether it belongs to ""main-body"" or not. After identifying the main semantic block, a DOM tree based algorithm that utilizes catalog's heuristic rules is implemented to find the central URLs in the segmentation. The evaluation results show that our approach obtains encouraging results with a high recall/precision ratio. This can be applied in topic-specific search engine development and other Web applications.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.71","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732851","Machine Learning;Web Information Retrival;Web Segmentation;Web URL Extraction","Crawlers;Data mining;Information retrieval;Search engines;Service oriented architecture;Support vector machine classification;Support vector machines;Text categorization;Uniform resource locators;Web pages","Internet;cataloguing;document handling;information retrieval;learning (artificial intelligence);pattern classification;search engines;support vector machines;tree data structures","DOM tree based analysis;Web crawler;Web site;catalog page;central URL extraction;content-based feature;document object model;heuristic rule;information retrieval;machine learning classification;structure-based feature;support vector machine;topic-specific search engine development","","0","","6","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Ontology for Geographical Names Management and Retrieval","G. Cheng; Q. Du","Coll. of Autom., Univ. of Electron. Sci. & Technol. of China, Chengdu","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","784","788","Geographical Names are key components of all georeferenced information systems, including GIS applications in many diverse fields of knowledge and services. This paper we focus on building an ontology for gazetteers, the ontology will better support the gazetteers applications, maintenances, and usability. The ontology contains place types, spatial and temporal concepts and their relations. We firstly establish a prototype of geographical name ontology. Secondly, we analyzed geographical names concepts and their semantics, to describe the knowledge structure for this field. Then we use OWL to provide a formal description for these concepts and relations and propose a unified semantic framework for the description of the geographical names information. Finally, we make an experiment by establishing ontology-based knowledge base. Through the analysis of examples we showed that ontology-based geographical names information can be shared and reused conveniently, and that the information retrieval by assistant of ontology can be easily realized.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732936","","Environmental management;Information analysis;Information retrieval;Information systems;Knowledge acquisition;Knowledge management;OWL;Ontologies;Resource management;Thesauri","geographic information systems;information retrieval;ontologies (artificial intelligence)","GIS;geographical names management;information retrieval;ontology;semantics","","0","","12","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Filtering Short Queries by Means of Fuzzy Semantic-Lexical Relations for Meta-searchers Using WordNet","J. Serrano-Guerrero; F. P. Romero; J. A. Olivas","Dept. of Inf. Technol. & Syst., Univ. of Castilla-La Mancha, Ciudad Real","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","269","272","Query expansion is one of the most complex tasks in information retrieval. Several new queries can be expanded related to a user one. The problem arises in choosing the queries that are more useful for search process. Here it is supposed that the most useful expanded queries are those queries which have similar meanings with regard to the original query but the number of words that they (original and expanded query) share is low. So, their meanings are similar but grammatically they are different. So, following this idea, several experiments have been carried out to assess a fuzzy measure that is able to select which are the most useful expanded queries, i.e., a fuzzy filtering process for query expansion.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.112","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740777","","Fuzzy systems;Information filtering;Information filters;Information management;Information retrieval;Information technology;Intelligent agent;Metasearch;Power system management;Search engines","fuzzy set theory;information filtering;query processing","Wordnet;fuzzy semantic-lexical relations;information retrieval;meta-searchers;query expansion;short query filter","","1","","8","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Comparison of Performance for SVM Based Relevance Feedback Document Retrieval in Several Vector Space Models","T. Onoda; H. Murata; S. Yamada","Central Res. Inst. of Electr. Power Ind., Komae","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","169","172","We investigate the following data mining problems from the document retrieval: From a large data set of documents, we need to find documents that relate to human interest as few iterations of human testing or checking as possible. In each iteration a comparatively small batch of documents is evaluated for relating to the human interest. We apply active learning techniques based on Support Vector Machine for evaluating successive batches, which is called relevance feedback. Our proposed approach has been very useful for document retrieval with relevance feedback experimentally. In this paper, we adopt several Vector Space Models into our proposed method, and then show the comparison results of the performance of our method in several Vector Space Models.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740753","document retrieval;relevance feedback;support vector machine;vector space model","Aerospace industry;Data mining;Displays;Feedback;Humans;Information retrieval;Intelligent agent;Mining industry;Space technology;Support vector machines","data mining;iterative methods;learning (artificial intelligence);relevance feedback;support vector machines","active learning technique;data mining;document retrieval;human testing;iterative method;large data set;performance comparison;relevance feedback;support vector machine;vector space model","","0","","7","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Event Importance Analysis Based on Directed Graph","H. Zhi; Z. Liu","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai","2008 International Symposium on Intelligent Information Technology Application Workshops","20081230","2008","","","451","454","Research shows that event is the storage unit of human proposition memory. Some events determine other events' beginning and ending, which means these events are in a superior position while others in an inferior position. So, it is meaningful to mining the difference between all these events. In order to do this, an event description model based on directed graph is given, which depicts the relationship between events. Based on this model, importance of event is calculated. The calculation is iterative process, which is proved to be convergent to a fix-point. Finally, a cased is given, and the performance of the calculation process is analyzed.","","POD:978-0-7695-3505-0","10.1109/IITA.Workshops.2008.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731975","Directed graph;Event;Importance;Markov process","Application software;Artificial intelligence;Calculus;Humans;Information analysis;Information retrieval;Information technology;Joining processes;Performance analysis","directed graphs;information retrieval;iterative methods","directed graph;event description model;event importance analysis;human proposition memory;iterative process","","0","","10","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Comparison of Re-ranking Methods in Digital Libraries Using User Profiles","T. T. Van; M. Beigbeder","Centre G2I, Ecole Nat. Super. des Mines de St.-Etienne, St. Etienne","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","751","754","In this paper we present a comparative study of re-ranking methods using user profiles in digital libraries which contain scientific articles. While most of present personalized search systems only use content-based methods to re-rank search results, in our work we use many different content-based and citation-based methods for this purpose. We also study many functions to combine scores computed by these methods. We conducted experiments on the test collection used in the INEX 2005 campaign to evaluate our strategies and received interesting results.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740542","Digital Libraries;Personalized Search;Re-ranking;User Profiles","Asynchronous transfer mode;Computer science;Content based retrieval;History;Information retrieval;Intelligent agent;Monitoring;Search engines;Software libraries;Testing","content-based retrieval;digital libraries","INEX 2005 campaign;citation-based methods;content-based methods;digital libraries;reranking methods;user profiles","","0","","11","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Unsupervised zoning of scientific articles using huffman trees","E. Kagan; I. Ben-Gal; N. Sharkov; O. Maimon","Dept. of Industrial Engineering, Tel-Aviv University, Ramat-Aviv, 69978, Israel","2008 IEEE 25th Convention of Electrical and Electronics Engineers in Israel","20090106","2008","","","399","402","In this report we propose a new method of unsupervised zoning based on Huffman coding trees. The suggested method acts on the level of sentences and obtains a Huffman tree whose upper part is equal to the tree created by the method of argumentative zoning. The proposed method gives a general framework for the unsupervised zoning, and may be straightforwardly transformed to supervised zoning by mapping the bits defined by human annotator into features.","","CD-ROM:978-1-4244-2482-5; POD:978-1-4244-2481-8","10.1109/EEEI.2008.4736557","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736557","Huffman coding;Text-mining;symbolic dynamics;unsupervised zoning","Data mining;Decision trees;Huffman coding;Humans;Information retrieval;Search problems;Statistical analysis;Text analysis;Text mining","Huffman codes;data mining;natural sciences computing;statistical analysis;text analysis;trees (mathematics)","Huffman coding tree;argumentative zoning method;scientific article;statistical scientific document segmentation;text-mining;unsupervised zoning method","","0","","10","","","3-5 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Improvement of Chinese Characters Location Algorithm Based on Video","X. Wang","Coll. of Math. & Comput. Sci., Hebei Univ., Baoding","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","634","637","There are still some shortcomings in the existing traditional location algorithm, so we focus on the improvement of the algorithm through the unique characteristics of video images, like edge, gradient, etc. First, we can determine which are the caption frames according to the region gradient value, then use the method of re-projection to locate the subtitles region on the basis of caption frames. The judgment of the caption frames of the video effectively reduces the complexity of the text recognition. The method of re-projection can avoid the false text region between the two lines of subtitles regions. It suits each kind of video images. The experiment indicates this method could locate the video image subtitles region well. Comparing with the other methods, it had great improving and provided a convenience for the next recognition.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.377","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739841","Sobel operator;false text region;frames;re-projection","Application software;Cameras;Computer science;Educational institutions;Filters;Image edge detection;Information retrieval;Information technology;Mathematics;Text recognition","image recognition;text analysis;video signal processing","Chinese characters location algorithm;caption frames;region gradient value;reprojection method;text recognition;video images","","0","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Partial Relevance Feedback for 3D Model Retrieval","H. Baokun; L. Yusheng; G. Shuming; H. Jing","State Key Lab. of CAD&CG, Zhejiang Univ., China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","2","","198","201","Relevance feedback (RF) proved an effect way to improve the precision and recall of 3D model retrieval. Unfortunately, through existing methods of RF, it is straightforward to find out whether a model is similar or not, but it is impossible to find out which local part is similar or not. The new partial method of RF proposed in this paper provides a good solution, in which not only the similar models are marked out but also the local parts which are similar or not are pointed out and taken advantage at the same time. This additional information contributes a lot to the improvement of 3D retrieval. Experiments show superiority in effectivity of the new method.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.234","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731602","3d model retrieval;partial relevance feedback;relevance feedback","Computer science;Feedback;Information retrieval;Kernel;Linear discriminant analysis;Radio frequency;Shape;Space technology;Wrapping","relevance feedback","3D model retrieval;partial relevance feedback","","0","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Co-occurrence Based Hierarchical Method for Clustering Web Search Results","Y. Zhang; B. Feng","Sch. of Electron. & Inf. Eng., Xian Jiaotong Univ., Xian","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","407","410","This study proposes a novel method to group and organize search results. We apply statistical techniques to term co-occurrence information in a corpus to retrieve bi-grams firstly, and then combine bi-grams into n-grams. After eliminating redundant n-grams, the remaining ones are ranked and selected as cluster labels. Base clusters are constructed according to these cluster labels and then agglomerated into higher-level clusters. We refer to the proposed algorithm as CoHC (co-occurrence based hierarchical clustering). we compare CoHC with three other search results clustering (SRC) algorithms: suffix tree clustering (STC), Lingo, and Vivisimo. We also analyze the properties of cluster labels produced by different SRC algorithms. The experimental results show that our method outperforms the other three SRC algorithms, and is helpful to the user for browsing and locating the results of interest.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740483","CoHC (Co-occurrence based hierarchical clustering);clustering evaluation;labeling-then-clustering approach;search results clustering","Algorithm design and analysis;Clustering algorithms;Data mining;Information retrieval;Intelligent agent;Internet;Scattering;Search engines;Singular value decomposition;Web search","Internet;information retrieval;pattern clustering;statistical analysis","Lingo;Vivisimo;Web search result clustering;cooccurrence based hierarchical clustering;statistical technique;suffix tree clustering","","3","","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Linked Topic and Interest Model for Web Forums","V. Cheng; C. H. Li","Dept. of Comput. Sci., Hong Kong Baptist Univ., Kowloon","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","279","284","In Web forum analysis, both the discussion topics and author interests are greatly concerned. We introduce a linked topic and interest model based on latent Dirichlet allocation (LDA) to explore discussion topics and author interests. Rather than having two separate models or modeling combined topics and interests with just one hidden topic assignment variable, the proposed model has separate but linked hidden variables for topic and interest exploration. As exact model parameter inference is intractable, Gibbs sampling is employed to estimate topic, author, and interest distributions. The joint distribution of the linked hidden variables also provides an interpretation of an interest in terms of weighted topics or vice versa. We apply the model to a NIPS data set and a corpus containing text contents of a popular digital camera Web forum. Topics and interests discovered by using the model is demonstrated. The model generalization capability is also assessed by means of perplexity and the results show that the linked topic and interest model has performance exceeding that of LDA document topic model and author topic model.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740461","LDA;topic model;user interest;web forums","Computer science;Content based retrieval;Digital cameras;Indexing;Information analysis;Information retrieval;Intelligent agent;Large scale integration;Linear discriminant analysis;Sampling methods","Internet;sampling methods;text analysis","Gibbs sampling;Web forum analysis;author interests model;discussion topic;latent Dirichlet allocation;model generalization capability","","1","","7","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Hybridization of K-Means and Harmony Search Methods for Web Page Clustering","R. Forsati; M. Meybodi; M. Mahdavi; A. Neiat","Dept. of Comput. Eng., Islamic Azad Univ., Qazvin","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","329","335","Clustering is currently one of the most crucial techniques for dealing with massive amount of heterogeneous information on the web, which is beyond human beingpsilas capacity to digest. Recent studies have shown that the most commonly used partitioning-based clustering algorithm, the K-means algorithm, is more suitable for large datasets. However, the K-means algorithm can generate a local optimal solution. In this paper we present novel harmony search clustering algorithms that deal with documents clustering based on harmony search optimization method. By modeling clustering as an optimization problem, first, we propose a pure harmony search based clustering algorithm that finds near global optimal clusters within a reasonable time. Contrary to the localized searching of the K-means algorithm, the harmony search clustering algorithm performs a globalized search in the entire solution space. Then harmony clustering is integrated with the K-means algorithm in three ways to achieve better clustering. The proposed algorithms improve the K-means algorithm by making it less dependent on the initial parameters such as randomly chosen initial cluster centers, hence more stable. In the experiments we conducted, we applied the proposed algorithms, K-means clustering algorithm on five different document datasets. Experimental results reveal that the proposed algorithms can find better clusters when compared to K-means and the quality of clusters is comparable and converge to the best known optimum faster than it.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.370","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740468","Clustering;Data Mining;Optimization","Clustering algorithms;Clustering methods;Data mining;Information retrieval;Intelligent agent;Optimization methods;Partitioning algorithms;Search methods;Stochastic processes;Web pages","Internet;optimisation;pattern clustering;search problems;text analysis","K-means algorithm;Web page clustering;document clustering;harmony search clustering algorithm;harmony search optimization method;partitioning-based clustering algorithm;text analysis","","16","","12","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Recognizing Textual Entailment Based on WordNet","J. Feng; Y. Zhou; T. Martin","Dept. of Comput. Sci., Beihang Univ., Beijing","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","2","","27","31","Textual entailment recognition (RTE) is one of the fundamental problems in many natural language processing applications. This paper proposes a new method for lexical entailment measure which is based on exploiting the information in the WordNet glosses. Further we perform textual entailment recognition based on this method and cast the RTE problem to be a classification problem. The experimental result on RTE challenge data sets indicates that our method is promising.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739720","Textual Entailment;WordNet","Application software;Conferences;Information retrieval;Machine learning;Machine learning algorithms;Natural language processing;Probability;Speech;Statistical analysis;Text recognition","natural language processing;pattern classification","RTE problem;WordNet;classification problem;lexical entailment measure;natural language processing;textual entailment recognition","","2","","20","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Land subsidence monitoring using InSAR time series, case study: Mashhad, Iran (2004–2007)","V. Akbari; M. Motagh; M. A. Rajabi; Y. Djamour; M. Seddighi","Dept. of Surveying and Geomatics Eng., University of Tehran, Iran","2008 Second Workshop on Use of Remote Sensing Techniques for Monitoring Volcanoes and Seismogenic Areas","20090106","2008","","","1","4","Interferometric Synthetic Aperture (InSAR) observations acquired by the Envisat satellite in a descending orbit during 2004-2007 are used to study land subsidence caused by groundwater over-exploitation in Mashhad Valley, northeast of Iran. Motagh et al (GJI 2006) presented a preliminary analysis of the subsidence in this area using a few interferograms covering the 2003-2005 periods. This paper utilizes ENVISAT data to retrieve the temporal evolution of the surface deformation in Mashhad.","2151-2019;21512019","CD-ROM:978-1-4244-2547-1; POD:978-1-4244-2546-4","10.1109/USEREST.2008.4740371","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740371","InSAR;Land subsidence;Least Squares","Geology;Information retrieval;Least squares methods;Monitoring;Radar detection;Satellites;Surface topography;Synthetic aperture radar;Synthetic aperture radar interferometry;Time series analysis","deformation;geomorphology;groundwater;radar interferometry;remote sensing by radar;synthetic aperture radar","AD 2004 to 2007;ENVISAT data;InSAR time series;Interferometric Synthetic Aperture Radar observation;Iran;Mashhad Valley;groundwater over-exploitation;interferograms;land subsidence monitoring;surface deformation temporal evolution","","0","","8","","","11-14 Nov. 2008","","IEEE","IEEE Conference Publications"
"Research on Activity Based Use Case Meta-Model","M. Lei; W. C. Jiang","","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","843","846","As an efficient way to describe functional requirements, use case is accepted by more and more developers. Despite their popularity, there are many problems in the usage of use cases. To solve the problems that encountered, we propound an activity based use case meta-model to represent use case in a multiple perspective and to enhance use case reuse.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737076","","Educational institutions;Information retrieval;Jacobian matrices;Memory;Programming;Prototypes;Software prototyping;Teamwork;Unified modeling language;Writing","Unified Modeling Language;software reusability","UML;activity based use case meta-model;functional requirements;use case reuse enhancement","","1","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Image Retrieval Based on Fuzzy Kernel Clustering and Invariant Moments","P. Hao; Y. Ding; Y. Fang","Sch. of Comput. Eng. & Sci., ShangHai Univ., Shanghai, China","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","1","","447","452","KFCM is a new clustering method, which is applied in pattern classification in some way. However, it has not been applied in the field of content-based image retrieval (CBIR). Considering the predefinition of clustering number and membership matrix is still a hot potato, a novel predefinition approach is proposed in this paper, what's more, a new CBIR method is suggested and validated. First, values of images are extracted, then they are clustered by fuzzy kernel clustering, and edges are detected by Canny operator, finally, edge invariant moments are calculated and formalized. After that, the Euclidean distance between two images' formalized moment vectors gives a measure of similarity. Experimental results show that the proposed algorithm having better ability in the anti-noise, and the precision and recall are remarkably improved as well.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739613","","Application software;Clustering algorithms;Content based retrieval;Image edge detection;Image retrieval;Image segmentation;Information retrieval;Information technology;Kernel;Shape","content-based retrieval;fuzzy set theory;image classification;image retrieval","CBIR method;Canny operator;Euclidean distance;KFCM;clustering number;content-based image retrieval;edge invariant moments;fuzzy kernel clustering;membership matrix;pattern classification;predefinition approach","","1","","15","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Digital Video Retrieval via Mobile Devices","C. M. Chen; Y. Z. Wang; H. A. Wang; C. Y. Chiu","Dept. of CSE, Yuan Ze Univ. Taoyuan, Taoyuan","2008 IEEE Fourth International Conference on eScience","20090106","2008","","","376","377","In this article, we present a content-based video search service for mobile device users. After taking a photograph, the user can upload it to our server, which will then return videos containing key frames that are similar to the uploaded picture. The proposed service demonstrates that the search application is feasible.","","CD-ROM:978-0-7695-3535-7; POD:978-1-4244-3380-3","10.1109/eScience.2008.153","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736804","Content-based retrieval;mobile search;shot change detect","Content based retrieval;Feature extraction;Gunshot detection systems;Image databases;Image retrieval;Information retrieval;Spatial databases;Video sharing;Videoconference;Web server","content-based retrieval;mobile computing;query formulation;video retrieval","content-based video search service;digital video retrieval;mobile devices;photograph","","0","","3","","","7-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Automatic Certificate Based Account Generation and Secure AJAX Calls in a Grid Portal","M. L. Green; D. A. Alexander; R. Pundaleeka; J. Matykiewicz","Tech-X Corporation, 5621 Arapahoe Avenue Suite A, Boulder, CO 80301. + 1 (303) 448-7751, mlgreen@txcorp.com","2008 Grid Computing Environments Workshop","20090106","2008","","","1","8","Virtual organizations are interested in providing secure grid-related services to individual scientist users through portals and invest significant time and effort in managing them. Systems are often in place for users to request and receive grid certificates in many grid infrastructures as a basis for their identity in the grid. These identities are, however, typically disconnected from Web portal accounts and this presents an administrative maintenance problem. Furthermore, integrating certificate identities with grid portal identities is complicated when dynamic AJAX technology is used in the portal to connect to services outside the portal. The User Centric Monitoring project has developed a solution for automatic generation of Web portal accounts that can be synchronized to a pre-existing list of grid certificate identities.","2152-1085;21521085","POD:978-1-4244-2860-1","10.1109/GCE.2008.4738444","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4738444","AJAX;Design;Experimentation;Grid computing;Java Portal;Management;Web 2.0","Application software;Computer networks;Computerized monitoring;Distributed computing;Grid computing;Identity management systems;Information retrieval;Information security;Mesh generation;Portals","Java;XML;authorisation;grid computing;portals","User Centric Monitoring project;Web portal accounts;automatic certificate based account generation;dynamic AJAX technology;grid certificate identities;grid portal identities;secure grid-related services;virtual organizations","","1","","14","","","12-16 Nov. 2008","","IEEE","IEEE Conference Publications"
"A Unified Framework for Thai Metadata Extraction Using Case-Based Reasoning","K. Khankasikam; N. Chakpitak","Sch. of Inf. Commun. & Technol., Naresuan Univ. Phayao, Phayao","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","210","214","Metadata is a very popular word in information technology today because it helps users to differentiate significant documents from non-significant documents. With the growth of the Internet and related tools, there has been a rapid growth of online resources. However, lack of metadata available for these resources stops their discovery and dissemination over the Internet. The process for manual metadata extraction is time-consuming, costly, and labor-extensive. This paper describes a framework for automatic metadata extraction from electronic Thai documents. The system consists of three main components: a case retrieval module for comparing problem case and stored case using nearest neighbor retrieval technique, a metadata creation module for automatically extracting metadata from electronic Thai documents using Thai information extraction techniques, and a metadata verification module for correcting the errors in extracted metadata. The experimental results show that using the proposed framework could reduce the labor work of Thai metadata creation process.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736952","Case-based Reasoning;Metadata Extraction","Artificial intelligence;Automatic speech recognition;Communications technology;Data mining;Face recognition;Information retrieval;Internet;Natural language processing;Speech recognition;Text recognition","case-based reasoning;document handling;information retrieval;meta data;natural language processing","Internet;Thai metadata extraction;case-based reasoning;electronic Thai documents;metadata verification module;nearest neighbor retrieval technique;online resources","","1","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Inference Networks for Chemical Similarity Searching","A. Abdo; N. Salim","Fac. of Comput. Sci. & Inf. Syst., Univ. Teknol. Malaysia, Skudai, Malaysia","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","408","412","Similarity searching is becoming the simplest tool available for similarity-based virtual screening of chemical databases. Over the years many methods have been developed. A variety of similarity metrics have been introduced, but by far the most prominent is the Tanimoto coefficient. Currently, Bayesian classifiers are increasingly widely used for virtual screening of chemical databases. In this paper, a novel similarity searching approach using inference Bayesian network is discussed. The retrieved of an active compound is obtained by means of an inference process through a network of dependences. Experiments on MDDR demonstrate that similarity approach based on Bayesian inference networks outperforms the similarity search approach with Tanimoto coefficient and offer promising alternative to existing similarity search approaches.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736991","Bayesian Inference Network;Inference Networks;Similarity Searching;Virtual Screening","Bayesian methods;Chemical engineering;Computer networks;Computer science;Data engineering;Information retrieval;Information systems;Query processing;Spatial databases;Turing machines","belief networks;chemistry computing;database management systems;pattern classification;probability;query processing","Bayesian classifier;Bayesian inference network;Tanimoto coefficient;chemical database;chemical similarity searching;probability distribution;query network;similarity-based virtual screening","","2","","20","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Novel Video Searching Model Based on Ontology Inference and Multimodal Information Fusion","J. Zhang","Dept. of Comput. Sci. & Eng., East China Univ. of Sci. & Technol., Shanghai, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","2","","489","492","Video comprises multiple types of textual, audio and visual information, and each of them contains abundant semantic information. Therefore multimodal features query and fusion are necessary in video retrieval. In this paper, we propose a new video retrieval model, which adopts multi-model including text, image, semantic concept and camera motion to query video. Then relation algebra expression is advanced to fuse multimodal information instead of traditional linear fusion method. In semantic concept detection model, Bayesian network based ontology is proposed to extract concepts. The experiments on TRECVID 2005 corpus have demonstrated a superior performance compared with exiting key approaches of video retrieval by multimodal information fusion.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.86","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731670","Multimodal information fusion;Relation algebra expression;Video retrieval;ontology","Algebra;Bayesian methods;Cameras;Computer science;Content based retrieval;Databases;Fuses;Image retrieval;Information retrieval;Ontologies","Bayes methods;ontologies (artificial intelligence);relational algebra;sensor fusion;video retrieval","Bayesian network;TRECVID 2005 corpus;camera motion;linear fusion method;multimodal information fusion;ontology inference;relation algebra expression;semantic information;video retrieval;video searching model","","0","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Cool Blog Identi?cation Using Topic-Based Models","K. Sriphaew; H. Takamura; M. Okumura","Precision & Intell. Lab., Tokyo Inst. of Technol., Yokohama","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","402","406","Among a huge number of blogs on the internet, only some of them are considered to have great contents and worth to be explored. We call such kind of blogs cool blogs and attempt to identify them. To solve the cool blog identification problem, we consider three assumptions on cool blogs: (1) cool blogs tend to have definite topics, (2) cool blogs tend to have sufficient amount of blog entries, and (3) cool blogs tend to have certain levels of topic consistency among their blog entries. Corresponding to these assumptions, we extract a mixture of topic probabilities using a topic model, exploit the number of blog entries of each blog, and calculate the topic consistency among blog entries using distance functions over topic probabilities, respectively. We show the benefits of the proposed assumptions through these features. A feature unification model is also presented to achieve highest effectiveness. The experimental results on Japanese blog data show that we can improve the classification results by applying proposed assumptions.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740482","Cool blog;topic consistency;topic-based model","Books;Data mining;Feature extraction;Information retrieval;Information services;Intelligent agent;Internet;Laboratories;Probability;Web sites","Internet;Web sites;classification;probability","Internet;classification;cool blog identification;distance functions;topic probabilities;topic-based models","","3","","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Towards Better Content Visibility in Video Recommender Systems","N. Chakoo; R. Gupta; J. Hiremath","Digital Media (R&D) Group, Samsung India Software Center, India","2008 Japan-China Joint Workshop on Frontier of Computer Science and Technology","20090106","2008","","","181","185","Current recommender systems based on filtering techniques implement a rather limited model for video content visibility. Most of these systems fall short to provide visual precursor to the user and concentrate only on making more accurate predictions; however, a few of them that focus their attention to the aspect of multimedia (video) item visibility do so in a limited scope. In this paper, we address this problem and propose to augment the existing recommender systems with a dynamic user-based scheme to provide users with superior, high-quality recommendation formulation and customized visibility of the recommended item. The domain of content visibility is dynamically crafted using the existing recommender system algorithm.","2159-6301;21596301","POD:978-0-7695-3540-1","10.1109/FCST.2008.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736526","Collaborative Filtering;Content Visibility;Recommender System;Scene Matrix;Video-on-Demand","Consumer electronics;Data mining;Filtering;Information retrieval;Layout;Multimedia systems;Recommender systems;Research and development;TV;Web and internet services","information filters;video retrieval","dynamic user-based scheme;video content visibility;video recommender system","","0","3","7","","","27-28 Dec. 2008","","IEEE","IEEE Conference Publications"
"Design and Implementation of Generalized R-Tree","H. Li; S. Ju; W. Chen","Sch. of Comput. Sci. & Telecommun. Eng., Jiangsu Univ., Zhenjiang, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","1","","777","781","Contemporary multi-dimensional database technology is severely limited at managing indexed data types of keys for many advanced application. Here, we present an elaborate retrieval method to extend the traditional R-tree, and we call it Generalized R-Tree(GRT). It can serve as an indexing structure in some multi-dimensional database systems. This method mainly addresses the problem of that traditional R-tree only index coordinate data but useless for ADTs. It means that GRT realizing the extensibility of indexed keys. GRT not only has common facilities of R-tree, but also leaves users a set of key-methods. So users can make use of them to help express their requirements to system. The advantage of this method is that it is easily extensible both in data types it can index and in the query predicates it can support, making retrieve processing more flexible and more extensible. It opens the application of R-tree to general extensibility. We also provide a simple method implementation procedure to illustrate the flexibility of GRT.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731540","data type of keys;extensibility of indexed keys;key-methods;traditional R tree","Application software;Computer science;Data engineering;Databases;Design engineering;Engineering management;Indexing;Information retrieval;Technology management;Telecommunication computing","database indexing;information retrieval","contemporary multidimensional database technology;generalized R-tree;indexing structure;multidimensional database systems;retrieval method;retrieve processing","","0","","6","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Tailoring Taxonomies for Efficient Text Categorization and Expert Finding","R. Wetzker; W. Umbrath; L. Hennig; C. Bauckhage; T. Alpcan; F. Metze","DAI-Labor, Tech. Univ. Berlin, Berlin","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","459","462","Automatic content categorization by means of taxonomies is a powerful tool for information retrieval and search technologies as it improves the accessibility of data both for humans and machines. While research on automatic categorization has mainly focused on the problem of classifier design, hardly any effort has been spent on the optimization of the taxonomy size itself. However, taxonomy tailoring may significantly improve computational efficiency and scalability of modern retrieval systems where taxonomies often consist of tens of thousands of non-uniformly distributed categories. In this paper we demonstrate empirically that small subtrees of a taxonomy already enable reliable categorization. We compare several measures for the optimal selection of sub-taxonomies and investigate to what extent a reduction affects the classification quality. We consider applications in classical document categorization and in the upcoming area of expert finding and report corresponding results obtained from experiments with standard benchmark data.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740821","optimization;tailoring taxonomies;text categorization","Computational efficiency;Content based retrieval;Design optimization;Humans;Information retrieval;Intelligent agent;Laboratories;Taxonomy;Text categorization;Usability","content management;information retrieval;text analysis","automatic content categorization;classical document categorization;expert finding;information retrieval;search technology;text categorization","","0","2","10","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"The MPEG Query Format: Unifying Access to Multimedia Retrieval Systems","J. R. Smith; M. Döller; R. Tous; M. Gruhne; K. Yoon; M. Sano; I. S. Burnett","IBM","IEEE MultiMedia","20090106","2008","15","4","82","95","The growth of multimedia is increasing the need for standards for accessing and searching distributed repositories. The moving picture experts group (MPEG) is developing the MPEG query format (MPQF) to standardize this interface as part of MPEG-7. The objective is to make multimedia access and search easier and interoperable across search engines and repositories. This article describes the MPQF and highlights some of the ways it goes beyond today's query languages by providing capabilities for multimedia query-by-example and spatiotemporal queries.","1070-986X;1070986X","","10.1109/MMUL.2008.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740394","","Database languages;Diversity reception;Information retrieval;Laboratories;MPEG 7 Standard;Mobile handsets;Multimedia databases;Multimedia systems;TV;XML","multimedia systems;query languages;query processing;video coding","MPEG query format;distributed repositories access;distributed repositories searching;moving picture experts group;multimedia query-by-example;multimedia retrieval systems;query languages;spatiotemporal queries;standards","","15","3","18","","","Oct.-Dec. 2008","","IEEE","IEEE Journals & Magazines"
"A New Scheme of Image Retrieval Based Upon Digital Watermarking","J. Xu; W. h. Qin; M. y. Ni","Coll. of Phys. Eng., Qufu Normal Univ., Qufu, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","1","","617","620","Watermark is a new effective digital copyright protection method and data security technology. A new scheme of image retrieval based upon digital watermarking has been proposed. First, embeds the binary watermark information in carried image, computes the value of NC (normalized correlation coefficient) between query watermark and extracted watermark,and gains the retrieval results. The watermarking algorithm is carried out in DCT (discrete cosine transform) domain, and extracting process is instantaneous and blind. The experimental results show that this method cannot only protect the copyright reliably, but also realize image retrieval effectively.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731504","copyright protection;digital watermarking;discrete cosine transform;image retrieval","Copyright protection;Data engineering;Data mining;Discrete cosine transforms;Educational institutions;Image databases;Image retrieval;Information retrieval;Real time systems;Watermarking","discrete cosine transforms;image coding;image retrieval;watermarking","data security technology;digital copyright protection method;digital watermarking;discrete cosine transform;extracted watermark;image retrieval scheme;normalized correlation coefficient;query watermark","","0","","6","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Mining relation between the blogger and query in blog retrieval system","D. Lin; D. Cao; S. Li","Department of Cognitive Science, XiaMen University, 361005, China","2008 3rd International Conference on Intelligent System and Knowledge Engineering","20081230","2008","1","","267","272","Blog is one of the important components in Web 2.0. Many blog retrieval systems still use the classical retrieval method in Web page retrieval. In this paper, we present a new retrieval approach which is based on the relation between the blogger and query. The advantage of this approach is collecting the semantic information which we called blogger role in retrieval model. The experiments show that this approach achieves a better performance than the classical retrieval model in blog retrieval.","","POD:978-1-4244-2196-1","10.1109/ISKE.2008.4730939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730939","","Cognitive science;Computers;Equations;Information retrieval;Information services;Intelligent networks;Intelligent systems;Internet;Knowledge engineering;Web sites","Web sites;data mining;query processing","Web 2.0;Web page retrieval;blog retrieval system;blogger","","0","","10","","","17-19 Nov. 2008","","IEEE","IEEE Conference Publications"
"The Related Techniques of Content-Based Image Retrieval","X. Yu; J. Xu","Coll. of Comput. Sci. & Inf. Enginerring, Zhejiang Gongshuang Univ., Hangzhou, China","2008 International Symposium on Computer Science and Computational Technology","20081230","2008","1","","154","158","With the popularity of the network and development of multimedia technology, the traditional information retrieval techniques do not meet the usersÂ¿ demand. Recently, the content-based image retrieval has become the hot topic and the techniques of content-based image retrieval have been achieved great development. In this paper, the basic components of content-based image retrieval system are introduced. Image retrieval methods based on color, texture, shape and semantic image are discussed, analyzed and compared. The semantic-based image retrieval is a better way to solve the Â¿semantic gapÂ¿ problem, so the semantic-based image retrieval method is stressed in this paper. Other related techniques such as relevance feedback and performance evaluation also discussed. In the end of paper the problems and challenges are proposed.","","POD:978-0-7695-3498-5","10.1109/ISCSCT.2008.136","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731396","","Computer science;Content based retrieval;Feature extraction;Humans;Image analysis;Image color analysis;Image retrieval;Information retrieval;Search engines;Shape","content-based retrieval;image retrieval","content-based image retrieval;multimedia technology;relevance feedback;semantic gap;semantic image","","3","","10","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Focused Crawling with Heterogeneous Semantic Information","R. Huang; F. Lin; Z. Shi","Key Lab. of Intell. Inf. Process., Chinese Acad. of Sci., Beijing","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","525","531","Focused crawlers selectively retrieve Web documents that are relevant to a predefined set of topics. To intelligently make predictions and decisions about relevant URLs and web pages, different topic models have been introduced to represent topic-specific knowledge. Yet it is difficult to support semantic interoperability among different models. Moreover, some manually specified additional semantic information, such as semantic markups and social annotations, could not be effectively used to improve crawling. This paper proposes to boost focused crawling with four kinds of semantic models and semantic information, including thesauruses, categories, ontologies, and folksonomies. A statistical semantic association model is proposed to integrate different semantic models, represent heterogeneous semantic information, and support semantic relevance computation. A focused crawling framework is developed which adopts both keyword based contents and different kinds of additional information for relevance prediction and ranking. Experiments show that the proposed model and framework effectively integrates heterogeneous semantic information for focused crawling.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.87","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740502","Category;Focused Crawling;Folksonomy;Ontology;Semantic Web;Thesaurus","Computers;Crawlers;Information processing;Information retrieval;Intelligent agent;Ontologies;Predictive models;Semantic Web;Uniform resource locators;Web pages","Internet;information retrieval;knowledge representation;open systems","URL;Web documents retrieval;Web pages;categories;focused crawling;folksonomies;heterogeneous semantic information;ontologies;semantic interoperability;statistical semantic association;thesauruses;topic-specific knowledge representation","","1","","15","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Trademark Image Retrieval Using Wavelet-based Shape Features","M. Jian; L. Xu","Sch. of Space Sci. & Phys., Shandong Univ. at Weihai, Weihai","2008 International Symposium on Intelligent Information Technology Application Workshops","20081230","2008","","","496","500","In this paper, we focus on the problem of image retrieval in trademark database and concentrate on the method for efficient trademark image retrieval based on new shape feature without complicated image segmentation. The proposed trademark image retrieval scheme comprises two stages: first, edge detection based on wavelet transform is performed on the trademark image, second, novel wavelet -based shape features are introduced to reflect the edge's characteristic. The new features contain four directionality information of the trademark edge, namely 0, pi/4 , 3pi/4 and pi. We used the shape features to indexing the image for the trademark image retrieval. In addition, one of the merit of the scheme is that the two stage are both used wavelet transform, this can quicken the retrieval efficiency. A wide range of trademark images for the experiments have performed, Experimental results show the method is promising.","","POD:978-0-7695-3505-0","10.1109/IITA.Workshops.2008.209","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731986","","Image databases;Image edge detection;Image retrieval;Image segmentation;Indexing;Information retrieval;Shape;Spatial databases;Trademarks;Wavelet transforms","image retrieval;image segmentation;wavelet transforms","edge detection;image segmentation;trademark image retrieval;wavelet transform;wavelet-based shape features","","3","1","16","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Revisiting the basic issue of parameter estimation in system identification - a new approach for multi-value estimation","S. Bittanti; S. Garatti","Dipartimento di Elettronica ed Informazione, Politecnico di Milano, p.zza L. da Vinci 32, 20133, Italy","2008 47th IEEE Conference on Decision and Control","20090106","2008","","","1956","1961","In this paper, we consider one of the basic estimation problem, that of identifying an unknown parameter in a given model from measurements of input/output data. The existing methods have been conceived for the estimation of the value taken by the parameter in a given functioning condition. However, there are situations where one has to provide an estimator equally valid for different values of the parameter associated with various functioning conditions (multi-value estimation problem). The application of the available techniques lead then to poor accuracy in estimation. In this paper we propose a novel approach, the two-stage approach, tailored to the multi-value estimation problem. We compare its performances with those achievable with other parameter estimation techniques such as prediction error and Kalman filter based methods. By means of a benchmark example, we spot out advantages and drawbacks of each method, by also discussing their domain of applicability. It turns that the two stage approach offers significant improvements.","0191-2216;01912216","POD:978-1-4244-3123-6","10.1109/CDC.2008.4739046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4739046","Extended Kalman filter methods;Parameter estimation;System identification;White box identification","Concrete;Design methodology;Information retrieval;Life estimation;Mathematical model;Noise generators;Parameter estimation;System identification;Tires;Vectors","Kalman filters;parameter estimation","Kalman filter based method;multi-value estimation;parameter estimation;prediction error method;system identification","","2","","23","","","9-11 Dec. 2008","","IEEE","IEEE Conference Publications"
"Evaluation of the Effects of User-Sensitivity on Text Summarization","H. Nguyen; E. Santos Jr.; R. Jacob; N. Smith","Dept. of Math & Comput. Sci., UW-Whitewater, Whitewater, WI","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","927","931","Along with research on information retrieval and filtering, text summarization is an effective technique to help users save time in finding critical information and making timely decisions. Some existing summarization approaches have used a userpsilas interests to develop a personalized text summarization system. However, there is inadequate focus on exploring cognitive styles, which have been found to affect the ways users think, perceive and remember information. Our main objective of this evaluation is to investigate the effect of a userpsilas cognitive style on multi-document summarization. We examine two dimensions of a userpsilas cognitive style which are the analytic/who list and verbal/imagery dimensions. We conducted an experiment to determine the impact of a userpsilas cognitive style when working with different types of document sets. The type of a document set refers to whether the content of this set is loosely related or closely related. Our results show that users in general are insensitive to the types of document sets both in terms of information covered in a summary as well as the way that a summary is written and presented. However, if we group users by the analytic/who list dimension, we found that people in groups are sensitive to the way that the information is presented for different types of document sets.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.375","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740578","Text summariation;cognitive styles;user study","Educational institutions;Image analysis;Information analysis;Information filtering;Information filters;Information retrieval;Intelligent agent;Jacobian matrices;System testing","cognition;human factors;text analysis","document set;information filtering;information retrieval;personalized text summarization system;user cognitive style;user-sensitivity effect evaluation","","2","","25","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"An Approach to Deep Web Crawling by Sampling","J. Lu; Y. Wang; J. Liang; J. Chen; J. Liu","Sch. of Comput. Sci., Univ. of Windsor, Windsor, ON","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","718","724","Crawling deep web is the process of collecting data from search interfaces by issuing queries. With wide availability of programmable interface encoded in Web services, deep web crawling has received a large variety of applications. One of the major challenges crawling deep web is the selection of the queries so that most of the data can be retrieved at a low cost. We propose a general method in this regard. In order to minimize the duplicates retrieved, we reduced the problem of selecting an optimal set of queries from a sample of the data source into the well-known set-covering problem and adopt a classical algorithm to resolve it. To verify that the queries selected from a sample also produce a good result for the entire data source, we carried out a set of experiments on large corpora including Wikipedia and Reuters. We show that our sampling-based method is effective by empirically proving that 1) The queries selected from samples can harvest most of the data in the original database; 2) The queries with low overlapping rate in samples will also result in a low overlapping rate in the original database; and 3) The size of the sample and the size of the terms from where to select the queries do not need to be very large.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740535","deep web","Computer science;Costs;Data mining;Databases;Information retrieval;Intelligent agent;Sampling methods;Telecommunication traffic;Uniform resource locators;Web services","Web services;Web sites;query processing;user interfaces","Reuters;Web services;Wikipedia;data source;deep Web crawling;sampling-based method;search interfaces","","11","","18","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Study on the Granularity of User Modeling for Tag Prediction","E. Frías-Martinez; M. Cebrián; A. Jaimes","Telefonica Res., Data Min. & User Modeling Group, Madrid","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","828","831","One of the characteristics of tag prediction mechanisms is that, typically, all user models are constructed with the same granularity. In this paper we hypothesize and empirically demonstrate that in order to increase tag prediction accuracy, the granularity of each user model has to be adapted to the level of usage of each particular user. We have constructed user models for tag prediction using association rules in Bibsonomy, a popular social bookmark and publication sharing system, at three granularity levels: (1) canonical, (2) stereotypical and (3) individual. Our experiments show that prediction accuracy improves if the level of granularity matches the level of participation of the user in the community (i.e., amount of tagging in Bibsonomy).","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.67","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740558","","Accuracy;Association rules;Data mining;Information retrieval;Intelligent agent;Libraries;Predictive models;Tagging","data mining;information analysis;user modelling","Bibsonomy;association rule;canonical granularity level;individual granularity level;publication sharing system;social bookmark;stereotypical granularity level;tag prediction;user modeling","","11","","14","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Answering Any Class of Japanese Non-factoid Question by Using the Web and Example Q&A Pairs from a Social Q&A Website","T. Mori; M. Sato; M. Ishioroshi","Grad. Sch. of Environ. & Inf. Sci., Yokohama Nat. Univ., Yokohama","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","59","65","In this paper, we propose a method of non-factoid Web question-answering that can uniformly deal with any class of Japanese non-factoid question by using a large number of example Q&A pairs. Instead of preparing classes of questions beforehand, the method retrieves already asked question examples similar to a submitted question from a set of Q&A pairs. Then, instead of preparing clue expressions for the writing style of answers according to each question class beforehand, it dynamically extracts clue expressions from the answer examples corresponding to the retrieved question examples. This clue expression information is combined with topical content information from the question to extract appropriate answer candidates. The experimental results showed that the clue expressions obtained from the set of examples improved the accuracy of answer candidate extraction.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740426","Question answering;Web documents;non-factoid questions;social Q&A website","Data mining;Information resources;Information retrieval;Intelligent agent;Search engines;Thesauri;Web search;Writing","information retrieval;natural languages;social networking (online)","Japanese nonfactoid Web question-answering method;clue expression information retrieval;social question-answering Web site","","1","2","9","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Digital Assets Navigating System Based on FCA","C. Shi; Z. Niu; T. Wang; X. Xu","Sch. of Comput. Sci., Beijing Inst. of Technol., Beijing","2008 International Symposium on Knowledge Acquisition and Modeling","20081230","2008","","","356","360","Formal concept analysis (FCA) has been developed to have a wide range of applications. A number of researchers have proposed several FCA lattice structures for Information Retrieval. In this paper, a Web-based digital assets navigating system is designed based on FCA. In the proposed design, several meta-templates tailored for certain metadata standards are used to processing the various asset types, and DC acts as the core managed and lattice-context extracting metadata standard to which other meta-templates can easily mapping. The second way to form lattice context is extracting the terms from the content of document-alike assets using the BC method. At last we suppose a Web-based navigating interface using an eye-frame to show or hide parts of the lattice via interactive shifting of a focus concept node.","","POD:978-0-7695-3488-6","10.1109/KAM.2008.152","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4732844","BC Method;Eye-Frame;Formal Concept Lattice;Meta-template","Application software;Asset management;Computer science;Data mining;Information retrieval;Knowledge acquisition;Laboratories;Lattices;Navigation;Process design","information retrieval;meta data","Information Retrieval;digital assets navigating system;formal concept analysis;lattice structures","","0","","21","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Web User Session Reconstruction Using Integer Programming","R. F. Dell; P. E. Román; J. D. Velásquez","Oper. Res. Dept., Naval Postgrad. Sch., Monterey, CA","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","385","388","An important input for Web usage mining is Web user sessions that must be reconstructed from Web logs (sessionization) when such sessions are not otherwise identified. We present a novel approach for sessionization based on an integer program. We compare results of our approach with the timeout heuristic on Web logs from an academic Web site. We find our integer program provides sessions that better match an expected empirical distribution with about half of the standard error of the heuristic.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740478","Integer Programming;Power Law;Sessionization;Web Logs;Web Usage Mining","Costs;Electrical capacitance tomography;Industrial engineering;Information retrieval;Intelligent agent;Linear programming;Operations research;USA Councils;Web pages;Web server","Internet;data mining;integer programming","Web logs;Web usage mining;Web user session reconstruction;academic Web site;integer programming;timeout heuristic","","12","1","7","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"A Model of Cognition-Driven Decision Process for Business Intelligence","L. Niu; G. Zhang","Fac. of Inf. Technol., Univ. of Technol., Sydney, NSW","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","1","","876","879","We proposed a cognition-driven decision process model for business intelligence. In this model, a managerpsilas situation awareness (SA) and mental models are developed and enriched for naturalistic decision making based on traditional business intelligence systems. Mental models are also used to supervise the process of situation information retrieval and presentation. The final decision-making process is based on recognition-primed decision model.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.216","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740567","business intelligence;cognitive decision support;decision support;mental models;situation awareness","Australia;Bismuth;Cognitive science;Decision making;Humans;Information retrieval;Information technology;Intelligent agent;Intelligent systems;Knowledge management","competitive intelligence;decision making","business intelligence;cognition-driven decision process;decision-making process;mental models;recognition-primed decision model;situation awareness","","2","","13","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Bayesian Active Learning in Relevance Feedback for Image Retrieval","J. Wu; Y. Fu; M. Lu","Sch. of Inf. Sci. & Technol., Dalian Maritime Univ., Dalian","2008 Second International Symposium on Intelligent Information Technology Application","20090106","2008","3","","371","375","One of the fundamental problems in content-based image retrieval (CBIR) has been the gap between low-level visual features and high-level semantic concepts. To narrow the gap, relevance feedback (RF) is introduced into CBIR. However, most RF methods are challenged by small size sample collection and asymmetric sample distributions between the positive and the negative samples. In this paper, a Bayesian active learning (BAL) mechanism is proposed to overcome these problems. First, by defining the confidence, we design a new selection criterion for the images with the low confidence, which to be labeled by user, and then the learner is retrained by the most informative samples obtained from the last round feedback. Moreover, different learning strategies are used for estimating the distributions of the positive and the negative samples. Based on above methods, the retrieval performance can be enhanced. The experimental results on Corel image database demonstrate the effectiveness of the proposed algorithm.","","POD:978-0-7695-3497-8","10.1109/IITA.2008.311","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740021","Bayesian Learning;Image retrieval;Relevance feedback","Bayesian methods;Content based retrieval;Image databases;Image retrieval;Information retrieval;Information technology;Machine learning;Negative feedback;Radio frequency;Support vector machines","Bayes methods;content-based retrieval;image retrieval;learning (artificial intelligence);relevance feedback","Bayesian active learning;asymmetric sample distribution;content-based image retrieval;high-level semantic concept;low-level visual feature;relevance feedback;small size sample collection","","3","","11","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Phrase based browsing for simulation traces of network protocols","N. J. Schmidt; P. Kemper","Department of Computer Science, College of William and Mary, Williamsburg, VA 23185, U.S.A.","2008 Winter Simulation Conference","20081230","2008","","","2811","2819","Most discrete event simulation frameworks are able to output simulation runs as a trace. The network simulator 2 (NS2) is a prominent example that does so to decouple generation of dynamic behavior from its evaluation. If a modeler is interested in the specific details and confronted with lengthy traces from simulation runs, support is needed to identify relevant pieces of information. In this paper, we present a new phrase-based browser that has its roots in information retrieval, language acquisition and text compression which is refined to work with trace data derived from simulation models. The browser is a new navigation feature of Traviando, a trace visualizer and analyzer for simulation traces. The browsing technique allows a modeler to investigate particular patterns seen in a trace, that may be of interest due to their frequent or rare occurrence. We demonstrate how this approach applies to traces generated with NS2.","0891-7736;08917736","CD-ROM:978-1-4244-2708-6; POD:978-1-4244-2707-9","10.1109/WSC.2008.4736401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736401","","Biological system modeling;Computational modeling;Computer science;Computer simulation;Data visualization;Discrete event simulation;Educational institutions;Information retrieval;Navigation;Protocols","discrete event simulation;information analysis;information retrieval","discrete event simulation frameworks;information retrieval;language acquisition;network protocols;network simulator 2;phrase based browsing;text compression;trace visualizer","","2","1","13","","","7-10 Dec. 2008","","IEEE","IEEE Conference Publications"
"Image Retrieval Based on MD5","H. Liao","Sch. of Software, JIANGXI Univ. of Finance & Econ., Nanchang","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","987","991","A new image retrieval method was introduced based on the combination of CBIR (content-based image retrieval) and MD5, after a brief introduction to current status of image retrieval technology. Kernel thought was that MD5 value was extracted from an image file and then indexed. These indexed MD5 values were used for image retrieval. Implementation of the method showed that the new image retrieval method is feasible and good for improvement of accuracy of the image retrieval rate.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.76","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737105","CBIR;Image Retrieval;MD5","Color;Content based retrieval;Data mining;Eigenvalues and eigenfunctions;Finance;Image databases;Image retrieval;Information retrieval;Kernel;National security","content-based retrieval;image retrieval;indexing","MD5;content-based image retrieval;indexing","","2","","8","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Semantic Framework for Free-Form Search of Grid Resources","C. Gupta; M. Govindaraju","Dept. of Comput. Sci., SUNY, Binghamton, NY","2008 IEEE Fourth International Conference on eScience","20090106","2008","","","454","455","The model of free-form queries has been an enormous success for HTML-based search engines on the web. If the same free-form search is made available for grid services, it will serve as a powerful tool for scientists to retrieve information on resources, monitoring data, replica location sets, and meta-data on scientific data sets, in an intuitive manner. Current implementations of XML-based grid service descriptions require end users to have intimate knowledge of service descriptions, related toolkits, and query languages. We have developed a system that abstracts away these fundamental complexities and provides a simple free-form query based scientific discovery system for grid users. In this paper, we present the design and initial implementation results of our ontological framework that employs matching algorithms, automated extension of ontologies, and semantic Web and ontological concepts to match free-form queries with corresponding grid resource information stored in RDF/OWL format.","","CD-ROM:978-0-7695-3535-7; POD:978-1-4244-3380-3","10.1109/eScience.2008.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4736843","Grid services;Ontology;Query matching;Semantic Web","Abstracts;Algorithm design and analysis;Database languages;Information retrieval;Monitoring;OWL;Ontologies;Resource description framework;Search engines;Semantic Web","XML;grid computing;hypermedia markup languages;ontologies (artificial intelligence);query processing;search engines;semantic Web","HTML-based search engines;RDF-OWL format;XML-based grid service;free-form queries;free-form query based scientific discovery system;grid resources;ontological framework;semantic Web;semantic framework","","1","","4","","","7-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Localized Independent Packet Scheduling for Buffered Crossbar Switches","D. Pan; Y. Yang","Florida International University, Miami","IEEE Transactions on Computers","20090106","2009","58","2","260","274","Buffered crossbar switches are a special type of crossbar switches. In such a switch, besides normal input queues and output queues, a small buffer is associated with each crosspoint. Due to the introduction of crosspoint buffers, output and input contention is eliminated, and the scheduling process for buffered crossbar switches is greatly simplified. Moreover, since different input ports and output ports work independently, the switch can easily schedule and transmit variable length packets. Compared with fixed length packet scheduling, variable length packet scheduling has some unique advantages: higher throughput, shorter packet latency, and lower hardware cost. In this paper, we present a fast and practical scheduling scheme for buffered crossbar switches called Localized Independent Packet Scheduling (LIPS). With LIPS, an input port or output port makes scheduling decisions solely based on the state information of its local crosspoint buffers, i.e., the crosspoint buffers where the input port sends packets to or the output port retrieves packets from. The localization feature makes LIPS suitable for a distributed implementation and thus highly scalable. Since no comparison operation is required in LIPS, scheduling arbiters can be efficiently implemented using priority encoders, which can make arbitration decisions quickly in hardware. Another advantage of LIPS is that each crosspoint needs only L (the maximum packet length) buffer space, which minimizes the hardware cost of the switches. We theoretically analyze the performance of LIPS and, in particular, prove that LIPS achieves 100 percent throughput for any admissible traffic with speedup of two. We also discuss in detail the implementation architecture of LIPS and analyze the packet transmission timing in different scenarios. Finally, simulations are conducted to verify the analytical results and measure the performance of LIPS.","0018-9340;00189340","","10.1109/TC.2008.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4599572","100 percent throughput;Buffered crossbar switches;I/O and Data Communications;Interconnections (Subsystems);Network Architecture and Design;Packet-switching networks;packet scheduling;priority encoders.","Costs;Delay;Hardware;Information retrieval;Lips;Packet switching;Performance analysis;Scheduling algorithm;Switches;Throughput","electronic switching systems;packet switching;queueing theory;scheduling","buffered crossbar switches;crosspoint buffers;input queues;length packet scheduling;localized independent packet scheduling;output queues;packet latency;scheduling arbiters","","18","1","36","","20080815","Feb. 2009","","IEEE","IEEE Journals & Magazines"
"Web Page's Blocks Based Topical Crawler","W. Zhang; B. Xu; H. Lu","Coll. of Comput., Nanjing Univ. of Posts & Telecommun., Nanjing, China","2008 IEEE International Symposium on Service-Oriented System Engineering","20081230","2008","","","44","49","Link context has been widely used in information retrieval and classification. In topical crawlers or vertical crawlers, the link contexts are used to forecast whether the links are related to topics. The context of a link or link context usually includes the anchor text of the link, the whole web page text or the words in the fixed scope near the link. The entire text of the page often contains too many themes, anchor text is too simple, and the scope of fixed windows is not easy to determine. In this paper, we propose to decide the scope of link context by the web page block technology. The links in the same block are more closely related. The corner classification based neural network is used to represent and filter the topics. Our experiments show that web crawlers using web page block based link context have better accuracy, and that the corner classification neural network is suitable for representing and filtering topics.","","CD-ROM:978-0-7695-3499-2","10.1109/SOSE.2008.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4730461","crawler;topic;web page block","Artificial neural networks;Biological neural networks;Crawlers;Educational institutions;Information filtering;Information filters;Information retrieval;Neural networks;Search engines;Web pages","Web sites;neural nets","Web crawlers;Web page block;corner classification;link context;neural network;topical crawler","","1","","10","","","18-19 Dec. 2008","","IEEE","IEEE Conference Publications"
"Research on Automatic Acquiring of Chinese Synonyms from Wiki Repository","L. Yong; H. Hanqing","Nanjing Univ. of Inf. Sci. & Technol., Nanjing","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","287","290","Automatic acquiring of synonyms plays an important role in information retrieval and semantic resource development. In order to enhance the ability of the Chinese synonyms acquiring, this paper presents pattern matching approach and PageRank algorithm approach based on the Wiki repository. In pattern matching approach, we analyze the defining and explaining paragraph of the entry in the Wiki repository and form some acquiring rules of synonyms by hands, then automatic extract synonyms by pattern matching. The second method is PageRank algorithm, we analyze the relation between given words and the other words, then construct the associated word graph., and finally use the PageRank algorithm to calculate the similarity degree and discover the synonyms in the associated word graph. The test result indicated that the method is feasible and practical.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.95","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740781","Wiki repository;automatic acquiring;synonyms","Educational institutions;Encyclopedias;Information retrieval;Information science;Intelligent agent;Natural language processing;Natural languages;Pattern matching;Terminology;Vocabulary","Web sites;graph theory;information retrieval;natural languages;pattern matching;vocabulary","Wiki repository;automatic Chinese synonym acquisition;information retrieval;pagerank algorithm approach;pattern matching;semantic resource development;vocabulary;word graph","","1","","8","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"FAQIH: Framework for Agent-Based Query-Enabled Integrated Information for Health and Nutrition","Y. A. Tijerino; T. H. El-Bassuny; J. M. Bradshaw","Kwansei Gakuin Univ., Sanda","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","20090106","2008","3","","550","553","As the processes of urbanization and globalization continue to gain momentum, issues relating to interdependencies among water, food, nutrition and public health policy have increased in complexity and scope. Thus, it is no longer sufficient for subject-matter experts to develop models for each of their underlying domains of expertise (e.g., nutrition, healthcare, and land and water management) independently. Both expert stakeholders and ordinary citizens would benefit from reliable and continually up-to-date models on which to base their decisions. In this preliminary overview paper, the authors propose to develop a Framework for Agent-based Query-Enabled Integrated Information for Health and Nutrition (FAQIH) to support healthcare professionals, policy makers, and citizens to obtain the knowledge they seek.","","POD:978-0-7695-3496-1","10.1109/WIIAT.2008.405","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740840","Nutrition;Ontology;Semantic Web","Data mining;Home appliances;Information retrieval;Intelligent agent;Medical services;Mobile handsets;OWL;Ontologies;Public healthcare;Software agents","health care;public information systems;query processing;software agents","FAQIH;agent-based query-enabled integrated information;citizen;healthcare professional;nutrition;policy maker","","0","","11","","","9-12 Dec. 2008","","IEEE","IEEE Conference Publications"
"Solution for Search Result Clustering by Using Singular Value Decomposition","V. Snasel; H. D. Abdulla","","2008 International Conference on Advanced Computer Theory and Engineering","20090106","2008","","","647","651","There are many search engines in the Web, but they return a long list of search results, ranked by the irrelevancies to the given query. Web users have to go through the list and examine the titles and (short)snippets sequentially to identify their required results.In this paper we present how usage of Singular Value Decomposition (SVD) as a very good solution for search results clustering.","2154-7491;21547491","POD:978-0-7695-3489-3","10.1109/ICACTE.2008.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4737037","Data clustering;Singular Value Decomposition;search result clustering","Computational linguistics;Computer science;Data analysis;Data mining;Information retrieval;Machine learning;Matrix decomposition;Search engines;Singular value decomposition;Sparse matrices","query processing;search engines;singular value decomposition","Web;query processing;search engine;search result clustering;singular value decomposition","","0","","9","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
