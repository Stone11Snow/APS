"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5363389,5363259,5359004,5360233,5360509,5364970,5362479,5359952,5361615,5365336,5357807,5362158,5360238,5363726,5360512,5360278,5364629,5366416,5357706,5360306,5362010,5367703,5358996,5360445,5358621,5357814,5365099,5363451,5362464,5360530,5358135,5358569,5363791,5360302,5362815,5362160,5359453,5360436,5365992,5364328,5366087,5365709,5364019,5366632,5366255,5367798,5365285,5366072,5364971,5359309,5365539,5363822,5365611,5359549,5361721,5360437,5362003,5362892,5362290,5367800,5360505,5366391,5358875,5366446,5360046,5361890,5364111,5365800,5359121,5358793,5359474,5362241,5360454,5364037,5362596,5363144,5360308,5362896,5360510,5363260,5358835,5358661,5357668,5366037,5364848,5362278,5363394,5357647,5365191,5364825,5358550,5366488,5361084,5364500,5363402,5364931,5360085,5366423,5357682,5361809",2017/05/04 20:55:38
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Research of Attribute Value Rough Equality Based-on the Hopfield Neural Network and Rough Set Theory","J. Gong; S. Sun","Dept. of Comput. Sci. & Eng., Yanshan Univ., Qinhuangdao, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","256","260","The problem of Attribute Value Rough Equality (AVRE) is a fundamental problem in the fields of Text Classification and Information Retrieval. However,challenge still exists. In practical application, the processed attribute values are often data/information set based on semantics. This situation is very difficult to be handled by the traditional theories and methods.To address the challenge, this paper proposes the Hopfield Neural Network Architecture (AVRE-HNNA) to solve the problem of attribute value rough equality by combining the Rough Set Theory with the Classification Mechanism of Neural Network. The neural network model (HNNM), the energy function,and learning algorithm are also presented in AVREHNNA.The HNNM is illustrated, evaluated and analyzed through using a simulation instance. The analyses show that the proposed AVRE-HNNA performed better in robustness and stability, and had higher matching precision and field independency. The corresponding algorithms had lower complexity than the traditional methods. The proposed AVRE-HNNA can well solve AVRE problem.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.424","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363451","Attribute Value Rough Equality;Hopfield Neural Network;Rough Set Theory","Algorithm design and analysis;Analytical models;Hopfield neural networks;Information retrieval;Neural networks;Performance analysis;Robust stability;Set theory;Stability analysis;Text categorization","Hopfield neural nets;learning (artificial intelligence);relational databases;rough set theory","Hopfield neural network;attribute value rough equality;energy function;information retrieval problem;learning algorithm;rough set theory;text classification problem","","0","","4","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Medical Image Retrieval Using Local Binary Patterns with Image Euclidean Distance","X. Xu; Q. Zhang","Sch. of Inf. Eng., Commun. Univ. of China, Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","For years, researchers in medical image retrieval area have been representing and recognizing medical images based on local binary patterns (LBP). Compared to Gabor wavelets, the LBP features can be extracted faster in a single scan through the raw image and lie in a lower dimensional space, whilst still retaining image information efficiently. To improve the recognition rate, several methods using local binary pattern (LBP) have been tried such as improved local binary pattern (ILBP), extended local binary pattern (ELBP) , extended local binary pattern (ELBP), local Gabor binary pattern (LGBP). This paper proposes a novel medical image retrieval method, local binary pattern with image Euclidean distance (IMED), which takes into account the spatial relationships of pixels, and it is robust to small perturbation of images. Experiments showed that IMED improved the performance of standard LBP algorithm.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365709","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365709","","Biomedical imaging;Euclidean distance;Face recognition;Feature extraction;Histograms;Image recognition;Image retrieval;Information retrieval;Pattern recognition;Robustness","feature extraction;image representation;image resolution;image retrieval;medical image processing;wavelet transforms","Gabor wavelets;LBP feature extraction;extended local binary pattern;image euclidean distance;improved local binary pattern;local Gabor binary pattern;local binary pattern with image Euclidean distance;local binary patterns;medical image recognition;medical image representation;medical image retrieval","","6","","6","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Audio Clips Retrieval Using Anchor Reference Space and Latent Semantic Analysis","K. Biatov","Fraunhofer IAIS, St. Augustin, Germany","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","32","37","This paper describes a technique for audio clips retrieval. The audio clips are modeled using a common universal codebook. The codebook is based on a bag-of-features (BOF). The features extracted from all clips are grouped into clusters using the k-means algorithm. The individual audio clips are modeled by the normalized distribution of the numbers of cluster bins. The latent semantic indexing (LSI) is applied to the feature-audio clip matrix to represent the data in latent semantic space. Then the primary audio clip description is converted to the vector in anchor reference space. Each component of the anchor vector is a probabilistic similarity between this clip and the clip corresponding to the considered component. Then LSI is applied to new feature-audio clip matrix, mapping the data to the latent semantic space based on anchor representation. For audio retrieval the nearest-neighbor (NN) algorithm is exploited. The described algorithm demonstrates high retrieval performance.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365285","","Audio databases;Euclidean distance;Information retrieval;Large scale integration;Linear discriminant analysis;Matrix converters;Mel frequency cepstral coefficient;Music information retrieval;Principal component analysis;Speech","audio coding;content-based retrieval;feature extraction;pattern clustering","anchor reference space;anchor representation;audio clip codebok;audio clips retrieval;audio content retrieval;data mapping;feature-audio clip matrix;features extraction;k-means clustering algorithm;latent semantic analysis;latent semantic indexing;nearest-neighbor algorithm;normalized distribution","","0","","18","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Combined Query Expansion Technique for Retrieving Opinions from Blogs","S. Momtazi; S. Kazalski; D. Klakow","Spoken Language Syst., Univ. of Saarland, Saarbrucken, Germany","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","791","796","In this paper, we discuss the the role of the retrieval component in an TREC style opinion question answering system. Since blog retrieval differs from traditional ad-hoc document retrieval, we need to work on dedicated retrieval methods. In particular we focus on a new query expansion technique to retrieve people's opinions from blog posts. We propose a combined approach for expanding queries while considering two aspects: finding more relevant data, and finding more opinionative data. We introduce a method to select opinion bearing terms for query expansion based on a chi-squared test and use this new query expansion to combine it in a liner weighting scheme with the original query terms and relevant feedback terms from Web. We report our experiments on the TREC 2006 and TREC 2007 queries from the blog retrieval track. The results show that the methods investigated here enhanced mean average precision of document retrieval from 17.91% to 25.20% on TREC 2006 and from 22.28% to 32.61% on TREC 2007 queries.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.196","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364037","","Blogs;Data mining;Feedback;Information retrieval;Intelligent systems;Natural language processing;Natural languages;Scattering;Testing;Web sites","Web sites;query processing;relevance feedback;statistical analysis","TREC;blog retrieval;chi-squared test;liner weighting scheme;opinion bearing term;opinion retrieval;query expansion technique;question answering system;relevant feedback","","0","","18","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Exploring Image Context for Semantic Understanding and Retrieval","H. Zhang; M. Jiang; X. Zhang","Coll. of Comput. Sci. & Technol., Wuhan Univ. of Sci. & Technol., Wuhan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Besides low-level visual features lots of researches focus on how to explore and utilize other kinds of related features for image semantic understanding and retrieval. Text is one of such related features. Some researches directly use semantic information from related texts to label image semantics, and ignore underlying low-level correlation. Differently, this paper explores low-level correlation between feature matrices of images and texts with kernel-based method; and then models semantic structure in the subspace based on manifold learning; we propose strategies to further refine manifold structure; also we discuss how to enable image retrieval with examples outside database. Our approach considers text as the context of images and uses content-based method to analyze statistical correlation between such context and image data. Users can submit a text or an image example to search similar images. Experiment and comparison results are encouraging and show that the performance of our approach is effective.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5364019","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364019","","Computer science;Content based retrieval;Educational institutions;Image analysis;Image databases;Image retrieval;Information retrieval;Kernel;Training data;Vectors","content-based retrieval;image retrieval","content-based method;feature matrices;image context;image retrieval;manifold learning;semantic retrieval;semantic understanding","","2","","12","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Evaluation of Metrics for Retrieval of MPEG-7 Semantic Descriptions","M. Lux","Klagenfurt Univ., Klagenfurt, Austria","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","546","551","MPEG-7 is an extensive multimedia metadata standard covering a huge number of aspects of metadata. However, as with most metadata standards details of usage and application of the standards are - at least partially - open to interpretation. In case of MPEG-7 storage and transmission of high level metadata on concept level are defined but retrieval methods are not proposed. So if for instance a user annotates photos using the MPEG-7 semantic description scheme, there are no standardized ways to retrieve the photos based on the annotation. In this paper we propose metrics for retrieval based on the MPEG-7 semantic description scheme and evaluate them in a digital photo retrieval scenario.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362596","MPEG-7;Multimedia;Retrieval","Database languages;Information retrieval;Layout;MPEG 7 Standard;Multimedia databases;Resource description framework;Tree data structures;Tree graphs;Videoconference;XML","multimedia systems;video coding;video retrieval","MPEG-7 semantic descriptions;digital photo retrieval;multimedia metadata standard","","0","","23","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Design of Component Retrieval Framework for Active Service","X. Xi; H. Xia","Dept. of Comput. Sci. & Technol., Wuhan Univ. of Technol., Wuhan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","In the active service model, the existing component retrieval method is not sufficient to meet the service requirements of intellectualization, individualization and comprehensiveness. Therefore, this paper designs a component retrieval framework for active service, proposes a component description model and component retrieval strategy based on ontology technology and assists the users to complement retrieval requirements with user interest model. The method enhances the retrieval efficiency, and accords with the active service demand better.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5366072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366072","","Artificial intelligence;Computer science;Information retrieval;Information science;Ontologies;Resource management;Security;Technology management;Web and internet services;Web services","Internet;customer satisfaction;customer services;information retrieval;ontologies (artificial intelligence);service industries","active service model;component description model;component retrieval;ontology technology","","0","","9","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Song Clustering Using Peer-to-Peer Co-occurrences","Y. Shavitt; U. Weinsberg","Sch. of Electr. Eng., Tel-Aviv Univ., Tel-Aviv, Israel","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","471","476","Peer-to-peer (p2p) content sharing networks are commonly used by millions of users for sharing music files, often performed by artists even before becoming mainstream. In such networks, as well as modern Web 2.0 services, users with similar musical taste often share similar files. This results in songs that have similar properties to be shared together by many users, where the higher the number of song co-occurrences in different users, the stronger is the indication of a tight relationship between these songs. In this work we leverage this feature and propose methods for detecting these ""natural"" clusters of similar songs. The resulting clusters are shown to be useful in recommender systems, as they almost mitigate the need to use meta-data which is known to be noisy due to its user-generated nature. We present data collected from the Gnutella network and its properties and show two techniques for recommending content to users, one is based on clustering similar-minded users and the other creates song similarity graph and maps users to clusters based on their songs. We show that both techniques result in relatively accurate recommendations, indicating that p2p networks can be leveraged for creating useful recommender systems that can be used for easier content retrieval.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363144","","Content based retrieval;IPTV;Law;Music information retrieval;Noise generators;Peer to peer computing;Recommender systems;Social network services;Tagging;User-generated content","Web services;audio databases;content-based retrieval;meta data;music;pattern clustering;peer-to-peer computing;recommender systems","Gnutella network;Web 2.0 service;content retrieval;content sharing network;meta-data;music file;natural cluster;p2p network;peer-to-peer cooccurrence;recommender system;song clustering;song similarity graph","","4","","14","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Large Scale Relation Acquisition Using Class Dependent Patterns","S. De Saeger; K. Torisawa; J. Kazama; K. Kuroda; M. Murata","Language Infrastruct. Group, Nat. Inst. of Inf. & Commun. Technol. (NICT), Seika, Japan","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","764","769","This paper proposes a minimally supervised method for acquiring high-level semantic relations such as causality and prevention from the Web. Our method learns linguistic patterns that express causality such as Â¿x gave rise to yÂ¿, and uses them to extract causal noun pairs like (global warming, malaria epidemic) from sentences like Â¿global warming gave rise to a new malaria epidemicÂ¿. The novelty of our method lies in the use of semantic word classes acquired by large scale clustering for learning class dependent patterns. We demonstrate the effectiveness of this class based approach on three large-scale relation mining tasks from 50 million Japanese Web pages. In two of these tasks we obtained more than 30,000 relation instances with over 80% precision, outperforming a state-of-the-art system by a large margin.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.140","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360308","","Communications technology;Data mining;Diseases;Frequency;Global warming;Information retrieval;Large-scale systems;Sea measurements;Text mining;Web pages","Internet;Web sites;causality;data acquisition;data mining;learning (artificial intelligence);natural language processing;pattern clustering","Japanese Web pages;World Wide Web;causality;class dependent patterns;high-level semantic relations;large scale clustering;large scale relation acquisition;large-scale relation mining tasks;linguistic patterns;semantic word classes;supervised method","","3","","15","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Experiment About Using Copulative and Comparative Sentences as Constraining Relations","A. Soto; J. A. Olivas; F. P. Romero; J. Serrano-Guerrero","Comput. Sci. Dept., Univ. of Carmen, Campeche, Mexico","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","79","84","Existing search engines and question-answering (QA) systems have made possible processing large volumes of textual information. Current work on QA has mainly focused on answering two basic types of questions: factoid and definition questions. However, the capability to synthesize an answer to a query by drawing on bodies of information which reside in various parts of the knowledge base is not among the capabilities of those systems. In this paper, a system oriented to infer query answers from a collection of propositions expressed in natural language is introduced. By means of a specific example, it is outlined how the system proceeds to face those situations. This approach is based on the use of formal constraining relations modeling copulative and comparative sentences. Combining those propositions with others contained in different knowledge bases and applying deduction rules, the desired answer could be obtained.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.224","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362896","generalized constraints;natural language;prototypical forms","Computer science;Data mining;Deductive databases;Dictionaries;Information retrieval;Information systems;Intelligent systems;Natural languages;Prototypes;Search engines","natural languages;search engines","constraining relations;copulative-comparative sentences;factoid;natural language;query answers;question-answering systems;search engines","","0","","25","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Localized Content Based Image Retrieval with Self-Taught Multiple Instance Learning","Q. Qiao; P. A. Beling","Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","170","175","There are many scenarios in which multi-instance learning problems may be difficult to solve because of a lack of correctly labeled examples for algorithm training. Labeled examples may be difficult or expensive to obtain because human effort is often needed to produce labels and because there may be limitations on the ability to collect large samples for training from a homogeneous population. In this paper, we present a technique called self-taught multiple-instance learning (STMIL) that deals with learning from a limited number of ambiguously labeled examples. STMIL uses a sparse representation for examples belonging to different classes in terms of a shared dictionary derived from the unlabeled data. This sparse representation can be optimized under the multiple instance setting to both construct high-level features and unite the data distribution. We present an optimization procedure for STMIL along with experiments on localized content-based image retrieval. Our experimental results suggest that, though it learns from a small number of labeled examples, STMIL is superior to standard algorithms in terms of computational efficiency and is at least competitive in terms of accuracy.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360510","","Conferences;Content based retrieval;Data engineering;Data mining;Image retrieval;Information retrieval;Semisupervised learning;Supervised learning;Systems engineering and theory;USA Councils","content-based retrieval;image retrieval;learning (artificial intelligence)","algorithm training;data distribution;homogeneous population;localized content based image retrieval;multi-instance learning problems;self-taught multiple instance learning;self-taught multiple-instance learning;sparse representation","","1","","10","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Extending the JColibri Open Source Architecture for Managing High-Dimensional Data and Large Case Bases","A. Bottrighi; G. Leonardi; S. Montani; L. Portinale","Dipt. di Inf., Univ. del Piemonte Orientale "A. Avogadro", Alessandria, Italy","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","269","275","CBR systems designers and developers' research can benefit from the availability of existing platforms, able to provide software design and implementation assistance. The JColibri platform, realized and maintained by the University of Madrid, is one of the most well known among such tools. In this work, we describe a couple of extensions we have provided to the core JColibri open source software. In particular, our extensions are meant to optimize case retrieval performances, in data-rich applications. Specifically, we focused our attention on treating (i) large case bases, in which retrieval time may become unacceptable, and (ii) cases with high-dimensional features - namely time series features - on which proper case representation and retrieval solutions need to be studied. The implemented code has been preliminarly tested, and it is now ready to be integrated with the JColibri code, and made available to the CBR research community. Additional extensions, always dealing with retrieval optimization, are foreseen as our future work.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364971","Case-based reasoning;Jcolibri framework;Pivoting-based retrieval;Time series;high-dimensional data;large case bases","Application software;Artificial intelligence;Computer architecture;Conference management;Design optimization;Information retrieval;Open source software;Software design;Software development management;Testing","information retrieval;public domain software;software architecture","CBR systems;JColibri open source architecture;JColibri platform;case retrieval performances;high-dimensional data management;large case bases;software design","","0","","32","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"High-Speed Similarity-Based Image Retrieval with Data-Alignment Optimization Using Self-Organization Algorithm","D. Matsubara; A. Hiroike","Central Res. Lab., Hitachi, Ltd., Kokubunji, Japan","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","312","317","In a retrieval system for vast amounts of image data, the primary storage cannot hold all image feature vectors because a huge data capacity would be required. Therefore, it is necessary to handle a slow-access secondary storage effectively as well as a first-access primary storage. In this paper, we propose a data-alignment optimization method in the secondary storage to access fast. Our idea is based on the premise that similar data have a high probability of simultaneous access in a similarity-based retrieval system. Then, we approximate the secondary storage by one dimensional alignment and allocates similar data to closer regions in the alignment. It is regarded as an optimization problem for a one-dimensional alignment that enables a fast retrieval by reducing a seek range. Through the experiments for 5 millions dataset, we confirmed that the data access time was reduced by 25.3% compared to no data-alignment optimization, which contributed significantly to speeding up the entire retrieval process.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.108","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363260","clustering;database;self-organization;similarity-based image search","Brightness;Broadband communication;Image databases;Image resolution;Image retrieval;Image storage;Information retrieval;Laboratories;Optimization methods;Videos","data handling;image retrieval;optimisation","data alignment optimization method;high-speed similarity-based image;self-organization algorithm","","0","","12","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Novel Retrieval Method for JPEG Image","H. l. Xu; S. Zhao","Sch. of Comput. Sci. & Technol., Henan Polytech. Univ., Jiaozuo, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","A novel image retrieval of JPEG image is proposed based on the statistical distribution and spatial information of the DCT coefficients. According to the distribution of the several AC coefficients, the AC distribution entropy is introduced. Furthermore, the effect of the spatial information of the AC coefficients on retrieval result is considered, a weight is introduced to improve the scheme. The experiment results show that the proposed method has a good performance both in retrieval efficiency and effectiveness.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5366416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366416","","Computer science;Data mining;Discrete cosine transforms;Discrete transforms;Entropy;Feature extraction;Image coding;Image retrieval;Information retrieval;Transform coding","content-based retrieval;discrete cosine transforms;image coding;image retrieval;statistical distributions","AC coefficients;AC distribution entropy;DCT coefficient;JPEG image retrieval;content-based image retrieval;spatial information;statistical distribution","","0","","9","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Cluster-Based Similarity Search in Time Series","L. Karamitopoulos; G. Evangelidis","Dept. of Appl. Inf., Univ. of Macedonia Thessaloniki, Thessaloniki, Greece","2009 Fourth Balkan Conference in Informatics","20091228","2009","","","113","118","In this paper, we present a new method that accelerates similarity search implemented via one-nearest neighbor on time series data. The main idea is to identify the most similar time series to a given query without necessarily searching over the whole database. Our method is based on partitioning the search space by applying the K-means algorithm on the data. Then, similarity search is performed hierarchically starting from the cluster that lies most closely to the query. This procedure aims at reaching the most similar series without searching all clusters. In this work, we propose to reduce the intrinsically high dimensionality of time series prior to clustering by applying a well known dimensionality reduction technique, namely, the piecewise aggregate approximation, for its simplicity and efficiency. Experiments are conducted on twelve real-world and synthetic datasets covering a wide range of applications.","","POD:978-0-7695-3783-2","10.1109/BCI.2009.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359309","clustering;data mining;similarity search;time series","Aggregates;Data mining;Databases;Degradation;Discrete Fourier transforms;Indexing;Informatics;Information retrieval;Multidimensional systems;Nearest neighbor searches","approximation theory;data mining;information retrieval;pattern clustering;time series","K-means algorithm;cluster-based similarity search;data mining;dimensionality reduction technique;one-nearest neighbor;piecewise aggregate approximation;time series data","","0","","23","","","17-19 Sept. 2009","","IEEE","IEEE Conference Publications"
"An Architecture of Semantic Knowledge System for Biosafety","X. Wang; T. Luo; C. Zhang; W. Liu","Sch. of Inf. Sci. & Eng., Grad. Univ. of Chinese Acad. of Sci., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","2","","178","182","The development and maintenance of domain knowledge based system need a lot of manual operations, and with the increasing amount of contents in the system, it is more and more difficult to find the relevant information. The keyword based search usually can not return the accurate result. To solve these problems, this paper proposes a semantic knowledge system with ontology engineering approach. It can acquire data and update knowledge system with less human efforts, and the feedback mechanism can help the knowledge system automatically correct the inaccurate metadata. The semantic query improves the keyword based query and returns the answer accurately. The customized interactive user interface is implemented with proper technology to display the knowledge hierarchy and data relationship, and improves the efficiency of the system user.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.493","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358835","knowledge system;metadata;ontology;semantic web","Birds;Collaboration;Humans;Influenza;Information retrieval;Instruments;Knowledge based systems;Knowledge engineering;Ontologies;Semantic Web","data acquisition;knowledge based systems;meta data;ontologies (artificial intelligence);semantic Web","biosafety;customized interactive user interface;data acquisition;domain knowledge based system development;domain knowledge based system maintenance;keyword based search;metadata;ontology engineering;semantic knowledge system architecture;semantic query","","0","","18","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Probabilistic Similarity Search in Uncertain Time-Series Database","A. Qian; X. Ding; Y. Lu","Sch. of Comput. Sci., Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","The nearest neighbor search over time-series databases has been a hot research topic for a long time period, which is widely used in many applications, including information retrieval, genetic data matching, data mining, and so on. However, due to high dimensionality (i.e. length) and uncertainty of the time series, the similarity search over directly indexed precise time series usually encounters serious problems, such as the ""dimensionality curse"" and ""trust ability curse"". Conventionally, many dimensionality reduction techniques and uncertainty processing strategies are proposed separately to break such drawbacks by reducing the dimensionality of time series and simulating the data uncertainty. However, among all the proposed methods, there does not have indexing mechanisms to support similarity queries, which supports efficiently search over very large uncertain time-series databases. In this paper, we re-investigate PLA for approximating and indexing uncertain time series. In particular, we propose a novel distance function in the reduced PLA-space, and this function leads to a lower bound of the Euclidean distance between the original uncertain time series, which can lead to no false negatives during the similarity search. In the following step, based on three lemmas, we develop an effective approach to index these lower bounds to improve the nearest neighbor query efficiency. Finally, extensive experiments over synthetic data sets have demonstrated the efficiency and effectiveness of PLA together with the newly proposed lower bound lemmas, in terms of both pruning power and wall clock time, compared with the baseline algorithm.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365539","","Clocks;Data mining;Databases;Euclidean distance;Genetics;Indexing;Information retrieval;Nearest neighbor searches;Programmable logic arrays;Uncertainty","indexing;query formulation;time series;uncertainty handling;very large databases","Euclidean distance;PLA-space reduction;dimensionality curse;dimensionality reduction technique;indexing mechanism;nearest neighbor search;probabilistic similarity search;similarity query support;trust ability curse;uncertain time series database;uncertainty processing strategy","","0","","12","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Study of Order-Based Block Color Feature Image Retrieval Compared with Cumulative Color Histogram Method","S. Wang; H. Qin","Lab. of Artificial Neural Networks, CAS, Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","81","84","Color is one of the most important features in image retrieval. Color histograms have proved to be stable representations of an image, but they might be similar in different kinds of images because they describe the global intensity distribution of images. A new color image representation method is proposed in this paper. At first, each color channel (R, G, B) of an image is divided into 48 blocks (6 rows X 8 columns). Secondly, statistical features are computed to characterize the block's color feature. Finally, all block features are combined to form an image's color feature. The experimental results show that the retrieval effectiveness of the proposed technique is better than color histogram-based method.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.294","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358661","cumulative histograms;image retrieval;order-based block feature","Color;Content based retrieval;Feature extraction;Histograms;Humans;Image classification;Image databases;Image retrieval;Indexing;Information retrieval","image colour analysis;image representation;image retrieval;statistical distributions","color image representation;cumulative color histogram method;global intensity distribution;order-based block color feature image retrieval","","1","","11","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Design patent image retrieval based on shape features","Wenli Yang; Zhiyuan Zeng; Yujie Bai","Digital Engineering and Simulation Research Center, Huazhong University of Science and Technology, Wuhan 430074, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","352","356","Based on the concrete characteristics and application background of design patent, according to the deficiengy of the present retrieval system of design patent database, this paper proposed an design patent image shape retrieval method based on the improved morphological description matrix and simulated annealing particle swarm optimization algorithm (SA-PSO), which can not only reflects the morphological characteristics of design patent image, but also has translation, rotation and scale invariances. The experimental results indicated that the proposed method can retrieve similar design patent images fast and efficiently, and improve the recall ratio and precision ratio of design patent image retrieval.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357668","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357668","Design patent image retrieval;Simulated annealing particle swarm optimization algorithm;morphological description matrix;similarity degree","Algorithm design and analysis;Concrete;Content based retrieval;Feature extraction;Image edge detection;Image retrieval;Image segmentation;Information retrieval;Shape;Simulated annealing","content-based retrieval;feature extraction;image retrieval;particle swarm optimisation;patents;simulated annealing","design patent database;design patent image retrieval;morphological description matrix;shape features;simulated annealing particle swarm optimization algorithm","","0","","13","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Trust Network Based Fuzzy Knowledge Sharing in Semantic Web","C. Zhang; M. Yan","Sch. of Inf. Eng., Chang'an Univ., Xi'an, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","5","In semantic Web, knowledge, always imperfect, is managed by a myriad of autonomous, loose-coupled Web agents, which usually have different perceptions of fuzziness for given knowledge. This fact makes knowledge sharing more difficult in semantic Web than in other finite-scaled environments. In this paper, we propose a trust network based fuzzy knowledge sharing model for semantic Web. According to this model, any agent can broadcast its knowledge queries through the trust network, and aggregate different opinions according to the trustworthiness of each agent echoed.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5366037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366037","","Aggregates;Autonomous agents;Broadcasting;Engineering management;Fuzzy control;Fuzzy logic;Information retrieval;Knowledge engineering;Knowledge management;Semantic Web","multi-agent systems;semantic Web","autonomous loose-coupled Web agents;semantic Web;trust network based fuzzy knowledge sharing","","0","","11","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Design of Community Information Management System Based on WebGIS","H. Liu; J. Cui","Coll. of Resource, Hebei Univ. of Eng., Handan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","3","On the basis of the peculiarity of modernization community management, a plan based on the technology of WebGIS for the community information management system is designed. The system adopts a browser / server (B / S) model of three-tier structure, realizing the share and management of the community service information; and it can achieve a variety of functions such as map browse, query, and so on for the residents or visitors, such as releasing and managing information for the community managers. The paper also introduces the WebGIS and the management organization of community data.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5364848","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364848","","Design engineering;Educational institutions;Geographic Information Systems;Information management;Information retrieval;Multimedia databases;Technology management;Web and internet services;Web server;Web sites","Internet;geographic information systems;information management","WebGIS;browser-server model;community information management system;information sharing;map browse;modernization community management;three-tier structure","","0","","9","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Automatic Approach for Domain-Specific Dictionary Expansion Based on Web Mining","Y. Sun; W. Ni; R. Men","Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","96","99","This paper proposes an automatic expansion approach for an existing domain-specific dictionary based on Web mining. Using the terminology pairs in a dictionary as queries, we first extract snippet fragments that potentially contain the Chinese translations of current English phrases. Based on matching patterns extracted from the Web, we can get the most likely translation for a new English phrase. Finally we use the vector space model to filter out the translation equivalents belong to our expected domain, and a domain-specific dictionary expanded by these new terminology pairs is thereby built. The performance of our approach is verified on a dictionary of finance and accounting, and a precision between 85-90% is achieved on considering different thresholds.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362278","automatic expansion;domain-specific dictionary;matching patterns;translation equivalents;web mining","Data mining;Dictionaries;Filtering;Filters;Information retrieval;Natural languages;Pattern matching;Search engines;Terminology;Web mining","Internet;data mining;dictionaries;language translation;natural language processing;query processing","Chinese translations;English phrases;Web mining;automatic expansion approach;domain-specific dictionary;domain-specific dictionary expansion;pattern matching;queries;snippet fragment extraction;vector space model","","0","","8","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"MSRA-MM 2.0: A Large-Scale Web Multimedia Dataset","H. Li; M. Wang; X. S. Hua","Inst. of Comput. Technol., Chinese Acad. of Sci., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","164","169","In this paper, we introduce the second version of Microsoft Research Asia Multimedia (MSRA-MM), a dataset that aims to facilitate research in multimedia information retrieval and related areas. The images and videos in the dataset are collected from a commercial search engine with more than 1000 queries. It contains about 1 million images and 20,000 videos. We also provide the surrounding texts that are obtained from more than 1 million Web pages. The images and videos have been comprehensively annotated, including their relevance levels to corresponding queries, semantic concepts of images, and category and quality information of videos. We define six standard tasks on the dataset: (1) image search reranking; (2) image annotation; (3) query-by-example image search; (4) video search reranking; (5) video categorization; and (6) video quality assessment.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360509","","Asia;Conferences;Data mining;Information retrieval;Large-scale systems;Multimedia computing;Quality assessment;Search engines;Videos;Web pages","Internet;information retrieval;multimedia computing;video signal processing","MSRA-MM 2.0;Microsoft Research Asia Multimedia;Web pages;commercial search engine;image annotation;image search reranking;large-scale Web multimedia dataset;multimedia information retrieval;query-by-example image search;video categorization;video quality assessment;video search reranking","","29","","28","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Agglomeration and Elimination of Terms for Dimensionality Reduction","P. M. Ciarelli; E. Oliveira","Dept. of Electr. Eng., Univ. Fed. do Espirito Santo, Vitoria, Brazil","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","547","552","The vector space model is the usual representation of texts database for computational treatment. However, in such representation synonyms and/or related terms are treated as independent. Furthermore, there are some terms that do not add any information at all to the set of text documents, on the contrary they even might harm the performance of the information retrieval techniques. In an attempt to reduce this problem, some techniques have been proposed in the literature. In this work we present a method to tackle this problem. In order to validate our approach, we carried out a series of experiments on four databases and we compare the achieved results with other well known techniques. The evaluation results is such that our method obtained in all cases a better or equal performance compared to the other literature techniques.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364970","agglomeration of terms;dimensionality reduction;feature selection;text classification","Costs;Data mining;Deductive databases;Feature extraction;Frequency;Information retrieval;Information science;Intelligent systems;Spatial databases;Text categorization","database management systems;information retrieval;text analysis","computational treatment;dimensionality reduction;information retrieval techniques;representation synonyms;text documents;texts database;vector space model","","5","","16","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Enhancing Concept Detection by Pruning Data with MCA-Based Transaction Weights","L. Lin; M. L. Shyu; S. C. Chen","Dept. of Electr. & Comput. Eng., Univ. of Miami, Coral Gables, FL, USA","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","304","311","With the rapid increase in the amount of multimedia data, the researches on semantic information retrieval are facing a very challenging problem - the number of positive data instances with the target concept/object/event compared with the number of negative data instances without the target concept/object/event is much smaller, which is also called the data imbalance issue. Therefore, one of the popular topics in multimedia information processing and retrieval is data pruning, a technique that can automatically identify and prune the data instances from the training data set so that the pruned data set is able to enhance the performance of model learning, classification, and concept detection. In this paper, a novel data pruning framework which gives each transaction a weight based on multiple correspondence analysis (MCA) is proposed. These transaction weights are used as the measure for pruning the training data set. Meanwhile, the testing data set could be weighted and pruned as well so that the computational cost is reduced not only when building the model but also when applying the classifiers. Experimenting with 18 high-level concepts and the benchmark (both balanced and imbalanced) data sets from TRECVID, our proposed framework achieves promising results to enhance the concept detection performance of three well-known classifiers commonly used for concept detection.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.125","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363259","concept detection;data pruning;multiple correspondence analysis;transaction weight","Collaboration;Content based retrieval;Information filtering;Information filters;Information retrieval;Multimedia computing;Object detection;Support vector machines;Training data;USA Councils","information retrieval;multimedia databases","concept detection enhancement;multimedia data;multiple correspondence analysis;pruning data;semantic information retrieval;target concept;target event;target object;transaction weights","","5","","24","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"An efficient similarity search algorithm for web video","Zheng Cao; Ming Zhu","Department of Automation, University of Science and Technology of China, Hefei, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","209","213","The amount of online video is increasing tremendously nowadays. For the convenience of information retrieval, video similarity search has become an important research issue in content-based video retrieval. There is still no satisfying scalable fast similarity search method for large database. In order to solve two challenging problems: similarity measure and fast search, a novel efficient video similarity search algorithm is proposed in this paper. A compact video image signature was computed according to the statistics of spatial-temporal distribution of video frame sequences. The video similarity is measured based on the calculation of the number of similar video components. For the scalable computing requirement, a novel efficient search method based on clustering index table was presented by index clustering. The experimental results from the query tests in large database show this method is highly efficient and effective for similar video search.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357706","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357706","clustering index table;image signature;video similarity search","Clustering algorithms;Content based retrieval;Feature extraction;Image databases;Information retrieval;Search methods;Spatial databases;Statistical distributions;Variable structure systems;Video sharing","Internet;content-based retrieval;image sequences;pattern clustering;video retrieval","Web video;compact video image signature;content-based video retrieval;index clustering;information retrieval;online video;spatial-temporal distribution;video frame sequences;video similarity search algorithm","","0","","16","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Development of Flora-Oriented Plant Ontology","J. Shi; L. Huang","Coll. of Inf. Eng., Northwest A&F Univ., Yangling, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","3","","7","10","Free text botanical descriptions contained in printed floras can provide a wealth of valuable scientific information. Domain ontology is greatly useful in knowledge acquisition, sharing and analysis. In order to acquire the richness of the information contained in Chinese floras efficaciously, we introduced the flora-oriented plant ontology (FPO) into the process of knowledge acquisition. In view of the botanical description's characteristic in the floras, this paper constructed the domain ontology mainly from the aspect of floristic morphologic description. FPO can reflect the flora domain knowledge hierarchical structure clearly, and can be used for application systems, such as information extraction systems and information retrieval systems.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362479","flora-oriented;ontology construction;plant ontology","Artificial intelligence;Buildings;Data mining;Databases;Educational institutions;Encoding;Information retrieval;Knowledge acquisition;Knowledge engineering;Ontologies","biology computing;botany;knowledge acquisition;ontologies (artificial intelligence)","Chinese floras;flora domain knowledge hierarchical structure;flora-oriented plant ontology;floristic morphologic description;free text botanical descriptions;information extraction systems;information retrieval systems;knowledge acquisition","","0","","24","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Delivering Semantics-aware Compressed OLAP Views in Mobile Environments with Hand-OLAP","A. Cuzzocrea; D. Saccà","ICAR-CNR, Univ. of Calabria, Calabria, Italy","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","206","213","In this paper, we present further research achievements due to hand-OLAP, a Java-based distributed system that relies on semantics-based intelligent data cube compression techniques, and effectively and efficiently supports OLAP in mobile environments. Hand-OLAP is based on a systematic approach according to which first a two-dimensional OLAP view of interest is extracted from the target multidimensional data cube via the so-called OLAP dimension flattening process, and then this view is compressed by means of a meaningful semantics-based data cube compression approach. The compressed two-dimensional view is finally delivered to mobile devices, and used to interactive OLAP exploration and querying tasks in an off-line manner.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363394","","Artificial intelligence;Bismuth;Data mining;Decision making;Information retrieval;Java;Marketing and sales;Mobile computing;Multidimensional systems;Query processing","Java;data compression;data mining;mobile computing","Java-based distributed system;OLAP dimension flattening process;hand-OLAP;mobile environments;query;semantics-aware compressed OLAP;semantics-based intelligent data cube compression techniques;systematic approach;target multidimensional data cube","","2","","21","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"A novel framework for semantic-based video retrieval","Xiaoming Nan; Zhicheng Zhao; Anni Cai; Xiaohui Xie","School of Information and Telecommunication Engineering, BUPT, Beijing, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","415","419","In this paper, a novel framework for semantic-based video retrieval is proposed. 15 low-level visual features on different levels are extracted and a supervised SVM classifier is trained for each feature. We have explored early fusion schemes between SIFT and SURF, and evaluated 4 kinds of later fusion strategies. Experiments on TRECVID dataset show that the proposed system is effective and stable.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357647","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357647","TRECVID;concept detection;feature extraction;semantic-based video retrieval","Content based retrieval;Data mining;Detectors;Feature extraction;Histograms;Information retrieval;Layout;Pipelines;Robustness;Vocabulary","support vector machines;video retrieval","fusion schemes;low level visual features;semantic based video retrieval;supervised SVM classifier","","1","","18","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Research on Universal GML Parser Based on IGSD","X. Gao; X. Qi; S. Zhang; Y. Sheng; G. Lv","Inf. Eng. Dept., Shandong Water Polytech., Rizhao, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Functional structure and framework of a universal GML schema-based parser, along with design and implementation of the integrative grammatical and semantic database (abbreviated to IGSD) that is the core component of GML parser, have been discussed in this paper. IGSD lays the foundation for GML grammar validation and universal parsing of GML data. Whereas universal GML parser based on IGSD would provide a public platform for many GIS researches on spatial data issues, such as storage, compression, index, query, retrieval, transformation, exchange, transmission, integration and sharing, etc.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365191","","Data engineering;Design engineering;Encoding;Engines;Geographic Information Systems;Information retrieval;Markup languages;Spatial databases;Transportation;XML","geographic information systems;grammars","GIS;GML grammar validation;geography markup language;integrative grammatical and semantic database;query;universal GML schema-based parser","","4","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Evaluation Measures for Ordinal Regression","S. Baccianella; A. Esuli; F. Sebastiani","Ist. di Scienza e Tecnol., Inf. Consiglio Naz. delle Ric., Pisa, Italy","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","283","287","Ordinal regression (OR-also known as ordinal classification) has received increasing attention in recent times, due to its importance in IR applications such as learning to rank and product review rating. However, research has not paid attention to the fact that typical applications of OR often involve datasets that are highly imbalanced. An imbalanced dataset has the consequence that, when testing a system with an evaluation measure conceived for balanced datasets, a trivial system assigning all items to a single class (typically, the majority class) may even outperform genuinely engineered systems. Moreover, if this evaluation measure is used for parameter optimization, a parameter choice may result that makes the system behave very much like a trivial system. In order to avoid this, evaluation measures that can handle imbalance must be used. We propose a simple way to turn standard measures for OR into ones robust to imbalance. We also show that, once used on balanced datasets, the two versions of each measure coincide, and therefore argue that our measures should become the standard choice for OR.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364825","Class imbalance;Evaluation measures;Ordinal classification;Ordinal regression;Product reviews","Data engineering;Information retrieval;Intelligent systems;Measurement standards;Robustness;System testing;Systems engineering and theory","pattern classification;regression analysis","imbalanced dataset;ordinal classification;ordinal regression;parameter optimization;product review rating;rank learning;trivial system","","34","","28","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"A Methodology for Clustering XML Documents Based on Labeled Tree","L. Liu; Y. Zheng; B. Ding; H. Liu","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","397","401","The amount of XML documents is increasing rapidly. In order to analyze the information represented in XML documents efficiently, researches on XML document clustering are actively in progress. The key issue is how to devise the similarity measure between XML documents to be used for clustering. Since XML documents have hierarchical structure, it is not appropriate to cluster them by using a general document similarity measure. In this paper, we propose the novel similarity calculation measure by reducing Nesting and repeating in the whole XML document. Then propose an improved Edge-set comparison algorithm to calculate two XML documents' similarity. Our experiments show that the proposed method improves accuracy on the clustering, compared to the previous works.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358550","Clustering;Data mining;Semi-structured data;Structural similarity;XML","Clustering algorithms;Computer science;Educational institutions;Fuzzy systems;Information analysis;Information retrieval;Knowledge management;Management information systems;Measurement standards;XML","XML;pattern clustering","XML documents;document clustering;document similarity measure;edge-set comparison algorithm;hypermedia markup language;labeled tree;nesting reduction measure;repeating reduction method","","0","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"CoFKM: A Centralized Method for Multiple-View Clustering","G. Cleuziou; M. Exbrayat; L. Martin; J. H. Sublemontier","FIFO, Univ. of Orleans, Orleans, France","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","752","757","This paper deals with clustering for multi-view data, i.e. objects described by several sets of variables or proximity matrices. Many important domains or applications such as information retrieval, biology, chemistry and marketing are concerned by this problematic. The aim of this data mining research field is to search for clustering patterns that perform a consensus between the patterns from different views. This requires to merge information from each view by performing a fusion process that identifies the agreement between the views and solves the conflicts. Various fusion strategies can be applied, occurring either before, after or during the clustering process. We draw our inspiration from the existing algorithms based on a centralized strategy. We propose a fuzzy clustering approach that generalizes the three fusion strategies and outperforms the main existing multi-view clustering algorithm both on synthetic and real datasets.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.138","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360306","centralized clustering;collaborative clustering;fuzzy clustering;multi-view data","Chemistry;Clustering algorithms;Collaboration;Computational linguistics;Data mining;Information analysis;Information retrieval;Morphology;Social network services;Web pages","data mining;fuzzy set theory;pattern clustering","CoFKM;biology;centralized method;chemistry;data mining;fusion process;fuzzy clustering approach;information retrieval;marketing;multipleview data clustering process;proximity matrices","","9","","15","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Research on Retrieving Aeolian Desertification Land Surface Temperature of North Shaanxi Province with MODIS Data","H. Aidi; W. Guoliang; Z. Jun","Sch. of Environ. Sci. & Eng., Chang'an Univ., Xi'an, China","2009 Fifth International Conference on Natural Computation","20091228","2009","6","","243","246","In this paper, two important parameters (surface emissive and atmospheric transmittance) are computed from the VIS, NIR and MIR of MODIS image data. The values of LST are calculated by means of a split-window method based on thermal infrared band (band31 and band32) of MODIS image data in North Shaanxi province, Furthermore, the result from two different empirical formulas parameters is compared with the surface temperature from the corresponding position weather station observation at the time when the satellite transits. The results indicated that the simplified method can be used to acquire the reasonable values of land surface temperature and it is fit for North Shaanxi province. Thus this paper shows a good manner for monitoring large-scale and real-time land surface temperature in Aeolian desertification area using thermal bands of MODIS image data.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366488","Atmospheric transmittance;Land surface temperature;MODIS data;Split-window algorithm;Surface emissive","Forestry;Information retrieval;Land surface;Land surface temperature;MODIS;Production;Remote monitoring;Surface fitting;Temperature measurement;Temperature sensors","geophysical image processing;land surface temperature;remote sensing","Eeolian desertification land surface temperature retrieval;LST;MIR;MODIS image data;NIR;North Shaanxi Province;VIS;atmospheric transmittance;band31;band32;split-window method;surface emissive;thermal infrared band","","0","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Dynamic Cluster Construction Method Based on Query Characteristics in Peer-to-Peer Networks","Y. Kobayashi; T. Watanabe; A. Kanzaki; T. Yoshihisa; T. Hara; S. Nishio","Dept. of Multimedia Eng., Osaka Univ., Suita, Japan","2009 First International Conference on Advances in P2P Systems","20091228","2009","","","168","173","To improve the efficiency of information retrieval in P2P networks, there have been many researches on categorizing data items and clustering peers. In almost all these researches, the number of categories and the policy of categorization are predetermined and static. However, users' requirements for information retrieval dynamically change. This leads to undesired increase of network traffic. In this paper, we propose a dynamic cluster construction method based on query characteristics and a search method using dynamic cluster. Our method dynamically constructs clusters, when the access frequencies for certain data items increase. This approach can reduce the number of query messages for searching data items further than static clustering methods.","","POD:978-1-4244-5084-8","10.1109/AP2PS.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359004","dynamic cluster;peer-to-peer networks;query characteristics","Clustering methods;Computer networks;Data engineering;Frequency;Information retrieval;Information science;Multimedia systems;Peer to peer computing;Search methods;Telecommunication traffic","information retrieval;peer-to-peer computing","P2P networks;categorization;categorizing data items;clustering peers;dynamic cluster construction method;information retrieval;network traffic;peer-to-peer networks;query characteristics;query messages;static clustering method","","2","","13","","","11-16 Oct. 2009","","IEEE","IEEE Conference Publications"
"Implementation of FII-based Image Retrieval Engine","Tan Hao; Chen Yu; Qiu Hang","Department of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, 610054, China","2009 International Conference on Apperceiving Computing and Intelligence Analysis","20091228","2009","","","349","351","An Image Feature Inverted Indexing(FII) method is proposed. Based on this method, a prototype of Content-Based Image Retrieval Engine named Eva is implemented. It extracts shape and texture feature from user's pictures, retrieves similar pictures with FII method. The efficiency of FII is also analyzed.","","POD:978-1-4244-5204-0","10.1109/ICACIA.2009.5361084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361084","Feature inverted indexing;Image retrieval engine;Shape and texture feature","Content based retrieval;Data mining;Feature extraction;Image retrieval;Indexing;Information retrieval;Internet;Prototypes;Search engines;Shape","content-based retrieval;feature extraction;image retrieval;indexing","Eva;FII method;content based image retrieval engine;image feature inverted indexing method;shape and texture feature extraction;shape extraction","","1","","3","","","23-25 Oct. 2009","","IEEE","IEEE Conference Publications"
"Event-centric View of Consumer Image Collections","S. Hibino; M. D. Wood","Eastman Kodak Co., Rochester, NY, USA","2009 11th IEEE International Symposium on Multimedia","20091228","2009","","","207","212","Benchmark and ground truth databases are critical for evaluating imaging- and event-based algorithms, but such databases can be time consuming to create, cannot be representative of all real-life consumer image collections, and do not necessarily provide feedback on the general utility of an imperfect algorithm applied to real-life data. An alternative solution is needed to complement evaluation by benchmark and ground truth databases. We designed and developed event analyzer as a tool to meet this need. Event analyzer combines data visualization of metadata with event and image retrieval results in a way that enables researchers to easily review data trends, quickly filter and select data, see relationships between metadata values, and visually scan retrieved results to determine correctness. In this paper, we describe the tool and discuss how it can and has been used to analyze real-life consumer collections in an event-centric manner.","","POD:978-1-4244-5231-6","10.1109/ISM.2009.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364500","consumer image collection;events;metadata validation;metadata visualization","Clustering algorithms;Data analysis;Data visualization;Feedback;Filters;Image databases;Image retrieval;Information retrieval;Multimedia databases;Visual databases","data visualisation;image retrieval;meta data;visual databases","consumer image collections;data visualization;event analyzer;event-based algorithm;event-centric view;ground truth databases;image retrieval;imaging-based algorithm;metadata","","0","2","10","","","14-16 Dec. 2009","","IEEE","IEEE Conference Publications"
"Non-relevance Feedback for Document Retrieval","X. Wang; Y. Li","Wuhan Univ. of Sci. & Eng., Wuhan, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","361","364","We need to find documents that relate to human interesting from a large data set of documents. The relevance feedback method needs a set of relevant and non-relevant documents to work usefully. However, the initial retrieved documents, which are displayed to a user, sometimes don't include relevant documents. In order to solve this problem, we propose a new feedback method using information of non-relevant documents only. The non-relevance feedback document retrieval is based on one-class support vector machine. Our experimental results show that this method can retrieve relevant documents using information of nonrelevant documents only.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362010","Document Retrieval;Non-Relevance Feedback;Web Personalization","Cities and towns;Feedback;Humans;Information retrieval;Kernel;Knowledge acquisition;Knowledge engineering;Support vector machine classification;Support vector machines;Training data","document handling;information retrieval;support vector machines","Web personalization;document retrieval;nonrelevance feedback;one-class support vector machine","","0","","10","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Wood Image Retrieval Algorithm Based on Keyblock Distribution","W. Song; C. Cai","Coll. of Inf. Eng., Northwest A&F Univ., Xi'an, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","As is known to all, there are many kinds of wood. If we distinguish the wood's characteristics by our eyesight, we can't distinguish the category and property of the wood correctly, and this way will cost enormous workload. In this paper, we propose the keyblock distribution based wood image retrieval algorithm, in order to make the wood image retrieval algorithm more precise and objective. Keyblocks are the representative blocks that we extract from all the candidate blocks. All the keyblocks form the codebook which is used to encode the wood image. By encoding the wood image into the form of index matrix we can extract the feature vector of the wood image. This keyblock distribution based wood image retrieval algorithm is similar to the keyword based text retrieval algorithm. In the text retrieval algorithm, keyword can be used to represent the content of the text. Similarly, the keyblock in our proposed algorithm can be used to represent the content characteristics of wood images. Keyblock can extract the spatial distribution of wood image's characteristics. Experimental results show that our proposed algorithm has achieved ideal performance.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5363402","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363402","","Content based retrieval;Costs;Data mining;Educational institutions;Feature extraction;Histograms;Humans;Image coding;Image retrieval;Information retrieval","feature extraction;image retrieval","codebook;feature extraction;index matrix;keyblock distribution;keyword based text retrieval algorithm;wood image retrieval","","0","","16","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Dynamic Representation of a Situation: A Step of a Decision Support Process","F. Kebair; F. Serin","Lab. d'Inf. de Traitement l'Inf. et des Syst., Le Havre Univ., Le Havre, France","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","473","478","A multiagent approach to build a decision support system is proposed in this paper. We think the system may be used in different applications types and is appropriate for complex problems as the risk management thanks to a mechanism of perception, representation, characterization and assessment. We focus here on a first level of this approach that intends to reflect the dynamic evolution of the current situation. The RoboCupRescue is used as a test bed. Experimentations and results are provided and discussed.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364931","Decision support system;factual agent;factual semantic feature;indicators","Application software;Crisis management;Decision support systems;Environmental management;Information retrieval;Intelligent systems;Large-scale systems;Risk management;Spread spectrum communication;Testing","decision support systems;multi-agent systems;risk management","RoboCupRescue;decision support process;decision support system;multiagent approach;risk management","","0","","12","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Sentence Similarity Measure Based on Events and Content Words","J. f. Shan; Z. t. Liu; W. Zhou","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","623","627","Similarity between sentences plays an important role in a variety of applications of natural language process. The paper proposes a novel method to calculate sentence similarity, which takes into account both semantic and syntax: measuring semantic similarity based on events, measuring syntactic similarity based on content words sequence. Our experimental results show that the method is reasonable and effective.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.926","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360085",":Sentence similarity;Content Words Sequence;Event;Event similarity","Application software;Books;Cognitive science;Computational linguistics;Data mining;Information retrieval;Natural languages;Statistics","computational linguistics;natural language processing;text analysis","content words sequence;event;natural language process;semantic similarity measurement;sentence similarity measurement;syntactic similarity measurement;syntax","","1","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Extracting Relevance Information from User Click through Data Using Conditional Random Field","B. Xie","Shanghai Jiao Tong Univ., Shanghai, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","It is now widely recognized that user interactions with search results can provide substantial relevance information on the documents. In this paper, we focus on extracting relevance information from one source of user interactions, user click-through data which record the sequence of documents being clicked in the result sets during a user search session. We emphasize the importance of the temporal nature of user click patterns and use conditional random fields to model its relations with the degree of relevance of the individual documents in the result sets. A key advantage of our models and algorithms is their ability to express the long-distance inter-actions conditioned on the click patterns. We test our algorithms using click-through data from a commercial search engine and evaluate the extracted relevance grades against those assigned by human judges.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5366423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366423","","Data mining;Design engineering;Feedback;Hidden Markov models;Humans;Information retrieval;Predictive models;Search engines;Testing;Web sites","information analysis;pattern recognition;search engines;user interfaces","commercial search engine;conditional random field;documents relevance information;relevance information extraction;search result;user click pattern;user interaction;user search session","","0","","11","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Image features optimizing for content-based image retrieval","Zhiping Shi; Xi Liu; Qing He; Zhongzhi Shi","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China. 100190","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","4","","260","264","Developing low-dimensional semantics-sensitive features is crucial for content-based image retrieval (CBIR). In this paper, we present a method called M2CLDA (merging 2-class linear discriminant analysis) to capture low-dimensional optimal discriminative features in the projection space. M2CLDA calculates discriminant vectors with respect to each class in the one-vs-all classification scenario and then merges all the discriminant vectors to form a projection matrix. The dimensionality of the M2CLDA space fits in with the number of classes involved. Moreover, when a new class is added, the new M2CLDA space can be approximated by only calculating a new discriminant vector for the new class. The features in the M2CLDA space have better semantic discrimination than those in traditional LDA space. Our experiments show that the proposed approach improves the performance of image retrieval and image classification dramatically.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357682","2-class LDA;discriminative features;image retrieval;image semantics","Content based retrieval;Data mining;Helium;Image classification;Image retrieval;Information retrieval;Linear discriminant analysis;Principal component analysis;Scattering;Vectors","content-based retrieval;image retrieval;matrix algebra;statistical analysis;vectors","CBIR;M2CLDA;content-based image retrieval;discriminant vector;image classification;image feature;low-dimensional semantics-sensitive feature;merging 2-class linear discriminant analysis;projection matrix","","0","","12","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Research and Implementation on Multi-Cues Based Page Segmentation Algorithm","Y. Hu; M. Miao","Comput. Sci. & Technol. Sch., Wuhan Univ. of Technol., Wuhan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","In view of that the exiting segmentation algorithms use only one kind of cue, but while users viewing the Web page, human brain can handle many cues and segment the pages subconsciously. So this paper considers many kinds of cues, simulates the process of user-perception, analyzes the structure of Web pages and proposes the multi-cues based page segmentation algorithm. After the segmentation, semantic information is added to every semantic block.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5363822","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363822","","Algorithm design and analysis;Brain modeling;Computer science;Content based retrieval;Data mining;HTML;Humans;Information retrieval;Internet;Web pages","Internet;information retrieval","Web page;human brain;multicues based page segmentation algorithm;semantic block;semantic information;user perception","","1","","4","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"SEIF: Search Enhanced by Intelligent Feedback in Unstructured P2P Networks","X. Yang; Y. Hu","Dept. of Electr. & Comput. Eng., Univ. of Cincinnati, Cincinnati, OH, USA","2009 International Conference on Parallel Processing","20091228","2009","","","494","501","To improve the performance of similarity search and information retrieval is an important research issue in peer-to-peer environment. In this paper, we propose a distributed architecture for enhancing the performance of similarity search in unstructured P2P networks. The key component of the proposed architecture is a distributed, content-based, heuristic feedback mechanism, which allows peers to keep track of recent queries and learn from the assessment of answers to previous queries, so as to self-adaptively route the subsequent query to the most relevant nodes which are responsible for the query. Therefore a high recall rate can be achieved by probing only a small amount of peers. We also propose a distributed automatic query expansion mechanism to improve the quality of query results. Since the architecture is entirely distributed, it scales well with the large sized networks. The experimental results show that our architecture can efficiently solve queries with a relatively small cost.","0190-3918;01903918","POD:978-1-4244-4961-3","10.1109/ICPP.2009.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362464","similarity search;unstructured peer-to-peer systems","Bandwidth;Computer architecture;Costs;Feedback;Information retrieval;Intelligent networks;Parallel processing;Peer to peer computing;Query processing;Routing","peer-to-peer computing;query processing;software architecture","SEIF;content-based feedback;distributed architecture;distributed automatic query expansion mechanism;heuristic feedback mechanism;information retrieval;peer-to-peer network;search enhanced by intelligent feedback;unstructured P2P networks","","0","","25","","","22-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Run to Potential: Sweep Coverage in Wireless Sensor Networks","M. Xi; K. Wu; Y. Qi; J. Zhao; Y. Liu; M. Li","Dept. of Comput. Sci., Xi'an Jiaotong Univ., Xi'an, China","2009 International Conference on Parallel Processing","20091228","2009","","","50","57","Wireless sensor networks have become a promising technology in monitoring physical world. In many applications with wireless sensor networks, it is essential to understand how well an interested area is monitored (covered) by sensors. The traditional way of evaluating sensor coverage requires that every point in the field should be monitored and the sensor network should be connected to transmit messages to a processing center (sink). Such a requirement is too strong to be financially practical in many scenarios. In this study, we address another type of coverage problem, sweep coverage, when we utilize mobile nodes as supplementary in a sparse and probably disconnected sensor network. Different from previous coverage problem, we focus on retrieving data from dynamic Points of Interest (POIs), where a sensor network does not necessarily have fixed data rendezvous points as POIs. Instead, any sensor node within the network could become a POI. We first analyze the relationship among information access delay, information access probability, and the number of required mobile nodes. We then design a distributed algorithm based on a virtual 3D map of local gradient information to guide the movement of mobile nodes to achieve sweep coverage on dynamic POIs. Using the analytical results as the guideline for setting the system parameters, we examine the performance of our algorithm compared with existing approaches.","0190-3918;01903918","POD:978-1-4244-4961-3","10.1109/ICPP.2009.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361809","","Algorithm design and analysis;Computer science;Computerized monitoring;Costs;Delay;Event detection;Information retrieval;Sensor phenomena and characterization;Sensor systems;Wireless sensor networks","distributed algorithms;sensor placement;wireless sensor networks","distributed algorithm;information access delay;information access probability;local gradient information;mobile nodes;sensor coverage;sweep coverage;virtual 3D map;wireless sensor networks","","5","","22","","","22-25 Sept. 2009","","IEEE","IEEE Conference Publications"
"Research on Topic Identification Technologies of Professional Search Engine Based on Hyperlink Analysis","X. Wang; X. Fu; H. Xu","Sci. & Technol. Inf. Res. Inst., Shandong Univ. of Technol., Zibo, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","In the face of difficulties and challenges of traditional search engine, the professional search engine turns up which can meet the needs of special group and is convenient to collect particular subjects or special Web topic resources. This paper analyzes 4 professional search engines' techniques of hyperlink analysis for topic identification and their algorithms. Furthermore, we find out some problems to these algorithms and give some advices for future research.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365611","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365611","","Algorithm design and analysis;Citation analysis;Crawlers;Filters;Hardware;Information analysis;Information retrieval;Search engines;Search methods;Vocabulary","Internet;information retrieval;search engines","Web topic resource;hyperlink analysis;professional search engine;topic identification","","0","","14","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Adaptability of a Deployment Decision Making System","R. Kusber; N. Brgulja; K. David","Dept. of Commun. Technol. (ComTec), Univ. of Kassel, Kassel, Germany","2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns","20091228","2009","","","27","32","In our living environments today, computer networks, computing devices, sensors and many other entities produce a large amount of data to be processed. This data comprise, for example, digital media content, news, computational resources like services, and much more. To be able to exploit this data, a (human or computer) user may utilize digital assistants. In this paper, we present such an assistant for deploying services and obtaining content data. We concentrate especially on how this assistant is able to adapt to changing situations, both, user-driven and in a self-adaptive manner. An experimental evaluation, based on real world digital video providers, demonstrates prerequisites, results, and potential of the various ways of adaptation within the presented approach.","","POD:978-1-4244-5166-1","10.1109/ComputationWorld.2009.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359549","adaptability;content retrieval;decision making;self-adaptation;service deployment","Communications technology;Computer networks;Content based retrieval;Decision making;Distributed decision making;Humans;Information retrieval;Information technology;Internet;Sensor systems","content management;decision support systems;information retrieval","data exploitation;deployment decision making system adaptability;digital assistant utilization;self-adaptive feature;user driven feature","","0","","11","","","15-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"MST Segmentation for Content-Based Medical Image Retrieval","Y. Lu; Y. Quan; Z. Zhang; G. Wang","Coll. of Comput. Sci. & Technol., Jilin Univ., Changchun, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","-This paper describes an improved segmentation algorithm based on Minimum Spanning Tree (MST) for content-based image retrieval system. MST segmentation is computationally efficient and captures both global and local image information, but it is prone to incur over-segmentation because of its neighbor system. To address this problem, an adaptive neighbor mode in the improved segmentation is defined by adding links between non-neighbor pixels of an image. The meaningful regions of an image are segmented automatically, and the region-based color features are exacted for the dominant segmented regions. The texture features are exacted using the Gabor filters, and are combined with the color features for retrieval The Experiments are performed using a medical database containing 370 images and the experimental results are shown and described finally.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5366632","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366632","","Biomedical imaging;Content based retrieval;Feature extraction;Gabor filters;Image databases;Image retrieval;Image segmentation;Information retrieval;Pixel;Spatial databases","Gabor filters;content-based retrieval;feature extraction;image retrieval;image segmentation;medical image processing","Gabor filters;MST segmentation;adaptive neighbor mode;color feature extraction;content-based retrieval;medical image retrieval;minimum spanning tree;texture feature extraction","","1","","16","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Ontology Learning Through Focused Crawling and Information Extraction","H. P. Luong; S. Gauch; Q. Wang","CSCE Dept., Univ. of Arkansas, Fayetteville, AR, USA","2009 International Conference on Knowledge and Systems Engineering","20091228","2009","","","106","112","Ontology learning aims to facilitate the construction of ontologies by decreasing the amount of effort required to produce an ontology for a new domain. However, there are few studies that attempt to automate the entire ontology learning process from the collection of domain-specific literature, to text mining to build new ontologies or enrich existing ones. In this paper, we present a complete framework for ontology learning that enables us to retrieve documents from the Web using focused crawling, and then use a SVM (support vector machine) classifier to identify domain-specific documents and perform text mining in order to extract useful information for the ontology enrichment process. We have carried out several experiments on components of this framework in a biological domain, amphibian morphology. This paper reports on the overall system architecture and our initial experiments on information extraction using text mining techniques to enrich the domain ontology.","","POD:978-1-4244-5086-2","10.1109/KSE.2009.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361721","SVM;focused crawling;information extraction;ontology learning;text mining","Data mining;Humans;Information retrieval;Machine learning;Morphology;Ontologies;Support vector machine classification;Support vector machines;Text mining;Vocabulary","biology computing;data mining;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);pattern classification;support vector machines;text analysis","SVM classifier;Web document retrieval;amphibian morphology;domain-specific documents;focused crawling;information extraction;ontology enrichment process;ontology learning;support vector machine;text mining","","4","","16","","","13-17 Oct. 2009","","IEEE","IEEE Conference Publications"
"Information Extraction for Clinical Data Mining: A Mammography Case Study","H. Nassif; R. Woods; E. Burnside; M. Ayvaci; J. Shavlik; D. Page","Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","37","42","Breast cancer is the leading cause of cancer mortality in women between the ages of 15 and 54. During mammography screening, radiologists use a strict lexicon (BI-RADS) to describe and report their findings. Mammography records are then stored in a well-defined database format (NMD). Lately, researchers have applied data mining and machine learning techniques to these databases. They successfully built breast cancer classifiers that can help in early detection of malignancy. However, the validity of these models depends on the quality of the underlying databases. Unfortunately, most databases suffer from inconsistencies, missing data, inter-observer variability and inappropriate term usage. In addition, many databases are not compliant with the NMD format and/or solely consist of text reports. BI-RADS feature extraction from free text and consistency checks between recorded predictive variables and text reports are crucial to addressing this problem. We describe a general scheme for concept information retrieval from free text given a lexicon, and present a BI-RADS features extraction algorithm for clinical data mining. It consists of a syntax analyzer, a concept finder and a negation detector. The syntax analyzer preprocesses the input into individual sentences. The concept finder uses a semantic grammar based on the BI-RADS lexicon and the experts' input. It parses sentences detecting BI-RADS concepts. Once a concept is located, a lexical scanner checks for negation. Our method can handle multiple latent concepts within the text, filtering out ultrasound concepts. On our dataset, our algorithm achieves 97.7% precision, 95.5% recall and an F<sub>1</sub>-score of 0.97. It outperforms manual feature extraction at the 5% statistical significance level.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360530","","Breast cancer;Cancer detection;Data mining;Data preprocessing;Detectors;Feature extraction;Information retrieval;Machine learning;Mammography;Spatial databases","cancer;data mining;feature extraction;information retrieval;learning (artificial intelligence);mammography","BI-RADS feature extraction;breast cancer classifiers;clinical data mining;concept finder;free text;information extraction;machine learning techniques;mammography case study;negation detector;semantic grammar;syntax analyzer","","7","","34","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Distributed Multimedia Metadata Tracking and Management: An Ontology-Based Approach with Use of RSS","T. Belis; A. Doulamis","Decision Support Syst. Lab., Tech. Univ. of Crete, Chania, Greece","2009 16th International Conference on Systems, Signals and Image Processing","20091228","2009","","","1","4","In this paper we present a multimedia metadata management system that uses ontologies for efficient multimedia traceability and management. The use of digital devices to produce image and video content even by novices is expected to significantly increase the amount of multimedia data. This raises the need of adoption of an effective ontology-based model for intelligent multimedia metadata management. The problem assumes greater significance due to different file formats and the necessity of integrating largely distributed and diverse information system implementations. Provided that efficient searching and retrieval systems are based on how annotated data are organized and managed, in our study we use the RSS 2.0 (Really Simple Syndication) format, for enhancing the ontology with multimedia information.","2157-8672;21578672","POD:978-1-4244-4530-1","10.1109/IWSSIP.2009.5367703","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367703","","Content management;Decision support systems;ISO standards;Information retrieval;Laboratories;Multimedia systems;Ontologies;Standardization;Vocabulary;XML","distributed databases;information retrieval;meta data;multimedia computing;ontologies (artificial intelligence)","RSS 2.0;annotated data;digital devices;distributed multimedia metadata tracking;intelligent multimedia metadata management;multimedia management;multimedia metadata management system;multimedia traceability;ontology-based approach;really simple syndication format;retrieval systems","","1","","10","","","18-20 June 2009","","IEEE","IEEE Conference Publications"
"Probabilistic Labeled Semi-supervised SVM","M. Qian; F. Nie; C. Zhang","Dept. of Autom., Tsinghua Univ., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","394","399","Semi-supervised learning has been paid increasing attention and is widely used in many fields such as data mining, information retrieval and knowledge management as it can utilize both labeled and unlabeled data. Laplacian SVM (LapSVM) is a very classical method whose effectiveness has been validated by large number of experiments. However, LapSVM is sensitive to labeled data and it exposes to cubic computation complexity which limit its application in large scale scenario. In this paper, we propose a multi-class method called Probabilistic labeled Semi-supervised SVM (PLSVM) in which the optimal decision surface is taught by probabilistic labels of all the training data including the labeled and unlabeled data. Then we propose a kernel version dual coordinate descent method to efficiently solve the dual problems of our Probabilistic labeled Semi-supervised SVM and decrease its requirement of memory. Synthetic data and several benchmark real world datasets show that PLSVM is less sensitive to labeling and has better performance over traditional methods like SVM, LapSVM (LapSVM) and Transductive SVM (TSVM).","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360437","","Data mining;Information retrieval;Kernel;Knowledge management;Labeling;Laplace equations;Large-scale systems;Semisupervised learning;Support vector machines;Training data","","","","2","","13","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Input Data Representation for Self-Organizing Map in Software Classification","Y. Lin; H. Ye","Sch. of Electr. Eng. & Comput. Sci., Univ. of Newcastle, Callaghan, NSW, Australia","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","350","353","A self-organizing map (SOM) is used to classify software documents and the associated software components with the aim to facilitate software reuse. SOM learns from input stimuli rather than training data, therefore the quality of input data representation is crucial to the success of SOM. In this paper, we use automatic indexing method to represent a document collection as the input data to train a SOM. The automatic indexing uses a phrase formation method to promote precision and a domain dependent relational thesaurus to enhance recall. A retrieval experiment based on a document collection containing 97 Unix manual pages was conducted to evaluate the effectiveness of this input data representation scheme. Promising retrieval results were observed.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362003","Self-Organizing Map;automatic indexing;software classification","Australia;Computer science;Content based retrieval;Humans;Information retrieval;Knowledge acquisition;Machine assisted indexing;Software reusability;Thesauri;Training data","Unix;data structures;indexing;information retrieval;relational databases;self-organising feature maps;software reusability","Unix manual pages;automatic indexing method;document retrieval;domain dependent relational thesaurus;input data representation;phrase formation method;self-organizing map;software classification;software components;software documents;software reuse","","2","1","9","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"CASTALIA: Architecture of a Fuzzy Metasearch Engine for Question Answering Systems","J. Serrano-Guerrero; J. A. Olivas; J. A. Gallego; F. P. Romero; A. Soto","Dept. of Inf. Technol. & Syst., Univ. of Castilla-La Mancha, Ciudad Real, Spain","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","73","78","The goal of this paper is to present the architecture of a metasearch engine called Castalia, still under development, which includes several underlying Q&A systems. Usually metasearch engines manage typical search engines like Google or Yahoo, but in this case the encapsulation of Q&A systems proposes new challenges that can be modeled by fuzzy logic apart from the other existing challenges such as the fuzzy modeling of temporal or causal questions.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362892","Fuzzy Logic;Metasearch engine;Question Answering System","Computer architecture;Data mining;Fuzzy logic;Fuzzy systems;Information processing;Information retrieval;Intelligent systems;Metasearch;Natural languages;Search engines","fuzzy logic;information retrieval;search engines","CASTALIA;fuzzy logic;fuzzy metasearch engine;question answering system","","0","","24","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"PASDS Plus PPAT Indexing Method for Multimedia Data","B. Wang; D. Gu; D. Yang; J. Zhang","Coll. of Comput. Software, Zhejiang Univ. of Technol., Hangzhou, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","2","","81","84","Indexing and query multimedia data is a challenging problem due to the high dimension of multimedia data. Clustering-based indexing structures are quite efficient for high-dimensional data indexing. Unfortunately, clustering-based indexing structures are normally static, and the whole structures have to be rebuilt after inserting new data. To resolve this issue, a two-level indexing method, called PASDS plus PPAT method, has been developed in this paper. In the PASDS level, clusters and their subspaces can be partially updated, while the indexing trees within the clusters are able to be partially updated at the PPAT level. By choosing proper number of children nodes, the proposed method can balance query accuracy and indexing efficiency. From experiments, the PASDS plus PPAT method is very efficient for updating clusters and inner indexing structures for newly inserted data, while its query accuracy and query time are almost the same with similar dynamic indexing methods.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362290","CBIR;Data clustering;Data mining;High-dimension data indexing;Knowledge retrieval","Clustering algorithms;Content based retrieval;Educational institutions;Image retrieval;Indexing;Information retrieval;Multimedia systems;Singular value decomposition;Software;Variable speed drives","content-based retrieval;data mining;indexing;multimedia computing;pattern clustering;trees (mathematics)","PASDS indexing method;PPAT indexing method;clustering-based indexing structures;content-based information retrieval;data mining;dynamic indexing methods;high-dimensional data indexing;multimedia data query;principal axis tree method;two-level indexing method","","0","","13","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Application of Color Change Feature in Gastroscopic Image Retrieval","C. Wu; X. Tai","Ningbo Inst. of Technol., Zhejiang Univ., Ningbo, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","3","","388","392","Content-based medical image retrieval is getting more and more importance in aspect of clinical assistant diagnose. In this paper a new method based on the characters of color change is proposed. First a color clustering technique is used for image segmentation in CIE L*a*b* color space. And then color change feature is extracted from the binary edge image. Kullback-Leibler distance is used to calculate the dissimilarity. Meanwhile a method combining both color change feature and dominant color information is proposed to carry out integrate retrieval. Finally, a system for gastroscopic image retrieval is developed which is available to support clinical decision making. Some contrast experiments are designed in the retrieval accuracies, the rank and the execution time. The comparison of the experimental results shows that the approach proposed in this paper is effective.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358996","Color Change Feature;Content-based Medical Image Retrieval;Gastroscopic Image;Integrated retrieval","Biomedical imaging;Content based retrieval;Data mining;Extraterrestrial measurements;Feature extraction;Image retrieval;Image segmentation;Information retrieval;Laboratories;Medical diagnostic imaging","content-based retrieval;decision making;feature extraction;image colour analysis;image retrieval;image segmentation;medical image processing;pattern clustering","CIE L*a*b* color space;Kullback-Leibler distance;binary edge image;clinical assistant diagnose;clinical decision making;color change feature extraction;color clustering technique;content-based medical image retrieval;dissimilarity calculation;gastroscopic image retrieval;image segmentation","","1","","11","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"PIDALION: Implementation Issues of a Java-Based Multimedia Search Engine over the Web","D. E. Charilas; O. I. Markaki","Dept. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece","2009 16th International Conference on Systems, Signals and Image Processing","20091228","2009","","","1","6","Fuelled by the rapid expansion of broadband connectivity and increasing interest in online multimedia-rich applications, the growth of digital multimedia content has skyrocketed. Among others, this growth is compounding the need for more effective methods for searching multimedia information. The automated web search engines that are currently used rely only on text descriptions and as a result provide matches of poor quality in case of multimedia content. The services of a multimedia search engine are therefore a possibility that the internet users still lack. Thus, the scope of this paper is to present an implementation approach for a personalized web-based multimedia search engine in the Java programming language. This approach combines the characteristics of the current search engines as well as new innovative features which guarantee at the same time the system's quick response and better search results. In this paper the reader can find an analytical presentation of all the components required to form a multimedia search engine, as well as indications on how to implement key algorithms and functions.","2157-8672;21578672","POD:978-1-4244-4530-1","10.1109/IWSSIP.2009.5367800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367800","","Content based retrieval;Crawlers;Data mining;Electronic mail;Image retrieval;Information retrieval;Java;Multimedia databases;Music information retrieval;Search engines","B-ISDN;Internet;Java;multimedia systems;search engines","Java based multimedia search engine;Java programming language;PIDALION;automated web search engines;broadband connectivity;digital multimedia content;internet users lack;key algorithms function;multimedia rich applications;searching multimedia information;web based multimedia search","","0","","14","","","18-20 June 2009","","IEEE","IEEE Conference Publications"
"A modified approach to keyword extraction based on word-similarity","Meng Wenchao; Liu Lianchen; Dai Ting","National CIMS Engineering Research Center, Tsinghua University, Beijing, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","3","","388","392","Two keyword-extraction ways are usually used, one is simply using the information from exactly single word like word frequency and TF.IDF, the other is based on the relationship between words. The relationship is usually described as word similarity which derives from a corpus (WordNet, HowNet) or man-made thesaurus. With the information explosion nowdays, the words we using are growing and changing rapidly. A lot of new words are not specified in man-made corpus. This paper proposes a new method to build a word similarity thesaurus. Using the semantic information from the thesaurus, together with TF.IDF and word's first occurrence, a keyword extraction algorithm is demonstrated, the results and analysis are also given.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5358135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358135","Jenson-Shannon divergence;Naïve Bayes;keyword extraction;word similarity","Algorithm design and analysis;Clustering algorithms;Computer integrated manufacturing;Costs;Data mining;Explosions;Frequency;Information analysis;Information retrieval;Thesauri","information retrieval;thesauri","TF.IDF;information retrieval;keyword extraction;word similarity thesaurus","","1","","16","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A K-means Approach Based on Concept Hierarchical Tree for Search Results Clustering","P. Jiang; C. Zhang; G. Guo; Z. Niu; D. Gao","Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","380","386","Search results clustering aims to facilitate users' information retrieval process and query refinement by online grouping similar documents returned from the search engine. It has stringent requirements on performance and meaningful cluster labels. Thus, most existing clustering algorithms such as K-means and agglomerative hierarchical clustering cannot be directly applied to the task of online search results clustering. In this paper, we propose a K-means approach based on concept hierarchical tree to cluster search results. This algorithm not only over comes weaknesses of the classic K-means method: the results produced depend on the initial seeds and the parameter k is often unknown, but also satisfies the requirements of online search results clustering. Our method utilizes the semantic relation among documents by mapping terms to concepts in the concept hierarchical tree, which can be constructed by WordNet. We have developed a meta-search and clustering system based on our approach, followed by using an impersonal and repeatable evaluation solution. Experimental results indicate that our proposed algorithm is effective and suitable in performing the task of clustering search results.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.658","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358569","","Clustering algorithms;Computer science;Filters;Fuzzy systems;Information retrieval;Metasearch;Rail transportation;Search engines;Web search;Web sites","pattern clustering;query formulation;search engines;trees (mathematics)","K-means approach;WordNet;concept hierarchical tree;information retrieval process;meta-search;online search results clustering;query refinement;search engine","","1","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"SemSLATES: Improving enterprise 2.0 information systems using semantic Web technologies","A. Passant; P. Laublet; J. G. Breslin; S. Decker","Digital Enterprise Research Institute, National University of Ireland, Galway, Ireland","2009 5th International Conference on Collaborative Computing: Networking, Applications and Worksharing","20091228","2009","","","1","10","While the use of Web 2.0 tools and principles in organizations - a practice commonly known as Enterprise 2.0 - helps knowledge workers to collaboratively build and exchange information more easily, it introduces several issues in terms of efficiently integrating and retrieving this information. In this paper, we describe how semantic Web technologies can be efficiently deployed to solve these issues and to enhance such ecosystems. We detail the SemSLATES methodology, a middleware architecture for Enterprise 2.0 that combines Social Web principles and Semantic Web technologies in a novel and innovative way for the benefit of end users. Since the work presented here has been applied in an industrial context, we emphasize our motivations and the benefits of the approach through a complete and real-world case study.","","CD-ROM:978-963-9799-76-9","10.4108/ICST.COLLABORATECOM2009.8369","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363791","","Collaborative tools;Collaborative work;Companies;Ecosystems;Information retrieval;Information systems;Management information systems;Middleware;Semantic Web;Social network services","business data processing;information retrieval;middleware;semantic Web","SemSLATES methodology;Web 2.0 tools;enterprise 2.0 information systems;industrial context;information retrieval;middleware architecture;semantic Web technologies;social Web principles","","2","","39","","","11-14 Nov. 2009","","IEEE","IEEE Conference Publications"
"TubeTagger - YouTube-based Concept Detection","A. Ulges; M. Koch; D. Borth; T. M. Breuel","IUPR Res. Group, German Res. Center for Artificial Intell. (DFKI) GmbH, Kaiserslautern, Germany","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","190","195","We present TubeTagger, a concept-based video retrieval system that exploits Web video as an information source. The system performs a visual learning on YouTube clips (i. e., it trains detectors for semantic concepts like ""soccer"" or ""windmill""), and a semantic learning on the associated tags (i.e., relations between concepts like ""swimming"" and ""water"" are discovered). This way, a text-based video search free of manual indexing is realized. We present a quantitative study on Web-based concept detection comparing several features and statistical models on a large-scale dataset of YouTube content. Beyond this, we report several key findings related to concept learning from YouTube and its generalization to different domains, and illustrate certain characteristics of YouTube-learned concepts, like focus of interest and redundancy. To get a hands-on impression of Web-based concept detection, we invite researchers and practitioners to test our Web demo.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360505","","Data mining;Detectors;Focusing;Image databases;Indexing;Information retrieval;Large-scale systems;Training data;Vocabulary;YouTube","Internet;content management;content-based retrieval;data mining;query formulation;search engines;social networking (online)","TubeTagger;Web based concept detection;Web video;YouTube based concept detection;YouTube clips;YouTube content large scale dataset;concept based video retrieval system;semantic learning;text based video search;visual learning","","3","","28","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Knowledge Transformation by Cross-Domain Belief Propagation","F. Wang; T. Li","Sch. of Comput. & Inf. Sci., Florida Int. Univ., Miami, FL, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","441","446","Belief propagation is an iterative algorithm for computing marginals of functions on a graphical model most commonly used in information retrieval. In this paper, we consider the problem of performing cross-domain belief propagation on multi-relational data for semi-supervised learning. We demonstrate that partial knowledge on one type of variables can help knowledge discovery on the other type of variables with cross-domain belief propagation by utilizing the existing relationships in multi-relation data. For example, in a word-document data set, information on the word domain can effectively enhance the labeling of document domain. In this paper, we explore this new area, knowledge transformation of multi-relation data for semi-supervised learning tasks. We show that partial knowledge on one data variable domain can help knowledge discovery on the other variable domain with cross-domain belief propagation by utilizing the existing relationships in multi-relation data. The experimental results on several real world data sets are presented to show the effectiveness of our method.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360445","","Belief propagation;Conferences;Data mining;Face;Graphical models;Information retrieval;Iterative algorithms;Labeling;Semisupervised learning;Text categorization","belief networks;data mining;iterative methods;learning (artificial intelligence);relational databases","cross domain belief propagation;information retrieval;iterative algorithm;knowledge discovery;knowledge transformation;multirelation data;multirelational data;semisupervised learning;word document data set","","0","","15","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Hierarchical Bayesian Models for Collaborative Tagging Systems","M. Bundschus; S. Yu; V. Tresp; A. Rettinger; M. Dejori; H. P. Kriegel","Inst. for Comput. Sci., Ludwig-Maximilians-Univ. Munchen, Munich, Germany","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","728","733","Collaborative tagging systems with user generated content have become a fundamental element of websites such as Delicious, Flickr or CiteULike. By sharing common knowledge, massively linked semantic data sets are generated that provide new challenges for data mining. In this paper, we reduce the data complexity in these systems by finding meaningful topics that serve to group similar users and serve to recommend tags or resources to users. We propose a well-founded probabilistic approach that can model every aspect of a collaborative tagging system. By integrating both user information and tag information into the well-known Latent Dirichlet Allocation framework, the developed models can be used to solve a number of important information extraction and retrieval tasks.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.121","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360302","LDA;collaborative tagging;user modeling","Bayesian methods;Computer science;Data mining;Data systems;Educational institutions;Information retrieval;International collaboration;Linear discriminant analysis;Tagging;USA Councils","Bayes methods;Web sites;data mining;groupware;identification technology","Web sites;collaborative tagging systems;data mining;hierarchical Bayesian models;latent Dirichlet allocation framework","","14","","10","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Document Representation Using Nonnegative Matrix Factorization","X. Pei; L. Xiao; C. Chen","Coll. of Software, HuaZhong Universirty of Sci. & Technol., Wuhan, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Non-negative matrix factorization (NMF) is an emerging technique of latent semantic analysis from the given document corpus. The existing NMF algorithms don not use the intrinsic structure information of original document corpus. In order to preserve intrinsic structure information in latent semantic space extracted by NMF, a NMF algorithm with intrinsic structure information properties is presented. The primary ideal is to extend the original NMF through incorporating the intrinsic structure information constraints inside the NMF decomposition. Our experimental results performed on the RCV1 and SECTOR data sets show that the proposed method is superior to NMF for document latent semantic analysis.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5362815","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362815","","Data mining;Educational institutions;Indexing;Information retrieval;Large scale integration;Matrix decomposition;Performance analysis;Space technology;Sparse matrices;Text analysis","document handling;information retrieval;matrix decomposition","SECTOR data sets;document representation;intrinsic structure information constraints;latent semantic analysis;nonnegative matrix factorization;vector space information retrieval","","0","","23","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Notice of Retraction<BR>A Hybrid Tree Spatial Indexing Method Based on the Clustering Algorithm","J. Yang; J. Shu; C. Xiong; X. Zhou","Dept. of Comput. & Inf. Eng., Wuhan Polytech. Univ., Wuhan, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Notice of Retraction<BR><BR>After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<BR><BR>We hereby retract the content of this paper. Reasonable effort should be made to remove all past references to this paper.<BR><BR>The presenting author of this paper has the option to appeal this decision by contacting TPII@ieee.org.<BR><BR>The paper first to carry on three clustering divisions to the spatial objects using the improved TGSOM algorithm, and obtains a series of similar nodes which contain the spatial objects of which have the same quantity and the same area on the whole, as well as a few noise spots which do not belong to any similar nodes, and then constitutes the dendritic structure after removing the noise spots; afterwards, optimize for the dendritic structure using the mixed structure based on the quad-division and the R* tree, which has eliminated the overlapping and coverage factors to the nodes, and has improved the retrieval efficiency of the mass data; Finally it has proved the validity and accuracy of the method through the experiment.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366391","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366391","","Clustering algorithms;Computer science;Data engineering;Indexes;Indexing;Information retrieval;Optimization methods;Performance analysis;Shape;Tree data structures","indexing;information retrieval;pattern clustering;tree data structures","R* tree structure;clustering algorithm;hybrid tree spatial indexing method;improved TGSOM algorithm;retrieval efficiency","","0","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Document Clustering Using Concept Space and Cosine Similarity Measurement","L. Muflikhah; B. Baharudin","Dept. of Comput. & Inf. Sci., Univ. Teknol. Petronas, Tronoh, Malaysia","2009 International Conference on Computer Technology and Development","20091228","2009","1","","58","62","Document clustering is related to data clustering concept which is one of data mining tasks and unsupervised classification. It is often applied to the huge data in order to make a partition based on their similarity. Initially, it used for Information Retrieval in order to improve the precision and recall from query. It is very easy to cluster with small data attributes which contains of important items. Furthermore, document clustering is very useful in retrieve information application in order to reduce the consuming time and get high precision and recall. Therefore, we propose to integrate the information retrieval method and document clustering as concept space approach. The method is known as Latent Semantic Index (LSI) approach which used Singular Vector Decomposition (SVD) or Principle Component Analysis (PCA). The aim of this method is to reduce the matrix dimension by finding the pattern in document collection with refers to concurrent of the terms. Each method is implemented to weight of term-document in vector space model (VSM) for document clustering using fuzzy c-means algorithm. Besides reduction of term-document matrix, this research also uses the cosine similarity measurement as replacement of Euclidean distance to involve in fuzzy c-means. And as a result, the performance of the proposed method is better than the existing method with f-measure around 0.91 and entropy around 0.51.","","POD:978-0-7695-3892-1","10.1109/ICCTD.2009.206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359952","LSI;cosine similarity;data mining;document clustering;fuzzy c-means","Clustering algorithms;Clustering methods;Data mining;Euclidean distance;Extraterrestrial measurements;Information retrieval;Information science;Large scale integration;Principal component analysis;Space technology","data mining;document handling;fuzzy set theory;matrix algebra;pattern classification;pattern clustering;principal component analysis;singular value decomposition;vectors","Euclidean distance;concept space;cosine similarity measurement;data attributes;data clustering concept;data mining tasks;document clustering;document collection;fuzzy c-means algorithm;information retrieval;latent semantic index approach;matrix dimension;principle component analysis;singular vector decomposition;term-document matrix;unsupervised classification;vector space model","","10","","18","","","13-15 Nov. 2009","","IEEE","IEEE Conference Publications"
"The Characteristic of Chinese Search Based on Sogou Log","X. Wang; M. Yang; S. Li; T. Zhao; Z. Zhang","Sch. of Comput. Sci. & Technol., Harbin Inst. of Technol., Harbin, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","1","","355","358","To characterize Chinese search, this paper investigates a one-month user log from Sogou, a famous Chinese search engine. The query log analysis we perform falls into two categories: analysis of the query composition, and analysis of the query structure. Statistical results reveal that, in addition to Chinese character, users are accustomed to using the full-width and half-width characters and Japanese occasionally in the query. From the view of query structure, the simple query amounts to 81.6% of the total number, while complex queries accounts for 18.4%. Finally the differences between the Chinese search engine and the English one in the query formulation are discussed. The findings of this paper are beneficial to the study of information retrieval modeling, as well as the future log analysis of search engine.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.270","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362160","Sogoue;log;query composition;query structure;search engine","Computer science;Database languages;Information analysis;Information retrieval;Knowledge acquisition;Large-scale systems;Natural languages;Performance analysis;Search engines;Statistics","query formulation;query processing;search engines;statistical analysis","Chinese character;Chinese search engine;English search engine;Japanese;Sogou log;full-width character;half-width character;information retrieval modeling;query composition analysis;query formulation;query log analysis;query structure analysis","","0","","14","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Linking the Drugs and Pharmaceutical Databases","K. Wegrzyn-Wolska; G. Dziczkowski; L. Bougueroua","ESIGETEL, Fontainebleau-Avon, France","2009 Fifth International Conference on Next Generation Web Services Practices","20091228","2009","","","3","8","The quantity of biomedical publications is growing at an exponential rate. With such explosive growth of the content, it is more and more difficult to locate, retrieve and manage the resulting information. This is why text mining has become a necessity. The main goal of biomedical research is to put knowledge to practical use in the form of diagnoses, prevention, and treatment. It is important to pool the resources between the different individuals researching results. The objective of this paper is to discuss the variety of issues and challenges surrounding the perspectives regarding the use of Information Retrieval and Text Mining methods in biomedicine. The article will first look at the directions in biomedical Text Mining and then describe the work done for the BIAM project, the French on-line Medical Data Base.","","POD:978-0-7695-3821-1","10.1109/NWeSP.2009.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361615","Biomedicines Text Mining;Named Entity Recognition;Synonyms and Abbreviation Extraction","Content based retrieval;Content management;Databases;Drugs;Explosives;Information management;Information retrieval;Joining processes;Pharmaceuticals;Text mining","data mining;drugs;information retrieval;medical information systems","BIAM project;French on-line Medical Data Base;biomedical publications;biomedical research;drugs databases;exponential rate;information retrieval;pharmaceutical databases;text mining","","1","","26","","","9-11 Sept. 2009","","IEEE","IEEE Conference Publications"
"Ontology Based Query Expansion in Vertical Search Engine","L. Ma; L. Chen; Y. Gao; Y. Yang","Integrate Inf. Syst. Res. Center, China Acad. of Sci., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","2","","285","289","Queries to search engine on the Internet are usually short, and cannot provide enough information for effective retrievals. Researchers have developed query expansion to cope with the problem and proved its usefulness. But previous researches have mainly on the general search engine and do not give the semantic enough attention. In this paper, we introduced a novel algorithm especially for the vertical search engine, which makes full use of the character that knowledge in special domain can be described more availably and powerfully than that in the open domain. In the algorithm, we utilize the knowledge, formalized by ontology, to generate semantic diagraph for combinations of words in one query. And then according to the semantic distance between the vertexes in the diagraph, we selected the candidates to be added. Terms added into the initial query are obviously related in semantic with the initial one. And we experimentally show that it can improve the search result clearly.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359453","domain knowledge;ontology;query expasion;vertical search engine","Automation;Databases;Feedback;Fuzzy systems;Information retrieval;Information systems;Internet;Ontologies;Search engines;Thesauri","Internet;information retrieval;ontologies (artificial intelligence);search engines","Internet;diagraph;information retrievals;ontology based query expansion;semantic diagraph;vertical search engine","","0","","12","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Context Centric Approach for Semantic Image Annotation and Retrieval","N. Elahi; R. Karlsen; S. Akselsen","Dept. of Comput. Sci., Univ. of Tromso, Tromso, Norway","2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns","20091228","2009","","","665","668","In this preliminary research, we discuss techniques to improve the quality of image retrieval and image management with the help of context information over the Web. Our hypothesis is that leveraging the semantic annotated contextual metadata of the image would yield the relevant search results and facilitate building a consistent, unambiguous image knowledge base. Inferencing capability of semantic technology is very useful to deduce the new metadata from the existing metadata about images. We discuss the three different aspects of image context such as spatial, temporal and social context. Spatial and temporal context of the image can easily be gathered by taking advantage of modern digital camera technology. In order to acquire social contextual metadata, we benefit from social network sites.","","POD:978-1-4244-5166-1","10.1109/ComputationWorld.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358875","context-aware;image retrieval;semantic web;social networks","Computer science;Content based retrieval;Content management;Context-aware services;Digital cameras;Image retrieval;Information retrieval;Quality management;Semantic Web;Social network services","content-based retrieval;image retrieval;semantic Web;social networking (online)","content-based image retrieval;context centric approach;digital camera technology;image management;semantic Web;semantic image annotation;semantic image retrieval quality;semantic technology inferencing capability;social network sites;text-based image retrieval;unambiguous image knowledge base","","1","","21","","","15-20 Nov. 2009","","IEEE","IEEE Conference Publications"
"Conditional Models for Non-smooth Ranking Loss Functions","A. Dubey; J. Machchhar; C. Bhattacharyya; S. Chakrabarti","IBM Res., India","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","129","138","Learning to rank is an important area at the interface of machine learning, information retrieval and Web search. The central challenge in optimizing various measures of ranking loss is that the objectives tend to be non-convex and discontinuous. To make such functions amenable to gradient based optimization procedures one needs to design clever bounds. In recent years, boosting, neural networks, support vector machines, and many other techniques have been applied. However, there is little work on directly modeling a conditional probability Pr(y|x<sub>q</sub>) where y is a permutation of the documents to be ranked and x<sub>q</sub> represents their feature vectors with respect to a query q. A major reason is that the space of y is huge: n! if n documents must be ranked. We first propose an intuitive and appealing expected loss minimization objective, and give an efficient shortcut to evaluate it despite the huge space of ys. Unfortunately, the optimization is non-convex, so we propose a convex approximation. We give a new, efficient Monte Carlo sampling method to compute the objective and gradient of this approximation, which can then be used in a quasi-Newton optimizer like LBFGS. Extensive experiments with the widely-used LETOR dataset show large ranking accuracy improvements beyond recent and competitive algorithms.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360238","Conditional Models;Learning to Rank;Monte Carlo Sampling","Boosting;Design optimization;Information retrieval;Loss measurement;Machine learning;Monte Carlo methods;Neural networks;Optimization methods;Support vector machines;Web search","Monte Carlo methods;convex programming;information retrieval;learning (artificial intelligence);neural nets;support vector machines","LETOR dataset;Monte Carlo sampling method;Web search;boosting;conditional probability;convex approximation;information retrieval;machine learning;neural networks;non-convex optimization;nonsmooth ranking loss functions;quasi-Newton optimizer;support vector machines","","2","","20","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Improved Multi Label Classification in Hierarchical Taxonomies","K. Punera; S. Rajan","","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","388","393","Hierarchical taxonomies are used to organize and retrieve information in many domains, especially those dealing with large and rapidly growing amounts of information. In many of these domains data also tends to be multi-label in nature. In this paper, we consider the problem of automated text classification in these scenarios. We present a post-processing based approach that performs smoothing on the output of an underlying one-vs-all ensemble. In order to do this we formulate a Regularized Unimodal Regression problem and give an exact algorithm to solve it. We evaluate the performance of our approach on several real-world large-scale multi-label hierarchical taxonomies and demonstrate that our proposed method provides significant gains over other related approaches.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.110","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360436","","Availability;Conferences;Data mining;Information retrieval;Large-scale systems;Navigation;Performance gain;Smoothing methods;Taxonomy;Text categorization","classification;information retrieval;regression analysis;text analysis","automated text classification;hierarchical taxonomies;information retrieval;multi label classification;regularized unimodal regression","","1","","11","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Rapid Shape Retrieval Using Improved Graph Transduction","J. Chen; Y. Zhou; B. Wang; L. Luo; W. Liu","Dept. of Electron. & Inf. Eng., Huazhong Univ. of Sci. & Technol., Wuhan, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","In this paper, we focus on the problem of shape retrieval. A novel approach, called improved graph transduction, is proposed. As preceding graph transduction method, we regard the shape as a node in a graph and the similarity of shapes is represented by the edge of the graph. Then we learn a new distance measure between the query shape and the testing shapes. The main contribution of our work is to merge the most likely node with the query node during the learning process. The appending process helps us to mine the latent information in the propagation. The experimental results on the MPEG-7 data set show that comparing with the existing methods, our method can complete shape retrieval with similar correct rate in less time.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366255","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366255","","Convergence;Geology;Horses;Information retrieval;Iterative algorithms;Iterative methods;MPEG 7 Standard;Semisupervised learning;Shape measurement;Testing","edge detection;graph theory;image coding;image retrieval","MPEG-7;graph edge;improved graph transduction;query shape;rapid shape retrieval;testing shapes","","1","","12","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Mechanism Retrieval in Conceptual Design Using ART1 Neural Network","R. F. Bo; R. Q. Li","Key Lab. for AMT of Shanxi Province, North Univ. of China, Taiyuan, China","2009 Fifth International Conference on Natural Computation","20091228","2009","1","","195","199","Selecting appropriate mechanism types that meet design requirements is a critical problem often encountered in conceptual design of mechanical system. A novel approach to mechanism coding is presented at first, in which the features of motion function and function quality for mechanism can be expressed respectively with a list of binary vectors. A retrieval approach to mechanism type selection is then proposed using adaptive resonance theory (ART) neural network. Under this approach, sets of binary vectors representing all mechanisms are fed into an ART1 network to structure mechanism clusters and a proper number of reference mechanisms can be received after a binary vector representing design requirements is fed into the pre-grouped network. Compared with other retrieval system, by adjusting the value of vigilance parameter, the designer can obtain an optimal mechanism or several satisfactory mechanisms more easily in terms of his design intent using this approach.","2157-9555;21579555","POD:978-0-7695-3736-8","10.1109/ICNC.2009.425","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366446","","Computer networks;Design methodology;Information retrieval;Laboratories;Mechanical products;Mechanical systems;Neural networks;Product design;Resonance;Spatial databases","adaptive resonance theory;information retrieval;neural nets","ART1 neural network;adaptive resonance theory;binary vector representation;binary vectors;conceptual design;mechanical system;mechanism coding;mechanism function quality;mechanism retrieval;motion function;retrieval approach;satisfactory mechanisms","","0","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Detecting Tag Spam in Social Tagging Systems with Collaborative Knowledge","K. Liu; B. Fang; Y. Zhang","Res. Center of Comput. Network & Inf. Security Technol., Harbin Inst. of Technol., Harbin, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","7","","427","431","Social tagging systems allow collaborative users to annotate shared resources with tags. Since they rely on user contributed content, social tagging systems are vulnerable to spam annotations, which are generated by malicious users to mislead or confuse legitimate users. Thus, mechanisms for spam detection need to be developed to combat the flexible strategies of spammers for the success of social tagging systems. Since annotations are lack of relevant feature, the classical method of training classifier to detect spam is hard to implement. However, with their collaborative nature, knowledge on the tagging scheme do exists in the way numerous participants annotating resources with tags. In this paper, we propose a simple but remarkably effective approach for detecting tag spam in social tagging systems with collaborative knowledge. We harness the wisdom of crowds to discover the knowledge on what should be high quality annotations for resources. This knowledge is then used to tell spam posts from the legitimate ones. A distinct feature of our approach is that, it can be easily extended for user level spam detection and can do well in both levels. The proposed approach is evaluated on data set collected from real-world system. Experimental results show a convincing performance of proposed approach.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360046","collaborative knowledge;social tagging;tag spam","Advertising;Computer networks;Fuzzy systems;Information retrieval;Information security;International collaboration;Internet;Search engines;Tagging;Unsolicited electronic mail","data mining;groupware;information retrieval;security of data;social networking (online);unsolicited e-mail","collaborative knowledge;data set collection;knowledge discovery;social tagging systems;spam annotations;tag spam detection;user level spam detection","","7","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Improved Semantic Retrieval Based on Domain Ontology","D. h. Yuan; D. y. Liu; S. q. Shen; P. Yan","Coll. of Comput. Sci. & Technol., Jilin Univ., Changchun, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","1","","207","211","Semantic retrieval is a hot area of Web search technology constantly because of the growing information. This paper proposed a creative semantic retrieval method with Path Weight Semantic Distance (PWSD) algorithm which is improved from current model. Based on the domain ontology built by protege, PWSD considers both the hierarchy and the property restrictions of the concepts synthetically, and provides an accurate computation of semantic distance between conceptions. We have investigated the feasibilities, advantages and statistical significances from the comparison between our system and personalized categorization system (PCAT) and found that our system has high performances with 95% or higher statistical significance for short queries tasks.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.404","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358621","Semantic retrieval;domain ontology;p-value;semantic distance","Computer science;Educational institutions;Educational technology;Fuzzy systems;Information retrieval;Laboratories;Ontologies;Search engines;Taxonomy;Web search","Internet;information retrieval;ontologies (artificial intelligence);statistical analysis","domain ontology;semantic retrieval","","0","","5","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Unifying Archaeological Databases Using Triples","I. Battenfeld; I. Beckmann; J. Schultze; H. Türk","Lehrstuhl fur Software-Technol., Tech. Univ. Dortmund, Dortmund, Germany","2009 Fourth International Conference on Cooperation and Promotion of Information Resources in Science and Technology","20091228","2009","","","281","284","We describe the information technological challenges in the project ArcheoInf which aims at providing a unified access to heterogeneous archaeological databases. We consider the difficulties caused by legacy databases not designed for structured data retrieval and propose an ontology-based solution to this problem. In particular we present a process that migrates the data into an ontology-based triple store system, which can be queried with SPARQL. The problem of heterogeneous vocabularies is solved by a mapping of the respective datafields into an archaeology-specific thesaurus which is also kept in the triple store. Our approach is expanded by the possibility to integrate further SQL-databases into the ArcheoInf-system without migrating them into the triple store, provided they are based on a datamodel which is suitably compatible to the ontology we use.","","POD:978-0-7695-3898-3","10.1109/COINFO.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361890","archaeology;databases;ontology;semantic web","Cultural differences;Database systems;Information resources;Information retrieval;Ontologies;Semantic Web;Software libraries;Spatial databases;Thesauri;Vocabulary","SQL;archaeology;ontologies (artificial intelligence);relational databases;semantic Web","ArcheoInf system;SQL databases;archaeological databases;data retrieval;legacy databases;ontology-based triple store system","","0","","15","","","21-23 Nov. 2009","","IEEE","IEEE Conference Publications"
"RSED: a Novel Recommendation Based on Emotion Recognition Methods","Q. q. Liu; J. Zhu; T. Kong","Dept. of Electr. & Inf. Eng., Daqing Pet. Inst., Daqing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","With the growth of e-commerce, the development of recommendation systems is helpful for users to select desirable products from all kinds of them. The existing e-commerce recommendation approaches are based on a user's preference on music. However, sometimes, it might better meet users' requirement to recommend products according to emotions. In this paper, we propose a novel framework model for emotion based e-commerce recommendation systems. The core of the recommendation framework is the construction of the product vs customer emotion model by two-dimensional overlap spaces, which plays an important role in conveying emotions in products. We investigate the product feature extraction and propose some related matching algorithms for the construction of product vs customer emotion model. Then the system model, data structures and so on are given in our paper. At last, experimental and analytical result shows the proposed emotion-based music recommendation achieves higher accuracy and faster retrieval speed.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5364111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364111","","Collaboration;Data structures;Emotion recognition;Feature extraction;Filtering;Music information retrieval;Petroleum;Recommender systems;System testing;Well logging","data structures;electronic commerce;emotion recognition;feature extraction;information retrieval;music;recommender systems","RSED;customer emotion model;data structure;e-commerce recommendation approach;emotion recognition methods;emotion-based music recommendation system;matching algorithms;product feature extraction;system model;two-dimensional overlap spaces","","0","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Hybrid Web-Based Measure for Computing Semantic Relatedness Between Words","G. Spanakis; G. Siolas; A. Stafylopatis","Intell. Syst. Lab., Nat. Tech. Univ. of Athens, Athens, Greece","2009 21st IEEE International Conference on Tools with Artificial Intelligence","20091228","2009","","","441","448","In this paper, we build a hybrid Web-based metric for computing semantic relatedness between words. The method exploits page counts, titles, snippets and URLs returned by a Web search engine. Our technique uses traditional information retrieval methods and is enhanced by page-count-based similarity scores which are integrated with automatically extracted lexico-synantic patterns from titles, snippets and URLs for all kinds of semantically related words provided by WordNet (synonyms, hypernyms, meronyms, antonyms). A support vector machine is used to solve the arising regression problem of word relatedness and the proposed method is evaluated on standard benchmark datasets. The method achieves an overall correlation of 0.88, which is the highest among other metrics up to date.","1082-3409;10823409","POD:978-1-4244-5619-2","10.1109/ICTAI.2009.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363726","Web mining;semantic relatedness","Artificial intelligence;Content based retrieval;Data mining;Databases;Hybrid intelligent systems;Information retrieval;Laboratories;Search engines;Uniform resource locators;Web search","information retrieval;regression analysis;search engines;semantic Web;support vector machines","Web search engine;WordNet;hybrid Web-based measure;information retrieval methods;lexico-synantic pattern extraction;page-count-based similarity scores;regression analysis;support vector machine","","2","","25","","","2-4 Nov. 2009","","IEEE","IEEE Conference Publications"
"Retrieval of Three-Dimensional Wind Field of Typhoon by SVVP Method","N. Li; M. Wei; X. Pei; L. Li","Sch. of Atmos. Phys., Nanjing Univ. of Inf. Sci. & Technol., Nanjing, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Typhoons landing in China have caused severe calamity and loss in past years. Therefore, disaster prevention and reduction, and life and possession protection are very important and to be imperative under the circumstances. Many Doppler radar covering extensive areas are erected along the coast of Southeastern China, and they are crucial for monitoring and warning of severe weather. The radial velocity information received by Doppler radar can be recovered to real wind field by some retrieval method, which is important for the research on wind field structure and development and evolvement of typhoons. Velocity volume processing (VVP) is one of the mainly used methods for wind field retrieval. However, VVP method is disturbed by ill-conditioned matrix in calculation, leading to great error and thus its application is too much limited. Step velocity volume processing (SVVP) is an improved VVP method. It efficiently overcomes the ill-conditioned matrix problem in VVP method, and can acquire exact horizontal wind, horizontal shear, vertical wind, etc. In this paper, it is attempted to retrieve the three-dimensional wind field of typhoon by SVVP method. According to the retrieval experiments on simulated and real typhoon radial velocity data, we focus on the retrieval validity and feasibility of the vertical wind.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365336","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365336","","Doppler radar;Educational technology;Information retrieval;Information science;Meteorology;Remote sensing;Sea surface;Tropical cyclones;Typhoons;Wind speed","Doppler radar;geophysics computing;information retrieval;storms","Doppler radar;SVVP method;disaster prevention;ill-conditioned matrix problem;radial velocity information;retrieval method;step velocity volume processing;three-dimensional typhoon wind field","","0","","7","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Personalization Mechanisms for Content Indexing, Search, Retrieval and Presentation in a Multimedia Search Engine","O. I. Markaki; D. E. Charilas","Dept. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece","2009 16th International Conference on Systems, Signals and Image Processing","20091228","2009","","","1","6","Interest on multimedia content analysis, archival, retrieval and delivery is steadily increasing. This interest emanates from the digital media explosion that we are witnessing. Among others, the growth of multimedia content is compounding the need for more effective methods for searching such information. The automated web search engines that are currently used rely only on text descriptions and as a result provide matches of poor quality in case of multimedia content. On the other hand, search engines that utilize low-level descriptors to support content-based retrieval focus on algorithmic approaches and not on the provision of services oriented at efficiently covering the user's needs. The scope of this paper is to present a personalized web-based multimedia search engine implemented in the Java programming language. The proposed system combines the characteristics of the current search engines as well as new innovative features which guarantee a) reduced response time b) improved search results c) adaptation to each user's preferences d) easy handling of multimedia content e) interactive multimedia searching f) support of context-based user groups. The analytic description of the system's mechanisms and features renders clear how the proposed search engine adapts its functionality to each user's individuality.","2157-8672;21578672","POD:978-1-4244-4530-1","10.1109/IWSSIP.2009.5367798","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5367798","","Content based retrieval;Electronic mail;Feedback;Humans;Image retrieval;Indexing;Information retrieval;Multimedia databases;Multimedia systems;Search engines","Java;content-based retrieval;indexing;multimedia computing;search engines;vocabulary","Java programming language;algorithmic approaches;automated web search engines;content based retrieval;content indexing;context based user groups;digital media explosion;low level descriptors;multimedia content analysis;multimedia content archival;multimedia content delivery;multimedia content retrieval;multimedia search engine;personalization mechanisms;reduced response time;text descriptions;user preference adaptation","","0","","14","","","18-20 June 2009","","IEEE","IEEE Conference Publications"
"A Study of Language Model for Image Retrieval","B. Geng; L. Yang; C. Xu","Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","158","163","Recently, various language model approaches have been proposed in the information retrieval realm, with their promising performances in general document and Web page retrieval applications. Based on these achievements, in this paper, we investigate and discuss whether language model approaches can be adapted to content based image retrieval (CBIR), based on the Â¿bag of visual wordsÂ¿ image representation. A critical element of language model estimation is smoothing, which adjusts the maximum likelihood estimation to overcome the data sparseness problem. Therefore, we perform extensive studies over different smoothing methods, strategies, and parameters, by showing their impacts to the retrieval performances. Experiments are performed over two popular image retrieval databases, together with some insightful conclusions to facilitate the adaptation of language model approaches to CBIR.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360512","content based image retrieval;language model","Adaptation model;Asia;Content based retrieval;Image databases;Image representation;Image retrieval;Information retrieval;Maximum likelihood estimation;Smoothing methods;Visual databases","content-based retrieval;image representation;image retrieval;visual databases","Web page retrieval applications;content based image retrieval;data sparseness problem;image representation;image retrieval databases;language model estimation;maximum likelihood estimation","","6","1","31","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Application of Query Expansion Technology in Audit Judgment","Y. Wang; X. Ge","Sch. of Bus. & Manage., Anyang Normal Univ., Anyang, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Audit judgments run through the whole audit process, and play a vital role in audit. But because of the development of the audit decision support system, the traditional process of the audit judgment is no longer adapted to the computer audit environment. In this paper, by study of the available Chinese query expansion technology, the paper proposes to improve the performance of Chinese information retrieval systems by expanding queries using automatically acquired related term groups, and uses it into the audit judgment and raises an overall design idea for the audit judgment for the computer audit environment. The paper designs a specific flowchart for the audit of an electrical company's main business income.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5365992","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365992","","Application software;Computer applications;Data mining;Decision support systems;Finance;Financial management;Flowcharts;Information retrieval;Technology management;Terminology","auditing;decision support systems;natural languages;query processing","Chinese information retrieval system;Chinese query expansion technology;audit decision support system;audit judgment;computer audit environment","","0","","6","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Community Discovery of P2P Resources Based on Bipartite Graph","J. Li; Z. r. Zhou","Coll. of Comput. & Inf. Sci., Southwest Univ., Chongqing, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","Finding related resources is important for assisting resource retrieval and recommendation in the P2P network. This paper proposes a method for discovering such clusters of related resources, which are called resource communities. Graph mining approach is applicable here. Discovering communities is based on bipartite graph which is composed of resources and keywords. The data is extracted from the analysis of users' search and download behavior. Experiment shows that this method is effective in discovering resource communities and improving the efficiency of resource retrieval.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365800","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365800","","Bipartite graph;Computer networks;Costs;Data mining;Educational institutions;Humans;Information retrieval;Information science;Optimization methods;Peer to peer computing","data mining;graph theory;information retrieval;peer-to-peer computing","P2P resources;bipartite graph;community discovery;graph mining approach;resource communities;resource recommendation;resource retrieval","","0","","4","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
"Convex Non-negative Matrix Factorization in the Wild","C. Thurau; K. Kersting; C. Bauckhage","Fraunhofer IAIS, St. Augustin, Germany","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","523","532","Non-negative matrix factorization (NMF) has recently received a lot of attention in data mining, information retrieval, and computer vision. It factorizes a non-negative input matrix V into two non-negative matrix factors V = WH such that W describes ""clusters"" of the datasets. Analyzing genotypes, social networks, or images, it can be beneficial to ensure V to contain meaningful ""cluster centroids"", i.e., to restrict W to be convex combinations of data points. But how can we run this convex NMF in the wild, i.e., given millions of data points? Triggered by the simple observation that each data point is a convex combination of vertices of the data convex hull, we propose to restrict W further to be vertices of the convex hull. The benefits of this convex-hull NMF approach are twofold. First, the expected size of the convex hull of, for example, n random Gaussian points in the plane is Â¿(Â¿log n), i.e., the candidate set typically grows much slower than the data set. Second, distance preserving low-dimensional embeddings allow one to compute candidate vertices efficiently. Our extensive experimental evaluation shows that convex-hull NMF compares favorably to convex NMF for large data sets both in terms of speed and reconstruction quality. Moreover, we show that our method can easily be applied to large-scale, real-world data sets, in our case consisting of 1.6 million images respectively 150 million votes on World of Warcraft Â® guilds.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360278","archetypal analysis;data handling;data mining;matrix decomposition;non negative matrix factorization;social network analysis","Computer vision;Data analysis;Data mining;Embedded computing;Image analysis;Image reconstruction;Information retrieval;Large-scale systems;Social network services;Voting","computer vision;data mining;information retrieval;matrix decomposition","cluster centroids;computer vision;convex hull non-negative matrix factorization;data convex hull;data mining;information retrieval;random Gaussian points","","17","","22","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"A Probability Based Approach for Processing Dimension Missing Data","Y. Cheng; T. Zhang","Dept. of Biomed. Eng., Tsinghua Univ., Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Processing missing value is one of the most important task in data mining. A great many applications, such as social commercial record, biological systems and remote sensing network, in which not only data values from particular features but even data dimension information may also be missing. Such missing values are known as dimension missing values-standard operation over these data may result in unrepresentable or uncertain problems. To tackle this problem of dealing with dimension missing data, in this paper, we first propose a probabilistic model to managing such data. Then, instead of enumerating all possible cases to recover the missed dimensions, we develop an effective and efficient bound confidence approach to speed up the retrieval process. A concrete evaluation using real data sets is reported, which shows that our method is effective and efficient on dimension incomplete data.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5364328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364328","","Automation;Biological systems;Biomedical engineering;Cleaning;Concrete;Data analysis;Data mining;Information retrieval;Remote sensing;Testing","data mining;information retrieval;probability","bound confidence approach;data mining;dimension missing data processing;missing value processing;probability based approach;retrieval process","","0","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"On Estimating Semantic Loss in Peer Data Management Systems","Y. Delveroudis; P. V. Lekeas; D. Souliou","ECE, NTUA, Greece","2009 First International Conference on Advances in P2P Systems","20091228","2009","","","51","53","Traditional data integration techniques have focused on centralized components to allow transparent querying of multiple heterogeneous databases. This requirement on global/mediated schemas impedes the deployment and success of such systems in modern highly dynamic and scalable computing environments. Peer Data Management Systems (PDMS) offer a truly decentralized solution by utilizing compositions of local pair-wise mappings to propagate queries through the network. Current PDMS proposals have been ignorant of the fact that query reformulation could result in semantic degradation due to the inherent heterogeneity of the nodes. A critical issue to effectively address this problem is the existence of a technique that computes the query difference, which results from this reformulation. In this work, we propose an algorithm that estimates the semantic loss of the rewritten queries in a generic way, based on the notion of containment mapping. This information can then be used as the basis for extending appropriately the schema mappings and improving the quality of the retrieved answers.","","POD:978-1-4244-5084-8","10.1109/AP2PS.2009.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359121","PDMS;Peer Data Management;Semantic Loss;Web and Databases","Computer network management;Conference management;Databases;Degradation;Impedance;Information retrieval;Peer to peer computing;Proposals;Sufficient conditions;Testing","data integrity;distributed databases;peer-to-peer computing;query formulation;query processing","data integration techniques;information retrieval;local pair-wise mappings;multiple heterogeneous databases;peer data management systems;queries propagation;query reformulation;rewritten queries;semantic degradation;semantic loss estimation;transparent querying","","0","","5","","","11-16 Oct. 2009","","IEEE","IEEE Conference Publications"
"Self-organized hierarchical k-means file clustering algorithm based on P2P sharing directories and its application","K. Lei; L. Han; W. Chen; H. Yuan; T. Sun","Center for Internet Research and Engineering (CIRE), Shenzhen Graduate School, Peking University, Shenzhen City, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","402","405","In order to improve the recall of search results and calculate file relevancy in P2P sharing systems, a file clustering algorithm using self-organized k-means method was proposed, which is based on the hierarchical structure of file sharing directories and file names' implication of classification. With uploaded file path information built into the indexes, a tree-structure like vector space model was designed. After analyzing the advantages and shortcomings of the traditional k-means method, we implemented a revised self-organized k-means algorithm. This algorithm can easily calculate the distances among file categories and file relevancies in a same category by adjusting two thresholds called as Â¿combined factorÂ¿ and Â¿correlation factorÂ¿. From the experiment and evaluation results, this model indicated that more target files can be found and improved recall rate to 83.54% and precision of the information retrieval to 85%.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357814","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357814","P2P Search;VSM;file clustering;self-organized K-means","Algorithm design and analysis;Cities and towns;Clustering algorithms;Content based retrieval;File servers;Information retrieval;Internet;Peer to peer computing;Sun;Topology","indexing;pattern classification;pattern clustering;peer-to-peer computing;query formulation;tree data structures","P2P sharing directories;classification implication;combined factor;correlation factor;file names;file relevancy;indexes;information retrieval;search result;selforganized hierarchical k-means file clustering algorithm;tree-structure like vector space model;uploaded file path information","","0","","7","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"A SWRL Rules Parser Algorithm Based on the Topic Semantic Comparability and Ant Colony Algorithm","N. Zong; Y. Zheng; Z. Wang","Chinese Acad. of Agric. Sci., Beijing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","2","","161","167","As the Web Ontology Language (OWL) and Semantic Web Rule Language SWRL is promoted as one of the semantic reasoning standards, the parser algorithm for the SWRL retrieval has been studied by many researchers. This paper introduces a retrieve algorithm which integrated both the Topic Semantic Comparability (TSC) and Ant Colony Algorithm (ACA) to select the proper rules for the parser according to the input The paper analyzed the experiment and developed ideas for the direction of future research.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358793","Ant Colony Algorithm;Modeling And Data Analysis;Parser Algorithm;SWRL;Semantic Comparability;Semantic Reasoning;Theory of Algorithms","Computational modeling;Distributed computing;Feedback;Inference algorithms;Information retrieval;Internet;Natural languages;OWL;Ontologies;Semantic Web","grammars;information retrieval;knowledge representation languages;semantic Web","SWRL rules parser algorithm;Web ontology language;ant colony algorithm;retrieve algorithm;semantic Web rule language;semantic comparability;semantic reasoning standards;topic semantic comparability","","0","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Study on Efficiency of Full-Text Retrieval Based on Lucene","S. Li; X. Lv; F. Ling; S. Shi","Chinese Inf. Process. Res. Center, Beijing Inf. Sci. & Technol. Univ., Beijing, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","Through researching and analyzing the structure of lucene package, we have developed a full-text information retrieval system on the basis of lucene full-text retrieval. After mastering index structure and principle, we increase the size of index buffer in memory and decrease the frequency of writing index to disk by a specific algorithm. What is more, we optimize index by merging it in memory and on disk. As a result, the efficiency of creating index for 70000 documents has been improved by 55.1% at the best circumstances, and that of information retrieval for 70000 documents has been improved by 15.6% at the best circumstances.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5363389","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363389","","Access protocols;Indexing;Information analysis;Information processing;Information retrieval;Information science;Information technology;Packaging;Search engines;Writing","indexing;information retrieval;text analysis","full-text information retrieval system;index buffer;lucene full-text retrieval;lucene package;mastering index structure","","2","","7","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"An Automat for the Semantic Processing of Structured Information","A. Leiva-Mederos; J. A. Senso; S. Domínguez-Velasco; P. Hípola","Univ. Central "Marta Abreu" de Las Villas, Santa Clara, Cuba","2009 Ninth International Conference on Intelligent Systems Design and Applications","20091228","2009","","","85","89","Using the database of the PuertoTerm project, an indexing system based on the cognitive model of Brigitte Enders was built. By analyzing the cognitive strategies of three abstractors, we built an automat that serves to simulate human indexing processes. The automat allows the texts integrated in the system to be assessed, evaluated and grouped by means of the bipartite spectral graph partitioning algorithm, which also permits visualization of the terms and the documents. The system features an ontology and a database to enhance its operativity. As a result of the application, we achieved better rates of exhaustivity in the indexing of documents, as well as greater precision and retrieval of information, with high levels of efficiency.","2164-7143;21647143","POD:978-1-4244-4735-0","10.1109/ISDA.2009.120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364629","","Analytical models;Automata;Deductive databases;Dictionaries;Humans;Indexing;Information retrieval;Intelligent structures;Intelligent systems;Ontologies","graph theory;indexing;information retrieval;ontologies (artificial intelligence)","Brigitte Enders cognitive model;PuertoTerm project;bipartite spectral graph partitioning algorithm;human indexing processes;indexing system;information retrieval;semantic processing;structured information","","1","","10","","","Nov. 30 2009-Dec. 2 2009","","IEEE","IEEE Conference Publications"
"Semantic Annotation for CSSCI Academic Resources Based on Ontology","H. Wang; X. n. Su; F. Liu","Inf. Manage. Dept., Nanjing Univ., Nanjing, China","2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery","20091228","2009","2","","374","385","The paper emphatically elaborates the process and method of realizing semantic annotation for domain data based on the CSSCI conceptualization which constructed before. The essence is that extracting the academic resource instances from CSSCI data under the guidance of the object-oriented knowledge organization model, setting values for properties of the instances by methods of directly extracting based on relational data model, directly statistic calculating assisted by TF-IDF algorithm, synthesis algorithm combined criterion weighting with formal concept analysis and so on, discovering and analyzing semantic association between instances, so as to integrate all CSSCI academic resources into a huge knowledge map based on ontology and to support the knowledge retrieval and citation analysis.","","POD:978-0-7695-3735-1","10.1109/FSKD.2009.338","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359474","CSSCI Academic Resources;Criterion Weighting;Formal Concept Analysis;Knowledge Description;Ontology;Probability Model;Semantic Annotation","Algorithm design and analysis;Citation analysis;Data mining;Databases;Information management;Information retrieval;Large-scale systems;Object oriented modeling;Ontologies;Technological innovation","citation analysis;information retrieval;object-oriented methods;ontologies (artificial intelligence)","CSSCI academic resources;TF-IDF algorithm;citation analysis;formal concept analysis;knowledge retrieval;object-oriented knowledge organization model;ontology;relational data model;semantic annotation;synthesis algorithm","","1","","10","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Introduction to Retrieval Knowledge Using Intelligent Education Software","Q. Ge; X. Peng; M. chen","Eng. Center for Educ. Inf. Technol., Huazhong Normal Univ., Wuhan, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","1","","148","151","The intelligent education software have brought much excitement into the computer-based teaching community, become more important in many mathematics curricula, take the super sketch pad (SSP) for example, which can help many students to learn new knowledge effectively, to retrieval knowledge easily. Firstly, this paper discusses the knowledge of dynamic geometry, introduces the free version of SSP in Chinese. Secondly, it emphasizes on retrieval new knowledge by geometric invariant, and automatic reasoning using SSP. Finally, it shows applications of the intelligent education software in mathematics teaching.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.159","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362241","automatic reasoning;dynamic geometry;intelligent education software;knowledge retrieval","Application software;Computer science education;Geometry;Information retrieval;Integral equations;Knowledge acquisition;Knowledge engineering;Mathematics;Polynomials;Space power stations","computer aided instruction;information retrieval;knowledge engineering;planning (artificial intelligence)","automatic reasoning;computer-based teaching;geometric invariant;intelligent education software;knowledge retrieval;mathematics curricula;super sketch pad","","0","","7","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"Ranking the Answers for Autonomous Web Database Fuzzy Queries","J. Zhang; X. Li; F. Li","Electron. & Inf. Eng. Coll., Liaoning Univ. of Technol., Jinzhou, China","2009 International Conference on Information Engineering and Computer Science","20091228","2009","","","1","4","An important issue arising from Web databases fuzzy query is how to rank the answers from data sources, this paper investigates the problem of ranking the answers by taking advantage of the user's needs and preferences. Firstly, based on fuzzy set theory, a satisfaction degree ranking method, which ranks the answer according to the tuple's satisfaction degree to the fuzzy query, is presented. Next, for the tuples with the same satisfaction degree in the answer, the adapted probabilistic models from Information Retrieval are applied, which leverages data and workload statistics, to derive the strengths of correlations between specified and unspecified attribute values in the query, consequently the tuple's relevance degree to the user's preferences can be obtained and used for distinguishing these tuples. Finally, the results of preliminary experiments, which demonstrate the efficiency as well as the quality of the ranking algorithm, are presented.","2156-7379;21567379","POD:978-1-4244-4994-1","10.1109/ICIECS.2009.5366087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5366087","","Cities and towns;Data engineering;Database languages;Educational institutions;Feedback;Fuzzy set theory;Fuzzy sets;Information retrieval;Relational databases;Statistics","Internet;fuzzy set theory;probability;query processing","autonomous Web database fuzzy queries;fuzzy set theory;information retrieval;probabilistic model;satisfaction degree ranking;tuple relevance degree;tuple satisfaction degree;workload statistics","","0","","12","","","19-20 Dec. 2009","","IEEE","IEEE Conference Publications"
"Probabilistic Similarity Query on Dimension Incomplete Data","W. Cheng; X. Jin; J. T. Sun","Sch. of Software, Tsinghua Univ., Beijing, China","2009 Ninth IEEE International Conference on Data Mining","20091228","2009","","","81","90","Retrieving similar data has drawn many research efforts in the literature due to its importance in data mining, database and information retrieval. This problem is challenging when the data is incomplete. In previous research, data incompleteness refers to the fact that data values for some dimensions are unknown. However, in many practical applications (e.g., data collection by sensor network under bad environment), not only data values but even data dimension information may also be missing, which will make most similarity query algorithms infeasible. In this work, we propose the novel similarity query problem on dimension incomplete data and adopt a probabilistic framework to model this problem. For this problem, users can give a distance threshold and a probability threshold to specify their retrieval requirements. The distance threshold is used to specify the allowed distance between query and data objects and the probability threshold is used to require that the retrieval results satisfy the distance condition at least with the given probability. Instead of enumerating all possible cases to recover the missed dimensions, we propose an efficient approach to speed up the retrieval process by leveraging the inherent relations between query and dimension incomplete data objects. During the query process, we estimate the lower/upper bounds of the probability that the query is satisfied by a given data object, and utilize these bounds to filter irrelevant data objects efficiently. Furthermore, a probability triangle inequality is proposed to further speed up query processing. According to our experiments on real data sets, the proposed similarity query method is verified to be effective and efficient on dimension incomplete data.","1550-4786;15504786","POD:978-1-4244-5242-2","10.1109/ICDM.2009.72","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360233","","Asia;Costs;Data mining;Databases;Filters;Information retrieval;Multidimensional systems;Query processing;Sun;Upper bound","data mining;query processing","data collection;data mining;data retrieval;dimension incomplete data;information retrieval;probabilistic similarity query;query processing","","0","","23","","","6-9 Dec. 2009","","IEEE","IEEE Conference Publications"
"Kernel- based Chinese recognition with ontology","Pang Shuxia; Li Rui; Yuan Zhanting; Zhang Qiuyu","School of Computer and Communication, Lanzhou University of Technology, China","2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","20091228","2009","1","","443","446","Since the Chinese Websites have increased in the explosive Internet era, making efficient information retrieval systems has become one of the major endeavors, especially in fields of Chinese recognition. In this paper, the authors study the integration of subsequence kernel function based on ontology. Using the vector space model (VSM) to create subsequence kernels, the kernel methodology described here not only overcomes the VSM ignoring any semantic relation between words, but also results both in functional similarity and in sequence/words similarity by gap-weighted subsequences kernels, and the most important is that semantic character is also taken into account, which is very useful for Chinese recognition on Internet. Experiments show that the method has more exact retrieval results, and its cost is under the accepted tolerance.","","POD:978-1-4244-4754-1","10.1109/ICICISYS.2009.5357807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5357807","chinese recognition;kernel;ontology","Character recognition;Costs;Data mining;Explosives;Humans;Information retrieval;Internet;Kernel;Ontologies;Text recognition","Internet;Web sites;character recognition;information retrieval systems;natural language processing;ontologies (artificial intelligence)","Chinese Web sites;Internet;functional similarity;gap-weighted subsequences kernels;information retrieval systems;kernel-based Chinese character recognition;ontology;sequence similarity;subsequence kernel function;vector space model;words similarity","","0","","17","","","20-22 Nov. 2009","","IEEE","IEEE Conference Publications"
"Extracting Event Temporal Information Based on Web","B. Yuan; Q. Chen; X. Wang; L. Han","Comput. Sci. & Technol. Dept., Harbin Inst. of Technol., Shenzhen, China","2009 Second International Symposium on Knowledge Acquisition and Modeling","20091228","2009","1","","346","350","Temporal information is an important characteristic of event. It can be used in information retrieval process to organize the returned result. In Chinese, the presentations of time expression are very complex, which make it difficult to both accurately recognize a time expression and precisely connecting it with a given event in a Web page that contains multiple events. To address these problems, this paper presents an innovative event time extraction model. Rather than just rely on local context within a Web page or a text, this model applies global context provided by all the Web pages that had been automatically judged as related with a given event. Our experiment results based on the evaluation criterions show the feasibility of the provided model.","","POD:978-0-7695-3888-4","10.1109/KAM.2009.134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362158","","Calendars;Computer science;Data mining;Information retrieval;Joining processes;Knowledge acquisition;Machine learning;Natural languages;Ontologies;Web pages","Internet;information retrieval;natural language processing","Web page;event temporal information extraction;information retrieval process;innovative event time extraction model;natural language processing","","1","1","13","","","Nov. 30 2009-Dec. 1 2009","","IEEE","IEEE Conference Publications"
"A Data Mining Method to Extract and Rank Papers Describing Coexpression Predicates Semantically","C. Zhang; R. Tiwari; W. B. Chen","Dept. of Comput. & Inf. Sci., Univ. of Alabama at Birmingham, Birmingham, AL, USA","2009 IEEE International Conference on Data Mining Workshops","20091228","2009","","","483","488","Information management and extraction in the field of biomedical research has become a requirement with the rapid increase in the amount of data being published in this area. In this paper, a graphical model, Conditional Random Fields has been used to extract a particular gene-gene relationship called Â¿coexpressionÂ¿ from the existing literature. First, a Conditional Random Fields based model has been trained and tested on full-length papers downloaded from PubMed, to label the predicates that talk about coexpression of genes. Proper local and contextual text features at both word and sentence levels are proposed and extracted during the pre-processing step. The classification performance of the model trained based on the proposed features has been compared with the that of Support Vector Machines, Nearest Neighbor with generalization, and Neural Networks algorithms, and seen to outperform them all. In our second experiment, the proposed ranking scheme, which is based on classification results, is applied to the ranked lists of papers returned by PubMed and Google, respectively. The comparison of our ranked results to that of PubMed and Google demonstrates that our proposed ranking scheme performs better than both in distinguishing a positive paper from a negative paper. In conclusion, this paper describes a specialized classification and ranking framework that can retrieve papers that really talk about coexpression between and among genes based on mining of semantics and not just lexical search.","2375-9232;23759232","POD:978-1-4244-5384-9","10.1109/ICDMW.2009.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5360454","","Data mining;Graphical models;Hidden Markov models;Information retrieval;Machine learning;Nearest neighbor searches;Neural networks;Support vector machine classification;Support vector machines;Text mining","data mining;information management;information retrieval;medical computing;neural nets;pattern recognition;support vector machines","biomedical research;coexpression predicates;conditional random fields;data mining;gene-gene relationship;graphical model;information extraction;information management;nearest neighbor;neural networks;support vector machines","","0","","14","","","6-6 Dec. 2009","","IEEE","IEEE Conference Publications"
"Wood Image Retrieval Using SIFT Descriptor","S. Huang; C. Cai; Y. Zhang","Coll. of Inf. Eng., Northwest A&F Univ., Xi'an, China","2009 International Conference on Computational Intelligence and Software Engineering","20091228","2009","","","1","4","In this paper, we propose a new representation and matching scheme for wood image retrieval using scale invariant feature transformation (SIFT). We extract SIFT feature points in scale space and perform matching based on the texture information around the feature points using SIFT feature operator. This scheme can be appended to most existing wood image retrieval systems and improve their retrieval accuracy and efficiency. Experimental results demonstrate that the performance of this scheme is efficient and stable enough for wood image retrieval technique.","","CD-ROM:978-1-4244-4507-3","10.1109/CISE.2009.5365099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365099","","Computer aided instruction;Content based retrieval;Educational institutions;Feature extraction;Image databases;Image retrieval;Information retrieval;Object recognition;Production;Spatial databases","feature extraction;image matching;image representation;image retrieval","SIFT descriptor;feature point extraction;image matching;image representation;scale invariant feature transformation;wood image retrieval systems","","1","","12","","","11-13 Dec. 2009","","IEEE","IEEE Conference Publications"
