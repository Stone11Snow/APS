"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4378681,4379597,4381119,4379750,4379510,4380525,4378726,4378682,4378737,4378923,4378756,4379511,4378916,4380238,4379179,4382797,4382794,4380745,4381158,4382197,4378714,4378919,4381532,4379434,4381775,4381120,4380068,4379134,4382214,4379399,4379512,4382748,4379595,4379591,4379264,4379131,4379403,4378677,4379551,4379601,4382779,4382191,4156619,4375740,4376032,4375605,4344414,4377084,4375597,4374466,4376679,4375079,4377050,4344731,4376425,4376984,4377107,4156617,4375222,4375628,4377098,4374392,4156575,4376995,4377031,4344613,4344351,4377052,4376531,4374475,4377023,4375990,4344220,4374254,4344244,4375855,4370843,4371257,4371427,4371271,4370725,4368056,4362903,4371376,4370394,4370652,4365413,4365843,4365425,4371173,4367773,4370663,4370407,4370734,4368067,4368063,4370850,4371021,4368070,4365456",2017/05/04 21:16:06
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"DB-GNG: A constructive Self-Organizing Map based on densilty","A. Ocsa; C. Bedregal; E. Guadros-Vargas","San Agustin National University, Av. Independencia Arequipa Peru. email: aocsa@ieee.org","2007 International Joint Conference on Neural Networks","20071029","2007","","","1953","1958","Nowadays applications require efficient and fast techniques due to the growing volume of data and its increasing complexity. Recent studies promote the use of access methods (AMs) with self-organizing maps (SOMs) for a faster similarity information retrieval. This paper proposes a new constructive SOM based on density, which is also useful for clustering. Our algorithm creates new units based on density of data, producing a better representation of the data space with a less computational cost for a comparable accuracy. It also uses AMs to reduce considerably the number of distance calculations during the training process, outperforming existing constructive SOMs by as much as 89%.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371257","","Clustering algorithms;Computational efficiency;Costs;Information retrieval;Management training;Multimedia databases;Network topology;Neural networks;Self organizing feature maps;Video compression","data structures;information retrieval;pattern clustering;self-organising feature maps;very large databases","DB-GNG constructive self-organizing map;access methods;data density;data representation;density based growing neural gas;information retrieval;large database clustering","","3","","16","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"A Neural Network Approach for Bridging the Semantic Gap in Texture Image Retrieval","Q. Li; Z. Shi; S. Luo","School of Computer and Information Technology, Beijing Jiaotong University, 100044, Beijing, China. phone: 8610-51688603; email: liqy@bjtu.edu.cn","2007 International Joint Conference on Neural Networks","20071029","2007","","","581","585","One of the big challenges faced by content-based image retrieval (CBIR) is the 'semantic gap' between the visual features and the richness of human semantics for image content. We put forward a neural network approach to extract the image fuzzy semantics ground on linguistic expression based image description framework (LEBID). We utilize the linguistic variable to depict the texture semantics according to Tamura texture model, so we can describe the image in linguistic expression such as coarse, very line-like. Moreover, we use feedforward neural network (NN) to model the vagueness of human visual perception and to extract the fuzzy semantic feature. Our experiments demonstrate that NN outperforms other method such as genetic algorithm on the complexity of model, and it also achieves good retrieval performance.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371021","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371021","","Content based retrieval;Face;Fuzzy neural networks;Genetic programming;Humans;Image retrieval;Information retrieval;Information technology;Machine learning;Neural networks","content-based retrieval;feedforward neural nets;fuzzy set theory;image retrieval;image texture","Tamura texture model;content-based image retrieval;feedforward neural network;fuzzy semantic feature;human semantics;human visual perception;image content;image description framework;image fuzzy semantics;linguistic expression;semantic gap;texture image retrieval;texture semantics;visual features","","1","","13","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"3D Model Retrieval Based on V System Rotation Invariant Moments","Z. Li; X. Men; Y. Liu; H. Li","China University of Petroleum, China; Chinese Academy of Science, China; University of North Carolina at Charlotte, USA","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","2","","565","569","This paper proposes a novel methodology based on V-system polynomials for content-based search and retrieval of 3D objects. The V-system is composed by piecewise polynomials, and is capable of exactly describing the geometric information expressed by the popularly and widely used spline curves and surface. We define rotation invariant moments-v-system moment by combining V-system polynomials with spherical harmonics. After preprocessing for translation and scale invariance, the spherical extension is used as input for V-system moments and the values of obtained coefficients are considered as components of the feature vector. We evaluate on the Princeton Shape Benchmark, the proposed descriptors regarding computational aspects and shape retrieval performance. The-performance of the proposed method is compared to some previous approaches by means of precision/recall tests. Generally, results show that the new approach introduces improvements in the SD model retrieval process.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344414","","Computer science;Content based retrieval;Feature extraction;Image retrieval;Information retrieval;Noise robustness;Petroleum;Polynomials;Shape;Solid modeling","computer vision;content-based retrieval;image retrieval","3D model retrieval;V system rotation invariant moments;content-based retrieval;content-based search;spherical harmonics;spline curves","","1","","8","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"Incremental Learning of First Order Logic Theories for the Automatic Annotations of Web Documents","F. Esposito; S. Ferilli; N. D. Mauro; T. Basile","Universita degli Studi di Bari-Dipartimento di Informatica","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","1093","1097","Organizing large repositories spread throughout the most diverse Web sites rises the problem of effective storage and efficient retrieval of documents. This can be obtained by selectively extracting from them the significant textual information, contained in peculiar layout components, that in turn depend on the identification of the correct document class. The continuous flow of new and different documents in a weakly structured environment like the Web calls for in- crementality, as the ability to continuously update or revise a faulty knowledge previously acquired, while the need to express structural relations among layout components suggest the exploitation of a powerful and symbolic representation language. This paper proposes the application of incremental first-order logic learning techniques in the document layout preprocessing steps, supported by good results obtained in experiments on a real dataset.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377084","","Automatic logic units;Data mining;Fault diagnosis;Indexing;Information retrieval;Learning systems;Ontologies;Organizing;Software libraries;Writing","Web sites;formal logic;information retrieval;learning (artificial intelligence);text analysis","Web documents;Web sites;automatic annotations;first order logic theories;incremental learning;layout components;symbolic representation language;textual information","","3","","9","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Anaphora Resolution in Hindi Documents","S. Agarwal; M. Srivastava; P. Agarwal; R. Sanyal","Indian Institute of Information Technology &#191; Allahabad, Allahabad, U.P., India, sagarwall","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","452","458","This paper presents anaphora resolution as a technique of semantic analysis of text documents written in Hindi language. The focus is on texts that mainly employ simple sentences, such as children's stories, short essays, etc. The technique works by locating sentences in the text that are semantically related through anaphors, analyzing their semantics and exploiting the latter for resolving referents of the respective anaphors. The approach used here is based on matching constraints for the grammatical attributes of different words. The algorithm for anaphora resolution has been tested extensively. The accuracy of anaphora resolution is nearly 96% for simple sentences and for compound and complex sentences; the accuracy is of the order of 80%. The causes of the errors are analyzed and possible techniques for improvements are discussed.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368070","","Algorithm design and analysis;Data mining;Genetics;Information retrieval;Information technology;Natural languages;Performance analysis;Speech;Tellurium;Testing","grammars;knowledge representation;natural languages;pattern matching;text analysis","Hindi language;anaphora resolution;knowledge representation;semantic text document analysis","","0","","11","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"SJCBMQ: A Novel Spatial Join-Based Algorithm for Continuous Border Monitoring Query Processing In Data Streams","Y. Zhang; C. Huang; D. Zhang","School of Electronics and Information Engineering, Xi'an Jiaotong University, Xi'an, P. R. China. yunyizh@gmail.com","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","291","296","In this paper, we propose a novel spatial join-based algorithm for Continuous Border Monitoring Query (CBMQ) processing, which we refer to as SJCBMQ. SJCBMQ transforms the CBMQ processing problems into the spatial join processing problems. Based on the transformation, SJCBMQ finds stream-query pairs which satisfy intersecting relationship. Another attractive contribution of our work is utilizing the locality characteristic of data streams. To take advantage of this characteristic, we cache the search result via an elaborate design. When a hit occurs, we reuse the cache result, avoiding re-evaluate the queries once again. Experimental results show that SJCBMQ significantly outperforms existing approaches in terms of both storage cost and search time.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365456","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365456","Border Monitoring;Corn Transformation;Data Stream","Costs;Data engineering;Degradation;Information retrieval;Joining processes;Monitoring;Query processing;Solids","monitoring;query processing","SJCBMQ algorithm;continuous border monitoring query processing;data stream;locality characteristics;spatial join-based algorithm","","0","","10","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"Supervised HITS Algorithm for MEDLINE Citation Ranking","Y. Liu; Y. Lin","Department of Computer Science, University of Texas at Dallas, Richardson, TX 75083-0688. ying.liu@utdallas.edu","2007 IEEE 7th International Symposium on BioInformatics and BioEngineering","20071105","2007","","","1323","1327","How to present information retrieval results is one main problem that needs to tackle in biomedical information retrieval. A single query may retrieve a large number of results and advanced ranking algorithms are necessary to rank the results so that most relevant result is shown on the top of the list. In this paper, we explored to rank MEDLINE citations using HITS (Hyperlink-Induced Topic Search) algorithm. HITS uses web links from one page to another to rank web pages. It has proven to be successful in web search engines. We further extended HITS to supervised HITS to rank citations. Our results showed that supervised HITS algorithm significantly outperforms HITS algorithm (p<0.01). Compared with HITS, supervised HITS can improve citation ranking from 15% to more than 59% in almost all the cases we tested. Furthermore, MeSH terms outperforms text words in ranking citations, especially when HITS was applied (p<0.01).","","POD:1-4244-1509-8","10.1109/BIBE.2007.4375740","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375740","Document Ranking;HITS;Medline;Supervised HITS","Abstracts;Computer science;Databases;Frequency;Information retrieval;Search engines;Sorting;Web pages;Web search;XML","citation analysis;information retrieval;medical computing","MEDLINE citation ranking;advanced ranking algorithms;biomedical information retrieval;hyperlink-induced topic search algorithm;text words;web pages;web search engines","","2","","14","","","14-17 Oct. 2007","","IEEE","IEEE Conference Publications"
"Word image based latent semantic indexing for conceptual querying in document image databases","S. Banerjee; G. Harit; S. Chaudhury","IIT Delhi, New Delhi, India","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","1208","1212","In this paper we present an application of latent semantic analysis (LSA) for indexing and retrieval of document images with text. The query is specified as a set of word images and the documents which best match with the query representation in the the latent semantic space are retrieved. We show through extensive experiments on a large database that use of LSA for document images provides improvements in retrieval precision as is the case with electronic text documents.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377107","","Character recognition;Image analysis;Image databases;Image retrieval;Image segmentation;Indexing;Information analysis;Information retrieval;Ontologies;Optical character recognition software","document image processing;image retrieval;indexing","conceptual querying;document image databases;document images indexing;document images retrieval;query representation;word image based latent semantic indexing;word images","","3","","15","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Case-Based Reasoning Approach for Invoice Structure Extraction","H. Hamza; Y. Belaid; A. Belaid","LORIA, University Nancy 2. France","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","327","331","This paper shows the use of case-based reasoning (CBR) for invoice structure extraction and analysis. This method, called CBR-DIA (CBR for document invoice analysis), is adaptive and does not need any previous training. It analyses a document by retrieving and analysing similar documents or elements of documents (cases) stored in a database. The retrieval step is performed thanks to graph comparison techniques like graph probing and edit distance. The analysis step is done thanks to the information found in the nearest retrieved cases. Applied on 950 invoices, CBR-DIA reaches a recognition rate of 85.29% for documents of known classes and 76.33% for documents of unknown classes.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378726","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378726","","Artificial intelligence;Data mining;Databases;Image analysis;Information analysis;Information retrieval;Problem-solving;Tagging;Terminology;Text analysis","case-based reasoning;document image processing;feature extraction;graph theory;image retrieval;optical character recognition","OCR;case-based reasoning approach;document database;document invoice analysis;document retrieval;edit distance;graph comparison technique;graph probing;invoice structure extraction","","2","","8","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Laplacian Affinity Propagation for Semi-Supervised Object Classification","Y. Fu; Z. Li; X. Zhou; T. S. Huang","Beckman Institute, University of Illinois at Urbana-Champaign (UIUC), Urbana, IL 61801, USA; Dept. of ECE, University of Illinois at Urbana-Champaign (UIUC), Urbana, IL 61801, USA. E-mail: yunfu2@ifp.uiuc.edu","2007 IEEE International Conference on Image Processing","20071112","2007","1","","I - 189","I - 192","We solve the semi-supervised multi-class object classification problem by a graph-based learning algorithm, called Laplacian affinity propagation (LAP). The idea is to model and train both labeled and unlabeled data by constructing a local neighborhood affinity graph in a smoothness formulation of Laplacian matrix, based on graph mincuts or harmonic energy minimization. The unknown labels for unlabeled data are inferred from an optimized graph embedding procedure subject to the labeled data. Such label-to-unlabel propagation scheme can provide a closed form solution via a learning framework that is flexible for any new design. LAP integrates embedding and classifier together and gives smooth labels with respect to the underlying manifold structure formed by the training data. Object classification experiments on COIL database demonstrate the effectiveness and applicability of such algorithm.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4378923","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378923","Semi-supervised learning;graph embedding;local affinity;object classification;spectral clustering","Closed-form solution;Clustering algorithms;Databases;Information retrieval;Labeling;Laplace equations;Learning systems;Pattern recognition;Semisupervised learning;Training data","graph theory;image classification;learning (artificial intelligence)","COIL database;Laplacian affinity propagation;Laplacian matrix;graph-based learning algorithm;harmonic energy minimization;local neighborhood affinity graph;semisupervised object classification","","2","","19","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Evolving Web Search Expressions","V. Sna; P. Kromer; S. Owais; H. O. Nyongesa; S. Maleki-dizaji","Technical University of Ostrava, Czech Republic","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","4","","532","538","As the volume and variety of information sources, especially on the World Wide Web (WWW), continues to grow, the requirements imposed on search applications are steadily increasing. The amount of available data is growing and so do user demands. Search application should provide the users with accurate, sensible responses to their requests. It is difficult to provide information that accurately matches user information needs. Search effectiveness can be seen as the accuracy of matching user information needs against the retrieved information. There are problems emerging: users often do not present search queries in the form that optimally represents their information need, the measure of a document's relevance is often highly subjective between different users and information sources might contain heterogeneous documents, in multiple formats and the representation of documents is not unified. This contribution presents a proposal to improve web search effectiveness via evolutionary optimization of Boolean and vector search queries based on individual user models.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.364","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344731","","Application software;Computer science;Convergence;Heart;Humans;Information retrieval;Proposals;Web search;Web sites;World Wide Web","Internet;evolutionary computation;information retrieval;query processing","Boolean queries;World Wide Web;evolutionary optimization;evolving Web search expressions;retrieved information;search queries;user information;vector search queries","","0","","21","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"Database Approaches and Data Representation in Structural Bioinformatics","K. Gopal; J. C. Sacchettini; T. R. Ioerger","Department of Computer Science, Texas A&M University, College Station, Texas, U.S.A.","2007 IEEE 7th International Symposium on BioInformatics and BioEngineering","20071105","2007","","","425","432","Database approaches are widely used in structural bioinformatics, since ab initio techniques are often computationally prohibitive, and the structure of biological macromolecules are typically derived from a limited set of motifs. There are several issues and challenges that arise when developing methods to enable efficient database retrieval. For example, how can complex data be represented efficiently, and what should be the size and composition of the database? In this work, we discuss some of these challenges, based on a crystallographic protein model-building program called TEXTAL. In particular, we discuss how structural information on amino acids is represented (as numeric features), how difficult it is to recognize amino acids (based on 3D electron density patterns), and what types of examples (and how many of them) need to be stored in the database. These insights are potentially useful in many other related applications, such as structure-based drug design, protein-protein interaction, discriminating nucleic acids and proteins in hybrid complexes, etc.","","POD:1-4244-1509-8","10.1109/BIBE.2007.4375597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375597","X-ray crystallography;electron density map interpretation;features;structural bioinformatics","Amino acids;Bioinformatics;Biology computing;Crystallography;Electrons;Information retrieval;Molecular biophysics;Pattern recognition;Proteins;Spatial databases","biology computing;crystal structure;data structures;information retrieval;molecular biophysics;molecular configurations;proteins","3D electron density patterns;TEXTAL;amino acids;biological macromolecules;crystallographic protein model-building program;data representation;database approaches;database retrieval;nucleic acids;protein-protein interaction;structural bioinformatics;structure-based drug design","","0","","25","","","14-17 Oct. 2007","","IEEE","IEEE Conference Publications"
"New Content Analysis Methods Effective in Multimedia Based Services","I. Pirnog; D. N. Vizireanu; R. M. Udrea; C. C. Oprea","Faculty of Electronic, Telecommunications and Information Tehnology, University `Polithenica' of Bucharest, B-dul Iuliu Maniu 1-3, 061071 Bucharest, Romania, E-mail: ionut@comm.pub.ro","2007 8th International Conference on Telecommunications in Modern Satellite, Cable and Broadcasting Services","20071105","2007","","","433","436","In this paper we present new content analysis methods effective in multimedia based services. The problem of multimedia content delivery and retrieval has become more and more important due to the growing amount of video information that is delivered to consumers today. The classical searching and retrieval mode in multimedia databases is by name; however the name cannot truly describe the semantic content of most video content. The solution for this problem is visual content extraction. This means that the multimedia content will be characterized not only by name but also by the most representative information contained. This information is known as visual feature and there are any methods that try to extract visual features from multimedia streams. The methods presented in this paper are based on colour and spatial information and are used for extracting patterns from images and videos. The process of multimedia content retrieval consists of three stages: semantic video modelling, video segmentation and feature extraction. The result of semantic video modelling is the representation of raw data in a more structured form, and it is essential in the following stage. Video segmentation means the partition of an image into a set of non overlapping homogenous regions whose union is the entire image. The presented segmentation methods used are edge-based, region-based and motion-based, and are used for moving or static object detection.","","CD-ROM:978-1-4244-1468-0; POD:978-1-4244-1467-3","10.1109/TELSKS.2007.4376032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376032","Content analysis;motion detection;segmentation;video modelling","Content based retrieval;Data mining;Feature extraction;Image edge detection;Image segmentation;Information retrieval;Multimedia databases;Multimedia systems;Object detection;Streaming media","feature extraction;image motion analysis;image retrieval;image segmentation;multimedia databases;object detection;video signal processing;video streaming","content analysis methods;multimedia based services;multimedia content delivery;multimedia content retrieval;multimedia databases;multimedia streams;pattern extraction;semantic video modelling;static object detection;video information;video segmentation;visual content extraction;visual feature extraction","","1","","12","","","26-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"Optimising the Hystereses of a Two Context Layer RNN for Text Classification","G. Arevian; C. Panchev","School of Computing and Technology, University of Sunderland, Sunderland SR6 0DD, United Kingdom. phone: +44 (0) 191 515 3259; email: garen.arevian@sunderland.ac.uk","2007 International Joint Conference on Neural Networks","20071029","2007","","","2936","2941","Established techniques from information retrieval (IR) and machine learning (ML) have shown varying degrees of success in the automatic classification of real-world text. The capabilities of an extended version of the Simple recurrent network (SRN) for classifying news titles from the Reuters-21578 Corpus are explored. The architecture is composed of two hidden layers where each layer has an associated context layer that takes copies of previous activation states and integrates them with current activations. This results in improved performance, stability and generalisation by the adjustment of the percentage of previous activation strengths kept ""in memory"" by what is defined as the hysteresis parameter. The study demonstrates that this partial feedback of activations must be carefully fine-tuned to maintain optimal performance. Correctly adjusting the hysteresis values for very long and noisy text sequences is critical as classification performance degrades catastrophic ally when values are not optimally set.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371427","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371427","","Computer architecture;Degradation;Hysteresis;Information retrieval;Machine learning;Neural networks;Recurrent neural networks;Stability;Text categorization;USA Councils","classification;information retrieval;learning (artificial intelligence);recurrent neural nets;text analysis","information retrieval;machine learning;recurrent neural network;text classification;two context layer RNN","","2","","41","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"A New Approach to Compute the Semantic Similarity of Chinese Question Sentence","K. Chen; X. Z. Fan; J. Liu; Z. T. Yu","School of Computer Science of Technology, Beijing Institute of Technology, Beijing 100081, China. E-MAIL: chenkang@bit.edu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","6","","3390","3395","The sentence similarity computation plays an important role in each field of Chinese information processing. A new approach to compute the Chinese question semantic similarity is presented, which is divided into two steps: the first step is to extract the question semantic representation from the question, and the second step is to compute the question semantic similarity based on the question semantic representation. This paper uses the method of question semantic model matching to extract the question semantic representation from the question. The experimental results show that the proposed algorithm worked more reasonable in the real calculation. In addition, our approach is of great value for many potential applications in the future.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370734","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370734","Chinese question;Question semantic representation;Semantic chunk;Semantic similarity","Automation;Computer science;Cybernetics;Data mining;Fuzzy systems;Information filtering;Information processing;Information retrieval;Machine learning;Natural language processing","information retrieval;knowledge representation;natural language processing","Chinese information processing;Chinese question semantic similarity;question semantic model matching;question semantic representation","","5","","12","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"New Metrics for Evaluating Performance in Document Analysis Tasks_Application to the Table Case","A. Costa e Silva","University of Edinburgh","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","481","485","Is an algorithm capable of high precision and recall at classifying lines as part of table really good at locating tables? Several document analysis tasks require gluing or cutting certain document elements to form others. The suitability of the commonly used precision and recall for such division/aggregation tasks is arguable, since their underlying assumption is that the granularity of the items at input is the same as at output. We propose new evaluation metrics especially suited for this type of tasks, and show their application in several table tasks. In the process we present robust table location and cell segmentation algorithms.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378756","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378756","","Cost function;Databases;Error correction;Functional analysis;Image analysis;Information retrieval;Measurement units;Performance analysis;Robustness;Text analysis","document handling;pattern classification","aggregation tasks;cell segmentation algorithms;division tasks;document analysis;evaluation metrics;robust table location","","2","","19","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Color Image Retrieval using Fuzzy Similarity Measures and Fuzzy Partitions","M. Nachtegael; D. Van der Weken; V. De Witte; S. Schulte; T. Melange; E. E. Kerre","Ghent Univ., Ghent","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 13","VI - 16","Color image retrieval is becoming more and more important, and so is the quest for automated and reliable retrieval systems. In this paper we present and illustrate a new color image retrieval system, of which the novelty lies in the use of a fuzzy partition of the HSI color space and fuzzy similarity measures. The system has the advantage that the images don't have to be characterized in advance using several features, and it is quite flexible since the database images are not required to have the same dimensions.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379511","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379511","color image;image retrieval;similarity measure","Color;Computer science;Fuzzy sets;Fuzzy systems;Image databases;Image retrieval;Information retrieval;Mathematical model;Mathematics;Spatial databases","fuzzy set theory;image colour analysis;image retrieval;visual databases","HSI color space;color image retrieval;fuzzy partitions;fuzzy similarity measures;image database","","5","","20","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"B-Tree Based Trust Model for Resource Selection in Grid","P. Varalakshmi; S. T. Selvi; A. J. Ashraf; K. Karthick","Department of Information Technology, MIT, Anna University. Email: sakthijayasundar@rediffmail.com","2007 International Conference on Signal Processing, Communications and Networking","20071105","2007","","","222","227","Trust management is an important issue in a grid environment where consumers and service providers are distributed geographically across autonomous administrative domains. In this paper, we propose reputation-based trust management architecture through the use of intermediaries, brokers. This architecture insists on multiple brokers in each domain. The entities (Consumers and the SPs) are distributed across these brokers, with each of these entities being associated with more than one broker. This improves the redundancy of information maintained at the broker sites, thereby improving the reliability. This also eases the network traffic at the broker sites while handling consumer requests and feedbacks. The issues rising out of such an arrangement of multiple brokers, namely the distribution of entities among the brokers and maintenance of consistency of information across the brokers, are addressed well in this paper. Trust-indices of SPs and consumers are evaluated and updated dynamically after the completion of each transaction. This enables the consumer to receive the response from the broker significantly quicker compared to other reputation-based-trust models where the trust-indices are computed at the request-time. To further improve the response time of each transaction, a B-tree indexing scheme has been proposed. Trust parameters such as satisfaction-value, number, cost and criticality of transactions, and different weights for past and recent transactions are considered for the trust evaluation. Our model shows a marked improvement in job success rate for various percentages of malicious entities. The selection query cost for each transaction is reduced thereby improving the overall response time is show-cased in this model. The impact of broker's feedback on the computation of trust-indices is also presented","","CD-ROM:1-4244-0997-7; POD:1-4244-0996-9","10.1109/ICSCN.2007.350735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4156617","","Certification;Costs;Delay;Feedback;Grid computing;High performance computing;Indexing;Information retrieval;Maintenance;Quality of service","database indexing;grid computing;query processing;resource allocation;security of data;tree data structures","B-tree based trust model;B-tree indexing scheme;grid computing;information consistency maintenance;multiple brokers;network traffic;redundancy;reliability;reputation-based trust management architecture;resource selection;selection query cost;trust-indices","","6","","10","","","22-24 Feb. 2007","","IEEE","IEEE Conference Publications"
"A Lightweight and Flexible Mobile Agent Platform Tailored to Management Applications","D. Gavalas","Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece. dgavalas@aegean.gr","2006 Proceedings of the First Mobile Computing and Wireless Communication International Conference","20071105","2006","","","203","208","Mobile Agents (MAs) represent a distributed computing technology that promises to address the scalability problems of centralized network management. A critical issue that will affect the wider adoption of MA paradigm in management applications is the development of MA Platforms (MAPs) expressly oriented to distributed management. However, most of available platforms impose considerable burden on network and system resources and also lack of essential functionality. In this paper, we discuss the design considerations and implementation details of a complete MAP research prototype that sufficiently addresses all the aforementioned issues. Our MAP has been implemented in Java and tailored for network and systems management applications.","","POD:978-9957-486-00-6","10.1109/MCWC.2006.4375222","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375222","","Computer network management;Environmental management;Information retrieval;Java;Knowledge management;Mobile agents;Prototypes;Resource management;Scalability;Technology management","Internet;Java;mobile agents;telecommunication network management","Java;centralized network management;distributed computing technology;distributed management;management applications;mobile agent platform;network management application;systems management application","","0","","12","","","17-20 Sept. 2006","","IEEE","IEEE Conference Publications"
"A New Shape Signature for Fourier Descriptors","A. El-ghazal; O. Basir; S. Belkasim","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON., Canada, N2L 3G1. Email: akrem@pami.uwaterloo.ca, obaisr@uwaterloo.ca","2007 IEEE International Conference on Image Processing","20071112","2007","1","","I - 161","I - 164","Shape-based image description is an important approach to content-based image retrieval (CBIR). A variety of techniques are reported in the literature that aim to represent objects based on their shapes; each of these techniques has its advantages and disadvantages. Fourier descriptor (FD), a simple yet powerful technique, has attractive properties such as rotational, scale, and translational invariance. In this paper we investigate this technique and present a novel shape registration method for extracting Fourier descriptors. When evaluated against curvature scale space (CSS) and Zernike moments (ZM) in shape-based image retrieval, the proposed technique exhibits superior performance.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4378916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378916","Fourier descriptors;Image retrieval;Shape","Cascading style sheets;Computer science;Content based retrieval;Digital images;Image databases;Image retrieval;Image storage;Information retrieval;Multimedia databases;Shape","content-based retrieval;image retrieval","Fourier descriptor extraction;content-based image retrieval;shape registration;shape signature;shape-based image description;shape-based image retrieval","","5","","20","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Applying the ReMiP to Web Site Migration","T. Gipp; A. Winter","University of Koblenz-Landau, 56070 Koblenz, Germany, tgi@uni-koblenz.de","2007 9th IEEE International Workshop on Web Site Evolution","20071112","2007","","","9","13","Web sites serve to publish information, both locally in intranets as well as on a global scale. Like all software systems, they have to cope with changing requirements and evolving technologies. The reference process model for software migration, ReMiP, provides a generic process model for software migration in general. The paper introduces ReMiP and summarises the application of a tailored ReMiP towards migrating a static HTML-based Web site to a content management system.","1550-4441;15504441","POD:978-1-4244-1450-5","10.1109/WSE.2007.4380238","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4380238","process model;web site migration","Application software;Bibliographies;Content management;Databases;Information retrieval;Maintenance engineering;Software maintenance;Visualization;Web page design;Web sites","Internet;content management;hypermedia markup languages;intranets","HTML-based Web site;ReMiP;Web site migration;content management system;intranets;software migration;software systems","","0","","17","","","5-6 Oct. 2007","","IEEE","IEEE Conference Publications"
"Digital Asset Management System for libraries","D. N. Kopaliani","College of Management, Lawrence Technological University, Southfield, MI 48075, USA","2007 IEEE International Conference on Electro/Information Technology","20071105","2007","","","527","531","Cataloging, searching and retrieving digital information can present hurdles in many libraries. Current methods of storing and retrieving information through databases involve the use of traditional relational architecture model. However, as new technologies and methods evolve, an object-oriented (OO) architecture model can better serve libraries' cataloging needs. This paper explores the possibility of using OO architecture model to provide scalable digital asset management system that can track multiple library assets and provide cross-sectional views of the assets. By implementing the OO model, end user will have greater power over data without programmers' involvement. The proposed approach can also be applied to cataloging, searching, and retrieving of other digital asset information that includes, but not limited to, equipments in engineering/science laboratories or facilities, business offices or facilities, manufacturing plants or warehouses, and city offices or storage areas and so on.","2154-0357;21540357","CD-ROM:978-1-4244-0941-9; POD:978-1-4244-0940-2","10.1109/EIT.2007.4374466","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4374466","Asset Management Model;Object-oriented model;digital asset management system;library cataloging","Asset management;Information retrieval;Laboratories;Object oriented databases;Object oriented modeling;Power engineering and energy;Power system modeling;Programming profession;Relational databases;Software libraries","cataloguing;digital libraries;information retrieval;object-oriented programming","digital asset management system;information retrieval;multiple library assets;object-oriented architecture;relational architecture model","","1","","6","","","17-20 May 2007","","IEEE","IEEE Conference Publications"
"Document Content Inventory and Retrieval","H. Baird; M. Moll","Lehigh University","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","93","97","We give an analysis of relationships between expected retrieval performance and classification recognition accuracy in the context of document image content extraction and inventory. By content extraction we mean location and measurement of regions containing handwriting, machine- printed text, photographs, blank space, etc, in documents represented as bilevel, grey-level, or color images. Recent experiments have shown that even modest per-pixel content classification accuracies can support usefully high recall and precision rates (of, e.g., 80-90%) for retrieval queries within document collections seeking pages that contain a given minimum fraction of a certain type of content. In an effort to elucidate this interesting empirical result, we have analyzed the interdependency of classification and retrieval under a variety of assumptions about the distribution of content types in document image collections. We show that under general conditions we cannot derive precision and recall measures from per-pixel classification measures alone, but we can estimate the expected values of these measures. If however the distribution of content and error rates are uniform across the entire collection, our results suggest, it is possible to predict precision and recall measures from classification accuracy and vice versa.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378682","","Content based retrieval;Image analysis;Image color analysis;Image recognition;Image retrieval;Information retrieval;Performance analysis;Pixel;Testing;Text analysis","content-based retrieval;document image processing;information retrieval;pattern classification","classification recognition accuracy;content classification accuracy;document content inventory;document image collections;document image content extraction;document retrieval;retrieval performance;retrieval query","","2","","11","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Towards Auto-Construction of Domain Ontology: An Auto-Constructed Domain Conceptual Lexicon and its Application to Extractive Summarization","H. H. Huang; Y. H. Kuo","Center for Research of E-life DIgital Technology (CREDIT), Department of Computer Science and Information Engineering, National Cheng Kung University, No. 1, Ta-Hsueh Road, Tainan, Taiwan. E-MAIL: hhhuang@ismp.csie.ncku.edu.tw","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","5","","2947","2952","A domain conceptual lexicon can be used for the construction of a domain ontology. In this paper, a method of auto-constructing a domain conceptual lexicon is proposed. The conceptual lexicon is represented by WordNet senses and their relations. Using the domain conceptual lexicon, an extractive summarization method is proposed. A characteristic of the scheme is that each sentence of a document is represented by a set of WordNet senses and constitutes a fuzzy transaction for mining conceptual lexicon and ranking relevance. A prototype of this automatic text summarization scheme is built and an intrinsic method with the information-retrieval criteria is used for measuring the summary quality.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370652","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370652","Fuzzy transaction;Key sentences;Semantic clustering;Sense representation;Text summarization","Application software;Clustering algorithms;Cybernetics;Data mining;Frequency;Information retrieval;Knowledge acquisition;Machine learning;Ontologies;Prototypes","data mining;fuzzy reasoning;natural language processing;ontologies (artificial intelligence);pattern clustering;relevance feedback;text analysis","WordNet sense;auto-constructed domain conceptual lexicon mining;automatic text summarization scheme;document linguistic processing;domain ontology auto-construction;extractive summarization method;fuzzy transaction;information-retrieval criteria;relevance ranking;semantic clustering","","0","","13","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Combining Matching Algorithms for Human Identification using Dental X-Ray Radiographs","O. Nomir; M. Abdel-Mottaleb","Member, IEEE, CS Dept. University of Mansoura Egypt, ECE Dept. University of Miami USA. Email: o.nomir@umiami.edu","2007 IEEE International Conference on Image Processing","20071112","2007","2","","II - 409","II - 412","The goal of forensic dentistry is to identify individuals based on their dental characteristics. In this paper we present a system for identifying individuals from their dental X-ray records. Given a dental record, usually a postmortem (PM) radiograph, the system searches a database of ante mortem (AM) radiographs and retrieves the best matches from the database. The system automatically segments dental X-ray images into individual teeth and extracts representative feature vectors for each tooth, which are later used for retrieval. The system integrates one method for teeth segmentation, and two different methods for representing and matching teeth. The first matching method represents each tooth contour by signature vectors obtained at salient points on the contour of the tooth. The second method uses hierarchical Chamfer distance for matching AM and PM teeth to reduce the search space and accordingly reduce the retrieval time. Given a query PM image, and according to a matching distance, AM radiographs that are most similar to the PM image, are found and presented to the user using the two matching methods. The experimental results show that the system is robust. We studied the performance of the different modules of the system as well as the results effusing the matching techniques.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379179","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379179","Forensic dentistry;biometrics;fusion","Dentistry;Forensics;Humans;Image databases;Image segmentation;Information retrieval;Radiography;Spatial databases;Teeth;X-ray imaging","dentistry;feature extraction;image matching;image representation;image retrieval;image segmentation;medical image processing;radiology","ante mortem radiographs;dental X-ray records;feature extraction;forensic dentistry;hierarchical Chamfer distance;human identification;image matching;image representation;image retrieval;postmortem radiographs;search space reduction;teeth segmentation;tooth contours","","2","","11","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Preference Learning for Category-Ranking based Interactive Text Categorization","F. Aiolli; F. Sebastiani; A. Sperduti","Dipartimento di Matematica Pura ed Applicata, Universita di Padova, Via Trieste 63, 35121 Padova - Italy. e-mail: aiolli@math.unipd.it","2007 International Joint Conference on Neural Networks","20071029","2007","","","2034","2039","Category Ranking is a variant of the multi-label classification problem, in which, rather than performing a (hard) assignment to an object of categories from a predefined set, we rank all categories according to their estimated ""degree of suitability"" to the object. Category ranking has many applications, all pertaining to ""interactive"" classification contexts in which the system, rather than taking a final categorization decision, is simply required to support a human expert who is in charge of taking this decision. Despite its high applicative potential in information retrieval applications, and in text categorization in particular, category ranking has mainly been tackled by standard text categorization methods. In this paper, we take a radically different stand to category ranking, i.e. one in which supervision is provided to the learner not in the standard form of labels attached to training documents, but in the form of preferences of type ""category c is to be preferred to category c2 for document d"". We apply to this problem a recently proposed, very general model for preferential learning, and show, through experiments performed on the standard Reuters-21578 benchmark, that this largely outperforms support vector machines, the learning method which has up to now proved the best-performing one in text categorization comparative experiments.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371271","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371271","","Chromium;Electronic mail;Humans;Information retrieval;Learning systems;Machine learning;Neural networks;Support vector machine classification;Support vector machines;Text categorization","classification;information retrieval;interactive systems;learning (artificial intelligence);text analysis","CR based interactive text categorization;CR multilabel classification problem;category ranking;information retrieval applications;preference learning;suitability degree;training documents","","1","5","13","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"Medical Image Retrieval Based on Bidimensional Empirical Mode Decomposition","W. Liu; W. Xu; L. Li","Institute for Biomedical Engineering and Instrumentation, School of Automation, Hangzhou Dianzi University, Hangzhou, China. bme.liuwei@gmail.com","2007 IEEE 7th International Symposium on BioInformatics and BioEngineering","20071105","2007","","","641","646","An approach of medical image decomposition and texture feature extraction based on the bidimensional empirical mode decomposition(BEMD), which can decompose the image into a set of functions denoted intrinsic mode functions (IMF) and a residue, was presented. Features extracted were the mean and standard deviation of the amplitude matrix, phase matrix and instantaneous frequency matrix of the IMFs and their Hilbert transformations. The extracted features were used for medical image retrieval. Moreover, according to the spatial relationship between local extrema points, a new boundary processing method based on clustering algorithm was proposed. In order to evaluate the proposed BEMD-based feature, we also presented a new multiscale fractal dimension feature. Preliminary comparison experimental results showed that the retrieval results of the BEMD-based feature were encouraged.","","POD:1-4244-1509-8","10.1109/BIBE.2007.4375628","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375628","bidimensional empirical mode decomposition;boundary processing;content-based medical image retrieval;texture analysis","Biomedical imaging;Clustering algorithms;Data mining;Feature extraction;Fractals;Image databases;Image retrieval;Information retrieval;Matrix decomposition;Spatial databases","Hilbert transforms;fractals;medical image processing","Hilbert transformations;amplitude matrix;bidimensional empirical mode decomposition;boundary processing method;clustering algorithm;instantaneous frequency matrix;intrinsic mode functions;medical image decomposition;medical image retrieval;multiscale fractal dimension feature;phase matrix;texture feature extraction","","7","","18","","","14-17 Oct. 2007","","IEEE","IEEE Conference Publications"
"Multi-Level Discrete Cosine Transform for Content-Based Image Retrieval by Support Vector Machines","Y. Li; X. Chen; X. Fu; S. Belkasim","Department of Computer Science, Georgia State University, Atlanta, GA 30303. cscyxlx@cs.gsu.edu","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 21","VI - 24","Texture feature extraction is widely used in content-based image retrieval (CBIR) and is not efficient to be implemented directly in the pixel domain due to high information redundancy and strong correlations in raw images. It is well known that low-frequency coefficients of the discrete cosine transforms (DCTs) preserve the most important image features. In this paper, we use multi-level DCTs (MDCTs) to generate image texture feature vectors for the purpose of CBIR. The texture feature vectors generated from MDCTs coefficients and Zernike moments are classified by support vector machines (SVMs). The experimental result shows good average retrieval accuracy. It also shows that DCT coefficients from low level resolution images are sufficient to extract image texture feature with significant less computing cost.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379510","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379510","CBIR;Feature Extraction;Multi-level Discrete Cosine Transform;SVMs;Zernike Moments","Content based retrieval;Discrete cosine transforms;Feature extraction;Image generation;Image retrieval;Image texture;Information retrieval;Pixel;Support vector machine classification;Support vector machines","content-based retrieval;discrete cosine transforms;feature extraction;image classification;image resolution;image retrieval;image texture;support vector machines","Zernike moments;content-based image retrieval;image classification;image resolution;image texture feature extraction;multilevel discrete cosine transform;support vector machines","","2","","16","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Two criteria for On-line Detection of Oscillations in Nuclear Fusion Experiments","N. Duro; J. S. Moreno; S. Dormido-Canto; R. Dormido; G. Farias; H. Vargas; J. Vega","Dpto. Inform&#225;tica y Autom&#225;tica, UNED, C/. Juan del Rosal 16, 28040 Madrid, Spain","2007 15th IEEE-NPSS Real-Time Conference","20071112","2007","","","1","6","The work presented in this paper is a first approach in the application of monitoring and assessment techniques developed in the control engineering field to the diagnosis and analysis of signals in nuclear fusion experiments. Two procedures to detect oscillations in process control are explained and modified to be applied to the on-line detection of oscillations in waveforms. Steps to further research on the application of monitoring and assessment techniques from the control engineering field to the fusion are given.","","CD-ROM:978-1-4244-0867-2; POD:978-1-4244-0866-5","10.1109/RTC.2007.4382797","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382797","Diagnosis;implementation;monitoring;oscillations;process control;supervision","Control engineering;Frequency;Fusion reactors;Information retrieval;Monitoring;Plasma applications;Plasma diagnostics;Plasma waves;Process control;Signal analysis","control engineering computing;fusion reactor design;fusion reactor instrumentation;plasma diagnostics;plasma oscillations;plasma waves;process control;process monitoring","assessment technique;control engineering field;diagnosis;monitoring technique;nuclear fusion experiments;on-line detection;plasma waveforms;process control;waveform oscillations","","0","","12","","","April 29 2007-May 4 2007","","IEEE","IEEE Conference Publications"
"Multi-Rate DSP/FPGA-Based Real-Time Acquisition and Control on the ISTTOK Tokamak","B. B. Carvalho; A. J. N. Batista; F. Patricio; M. Correia; H. Fernandes; J. Sousa","Associa&#231;&#227;o EURATOM/IST, Centro de Fus&#227;o Nuclear, Av. Rovisco Pais 1, 1049-001 Lisboa, Portugal.","2007 15th IEEE-NPSS Real-Time Conference","20071112","2007","","","1","3","Data acquisition on the ISTTOK tokamak is being upgraded from VME to PCI using a general purpose especially developed PCI acquisition board with 8 galvanic isolated channels and 14bit/2Msamples/sec 512 Mbytes of SDRAM, and integrated FPGA/DSP capabilities. Due to the wide range of signal spectrum present in the experimental device data-reduction is crucial to efficiently use data retrieval and analysis systems. To avoid long latency offline processing and also to allow real-time control implemented in the DSP, multi-rate real time decimation in the FPGA has been implemented. This paper describes the data processing techniques developed using either FIR or cascaded- integrator-comb CIC filter comparing both approaches. The digital DC baseline restorer was also implemented in the FPGA.","","CD-ROM:978-1-4244-0867-2; POD:978-1-4244-0866-5","10.1109/RTC.2007.4382794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382794","","Data acquisition;Data analysis;Digital signal processing;Field programmable gate arrays;Finite impulse response filter;Galvanizing;Information retrieval;SDRAM;Signal analysis;Tokamaks","FIR filters;Tokamak devices;control engineering computing;data acquisition;digital signal processing chips;field programmable gate arrays;fusion reactor instrumentation;nuclear engineering computing;peripheral interfaces;real-time systems","DSP chips;FIR filters;FPGA;ISTTOK tokamak;PCI acquisition board;SDRAM;VME;cascaded- integrator-comb CIC filter;data acquisition;data processing techniques;digital DC baseline restorer;digital signal processing chips;field programmable gate arrays;fusion plasma device;galvanic isolated channels;multirate real time control","","0","","5","","","April 29 2007-May 4 2007","","IEEE","IEEE Conference Publications"
"An Automated Term Definition Extraction using the Web Corpus in Chinese Language","F. Y. Leu; C. C. Ko","Department of Computer Science and Information Engineering, Tunghai University, leufy@thu.edu.tw","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","435","440","This paper proposes a system, named DefExplorer, which extracts term definitions from the Web, determines the type of question terms, and selects answers from noisy Web pages automatically. DefExplorer filters out invalid data with a semantic approach. We deployed two types of candidate sets, common and domain specific, to group similar candidates and determine candidates' importance for selecting final answers. Experimental results show that DefExplorer can effectively extract term definitions from the Web, especially for the definitions of out-of-vocabulary terms.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368067","Chinese Language;Definitions;Information Extraction;Web corpus","Assembly;Computer science;Data mining;Dictionaries;Encyclopedias;Filters;Information retrieval;Natural languages;Vocabulary;Web pages","information retrieval;natural language processing;semantic Web;vocabulary","Chinese language;DefExplorer;Web corpus;automated term definition extraction;noisy Web pages;semantic approach","","1","","8","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Dynamic Reconfiguration Management Based on a Distributed Object Model","J. Dondo; F. Rincon; J. Barba; F. Moya; F. J. Villanueva; D. Villa; J. C. Lopez","School of Computer Science - University of Castilla-La Mancha. email: jdondo@inf-cr.uclm.es","2007 International Conference on Field Programmable Logic and Applications","20071112","2007","","","684","687","In this paper we propose a contribution to reduce the complexity of management of dynamic reconfiguration. The model for dynamic reconfiguration presented here is based on the object-oriented paradigm and a clear separation between the functionality inside the reconfigured cores and the communication infrastructure. This infrastructure will be the responsible not only for managing data transferences between objects but also for transparently handling other aspects such as state storage and retrieval or controlled object stopping and resuming.","1946-147X;1946147X","CD-ROM:978-1-4244-1060-6; POD:978-1-4244-1059-0","10.1109/FPL.2007.4380745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4380745","","Communication system control;Computer science;Data mining;Design methodology;Encapsulation;Information retrieval;Middleware;Object oriented modeling;Object oriented programming;Programming profession","distributed object management;electronic engineering computing;object-oriented programming;reconfigurable architectures;system-on-chip","data transference management;distributed object model;dynamic reconfiguration management complexity;object-oriented paradigm;state storage;system-on-chip","","2","","7","","","27-29 Aug. 2007","","IEEE","IEEE Conference Publications"
"Using Fractal Dimension as Texture Discriminator for Context Base Image Retrieval","R. Dobrescu; S. Mocanu","POLITEHNICA University of Bucharest, Faculty of Automatic Control and Computers, 313 Splaiul Independen&#191;ei, Bucharest, Romania. E-mail: radud@isis.pub.ro","2007 14th International Workshop on Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services","20071112","2007","","","82","85","The objective of the present work is to evaluate the potential of the use of the image fractal dimension as textural feature in a content-based image retrieval system. In order to compare and classify the regions of an image, we have used two distances between two partitions of the image: (1) a classic distance computed with some features (contrast, energy, entropy, homogeneity, correlation) extracted form cooccurrence matrix and (2) a distance between the fractal dimensions of the two regions. The experiments proved that the degree of confidence is increased when adding the fractal dimension to the other textural features.","","CD-ROM:978-961-248-029-5; POD:978-961-248-036-3","10.1109/IWSSIP.2007.4381158","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381158","CBIR;binarization threshold;computer vision;distance;fractal dimension;histograms;patterns;texels;textural feature","Computer vision;Content based retrieval;Data mining;Feature extraction;Fractals;Histograms;Image databases;Image retrieval;Information retrieval;Shape","feature extraction;fractals;image retrieval;image texture;matrix algebra","context base image retrieval;cooccurrence matrix;fractal dimension;image regions;textural feature;texture discriminator","","0","","11","","","27-30 June 2007","","IEEE","IEEE Conference Publications"
"Exploring Wikipedia and Query Log's Ability for Text Feature Representation","B. Li; Q. C. Chen; D. S. Yeung; W. W. Y. Ng; X. L. Wang","Media and Life Science Computing Laboratory, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518055, China. E-MAIL: Tereas.bing@gmail.com","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","6","","3343","3348","The rapid increase of Internet technology requires a better management of Web page contents. Many text mining researches has been conducted, like text categorization, information retrieval, text clustering. When machine learning methods or statistical models are applied to such a large scale of data, the first step we have to solve is to represent a text document into the way that computers could handle. Traditionally, single words are always employed as features in vector space model, which make up the feature space for all text documents. The single-word based representation is based on the word independence and doesn't consider their relations, which may cause information missing. This paper proposes Wiki-Query segmented features to text classification, in hopes of better using the text information. The experiment results show that a much better F1 value has been achieved than that of classical single-word based text representation. This means that Wikipedia and query segmented feature could better represent a text document.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370725","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370725","Query-Log;Text feature representation;Wikipedia (Wiki);Word-Based model","Content management;Information retrieval;Internet;Large-scale systems;Learning systems;Technology management;Text categorization;Text mining;Web pages;Wikipedia","Internet;text analysis","Internet technology;Web page contents;Wikipedia;information retrieval;text categorization;text classification;text clustering;text feature representation;text mining;vector space model","","0","","15","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Design of Wearable Gadgets for Life-Log Service based on UTC","D. W. Ryoo; J. H. Won; C. S. Bae","Department of Post-PC Research Group Digital Home Research Division, Electronics and Telecommunications Research Institute. e-mail: dwryoo@etri.re.kr","2007 IEEE International Symposium on Consumer Electronics","20071112","2007","","","1","6","Recently, the technology of the memory has been developed for storage of data. According to the technology of the memory, storage capacity has rapidly been increased. The new demand to store user's special situations or the daily life appears accordingly. A life-log means a recording the interesting events or the daily life of an individual as the digital method. The information for life log are as follows: a photograph, voice, the activity, physiological signals, time information, and location of user. In this paper, the design of wearable gadgets for life-log service based on UTC is presented. We designed of two kinds of wearable gadgets. The firstly is wearable gadget for low rate data (e.g., location), the second is wearable gadget for high rate data (e.g., video). The gadgets acquire the UTC (Universal Time Coordinated) time information by using GPS from a satellite. The acquired time (UTC) are included in acquired life log data from the different systems such as an image, an audio, a bio-signal, environmental information, etc. The measured life- log signals and environment signals in a daily life can be merged with the synchronized time and position information. This information can be realized the obtained time of life log data later. Therefore, it makes more and more useful information can be obtained. This can also provide many usabilities to retrieve data of life log.","0747-668X;0747668X","CD-ROM:978-1-4244-1110-8; POD:978-1-4244-1109-2","10.1109/ISCE.2007.4382197","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382197","UTC;Wearable;gadget;life-log","Digital recording;Global Positioning System;Information retrieval;Mobile computing;Position measurement;Satellites;Synchronization;Time measurement;Usability;Wearable computers","Global Positioning System;computer networks;digital storage;information services;information storage;mobile computing;personal computing;wearable computers","GPS;acquired time;daily life event;interesting event recording;life log service;universal time coordinated time information;wearable gadgets","","0","","7","","","20-23 June 2007","","IEEE","IEEE Conference Publications"
"Iterated Document Content Classification","C. An; H. Baird; P. Xiu","Lehigh University","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","252","256","We report an improved methodology for training classifiers for document image content extraction, that is, the location and segmentation of regions containing handwriting, machine-printed text, photographs, blank space, etc. Our previous methods classified each individual pixel separately (rather than regions): this avoids the arbitrariness and restrictiveness that result from constraining region shapes (to, e.g., rectangles). However, this policy also allows content classes to vary frequently within small regions, often yielding areas where several content classes are mixed together. This does not reflect the way that real content is organized: typically almost all small local regions are of uniform class. This observation suggested a post-classification methodology which enforces local uniformity without imposing a restricted class of region shapes. We choose features extracted from small local regions (e.g. 4-5 pixels radius) with which we train classifiers that operate on the output of previous classifiers, guided by ground truth. This provides a sequence of post-classifiers, each trained separately on the results of the previous classifier. Experiments on a highly diverse test set of 83 document images show that this method reduces per-pixel classification errors by 23%, and it dramatically increases the occurrence of large contiguous regions of uniform class, thus providing highly usable near-solid 'masks' with which to segment the images into distinct classes. It continues to allow a wide range of complex, non-rectilinear region shapes.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378714","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378714","","Classification tree analysis;Data mining;Feature extraction;Image analysis;Image retrieval;Image segmentation;Information retrieval;Pixel;Shape;Testing","content-based retrieval;document image processing;image classification;image retrieval","document image content extraction;iterated document content classification;per-pixel classification errors;region shapes","","10","","8","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Shared Parts Model for Document Image Recognition","M. D. Gupta; P. Sarkar","University of Illinois, Urbana-Champaign","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","1163","1172","We address document image classification by visual appearance. An image is represented by a variable-length list of visually salient features. A hierarchical Bayesian network is used to model the joint density of these features. This model promotes generalization from a few samples by sharing component probability distributions among different categories, and by factoring out a common displacement vector shared by all features within an image. The Bayesian network is implemented as a factor graph, and parameter estimation and inference are both done by loopy belief propagation. We explain and illustrate our model on a simple shape classification task. We obtain close to 90% accuracy on classifying journal articles from memos in the UWASH-II dataset, as well as on other classification tasks on a home-grown data set of technical articles.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377098","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377098","","Bayesian methods;Belief propagation;Image classification;Image recognition;Indexing;Information retrieval;Optical character recognition software;Parameter estimation;Probability distribution;Shape","belief networks;document image processing;image classification;parameter estimation;statistical distributions","Bayesian network;component probability distributions;document image classification;document image recognition;loopy belief propagation;parameter estimation;parameter inference;shared parts model","","0","2","12","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Effect of Word Sets with Non-Taxonomical Relation for Retrieval Support","E. Yamamoto; H. Isahara","Computational Linguistics Group, National Institute of Information and Communications Technology, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289, Japan, eiko@nict.go.jp","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","407","412","At least two kinds of relations exist among related words: the taxonomical relation and the thematic relation. However, although words with a taxonomical relation are easy to identify from linguistic resources such as dictionaries and thesauri, words with a thematic relation are difficult to identify because they are rarely maintained in linguistic resources. In this paper, we present a method of extracting thematically (non-taxonomically) related word sets among words for retrieval support by employing case-marking articles derived from syntactic analysis. For verifying the capability of such word sets, we compared the results retrieved with words related only taxonomically and those retrieved with words including a word related non-taxonomically to the other words. We found additional term which is thematically related to other terms is effective at retrieving informative pages.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368063","","Communications technology;Computational linguistics;Dairy products;Data mining;Dictionaries;Information retrieval;Layout;Natural language processing;Pediatrics;Thesauri","computational linguistics;information analysis;information retrieval;natural language processing","case-marking articles;dictionaries;linguistic resources;nontaxonomical relation;retrieval support;syntactic analysis;thematic relation;thesauri;word sets;words","","0","","15","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Network Discovery Mechanisms for Fast-handoff","A. Dutta; S. Madhani; T. Zhang; Y. Ohba; K. Taniuchi","Telcordia Technologies, Henning Schulzrinne, Columbia University","2006 3rd International Conference on Broadband Communications, Networks and Systems","20071105","2006","","","1","11","Proactive handoff mechanisms involving secure pre-authentication and proactive configuration help reduce the delay and transient data loss for real-time communication during movement between homogeneous or heterogeneous access networks. Pre-authentication is meant to perform authentication with a network before a mobile moves into the network. To achieve secure pre- authentication with a target neighboring network, a mobile needs to obtain an IP address of the authentication server from the target network when the mobile is still outside the target network and then to establish a security association with the authentication agent in the target network. This requires the mobile to discover the parameters of various network elements in the target network ahead of time so that the mobile can communicate with these network elements to establish proactive security associations. We describe several approaches for a mobile to discover the network elements in target networks before moving into these target networks. We also describe how network discovery can help provide fast-handoff using secure pre-authentication and proactive IP address acquisition during handover between different access networks.","","CD-ROM:978-1-4244-0425-4; POD:978-1-4244-0424-7","10.1109/BROADNETS.2006.4374392","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4374392","","Authentication;Data security;Databases;Information retrieval;Information security;Mobile communication;Network servers;Protocols;Web server;Wireless LAN","message authentication;mobile radio;radio access networks;telecommunication security;wireless LAN","homogeneous-heterogeneous access network;mobile radio;network discovery mechanism;proactive IP address acquisition;proactive handoff mechanism;secure pre-authentication;wireless LAN","","6","3","19","","","1-5 Oct. 2006","","IEEE","IEEE Conference Publications"
"3-Way-Trees: A Similarity Search Method for High-Dimensional Descriptor Matching","E. Valle; M. Cord; S. Philipp-Foliguet","&#201;quipes Traitement des Images et du Signal &#191; ETIS UMR CNRS 8051. valle@ensea.fr","2007 IEEE International Conference on Image Processing","20071112","2007","1","","I - 173","I - 176","In this paper we look into the problem of high-dimensional local descriptor matching for image identification on cultural databases, presenting an important improvement over a classic method, the KD-tree. Our method, the 3-way tree, uses redundant, overlapping sub-trees, in order to avoid the boundary effects that disrupt the KD-tree in higher dimensionalities, achieving more precision for the same querying times.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4378919","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378919","descriptor matching;image identification;kd-tree;local descriptors;nearest neighbor search","Cultural differences;Image databases;Information retrieval;Nearest neighbor searches;Phase detection;Robustness;Search methods;Signal processing;Visual databases;Voting","image matching;search problems;trees (mathematics);visual databases","boundary effects;cultural databases;high-dimensional descriptor matching;image identification;similarity search methods","","1","","8","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"SQS: Similarity Query Scheme for Peer-to-Peer Databases","J. P. Ahullo; P. G. Lopez; M. S. Artigas; A. F. G. Skarmeta","Universitat Rovira i Virgili, Tarragona, Spain. jordi.pujol@urv.cat","2007 12th IEEE Symposium on Computers and Communications","20071112","2007","","","1107","1112","Similarity search is a hot research topic on peer-to-peer systems. In this paper we present SQS, a similarity query scheme for peer-to-peer databases. In this work we provide a novel linearization mechanism that enables structured queries without the burden of a global information maintenance scheme. The system offers exact match and range searches to multidimensional data. SQS employs Cyclone, a hierarchical overlay that is able to build disjoint clusters in terms of network latency and enables data search load balancing by caching per cluster scheme. Finally, we show the good properties of SQS through representative simulation results.","1530-1346;15301346","CD-ROM:978-1-4244-1521-2; POD:978-1-4244-1520-5","10.1109/ISCC.2007.4381532","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381532","","Cyclones;Databases;Delay;Image retrieval;Information retrieval;Large-scale systems;Load management;Multidimensional systems;Peer to peer computing;Routing","distributed databases;peer-to-peer computing;query processing;resource allocation","data search load balancing;information maintenance scheme;novel linearization mechanism;peer-to-peer database;similarity query scheme","","1","","10","","","1-4 July 2007","","IEEE","IEEE Conference Publications"
"3D Content-Based Retrieval in Artwork Databases","D. Gorisse; M. Cord; M. Jordan; S. Philipp-Foliguet; F. Precioso","ETIS - CNRS, Universit&#233; de Cergy-Pontoise / ENSEA, 6 avenue du Ponceau, F95014 Cergy-Pontoise - France","2007 3DTV Conference","20071112","2007","","","1","4","In this paper, we present first results obtained in the frame of the EROS-3D project, which aims at dealing with a collection of artwork 3D models, i.e. visualize them, classify them and compare them. Some 3D descriptors are used, in association with our active learning search engine RETIN. 3D features are described as well as our new system of classification and retrieval of objects, which we called RETIN-3D.","2161-2021;21612021","CD-ROM:978-1-4244-0722-4; POD:978-1-4244-0721-7","10.1109/3DTV.2007.4379434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379434","3D model;active learning;cultural heritage;indexing;retrieval","Content based retrieval;Databases;Displays;Gravity;Histograms;Information retrieval;Principal component analysis;Search engines;Venus;Visualization","image retrieval;learning (artificial intelligence);search engines;vocabulary","active learning search engine;artwork databases;content-based retrieval;cultural heritage;descriptors;indexing","","5","","9","","","7-9 May 2007","","IEEE","IEEE Conference Publications"
"A Reference of Intentions for Better Medical Communication","N. Matsumoto; A. Tokosumi","Graduate School of Decision Science and Technology, Tokyo Institute of Technology, 2-12-1 Ookayama, Meguro-ku, Tokyo JAPAN 1528552. matsun@valde.titech.ac.jp","2007 IEEE/ICME International Conference on Complex Medical Engineering","20071112","2007","","","453","456","Within the medical settings, multiple intelligent agents (including doctors, nurses, patients, and various medical information systems) exist that differ in terms of backgrounds, knowledge bases, and their usage of terminology. In order to support safe and effective medical communication between these multiple intelligent agents, this paper reviews and discusses some ontological studies of verbal communication. In medical settings, breakdowns in verbal communication can sometimes occur between the parties involved. Two important conditions for successful verbal communication are (a) recognizing the speaker's intention and (b) understanding the contents of their verbal message. To realize better medical communication, it is essential to respond appropriately to both intentions and content. Recently, there has been an emergence of ontological research seeking to systematize knowledge to the aim of effective information exchange on the World Wide Web. We survey recent trends in ontological studies of verbal communication related to intentions and discuss some contributions for safer medical communication. This paper also introduces our intention reference system that is based on cognitive analysis of performative verbs, which convey utterance intentions. This system illustrates the differences in nuance between intentions such as [tanomu (ask for)] and [youkyuu-suru (request)], which could contribute in reducing communication errors.","","CD-ROM:978-1-4244-1078-1; POD:978-1-4244-1077-4","10.1109/ICCME.2007.4381775","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381775","better communication;conversation;ontology;reference system;speaker intention","Data mining;Face recognition;Information retrieval;Intelligent agent;Knowledge management;Medical information systems;Natural language processing;Ontologies;Performance analysis;Text recognition","biomedical communication;information dissemination;medical information systems;ontologies (artificial intelligence);speech","Japanese language;World Wide Web;information exchange;medical communication;medical information systems;multiple intelligent agents;ontological studies;utterance intentions;verbal communication","","1","","8","","","23-27 May 2007","","IEEE","IEEE Conference Publications"
"A Practical Image Retrieval Framework for Tourism Industry","S. Zhao; V. Potdar; E. Chang","Digital Ecosystems and Business Intelligence Institute, Curtin University of Technology, Perth, Australia. Email: s.zhao@curtin.edu.au","2007 IEEE International Symposium on Industrial Electronics","20071105","2007","","","2928","2932","Image retrieval (IR) is one of the most exciting and fastest growing research domains in the field of multimedia technology. And in the industrial ecosystems, images of products, activities, marketing materials etc are needed to be managed and fetched in an efficient way to support and facilitate business processes. Current techniques for IR including keyword based, content based and ontology based image retrieval have several unsolved issues. We promote the ontology based IR approach and focus on two issues: firstly, the difficulty in constructing ontologies of images for those industries without ontology professionals, and, secondly, none of the existing approaches consider image content ranking in search results. In this paper, we propose a practical framework to tackle these issues by introducing an abstract image ontology that serves as a blueprint of image ontologies and by incorporating a concept instance ranking scheme to allow ranking of each of the contents expressed in images, thus providing extra information for IR process. An application scenario in the tourism industry area is also presented.","2163-5137;21635137","CD-ROM:978-1-4244-0755-2; POD:978-1-4244-0754-5","10.1109/ISIE.2007.4375079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375079","","Australia;Content based retrieval;Ecosystems;Feedback;Image databases;Image retrieval;Information retrieval;Internet;Ontologies;Rivers","content-based retrieval;image retrieval;multimedia computing;ontologies (artificial intelligence);travel industry","business process support;concept instance ranking scheme;content based image retrieval;image content ranking;image retrieval framework;keyword based image retrieval;multimedia technology;ontology based image retrieval;tourism industry","","0","","20","","","4-7 June 2007","","IEEE","IEEE Conference Publications"
"Content-Based Image Retrieving Improved by Pixel-Based Search","I. Stojanovic; S. Bogdanova; M. Bogdanov","Faculty of Electrical Engineering and Information Technologies, Karpos II b.b., P.O. Box 574, 1000 Skopje, Macedonia. Phone: (389) 2-306 2224 Fax: (389) 2-306 4262 E-mail: Igor.Stojanovic@feit.ukim.edu.mk","2007 14th International Workshop on Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services","20071112","2007","","","377","380","Content-based search of images followed by pixel-based search from databases is considered. The pixel-based search is performed using Stone's method of progressive wavelet correlation. The interface between the Matlab workspace and the database is described. The Oracle Database and the IBM QBIC are used for investigation purposes.","","CD-ROM:978-961-248-029-5; POD:978-961-248-036-3","10.1109/IWSSIP.2007.4381120","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381120","Content/pixel based search;database;image retrieval;normalized correlation","Biomedical imaging;Content based retrieval;Humans;Image databases;Image retrieval;Information retrieval;Pixel;Shape;Spatial databases;Visual databases","content-based retrieval;correlation methods;image retrieval;mathematics computing;relational databases;visual databases;wavelet transforms","IBM QBIC;Matlab workspace;Oracle Database;Stones method;content-based image retrieval;image database;pixel-based search;progressive wavelet correlation","","1","","6","","","27-30 June 2007","","IEEE","IEEE Conference Publications"
"Vector Model Based Indexing and Retrieval of Handwritten Medical Forms","H. Cao; V. Govindaraju","University at Buffalo, Amherst, NY","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","88","92","A vector model based information retrieval of handwritten medical forms is presented in this paper. In order to improve the IR performance on the erroneous output of handwriting recognition (HR) systems, a variation of the vector model is made to estimate the number of occurrences of terms from word segmentation and recognition probabilities. IR Tests show that our approach outperforms the retrieval of ordinary HR text in terms of mean average precision (MAP), R-Precision, and interpolated 11-point precisions.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378681","","Frequency;Handwriting recognition;Image databases;Image recognition;Image retrieval;Image segmentation;Indexing;Information retrieval;Medical services;Optical character recognition software","handwriting recognition;image recognition;image segmentation;information retrieval;medical computing;medical information systems;probability","handwriting recognition system;handwritten medical form retrieval;vector model based indexing;word image segmentation;word recognition probability","","3","","16","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"A Efficient Method for Motion Retrieval Based on Mocap Database","J. Xiang; H. Zhu","School of Information and Electronic Engineering, ZheJiang University of Science and Technology, HangZhou, China. freexiang@gmail.com","2007 IEEE International Conference on Control and Automation","20071105","2007","","","595","599","In this paper, a novel approach is presented for motion retrieval based on double-reference inde(DRI) in motion capture(mocap) database. Due to high dimensionality of motion's feature, first 3D temporal-spatial features and their keyspaces of each human joint are extracted. Then DRI is build based on selecting a small set of representative motion clips in the database by these features. So we can get candidate set by abandoning most unrelated motion clips to reduce the number of costly similarity measure significantly. Experimental results show that our methods are effective for motion data retrieval in large database.","1948-3449;19483449","CD-ROM:978-1-4244-0818-4; POD:978-1-4244-0817-7","10.1109/ICCA.2007.4376425","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376425","3D temporal-spatial feature;Mocap database;Motion Retrieval;reference index","Data mining;Educational institutions;Feature extraction;Humans;Indexes;Indexing;Information retrieval;Joints;Large-scale systems;Spatial databases","feature extraction;image motion analysis;image retrieval;information retrieval systems;temporal databases;visual databases","3D temporal-spatial feature extraction;Mocap database;double-reference index;motion capture database;motion retrieval system;unrelated motion clips","","0","","5","","","May 30 2007-June 1 2007","","IEEE","IEEE Conference Publications"
"Weighted Co-SVM for Image Retrieval with MVB Strategy","X. Zhang; J. Cheng; H. Lu; S. Ma","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100080, China. xyzhang@nlpr.ia.ac.cn","2007 IEEE International Conference on Image Processing","20071112","2007","4","","IV - 517","IV - 520","In relevance feedback, active learning is often used to alleviate the burden of labeling by selecting only the most informative data. Traditional data selection strategies often choose the data closest to the current classification boundary to label, which are in fact not informative enough. In this paper, we propose the moving virtual boundary (MVB) strategy, which is proved to be a more effective way for data selection. The co-SVM algorithm is another powerful method used in relevance feedback. Unfortunately, its basic assumption that each view of the data be sufficient is often untenable in image retrieval. We present our weighted co-SVM as an extension of co-SVM by attaching weight to each view, and thus relax the view sufficiency assumption. The experimental results show that the weighted co-SVM algorithm outperforms co-SVM obviously, especially with the help of MVB data selection strategy.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4380068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4380068","Active learning;Image retrieval;Multi-view learning;Relevance feedback;Support vector machine","Feedback;Image retrieval;Information retrieval;Labeling;Laboratories;Learning systems;Machine learning;Pattern recognition;Support vector machine classification;Support vector machines","image retrieval;learning (artificial intelligence);relevance feedback;support vector machines","MVB strategy;active learning;data selection;image retrieval;moving virtual boundary;relevance feedback;support vector machine;weighted co-SVM","","2","","5","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Fast Method for Joint Retrieval and Identification of JPEG Coded Images Based on DCT Sign","F. Arnia; I. Iizuka; M. Fujiyoshi; H. Kiya","Department of Electrical Engineering, Tokyo Metropolitan University, 6-6, Asahigaoka, Hino City, Tokyo, 191-0065, Japan.","2007 IEEE International Conference on Image Processing","20071112","2007","2","","II - 229","II - 232","We propose a fast method to retrieve images from a JPEG image database. The proposed method is intended to retrieve similar images, including their compressed versions, and to identify exact match and all compressed versions of a query image simultaneously. Similarity level is measured based on the non-zero DCT coefficients signs, which serve as features. The method is simple and fast because the DCT coefficients signs can be obtained by only entropy-decoding the bitstream. There is no need to calculate features explicitly. Furthermore, the method is robust to JPEG compression, particularly for image identification purpose.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379134","DCT coefficient sign;copy detection;image identification;image retrieval;image similarity","Computational complexity;Decoding;Discrete cosine transforms;Entropy;Image coding;Image databases;Image retrieval;Information retrieval;Robustness;Transform coding","copy protection;data compression;decoding;discrete cosine transforms;entropy codes;image coding;image retrieval;image sequences;visual databases","DCT coefficient sign;JPEG image coding;JPEG image database;bitstream entropy-decoding;copy detection;image compression;image retrieval","","9","","10","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Design and Implement of Personalize Meta-Search Engine Based on FCA","J. Tang; Y. J. Du; K. L. Wang","School of Mathematica & Computer engineering, Xihua University, Chengdu 610039, China. E-MAIL: juan","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","7","","4026","4031","Recent years, the research of the meta-search engines becomes hotspot due to the unified access of this kind of search engines to users. It is convenient and efficient for an ordinary user to invoke multiple search engines and identify useful documents from returned results. In this paper, MySearch, a new personalize meta-search engine is introduced based on formal concept analysis (FCA). It extracts user's information implicitly and provides real-time response by re-ranking the results. Re-ranking is done by using concept lattice built by user's usage logs and the results of source engine. Finally, the improved re-rank is returned by MySearch. Experimental results show our method has a significant improvement on satisfactory degree in terms of the search result and user's requirement.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370850","Concept lattices;Formal concept analysis;Meta-search engine;Personalize","Cybernetics;Data mining;Databases;Design engineering;Information retrieval;Information science;Lattices;Machine learning;Metasearch;Search engines","Web sites;information retrieval;search engines","concept lattice;formal concept analysis;information extraction;personalize meta-search engine;real-time response;user usage log","","0","","12","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"A Characteristic Inter Database Retrieval System and Its Collaborative Mechanism","J. Ye; M. Chen","College of Information Technology, Shanghai Fisheries University, Shanghai, P. R. China. jcye@stmail.shfu.edu.cn","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","62","67","Some of the universities or special libraries will have special requirements for the information query. According to some of the special requirements, a multi-agent coalition inter database retrieval system architecture is constructed to support unified access to multiple databases. This paper gives the details about the model structure of collaborative agent and the collaborative mechanism in the system.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365413","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365413","Inter Database Retrieval System;Multi-Agent;collaboration","Access protocols;Aquaculture;Collaboration;Educational institutions;Frequency;Information retrieval;Internet;Search engines;Software libraries;Spatial databases","information retrieval systems;multi-agent systems;query processing","collaborative agent;multiagent coalition interdatabase retrieval system","","0","","8","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"An Adaptive Multiscaling Imaging Technique Based on a Fuzzy-Logic Strategy for Dealing With the Uncertainty of Noisy Scattering Data","M. Benedetti; A. Casagranda; M. Donelli; A. Massa","Univ. of Trento, Trento","IEEE Transactions on Antennas and Propagation","20071112","2007","55","11","3265","3278","Inverse scattering data, even though collected in a controlled-environment, are usually corrupted by noise, which strongly affects the effectiveness of the reconstruction techniques because of the intrinsic ill-positioning of the problem. In order to limit the effects of the noise on the retrieval procedure and to fully exploit the information content available from the measurements, an innovative inversion scheme based on the integration of an adaptive multiscale procedure and a fuzzy-logic (FL)-based strategy is proposed. The main goal of the approach is to reduce the complexity of the problem as well as to improve the robustness of the inversion procedure allowing an accurate retrieval of the profile under test. The approach is based on an adaptive, coarse-to-fine successive representation of the unknown object obtained through a sequence of reconstructions where suitable weighting coefficients are defined through a FL. Key elements of the theoretical analysis are given and several numerical examples, concerned with synthetic and experimental test cases, illustrate the consequences of the proposed approach in terms of both resolution accuracy and robustness as well as computational costs.","0018-926X;0018926X","","10.1109/TAP.2007.908791","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4380525","Fuzzy-logic;inverse scattering;iterative multiscaling approach;microwave imaging","Computational efficiency;Content based retrieval;Image reconstruction;Information retrieval;Inverse problems;Noise measurement;Robustness;Scattering;Testing;Uncertainty","electromagnetic wave scattering;fuzzy logic;image denoising;image reconstruction;image representation;image resolution;microwave imaging","adaptive iterative multiscaling imaging;electromagnetic wave scattering;fuzzy-logic strategy;image reconstruction;image resolution;inverse noisy scattering data uncertainty;microwave imaging;object representation","","9","","40","","","Nov. 2007","","IEEE","IEEE Journals & Magazines"
"A Mobile Interface for Hierarchical Information Visualization and Navigation","J. Hao; K. Zhang","Department of Computer Science, The University of Texas at Dallas, Richardson, TX 75083-0688, USA. jxh049000@utdallas.edu","2007 IEEE International Symposium on Consumer Electronics","20071112","2007","","","1","7","There is a dramatic increase in the population who use mobile computing devices. Though the hardware becomes more powerful, effective support for information rendering on small screens very much lags behind. To display hierarchical information, researchers have proposed many algorithms for desktop screen visualization. Such algorithms are generally divided into connection and enclosure. Connection approach displays hierarchy with a clear structure but consume display area. Enclosure can maximally utilize the screen space but the layout is essentially implicit. This paper describes a new Radial Edgeless Tree (RELT) for visualizing hierarchical data on palm sized devices. The aim of RELT is to combine the advantages of connection and enclosure approaches. By recursively partitioning the display area, this technique maximizes the space usage. The structural clarity of layout can be reached by arranging location of non-overlapping regions. RELT can be adapted for visualizing structural information for various applications.","0747-668X;0747668X","CD-ROM:978-1-4244-1110-8; POD:978-1-4244-1109-2","10.1109/ISCE.2007.4382214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382214","Hierarchy visualization;Mobile interface;Music classification;Navigation;Usability","Computer interfaces;Computer science;Data visualization;Design methodology;Displays;Information retrieval;Mobile computing;Navigation;Power generation economics;Usability","data visualisation;mobile computing;notebook computers;rendering (computer graphics);screens (display);user interfaces","data visualization;desktop screen visualization;information navigation;information rendering;information visualization;mobile computing devices;mobile interface;palm sized devices;radial edgeless tree","","7","1","11","","","20-23 June 2007","","IEEE","IEEE Conference Publications"
"Hash Mapping Strategy for Improving Retrieval Effectiveness in Semantic Cache System","M. R. Sumalatha; V. Vaidehi; A. Kannan; M. Rajasekar; M. Karthigaiselvan","Department of Information Technology, Anna University, Chennai-600044, India. Email: rsumalatha@yahoo.com","2007 International Conference on Signal Processing, Communications and Networking","20071105","2007","","","233","237","The emergence of Web applications has encouraged us to have much recent research on data caching. In our proposed work we have given a new strategy, dynamic hash mapping technique which gives fast information retrieval semantically with the cache. This increases the speed up in the information retrieval for semantic caching which is a method of data caching where it is rule based. The semantic caching technology can help to improve the efficiency of XML query processing in the Web environment. Unlike from the traditional tuple or page-based caching systems, semantic caching systems exploit the idea of reusing cached query results to answer new queries based on the query containment and rewriting techniques. The primary contribution of this article is to revisit the performance of semantic caching by this new mapping technique, which increases the efficiency in information retrieval in the semantic caching system. Our proposed method gives enhanced performance by reduced network traffic and searches the exact information from a large database, which is crucial, in a range of applications, especially in network-constrained environments","","CD-ROM:1-4244-0997-7; POD:1-4244-0996-9","10.1109/ICSCN.2007.350737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4156619","","Costs;Data structures;Databases;Information analysis;Information retrieval;Information technology;Query processing;Service oriented architecture;Telecommunication traffic;XML","Internet;XML;cache storage;query processing;relational databases","Web applications;XML query processing;cached query;data caching;dynamic hash mapping strategy;information retrieval effectiveness;network traffic;page-based caching system;query containment;rewriting techniques;semantic cache system;tuple caching system","","2","","10","","","22-24 Feb. 2007","","IEEE","IEEE Conference Publications"
"Question Answering System of Confucian Analects based on Pragmatics Information and Categories","Y. Yang; S. Liu; S. Kuroiwa; F. Ren","Department of Information Science and Intelligent Systems, Tokushima University / Tokushima, Japan, yang@is.tokushima-u.ac.jp","2007 International Conference on Natural Language Processing and Knowledge Engineering","20071029","2007","","","361","366","This paper constructs a question answering system of Confucian Analects. As a result of context change and the difference of words' connotation between modern Chinese and ancient Chinese, the accuracy of content-based retrieval and category-based retrieval in the classical literature is quite low. In view of this, the paper has established the categories and pragmatics information base for Confucian Analects. It also proposes a retrieval method based on pragmatics information and categories. To increase accuracy and efficiency, the category keyword collection and the question type keyword table are established as well. When the system recognize the type and category of the user's question, it uses key word semantic matching. Namely, the category keyword collection and the question type keyword table are separately used to decide the category and the type. The experiments evidenced the effectiveness of answer extraction approach based on pragmatics information specific to in query with deep meaning.","","CD-ROM:978-1-4244-1611-0; POD:978-1-4244-1610-3","10.1109/NLPKE.2007.4368056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4368056","","Content based retrieval;Data mining;Databases;Globalization;Information retrieval;Information science;Information technology;Intelligent systems;Modems;Natural languages","content-based retrieval;natural language processing","Chinese language;Confucian Analect;category-based retrieval;content-based retrieval;pragmatics information;question answering system;question type keyword table","","1","","10","","","Aug. 30 2007-Sept. 1 2007","","IEEE","IEEE Conference Publications"
"Retrieval of Handwritten Lines in Historical Documents","L. Schomaker","","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","594","598","This study describes methods for the retrieval of handwritten lines of text in a historical administrative collection. The goal is to develop generic methods for bootstrapping the retrieval system from a tabula rasa starting condition, i.e., the virtual absence of labeled samples. By exploiting the currently available computing power and the fact that computation takes place off line, it should be possible to provide a good starting point for statistical learning methods. In this manner, a closed collection can be incrementally indexed. A cross-correlation method on line-strip images is presented and results are compared to feature-based methods.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4376984","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376984","","Handwriting recognition;Humans;Image quality;Image retrieval;Image segmentation;Information retrieval;Labeling;Optical character recognition software;Strips;Text recognition","administrative data processing;document image processing;feature extraction;handwriting recognition;information retrieval;learning (artificial intelligence);text analysis","bootstrapping;cross-correlation method;feature-based methods;handwritten line retrieval;handwritten text;historical administrative collection;historical documents;line-strip images;statistical learning;tabula rasa starting condition","","1","","7","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Harmonic Silhouette Matching for 3D Models","A. Makadia; M. Visontai; K. Daniilidis","Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, 19104, USA. makadia@cis.upenn.edu","2007 3DTV Conference","20071112","2007","","","1","4","The ability to perform fast retrieval from a database of 3D models is becoming a growing necessity as the number of models in circulation is rapidly increasing. Several of the many existing methods dealing with this problem consider similarity measures based on visual appearance. This idea of comparing models using their respective silhouettes performs well on a number of benchmarks, but comes with a few inherent limitations, the biggest of which is that at the time of comparison all possible rotational alignments between two models need to be considered. In this paper we present two retrieval algorithms based on a silhouette representation. The first method shows how model similarity can be computed using fast harmonic matching techniques, and the second method reduces the problem to fast vector differencing using rotation-invariant properties of the representations.","2161-2021;21612021","CD-ROM:978-1-4244-0722-4; POD:978-1-4244-0721-7","10.1109/3DTV.2007.4379399","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379399","","Availability;Harmonic analysis;Image reconstruction;Information retrieval;Information science;Large-scale systems;Laser modes;Performance evaluation;Solid modeling;Visual databases","image matching;image retrieval;visual databases","database retrieval;fast vector differencing;harmonic matching;harmonic silhouette matching;rotation-invariant properties;three-dimensional models;visual appearance","","1","","15","","","7-9 May 2007","","IEEE","IEEE Conference Publications"
"Multimedia Content Segmentation Based on Speaker Recognition","J. Babu; V. Pathari","Motorola India Pvt. Ltd., No. 66/1, Plot No.5, Bagmane, Techpark, C. V. Raman Nagar Post, Bangalore- 560093, India. Email: jasinekb@gmail.com","2007 International Conference on Signal Processing, Communications and Networking","20071105","2007","","","16","19","Many recent works attempt to index multimedia data based on characteristics such as speaker identity and emotional content. In this work, speaker segmentation is performed on movies to extract the shots in which the target actor is speaking. A case of speaker identification on conversational speech under noisy conditions-this work is organized into two phases; an audio classification phase, for the removal of non-speech content, followed by a speaker recognition phase. Along with the speaker models, Gaussian mixture models are constructed for sound effects like fight sequences and drum beats to refine the removal of non-speech sounds. Results prove the effectiveness of this deviation from the conventional methods","","CD-ROM:1-4244-0997-7; POD:1-4244-0996-9","10.1109/ICSCN.2007.350672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4156575","","Acoustic noise;Data mining;Face detection;Indexing;Information retrieval;Loudspeakers;Motion pictures;Multimedia databases;Speaker recognition;Speech processing","Gaussian processes;audio signal processing;multimedia communication;speaker recognition","Gaussian mixture model;multimedia content segmentation;speaker recognition","","0","","13","","","22-24 Feb. 2007","","IEEE","IEEE Conference Publications"
"A Greedy Performance Driven Algorithm for Decision Fusion Learning","D. Joshi; M. Naphade; A. Natsev","Department of Computer Science and Engineering, The Pennsylvania State University, University Park, PA 16802. djoshi@cse.psu.edu","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 25","VI - 28","We propose a greedy performance driven algorithm for learning how to fuse across multiple classification and search systems. We assume a scenario when many such systems need to be fused to generate the final ranking. The algorithm is inspired from Ensemble Learning but takes that idea further for improving generalization capability. Fusion learning is applied to leverage text, visual and model based modalities for 2005 TRECVID query retrieval task. Experiments using the well established retrieval effectiveness measure of mean average precision reveal that our proposed algorithm improves over naive baseline (fusion with equal weights) as well as over Caruana's original algorithm (NACHOS) by 36% and 46% respectively.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379512","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379512","TRECVID;hill climbing;late fusion;mean average precision","Boosting;Computer science;Fuses;Fusion power generation;Information retrieval;Machine learning;Machine learning algorithms;Robustness;Search engines;Testing","image classification;image fusion;image retrieval;learning (artificial intelligence)","decision fusion learning;greedy performance;image classification;query retrieval task;search system","","1","","11","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"A Universal Algorithm for Random-Access Compression and Applications for Annotated DNA Sequences","G. Korodi; I. Tabus","Institute of Signal Processing, Tampere University of Technology, P.O Box 553, FIN-33101 Tampere, Finland, e-mail: gergely.korodi@tut.fi","2007 IEEE International Workshop on Genomic Signal Processing and Statistics","20071029","2007","","","1","4","This article introduces a universal algorithm for creating compressed archives with instantaneous access and decodability of designated functional elements. A special-purpose variant is also given to enhance performance for DNA sequences. The resulting algorithm integrated into an earlier scheme achieves a marked improvement at the randomly accessible coding for annotated genome files, while completely retaining the functionality of instantaneous retrieval of all feature entries.","2150-3001;21503001","CD-ROM:978-1-4244-0999-0; POD:978-1-4244-0998-3","10.1109/GENSIPS.2007.4365843","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365843","","Algorithm design and analysis;Bioinformatics;Context modeling;DNA;Decoding;Genomics;Information retrieval;Sequences;Signal design;Signal processing algorithms","DNA;biology computing;decoding;genetics;information retrieval;molecular biophysics","annotated DNA sequences;annotated genome files;compressed archives;decodability;information retrieval;instantaneous access;random-access compression;randomly accessible coding;universal algorithm","","0","","8","","","10-12 June 2007","","IEEE","IEEE Conference Publications"
"Redundant Bit Vectors for Robust Indexing and Retrieval of Electronic Ink","K. Chellapilla; J. Platt","Microsoft Resear","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","387","391","This paper presents a redundant bit vector approach for indexing and retrieval of handwritten words captured using an electronic pen or tablet. Handwritten words (cursive or print) are first segmented into strokes and each stroke is featurized using a neural network. Oriented principal component analysis (OPCA) is used for dimensionality reduction while ensuring robustness to handwriting variation (noise). Redundant bit vectors are used to index the resulting low dimensional representations for efficient storage and retrieval. Experimental results on large datasets with 898,652 handwritten words show good retrieval performance that is robust to handwriting variations and generalizes well over different writers and writing styles.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378737","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378737","","Chebyshev approximation;Handwriting recognition;Indexing;Information retrieval;Ink;Neural networks;Noise robustness;Personal digital assistants;Principal component analysis;Shape","indexing;information retrieval;neural nets;principal component analysis","electronic ink retrieval;electronic pen;handwritten words indexing;handwritten words retrieval;neural network;oriented principal component analysis;redundant bit vectors;robust indexing;writing styles","","1","","10","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Mobile-Host-Centric Transport Protocol for EAST Experiment","Y. Shu; W. Ge; N. Jiang; Y. Kang; J. Luo","Department of Computer Science, Tianjin University, Tianjin 300072, China. YTSHU@TJU.EDU.CN","2007 15th IEEE-NPSS Real-Time Conference","20071112","2007","","","1","8","Some physics researchers retrieve EAST experiment data using TCP in wireless local area network (WLAN). TCP is the most commonly used transport control protocol. It assumes that every packet loss is caused by network congestion and invokes congestion control and avoidance. TCP's blind congestion control results in degraded performance in the lossy wireless networks. In a wireless network, mobile hosts have first-hand knowledge of the lossy wireless links; therefore, mobile stations can make better transmission control based on the known status of wireless link. In this paper, we proposed a new mobile-host-centric transport protocol (MCP) that integrates the characteristics of sender-centric and receiver-centric transport control schemes. MCP shifts most control policies to the mobile host side. The general behavior of MCP is similar to the TCP, but by utilizing the local information collecting from the mobile node in WLAN, MCP allows for better congestion control and loss recovery. Specifically, we designed a cross-layer implementation of MCP and ran it on NS-2. With valuable MAC (Medium Access Control) layer feedback information, MCP is able to distinguish packet loss caused by wireless random errors from network congestion more clearly and can perform a more accurate congestion control. We did extensive simulations of MCP on various WLAN scenarios, and the results show that the throughput of MCP with cross-layer feedback is higher than that of TCP Reno and Westwood.","","CD-ROM:978-1-4244-0867-2; POD:978-1-4244-0866-5","10.1109/RTC.2007.4382748","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382748","","Degradation;Feedback;Information retrieval;Performance loss;Physics;Propagation losses;Radio access networks;Transport protocols;Wireless LAN;Wireless networks","access protocols;mobile radio;telecommunication congestion control;transport protocols;wireless LAN","EAST experiment;Experimental Advanced Superconducting Tokamak;MAC layer feedback information;MCP;TCP;WLAN;congestion control;medium access control;mobile stations;mobile-host-centric transport protocol;transmission control protocol;transport control scheme;wireless local area network","","0","","14","","","April 29 2007-May 4 2007","","IEEE","IEEE Conference Publications"
"Research on the Architecture of Ontology-based Context-aware Application in Pervasive Environment","Y. Dong; Q. Li; Y. Shi","School of Computer Science and Technology, Shandong University, Jinan, P.R. China; School of Computer Science and Technology, Xuzhou Normal University, Xuzhou, P.R. China. dongyongquan@mail.sdu.edu.cn","2007 2nd International Conference on Pervasive Computing and Applications","20071029","2007","","","128","132","With the prevalence of pervasive devices, plenty of applications need to support context awareness. Due to the heterogeneity of context information, it is necessary to provide a set of common vocabularies with shared semantics. Based on above requirements, the paper presents an architecture of ontology-based context-aware application in pervasive environment. In the architecture context processing is regarded as a separated module which conforms to the principle of software engineering, ""seperation of concerns "". The architecture enables applications to focus on the information that they desire, and reduces the need to worry about how contextual information is retrieved. In order to reuse of the ontology, the paper designs two level's ontology-generic ontology and domain-specific ontology which unifies semantics of context information. At last an example scenario of home domain is given to illustrate the rationality and effectiveness of the architecture.","","CD-ROM:978-1-4244-0971-6; POD:978-1-4244-0970-9","10.1109/ICPCA.2007.4365425","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365425","Context;Context-aware Application;Ontology;Pervasive Computing","Application software;Computer architecture;Computer science;Context awareness;Context modeling;Information retrieval;Ontologies;Pervasive computing;Software engineering;Vocabulary","information retrieval;ontologies (artificial intelligence);software engineering;ubiquitous computing;vocabulary","architecture context processing;information retrieval;ontology-based context-aware application;pervasive devices;software engineering;vocabulary","","0","","12","","","26-27 July 2007","","IEEE","IEEE Conference Publications"
"Curvelets Based Queries for CBIR Application in Handwriting Collections","G. Joutel; V. Eglin; S. Bres; H. Emptoz","LIRIS, INSA-Lyon, F-69621, France","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","649","653","This paper presents a new use of the curvelet transform as a multiscale method for indexing linear singularities and curved handwritten shapes in documents images. As it belongs to the wavelet family, this representation can be useful at several scales of details. The proposed scheme for handwritten shape characterization targets to detect oriented and curved fragments at different scales so as to compose an unique signature for each handwritten analyzed samples. In this way, curvelets coefficients are used as a representation tool for handwriting when searching in large manuscripts databases by finding similar handwritten samples. Current results of ancient manuscripts retrieval are very promising with very satisfying precisions and recalls.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4376995","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376995","","Anisotropic magnetoresistance;Content based retrieval;Databases;Image retrieval;Image storage;Indexing;Information retrieval;Robustness;Shape;Writing","content-based retrieval;curvelet transforms;handwriting recognition;image retrieval","content based image retrieval;curved handwritten shape;curvelet based queries;curvelet transform;documents image;handwriting collection;handwritten shape characterization;indexing linear singularities","","7","","11","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"View-Based Web Page Retrieval using Interactive Sketch Query","Y. Watai; T. Yamasaki; K. Aizawa","Dept. of Frontier Informatics, The University of Tokyo","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 357","VI - 360","We propose a novel view-based Web page retrieval system that enables a user to search Web pages using a visual query, namely the user's freehand sketch. We believe the proposed method will suit retrieval from a set of web pages such as a user's local browsing history. The system aims to help the user revisit a particular Web page without using query words. Using color signature features and Earth-Mover's distance, the system evaluates the similarity between web pages and the user's sketch drawn via the GUI of the system. In order to accelerate the interaction, the results of the similarity evaluations are shown immediately after the user draws each stroke of the sketch, with the results being interactively reordered. Experiments using our prototype system showed that users find their target pages after only a few strokes. Experimental results for inexperienced users showed that 71% of search tasks were completed within one minute, using the prototype system. The median time for the tasks was 40 seconds.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379595","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379595","content-based image retrieval;query by sketch;user interaction;user interface;web page retrieval","Data mining;Feature extraction;HTML;History;Humans;Image analysis;Image retrieval;Information retrieval;Prototypes;Web pages","content-based retrieval;image retrieval;interactive systems","Web page retrieval;content-based image retrieval;interactive sketch query;search Web;user interaction","","0","1","10","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Fast Approximate Matching of Programs for Protecting Libre/Open Source Software by Using Spatial Indexes","A. J. M. Molina; T. Shinohara","Kyushu Institute of Technology, Japan","Seventh IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2007)","20071029","2007","","","111","122","To encourage open source/libre software development, it is desirable to have tools that can help to identify open source license violations. This paper describes the implementation of a tool that matches open source programs embedded inside pirate programs. The problem of binary program matching can be approximated by analyzing the similarity of program fragments generated from low-level instructions. These fragments are syntax trees that can be compared by using a tree distance function. Tree distance functions are generally very costly. Sequentially calculating the similarities of fragments with them becomes prohibitively expensive. In this paper we experimentally demonstrate how a spatial index can be used to substantially increase matching performance. These techniques allowed us to do exhaustive experiments that confirmed previous results on the subject. The paper also introduces the novel idea of using information retrieval techniques for calculating the similarity of bags of program fragments. It is possible to identify programs even when they are heavily obfuscated with the innovative approach described here.","","POD:0-7695-2880-5","10.1109/SCAM.2007.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4362903","","Artificial intelligence;Data mining;Fingerprint recognition;Information retrieval;Licenses;Nearest neighbor searches;Open source software;Protection;Spatial databases;Spatial indexes","information retrieval;public domain software;security of data","binary program matching;information retrieval;libre software protection;low-level instructions;open source license violations;open source software protection;program fast approximate matching;program fragment analysis;program identification;software tools;spatial indexes;syntax trees;tree distance function","","0","3","48","","","Sept. 30 2007-Oct. 1 2007","","IEEE","IEEE Conference Publications"
"Similarity-based Image Retrieval by Self-Organizing Map with Refractoriness","K. Nagashima; M. Nakada; Y. Osana","Tokyo University of Technology, Hachioji, Tokyo, 192-0982, Japan","2007 International Joint Conference on Neural Networks","20071029","2007","","","2647","2652","In this research, we proposed a similarity-based image retrieval by self-organizing map with refractoriness. In the self-organizing map with refractoriness, the plural neurons in the map layer corresponding to the input can fire sequentially because of the refractoriness. The image retrieval system using the self-organizing map with refractoriness makes use of this property in order to retrieve plural similar images. In this image retrieval system, as the image feature, not only color information but also spectrum, impression words and key words are employed. We carried out a series of computer experiments and confirmed that the effectiveness of the proposed system.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371376","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371376","","Artificial neural networks;Associative memory;Biological neural networks;Brain modeling;Chaos;Fires;Image retrieval;Information processing;Information retrieval;Neurons","content-based retrieval;feature extraction;image retrieval;information retrieval systems;self-organising feature maps","image feature;impression words;key words;plural neurons;plural similar image retrieval;refractoriness property;self-organizing map;similarity-based image retrieval system","","12","","13","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"Dominant Color Structure Descriptor for Image Retrieval","K. M. Wong; L. M. Po; K. W. Cheung","Department of Electronic Engineering, City University of Hong Kong, 83 Tat Chee Avenue, Kowloon, Hong Kong SAR of China. kmwong@ee.cityu.edu.hk","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 365","VI - 368","A new dominant color structure descriptor (DCSD) is proposed in this paper. It is designed to provide an efficient way to represent both color and spatial structure information with single compact descriptor. The descriptor combines the compactness of dominant color descriptor (DCD) and the retrieval accuracy of color structure descriptor (CSD) to enhance the retrieval performance in a highly efficient manner. The feature extraction and similarity measure of the descriptor are designed to address the problems of the existing descriptors while utilize the advantages of them. Experimental results show that DCSD has a significant improvement on both retrieval performance and descriptor size over DCD. An eight-color DCSD (DCSD 8) gives an averaged normalized modified retrieval rate (ANMRR) of 0.0993 using MPEG-7 common color dataset, outperforming compact configurations of scalable color descriptor and color structure descriptor with smaller descriptor size.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379597","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379597","Content Based Image Retrieval;Dominant Color Structure Descriptor","Cross layer design;Feature extraction;Histograms;Image databases;Image retrieval;Information retrieval;MPEG 7 Standard;Multimedia databases;Multimedia systems;Quantization","feature extraction;image colour analysis;image matching;image representation;statistical analysis","color image representation;dominant color structure descriptor;feature extraction;image matching;image retrieval;similarity measure algorithm;spatial structure information;structure histogram","","6","","9","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"A New Method for Writer Identification and Verification Based on Farsi/Arabic Handwritten Texts","F. Nejad; M. Rahmati","Amirkabir University of Technology (Tehran Polytechnic), Tehran, Iran.","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","829","833","Most studies about writer identification are based on English documents and to our knowledge no research has been reported on Farsi or Arabic documents. In this paper, we have proposed a method for off-line writer identification and verification based on Farsi handwriting, which is text-dependent. Based on the idea that has been presented in the previous studies, here we assume handwriting as texture image and after normalization step, the Gabor filters are applied to image and then new features are extracted. Substantially, the property of proposed method is using of the bank of Gabor filters which is appropriate for the structure of Farsi handwritten texts and vision system. Also, a new method for feature extraction from output of Gabor filters is proposed which is based on moments and nonlinear transform. In this paper, with definition a confidence criterion, a new method for writer verification is proposed. Evaluation of other methods and proposed method demonstrates that proposed method achieves better performance on Farsi handwritten from 40 peoples.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377031","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377031","","Data mining;Feature extraction;Filtering;Gabor filters;Hidden Markov models;Information retrieval;Machine vision;Probability distribution;Shape;Writing","Gabor filters;handwriting recognition;image texture;text analysis","Arabic handwriting;Farsi handwriting;Farsi/Arabic handwritten texts;Gabor filters;texture image;writer identification;writer verification","","10","","15","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Block DCT Vectors Construction for Face Retrieval Based on Genetic Algorithm","Y. Xie; L. Setia; H. Burkhardt","Nanjing University of Information Science and Technology, China","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","3","","770","775","Effective feature extraction is one of the most important steps in content-based face image retrieval applications. A vectors construction method for face retrieval based on block DCT and genetic algorithm is proposed in this paper. According to this method, the block DCT coefficients are firstly selected according to the histogram of each block image, and then genetic algorithm is used to select and construct ultimate discriminative vectors for image retrieval. The experimental results on AR gray face database show that the proposed method is robust to facial situations of pose, expression, illumination and partial occlusion, and can get better performance of retrieval accuracy and speed simultaneously.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.286","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344613","","Content based retrieval;Discrete cosine transforms;Feature extraction;Genetic algorithms;Histograms;Image databases;Image retrieval;Information retrieval;Lighting;Robustness","content-based retrieval;discrete cosine transforms;face recognition;feature extraction;genetic algorithms;image retrieval","block DCT coefficients;content-based face image retrieval;face retrieval;feature extraction;genetic algorithm;image histogram;vectors construction","","2","","11","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"Wavelet-Based Texture Retrieval using Independent Component Analysis","R. Zhang; X. P. Zhang; L. Guan","Department of Electrical and Computer Engineering, Ryerson University, 350 Victoria Street, Toronto, ON, Canada, M5B 2K3","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 341","VI - 344","In this paper, a novel approach to texture retrieval using independent component analysis (ICA) in wavelet domain is proposed. It is well recognized that the wavelet coefficients in different subbands are statistically correlated, resulting in the fact that the product of the marginal distributions of wavelet coefficients is not accurate enough to characterize the stochastic properties of texture images. To tackle this problem, we employ (ICA) in feature extraction to decorrelate the analysis coefficients in different subbands, followed by modeling the marginal distributions of the separated sources using generalized Gaussian density (GGD), and perform similarity measure based on the maximum likelihood criterion. It is demonstrated by simulation results on a database consisting of 1776 texture images that the proposed method improve the accuracy of texture image retrieval in terms of average retrieval rate, compared with the traditional method using GGD for feature extraction and Kullback-Leibler divergence for similarity measure.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379591","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379591","Content-based image retrieval;generalized gaussian density;independent component analysis;mutual information;texture retrieval","Character recognition;Feature extraction;Image recognition;Image retrieval;Independent component analysis;Information retrieval;Stochastic processes;Wavelet analysis;Wavelet coefficients;Wavelet domain","Gaussian processes;feature extraction;image texture;independent component analysis;maximum likelihood estimation;statistical distributions;wavelet transforms","feature extraction;generalized Gaussian density;independent component analysis;marginal distribution;maximum likelihood criterion;stochastic properties;wavelet-based texture retrieval","","4","","5","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Multi-document Summarization Based on Cohesion with Disambiguation","Y. Chen; X. Lou","China Jiliang University, China","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","2","","232","236","The mass information of Internet boosts the requirement for quick and accurate methods of information acquisition. To fulfill the requirement for high quality multi-document system, this paper investigates using lexical cohesion as a model of multiple-documents written in Chinese to generate an indicative, moderately fluent summary. The method constructs lexical chains with polysemant disambiguation and identifies strong chains first. An unique disambiguation method that combined the sense definitions in the dictionary with the expanded context of the words is presented. Then significant sentences that extracted from each document are merged, and redundant information are recognized and removed. Finally, the summary is generated in chronological order. Evaluation results show that the performance of the presented system is obviously better than that of the baseline system.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.484","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344351","","Artificial intelligence;Cognitive science;Computational linguistics;Data mining;Dictionaries;Educational institutions;Humans;Information retrieval;Information systems;Internet","natural languages;text analysis","information acquisition;multi-document summarization;polysemant disambiguation","","0","","16","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"Searching for Tables in Digital Documents","Y. Liu; K. Bai; P. Mitra; C. Giles","Pennsylvania State University","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","934","938","Tables are ubiquitous. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. Current search engines do not allow the end-user to search for relevant tables. In this paper, we describe TableSeer, an automatic table extraction and search engine system. TableSeer crawls scientific documents, identifies documents with tables, extracts tables from documents, indexes them and enables end-users to search for tables. We also propose an extensive set of medium-independent metadata for tables representation. Given a query, TableSeer ranks the returned results using an innovative ranking algorithm - TableRank. Our results show that TableSeer outperforms popular search engines, such as Google Scholar when the end-user seeks for tables.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377052","","Data mining;Displays;Economic indicators;Floods;Image retrieval;Indexing;Information retrieval;Internet;Search engines;Software libraries","search engines;ubiquitous computing","TableSeer;automatic table extraction;digital documents;innovative ranking algorithm;medium-independent metadata;search engine system;statistical data","","2","","8","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"A P2P-based Network Model Design and Its Application on Educational Information & Resources","Y. Guo-xiang; Z. Yan-jun","Information College, Jiman University, Guangzhou, China. Email: yao@jnu.edu.cn","2007 IEEE International Conference on Control and Automation","20071105","2007","","","1106","1109","Sometimes we will search varieties of resources in the network, yet it is difficult to meet some special demands properly by using general searching-engine. P2P network is an effective method of sharing and searching resources. We have proposed a model of P2P-based resource network (PBRN), through analyzing the basic architecture and resource sharing property of P2P network. PBRN is a distributed, virtual, dynamic and loose pure P2P network and it is composed by resource entity freely. And we have analyzed its application on educational information and resources with real examples.","1948-3449;19483449","CD-ROM:978-1-4244-0818-4; POD:978-1-4244-0817-7","10.1109/ICCA.2007.4376531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376531","Entity Graph;P2P-Based Resource Network (PBRN);Peer-to-peer (P2P) Network;Propagate;Resource Entity;Servent","Automatic control;Design automation;Educational institutions;IP networks;Information analysis;Information retrieval;Internet;Network servers;Resource management;Web server","Internet;educational computing;peer-to-peer computing","P2P-based network model design;distributed P2P network;dynamic P2P network;educational information;educational resources;resource sharing;searching engine;virtual P2P network","","0","","12","","","May 30 2007-June 1 2007","","IEEE","IEEE Conference Publications"
"Research on Graphical Annotation and Retrieval of Image Semantic","Q. Q. Li; A. M. Yang","College of Computer and Communication, Hunan University of Technology, Zhuzhou 412008, China. E-MAIL: fengxinzi5101@163.com","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","3","","1565","1569","In order to solve the existing problems in image semantic retrieval, a whole content annotation and retrieval framework of image semantic is presented. Based on semantic description scheme in MPEG-7 standard, the graphical structure is used to implement content description of image semantic, and then the path information of semantic description graph is used to implement image retrieval. Experimental results indicate that the retrieval method presented in this paper can efficiently implement image retrieval based on semantic.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370394","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370394","Graphical Annotation;Image semantic;MPEG-7;Semantic Retrieval","Content based retrieval;Cybernetics;Educational institutions;Image converters;Image retrieval;Informatics;Information retrieval;MPEG 7 Standard;Machine learning;Natural languages","image retrieval","MPEG-7;graphical annotation;graphical structure;image retrieval;image semantic","","1","","9","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"Using Statistical Machine Translation Model to Improve Domain-Specific Metasearch Engines","K. Lin","Software School, Xiamen University, Xiamen, Fujian, China. khlin@xmu.edu.cn","2007 IEEE International Conference on Control and Automation","20071105","2007","","","1837","1839","In order to improve the recall of the domain-specific information retrieval, an efficient query expansion mechanism is proposed for the metasearch engines. This mechanism uses the statistical machine translation model to compute the relevance between general query words and domain-relevant query words and dispatches the expanded queries to component search engines. The key ingredient of translation model is the expectation maximization (EM) algorithm. The experimental results show that the proposed expansion mechanism is a desirable and efficient method to improve the domain-relevance of the pages returned by a metasearch engine.","1948-3449;19483449","CD-ROM:978-1-4244-0818-4; POD:978-1-4244-0817-7","10.1109/ICCA.2007.4376679","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376679","EM algorithm;metasearch engine;statistical machine translation","Automatic control;Automation;Information resources;Information retrieval;Internet;Metasearch;Natural languages;Research and development;Search engines;Web pages","computational linguistics;expectation-maximisation algorithm;language translation;query formulation;search engines","EM algorithm;Internet;domain-relevant query words;domain-specific information retrieval;domain-specific metasearch engines;expectation maximization algorithm;query expansion mechanism;statistical machine translation model","","0","","7","","","May 30 2007-June 1 2007","","IEEE","IEEE Conference Publications"
"Efficient memory-based FFT processors for OFDM applications","Chin-Long Wey; Shin-Yo Lin; Wei-Chien Tang","Department of Electrical Engineering, National Central University, Jhongli, Taiwan","2007 IEEE International Conference on Electro/Information Technology","20071105","2007","","","345","350","This paper presents Radix-2 memory-based FFT (MBFFT) processors. Taking the advantages of low hardware cost of MBFFT architectures, this study improves the speed performance. The improvement was achieved by an efficient memory retrieval scheme for reducing the control complexity and a clock scheme with parallel structures for reducing the cycle times and latency. Instead of using dual-port memories for data storage and retrieval, our designs use single-port memories with pre-fetch registers for hardware cost reduction. Based on the pre-layout simulation results, the core area of the developed MBFFT is 2.04 mm with the maximal work frequency of 198 MHz for N=8192 points (24 bits per word).","2154-0357;21540357","CD-ROM:978-1-4244-0941-9; POD:978-1-4244-0940-2","10.1109/EIT.2007.4374475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4374475","","Clocks;Computer architecture;Costs;Delay;Discrete Fourier transforms;Hardware;Information retrieval;Memory architecture;OFDM;Registers","OFDM modulation;fast Fourier transforms;microprocessor chips;parallel architectures","OFDM;clock scheme;data storage;frequency 198 MHz;memory retrieval;parallel structure;pre-fetch register;radix-2 memory-based FFT processor;size 2.04 mm","","9","","13","","","17-20 May 2007","","IEEE","IEEE Conference Publications"
"Fiber Tracking on HARDI Data using Robust ODF Fields","H. E. Assemlal; D. Tschumperle; L. Brun","GREYC IMAGE (CNRS UMR 6072), 6 Bd Mar&#233;chal Juin, 14050 Caen Cedex, France","2007 IEEE International Conference on Image Processing","20071112","2007","3","","III - 133","III - 136","We present a robust method to retrieve neuronal fibers in human brain white matter from high-angular resolution MRI (HARDI datasets). Contrary to classical fiber-tracking techniques done on the traditional 2nd-order tensor model (DTI) which may lead to truncated or biased estimated diffusion directions in case of fiber crossing configurations, we propose here a more complex approach based on a variational estimation of orientation diffusion functions (ODF) modeled with spherical harmonics. This kind of model can correctly retrieve multiple fiber directions corresponding to underlying intra-voxel fibers populations. Our technique is able to consider the Rician noise model of the MRI acquisition in order to better estimate the white matter fiber tracks. Results on both synthetic and real human brain white matter HARDI datasets illustrate the effectiveness of the proposed approach.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379264","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379264","Diffusion MRI;Fiber-tracking;ODF estimation;Variational methods and PDEs","Diffusion tensor imaging;High-resolution imaging;Humans;Image resolution;Image retrieval;Information retrieval;Magnetic resonance imaging;Rician channels;Robustness;Tensile stress","biomedical MRI;brain;estimation theory;harmonic analysis;image resolution;medical image processing;neurophysiology;optical tracking;tensors;variational techniques","Rician noise model;high-angular resolution MRI;human brain white matter;neuronal fiber tracking;orientation diffusion function;spherical harmonics;tensor model;variational estimation","","5","","16","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"An Indexing Method for Graphical Documents","S. Tabbone; D. Zuwala","University Nancy2-INPL","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","789","793","In this paper, a method to browse symbols into graphical documents is presented. More precisely, we propose a combined filtering and indexing mechanism that retrieves in an efficient way the most similar symbols to a given input query. For a database of 200000 symbols the retrieval time has been divided by a factor of 4, 5 compared to a linear search.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377023","","Algorithm design and analysis;Delay;Density measurement;Filtering;Image databases;Image retrieval;Indexing;Information retrieval;Skeleton;Subspace constraints","document handling;indexing;information filtering","database;filtering mechanism;graphical documents;indexing method;similar symbol retrieval;symbol browsing","","4","","12","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Towards Circuit Design with Auto-Associative Memories","K. Deh; S. Prasad; V. Markovic","School of Electrical and Computer Engineering Northeastern University Boston, MA 02115, USA Email: kdeh@ece.neu.edu","2007 8th International Conference on Telecommunications in Modern Satellite, Cable and Broadcasting Services","20071105","2007","","","271","274","In this paper, we discuss current and possible methods for synthesizing circuits using autoassociative neural networks. The ability of these networks to automatically converge to stable states when given an unknown input makes them suitable for storing and retrieving design information for a circuit. We demonstrate the use of the Hopfield network for realizing an amplifier and a filter. The limitations of the Hopfield network and the possible use of other neural network architectures are discussed in conclusion.","","CD-ROM:978-1-4244-1468-0; POD:978-1-4244-1467-3","10.1109/TELSKS.2007.4375990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375990","","Circuit synthesis;Filters;Genetic programming;Hopfield neural networks;Information retrieval;Network synthesis;Neural networks;Neurons;Robustness;USA Councils","Hopfield neural nets;amplifiers;circuit CAD;content-addressable storage;filters;neural net architecture","Hopfield neural network architecture;amplifier design;autoassociative memory;autoassociative neural network;circuit design;circuit synthesis;filter design","","0","","12","","","26-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"Boosting of Maximal Figure of Merit Classifiers for Automatic Image Annotation","F. Vella; C. H. Lee; S. Gaglio","Istituto di Calcolo e Reti ad Alte Prestazioni, I.C.A.R.-C.N.R., Sede di Palermo. vella@pa.icar.cnr.it","2007 IEEE International Conference on Image Processing","20071112","2007","2","","II - 217","II - 220","Visual information contained in a scene is very complex and can be represented with multiple features describing aspects of the entire information. In this paper we propose a boosting approach to automatic image annotation by building strong classifiers based on multiple collections of weak concept classifiers with each collection focused on a single visual feature. The weak classifiers are trained with a maximal figure-of-merit learning approach. By exploiting multiple features the boosting procedure allows to build classifiers able to pick the most discriminative feature for the specific annotation task.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379131","Boosting;Image Annotation;Maximal Figure of Merit;Multi-Topic;Text Categorization","Boosting;Data mining;Entropy;Image converters;Image representation;Information retrieval;Layout;Linear discriminant analysis;Magneto electrical resistivity imaging technique;Text categorization","image representation;learning (artificial intelligence);text analysis","automatic image annotation;boosting approach;image scene;maximal figure-of-merit learning;merit classifiers;multiple feature image representation;visual information","","5","","17","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"High-Density Scanning for Virtual Heritage and Archeology : Reproduction and Restoration","J. Doi; K. Shimizu; W. Sato","The University of Tokyo","2007 3DTV Conference","20071112","2007","","","1","4","Surface models with unorganized triangular meshes have already been built based on the ""retrieving topology from the ranged surface data,"" procedure using, for example, Delaunay tessellations from the scanned cloud points. The procedure is widely used; however, when a high-density scanning is required, ranging error goes beyond the scanning interval and high-precision reconstruction becomes impossible. To overcome the problem, a topology pre-assigned high-resolution (up to 1-10 mum) modeling procedure, is proposed for the irregular and complicated artifacts in shape. This procedure enables one always to construct a watertight model with potentially infinitesimal spatial resolutions for complete reproduction of the artifacts in shape and color, to manipulate the shape of the resulting model for virtual redesigning, restoration, cosmetic surgery, morphological anthropology and counterfeit detection. This proposal is practicable for all kinds of objects, and producing a versatile successive 3D shape manipulation.","2161-2021;21612021","CD-ROM:978-1-4244-0722-4; POD:978-1-4244-0721-7","10.1109/3DTV.2007.4379403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379403","Biomedical engineering;computer graphics;design automation;geometric modeling;machine vision;shape measurement","Clouds;Counterfeiting;Information retrieval;Proposals;Shape;Spatial resolution;Surface morphology;Surface reconstruction;Surgery;Topology","image resolution;image retrieval;medical image processing;virtual reality","3D shape manipulation;archeology;high-density scanning;topology retrieval;triangular meshes;virtual heritage;watertight model","","0","","8","","","7-9 May 2007","","IEEE","IEEE Conference Publications"
"Exponential Bidirectional Associative Memory Based on Small-world Architecture","M. Wang; S. Chen","Hohai University, China; Nanjing University of Aeronautics & Astronautics, China","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","1","","391","397","Most of neural associative memory models have fully- connected structure. However, from both the neurobiological viewpoint and the hardware implementation perspective, it seems more reasonable to consider such networks with both predominantly local connectivity and sparsely global connectivity. Small- world architecture (SWA) provides an interesting approach to implementing this design. Recently, Bohland et al. have introduced SWA into Hopfield network and verified the effectiveness of such structure. However, such an attention has not yet been paid to another important type of associative memories, i.e. bidirectional associative memory (BAM). At the first glance, the introduction of SWA to BAM seems straightforward and easy. However, in fact, the randomly-rewiring procedure done for Hopfield network, cannot be directly applied to BAM or its variants because of their multi-layer structure and bidirectional associative mode. In this paper, we use an artful transformation to overcome the difficulty and propose a new exponential BAM model based on SWA, called SWeBAM. It is a brand-new extension to Hopfield network based on SWA in both associative mode and storage capacity. The experimental results demonstrate that with comparatively much fewer inter-neural connections, SWeBAM can obtain almost equivalent performances to the original exponential BAM (eBAM) in both storage capacity and error-correction capability. Moreover, owing to the introduction of SWA, SWeBAM can be realized more easily in hardware than eBAM.","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344220","","Associative memory;Biological neural networks;Computer architecture;Computer science;Content based retrieval;Hebbian theory;Humans;Information retrieval;Magnesium compounds;Neural network hardware","content-addressable storage;neural chips","Hopfield network;bidirectional associative memory;exponential bidirectional associative memory;neural associative memory models;small-world architecture;sparsely global connectivity","","0","","21","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"How Stochastic Noise Helps Memory Retrieval in a Chaotic Brain.","C. Molter; U. Salihoglu; H. Bersini","Dynamics of Emergent Intelligence, RIKEN-Brain Science Institute, Japan. cmolter@brain.riken.jp","2007 International Joint Conference on Neural Networks","20071029","2007","","","1458","1463","How information and more particularly memories are represented in brain dynamics is still an open question. By using, a recurrent network receiving a stimulus dependent external input, the author have demonstrated that the use of limit cycle attractors encompass in many aspects the limitations of fixed points attractors and gives better correspondence with neurophysiological facts. A main outcome of this perspective is the apparition of chaotic trajectories: instead of the overwhelming presence of spurious attractors, chaotic dynamics shows up when facing ambiguous situation. Contrary to intuition, many studies reported that noise can have beneficial effects in dynamical systems. Inline with these studies, it is demonstrated here how stochastic noise can make converge the chaotic trajectories to the expected limit cycle attractors and accordingly can improve consequently the retrieval performance. This noise induced retrieval enhancement is very dependent of the type of chaotic dynamics which is function of how information is coded.","2161-4393;21614393","CD-ROM:978-1-4244-1380-5; POD:978-1-4244-1379-9","10.1109/IJCNN.2007.4371173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371173","","Artificial neural networks;Biological neural networks;Chaos;Encoding;Information retrieval;Limit-cycles;Neurons;Noise level;Signal to noise ratio;Stochastic resonance","brain;chaos;limit cycles;neurophysiology;recurrent neural nets;stochastic processes;time-varying systems","brain dynamics;chaotic brain;chaotic dynamics;dynamical systems;limit cycle attractors;memory retrieval;neurophysiological facts;recurrent network;stochastic noise","","1","","34","","","12-17 Aug. 2007","","IEEE","IEEE Conference Publications"
"A Fast Keyword-Spotting Technique","L. Li; S. J. Lu; C. L. Tan","National University of Singapore","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071112","2007","1","","68","72","In order to capture the content of an imaged document but avoid the time-consuming full-scale OCR which is fragile to handle touching characters, a fast and segmentation- free keyword spotting method is proposed in this paper. The keyword spotting method is based on word shape coding technique. The proposed coding scheme has little ambiguity, and can be swiftly executed. It is a promising technique to boost better document image retrieval. The strength of the proposed method is demonstrated in a document filtering experiment. The experimental results show that document filtering based on the proposed method is more than 20 times faster than the one based on OCR, and has comparable filtering accuracy.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4378677","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378677","","Character recognition;Computer science;Filtering;Image coding;Image retrieval;Image segmentation;Information retrieval;Optical character recognition software;Shape;Software libraries","document image processing;image retrieval;optical character recognition","document filtering;document image retrieval;full-scale OCR;imaged document;segmentation-free keyword spotting method;touching characters;word shape coding technique","","2","","8","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Combining Novel features for Content Based Image Retrieval","K. S. S. Prakash; R. Sundaram","Department of Computer Science and Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, Tamil Nadu, India-641 105. Phone: +91(422) 2656422 Fax: +91(422) 2656274 E-mail: ssai@acm.org","2007 14th International Workshop on Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services","20071112","2007","","","373","376","Recent advances in technology have made fabulous amount of multimedia information on the Internet. Content based image retrieval (CBIR) aims at retrieving the similar set of images from the database corresponding to the users query. To do so, a set of features need to be extracted from the images and stored in the database prior to accepting users query. In this paper we introduce a system for interactive image retrieval that combines different approaches to feature based queries. The proposed technique is tested on two types of datasets, first one consisting of different animals and the second dataset consisting of birds, flowers and buildings. The retrieval accuracy is 96.4% and 92.2% for a database size of 530 each.","","CD-ROM:978-961-248-029-5; POD:978-961-248-036-3","10.1109/IWSSIP.2007.4381119","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381119","Fuzzy color Histogram;Phase Congruency;Tamura Features","Animals;Content based retrieval;Data mining;Image databases;Image retrieval;Information retrieval;Internet;Multimedia databases;Spatial databases;Testing","content-based retrieval;feature extraction;image retrieval;interactive systems;visual databases","Internet;content based interactive image retrieval;feature extraction;image database;multimedia information;user query","","3","","8","","","27-30 June 2007","","IEEE","IEEE Conference Publications"
"Comparing four Methods to Select Keywords that Use n-Grams to Generate Summaries","L. L. Bando; K. R. Lopez; M. T. Vidal; D. V. Ayala; B. B. Martinez","Benemerita Universidad Autonoma de Puebla, Mexico","Electronics, Robotics and Automotive Mechanics Conference (CERMA 2007)","20071029","2007","","","724","728","In this paper an algorithm to generate document extracts is proposed. This extract is composed of the most significative sentences of the current document. These sentences are chosen by considering their similitude with a so-denominated virtual paragraph (VP). The VP is formed by the key words that are obtained by the four methods that use n-grams, employed in this research. The experiments are performed over 100 documents of the DUC-2000 collection.","","POD:0-7695-2974-7","10.1109/CERMA.2007.4367773","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4367773","","Automation;Automotive engineering;Data mining;FCC;Frequency;Genetic algorithms;Information retrieval;Logic;Robots;Vocabulary","abstracting;document handling;information retrieval","document extracts generation;information retrieval;keyword selection;n-grams;summary generation;virtual paragraph","","0","","6","","","25-28 Sept. 2007","","IEEE","IEEE Conference Publications"
"Propagating Image-Level Part Statistics to Enhance Object Detection","S. Gao; J. H. Lim; Q. Sun","Institute for Infocomm Research (I2R), A-Star, Singapore, 119613. gaosheng@i2r.a-star.edu.sg","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 181","VI - 184","The bag-of-words approach has become increasingly attractive in the fields of object category recognition and scene classification, witnessed by some successful applications [5, 7, 11]. Its basic idea is to quantize an image using visual terms and exploit the image-level statistics for classification. However, the previous work still lacks the capability of modeling the spatial dependency and the correspondence between patches and object parts. Moreover, quantization always deteriorates the descriptive power of the patch feature. This paper proposes the hidden maximum entropy (HME) approach for modeling the object category. Each object is modeled by the parts, each having a Gaussian distribution. The spatial dependency and image-level statistics of parts are modeled through the maximum entropy approach. The model is learned by an EM-IIS (expectation maximum embedded with improved iterative scaling) algorithm. Our experiments on the Caltech 101 dataset show that the relative reduction of equal error rate of 23.5 % and relative improvement of AUC (area under ROC) of 22.0 % are obtained when comparing the HME based system with the ME based baseline system.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379551","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379551","EM-IIS;area under ROC;bag-of-words;hidden maximum entropy;object detection","Entropy;Gaussian distribution;Information retrieval;Iterative algorithms;Layout;Object detection;Object recognition;Quantization;Statistical distributions;Statistics","Gaussian distribution;image classification;iterative methods;maximum entropy methods;object detection","Gaussian distribution;bag-of-words approach;hidden maximum entropy approach;image classification;image-level part statistics;improved iterative scaling algorithm;object detection","","1","","12","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Adaptive Cluster-Distance Bounding for Nearest Neighbor Search in Image Databases","S. Ramaswamy; K. Rose","Signal Compression Lab, Dept. of Electrical and Computer Engineering, University of California, Santa Barbara, CA 93106 - 9560. rsharadh@ece.ucsb.edu","2007 IEEE International Conference on Image Processing","20071112","2007","6","","VI - 381","VI - 384","We consider approaches for exact similarity search in a high dimensional space of correlated features representing image datasets, based on principles of clustering and vector quantization. We develop an adaptive cluster distance bound based on separating hyperplanes, that complements our index in selectively retrieving clusters that contain data entries closest to the query. Experiments conducted on real data-sets confirm the efficiency of our approach with random disk IOs reduced by 100X, as compared with the popular vector approximation-file (VA-File) approach, when allowed (roughly) the same number of sequential disk accesses, with relatively low preprocessing storage and computational costs.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379601","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379601","Similarity search;clustering;multi-dimensional indexing;retrieval;vector quantization","Biomedical imaging;Image databases;Image storage;Indexing;Information retrieval;Multimedia databases;Nearest neighbor searches;Search engines;Spatial databases;Vector quantization","image retrieval;indexing;pattern clustering;vector quantisation;visual databases","adaptive cluster distance bounding;image database;image retrieval;indexing;nearest neighbor search;vector quantization","","2","2","7","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"Data Quality Monitoring Framework for the ATLAS Experiment at the LHC","Corso-Radu; S. Kolos; H. Hadavand; R. Kehoe; M. Hauschild","California Univ., Irvine","2007 15th IEEE-NPSS Real-Time Conference","20071112","2007","","","1","5","Data quality monitoring (DQM) is an important and integral part of the data taking process of HEP experiments. DQM involves automated analysis of monitoring data through user-defined algorithms and relaying the summary of the analysis results while data is being processed. When DQM occurs in the online environment, it provides the shifter with current run information that can be used to overcome problems early on. During the offline reconstruction, more complex analysis of physics quantities is performed by DQM, and the results are used to assess the quality of the reconstructed data. The ATLAS data quality monitoring framework (DQMF) is a distributed software system providing DQM functionality in the online environment. The DQMF has a scalable architecture achieved by distributing execution of the analysis algorithms over a configurable number of DQMF agents running on different nodes connected over the network. The core part of the DQMF is designed to only have dependence on software that is common between online and offline (such as ROOT) and therefore is used in the offline framework as well. This paper describes the main requirements, the architectural design, and the implementation of the DQMF.","","CD-ROM:978-1-4244-0867-2; POD:978-1-4244-0866-5","10.1109/RTC.2007.4382779","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382779","","Algorithm design and analysis;Computerized monitoring;Control systems;Data analysis;Databases;Histograms;Information retrieval;Large Hadron Collider;Physics;Relays","data acquisition;high energy physics instrumentation computing","ATLAS experiment;HEP experiments;data quality monitoring framework;distributed software system;user-defined algorithms","","1","","10","","","April 29 2007-May 4 2007","","IEEE","IEEE Conference Publications"
"Image Retrieval using Long Term Learning Relevance Feedback","B. Wang; M. W. He; S. Wang; M. Wang","College of Mathematics and Computer Science, Hebei University, Baoding 071002, China. E-MAIL: wangbing@hbu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","7","","3985","3990","Relevance feedback which is used in content-based image retrieval (CBIR) has been considered as the efficient technique to improve the retrieval performances. The traditional relevance feedback technique demonstrates a disability to use the users' historical feedback information sufficiently gotten together by the system in the former retrieval processes when initiating a new query session. In this paper, an approach to relevance feedback based on long-term learning strategy using the historical retrieval information is presented for the content-based image similarity retrieval. The approach adopts a semantic covering set constructed dynamically to deposit the users' historical retrieval information produced in previous retrieval processes, and predicts the semantic correlation between the images in database and query sample according to the historical retrieval information when carrying out a new query session. The performance of an experimental image retrieval system using this approach is evaluated on a database of around 3000 images. Empirical results demonstrate improved performances compared with the CBIR system with the traditional relevance feedback technique using the same image similarity measure.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370843","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370843","Content-based Image similarity retrieval;Image semantic;Relevance feedback;Semantic covering set","Content based retrieval;Cybernetics;Educational institutions;Feedback;Image databases;Image retrieval;Information retrieval;Machine learning;Performance evaluation;Spatial databases","content-based retrieval;image retrieval;relevance feedback","content-based image similarity retrieval;historical retrieval information;long term learning relevance feedback;query sample;query session;semantic covering set","","1","","9","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"TV-Anytime Metadata Authoring Tool for Personalized Broadcasting Services","S. J. Yang; J. W. Kang; D. S. Jun; M. J. Kim; H. K. Lee","Electronics and Telecommunications Research Institute","2007 IEEE International Symposium on Consumer Electronics","20071112","2007","","","1","6","In spite of a useful services based on TV-anytime metadata, the metadata authoring still remains as a harassing and time consuming task. In this paper, we present a design and implementation of a TV-anytime metadata authoring tool to provide personalized broadcasting services. For easily authoring metadata, the proposed metadata authoring tool provides the following key functionalities: metadata visualization, media access, and semi-automatic method for editing segment related metadata.","0747-668X;0747668X","CD-ROM:978-1-4244-1110-8; POD:978-1-4244-1109-2","10.1109/ISCE.2007.4382191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382191","Authoring Tool;Broadcasting Service;Metadata;TV-Anytime","Audio recording;Broadcast technology;Content based retrieval;Data visualization;Digital multimedia broadcasting;Humans;Information retrieval;Multimedia communication;TV broadcasting;Watches","television broadcasting","TV-anytime metadata authoring tool;broadcasting services;media access;metadata visualization;semiautomatic method","","0","","16","","","20-23 June 2007","","IEEE","IEEE Conference Publications"
"Diagnostics and engine management/numeric database","S. Hidalgo","Infotech Aerospace Services, Inc., 699 Industrial Avenue Isabela, PR 00662, USA","2007 IEEE Autotestcon","20071105","2007","","","462","468","Aerospace services (IAS) is an aerospace engineering service provider with a customer that develops commercial and military jet engines. Each type of engine has unique maintenance parameters that must be constantly monitored as part of the standard maintenance-tracking plan. Engine data and error codes captured during a flight cycle (from takeoff to landing) are downloaded and stored in a maintenance database that is implemented in Oracle. This data is analyzed for performance and engine health (safety). The design engineers develop a thermodynamic model (also known as the numerics) for each engine model and or application. These Numerics contain the thresholds and ranges that will be used to generate the error conditions. Each engine model requires a different set of Numerics due to differences in operation and possible error conditions that exist between different engine models. These error conditions could be in the form of a scalar, a vector or a matrix. The maintenance engineers must associate the correct Numerics with the engine model and run diagnostic software to analyze the data retrieved, in order to improve performance and detect maintenance issues before they become safety concerns. IAS has developed an elastic oracle database design that collects the customized set of numerics generated by the design engineers so that the software needs only the engine model in order to retrieve the data in the format necessary for the diagnostic analysis. This paper discusses the design of the database used to normalize the numerics data produced from the customer's design engineers and how this general approach applies to many other applications that could handle different products.","1088-7725;10887725","CD-ROM:978-1-4244-1239-6; POD:978-1-4244-1238-9","10.1109/AUTEST.2007.4374254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4374254","","Aerospace engineering;Data analysis;Data engineering;Databases;Design engineering;Engines;Information retrieval;Military aircraft;Performance analysis;Software safety","","","","0","1","6","","","17-20 Sept. 2007","","IEEE","IEEE Conference Publications"
"Microcalcification Classification Assisted by Content-Based Image Retrieval for Breast Cancer Diagnosis","Y. Yang; L. Wei; R. M. Nishikawa","Dept. of Electrical and Computer Engineering, Illinois Institute of Technology, 3301 S. Dearborn Street, Chicago, IL 60616","2007 IEEE International Conference on Image Processing","20071112","2007","5","","V - 1","V - 4","In this paper we propose a microcalcification classification scheme, assisted by content-based mammogram retrieval, for breast cancer diagnosis. We recently developed a machine learning approach for mammogram retrieval where the similarity measure between two lesion mammograms is modeled after expert observers. In this work we investigate how to use retrieved similar cases as references to improve the performance of a numerical classifier. Our rationale is that by adap-tively incorporating local proximity information into a classifier, it can help improve its classification accuracy, thereby leading to an improved ""second opinion"" to radiologists. Our experimental results on a mammogram database demonstrate that the proposed retrieval-driven approach with an adaptive support vector machine (SVM) could improve the classification performance from 0.78 to 0.82 in terms of the area under the ROC curve.","1522-4880;15224880","CD-ROM:978-1-4244-1437-6; POD:978-1-4244-1436-9","10.1109/ICIP.2007.4379750","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4379750","adaptive support vector machine;image retrieval;microcalcification classification","Biomedical computing;Biomedical engineering;Breast cancer;Content based retrieval;Image databases;Image retrieval;Information retrieval;Machine learning;Support vector machine classification;Support vector machines","content-based retrieval;image classification;image retrieval;learning (artificial intelligence);mammography;medical image processing;support vector machines","adaptive support vector machine;breast cancer diagnosis;classification accuracy;content-based image retrieval;content-based mammogram retrieval;local proximity information;machine learning;mammogram database;microcalcification classification;similarity measure","","1","","8","","","Sept. 16 2007-Oct. 19 2007","","IEEE","IEEE Conference Publications"
"A Data Mining Approach to Reading Order Detection","M. Ceci; M. Berardi; G. Porcelli; D. Malerba","University of Bari","Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)","20071105","2007","2","","924","928","Determining the reading order for layout components extracted from a document image can be a crucial problem for several applications. It enables the reconstruction of a single textual element from texts associated to multiple layout components and makes both information extraction and content-based retrieval of documents more effective. A common aspect for all methods reported in the literature is that they strongly depend on the specific domain and are scarcely reusable when the classes of documents or the task at hand changes. In this paper, we investigate the problem of detecting the reading order of layout components by resorting to a data mining approach which acquires the domain specific knowledge from a set of training examples. The input of the learning method is the description of the ""chains"" of layout components defined by the user. Only spatial information is exploited to describe a chain, thus making the proposed approach also applicable to the cases in which no text can be associated to a layout component. The method induces a probabilistic classifier based on the Bayesian framework which is used for reconstructing either single or multiple chains of layout components. It has been evaluated on a set of document images.","1520-5363;15205363","POD:0-7695-2822-8","10.1109/ICDAR.2007.4377050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4377050","","Bayesian methods;Content based retrieval;Data mining;Encoding;Image recognition;Image reconstruction;Information retrieval;Labeling;Learning systems;Predictive models","Bayes methods;content-based retrieval;data mining;document image processing;learning (artificial intelligence);pattern classification;probability","Bayesian framework;content-based retrieval;data mining approach;document image;domain specific knowledge;information extraction;layout components;learning method;probabilistic classifier;reading order detection","","2","","10","","","23-26 Sept. 2007","","IEEE","IEEE Conference Publications"
"Automatic Audio Genre Classification Based on Support Vector Machine","Y. Zhu; Z. Ming; Q. Huang","Shenzhen University, China; Harbin Institute of Technology, China","Third International Conference on Natural Computation (ICNC 2007)","20071105","2007","1","","517","521","Audio classification is very important in audio indexing, analysis and content-based video retrieval. In this paper, we have proposed a clip-based support vector machine (SVM) approach to classify audio signals into six classes, which are pure speech, music, silence, environmental sound, speech with music and speech with environmental sound. The classification results are then used to partition a video into homogeneous audio segments, which is used to analyze and retrieve its high-level content. The experimental results show that the proposed system not only improves classification accuracy, but also performs better than the other classification systems using the decision tree (DT), K nearest neighbor (K-NN) and neural network (NN).","2157-9555;21579555","POD:0-7695-2875-9","10.1109/ICNC.2007.277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344244","","Classification tree analysis;Content based retrieval;Decision trees;Indexing;Multiple signal classification;Music information retrieval;Neural networks;Speech;Support vector machine classification;Support vector machines","audio signal processing;signal classification;spectral analysis;support vector machines","audio analysis;audio indexing;audio signal classification;automatic audio genre classification;clip-based support vector machine;content-based video retrieval;homogeneous audio segment","","2","1","11","","","24-27 Aug. 2007","","IEEE","IEEE Conference Publications"
"Information-Theoretically Secure Number-Product Protocol","C. H. Shen; J. Zhan; D. W. Wang; T. S. Hsu; C. J. Liau","Institute of Information Science, Academia Sinica, Taipei, Taiwan. E-MAIL: shench@iis.sinica.edu.tw","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","5","","3006","3011","A secure multiparty number-product protocol is an important building block in the area of secure multiparty computation. With proper composition of the building block, most applications, such as circuit evaluation, data mining, and private information retrieval, can be executed securely and collaboratively by potentially dishonest parties. In this work, we propose a commodity-based secure number-product protocol, the security of which has been validated with the metrics proposed by Chiang et al. based on information theory. We prove that the protocol can be executed securely under the assumption of semi-honest behavior. Furthermore, if an extra semi-trusted party exists, the proposed protocol can resist any number of corrupt parties. In addition to the security issue, we compare the protocol's communication and computation costs with those of the theoretically secure solution proposed by Ben-Or et al.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370663","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370663","Commodity-based Paradigm;Number-product Protocol;Secure Multiparty Computation","Circuits;Collaborative work;Computational efficiency;Data mining;Data security;Information retrieval;Information security;Information theory;Protocols;Resists","information theory;protocols;security of data","commodity;information theory;multiparty number-product protocol security","","8","","12","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
"HEXA: Compact Data Structures for Faster Packet Processing","S. Kumar; J. Turner; P. Crowley; M. Mitzenmacher","Washington University, Computer Science and Engineering, sailesh@arl.wustl.edu","2007 IEEE International Conference on Network Protocols","20071105","2007","","","246","255","Data structures representing directed graphs with edges labeled by symbols from a finite alphabet are used to implement packet processing algorithms used in a variety of network applications. In this paper we present a novel approach to represent such data structures, which significantly reduces the amount of memory required. This approach called history-based encoding, execution and addressing (HEXA) challenges the conventional assumption that graph data structures must store pointers of lceillog<sub>2</sub>nrceil bits to identify successor nodes. We show how the data structures can be organized so that implicit information can be used to locate successors, significantly reducing the amount of information that must be stored explicitly. We demonstrate that the binary tries used for IP route lookup can be implemented using just two bytes per stored prefix (roughly half the space required by Eatherton's tree bitmap data structure) and that string matching can be implemented using 20-30% of the space required by conventional data representations. Compact representations are useful, because they allow the performance-critical part of packet processing algorithms to be implemented using fast, on-chip memory, eliminating the need to retrieve information from much slower off-chip memory. This can yield both substantially higher performance and lower power utilization. While enabling a compact representation, HEXA does not add significant complexity to the graph traversal and update, thus maintaining a high performance.","1092-1648;10921648","CD-ROM:978-1-4244-1588-5; POD:978-1-4244-1587-8","10.1109/ICNP.2007.4375855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375855","IP lookup;content inspection;string matching","Application software;Bandwidth;Computer science;Data structures;Encoding;History;Information retrieval;Inspection;Maintenance engineering;Tree data structures","IP networks;computational complexity;data structures;directed graphs;string matching;telecommunication network routing","HEXA compact data structure;IP route lookup;directed graphs;faster packet processing;history-based encoding-execution-addressing;network application;string matching","","14","","27","","","16-19 Oct. 2007","","IEEE","IEEE Conference Publications"
"Toward a Nanobioinformatics Infrastructure for Nanotechnology-based Prostate Cancer Therapeutic Response Tracking","D. S. Paik","Department of Radiology, Stanford University, Stanford, CA","2007 IEEE 7th International Symposium on BioInformatics and BioEngineering","20071105","2007","","","486","486","Nanobioinformatics is an emerging field of study born out of a necessity of nanotechnology researchers in the life sciences whose work is dependent on timely access to an emerging wealth of data. It brings together the three very diverse fields of nanotechnology, molecular biology and biomedical informatics that until now have had little overlap and where major cultural gaps exist. It is critical that nanobioinformatics be embraced as an extension of biomedical informatics and not be orphaned prematurely. Because of the combinatorial nature of nanoparticle composition (core + surface modifier + payload) and the enthusiasm for this area in general, nanotechnology in biomedicine will see a rapid exponential increase in the data produced, thus making it critical to develop robust infrastructure to support data standardization and storage, modeling and simulation, symbolic reasoning and information retrieval. The goal of the multi-institutional Center for Cancer Nanotechnology Excellence focused on therapy response (CCNE-TR) at Stanford University is to develop a combined ex vivo nanosensor and in vivo molecular imaging approach toward highly sensitive tracking of prostate cancer response to therapy. As a part of this effort, we are developing an informatics platform to serve the diverse needs of this group. In particular, our data portal is designed to support electronic communication and data sharing within the center as well as data and knowledge sharing with the greater scientific community. We are developing this platform to be caBIG compatible integrating a number of different caBIG components that are each the best of breed solution for their particular area. While our approach is designed to meet the needs of our specific center, the methods and infrastructure developed should prove useful for other similar informatics efforts as well.","","POD:1-4244-1509-8","10.1109/BIBE.2007.4375605","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375605","Nanobioinformatics;caBIG;informatics;nanotechnology","Biomedical informatics;Cultural differences;Information retrieval;Medical treatment;Nanobioscience;Nanotechnology;Payloads;Prostate cancer;Robustness;Standardization","biological organs;biomedical electronics;biomedical imaging;biosensors;cancer;information retrieval;information technology;medical information systems;molecular biophysics;nanobiotechnology;radiation therapy","biomedical informatics;biomedicine;caBIG compatible integrating;center development;core-surface modifier-payload system;data modeling;data sharing;data simulation;data standardization;data storage;electronic communication;information retrieval;knowledge sharing;life sciences;molecular biology;molecular imaging;nanobioinformatics infrastructure;nanoparticle composition;nanosensor;nanotechnology;nanotechnology-based prostate cancer;prostate cancer therapy response;symbolic reasoning;therapeutic response tracking;therapy response","","0","","","","","14-17 Oct. 2007","","IEEE","IEEE Conference Publications"
"Similarity Search Over Data Stream using LPC-DTW","W. M. Li; F. Li; J. W. Liu; J. J. Le","College of Computer Science and Technology of Donghua University, 1882 West Yan'an Road, Shanghai, China, 200051. E-MAIL: 108wml@mail.dhu.edu.cn","2007 International Conference on Machine Learning and Cybernetics","20071029","2007","3","","1631","1634","Effective similarity search over data stream is of importance for applications like network monitoring, information retrieval and financial service, etc. Linear predictive coding (LPC) is a tool using the information of a linear predictive model. In this paper, we propose similarity search over data stream based on LPC cepstral coefficients using dynamic time warping (DTW). Compared with traditional approaches, such as similarity search based on discrete Fourier transform (DFT) and discrete wavelet transform (DWT), the proposed method LPC-DTW can use fewer coefficients to capture desired features from data stream for similarity search. In distance metric of similarity search, DTW that replaces the Euclidean distance metric could bring better performance. The relative experiment results demonstrate the proposed method is better than the traditional approaches.","2160-133X;2160133X","CD-ROM:978-1-4244-0973-0; POD:978-1-4244-0972-3","10.1109/ICMLC.2007.4370407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370407","DTW;Data stream;LPC;Similarity search","Cepstral analysis;Data mining;Discrete Fourier transforms;Discrete wavelet transforms;Educational institutions;Euclidean distance;Feature extraction;Information retrieval;Linear predictive coding;Predictive models","discrete Fourier transforms;discrete wavelet transforms;linear predictive coding;search problems","DFT;DWT;Euclidean distance metric;LPC-DTW;cepstral coefficients;data stream;discrete Fourier transform;discrete wavelet transform;dynamic time warping;linear predictive coding;linear predictive model;similarity search","","2","","15","","","19-22 Aug. 2007","","IEEE","IEEE Conference Publications"
