"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6843227,6843230,6843232,6843229,6843231,6843233,6843226,6843228,6836638,6835696,6830262,6824457,6822126,6821774,6821051,6819189,6818959,6816262,6818111,6818305,6816754,6815907,6815908,6815906,6816301,6816596,6815289,6815805,6814045,6805002,6798740,6784818,6786128,6784643,6780087,6778353,6778634,6754763,6778609,6574843,6701298,6766101,6766105,6519224,6758699,6761164,6758698,6753943,6755309,6560008,6747185,6646267,6740401,6735325,6732696,6732564,6732537,6732723,6732511,6726794,6727276,6727161,6722080,6723072,6716682,6719974,6714670,6716690,6719938,6709999,6703310,6698256,6693511,6700236,6694296,6695527,6693488,6690734,6690008,6690557,6690025,6691761,6690746,6690716,6689560,6685668,6689278,6680952,6680464,6676908,6399473,6671333,6664904,6662673,6664640,6633083,6657167,6654618,6216357,6650241",2017/05/04 20:48:25
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Query expansion using WordNet in N-layer vector space model","J. R. Gadge; S. S. Sane; H. B. Kekre","VJTI, Mumbai, India","2013 Nirma University International Conference on Engineering (NUiCONE)","20140331","2013","","","1","5","Information Retrieval is concerned with the identification of documents in the collection that are relevant to users information needs. Queries formed by user are generally short and vague which makes it difficult to estimate the exact user need. Information retrieval may improve their effectiveness by using process of query expansion, which automatically adds new terms to the original query posed by the user. In this paper, a new technique is proposed based on WordNet for N-layer vector space approach. WordNet is an online lexical dictionary which describes word semantic relationships in terms of Synset. New query expansion approach is proposed to use semantic relationship while adding new terms. The concept of term association is used to mine out the word from semantic relation. The result shows that N-layer vector space model with proposed query expansion approach improves precision by approximately 5% and recall is improved by approximately 20%.","2375-1282;23751282","Electronic:978-1-4799-0727-4; POD:978-1-4799-0725-0","10.1109/NUiCONE.2013.6780087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6780087","N-layer vector space model;Synset;WordNet;query expansion;semantic relationship","Computers;Data mining;Educational institutions;Information retrieval;Semantics;Thesauri;Vectors","dictionaries;query processing;thesauri","N-layer vector space model;Synset;WordNet;document identification;information retrieval;online lexical dictionary;query expansion process;term association;word semantic","","0","","14","","","28-30 Nov. 2013","","IEEE","IEEE Conference Publications"
"Promoting electronic health record search through a time-aware approach","J. Zhang; J. X. Huang; J. Guo; W. Xu","Beijing Univ. of Posts & Telecommun., Beijing, China","2013 IEEE International Conference on Bioinformatics and Biomedicine","20140206","2013","","","593","596","In this paper, we propose a time-aware approach to promoting textual retrieval performance for Electronic Health Record (EHR) search. The proposed approach focuses on identifying patients cohorts from the perspective of EHR temporal correlation. First, an EHR temporal profile is created according to EHR distribution on time interval for each patient. Second, the temporal similarity is computed and used as a feature for discovering temporal cohorts. In each cohort, the highest-ranked profile in textual retrieval is considered as the centroid, and a temporal relevance score is computed by multiplying temporal similarity with the textual relevance of the centroid. Finally, the temporal relevance is combined linearly with the textual relevance for re-ranking. Extensive experiments are conducted to demonstrate the effectiveness of the proposed approach in promoting retrieval performance for EHR search.","","Electronic:978-1-4799-1309-1; POD:978-1-4799-1311-4","10.1109/BIBM.2013.6732564","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732564","EHR;IR;temporal distribution;temporal relevance","Couplings;Data mining;Diseases;Educational institutions;Electronic medical records;Information retrieval;Vectors","data mining;electronic health records;information retrieval;medical computing;search engines;text analysis","EHR distribution;EHR search;EHR temporal correlation;EHR temporal profile;Electronic Health Record search;centroid textual relevance;electronic health record search;highest-ranked profile;patient cohort identification;reranking;temporal cohort discovery;temporal relevance score;temporal similarity;textual retrieval performance;time interval;time-aware approach","","1","","18","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Interconnected Service Models -- Emergence of a Comprehensive Logistics Service Model","C. Augenstein; A. Ludwig","Inf. Syst. Inst., Univ. of Leipzig, Leipzig, Germany","2013 17th IEEE International Enterprise Distributed Object Computing Conference Workshops","20131223","2013","","","239","245","Logistics service industry is characterized by a high level of collaboration between logistics customers and providers. In recent years sophisticated, knowledge-intense business models such as fourth party and lead logistics evolved that are responsible for planning, coordination, and monitoring entire supply chains across logistics companies. The Logistics Service Engineering and Management (LSEM) platform is a service-oriented infrastructure for the development and management of collaborative contract logistics enabling fourth party and lead logistics. The Service Modeling Framework (SMF) is a pivotal element of the LSEM platform. It allows users of the platform to define, manage and combine logistics services from different providers and allows for an integrated view on complex services setups. In doing so, the SMF enables fourth party and lead logistics not only to work with logistics services but to integrate related service models in order to realize an interconnection of models thus leading to the emergence of a comprehensive logistics service model. In this paper we present how to accomplish the bottom up construction of a comprehensive service model on metamodel as well as on model level and present resulting benefits of interconnected models in terms of information extraction and transformation and in terms of flexibility and robustness of the overall approach.","2325-6583;23256583","Electronic:978-1-4799-3048-7; POD:978-1-4799-3049-4","10.1109/EDOCW.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690557","logistics;metamodeling;model transformation;model-driven logistics service engineering;service modeling","Adaptation models;Biological system modeling;Contracts;Information retrieval;Load modeling;Logistics;Planning","groupware;logistics data processing;service-oriented architecture","LSEM platform;SMF;collaborative contract logistics development;collaborative contract logistics management;comprehensive logistics service model;fourth party logistics;interconnected service models;lead logistics;logistics service engineering and management;logistics service industry;metamodel;service modeling framework;service-oriented infrastructure","","0","","37","","","9-13 Sept. 2013","","IEEE","IEEE Conference Publications"
"Sentence Subjectivity Analysis in Social Domains","M. Karamibekr; A. A. Ghorbani","Fac. of Comput. Sci., Univ. of New Brunswick, Fredericton, NB, Canada","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","1","","268","275","Subjectivity analysis recognizes the contextual polarity of opinions, attitudes, emotions, feelings etc. regarding products, services, topics, or issues. Subjectivity classification categorizes the given text as subjective or objective. While an objective text contains one or more facts about a product or an issue, a subjective text expresses author's opinions. Statistical analysis shows that subjectivity analysis of social issues is different from that of products. This paper focuses on subjectivity analysis of social issues. Subjectivity of a document strongly depends on its sentences. Hence, a lexical-syntactical approach is proposed to recognize and classify subjectivity at the sentence level. This approach considers the role of various opinion terms especially verbs on opinions regarding social issues. Evaluation of the proposed approach on a data-set consisting comments about abortion shows that it slightly outperforms other similar works. It has a good accuracy especially on the strong sentences which express explicit opinions. Its reasonable F-measure demonstrates a good balance between the precision and recall which makes it suitable for applications such as sentiment polarity classification, text sentiment summarization, and opinion question answering.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690025","Opinion Mining;Sentiment analysis;Sentiment classification;Subjectivity analysis","Context;Information retrieval;Knowledge discovery;Semantics;Support vector machines;Syntactics;Text mining","data analysis;pattern classification;social sciences computing;statistical analysis;text analysis","F-measure;lexical-syntactical approach;objective text;opinion question answering;opinion terms;precision measure;recall measure;sentence subjectivity analysis;sentiment polarity classification;social domains;social issues;statistical analysis;subjective text;subjectivity classification;subjectivity recognition;text sentiment summarization","","4","","27","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"Enhancing entity annotation using web service and ontology hierarchy in biomedical domains","Y. Shang; Y. An; X. T. Hu; M. Zhang; X. Lin","Coll. of Comput. & Inf., Drexel Univ., Philadelphia, PA, USA","2013 IEEE International Conference on Bioinformatics and Biomedicine","20140206","2013","","","465","468","Entity annotation is a fundamental step for entity relation extraction, information visualization and semantic web creation. Using domain specific ontologies to annotate a dataset for exploring, analyzing and integrating the entities and relations within the corpus is an important step for further study of the data. In this paper, we present an ontology based entity annotation system to annotate entities in neuroscience documents. To improve the annotation performance, we propose an ontology entity expansion method based on web service and ontology structure. We evaluate the proposed entity annotation method on real data obtained from Elsevier's BrainNavigator. The results show that using web service and ontology structure to expand ontology entities can improve the annotation result.","","Electronic:978-1-4799-1309-1; POD:978-1-4799-1311-4","10.1109/BIBM.2013.6732537","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732537","Entity Annotation;Information Extraction;Ontology Expansion","Brain;Informatics;Information retrieval;Neuroscience;Ontologies;Semantics;Web services","Web services;bioinformatics;data visualisation;entity-relationship modelling;ontologies (artificial intelligence);semantic Web","Elsevier BrainNavigator;Web service;biomedical domains;entity annotation;entity relation extraction;information visualization;ontology entity expansion method;ontology hierarchy;ontology structure;semantic Web creation","","0","","15","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Impact analysis of different spatial resolution DEM on object-oriented landslide extraction from high resolution remote sensing images","Q. Chen; X. Liu; C. Liu; R. Ji","Fac. of Inf. Eng., China Univ. of Geosci., Wuhan, China","2013 Ninth International Conference on Natural Computation (ICNC)","20140519","2013","","","940","945","Information extraction of landslides is a critical issue for the disaster hazard analysis. Although DEM (Digital Elevation Model) is an important feature for landslide recognition, it's difficult to obtain the high-resolution DEM in study areas in practical application. In order to analyze the impact of DEM resolution on landslide extraction and to determine the resolution to the meet application requirements, we resample the DEM data into five groups on different spatial resolution and then adopt the object-oriented method to extract the landslides information to combine with high-resolution images. The experimental results show that, when the DEM resolution is greater than 30 meters, we can obtain better recognition and classification results for the landslide with area greater than 5000m<sup>2</sup>. When the resolution is less than 30 meters, it is difficult to distinguish between landslide types, but by adjusting parameter values we can still achieve the detection of landslides. This research has certain guiding significance and reference value for the selection of DEM spatial resolution on the landslides information extraction.","2157-9555;21579555","Electronic:978-1-4673-4714-3; POD:978-1-4673-4712-9","10.1109/ICNC.2013.6818111","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818111","Digital Elevation Model (DEM);high resolution;landslide extraction;object-oriented;remote sensing images","Feature extraction;Information retrieval;Remote sensing;Rocks;Spatial resolution;Terrain factors","digital elevation models;disasters;geomorphology;geophysical image processing;image classification;image resolution;information retrieval;object-oriented methods;remote sensing","digital elevation model;disaster hazard analysis;high resolution remote sensing images;high-resolution DEM;impact analysis;landslide information extraction;object-oriented landslide extraction;object-oriented method;spatial resolution DEM","","1","","11","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"Data extraction from SystemC designs using debug symbols and the SystemC API","J. Stoppe; R. Wille; R. Drechsler","Inst. of Comput. Sci., Univ. of Bremen, Bremen, Germany","2013 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)","20131107","2013","","","26","31","Due to the ever increasing complexity of hardware and hardware/software co-designs, developers strive for higher levels of abstractions in the early stages of the design flow. To address these demands, design at the Electronic System Level (ESL) has been introduced. SystemC currently is the “defacto standard” for ESL design. The extraction of data from system designs written in SystemC is thereby crucial e.g. for the proper understanding of a given system. However, no satisfactory support of reflection/introspection of SystemC has been provided yet. Previously proposed methods for this purpose either focus on static aspects only, restrict the language means of SystemC, or rely on modifications of the compiler and/or parser. In this work, we present an approach that overcomes these limitations. A methodology is introduced which enables full extraction of the desired information from a given SystemC design without changing the SystemC library or the compiler. For this purpose, debug symbols generated by the compiler and SystemC API calls are exploited. The proposed system retrieves both, static and dynamic information. A comparison to previously proposed solutions shows the benefits of the proposed method, while its application is illustrated by means of a visualization engine.","2159-3469;21593469","Electronic:978-1-4799-1331-2; POD:978-1-4799-1329-9","10.1109/ISVLSI.2013.6654618","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654618","","Adders;Data mining;Hardware;Information retrieval;Libraries;Software systems;Standards","C language;application program interfaces;hardware-software codesign;program debugging","ESL;SystemC API;SystemC design;compiler;data extraction;debug symbol;electronic system level;hardware-software codesign;static aspect;visualization engine","","4","","22","","","5-7 Aug. 2013","","IEEE","IEEE Conference Publications"
"The PageRank Problem, Multiagent Consensus, and Web Aggregation: A Systems and Control Viewpoint","H. Ishii; R. Tempo","Dept. of Comput. Intell. & Syst Sci, Tokyo Inst. of Technol., Tokyo, Japan","IEEE Control Systems","20140514","2014","34","3","34","53","PageRank is an algorithm introduced in 1998 and used by the Google Internet search engine. It assigns a numerical value to each element of a set of hyperlinked documents (that is, Web pages) within the World Wide Web with the purpose of measuring the relative importance of each page [1]. The key idea in the algorithm is to give a higher PageRank value to Web pages that are visited often by Web surfers. Google describes PageRank as: ""PageRank reflects our view of the importance of Web pages by considering more than 500 million variables and 2 billion terms. Pages that are considered important receive a higher PageRank and are more likely to appear at the top of the search results"".","1066-033X;1066033X","","10.1109/MCS.2014.2308672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815805","","Algorithm design and analysis;Information retrieval;Ranking (statistics);Search engines;Search methods;Web pages;Web search","Internet;Web sites;multi-agent systems;search engines","Google Internet search engine;PageRank problem;Web aggregation;Web page;Web surfers;World Wide Web;hyperlinked documents;multiagent consensus","","14","","53","","","June 2014","","IEEE","IEEE Journals & Magazines"
"Application in Effort Estimation of Collaborative Filtering","X. Ren; Y. Dai; L. Zhou","Coll. of Comput. Sci. & Eng., Qujing Normal Univ., Qujing, China","2013 Sixth International Symposium on Computational Intelligence and Design","20140424","2013","1","","330","333","Accurate project effort prediction is an important goal for the software engineering community. To date most work has focused upon building algorithmic models of effort, for example COCOMO. These can be calibrated to local environments. An approach to estimation effort based upon analogy researched in the paper. Collaborative Filtering has been developed in information retrieval researchers successfully which recommends items based on other user's reference in historical data set. Effort estimation based on Collaborative Filtering is researched. The similar projects set are found from historical projects set using the method for document similarity, and then effort is estimated using the weighted sum of the efforts in k-nearest neighbors. The method is applied in an experimental case to evaluate the effort estimation, and the result shows the accuracy of estimation may arrive to 90%.","","Electronic:978-0-7695-5079-4; POD:978-1-4799-0906-3","10.1109/ISCID.2013.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6805002","analogy;case-based reasoning;collaborative filtering;effort estimate","Accuracy;Collaboration;Estimation;Filtering;Information retrieval;Measurement;Software","collaborative filtering;document handling;project management;recommender systems;software engineering","COCOMO;collaborative filtering;document similarity;historical data set;information retrieval;item recommendation;k-nearest neighbors;local environments;project effort estimation;software engineering community;user reference;weighted effort sum","","0","","14","","","28-29 Oct. 2013","","IEEE","IEEE Conference Publications"
"Information Extraction from the Web: An Ontology-Based Method Using Inductive Logic Programming","R. Lima; B. Espinasse; H. Oliveira; L. Pentagrossa; F. Freitas","Inf. Center, Fed. Univ. of Pernambuco, Recife, Brazil","2013 IEEE 25th International Conference on Tools with Artificial Intelligence","20140210","2013","","","741","748","Relevant information extraction from text and web pages in particular is an intensive and time-consuming task that needs important semantic resources. Thus, to be efficient, automatic information extraction systems have to exploit semantic resources (or ontologies) and employ machine-learning techniques to make them more adaptive. This paper presents an Ontology-based Information Extraction method using Inductive Logic Programming that allows inducing symbolic predicates expressed in Horn clausal logic that subsume information extraction rules. Such rules allow the system to extract class and relation instances from English corpora for ontology population purposes. Several experiments were conducted and preliminary experimental results are promising, showing that the proposed approach improves previous work over extracting instances of classes and relations, either separately or altogether.","1082-3409;10823409","Electronic:978-1-4799-2972-6; POD:978-1-4799-2973-3; USB:978-1-4799-2971-9","10.1109/ICTAI.2013.114","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6735325","Inductive Logic Programming;Ontology Population;Ontology-based Information Extraction","Feature extraction;Information retrieval;Logic programming;Natural language processing;Ontologies;Semantics;Sociology","Internet;Web sites;data mining;inductive logic programming;information retrieval;ontologies (artificial intelligence);text analysis","English corpora;Horn clausal logic;Web pages;World Wide Web;automatic information extraction systems;inductive logic programming;information extraction rules;machine learning techniques;ontology population;ontology-based information extraction method;semantic resources;symbolic predicates;text;time-consuming task","","1","","16","","","4-6 Nov. 2013","","IEEE","IEEE Conference Publications"
"Automatic melodic segmentation of Turkish makam music scores","B. Bozkurt; M. K. Karaosmanoglu; B. Karaçalı; E. Ünal","Elektrik-Elektron. Muhendisligi Bolumu, Bahcesehir Univ., Istanbul, Turkey","2014 22nd Signal Processing and Communications Applications Conference (SIU)","20140612","2014","","","449","452","Automatic melodic segmentation is one of the important steps in computational analysis of melodic content from symbolic data. This widely studied research problem has been very rarely considered for Turkish makam music. In this paper we first present test results for state-of-the-art techniques from literature on Turkish makam music data. Then, we present a statistical classification-based segmentation system that exploits the link between makam melodies and usual and makam scale hierarchies together with the well-known features in literature. We show through tests on a large dataset that the proposed system has a higher accuracy.","2165-0608;21650608","Electronic:978-1-4799-4874-1; POD:978-1-4799-4873-4","10.1109/SIU.2014.6830262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6830262","makam music;melodic analysis","Cognition;Computational modeling;Conferences;Music;Music information retrieval;Presses;Signal processing","music;signal classification;statistical analysis","Turkish makam music scores;automatic melodic segmentation;statistical classification-based segmentation system","","0","","20","","","23-25 April 2014","","IEEE","IEEE Conference Publications"
"The Microsoft Academic Search challenges at KDD Cup 2013","M. De Cock; S. B. Roy; S. Savvana; V. Mandava; B. Dalessandro; C. Perlich; W. Cukierski; B. Hamner","Dept. of Appl. Math., CS and Statistics, Ghent University, 9000 Gent, Belgium","2013 IEEE International Conference on Big Data","20131223","2013","","","1","4","Microsoft Academic Search is a free search engine specific to scholarly material. It currently covers more than 50 million publications and over 19 million authors across a variety of domains. One of the main challenges in correctly indexing this material is author name ambiguity and the resulting noise in author profiles. KDD Cup 2013 invited participants to tackle this problem in 2 ways: (1) by automatically determining which papers in an author profile are truly written by a given author, and (2) by identifying which author profiles need to be merged because they belong to the same author. This paper presents a brief account of the contest and the lessons learned.","","Electronic:978-1-4799-1293-3; POD:978-1-4799-1294-0","10.1109/BigData.2013.6691761","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691761","Microsoft Academic Search;author name disambiguation","Educational institutions;Electronic mail;Information retrieval;Lead;Materials;Measurement;Training","data mining;indexing;search engines;text analysis","KDD Cup 2013;Microsoft Academic Search;author name ambiguity;author profiles;material indexing;resulting noise;scholarly material;search engine","","0","","4","","","6-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Semantic fusion of live Web content: System design and implementation experiences","V. Lenders","Armasuisse, Switzerland","2013 Workshop on Sensor Data Fusion: Trends, Solutions, Applications (SDF)","20140102","2013","","","1","6","Conventional Web search models are ineffective at providing quick and comprehensive answers to questions related to live content such as real-time data or temporal relationships between actors. Semantic data fusion techniques have the potential to provide a more suitable abstraction model for efficient search on this type of data. However, myriad architectural and technical implementation challenges arise when trying to implement a working system. This paper summarizes our efforts and experiences at implementing a functional semantic fusion system for live content from the Web. Besides semantic data fusion techniques, we make extensive use of natural language processing, semantic Web technologies and Bayesian statistics to render the system a self-contained framework acting directly between Web resources of interest and end-user search applications. We first present the semantic fusion architecture design that we have developed. We have implemented this architecture and tested its effectiveness using real-world live data from the Web over multiple weeks. We then report about our major experiences and lessons-learned of this experiment.","","Electronic:978-1-4799-0778-6; POD:978-1-4799-0776-2","10.1109/SDF.2013.6698256","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698256","","Data collection;Data integration;Information retrieval;Natural language processing;Ontologies;Resource description framework;Semantics","Bayes methods;natural language processing;query processing;question answering (information retrieval);semantic Web;sensor fusion","Bayesian statistics;Web resources;Web search models;abstraction model;data search;end-user search applications;functional semantic fusion system;natural language processing;question-answering system;real-time data;real-world live data;self-contained framework;semantic Web technologies;semantic data fusion techniques;semantic fusion architecture design;semantic live Web content fusion;temporal relationships","","0","","33","","","9-11 Oct. 2013","","IEEE","IEEE Conference Publications"
"Optimal Data Retrieval Scheduling in the Multichannel Wireless Broadcast Environments","Z. Lu; W. Wu; B. Fu","Dept. of Comput. Sci., Univ. of Texas at Dallas, Richardson, TX, USA","IEEE Transactions on Computers","20131104","2013","62","12","2427","2439","Wireless data broadcast is an efficient way of disseminating data to users in the mobile computing environments. From the server's point of view, how to place the data items on channels is a crucial issue, with the objective of minimizing the average access time and tuning time. Similarly, how to schedule the data retrieval process for a given request at the client side such that all the requested items can be downloaded in a short time is also an important problem. In this paper, we investigate the multi-item data retrieval scheduling in the push-based multichannel broadcast environments. We prove the decision version of this problem is NP-complete, and we devise an algebraic algorithm to search for the best solution. We also develop a heuristic that can employ the algebraic algorithm to download a large number of items efficiently. When there is no replicated item in a broadcast cycle, we show that an optimal retrieval schedule can be obtained in polynomial time. The performances of proposed algorithms are analyzed theoretically and evaluated through simulation. The experimental results show that our algorithms can significantly reduce the access time for multi-item requests.","0018-9340;00189340","","10.1109/TC.2012.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216357","$({cal NP})$-complete;Wireless data broadcast;data retrieval scheduling;multichannel","Data broadcasting;Information retrieval;Processor scheduling;Scheduling;Wireless communication","computational complexity;information dissemination;information retrieval;mobile computing;scheduling","NP-complete problem;algebraic algorithm;broadcast cycle;client side;data dissemination;mobile computing environments;multichannel wireless broadcast environments;multiitem data retrieval scheduling;multiitem requests;optimal data retrieval scheduling;optimal retrieval schedule;polynomial time;push-based multichannel broadcast environments;server view point;wireless data broadcast","","6","","31","","20120612","Dec. 2013","","IEEE","IEEE Journals & Magazines"
"Social Multimedia Crawling for Mining and Search","S. Papadopoulos; Y. Kompatsiaris","","Computer","20140520","2014","47","5","84","87","Social multimedia can be leveraged for a wide range of applications, but mining and search systems require innovative crawling solutions to meet both technical and policy-related obstacles.","0018-9162;00189162","","10.1109/MC.2014.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818959","Big Data;data analysis;mining and search systems;online social networks;social computing;social multimedia","Crawlers;Data mining;Information retrieval;Media;Multimedia communication;Search methods;Social network services;Twitter","data mining;information retrieval;multimedia systems;social networking (online)","innovative crawling solutions;mining;policy-related obstacles;search systems;social multimedia crawling;technical obstacles","","1","","6","","","May 2014","","IEEE","IEEE Journals & Magazines"
"A proposal of Smart TV System focused on findability","T. Kobayashi","Division of Electrical Engineering and Computer Science, Graduate School of Engineering, Nagasaki University, Nagasaki, Japan","2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)","20131114","2013","","","507","508","I propose a Smart TV System focused on findability. This system allows us to retrieve information without typing-in search key words. It also allows us to see retrieved information via multi-screen environment based on the intuitive user interface. I show an information finding model as a fundamental concept of this system, system configuration and user interface. I believe that this system will solve the problem of information retrieval capability differentials among users.","2378-8143;23788143","Electronic:978-1-4799-0892-9; POD:978-1-4799-0891-2","10.1109/GCCE.2013.6664904","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664904","HTML5;Smart TV;findability;user interface","Browsers;Information retrieval;Monitoring;Proposals;Servers;TV;User interfaces","information retrieval;television;user interfaces","information finding model;information retrieval;intuitive user interface;multiscreen environment;smart TV system;system configuration","","3","","5","","","1-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"The Use of Horizontal Visibility Graphs to Identify the Words that Define the Informational Structure of a Text","D. V. Lande; A. A. Snarskii; E. V. Yagunova; E. V. Pronoza","Inst. for Inf. Recording NAS of Ukraine, NTUU &#x201C;Kiev Polytech. Inst.&#x201D;, Kiev, Ukraine","2013 12th Mexican International Conference on Artificial Intelligence","20140123","2013","","","209","215","A compactified horizontal visibility graph for the language network and identification of the words that define the informational structure of a text is proposed. It was found that the networks constructed in such a way are scale free, and have a property that among the nodes with largest degrees there are words that determine not only communicative text structure, but also its informational structure.","","Electronic:978-1-4799-2605-3; POD:978-1-4799-2606-0","10.1109/MICAI.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714670","TFIDF;dispersion estimated value;horizontal visibility graph;informational structure;language network;text coherence","Coherence;Complex networks;Digital signal processing;Dispersion;Information retrieval;Rivers;Signal processing algorithms","graph theory;network theory (graphs);text analysis","communicative text structure;horizontal visibility graphs;language network;text informational structure;words identification","","1","","23","","","24-30 Nov. 2013","","IEEE","IEEE Conference Publications"
"Scholarly big data information extraction and integration in the CiteSeer<sup>χ</sup> digital library","K. Williams; J. Wu; S. R. Choudhury; M. Khabsa; C. L. Giles","Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA","2014 IEEE 30th International Conference on Data Engineering Workshops","20140519","2014","","","68","73","CiteSeer<sup>χ</sup> is a digital library that contains approximately 3.5 million scholarly documents and receives between 2 and 4 million requests per day. In addition to making documents available via a public Website, the data is also used to facilitate research in areas like citation analysis, co-author network analysis, scalability evaluation and information extraction. The papers in CiteSeer<sup>χ</sup> are gathered from the Web by means of continuous automatic focused crawling and go through a series of automatic processing steps as part of the ingestion process. Given the size of the collection, the fact that it is constantly expanding, and the multiple ways in which it is used both by the public to access scholarly documents and for research, there are several big data challenges. In this paper, we provide a case study description of how we address these challenges when it comes to information extraction, data integration and entity linking in CiteSeer<sup>χ</sup>. We describe how we: aggregate data from multiple sources on the Web; store and manage data; process data as part of an automatic ingestion pipeline that includes automatic metadata and information extraction; perform document and citation clustering; perform entity linking and name disambiguation; and make our data and source code available to enable research and collaboration.","","Electronic:978-1-4799-3481-2; POD:978-1-4799-3482-9","10.1109/ICDEW.2014.6818305","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818305","","Data handling;Data mining;Data storage systems;Feature extraction;Information management;Information retrieval;Joining processes","Big Data;Web sites;citation analysis;data integration;digital libraries;information retrieval;meta data;pattern clustering","CiteSeer<sup>χ</sup> digital library;automatic ingestion pipeline;automatic metadata;automatic processing steps;big data information extraction;big data information integration;citation analysis;information extraction;public Website","","0","","19","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Usage of spreading activation for content retrieval in an autonomous agent","A. Wendt; S. Schaat; F. Gelbard; C. Muchitsch; D. Bruckner","Vienna Univ. of Technol., Vienna, Austria","IECON 2013 - 39th Annual Conference of the IEEE Industrial Electronics Society","20140102","2013","","","6672","6677","For cognitive agents that decide based on experiences, memory retrieval is a significant issue. In this article a contribution to this field is made by introducing the concept of psychic spreading activation for memory retrieval in an autonomous agent. Using the psychoanalytical foundation of that as a constraint, a variant of spreading activation was created to regard perceptional as well as motivational inputs and considering the emotional component of a situation. Results show how this type of memory retrieval can influence the decision making process.","1553-572X;1553572X","Electronic:978-1-4799-0224-8; POD:978-1-4799-0225-5; USB:978-1-4799-0223-1","10.1109/IECON.2013.6700236","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6700236","ARS;artificial general intelligence;artificial intelligence;artificial recognition system;cognitive architecture;database;image;memory retrieval;psychic spreading activation;spreading activation","Artificial intelligence;Autonomous agents;Computer architecture;Decision making;Educational institutions;Information retrieval;Semantics","cognitive systems;content-based retrieval;decision making;psychology;software agents","autonomous agent;cognitive agents;content retrieval;decision making process;emotional component;memory retrieval;motivational inputs;perceptional inputs;psychic spreading activation;psychoanalytical foundation","","2","","20","","","10-13 Nov. 2013","","IEEE","IEEE Conference Publications"
"Towards a Universal Notification System","S. Banerjee; D. Mukherjee","TCS Innovation Labs., Tata Consultancy Services, Kolkata, India","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","3","","286","287","As the world is getting more and more connected, a requirement for a connected notification system has emerged. In this paper a universal notification system namely UNS based on stream reasoning is described that not only meets the requirement of knowledge sharing among applications but can cater to different varying and custom scenarios, is flexible and semantic web compliant. Experimentation was done considering a meeting use case in a simulated condition on real data of smart city, and the experimental results were found to be promising.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.200","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690746","linked data;notification system;stream reasoning","Cities and towns;Cognition;Conferences;Context;Electricity;Information retrieval;Knowledge engineering","inference mechanisms;information networks","UNS;knowledge sharing;semantic Web;smart city;stream reasoning;universal notification system","","1","","4","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"Information extraction from nanotoxicity related publications","L. Xiao; K. Tang; X. Liu; H. Yang; Z. Chen; R. Xu","Intell. Autom. Inc., Rockville, MD, USA","2013 IEEE International Conference on Bioinformatics and Biomedicine","20140206","2013","","","25","30","High-quality experimental data are important when developing predictive models for studying nanomaterial environmental impact (NEI). Given that raw data from experimental laboratories and manufacturing workplaces are usually proprietary and small-scaled, extracting information from publications is an attractive alternative for collecting data. We developed an information extraction system that can extract useful information from full-text nanotoxicity related publications. This information extraction system consists of five components: raw data transformation into machine readable format, data preprocessing, ontology-based named entity recognition, rule-based numerical attribute extraction from both tables and unstructured text, and relation extraction among entities and attributes. The information extraction system is applied on a dataset made of 94 publications, and results in an acceptable accuracy. By storing extracted data into a table according to relations among the data, a dataset that can be used to predict nanomaterial environmental impact is obtained. Such a system is unique in current nanomaterial community, and can help nanomaterial scientists and practitioners quickly locate useful information they need without spending lots of time reading articles.","","Electronic:978-1-4799-1309-1; POD:978-1-4799-1311-4","10.1109/BIBM.2013.6732723","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732723","Nanoinformatics;data mining;information extraction;named entity recognition;nanotoxicity;relation extraction","Data mining;Information retrieval;Nanoparticles;Ontologies;Pattern matching;Shape;XML","data mining;medical computing;nanomedicine;numerical analysis;toxicology","data preprocessing;full-text nanotoxicity;information extraction system;machine readable format;nanomaterial community;nanomaterial environmental impact;nanotoxicity related publications;ontology-based named entity recognition;predictive models;raw data transformation;rule-based numerical attribute extraction","","0","","17","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Sequential pattern based multi document summarization — An exploratory approach","S. Alias; S. K. Muhammad","Sch. of Eng. & Inf. Technol., Univ. Malaysia Sabah, Kota Kinabalu, Malaysia","2013 International Conference on Research and Innovation in Information Systems (ICRIIS)","20140123","2013","","","85","90","Sequential Pattern Mining which aims to discover all frequent sequences of itemsets (patterns) from a large data collection has been applied in the Text Mining domain such as Text Categorization and Pattern Identification. However, in the area of Document Summarization the effort is still considered as green and exploratory. In the real world, a sentence is more than just a collection of un-ordered sequence of words, where each sentence carries their own meaning. By discovering these textual patterns is essential since the patterns can describe the text, by preserving the sequential order of the words in the document. Thus, the motivation here is to investigate the feasibility to develop a Sequential Pattern-based Summarizer model near future in order to reduce redundancy information from multiple text resources; at same time preserving the meaning of the original text document using the Semantic similarity approach. This paper reviewed some of the existing techniques in the area of multiple document summarizations to better understand the gap and issues underlying this area. By incorporating the semantic knowledge of sentences in the multiple documents is hoped to assist and alleviate the long-winding process for non-subject expert researches in trying to find the similarities and correlation between text resources.","2324-8149;23248149","Electronic:978-1-4799-2487-5; POD:978-1-4799-2488-2","10.1109/ICRIIS.2013.6716690","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716690","MultiDocument;Sequential Pattern Mining;Summarization","Databases;Information retrieval;Information systems;Semantics;Technological innovation;Text mining","data mining;pattern recognition;text analysis","data collection;multidocument summarization;pattern identification;redundancy information reduction;semantic similarity approach;sentence semantic knowledge;sequential pattern mining;sequential pattern-based summarizer model;text categorization;text mining","","0","","28","","","27-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"Information resilience: source recovery in an information-centric network","M. F. Al-Naday; M. J. Reed; D. Trossen; K. Yang","Univ. of Essex, Colchester, UK","IEEE Network","20140626","2014","28","3","36","42","Recent years have witnessed explosive growth in traffic demands combined with evolving content characteristics and dissemination patterns. This growth has resulted in an increasing demand for information identification as well as information-based communication functions that can meet this evolution. Consequently, information-centric networking envisions a shift in the future Internet communication paradigm from relying on the notion of an end node toward making information itself the primary object. This is realized by adopting information as the primary identifier of a user's demand. With this new concept in networking, new (information- focused) solutions can be developed to conventional problems found in IP networks, such as resilient content delivery. In this article we introduce a novel resiliency solution that goes beyond the scope of path recovery to tackle source failure scenarios in order to achieve the more general form of information resilience. We show that by utilizing the knowledge of information, offered by a publish/subscribe information-centric networking model, multiple publishers of a single information item can be natively identified, thereby allowing for recovery of the delivery process using alternative publishers should a publisher fail.","0890-8044;08908044","","10.1109/MNET.2014.6843230","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843230","","IP networks;Information retrieval;Information technology;Internet;Knowledge engineering;Network architecture;Network topology;Resilience;Routing;Streaming media","IP networks;computer networks;message passing;middleware","IP networks;Internet communication;computer networks;content characteristics;dissemination patterns;information based communication functions;information identification;information resilience;publish-subscribe information centric networking model;source recovery","","5","","15","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Privacy-Preserving Medical Reports Publishing for Cluster Analysis","A. Hmood; B. C. M. Fung; F. Iqbal","Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada","2014 6th International Conference on New Technologies, Mobility and Security (NTMS)","20140512","2014","","","1","8","Health data mining is an emerging research direction. High-quality health data mining results rely on having access to high-quality patient information. Yet, releasing patient-specific medical reports may potentially reveal sensitive information of the individual patients. In this paper, we study the problem of anonymizing medical reports and present a solution to anonymize a collection of medical reports while preserving the information utility of the medical reports for the purpose of cluster analysis. Experimental results show that our proposed approach can the impact of anonymization on the cluster quality is minor, suggesting that the feasibility of simultaneously preserving both information utility and privacy in anonymous medical reports.","2157-4952;21574952","Electronic:978-1-4799-3223-8; POD:978-1-4799-3224-5","10.1109/NTMS.2014.6814045","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6814045","","Clustering algorithms;Data privacy;Diseases;Information retrieval;Medical diagnostic imaging;Privacy","data mining;data privacy;electronic health records;pattern clustering","cluster analysis;health data mining;information utility;medical report anonymization;patient-specific medical reports;privacy-preserving medical reports publishing","","0","","38","","","March 30 2014-April 2 2014","","IEEE","IEEE Conference Publications"
"Software engineering tools classification based on SWEBOK taxonomy and software profile","W. Roongkaew; N. Prompoon","Dept. of Comput. Eng., Chulalongkorn Univ., Bangkok, Thailand","2013 Second International Conference on Informatics & Applications (ICIA)","20131031","2013","","","122","128","In the field of software engineering, it is necessary for users to use various software engineering tools for developing quality software throughout the Software Development Life Cycle (SDLC). Currently, there are many software engineering tools served various aspects of software processes. User may need to select tool for a particular purpose. Selecting a suitable tool from software engineering point of view is a challenge issue. Therefore, we propose an approach for software engineering tool retrieval that is accurate and appropriate for the users' type of usage. We use the categories of software engineering tools specified by IEEE's Software Engineering Body of Knowledge as headings and software tool profile for classifying the tools, and use the K-Means on Batch mode algorithm for classification. This classification before the retrieval step allows the retrieval to have more precision than the classic information retrieval approach, and this method can be applied to searches in other fields with a given taxonomy.","","Electronic:978-1-4673-5256-7; POD:978-1-4673-5254-3","10.1109/ICoIA.2013.6650241","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6650241","Classification;SWEBOK;Software engineering;Software engineering tool","Equations;Indexes;Information retrieval;Knowledge engineering;Mathematical model;Software;Software engineering","software quality","K-means algorithm;SDLC;SWEBOK taxonomy;batch mode algorithm;software development life cycle;software engineering tool classification;software profile;software quality","","0","","13","","","23-25 Sept. 2013","","IEEE","IEEE Conference Publications"
"Quantitative evaluation of violin solo performance","Y. Lin; W. C. Chang; A. W. Y. Su","Dept. of Comput. Sci. & Eng., Nat. Cheng-Kung Univ., Tainan, Taiwan","2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference","20140102","2013","","","1","6","Evaluation of performances of musical instruments is usually subjective. It may be easier for keyboard instruments. For bowed-string instruments such as a violin, delicate articulations are required in its performance such that there exhibit much complexities in its sound, making the evaluation more difficult. In this paper, a note separation algorithm based on spectral domain factorization is used to extract the notes from recordings of violin solo performances. Each note can then be quantitatively evaluated based on a set of metrics that is designed to provide various aspects of violin performances including pitch accuracy, bowing steadiness, vibrato depth/rate, bowing intensity, tempo, and timbre characteristics and so on. The tools should be useful in musical instrument performance education.","","Electronic:978-986-90006-0-4; POD:978-1-4799-2794-4","10.1109/APSIPA.2013.6694296","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694296","","Frequency conversion;Frequency estimation;Instruments;Music information retrieval;Timbre;Time-frequency analysis","audio signal processing;matrix decomposition;musical instruments","bowed-string instruments;bowing steadiness;keyboard instruments;musical instrument performance education;musical instruments;note separation algorithm;pitch accuracy;quantitative evaluation;spectral domain factorization;tempo;vibrato depth/rate;violin solo performance","","0","","20","","","Oct. 29 2013-Nov. 1 2013","","IEEE","IEEE Conference Publications"
"KnowLife: A knowledge graph for health and life sciences","P. Ernst; C. Meng; A. Siu; G. Weikum","Databases & Inf. Syst., Max-Planck Inst. for Inf., Saarbrucken, Germany","2014 IEEE 30th International Conference on Data Engineering","20140519","2014","","","1254","1257","Knowledge bases (KB's) contribute to advances in semantic search, Web analytics, and smart recommendations. Their coverage of domain-specific knowledge is limited, though. This demo presents the KnowLife portal, a large KB for health and life sciences, automatically constructed from Web sources. Prior work on biomedical ontologies has focused on molecular biology: genes, proteins, and pathways. In contrast, KnowLife is a one-stop portal for a much wider range of relations about diseases, symptoms, causes, risk factors, drugs, side effects, and more. Moreover, while most prior work relies on manually curated sources as input, the KnowLife system taps into scientific literature as well as online communities. KnowLife uses advanced information extraction methods to populate the relations in the KB. This way, it learns patterns for relations, which are in turn used to semantically annotate newly seen documents, thus aiding users in “speed-reading”. We demonstrate the value of the KnowLife KB by various use-cases, supporting both layman and professional users.","1063-6382;10636382","Electronic:978-1-4799-2555-1; POD:978-1-4799-2556-8; USB:978-1-4799-2554-4","10.1109/ICDE.2014.6816754","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816754","","Diseases;Drugs;Information retrieval;Portals;Semantics;Unified modeling language","knowledge based systems;medical computing;portals","KnowLife portal;KnowLife system;Web analytics;Web sources;biomedical ontologies;documents annotation;domain-specific knowledge;genes;health science;knowledge base;knowledge graph;life science;molecular biology;online communities;pathways;proteins;scientific literature;semantic search;smart recommendations;speed-reading","","1","","13","","","March 31 2014-April 4 2014","","IEEE","IEEE Conference Publications"
"Design and implementation of information hiding system based on RGB","X. Tang; M. Chen","Sch. of Inf. & Commun. Guilin, Univ. of Electron. Technol., Guilin, China","2013 3rd International Conference on Consumer Electronics, Communications and Networks","20140109","2013","","","217","220","The improved method of text steganography based on RGB is proposed in this paper, and we present a promising algorithm for information hiding in Word document, which by means of changing the RGB values of character and underline. Specially, the most important part is an information hiding system which is designed based on the attribute of characters. The general methods of text information hiding are analyzed briefly. In this algorithm, the RGB values of character and underline are converted to ensure the information hiding capacity of each character hide 8-bit information. Tests and comparisons show that the algorithm expands the hidden capacity and improves the imperceptibility of carrier document. Furthermore, it obtains a favorable compromise between robustness and imperceptibility.","","DVD:978-1-4799-2858-3; Electronic:978-1-4799-2860-6; POD:978-1-4799-2861-3","10.1109/CECNet.2013.6703310","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6703310","RGB;information hiding;text steganography;word document","Algorithm design and analysis;Color;Cryptography;Educational institutions;Information retrieval;Internet;Redundancy","steganography;text analysis","RGB;information hiding system;text steganography;word document","","0","","12","","","20-22 Nov. 2013","","IEEE","IEEE Conference Publications"
"An approach for mining heterogeneous data for cross-media retrieval","K. M. Pavan; V. S. Ananthanarayana","Dept. of Inf. Technol., Nat. Inst. of Technol. Karnataka, Mangalore, India","2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)","20140130","2013","","","1","5","Due to the wide availability of huge amount of multimedia data in various modalities such as image and text documents, having a great amount of similarity among them is inevitable. In this paper, we present an efficient model which correlates the similarity among documents belonging to various modalities to achieve cross-media retrieval. Cross-media retrieval is a content based information retrieval system where heterogeneous data is mined to retrieve results of various modalities, i.e., input object and returned results may be of different modalities. For example, text objects can be retrieved as a result to image input. First, features are extracted from multimedia objects by which the objects are labeled. Using the labels, similar documents are grouped to generate Multimedia Documents. We construct a cross-media correlation graph with documents as vertices, where positive weight is assigned to every single edge according to the amount of similarity between vertices. The cross-media retrieval system identifies the input document and as a result returns required number of documents with highest weights.","","Electronic:978-1-4799-3926-8; POD:978-1-4799-3927-5","10.1109/ICCCNT.2013.6726794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726794","cross-media correlation graph;cross-media retrieval;image segmentation;multimedia document","Animals;Correlation;Feature extraction;Image segmentation;Information retrieval;Multimedia communication;Training data","data mining;graph theory;information retrieval;multimedia computing;text analysis","cross media correlation graph;cross media retrieval;data mining;image documents;information retrieval system;multimedia data;multimedia documents;multimedia objects;text documents","","0","","18","","","4-6 July 2013","","IEEE","IEEE Conference Publications"
"Securing building management systems using named data networking","W. Shang; Q. Ding; A. Marianantoni; J. Burke; L. Zhang","","IEEE Network","20140626","2014","28","3","50","56","Recently, building automation and management systems, BASs and BMSs, have shifted from using proprietary protocols and specialized hardware toward widespread adoption of IP-based open standard technologies. While the IP protocol suite improves software and hardware interoperability, practical large-scale BMS deployments face challenges, including the complexity of network addressing and other configuration, reliance on middleware for even relatively simple tasks, and a lack of security. In this article, we propose a data-centric BMS design that uses named data networking, one of the proposed information-centric networking architecture designs. Our sensor data acquisition system uses a hierarchical namespace for data, encryption keys, and access control lists, implements encryption-based access control, and provides a web browser-based data visualization interface that communicates in NDN. Our design has been deployed on a UCLA campus testbed that captures, archives, and visualizes data from industry standard sensors.","0890-8044;08908044","","10.1109/MNET.2014.6843232","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843232","","Access control;Building automation;Cryptography;IP networks;Information retrieval;Information technology;Logic gates;Network architecture;Network security;Protocols","Internet;authorisation;building management systems;cryptography;data acquisition;data visualisation;online front-ends","IP-based open standard technologies;Internet architecture;NDN;UCLA campus testbed;Web browser-based data visualization interface;access control lists;building automation systems;building management systems;data-centric BMS design;encryption keys;encryption-based access control;hierarchical data namespace;industry standard sensors;information-centric networking architecture designs;named data networking;sensor data acquisition system;software-hardware interoperability","","15","","13","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Comparative analysis of similarity measures for sentence level semantic measurement of text","S. M. Saad; S. S. Kamarudin","Product Quality & Reliability Eng., MIMOS Berhad, Kuala Lumpur, Malaysia","2013 IEEE International Conference on Control System, Computing and Engineering","20140123","2013","","","90","94","The accuracy of similarity measurement between sentences is critical to the performance of several applications such as text mining, question answering, and text summarization. This paper focuses on calculating semantic similarities between sentences and performing a comparative analysis among identified similarity measurement techniques. Comparison between three popular similarity measurements which are Jaccard, Cosine and Dice similarity measures has been conducted. The performance of each identified measurement was evaluated and recorded. In this paper, we use a large lexical database of English known as WordNet to calculate the word-to-word semantic similarity. The result of this research concludes that the Jaccard and Dice performs better in measuring the semantic similarity between sentences.","","Electronic:978-1-4799-1508-8; POD:978-1-4799-1507-1","10.1109/ICCSCE.2013.6719938","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719938","Semantic Similarity;Sentence Similarity;Similarity Measurement","Benchmark testing;Conferences;Control systems;Information retrieval;Measurement techniques;Semantics;Vectors","database management systems;natural language processing;text analysis","Cosine similarity measure;Dice similarity measure;English lexical database;Jaccard similarity measure;WordNet;comparative analysis;sentence semantic similarity;similarity measurement technique;text sentence level semantic measurement;word-to-word semantic similarity","","0","","22","","","Nov. 29 2013-Dec. 1 2013","","IEEE","IEEE Conference Publications"
"Heterogeneous biological data integration with declarative query language","H. Nguyen; L. Michel; J. D. Thompson; O. Poch","","IBM Journal of Research and Development","20140415","2014","58","2/3","15:1","15:12","The requirements for scalable data integration systems for modern biology are indisputable, due to the very large, heterogeneous, and complex datasets available in public databases. The management and fusion of this “big data” with local databases represents a major challenge, since it underlies the computational inferences and models that will be subsequently generated and validated experimentally. In this paper, we present an alternative conception for local data integration, called BIRD (Biological Integration and Retrieval Data), based on four concepts: (i) a hybrid flat file and relational database architecture permits the rapid management of large volumes of heterogeneous datasets; (ii) a generic data model allows the simultaneous organization and classification of local databases according to real-world requirements; (iii) configuration rules are used to divide and map each data resource into several data model entities; and (iv) a simple, declarative query language (BIRD-QL) facilitates information extraction from heterogeneous datasets. This flexible, generic design allows the integration of diverse data formats in a searchable database with high-level functionalities depending on the specific scientific context. It has been validated in the context of real world projects, notably the SM2PH (Structural Mutation to the Phenotypes of Human Pathologies) project.","0018-8646;00188646","","10.1147/JRD.2014.2309032","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6798740","","Biology;Data integration;Data models;Database languages;Information retrieval;Query processing;Relational databases;Scalability","","","","0","","","","","March-May 2014","","IBM","IBM Journals & Magazines"
"Performance analysis and improvement of naïve Bayes in text classification application","Wei Zhang; Feng Gao","MOE KLINNS Lab, Xi'an Jiaotong University, Shaanxi Province, China","IEEE Conference Anthology","20140410","2013","","","1","4","Naive Bayes classifier is widely used in machine learning for its simplicity and efficiency. However, most of the existing work on naïve Bayes focused on improving the Bayes model itself or whether the “naïve assumption” is satisfied. In this paper, the performance of naïve bayes in text classification is analyzed and the corresponding results from different points of view is proposed, then an improving way for text classification with highly asymmetric misclassification costs is provided. Finally the related experiments proved the above proposed method were efficient.","","Electronic:978-1-4799-1660-3","10.1109/ANTHOLOGY.2013.6784818","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784818","Feature Selection;Machine Learning;Naïve Bayes;Text Classification","Educational institutions;Information retrieval;Performance analysis;Postal services;Random variables;Text categorization;Unsolicited electronic mail","","","","0","","15","","","1-8 Jan. 2013","","IEEE","IEEE Conference Publications"
"Semisupervised Wrapper Choice and Generation for Print-Oriented Documents","A. Bartoli; G. Davanzo; E. Medvet; E. Sorio","Dept. of Eng. & Archit. (DIA), Univ. of Trieste, Trieste, Italy","IEEE Transactions on Knowledge and Data Engineering","20131125","2014","26","1","208","220","Information extraction from printed documents is still a crucial problem in many interorganizational workflows. Solutions for other application domains, for example, the web, do not fit this peculiar scenario well, as printed documents do not carry any explicit structural or syntactical description. Moreover, printed documents usually lack any explicit indication about their source. We present a system, which we call PATO, for extracting predefined items from printed documents in a dynamic multisource scenario. PATO selects the source-specific wrapper required by each document, determines whether no suitable wrapper exists, and generates one when necessary. PATO assumes that the need for new source-specific wrappers is a part of normal system operation: new wrappers are generated online based on a few point-and-click operations performed by a human operator on a GUI. The role of operators is an integral part of the design and PATO may be configured to accommodate a broad range of automation levels. We show that PATO exhibits very good performance on a challenging data set composed of more than 600 printed documents drawn from three different application domains: invoices, datasheets of electronic components, and patents. We also perform an extensive analysis of the crucial tradeoff between accuracy and automation level.","1041-4347;10414347","","10.1109/TKDE.2012.254","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6399473","Document management;administrative data processing;business process automation;data entry;human-computer interaction;retrieval models","Accuracy;Automation;Data mining;Graphical user interfaces;Humans;Information retrieval;Patents","document handling;information retrieval","GUI;PATO;automation levels;dynamic multisource scenario;electronic component datasheets;interorganizational workflows;invoices;normal system operation;patents;point-and-click operations;predefined item extraction;print-oriented documents;printed documents;semisupervised wrapper choice;semisupervised wrapper generation;source-specific wrappers","","0","","33","","20121231","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"What's Missing from Collaborative Search?","M. A. Hearst","Univ. of California, Berkeley, Berkeley, CA, USA","Computer","20140312","2014","47","3","58","61","Research shows that people frequently try to search for information with other people. The fact that no user interface for collaborative searching has yet caught fire suggests that the best parts of the design space have yet to be investigated.","0018-9162;00189162","","10.1109/MC.2014.77","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6766105","collaborative information seeking;collaborative search;search tools;user interface","Collaboration;Information retrieval;Knowledge discovery;Search methods;Search problems;User interfaces;Web search","collaborative filtering","collaborative searching;information search;user interface","","2","","19","","","Mar. 2014","","IEEE","IEEE Journals & Magazines"
"Enabling persistent queries for cross-aggregate performance monitoring","A. Mandal; I. Baldin; Y. Xin; P. Ruth; C. Heerman","Rice Univ., Houston, TX, USA","IEEE Communications Magazine","20140519","2014","52","5","157","164","It is essential for distributed, data-intensive applications to monitor the performance of the underlying network, storage, and computational resources. Increasingly, distributed applications need performance information from multiple aggregates, and tools need to make real-time steering decisions based on the performance feedback. With increasing scale and complexity, the volume and velocity of monitoring data is increasing, posing scalability challenges. In this work, we have developed a persistent query agent (PQA) that provides real-time application and network performance feedback to clients/ applications, thereby enabling dynamic adaptations. The PQA enables federated performance monitoring by interacting with multiple aggregates and performance monitoring sources. Using a publish-subscribe framework, it sends triggers asynchronously to applications/clients when relevant performance events occur. The applications/clients register their events of interest using declarative queries and get notified by the PQA. The PQA leverages a complex event processing (CEP) framework for managing and executing the queries expressed in a standard SQL-like query language. Instead of saving all monitoring data for future analysis, PQA observes performance event streams in real time, and runs continuous queries over streams of monitoring events. In this work, we present the design and architecture of the PQA, and describe some relevant use cases.","0163-6804;01636804","","10.1109/MCOM.2014.6815907","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815907","","Distributed processing;Information retrieval;Internet;Java;Performance evaluation;Query processing;Real-time systems;Search methods","computer network management;computer network performance evaluation;query languages;software agents","PQA;SQL-like query language;complex event processing;computational resource monitoring;cross aggregate performance monitoring;data intensive applications;distributed applications;network performance feedback;network resource monitoring;performance monitoring source;persistent query agent;real time application;storage resource monitoring","","1","","15","","","May 2014","","IEEE","IEEE Journals & Magazines"
"Supporting Interpersonal Interaction during Collaborative Mobile Search","J. Teevan; M. R. Morris; S. Azenkot","","Computer","20140312","2014","47","3","54","57","O-SNAP is a mobile application that explicitly supports in-person collaborative search by enabling users to physically signal their willingness to share and by facilitating face-to-face search-related communication. The Web extra at http://youtu.be/AKoITuxB9BY is a video in which author Meredith Ringel Morris discusses scenarios that can prompt collaborative information seeking.","0018-9162;00189162","","10.1109/MC.2013.449","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6701298","collaborative search;local search;mobile search","Collaboration;Computer applications;Information retrieval;Knowledge discovery;Mobile communication;Mobile handsets;Search methods;Visualization","groupware;information retrieval;mobile computing;social networking (online)","O-SNAP;Web extra;collaborative information seeking;collaborative mobile search;face-to-face search-related communication;in-person collaborative search;interpersonal interaction;mobile application","","2","","5","","20140102","Mar. 2014","","IEEE","IEEE Journals & Magazines"
"Browse and Search in Maritime Document Collections","V. Dragos","ONERA-The French Aerosp. Lab., Palaiseau, France","2013 European Intelligence and Security Informatics Conference","20131107","2013","","","225","225","This paper presents an approach to explore collection of documents in the maritime domain. Documents are reports created by experts in order to explain suspicious vessel behaviours and the collection is semantically integrated by using a domain ontology and associated instance elements. Browse and search strategies allows us to find events occurring in various maritime areas and to highlight clues explaining abnormal behaviour of vessels.","","Electronic:978-0-7695-5062-6; POD:978-1-4799-0775-5","10.1109/EISIC.2013.57","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6657167","information sharing","Europe;Indexes;Information retrieval;Knowledge management;Ontologies;Security;Semantics","document handling;information retrieval;marine engineering;ontologies (artificial intelligence)","associated instance elements;browse and search strategies;domain ontology;maritime document collections;suspicious vessel behaviours;vessel abnormal behaviour","","0","","4","","","12-14 Aug. 2013","","IEEE","IEEE Conference Publications"
"Topics and Terms Mining in Unstructured Data Stores","R. K. Lomotey; R. Deters","Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada","2013 IEEE 16th International Conference on Computational Science and Engineering","20140306","2013","","","854","861","One of the major challenges of the ""Big Data"" epoch is unstructured data mining. The problem arises due to the storage of high-dimensional data that has no standard schema. While knowledge discovery in database (KDD) algorithms were designed for data extraction, the algorithms best fit for structured data storages. Moreover, today, at the data storage level, NoSQL databases have been deployed in response to accommodate the unstructured data. However, the over-reliance on multiple APIs by NoSQL storages hampers efficient data extraction from different NoSQL storages. Also, there are limited numbers of tools available that can perform KDD tasks on NoSQL data stores. In this work, we explore the trend in unstructured data mining and detail the future direction and challenges. Then, focusing on topics and terms extraction from NoSQL databases, we propose a tool called TouchR2, which algorithmically relies on bloom filtering and parallelization. Using the CouchDB data storage as the test case, the evaluation of TouchR2 shows high accuracy for terms extraction and organization within a much optimized duration.","","Electronic:978-0-7695-5096-1; POD:978-1-4799-4897-0","10.1109/CSE.2013.129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755309","Association Rules;Big Data;Bloom Filtering;NoSQL;Terms;Topics;Unstructured Data Mining","Association rules;Data handling;Data storage systems;Databases;Information management;Information retrieval","application program interfaces;data mining;data structures;software tools;storage management","Big Data epoch;CouchDB data storage;KDD algorithms;NoSQL databases;TouchR2 tool;bloom filtering;data extraction;data storage level;high-dimensional data storage;knowledge discovery in database algorithms;multiple APIs;structured data storages;terms extraction;terms mining;topics extraction;topics mining;unstructured data mining;unstructured data stores","","1","","33","","","3-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Digital libraries for disabled persons","V. Pasichnyk; N. Kunanets; O. Malynovskyi","Inf. Syst. & Networks Dept., Lviv Polytech. Nat. Univ., Lviv, Ukraine","2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)","20131114","2013","01","","212","215","The ways to improve the efficiency of submission information using multimedia technology were examined in this report, thus ensuring the use of a powerful new tool for perception of information by disabled persons. The formation peculiarities of multimedia information content for disabled persons were analyzed. This paper considers digital library as an information system, where information is formed and collected from different sources, sorted, structured and intellectually processed and it's proposed a set of information technology services, making multimedia information content accessible for disabled persons.","","Electronic:978-1-4799-1429-6; POD:978-1-4799-1425-8","10.1109/IDAACS.2013.6662673","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662673","digital library;disabled persons;information content;multimedia","Information retrieval;Information technology;Libraries;Market research;Multimedia communication","digital libraries;handicapped aids;information retrieval;information systems;multimedia computing;sorting","digital libraries;disabled persons;information collection;information forming;information perception;information sorting;information structuring;information system;information technology services;intellectually processed information;multimedia information content accessibility;submission information efficiency improvement","","0","","10","","","12-14 Sept. 2013","","IEEE","IEEE Conference Publications"
"A Multimodal Approach to Song-Level Style Identification in Pop/Rock Using Similarity Metrics","C. H. Chuan","Sch. of Comput., Univ. of North Florida, Jacksonville, FL, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","2","","321","324","This paper presents a multimodal approach to style identification in pop/rock music. Considering the intuitive feelings of similarity from the listener's perspective, this study focuses on features that are computed using similarity metrics for melodies, harmonies, and audio signals for style identification. Support vector machine is used as a binary classifier to determine if two songs are created by the same artist given their similarity distances in the three aspects. Experiments are conducted using songs of four well-known pop/rock bands from 6 albums. The preliminary result shows that the approach achieves the best result in correct rate of 85% using only seven similarity metrics.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786128","Gaussian mixture models;melodic contour;music similarity;n-grams;style","Feature extraction;Measurement;Music;Music information retrieval;Rocks;Support vector machines","Gaussian processes;audio signals;music;pattern classification;support vector machines","Gaussian mixture models;audio signals;binary classifier;harmonies;intuitive similarity feelings;melodies;multimodal approach;pop music;rock music;similarity distances;similarity metrics;song-level style identification;support vector machine","","0","","17","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Multi-abstraction Concern Localization","T. D. B. Le; S. Wang; D. Lo","Sch. of Inf. Syst., Singapore Manage. Univ., Singapore, Singapore","2013 IEEE International Conference on Software Maintenance","20131202","2013","","","364","367","Concern localization refers to the process of locating code units that match a particular textual description. It takes as input textual documents such as bug reports and feature requests and outputs a list of candidate code units that need to be changed to address the bug reports or feature requests. Many information retrieval (IR) based concern localization techniques have been proposed in the literature. These techniques typically represent code units and textual descriptions as a bag of tokens at one level of abstraction, e.g., each token is a word, or each token is a topic. In this work, we propose multi-abstraction concern localization. A code unit and a textual description is represented at multiple abstraction levels. Similarity of a textual description and a code unit, is now made by considering all these abstraction levels. We have evaluated our solution on AspectJ bug reports and feature requests from the iBugs benchmark dataset. The experiment shows that our proposed approach outperforms a baseline approach, in terms of Mean Average Precision, by up to 19.36%.","1063-6773;10636773","Electronic:978-0-7695-4981-1; POD:978-1-4673-5218-5","10.1109/ICSM.2013.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6676908","Concern Localization;Latent Dirichlet Allocation;Multi-Abstraction;Text Retrieval;Topic Model","Computational modeling;Europe;Information retrieval;Java;Mathematical model;Standards;Vectors","information retrieval","AspectJ bug reports;IR based concern localization techniques;code unit localization;feature requests;iBugs benchmark dataset;information retrieval;input textual documents;mean average precision;multiabstraction concern localization;multiple abstraction levels;textual description;token","","5","","14","","","22-28 Sept. 2013","","IEEE","IEEE Conference Publications"
"A rural construction land extraction algorithm for UAV images based on improved Gaussian mixture model and Markov random field","W. Wang; Y. Chen; X. Zhang","State Key Lab. of Earth Surface Processes & Resource Ecology, Beijing Normal Univ., Beijing, China","2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS","20140127","2013","","","1505","1508","In this paper, we propose a novel rural construction land extraction algorithm for Unmanned Aerial Vehicle images using an improved Gaussian mixture model. Firstly, in the Gaussian mixture model, instead of mixed probability of various types of surface features, we calculate the prior probability of the various features in the neighborhood of each pixel using Markov random field. It can reflect the features' spatial correlation. Secondly, we use the simulated annealing to obtain the global optimum parameter estimates in the process of parameter estimation. Finally, we calculate the posterior probability of each pixel for the features using the parameters' estimated value. Then, we can obtain the spatial distribution of various features. The effect of the proposed algorithm is analyzed through experiment. The experiment shows that our proposed method can improve accuracy of construction land information extraction and has better performance than other methods.","2153-6996;21536996","Electronic:978-1-4799-1114-1; POD:978-1-4799-1112-7","10.1109/IGARSS.2013.6723072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6723072","Gaussian Mixture Model;Information Extraction;Simulated Annealing","Accuracy;Educational institutions;Feature extraction;Gaussian mixture model;Information retrieval;Simulated annealing","Gaussian processes;Markov processes;autonomous aerial vehicles;geophysical image processing;mixture models;parameter estimation;probability;robot vision;simulated annealing;terrain mapping","Markov random field;construction land information extraction accuracy;global optimum parameter;improved Gaussian mixture model;mixed probability;parameter estimation;posterior probability;prior probability;rural construction land extraction algorithm;simulated annealing;spatial correlation;spatial distribution;surface features;unmanned aerial vehicle images","","0","","8","","","21-26 July 2013","","IEEE","IEEE Conference Publications"
"Query by Humming by Using Scaled Dynamic Time Warping","Y. Kim; C. H. Park","Dept. of Comput. Sci. & Eng., Chungnam Nat. Univ., Daejeon, South Korea","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","1","5","Query by Singing/Humming(QBSH) is to retrieve songs in the music database using user's singing or humming. Open-End Dynamic Time Warping (OEDTW) is one of the methods which are commonly used in QBSH studies. This paper proposes a method for improving OEDTW performance using optimal scaling factor taken from Linear scaling phase. The proposed method finds an optimal global scale of a query for each target song by linear scaling and key shifting of the query and target song over the obtained scale can complement DTW or OEDTW. The experimental results demonstrate that the proposed method can improve Top-1 hit rate by 32% compared with the original DTW.","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727161","Dynamic Time Warping (DTW);Linear Scaling (LS);Open-end Dynamic Time Warping (OEDTW);Query by Singing/Humming (QBSH)","Data mining;Feature extraction;Filtering;Internet;Multimedia communication;Music information retrieval;Vectors","music;query processing","OEDTW performance improvement;QBSH;key shifting;linear scaling phase;music database;open-end dynamic time warping;optimal scaling factor;query by singing/humming;scaled dynamic time warping;song retrieval","","1","","21","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"A Novel Method of Citation Sequence Labeling Based on Conditional Random Fields","J. Zhou; D. Shen; T. Nie; Y. Kou; G. Yu","Coll. of Inf. Sci. & Eng., Northeastern Univ., Shenyang, China","2013 10th Web Information System and Application Conference","20140327","2013","","","184","187","Citation sequence labeling is an essential phase in citation entity resolution and other applications on citations. Scholars proposed many methods and models. In all the statistical learning models, the conditional random fields (CRFs) is the best one which is studied and used extensively. Most of the papers which study applications based on conditional random fields focus on the three basic questions and pay less attention to feature selection, granularity choosing and structure learning. This paper has discussed the use of text features in citation sequence labeling based on conditional random fields model. According to this, this paper made some differences in structure learning and feature selection. Experimental results show that our algorithm make a further improvement in the precision of citation sequence labeling.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778634","citation sequence labeling;conditional random fields;statistical learning model;text features","Hidden Markov models;Information retrieval;Labeling;Parameter estimation;Semantics;Statistical learning;Training data","citation analysis;learning (artificial intelligence);random processes;text analysis","citation entity resolution;citation sequence labeling;conditional random fields;feature selection;granularity choosing;statistical learning model;structure learning;text features","","0","","14","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"Characterization of Corpora from Enterprise Technology Creation for Retrieval and Mining","V. Deolalikar","HP-Autonomy Res., Sunnyvale, CA, USA","2013 IEEE 13th International Conference on Data Mining Workshops","20140306","2013","","","365","369","Enterprise information management (EIM) deals with the demands upon enterprise unstructured information placed by applications such as eDiscovery, compliance, information lifecycle management, etc. Each of these applications poses a unique challenge to the retrieval and data mining of enterprise unstructured information. However, the study of EIM as a research field has long been hampered by the lack of availability of enterprise corpora. Due to this paucity of enterprise datasets, much of the research on information retrieval and mining that is meant for EIM is benchmarked on corpora that are vastly different in their structure than a typical enterprise corpus. An important category of enterprise corpora are those that arise during technology creation in an enterprise. Such corpora take center stage, for example, during eDiscovery requests arising from technology patent related litigation: an area of immense commercial impact. In this paper, we highlight the primary characteristics of enterprise corpora that arise during technology creation. At a high-level, these properties are project structure, heterogeneity, collaborations, and skew ness along various axes. We then study these characteristics in a carefully chosen enterprise corpus from a technology creation effort at a Fortune 10 corporation. In summary, we study the salient features of enterprise corpora and emphasize their structural properties. We hope that our study will spur effort in devising retrieval and mining techniques that are designed for EIM.","2375-9232;23759232","Electronic:978-1-4799-3142-2; POD:978-1-4799-3144-6","10.1109/ICDMW.2013.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6753943","Enterprise Corpora;Enterprise Information Management;Technology Creation","Aggregates;Benchmark testing;Collaboration;Data mining;Information management;Information retrieval;Organizations","business data processing;data mining;information retrieval","EIM;corpora characterization;enterprise information management;enterprise technology creation;enterprise unstructured information data mining;enterprise unstructured information retrieval","","1","","8","","","7-10 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Information Extraction from Texts with Inference and Linguistic Knowledge Acquisition Rules","D. A. d. Araujo; S. J. Rigo; C. Muller; R. Chishman","PIPCA, UNISINOS, Sa&#x0303;o Leopoldo, Brazil","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","3","","151","154","In this paper we present a novel methodology for automatic information extraction from natural language texts, based on the integration of linguistic rules, multiple ontologies and inference resources, integrated with an abstraction layer for linguistic annotation and data representation. The methodology allows ontology population with instances of events. The main contribution presented is related to the exploration of the flexibility of linguistic rules and domain knowledge representation, through their manipulation and integration by a reasoning system. The results from the case study indicate that the proposed approach is effective for the legal domain.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690716","information extraction;natural language processing;ontolog;reasoning","Information retrieval;Law;Natural languages;OWL;Ontologies;Pragmatics","inference mechanisms;knowledge acquisition;natural language processing;ontologies (artificial intelligence);text analysis","abstraction layer;automatic information extraction;data representation;domain knowledge representation;inference resources;legal domain;linguistic annotation;linguistic knowledge acquisition rules;linguistic rules integration;natural language texts;ontologies;ontology population;reasoning system","","0","1","19","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"An improved Arabic light stemmer","O. M. Elrajubi","Dept. of Commun. & Networks, Misurata Univ., Misurata, Libya","2013 International Conference on Research and Innovation in Information Systems (ICRIIS)","20140123","2013","","","33","38","According to the desired level of analyzing words, Arabic stemming algorithms can be classified into stem-based (light stemming algorithms), and root-based algorithms. Light stemming algorithms only remove prefixes and suffixes from the words, while root-based algorithms remove prefixes, suffixes and infixes. There are several light stemmers for Arabic (Light1, Light2, Light3, Light8, and Light10), For retrieval information Light10 stemmer is out-performed the other light stemmers. In this paper, Arabic stemming algorithms are studied. And, literature review of Arabic stemmers is discussed. In addition, a new Arabic light stemmer was proposed and Implemented. The main step of the light stemmer is removing the prefixes and suffixes of the words. And because this step causes changing of the meaning of some words, many other steps are designed and implemented in the proposed stemmer. The proposed stemmer and Light10 stemmer were tested on the same Arabic data which is developed in this work. The accuracy rate of Light10 stemmer was 66%, while the accuracy rate of the proposed stemmer was 88.25 %. The reasons for incorrect stemming of the proposed stemmer are mentioned.","2324-8149;23248149","Electronic:978-1-4799-2487-5; POD:978-1-4799-2488-2","10.1109/ICRIIS.2013.6716682","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6716682","Arabic light stemmer;Arabic retrieval;Arabic stemming;suffixes and prefixes stripping","Accuracy;Algorithm design and analysis;Classification algorithms;Information retrieval;Information systems;Internet;Technological innovation","information retrieval;natural language processing","Arabic light stemmer;Light1 stemmer;Light10 stemmer;Light2 stemmer;Light3 stemmer;Light8 stemmer;infix removal;information retrieval;light stemming algorithms;prefix removal;root-based algorithms;stem-based algorithms;suffix removal;words analysis","","3","","15","","","27-28 Nov. 2013","","IEEE","IEEE Conference Publications"
"NLP as an essential ingredient of effective OSINT frameworks","S. Noubours; A. Pritzkau; U. Schade","Fraunhofer Inst. for Commun., Inf. Process. & Ergonomics FKIE, Wachtberg, Germany","2013 Military Communications and Information Systems Conference","20140102","2013","","","1","7","The immense amount of information that can be collected from open sources have become increasingly important to the academic and business communities over the past two decades. Also national and global security is becoming more and more reliant on rapidly making sense of and managing the relevant intelligence data. The enormous size and complexity of the gathered data require advanced and unique data storage, management, analysis, and visualization technologies. The technologies and applications currently adopted typically involve elements like text mining, natural language processing, and stochastic-based algorithms. Natural language processing, in particular, has been a prominent research topic for many years now. We have conceptualized an analysis framework with a strong focus on various techniques of natural language processing to aggregate, manipulate, and analyze intelligence information.","","CD-ROM:978-83-934848-8-1; Electronic:978-83-934848-4-3; POD:978-1-4799-1261-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6695527","natural language processing;open sources intelligence;text analysis;text mining","Context;Information retrieval;Natural language processing;Pragmatics;Semantics;Text categorization","data mining;natural language processing;text analysis","NLP;OSINT frameworks;global security;intelligence data;national security;natural language processing;open sources intelligence;stochastic-based algorithms;text mining","","1","","17","","","7-9 Oct. 2013","","IEEE","IEEE Conference Publications"
"Tolerance Rough Set Model and Its Applications in Web Intelligence","H. S. Nguyen","Inst. of Math., Univ. of Warsaw, Warsaw, Poland","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","3","","237","244","Tolerance Rough Set Model (TRSM) has been introduced as a tool for approximation of hidden concepts in text databases. In recent years, numerous successful applications of TRSM in web intelligence including text classification, clustering, thesaurus generation, semantic indexing, and semantic search, etc., have been proposed. This paper will review the fundamental concepts of TRSM, some of its possible extensions and some typical applications of TRSM in text mining. Moreover, the architecture o a semantic information retrieval system, called SONCA, will be presented to demonstrate the main idea as well as stimulate the further research on TRSM.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690734","Tolerance rough set model;classification;clustering;semantic indexing;semantic search","Approximation methods;Indexes;Information retrieval;Ontologies;Semantics;Standards;Vectors","data mining;information retrieval systems;ontologies (artificial intelligence);rough set theory;text analysis","SONCA system;TRSM;Web intelligence;clustering;search based on ontologies and compound analytics;semantic indexing;semantic information retrieval system;semantic search;text classification;text databases;text mining;thesaurus generation;tolerance rough set model","","0","","39","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"VICN: a versatile deployment framework for information-centric networks","J. Ren; K. Lu; S. Wang; X. Wang; S. Xu; L. Li; S. Liu","Commun. Eng., Univ. of Electron. Sci. & Technol. of China, Chengdu, China","IEEE Network","20140626","2014","28","3","26","34","Information-centric networking, ICN, is a promising technology for future Internet design, with which a user can directly obtain a content object by its name (or identification), without specifying the location of the content object. In recent years, various ICN architectures have been proposed, and they differ significantly in terms of naming, routing, etc. Consequently, it becomes a major challenge to convince network service providers to deploy ICN-enabled networks. In this article, we will address this challenging issue by proposing a novel deployment framework, versatile ICN, based on software-defined networking concepts, which can efficiently enable different ICN architectures and can facilitate interoperation among ICN instances. Specifically, we first review existing ICN architectures and abstract their core functions. We then elaborate on the main ideas of the VICN framework, including application scenarios, design criteria, and key hardware and software components. To illustrate how the framework can be applied, we develop a prototype that can enable two major ICN architectures, and also facilitate interoperation between them. Using the prototype, we conduct evaluations to show how a user of one ICN instance can obtain a content object from another ICN instance, where the two ICN instances adopt different ICN architectures and are deployed on two NSP networks. Evaluation results confirm that the proposed framework is viable and can lead to much better delay and throughput performance.","0890-8044;08908044","","10.1109/MNET.2014.6843229","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843229","","Computer architecture;Information retrieval;Information technology;Internet;Network architecture;Prototypes;Routing protocols;Switches","Internet;open systems;telecommunication network routing","Internet;VICN;content naming;content request routing;information-centric networks;interoperation;software-defined networking;throughput performance;versatile ICN;versatile deployment framework","","4","1","14","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Open Information Extraction via Contextual Sentence Decomposition","H. Bast; E. Haussmann","Dept. of Comput. Sci., Univ. of Freiburg, Freiburg, Germany","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","154","159","We show how contextual sentence decomposition (CSD), a technique originally developed for high-precision semantic search, can be used for open information extraction (OIE). Intuitively, CSD decomposes a sentence into the parts that semantically ""belong together"". By identifying the (implicit or explicit) verb in each such part, we obtain facts like in OIE. We compare our system, called CSD-IE, to three state-of-the-art OIE systems: ReVerb, OLLIE, and ClausIE. We consider the following aspects: accuracy (does the extracted triple express a meaningful fact, which is also expressed in the original sentence), minimality (can the extracted triple be further decomposed into smaller meaningful triples), coverage (percentage of text contained in at least one extracted triple), and number of facts extracted. We show how CSD-IE clearly outperforms ReVerb and OLLIE in terms of coverage and recall, but at comparable accuracy and minimality, and how CSD-IE achieves precision and recall comparable to ClausIE, but at significantly better minimality.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693511","contextual sentence decomposition;open information extraction;semantic search","Accuracy;Context;Data mining;Educational institutions;Information retrieval;Semantics;Thyristors","information retrieval","CSD technique;CSD-IE system;ClausIE system;OLLIE system;ReVerb system;accuracy aspect;contextual sentence decomposition technique;coverage aspect;explicit verb;high-precision semantic search;implicit verb;minimality aspect;open information extraction;recall aspect","","2","","10","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Simulation of numerical semantic operations on strings in medical domain","T. Jo","School of Computer and Information Engineering Inha University Incheon, South Korea","2013 IEEE International Conference on Granular Computing (GrC)","20140217","2013","","","167","171","In this research, we define and simulate the numerical semantic operations on strings in the medical domain. The demand for processing medical documents more intelligently and the necessity of semantic computing on words in them are increasing, continually. What does in this research is to construct the similarity matrix which is the basis from the medical document corpus, define the numerical semantic operations, and simulate them on the corpus. This research provides the basis of developing semantic analysis tools of medical documents as the benefit from it. Thus, in the simulation, we will observe values of semantic similarity averages and variances on groups of words in the medical domain.","","Electronic:978-1-4799-1282-7","10.1109/GrC.2013.6740401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6740401","","Diseases;Encoding;Information retrieval;Semantics;Text categorization;Text mining;Vectors","medical information systems;numerical analysis;text analysis","medical document corpus;medical document processing;medical domain strings;numerical semantic operation simulation;semantic analysis tools;semantic computing necessity;similarity matrix;word groups","","0","","13","","","13-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"On the use of positional proximity in IR-based feature location","E. Hill; B. Sisman; A. Kak","Dept. of Comput. Sci., Montclair State Univ., Montclair, NJ, USA","2014 Software Evolution Week - IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE)","20140227","2014","","","318","322","As software systems continue to grow and evolve, locating code for software maintenance tasks becomes increasingly difficult. Recently proposed approaches to bug localization and feature location have suggested using the positional proximity of words in the source code files and the bug reports to determine the relevance of a file to a query. Two different types of approaches have emerged for incorporating word proximity and order in retrieval: those based on ad-hoc considerations and those based on Markov Random Field (MRF) modeling. In this paper, we explore using both these types of approaches to identify over 200 features in five open source Java systems. In addition, we use positional proximity of query words within natural language (NL) phrases in order to capture the NL semantics of positional proximity. As expected, our results indicate that the power of these approaches varies from one dataset to another. However, the variations are larger for the ad-hoc positional-proximity based approaches than with the approach based on MRF. In other words, the feature location results are more consistent across the datasets with MRF based modeling of the features.","","Electronic:978-1-4799-3752-3; POD:978-1-4799-3753-0","10.1109/CSMR-WCRE.2014.6747185","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6747185","feature location;software maintenance;source code search","Information retrieval;Java;Markov random fields;Natural languages;Semantics;Software maintenance","Java;Markov processes;natural language processing;software maintenance","IR-based feature location;Java system;MRF modeling;Markov random field;NL semantics;ad-hoc positional proximity;bug localization;natural language semantics;query word;software maintenance;word proximity","","1","","24","","","3-6 Feb. 2014","","IEEE","IEEE Conference Publications"
"Determining Relation Semantics by Mapping Relation Phrases to Knowledge Base","F. Liu; Y. Liu; G. Zhou; K. Liu; J. Zhao","Nat. Lab. of Pattern Recognition (NLPR), Inst. of Autom., Beijing, China","2013 2nd IAPR Asian Conference on Pattern Recognition","20140327","2013","","","420","424","Open Information Extraction (Open IE) recognizes domain-independent relational triples from natural language texts but does not recognize the exact semantics of the triples. Nevertheless, relations in existing knowledge bases, like manually edited attributes in Wikipedia Info boxes, have provided the semantic meaning of open relations. Therefore, our goal is to bridge the gap between open relation phrases extracted by an Open IE system and a pre-defined attributes in knowledge base. This task is important for Information Extraction. In this paper, we proposed a novel approach to map relation phrases to attributes in knowledge base. We matched relational triples extracted from Wikipedia articles with attribute triples generated from Wikipedia Info boxes. Finally, our system expanded 509 Wikipedia attributes with a total of 2,527 phrases. Experiments show that the proposed approach can achieve an average precision of 0.88±0.02 over all mapped relation pairs.","0730-6512;07306512","Electronic:978-1-4799-2190-4; POD:978-1-4799-2191-1","10.1109/ACPR.2013.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778353","Open Information Extraction;Relation Mapping;Wikipedia Infobox","Electronic publishing;Encyclopedias;Information retrieval;Internet;Knowledge based systems;Semantics","Web sites;information retrieval;knowledge based systems;natural language processing;semantic Web;text analysis","Wikipedia Info boxes;Wikipedia articles;Wikipedia attributes;attribute triples;domain-independent relational triples;knowledge base attributes;knowledge bases;natural language texts;open IE system;open information extraction;open relation phrases;relation phrases mapping;relation semantics;semantic meaning","","0","","18","","","5-8 Nov. 2013","","IEEE","IEEE Conference Publications"
"Finding Good XML Fragments Based on k-Medoid Cluster Number Optimization and Ranking Model for Feedback","Z. Minjuan","Sch. of Inf. Technol., Jiangxi Univ. of Finance & Econ., Nanchang, China","2013 International Conference on Information Technology and Applications","20140111","2013","","","333","337","Due to low quality feedback set, traditional pseudo relevance feedback may bring into topic drift. This paper studies how to identify or find good xml documents(fragments) for feedback. We propose an effective method, in which xml element search results clustering is performed firstly by k-mediod cluster number optimization, and then those fragments with high relevant to the query are identified and ranked in the top position by ranking model. The final experimental results show that the proposed approach produces better performance and achieves high quality feedback set.","","Electronic:978-1-4799-2877-4; POD:978-1-4799-2878-1","10.1109/ITA.2013.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6709999","Pseudo Relevance Feedback;XML feedback fragment;cluster number optimization;ranking model","Clustering algorithms;Frequency measurement;Information retrieval;Mathematical model;Optimization;Presses;XML","XML;document handling;pattern clustering;relevance feedback","XML documents;XML element search results clustering;XML fragments;high quality feedback set;k-medoid cluster number optimization;low quality feedback set;pseudo relevance feedback;ranking model;topic drift","","0","","9","","","16-17 Nov. 2013","","IEEE","IEEE Conference Publications"
"Investigating Collaborative Sensemaking Behavior in Collaborative Information Seeking","Y. Tao; A. Tombros","Queen Mary Univ. of London, London, UK","Computer","20140312","2014","47","3","38","45","Collaborative sensemaking is an important but under-studied aspect of collaborative information seeking. A better understanding of collaborative sensemaking behavior as it relates to online searches and the support needed to perform collaborative information-seeking tasks will lead to improvements in system designs for these activities.","0018-9162;00189162","","10.1109/MC.2014.64","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6766101","collaborative information seeking;sensemaking;user behavior;user study","Collaboration;Computer science;Information retrieval;Knowledge discovery;Knowledge engineering;Online services;Search methods","groupware;information retrieval","collaborative information seeking;collaborative sensemaking behavior;online search","","3","","18","","","Mar. 2014","","IEEE","IEEE Journals & Magazines"
"Effective search and exploitation of electromagnetic knowledge in the web [EM programmer's notebook]","A. Esposito; L. Tarricone; M. Zappatore; G. D. Fiori","Department of Innovation Engineering, University of Salento, Via Monteroni, 73100 Lecce - Italy","IEEE Antennas and Propagation Magazine","20140529","2014","56","1","182","199","We all are aware of the huge amount of electromagnetic information and knowledge available in the Web, both in the form of PDF scientific papers, and in other forms (e.g., software, datasets). Similarly, we all have experienced the frustration of searching the Web for papers and other information, and getting useless or unsatisfactory results. All these limitations clearly demonstrate that information technologies (IT) need further progress so as to improve the efficiency of the mentioned processes. Indeed, there is fervid activity around this goal, and some interesting achievements have begun to appear in terms of search effectiveness and navigation satisfaction. Novel formats for representing scientific-paper contents are proposed, enhancing machine processing capability. However, embracing the new information technology proposals requires a cultural change from authors and from editors, and we cannot take it for granted that it will happen in the near future. Moreover, already-published papers should not be left out from approaching Web innovations. In this paper, we therefore focus both on the emerging technologies for generating more searchable files, and on those technologies allowing the transformation of existing PDF files into more-effective formats. These technologies need to be customized to each specific domain, thus rendering the codification of specific electromagnetic (EM) concepts of paramount importance. A use case is proposed on a specific EM example, so as to demonstrate the viability and effectiveness of the proposed approach.","1045-9243;10459243","","10.1109/MAP.2014.6821774","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821774","Semantic Web;annotation;knowledge discovery;natural language processing;ontology;search methods","Electromagnetic devices;Information retrieval;Navigation;Ontologies;Publishing;Search methods;Web services;Wireless networks;information anlaysis","","","","0","","18","","","Feb. 2014","","IEEE","IEEE Journals & Magazines"
"Mashup technology: Beyond open programming interfaces","H. Han; Y. Xue; K. Oyama","Kanagawa Univ., Yokohama, Japan","Computer","20131219","2013","46","12","96","99","Web application integration at the presentation and logic layers is an appealing approach to enhancing Web services technologies. However, it's certainly not without challenges.","0018-9162;00189162","","10.1109/MC.2013.429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6689278","UI component;extraction;integration;mashup;retrieval;reuse;security;testing","Computer security;Information retrieval;Mashups;Security;User interfaces;Web and internet services","Web services;application program interfaces","Web application integration;Web services technologies;logic layer;mashup technology;open programming interfaces;presentation layer","","0","","","","","Dec. 2013","","IEEE","IEEE Journals & Magazines"
"Hybrid Ontology-Based Information Extraction for Automated Text Grading","F. Gutierrez; D. Dou; A. Martini; S. Fickas; H. Zong","Dept. of Comput. & Inf. Sci., Univ. of Oregon, Eugene, OR, USA","2013 12th International Conference on Machine Learning and Applications","20140410","2013","1","","359","364","Although automatic text grading systems have reached an accuracy level comparable to human grading, with successful commercial and research implementations (e.g., Latent Semantic Analysis), these systems can provide limited feedback about which statements of the text are incorrect and why they are incorrect. In the present work, we propose the use of a hybrid Ontology-based Information Extraction (OBIE) system to identify both correct and incorrect statements by combining extraction rules and machine learning based information extractors. Experiments show that given 77 student answers to a Cell Biology final exam question, our hybrid system can identify both correct and incorrect statements with high precision and recall measures.","","CD-ROM:978-1-4799-4154-4; Electronic:978-0-7695-5144-9; POD:978-1-4799-4155-1","10.1109/ICMLA.2013.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784643","","Biology;Data mining;Feature extraction;Information retrieval;Natural language processing;Ontologies;Semantics","educational administrative data processing;ontologies (artificial intelligence);text analysis","OBIE system;automated text grading;cell biology final exam question;extraction rules;hybrid ontology-based information extraction;learning based information extractors","","1","","16","","","4-7 Dec. 2013","","IEEE","IEEE Conference Publications"
"Evaluation of Triple Indices in Retrieving Web Documents","N. S. S. Zulkefli; N. A. Rahman; Z. A. Bakar; S. Nordin; T. M. T. Sembok; N. H. I. Teo","Dept. of Comput. Sci., Univ. Teknol. MARA, Shah Alam, Malaysia","2013 International Conference on Advanced Computer Science Applications and Technologies","20140619","2013","","","525","529","Indexing is one of the important technique used to make searching and retrieval process more accurate and faster. In this paper, the indexing features of triple stores are investigated to see the pattern of semantic indexing that will improve the current information retrieval indexing. To do the evaluation, we choose the best triple stores, Allegro Graph. Allegro Graph require more than one triple indices pattern to be matched with the query. Therefore we do the evaluation of triple indices to determine which triple indices pattern gives for fast retrieval. During experiment, we use RDF data. Then we matched the triple indices pattern with the SPARQL query to retrieve the relevant data. As the result, it would take longer if the system contains unneeded triple indices which will waste CPU times and disk space. Removing unneeded triple indices pattern will provide for fast retrieval.","","Electronic:978-1-4799-2758-6; POD:978-1-4799-2759-3","10.1109/ACSAT.2013.109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6836638","AllegroGraph;RDF;SPARQL query;Semantic indexing;Triple stores","Conferences;Indexing;Information retrieval;Pattern matching;Resource description framework;Semantics","Internet;document handling;indexing;query processing","Allegro graph;RDF data;SPARQL query;Web documents retrieval;indexing technique;information retrieval indexing;resource description framework;retrieval process;searching process;semantic indexing;triple indices evaluation","","0","","24","","","23-24 Dec. 2013","","IEEE","IEEE Conference Publications"
"Word-level information extraction from science and technology announcements corpus based on CRF","Y. Cao; J. Wang; L. Li","Sch. of Eng. & Appl. Sci., Univ. of Pennsylvania, Philadelphia, PA, USA","2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems","20131114","2012","03","","1529","1533","Conditional Random Field (CRF) has been applied widely in information extraction and natural language processing. However, according to corpus types, it has not been made much use of on corpus about science and technology declarations. In this paper, we extract word-level information from amounts of science and technology announcements corpus, and analyze the performance of CRF, comparing with Naïve Bayes as a baseline. According to our experiments, we show that CRF has much high precision except for a few unknown data. Also, Naïve Bayes model is satisfactory in closed domains, but it always makes mistakes when the data belong to a less weighted class.","2376-5933;23765933","Electronic:978-1-4673-1857-0; POD:978-1-4673-1856-3","10.1109/CCIS.2012.6664640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664640","conditional random field;information extraction;naïve bayes;science and technology corpus;word-level","Data mining;Data models;Hidden Markov models;Information retrieval;Niobium;Testing;Training","information resources;natural language processing;scientific information systems;text analysis","CRF;closed domains;conditional random field;naïve Bayes;natural language processing;science and technology announcements corpus;science and technology declarations;word-level information;word-level information extraction","","0","","14","","","Oct. 30 2012-Nov. 1 2012","","IEEE","IEEE Conference Publications"
"Web Information at Your Fingertips: Paper as an Interaction Metaphor","Z. Chen; J. T. Sun; X. Huang","","Computer","20140312","2014","47","3","62","66","The prototype O system seamlessly integrates Web searching and browsing on touch-enabled tablets using two-handed gesture interaction, much like handling and marking content on a piece of paper. The system also leverages contextual information to infer user intent and significantly improve search results over traditional keyword-based approaches, enabling users to go beyond websites' ""walled garden""' and more fully explore information objects.","0018-9162;00189162","","10.1109/MC.2013.188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6519224","MSN for iPad;Web browsing;Web search;Web technologies;gesture interaction;hyperTEC;hypertext;iPad;the O system;touch-enabled devices","Feature extraction;Information retrieval;Search engines;Search problems;Table computers;Tablet computers;Web search","Internet;gesture recognition;notebook computers;touch sensitive screens","Web browsing;Web information;Web searching;contextual information;fingertips;handed gesture interaction;information objects;interaction metaphor;prototype O system;touch enabled tablets;walled garden","","0","","14","","20130523","Mar. 2014","","IEEE","IEEE Journals & Magazines"
"Context-Aware Recommendation System Using Content Based Image Retrieval with Dynamic Context Considered","Y. Miyazawa; Y. Yamamoto; T. Kawabe","Sch. of Inf. Environ., Tokyo Denki Univ., Inzai, Japan","2013 International Conference on Signal-Image Technology & Internet-Based Systems","20140130","2013","","","779","783","This paper conceptually proposes a context-aware recommendation system that gives/recommends optimal information for users based on 1) the content of an image using content-based image retrieval engines, 2) the contextual information of its similar images on the Web, and 3) user context, namely users' situations such as their location, we are aiming to extract the detailed information to the text-unpresentable images. It is expected to increase the precision of content-based image matching by combining the partial context obtained there from other types of data such as contextual information.","","Electronic:978-1-4799-3211-5; POD:978-1-4799-3212-2","10.1109/SITIS.2013.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727276","context-aware;image retrieval;recommendation","Context;Data mining;Image retrieval;Information retrieval;Knowledge discovery;Natural languages;Poles and towers","content-based retrieval;image matching;image retrieval;recommender systems","content based image retrieval;content-based image matching;context-aware recommendation system;contextual information;dynamic context;image content;optimal information;partial context;text-unpresentable images;user context","","0","","7","","","2-5 Dec. 2013","","IEEE","IEEE Conference Publications"
"Indonesian Hadith Retrieval System using thesaurus","I. Rasyidi; A. Romadhony; A. T. Wibowo","Inf. Fac., Telkom Inst. of Techology, Indonesia","2013 International Conference on Computer, Control, Informatics and Its Applications (IC3INA)","20140522","2013","","","285","288","Along with the growth of Islamic religion in Indonesia, the need for information of Hadits becomes very important. Hadith as the second source of law in Islam after Al-Quran has a high position in moslem life. But application related with Hadith Retrieval is still limited. This limitation especially found in non-arabic language environment. Existing Hadith Retrieval System in Indonesia execute input query directly to DBMS, causing low quality search result. To overcome the problem, we try to implement thesaurus in the system. This study carried out research on the application of thesaurus for query expansion in Indonesian Hadith Retrieval System. Thesaurus construction done automatically using co-coccurence analysis followed by manual validation process. The thesaurus documents will be used in the process of query expansion while searching process. Performance measurements includes Precision at 10, Mean Average Precision (MAP) and Recall generated by the system after applying the thesaurus for query expansion. From the results, the accuracy for Precisison at 10 (P@10) increased by 34% between searches with query expansion using a thesaurus and without query expansion using thesaurus. As for the MAP value increased by 16% and 34% for recall.","","CD-ROM:978-1-4799-1076-2; Electronic:978-1-4799-1078-6; POD:978-1-4799-1077-9","10.1109/IC3INA.2013.6819189","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6819189","hadith retrieval system;query expansion;thesaurus","Buildings;Informatics;Information retrieval;Manuals;System performance;Testing;Thesauri","database management systems;information retrieval systems;query processing;thesauri","DBMS;Indonesian hadith retrieval system;MAP;input query execution;mean average precision;query expansion;thesaurus construction","","0","","11","","","19-21 Nov. 2013","","IEEE","IEEE Conference Publications"
"Relative Lempel-Ziv with Constant-Time Random Access","T. Gagie; S. J. Puglisi","Univ. of Helsinki, Helsinki, Finland","2014 Data Compression Conference","20140605","2014","","","405","405","Relative Lempel-Ziv [1] (RLZ) is a variant of LZ77 that can compress collections of similar genomes well, while still allowing fast random access to them. We implemented RLZ using compressed bit vectors to support constant-time random access at the cost of sublinear extra space. We compared our implementation of RLZ to Deorowicz and Grabowski's GDC [11] scheme and achieved comparable compression and much smaller access times for short substrings.","1068-0314;10680314","Electronic:978-1-4799-3882-7; POD:978-1-4799-3418-8","10.1109/DCC.2014.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824457","random access;relative Lempel-Ziv","Bioinformatics;Data compression;Educational institutions;Genomics;Information retrieval;Libraries;Robustness","bioinformatics;data compression;genomics","LZ77;RLZ;compressed bit vectors;constant time random access;genomes collection compression;relative Lempel-Ziv;sublinear extra space","","0","","2","","","26-28 March 2014","","IEEE","IEEE Conference Publications"
"Patient information extraction in noisy tele-health texts","M. Y. Kim; Y. Xu; O. Zaiane; R. Goebel","Dept. of Comput. Sci., Univ. of Alberta, Edmonton, AB, Canada","2013 IEEE International Conference on Bioinformatics and Biomedicine","20140206","2013","","","326","329","We explore methods for effectively extracting information from clinical narratives, which are captured in a public health consulting phone service called HealthLink. The currently available data consists of dialogues constructed by nurses while consulting patients on the phone. Since the data are interviews transcribed by nurses during phone conversations, they include a significant volume and variety of noise: First is explicit noise, which includes spelling errors, unfinished sentences, omission of sentence delimiters, variants of terms, etc. Second is implicit noise, which includes non-patient's information and negation of patient's information. To filter explicit noise, we propose our biomedical term detection/normalization method: it resolves misspelling, term variations, and arbitrary abbreviation of terms by nurses. In detecting temporal terms and other types of named entities (which show patients' personal information such as age, and sex), we propose a bootstrapping-based pattern learning to detect all kinds of arbitrary variations of the named entities. To address implicit noise, we propose a dependency path-based filtering method. The result of our denoising is the extraction of normalized patient information. The experimental results show that we achieve reasonable performance with our noise reduction methods.","","Electronic:978-1-4799-1309-1; POD:978-1-4799-1311-4","10.1109/BIBM.2013.6732511","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732511","","Data mining;Diseases;Information retrieval;Noise;Semantics;Syntactics;Unified modeling language","electronic health records;information filtering;learning (artificial intelligence);personal information systems;telemedicine;text analysis","biomedical term variations;bootstrapping-based pattern learning;de-noising;detection-normalization method;filter explicit noise;healthlink;misspelling;noise reduction methods;noisy telehealth texts;nonpatient information;normalized patient information extraction;nurses;path-based filtering method;patient personal information;phone conversations;public health consulting phone service;sentence delimiter omission;spelling errors;unfinished sentences","","2","","13","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Beyond content delivery: can ICNs help emergency scenarios?","G. Tyson; E. Bodanese; J. Bigham; A. Mauthe","Queen Mary Univ. of London, London, UK","IEEE Network","20140626","2014","28","3","44","49","Natural disasters are becoming more and more prominent in our world today, increasing by over 400 percent in the last 20 years alone. To overcome the challenges brought about by such situations, it has been proven vital to ensure continued and effective communication. Unfortunately, however, this has often been difficult with network failures commonplace, particularly during large-scale emergencies, e.g. earthquakes. In this article we explore the potential of information-centric networks (ICNs) to provision highly resilient communications during disaster scenarios. We first provide background to the area, before highlighting the key characteristics of ICNs that are well suited to augmenting resilience in the domain. Following this, we explore remaining challenges of note, concluding that, despite its potential, several key obstacles must be overcome before a truly resilient ICN can be realized.","0890-8044;08908044","","10.1109/MNET.2014.6843231","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843231","","Ad hoc networks;Content-based retrieval;Disasters;Earthquakes;Emergency services;Information retrieval;Information technology;Mobile communication;Routing protocols","computer networks","ICN;computer networks;content delivery;emergency scenarios;information centric networks;natural disasters;network failures","","6","","14","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Real-Time Effective Framework for Unstructured Data Mining","R. K. Lomotey; R. Deters","Dept. of Comput. Sci., Univ. of Saskatchewan, Saskatoon, SK, Canada","2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications","20131212","2013","","","1081","1088","Today, the enterprise landscape faces voluminous amount of data. The information gathered from these data sources are useful for improving on product and services delivery. However, it is challenging to perform knowledge discovery in database (KDD) activities on these data sources because of its unstructured nature. Previous studies have proposed the hierarchical clustering methodology since it enhances human readability and provides clear dependency structure through topics, term and document organization. But, the methodology can be resource intensive and time consuming. In order to improve on the terms extraction process, we propose a tool called RSenter that searches through interconnected Hyperlinks and NoSQL database (specifically, CouchDB). We evaluate the tool based on search algorithms such as parallelization, random walk (or linear search), pessimistic search, and optimistic search. The tool shows high accuracy and optimality in view of the search time.","2324-898X;2324898X","Electronic:978-0-7695-5022-0; POD:978-1-4799-1444-9","10.1109/TrustCom.2013.131","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680952","big data;data mining;hierarchical clustering;information extraction;terms;topics;unstructured data","Clustering algorithms;Communities;Data mining;Databases;Information retrieval;Organizations;Thesauri","SQL;data mining;database management systems;information retrieval;pattern clustering;search problems","KDD activities;NoSQL database;RSenter;data sources;dependency structure;document organization;enterprise landscape;hierarchical clustering methodology;human readability;interconnected Hyperlinks;knowledge discovery in database activities;optimistic search;pessimistic search;product delivery;random walk;real-time effective framework;search algorithms;service delivery;term extraction process;unstructured data mining","","1","","37","","","16-18 July 2013","","IEEE","IEEE Conference Publications"
"Model Analysis in Information Behavior","Z. Dan; X. Shengjun","Libr., Wuhan Univ. of Technol., Wuhan, China","2013 International Conference on Computer Sciences and Applications","20140619","2013","","","707","710","This paper gives a introduction about several theoretical models of information behavior and information seeking behavior. These representative models in Western countries include Dervin's theory and model of sense-making which is accepted in information studies as the metatheory to investigate information behavior, Ellis' model of information seeking behavior, Kuhlthau's model of information seeking process and Wilson's model of information seeking behavior. Detailed comparative analysis and objective evaluation on these four models. Their differences and shared features are summarized.","","Electronic:978-0-7695-5125-8; POD:978-1-5090-0009-8","10.1109/CSA.2013.170","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835696","information behaviour;information seeking behaviour;information seeking process","Analytical models;Bridges;Computational modeling;Context;Information retrieval;Information science;Psychology","information needs;information retrieval;information use;social aspects of automation","Western countries;information needs;information seeking behavior;information seeking process;information use;metatheory;model analysis;sense-making model","","0","","13","","","14-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"Automatic Information Extraction in the Medical Domain by Cross-Lingual Projection","A. B. Abacha; P. Zweigenbaum; A. Max","Ressource Centre for Health Care Technol., Centre de Rech. Public Henri Tudor, Luxembourg, Luxembourg","2013 IEEE International Conference on Healthcare Informatics","20131212","2013","","","82","88","This research tackles the automatic annotation of texts written in a language L1 by exploiting resources and tools available for another language L2. Our approach involves the use of a parallel corpus (L1-L2) aligned at the level of sentences and words. To address the lack of annotated French corpus in the medical field, we focus on the French-English language pair to annotate French medical texts automatically. We focus in this article on Medical Entity Recognition (MER). We evaluate our MER method on the English corpus and the projection of the annotations on the French corpus. We also discuss the problem of scalability since we use a parallel corpus extracted from the Web and propose a statistical method to handle heterogeneous corpora.","","Electronic:978-0-7695-5089-3; POD:978-1-4799-0974-2","10.1109/ICHI.2013.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6680464","cross-lingual projection;medical entity recognition","Diseases;Feature extraction;Information retrieval;Manuals;Medical diagnostic imaging;Semantics","medical computing;natural language processing;statistical analysis;text analysis","English corpus;French medical texts;French-English language;MER method;annotated French corpus;automatic annotation;automatic information extraction;cross lingual projection;medical domain;medical entity recognition;medical field;parallel corpus;statistical method","","0","","23","","","9-11 Sept. 2013","","IEEE","IEEE Conference Publications"
"Information-centric networking for machine-to-machine data delivery: a case study in smart grid applications","K. V. Katsaros; W. K. Chai; N. Wang; G. Pavlou; H. Bontius; M. Paolone","","IEEE Network","20140626","2014","28","3","58","64","Largely motivated by the proliferation of content-centric applications in the Internet, information-centric networking has attracted the attention of the research community. By tailoring network operations around named information objects instead of end hosts, ICN yields a series of desirable features such as the spatiotemporal decoupling of communicating entities and the support of in-network caching. In this article, we advocate the introduction of such ICN features in a new, rapidly transforming communication domain: the smart grid. With the rapid introduction of multiple new actors, such as distributed (renewable) energy resources and electric vehicles, smart grids present a new networking landscape where a diverse set of multi-party machine-to-machine applications are required to enhance the observability of the power grid, often in real time and on top of a diverse set of communication infrastructures. Presenting a generic architectural framework, we show how ICN can address the emerging smart grid communication challenges. Based on real power grid topologies from a power distribution network in the Netherlands, we further employ simulations to both demonstrate the feasibility of an ICN solution for the support of real-time smart grid applications and further quantify the performance benefits brought by ICN against the current host-centric paradigm. Specifically, we show how ICN can support real-time state estimation in the medium voltage power grid, where high volumes of synchrophasor measurement data from distributed vantage points must be delivered within a very stringent end-to-end delay constraint, while swiftly overcoming potential power grid component failures.","0890-8044;08908044","","10.1109/MNET.2014.6843233","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843233","","Content-based retrieval;Delays;Information retrieval;Information technology;Network architecture;Network topology;Phasor measurement units;Power distribution;Real-time systems;Smart grids","Internet;distribution networks;phasor measurement;smart power grids;spatiotemporal phenomena","ICN;Internet;Netherlands;content-centric applications;distributed energy resources;electric vehicles;host-centric paradigm;in-network caching;information-centric networking;machine-to-machine data delivery;medium voltage power grid topologies;power distribution network;power grid component failures;smart grid;smart grid applications;spatiotemporal decoupling;synchrophasor measurement data","","23","1","15","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"An ontology-based approach for text mining of stroke electronic medical records","Y. Yang; Y. Cai; W. Luo; Z. Li; Z. Ma; X. Yu; H. Yu","Shenzhen Inst. of Adv. Technol., Res. Center for Biomed. Inf. Technol., Shenzhen, China","2013 IEEE International Conference on Bioinformatics and Biomedicine","20140206","2013","","","288","291","In this paper, we propose a novel ontology-based approach for text mining of EMR information retrieval. The advantage of this approach is that it is capable of handling numerous variations in nature text which essentially refer to the same identity, as well as inferring implicit information from the plain text, which are both important in data mining of medical records. We applied the approach to text mining of EMR documents for stroke patients in a Chinese medical hospital. A benchmark study on an independent test set shows that the proposed pipeline can accurately extract the vast majority of useful information from the EMR documents, including the implicit ones through ontology inference. We also carry out a primary statistical analysis on a sample EMR set to illustrate the utilization of the approach on medical studies.","","Electronic:978-1-4799-1309-1; POD:978-1-4799-1311-4","10.1109/BIBM.2013.6732696","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6732696","electronic medical record;ontology;stroke;text mining","Cognition;Electronic medical records;Information retrieval;Medical diagnostic imaging;Ontologies;Text mining","data mining;electronic health records;inference mechanisms;information retrieval;ontologies (artificial intelligence);statistical analysis;text analysis","Chinese medical hospital;EMR document text mining;EMR information retrieval;data mining;ontology inference;ontology-based approach;plain text;statistical analysis;stroke electronic record text mining;stroke patients","","0","","11","","","18-21 Dec. 2013","","IEEE","IEEE Conference Publications"
"Structural Parse Tree Features for Text Representation","S. Massung; C. Zhai; J. Hockenmaier","Dept. of Comput. Sci., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","2013 IEEE Seventh International Conference on Semantic Computing","20140102","2013","","","9","16","We propose and study novel text representation features created from parse tree structures. Unlike the traditional parse tree features which include all the attached syntactic categories to capture linguistic properties of text, the new features are solely or primarily defined based on the tree structure, and thus better reflect the pure structural properties of parse trees. We hypothesize that these new complex structural features capture an orthogonal perspective of text even compared to advanced syntactic ones. Evaluation based on three different text categorization tasks (i.e., nationality detection, essay scoring, and sentiment analysis) shows that the proposed new tree structure features complement the existing ones to enrich text representation. Experiment results further show that a combination of the proposed new structure features with word n-grams can improve F<sub>1</sub> score and classification accuracy.","","Electronic:978-0-7695-5119-7; POD:978-1-4799-1371-8","10.1109/ICSC.2013.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6693488","","Accuracy;Feature extraction;Information retrieval;Production;Skeleton;Syntactics;Text categorization","classification;computational linguistics;text analysis;trees (mathematics)","F1 score;classification accuracy;complex structural features;essay scoring;linguistic properties;nationality detection;orthogonal perspective;parse tree structures;sentiment analysis;structural parse tree features;structural properties;syntactic categories;text categorization tasks;text representation;word n-grams","","1","","34","","","16-18 Sept. 2013","","IEEE","IEEE Conference Publications"
"Building a standard measurement platform","M. Bagnulo; T. Burbridge; S. Crawford; P. Eardley; J. Schoenwaelder; B. Trammell","Univ. Carlos III de Madrid, Legane&#x0301;s, Spain","IEEE Communications Magazine","20140519","2014","52","5","165","173","Network management is achieved through a large number of disparate solutions for different technologies and parts of the end-to-end network. Gaining an overall view, and especially predicting the impact on a service user, is difficult. Recently, a number of proprietary platforms have emerged to conduct end-to-end testing from user premises; however, these are limited in scale, interoperability, and the ability to compare like-for-like results. In this article we show that these platforms share similar architectures and can benefit from the standardization of key interfaces, test definitions, information model, and protocols. We take the SamKnows platform as a use case and propose an evolution from its current proprietary protocols to standardized protocols and tests. In particular, we propose to use extensions of the IETF's IPFIX and NETCONF/YANG in the platform. Standardization will allow measurement capabilities to be included on many more network elements and user devices, providing a much more comprehensive view of user experience and enabling problems and performance bottlenecks to be identified and addressed.","0163-6804;01636804","","10.1109/MCOM.2014.6815908","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815908","","Information retrieval;Internet;Measurement;Protocols;Query processing;Standards","protocols;telecommunication network management","IETF's IPFIX;NETCONF/YANG;SamKnows platform;end-to-end network;end-to-end testing;information model;interoperability;network elements;network management;proprietary platforms;proprietary protocols;service user;standard measurement platform;test definitions;user devices;user experience;user premises","","2","","12","","","May 2014","","IEEE","IEEE Journals & Magazines"
"DAG Based Feature Additive XML Schema Generation for Unstructured Text","K. Rajbabu; S. Sudha","Bharat Heavy Electricals Ltd., Tiruchirappalli, India","2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery","20131219","2013","","","117","124","Recent works on handling unstructured text employ multilevel filtering techniques for identifying the key terms in documents and then apply mining techniques to extract necessary information. Though these techniques are more efficient in information retrieval, they cannot be applied directly for information extraction, for documents that are more critical in context and also accuracy cannot be expected. Further, loss of hidden and significant information cannot be tolerated in data critical applications emerging based on unstructured documents. Hence, a novel idea of re-organizing the unstructured textual model into feature enriched structured graphical model by adding spatial, logical, lexical, syntactical and semantic features is proposed. The generated graph depicts relationships across the document at all levels from its micro level token to macro level document. Moreover, a structural pattern identification algorithm for generating an XML schema from the generated graph is also recommended. The experimental outcome for a real-time dataset is presented.","","Electronic:978-0-7695-5106-7; POD:978-1-4799-1327-5","10.1109/CyberC.2013.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685668","DAG;Feature Categorization;Feature Enrichment;XML Schema;unstructured text","Context;Data mining;Feature extraction;Information retrieval;Object oriented modeling;Semantics;XML","XML;data mining;directed graphs;information filtering;text analysis","DAG based feature additive XML schema generation;data critical applications;directed acyclic graph;information extraction;information retrieval;lexical features;logical features;macro level document;microlevel token;mining techniques;multilevel filtering techniques;semantic features;spatial features;structural pattern identification algorithm;structured graphical model;syntactical features;unstructured documents;unstructured textual model","","0","","16","","","10-12 Oct. 2013","","IEEE","IEEE Conference Publications"
"Ontology based annotation mechanism for financial documents","K. Perera; D. D. Karunarathne; A. Siriwardena; D. Balaretnaraja","Lanka Software Found., Colombo, Sri Lanka","2013 International Conference on Advances in ICT for Emerging Regions (ICTer)","20140310","2013","","","110","117","The Vast number of publicly available electronic financial documents and document repositories and their rapid growth pose a great challenge in understanding, managing and structuring the information. Due to several reasons content of these documents is open to variety of differing interpretations and resulting ambiguity. Annotating these data with semantics to constrain the inconsistent interpretation of data facilitates better reuse and interoperability. We propose a semi-supervised approach for creating annotations for the extracted text of financial documents. A Supervised approach would include human experts in the annotation process. Unsupervised or machine based annotation is done by recommending Financial Industry Business Ontology (FIBO) terms for document sections based on the Okapi Similarity measure. Annotation data can be used to infer knowledge from important sentences or document sections to gain better understanding or decision making. Our annotation results indicate that similar pairs of sections have more common FIBO terms and different pairs of sections have a lesser number of similar FIBO terms.","","Electronic:978-1-4799-1276-6; POD:978-1-4799-1273-5","10.1109/ICTer.2013.6761164","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6761164","Annotation;Financial Data;Ontology;Semantic Web","Contracts;Frequency measurement;Information retrieval;Knowledge based systems;Ontologies;Semantics","financial data processing;ontologies (artificial intelligence);text analysis","FIBO terms;Financial Industry Business Ontology terms;Okapi similarity measure;document repositories;electronic financial documents;machine based annotation;ontology based annotation mechanism;semisupervised approach;text extraction;unsupervised based annotation","","0","","20","","","11-15 Dec. 2013","","IEEE","IEEE Conference Publications"
"mPlane: an intelligent measurement plane for the internet","B. Trammell; P. Casas; D. Rossi; A. Bär; Z. B. Houidi; I. Leontiadis; T. Szemethy; M. Mellia","","IEEE Communications Magazine","20140519","2014","52","5","148","156","The Internet's universality is based on its decentralization and diversity. However, its distributed nature leads to operational brittleness and difficulty in identifying the root causes of performance and availability issues, especially when the involved systems span multiple administrative domains. The first step to address this fragmentation is coordinated measurement: we propose to complement the current Internet's data and control planes with a measurement plane, or mPlane for short. mPlane's distributed measurement infrastructure collects and analyzes traffic measurements at a wide variety of scales to monitor the network status. Its architecture is centered on a flexible control interface, allowing the incorporation of existing measurement tools through lightweight mPlane proxy components, and offering dynamic support for new capabilities. A focus on automated, iterative measurement makes the platform well-suited to troubleshooting support. This is supported by a reasoning system, which applies machine learning algorithms to learn from success and failure in drilling down to the root cause of a problem. This article describes the mPlane architecture and shows its applicability to several distributed measurement problems involving content delivery networks and Internet service roviders. A first case study presents the tracking and iterative analysis of cache selection policies in Akamai, while a second example focuses on the cooperation between Internet service providers and content delivery networks to better orchestrate their traffic engineering decisions and jointly improve their performance.","0163-6804;01636804","","10.1109/MCOM.2014.6815906","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815906","","Coordinate measuring machines;Information retrieval;Internet;Machine learning;Monitoring;Query processing;Telecommunication network management","Internet;iterative methods;telecommunication traffic","Akamai;Internet service roviders;content delivery networks;control plane;distributed measurement infrastructure;intelligent measurement plane;iterative measurement;mPlane;machine learning;traffic measurements","","9","","8","","","May 2014","","IEEE","IEEE Journals & Magazines"
"The Partition Heuristic Information Extraction Algorithm of Unstructured Data","C. Li; C. Zou; L. Zhong; J. Zhu","Sch. of Comput. Sci. & Technol., Wuhan Univ. of Technol., Wuhan, China","2013 International Conference on Cloud Computing and Big Data","20140526","2013","","","570","576","In this paper, we propose a method that extracts attributes of given entity from unstructured data for the field of logistics by using the idea of divide and conquer as to the characters of logistics information. After the full study of logistics information, we make a statistical analysis for the text logistics information and summarize the common attributes of text information entity. According to the different attributes and attribute values, we divided text information entity by the idea of divide and conquer. As to the entity we get from last step we make an internal processing based on segmentation method of tagging and graph. We extracted valuable attributes and attribute values from the unstructured data. Experimental results show that this method is valid for the logistics information which we achieve from a well-known logistics system.","","Electronic:978-1-4799-2830-9; POD:978-1-4799-2831-6","10.1109/CLOUDCOM-ASIA.2013.104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821051","divide-and-conquer method;extraction;information;logistics information;unstructured data;words segmentation","Cities and towns;Data mining;Educational institutions;Information retrieval;Logistics;Statistical analysis;Vehicles","divide and conquer methods;information retrieval;logistics data processing;statistical analysis;text analysis","attribute extraction;divide and conquer method;graph;partition heuristic information extraction algorithm;statistical analysis;tagging segmentation method;text information entity;text logistics information;unstructured data","","0","","23","","","16-19 Dec. 2013","","IEEE","IEEE Conference Publications"
"Co-training based semi-supervised Web spam detection","Wei Wang; Xiao-Dong Lee; An-Lei Hu; G. G. Geng","Comput. Network Inf. Center, China Internet Network Inf. Center, Beijing, China","2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20140519","2013","","","789","793","Traditional Web spam classifiers use only labeled data (feature/label pairs) to train. Labeled spam instances, however, are very difficult, expensive, or time consuming to obtain, as they require the efforts of experienced human annotators. Meanwhile unlabeled samples are relatively easy to collect. Semi-supervised learning addresses the classification problem by using large amount of unlabeled data, together with the labeled data, to build better classifiers. This paper proposes two new semi-supervised learning algorithms to boost the performance of Web spam classifiers. The algorithms integrate the traditional co-training with the topological dependency based hyperlink learning. The proposed methods extend our previous work on self-training based semi-supervised Web spam detection. The experimental results with 100/200 labeled samples on the standard WEBSPAM-UK2006 benchmark showed that the algorithms are effective.","","Electronic:978-1-4673-5253-6; POD:978-1-4673-5251-2","10.1109/FSKD.2013.6816301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816301","","Feature extraction;Information retrieval;Prediction algorithms;Semisupervised learning;Standards;Training;Unsolicited electronic mail","Internet;security of data","Web spam classifiers;classification problem;cotraining based semisupervised Web spam detection;human annotators;hyperlink learning;self-training based semisupervised Web spam detection;semisupervised learning algorithms;spam instances;topological dependency","","1","","20","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"Despeckling and Information Extraction From SLC SAR Images","D. Gleich; M. Datcu","Lab. of Signal Process. & Remote Control, Univ. of Maribor, Maribor, Slovenia","IEEE Transactions on Geoscience and Remote Sensing","20140227","2014","52","8","4633","4649","This paper presents an information extraction and image enhancement technique using single-look complex (SLC) synthetic aperture radar data. The novelty of this method is the proposed complex-domain despeckling stage. Tikhonov-like optimization is used for minimizing the cost function, which consists of a Gauss-Markov random field (GMRF) prior. The GMRF model is used for texture modeling. The texture parameters of the GMRF are estimated using the evidence maximization framework. The experimental results showed that despeckled SLC images have well-preserved textural features, structures, and point scatterers. The phase of the reconstructed image is well preserved and provides good-quality interferograms of high-resolution spotlight images.","0196-2892;01962892","","10.1109/TGRS.2013.2283157","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6646267","Despeckling;Gauss–Markov random fields (GMRFs);Gauss??Markov random fields (GMRFs);image enhancement;information extraction;synthetic aperture radar (SAR)","Bayes methods;Cost function;Data models;Estimation;Information retrieval;Speckle;Synthetic aperture radar","image enhancement;radar imaging;speckle;synthetic aperture radar","Gauss-Markov random field;SLC SAR images;Tikhonov-like optimization;complex-domain despeckling stage;image enhancement technique;information extraction;reconstructed image phase;single-look complex synthetic aperture radar data;texture modeling","","2","","36","","20131024","Aug. 2014","","IEEE","IEEE Journals & Magazines"
"Improved Semantic Retrieval of Spoken Content by Document/Query Expansion with Random Walk Over Acoustic Similarity Graphs","H. Y. Lee; L. S. Lee","Dept. of Electr. Eng., Nat. Taiwan Univ., Taipei, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20131113","2014","22","1","80","94","In a text context, document/query expansion has proven very useful in retrieving objects semantically related to the query. However, when applying text-based techniques on spoken content, the inevitable recognition errors seriously degrade performance even when the retrieval process is performed over lattices. We propose the estimation of more accurate term distributions (or unigram language models) for the spoken documents by acoustic similarity graphs. In this approach, a graph is constructed for each term describing the acoustic similarity among all signal regions hypothesized to be the considered term. Score propagation based on a random walk over the graph offers more reliable scores of the term hypotheses, which in turn yield more accurate term distributions (or unigram language models). This approach was applied with the language modeling retrieval approach, including using document expansion based on latent topic analysis and query expansion with a query-regularized mixture model. We extend these approaches from words to subword n-grams, and the query expansion from document-level to utterance-level and from term-based to topic-based. Experiments performed on Mandarin broadcast news showed improved performance under almost all tested conditions.","2329-9290;23299290","","10.1109/TASLP.2013.2285469","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6633083","Document expansion;latent semantic analysis;query expansion;random walk;spoken content retrieval","Acoustics;Analytical models;Estimation;Information retrieval;Lattices;Materials;Semantics","content-based retrieval;graph theory;natural language processing;query processing","Mandarin broadcast news;acoustic similarity graphs;document expansion;document-level query expansion;improved semantic spoken content retrieval;language modeling retrieval approach;latent topic analysis;object retrieval;query expansion;query-regularized mixture model;random walk;recognition errors;score propagation;signal regions;subword n-grams;term distributions;term-based query expansion;text-based techniques;topic-based query expansion;unigram language models;utterance-level query expansion","","2","","65","","20131017","Jan. 2014","","IEEE","IEEE Journals & Magazines"
"OBSemE: An ontology-based semantic metadata extraction system for learning objects","R. Farhat; B. Jebali","Res. Lab. of Technol. of Inf. & Commun. & Electr. Eng. (LaTICE), Univ. Of Tunis, Bab Menara, Tunisia","Fourth International Conference on Information and Communication Technology and Accessibility (ICTA)","20140515","2013","","","1","5","In this paper we describe OBSemE an ontology-based semantic metadata extraction system which implement our approach dedicated to the automatic extraction of semantic metadata for learning objects. The process of semantic metadata extraction is based on ontology metadata information extraction method's principles. This choice is due to the advantages of the use of ontologies. The input of our system is a set of LOM metadata elements respecting three requirements. The first requirement is that each chosen LOM data element must describe the educational content of the learning object. The second requirement is that the LOM data element must be required by most of the widely used LOM application profiles. The third requirement is that the LOM data element has to be mostly fulfilled by the learning object's authors in practice. The output of our system is a set of semantic metadata describing the learning object content. We have designed an RDF schema to encode semantic metadata with a computable formalism. We provide also some experimental results as a proof of the feasibility of our approach and the quality of our implementation.","2379-4399;23794399","Electronic:978-1-4799-2725-8; POD:978-1-4799-2726-5","10.1109/ICTA.2013.6815289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815289","LOM;learning objects;ontology based information extraction;semantic metadata","Information retrieval;Interoperability;Ontologies;Resource description framework;Semantics;Standards;Training","computer aided instruction;formal specification;meta data;ontologies (artificial intelligence)","LOM metadata elements;OBSemE;RDF schema;computable formalism;learning object content;ontology-based semantic metadata extraction system","","0","","35","","","24-26 Oct. 2013","","IEEE","IEEE Conference Publications"
"CoLoR: an information-centric internet architecture for innovations","H. Luo; Z. Chen; J. Cui; H. Zhang; M. Zukerman; C. Qiao","Beijing Jiaotong Univ., Beijing, China","IEEE Network","20140626","2014","28","3","4","10","In this article, we describe an information-centric Internet architecture called CoLoR that couples service location and inter-domain routing while decoupling them from forwarding. Preliminary results based on implementation and analysis show that CoLoR is promising since it satisfies many requirements of the future Internet, including being information-centric, encouraging innovations, and providing efficient support for mobility, multicast, multi-homing, and middleboxes.","0890-8044;08908044","","10.1109/MNET.2014.6843226","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843226","","Color;IP networks;Image color analysis;Information retrieval;Information technology;Internet;Network architecture;Network security;Peer-to-peer computing","Internet;telecommunication network routing","CoLoR;information centric Internet architecture;interdomain routing;service location","","8","","17","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Comparison of Personalised Systems","S. Abbey; S. Joglekar; M. Bedekar","K.K. Birla Goa Campus, BITS Pilani, Pilani, India","2013 6th International Conference on Emerging Trends in Engineering and Technology","20140327","2013","","","7","12","Personalization is omnipresent everywhere in today's modern world applications. It is primarily employed to improve user experience by adapting and learning from the patterns and information extracted from the user. There are various methods of making a system learn from the user behaviour. This paper gives a review of some of the techniques used for user profiling and personalisation systems. The paper puts forth the characteristics and advantages of user profiling and why it is so essential in today's world, with specific reference to internet usage. It also explains which factors of the usage should be taken into consideration and the importance of these factors in user profiling. The paper elaborates on the studied techniques with respect to internet usage because of its ever-growing nature, complexity in learning from the vast source, adapting to changes in usage patterns and the ultimate objective of providing a better user experience while being on-line. The commonality and differences in various proposed techniques are also summarised and highlighted.","2157-0477;21570477","CD-ROM:978-1-4799-2560-5; Electronic:978-1-4799-2561-2; POD:978-1-4799-2562-9","10.1109/ICETET.2013.3","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754763","Data mining;Information management;Knowledge based systems;Learning systems;Machine intelligence;Ontology;User Profiling","Accuracy;Adaptive systems;Algorithm design and analysis;Data mining;Information retrieval;Noise;Servers","Internet;user modelling","Internet usage;personalised systems;user experience improvement;user profiling","","0","","16","","","16-18 Dec. 2013","","IEEE","IEEE Conference Publications"
"An Automated Framework for Incorporating News into Stock Trading Strategies","W. Nuij; V. Milea; F. Hogenboom; F. Frasincar; U. Kaymak","Semlab, Alphen a/d Rijn, Netherlands","IEEE Transactions on Knowledge and Data Engineering","20140321","2014","26","4","823","835","In this paper we present a framework for automatic exploitation of news in stock trading strategies. Events are extracted from news messages presented in free text without annotations. We test the introduced framework by deriving trading strategies based on technical indicators and impacts of the extracted events. The strategies take the form of rules that combine technical trading indicators with a news variable, and are revealed through the use of genetic programming. We find that the news variable is often included in the optimal trading rules, indicating the added value of news for predictive purposes and validating our proposed framework for automatically incorporating news in stock trading strategies.","1041-4347;10414347","","10.1109/TKDE.2013.133","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574843","Computer applications;evolutionary computing and genetic algorithms;learning;natural language processing;web text analysis","Companies;Context;Corporate acquisitions;Genetic programming;Indexes;Information retrieval;Stock markets","genetic algorithms;stock markets","automated framework;event extraction;financial markets;genetic programming;incorporating news;stock trading strategies;technical trading indicators","","7","","32","","20130805","April 2014","","IEEE","IEEE Journals & Magazines"
"Story Link Detection in Turkish Corpus","G. Köse; Y. Tonta; H. Ahmadlouei; A. C. Polatkan","Dept. of Inf. Manage., Hacettepe Univ., Ankara, Turkey","2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","20131223","2013","1","","154","158","Story Link Detection (SLD) is known as a sub-task of Topic Detection and Tracking (TDT). SLD aims to specify whether two randomly selected stories discuss the same topic or not. This sub-task drew special attention within the TDT research community as many tasks in TDT are thought to be solved automatically once SLD performs as expected. In this study, performance tests were carried out on the BilCol-2005 Turkish news corpus composed of approximately 209,000 news items using vector space model (VSM) and relevance model (RM) methods with respect to varied index term counts. Accordingly, best results obtained were as follows: the VSM method performed best with 30 terms (F-measure=0.2970) while RM method did with 4 terms (F-measure=0.1910). Furthermore, the combination of two methods using the AND and OR functions increased the precision ratio by 7.9% and recall ratio by 1.2%, respectively, indicating that retrieval performance of SLD algorithms can be increased to some extent by employing both VSM and RM models.","","Electronic:978-0-7695-5145-6; POD:978-1-4799-3932-9","10.1109/WI-IAT.2013.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690008","relevance model;story link detection;topic detection and tracking;vector space model","Computational modeling;Event detection;Indexes;Information retrieval;Research and development;Superluminescent diodes;Vectors","information retrieval;natural language processing;vectors","BilCol-2005 Turkish news corpus;RM models;SLD;TDT;VSM;randomly selected stories;relevance model methods;story link detection;topic detection and tracking;vector space model","","0","","33","","","17-20 Nov. 2013","","IEEE","IEEE Conference Publications"
"Query Expansion Based on the Distance Constraint Activation of Human Memory","X. Zhao; X. Luo","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2013 Ninth International Conference on Semantics, Knowledge and Grids","20140519","2013","","","143","150","Query Expansion is usually used to enhance user's query in document retrieval and knowledge recommender system. It aims to help user extend the original query to resolve the problems of user's fuzzy demand and limited domain knowledge when user faces complex knowledge demand. Current researches extend user's query mainly based on statistical method while the characteristics of human memory retrieval process are seldom taken into account. However, the process of human memory retrieval has good ability of extending the query when human faces fuzzy demand and limited domain knowledge. In this paper, we put forward a new model for Query Expansion based on the Distance Constraint Activation model of human memory. We build up the ALN (Association Link Network) of documents corpus to imitate human memory network and do the Distance Constraint Activation process on it in order to offer user Query Expansion service in accordance with the pattern of human memory retrieval process. Comparing with the traditional Query Expansion methods, our method is able to provide the semantic relation expansion and the semantic community expansion to the user. All these expansions aim to help user understand his/her demand or extend his/her knowledge in the domain corpus more easily. Several examples given in the experiments show that the semantic-close terms our method provides make the expansion terms more semantic coherent. And the semantic relations and semantic communities can give user a brief description of the knowledge to further understand his/her demand and extend his/her domain knowledge.","","Electronic:978-1-4799-3012-8; POD:978-1-4799-3013-5","10.1109/SKG.2013.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816596","Association Link Network;Spreading Activation;human memory retrieval process;query expansion","Adaptation models;Biological system modeling;Communities;Information retrieval;Knowledge engineering;Semantics;Vectors","fuzzy set theory;query processing;recommender systems;statistical analysis","association link network;complex knowledge demand;distance constraint activation model;distance constraint activation process;document retrieval;human memory retrieval process;knowledge recommender system;limited domain knowledge;query expansion service;statistical method;users fuzzy demand","","0","","18","","","3-4 Oct. 2013","","IEEE","IEEE Conference Publications"
"Future trends in managing extracted information","W. M. S. Yafooz; S. Z. Z. Abidin; N. Omar; Z. Idrus","Fac. of Comput. & Math. Sci., Univ. Teknol. MARA, Shah Alam, Malaysia","2013 IEEE International Conference on Control System, Computing and Engineering","20140123","2013","","","279","283","Web technology is currently used in all daily activities and is considered a backbone of life. The amount of information continuously increases and grows, specifically that of unstructured information that has no rules or constraints. Such information is difficult to handle and thus requires organization and management before it can be useful. Information extraction techniques are efficient methods of converting unstructured documents into structured data. Attempts have been made to extract structured information that can be used with small amounts of textual data. However, for large amounts of data such as those found in the World Wide Web, the amount of extracted information is huge, and the relationships between extracted information are difficult to determine. Studies that focus on managing extracted information are few. In this paper, we present an overview of the recent studies on managing unstructured information, information extraction and managing extracted information. Managing extracted data using our proposed model for the rapid extraction and clustering of unstructured data for back-end applications in low-level of relational database systems is highlighted. This paper is intended for researchers interested in information extraction management and its applications.","","Electronic:978-1-4799-1508-8; POD:978-1-4799-1507-1","10.1109/ICCSCE.2013.6719974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719974","extracted information management;information extraction;managing unstructured information;relational databases","Communities;Computers;Conferences;Data mining;Databases;Information retrieval;Semantics","Web sites;information retrieval;pattern clustering;relational databases;text analysis","Web technology;World Wide Web;backend applications;daily activity;information extraction management;relational database systems;structured information extraction;textual data;unstructured data clustering;unstructured documents;unstructured information management","","1","","41","","","Nov. 29 2013-Dec. 1 2013","","IEEE","IEEE Conference Publications"
"SOFIA: toward service-oriented information centric networking","Q. Wu; Z. Li; J. Zhou; H. Jiang; Z. Hu; Y. Liu; G. Xie","ICT/CAS, China","IEEE Network","20140626","2014","28","3","12","18","This article presents SOFIA, a service-oriented information-centric networking architecture. SOFIA is designed by exploring the design space between host abstraction and content abstraction. It can facilitate ICN to easily support various applications beyond content retrieval. SOFIA decouples flexible service processing and efficient data transmission into two stack layers: the service and network layers. Service requesting is driven by service name and processed by intermediate routers according to processing rules at the service layer. Applications build on the service layer and manipulate information over service sessions. A service session can further map to multiple service connections for flexibility and high throughput. We also detail three important communication types enabled by SOFIA. Finally, we implement the SOFIA stack based on a Click modular router and develop a few applications.","0890-8044;08908044","","10.1109/MNET.2014.6843227","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843227","","Data communication;Information retrieval;Information technology;Internet;Mobile communication;Network architecture;Routing;Servers;Service-oriented architecture;Throughput","Internet;telecommunication network routing","ICN;SOFIA;click modular router;content abstraction;content retrieval;data transmission;design space;flexible service processing;host abstraction;intermediate routers;network layer;processing rules;service connections;service layer;service name;service requesting;service session;service-oriented future Internet architecture;service-oriented information-centric networking architecture;stack layer","","5","","15","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"Introduction to Data, Text, and Web Mining for Managerial Decision Support Minitrack","D. Delen; A. Oztekin","","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","768","768","This mini-track has five papers that are about developing systems for decision support by means of data, text, or web mining. These five papers focus on a wide range of application areas from healthcare to social media, reinforcing the fact that data, text, and web mining are effective and recently popularized tools to develop decision support systems in various domains.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758698","Data mining;Web mining;decision support;text mining","Blood;Educational institutions;Information retrieval;Logistics;Medical services;Web mining","","","","0","","","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"A semantic query expansion-based patent retrieval approach","Feng Wang; Lanfen Lin; Shuai Yang; Xiaowei Zhu","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)","20140519","2013","","","572","577","Since patent documents are important technical resources, effective patent retrieval has become more and more crucial. Unlike common information retrieval, patent retrieval is a recall-oriented retrieval, and patent query inputs are usually long. However, current patent retrieval approaches cannot effectively capture user query intents and obtain good expansion terms, which lead to low retrieval effectiveness. To address this issue, this paper proposes a novel semantic query expansion-based patent retrieval approach according to patent-specific characteristics. Firstly, patent domain features are extracted by using a domain-dependent term frequency scheme. Based on domain features, query inputs are analyzed to determine query domains. Furthermore, query domain matching is employed to generate candidate expansion terms, and semantic-based similarity computation is adopted to select expansion terms. Experiment results show that our approach achieves better retrieval performance than other state-of-art approaches.","","Electronic:978-1-4673-5253-6; POD:978-1-4673-5251-2","10.1109/FSKD.2013.6816262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6816262","patent document;patent retrieval;query expansion;semantic","Entropy;Feature extraction;Indexing;Information retrieval;Patents;Semantics;Standards","patents;query processing","domain-dependent term frequency scheme;expansion terms;patent documents;patent query inputs;patent retrieval approach;patent-specific characteristics;query domains;query inputs;recall-oriented retrieval;retrieval effectiveness;semantic query expansion;semantic-based similarity computation;technical resources;user query intents","","4","","21","","","23-25 July 2013","","IEEE","IEEE Conference Publications"
"An Evaluation of Symbolic Feature Sets and Their Combination for Music Genre Classification","H. C. B. Piccoli; C. N. Silla; P. J. P. d. Léon; A. Pertusa","Comput. Music Technol. Lab., Fed. Univ. of Technol. of Parana (UTFPR-CP), Cornelio Procopio, Brazil","2013 IEEE International Conference on Systems, Man, and Cybernetics","20140127","2013","","","1901","1905","The automatic music genre classification task is an active area of research in the field of Music Information Retrieval. In this paper we use two different symbolic feature sets for genre classification and combine them using an early fusion approach. Our results show that early fusion achieves better classification accuracy than using any of the individual feature sets. Furthermore, when compared with some of the state of the art approaches using the same experimental conditions, early fusion of symbolic features is ranked the second best method.","1062-922X;1062922X","Electronic:978-1-4799-0652-9; POD:978-1-4799-0650-5","10.1109/SMC.2013.327","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722080","","Accuracy;Cultural differences;Databases;Feature extraction;Multiple signal classification;Music;Music information retrieval","information retrieval;music;signal classification","automatic music genre classification task;early fusion approach;music information retrieval;symbolic feature sets","","0","","29","","","13-16 Oct. 2013","","IEEE","IEEE Conference Publications"
"3rd workshop on Mining Unstructured Data","A. Bacchelli; N. Bettenburg; L. Guerrouj; S. Haiduc","Delft University of Technology, The Netherlands and University of Lugano, Switzerland","2013 20th Working Conference on Reverse Engineering (WCRE)","20131121","2013","","","491","492","Software development knowledge resides in the source code and in a number of other artefacts produced during the development process. To extract such a knowledge, past software engineering research has extensively focused on mining the source code, i.e., the final product of the development effort. Currently, we witness an emerging trend where researchers strive to exploit the information captured in artifacts such as emails and bug reports, free-form text requirements and specifications, comments and identifiers. Being often expressed in natural language, and not having a well-defined structure, the information stored in these artifacts is defined as unstructured data. Although research communities in Information Retrieval, Data Mining and Natural Language Processing have devised techniques to deal with unstructured data, these techniques are usually limited in scope (i.e., designed for English language text found in newspaper articles) and intended for use in specific scenarios, thus failing to achieve their full potential in a software development context. The workshop on Mining Unstructured Data (MUD) aims to provide a common venue for researchers and practitioners across software engineering, information retrieval and data mining research domains, to share new approaches and emerging results in mining unstructured data.","1095-1350;10951350","Electronic:978-1-4799-2931-3; POD:978-1-4799-2932-0","10.1109/WCRE.2013.6671333","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671333","","Conferences;Data mining;Educational institutions;Information retrieval;Multiuser detection;Software;Software engineering","","","","0","","","","","14-17 Oct. 2013","","IEEE","IEEE Conference Publications"
"On the incentives and incremental deployments of ICN technologies for OTT services","D. Saucez; S. Secci; C. Barakat","","IEEE Network","20140626","2014","28","3","20","25","With the explosion of broadband Over-The-Top (OTT) services, the Internet is autonomously migrating toward overlay and incrementally deployable content distribution infrastructures. Information-Centric Networking (ICN) technologies are the natural candidates to efficiently distribute popular content to users. However, the strategic incentives in exploiting ICN, for both users and ISPs, are much less understood to date. In this article we highlight strategic incentives for ICN overlay adoption in OTT services, that is, we discus how OTTs shall shape their prices to motivate ICN overlay usages.","0890-8044;08908044","","10.1109/MNET.2014.6843228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6843228","","Broadband;Collaboration;Games;IP networks;Information retrieval;Information technology;Internet;Routing protocols;Servers","Internet;broadband networks;incentive schemes;internetworking;overlay networks;telecommunication services","ICN overlay adoption;ICN technology;ISP;Internet;Internet service provider;OTT service;broadband over-the-top service;incremental deployment;information-centric networking technology;strategic incentives","","1","","5","","","May-June 2014","","IEEE","IEEE Journals & Magazines"
"An Ontology-Based Information Extraction (OBIE) Framework for Analyzing Initial Public Offering (IPO) Prospectus","J. Tao; A. V. Deokar; O. F. El-Gayar","Dakota State Univ., Madison, SD, USA","2014 47th Hawaii International Conference on System Sciences","20140310","2014","","","769","778","With the large amounts of information associated with the Initial Public Offering (IPO) process, an intelligent tool is needed for assisting the decision-making activities for both the investors and the underwriters. Even though a large body of related studies exists in extant literature, minimum attention has been devoted to the aspect of understanding hidden semantics within the informative contents of IPO prospectus. In this paper, we present a framework for processing the textual content of IPO prospectus based on an emerging technique named Ontology Based Information Extraction (OBIE). Preliminary results indicates that the framework is capable of meeting the design requirements identified. Moreover, lessons learned during the design and implementation span technical and organizational considerations and can serve as guidance for future research and development in related areas.","1530-1605;15301605","Electronic:978-1-4799-2504-9; POD:978-1-4799-2505-6","10.1109/HICSS.2014.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758699","Initial Public Offering;Ontology Based Information Extraction;Ontology-based Reasoning;Text Mining","Cognition;Data mining;IEEE Potentials;Information retrieval;Knowledge based systems;Ontologies;Semantics","data mining;decision making;information retrieval;ontologies (artificial intelligence);stock markets","IPO process;IPO prospectus;OBIE framework;decision making activities;hidden semantics;informative contents;initial public offering;intelligent tool;ontology-based information extraction framework","","0","","38","","","6-9 Jan. 2014","","IEEE","IEEE Conference Publications"
"Matching Reviews to Database Objects Based on Labeled Latent Dirichlet Allocation Model","Y. Zhu; Q. Li; Y. Zhu","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China","2013 10th Web Information System and Application Conference","20140327","2013","","","48","51","We develop a method for matching unstructured reviews to database objects in data integration, where each object has a set of attributes. To this end, we propose a Labeled Latent Dirichlet Allocation model. We model reviews as if they were generated by a two-stage stochastic process. Each review is represented by a probability distribution over attributes, and each attribute is represented as a probability distribution over words for that attribute. We introduce the label for each attribute, and then the model integrates object information. We use an unsupervised manner to estimate the model parameters, and use this model to find, given a review, the most likely object to be the topic of the review. Experiments in multiple domains show that our method is superior to the TFIDF method as well as a recent RLM method for the review matching problem.","","Electronic:978-1-4799-3219-1; POD:978-1-4799-3220-7","10.1109/WISA.2013.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6778609","Gibbs sampling;Latent Dirichlet Allocatio;data integration;review matching","Accuracy;Data integration;Databases;Information retrieval;Motion pictures;Probability distribution;Resource management","data integration;database management systems;parameter estimation;statistical distributions;stochastic processes","RLM method;TFIDF method;data integration;database objects;labeled latent Dirichlet allocation model;model parameter estimation;probability distribution;two-stage stochastic process;unstructured review matching","","0","","20","","","10-15 Nov. 2013","","IEEE","IEEE Conference Publications"
"AnnoPharma: Detection of substances responsible of ADR by annotating and extracting information from MEDLINE abstracts","S. Benzarti; W. Ben Abdessalem Karaa","Comput. Sci., High Inst. of Manage., Tunisia","2013 International Conference on Control, Decision and Information Technologies (CoDIT)","20131223","2013","","","294","299","Several studies have been conducted in different areas in order to annotate the medical data and extract knowledge, related to diseases, amino acid, genes, proteins, etc. Our research concerns the field of pharmacology which is wealthy but rarely studied. However it is a very interesting field and has great value as it is directly connected to human life. The aim of our research is to annotate MEDLINE abstracts belonging to the domain of pharmacology in order to extract the substances responsible of Adverse Reactions (ADRs) on the human body organs. To validate our approach, we implemented a prototype of a system (AnnoPharma). For this purpose we designed a new approach, based on semantic annotation, showing heartening performance.","","Electronic:978-1-4673-5549-0; POD:978-1-4673-5548-3","10.1109/CoDIT.2013.6689560","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6689560","ADR;Annotation;Information Extraction;MEDLINE;OWL;RDF;UMLS;pharmacology","Abstracts;Biological systems;Data mining;Drugs;Information retrieval;Ontologies;Semantics","diseases;genetics;knowledge acquisition;medical information systems;proteins","ADR;AnnoPharma;MEDLINE abstracts;adverse reactions;amino acid;diseases;genes;human body organs;information annotation;information extraction;knowledge extraction;medical data;pharmacology;proteins","","2","","11","","","6-8 May 2013","","IEEE","IEEE Conference Publications"
"Research on Ontology-Based Chinese Semantic Retrieval Model","Q. Chang; Y. Zhou; L. Zheng; S. Xu; J. Li; B. Yan","Univ. of Chinese Acad. of Sci., Beijing, China","2014 International Conference on Computational Science and Computational Intelligence","20140529","2014","1","","302","307","This paper introduces the Chinese Semantic Retrieval model and the key technology. It initially points out the core idea of mapping natural language to RDF triples. Based on the Language Technology Platform dependency relationship, it classifies the Chinese question. Then, the article outlines the concrete method of mapping Chinese question to SPARQL query with examples. At last, it implements the system and gives the retrieval result, which decreases the irrelevant searching return compared with the tradition information retrieval method based on keyword matching.","","Electronic:978-1-4799-3010-4; POD:978-1-4799-3011-1; USB:978-1-4799-3009-8","10.1109/CSCI.2014.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822126","classification;dependency relationship;mapping rule;semantic retrieval;sparql","Grammar;Information retrieval;Natural languages;Ontologies;Resource description framework;Semantics;Syntactics","natural language processing;ontologies (artificial intelligence);pattern matching;query processing","Chinese question;RDF triples;SPARQL query;information retrieval method;keyword matching;language technology platform dependency relationship;natural language mapping;ontology-based Chinese semantic retrieval model","","0","","8","","","10-13 March 2014","","IEEE","IEEE Conference Publications"
"A Multimedia Semantic Retrieval Mobile System Based on HCFGs","Y. Yang; H. Y. Ha; F. C. Fleites; S. C. Chen","","IEEE MultiMedia","20140305","2014","21","1","36","46","A multimedia semantic retrieval system based on hidden coherent feature groups (HCFGs) can support multimedia semantic retrieval on mobile applications. The system can capture the correlation between features and partition the original feature set into HCFGs, which have strong intragroup correlation while maintaining low intercorrelation. The authors present a novel, multimodel fusion scheme to effectively fuse the multimodel results and generate the final ranked retrieval results. In addition, to incorporate user interaction for effective retrieval, the proposed system also features a user feedback mechanism that helps refine the retrieval results.","1070-986X;1070986X","","10.1109/MMUL.2013.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560008","HCFGs;affinity propagation;correlation;hidden coherent feature groups;mobile applications;mobile computing;multimedia;multimedia data management;multimedia semantic retrieval;multimodel fusion","Feature extraction;Hidden Markov models;Information retrieval;Mobile communication;Mobile computing;Multimedia communication;Semantics","group theory;information retrieval systems;mobile computing;multimedia systems;sensor fusion","HCFG;feature set partition;hidden coherent feature groups;intercorrelation;intragroup correlation;multimedia semantic retrieval mobile system;multimodel fusion scheme;retrieval results ranking;user feedback mechanism;user interaction","","6","","8","","20130716","Jan.-Mar. 2014","","IEEE","IEEE Journals & Magazines"
