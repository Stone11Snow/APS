"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7338531,7339221,7332517,7332558,7335365,7335409,7334991,7225173,7321214,7321610,7014223,6873230,7314643,7314287,7072494,7300300,7294487,7296366,7292374,7282977,7280529,7284129,7277246,7277260,7272945,7270735,7272551,7263511,7224784,7219809,1016491,1016642,1016509,7219859,7219765,7208640,7203123,7193083,7185355,7182624,7181818,7178003,7177949,7178965,7175771,7178037,7175948,7177956,7178055,7177947,7168324,7165944,7164788,7160416,7149267,7122855,7149310,7148354,7140321,7130443,7130006,7130337,7130034,7128902,7124872,6879338,7119544,7119356,7070687,7113420,7113407,7006392,7102596,7100530,7100244,7096173,7096236,7098043,7086210,7064258,7081946,7081874,7077471,7073405,7078667,7073412,7073262,7073235,7072850,7073237,7072835,7077255,7065859,7066639,7060695,7062746,7009977,7054207,7050785,7049887",2017/05/04 20:47:29
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An Ontology-Based Information Extraction System for bridging the configuration gap in hybrid SDN environments","A. Martinez; M. Yannuzzi; J. E. L. de Vergara; R. Serral-Gracià; W. Ramírez","Networking and Information Technology Lab (NetIT Lab), Technical University of Catalonia (UPC). Spain","2015 IFIP/IEEE International Symposium on Integrated Network Management (IM)","20150702","2015","","","441","449","Hybrid Software-Defined Networks (SDNs) are growing at a remarkable speed, so network administrators need to deal with the configuration of a plethora of devices including OpenFlow elements, traditional equipment, and nodes supporting both OpenFlow and traditional features. The OpenFlow Management and Configuration Protocol (OF-CONFIG) is positioned as a solid candidate for the remote configuration of OpenFlow devices, but the fact that OF-CONFIG relies on NETCONF for its transport constrains its potential considerably. Indeed, the lack of comprehensive and standardized data models has hindered the utilization of NETCONF itself in traditional networks, and will likely confine OF-CONFIG to an elementary set of configurations until the expected data models arrive. In this paper, we present a semantic-based approach that eases and automates the configuration of network devices while complementing the capabilities of OF-CONFIG and NETCONF. Our main contributions can be summarized as follows. First, we have formalized the semantics of the switch/router configuration domain using the Web Ontology Language (OWL). Second, we have developed an Ontology-Based Information Extraction (OBIE) system from the Command-Line Interface (CLI) of network devices. Third, we have defined a learning algorithm that enables automated interpretation of CLIs' configuration capabilities in heterogeneous (multi-vendor) network scenarios. The potential of our approach is demonstrated through experiments carried out on different network elements.","1573-0077;15730077","Electronic:978-1-4799-8241-7; POD:978-1-4799-8242-4","10.1109/INM.2015.7140321","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140321","","Data models;Information retrieval;OWL;Ontologies;Protocols;Semantics;Switches","ontologies (artificial intelligence);program interpreters;protocols;software defined networking","CLI configuration capabilities;NETCONF;OBIE system;OF-CONFIG;OWL;OpenFlow Management and Configuration Protocol;OpenFlow elements;Web ontology language;command-line interface;configuration gap;data models;heterogeneous multivendor network scenarios;hybrid SDN environments;hybrid software-defined networks;learning algorithm;network administrators;network device configuration;network devices;ontology-based information extraction system;remote configuration;router configuration semantics;switch configuration semantics;transport constrains","","2","","25","","","11-15 May 2015","","IEEE","IEEE Conference Publications"
"Semi-supervised Chinese Open Entity Relation Extraction","Mingyin Wang; Lei Li; Fang Huang","Beijing University of Posts and Telecommunications, 100876, China","2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems","20150806","2014","","","415","420","Open Information Extraction (IE) systems extract relational tuples from text, without requiring a pre-specified vocabulary, by identifying relation phrases and associated arguments in arbitrary sentences. A lot of work have been done for English Open IE, and now the Chinese Open IE field is attracting more and more researchers and scholars. In this paper we present a novel SCOERE (Semi-supervised Chinese Open Entity Relation Extraction) method. This approach combines the advantages of both unsupervised and supervised methods, which needs very little human work to annotate the corpus and would iteratively extract tuples until there is no new relation keywords generated. The experiments show that our method could get a good recall rate and a reasonable accuracy rate.","2376-5933;23765933","Electronic:978-1-4799-4719-5; POD:978-1-4673-6954-1","10.1109/CCIS.2014.7175771","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175771","COERE;Open IE;Semi-supervision","Electronic publishing;Encyclopedias;Feature extraction;Information analysis;Information retrieval;Internet","natural language processing;text analysis;unsupervised learning","Chinese open IE field;English open IE;SCOERE method;accuracy rate;arbitrary sentences;associated argument identification;corpus annotation;open information extraction systems;recall rate;relation keyword generation;relation phrases identifying;semisupervised Chinese open entity relation extraction method;semisupervised chinese open entity relation extraction;supervised method;text relational tuple extraction;unsupervised method","","0","","10","","","27-29 Nov. 2014","","IEEE","IEEE Conference Publications"
"Text mining: Challenges and future directions","A. Akilan","Department of Information Technology, Annai College of Arts and Science, Kumbakonam","2015 2nd International Conference on Electronics and Communication Systems (ICECS)","20150618","2015","","","1679","1684","In today's world, the amount of stored information has been enormously increasing day by day which is generally in the unstructured form and cannot be used for any processing to extract useful information, so several techniques such as summarization, classification, clustering, information extraction and visualization are available for the same which comes under the category of text mining. Text Mining can be defined as a technique which is used to extract interesting information or knowledge from the text documents. Text mining, also known as text data mining or knowledge discovery from textual databases, refers to the process of extracting interesting and non-trivial patterns or knowledge from text documents. Regarded by many as the next wave of knowledge discovery, text mining has very high commercial values.","","Electronic:978-1-4799-7225-8; POD:978-1-4799-7226-5","10.1109/ECS.2015.7124872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7124872","Text mining;data mining;knowledge discovery","Databases;Information retrieval;Internet;Knowledge discovery;Semantics;Text mining","data mining;document handling;pattern classification;pattern clustering","classification;clustering;information extraction;information visualization;knowledge discovery;summarization;text data mining;text documents;textual databases","","0","","6","","","26-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"Semantic-Aware Co-Indexing for Image Retrieval","S. Zhang; M. Yang; X. Wang; Y. Lin; Q. Tian","School of Electronic Engineering and Computer Science, Peking University, No. 5 Yiheyuan Road Haidian District, Beijing, P.R. China","IEEE Transactions on Pattern Analysis and Machine Intelligence","20151030","2015","37","12","2573","2587","In content-based image retrieval, inverted indexes allow fast access to database images and summarize all knowledge about the database. Indexing multiple clues of image contents allows retrieval algorithms search for relevant images from different perspectives, which is appealing to deliver satisfactory user experiences. However, when incorporating diverse image features during online retrieval, it is challenging to ensure retrieval efficiency and scalability. In this paper, for large-scale image retrieval, we propose a semantic-aware co-indexing algorithm to jointly embed two strong cues into the inverted indexes: (1) local invariant features that are robust to delineate low-level image contents, and (2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. Specifically, for an initial set of inverted indexes of local features, we utilize semantic attributes to filter out isolated images and insert semantically similar images to this initial set. Encoding these two distinct and complementary cues together effectively enhances the discriminative capability of inverted indexes. Such co-indexing operations are totally off-line and introduce small computation overhead to online retrieval, because only local features but no semantic attributes are employed for the query. Hence, this co-indexing is different from existing image retrieval methods fusing multiple features or retrieval results. Extensive experiments and comparisons with recent retrieval methods manifest the competitive performance of our method.","0162-8828;01628828","","10.1109/TPAMI.2015.2417573","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072494","Deep CNN;Inverted Indexing;Large-scale Image Retrieval;Semantic Attributes;Vocabulary Trees","Data visualization;Image retrieval;Indexes;Information retrieval;Semantics;Vocabulary","content-based retrieval;database indexing;feature extraction;image coding;image fusion;image retrieval;visual databases","computation overhead;content-based image retrieval;cue encoding;database image access;discriminative capability enhancement;image contents;image features;image search;inverted indexes;isolated image filtering;knowledge summarization;large-scale image retrieval;large-scale object recognition;local invariant features;low-level image contents;multiple clue Indexing;multiple feature fusion;online retrieval;query processing;retrieval efficiency;retrieval scalability;semantic attributes;semantic-aware co-indexing;semantically similar image insertion;user experiences","","1","","57","","20150330","Dec. 1 2015","","IEEE","IEEE Journals & Magazines"
"A Rule-Based Annotation System to Extract Tajweed Rules from Quran","A. Alfaries; M. Albahlal; M. Almazrua; A. Almazrua","IT Department, IWAN Res. Group, King Saud Univ., Riyadh, Saudi Arabia","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","281","286","Quran Recitation relies on identifying and applying different Tajweed rules [ÞæÇÚÏ ÇáÊÌæíÏ] such as Muddud [ãÏæÏ] and Tanween [Êäæíä] in the Quran text. This research is aimed at providing a tool that automatically finds and annotates letters that embody Tajweed rules in Quran text. This field remains an open research area due to the lack of open source NLP tools that support the Arabic language. Applying Natural Language Processing (NLP) techniques on Quran text to extract Tajweed letters is considered an important Information Extraction (IE) step. This research explores the field of applying IE techniques on Quran text. Rule based IE techniques are well known to achieve optimal results. This research explores NLP techniques on Quranic text using GATE, an open source flexible NLP environment. GATE is employed for this research to build the application that processes un-annotated Quranic text corpus. The developed application is evaluated using the well known IE evaluation metrics precision and recall. By comparing the system's automatically annotated text with a gold standard (i.e. Quran text). The system proved to be efficient by achieving 100% precision and recall of the implemented Tajweed rules.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277260","Arabic NLP;Arabic text analysis;GATE;Infomratio extraction;Quran;Tajweed Rules","Data mining;Gold;Information retrieval;Lips;Logic gates;Natural language processing;Standards","humanities;information retrieval;natural language processing;public domain software;text analysis","Arabic language;GATE;IE evaluation metrics;Muddud;Quran recitation;Tajweed letter extraction;Tajweed rule extraction;Tanween;gold standard;information extraction;letter annotation;natural language processing techniques;open source flexible NLP environment;precision metric;recall metric;rule-based IE techniques;rule-based annotation system;unannotated Quranic text corpus processing","","","","","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"Document Counting in Compressed Space","T. Gagie; A. Hartikainen; J. Kärkkäinen; G. Navarro; S. J. Puglisi; J. Sirén","Dept. of Comput. Sci., Univ. of Helsinki, Helsinki, Finland","2015 Data Compression Conference","20150706","2015","","","103","112","We address the problem of counting the number of strings in a collection where a given pattern appears, which has applications in information retrieval and data mining. Existing solutions are in a theoretical stage. In this pa-per we implement these solutions and explore compressed variants, aiming to reduce data structure size. Our main result is to uncover some unexpected compressibility properties of the fastest known data structure for the problem. By taking advantage of these properties, we can reduce the size of the structure by a factor of 5-400, depending on the dataset.","1068-0314;10680314","Electronic:978-1-4799-8430-5; POD:978-1-4799-8431-2","10.1109/DCC.2015.55","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7149267","","Arrays;Data compression;Data mining;Encoding;Indexes;Information retrieval","data mining;document handling;information retrieval;string matching","compressed space;compressibility properties;data mining;data structure size reduction;document counting;information retrieval;string counting","","1","","16","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"Let's Weave the Visual Web","R. Jain","University of California, Irvine","IEEE MultiMedia","20150807","2015","22","3","66","72","A major disruption is taking place in terms of how photographs are captured and the role they play in modern society, offering the tantalizing possibility of creating visual connections and conversations beyond anything we've yet seen or imagined. The author reviews the evolution of visual documentation and considers where we're headed, introducing the Visual Web. This department is part of a special issue on social multimedia and storytelling.","1070-986X;1070986X","","10.1109/MMUL.2015.60","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181818","Internet/Web technologies;big data;data analysis;graphics;mobile;multimedia;the Visual Web;visual documentation;visualization","Big data;Context modeling;Data analysis;Information retrieval;Multimedia communication;Videos;Visualization;Web and internet services","Internet;social networking (online);visual databases","photograph;social multimedia;visual Web;visual documentation","","0","","11","","","July-Sept. 2015","","IEEE","IEEE Journals & Magazines"
"The method of synonyms extraction from unannotated corpus","A. A. Pak; S. S. Narynov; A. S. Zharmagambetov; S. N. Sagyndykova; Z. E. Kenzhebayeva; I. Turemuratovich","LLC AlemResearch, Almaty, Kazakhstan","2015 Third International Conference on Digital Information, Networking, and Wireless Communications (DINWC)","20150305","2015","","","1","5","The structuring of large volumes of e-documents assumes the organization of text on several levels, namely paragraphs, sentences, phrases, words. Methods of lexical paradigms extraction using statistical analysis were developed long ago. In this paper we attempt to move from lexical correlatives to the list of synonyms on various levels of generalization on the basis of local and global contexts' statistics.","","CD-ROM:978-1-4799-6375-1; Electronic:978-1-4799-6376-8; POD:978-1-4799-6377-5","10.1109/DINWC.2015.7054207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7054207","Data Mining;Extracting synonym algorithm;categorize the topics of texts;construction of a semantic map concepts;e-documents","Clustering algorithms;Context;Data mining;Educational institutions;Histograms;Information retrieval;Semantics","data mining;statistical analysis;text analysis","e-document structuring;generalization levels;global statistics;lexical correlatives;lexical paradigm extraction method;local statistics;paragraphs;phrases;sentences;statistical analysis;synonym extraction method;synonym list;text organization;unannotated corpus;words","","2","","5","","","3-5 Feb. 2015","","IEEE","IEEE Conference Publications"
"Word Sense Disambiguation for English Quranic IR System","S. Tiun; H. Zakr; M. Mohd; N. Z. Abidin; A. I. I. Hisham","Fac. of Technol. & Inf. Sci., Univ. Kebangsaan Malaysia, Bangi, Malaysia","2013 Taibah University International Conference on Advances in Information Technology for the Holy Quran and Its Sciences","20150928","2013","","","199","202","Quranic text Information Retrieval (IR) is quite demanding yet very trivial due to that user will not always use the exact keywords to retrieve the relevant Quranic text (verse). Many have tried to overcome this problem by expanding or reformulating the query entered by users using semantic approaches with resources such as ontologies and thesauri. Word Sense Disambiguation (WSD) has been less interest to the IR research community due to the insignificant or very little significant impact on the IR performance. Recently, researchers pay interest on applying WSD to the IR problem due to the intuition that deep semantic analysis on the query process will give good impact on the IR performance. However, we have not seen any articles mentioning the use of WSD for Quranic IR, which we are assuming less or none research on WSD for Quranic IR have been carried out. Thus, this motivates us to explore WSD impact on Quranic IR performance. This paper will describe our on-going project on building an English Quranic WSD at the early stage, which is still at the proposal stage, where we layout what could be the best approach, resources and disambiguation algorithm for Quranic WSD for IR.","","Electronic:978-1-4799-2823-1; POD:978-1-4799-2824-8","10.1109/NOORIC.2013.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7277246","Quranic IR;Quranic Translated Text;Unsupervised Word Sense Disambiguation","Accuracy;Earth;Indexes;Information retrieval;Semantics;Standards;Training","humanities;information retrieval systems;natural language processing;query processing","English Quranic IR system;WSD;information retrieval system;query process;semantic approach;word sense disambiguation","","","","9","","","22-25 Dec. 2013","","IEEE","IEEE Conference Publications"
"An information extraction framework for legal documents: A case study of Thai Supreme Court verdicts","K. Kowsrihawat; P. Vateekul","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20150827","2015","","","275","280","A summary judgement of Thai Supreme Court's case is necessary for legal research. Unfortunately, among thousands of decisions, judges traditionally spend a couple of months to manually create just one of them. In this paper, we present a system called “JudgeDoll, ” which automatically extracts the gist information and provides a legal summary of the full judgement. This system can help the judge to rapidly summarize points of law with correct and reliable results. The experiment was conducted on the data set of Thai Supreme Court's cases, particularly about civil and criminal. For the information extraction part, the results showed that our system achieves more than 90% of accuracy in terms of F<sub>1</sub>. For the legal-case summarization part, experts evaluated that they are very satisfied with the summary provided by our system. Furthermore, it requires just only few minutes to process each legal case.","","Electronic:978-1-4799-1966-6; POD:978-1-4799-1967-3","10.1109/JCSSE.2015.7219809","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219809","Thai Supreme Court;information extraction;legal documents;text summarization","Information retrieval;Law;Libraries;Prototypes;Testing","document handling;law","Thai Supreme Court verdicts;gist information;information extraction;legal documents;legal research;legal-case summarization","","0","","12","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Extracting phrase-content pairs for Turkish sentences","İ. Dönmez; E. Adali","Department of Computer Engineering, &#x0130;stanbul Technical University, Turkey","2015 9th International Conference on Application of Information and Communication Technologies (AICT)","20151130","2015","","","128","132","In this paper we present a framework for extraction of Turkish phrases and their concepts. The objective of the study is meeting the requirement of sources for Turkish Semantic Extractions and represent a Turkish sentence at phrase-concept level. The semantic and grammatical analysis of a sentence is a basic content of Natural Language Processing (NLP) which is a branch of Artificial Intelligence (AI). In our study Turkish Phrase-Content Finding system is formed as a source for the other application areas in NLP. This system can be used in Summarization Systems, Information Extraction, Automatic Question Answering System, Semantic Role Labeling, and other semantic application.","","Electronic:978-1-4673-6856-8; POD:978-1-4673-6857-5","10.1109/ICAICT.2015.7338531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7338531","Phrase finder;concept extraction;sentence analysis","Accuracy;Animals;Compounds;Information retrieval;Instruments;Labeling;Semantics","natural language processing;text analysis","AI;NLP;Turkish phrase-content finding system;Turkish phrases;Turkish semantic extractions;Turkish sentences;artificial intelligence;automatic question answering system;grammatical analysis;information extraction;natural language processing;phrase-concept level;phrase-content pairs;semantic application;semantic role labeling;summarization systems","","","","22","","","14-16 Oct. 2015","","IEEE","IEEE Conference Publications"
"Semantic document retrieval system using fuzzy clustering and reformulated query","D. Murali; A. Damodaram","CSE, CMR CET, Hyderabad, T.S, India","2015 International Conference on Advances in Computer Engineering and Applications","20150723","2015","","","746","753","In this paper, we develop an algorithm for document retrieval system through clustering process and query basis. Initially, the pre-processing is applied on whole documents to remove the unnecessary words and phrases of every document. Then the clustering process in applied to make the partition of the documents through the proposed semantic similarity measure used in the possibilistic fuzzy c means (PFCM) clustering algorithm. For each cluster, the index constructed, which contains common important keywords of the documents of cluster. Once the user enter the keyword as the input to the system, it will process the keywords with the WORDNET ontology to obtain the neighbourhood keywords and related synset keywords. From the set of keywords obtained from the WORDNET is refined and the refined keywords are matched with the index keywords of the clusters to calculate the matching score. Finally, the documents inside the cluster are released at first as the resultant related documents for the query keyword, which clusters have the maximum matching score values. The experimentation process is carried out with the help of different set of documents to achieve the results, the performance analysis of the proposed approach is estimated by precision, and we proved our proposed approach is outperformed in terms of precision.","","DVD:978-1-4673-6910-7; Electronic:978-1-4673-6911-4; POD:978-1-4673-6912-1","10.1109/ICACEA.2015.7164788","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7164788","Document clustering;Ontology;Semantic similarity measure;WORDNET;possibilistic fuzzy c means","Clustering algorithms;Computers;Indexing;Information retrieval;Ontologies;Semantics","document handling;fuzzy set theory;ontologies (artificial intelligence);pattern clustering;query processing","PFCM clustering algorithm;WORDNET ontology;clustering process;documents partition;fuzzy clustering;matching score;neighbourhood keywords;performance analysis;possibilistic fuzzy c means;query basis;query keyword;reformulated query;semantic document retrieval system","","0","","27","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Measuring the Effectiveness of Various Features for Thematic Information Extraction From Very High Resolution Remote Sensing Imagery","X. Chen; T. Fang; H. Huo; D. Li","Autom. Dept., Shanghai Jiao Tong Univ., Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","20150608","2015","53","9","4837","4851","Generally, some object-based features are more relevant to a thematic class than other features. These strongly relevant features, termed as class-specific features, would significantly contribute to thematic information extraction for very high resolution (VHR) images. However, many existing feature selection methods have been designed to select a good feature subset for all classes, rather than an independent feature subset for the thematic class. The latter might better meet the requirement of thematic information extraction than the former. In addition, the lack of quantitative evaluation of the contribution of the selected features to thematic classes also weakens our understandability of these features. To address the problems, class-specific feature selection methods are developed to measure the effectiveness of features for extracting thematic information from VHR images. First, the one-versus-all scheme is combined with traditional feature selection methods, such as ReliefF and LeastC. Also, one-versus-one scheme is utilized for alleviating the negative impact of a class imbalance problem arising from the one-versus-all scheme. Then, the relative contributions of features to thematic classes are obtained by the class-specific feature selection methods to describe the effectiveness of features for thematic information extraction. Finally, the class-specific feature selection methods are compared with the original methods on three different VHR image data sets by the nearest neighbor and support vector machine. Experimental results show that the class-specific feature selection methods outperform the corresponding conventional methods, and the one-versus-one scheme surpasses one-versus-all scheme. Additionally, many features are evaluated by the class-specific feature selection methods, to provide end users advice on effectiveness of the features.","0196-2892;01962892","","10.1109/TGRS.2015.2411331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7070687","Classification;class-specific feature selection;object-based features;one-versus-one scheme;thematic class","Accuracy;Data mining;Feature extraction;Image resolution;Information retrieval;Robustness;Vectors","feature extraction;geophysical image processing;remote sensing;support vector machines","LeastC method;ReliefF method;class-specific feature selection method;nearest neighbor;one-versus-all scheme;one-versus-one scheme;support vector machine;thematic class;thematic information extraction;very high resolution images;very high resolution remote sensing imagery","","2","","49","","20150327","Sept. 2015","","IEEE","IEEE Journals & Magazines"
"Design and evaluation of a high-level interface for data mining","Ruoming Jin; G. Agrawal","","Proceedings 16th International Parallel and Distributed Processing Symposium","20150827","2002","","","8 pp","","","","POD:0-7695-1573-8","10.1109/IPDPS.2002.1016491","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1016491","","Application software;Availability;Biomedical informatics;Computer interfaces;Data analysis;Data mining;High performance computing;Information retrieval;Parallel programming;Performance analysis","","","","1","","23","","","15-19 April 2001","","IEEE","IEEE Conference Publications"
"On the use of the tempogram to describe audio content and its application to Music structural segmentation","M. Tian; G. Fazekas; D. A. A. Black; M. Sandler","Centre for Digital Music, Queen Mary University of London, E1 4NS, UK","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","419","423","This paper presents a new set of audio features to describe music content based on tempo cues. Tempogram, a mid-level representation of tempo information, is constructed to characterize tempo variation and local pulse in the audio signal. We introduce a collection of novel tempogram-based features inspired by musicological hypotheses about the relation between music structure and its rhythmic components prominent at different metrical levels. The strength of these features is demonstrated in music structural segmentation, an important task in Music information retrieval (MIR), using several published popular music datasets. Results indicate that incorporating tempo information into audio segmentation is a promising new direction.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178003","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178003","Audio signal processing;music segmentation;rhythm feature extraction;tempogram","Feature extraction;Music information retrieval;Rhythm;Speech;Speech processing","acoustic signal processing;audio signal processing;music","Music information retrieval;audio music content;audio segmentation;music structural segmentation;music structure;musicological hypotheses;rhythmic components;tempo cues;tempo information;tempo variation;tempogram","","2","","16","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"An information extraction system for protein function prediction","K. Taha; P. D. Yoo","Electrical and Computer Engineering Department, Khalifa University, UAE","2015 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","20151019","2015","","","1","7","We present a Natural Language Processing extraction system called IESforPFP, which can retrieve useful information from biomedical abstracts. IESforPFP aims at enhancing the state of the art of biological text mining by applying novel linguistic computational technique. By retrieving significant patterns of associations between proteins and molecules from biomedical abstracts, IESforPFP can determine the functions of un-annotated proteins. The system determines the semantic relationship between each protein-molecule pair in sentences using novel semantic rules. It applies a semantic relationship extraction model that retrieves information from different structural forms of constituents in sentences. In the framework of IESforPFP, each protein p is represented by a vector of weights. Each weight reflects the significance of a molecule m in the biomedical abstracts associated with p. That is, each weight quantifies the likelihood of the association between m and p. IESforPFP determines the set of annotated proteins that is semantically similar to p by comparing their vectors. It then annotates p with the functions of these annotated proteins. We evaluated the quality of IESforPFP by comparing it experimentally with two other systems. Results showed marked improvement.","","Electronic:978-1-4799-6926-5; POD:978-1-4799-6927-2","10.1109/CIBCB.2015.7300300","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300300","Dependency parser;Text mining;biological NLP;biomedical literature;information extraction","Information retrieval;Pragmatics;Protein engineering;Proteins;Semantics;Syntactics","bioinformatics;data mining;feature extraction;molecular biophysics;molecular configurations;natural language processing;proteins;query languages","IESforPFP;biological text mining;biomedical abstracts;information extraction system;linguistic computational technique;natural language processing extraction system;pattern retrieval;protein function prediction;protein-molecule pair;semantic relationship;semantic rules;structural forms;unannotated proteins","","","","26","","","12-15 Aug. 2015","","IEEE","IEEE Conference Publications"
"Research on Pattern Representation Method in Semi-supervised Semantic Relation Extraction Based on Bootstrapping","F. Ye; H. Shi; S. Wu","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","1","","568","572","Semantic relation extraction is an important part of information extraction, it has application value in the automatic question answering system, retrieval system, ontology learning, semantic web annotation, and many other areas. Pattern representation method is context pattern in previous semi-Supervised semantic relation extraction based on bootstrapping, but it did not consider the role of the keywords in the semantic relation. This paper presents an improved context pattern, which has a stronger semantic expressiveness, which is used to extract semantic relations and makes the semantic relation extraction more accurate. First of all, the sentence context pattern is obtained by lexical analysis. Then, the syntax tree model is obtained by syntactic analysis, calculate words weight using the syntax tree pattern. Finally, extract semantic relations using semi-Supervised machine learning method based on bootstrapping. The experimental results show that this method can effectively extract the semantic relations.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.154","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064258","Bootstrapping;Information Extraction;Pattern;Semantic relation;Semi-Supervised","Context;Data mining;Feature extraction;Information retrieval;Kernel;Semantics;Syntactics","computational linguistics;information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);semantic networks;statistical analysis;trees (mathematics)","automatic question answering system;bootstrapping;information extraction;lexical analysis;ontology learning;pattern representation method;retrieval system;semantic Web annotation;semisupervised machine learning method;semisupervised semantic relation extraction;sentence context pattern;syntactic analysis;syntax tree model","","2","","23","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Adaptive information extraction of disaster information from Twitter","R. V. J. Regalado; J. L. Chua; J. L. Co; H. C. Cheng; A. B. L. Magpantay; K. M. D. F. Kalaw","Center for Language Technologies De La Salle University, Manila","2014 International Conference on Advanced Computer Science and Information System","20150326","2014","","","286","289","With the popularity of the Internet and social media platforms, information that is potentially useful in disaster response becomes available online in the hours and days immediately following a disaster. The use of information extraction in retrieving relevant disaster information from all these crowdsourced data would provide more information coming from both official reports, and the affected people themselves which in turn facilitate better decision making environments for disaster managers. This paper describes a system which performs an adaptive information retrieval of disaster related information coming from Twitter. Result shows 94.33% accuracy when extracting disaster and location information in the typhoon corpus while 90.79% accuracy for the fire corpus.","","Electronic:978-1-4799-8075-8; POD:978-1-4799-8076-5; USB:978-1-4799-8074-1","10.1109/ICACSIS.2014.7065859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065859","","Data mining;Decision support systems;Fires;Information retrieval;Signal detection","emergency management;information retrieval;outsourcing;social networking (online)","Internet platform;Twitter;adaptive disaster information retrieval;adaptive information extraction;crowdsourced data;decision making environments;disaster response;fire corpus;location information extraction;social media platform;typhoon corpus","","0","","12","","","18-19 Oct. 2014","","IEEE","IEEE Conference Publications"
"Using compatible keys for secure multicasting in E-commerce","I. Ray; I. Ray","","Proceedings 16th International Parallel and Distributed Processing Symposium","20150827","2002","","","8 pp","","","","POD:0-7695-1573-8","10.1109/IPDPS.2002.1016642","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1016642","","Access protocols;Bandwidth;Broadcasting;Computer science;Cryptography;Electronic commerce;Information retrieval;Quality management;Quality of service;Subscriptions","","","","2","1","15","","","15-19 April 2001","","IEEE","IEEE Conference Publications"
"Amazighe Named Entity Recognition using a A rule based approach","S. Boulaknadel; M. Talha; D. Aboutajdine","Royal Institut of Amazighe Culture Allal El Fassi Avenue, Madinat Al Irfane, Rabat-Instituts, Morocco","2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)","20150402","2014","","","478","484","The Named Entity Recognition (NER) is very important task revolving around many natural language processing applications. However, many studies have achieved the maturity stage in a variety of languages such as English and French, but a few limited research efforts have attacked the named entity recognition problem in Amazighe script. This is due to the resources scarcity for Amazighe named entities and the limited work made in Amazighe natural language processing in general. In this paper, we describe our attempt at the development and implementation of a named entity recognition system for the Amazighe Language using a rule based approach. Our system has been effectively evaluated using our own corpus; it reached acceptable results in terms of precision, recall, and F-measure.","2161-5322;21615322","Electronic:978-1-4799-7100-8; POD:978-1-4799-7101-5","10.1109/AICCSA.2014.7073237","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073237","Amazighe Language;GATE;NLP;Named Entity;Recognition (NER);Rule-based Approach","Companies;Grammar;Information retrieval;Logic gates;Natural language processing;Pragmatics","knowledge based systems;natural language processing","Amazighe language;Amazighe named entity recognition;Amazighe script;F-measure;corpus;natural language processing applications;rule based approach","","1","","21","","","10-13 Nov. 2014","","IEEE","IEEE Conference Publications"
"Business protocol discovery from log files using a TF-IDF-based technique","A. Moudjari; S. Chikhi; A. Draa","MISC Laboratoory, Department of Fundamental Informatics and its Applications, Abdelhamid Mehri University Constantine, Algeria","2015 Seventh International Conference on Ubiquitous and Future Networks","20150810","2015","","","651","656","In this paper, a new algorithm for web service business protocol discovery is presented. It is based on an information retrieval and document indexing technique, the TF-IDF. The latter's formula has been modified and adapted for computing importance of edges of the graphs corresponding to business protocols in question. Log files describing the execution history of web services are used without any a priori information. The proposed approach has been tested on synthetically generated log files and found to be very efficient in discovering business protocols.","2165-8528;21658528","Electronic:978-1-4799-8993-5; POD:978-1-4799-8994-2; USB:978-1-4799-8992-8","10.1109/ICUFN.2015.7182624","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7182624","","Business;Frequency measurement;Information retrieval;Mathematical model;Noise;Protocols;Web services","Web Services Business Process Execution Language;information retrieval;protocols","TF-IDF-based technique;document indexing technique;information retrieval;log files;web service business protocol discovery","","0","","18","","","7-10 July 2015","","IEEE","IEEE Conference Publications"
"The impact of cross-distribution bug duplicates, empirical study on Debian and Ubuntu","V. Boisselle; B. Adams","MCIS, Polytechnique Montr&#x00E9;al, Qu&#x00E9;bec, Canada","2015 IEEE 15th International Working Conference on Source Code Analysis and Manipulation (SCAM)","20151123","2015","","","131","140","Although open source distributions like Debian and Ubuntu are closely related, sometimes a bug reported in the Debian bug repository is reported independently in the Ubuntu repository as well, without the Ubuntu users nor developers being aware. Such cases of undetected cross-distribution bug duplicates can cause developers and users to lose precious time working on a fix that already exists or to work individually instead of collaborating to find a fix faster. We perform a case study on Ubuntu and Debian bug repositories to measure the amount of cross-distribution bug duplicates and estimate the amount of time lost. By adapting an existing within-project duplicate detection approach (achieving a similar recall of 60%), we find 821 cross-duplicates. The early detection of such duplicates could reduce the time lost by users waiting for a fix by a median of 38 days. Furthermore, we estimate that developers from the different distributions lose a median of 47 days in which they could have collaborated together, had they been aware of duplicates. These results show the need to detect and monitor cross-distribution duplicates.","","Electronic:978-1-4673-7529-0; POD:978-1-4673-7530-6","10.1109/SCAM.2015.7335409","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335409","","Collaboration;Computer bugs;Feature extraction;Generators;Information retrieval;Linux;Organizations","program debugging;public domain software","Debian bug repository;Ubuntu bug repository;cross-distribution bug duplicate;open source distribution","","","","20","","","27-28 Sept. 2015","","IEEE","IEEE Conference Publications"
"A sample partition method for learning to rank based on query-level vector extraction","J. Xu; Shilong Zhou; Hong Chen; Pengfei Li","School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing, China","2015 International Joint Conference on Neural Networks (IJCNN)","20151001","2015","","","1","7","Learning to rank plays a very important role in information retrieval. Existing works mainly focus on applying one ranking model to all samples, which may not be suitable for the reality. In this paper, a new method for learning to rank based on query-level vector extraction is proposed, in which we assume that all samples can be divided into multiple parts, and each part is used to train one set of parameters for the model. Based on this assumption, we extracted query-level vector and proposed a dataset partition method based on k-means++, which is used to optimize the ListNet method and RankNet method. Experimental results show that our assumption is right and our method plays a very important role in improving the performance of ListNet and RankNet, and which is also easy to be extended to other learning to rank methods.","2161-4393;21614393","Electronic:978-1-4799-1960-4; POD:978-1-4799-1961-1","10.1109/IJCNN.2015.7280529","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280529","","Information retrieval;Nickel","learning (artificial intelligence);query processing;vectors","ListNet method;RankNet method;dataset partition method;information retrieval;k-means++ method;learning to rank;query-level vector extraction;sample partition method","","","","25","","","12-17 July 2015","","IEEE","IEEE Conference Publications"
"I-vector based language modeling for query representation","K. Y. Chen; H. M. Wang; B. Chen; H. H. Chen","Institute of Information Science, Academia Sinica, Taipei, Taiwan","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","5211","5215","Since more and more multimedia data associated with spoken documents have been made available to the public, spoken document retrieval (SDR) has become an important research subject in the past two decades. Following the research tendency, many efforts have been devoted towards developing indexing and modeling techniques for representing spoken documents, but only few have been made on improving query formulation for better representing users' information needs. The i-vector based language modeling (IVLM) framework, stemming from the state-of-the-art i-vector framework for language identification and speaker recognition, has been proposed and formulated to represent documents in SDR with good promise recently. However, a major challenge of using IVLM for query modeling is that a query usually consists of only a few words; thus, it is hard to learn a reliable representation accordingly. In this paper, we focus our attention on query reformulation and propose three novel methods on top of IVLM to more accurately represent users' information needs. In addition, we also explore the use of multi-levels of index features, including word- and subword-level units, to work in concert with the proposed methods. A series of empirical SDR experiments conducted on the TDT-2 (Topic Detection and Tracking) collection demonstrate the good effectiveness of our proposed methods as compared to existing state-of-the-art methods.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178965","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178965","Spoken document retrieval;i-vector;language modeling;query representation","Analytical models;Indexes;Information retrieval;Maximum likelihood estimation;Semantics;Speaker recognition;Speech recognition","data structures;document handling;indexing;multimedia computing;query processing;speaker recognition;vectors","IVLM framework;SDR;TDT-2 collection;i-vector based language modeling framework;indexing technique;language identification;multimedia data;query formulation improvement;query representation;speaker recognition;spoken document representation;spoken document retrieval;subword-level units;topic detection-and-tracking collection;word-level units","","0","","37","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Relevance feedback versus web search document clustering","M. Alam; K. Sadaf","Dept. of Computer Science, JMI, New Delhi, INDIA","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","1665","1669","The performance of an IR system is deteriorated by factors including short and vague queries put up by the users, ever increasing volume of documents on the web, users not knowing their exact information need etc. Relevance feedback (RF) and web search document clustering are techniques to improve the performance of an Information Retrieval (IR) system. Relevance feedback provides a method to get more relevant search result from an IR system using documents that are marked relevant by the user as a feedback to reformulate query. This refined query is then used to retrieve the documents. In document clustering approach, the search result is divided into thematic groups where documents of one group are similar to each other and dissimilar to the documents of other groups. This paper presents a report on the effectiveness of relevance feedback technique as compared to document clustering in context of web information retrieval and why document clustering is the most preferred approach.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100530","Document Clustering;IR;Relevance Feedback;web search","Engines;Information retrieval","Internet;document handling;pattern clustering;query formulation;query processing;relevance feedback","IR system;Web documents;Web information retrieval;Web search document clustering approach;information need;query reformulation;relevance feedback technique","","0","","17","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Inverted Index Compression Using Multi-codes","D. Sun; X. Wang","Coll. of Inf. Sci. & Technol., Bohai Univ., Jinzhou, China","2014 Seventh International Symposium on Computational Intelligence and Design","20150409","2014","2","","96","99","How to decrease the space consumed by index is a key issue in big data processing. In this paper, a new compression method is proposed to decrease the space consumption of inverted index. First, a lot of redundant integers are removed by using the techniques of splitting inverted list, adding tags and making groups. Second, the total number of small integers is increased by using d-gaps in each group. Third, these sub sequences are compressed using different codes. At last, all compressed sub sequences are combined into a long sequence. Experiment results show that our method decreases the compression ratio and its decoding speed is also fast.","","Electronic:978-1-4799-7005-6; POD:978-1-4799-7006-3","10.1109/ISCID.2014.81","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081946","big data;index compression;integer coding;inverted index;text retrieval","Big data;Conferences;Decoding;Encoding;Indexes;Information retrieval","Big Data;data compression;encoding;information retrieval","big data processing;compression ratio;d-gaps;data compression method;decoding speed;inverted index compression;multicodes;redundant integers;space consumption","","0","","14","","","13-14 Dec. 2014","","IEEE","IEEE Conference Publications"
"Fundamental frequency estimation for monophonical Turkish music by using VMD","B. Ö. Şimşek; A. Akan; B. Bozkurt","Elektronik M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, &#x0130;stanbul K&#x00FC;lt&#x00FC;r &#x00DC;niversitesi, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1022","1025","In this study, a new method is presented for the fundamental frequency estimation of Turkish makam music recordings by using Variational Mode Decomposition (VMD). VMD is a method to decompose an input signal into an ensemble of sub-signals (modes) which is entirely non-recursive and determines the relevant bands adaptively and estimates the corresponding modes concurrently. In order to decompose a given signal optimally, actuated by the narrow-band properties corresponding to the Intrinsic Mode Function (IMF) definition used in Emprical Mode Decomposition (EMD), and we seek an ensemble of modes. Simulation results on fundamental frequency estimation of real music and synthetic test data show better performance compared to other common decomposition methods for music signals such as spectrogram, YIN, MELODIA and EMD based methods.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130006","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130006","Turkish maqam music;Variational Mode Decomposition;monophonic music;pitch frequency","Adaptation models;Conferences;Frequency estimation;Multiple signal classification;Music information retrieval;Time-frequency analysis","music;signal processing;variational techniques","EMD based methods;IMF definition;MELODIA;Turkish makam music recordings;VMD;YIN;empirical mode decomposition;fundamental frequency estimation;intrinsic mode function;monophonical Turkish music;music signals;narrow-band properties;real music;spectrogram;subsignals;synthetic test data;variational mode decomposition","","0","","16","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Graph connectivity for unsupervised Word Sense Disambiguation for HINDI language","L. Nandanwar","Department of Computer Technology, Yeshwantrao Chavan College of Engineering Nagpur, India","2015 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS)","20150813","2015","","","1","4","Word Sense Disambiguation (WSD) aims to identify the correct sense of a word in a given sentence. WSD is considered to be an open and AI-hard problem in Natural Language Processing (NLP). WSD is most important in many applications like Machine Translation (MT), Information Retrieval (IR), Information Extraction (IE), Text mining, and Lexicography etc. Supervised, Semi-supervised and Unsupervised Approaches to WSD are important and successful learning approaches. In this paper, we proposed the graph-based Unsupervised Word Sense Disambiguation Algorithm to resolve the ambiguity of a word in a given HINDI Language sentence. Finding the proper meaning of a word here implies identification of the most important node from the set of graph nodes which are representing the senses. We make use of HINDI wordnet developed at IIT Bombay as reference library of words to form the sense graph.","","Electronic:978-1-4799-6818-3; POD:978-1-4799-6819-0","10.1109/ICIIECS.2015.7193083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7193083","Graph Based Approach;HINDI Language;HINDI wordnet;Natural Language Processing (NLP);Unsupervised Approach;Word Sense Disambiguation (WSD)","Communication systems;Conferences;Context;Information retrieval;Libraries;Natural language processing;Technological innovation","graph theory;natural language processing","AI-hard problem;HINDI Language sentence;HINDI language;HINDI wordnet;IE;IR;MT;NLP;WSD;graph connectivity;information extraction;information retrieval;lexicography;machine translation;natural language processing;semisupervised approach;text mining;unsupervised approach;unsupervised word sense disambiguation algorithm","","1","","16","","","19-20 March 2015","","IEEE","IEEE Conference Publications"
"Big Text Visual Analytics in Sensemaking","L. Bradel; N. Wycoff; L. House; C. North","Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA","2015 Big Data Visual Analytics (BDVA)","20151102","2015","","","1","8","Learning from text data often involves a loop of tasks that iterate between foraging for information and synthesizing it in incremental hypotheses. Past research has shown the advantages of using spatial workspaces as a means for synthesizing information through externalizing hypotheses and creating spatial schemas. However, spatializing the entirety of datasets becomes prohibitive as the number of documents available to the analysts grows, particularly when only a small subset are relevant to the tasks at hand. To address this issue, we applied the multi-model semantic interaction (MSI) technique, which leverages user interactions to aid in the display layout (as was seen in previous semantic interaction work), forage for new, relevant documents as implied by the interactions, and place them in context of the user's existing spatial layout. Thus, this approach cleanly embeds visual analytics of big text collections directly into the human sensemaking process.","","Electronic:978-1-4673-7343-2; POD:978-1-4673-7344-9","10.1109/BDVA.2015.7314287","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314287","","Context;Encoding;IEEE Xplore;Information retrieval;Layout;Semantics;Visualization","Big Data;data visualisation;human computer interaction;learning (artificial intelligence);text analysis","MSI technique;big text collection;big text visual analytics;human sensemaking process;learning;multimodel semantic interaction technique","","","","55","","","22-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Performance evaluation of a distributed video storage system","A. Bonhomme; L. Prylli","","Proceedings 16th International Parallel and Distributed Processing Symposium","20150827","2002","","","10 pp","","","","POD:0-7695-1573-8","10.1109/IPDPS.2002.1016509","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1016509","","Costs;Databases;Design optimization;File systems;Information retrieval;Memory;Personal communication networks;Scalability;Streaming media;TV","","","","2","3","14","","","15-19 April 2001","","IEEE","IEEE Conference Publications"
"A Literature Survey on Various Approaches of Word Sense Disambiguation","G. Chandra; S. K. Dwivedi","Comput. Sci. Dept., Central Univ., Lucknow, India","2014 2nd International Symposium on Computational and Business Intelligence","20150611","2014","","","106","109","Word Sense Disambiguation (WSD) is the process of selecting the correct sense for a word in a context. WSD has become a growing research area in the field of Natural Language Processing (NLP). Over the decades, lot of studies had been carried out to suggest different approaches for WSD process. A break-through in this field would have a significant impact on many relevant web-based applications, such as information retrieval (IR), information extraction etc. This paper describes various approaches of WSD like knowledge based approach, supervised approach, unsupervised approach and semi-supervised approach. It also describes various applications of WSD like information retrieval (IR), machine translation (MT), speech recognition, computational advertising, text processing, classification of documents and biometrics.","","Electronic:978-1-4799-7552-5; POD:978-1-4799-7553-2","10.1109/ISCBI.2014.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119544","Knowledge based approach;supervised approach;unsupervised approach and semi supervised approach","Computational linguistics;Context;Information retrieval;Knowledge based systems;Semantics;Training;Training data","Internet;information retrieval;knowledge based systems;language translation;natural language processing;pattern classification;speech recognition;text analysis;unsupervised learning","WSD process;biometrics;computational advertising;document classification;information extraction;information retrieval;knowledge based approach;machine translation;natural language processing;semisupervised approach;speech recognition;supervised approach;text processing;unsupervised approach;web-based applications;word sense disambiguation","","0","","38","","","7-8 Dec. 2014","","IEEE","IEEE Conference Publications"
"Inferencing in information extraction: Techniques and applications","D. Barbosa; H. Wang; C. Yu","University of Alberta, Edmonton, Canada","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1534","1537","Information extraction at Web scale has become one of the most important research topics in data management since major commercial search engines started incorporating knowledge in their search results a couple of years ago [1]. Users increasingly expect structured knowledge as answers to their search needs. Using Bing as an example, the result page for “Lionel Messi” is full of structured knowledge facts, such as his birthday and awards. The research efforts towards improving the accuracy and coverage of such knowledge bases have led to significant advances in Information Extraction techniques [2], [3]. As the initial challenge of accurately extracting facts for popular entities are being addressed, more difficult challenges have emerged such as extending knowledge coverage to long tail entities and domains, understanding interestingness and usefulness of facts within a given context, and addressing information-seeking needs more directly and accurately. In this tutorial, we will survey the recent research efforts and provide an introduction to the techniques that address those challenges, and the applications that benefit from the adoption of those techniques. In particular, this tutorial will focus on a variety of techniques that can be broadly viewed as knowledge inferencing, i.e., combining multiple data sources and extraction techniques to verify existing knowledge and derive new knowledge. More specifically, we focus on four main categories of inferencing techniques: 1) deep natural language processing using machine learning techniques, 2) data cleaning using integrity constraints, 3) large-scale probabilistic reasoning, and 4) leveraging human expertise for domain knowledge extraction.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113420","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113420","","Cleaning;Data mining;Google;Information retrieval;Knowledge based systems;Knowledge engineering;Tutorials","Internet;data integrity;inference mechanisms;information retrieval;learning (artificial intelligence);natural language processing;search engines","Bing;Lionel Messi;Web scale;commercial search engines;data cleaning;data management;deep natural language processing;domain knowledge extraction;fact extraction;human expertise leverage;information extraction techniques;information-seeking needs;integrity constraints;knowledge coverage;knowledge inferencing;large-scale probabilistic reasoning;machine learning techniques;multiple data sources","","1","","25","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Automating the translation of assertions using natural language processing techniques","M. Soeken; C. B. Harris; N. Abdessaied; I. G. Harris; R. Drechsler","Department of Mathematics and Computer Science, University of Bremen, Germany","Proceedings of the 2014 Forum on Specification and Design Languages (FDL)","20150611","2014","978-2-9530504-9-3","","1","8","In order to verify natural language assertions from a specification automatically, they need to be translated into formal representations. This process is error-prone and can lead to a product that does not meet the initial intentions.We automate this process by first partitioning all assertions into subsets based on sentence similarity and then providing a translation template for each subset which must be completed by the designer. Since many assertions are described by similar sentences, the number of manual translation steps can be decreased significantly. We evaluated our approach by translating English constraint sentences from an industrial specification into SystemVerilog assertions.","1636-9874;16369874","Electronic:978-2-9530504-9-3; POD:978-1-4799-4349-4; USB:979-10-92279-04-7","10.1109/FDL.2014.7119356","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119356","Design automation;Natural language processing","Data mining;Databases;Information retrieval;Natural language processing;Pragmatics;Robustness","natural language processing;program interpreters","English constraint sentences;SystemVerilog assertions;assertion translation;formal representation;industrial specification;natural language processing techniques;translation template","","2","","17","","","14-16 Oct. 2014","","IEEE","IEEE Conference Publications"
"Class-Specific Feature Selection With Local Geometric Structure and Discriminative Information Based on Sparse Similar Samples","X. Chen; Y. Gu","Dept. of Inf. Eng., Harbin Inst. of Technol., Harbin, China","IEEE Geoscience and Remote Sensing Letters","20150324","2015","12","7","1392","1396","It is necessary while quite challenging to select features strongly relevant to a thematic class, i.e., class-specific features, from very high resolution (VHR) remote sensing images. To meet this challenge, a class-specific feature selection method based on sparse similar samples (CFS4) is proposed. Specifically, CFS4 incorporates the local geometrical structure and discriminative information of the data into a sparsity regularization problem. The experimental results on VHR satellite images well validate the effectiveness and practicability of the proposed method.","1545-598X;1545598X","","10.1109/LGRS.2015.2402205","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060695","Class-based features;object-oriented image analysis;remote sensing;supervised feature selection","Accuracy;Computational modeling;Feature extraction;Information retrieval;Object oriented modeling;Remote sensing;Support vector machines","artificial satellites;feature selection;geophysical image processing;image resolution;remote sensing","CFS4;VHR remote sensing images;VHR satellite image;class specific feature selection method based on sparse similar sample;discriminative information;geometrical structure;sparsity regularization problem;very high resolution","","2","","18","","20150313","July 2015","","IEEE","IEEE Journals & Magazines"
"Invoice Content table analysis with feature fusion","U. S. Unal; E. Unver; T. Karakaya; Y. S. Akgul","Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Gebze Teknik &#x00DC;niversitesi, Kocaeli, 41400, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","2298","2301","Invoice processing and financial information extraction have been popular topics among researchers for decades. Corporations like participation banks process invoices manually. Extraction of important information from invoices like product, price, amount etc. is a prerequisite for these banks. In this paper we propose a novel technique for processing invoice image tables automatically. Invoice images we process are mostly sent by customers as scanned or fax images which have low image quality. In order to process these invoices we run different methods several times with different parameters. Results from each method are fused to get candidate tables. The proposed methods are robust to the character set used in a document, the image resolution and the noise ratio of the document image, and can perform detection operations in a highly effective manner. In addition to success in low quality images, this method can be applied both on tables with and without borders. The quantitative results obtained by applying this method on real business invoices have very favorable results.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130337","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130337","invoice processing;table analysis;table detection","Facsimile;Image quality;Information retrieval;Probabilistic logic;Robustness;Text analysis","character recognition;document image processing;feature extraction;financial data processing;image fusion;image resolution;invoicing","business invoices;character set;corporations;document image;fax images;feature fusion;financial information extraction;image quality;image resolution;invoice content table analysis;invoice image tables;invoice processing;noise ratio;scanned images","","0","","9","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"An optimization approach for invoice image analysis","E. Aslan; T. Karakaya; E. Unver; Y. S. Akgul","GIT Vision Lab, Bilgisayar M&#x00FC;hendisli&#x011F;i B&#x00F6;l&#x00FC;m&#x00FC;, Gebze Teknik &#x00DC;niversitesi, Kocaeli, 41400, T&#x00FC;rkiye","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","1130","1133","Automated invoice processing and information extraction has attracted remarkable interest from business and academic circles. Invoice processing is a very critical and costly operation for participation banks because credit authorization process must be linked with real trade activity via invoices. Therefore this paper proposes a new invoice parsing method that uses a two-phase optimization structure and eliminates invoice classes. The first phase uses individual invoice part detectors such as SVM, maximum entropy and HOG to produce candidates for the various types of invoice parts. At the second phase, the basic idea is to parse an invoice by parts arranged in a deformable composition. This system can handle any type of invoice because PBM is an optimization based method. The proposed system is tested with real invoices and found to be promising for real world employment.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130034","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130034","image processing;optimization;part based modeling","Cognition;Feature extraction;Finance;Image analysis;Information retrieval;Optimization;Text analysis","authorisation;bank data processing;document image processing;image retrieval;invoicing;object detection;optimisation;support vector machines","HOG;SVM;academic circle;automated invoice processing;business circle;credit authorization process;deformable composition;information extraction;invoice class elimination;invoice image analysis;invoice parsing method;maximum entropy;optimization approach;participation banks;real trade activity;two-phase optimization structure","","0","","12","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Complementary semantic model for content-based image retrieval","K. Kumar; M. J. Hussain; J. P. Li; A. Khan; S. A. Khan; R. A. Shaikh","School of Computer Science & Engineering, UESTC, Chengdu, 611731, China","2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP)","20150402","2014","","","266","270","Multimedia technology is known as the single repository source for information retrieval that includes images, audio and video. Nowadays, it is growing with tremendous amount in the field of communication technology. Traditional text based retrieval techniques of information retrieval are inefficient at searching user's intended information from the large multimedia database. To address this problem, content based image retrieval techniques are applied for information retrieval. Content-based image retrieval has been hot topic from past two decades by many researchers' community. This topic covers many fields such as image processing, artificial intelligence, pattern recognition, and data mining and beside other related area. In this paper image retrieval techniques on the basis of color, texture and shape are explained, studies and compared. While relevance feedback technique, system accuracy, efficiency have also been discussed. Emphasize on the concept of `semantic-based image retrieval techniques' have been proposed in this paper, which is better technique to overcome the problem of `semantic gap' in the context of image retrieval.","","CD-ROM:978-1-4799-7206-7; Electronic:978-1-4799-7208-1; POD:978-1-4799-7209-8","10.1109/ICCWAMTIP.2014.7073405","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073405","Content-Based Image Retrieval;Semantic Gap;Semantic-Based Image Retrieval","Feature extraction;Image color analysis;Image retrieval;Information retrieval;Semantics;Shape;Visualization","content-based retrieval;image colour analysis;image retrieval;image texture;relevance feedback","artificial intelligence;communication technology;complementary semantic model;content-based image retrieval;data mining;image color;image processing;image shape;image texture;information retrieval;multimedia database;multimedia technology;pattern recognition;relevance feedback technique;semantic gap problem;semantic-based image retrieval technique;text based retrieval technique","","3","","22","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Compensating for asynchronies between musical voices in score-performance alignment","S. Wang; S. Ewert; S. Dixon","Queen Mary University of London, UK","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","589","593","The goal of score-performance synchronisation is to align a given musical score to an audio recording of a performance of the same piece. A major challenge in computing such alignments is to account for musical parameters including the local tempo or playing style. To increase the overall robustness, current methods assume that notes occurring simultaneously in the score are played concurrently in a performance. Musical voices such as the melody, however, are often played asynchronously to other voices, which can lead to significant local alignment errors. In this paper, we present a novel method that handles asynchronies between the melody and the accompaniment by treating the voices as separate time lines in a multi-dimensional variant of dynamic time warping (DTW). Constraining the alignment with information obtained via classical DTW, our method measurably improves the alignment accuracy for pieces with asynchronous voices and preserves the accuracy otherwise.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178037","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178037","asynchrony;melody lead;multi-dimensional dynamic time warping;score-audio alignment","Accuracy;Acoustics;Hidden Markov models;Music information retrieval;Robustness;Synchronization;Tensile stress","audio signal processing","DTW;audio recording;dynamic time warping;musical parameters;musical score;musical voices;score-performance alignment;score-performance synchronisation","","1","","29","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Semantic search using a similarity graph","L. Stanchev","Computer Science Department, Indiana University - Purdue University Fort Wayne, USA","Proceedings of the 2015 IEEE 9th International Conference on Semantic Computing (IEEE ICSC 2015)","20150302","2015","","","93","100","Given a set of documents and an input query that is expressed in a natural language, the problem of document search is retrieving the most relevant documents. Unlike most existing systems that perform document search based on keywords matching, we propose a search method that considers the meaning of the words in the query and the document. As a result, our algorithm can return documents that have no words in common with the input query as long as the documents are relevant. For example, a document that contains the words “Ford”, “Chrysler” and “General Motors” multiple times is surely relevant for the query “car” even if the word “car” does not appear in the document. Our semantic search algorithm is based on a similarity graph that contains the degree of semantic similarity between terms, where a term can be a word or a phrase. We experimentally validate our algorithm on the Cranfield benchmark that contains 1400 documents and 225 natural language queries. The benchmark also contains the relevant documents for every query as determined by human judgment. We show that our semantic search algorithm produces a higher value for the mean average precision (MAP) score than a keywords matching algorithm. This shows that our approach can improve the quality of the result because the meaning of the words and phrases in the documents and the queries is taken into account.","","Electronic:978-1-4799-7935-6; POD:978-1-4799-7936-3; USB:978-1-4799-7934-9","10.1109/ICOSC.2015.7050785","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050785","","Electronic publishing;Encyclopedias;Information retrieval;OWL;Ontologies","natural language processing;query processing;semantic Web","MAP score;cranfield benchmark;document search;infonnation retrieval system;keyword matching algorithm;mean average precision score;natural language queries;semantic search algorithm;semantic similarity degree;similarity graph","","0","","47","","","7-9 Feb. 2015","","IEEE","IEEE Conference Publications"
"Multi agent architecture for unification of association rule mining","I. Qureshi; M. A. Shaik; G. R. Murthy","CSE Department, Guru Nanak Institute of Technology, Ibrahimpatnam, Hyderabad, Telangana, India","2015 International Conference on Soft-Computing and Networks Security (ICSNS)","20151008","2015","","","1","4","Although information extraction, data mining and unification may appear all together in many applications, their implemented interfaces in the majority of the existing systems would be preferred by most of the researchers to be described as serialized integration rather than as tightly coupled integration. The main aim of this paper is to present an agent system that performs unification of data mining results in any type of distributed agent platform.","","Electronic:978-1-4799-1753-2; POD:978-1-4799-1754-9","10.1109/ICSNS.2015.7292374","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7292374","Agent;Data mining;Knowledge;Unification","Association rules;Communication networks;Information retrieval;Knowledge discovery;Protocols;Security","data mining;multi-agent systems;software architecture","association rule mining;data mining;distributed agent platform;information extraction;multiagent architecture;tightly coupled integration","","","","7","","","25-27 Feb. 2015","","IEEE","IEEE Conference Publications"
"The automatic summarization of text documents in the Cognitive Integrated Management Information System","M. Hernes; M. Maleszka; N. T. Nguyen; A. Bytniewski","Wroc&#x0142;aw University of Economics, ul. Komandorska 118/120, 53-345, Poland","2015 Federated Conference on Computer Science and Information Systems (FedCSIS)","20151109","2015","","","1387","1396","This paper presents issues related to a process of the automatic summarization of the text documents connected with economic knowledge performed by the cognitive agents in an integrated management information system. In contemporary companies, the unstructured knowledge is essential, mainly due to the possibility of obtaining better flexibility and competitiveness of the organization. Therefore more often the decision are taken in the enterprises on the basis of the summaries. The first part of the paper shortly presents the state-of-the-art in the considered field; next, the summarization process in the Cognitive Integrated Management Information System is characterized; the case study related with the summaries generating agent is presented in the last part of this paper.","","Electronic:978-8-3608-1065-1; POD:978-1-4799-6747-6; USB:978-8-3608-1067-5","10.15439/2015F188","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321610","","Computer architecture;Databases;Economics;Information retrieval;Management information systems;Semantics;Text analysis","management information systems;text analysis","automatic text document summarization process;cognitive agents;cognitive integrated management information system;economic knowledge;unstructured knowledge","","","","50","","","13-16 Sept. 2015","","IEEE","IEEE Conference Publications"
"Content factors segmentation with CBIR in real world","R. A. Shaikh; S. Deep; J. P. Li; M. H. Memon; A. Khan; K. Kumar","School of Computer Science & Engineering, UESTC, Chengdu, 611731, China","2014 11th International Computer Conference on Wavelet Actiev Media Technology and Information Processing(ICCWAMTIP)","20150402","2014","","","297","300","World dynamic situation are full of random changes which include multiple factors like audio, video and image. So cause of concurrent incident and simultaneously device performance requirement become typical for information retrieval. That make segmentation approach a method of combining feature transformation with clustering algorithm which is proposed for adequate retrieval of image, that could take input approach equally as similar platform and after function performance of analyses and processing that methodology make image, audio, video information separate and retrieve them as much clear as possible then give a best clear resultant as per certainty.","","CD-ROM:978-1-4799-7206-7; Electronic:978-1-4799-7208-1; POD:978-1-4799-7209-8","10.1109/ICCWAMTIP.2014.7073412","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073412","CBIR;Dynamic Texture;Feature Extraction;Image Segmentation","Computer science;Computer vision;Heuristic algorithms;Hidden Markov models;Image segmentation;Information retrieval;Visualization","content-based retrieval;feature extraction;image retrieval;image segmentation","CBIR;clustering algorithm;content factors segmentation;content-based image retrieval;feature transformation","","0","","21","","","19-21 Dec. 2014","","IEEE","IEEE Conference Publications"
"Information extraction methods for text documents in a Cognitive Integrated Management Information System","M. Hernes","Department of Economic Informatics, Wroc&#x0142;aw University of Economics, Poland","2015 IEEE 2nd International Conference on Cybernetics (CYBCONF)","20150806","2015","","","287","292","In contemporary companies unstructured knowledge is essential, mainly due to the possibility to obtain better flexibility and competitiveness of the organization. For example, on the basis of automatic analysis of the experts' opinions, the decision-makers are capable of taking decisions (for example decisions concerning investments). This paper presents issues related to developing and evaluating a methods of information extraction performed by cognitive agent running in integrated management information system. The main advantages of this approach are cognitive agents' ability of including a context of extracted information and its ability of automatic decision-making on the basis of extracted information.","","Electronic:978-1-4799-8322-3; POD:978-1-4799-8323-0","10.1109/CYBConf.2015.7175948","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175948","cognitive agents;information extraction;integrated management information systems","Context;Data mining;Gold;Information retrieval;Investment;Semantics;Sensitivity","data mining;management information systems;organisational aspects;text analysis","automatic analysis;automatic decision-making;cognitive agent ability;cognitive integrated management information system;expert opinions;information extraction methods;organization competitiveness;organization flexibility;text documents;unstructured knowledge","","1","","27","","","24-26 June 2015","","IEEE","IEEE Conference Publications"
"A feature selection method based on minimum redundancy maximum relevance for learning to rank","M. B. Shirzad; M. R. Keyvanpour","Department of Computer Engineering Islamic Azad University, Qazvin Branch Qazvin, Iran","2015 AI & Robotics (IRANOPEN)","20150921","2015","","","1","5","Learning to rank has considered as a promising approach for ranking in information retrieval. In recent years feature selection for learning to rank introduced as a crucial issue. Reducing the feature set by removing irrelevant and redundant features can improve the prediction performance. In this paper we address the problem of filter feature selection for ranking. We propose to apply minimum redundancy maximum relevance (mRMR) method that select feature subset based on importance of features and similarity between them. We reweight the component of mRMR to balance between importance and similarity. We apply two methods for measuring the similarity between features and two methods for evaluating importance. Experimental results on two standard datasets from Letor demonstrate that the proposed algorithm 1)outperform two stateof- the-art learning to rank algorithms in term of accuracy, 2) learn a more spars model compared to a feature selection model for ranking.","","Electronic:978-1-4799-8733-7; POD:978-1-4799-8734-4","10.1109/RIOS.2015.7270735","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270735","Learning to rank;feature selection;mRMR;sparsity","Accuracy;Boosting;Correlation coefficient;Feature extraction;Filtering algorithms;Information retrieval;Optimization","feature selection;information filtering;learning (artificial intelligence)","feature importance;feature set reduction;feature similarity;feature subset selection;filter feature selection;information retrieval;irrelevant feature removal;learning;minimum redundancy maximum relevance;ranking;redundant feature removal","","1","","16","","","12-12 April 2015","","IEEE","IEEE Conference Publications"
"Extracting Various Classes of Data From Biological Text Using the Concept of Existence Dependency","K. Taha","Electrical and Computer Engineering, Department, Khalifa University, Abu Dhabi, United Arab Emirates","IEEE Journal of Biomedical and Health Informatics","20151103","2015","19","6","1918","1928","One of the key goals of biological natural language processing (NLP) is the automatic information extraction from biomedical publications. Most current constituency and dependency parsers overlook the semantic relationships between the constituents comprising a sentence and may not be well suited for capturing complex long-distance dependences. We propose in this paper a hybrid constituency-dependency parser for biological NLP information extraction called EDCC. EDCC aims at enhancing the state of the art of biological text mining by applying novel linguistic computational techniques that overcome the limitations of current constituency and dependency parsers outlined earlier, as follows: 1) it determines the semantic relationship between each pair of constituents in a sentence using novel semantic rules; and 2) it applies a semantic relationship extraction model that extracts information from different structural forms of constituents in sentences. EDCC can be used to extract different types of data from biological texts for purposes such as protein function prediction, genetic network construction, and protein-protein interaction detection. We evaluated the quality of EDCC by comparing it experimentally with six systems. Results showed marked improvement.","2168-2194;21682194","","10.1109/JBHI.2015.2392786","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014223","Text mining;biological NLP;biomedical literature;dependency parsers;information extraction","Information retrieval;Natural language processing;Semantics;Text mining","","","","3","","40","","20150119","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Codes for distributed PIR with low storage overhead","A. Fazeli; A. Vardy; E. Yaakobi","University of California San Diego, La Jolla, 92093, USA","2015 IEEE International Symposium on Information Theory (ISIT)","20151001","2015","","","2852","2856","Private information retrieval (PIR) protocols allow a user to retrieve a data item from a database without revealing any information about the identity of the item being retrieved. Specifically, in information-theoretic k-server PIR, the database is replicated among k non-communicating servers, and each server learns nothing about the item retrieved by the user. The cost of PIR protocols is usually measured in terms of their communication complexity, which is the total number of bits exchanged between the user and the servers. However, another important cost parameter is the storage overhead, which is the ratio between the total number of bits stored on all the servers and the number of bits in the database. Since single-server information-theoretic PIR is impossible, the storage overhead of all existing PIR protocols is at least 2 (or k, in the case of k-server PIR). In this work, we show that information-theoretic PIR can be achieved with storage overhead arbitrarily close to the optimal value of 1, without sacrificing the communication complexity. Specifically, we prove that all known k-server PIR protocols can be efficiently emulated, while preserving both privacy and communication complexity but significantly reducing the storage overhead. To this end, we distribute the n bits of the database among s + r servers, each storing n/s coded bits (rather than replicas). Notably, our coding scheme remains the same, regardless of the specific k-server PIR protocol being emulated. For every fixed k, the resulting storage overhead (s +r)/s approaches 1 as s grows; explicitly we have equation. Moreover, in the special case k = 2, the storage overhead is only 1 + 1/s. In order to achieve these results, we introduce and study a new kind of binary linear codes, called here k-server PIR codes. Finally, we show how such codes can be constructed from multidimensional cubic, from Steiner systems, and from one-step majority-logic decodable codes.","2157-8095;21578095","Electronic:978-1-4673-7704-1; POD:978-1-4673-7705-8; USB:978-1-4673-7703-4","10.1109/ISIT.2015.7282977","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7282977","","Complexity theory;Databases;Information retrieval;Linear codes;Privacy;Protocols;Servers","binary codes;communication complexity;information retrieval;linear codes;protocols","Steiner system;binary linear code;communication complexity;distributed information-theoretic k-server PIR protocol;multidimensional cubic;private information retrieval protocol;storage overhead reduction","","1","","22","","","14-19 June 2015","","IEEE","IEEE Conference Publications"
"Mining Enterprise Models for Knowledgeable Decision Making","S. Roychoudhury; V. Kulkarni; N. Bellarykar","Tata Consultancy Services, Tata Res. Dev. & Design Center, India","2015 IEEE/ACM 4th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering","20150730","2015","","","1","6","Knowledge is stored in an enterprise in various forms ranging from unstructured operational data, legal documents to structured information like programs, as well as relational data stored in databases to semi-structured information stored in xml files. All these information if viewed from a holistic standpoint can help an enterprise to understand and reflect upon itself and thereby make knowledgeable decisions whenever required. In order to satisfy this objective of holistic knowledge representation and decision making, we begin with mining unstructured information present in an enterprise. In particular, in this paper, we intend to mine a document intensive business processes and extract information as a knowledge repository that captures the various stakeholders along with their intentions and the tasks they perform. The goal is to automate the validation of such business processes by eliminating any manual verification, which is time consuming and error prone. We believe this is the first step towards realizing our broader objective of collective modeling of enterprise knowledge that will involve mining of information available in unstructured, structured, relational as well as semi-structured form present in an enterprise.","","Electronic:978-1-4673-7064-6; POD:978-1-4673-7065-3","10.1109/RAISE.2015.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7168324","Knowledge representation;decision making;enterprise modeling;information extraction;semantic matching","Data mining;Data models;Decision making;Hidden Markov models;Information retrieval;Kernel","XML;business data processing;data mining;database management systems;decision making;knowledge representation","XML files;collective modeling;document intensive business processes;enterprise knowledge;information extraction;knowledge repository;knowledge representation;knowledgeable decision making;knowledgeable decisions;legal documents;mining enterprise models;relational data;semistructured information;unstructured operational data","","0","","12","","","17-17 May 2015","","IEEE","IEEE Conference Publications"
"Novel audio features for capturing tempo salience in music recordings","B. Thoshkahna; M. Müller; V. Kulkarni; N. Jiang","Fraunhofer Institute for Integrated Circuits IIS, Erlangen, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","181","185","In music compositions, certain parts may be played in an improvisational style with a rather vague notion of tempo, while other parts are characterized by having a clearly perceivable tempo. Based on this observation, we introduce in this paper some novel audio features for capturing tempo-related information. Rather than measuring the specific tempo of a local section of a given recording, our objective is to capture the existence or absence of a notion of tempo, a kind of tempo salience. By a quantitative analysis within an Indian music scenario, we demonstrate that our audio features capture the aspect of tempo salience well, while being independent of continuous fluctuations and local changes in tempo.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7177956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177956","Analysis;Audio;Classification;Music;Salience;Segmentation;Tempo","Data mining;Frequency modulation;Indexes;Multiple signal classification;Music information retrieval;Rhythm","acoustic signal processing;musical acoustics","Indian music scenario;capturing tempo salience;music recordings;novel audio features;tempo salience;tempro-related information","","1","","23","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Recovering transitive traceability links among software artifacts","K. Nishikawa; H. Washizaki; Y. Fukazawa; K. Oshima; R. Mibe","Dept. Computer Science, Waseda University, Tokyo, Japan","2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)","20151123","2015","","","576","580","Although many methods have been suggested to automatically recover traceability links in software development, they do not cover all link combinations (e.g., links between the source code and test cases) because specific documents or artifact features (e.g., log documents and structures of source code) are used. In this paper, we propose a method called the Connecting Links Method (CLM) to recover transitive traceability links between two artifacts using a third artifact. Because CLM uses a different artifact as a document, it can be applied to kinds of various data. Basically, CLM recovers traceability links using the Vector Space Model (VSM) in Information Retrieval (IR) methods. For example, by connecting links between A and B and between B and C, CLM retrieves the link between A and C transitively. In this way, CLM can recover transitive traceability links when a suggested method cannot. Here we demonstrate that CLM can effectively recover links that VSM is hard using Open Source Software.","","Electronic:978-1-4673-7532-0; USB:978-1-4673-7531-3","10.1109/ICSM.2015.7332517","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332517","connecting links;traceability link recovery;transitive traceability links","Computer science;Indexes;Information retrieval;Joining processes;Open source software;Yttrium","information retrieval;software engineering","CLM;IR method;VSM;connecting links method;information retrieval method;software artifacts;software development;transitive traceability link recovery;vector space model","","","","26","","","Sept. 29 2015-Oct. 1 2015","","IEEE","IEEE Conference Publications"
"Identifying semantic and syntactic relations from text documents","Chien Ta DC; Tuoi Phan Thi","Faculty of Computer Science and Engineering, HoChiMinh City University of Technology, Vietnam","The 2015 IEEE RIVF International Conference on Computing & Communication Technologies - Research, Innovation, and Vision for Future (RIVF)","20150226","2015","","","127","131","Semantic and syntactic relations play an important role of applications in recent years, especially on Semantic Web, Information Retrieval, Information Extraction, and Question Answering. Semantic and syntactic relations content main ideas in the sentences or paragraphs. This paper presents our proposed algorithms for identifying semantic and syntactic relations between objects and their properties in order to enrich a domain specific ontology, namely Computing Domain Ontology, which is used in Information extraction system. We combine the methodologies of Natural Language Processing with Machine Learning in these proposed algorithms in order to extract the explicit and implicit relations. We exploit these relations from distinct resources, such as WordNet, Wikipedia and text documents of ACM Digital Libraries. We also use Natural Language Processing tools, such as OpenNLP, Stanford Lexical Dependency Parser in order to analyze and parse sentences. A random sample among 245 categories of ACM Categories is used to evaluate. Results generated show that our proposed approach achieves high precision.","","Electronic:978-1-4799-8044-4; POD:978-1-4799-8045-1","10.1109/RIVF.2015.7049887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7049887","Domain ontology;Information Extraction;Semantic relation","Data mining;Information retrieval;Libraries;Natural language processing;Ontologies;Semantics;Syntactics","Web sites;digital libraries;grammars;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);question answering (information retrieval);semantic Web;text analysis","ACM digital library;OpenNLP;Stanford lexical dependency parser;Wikipedia;WordNet;computing domain ontology;domain specific ontology;information extraction system;information retrieval;machine learning;natural language processing;question answering;semantic Web;semantic relation;syntactic relation;text document","","0","","15","","","25-28 Jan. 2015","","IEEE","IEEE Conference Publications"
"Retrieving Diverse Opinions from App Reviews","E. Guzman; O. Aly; B. Bruegge","Tech. Univ. Munchen, Garching, Germany","2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","20151109","2015","","","1","10","Context: Users can have conflicting opinions and different experiences when using software and user reviews serve as a channel in which users can document their opinions and experiences. To develop and evolve software that is usable and relevant for a diverse group of users, different opinions and experiences need to be taken into account. Goal: In this paper we present DIVERSE, a feature and sentiment centric retrieval approach which automatically provides developers with a diverse sample of user reviews that is representative of the different opinions and experiences mentioned in the whole set of reviews. Results: We evaluated the diversity retrieval performance of our approach on reviews from seven apps from two different app stores. We compared the reviews retrieved by DIVERSE with a feature-based retrieval approach and found that on average DIVERSE outperforms the baseline approach. Additionally, a controlled experiment revealed that DIVERSE can help develop- ers save time when analyzing user reviews and was considered useful for detecting conflicting opinions and software evolution. Conclusions: DIVERSE can therefore help developers collect a comprehensive set of reviews and aid in the detection of conflicting opinions.","1949-3770;19493770","Electronic:978-1-4673-7899-4; POD:978-1-4673-7900-7","10.1109/ESEM.2015.7321214","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321214","","Feature extraction;Google;Greedy algorithms;Information retrieval;Measurement;Sentiment analysis;Software","information retrieval;software engineering","App reviews;diverse opinion retrieval;sentiment centric retrieval approach;software development;software evolution","","","","28","","","22-23 Oct. 2015","","IEEE","IEEE Conference Publications"
"Automatic identification Genre of audiovisual documents","M. Fourati; A. Jedidi; F. Gargouri","Laboratory MIR@CL University of Sfax, Tunis, Tunisia","2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)","20150402","2014","","","466","469","Identifying the Genre of an audiovisual document is among the major challenges for multimedia retrieval. Indeed, the lack of semantic metadata extraction makes these resources underused in the retrieval process. To overcome these difficulties, the extraction of semantic descriptions requires an analysis of the audiovisual document's content. The automation of the process of describing audiovisual documents is essential because of the richness and the diversity of the available analytical criteria. In this paper, we present a method that allows the identification of a semantic and automatic description from the content such as genre. We chose to describe the cinematic audiovisual documents based on the documentation prepared in the pre-production phase of films, namely synopsis. The experimental result on Imdb (Internet Movie Database) and the Wikipedia encyclopedia indicate that our method of genre detection is better than the result of these corpuses.","2161-5322;21615322","Electronic:978-1-4799-7100-8; POD:978-1-4799-7101-5","10.1109/AICCSA.2014.7073235","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073235","Audiovisual documents;Genre;Identification;Semantic","Databases;Feature extraction;Information retrieval;Motion pictures;Multimedia communication;Pragmatics;Semantics","audio signal processing;document handling;information retrieval;multimedia computing","Imdb;Internet Movie Database;Wikipedia encyclopedia;automatic description identification;automatic genre identification;cinematic audiovisual documents;genre detection;multimedia retrieval;semantic description extraction;semantic identification;semantic metadata extraction;synopsis","","1","","23","","","10-13 Nov. 2014","","IEEE","IEEE Conference Publications"
"Research on text similarity computing based on word vector model of neural networks","Y. Sun; W. Li; P. Dong","School of Information Engineering, Minzu University of China, Beijing, China","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","20151130","2015","","","994","997","Text similarity computing plays an important role in natural language processing. In this paper, we build a word vector model based on neural network, and train Chinese corpus from Sohu News, World News, and so on. Meanwhile, a method of calculating the text semantic similarity using word vector is proposed. Finally, through comparing with the traditional calculation method TF-IDF, the experimental results prove the method is effective.","2327-0586;23270586","CD-ROM:978-1-4799-8351-3; Electronic:978-1-4799-8353-7; POD:978-1-4799-8354-4","10.1109/ICSESS.2015.7339221","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339221","neural networks;semantic;text similarity;word vector","Buildings;Computational modeling;Information retrieval;Linear programming;Neural networks;Semantics;Training","natural language processing;neural nets;text analysis","TF-IDF;natural language processing;neural network;text semantic similarity computing;word vector model","","","","15","","","23-25 Sept. 2015","","IEEE","IEEE Conference Publications"
"Independent knowledge extraction in nature of humorous text analysis review using online text analysis tool","J. Emmanual Robin; N. Krishnamoorthy; M. Karthikeyan; A. John Felix","Department of MCA, Jayaram College of Engineering & Technology, Trichy, India","2014 International Conference on Communication and Network Technologies","20150319","2014","","","162","164","The purpose of Text Mining is to process unstructured (textual) information, extracting meaningful numeric indices from the text, and, thus, make the information contained in the text accessible to the various data mining (statistical and machine learning) algorithms. Information can be extracted to derive summaries for the words contained in the documents or to compute summaries for the documents based on the words contained in them. Hence, we can analyze words, clusters of words used in documents, etc., or we can analyze documents and determine similarities between them or how they are related to other variables of interest in the data mining project. This topic that might be integrated with massive files of very disparate joke clusters, bound only because someone thought that they were funny or someone had an interesting thing for light-bulb jokes. Therefore, there are probably tons of doubles and triples and what you have in this collection, and there's just not enough time in the day to sort them, manually. This paper is going to analyze the different variation and analysis of funny or humorous words using data mining techniques.","","DVD:978-1-4799-6264-8; Electronic:978-1-4799-6266-2; POD:978-1-4799-6267-9","10.1109/CNT.2014.7062746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062746","Humorous;Text mining;analysis;data mining;funny","Abstracts;Association rules;Correlation;Databases;Information retrieval;Text analysis","data mining;information retrieval;learning (artificial intelligence);text analysis","data mining;documents;funny words;humorous text analysis review;humorous words;information extraction;joke clusters;knowledge extraction;light-bulb jokes;machine learning algorithms;numeric indices;online text analysis tool;statistical learning;text mining;unstructured textual information process;words summaries","","0","","5","","","18-19 Dec. 2014","","IEEE","IEEE Conference Publications"
"Drug-related crime information extraction and analysis","K. R. Rahem; N. Omar","Center for AI Technology, FTSM, University Kebangsaan Malaysia, UKM, 43000 Bangi Selangor, Malaysia","Proceedings of the 6th International Conference on Information Technology and Multimedia","20150326","2014","","","250","254","Although valuable crime information is available in human-readable form in online newspapers and electronic archives, software systems that can extract and present relevant information are limited and are of significant interest to researchers in the field of information extraction. This work aims to extract available drug crime information from online newspaper articles. This work has the following subtasks: assess where and how drug traffickers hide drugs, identify the nationalities of drug dealers, identify the types (names) of drugs, and assess the quantity and prices of drugs in the local market. This paper presents a rule-based approach to extract information on the basis of a set of drug crime gazetteers and on a set of grammatical and heuristic rules. This work is validated through experiments. Results show that the technique developed here are promising.","","Electronic:978-1-4799-5423-0; POD:978-1-4799-5424-7","10.1109/ICIMU.2014.7066639","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066639","Drug crimes;Grammatical and heuristic rules;Information extraction;Rule-based Approach","Conferences;Data mining;Drugs;Information retrieval;Information technology;Multimedia communication;Organizations","information analysis;information retrieval;publishing;social sciences computing","drug crime gazetteers;drug-related crime information;grammatical rule;heuristic rule;information analysis;information extraction;online newspaper articles;rule-based approach;software system","","1","","11","","","18-20 Nov. 2014","","IEEE","IEEE Conference Publications"
"Predicting Best Answerers for New Questions: An Approach Leveraging Distributed Representations of Words in Community Question Answering","H. Dong; J. Wang; H. Lin; B. Xu; Z. Yang","Sch. of Comput. Sci. & Technol., Dalian Univ. of Technol., Dalian, China","2015 Ninth International Conference on Frontier of Computer Science and Technology","20151102","2015","","","13","18","Community Question Answering (CQA) sites are becoming an increasingly important source of information where users can share knowledge on various topics. Although these sites provide opportunities for users to seek for help or provide answers, they also bring new challenges. One of the challenges is most new questions posted everyday cannot be routed to the appropriate users who can answer them in CQA. That is to say, experts cannot receive questions that match their expertise. Therefore new questions cannot be answered in time. In this paper, we propose an approach which based on distributed representations of words to predict the best answerer for a new question on CQA sites. Our approach considers both user activity and user authority. The user activity and user authority are based on the previous questions answered by the user. We have applied our model on the dataset downloaded from StackOverflow, one of the biggest CQA sites. The results show that our approach performs better than the TF-IDF and Language Model based methods.","2159-6301;21596301","CD-ROM:978-1-4673-9294-5; Electronic:978-1-4673-9295-2; POD:978-1-4673-9296-9","10.1109/FCST.2015.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314643","CQA;activity;authority;distributed representations of words","Computational modeling;History;Information retrieval;Knowledge discovery;Measurement;Natural language processing;Semantics","question answering (information retrieval)","CQA sites;StackOverflow;best answerer prediction;community question answering sites;distributed representations;distributed word representations;user activity;user authority","","1","","25","","","26-28 Aug. 2015","","IEEE","IEEE Conference Publications"
"A tempo-insensitive representation of rhythmic patterns","J. H. Jensen; M. G. Christensen; S. H. Jensen","Department of Electronic Systems, Aalborg University, Denmark","2009 17th European Signal Processing Conference","20150406","2009","","","1509","1512","We introduce a representation for rhythmic patterns that is insensitive to minor tempo deviations and that has well-defined behavior for larger changes in tempo. We have combined the representation with an Euclidean distance measure and compared it to other systems in a classification task of ballroom music. Compared to the other systems, the proposed representation shows much better generalization behavior when we limit the training data to songs with different tempi than the query. When both test and training data contain songs with similar tempo, the proposed representation has comparable performance to other systems.","","POD:978-161-7388-76-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077471","","Correlation;Estimation;Music information retrieval;Rhythm;Training;Vectors","acoustic signal processing;audio signal processing;music;signal classification;signal representation","Euclidean distance measure;ballroom music;classification task;rhythmic patterns;tempo deviations;tempo-insensitive representation","","0","","21","","","24-28 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Study of Various Approaches and Tools on Ontology","S. Mishra; S. Jain","Dept. of Comput. Applic., Teerthankar Mahaveer Univ., Moradabad, India","2015 IEEE International Conference on Computational Intelligence & Communication Technology","20150402","2015","","","57","61","The increasing volume and unstructured nature of data available on the World Wide Web (WWW) makes information retrieval a tedious and mechanical task. Lots of this information is not semantic driven, and hence not machine process able, but its only in human readable form. The WWW is designed to builds up a source of reference for web of meaning. Ontology information on different subjects spread globally is made available at one place. The Semantic Web (SW), moreover as an extension of WWW is designed to build as a foundation of vocabularies and effective communication of Semantics. The promising area of Semantic Web is logical and lexical semantics. Ontology plays a major role to represent information more meaningfully for humans and machines for its later effective retrieval. This paper constitutes the requisite with a unique approach for a representation and reasoning with ontology for semantic analysis of various type of document and also surveys multiple approaches for ontology learning that enables reasoning with uncertain, incomplete and contradictory information in a domain context.","","Electronic:978-1-4799-6023-1; POD:978-1-4799-6024-8","10.1109/CICT.2015.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078667","Concept Hierarchy;Concepts;Ontology;Ontology Learning;Semantic Web","Birds;Diseases;Information retrieval;OWL;Ontologies;Semantics","Web sites;inference mechanisms;information retrieval;ontologies (artificial intelligence);semantic Web;text analysis","WWW;World Wide Web;document type;information representation;information retrieval;lexical semantics;logical semantics;ontology information;ontology learning;semantic Web;semantic analysis","","1","","22","","","13-14 Feb. 2015","","IEEE","IEEE Conference Publications"
"CLOpinionMiner: Opinion Target Extraction in a Cross-Language Scenario","X. Zhou; X. Wan; J. Xiao","Institute of Computer Science and Technology, the MOE Key Laboratory of Computational Linguistics, Peking University, Beijing, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20150306","2015","23","4","619","630","Opinion target extraction is a subtask of opinion mining which is very useful in many applications. The problem has usually been solved by training a sequence labeler on manually labeled data. However, the labeled training datasets are imbalanced in different languages, and the lack of labeled corpus in a language limits the research progress on opinion target extraction in this language. In order to address the above problem, we propose a novel system called CLOpinionMiner which investigates leveraging the rich labeled data in a source language for opinion target extraction in a different target language. In this study, we focus on English-to-Chinese cross-language opinion target extraction. Based on the English dataset, our method produces two Chinese training datasets with different features. Two labeling models for Chinese opinion target extraction are trained based on Conditional Random Fields (CRF). After that, we use a monolingual co-training algorithm to improve the performance of both models by leveraging the enormous unlabeled Chinese review texts on the web. Experimental results show the effectiveness of our proposed approach.","2329-9290;23299290","","10.1109/TASLP.2015.2392381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009977","Cross-language information extraction;opinion mining;opinion target extraction","Cameras;Data mining;Data models;Feature extraction;Information retrieval;Labeling;Training","data mining;language translation;linguistics;natural language processing;random processes;text analysis","CLOpinionMiner;CRF;Chinese review texts;Chinese training datasets;English dataset;English-to-Chinese cross-language opinion target extraction;conditional random fields;cross-language scenario;labeled corpus;labeled data;labeled training datasets;labeling models;monolingual co-training algorithm;opinion mining;sequence labeler training","","1","","40","","20150114","April 2015","","IEEE","IEEE Journals & Magazines"
"An evaluation of methodologies for melodic similarity in audio recordings of Indian art music","S. Gulati; J. Serrà; X. Serra","Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","678","682","We perform a comparative evaluation of methodologies for computing similarity between short-time melodic fragments of audio recordings of Indian art music. We experiment with 560 different combinations of procedures and parameter values. These include the choices made for the sampling rate of the melody representation, pitch quantization levels, normalization techniques and distance measures. The dataset used for evaluation consists of 157 and 340 annotated melodic fragments of Carnatic and Hindustani music recordings, respectively. Our results indicate that melodic fragment similarity is particularly sensitive to distance measures and normalization techniques. Sampling rates do not have a significant impact for Hindustani music, but can significantly degrade the performance for Carnatic music. Overall, the performed evaluation provides a better understanding of the processing steps and parameter settings for melodic similarity in Indian art music. Importantly, it paves the way for developing unsupervised melodic pattern discovery approaches, whose evaluation is a challenging and, many times, ill-defined task.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7178055","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178055","Indian art music;Melodic similarity;evaluation;melodic patterns;motifs;pakads","Art;Euclidean distance;Lead;Music;Music information retrieval;Noise","audio recording;audio signal processing;feature extraction;music;quantisation (signal);signal representation","Carnatic music;Hindustani music recordings;Indian art music;audio recordings;distance measures;melodic similarity;melody representation;normalization techniques;pitch quantization levels","","2","","25","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Phase Oscillatory Network and Visual Pattern Recognition","R. Follmann; E. E. N. Macau; E. Rosa; J. R. C. Piqueira","Department of Telecommunications and Control Engineering, Polytechnic School of University of S&#227;o Paulo, S&#x00E3;o Paulo, Brazil","IEEE Transactions on Neural Networks and Learning Systems","20150616","2015","26","7","1539","1544","We explore a properly interconnected set of Kuramoto type oscillators that results in a new associative-memory network configuration, which includes second- and third-order additional terms in the Fourier expansion of the network's coupling. Investigation of the response of the network to different external stimuli indicates an increase in the network capability for coding and information retrieval. Comparison of the network output with that of an equivalent experiment with subjects, for recognizing perturbed binary patterns, shows comparable results between the two approaches. We also discuss the enhanced storage capacity of the network.","2162-237X;2162237X","","10.1109/TNNLS.2014.2345572","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879338","Associative memory;information processing;phase oscillator;synchronization","Couplings;Eigenvalues and eigenfunctions;Information retrieval;Neurons;Oscillators;Pattern recognition;Visualization","content-addressable storage;encoding;information retrieval;pattern recognition","Fourier expansion;Kuramoto type oscillators;associative-memory network configuration;coding;external stimuli;information retrieval;network coupling;perturbed binary pattern recognition;phase oscillatory network;second-order additional terms;storage capacity;third-order additional terms;visual pattern recognition","0","5","","27","","20140815","July 2015","","IEEE","IEEE Journals & Magazines"
"Adaptive and multiple interest-aware user profiles for personalized search in folksonomy: A simple but effective graph-based profiling model","K. Han; J. Park; M. Y. Yi","Department of Knowledge Service Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","225","231","The data derived from the social tagging system, known as folksonomy, is a potentially useful source for understanding users' intentions. This study seeks to uncover some of the unexplored areas of folksonomy and examine the plausibility of new ideas for the improvement of personalized search. In particular, we challenge several state-of-the-art algorithms by exploiting folksonomy network structures used in creating user profiles that are adaptive and aware of multiple interests of a user, for the personalization of search results. The results obtained from the proposed approach shows a unanimous increase in the performance of personalization when compared to other state-of-the-art algorithms.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072835","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072835","collaborative systems;folksonomy;personalized search;resource profiles;user profiles","Adaptation models;Clustering algorithms;Communities;Information retrieval;Measurement;Semantics;Vectors","graph theory;search engines;social networking (online)","adaptive multiple interest-aware profiles;folksonomy network structures;graph-based profiling model;personalized search performance improvement;social tagging system;user intentions;user interests;user profile creation","","1","","18","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"The Use of Text Retrieval and Natural Language Processing in Software Engineering","V. Arnaoudova; S. Haiduc; A. Marcus; G. Antoniol","Univ. of Texas at Dallas, Richardson, TX, USA","2015 IEEE/ACM 37th IEEE International Conference on Software Engineering","20150817","2015","2","","949","950","This technical briefing presents the state of the art Text Retrieval and Natural Language Processing techniques used in Software Engineering and discusses their applications in the field.","0270-5257;02705257","Electronic:978-1-4799-1934-5; POD:978-1-4799-1935-2","10.1109/ICSE.2015.301","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7203123","Text retrieval;natural language processing","Committees;Conferences;Information retrieval;Natural language processing;Software;Software engineering;Tutorials","information retrieval;natural language processing;software engineering;text analysis","natural language processing techniques;software engineering;text retrieval","","1","","","","","16-24 May 2015","","IEEE","IEEE Conference Publications"
"Question focus extraction and answer passage retrieval","A. Bayoudhi; L. H. Belguith; H. Ghorbel","ANLP Group, MIRACL laboratory, FSEGS, University of Sfax, B.P. 1088, 3018, Sfax, TUNISIA","2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)","20150402","2014","","","658","665","Question Analysis is an important task in Question Answering Systems (QAS). It consists generally in identifying the semantic type of the question and extracting the main focus of the question. The goal is to better specify the required information by the question. In this context and as part of a framework aiming to implement an Arabic opinion QAS for political debates, this paper addresses the problem of defining the focus of opinion questions and proposes particularly an approach for extracting the focus of attitude questions. The proposed approach is based on semi-automatically constructed lexico-syntactic patterns. Furthermore, the paper presents an adapted Vector Space Model (VSM) based method to retrieve candidate answer passages from a transcribed TV political show. Several experiments were carried out and showed that the focus extraction approach has achieved over 72% as F1 score for holder and target extraction, and has improved the baseline passage retrieval task by over than 25%.","2161-5322;21615322","Electronic:978-1-4799-7100-8; POD:978-1-4799-7101-5","10.1109/AICCSA.2014.7073262","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7073262","Question Answering Systems;answer passage retrieval;lexico-syntactic patterns;opinion question analysis;question focus extraction","Context;Information retrieval;Pattern matching;Pragmatics;Semantics;Syntactics;TV","natural language processing;politics;question answering (information retrieval)","Arabic opinion QAS;VSM based method;answer passage retrieval;opinion questions;political debates;question analysis;question answering systems;question focus extraction;question semantic type identification;semiautomatically constructed lexico-syntactic pattern;transcribed TV political show;vector space model based method","","0","","31","","","10-13 Nov. 2014","","IEEE","IEEE Conference Publications"
"Query expansion via WordNet for effective code search","Meili Lu; X. Sun; S. Wang; D. Lo; Yucong Duan","School of Information Engineering, Yangzhou University, China","2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)","20150409","2015","","","545","549","Source code search plays an important role in software maintenance. The effectiveness of source code search not only relies on the search technique, but also on the quality of the query. In practice, software systems are large, thus it is difficult for a developer to format an accurate query to express what really in her/his mind, especially when the maintainer and the original developer are not the same person. When a query performs poorly, it has to be reformulated. But the words used in a query may be different from those that have similar semantics in the source code, i.e., the synonyms, which will affect the accuracy of code search results. To address this issue, we propose an approach that extends a query with synonyms generated from WordNet. Our approach extracts natural language phrases from source code identifiers, matches expanded queries with these phrases, and sorts the search results. It allows developers to explore word usage in a piece of software, helps them quickly identify relevant program elements for investigation or quickly recognize alternative words for query reformulation. Our initial empirical study on search tasks performed on the JavaScript/ECMAScript interpreter and compiler, Rhino, shows that the synonyms used to expand the queries help recommend good alternative queries. Our approach also improves the precision and recall of Conquer, a state-of-the-art query expansion/reformulation technique, by 5% and 8% respectively.","1534-5351;15345351","Electronic:978-1-4799-8469-5; POD:978-1-4799-8470-1","10.1109/SANER.2015.7081874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081874","","Conferences;Information retrieval;Natural languages;Software engineering;Software maintenance;Software systems","Java;natural language processing;program compilers;program interpreters;public domain software;query formulation;software maintenance;source code (software)","Conquer;JavaScript-ECMAScript interpreter;Rhino;WordNet;compiler;natural language phrases;query expansion technique;query quality;query reformulation technique;search technique;software maintenance;source code identifiers;source code search","","1","","20","","","2-6 March 2015","","IEEE","IEEE Conference Publications"
"Iterative joint extraction of entities, relationships and coreferences from text sources","S. Žitnik; M. Bajec","University of Ljubljana, Faculty of computer and information science, Ve&#x010D;na pot 113, SI-1000, Slovenia","2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)","20150622","2015","","","412","422","Machine understanding of textual documents has been challenging since the early computer era. Since the information extraction research field emerged it has inferred multiple natural language processing tasks, such as named entities recognition, relationships extraction and coreference resolution. Even though for the purpose of the end-to-end information extraction all of the three tasks are crucial, existing work has been focusing merely on one specific task at the time or at best on their connection in a pipeline. In this paper we introduce a novel iterative and joint information extraction system that interconnects all the three tasks together using iterative feature functions which use the advantage of the intermediate extractions. Furthermore, we introduce a special transformation of data into skip-mention sequences to enable the extraction of relations and coreferences using fast first-order graphical models. Additionally, the system uses an ontology as its knowledge source, as a list of inferred extraction rules, and as a data schema of extracted results. Experimental results show that the accuracy of extractions improves after each iteration. In particular, our model obtained a 15% error reduction on named entity recognition over individual models.","2151-1349;21511349","Electronic:978-1-4673-6630-4; POD:978-1-4673-6631-1; USB:978-1-4673-6629-8","10.1109/RCIS.2015.7128902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7128902","","Data mining;Feature extraction;Information retrieval;Joints;Ontologies;Organizations;Training","iterative methods;natural language processing;ontologies (artificial intelligence);text analysis","coreference resolution;end-to-end information extraction;first-order graphical model;iterative feature function;iterative joint extraction;machine understanding;multiple natural language processing task;named entity recognition;ontology;relationships extraction;textual document","","0","","67","","","13-15 May 2015","","IEEE","IEEE Conference Publications"
"Unsupervised Hindi word sense disambiguation based on network agglomeration","A. Jain; D. K. Lobiyal","Ambedkar Institute of Advanced Communications Technology and Research (Jawaharlal Nehru University) Delhi, India","2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom)","20150504","2015","","","195","200","Word sense disambiguation (WSD) is an essential task in computational linguistics for language understanding applications such as information retrieval, question answering, machine translation, text summarization etc. In this paper we propose an unsupervised WSD method for a Hindi sentence based on network agglomeration. First we create the sentence graph G for the given sentence. This sentence graph collectively represents all the interpretations of the sentence. Now from this sentence graph G we create the interpretation graph G' ⊆ G for each of the interpretation of the sentence. To identify the desired interpretation we compute network agglomeration for all the interpretation graphs. Thus the relevant interpretation having highest value of network agglomeration is identified. The results on the standard sense tagged corpus show better performance for the proposed method than the previous approaches.","","Electronic:978-9-3805-4416-8; POD:978-1-4799-6832-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100244","Hindi WordNet;Network Agglomeration;Word Sense Disambiguation","Computers;Context;Information retrieval;Knowledge based systems;Knowledge discovery;Natural language processing;Standards","computational linguistics;graph theory;natural language processing","computational linguistics;interpretation graph;language understanding applications;network agglomeration;sentence graph;standard sense tagged corpus;unsupervised Hindi word sense disambiguation;unsupervised WSD method","","0","","18","","","11-13 March 2015","","IEEE","IEEE Conference Publications"
"Probabilistic graphical models for multi-source fusion from text sources","G. Levchuk; E. Blasch","Aptima Inc., 12 Gill Street, Suite 1400, Woburn, MA, USA 01801","2015 IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA)","20150820","2015","","","1","10","In this paper we present probabilistic graph fusion algorithms to support information fusion and reasoning over multi-source text media. Our methods resolve misinformation by combining knowledge similarity analysis and conflict identification with source characterization. For experimental purposes, we used the dataset of the articles about current military conflict in Eastern Ukraine. We show that automated knowledge fusion and conflict detection is feasible and high accuracy of detection can be obtained. However, to correctly classify mismatched knowledge fragments as misinformation versus additionally reported facts, the knowledge reliability and credibility must be assessed. Since the true knowledge must be reported by many reliable sources, we compute knowledge frequency and source reliability by incorporating knowledge provenance and analyzing historical consistency between the knowledge reported by the sources in our dataset.","2329-6267;23296267","CD-ROM:978-1-4673-7556-6; Electronic:978-1-4673-7557-3; POD:978-1-4673-7558-0","10.1109/CISDA.2015.7208640","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7208640","graphical fusion;information wars;knowledge graph;misinformation detection;multi-source fusion;open source exploitation;situation assessment","Data mining;Government;Information retrieval;Joints;Media;Probabilistic logic;Semantics","information dissemination;pattern classification;probability;reliability;sensor fusion","Eastern Ukraine;information fusion;knowledge credibility;knowledge fusion;knowledge reliability;knowledge similarity analysis;mismatched knowledge fragment classification;multisource fusion;multisource text media;probabilistic graph fusion algorithm;probabilistic graphical model;source characterization;source reliability","","0","","31","","","26-28 May 2015","","IEEE","IEEE Conference Publications"
"Event extraction on Indonesian news article using multiclass categorization","M. L. Khodra","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia","2015 2nd International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA)","20151123","2015","","","1","5","Event extraction identifies who did what, when, where, why, and how, which is known as 5W1H. We aim to investigate event extraction on Indonesian news articles as multiclass-categorization problem, and apply statistical learning-based approach that treats event extraction as a sequence labeling problem under BIO (Begin Inside Outside) labeling scheme. Each token of input text will be classified into one of 13 predefined classes. Our contributions are providing 5W1H corpus, and the best technique to build model of event extraction. Our experiments show that C4.5 is better than AdaboostM1 although Adaboost can identify minority labels better than C4.5. In addition, C4.5 with all features gave the best Fmeasure of 0.666.","","Electronic:978-1-4673-8143-7; POD:978-1-4673-8144-4","10.1109/ICAICTA.2015.7335365","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335365","AdaboostM1;BIO labeling;C4.5;event extraction;multiclass-categorization;sequence labeling","Decision trees;Feature extraction;Information retrieval;Labeling;Standards;Text categorization","electronic publishing;information retrieval;learning (artificial intelligence)","5W1H corpus;AdaboostM1;BIO labeling scheme;C4.5;Fmeasure;Indonesian news article;begin inside outside labeling scheme;event extraction;multiclass categorization;multiclass-categorization problem;sequence labeling problem;statistical learning-based approach;who did what-when-where-why-and how","","","","15","","","19-22 Aug. 2015","","IEEE","IEEE Conference Publications"
"Estimating double thumbnails for music recordings","N. Jiang; M. Müller","International Audio Laboratories Erlangen, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","146","150","Audio thumbnailing, which aims at finding the most representative audio segment of a music recording, is an important task in music information retrieval. In general, the notion of a thumbnail is not well-defined and several musical parts may be good thumbnail candidates. For example, for popular music, both a verse and a refrain section may serve as suitable thumbnail candidates. Instead of considering only one thumbnail, we consider in this paper the problem of finding the two most representative segments that correspond to different musical parts. We denote these two segments as double thumbnails. As our main technical contributions, we propose two approaches for computing double thumbnails, both extending a previously introduced repetition-based thumbnailing procedure. In the first approach, which is straightforward, we simply apply the original thumbnailing procedure two times in an iterative fashion. In the second approach, we introduce a novel method for jointly estimating the two thumbnails within one optimization procedure. Finally, we report on experimental results demonstrating the performances of the two double thumbnailing procedures and indicate directions towards full music structure analysis.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7177949","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177949","Music;Repetition;Segmentation;Structure;Thumbnailing","Acoustics;Audio recording;Estimation;Iterative methods;Joints;Music information retrieval;Optimization","audio recording;audio signal processing;information retrieval;iterative methods;optimisation;signal representation","audio segment;audio thumbnailing;double thumbnails;full music structure analysis;music information retrieval;music recording;musical parts;optimization procedure;refrain section;repetition-based thumbnailing procedure;representative segments;thumbnail candidates;verse","","0","","22","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Centralized student learning platform","G. Eichler; C. Erfurth; K. H. Lüke","Internet & Services Telekom Innovation Laboratories Darmstadt, Germany","2015 15th International Conference on Innovations for Community Services (I4CS)","20151012","2015","","","1","7","How does a future centralized learning platform for students in an academic environment look like? What are the needs and requirements for current and potential academic users? Are Facebook, WhatsApp and Dropbox the winners? Which recommendations can be worked out for a suitable IT landscape and how does an integrated data security concept look like? This paper analyses the needs and requirements for a centralized learning platform from a students' point of view.","","Electronic:978-1-4673-7328-9; POD:978-1-4673-7329-6","10.1109/I4CS.2015.7294487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294487","academic needs and technical requiements;data security;learning management system;learning platform;tool and system classification","Authentication;Business;Information retrieval;Learning management systems;Least squares approximations;Springs","computer aided instruction;information technology;security of data;social networking (online);student experiments","Dropbox;Facebook;IT landscape;WhatsApp;academic environment;academic users;centralized student learning platform;data security","","","","10","","","8-10 July 2015","","IEEE","IEEE Conference Publications"
"Is Learning-to-Rank Cost-Effective in Recommending Relevant Files for Bug Localization?","F. Zhao; Y. Tang; Y. Yang; H. Lu; Y. Zhou; B. Xu","State Key Lab. for Novel Software Technol., Nanjing Univ., Nanjing, China","2015 IEEE International Conference on Software Quality, Reliability and Security","20150924","2015","","","298","303","Software bug localization aiming to determine the locations needed to be fixed for a bug report is one of the most tedious and effort consuming activities in software debugging. Learning-to-rank (LR) is the state-of-the-art approach proposed by Ye et al. to recommending relevant files for bug localization. Ye et al.'s experimental results show that the LR approach significantly outperforms previous bug localization approaches in terms of ""precision"" and ""accuracy"". However, this evaluation does not take into account the influence of the size of the recommended files on the efficiency in detecting bugs. In practice, developers will generally spend more code inspection effort to detect bugs if larger files are recommended. In this paper, we use six large-scale open-source Java projects to evaluate the LR approach in the context of effort-aware bug localization. Our results, surprisingly, show that, when taking into account the code inspection effort to detect bugs, the LR approach is similar to or even worse than the standard VSM (Vector Space Model), a naïve IR-based bug localization approach.","","Electronic:978-1-4673-7989-2; POD:978-1-4673-7990-8","10.1109/QRS.2015.49","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272945","bug localization;bug reports;effort-aware;empirical study;learning-to-rank","Computer bugs;Context;Information retrieval;Inspection;Measurement;Software;Standards","Java;information retrieval;learning (artificial intelligence);program debugging;public domain software;vectors","IR-based bug localization approach;VSM;information retrieval;learning-to-rank;open-source Java projects;recommended files;software bug localization;software debugging;vector space model","","","","19","","","3-5 Aug. 2015","","IEEE","IEEE Conference Publications"
"Never-ending ontology extension through machine reading","P. H. Barchi; E. Rafael Hruschka","Computer Science Department, Federal University of S&#x00E3;o Carlos, DC/UFSCar, S&#x00E3;o Carlos - S&#x00E3;o Paulo, Brazil","2014 14th International Conference on Hybrid Intelligent Systems","20150416","2014","","","266","272","NELL (Never Ending Language Learning system) is the first system to practice the Never-Ending Machine Learning paradigm techniques. It has an inactive component to continually extend its KB: OntExt. Its main idea is to identify and add to the KB new relations which are frequently asserted in huge text data. Co-occurrence matrices are used to structure the normalized values of co-occurrence between the contexts for each category pair to identify those context patterns. The clustering of each matrix is done with Weka K-means algorithm: from each cluster, a new possible relation. This work present newOntExt: a new approach with new features to turn the ontology extension task feasible to NELL. This approach has also an alternative task of naming new relations found by another NELL component: Prophet. The relations are classified as valid or invalid by humans; the precision is calculated for each experiment and the results are compared to those relative to OntExt. Initial results show that ontology extension with newOntExt can help Never-Ending Learning systems to expand its volume of beliefs and to keep learning with high precision by acting in auto-supervision and auto-reflection.","","Electronic:978-1-4799-7633-1; POD:978-1-4799-7634-8","10.1109/HIS.2014.7086210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7086210","knowledge aquisition;machine learning;machine reading;ontology extension","Arthritis;Context;Data mining;Information retrieval;Integrated circuits;Knowledge based systems;Ontologies","belief maintenance;learning (artificial intelligence);matrix algebra;ontologies (artificial intelligence);pattern clustering;text analysis","NELL;Never Ending Language Learning system;Prophet;Weka K-means algorithm;autoreflection;autosupervision;belief expansion;context pattern;cooccurrence matrices;machine reading;matrix clustering;never-ending machine learning paradigm technique;never-ending ontology extension;newOntExt;ontology extension task;relation classification;relation naming;text data","","0","","13","","","14-16 Dec. 2014","","IEEE","IEEE Conference Publications"
"Generating Rules with Common Knowledge: A Framework for Sentence Information Extraction","D. Rao; Y. Zhu; Z. Jiang; G. Zhao","Sch. of Comput., Guangdong Univ. of Technol., Guangzhou, China","2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics","20151123","2015","2","","373","376","There are many nature language processing applications. A typical example is information extraction whose target is a sentence. Various rules are often used in this kind of applications. However, automated processing is not accurate enough in some cases. This is because it is easy to construct syntax rules of a sentence but difficult to semantic rules. On the other hand, the knowledge representation community paid much attention to common knowledge. It is insightful to use rules based on this sense on common things in nature language processing. Therefore, we propose an approach to combine the common knowledge and the nature language processing rules. It first applied the name entity reorganization technology and then generated rules based on a specific common knowledge database. As a result, this approach can be a framework for many (but not all) nature language processing applications. In our experimental example, this approach performed well.","","Electronic:978-1-4799-8646-0; POD:978-1-4799-8647-7","10.1109/IHMSC.2015.113","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7334991","common knowledge;nature language processing;rule reasoning","Computers;Context;Data mining;Information retrieval;Semantics;Standards;Syntactics","computational linguistics;knowledge representation;natural language processing","knowledge database;knowledge representation community;name entity reorganization technology;nature language processing rule;semantic rule;sentence information extraction;syntax rules","","","","15","","","26-27 Aug. 2015","","IEEE","IEEE Conference Publications"
"Exploring threats and vulnerabilities in hacker web: Forums, IRC and carding shops","V. Benjamin; W. Li; T. Holt; H. Chen","Department of Management Information Systems, The University of Arizona, Tucson, AZ 85721","2015 IEEE International Conference on Intelligence and Security Informatics (ISI)","20150727","2015","","","85","90","Cybersecurity is a problem of growing relevance that impacts all facets of society. As a result, many researchers have become interested in studying cybercriminals and online hacker communities in order to develop more effective cyber defenses. In particular, analysis of hacker community contents may reveal existing and emerging threats that pose great risk to individuals, businesses, and government. Thus, we are interested in developing an automated methodology for identifying tangible and verifiable evidence of potential threats within hacker forums, IRC channels, and carding shops. To identify threats, we couple machine learning methodology with information retrieval techniques. Our approach allows us to distill potential threats from the entirety of collected hacker contents. We present several examples of identified threats found through our analysis techniques. Results suggest that hacker communities can be analyzed to aid in cyber threat detection, thus providing promising direction for future work.","","CD-ROM:978-1-4799-9888-3; Electronic:978-1-4799-9889-0; POD:978-1-4799-9890-6","10.1109/ISI.2015.7165944","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7165944","Carding shops;Cyber security;Hacker IRC;Hacker forums;Threats;Vulnerabilities","Communities;Computer crime;Computer hacking;Credit cards;Information retrieval;Servers","Web sites;computer crime;information retrieval;learning (artificial intelligence)","IRC channels;carding shops;cyber defenses;cyber threat detection;cybercriminals;cybersecurity;hacker Web;hacker forums;information retrieval techniques;machine learning methodology;online hacker communities;threat identification;vulnerabilities","","7","","12","","","27-29 May 2015","","IEEE","IEEE Conference Publications"
"Usage of databases and the information literacy of students of the Faculty of Electrical Engineering and Computing","N. Jelača","University of Zagreb, Faculty of Electrical Engineering and Computing / Central Library, Unska 3, 10000, Croatia","2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)","20150716","2015","","","974","978","Given the area of their research, the students of the Faculty of Electrical Engineering and Computing (FER) need the latest scientific information from both domestic and foreign journals. That is why the Croatian Ministry of Science, Education and Sports has provided them with the access to various databases of scientific and technical journals. Furthermore, the Faculty of Electrical Engineering and Computing is a provider of one of the most important databases for engineers - IEEE Explore. Students can access these databases either from their homes or from the Faculty premises; they can also attend seminars on information retrieval. The goal of this article is presenting the research on students of the Faculty of Electrical Engineering and Computing, their usage of available databases and their familiarity with the search tools for those databases.","","DVD:978-9-5323-3085-4; Electronic:978-9-5323-3082-3; POD:978-1-4799-8174-8","10.1109/MIPRO.2015.7160416","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160416","","Databases;Electrical engineering;Google;IEEE Xplore;Information retrieval;Libraries;Seminars","electrical engineering computing;electrical engineering education;information retrieval;information science education","FER;Faculty of Electrical Engineering and Computing;IEEE Explore;databases;information literacy;information retrieval;scientific information","","0","","16","","","25-29 May 2015","","IEEE","IEEE Conference Publications"
"Technology Research of Tibetan Hot Topics Extraction","G. Xu; L. Qiu","Sch. of Inf. Eng., Minzu Univ. of China, Beijing, China","2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops","20150430","2015","","","204","208","With the increase of a large numbers of Tibetan information, Tibetan text processing has become popular and important. Tibetan hot topics extraction has become one of the Tibetan information analysis tools. This paper describes a method of the hot topics extraction from Tibetan text. First, construction of the dataset is described. Second, Tibetan word segmentation is presented. Third, the feature selection and the text representation are conducted. The classical TFIDF is used to calculate the weights of features. At last, statistical-based method is utilized to extract the hot topics. The experiment shows it can extract the topics effectively and the results can reflect the characteristics of hot topic category. It is helpful and meaningful for text classification, information retrieval as well as construction of high-quality corpus.","","Electronic:978-1-4799-1775-4; POD:978-1-4799-1776-1","10.1109/WAINA.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096173","TFIDF weighting calculation;feature selection;hot topic extraction;tibetan information processing","Feature extraction;Information processing;Information retrieval;Monitoring;Text categorization;XML","feature selection;information retrieval;linguistics;natural language processing;pattern classification;statistical analysis;text analysis;word processing","TFIDF;Tibetan hot topic extraction;Tibetan information analysis tools;Tibetan text processing;Tibetan word segmentation;feature selection;high-quality corpus;information retrieval;statistical-based method;text classification;text representation","","0","","16","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Extracting the features of similarity in short texts","T. Kışla; S. K. Metin; B. Karaoğlan","Bilgisayar ve Ogretim Teknolojileri Egitimi Bolumu, Ege Univ., I&#x0307;zmir, Turkey","2015 23nd Signal Processing and Communications Applications Conference (SIU)","20150622","2015","","","180","183","Automatic identification of text similarity has found applications in information retrieval, text summarization, assessment of machine translation, assessment of question answering, word sense disambiguation and many more. In this work, the results of discrimant analysis applied to find out the cumulative effect of the attributes used in the literature so far (ratio of common words, text lentgths, common word sequences, synonyms, hypernyms, hyponyms) in detecting word similarity are reported.","2165-0608;21650608","Electronic:978-1-4673-7386-9; POD:978-1-4673-7387-6","10.1109/SIU.2015.7130443","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130443","discrimant analysis;paraphrase corpus;text similarity","Computational linguistics;Databases;Feature extraction;Information retrieval;Knowledge discovery;Presses;Semantics","feature extraction;text analysis","attributes cumulative effect;automatic identification;common word sequences;discrimant analysis;features extraction;hypernyms;hyponyms;information retrieval;machine translation assessment;question answering assessment;short texts similarity;synonyms;text lengths;text summarization;word sense disambiguation","","0","","31","","","16-19 May 2015","","IEEE","IEEE Conference Publications"
"Semi-automatic Generation of Extended Finite State Machines from Natural Language Standard Documents","J. G. Greghi; E. Martins; A. M. B. R. Carvalho","Comput. Sci. Dept., Univ. of Lavras, Lavras, Brazil","2015 IEEE International Conference on Dependable Systems and Networks Workshops","20150921","2015","","","45","50","Many requirement documents are written in natural language and, therefore, may contain problems such as inconsistencies and ambiguities. To minimize these problems, there is a trend in Software Engineering to use models to represent systems. These models are obtained from textual requirements. However, manual modelling is a complex task and, in order to do it semi-automatically, one has to deal with problems such as the kind of model to be generated, the automation degree to be achieved, and the quality of the document that must be processed. We propose a methodology to semi-automatically generate Extended Finite State Machines (EFSMs) from natural language standard documents. We used Natural Language Processing (NLP) techniques and tools to extract information from the document, and implemented a prototype which generates EFSMs. The generated EFSMs were validated with a model checking tool, and manually evaluated by comparing them with the manually generated models.","2325-6648;23256648","Electronic:978-1-4673-8044-7; POD:978-1-4673-8045-4","10.1109/DSN-W.2015.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7272551","Aerospace Domain;Extended Finite State Machines;Model Generation;Natural Language Processing","Analytical models;Automata;Data mining;Information retrieval;Natural languages;Standards;Unified modeling language","document handling;finite state machines;formal specification;natural language processing","EFSM;NLP techniques;NLP tools;extended finite state machines;information extraction;model checking tool;natural language processing;natural language standard documents;semiautomatic generation;software engineering;textual requirements","","1","","25","","","22-25 June 2015","","IEEE","IEEE Conference Publications"
"Computing text similarity using Tree Edit Distance","G. Sidorov; H. Gómez-Adorno; I. Markov; D. Pinto; N. Loya","Center for Computing Research (CIC), Instituto Polit&#x00E9;cnico Nacional (IPN), Mexico City, Mexico","2015 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS) held jointly with 2015 5th World Conference on Soft Computing (WConSC)","20151001","2015","","","1","4","In this paper, we propose the application of the Tree Edit Distance (TED) for calculation of similarity between syntactic n-grams for further detection of soft similarity between texts. The computation of text similarity is the basic task for many natural language processing problems, and it is an open research field. Syntactic n-grams are text features for Vector Space Model construction extracted from dependency trees. Soft similarity is application of Vector Space Model taking into account similarity of features. First, we discuss the advantages of the application of the TED to syntactic n-grams. Then, we present a procedure based on the TED and syntactic n-grams for calculating soft similarity between texts.","","Electronic:978-1-4673-7248-0; POD:978-1-4673-7249-7; USB:978-1-4673-7247-3","10.1109/NAFIPS-WConSC.2015.7284129","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7284129","","Computational modeling;Cost function;Heuristic algorithms;Information retrieval;Natural language processing;Semantics;Syntactics","natural language processing;text analysis;trees (mathematics)","TED;dependency trees;natural language processing;soft text similarity;syntactic n-grams;tree edit distance;vector space model construction","","1","","14","","","17-19 Aug. 2015","","IEEE","IEEE Conference Publications"
"A multi-level system for sequential update summarization","Chunyun Zhang; Zhanyu Ma; Jiayue Zhang; Weiran Xu; Jun Guo","School of Computer Science and Technology, Shandong University of Finance and Economics, Jinan, China","2015 11th International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QSHINE)","20151123","2015","","","144","148","When an emergency occurs, such as the outbreak of natural disaster, the news about the incident showed a trend of blowout. Mostly, these news are reproduced by people and spread out with duplicate, unimportant or wrong information. Hence, it is necessary and vital to provide individuals with timely and important information of these incidents during their development. In this paper, we present a new multi-level system which can broadcasts with useful, new, and timely sentence-length updates about a developing event. The new system proposed a novel method, which incorporates techniques from topic-level and sentence-level summarization. To evaluate the performance of the proposed system, we applied it to the task of sequential update summarization of Temporal Summarization (TS) track at Text Retrieval Conference (TREC). Experimental results showed that our proposed method have a good performance.","","Electronic:978-1-6319-0063-1; POD:978-1-4799-8217-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332558","","Accidents;Computer crashes;Data mining;Earthquakes;Hurricanes;Information retrieval;Measurement","information resources;information retrieval;text analysis","TREC;multilevel system;natural disaster;performance evaluation;sentence-level summarization;sequential update summarization;temporal summarization;text retrieval conference;timely sentence-length updates;topic-level summarization","","","","28","","","19-20 Aug. 2015","","IEEE","IEEE Conference Publications"
"selP: Selective tracking and presentation of data provenance","D. Deutch; A. Gilad; Y. Moskovitch","Computer Science Department, Tel Aviv University, Israel","2015 IEEE 31st International Conference on Data Engineering","20150601","2015","","","1484","1487","Highly expressive declarative languages, such as Datalog, are now commonly used to model the operational logic of data-intensive applications. The typical complexity of such Datalog programs, and the large volume of data that they process, call for the tracking and presentation of data provenance. Provenance information is crucial for explaining and justifying the Datalog program results. However, the size of full provenance information is in many cases too large (and its concise representations are too complex) to allow its presentation to the user. To this end, we propose a demonstration of selP, a system that allows the selective presentation of provenance, based on user-specified top-k queries. We will demonstrate the usefulness of selP using a real-life program and data, in the context of Information Extraction.","1063-6382;10636382","Electronic:978-1-4799-7964-6; POD:978-1-4799-7965-3; USB:978-1-4799-7963-9","10.1109/ICDE.2015.7113407","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7113407","","Complexity theory;Context;Data mining;Databases;Information retrieval;Knowledge based systems;Pattern matching","DATALOG;query processing","Datalog programs;data processing;data volume;data-intensive applications;information extraction;operational logic;provenance information;real-life program;selP;selective data provenance presentation;selective data provenance tracking;user-specified top-k queries","","1","","12","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Structural segmentation of Hindustani concert audio with posterior features","P. Verma; V. T. P.; P. Pandit; P. Rao","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai 400076, India","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20150806","2015","","","136","140","Structural segmentation of music involves identifying boundaries between homogenous regions where the homogeneity involves one or more musical dimensions, and therefore depends on the musical genre. In this work, we address the segmentation of Hindustani instrumental concert recordings at the highest time-scale, that is, concert sections marked by prominent changes in rhythmic structure. Tempo features are effectively combined with energy and chroma features motivated by musicological knowledge and acoustic observations. Posterior probability features from unsupervised model fitting of the frame-level acoustic features are shown to significantly improve robustness to local acoustic variations. Finally, two diverse change detection criteria are combined to obtain a superior segmentation system.","1520-6149;15206149","Electronic:978-1-4673-6997-8; POD:978-1-4673-6998-5; USB:978-1-4673-6996-1","10.1109/ICASSP.2015.7177947","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177947","music segmentation;posterior features;structural segmentation","Feature extraction;Instruments;Music information retrieval;Noise measurement;Rhythm","music;probability;unsupervised learning","Hindustani concert audio;Hindustani instrumental concert recordings;acoustic observations;frame-level acoustic features;homogenous regions;musicological knowledge;posterior features;posterior probability features;structural segmentation;tempo features;unsupervised model fitting","","1","","17","","","19-24 April 2015","","IEEE","IEEE Conference Publications"
"Estimation of size and shape of citrus fruits using image processing for automatic grading","S. M. Iqbal; A. Gopal; P. E. Sankaranarayanan; A. B. Nair","CSIR-CEERI Chennai Centre, CSIR Madras Complex, Taramani, 600113, India","2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN)","20150827","2015","","","1","8","Size is one of the important parameters in grading of fruits. Also quantifying the fruit's shape gives value addition to the fruits. This paper describes analytical methods to estimate the size and shape of citrus fruits to grade them based on single view fruit images. Sweet-lime and orange fruits are taken for case study of size and shape determination respectively. The size of the sweet-lime fruits were estimated and graded into three categories using simple methods like radius signature method, area method and perimeter method. Also the existing method based on Light Detection and Ranging (LIDAR) sensor for citrus fruits size determination was improved through a method employing image processing. The shapes of the orange fruits were estimated using Heuristic Shape separator method and shape numbers were obtained for varying shaped orange fruits. The results were found to be reasonably in good agreement with the human assessment.","","CD-ROM:978-1-4673-6822-3; Electronic:978-1-4673-6823-0; POD:978-1-4673-6824-7","10.1109/ICSCN.2015.7219859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219859","LIDAR;grading;image processing;machine vision;shape;single view;size","Harmonic analysis;Information retrieval;Irrigation;Laser radar;Manuals;Shape measurement","agricultural products;estimation theory;optical radar;radar imaging;remote sensing by radar","LIDAR sensor;area method;automatic grading;citrus fruits size determination;fruit shape;heuristic shape separator method;human assessment;image processing;light detection and ranging;orange fruits;perimeter method;radius signature method;shape determination;single view fruit images;sweet-lime fruits","","0","","16","","","26-28 March 2015","","IEEE","IEEE Conference Publications"
"Improving the Search Mechanism for Unstructured Peer-to-Peer Networks Using the Statistical Matrix Form","C. H. Lin; J. J. Zseng; S. Y. Hsieh","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Access","20150706","2015","3","","926","941","In a traditional file search mechanism, such as flooding, a peer broadcasts a query to its neighbors through an unstructured peer-to-peer (P2P) network until the time-to-live decreases to zero. A major disadvantage of flooding is that, in a large-scale network, this blind-choice strategy usually incurs an enormous traffic overhead. In this paper, we propose a method, called the statistical matrix form (SMF), which improves the flooding mechanism by selecting neighbors according to their capabilities. The SMF measures the following peer characteristics: (1) the number of shared files; (2) the content quality; (3) the query service; and (4) the transmission distance between neighbors. Based on these measurements, appropriate peers can be selected, thereby reducing the traffic overhead significantly. Our experimental results demonstrate that the SMF is effective and efficient. For example, compared with the flooding search mechanism in dynamic unstructured P2P networks, the SMF reduces the traffic overhead by more than 80%. Moreover, it achieves a good success rate and shorter response times.","2169-3536;21693536","","10.1109/ACCESS.2015.2444872","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122855","Unstructured peer-to-peer networks;flooding search mechanism;statistical matrix form;traffic overhead","IP networks;Information retrieval;Network topology;Peer-to-peer computing;Query processing;Radio frequency;Search methods","matrix algebra;peer-to-peer computing;query processing;statistical analysis;telecommunication traffic","SMF measures;blind-choice strategy;content quality;dynamic unstructured P2P networks;file search mechanism;flooding mechanism improvement;flooding search mechanism;large-scale network;peer characteristics;peer selection;query broadcasting;query service;search mechanism improvement;statistical matrix form;traffic overhead;transmission distance;unstructured peer-to-peer networks","","1","","75","","20150612","2015","","IEEE","IEEE Journals & Magazines"
"Exploring Technical Phrase Frames from Research Paper Titles","Y. Win; T. Masada","Grad. Sch. of Eng., Nagasaki Univ., Nagasaki, Japan","2015 IEEE 29th International Conference on Advanced Information Networking and Applications Workshops","20150430","2015","","","558","563","This paper proposes a method for exploring technical phrase frames by extracting word n-grams that match our information needs and interests from research paper titles. Technical phrase frames, the outcome of our method, are phrases with wildcards that may be substituted for any technical term. Our method, first of all, extracts word trigrams from research paper titles and constructs a co-occurrence graph of the trigrams. Even by simply applying Page Rank algorithm to the co-occurrence graph, we obtain the trigrams that can be regarded as technical key phrases at the higher ranks in terms of Page Rank score. In contrast, our method assigns weights to the edges of the co-occurrence graph based on Jaccard similarity between trigrams and then apply weighted Page Rank algorithm. Consequently, we obtain widely different but more interesting results. While the top-ranked trigrams obtained by unweighted Page Rank have just a self-contained meaning, those obtained by our method are technical phrase frames, i.e., A word sequence that forms a complete technical phrase only after putting a technical word (or words) before or/and after it. We claim that our method is a useful tool for discovering important phrase logical patterns, which can expand query keywords for improving information retrieval performance and can also work as candidate phrasings in technical writing to make our research papers attractive.","","Electronic:978-1-4799-1775-4; POD:978-1-4799-1776-1","10.1109/WAINA.2015.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7096236","Jaccard similarity;PageRank;keyphrase extraction;phrase frames;word n-grams","Algorithm design and analysis;Data mining;Feature extraction;Information retrieval;Natural language processing;Pragmatics;Probability","graph theory;query processing","Jaccard similarity;Page Rank algorithm;cooccurrence graph;information retrieval;query keywords;research paper titles;technical phrase frames;trigrams;word n-grams extraction;word sequence","","0","","14","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Korean paraphrase evaluation using morphological analysis","S. W. Moon; H. Choi; G. Gweon","Dep. Of Knowledge Service Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Rep. Of Korea","2015 17th International Conference on Advanced Communication Technology (ICACT)","20150827","2015","","","201","204","Paraphrase evaluation is used to determine whether two input sentences share a same meaning. The automatic analysis for paraphrase evaluation technology has a potential use in the area of information retrieval technology since correctly paraphrased sentences can be used as alternative input sentence in the retrieval process. In this paper, we suggest an evaluation method that is suitable for the Korean language by using morphological analysis. Using our method, we present preliminary results on how our automatic evaluation scores compare to the human evaluation scores.","1738-9445;17389445","CD-ROM:978-8-9968-6504-9; Electronic:978-8-9968-6505-6; POD:978-1-4673-8116-1","10.1109/ICACT.2015.7224784","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224784","Morphological analysis;Paraphrase evaluation","Computational linguistics;Correlation;Information retrieval;Knowledge engineering;Manuals;Natural language processing;Syntactics","information analysis;natural language processing","Korean paraphrase evaluation;automatic evaluation scores;human evaluation scores;information retrieval technology;morphological analysis;paraphrase evaluation technology;sentence meaning","","0","","14","","","1-3 July 2015","","IEEE","IEEE Conference Publications"
"Real-Time Piano Music Transcription Based on Computer Vision","M. Akbari; H. Cheng","Department of Mathematics and Computer Science, University of Lethbridge, Lethbridge, Canada","IEEE Transactions on Multimedia","20151113","2015","17","12","2113","2121","One important problem in musical information retrieval is automatic music transcription, which is an automated conversion process from played music to a symbolic notation such as MIDI file. Since the accuracy of previous audio-based transcription systems is not satisfactory, we propose an innovative computer vision-based automatic music transcription system named claVision to perform piano music transcription. Instead of processing the music audio, the system performs the transcription only from the video performance captured by a camera mounted over the piano keyboard. In this paper, we describe the architecture and the algorithms used in claVision. The claVision system has a high accuracy ( F1 score over 0.95) and a very low latency (about 7.0 ms) in real-time music transcription, even under different illumination conditions. This technology can also be used for other musical keyboard instruments.","1520-9210;15209210","","10.1109/TMM.2015.2473702","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7225173","Automatic music transcription;claVision;computer vision;multipitch estimation;piano","Accuracy;Algorithm design and analysis;Cameras;Computer vision;Keyboards;Music;Music information retrieval;Real-time systems","audio signal processing;computer vision;information retrieval;music;real-time systems;video signal processing","MIDI file;audio-based transcription systems;automatic music transcription;computer vision;musical information retrieval;real-time piano music transcription;video performance","","0","","31","","20150826","Dec. 2015","","IEEE","IEEE Journals & Magazines"
"An automated stock recommendation system from stock investment research using domain specific information extraction","T. Tapjinda; P. Vechpanich; N. Leelasupakul; N. Prompoon; C. Patanothai","Dept. of Comput. Eng., Chulalongkorn Univ., Bangkok, Thailand","2015 12th International Joint Conference on Computer Science and Software Engineering (JCSSE)","20150827","2015","","","30","35","The rise of internet web-based application and smart phone ease access to the stock market, attracting newcomer investors. Most investors have made their decision based on information from stock investment researches published by the brokers. An automated stock recommendation system from stock investment research is introduced in this paper. The system collects several investment researches from multiple broker sites daily, converts the researches from pdf to text file, and extracts stock recommendation from the text and saves them to the database. A web application were also developed to serve the user as an interface to access those extracted information. The developed system is capable of extracting 79% of recommendations with the precision of 85%. The web application function also meets the expected both functional requirements.","","Electronic:978-1-4799-1966-6; POD:978-1-4799-1967-3","10.1109/JCSSE.2015.7219765","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7219765","Information extraction;SET;stock","Accuracy;Containers;Data mining;Databases;Information retrieval;Investment;Servers","Internet;investment;mobile computing;recommender systems;stock markets","Internet Web-based application;automated stock recommendation system;domain specific information extraction;smart phone;stock investment research;stock market","","0","","","","","22-24 July 2015","","IEEE","IEEE Conference Publications"
"Navigating Information Overload Caused by Automated Testing - a Clustering Approach in Multi-Branch Development","N. Erman; V. Tufvesson; M. Borg; P. Runeson; A. Ardo","Qlik, Lund, Sweden","2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)","20150507","2015","","","1","9","Background. Test automation is a widely used technique to increase the efficiency of software testing. However, executing more test cases increases the effort required to analyze test results. At Qlik, automated tests run nightly for up to 20 development branches, each containing thousands of test cases, resulting in information overload. Aim. We therefore develop a tool that supports the analysis of test results. Method. We create NIOCAT, a tool that clusters similar test case failures, to help the analyst identify underlying causes. To evaluate the tool, experiments on manually created subsets of failed test cases representing different use cases are conducted, and a focus group meeting is held with test analysts at Qlik. Results. The case study shows that NIOCAT creates accurate clusters, in line with analyses performed by human analysts. Further, the potential time-savings of our approach is confirmed by the participants in the focus group. Conclusions. NIOCAT provides a feasible complement to current automated testing practices at Qlik by reducing information overload.","2159-4848;21594848","Electronic:978-1-4799-7125-1; POD:978-1-4799-7126-8","10.1109/ICST.2015.7102596","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7102596","","Companies;HTML;Information retrieval;Navigation;Software;Software testing","pattern clustering;program testing;software tools","NIOCAT tool;Qlik;automated testing practices;clustering approach;failed test cases;information overload reduction;multibranch development;software testing;test automation;test case failures;time-savings;use cases","","0","","28","","","13-17 April 2015","","IEEE","IEEE Conference Publications"
"Privacy Preserving Data Processing","H. Yamaguchi; M. Gotaishi; P. C. Y. Sheu; S. Tsujii","Chuo Univ., Tokyo, Japan","2015 IEEE 29th International Conference on Advanced Information Networking and Applications","20150430","2015","","","714","719","A data processing functions are expected as a key-issue of knowledge-intensive service functions in the Cloud computing environment. Cloud computing is a technology that evolved from technologies of the field of virtual machine and distributed computing. However, these unique technologies brings unique privacy and security problems concerns for customers and service providers due to involvement of expertise (such as knowledge, experience, idea, etc.) in data to be processed. We propose the cryptographic protocols preserving the privacy of users and confidentiality of the problem solving servers.","1550-445X;1550445X","Electronic:978-1-4799-7905-9; POD:978-1-4799-7906-6","10.1109/AINA.2015.258","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7098043","Cloud Computing;Cryptographic Protocol;Privacy;Security","Data processing;Indexes;Information retrieval;Security;Servers;Web services","cloud computing;cryptographic protocols;data privacy;virtual machines","cloud computing environment;cryptographic protocols;data processing functions;distributed computing;knowledge-intensive service functions;privacy preserving data processing;problem solving server confidentiality;virtual machine","","1","","21","","","24-27 March 2015","","IEEE","IEEE Conference Publications"
"Enhanced Direct Access to Huffman Encoded Files","J. Herzberg; S. T. Klein; D. Shapira","Comput. Sci. Dept., Bar Ilan Univ., Ramat Gan, Israel","2015 Data Compression Conference","20150706","2015","","","447","447","Given a file T, and the Huffman encoding of its elements, we present a data structure that enables direct access to the i-th element of T by reordering the bits of the compressed file and using some additional space. When compared to a Wavelet tree for Huffman Codes, our different reordering of the bits requires less additional storage overhead by reducing the need for auxiliary rank structures, while improving processing time for extracting the ith element of T.","1068-0314;10680314","Electronic:978-1-4799-8430-5; POD:978-1-4799-8431-2","10.1109/DCC.2015.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7149310","Huffman code;Skeleton tree;Wavelet tree","Computer science;Data compression;Decoding;Information retrieval;Memory management;Skeleton;Topology","Huffman codes;data compression;data structures;trees (mathematics)","Huffman code;Huffman encoded files;Huffman encoding;auxiliary rank structure;compressed file;data structure;direct access;storage overhead;wavelet tree","","0","","3","","","7-9 April 2015","","IEEE","IEEE Conference Publications"
"Identifying adverse drug events from patient social media: A case study for diabetes","X. Liu; H. Chen","University of Arizona, AZ, USA","IEEE Intelligent Systems","20150522","2015","30","3","44","51","Patient social media sites have emerged as major platforms for discussion of treatments and drug side effects, making them a promising source for listening to patients' voices in adverse drug event reporting. However, extracting patient reports from social media continues to be a challenge in health informatics research. In light of the need for more robust extraction methods, the authors developed a novel information extraction framework for identifying adverse drug events from patient social media. They also conducted a case study on a major diabetes patient social media platform to evaluate their framework's performance. Their approach achieves an f-measure of 86 percent in recognizing discussion of medical events and treatments, an f-measure of 69 percent for identifying adverse drug events, and an f-measure of 84 percent in patient report extraction. Their proposed methods significantly outperformed prior work in extracting patient reports of adverse drug events in health social media.","1541-1672;15411672","","10.1109/MIS.2015.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006392","ADE;adverse drug effects;clinical trials;diabetes;health;intelligent systems;predictive analytics;social media","Data mining;Diabetes;Drugs;Informatics;Information retrieval;Media;Patient monitoring;Safety;Social network services","diseases;medical information systems;patient treatment;pharmaceuticals;social networking (online)","adverse drug event reporting;adverse drug events;diabetes;drug side effects;f-measure;health social media;information extraction framework;patient report extraction;patient social media sites;robust extraction methods;treatment discussion","","2","","15","","20150112","May-June 2015","","IEEE","IEEE Journals & Magazines"
"Suggesting biomedical topics for unseen research articles based on MeSH descriptors","C. G. Lim; B. S. Jeong; H. J. Choi","Dept. of Computer Engineering, Kyung Hee University 1732 Deogyeong-daero, Giheung-gu, Yongin-si, Korea","2015 International Conference on Big Data and Smart Computing (BIGCOMP)","20150402","2015","","","51","54","Due to the huge number of research articles in the biomedical domain, it becomes more and more important to develop methods to find relevant articles of our specific research interests. Keyword extraction is a useful method to find important topics from documents and summarize their major information. Unfortunately, it is hard to select appropriate keywords extracted by traditional method of keyword extraction from specific research fields such as biomedical domain. Although human experts can support to understand details of the keywords, extra time should be required to read contents of the documents. In this paper, we propose a method for suggesting keyword-based topics for unseen biomedical research articles from PubMed. Our method uses MeSH descriptors to summarize each document by obtaining frequencies of them. The list of frequencies is used to make keyword suggestions for given documents based on the MeSH. In the experiments, we evaluate the performance of the method by measuring the accuracy of keyword suggestions for a given set of unseen documents.","2375-933X;2375933X","Electronic:978-1-4799-7303-3; POD:978-1-4799-7304-0; USB:978-1-4799-7302-6","10.1109/35021BIGCOMP.2015.7072850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7072850","MeSH descriptor;biomedical topic suggestion;frequency of keywords;keyword extraction","Accuracy;Data mining;Information retrieval;Labeling;Libraries;Ontologies;Semantics","document handling;information retrieval;medical information systems","MeSH descriptors;Medical Subject Headings;PubMed;biomedical domain;document summarization;keyword extraction;keyword suggestions;keyword-based topics;unseen biomedical research articles","","0","","15","","","9-11 Feb. 2015","","IEEE","IEEE Conference Publications"
"Color image (dis)similarity assessment and grouping based on dominant colors","J. Karasek; R. Burget; V. Uher; J. Masek; M. K. Dutta","Brno University of Technology, Department of Telecommunications, Technicka 12, 612 00 Brno, Czech Republic","2015 38th International Conference on Telecommunications and Signal Processing (TSP)","20151012","2015","","","756","759","The computer vision connected to image understanding becomes more and more important in everyday life. This paper concerns the image (dis)similarity assessment and grouping. The main contribution of this paper is the method for image (dis)similarity assessment based on dominant colors. The experimental results showed better results than the Direct Pixel Similarity and Color Histograms and method proved to be capable of detecting images similar to the target image.","","Electronic:978-1-4799-8498-5; POD:978-1-4799-8499-2; USB:978-1-4799-8497-8","10.1109/TSP.2015.7296366","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296366","Categorization;Classification;Clustering;Computer Vision;Image Processing;Image Similarity Measure","Cities and towns;Distance measurement;Feature extraction;Histograms;Image color analysis;Information retrieval;Telecommunications","computer vision;image colour analysis","color histograms;color image dissimilarity assessment;color image grouping;computer vision;direct-pixel similarity;dominant colors;image detection;target image","","","","11","","","9-11 July 2015","","IEEE","IEEE Conference Publications"
"A Novel Fast Retrieval Algorithm for Huge Amounts of Data","W. Z. You","Dept. of Film & Telev. Arts, Shanghai Publishing & Printing Coll., Shanghai, China","2015 Seventh International Conference on Measuring Technology and Mechatronics Automation","20150914","2015","","","47","50","With the rapid development of Internet, information explosively grows at a geometric rate. How to retrieve useful information from the vast amounts of multimedia information resources is a hot research topic. A multi-feature-based image retrieval system on the condition of extracted multi-feature has been carried out. PCA method was used for dimensionality reduction. Relevance feedback technique is used to get the connection of system and users, and adjust the values of the features according to the feedback of users, to raise the accuracy of image retrieval and satisfy the users' need. The experiment shows that the proposed algorithm has better retrieval performance.","2157-1473;21571473","CD-ROM:978-1-4673-7142-1; Electronic:978-1-4673-7143-8; POD:978-1-4673-7144-5","10.1109/ICMTMA.2015.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7263511","PCA;huge amounts of data;relevance feedback;retrieval algorithm","Accuracy;Feature extraction;Image color analysis;Image retrieval;Information retrieval;Principal component analysis;Semantics","feature extraction;image retrieval;principal component analysis;relevance feedback","PCA method;dimensionality reduction;fast retrieval algorithm;multifeature extraction;multifeature-based image retrieval system;relevance feedback technique","","","","10","","","13-14 June 2015","","IEEE","IEEE Conference Publications"
"Musical Onset Detection Using Constrained Linear Reconstruction","C. Y. Liang; L. Su; Y. H. Yang","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","IEEE Signal Processing Letters","20150813","2015","22","11","2142","2146","This letter presents a multi-frame extension of the well-known spectral flux method for unsupervised musical onset detection. Instead of comparing only the spectral content of two frames, the proposed method takes into account a wider temporal context to evaluate the dissimilarity between a given frame and its previous frames. More specifically, the dissimilarity is measured by using the previous frames to obtain a linear reconstruction of the given frame, and then calculating the rectified, l<sub>2</sub>-norm reconstruction error. Evaluation on a dataset comprising 2,169 onset events of 12 instruments shows that this simple idea works fairly well. When a non-negativity constraint is imposed in the linear reconstruction, the proposed method can outperform the state-of-the-art unsupervised method SuperFlux by 2.9% in F-score. Moreover, the proposed method is particularly effective for instruments with soft onsets, such as violin, cello, and ney. The proposed method is efficient, easy to implement, and is applicable to scenarios of online onset detection.","1070-9908;10709908","","10.1109/LSP.2015.2466447","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7185355","Exemplar;linear reconstruction;musical onset","Context;Indexes;Instruments;Measurement uncertainty;Multiple signal classification;Music information retrieval;Signal processing algorithms","music;signal reconstruction;unsupervised learning","SuperFlux;constrained linear reconstruction;l<sub>2</sub>-norm reconstruction error;linear reconstruction;unsupervised musical onset detection","","1","","44","","20150811","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Text document clustering on the basis of inter passage approach by using K-means","R. K. Mishra; K. Saini; S. Bagri","Computer Science and Engineering, Manav Rachna College of Engineering, Faridabad, India","International Conference on Computing, Communication & Automation","20150706","2015","","","110","113","Document clustering usually deals with clustering of documents that revolve around a single topic. To achieve more efficient clustering results, it is important to consider the fact that a document may deal with more than one topic. Our research work proposes a new inter-passage based clustering technique which will cluster the segment of the documents on the basis of similarities. The input will be the collection of documents consisting of multi topic segments taken from web. SentiWordNet has been used to calculate the segment score of the segments within the documents. Based upon the segment score segment based clustering is performed on the intra-document level. Once we are done with intra-document segment based clustering then k-means approach is applied to the entire collection of documents to perform inter-document clustering in which the similar segments of various documents will be clustered under a single cluster. Our proposed technique would help in efficient organization of multi topic documents into their corresponding clusters.","","Electronic:978-1-4799-8890-7; POD:978-1-4799-8891-4","10.1109/CCAA.2015.7148354","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148354","Document Clustering;Inter Document Clustering;Intra Document Clustering;SentiWordNet;Sentiment analysis","Automation;Cleaning;Clustering algorithms;Computer science;Information retrieval;Organizations;Partitioning algorithms","learning (artificial intelligence);pattern clustering;text analysis","K-means clustering;SentiWordNet;document similarity;inter passage approach;inter-document clustering;intra-document segment based clustering;segment score segment based clustering;text document clustering","","2","","6","","","15-16 May 2015","","IEEE","IEEE Conference Publications"
"Identifying Similar Cases in Document Networks Using Cross-Reference Structures","T. Botsis; J. Scott; E. J. Woo; R. Ball","Office of Biostatistics and Epidemiology, Center for Biologics Evaluation and Research, Food and Drug Administration, MD, USA","IEEE Journal of Biomedical and Health Informatics","20151103","2015","19","6","1906","1917","Our objective was to explore the creation of document networks based on different thresholds of shared information and different clustering algorithms on those networks to identify document clusters describing similar clinical cases. We created networks from vaccine adverse event report sets using seven approaches for linking reports. We then applied three clustering algorithms [visualization of similarities (VOS), Louvain, k-means] to these networks and evaluated their ability to identify known clusters. The report sets included one simulated set and three sets from the Vaccine Adverse Event Reporting System; each was split into training and testing subsets. Training subsets were used to estimate parameter values for the clustering algorithms and testing subsets to evaluate clusters. We created the networks by linking reports based on shared information in the form either of individual Medical Dictionary for Regulatory Activities Preferred Terms (PTs) or of dyads, triplets, quadruplets, quintuplets, and sextuplets of PTs; we created another network by weighting the single PT network connections by Lin's information theoretic approach to similarity. We then repeated this entire process using networks based on text mining output rather than structured data. We evaluated report clustering using recall, precision, and f-measure. The VOS algorithm outperformed Louvain and k-means in general. The best weighting scheme appeared to be related to the complexity of the known cluster. For example, singleton weighting performed best for an intussusception cluster driven by a single PT. We observed marginal differences between the code- and textual-based clustering. In conclusion, our approach supported identification of similar nodes in a document network.","2168-2194;21682194","","10.1109/JBHI.2014.2345873","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6873230","Classification;clustering;document networks;postmarketing product surveillance;similarity","Algorithm design and analysis;Clustering algorithms;Information retrieval;Network topology;Training","data mining;data structures;electronic health records;parameter estimation;pattern classification;pattern clustering","Lin's information theoretic approach;Louvain method;VOS algorithm;clustering algorithms;cross-reference structures;document networks;f-measure;individual medical dictionary-for-regulatory activities preferred terms;intussusception cluster;k-means method;parameter estimation values;testing subsets;text mining output;textual-based clustering;training subsets;vaccine adverse event report sets;visualization-of-similarities","","1","","38","","20140807","Nov. 2015","","IEEE","IEEE Journals & Magazines"
"Semantic Annotation and Classification in Practice","O. R. Rocha; I. Vagliano; C. Figueroa; F. Cairo; G. Futia; C. A. Licciardi; M. Marengo; F. Morando","Politecnico di Torino","IT Professional","20150402","2015","17","2","33","39","The Web's evolution into a Semantic Web and the continuous increase in the amount of data published as linked data open up new opportunities for annotation and categorization systems to reuse these data as semantic knowledge bases. Accordingly, information extraction systems use linked data to exploit semantic knowledge bases, which can be interconnected and structured to increase the precision and recall of annotation and categorization mechanisms. TellMeFirst classifies and enriches textual documents written in English and Italian. Although various works present solutions for text annotation and classification, this article describes and studies the use case of a telecommunications operator that has adopted TellMeFirst to add value to two services available to its users: FriendTV and Society.","1520-9202;15209202","","10.1109/MITP.2015.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7077255","information extraction;linked data;semantic annotation;semantic classification","Classification algorithms;Electronic publishing;Information retrieval;Information services;Information technology;Knowledge based systems;Semantic Web;Semantics;Training","knowledge acquisition;knowledge based systems;pattern classification;semantic Web;text analysis","TellMeFirst functionality;categorization system;data classification;information extraction system;linked data;semantic Web;semantic annotation;semantic knowledge base;telecommunications operator","","0","","15","","","Mar.-Apr. 2015","","IEEE","IEEE Journals & Magazines"
