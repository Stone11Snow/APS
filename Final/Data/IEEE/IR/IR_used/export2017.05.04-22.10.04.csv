"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=7574910,7576524,7445241,7571864,7571935,7571850,7573124,7571916,7573685,7571914,7573737,7570874,7569362,7570887,7569350,7569260,7568434,7568452,7565980,7568388,7565988,7566565,7566043,7564969,7566588,7566616,7564866,7553439,7507122,7563628,7564058,7563688,7561531,7561521,7562805,7563146,7559591,7559583,7559600,7560317,7559586,7559596,7560378,7559595,7559594,7559568,7559612,7559565,7559571,7559575,7559567,7559619,7559620,7559570,7559605,7559621,7557693,7557774,7557572,6917207,7557431,7557597,7557649,7557529,7557585,7556058,7557430,7555288,7552956,7552960,7554173,7552081,7550939,7550853,7550802,7550834,7550911,7550910,7549363,7550840,7550847,7551996,7549412,7549480,7551676,7552075,7549372,7551571,7551685,7532348,7532403,7532401,7532764,7546329,7544009,7545018,7545901,7546330,7546009,7546004",2017/05/04 22:10:04
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Study on intelligent defect management strategy based on cloud mode","L. Zhendong; S. Wei; W. Chong; Y. Wenbo; D. Yanping; Z. Wei; L. Qimeng","State Grid Jibei Electricity Power Maintenance Company, Beijing, China","2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference","20160905","2016","","","51","54","Because devices and equipment are on the increase, defect types coming out one after the other, traditional defect management seriously lagging behind power grid development, etc. in-depth improvement and study of defect treatment procedures, data classification and filing, standardized operation procedures, etc. are made in this article. First, gather, trace, classify and zone all kinds of defects, and then store them in a cloud encrypted client in the form of illustrated “big data” by working via system Apps such as mobile ISO, etc. we can trace and start up defect treatment procedures at any time and at any place and rapidly browse and update data, realizing data sharing simply and effectively. The callback mode of Parser Call back web page is used to avoid the effect due to network delay, and multi-thread search method is used to upgrade the positioning of key words in the aspect of search engine. In applications, intelligent cloud defect management method can help a troubleshooter quickly position failures and complete operations in a standard manner according to system prompts, which not only improves efficiency and ensures personal safety. The implementation of strategy combines on-site technology and Internet + perfectly, realizing informatization, automation and interaction.","","CD-ROM:978-1-4673-9193-1; Electronic:978-1-4673-9194-8; POD:978-1-4673-9195-5","10.1109/ITNEC.2016.7560317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560317","big data;intelligent cloud defect management method;position failures;standard process","Accidents;Cloud computing;Libraries;Maintenance engineering;Mobile handsets;Safety;Standards","Big Data;cloud computing;cryptography;electrical safety;failure analysis;information retrieval;mobile computing;multi-threading;pattern classification;power engineering computing;power grids;power system faults;power system reliability;search engines","Internet;big data;callback mode;cloud encrypted client;cloud mode;data classification;data filing;data sharing;defect treatment procedures;efficiency improvement;failure positioning;in-depth improvement;intelligent cloud defect management method;key words positioning;mobile ISO;multithread search method;network delay;on-site technology;parser call back Web page;personal safety;power grid development;search engine;standardized operation procedures;system Apps;troubleshooter","","","","","","","20-22 May 2016","","IEEE","IEEE Conference Publications"
"Automated extraction of concept matcher thesaurus from semi-structured catalogue-like sources of data on the web","M. Lapaev","ITMO University, St. Petersburg, Russia","2016 18th Conference of Open Innovations Association and Seminar on Information Security and Protection of Information Technology (FRUCT-ISPIT)","20160908","2016","","","153","160","Ontology design and the process of populating a data-set with knowledge following the chosen or developed ontology to fit the principles of Semantic Web and Linked Open Data is a time-consuming and iterative process, requiring either expert knowledge or a set of tools for data scraping from web. A valid and consistent ontology and knowledge withing the data-set require unification of concepts which means overcoming ambiguity and synonymy of terms which become individuals of ontology. In this paper we spot on techniques used for organising a Russian food product data-set under a light-weight FOOD Ontology and concept matching in particular. Main approaches to data-set concept unification, synonymic term matching and ways to collect dictionaries for matcher are mentioned. The tool for catalogue-like semi-structured resources parsing and thesaurus extraction is developed and introduced for the task of on-the-fly concept matching.","","Electronic:978-9-5268-3973-8; POD:978-1-5090-2500-8","10.1109/FRUCT-ISPIT.2016.7561521","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561521","","Data mining;Databases;Manuals;Ontologies;Semantic Web;Thesauri","cataloguing;dictionaries;grammars;information retrieval;ontologies (artificial intelligence);pattern matching;semantic Web;thesauri","FOOD ontology;Russian food product data-set;automated extraction;catalogue-like semistructured resources parsing;concept matcher thesaurus;concept matching;data-set concept unification;dictionaries;linked open data;ontology design;semantic Web;semistructured catalogue-like data sources;synonymic term matching;thesaurus extraction","","","","","","","18-22 April 2016","","IEEE","IEEE Conference Publications"
"Domain-Specific Video Compression for Long-Term Archiving of Endoscopic Surgery Videos","B. Münzer; K. Schoeffmann; L. Böszörmenyi","Lakeside Labs., Klagenfurt Univ., Klagenfurt, Austria","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","312","317","Common lossy video compression methods have already reached a very high performance level and are about to reach their natural limit. However, their compression efficiency is still insufficient for certain domains where a plethora of video data should be archived. One example is the domain of medical endoscopy where entire surgeries are recorded for documentation with high visual quality because it is not possible to anticipate if and when exceptional situations may happen. Eventually, only a fraction of the video footage is of actual relevance for post-operative review. In this paper, we introduce the concept of domain-specific video compression by the example of this very specific domain. We identify several characteristics of endoscopic surgery videos that can be exploited by content-based analysis algorithms to achieve a significantly higher compression efficiency than in current practice. The extensive evaluation shows that the proposed methods massively reduce the data volume without any semantic information loss and thus allow for long-term video archiving of endoscopic surgery videos. Moreover, we expect to stimulate future research in this challenging new field.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546009","Domain-specific video compression;content-based video analysis;endoscopic video","Biomedical imaging;Documentation;Endoscopes;Semantics;Surgery;Video compression;Visualization","data compression;endoscopes;information retrieval systems;medical image processing;surgery;video coding","compression efficiency;content-based analysis algorithms;domain-specific video compression;endoscopic surgery videos;long-term video archiving;lossy video compression;medical endoscopy","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"A unified approach to automate geospatial data retrieval using semantic web technologies","Y. Zhang; C. Li; S. Liu; F. Wen; L. Du; H. He","School of Control and Computer Engineering, North China Electric Power University, Beijing, 102206, P.R. China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","There is a tremendous number of geospatial data becoming available and there are numerous methods for getting access to geospatial sources. However, diverse geospatial data sources lead to various extracting ways. Users without adequate background knowledge are unable to fully exploit the growing amount of geospatial data. Our work provides users with a uniform interaction paradigm to tackle the variant retrieval problems in a universal way. Unifying the retrieval methods requires the ability to invoke processing algorithms by a uniform interaction paradigm. Our approach, implemented in a tool called Karma, encapsulates these algorithms as Web Services. As different sources present diverse non-semantic geospatial data, users cannot fully understand the extracted geospatial data. We have defined a general ontology to align and semantify the retrieved data. In addition, we present the principles underlying our approach, and several running examples are given to demonstrate the feasibility and effectiveness of our prototype.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550834","Geospatial data retrieval;ontology;semantic modeling;unified retrieving","Data models;Decision support systems;Erbium;Joining processes;Ontologies;Semantics;Web services","Web services;geography;information retrieval;ontologies (artificial intelligence);semantic Web","Karma;Web services;diverse geospatial data sources;diverse nonsemantic geospatial data;geospatial data retrieval;ontology;semantic Web technologies;uniform interaction paradigm","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"On physical web browser","D. Namiot; M. Sneps-Sneppe","Lomonosov Moscow State University, Moscow, Russia","2016 18th Conference of Open Innovations Association and Seminar on Information Security and Protection of Information Technology (FRUCT-ISPIT)","20160908","2016","","","220","225","In this paper, we present the Physical Web Browser project for web applications depending on the environment. At this moment, many of users all over the world visit websites using their mobile devices only. Any mobile device (e.g., smartphone) has sensors to capture the environmental information. This information (context) could be analyzed and used within the web applications. There are, at least, two models for using this information. Firstly, we can use context information for data gathering requests in a web application. In this case, the output depends on the context. It is the classical model for context-aware data retrieval. In the second model, we can use context-aware data for improving user experience (for changing and tuning user interfaces). In other words, we present a way for the adaptation of web applications depending on the environment.","","Electronic:978-9-5268-3973-8; POD:978-1-5090-2500-8","10.1109/FRUCT-ISPIT.2016.7561531","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561531","","Browsers;Context;Context modeling;Mobile communication;Mobile handsets;Sensors;Servers","Web sites;information retrieval;mobile computing;online front-ends;sensor fusion;user interfaces","Web applications;Websites;context-aware data retrieval;data gathering requests;environmental information;information fusion;mobile devices;physical Web browser project;sensors;user experience;user interfaces","","","","","","","18-22 April 2016","","IEEE","IEEE Conference Publications"
"Continuous Development and Operation of a Regional Digital Archives System as Real PBL","T. Okuno; T. Kawashima","Dept. of Media Archit., Future Univ. Hakodate, Hakodate, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","1078","1083","Future University Hakodate, in cooperation with Hakodate city Central Library, has developed a digital archives system. For the purpose of both maintaining the archives within the limited budget and making use of the archives as the field of research and education, students have participated in the development and the operation of the archives. The activities concerning the digital archives are particularly valuable field of project based learning. The skills to be obtained through the activities includes both system development and project management. The former includes not only programming but also the system integration for real business application. The latter includes not only team management but also stakeholder management.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557774","digital archives;project based learning;project management;system development;system integration","Databases;Education;Information systems;Libraries;Project management;Prototypes;Urban areas","academic libraries;computer aided instruction;educational institutions;information retrieval systems;project management;team working","Hakodate city Central Library;PBL;continuous development;digital archives;education field;project based learning;project management;regional digital archive system;research field;stakeholder management;system development;system integration;team management","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Avoiding the Drunkard's search: Investigating collection strategies for building a Twitter dataset","C. Llewellyn; L. Cram; A. Favero","University of Edinburgh, 2F2 Buccleuch Place Edinburgh, UK","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","205","206","We investigate methods for collecting data to form an archive on the debate within Twitter surrounding the UK's inclusion in the EU. We use three strategies, gathering data using hashtags, extracting data from the random stream and collecting from users known to be discussing the debate. We explore the various bias in the resulting datasets.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559586","Data Analytics;Data Selection;Social Media Analysis","Buildings;Data collection;Data mining;Media;Tagging;Time-frequency analysis;Twitter","information retrieval;social networking (online)","Twitter dataset;data collection strategies;data extraction;hashtags","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"The research on event extraction of Chinese news based on subject elements","C. Zhang; S. Hong; P. Zhang","School of Computer Science, Communication University of China, Beijing, P.R. China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","5","Nowadays, with the rapid economic development, the amount of social information is also going up. Facing the daily explosive growth of the news quantity, the audience can difficultly get important information. To this end, the paper puts forward a method of Chinese news event extraction based on subject elements, which mixes the study of news topic sentence extraction and the research of event extraction together. According to the characteristics of news sentence, use dependency parsing to analyze the syntax. With the result of syntactic parsing to be a feature, distinguishably use Conditional Random Field algorithm (CRF) and Manual rules to identify the triggers in complex and simple sentences. Finally, Semantic Role Labeling algorithm (SRL) is used to identify the key elements of news events. What's more, the method will help readers quickly get the key elements from the long news, improving the efficiency of getting message.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550911","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550911","CRF;event extraction;manual rules;subject elements","Algorithm design and analysis;Data mining;Feature extraction;Manuals;Pattern matching;Semantics;Syntactics","grammars;information retrieval;random processes;text analysis","CRF;Chinese news event extraction;SRL;conditional random field algorithm;dependency parsing;long news;news sentence characteristics;news topic sentence extraction;rapid economic development;semantic role labeling algorithm;social information;subject elements;syntactic parsing;syntax analysis","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Increasing datasets discoverability in an engineering data platform using keyword extraction","P. Gopavarapu; L. C. Pouchard; S. Pujol","Purdue University, 112 E Wood St, West Lafayette, IN 47906","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","225","226","In this paper we describe the use of keyword extraction in a data management platform for the storage, publication, and sharing of scientific and engineering datasets primarily related to the stress of concrete structures under earthquake conditions. To improve discoverability of datasets and assist scientists who upload data, we designed an automated keyword extraction system that will propose keywords for uploaded datasets.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559596","Data discovery;data repository;keyword extraction","Concrete;Data mining;Frequency measurement;Matrix decomposition;Semantics;Stress;XML","information retrieval","automated keyword extraction system;concrete structures;data management platform;earthquake conditions;engineering data platform","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Research and design of similar file forensics system based on fuzzy hash","J. Jianguo; C. Jiuming; Y. Qian; L. Kunying; L. Chao","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference","20160905","2016","","","342","346","The collection and identification of digital evidence is an essential procedure in file forensics, which contains manual retrieval, traditional hash techniques and query by keywords techniques etc. For the vulnerability of electronic documents, it is easy to be changed or tampered with. So looking for files similar with target files becomes important for forensic. However, the traditional forensic system is usually based on searching for keywords or just scan the entire files, both lack of high enough speed and accuracy to support nowadays forensic tasks. Considering the fuzzy hash algorithm is of great value to calculating the similarity rate between files, in this paper, we analyzed the process and the improvement of the fuzzy hash algorithm, and verified the accuracy and efficiency of the improved algorithm, we innovatively applied fuzzy hash technology to the field of file forensic and designed a set of more adaptable and more accurate files forensic system, which follows the process of the acquisition of storage media, the collection of evident files, and the preservation of evident files, combined with text mining, data recovery technology, text clustering, classification, and some other technologies We believed that this system is a breakthrough of existing problems in file forensics field such like large manual workload and low accuracy.","","CD-ROM:978-1-4673-9193-1; Electronic:978-1-4673-9194-8; POD:978-1-4673-9195-5","10.1109/ITNEC.2016.7560378","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560378","electronic forensics;file forensics system;fuzzy hash;similar files forensics","Algorithm design and analysis;Decision support systems;Forensics;VLIW","data mining;digital forensics;fuzzy set theory;information retrieval;pattern classification;pattern clustering;storage management;text analysis","data recovery;digital evidence collection;digital evidence identification;electronic document vulnerability;file scanning;file similarity rate calculation;fuzzy hash algorithm;improved algorithm accuracy verification;improved algorithm efficiency verification;keywords search;similar file forensics system design;storage media acquisition;text classification;text clustering;text mining","","","","","","","20-22 May 2016","","IEEE","IEEE Conference Publications"
"Massively parallel implementation of sparse message retrieval algorithms in Clustered Clique Networks","P. Tigréat; P. H. Horrein; V. Gripon","Electronics Department, Telecom Bretagne, Brest, France","2016 International Conference on High Performance Computing & Simulation (HPCS)","20160915","2016","","","935","939","Auto-associative memories are a family of algorithms designed for pattern completion. Many of them are based on neural networks, as is the case for Clustered Clique Networks which display competitive pattern retrieval abilities. A sparse variant of these networks was formerly introduced which enables further improved performances. Specific pattern retrieval algorithms have been proposed for this model, such as the Global-Winners-Take-All and the Global-Losers-Kicked-Out. We hereby present accelerated implementations of these strategies on graphical processing units (GPU). These schemes reach interesting factors of acceleration while preserving the retrieval performance.","","Electronic:978-1-5090-2088-1; POD:978-1-5090-2089-8","10.1109/HPCSim.2016.7568434","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568434","CUDA;Clustered Clique Networks;GPGPU;Parallel processing","Acceleration;Algorithm design and analysis;Clustering algorithms;Graphics processing units;Instruction sets;Message systems;Neurons","content-addressable storage;graphics processing units;information retrieval;neural chips;parallel architectures","CUDA;GPU;auto-associative memories;clustered clique networks;competitive pattern retrieval abilities;compute unified device architecture;global-losers-kicked-out;global-winners-take-all;graphical processing units;massively parallel implementation;neural networks;pattern completion;pattern retrieval algorithms;retrieval performance;sparse message retrieval algorithms","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"Exome_pipe: An automatic exome data analysis pipeline","Y. Choi; J. Shin; J. Kong; J. Yoon; K. Lee","Department of Computer Engineering, Hallym University, Chuncheon, Korea","2016 International Conference on High Performance Computing & Simulation (HPCS)","20160915","2016","","","1029","1030","In this research, we propose a pipeline system to identify disease-causal genes in whole exome sequencing data. The pipeline automates the execution of the following steps: 1) initial read data control and cleaning; 2) alignment to a reference genome; 3) post alignment analysis; 4) variant discovery. It also provides a variant analyses tool Exome data analyzer, which allows the users to browse the genomic variations (SNP, Indel, CNV) in multi-scale of genetic regions and easily access to OMIM, dbSNP, DGV, or RefSeq database for discovering variants-related information. Our pipeline offers an easy-to-use graphical interface for submitting and tracking jobs which run on MS Window platform. Through our system non-IT mastered users can access to efficient public open software and biological databases, and quickly perform experiments and analysis for identifying disease-causing gene.","","Electronic:978-1-5090-2088-1; POD:978-1-5090-2089-8","10.1109/HPCSim.2016.7568452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568452","","","data analysis;diseases;genetics;genomics;graphical user interfaces;information retrieval;medical computing;pipeline processing","CNV;DGV;Exome data analyzer;Exome_pipe;Indel;MS Window platform;OMIM;RefSeq database;automatic exome data analysis pipeline;biological database;data cleaning;dbSNP;disease-causal gene identification;disease-causing gene;exome sequencing data;genomic variations;graphical interface;initial read data control;multiscale of genetic region;pipeline execution;pipeline system;post alignment analysis;public open software;reference genome alignment;variant analysis;variant discovery;variants-related information discovery","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"The discovery and identification of video page based on topic web crawler","X. Ren; S. Qin; P. Zang","Communication University of China, Beijing, P.R. China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","4","With the development of Internet technology, locating and identifying the page needed quickly from a sea of pages has become one of the most pressing and important demand. For the sake of acquiring video pages from mass web pages and analyzing their principal characteristics, this paper proposes the technology, which combines the form and content feature of the video page with topic web crawler of search engine technology, to identify video pages and video portals for the first time. To feed back to users about the results. So that they can access all video information on the Internet quickly. The result and analysis of environment shows that the algorithm is able to detect video pages with higher efficiency and accuracy.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550910","discovery and identification;topic web crawler;video page;video website","Crawlers;Internet;Libraries;Portals;Search problems;Uniform resource locators;Web pages","data mining;information retrieval;portals;search engines","Internet technology;search engine;topic Web crawler;video page discovery;video page identification;video portal","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Question identification and classification on an academic question answering site","B. Ojokoh; T. Igbe; A. Araoye; F. Ameh","Department of Computer Science, Federal University of Technology, Akure, Nigeria","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","223","224","Online communities such as wikis, blogs, forums, scientific communities and other social networking services have enabled new levels of interactions and interconnections among individuals, documents and data and have become places for people to seek and share expertise. In this paper, we propose a systematic approach to identification and classification of questions. The questions were first identified using semantic occurrence of Part of Speech (POS) tag in English Language, after which they were classified based on maximum probability value of Naïve Bayes classification. The model was validated and evaluated with experiments on some crawled web pages from ResearchGate.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559595","Classification;Online Forums;Questions;Research Gate","Blogs;Computer science;Electronic publishing;Information services;Knowledge discovery;Speech;User-generated content","Bayes methods;natural language processing;question answering (information retrieval);social networking (online)","English language;POS tag;academic question answering site;maximum probability value;naïve Bayes classification;online communities;part of speech tag;question classification;question identification;social networking services","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Cross-Language Plagiarism Detection Method: Arabic vs. English","E. Hattab","Res. Unit, Al-Dar Univ. Coll., Dubai, United Arab Emirates","2015 International Conference on Developments of E-Systems Engineering (DeSE)","20160912","2015","","","141","144","Copying & pasting ideas across languages have created many challenges in copyrights. Though many methods have been developed to detect plagiarized content in a given language, however, detecting cross-languages plagiarism is still a challenge. This paper uses Latent Semantic Indexing (LSI) to build cross-language semantic space, from which it checks the contextual similarity of two given research papers, one in English and another in Arabic. Results shown that this method works fine in detecting cross-language English-Arabic plagiarism with 93% similarity.","","","10.1109/DeSE.2015.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563628","citation based detection;contextual similarity;cross-language plagiarism detection;latent semantic indexing","Indexing;Large scale integration;Plagiarism;Search engines;Semantics;Statistical analysis","copyright;information retrieval;natural language processing","Arabic language;English language;LSI;contextual similarity;copyright;cross-language plagiarism detection method;cross-language retrieval;latent semantic indexing","","","","","","","13-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Leveraging human factors to enhance query answering in crowdsourcing systems","D. Koulougli; A. Hadjali; I. Rassoul","LARI, UMMTO, Algeria","2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)","20160825","2016","","","1","6","In recent years, crowdsourcing has become essential in a wide range of Web applications. Human factors play a key role in achieving high quality answers in crowdsourcing-based solving tasks. The most major factor is pertained to the uncertainty of workers about the responses that they provide to resolve the task at hand. On the other hand, workers may have diverse levels of expertise and skill. It is then important to take into account both the degrees of uncertainty and expertise when aggregating the set of worker answers. In this paper, we investigate some advanced crowdsourcing aggregation methods to find the correct answers by leveraging both expertise and uncertainty of workers in a unified way. Workers' uncertainty is represented in a possibilistic way, while a fine-grained scale for interpreting the degrees of skill is introduced. Finally, we present some comprehensive experiments to validate the effectiveness of our proposal.","","Electronic:978-1-4799-8710-8; POD:978-1-4799-8711-5","10.1109/RCIS.2016.7549363","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549363","Aggregation Methods;Crowdsourcing;Degree of Skill;Degree of Uncertainty;Human behavior;Quality Control","Context;Crowdsourcing;Data models;Human factors;Reliability;Servers;Uncertainty","human factors;information retrieval systems;query processing","Web applications;crowdsourcing systems;crowdsourcing-based solving task;human factors;query answering","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"The research of retrieval keyword analysis on stage's design knowledge base","W. Fu; L. Jin; W. Gong; K. Wang","Information Engineering School, Communication University of China, CUC, Beijing, China","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","4","The source of retrieval about stage's design knowledge base is text script, and text processing has become the key technologies about obtaining related information from script. This paper proposes a method of extracting from the script in the keyword categories by analyzing the characteristics of the script, furthermore, develop technical solutions for analysis of script's emotion by experiment.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550939","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550939","Analysis of script's emotion;Stage's design knowledge base;Text Retrieval;Text processing","Classification algorithms;Feature extraction;Knowledge based systems;Mutual information;Rain;Sun","information retrieval;knowledge based systems;text analysis","design knowledge base;retrieval keyword analysis;script emotion;text processing;text script","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"A Mobile Application for Interactive Exploratory Search of Apparel Products","E. Koike; T. Itoh","Ochanomizu Univ., Tokyo, Japan","2016 Nicograph International (NicoInt)","20160912","2016","","","120","123","Many people (especially women) tend to take relatively longer time for shopping, and therefore it is an interesting topic to develop enjoyable user interface for shopping. We discussed how to develop systems for apparel product retrieval inspired by psychology of women's shopping activity in our previous paper, and actually presented an implementation for personal computers. This paper presents a mobile application for apparel product shopping inheriting our previous study. The presented mobile application supports just three single-finger operations: tap, next, and shuffle. It shows pictures of products over and over while learning preferences of users applying interactive genetic algorithm. This paper presents the user interface design and processing flow of the presented application, and introduces our experiments.","","","10.1109/NicoInt.2016.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7564058","Graphical User Interface;Interactive Exploratory Search;Mobile application","Genetic algorithms;Graphical user interfaces;Microcomputers;Mobile applications;Psychology;Smart phones","clothing;genetic algorithms;information retrieval;interactive systems;mobile computing;retail data processing","apparel product retrieval;apparel product shopping;interactive exploratory search;interactive genetic algorithm;learning preferences;mobile application;psychology;single-finger operations;user interface design;women shopping activity","","","","","","","6-8 July 2016","","IEEE","IEEE Conference Publications"
"App controlled: Cloud service oriented smart city traffic management","K. B. Malagund; S. N. Mahalank; R. M. Banakar","School of Electronics and Communication Engineering, KLE Technological University, BVB Campus, Hubli-31","2016 Symposium on Colossal Data Analysis and Networking (CDAN)","20160919","2016","","","1","6","With the advent Internet in the 1990s to the present day facilities of ubiquitous computing, the Internet has changed the computing world in a drastic way. It has traveled from the concept of parallel computing to distributed computing to grid computing and recently to cloud computing. Anatomy of Cloud Computing is discussed in detail. Essential features of cloud services which are useful for the reduction of traffic congestion in the city is presented. Storage of data into cloud and retrieving data from the cloud from mobile application is presented, this theme is used as main platform to solve the traffic related problems in the city, as the traffic congestion has influenced on the citizens routine. The practical challenge faced using the open source cloud during the implementation needs a special mention.","","","10.1109/CDAN.2016.7570887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7570887","Internet;Storage of data;cloud computing;mobile applications;retrieving data;traffic congestion","Cloud computing;Companies;Computational modeling;Google;Vehicles","cloud computing;information retrieval;mobile computing;public domain software;smart cities;storage management;traffic engineering computing","Internet;cloud service oriented smart city traffic management;data retrieval;data storage;mobile App;mobile application;open source cloud;traffic congestion reduction;ubiquitous computing","","","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Music similarity retrieval method considering music arrangement","K. Kogo; K. Kawagoe; T. Hochin","Department of Information Science, Kyoto Institute of Technology, Kyoto, Japan","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","This paper proposes a music similarity retrieval method considering the shift of the pitch and the difference of tempos of music pieces. These are not considered in the current various services yet. The proposed method can retrieve music pieces arranged from the original ones as similar ones. The proposed method uses the pitch information and the length of the sound. The pitch and the tempo are normalized in calculating the similarity of music pieces. The effectiveness of the proposed method is experimentally shown.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550853","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550853","","Art;Computational efficiency;Mathematical model;Mood;Music;Standards;Time series analysis","dynamic programming;information retrieval;music","DTW;dynamic time warping;music arrangement;music similarity retrieval;pitch information;pitch shift;sound length;tempo difference","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Knowledge extraction for literature review","T. Erekhinskaya; M. Balakrishna; M. Tatu; S. Werner; D. Moldovan","Lymba Corporation, 901 Waterfall Way, Bldg 5 Richardson, Texas 75080","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","221","222","Researchers in all domains need to keep abreast with recent scientific advances. Finding relevant publications and reviewing them is a labor-intensive task that lacks efficient automatic tools to support it. Current tools are limited to standard keyword-based search systems that return potentially relevant documents and then leave the user with a monumental task of sifting through them. In this paper, we present a semantic-driven system to automatically extract the most important knowledge from a publication and reduces the effort required for the literature review. The system extracts key findings from biomedical papers in PubMed, populates a predefined template and displays it. This allows the user to get the key ideas of the content even before opening or downloading the publication.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559594","Literature review;knowledge extraction;semantic relation","Calculus;Diabetes;Hypertension;Medical diagnostic imaging;Semantics;Sociology;Statistics","information retrieval;medical computing;reviews","PubMed;biomedical papers;knowledge extraction;standard keyword-based search systems","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Characterizing users tagging behavior in academic blogs","L. Li; C. Zhang","Department of Information Management, Nanjing University of Science & Technology, No.200 Xiaolingwei Nanjing 210094, China","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","215","216","Along with popular of academic social media, academic blogs are one of the user generated academic information that can be annotated using social tags for user's information retrieval and organization. In order to improve the existing social tagging system to satisfy the users' needs, users' tagging behavior need to be understood. However, there is no researches on characterizing user tagging behaviors of academic resources. In this paper, using the tag of academic blog as the research object, the author analyze user's tagging behaviors based on the characteristics of tags (tags-based features) and those related to blog contents (content-based features). These characteristics can be used to the academic tagging system to promote organization and propagation of academic knowledge.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559591","Tagging behavior;academic blogs;academic social media;narrow folksonomy","Blogs;Context;Entropy;Histograms;Organizations;Speech;Tagging","educational administrative data processing;information retrieval;social networking (online)","academic blogs;academic resources;academic social media;content-based features;social tagging system;tags-based features;user generated academic information;user information organization;user information retrieval;user tagging behavior characterization","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Evaluating link-based recommendations for Wikipedia","M. Schwarzer; M. Schubotz; N. Meuschke; C. Breitinger; V. Markl; B. Gipp","TU Berlin","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","191","200","Literature recommender systems support users in filtering the vast and increasing number of documents in digital libraries and on the Web. For academic literature, research has proven the ability of citation-based document similarity measures, such as Co-Citation (CoCit), or Co-Citation Proximity Analysis (CPA) to improve recommendation quality. In this paper, we report on the first large-scale investigation of the performance of the CPA approach in generating literature recommendations for Wikipedia, which is fundamentally different from the academic literature domain. We analyze links instead of citations to generate article recommendations. We evaluate CPA, CoCit, and the Apache Lucene MoreLikeThis (MLT) function, which represents a traditional text-based similarity measure. We use two datasets of 779,716 and 2.57 million Wikipedia articles, the Big Data processing framework Apache Flink, and a ten-node computing cluster. To enable our large-scale evaluation, we derive two quasi-gold standards from the links in Wikipedia's “See also” sections and a comprehensive Wikipedia clickstream dataset. Our results show that the citation-based measures CPA and CoCit have complementary strengths compared to the text-based MLT measure. While MLT performs well in identifying narrowly similar articles that share similar words and structure, the citation-based measures are better able to identify topically related information, such as information on the city of a certain university or other technical universities in the region. The CPA approach, which consistently outperformed CoCit, is better suited for identifying a broader spectrum of related articles, as well as popular articles that typically exhibit a higher quality. Additional benefits of the CPA approach are its lower runtime requirements and its language-independence that allows for a cross-language retrieval of articles. We present a manual analysis of exemplary articles to demon- trate and discuss our findings. The raw data and source code of our study, together with a manual on how to use them, are openly available at: https://github.com/wikimedia/citolytics.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559583","Co-Citation;Co-Citation Proximity Analysis;big data;citation analysis;digital libraries;document similarity measures;large-scale evaluations;link-based;literature recommendations","Context;Electronic publishing;Encyclopedias;Internet;Libraries;Standards","Big Data;Web sites;citation analysis;information retrieval;recommender systems","Big Data processing framework;CPA approach;Wikipedia;citation-based document similarity measures;cross-language retrieval;large-scale evaluation;link-based recommendations;literature recommender systems;text-based MLT measure","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Influence analysis for celebrities via public cloud and social platform","L. Liu; H. Liang","College of Movie and Media, Sichuan Normal University, China","China Communications","20160909","2016","13","8","53","62","Recently, the online social networks have emerged as one of the important platforms for social users. Among millions of users, famous person from entertainment circle arouse our interest. They promote social relationship and establish their reputation via these platforms. To analyze the social influence of entertainment stars, we propose and implement a public cloud based framework to crawl celebrities' social messages from Sina Weibo, store the gathered messages, and conduct various analysis to assess the social influence. It consist of three key components: task generation, resource management and task scheduling, and influence analysis. The task generation is responsible of acquiring celebrities' social accounts and issue crawling tasks. We propose a cross-media method to extract social accounts from webpages. The resource management and task scheduling will dynamic adjust the rented resource to minimize the total computing cost while keeping QoS. We propose a dynamic instance provisioning strategy based on the large deviation principle. The influence analysis will undertake various types of analysis, such as fan count, posting frequency, textual analysis, and so on. More than 10,000 celebrities' microblogs have been gathered so far, and some related gainers, such as celebrities and ad agencies can gain the illumination brought by our analysis.","1673-5447;16735447","","10.1109/CC.2016.7563688","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563688","cloud computing;large deviation principle;social media analytics","Cloud computing;Entertainment industry;Fans;Media;Navigation;Resource management;TV","cloud computing;information analysis;information retrieval;quality of service;resource allocation;scheduling;social networking (online);social sciences computing","QoS;Sina Weibo;celebrities;crawling task;cross-media method;dynamic instance provisioning strategy;entertainment circle;entertainment stars;influence analysis;large deviation principle;microblogs;online social networks;public cloud platform;quality of service;resource management;social influence assessment;social platform;social relationship;social users;task generation;task scheduling","","","","","","","Aug. 2016","","IEEE","IEEE Journals & Magazines"
"Analysis of combined features at semantic argument classification","N. Azkalhaq; M. A. Bijaksana; S. Sa'adah","School of Computing, Telkom University, Bandung, Indonesia","2016 4th International Conference on Information and Communication Technology (ICoICT)","20160922","2016","","","1","6","Getting semantic argument representation of a sentence is necessary in natural language processing, such as information extraction and question answering. In the semantic role labeling, selection of features become influential on its performance and also affect the recall and precision produced. The problem now is how to combine the features and combinations such as what is used in order to get the expected performance for semantic role labeling. This research tries to analyze and combine some of the features that have already existed and shown optimal result performance in previous studies. Features used in this research are Baseline Feature plus Noun Head of PP, First Word in Constituent, Syntactic Frame, Argument Order and Constituent Order, that will be used in the classification of a semantic argument. Results from this study indicate that not all random combinations of features can improve performance of semantic argument classification, there are some features that would degrade the performance classification if they are not combined with the right features. Based on the average of all scenarios, the best combination is the combination with the use of five additional features used in this study with an accuracy of 75.3% and F-score of 74.6%. The addition of training data can also improve the performance of the classification.","","","10.1109/ICoICT.2016.7571916","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571916","","Blood;Feature extraction;Labeling;Natural language processing;Semantics;Syntactics;XML","classification;data analysis;natural language processing;question answering (information retrieval)","argument order;constituent order;information extraction;natural language processing;question answering;semantic argument classification;semantic argument representation;semantic role labeling;syntactic frame;training data","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Visualization of Statistics from MEDLINE®","J. Kim; P. LoBuglio; G. R. Thoma","Lister Hill Nat. Center for Biomed. Commun., Nat. Libr. of Med., Bethesda, MD, USA","2016 IEEE 29th International Symposium on Computer-Based Medical Systems (CBMS)","20160818","2016","","","290","291","We propose a system to visualize statistics collected from NLM's MEDLINE® database that contains citations related to biomedical journal articles. The system extracts information from author affiliations in the articles such as organization, city, state, country, etc., categorizes the articles into several groups using the information, collects statistics such as the number of articles published per country each year, etc., and displays the statistics through a Web site using tables and choropleth maps. Hidden Markov Model (HMM) and statistics are used to extract the information from the affiliations, and Google Map API, JSON, JavaScript and other APIs are used for the development of the site.","","Electronic:978-1-4673-9036-1; POD:978-1-4673-9037-8","10.1109/CBMS.2016.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546004","MEDLINE;affiliation;statistics;visualization","Data mining;Hidden Markov models;Organizations;Standards organizations;Urban areas;Visualization;Web sites","Web sites;citation analysis;data visualisation;electronic publishing;hidden Markov models;information retrieval;medical computing","Google Map API;HMM;JSON;JavaScript;NLM MEDLINE database;Web site;article categorization;author affiliations;biomedical journal articles;choropleth maps;citations;hidden Markov model;information extraction;statistics;visualization","","","","","","","20-24 June 2016","","IEEE","IEEE Conference Publications"
"Comparing Public Library Management under Designated Administrator System with Direct Management: Forcusing on Reference Service","Y. Mizunuma; K. Tsuji","Grad. Sch. of Libr., Inf. & Media Studies, Univ. of Tsukuba, Tsukuba, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","37","42","In Japan, public libraries have long been managed by local governments. However, with the introduction of the designated administrator system (DAS) in 2003, other organizations including private companies began to take over library management. In this study, we examine the differences between public libraries managed under DAS and those managed directly by local government (LG), with a focus on reference services. We compare the contents of the services provided and the number of reference questions received. The results show that LG libraries tend to answer users' questions directly, whereas DAS libraries tend to develop environments where users can find answers for themselves, such as by providing PCs connected to the Web and by offering classes on information-seeking skills. Our analysis shows that the DAS libraries receive more reference questions than LG libraries.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557572","designated administrator system;library management;public libraries;reference services","Companies;Computers;Libraries;Local government;Media;Urban areas","Internet;information retrieval;library automation;local government;public libraries","DAS libraries;Japan;Web;designated administrator system;direct management;information-seeking skills;local government;private companies;public library management;reference services","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Performance evaluation of distributed maximum weighted matching algorithms","C. U. Ileri; O. Dagdeviren","International Computer Institute, Ege University, Izmir, Turkey","2016 Sixth International Conference on Digital Information and Communication Technology and its Applications (DICTAP)","20160818","2016","","","103","108","Graph matching is a fundamental graph theory problem which has a broad application range including information retrieval, pattern recognition, graph partitioning, chemical structure analysis, protein function prediction, backup placement and cellular coverage. This problem has gained attention in distributed computing as there are distributed matching algorithms with asymptotically guaranteed time bounds and approximation ratios. On the other side, we do not know the practical performance of these algorithms. In this paper, we provide a detailed performance evaluation of asynchronous distributed maximum weighted matching (MWM) algorithms. We assume a message-passing system in CONGEST model in which the message size is limited to O(log n) where n is the number of nodes. This model is popular for energy-efficient networks such as wireless sensor networks. We used a discrete event simulator, SimPy, to model the assumed network structures. We provide the implementations of Watthenhofer and Wattenhofer's algorithm, Hoepman's algorithm, Lotker et al.'s algorithm and Lotker et al.'s improvement algorithm. The results show that the greedy algorithm of Hoepman performed best in approximating the optimum result in all types of networks, even achieving an approximation ratio of 0.99 in some instances. To the best of our knowledge this is the first study which provides an extensive performance evaluation of distributed MWM algorithms.","","CD-ROM:978-1-4673-9608-0; Electronic:978-1-4673-9609-7; POD:978-1-4673-9610-3","10.1109/DICTAP.2016.7544009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7544009","Distributed Computing;Graph Matching;Performance Evaluation","Algorithm design and analysis;Approximation algorithms","discrete event simulation;energy conservation;graph theory;information retrieval;message passing;pattern recognition;software performance evaluation","CONGEST model;MWM algorithms;SimPy;asynchronous distributed maximum weighted matching algorithms;backup placement;cellular coverage;chemical structure analysis;discrete event simulator;distributed computing;energy-efficient networks;graph matching;graph partitioning;graph theory;information retrieval;message passing system;pattern recognition;performance evaluation;protein function prediction","","","","","","","21-23 July 2016","","IEEE","IEEE Conference Publications"
"Performance improvement of multi-dimensional indexing system for big data analysis","K. Nakanishi; T. Hochin; H. Nomiya","Department of Information Science, Kyoto Institute of Technology, Kyoto, Japan","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","This paper proposes the methods for improving performance of multi-dimensional index system. In the previous system, data are inserted into a reception-node, and are stored in a reception-index. When a reception-index stores a certain number of data, the reception-index is moved to a normal-node, and becomes a partial-index. At this time, insertion is paused. In addition, if the numbers of data in a normal-node are skewed, the retrieval performance degrades. This paper proposes an architecture enabling data to be inserted without a pause. Moreover, when a reception-index is moved to a normal-node, all normal-nodes are tried to store partial-indexes equally. It is experimentally clarified that the insertion time decreases by the proposed architecture. It is also clarified that partial-indexes can be distributed equally based on the proposed method, and that the retrieval performance can be improved.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550840","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550840","Insertion performance;Multi-dimensional indexing;Parallel processing;Retrieval performance","","Big Data;data analysis;database indexing;information retrieval;storage management","big data analysis;data insertion;data storage;multidimensional indexing system;normal-node;partial-index;reception-index;reception-node;retrieval performance","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Estimation of factor scores from feature values of english question and answer statements","Y. Yokoyama; T. Hochin; H. Nomiya","Graduate School of Life and Environmental Sciences, Kyoto Prefectural University, Kyoto, Japan","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","6","In order to eliminate mismatches between the intentions of questioners and respondents of Question and Answer (Q&A) sites, nine factors of impressions for Japanese statements have experimentally been obtained. Nine factors have also been obtained from the impression of English Q&A statements. This paper estimates factor scores of English Q&A statements through multiple regression analysis. These are words and characters, syntactic information, and appearance percentages. It is shown that estimation accuracies of all of the nine factors are very good.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550847","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550847","Q&A site;factor;factor score;feature value of statements;multiple regression analysis","Decision support systems","Web sites;natural language processing;question answering (information retrieval)","English Q and A statements;English question and answer statements;Japanese statements;appearance percentages;factor scores;feature values;multiple regression analysis;question and answer sites;syntactic information","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Towards Correlating Search on Google and Asking on Stack Overflow","C. Chen; Z. Xing","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","1","","83","92","Search engines and Question and Answer (Q&A) sites are the two commonly used ways for developers to seek information on the web. In this paper, we ask whether the questions developers ask on Q&A sites correlate with the information developers search for using search engines. We report on our empirical study to investigate the correlations of the 185 popular technical terms developers search on Google and ask on Stack Overflow using search statistics obtained from Google Trends over a 574-weeks span and question statistics derived from Stack Overflow Data Dump over a 300-weeks span. Our study shows that technical terms searched and asked have strong correlation over time. Search and asking of newer, specific technical terms have stronger correlation, compared with older, general technical terms. We have developed a web interface for accessing our dataset and empirical results available at http://comparetrend.appspot.com/. Inspired by our empirical results, we present future directions that can harness Stack Overflow as sampled data for supporting time-aware search and semantic search.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.210","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551996","Google Trends;Stack Overflow;Trend correlation;tag;technology","Computers;Correlation;Google;Java;Market research;Programming;Search engines","Internet;question answering (information retrieval);search engines;software engineering","Google Trends;Stack Overflow;question and answer Web sites;question statistics;search engines;search statistics;semantic search;time-aware search","","","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"Coagmento 2.0: A system for capturing individual and group information seeking behavior","M. Mitsui; C. Shah","Department of Computer Science, Rutgers University, New Brunswick, NJ, USA, 08901","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","233","234","In this demo, we present Coagmento 2.0, a Web-based, open-source platform that provides support for one working in individual or group projects spanning multiple sessions that involve looking for, collecting, and synthesizing information. The system also provides a highly customizable platform for researchers who want to investigate individual and group information seeking behaviors in a lab or a field setting. The demo not only shows back-end components and front-end interaction elements of the system, but also how one could easily configure Coagmento for user studies involving information seeking/retrieval with digital libraries (including the Web).","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559600","CSCW;Collaborative information seeking;exploratory search;information synthesis;interactive search;sense-making","Collaboration;Databases;Libraries;Real-time systems;Servers;Web pages;Web search","Internet;information retrieval;public domain software","Coagmento 2.0;Web-based open-source platform;back-end components;digital libraries;front-end interaction elements;group information seeking behavior;information collection;information retrieval;information synthesis","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"TripleFCA: FCA-Based Approach to Enhance Semantic Web Data Management","S. Albahli; A. Melton","Kent State Univ., Kent, OH, USA","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","1","","625","630","There has been a recent explosion in data as the number of RDF triples increases. With this increase, RDF datasets and their graph relationships become more complex. Accordingly, there is a need to store and handle these huge volumes of triples with highly desired scalability. Therefore, we attempt in this paper to bridge the gaps of the current RDF storage methods in RDBMS by combing the strengths and most sophisticated database physical models with the inferencing techniques that ontology and Formal Concept Analysis (FCA) support. We, thus, aim at analyzing and narrowing the gap between a state-of-the-art method by developing an RDF storage model based on ontologies with the help of FCA clustering solutions for speed and high scalability. Hence, we have proposed a new framework, TripleFCA, to maximize the information retrieval benefits and improve the query response time of RDF triple storages. Our evaluation shows that TripleFCA decreases major bottlenecks of property-table, one of the state-of-the-art RDF storage methods into RDBMS, and yields a much better performance thanks to the benefits of combining ontology and FCA over RDF storage. Our results also demonstrate the weaknesses of property-table and how they can be mitigated.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552081","FCA;Ontology;Relational Database;Semantic Web;Triple Store","Data models;Databases;Lattices;Ontologies;Resource description framework;Scalability","formal concept analysis;information retrieval;ontologies (artificial intelligence);relational databases;semantic Web","FCA clustering;RDBMS;RDF storage method;RDF triple;TripleFCA;formal concept analysis;graph relationship;information retrieval;ontology;query response time;semantic Web data management","","","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"ArchiveSpark: Efficient Web archive access, extraction and derivation","H. Holzmann; V. Goel; A. Anand","L3S Research Center, Appelstr. 9a, 30167 Hanover, Germany","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","83","92","Web archives are a valuable resource for researchers of various disciplines. However, to use them as a scholarly source, researchers require a tool that provides efficient access to Web archive data for extraction and derivation of smaller datasets. Besides efficient access we identify five other objectives based on practical researcher needs such as ease of use, extensibility and reusability. Towards these objectives we propose ArchiveSpark, a framework for efficient, distributed Web archive processing that builds a research corpus by working on existing and standardized data formats commonly held by Web archiving institutions. Performance optimizations in ArchiveSpark, facilitated by the use of a widely available metadata index, result in significant speed-ups of data processing. Our benchmarks show that ArchiveSpark is faster than alternative approaches without depending on any additional data stores while improving usability by seamlessly integrating queries and derivations with external tools.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559568","Big Data;Data Extraction;Web Archives","Benchmark testing;Buildings;Data mining;Distributed databases;Indexes;Metadata;Uniform resource locators","Internet;digital libraries;information retrieval systems;meta data;query processing","ArchiveSpark;Web archive data access;Web archive data derivation;Web archive data extraction;data processing;distributed Web archive processing;metadata index;performance optimizations;query integration;research corpus;standardized data formats;usability improvement","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Provenance Constraints and Attributes Definition in OWL Ontology to Support Machine Learning","M. Pandey; R. Pandey","Amity Inst. of Inf. Technol., Amity Univ., Lucknow, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","1408","1414","The Semantic Web considered an intelligent web is an effective way to retrieve data. Though the semantic data is returned by the semantic web it may lack trust and cannot be suitable for consumption by man or machine without the evaluation of provenance. The integration of Provenance in the Trust layer of Semantic web not only allows for intelligent knowledge retrieval but also leads to retrieving trustworthy data. This can be efficiently achieved if we bring to use the various layers of the Provenance Stack thereby creating valid provenance instances. This paper explores the need for information trustworthiness in OWL Ontology and has deliberated the rules to incorporate trustworthiness so as to develop valid provenance instances by means of the constraints provided in the PROV-CONSTRAINTS layer. The resultant Ontology can thus be used by machines for learning & making semantic inferences.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.334","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546330","Ontology;PROV-Constraints;Provenance Stack;Semantic Web;Trust","Data models;OWL;Ontologies;Semantics;Service-oriented architecture;Vocabulary","information retrieval;knowledge representation languages;learning (artificial intelligence);ontologies (artificial intelligence);semantic Web;trusted computing","OWL ontology;PROV-CONSTRAINTS layer;information trustworthiness;intelligent knowledge retrieval;machine learning;provenance constraints;provenance stack;semantic Web trust layer;semantic data;semantic inferences;trustworthy data retrieval","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"Parallel Erasure Coding: Exploring Task Parallelism in Erasure Coding for Enhanced Bandwidth and Energy Efficiency","H. b. Chen; S. Fu","High-Performance Comput.-Design Group, Los Alamos Nat. Lab., Los Alamos, NM, USA","2016 IEEE International Conference on Networking, Architecture and Storage (NAS)","20160825","2016","","","1","4","Very large data sets within the range of megabytes to terabytes generated daily from checkpoint-and- restart processes are seen in today's scientific simulations. Reliability and durability are two important factors to build an archive storage system. Erasure code based object storage systems are becoming popular choices for archive storage systems due to cost-effective storage space saving schemes and higher fault-resilience capabilities. Both erasure code encoding and decoding procedures involve heavy array, matrix, and table-lookup compute intensive operations. Current solutions of the erasure coding process are based on single process approach which is not capable of processing very large data sets efficient and effectively. In this paper, we address the bottleneck problem of single process erasure encoding by leveraging task parallelism offered by multi-core computers. We add parallel processing capability to the erasure coding process. More specifically, we develop a parallel erasure coding software, called parEC. It explores the MPI run time parallel I/O environment and integrates data placement process for distributing encoded data blocks to destination storage devices. We evaluate the performance of parEC in terms of both encoding throughput and energy efficiency. We also compare the performance of two task scheduling algorithms for parEC. Our experimental results show parEC can significantly reduce the encoding time (i.e., by 74.06%-96.86%) and energy consumption (i.e., by 73.57%-96.86%), and Demand-based Workload Assignment (DBWA) algorithm can a high system utilization (i.e., 95.23%).","","Electronic:978-1-5090-3315-7; POD:978-1-5090-3316-4","10.1109/NAS.2016.7549412","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549412","","Encoding;Multicore processing;Parallel processing;Servers;Software systems;Testing","application program interfaces;checkpointing;durability;energy conservation;information retrieval systems;input-output programs;matrix algebra;multiprocessing programs;parallel processing;software reliability;storage management;table lookup","DBWA;MPI run time parallel I/O environment;archive storage system;checkpoint-and-restart process;demand-based workload assignment;durability;energy efficiency;enhanced bandwidth;matrix;multicore computers;parallel erasure coding;reliability;table-lookup compute intensive operations;task parallelism;very large data sets","","","","","","","8-10 Aug. 2016","","IEEE","IEEE Conference Publications"
"A survey on privacy preserving mining implementing techniques","B. Vishwakarma; H. Gupta; M. Manoria","Department of Computer Science & Engineering, TRUBA Institute of Engg. & IT, Bhopal, India","2016 Symposium on Colossal Data Analysis and Networking (CDAN)","20160919","2016","","","1","5","The large aggregated data to be extracted is stored on the various servers for the effortless and rapid access. Information retrieval from this huge amount of competent data plays crucial role in data mining. But this excerption leads to harm individual privacy of the users, community, etc. So it is required to provide privacy for the sensitive records from the data miners. This paper focus on various approaches implement by the miners for preserving of information at individual level, class level, etc. A detail description with limitation and strength of different techniques of privacy preserving is explained. This paper explicates different evaluation parameters for the analysis of the preserved dataset.","","","10.1109/CDAN.2016.7570874","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7570874","Aggregation;Association Rule Mining;Data Perturbation;Data Swapping;Privacy Preserving Mining","Computer science;Data analysis;Data privacy;Privacy;Probability distribution;Servers","data mining;data privacy;information retrieval","data mining;evaluation parameters;information preservation;information retrieval;large aggregated data extraction;privacy preserving mining technique;sensitive records;user privacy","","1","","","","","18-19 March 2016","","IEEE","IEEE Conference Publications"
"Singing Voice Separation and Pitch Extraction from Monaural Polyphonic Audio Music via DNN and Adaptive Pitch Tracking","Z. C. Fan; J. S. R. Jang; C. L. Lu","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2016 IEEE Second International Conference on Multimedia Big Data (BigMM)","20160818","2016","","","178","185","With the explosive growth of audio music everywhere over the Internet, it is becoming more important to be able to classify or retrieve audio music based on their key components, such as vocal pitch for common popular music. This paper proposes a novel and effective two-stage approach to singing pitch extraction, which involves singing voice separation and pitch tracking for monaural polyphonic audio music. The first stage extracts singing voice from the songs by using deep neural networks in a supervised setting. Then the second stage estimates the pitch based on the extracted singing voice in a robust manner. Experimental results based on MIR-1K showed that the proposed approach outperforms a previous state-of-the-art approach in raw-pitch accuracy. Moreover, the proposed approach has been submitted to the singing voice separation and audio melody extraction tasks of Music Information Retrieval Evaluation eXchange (MIREX) in 2015. The results of the competition shows that the proposed approach is superior to other submitted algorithms, which demonstrates the feasibility of the method for further applications in music processing.","","Electronic:978-1-5090-2179-6; POD:978-1-5090-2180-2","10.1109/BigMM.2016.56","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545018","Audio melody extraction;deep neural networks;multimedia;singing pitch extraction;singing voice separation","Dynamic programming;Feature extraction;Hidden Markov models;Linear programming;Neural networks;Robustness;Time-frequency analysis","audio signal processing;information retrieval;music;neural nets;speech","DNN;Internet;MIR-1K;MIREX;adaptive pitch tracking;audio melody extraction tasks;deep neural networks;monaural polyphonic audio music;music information retrieval evaluation exchange;music processing;raw-pitch accuracy;singing pitch extraction;singing voice separation;supervised setting","","","","","","","20-22 April 2016","","IEEE","IEEE Conference Publications"
"Hierarchical content group detection from different social media platforms using Web link structure","D. Takehara; R. Harakawa; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, N-14, W-9, Kita-ku, Sapporo, 060-0814, Japan","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","479","483","This paper presents a method for hierarchical content group detection from different social media platforms, which can reveal hierarchical structure of content groups. In this paper, content groups are defined as sets of contents with similar topics. Based on the revealed hierarchical structure, our method enables users to efficiently find the desired contents from large amount of contents placed in diversified social media platforms. The main contributions of this paper are twofold. First, effective latent features for comparing the contents placed in different social media platforms can be extracted by the combination use of the correlation between features obtained from different social media platform and the Web link structure. Second, the hierarchical structure of the content groups, which captures their various abstraction levels, can be revealed by hierarchically detecting their content groups. Experimental results on the real-world dataset containing YouTube videos and Wikipedia articles show the effectiveness of our method.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532403","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532403","Hierarchical content group detection;Social media platform;Web link structure;Wikipedia;YouTube","Electronic publishing;Encyclopedias;Feature extraction;Media;Videos;YouTube","Internet;feature extraction;information retrieval;social networking (online)","Web link structure;Wikipedia articles;YouTube videos;hierarchical content group detection;hierarchical structure;latent features;social media platforms","","","","30","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"User activity characterization in a cultural heritage digital library system","C. Suire; A. Jean-Caurant; V. Courboulay; P. Estraillier; J. C. Burie","L3ilaboratory, University of La Rochelle La Rochelle, France","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","257","258","Digital access to large amount of heterogeneous data can create methodological biases regarding the discovery and exploitation of resources, particularly when it comes to Social Sciences. In order to provide relevant adaptivity for social scientists, it is important to fully consider their research practice diversity. To do so, we consider an activity-based approach for researchers' information search behavior. We have also conducted an experiment in a Cultural Heritage use case. The main result shows us that social scientists have the same research behaviors as those observed in exact Sciences.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559612","Cultural Heritage;Humanities;Information Seeking;Task Models;User Behavior;User Modeling","Computers;Context;Cultural differences;Libraries;Portals;Proposals;Search engines","behavioural sciences computing;digital libraries;history;information retrieval;social sciences computing","cultural heritage digital library system;cultural heritage use case;heterogeneous data can;information search behavior;resource discovery;resource exploitation;social sciences;user activity characterization","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Research on the follow-up actions of college students' mobile search","D. Wu; S. Liang","School of Information Management, Wuhan University, Luojia Hill, Wuhan, China, 430072","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","59","62","This paper focuses on the follow-up actions triggered by college students' mobile searches, which involved 30 participants conducting an uncontrolled experiment in fifteen days. We collected the mobile phone usage data by an app called AWARE, and combined with structured diary and interviews to perform a quantitative and qualitative study. The results showed that, there were three categories of follow-up actions and majority of these actions occurred within one hour after the initial search session. We also found that participants often conducted follow-up actions with different apps, and certain information needs triggered more follow-up actions. We finally discussed the characteristics and the causes of these actions, and stated further studies which include comparing follow-up actions triggered by mobile search and that of Web search, and building a model for the follow-up actions.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559565","Follow-up action;Mobile search;Search behavior;User behavior","Google;Information management;Interviews;Mobile communication;Mobile handsets;Vocabulary;Web search","Internet;behavioural sciences computing;information retrieval;mobile computing","AWARE app;Web search;college students mobile search;follow-up actions;interviews;mobile phone usage data collection;search behavior;structured diary;user behavior","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Automatic creation of magazine-page-like social media visual summary for mobile browsing","S. Ma; C. W. Chen","State University of New York at Buffalo, Buffalo, NY, USA","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","469","473","Today, mobile users are struggling with accessing overloading and unstructured social media feeds on the severely constrained mobile display. To overcome the challenges associated with browsing social media feeds on mobile devices, we are developing an innovative scheme to automatically create and synthesize the mixed social media digest (pictures, texts and videos) into a magazine-page-like social media visual summary. Given a set of personalized social media digest, a multi-objective optimization is formulated to organize the digest into visual summary in a 9-block-partition fashion with consideration of informative delivery, aesthetic rules and visual perception principles. Each block will be optimized interactively in terms of size, position and color to best represent the overall social media digest. Extensive evaluation and analysis based on user studies demonstrate that the proposed approach is effective in presenting social media content in a visually appealing and compact way. It is expected that this visual summary will lead to much enhanced user experiences for browsing social media digest on mobile devices.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532401","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532401","Magazine-page design;aesthetically appealing;info maximization;mobile browsing;visual summary","Feeds;Image color analysis;Media;Mobile communication;Videos;Visual perception;Visualization","content management;graphical user interfaces;information retrieval;mobile computing;optimisation;social networking (online);visual perception","aesthetic rule;digest organization;informative delivery;magazine-page-like social media visual summary;mixed social media digest;mobile browsing;mobile device;mobile users;multiobjective optimization;personalized social media digest;pictures;severely constrained mobile display;social media content;social media feed browsing;texts;user experience;videos;visual perception","","","","18","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"STeller: An approach for context-aware story detection using different similarity metrics and dense subgraph mining","M. Zhao; C. Zhang; S. Lu; H. Zhang","Science and Technology on Integrated Information System Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing 100190, China","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","152","157","The real-time information on the Web changes dynamically and surge quickly, which cause considerable difficulty in access to interested information. How to mine hot events, how to analyze the correlation of events and how to organize information structurally are challenging tasks. In this paper, to address these problems, we propose STeller, an approach to mine context-aware story - a series of correlated events. Firstly, we cluster similar pieces of information text into a meme-a piece of information and all its variants. This is also the process of information flow tracking. We view a meme as a fine-grained event. Then we use three novel efficient similarity metrics to measure content similarity and correlation of events. The social stream can be transformed into co-occurrence graph and we define the context-aware story as a novel dense subgraph type called (λ,d)-Clique. Lastly, two corresponding dense subgraph mining algorithms are developed to extract (λ,d)-Clique structure. We also perform detailed experiments on real news data and the results demonstrate the value of our work.","","","10.1109/CSCWD.2016.7565980","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565980","","Correlation;Data mining;Image edge detection;Kernel;Measurement;Probabilistic logic;Semantics","data mining;information retrieval;text analysis","(λ,d)-Clique structure;STeller approach;Web information;co-occurrence graph;content similarity;context-aware story detection;dense subgraph mining;dense subgraph type;events correlation;information text;meme;similarity metrics","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"Support Vector Feature Selection for Early Detection of Anastomosis Leakage From Bag-of-Words in Electronic Health Records","C. Soguero-Ruiz; K. Hindberg; J. L. Rojo-Álvarez; S. O. Skrøvseth; F. Godtliebsen; K. Mortensen; A. Revhaug; R. O. Lindsetmo; K. M. Augestad; R. Jenssen","Department of Teor&#x00ED;a de la Se&#x00F1;al y Comunicaciones, Universidad Rey Juan Carlos, 28943 Madrid, Spain","IEEE Journal of Biomedical and Health Informatics","20160901","2016","20","5","1404","1415","The free text in electronic health records (EHRs) conveys a huge amount of clinical information about health state and patient history. Despite a rapidly growing literature on the use of machine learning techniques for extracting this information, little effort has been invested toward feature selection and the features' corresponding medical interpretation. In this study, we focus on the task of early detection of anastomosis leakage (AL), a severe complication after elective surgery for colorectal cancer (CRC) surgery, using free text extracted from EHRs. We use a bag-of-words model to investigate the potential for feature selection strategies. The purpose is earlier detection of AL and prediction of AL with data generated in the EHR before the actual complication occur. Due to the high dimensionality of the data, we derive feature selection strategies using the robust support vector machine linear maximum margin classifier, by investigating: 1) a simple statistical criterion (leave-one-out-based test); 2) an intensive-computation statistical criterion (Bootstrap resampling); and 3) an advanced statistical criterion (kernel entropy). Results reveal a discriminatory power for early detection of complications after CRC (sensitivity 100%; specificity 72%). These results can be used to develop prediction models, based on EHR data, that can support surgeons and patients in the preoperative decision making phase.","2168-2194;21682194","","10.1109/JBHI.2014.2361688","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6917207","Anastomosis leakage (AL);bag-of-words (BoWs);colorectal cancer (CRC);early detection;electronic health record (EHR);feature selection (FS);kernel entropy;support vector machine (SVM)","Entropy;Feature extraction;Kernel;Probability density function;Support vector machines;Surgery;Vectors","electronic health records;feature selection;information retrieval;learning (artificial intelligence);pattern classification;sampling methods;support vector machines;surgery;text analysis","AL detection;AL prediction;EHR;advanced statistical criterion;bag-of-words model;bootstrap resampling;clinical information;colorectal cancer;complications early detection;early anastomosis leakage detection;elective surgery;electronic health records;free text;health state;high data dimensionality;information extraction;intensive-computation statistical criterion;kernel entropy;leave-one-out-based test;machine learning techniques;medical interpretation;patient history;preoperative decision making phase;robust support vector machine linear maximum margin classifier;simple statistical criterion;support vector feature selection","","0","","","","20141008","Sept. 2016","","IEEE","IEEE Journals & Magazines"
"Semantic roles labeling for reuse in CBR based QA system","W. Suwarningsih; A. Purwarianti; I. Supriana","School of Electronic Engineering and Informatics, Institute Technology Bandung, Indonesia","2016 4th International Conference on Information and Communication Technology (ICoICT)","20160922","2016","","","1","5","Reuse process in CBR (Case-Based Reasoning) cycle is responsible for proposing solutions to a number of new problems from a retrieval process. The aim of this paper is to develop a new scheme to select some cases and solutions that form QA-pairs using Semantic Role Labeling (SRL). In previous studies, the selection process of cases and solutions have been done using named entity and word co-occurrence. However, the result have not satisfaction and achieved an accuracy only 70.13%. This research work is focused on QA-pairs sorting. The sorting method used extracting the rules of sentence structure patterns that have been labeled semantic roles. Based on Indonesian medical Ontology, we use 123 samples of QA-pairs for testing the performance of the system. The results of this study showed a value of 80.15% accuracy.","","","10.1109/ICoICT.2016.7571935","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571935","Indonesian Medical Sentences;QA-pairs;Reuse Solution;Rule Extraction;Semantic Role Labeling","Feature extraction;Labeling;Pattern matching;Semantics;Sociology;Statistics;Syntactics","case-based reasoning;medical computing;ontologies (artificial intelligence);question answering (information retrieval);sorting","CBR based QA system;Indonesian medical ontology;QA-pairs sorting;SRL;case-based reasoning;information retrieval process;named entity;reuse process;semantic role labeling;sentence structure patterns rule extraction;word cooccurrence","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Content selection and curation for web archiving: The gatekeepers vs. the masses","I. Milligan; N. Ruest; J. Lin","University of Waterloo","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","107","110","Any preservation effort must begin with an assessment of what content to preserve, and web archiving is no different. There have historically been two answers to the question “what should we archive?” The Internet Archive's broad entire-web crawls have been supplemented by narrower domain-or topic-specific collections gathered by numerous libraries. We can characterize this as content selection and curation by “gatekeepers”. In contrast, we have witnessed the emergence of another approach driven by “the masses” - we can archive pages that are contained in social media streams such as Twitter. The interesting question, of course, is how these approaches differ. We provide an answer to this question in the context of a case study about the 2015 Canadian federal elections. Based on our analysis, we recommend a hybrid approach that combines an effort driven by social media and more traditional curatorial methods.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559571","","Internet;Libraries;Logic gates;Media;Nominations and elections;Tagging;Twitter","Internet;information retrieval systems;social networking (online)","Canadian federal elections;Internet;Twitter;Web archiving system;content selection;social media streams","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"A time-aware approach for boosting medical records search","J. Zhang; W. Xu; J. Guo","Lab for Pattern Recognition and Intelligent Systems, School of Information and Communications Engineering, Beijing University of Posts and Telecommunications, China","2016 Digital Media Industry & Academic Forum (DMIAF)","20160926","2016","","","99","102","Medical records are collections of documents recording a patient's changing conditions, exhibiting temporal characteristic. Yet previous works on medical records search did not pay attention to it. We propose to model the medical records as sequential data, and utilize the temporal similarity between them to improve the performance of medical records search. In this paper, we propose a Temporal Bag-of-Words model to represent medical records as document sequence. In which framework, we adopt Dynamic Time Warping algorithm to calculate the temporal similarity between sequences. Then a clustering-based combination method is proposed for re-ranking. Experiments on TREC Medical Track data shows the effectiveness of the proposed framework for boosting medical records search.","","","10.1109/DMIAF.2016.7574910","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574910","","Algorithm design and analysis;Bioinformatics;Biological system modeling;Boosting;Clustering algorithms;Data models;Heuristic algorithms","document handling;electronic health records;information retrieval;pattern clustering","TREC Medical Track data;clustering-based combination method;document sequence;dynamic time warping algorithm;medical records search;sequential data;temporal bag-of-words model;temporal similarity;time-aware approach","","","","","","","4-6 July 2016","","IEEE","IEEE Conference Publications"
"An ontology for Juz' Amma based on expert knowledge","N. S. H. A. R. Periamalai; A. Mustapha; A. Alqurneh","Faculty of Computer Science and Information System, Universiti Tun Hussein Onn Malaysia, 86400 Batu Pahat, Johor, Malaysia","2016 7th International Conference on Computer Science and Information Technology (CSIT)","20160825","2016","","","1","5","This paper reports the development of an ontology for Juz' Amma in the Quran manuscript that is designed based on the contextual information support sourced from expert knowledge. The ontology development adopts an existing methology called the Methontology that covers steps from identifying motivation scenarios, formulating the competency questions, development, and evaluation. The ontology was evaluated based on the competency questions determined at the beginning of the development life cycle and the results were promising. The developed ontology is hoped to serve as the domain knowledge for other applications such as the question-answering, dialogue or expert systems.","","Electronic:978-1-4673-8914-3; POD:978-1-4673-8915-0","10.1109/CSIT.2016.7549480","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549480","","Computer science;Conferences;Description logic;Electronic mail;Information systems;Information technology","expert systems;interactive systems;ontologies (artificial intelligence);question answering (information retrieval)","Juz' Amma;Quran manuscript;competency questions;contextual information support;development life cycle;dialogue systems;domain knowledge;expert knowledge;expert systems;methontology;question answering systems","","","","","","","13-14 July 2016","","IEEE","IEEE Conference Publications"
"Elastic stateful stream processing in storm","V. Cardellini; M. Nardelli; D. Luzi","Department of Civil Engineering and Computer Science Engineering, University of Rome Tor Vergata, Italy","2016 International Conference on High Performance Computing & Simulation (HPCS)","20160915","2016","","","583","590","The advent of the Big Data era and the diffusion of Cloud computing have renewed the interest in Data Stream Processing (DSP) applications, which can timely extract useful information from distributed data sources. Due to the unpredictable rate at which the sources may produce data, DSP applications demand high dynamism. Storm has emerged as a widely adopted DSP system, which, although having many desirable features, shows some limitations due to the lack of adaptation capabilities. In this paper, we extend Storm with two mechanisms that support the run-time adaptation of DSP applications. Specifically, we introduce new components that allow automatic elasticity and stateful migration of the application components. The experimental results show the benefits of the newly introduced functionalities that, albeit equipped with proof of concept policies, allow to properly cope with workload variations while improving the resource utilization of the underlying infrastructure.","","Electronic:978-1-5090-2088-1; POD:978-1-5090-2089-8","10.1109/HPCSim.2016.7568388","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7568388","","Computational modeling;Digital signal processing;Distributed databases;Elasticity;Fasteners;Storms;Topology","Big Data;cloud computing;data flow computing;information retrieval","Big Data era;DSP applications;automatic elasticity;cloud computing;data stream processing;distributed data sources;elastic stateful stream processing;information extraction;resource utilization;run-time adaptation;stateful application components migration;storm DSP system","","","","","","","18-22 July 2016","","IEEE","IEEE Conference Publications"
"An answer recommendation algorithm for medical community question answering systems","J. Wang; C. Man; Y. Zhao; F. Wang","College of Automation, Harbin University of Science & Technology, Harbin, Heilongjiang Province, China","2016 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)","20160825","2016","","","139","144","Online medical community question answering (cQA) systems are playing important roles as a supplement of the traditional medical service systems. The answer recommendation service provides guidance to diagnose diseases and brings convenience and valuable reference to users. In this paper, we propose a method to recommend answer for particular questions on medical cQA system. There are three steps for the answer recommendation system, including similar cases retrieval, answers quality estimation and answer recommendation. The proposed algorithm is tested on a dataset collected from online medical community question answering system. The results show a good performance in answer recommendation.","","Electronic:978-1-5090-2927-3; POD:978-1-5090-2928-0; USB:978-1-5090-2926-6","10.1109/SOLI.2016.7551676","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551676","answer quality estimation;data mining;medical community question answering systems;similar cases retrieval","Estimation;Feature extraction;History;Knowledge discovery;Medical diagnostic imaging;Medical services;Training","medical information systems;patient diagnosis;question answering (information retrieval);recommender systems","answer recommendation algorithm;answers quality estimation;disease diagnosis;medical cQA system;medical service systems;online medical community question answering system","","","","","","","10-12 July 2016","","IEEE","IEEE Conference Publications"
"SOLinker: Constructing Semantic Links between Tags and URLs on StackOverflow","W. Mo; J. Zhu; Z. Qian; B. Shen","Sch. of Electron. Inf. & Electr. Eng., Shanghai Jiao Tong Univ., Shanghai, China","2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)","20160825","2016","1","","582","591","Thanks to the strength of crowdsourcing, there is a lot of useful information on StackOverflow, the most popular Question and Answer (Q&A) platform in software engineering area. This information can be treated as numerous URLs (Uniform Resource Locators), which can be categorized into URLs of Q&As and URLs in Q&As. The domain of former ones is StackOverflow itself, while domains of latter ones are miscellaneous, such as some personal blogs and so on. Although each Q&A has been manually assigned tags, relations between URLs and tags are not clear enough. In this paper, we propose SOLinker, a method to build semantic links between various URLs and tags. Firstly, SOLinker identifies proper relations from a predefined relation set between tags and URLs, which is modeled as a text classification problem. Features are extracted from content of Q&A, the URL and the tag list, and classification algorithms are Logistic Regression and Gradient Boosting Decision Tree, depending on the category of URLs. Secondly, there exists a partial tagging problem, which means for a URL in a Q&A, there are only a part of tags of the Q&A relating to the URL. To address this problem, we propose a semantic analysis method to analyze context of this URL and the URL itself from both implicit and explicit aspects. Then SOLinker will infer proper tags by the label propagation technique. Results show that our method is feasible and practical in constructing semantic links between tags and URLs of/in Q&As. In particular, the F-Score of semantic relation identification is around 78%, 5% higher than the other existing method, and F-Score of partial tagging solving is around 88%.","","Electronic:978-1-4673-8845-0; POD:978-1-4673-8846-7","10.1109/COMPSAC.2016.194","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552075","Label Propagation;StackOverflow;Text Classification;URL Classification","Context;Couplings;Data mining;Feature extraction;Semantics;Tagging;Uniform resource locators","Internet;decision trees;gradient methods;pattern classification;question answering (information retrieval);regression analysis;software engineering;text analysis","F-score;Q&A platform;SOLinker;StackOverflow;URL;classification algorithms;gradient boosting decision tree;logistic regression;partial tagging problem;question and answer platform;semantic analysis method;semantic links;semantic relation identification;software engineering;tag list;text classification;uniform resource locators","","","","","","","10-14 June 2016","","IEEE","IEEE Conference Publications"
"Using text mining to locate concepts in execution traces","M. Abdelkader; R. Perez-Castillo; M. Mimoun","University of Dr TaharMoulay & EEDIS, Saida, Algeria","2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)","20160912","2015","","","1","6","Concept location is a key activity during software modernization since it allows maintainers to exactly determine what pieces of source code support a specific concept. When concepts supported by an information system are getting outdated or misaligned, concept location becomes a time-consuming and error-prone task. Moreover, information systems embed significant business knowledge over time that is neither present nor documented anywhere else. For this reason, this paper proposes an approach to locate concepts in execution traces, which contain the actual and current information derived from the execution of the existing code. This approach, based on text segmentation tools, first retrieves and depicts relevant information from the execution traces, and then, it provides a mapping between such information and particular pieces of source code. The main idea of the approach is to take the file of the trace as text where the content of each function (i.e., method) appearing in the trace is a sentence composing the text and then applying the C99 algorithm to segment the text to a thematically coherent segments. The C99 is the state of the art algorithm proposed in text mining community to segment natural text. Each produced segment is composed by a set of functions or methods and bears a concept. Also, under this idea all techniques, proposed by text mining community, for text segmentation will be accessible to the software evolution community. We evaluated our approach on different execution scenarios of JHotDraw and ArgoUML.","","Electronic:978-1-5090-0478-2; POD:978-1-5090-0479-9; USB:978-1-5090-0477-5","10.1109/AICCSA.2015.7507122","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7507122","Concept Location;Execution Traces;Software modernization;Text Mining;Text segmentation","Information systems;Instruments;Software algorithms;Software systems;Text mining;Vocabulary","data mining;information retrieval;software engineering;text analysis","ArgoUML;C99 algorithm;JHotDraw;concept location;execution traces;information mapping;information retrieval;information systems;software evolution community;software modernization;text mining;text segmentation tools","","","","","","","17-20 Nov. 2015","","IEEE","IEEE Conference Publications"
"A new way for semi supervised learning based on data mining for product reviews","M. Patkar; P. Pawar; M. Singh; A. Save","Comp. Engg., VIVA Institute of Technology, Virar, India","2016 IEEE International Conference on Engineering and Technology (ICETECH)","20160919","2016","","","819","824","Rapid increase in internet users along with growing power of online review sites and social media has given birth to Sentiment analysis or Opinion mining, which aims at determining what other people think and comment. Nowadays, several websites are available on which a variety of products are advertised and sold. Prior to making a purchase an online shopper typically browses through several similar products of different brands before reaching a final decision. This seemingly simple information retrieval task actually involves a lot of feature-wise comparison and decision making, especially since all manufacturers advertise similar features and competitive prices for most products. The proposed system presents a semi supervised approach for mining online user reviews to generate comparative feature-based statistical summaries that can guide a user in making an online purchase. In this system sentiment analysis of product reviews gives us not only positive and negative reviews but also gives neutral and constructive opinion where system can suggest some improvement about product also the result is represented in graphical and tabular method.","","","10.1109/ICETECH.2016.7569362","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569362","Data Mining;Feature-Orientation (FO) Table;Opinion Mining;Sentiment analysis;Text Summarizing","Algorithm design and analysis;Conferences;Crawlers;Data mining;Feature extraction;Grammar;Sentiment analysis","Internet;data mining;information retrieval;learning (artificial intelligence);retail data processing;sentiment analysis;social networking (online);statistical analysis","data mining;decision making;feature-based statistical summaries;graphical method;information retrieval;online review sites;online shopper;opinion mining;product reviews;semisupervised learning;sentiment analysis;social media;tabular method","","","","","","","17-18 March 2016","","IEEE","IEEE Conference Publications"
"Text analytics on start-up descriptions","O. Parisot; P. Hitzelberger; Y. Didry; G. Vierke; H. Rieder","Luxembourg Institute of Science and Technology, 41 rue du Brill, Belvaux, Luxembourg","2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)","20160825","2016","","","1","2","In order to analyze the descriptions of various active start-ups, we have developed a web application to retrieve and to analyze available textual data about them. The tool aims at extracting the frequent topics and applying semantic similarity analysis to the start-up descriptions.","","Electronic:978-1-4799-8710-8; POD:978-1-4799-8711-5","10.1109/RCIS.2016.7549372","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549372","","Companies;Data visualization;Java;Libraries;Prototypes;Semantics;Tag clouds","Internet;data mining;information retrieval;text analysis","Web application;active start-ups;frequent topic extraction;semantic similarity analysis;text analytics","","","","","","","1-3 June 2016","","IEEE","IEEE Conference Publications"
"An Ontology-Based Interoperability Solution for Electronic-Identity Systems","W. P. Filho; C. Ribeiro; T. Zefferer","Inst. Super. Tecnico, Univ. de Lisboa, Lisbon, Portugal","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","17","24","Electronic identity (eID) systems enable electronic services and applications to identify users reliably. In an eID system, unique data, i.e. an eID, is assigned to each user. The eID unambiguously identifies the user within the eID system. In most cases, the user's eID is extended by additional attributes such as name, address, or date of birth. The assigned eID and associated attributes are used by electronic services and applications to identify users unambiguously and to obtain required information about these users. In practice, required user attributes potentially need to be exchanged between different eID systems. Unfortunately, each eID system uses its own ontology to represent and organize eIDs and associated attributes. This diversity of ontology definitions prevents an easy exchange of eIDs and attributes between eID systems. To address this issue, we propose an ontology-alignment solution that provides interoperability between eID systems. We show the feasibility of the proposed solution through a Web service (WS) based implementation. This WS enables eID-based applications to retrieve eID attributes from different eID systems. Experiments conducted show that the proposed solution and the resulting WS works with arbitrary ontologies and hence provides interoperability between eID systems.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557431","LSH functions;attributes;eID;interoperability;ontology alignment","Authentication;Electronic government;Electronic mail;Europe;Interoperability;Ontologies;Smart cards","Web services;government data processing;information retrieval;ontologies (artificial intelligence);open systems","WS based implementation;Web service based implementation;address attribute;arbitrary ontologies;date-of-birth attribute;eID attribute retrieval;electronic services;electronic-identity systems;name attribute;ontology-alignment solution;ontology-based interoperability;user attributes;user identification","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"Evaluating the quality of educational answers in community question-answering","L. T. Le; C. Shah; E. Choi","Department of Computer Science, Rutgers University","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","129","138","Community Question-Answering (CQA), where questions and answers are generated by peers, has become a popular method of information seeking in online environments. While the content repositories created through CQA sites have been used widely to support general purpose tasks, using them as online digital libraries that support educational needs is an emerging practice. Horizontal CQA services, such as Yahoo! Answers, and vertical CQA services, such as Brainly, are aiming to help students improve their learning process by answering their educational questions. In these services, receiving high quality answer(s) to a question is a critical factor not only for user satisfaction, but also for supporting learning. However, the questions are not necessarily answered by experts, and the askers may not have enough knowledge and skill to evaluate the quality of the answers they receive. This could be problematic when students build their own knowledge base by applying inaccurate information or knowledge acquired from online sources. Using moderators could alleviate this problem. However, a moderator's evaluation of answer quality may be inconsistent because it is based on their subjective assessments. Employing human assessors may also be insufficient due to the large amount of content available on a CQA site. To address these issues, we propose a framework for automatically assessing the quality of answers. This is achieved by integrating different groups of features - personal, community-based, textual, and contextual - to build a classification model and determine what constitutes answer quality. To test this evaluation framework, we collected more than 10 million educational answers posted by more than 3 million users on Brainly's United States and Poland sites. The experiments conducted on these datasets show that the model using Random Forest (RF) achieves more than 83% accuracy in identifying high quality of answers. In addition, the findings indicate that personal - nd community-based features have more prediction power in assessing answer quality. Our approach also achieves high values on other key metrics such as F1-score and Area under ROC curve. The work reported here can be useful in many other contexts where providing automatic quality assessment in a digital repository of textual information is paramount.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559575","Answer Quality;Community Question-Answering (CQA);Features","Brain modeling;Context;Education;Feature extraction;Internet;Libraries;Quality assessment","educational computing;question answering (information retrieval)","CQA sites;classification model;community question-answering;educational answers;information seeking;online digital libraries;random forest algorithm","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Constructing initial design patterns for online social network-based applications","P. Pongpradit; N. Prompoon","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS)","20160825","2016","","","1","7","Social network websites are currently highly popular. The number of users and amount of data is increasing rapidly. Many researchers or developers that want to use that data for analysis and determining relationships in the data, as well as analyzing behavioral data of such websites' users. Connecting to the application programming interface of each social network website, as well as the properties of the data, has different characteristics, and requires a long time to understand before data requests may be performed and the data may be applied to use. This research presents initial design patterns for social networking applications that can identify the basic requirements of connecting to the application programming interface of social network websites, as well as propose approaches for retrieving information from social networks, as an approach for application.","","Electronic:978-1-5090-0806-3; POD:978-1-5090-0807-0","10.1109/ICIS.2016.7550802","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550802","API;Initial Design Patterns;Online Social Network","Complexity theory;Data analysis;Joining processes;Mashups;Media;Social network services;Unified modeling language","data analysis;information retrieval;object-oriented methods;object-oriented programming;social networking (online)","data analysis;design pattern construction;information retrieval;online social network;social network Web site","","","","","","","26-29 June 2016","","IEEE","IEEE Conference Publications"
"Classification of classic Turkish music makams by using deep belief networks","M. A. K. Sağun; B. Bolat","Yildiz Technical University, Istanbul, Turkey","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","6","Automatic classification of makams from sound data is a challenging yet rarely studied topic. In this work, it is aimed to develop an MIR system which determines a song's makam. To overcome this problem, mel frequency cepstral coefficients were utilized as features. Five classifiers were considered. The best result was obtained by deep belief network as 93.10 which is comparable to the recent works.","","","10.1109/INISTA.2016.7571850","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571850","Classic Turkish Music Makams;Deep Belief Networks;Generalized Regression Neural Network;Mel-Frequency Cepstrum Coefficients;Probabilistic Neural Network;Radial Basis Function Network;Support Vector Machine","Biological neural networks;Instruments;Mel frequency cepstral coefficient;Neurons;Probabilistic logic;Support vector machines;Training","belief networks;information retrieval;music;pattern classification","MIR system;classic Turkish music makams classification;deep belief networks;mel frequency cepstral coefficients;music information retrieval;sound data","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Using WordNet Similarity and Translations to Create Synsets for Ontology-Based Vietnamese WordNet","L. T. Nguyen; K. M. Huynh","Fac. of Sci. & Technol., Hoa Sen Univ., Ho Chi Minh City, Vietnam","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","651","656","It is necessary to build a large-scale online lexical-semantic network for the Vietnamese language because it fosters the research and applications in natural language processing, information retrieval, and other areas. The goal of this research is to propose an approach to create Vietnamese WordNet (VWN) automatically. The WordNet similarity was used in order to improve the accuracy of using English WordNet and translations when creating synsets for VWN. For experiment and evaluation, a sub VWN in IT area was generated by an implemented tool that takes input is a list of IT keywords. We compare the outputs with existing Vietnamese resources. The results show that 86.6% of synsets generated by our method is equivalent to synsets created by human.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.217","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557693","Vietnamese WordNet;ontology;semantic similarity;synset","Buildings;Natural language processing;Ontologies;Semantic Web;Semantics;Taxonomy","information retrieval;natural language processing;ontologies (artificial intelligence)","English WordNet;VWN;Vietnamese WordNet;Vietnamese language;Vietnamese resources;WordNet similarity;create synsets;information retrieval;natural language processing;online lexical semantic network;ontology","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"The Dawn of today's popular domains: A study of the archived German Web over 18 years","H. Holzmann; W. Nejdl; A. Anand","L3S Research Center, Appelstr. 9a, 30167 Hanover, Germany","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","73","82","The Web has been around and maturing for 25 years. The popular websites of today have undergone vast changes during this period, with a few being there almost since the beginning and many new ones becoming popular over the years. This makes it worthwhile to take a look at how these sites have evolved and what they might tell us about the future of the Web. We therefore embarked on a longitudinal study spanning almost the whole period of the Web, based on data collected by the Internet Archive starting in 1996, to retrospectively analyze how the popular Web as of now has evolved over the past 18 years. For our study we focused on the German Web, specifically on the top 100 most popular websites in 17 categories. This paper presents a selection of the most interesting findings in terms of volume, size as well as age of the Web. While related work in the field of Web Dynamics has mainly focused on change rates and analyzed datasets spanning less than a year, we looked at the evolution of websites over 18 years. We found that around 70% of the pages we investigated are younger than a year, with an observed exponential growth in age as well as in size up to now. If this growth rate continues, the number of pages from the popular domains will almost double in the next two years. In addition, we give insights into our data set, provided by the Internet Archive, which hosts the largest and most complete Web archive as of today.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559567","Analysis;Longitudinal;Retrospective;Statistics;Web Dynamics","Business;Crawlers;Games;Indexes;Internet;Metadata;Uniform resource locators","Web sites;information retrieval systems","German Website;Internet archive;Web dynamics","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Framework for Distributed Semantic Web Crawler","N. Kumar; M. Singh","AIIT, Amity Univ., Noida, India","2015 International Conference on Computational Intelligence and Communication Networks (CICN)","20160818","2015","","","1403","1407","Relevant information retrieval from the www mainly depends on the technique and efficiency of a crawler. So crawlers must be capable enough to understand the text and context of a link which they are going to crawl. Anchor text contains a very useful information to know about the target web page. Because knowledge about the target web page content helps the crawlers to decide their preferences of crawling the particular page. In this paper we have presented a design of distributed semantic web crawler capable of crawling both HTML and semantic web pages written using owl/RDf. In our crawler a component called page analyser is used to understand the theme of content of page and context of anchor tag in the page. The output of the page analyser is used to make crawling decisions. Our approach have revealed the great improvement in extracting the information from the links and guide the crawler for more relevant domain specific crawling.","","Electronic:978-1-5090-0076-0; POD:978-1-5090-0077-7","10.1109/CICN.2015.272","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7546329","Distributed System;OWL;RDF;Semantic Web;Semantic web Crawler","Context;Crawlers;Ontologies;Semantic Web;Semantics;Web pages;World Wide Web","hypermedia markup languages;information retrieval;knowledge representation languages;semantic Web","HTML;anchor tag context;anchor text;crawling decisions;crawling preferences;distributed semantic Web crawler;information retrieval;owl-RDf;page analyser;semantic Web pages;target Web page content","","","","","","","12-14 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Sentiment and Interest Based Approach for Product Recommendation","V. Jawa; V. Hasija","Appl. Math. Dept., Delhi Technol. Univ., Delhi, India","2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim)","20160926","2015","","","75","80","The growing popularity of social networks has led to abundant availability of user sentiments, making them a crucial factor in buying decisions, public opinions, and brand reputations. Rise of real-time web has provided an opportunity to utilise time-sensitive data which is available in the form of tweets on public and private Twitter streams, as the basis for product recommendation based on Sentiment analysis. In this paper, we propose a model working on the basics of Interest graph in conjunction with Sentiment analysis to compute the correlation between different entities and provide recommendations, which range from whom to follow on Twitter to what to buy online.","","","10.1109/UKSim.2015.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576524","Algorithm;Interest Graph;Recommendations;Sentiment Analysis;Twitter","Algorithm design and analysis;Analytical models;Data collection;Mathematical model;Sentiment analysis;Twitter","Internet;graph theory;information retrieval;sentiment analysis;social networking (online)","brand reputation;buying decision;interest based approach;interest graph;online buying;private Twitter stream;product recommendation;public Twitter stream;public opinion;real-time Web;sentiment analysis;sentiment based approach;social network;time-sensitive data;tweets;user sentiment","","1","","","","","25-27 March 2015","","IEEE","IEEE Conference Publications"
"The Producer-Consumer Collusion Attack in Content-Centric Networks","A. Luiz Nasserala Pires; I. Monteiro Moraes","Univ. Fed. do Acre, Rio Branco, Brazil","IEEE Latin America Transactions","20160829","2016","14","6","3003","3010","This paper evaluates a denial-of-service attack in information-centric networks based on the Content Centric Networking (CCN) architecture. This attack aims at increasing the content retrieval time. In this attack, both malicious consumers and producers collude, by generating, publishing, and changing content popularity. Malicious contents are stored by intermediate nodes and occupy the cache space that should be occupied by legitimate content. Thus, the probability of a legitimate consumer retrieves content directly from the producer increases as well as the content retrieval time. We evaluate the impact of the attack by varying the number of consumers and producers in collusion, the interest packets rate, and the way malicious contents are requested. Results show if 20% of consumers are malicious and send 500 interests/s each, the content retrieval time experienced by legitimate users increases by 20 times, which shows the effectiveness of the attack.","1548-0992;15480992","","10.1109/TLA.2016.7555288","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555288","CCN;Denial of Service;Future Internet;Security","Computer crime;Internet;Nanoelectromechanical systems;Publishing;Robustness;TCPIP","Internet;cache storage;computer network security;information retrieval","CCN architecture;cache space;content retrieval time;content-centric networks;denial-of-service attack;information-centric networks;interest packet rate;intermediate nodes;producer-consumer collusion attack","","","","","","","June 2016","","IEEE","IEEE Journals & Magazines"
"Continuation Support of Conversation by Recommending Next Topics Relating to a Present Topic","W. Sunayama; Y. Shibata; Y. Nishihara","Sch. of Eng., Univ. of Shiga Prefecture, Hikone, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","168","172","This paper proposes a conversation support system that recommends next topics relating to the present topic. The purpose of the proposed system is to support to continue conversation. The proposed system detects spoken words of two users, makes a log text of conversation. Then, the system extracts the present topic from the log text of conversation, and evaluates the relations between the present topic and next topic candidates. The system chooses next topics and recommends them to the users. The proposed system has an interface of Head Mounted Display (HMD) showing a log text of conversation, a word of the present topic, and words of the next topic. One of the users wearing the HMD can grasp what topic is talked, and choose a next topic from recommended them. The users can continue conversations by talking about recommended topics. Experimental results showed that the proposed system could support to continue conversations. We also found that the proposed system supported users to obtain equal chances to speak.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.90","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557597","","Engines;Internet;Production facilities;Servers;Speech recognition;Systems support;Web search","helmet mounted displays;information retrieval;recommender systems;speech recognition;text analysis","HMD;conversation continuation support;conversation log text;conversation support system;head mounted display;next topic recommendation;spoken word detection","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"MeSH taxonomy-based intrinsic information content method","I. Gabsi; H. Kammoun; H. Bougares; M. Ben Aouicha; I. Amous","Sfax University: MIRACL Laboratory, Sfax, Tunisia","2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","20160922","2016","","","1","7","The biomedical field is an especially relevant domain due to the continuous increase of biomedical textual resources. Recently, the computation of the similarity between concepts has been used to improve the performance of the information retrieval from biomedical sources. Moreover, information content has shown an important role in measuring semantic similarity of concepts. In this paper, we present an information content computing survey with a critical study. Then, we propose a new intrinsic information content computing method. This method attempts to improve the estimation of the semantic likeness between concepts. It exploits the structure of the semantic resource “MeSH”, a reference thesaurus in the biomedical field. Drawing on previous works, for a given concept, the number of its hypernyms, the number of its hyponyms, and, the depth of every hyponym have been considered in our new method. The latter was evaluated and compared with related works by referring to benchmarks widely used in the biomedical field. Experiment shows that our method is able to provide more accurate similarity evaluation and achieves significant performance improvements in terms of correlation coefficient compared to related works.","","","10.1109/INISTA.2016.7571864","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571864","Intrinsic information content;MeSH;semantic similarity","Biomedical measurement;Diseases;Estimation;Integrated circuits;Semantics;Taxonomy;Thesauri","content-based retrieval;information retrieval;text analysis","MeSH taxonomy-based intrinsic information content method;biomedical field;biomedical textual resources;concepts similarity computation;hypernyms;hyponyms;information content computing method;information retrieval;reference thesaurus;semantic likeness","","","","","","","2-5 Aug. 2016","","IEEE","IEEE Conference Publications"
"Big data processing of school shooting archives","M. Farag; P. Nakate; E. A. Fox","Virginia Tech, Blacksburg, VA 24061","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","271","272","Web archives about school shootings consist of webpages that may or may not be relevant to the events of interest. There are 3 main goals of this work; first is to clean the webpages, which involves getting rid of the stop words and non-relevant parts of a webpage. The second goal is to select just webpages relevant to the events of interest. The third goal is to upload the cleaned and relevant webpages to Apache Solr so that they are easily accessible. We show the details of all the steps required to achieve these goals. The results show that representative Web archives are noisy, with 2%-40% relevant content. By cleaning the archives, we aid researchers to focus on relevant content for their analysis.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559619","Big Data Processing;Classification;Digital Libraries;Web Archives","Big data;Cleaning;Feature extraction;HTML;Libraries;Support vector machines","Big Data;Internet;information retrieval systems","Apache Solr;Big Data processing;Web archives;school shooting archives","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"An answerer recommender system exploiting collaboration in CQA services","N. Wang; M. H. Abel; J. P. Barthès; E. Negre","Sorbonne Universit&#x00E9;s, Universit&#x00E9; de Technologie de Compi&#x00E8;gne, CNRS UMR 7253 Heudiasyc, France","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","198","203","Community-based Question Answering (CQA) services are becoming popular as the public gets used to look for help and obtain information. Existing CQA services try to recommend someone for answering new questions. On the other hand, people are allowed to exchange information and experience using various collaborative tools. It would be interesting to combine the two approaches to increase the reliability of recommending an answerer. Thus, relying on semantically modeled traces, we propose a comprehensive approach that recommends an answerer in a collaborative environment. From a global point of view, this approach consists in evaluating users by the performance in the CQA services and the corresponding knowledge sharing activities in which they participated in a collaborative context. By modeling and analyzing users' behavior, we assess the competency of an answerer in a particular collaborative context.","","","10.1109/CSCWD.2016.7565988","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7565988","","Collaboration;Context;Internet;Logistics;Prototypes;Recommender systems;Semantics","groupware;information management;knowledge management;question answering (information retrieval);recommender systems","CQA service;answerer recommender system;collaborative tool;community-based question answering;information exchange;knowledge sharing","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"Topic summarisation on tweets","T. Divyasree; P. K. Sujatha","Department of Information Technology, Madras Institute of Technology, Anna University, Chennai - 600044","2015 Seventh International Conference on Advanced Computing (ICoAC)","20160908","2015","","","1","6","Due to the sheer volume of tweets generated by a micro blog site like Twitter, it is often difficult to summarize the required content of the user or the data analyst to evaluate the stream of Twitter data from tweets in million amount which contain enormous redundancy and amount of noise is large. In an attempt to efficiently summarize the Twitter data and achieve better retrieval of the required topic, this research work focuses on the topic summarization on tweet streams, which produce better performance enhancement when processed in the distributed system. This work enhances the Weighted PageRank algorithm which considers both the Inlink and the Outlink value of the Tweets and Summarises the tweets efficiently and compare it with existing concept of similarity which was concerned with the mathematical cosine formulation. It also presents a timeline generation of tweets which enhance the summarization to analyses the tweet content according to the time. In order to enhance a special feature of Twitter posts, this work includes an effective analysis of performance results, that gives more improvement than the existing system. The experimental results on frequency measure when comparing it with the Weighted PageRank algorithm shows more efficiency than the existing cosine similarity computation.","","","10.1109/ICoAC.2015.7562805","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562805","Big Data;Clustering;Hadoop;Summarisation;Twitter Data","Algorithm design and analysis;Blogs;Clustering algorithms;Decision support systems;Frequency measurement;Information technology;Twitter","Big Data;information retrieval;social networking (online)","Big Data;Twitter data summarization;mathematical cosine formulation;microblog Web site;topic retrieval;topic summarisation;tweet streams;tweets inlink value;tweets outlink value;tweets timeline generation;weighted PageRank algorithm","","","","","","","15-17 Dec. 2015","","IEEE","IEEE Conference Publications"
"A Framework Research of Power Grid Knowledge Recommendation and Situation Reasoning Based on Cloud Computing and CEP","J. Su; Y. Huang; G. Lv; H. Liu; P. Jin","Dept. of Power Distrib. Network, China Electr. Power Res. Inst., Beijing, China","2016 IEEE 3rd International Conference on Cyber Security and Cloud Computing (CSCloud)","20160818","2016","","","79","83","Modern power grid can produce a large amount of data at run time which shows a feature of fragmentation and disordering. Using the method of cloud-based knowledge management to achieve grid data, information retrieval, situation deducing and disaster warning, are important thoughts to be implemented. To solve the challenge, we put forward a software framework including knowledge recommendation and situation inference based on cloud computing and CEP(Complex Event Process). The framework can realize Large-scale analysis and intelligent recommendation for power grid and build reduction rules and models of power grid accident to implement disaster warning through CEP. Also, we show the prototype system.","","Electronic:978-1-5090-0946-6; POD:978-1-5090-0947-3","10.1109/CSCloud.2016.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7545901","Cloud Computing;Knowledge Recommendation;Power Grid;Situation Reasoning;complex event processing","Cloud computing;Computer security;Conferences","cloud computing;emergency management;information retrieval;knowledge management;power engineering computing;power grids;power system security;recommender systems","CEP;cloud computing;cloud-based knowledge management;complex event process;disaster warning;grid data;information retrieval;power grid accident;power grid knowledge recommendation;reduction rules","","","","","","","25-27 June 2016","","IEEE","IEEE Conference Publications"
"Questions and Answers Database Construction for Adaptive Online IRT Testing Systems: Analysis Course and Linear Algebra Course","H. Hirose; M. Takatou; Y. Yamauchi; T. Taniguchi; T. Honda; F. Kubo; M. Imaoka; T. Koyama","Data Sci. Res. Center, Hiroshima Inst. of Technol., Hiroshima, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","433","438","To take care of students who were taught insufficiently in high schools and junior high schools, we have recently established the follow-up program aimed at helping students who need basic learning and aimed at assisting teachers who have to engage in teaching a variety of educational students. The follow-up systems are recognized as a part of the follow-up program, and consist of the learning check testing, follow-up program testing, and collaborative work testing. These testing systems use a large number of structured problem items installed in the database (i.e., item bank). In this paper, we introduce the database system configuration and show how we have constructed the database. The novel aspect is the item registration scheme. The databases were constructed by expertise such as mathematics professors in a way of collaborative work. For one subject teaching in one semester, such as Analysis or Linear Algebra, more than 20 sections are covered, and more than 50 problem items to each section are collected from the contributors.","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557649","adaptive online testing;collaborative work testing;expertise;follow-up program testing;item bank;item contributor;item response theory;learning check testing","Adaptive systems;Collaborative work;Continuous wavelet transforms;Databases;Linear algebra;Testing","Internet;computer aided instruction;database management systems;educational courses;groupware;linear algebra;mathematics computing;question answering (information retrieval);teaching","adaptive online IRT testing systems;analysis course;collaborative work;collaborative work testing;database system configuration;educational students;follow-up program testing;follow-up systems;item registration scheme;junior high schools;learning check testing;linear algebra course;mathematics professors;questions and answers database construction;subject teaching;teaching","","2","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"DBLSTM-based multi-scale fusion for dynamic emotion prediction in music","X. Li; J. Tian; M. Xu; Y. Ning; L. Cai","Key Laboratory of Pervasive Computing, Ministry of Education, Tsinghua National Laboratory for Information Science and Technology (TNList) Department of Computer Science and Technology, Tsinghua University, Beijing, China","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Dynamic Music Emotion Prediction is crucial to the emerging applications of music retrieval and recommendation. Considering the influence of temporal context and hierarchical structure on emotion in music, we propose a Deep Bidirectional Long Short-Term Memory (DBLSTM) based multi-scale regression method. In this method, a post-processing component is utilised for individual DBSLTM output to further enhance the ability of temporal context processing and a fusion component is to integrate the output of all DBLSTM models with different scales. In addition, we investigate how the difference of sequence length between the training and predicting phase affects the performance of DBLSTM. We conduct our experiments on a public database of Emotion in Music task at MediaEval 2015, and the result shows that our method achieves significant improvement when compared with the state-of-art methods.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552956","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552956","Dynamic music emotion prediction;deep bidirectional long-short term memory;fusion;multi-scale;post-processing","Context;Context modeling;Correlation;Data models;Feature extraction;Predictive models;Training","information retrieval;music;regression analysis","DBLSTM;deep bidirectional long short-term memory;dynamic music emotion prediction;hierarchical structure;multiscale fusion;multiscale regression method;music recommendation;music retrieval;temporal context processing","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"MedRec: Using Blockchain for Medical Data Access and Permission Management","A. Azaria; A. Ekblaw; T. Vieira; A. Lippman","Media Lab., Massachusetts Inst. of Technol., Cambridge, MA, USA","2016 2nd International Conference on Open and Big Data (OBD)","20160922","2016","","","25","30","Years of heavy regulation and bureaucratic inefficiency have slowed innovation for electronic medical records (EMRs). We now face a critical need for such innovation, as personalization and data science prompt patients to engage in the details of their healthcare and restore agency over their medical data. In this paper, we propose MedRec: a novel, decentralized record management system to handle EMRs, using blockchain technology. Our system gives patients a comprehensive, immutable log and easy access to their medical information across providers and treatment sites. Leveraging unique blockchain properties, MedRec manages authentication, confidentiality, accountability and data sharing- crucial considerations when handling sensitive information. A modular design integrates with providers' existing, local data storage solutions, facilitating interoperability and making our system convenient and adaptable. We incentivize medical stakeholders (researchers, public health authorities, etc.) to participate in the network as blockchain “miners”. This provides them with access to aggregate, anonymized data as mining rewards, in return for sustaining and securing the network via Proof of Work. MedRec thus enables the emergence of data economics, supplying big data to empower researchers while engaging patients and providers in the choice to release metadata. The purpose of this short paper is to expose, prior to field tests, a working prototype through which we analyze and discuss our approach.","","","10.1109/OBD.2016.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573685","access control;cryptographic protocols;distributed information systems;electronic medical records","Contracts;Cryptography;Databases;History;Interoperability;Peer-to-peer computing;Prototypes","Big Data;authorisation;data aggregation;data mining;data privacy;electronic health records;health care;information retrieval;meta data;records management","EMR handling;MedRec;Proof of Work;accountability;authentication;big data supply;blockchain technology;confidentiality;data aggregation;data anonymization;data economics;data science;data sharing;decentralized record management system;electronic medical records;healthcare;interoperability;local data storage;medical data access;medical information access;medical stakeholder incentivization;metadata;mining reward;network security;permission management;personalization;public health authorities;sensitive information handling;system adaptability;treatment sites","","","","","","","22-24 Aug. 2016","","IEEE","IEEE Conference Publications"
"Multi-sentence compression-construct knowledge using paraphrased text and vertical crawling","A. Kedar; N. Parikh; R. Shah; S. Kurhade","Information Technology Department, Sardar Patel Institute of Technology, Mumbai, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","20160915","2016","","","2367","2370","It is truly said by Michelangelo Antonisoni that “We live in a society that compels us to go on using the concepts, and we no longer know what they mean”. A central challenge in understanding the vital concepts of a thesis lies in the complexity of jargons. Our goal is to build an interactive Web application coupled with a chat interface to make learning or knowledge gaining easier. Thus our Web application consists of two distinct components- text mining to extract data from the corpus and secondly to present data in different dimensions using a web crawler. It features a Learning Autobot which extracts information from the corpus, constructs knowledge and reduces the complexity of jargons hence reformulating the concepts in simplified form.","","","10.1109/WiSPNET.2016.7566565","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566565","jargons;paraphrase;text mining;vertical search;web crawler","Complexity theory;Computational linguistics;Conferences;Engines;Feature extraction;Keyword search;Semantics","Internet;data mining;information retrieval;interactive systems;text analysis","Learning Autobot;Web crawler;chat interface;corpus information extraction;data extraction;interactive Web application;jargon complexity;knowledge construction;multisentence compression;paraphrased text;text mining;vertical crawling","","","","","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"The K-means with mini batch algorithm for topics detection on online news","S. R. Fitriyani; H. Murfi","Department of Mathematics, University of Indonesia, Depok, Indonesia","2016 4th International Conference on Information and Communication Technology (ICoICT)","20160922","2016","","","1","5","Online media is the most important media for accessing a wide range of information, such as news. Nowadays, there are many news agencies publish digital news via online media. The popularity of the online news makes the increasing volume of available news. This leads to the necessity of automated methods for news analysis, i.e. topics detection. One of The topic detection methods is the K-means algorithm. However, this algorithm is slow for big datasets. Therefore, the mini batch approach is used to reduce the computational time. Our experiments show that the computational times of the mini batch approach is much faster for the comparable accuracies.","","","10.1109/ICoICT.2016.7571914","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7571914","K-means algorithm;mini batch;online news;topic detection","Algorithm design and analysis;Clustering algorithms;Clustering methods;Convergence;Internet;Linear programming;Media","electronic publishing;information retrieval;social networking (online);text analysis","K-means algorithm;digital news;minibatch algorithm;news analysis;online media;online news;topic detection","","","","","","","25-27 May 2016","","IEEE","IEEE Conference Publications"
"Information Extraction to improve Link Prediction in scientific social networks","V. Ströde; F. Campos; C. K. Pereira; G. Zimbrão; J. M. Souza","PGCC - Postgraduate Program in Computer Science, UFJF - Federal University of Juiz de Fora, Brazil","2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20160915","2016","","","515","520","Link Prediction is a classic social networks analysis problem. Knowing in advance future actions in social network can help, for example, agents decision. Link Prediction techniques are based on metrics that have different approaches. In this paper, we model a multi-relational scientific social network to assess the impact of content extraction on topological metrics. Thus, a metric composed of topological and semantic approach is proposed to solve link prediction problem. The results were compared with those presented by Katz metric.","","","10.1109/CSCWD.2016.7566043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566043","Information Extraction;Link Prediction;Scientific Social Network","Decision support systems;Lead;Measurement;Semantics;Social network services","information retrieval;social networking (online)","Katz metric;content extraction;information extraction;link prediction technique;multirelational scientific social network;semantic approach;topological approach;topological metrics","","","","","","","4-6 May 2016","","IEEE","IEEE Conference Publications"
"APISENSE (http://apisense.io)","R. Rouvoy","Univ. of Lille, Lille, France","2016 17th IEEE International Conference on Mobile Data Management (MDM)","20160825","2016","2","","61","61","Summary form only given. APISENSE (http://apisense.io) is a crowd-sensing platform that leverages the gathering of field datasets at scale. In particular, APISENSE is designed as a Software-as-a-Service (SaaS) solution that remotely orchestrates crowds of mobile devices to monitor physical events or human behaviours in the wild. Collecting data in the field tends to be a tedious tasks for most of researchers as it requires to spend time, energy and money to develop dedicated mobile apps. The role of APISENSE is therefore to catalyse this process by delivering to the scientific community a comprehensive distributed infrastructure that guarantee both privacy and energy consumption of participants. The applications of APISENSE encompasses case studies in the domains of telecom, smart cities, air quality, or human sciences.","","Electronic:978-1-5090-0883-4; POD:978-1-5090-0884-1","10.1109/MDM.2016.99","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551571","","Conferences;Energy consumption;Mobile communication;Mobile handsets;Monitoring;Privacy;Software as a service","cloud computing;information retrieval","APISENSE platform;SaaS solution;crowdsensing platform;software-as-a-service solution","","","","","","","13-16 June 2016","","IEEE","IEEE Conference Publications"
"Selecting Best Answer: An Empirical Analysis on Community Question Answering Sites","T. P. Sahu; N. K. Nagwani; S. Verma","Department of Information Technology, National Institute of Technology Raipur, Raipur, India","IEEE Access","20160913","2016","4","","4797","4808","A community question answering (CQA) site is a well-known online community, where user interacts on a wide variety of topics. To the best of our knowledge, the selection of a best answer for the question asked on the CQA site is done manually, which is traditional and tedious. In this paper, a model is developed for selecting best answer for the question asked on the CQA site. Instead of taking data related to question-answer only into account as done in manual process, this model takes both question-answer and answerers' data into account, which gives an insight view into the answers given by the experts that is more likely to be selected as the best answer. The presented approach analyzes StackOverflow Q&A posts with at least five answers to extract features for pattern identification using which the best answer is selected for the asked questions based on topic modeling and classifier. To evaluate correctness of the proposed model, a set of parameters are used, such as Receiver Operating Characteristics Area Under Curve, Precision Recall Area Under Curve, Gmean, and Accuracy. Results show that the proposed model is effective in predicting the best answer.","2169-3536;21693536","","10.1109/ACCESS.2016.2600622","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7553439","Classifier;community question answering (CQA);feature identification;online community;statistical analysis;topic modelling","Analytical models;Computational modeling;Feature extraction;Knowledge discovery;Predictive models;Probabilistic logic;Web pages","feature extraction;question answering (information retrieval);statistical analysis","StackOverflow Q&A post;community question answering sites;empirical analysis;feature extraction;pattern identification;receiver operating characteristics area under curve;statistical analysis;topic modelling","","","","","","20160826","2016","","IEEE","IEEE Journals & Magazines"
"Trust-based and privacy-preserving fine-grained data retrieval scheme for MSNs","E. Oriero; K. Rabieh; M. Mahmoud; M. Ismail; E. Serpedin; K. Qaraqe","Department of Electrical & Computer Engineering, Tennessee Tech University, Cookeville, TN, USA","2016 IEEE Wireless Communications and Networking Conference","20160915","2016","","","1","6","In this paper, we propose a trust-based and privacy-preserving fine-grained data retrieval scheme for mobile social networks (MSNs). The scheme enables users to create a log of trusted users who store (or are interested in) some topics related to a subject of interest. A subject is a broad term that can cover many fine-grained topics. In creating logs, we leverage friends-of-friends relationships and transferrable trust concept. Each user trusts its friends and the friends of friends. If a friend is not interested in a subject, he can help his friend in creating the log by linking the friend to his friends without knowing the subject to preserve privacy. In order to reduce the storage and computation overhead, we use Bloom filters to store the topics. A distinctive feature in our scheme is that it can query users who possess a fine-grained topic, rather than querying users who are interested in the broad subject but they may not have the specific topic of interest. We analyze the security and privacy of our scheme and evaluate the communication and computation overhead.","","Electronic:978-1-4673-9814-5; POD:978-1-4673-9815-2","10.1109/WCNC.2016.7564969","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7564969","Data Retrieval;Mobile Social Networks;Trust;privacy preservation","Automobiles;Maintenance engineering;Mobile communication;Privacy;Public key;Web pages","data privacy;data structures;information retrieval;mobile computing;social networking (online);trusted computing","Bloom filters;MSN;fine-grained topic;friends-of-friends relationships;mobile social networks;privacy-preserving fine-grained data retrieval scheme;trust-based data retrieval scheme","","","","","","","3-6 April 2016","","IEEE","IEEE Conference Publications"
"Personalized Service Recommendation for Collaborative Tagging Systems with Social Relations and Temporal Influences","Z. Jiang; A. Zhou; S. Wang; Q. Sun; R. Lin; F. Yang","State Key Lab. of Networking & Switching Technol., Beijing Univ. of Posts & Telecommun., Beijing, China","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","786","789","Personalized service recommendation becomes increasingly essential because of the growing number of services. To enhance the performance of personalized service recommendation in collaborative tagging systems, not only tag information but also time and social relations information should be considered. In this paper, we propose a hybrid method aiming at taking advantage of tag, time and users' social relations information for a preferable service recommendation. We first improve a simple tag-based recommendation method by a time-decay function. Then we develop a temporal social-based recommendation method which analyzes user familiarity and user preference similarity between friends. Based on these two steps we integrate them as a temporal tag-and social-based (TTS) recommendation algorithm. Experiment results indicate that our method outperforms general tag-based and social-based recommendation methods.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.107","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557529","collaborative tagging systems;service recommendation;temporal influences;user relations","Collaboration;Mathematical model;Quality of service;Tagging;Testing;Training data;Weight measurement","information retrieval systems;recommender systems","TTS recommendation algorithm;collaborative tagging systems;personalized service recommendation;social relations;social relations information;social-based recommendation algorithm;tag information;tag-based recommendation method;temporal influences;time-decay function;user familiarity;user preference similarity","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
"A big data based product ranking solution","J. Li; B. Shao; J. Xu; H. Li; Q. Wang","Industry & Solutions Research, IBM Research-China, Diamond building 19-A, Donbeiwang West Road No.8, Beijing, 100193, P.R. China","2016 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)","20160825","2016","","","190","194","Users' online behavior, generated from endpoints of e-commerce website and app, is regarded as big data which can create large business value by mining them to acquire insights of users' preference, inclination and purpose. A good ranking result of product search and product assortment in online category classification can lift user's click rate, increase purchasing conversion rate and improve customer online experience. In this paper, we will introduce an online product based learning to rank model to intelligently learn product ranking. A big data architecture will also be introduced to implement this learning to rank model which analyzes huge amount of users' online behavior.","","Electronic:978-1-5090-2927-3; POD:978-1-5090-2928-0; USB:978-1-5090-2926-6","10.1109/SOLI.2016.7551685","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551685","","Big data;Data models;Feature extraction;Numerical models;Support vector machines;Training;Training data","Big Data;Web sites;behavioural sciences computing;classification;electronic commerce;information retrieval;learning (artificial intelligence);purchasing","Big Data architecture;Big Data based product ranking solution;customer online experience;data mining;e-commerce Web site;e-commerce application;large business value;online category classification;online product based learning;product assortment;product search;purchasing conversion rate;user click rate;user online behavior","","","","","","","10-12 July 2016","","IEEE","IEEE Conference Publications"
"Editing Unfit Questions in Q&amp;A","A. W. Vargo; S. Matsubara","Dept. of Social Inf., Kyoto Univ., Kyoto, Japan","2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","20160901","2016","","","107","112","Community editing is an effective tool for improving contributions in peer production communities like Wikipedia and question-answer (Q&A) communities. However, the mechanisms behind who edits and why is not well understood. Previous studies have focused on the effectiveness of editing and emergent hierarchies in editing communities. What is unknown is how editing is executed in a system that contains gamified motivations for contributing edits. In this paper, we examine participants editing unfit questions on Stack Overflow (SO), a large computer programming Q&A community. The combination of SO's community and reputation system with the dynamics of unfit questions allows us to examine how different actors behave. We find that early edits come from high-reputation users who do not participate as a questioner or answerer, indicating that these users work to retain certain questions. These results suggest that high-reputation user actions can be used to identify bad questions that have archival quality..","","Electronic:978-1-4673-8985-3; POD:978-1-4673-8986-0","10.1109/IIAI-AAI.2016.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557585","Q&amp;A;community standards;editing;gamification","Collaboration;Electronic publishing;Encyclopedias;Informatics;Internet;Production","programming;question answering (information retrieval);social networking (online);social sciences computing","Q&A community;SO community;Wikipedia;community editing;computer programming;question-answer community;reputation system;stack overflow;unfit question editing","","","","","","","10-14 July 2016","","IEEE","IEEE Conference Publications"
"Interplanetary Wayback: The permanent web archive","S. Alam; M. Kelly; M. L. Nelson","Old Dominion University, Department of Computer Science, Norfolk VA, 23529, USA","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","273","274","To facilitate permanence and collaboration in web archives, we built Interplanetary Wayback to disseminate the contents of WARC files into the IPFS network. IPFS is a peer-to-peer content-addressable file system that inherently allows deduplication and facilitates opt-in replication. We split the header and payload of WARC response records before disseminating into IPFS to leverage the deduplication, build a CDXJ index, and combine them at the time of replay. From a 1.0 GB sample Archive-It collection of WARCs containing 21,994 mementos, we found that on an average, 570 files can be indexed and disseminated into IPFS per minute. We also found that in our naive prototype implementation, replay took on an average 370 milliseconds per request.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559620","","File systems;Indexing;Interplanetary;Payloads;Peer-to-peer computing;Prototypes","Internet;information retrieval systems","IPFS network;WARC;archive-it collection;interplanetary wayback;peer-to-peer content-addressable file system;permanent Web archive","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Desiderata for exploratory search interfaces to Web archives in support of scholarly activities","A. Jackson; J. Lin; I. Milligan; N. Ruest","The British Library","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","103","106","Web archiving initiatives around the world capture ephemeral web content to preserve our collective digital memory. In this paper, we describe initial experiences in providing an exploratory search interface to web archives for humanities scholars and social scientists. We describe our initial implementation and discuss our findings in terms of desiderata for such a system. It is clear that the standard organization of a search engine results page (SERP), consisting of an ordered list of hits, is inadequate to support the needs of scholars. Shneiderman's mantra for visual information seeking (“overview first, zoom and filter, then details-on-demand”) provides a nice organizing principle for interface design, to which we propose an addendum: “Make everything transparent”. We elaborate on this by highlighting the importance of the temporal dimension of web pages as well as issues surrounding metadata and veracity.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559570","","Libraries;Market research;Organizations;Prototypes;Standards organizations;Visualization","Internet;information retrieval systems;search engines","SERP;Shneiderman mantra;Web archiving initiatives;collective digital memory;desiderata;ephemeral Web content;exploratory search interfaces;metadata;search engine results page;visual information seeking","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Efficient Data Placement for Improving Data Access Performance on Domain-Wall Memory","X. Chen; E. H. M. Sha; Q. Zhuge; C. J. Xue; W. Jiang; Y. Wang","College of Computer Science, Chongqing University, Chongqing, China","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20160926","2016","24","10","3094","3104","A domain-wall memory (DWM) is becoming an attractive candidate to replace the traditional memories for its high density, low-power leakage, and low access latency. Accessing data on DWM is accomplished by shift operations that move data located on nanowires to read/write ports. Due to this kind of construction, data accesses on DWM exhibit varying access latencies. Therefore, data placement (DP) strategy has a significant impact on the performance of data accesses on DWM. In this paper, we prove the nondeterministic polynomial time (NP)-completeness of the DP problem on DWM. For the DWMs organized in single DWM block cluster (DBC), we present integer linear programming formulations to solve the problem optimally. We also propose an efficient single DBC placement (S-DBC-P) algorithm to exploit the benefits of multiple read/write ports and data locality. Compared with the sequential DP strategy, S-DBC-P reduces 76.9% shift operations on average for eight-port DWMs. Furthermore, for DP problem on the DWMs organized in multiple DBCs, we develop an efficient multiple DBC placement (M-DBC-P) algorithm to utilize the parallelism of DBCs. The experimental results show that the M-DBC-P achieves 90% performance improvement over the sequential DP strategy.","1063-8210;10638210","","10.1109/TVLSI.2016.2537400","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445241","Data placement (DP);domain-wall memory (DWM);optimization;shift operation","Algorithm design and analysis;Magnetic domain walls;Magnetic domains;Magnetic separation;Magnetic tunneling;Nanowires;Silicon","information retrieval;integer programming;integrated memory circuits;linear programming;nanowires;polynomials;walls","DBC;DWM block cluster;M-DBC-P algorithm;S-DBC-P algorithm;access latency;data access performance;domain-wall memory;integer linear programming formulation;multiple DBC placement;nanowire;nondeterministic polynomial time NP-completeness;read/write ports;sequential DP strategy;shift operation;single DBC placement","","2","","","","20160331","Oct. 2016","","IEEE","IEEE Journals & Magazines"
"MemGator — A portable concurrent memento aggregator: Cross-platform CLI and server binaries in Go","S. Alam; M. L. Nelson","Department of Computer Science, Old Dominion University, Norfolk, Virginia - 23529 (USA)","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","243","244","The Memento protocol makes it easy to build a uniform lookup service to aggregate the holdings of web archives. However, there is a lack of tools to utilize this capability in archiving applications and research projects. We created MemGator, an open source, easy to use, portable, concurrent, cross-platform, and self-documented Memento aggregator CLI and server tool written in Go. MemGator implements all the basic features of a Memento aggregator (e.g., TimeMap and TimeGate) and gives the ability to customize various options including which archives are aggregated. It is being used heavily by tools and services such as Mink, WAIL, OldWeb. today, and archiving research projects and has proved to be reliable even in conditions of extreme load.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559605","Aggregator;MemGator;Memento;Web Archiving","Aggregates;Computer science;Concurrent computing;Protocols;Reliability;Servers;Stress","Internet;information retrieval systems","CLI;MemGator;Web archives;archiving research projects;portable concurrent memento aggregator","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Analyzing and predicting knowledge of contributors in community question answering services","M. R. Sumalatha; N. A. Priyanka","Department of Information Technology, Anna University, Chennai, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","20160915","2016","","","2473","2477","Online education has become increasingly important as Internet technology continuously evolves various endeavours like info please, Wikipedia which helps to express and explore the information to the user. This web support provides the flexibility to improve and update their skill sets. Q&A sites provide a rapid growth that augments a regular links between the users. After a study, the knowledge Identity of user's shares only a few knowledge categories- this is due to lack of identification of individual expertise's area. To enhance the online social community service the intelligent contributor and their expertise are to be predicted. This collective knowledge share help the user to delivers the most accurate results. This approach automatically increase the adaption of more powerful friendship selection[7], identify the best and worst contributor for the question & reduce the spam in sharing when there is no desirable result. While analyzing the user's expertise, sharing and providing suggestion [9] to the user this improves the Q&A sites aspect and it enhances the Interaction Bridge and leverage. This method of social media knowledge thus improves user performance in Q&A services.","","","10.1109/WiSPNET.2016.7566588","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566588","Interaction Bridge;Q&A-Question and answering;Social Networks;knowledge sharing","","question answering (information retrieval);social networking (online)","community question answering services;online education;online social community service","","","","","","","23-25 March 2016","","IEEE","IEEE Conference Publications"
"Intelligent question answering system based on Artificial Neural Network","A. Ansari; M. Maknojia; A. Shaikh","Dept. of Computer Engineering, M.H. Saboo Siddik College of Engineering, Mumbai, India","2016 IEEE International Conference on Engineering and Technology (ICETECH)","20160919","2016","","","758","763","The ability of the machine to infer knowledge from the user documents can be tested based on its ability to answer the question asked. Conventional Artificial Neural Network (ANN) models for knowledge extraction only answer to the questions which are simple and objective as they don't analyze the questions and don't try to understand what really the content of document mean. The proposed question answering system (QAS) uses deep cases along with ANN to understand the contents of the documents. We divide the sentences of natural language into knowledge units and assign deep case to each word to improve the quality of knowledge extraction.","","","10.1109/ICETECH.2016.7569350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569350","Artificial Neural Network;NLP;Question Answering System","Artificial neural networks;Biological neural networks;Computers;Conferences;Knowledge engineering;Natural language processing","document handling;natural language processing;neural nets;question answering (information retrieval)","ANN;QAS;artificial neural network;intelligent question answering system;knowledge extraction;knowledge units;natural language sentences;user document contents","","","","","","","17-18 March 2016","","IEEE","IEEE Conference Publications"
"New Joint Dual Mobile Service Discovery-Exposure Model using Bipartite Graph","W. El Ayeb; Z. Choukair","Higher School of Communications of Tunis, Mediatron Lab, Tunisia","2015 5th International Conference on Communications and Networking (COMNET)","20160915","2015","","","1","8","IMS (IP Multimedia Subsystem) presents a variety of services and features to meet the needs and expectation of subscribers. This variety of choices presents risks of retrieving non oriented services while responding to subscriber request. This may be due to similarities between services and to the huge amount of available services. In addition to service information, it is possible to extract and explore subscriber information in IMS network. Thus, it becomes interesting to consider, besides of request details, subscriber profile information in service discovery process. This paper presents an overview of our model and its mechanism based upon IMS architecture which provides service discovery combined with proactive service exposure to better respond to subscribers' needs and expectations. The results show improvement of usual state of the art models on several axes.","","","10.1109/COMNET.2015.7566616","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566616","Hungarian algorithm;IMS;Service discovery;bipartite graph;proactive service exposure;subscriber profile","Bipartite graph;Data mining;Libraries;Protocols;Quality of service;Semantics;Servers","IP networks;graph theory;information retrieval;mobile computing;multimedia systems","IMS network;IP multimedia subsystem;bipartite graph;joint dual mobile service discovery-exposure model;proactive service exposure;subscriber information exploration;subscriber information extraction","","","","","","","4-7 Nov. 2015","","IEEE","IEEE Conference Publications"
"Asymmetric distance for spherical hashing","Z. Weng; W. Yao; Z. Sun; Y. Zhu","Communication and Information Security Lab, Institute of Big Data Technologies, Shenzhen Graduate School, Peking University","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","206","210","Usually, most of hashing methods for information retrieval have a two-step procedure, embedding the data into a low-dimensional intermediate space and then quantizing them into binary codes. In the hyperplane-based hashing methods, the distance between the data in the intermediate space can replace the Hamming distance to improve the retrieval accuracy. In this paper, a novel asymmetric distance for the hypersphere-based method is proposed to improve the accuracy of similarity search. By showing that the distance in the intermediate space can approximate the Euclidean distance between the data points, more useful information can be taken to improve the retrieval accuracy. According to the characteristics of the hypersphere-based hashing method, various asymmetric distance models are developed and described. Our experiments with two datasets have demonstrated that the proposed method can improve the retrieval accuracy of the hypersphere-based hashing methods significantly and achieve the state-of-the-art recall performance.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532348","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532348","Hashing;asymmetric distance;similarity search","Binary codes;Computational modeling;Data models;Euclidean distance;Loss measurement;Probability;Search problems","Hamming codes;cryptography;information retrieval","Euclidean distance;binary codes;hamming distance;hyperplane-based hashing methods;hypersphere-based method;information retrieval;low-dimensional intermediate space;retrieval accuracy improvement;spherical hashing;two-step procedure","","","","16","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"Improving similar document retrieval using a recursive pseudo relevance feedback strategy","K. Williams; C. L. Giles","Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802, USA","2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL)","20160905","2016","","","275","276","We present a recursive pseudo relevance feedback strategy for improving retrieval performance in similarity search. The strategy recursively searches on search results returned for a given query and produces a tree that is used for ranking. Experiments on the Reuters 21578 and WebKB datasets show how the strategy leads to a significant improvement in similarity search performance.","","Electronic:978-1-4503-4229-2; POD:978-1-5090-5254-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559621","","Computer science;Libraries;Mathematical model;Search problems;Testing;Text analysis","document handling;information retrieval;trees (mathematics)","Reuters 21578;WebKB datasets;recursive pseudo relevance feedback strategy;similarity search","","","","","","","19-23 June 2016","","IEEE","IEEE Conference Publications"
"Online self-organizing hashing","J. Chen; Y. Li; H. Lu","Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Department of Computer Science and Engineering, Shanghai Jiao Tong University, P.R. China","2016 IEEE International Conference on Multimedia and Expo (ICME)","20160829","2016","","","1","6","Hashing for similarity search in large scale data has become an increasingly popular technique. K-means Hashing (KMH) has been proven effective because of the benefits of adaptive k-means quantization. However, KMH is a batch-based learning model requiring high time and storage complexities, which makes it hard to load large scale data into memory to train and deal with streaming data. To address this problem, in this paper we propose an online hashing method using Self-Organizing Map (SOM) algorithm, named as Online Self-Organizing Hashing (SOH). Specifically, we map the training data to an affinity preserving hyper-cube with each vertex assigned a binary code using a SOM alike algorithm. After training, a new data point is quantized into a vertex of the hyper-cube and encoded into related binary code. Experimental results demonstrate that SOH has better or comparable retrieval performance to various state-of-the-art hashing methods while simultaneously requiring rather low computational complexity and storage space.","","Electronic:978-1-4673-7258-9; POD:978-1-4673-7259-6; USB:978-1-4673-7257-2","10.1109/ICME.2016.7552960","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552960","Hashing;Self-Organizing Map;Unsupervised Learning","Binary codes;Hamming distance;Image color analysis;Indexes;Neurons;Quantization (signal);Self-organizing feature maps","data handling;file organisation;information retrieval;learning (artificial intelligence);self-organising feature maps","K-means hashing;KMH;SOM algorithm;SOM alike algorithm;adaptive k-means quantization;affinity preserving hypercube;batch-based learning model;binary code;computational complexity;data point quantization;hypercube vertex;large scale data;online SOH;online hashing method;online self-organizing hashing;retrieval performance;self-organizing map;similarity search;storage complexity;storage space;streaming data;time complexity;training data mapping","","","","","","","11-15 July 2016","","IEEE","IEEE Conference Publications"
"Two phase enhancing replica selection in cloud storage system","M. Xue; J. Shen; X. Guo","The Information Engineering University, Zhengzhou, Henan, 450000, China","2016 35th Chinese Control Conference (CCC)","20160829","2016","","","5255","5260","Data replica selection is an important issue in the cloud storage system, which has been widely studied. The local cache file is an effective method to reduce the file request time. To solve local cache methods' superabundant consumption of hard disk space and tackle user's various QoS preference, we proposed a dynamic intelligent replica selection algorithm (named 2PhaseEnhencing algorithm) which reduce file request time in two phases. The proposed algorithm reduce catalog search time in the first phase using a local file that records the historical file request of each user and select the best site with highest score according to user's QoS and the context of the network in the second phase. The simulation experiment in cloudsim conclusively demonstrate the proposed algorithm can efficiently reduce file average request time versus two traditional methods.","","Electronic:978-9-8815-6391-0; POD:978-1-5090-0910-7","10.1109/ChiCC.2016.7554173","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554173","Cloud Storage System;CloudSim;Data Replica;Replica Selection","Algorithm design and analysis;Bandwidth;Cloud computing;Electronic mail;Heuristic algorithms;Prediction algorithms;Quality of service","cloud computing;information retrieval;quality of service;storage management","QoS preference;catalog search time;cloud storage system;cloudsim;data replica selection;dynamic intelligent replica selection algorithm;file request time;hard disk space;two phase enhancing replica selection","","","","","","","27-29 July 2016","","IEEE","IEEE Conference Publications"
"Recommendations Based on LDA Topic Model in Android Applications","T. Pan; W. Zhang; Z. Wang; L. Xu","Sch. of Comput. Sci. & Technol., Nanjing Univ. of Posts & Telecommun., Nanjing, China","2016 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)","20160922","2016","","","151","158","With the popularity of smart phones, mobile applications have become an essential element in people's lives. Wherever you are, the Android market can allow people to download these applications. When you open Android mobile phone market in a mobile application program interface, we can see not only the application content presentation but also other information. The user can also see the scoring for this application, comments and so on. The text describes the application content information and user reviews, no more than 200 words, the contents of which are closely related to mobile applications. How to use these text data to obtain valuable information for the users has been an important research field of data mining, it is also the focus of this study. The topics of different mobile applications are the summary of their contents. This generalization to some extent reflects the different mobile application content core idea. Therefore mobile applications relating to mining user interest analysis has important significance, the results relating to mining can provide data support for topic-based personalized recommendation applications. This article extracts the contents and users' descriptions from a real Android Market dataset, and builds a new topic model called combineLDA to analyze different topics of each mobile application. By combineLDA model we can analyze the topic probability distribution of each mobile application, and then we can calculate the similarity and recommend to users with high similarity applications.","","","10.1109/QRS-C.2016.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573737","Android mobile phone market;combineLDA;mining theme;personalized recommendations;similarity calculation;users' descriptions","Conferences;Security;Software quality;Software reliability","Android (operating system);data mining;information retrieval;mobile computing;smart phones;statistical distributions;text analysis","Android Market dataset;Android application;Android market;LDA topic model based recommendation;application content information;application content presentation;combineLDA;data mining;high similarity application;mobile application program interface;smart phones;topic probability distribution;topic-based personalized recommendation application;user description;user interest analysis mining;user review","","","","","","","1-3 Aug. 2016","","IEEE","IEEE Conference Publications"
"An ontology for Western Saharan manuscripts","M. L. Diakité; B. B. Markhoff; A. O. Boubacar","D&#x00E9;partement de Math&#x00E9;matiques et Informatique, FST, USTM, Nouakchott, Mauritanie","2016 International Conference on Digital Economy (ICDEc)","20160908","2016","","","60","67","As more efforts are performed to digitize Western Saharan manuscripts, for preserving the memory they represent, the need to be able to work on these digitized materials naturally grows. Beyond cataloguing, an ontology is the basis to provide to researchers new tools for retrieving and integrating these knowledge sources. In this paper, we present an ontology describing West-Saharan manuscripts. We first precise the domain and the purposes, then we illustrate each step of the ontology's building, from experts and local resources to its alignment with well-established reference ontologies, including its automatic enrichment from existing thesaurus. This incremental process may be reused in other projects.","","CD-ROM:978-1-5090-1186-5; Electronic:978-1-5090-2230-4; POD:978-1-5090-2231-1","10.1109/ICDEC.2016.7563146","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7563146","Ancient Manuscript;Ontology Design;Semantic Web;Thesaurus","Libraries;Ontologies;Optical character recognition software;Semantic Web;Standards;Thesauri","history;information retrieval;ontologies (artificial intelligence);semantic Web","Western Saharan manuscripts;digitized materials;knowledge source integration;knowledge source retrieval;ontology;thesaurus","","","","","","","28-30 April 2016","","IEEE","IEEE Conference Publications"
"Keyword based searching in social networks","Z. Nayyar; N. Hashmi; N. Rafique; K. Mahmood","Department of Computer Engineering, National University of Sciences and Technology, Islamabad, Pakistan","2016 SAI Computing Conference (SAI)","20160901","2016","","","701","705","The main purpose of analyzing the social network data is to observe the behaviors and trends that are followed by people. How people interact with each other, what they usually share, what are their interests on social networks, so that analysts can focus new trends for the provision of those things which are of great interest for people so in this paper an easy approach of gathering and analyzing data through keyword based search in social networks is examined using NodeXL and data is gathered from twitter in which political trends have been analyzed. As a result it will be analyzed that, what people are focusing most in politics.","","Electronic:978-1-4673-8460-5; POD:978-1-4673-8461-2","10.1109/SAI.2016.7556058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556058","NodeXL;keyword searching;social networks;twitter","Computers;Databases;Keyword search;Market research;Media;Social network services;Visualization","information retrieval;social networking (online)","NodeXL;Twitter;keyword based searching;political trend;social network","","","","","","","13-15 July 2016","","IEEE","IEEE Conference Publications"
"A semantic approach for implicit topical term identification and ranking","Sivaranjani M. S.; Sunitha R.","Department of Computer Science, Pondichery University, India","2016 IEEE International Conference on Engineering and Technology (ICETECH)","20160919","2016","","","284","288","Opinion mining is the process of retrieving the opinion evidences from the reviews and finding their polarity such as positive, negative. Topical term mining enhances the opinion mining in which topical terms have to be extracted along with opinion evidences. Topical terms are specific attribute or quality of a topic. This paper proposes an approach for topical term mining. It aims to assist the users in decision making utilizing the score table. Score table comprises the topical terms of a specific topic along with its positive, negative scores and neutral counts individually. Proposed work incorporates the ontology for identifying implicit topical terms and the variation of maximum opinion score algorithm for finding the polarity. Goals of this approach are 1) to improve the identification of implicit topical terms using ontology 2) to provide accurate estimation of sentiment polarity.","","","10.1109/ICETECH.2016.7569260","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569260","aspect mining;feature mining;ontology;opinion polarity","Conferences;Databases;Entertainment industry;Motion pictures;Ontologies;Semantics;Tagging","data mining;decision making;information retrieval;ontologies (artificial intelligence);sentiment analysis","decision making;implicit topical term identification;implicit topical term ranking;maximum opinion score algorithm;negative reviews;neutral counts;ontology;opinion evidence retrieval;opinion mining;positive reviews;score table;sentiment polarity;topical term mining","","","","","","","17-18 March 2016","","IEEE","IEEE Conference Publications"
"Secure data storage structure and privacy-preserving mobile search scheme for public safety networks","H. Ghafghazi; A. ElMougy; H. T. Mouftah; C. Adams","Department of Electrical Engineering and Computer Science, University of Ottawa","2016 IEEE Wireless Communications and Networking Conference","20160915","2016","","","1","7","In a Public Safety (PS) situation, agents may require critical and personally identifiable information. Therefore, not only does context and location-aware information need to be available, but also the privacy of such information should be preserved. Existing solutions do not address such a problem in a PS environment. This paper proposes a framework in which anonymized Personal Information (PI) is accessible to authorized public safety agents under a PS circumstance. In particular, we propose a secure data storage structure along with privacy-preserving mobile search framework, suitable for Public Safety Networks (PSNs). As a result, availability and privacy of PI are achieved simultaneously. However, the design of such a framework encounters substantial challenges, including scalability, reliability of the data, computation and communication and storage efficiency, etc. We leverage Secure Indexing (SI) methods and modify Bloom Filters (BFs) to create a secure data storage structure to store encrypted meta-data. As a result, our construction enables secure and privacy-preserving multi-keyword search capability. In addition, our system scales very well, maintains availability of data, imposes minimum delay, and has affordable storage overhead. We provide extensive security analysis, simulation studies, and performance comparison with the state-of-the-art solutions to demonstrate the efficiency and effectiveness of the proposed approach. To the best of our knowledge, this work is the first to address such issues in the context of PSNs.","","Electronic:978-1-4673-9814-5; POD:978-1-4673-9815-2","10.1109/WCNC.2016.7564866","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7564866","Data Availability;Privacy;Public Safety Network","Authorization;Cloud computing;Delays;Encryption;Safety;Servers","data privacy;data structures;indexing;information retrieval;mobile computing","BF;Bloom filters;PI;PS situation;PSN;SI methods;personal information;privacy-preserving mobile search scheme;privacy-preserving multi-keyword search capability;public safety networks;secure data storage structure;secure indexing methods","","","","","","","3-6 April 2016","","IEEE","IEEE Conference Publications"
"HyperLink: Virtual Machine Introspection and Memory Forensic Analysis without Kernel Source Code","J. Xiao; L. Lu; H. Wang; X. Zhu","Boise State Univ., Boise, ID, USA","2016 IEEE International Conference on Autonomic Computing (ICAC)","20160922","2016","","","127","136","Virtual Machine Introspection (VMI) is an approach to inspecting and analyzing the software running inside a virtual machine from the hypervisor. Similarly, memory forensics analyzes the memory snapshots or dumps to understand the runtime state of a physical or virtual machine. The existing VMI and memory forensic tools rely on up-to-date kernel information of the target operating system (OS) to work properly, which often requires the availability of the kernel source code. This requirement prevents these tools from being widely deployed in real cloud environments. In this paper, we present a VMI tool called HyperLink that partially retrieves running process information from a guest virtual machine without its source code. While current introspection and memory forensic solutions support only one or a limited number of kernel versions of the target OS, HyperLink is a one-for-many introspection and forensic tool, i.e., it supports most, if not all, popular OSes regardless of their versions. We implement both online and offline versions of HyperLink. We validate the efficacy of HyperLink under different versions of Linux, Windows, FreeBSD, and Mac OS X. For all the OSes we tested, HyperLink can successfully retrieve the process information in one minute or several seconds. Through online and offline analyses, we demonstrate that HyperLink can help users detect real-world kernel rootkits and play an important role in intrusion detection. Due to its version-agnostic property, HyperLink could become the first introspection and forensic tool that works well in autonomic cloud computing environments.","","Electronic:978-1-5090-1654-9; POD:978-1-5090-1655-6","10.1109/ICAC.2016.46","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7573124","Memory Forensics;Process Linked List;Virtual Machine Introspection","Cloud computing;Data structures;Forensics;Kernel;Layout;Linux;Virtual machining","Linux;cloud computing;digital forensics;information retrieval;operating system kernels;virtual machines","FreeBSD;Hyperlink;Linux;Mac OS X;VMI;Windows;autonomic cloud computing environments;dumps analysis;hypervisor;intrusion detection;kernel versions;memory forensic analysis;memory snapshot analysis;operating system;real-world kernel rootkit detection;running process information retrieval;runtime state;software analysis;software inspection;version-agnostic property;virtual machine introspection","","","","","","","17-22 July 2016","","IEEE","IEEE Conference Publications"
"Simple and effective visual question answering in a single modality","Y. Lin; Z. Pang; Y. Li; D. Wang","Zhejiang University, College of Computer Science, Hangzhou, P. R. China","2016 IEEE International Conference on Image Processing (ICIP)","20160819","2016","","","2276","2280","Visual question answering (VQA) comes as a result of great development in computer vision and natural language processing, which requires deep understanding of images and questions and effective integration of them. Current works on VQA simply concatenated visual and textual features or compared them via dot product, which were unable to eliminate the semantic difference between them. We argue to transfer VQA problem into a single modality and propose a simple and effective baseline method, utilizing Long Short-Term Memory (LSTM) properties to filter particular information specified by questions in the generic descriptions of the image. We provide thorough analysis and extensive experiments on VQA benchmark dataset to discuss performance of different methods and prove the effectiveness of our proposed method.","","Electronic:978-1-4673-9961-6; POD:978-1-4673-9962-3","10.1109/ICIP.2016.7532764","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532764","Feature Representation;Long Short-Term Memory;Visual Question Answering","Benchmark testing;Encoding;Knowledge discovery;Natural languages;Semantics;Training;Visualization","computer vision;natural language processing;question answering (information retrieval)","LSTM;VQA benchmark dataset;VQA problem;computer vision;dot product;long short-term memory;natural language processing;single modality;textual features;visual question answering","","","","30","","","25-28 Sept. 2016","","IEEE","IEEE Conference Publications"
"User Attribute Inference in Directed Social Networks as a Service","B. S. Vidyalakshmi; R. K. Wong; C. H. Chi","Univ. of New South Wales, Sydney, NSW, Australia","2016 IEEE International Conference on Services Computing (SCC)","20160901","2016","","","9","16","Social networking has become a frequent activity with many users having accounts on multiple social networking sites. Profile attribute inference has gained popularity due to its usefulness in applications such as link prediction and recommender systems. This paper proposes to infer ego user attributes, by propagating the known attribute values of followers or followings within certain circles. With the ability to follow or be followed by any user, the possibility of many weak links being formed is high. We utilize tie-strength to address this and differentiate each users' influence in the ego user attribute inference. We show that our approach based on followers sub-network, following sub-network and all links sub-network yields better accuracy than friends sub-network, which is the converted undirected network obtained from a directed social network. We conduct extensive experiments and achieve better accuracy than the previous best method for attribute inference.","","Electronic:978-1-5090-2628-9; POD:978-1-5090-2629-6","10.1109/SCC.2016.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7557430","Attribute inference;Privacy;Social networks","Australia;Employment;Facebook;Privacy;Recommender systems;Twitter","inference mechanisms;information retrieval;recommender systems;social networking (online)","directed social network as a service;ego user attribute inference;follower attribute values;follower subnetwork;friends subnetwork;link prediction;links subnetwork;recommender system;social networking sites;tie-strength","","","","","","","June 27 2016-July 2 2016","","IEEE","IEEE Conference Publications"
