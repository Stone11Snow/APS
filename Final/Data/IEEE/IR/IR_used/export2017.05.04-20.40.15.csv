"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=6394918,6405343,6395197,6406818,6406391,6395003,6396036,6353544,6395381,6392116,6392667,6391727,6392055,6081863,6385109,6385216,6385149,6227347,6378148,6377730,6375185,6375419,6359023,6359475,6359683,6359705,6354356,6340249,6347797,6341547,6143910,6349496,6337094,6337098,6334963,5936066,6329884,6327419,6327429,6327290,6322753,6322542,6320289,6320318,6320539,6243190,6313727,6308943,5989838,6305919,6308038,6303017,6303063,6299999,6295826,6288292,6287917,6287820,6288387,6287832,6263120,6288299,6288065,6285082,6285012,6266272,6269402,6268100,6269761,6268624,6268520,6242372,6251172,6205337,6261957,6261955,6213086,6257618,6258512,6245781,5887334,6138865,6240488,6193081,6240487,6175895,6234417,6234372,6234145,6227970,6142100,6223020,6221807,6220367,6216614,6216610,6215567,6216656,6217475,6216662",2017/05/04 20:40:15
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"TraceME: Traceability Management in Eclipse","G. Bavota; L. Colangelo; A. De Lucia; S. Fusco; R. Oliveto; A. Panichella","Univ. of Salerno, Fisciano, Italy","2012 28th IEEE International Conference on Software Maintenance (ICSM)","20130110","2012","","","642","645","In this demo we present TraceME (Traceability Management in Eclipse), an Eclipse plug-in, that supports the software engineer in capturing and maintaining traceability links between different types of artifacts. A comparative analysis of the functionalities of the tools supporting traceability recovery highlights that TraceME is the more comprehensive tool for supporting such a critical activity during software development.","1063-6773;10636773","Electronic:978-1-4673-2312-3; POD:978-1-4673-2313-0","10.1109/ICSM.2012.6405343","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6405343","Information Retrieval;Traceability Management","Engines;Information retrieval;Large scale integration;Software maintenance;Visualization;XML","object-oriented programming;program diagnostics;software maintenance;software management;software reusability","Eclipse plug-in;TraceME;code component reusability;impact analysis;program comprehension;software artifacts;software development;software maintenance;traceability link capture;traceability link maintenance;traceability management;traceability recovery highlights","","1","","13","","","23-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Interactive visualization of the social network of research collaborations","M. Alsukhni; Y. Zhu","Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, Canada","2012 IEEE 13th International Conference on Information Reuse & Integration (IRI)","20120917","2012","","","247","254","Social networks have been evolving over the past few years, leading to a rapid increase in the number and complexity of relationships among their entities. In this paper, we focus on a large scale dataset known as the Digital Bibliography and Library Project (DBLP), which contains information on all publications that have been published in computer and information science related journals and conference proceedings. We model the DBLP dataset as a social network of research collaborations. DBLP is a structured and dynamic dataset stored in the XML file format; it contains over 850,000 authors and 2 million publications and the resulting collaboration social network is a scale-free network. We define DBLP collaboration social network as a graph that consists of researchers as nodes and links representing the collaboration among the researchers. In this work, we implement a data analysis algorithm called Multidimensional Scaling (MDS) to represent the degree of collaboration among the DBLP authors as Euclidean distances in order to analyze, mine and understand the relational information in this large scale network in a visual way. MDS requires a highly computational complexity for large scale graphs such as the DBLP graph. Therefore, we propose different solutions to overcome this problem, and improve the MDS performance. In addition, as the quality of the MDS result is measured by a metric known as the stress value, we use the steepest descent method to minimize the stress in an iterative process called stress optimization in order to generate the best geometric layout of the graph. We also propose a solution to further enhance the graph visualization by partitioning the graph into sub-graphs and using repelling forces among nodes within the same sub-graph.","","Electronic:978-1-4673-2284-3; POD:978-1-4673-2282-9; USB:978-1-4673-2283-6","10.1109/IRI.2012.6303017","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303017","Multidimensional scaling;Social network;co-authorships network;digital bibliography and library project;gradient descent;graphs;information retrieval","Collaboration;Data visualization;Equations;Mathematical model;Social network services;Stress;XML","XML;bibliographic systems;computational complexity;data analysis;data visualisation;electronic publishing;gradient methods;graph theory;groupware;interactive systems;optimisation;social networking (online)","DBLP author;DBLP collaboration social network;DBLP dataset;DBLP graph;Euclidean distance;MDS performance;XML file format;computational complexity;computer science related journal;conference proceedings;data analysis algorithm;digital bibliography and library project;geometric layout;graph partitioning;graph visualization;information science related journal;interactive visualization;iterative process;large scale graph;large scale network;multidimensional scaling;publication;relational information;research collaboration;scale-free network;steepest descent method;stress optimization;stress value;subgraph","","1","","13","","","8-10 Aug. 2012","","IEEE","IEEE Conference Publications"
"Design of an Automatic Ontology Construction Mechanism Using Semantic Analysis of the Documents","P. Dixit; S. Sethi; A. K. Sharma; A. Dixit","Dept. of Inf. Technol., Manav Rachna Int. Univ., Faridabad, India","2012 Fourth International Conference on Computational Intelligence and Communication Networks","20121206","2012","","","611","616","Ontologies play a major role in supporting information exchange processes in various areas. At present, ontologies are applied to the World Wide Web for creation of semantic web. The main application area of ontology technology is Knowledge Management. In the present scenario, it is difficult to acquire knowledge and then to maintain knowledge in a given domain. Manual ontology population is labor intensive and time consuming. Hence there is need to devise a method to provide fully automatic feeding of Web-based knowledge to the ontology. Moreover, for constructing ontology automatically, there is a need to discover a way to find, structure, and display the relationships between attributes and objects of a sentence. In this paper, a technique of Automatic Semantic Domain-ontology Populator (ASDP) towards construction of given domain modeled by the database is being proposed. ASDP is a way to find, structure, and display relationships between concepts, which consist of attributes and objects. This method helps in understanding a given domain and in building a domain model for it.","","Electronic:978-0-7695-4850-0; POD:978-1-4673-2981-1","10.1109/CICN.2012.89","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375185","Domain-ontology;Information Retrieval;Ontology","Humans;Object recognition;Ontologies;Semantics;Sociology;Statistics","document handling;knowledge management;ontologies (artificial intelligence);semantic Web","ASDP;Semantic Web;Web based knowledge;World Wide Web;automatic ontology construction mechanism;automatic semantic domain ontology populator;document handling;information exchange process;knowledge management;ontology population;semantic analysis","","0","","7","","","3-5 Nov. 2012","","IEEE","IEEE Conference Publications"
"Virtual Appliances, Cloud Computing, and Reproducible Research","B. Howe","University of Washington","Computing in Science & Engineering","20120716","2012","14","4","36","41","As science becomes increasingly computational, reproducibility has become increasingly difficult, perhaps surprisingly. In many contexts, virtualization and cloud computing can mitigate the issues involved without significant overhead to the researcher, enabling the next generation of rigorous and reproducible computational science.","1521-9615;15219615","","10.1109/MCSE.2012.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6193081","Cloud computing;Context awareness;Documentation;Information retrieval;Reproducibility of results;Research and development;Scientific computing;Virtual machining;case studies in scientific applications;cloud computing;information storage and retrieval;reproducible results;scientific computing;services computing","Cloud computing;Context awareness;Documentation;Information retrieval;Reproducibility of results;Research and development;Scientific computing;Virtual machining","","","","19","","10","","20120501","July-Aug. 2012","","IEEE","IEEE Journals & Magazines"
"Supporting Crisis Management via Sub-event Detection in Social Networks","D. Pohl; A. Bouchachia; H. Hellwagner","Inst. of Inf. Technol., Klagenfurt Univ., Klagenfurt, Austria","2012 IEEE 21st International Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises","20120816","2012","","","373","378","Social networks give the opportunity to gather and share knowledge about a situation of relevance. This so called user-generated content is getting increasingly important during crisis management. It facilitates the collaboration with citizens or parties involved from the very beginning of the crisis. The information captured in form of images, text or videos is a valuable source of identifying sub-events of a crisis. In this study, we use metadata of images and videos collected from Flickr and YouTube to extract sub-events in crisis situations. We investigate the suitability of clustering techniques to detect sub-events. In particular two algorithms are evaluated on several data sets related to crisis situations. The results show the high potential of the approach proposed.","1524-4547;15244547","Electronic:978-0-7695-4717-6; POD:978-1-4673-1888-4","10.1109/WETICE.2012.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269761","Clustering;Crisis Management;Information Retrieval;Sub-Event Detection","Crisis management;Indexes;Media;Social network services;Terrorism;Vectors;Videos","emergency services;meta data;pattern clustering;social networking (online)","Flickr;YouTube;captured information;clustering techniques;crisis management;crisis situations;metadata;social networks;subevent detection;user-generated content","","3","","23","","","25-27 June 2012","","IEEE","IEEE Conference Publications"
"A music retrieval system using chroma and pitch features based on conditional random fields","K. Sumi; M. Arai; T. Fujishima; S. Hashimoto","Corp. R&amp;D Center, Yamaha Corp., Shizuoka, Japan","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","1997","2000","This paper presents a new symbol-based retrieval method on a polyphonic music collection which takes a sequence data of users' performances as a query. We focus on chroma and pitch features to yield a robust retrieval with queries which are generated from different arrangements and which include some mistakes. Conditional random fields (CRFs) are used to enhance simultaneous utilization of chroma and pitch features. This is because CRFs can discriminate the correct sequence from all the other candidate sequences without independence assumptions for features of the inputs. Experimental results show that the use of multiple features based on CRFs leads to a significant improvement of retrieval accuracy and accomplishes robust music retrieval regardless of performance style of queries.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6288299","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6288299","conditional random fields;machine learning;music information retrieval","Data models;Databases;Feature extraction;Hidden Markov models;Labeling;Robustness;Vectors","music;query processing","chroma features;conditional random fields;music retrieval system;pitch features;polyphonic music collection;robust retrieval;symbol-based retrieval method","","1","","","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"ObliviAd: Provably Secure and Practical Online Behavioral Advertising","M. Backes; A. Kate; M. Maffei; K. Pecina","MPI-SWS, Germany","2012 IEEE Symposium on Security and Privacy","20120709","2012","","","257","271","Online behavioral advertising (OBA) involves the tracking of web users' online activities in order to deliver tailored advertisements. OBA has become a rapidly increasing source of revenue for a number of web services, and it is typically conducted by third-party data analytics firms such as brokers, which track user behaviors across web-sessions using mechanisms such as persistent cookies. This practice raises significant privacy concerns among users and privacy advocates alike. Therefore, the task of designing OBA systems that do not reveal user profiles to third parties has been receiving growing interest from the research community. Nevertheless, existing solutions are not ideal for privacy preserving OBA: some of them do not provide adequate privacy to users or adequate targeting information to brokers, while others require trusted third parties that are difficult to realize. In this paper, we propose ObliviAd a provably secure architecture for privacy preserving OBA. The distinguishing features of our approach are the usage of secure hardware-based private information retrieval for distributing advertisements and high-latency mixing of electronic tokens for billing advertisers without disclosing any information about client profiles to brokers. ObliviAd does not assume any trusted party and provides brokers an economical alternative that preserves the privacy of users without hampering the precision of ads selection. We present the first formal security definitions for OBA systems (namely, profile privacy, profile unlink ability, and billing correctness) and conduct a formal security analysis of ObliviAd using ProVerif, an automated cryptographic protocol verifier, establishing the aforementioned security properties against a strong adversarial model. Finally, we demonstrated the practicality of our approach with an experimental evaluation.","1081-6011;10816011","Electronic:978-07695-4681-0; POD:978-1-4673-1244-8","10.1109/SP.2012.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234417","behavorial advertising;formal verification;oblivious ram;privacy;private information retrieval;trusted hardware;unlinkability","Advertising;Coprocessors;Cryptography;Privacy;Protocols;Servers","Web services;advertising;behavioural sciences computing;data privacy;information retrieval","OBA;ObliviAd;Web services;Web users online activities;billing advertisers;billing correctness;data analytics;distributing advertisements;economical alternative;electronic tokens;hardware based private information retrieval;high-latency mixing;persistent cookies;practical online behavioral advertising;profile privacy;profile unlink ability;provably secure online behavioral advertising;research community;tailored advertisements;trusted party","","15","","51","","","20-23 May 2012","","IEEE","IEEE Conference Publications"
"Effect of aggregation functions on the habitat preference modelling using a genetic Takagi-Sugeno fuzzy system","S. Fukuda","Institute of Tropical Agriculture, Kyushu University, Fukuoka, Japan","2012 IEEE International Conference on Fuzzy Systems","20120813","2012","","","1","8","Uncertainties originating from the behaviour of target species and modelling approaches affect predictive accuracy and information retrieved, which can thus influence the applicability and reliability of a model. This paper aimed to assess the effects of aggregation functions for computing composite habitat preference on the prediction of species distributions and habitat preference evaluation using a 0-order genetic Takagi-Sugeno fuzzy model. The effects were evaluated based on the predictive accuracy and habitat preference information. In order to reduce the data uncertainty, artificial data were generated using hypothetical habitat preference curves (HPCs) under different assumptions on the interaction between habitat variables and habitat preference of an artificial fish. In total, twelve data sets were generated, from which forty-eight fuzzy habitat preference models (FHPMs) with different aggregation functions were developed. As a result, the FHPMs produced similar HPCs across the different data sets, while slight differences were found between the FHPMs with different aggregation functions. Although none of the models could represent hypothetical habitat preference, the product-type aggregation function showed relatively higher performance for both accuracy and HPCs.","1098-7584;10987584","Electronic:978-1-4673-1506-7; POD:978-1-4673-1507-4","10.1109/FUZZ-IEEE.2012.6251172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6251172","artificial data;fuzzy systems;genetic algorithms;information retrieval;predictive performance;preference modelling","Accuracy;Biological system modeling;Data models;Manganese;Marine animals;Predictive models;Vegetation","ecology;fuzzy systems","0-order genetic Takagi-Sugeno fuzzy model;FHPM;HPC;aggregation functions;composite habitat preference;fuzzy habitat preference models;genetic Takagi-Sugeno fuzzy system;habitat preference evaluation;habitat preference modelling;hypothetical habitat preference curves;model reliability;species distributions prediction","","1","","32","","","10-15 June 2012","","IEEE","IEEE Conference Publications"
"A kind of query system on public Touch Screen that can input chinese characters","Min Li","NanChang Institute of Technology, Jiangxi 330099, China","2012 International Conference on Computer Science and Information Processing (CSIP)","20120924","2012","","","672","675","Common information query system on public Touch Screen only can accept click inputting. Many information query system on public touch screen only offer inputting the digits. This paper introduces the technologies about how to realize input Chinese character as inquiring condition.","","DVD:978-1-4673-1409-1; Electronic:978-1-4673-1411-4; POD:978-1-4673-1410-7","10.1109/CSIP.2012.6308943","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6308943","Chinese character inputting;Digits inputting;Information retrieval;remote public touch screen","Artificial intelligence;Helium;Hidden Markov models;Reliability","natural languages;public information systems;query processing;touch sensitive screens;user interfaces","Chinese character;information query system;public touch screen","","0","","8","","","24-26 Aug. 2012","","IEEE","IEEE Conference Publications"
"Knowledge Reposiory as Entity Similarity Computing Enabler","M. Ba; G. Diallo","LESIM-ISPED, Univ. of Bordeaux, Bordeaux, France","2012 Eighth International Conference on Signal Image Technology and Internet Based Systems","20130110","2012","","","975","981","With the adoption of Semantic Web technologies, knowledge based applications are nowadays common. They rely on the use of numerous and varied knowledge organization systems. This raises the problem of the interoperability of the underlying models in particular for data integration purpose. We present in this paper an approach based on an ontology server and providing functionalities including ontology matching and change detection. The evaluation of the matching approach using standard measure of recall/precision/F-measure shows results which outperform in certain contexts current available systems which are able to process large data set.","","Electronic:978-0-7695-4911-8; POD:978-1-4673-5152-2","10.1109/SITIS.2012.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395197","entities similarity;knowledge repository information retrieval;ontology server","Indexing;Libraries;Ontologies;Organizations;Semantics;Servomotors","ontologies (artificial intelligence);open systems;organisational aspects;semantic Web","Semantic Web technologies;data integration;entity similarity computing enabler;interoperability;knowledge based applications;knowledge organization systems;knowledge reposiory;ontology server","","0","","21","","","25-29 Nov. 2012","","IEEE","IEEE Conference Publications"
"Using search engines and artificial neural networks for style checking","C. A. N. Reis; L. Naffah Ferreira","Information Systems Course, Anhanguera College of Belo Horizonte, Avenida dos Andradas, 436 Centro - CEP: 30120-010 - MG - Brasil","International Conference on Information Society (i-Society 2012)","20120827","2012","","","227","228","Choosing the best words for expressing the thoughts is never an easy task, especially in a foreign language. However, the huge amount of text available on the Web can provide a clue. In fact, the frequency of distinct expressions or phrases that have the same meaning can help to separate the wheat from the chaff. This paper proposes an approach based on artificial neural networks - ANN to generalize this idea, taking the frequency of the words in an expression as the input to the ANN and setting the output to one for the most common phrase and zero for the least, using the training data.","","Electronic:978-1-908320-05-6; POD:978-1-4673-0838-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6285082","artificial neural network;computacional linguistics;information retrieval;search engine","Biological neural networks","Internet;information retrieval;neural nets;search engines","ANN;Web;artificial neural networks;distinct expressions;foreign language;search engines;style checking;training data","","0","","7","","","25-28 June 2012","","IEEE","IEEE Conference Publications"
"Enhancing query retrieval efficiency using BGIT coding","A. A. Al-Jedady; I. M. Alsmadi; E. M. Al-Shawakfa; M. N. Al-Kabi","CIS Department, IT Faculty, Yarmouk University, Irbid, Jordan","2012 International Conference on Computer, Information and Telecommunication Systems (CITS)","20120621","2012","","","1","5","Data compression techniques are used to optimize time and space while sending and retrieving data. In information retrieval, data compression techniques are used by Search engines to reduce the size of their indexes which will result in optimizing the speed and performance of retrieving relevant information. The goal of this research project is to propose some enhancements on search engines indexing using Bigram index term coding. Evaluation of the improvements on search-engine performance resulting from encoding the terms of its index is also conducted. Our experiments showed a good reduction in the size of index terms which contributes to the overall index size. It also showed a significant reduction of the number of comparisons made to process the user queries as a result of reducing the number of symbols representing each index term.","","Electronic:978-1-4673-1550-0; POD:978-1-4673-1549-4","10.1109/CITS.2012.6220367","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6220367","Information retrieval;bigram;fixed-length coding;index compression;indexing;search engine index","Encoding;Indexing;Search engines;Standards","data compression;indexing;natural language processing;query processing;search engines","Arabic language;BGIT coding;bigram based index term coding;data compression techniques;data retrieval;data sending;information retrieval;query retrieval efficiency enhancement;search engines indexing;search-engine performance improvement evaluation","","0","","14","","","14-16 May 2012","","IEEE","IEEE Conference Publications"
"Improving Bug Location Using Binary Class Relationships","N. Ali; A. Sabané; Y. G. Guéhéneuc; G. Antoniol","DGIGL, Ecole Polytech. de Montreal, Montreal, QC, Canada","2012 IEEE 12th International Working Conference on Source Code Analysis and Manipulation","20121224","2012","","","174","183","Bug location assists developers in locating culprit source code that must be modified to fix a bug. Done manually, it requires intensive search activities with unpredictable costs of effort and time. Information retrieval (IR) techniques have been proven useful to speedup bug location in object-oriented programs. IR techniques compute the textual similarities between a bug report and the source code to provide a list of potential culprit classes to developers. They rank the list of classes in descending order of the likelihood of the classes to be related to the bug report. However, due to the low textual similarity between source code and bug reports, IR techniques may put a culprit class at the end of a ranked list, which forces developers to manually verify all non-culprit classes before finding the actual culprit class. Thus, even with IR techniques, developers are not saved from manual effort. In this paper, we conjecture that binary class relationships (BCRs) could improve the rankings by IR techniques of classes and, thus, help reducing developers' manual effort. We present an approach, LIBCROOS, that combines the results of any IR technique with BCRs gathered through source code analyses. We perform an empirical study on four programs -- Jabref, Lucene, muCommander, and Rhino -- to compare the accuracy, in terms of ranking, of LIBCROOS with two IR techniques: latent semantic indexing (LSI) and vector space model (VSM). The results of this empirical study show that LIBCROOS improves the rankings of both IR technique statistically when compared to LSI and VSM alone and, thus, may reduce the developers' effort.","","Electronic:978-0-7695-4783-1; POD:978-1-4673-2398-7","10.1109/SCAM.2012.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392116","Feature location;binary class relationships;information retrieval;object-oriented","Accuracy;Analytical models;Engines;Java;Large scale integration;Object oriented modeling;Vectors","information retrieval;object-oriented programming;program debugging;program diagnostics","IR techniques;Jabref;LIBCROOS;LSI;Lucene;Rhino;VSM;binary class relationships;bug location;bug report;culprit source code;information retrieval techniques;latent semantic indexing;muCommander;nonculprit classes;object-oriented programs;search activity;source code analyses;textual similarity;unpredictable costs;vector space model","","4","","26","","","23-24 Sept. 2012","","IEEE","IEEE Conference Publications"
"VIQI: A new approach for visual interpretation of deep web query interfaces","R. Boughammoura; L. Hlaoua; M. N. Omri","Department of Sciences of Data Processing, Faculty of Sciences of Monastir, Research Unit MARS, Monastir, Tunisia","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","Deep Web databases contain more than 90% of pertinent information of the Web. Despite their importance, users don't profit of this treasury. Many deep web services are offering competitive services in term of prices, quality of service, and facilities. As the number of services is growing rapidly, users have difficulty to ask many web services in the same time. In this paper, we imagine a system where users have the possibility to formulate one query using one query interface and then the system translates query to the rest of query interfaces. However, interfaces are created by designers in order to be interpreted visually by users, machines can not interpret query from a given interface. We propose a new approach which emulates capacity of interpretation of users and extracts query from deep web query interfaces. Our approach has proved good performances on two standard datasets.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216656","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216656","Information Retrieval;Query Extraction;Query Model;Web","Feature extraction;Noise;Semantics;Standards;Visualization;Web pages;Web services","Web services;database management systems;query formulation;user interfaces","VIQI;deep Web database;deep Web query interfaces;deep Web services;query extraction;query formulation;user interpretation;visual interpretation approach","","0","","20","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"SCAN: An Approach to Label and Relate Execution Trace Segments","S. Medini; G. Antoniol; Y. G. Guéhéneuc; M. Di Penta; P. Tonella","DGIGL, Ecole Polytech. de Montreal, Montreal, QC, Canada","2012 19th Working Conference on Reverse Engineering","20121220","2012","","","135","144","Identifying concepts in execution traces is a task often necessary to support program comprehension or maintenance activities. Several approaches -- static, dynamic or hybrid -- have been proposed to identify cohesive, meaningful sequence of methods in execution traces. However, none of the proposed approaches is able to label such segments and to identify relations between segments of the same trace. This paper present SCAN (Segment Concept AssigNer) an approach to assign labels to sequences of methods in execution traces, and to identify relations between such segments. SCAN uses information retrieval methods and formal concept analysis to produce sets of words helping the developer to understand the concept implemented by a segment. Specifically, formal concept analysis allows SCAN to discover commonalities between segments in different trace areas, as well as terms more specific to a given segment and high level relations between segments. The paper describes SCAN along with a preliminary manual validation -- upon execution traces collected from usage scenarios of JHotDraw and ArgoUML -- of SCAN accuracy in assigning labels representative of concepts implemented by trace segments.","1095-1350;10951350","Electronic:978-0-7695-4891-3; POD:978-1-4673-4536-1","10.1109/WCRE.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385109","Concept identification;dynamic analysis;formal concept analysis;information retrieval","Corporate acquisitions;Information retrieval;Java;Labeling;Lattices;Manuals","formal concept analysis;information retrieval;software maintenance","ArgoUML;JHotDraw;SCAN;execution trace segment labelling;formal concept analysis;high-level relations;information retrieval methods;program comprehension;program maintenance;segment concept assigner approach;trace areas","","2","","30","","","15-18 Oct. 2012","","IEEE","IEEE Conference Publications"
"Melodic Segmentation Using the Jensen-Shannon Divergence","Marcelo; Enrique; Rodríguez; López; A. Volk","Dept. of Inf. &amp; Comput. Sci., Utrecht Univ., Utrecht, Netherlands","2012 11th International Conference on Machine Learning and Applications","20130110","2012","2","","351","356","This paper introduces an unsupervised model for melodic segmentation that extends a method initially proposed in computational biology. In the model segments are identified as sections of maximal contrast within a musical piece, using for this the Jensen-Shannon divergence. The model is extended upon its original formulation, and experiments to test its performance are carried out for a small set of selected folk song melodies. Generalization of the model is tested on 100 folk songs. Our results show a significant improvement upon the model's original formulation. In addition, we situate our model in the context of a cognition-based ensemble learning framework and justify its use within it. The need for such a cognition-based ensemble approach is also discussed.","","Electronic:978-0-7695-4913-2; POD:978-1-4673-4651-1","10.1109/ICMLA.2012.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406818","ensemble methods;information theory;melodic segmentation;music information retrieval","Biological system modeling;Computational modeling;Context;Context modeling;Markov processes;Music;Predictive models","cognition;entropy;music;unsupervised learning","Jensen-Shannon divergence;cognition-based ensemble learning framework;computational biology;folk song melodies;melodic segmentation;musical piece;unsupervised model","","0","","22","","","12-15 Dec. 2012","","IEEE","IEEE Conference Publications"
"Topic Detection over Online Forum","F. Chen; J. Du; W. Qian; A. Zhou","Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China","2012 Ninth Web Information Systems and Applications Conference","20121220","2012","","","235","240","Topic detection is an hot research in the area of information retrieval. However, the new environment of Internet, the content of which are usually user-generated, asks for new requirements and brings new challenges. Topic detection has to resolve the problem of its lower quality and large amount of noisy. This paper not only provides a solution for detecting hot topics, but also giving its semantic descriptions as result. Our method integrates two kinds of term features (local features and global features), and use single pass clustering to perform topic detection in a web forum. It's efficient to filter non-topic documents and get readable descriptions of topic in our system. By comparison with baseline and topic model LDA, our method gets better performance and readable result.","","Electronic:978-0-7695-4819-7; POD:978-1-4673-3054-1","10.1109/WISA.2012.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385216","Information Retrieval;Topic Detection","Clustering algorithms;Context;Feature extraction;Internet;Noise measurement;Semantics;Training","document handling;information retrieval;pattern clustering;social networking (online)","Internet;LDA;information retrieval;nontopic documents;online forum;semantic descriptions;single pass clustering;topic detection","","2","","19","","","16-18 Nov. 2012","","IEEE","IEEE Conference Publications"
"IPedagogy: Question Answering System Based on Web Information Clustering","R. Perera","Dept. of Comput. Sci. Inf., Inst. of Technol., Colombo, Sri Lanka","2012 IEEE Fourth International Conference on Technology for Education","20120920","2012","","","245","246","As with the excessive information growth in the web, retrieving the exact segment of information even for a simple query, has transformed to a difficult and resource expensive state. Specially, in e-learning domain it is vital to search knowledge frequently and focusing on a limited well defined search space. IPedagogy is a question answering system which works with natural language powered queries and retrieve answers from selected information clusters by reducing the search space of information retrieval. In addition, IPedagogy is empowered by several natural language processing techniques which direct the system to extract the exact answer for a given query. System is evaluated with the use of mean reciprocal rank and it is noted that system has 0.73 of average accuracy level for 10sets of questions where each set is consisted of 35 questions.","","Electronic:978-0-7695-4759-6; POD:978-1-4673-2173-0","10.1109/T4E.2012.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6305919","e-learning;information retrieval;informationclustering;mean reciprocal rank;natural language processing;question answering system","Accuracy;Algorithm design and analysis;Clustering algorithms;Information retrieval;Natural language processing;Signal processing algorithms","Internet;computer aided instruction;natural language processing;pattern clustering;query processing;question answering (information retrieval);search engines","IPedagogy;Web information clustering;World Wide Web;e-learning domain;information clusters;information growth;information retrieval;mean reciprocal rank;natural language powered query;natural language processing techniques;question answering system;resource expensive state;search space","","1","","9","","","18-20 July 2012","","IEEE","IEEE Conference Publications"
"WORDGRAPH: Keyword-in-Context Visualization for NETSPEAK's Wildcard Search","P. Riehmann; H. Gruendl; M. Potthast; M. Trenkmann; B. Stein; B. Froehlich","Bauhaus-Universit&#x0E4;t Weimar, Weimar","IEEE Transactions on Visualization and Computer Graphics","20120712","2012","18","9","1411","1423","The WORDGRAPH helps writers in visually choosing phrases while writing a text. It checks for the commonness of phrases and allows for the retrieval of alternatives by means of wildcard queries. To support such queries, we implement a scalable retrieval engine, which returns high-quality results within milliseconds using a probabilistic retrieval strategy. The results are displayed as WORDGRAPH visualization or as a textual list. The graphical interface provides an effective means for interactive exploration of search results using filter techniques, query expansion, and navigation. Our observations indicate that, of three investigated retrieval tasks, the textual interface is sufficient for the phrase verification task, wherein both interfaces support context-sensitive word choice, and the WORDGRAPH best supports the exploration of a phrase's context or the underlying corpus. Our user study confirms these observations and shows that WORDGRAPH is generally the preferred interface over the textual result list for queries containing multiple wildcards.","1077-2626;10772626","","10.1109/TVCG.2012.96","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175895","Information visualization;Web n-grams;information retrieval;text visualization;visual queries;wildcard search.","Engines;Google;Indexes;Layout;Navigation;Visualization","data visualisation;information retrieval;probability","NETSPEAK wildcard search;WORDGRAPH;filter techniques;graphical interface;interactive exploration;keyword-in-context visualization;phrase context;probabilistic retrieval strategy;query expansion;query navigation;scalable retrieval engine;underlying corpus;visually choosing phrases;wildcard queries","","3","","27","","20120403","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Analysis of Security Messages Posted on Twitter","L. A. F. Santos; R. Campiolo; M. A. Gerosa; D. M. Batista","Univ. Tecnol. Fed. do Parana, Campo Moura&#x0303;o, Brazil","2012 Brazilian Symposium on Collaborative Systems","20121224","2012","","","20","28","The fast spread of computer security alerts, like vulnerabilities notifications, applications updates and threats of attacks, is essential to efficient reactive measures against security incidents. This paper presents an empirical study that evaluates the efficiency of using twitter posts, related to computer security, as notifications of security alerts. The justification to this study is the fact that posts from microblogs have a very fast spread over the Internet. By using similarity analysis and clustering between twitter posts and alerts from specialized sites, it was verified that microblogs spread computer security alerts in a reliable way, reach a high level of dissemination and inform about security threats before some specialized sites.","2326-2826;23262826","Electronic:978-0-7695-4890-6; POD:978-1-4673-4696-2","10.1109/SBSC.2012.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391727","information retrieval;microblogs;security;social network analysis","Computer hacking;Feeds;Malware;Software;Twitter","Internet;information dissemination;pattern clustering;security of data;social networking (online);text analysis","Internet;Twitter post;application update;attack threat;clustering;computer security alert;dissemination;microblog;security incident reactive measure;security message analysis;similarity analysis;vulnerability notification","","0","","24","","","15-18 Oct. 2012","","IEEE","IEEE Conference Publications"
"Context-based search to overcome learning barriers in software development","J. Cordeiro; B. Antunes; P. Gomes","Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal","2012 First International Workshop on Realizing AI Synergies in Software Engineering (RAISE)","20120702","2012","","","47","51","During the software development process, developers are often faced with problem solving situations that motivate the use of the Web to search for information. However, there is a gap between the IDE and the Web, requiring the developers to spend significant time searching for relevant information and navigating through web pages in a Web browser. We propose a tool that aim to aid developers overcoming the learning barriers that exist when working with technologies that they do not master, facilitating the access to question/answer web resources through a context-based search interface, integrated in the IDE. We present an example of use, to better understand our approach.","","Electronic:978-1-4673-1753-5; POD:978-1-4673-1752-8","10.1109/RAISE.2012.6227970","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227970","Context Modeling;Information Retrieval;Software Development","Browsers;Context;Context modeling;Data mining;Java;Programming;USA Councils","Internet;information retrieval;software engineering","IDE;Web browser;Web pages;context-based search interface;learning barriers;software development process","","1","","9","","","5-5 June 2012","","IEEE","IEEE Conference Publications"
"Exemplar: A Source Code Search Engine for Finding Highly Relevant Applications","C. McMillan; M. Grechanik; D. Poshyvanyk; C. Fu; Q. Xie","College of William and Mary, Williamsburg","IEEE Transactions on Software Engineering","20120924","2012","38","5","1069","1087","A fundamental problem of finding software applications that are highly relevant to development tasks is the mismatch between the high-level intent reflected in the descriptions of these tasks and low-level implementation details of applications. To reduce this mismatch we created an approach called EXEcutable exaMPLes ARchive (Exemplar) for finding highly relevant software projects from large archives of applications. After a programmer enters a natural-language query that contains high-level concepts (e.g., MIME, datasets), Exemplar retrieves applications that implement these concepts. Exemplar ranks applications in three ways. First, we consider the descriptions of applications. Second, we examine the Application Programming Interface (API) calls used by applications. Third, we analyze the dataflow among those API calls. We performed two case studies (with professional and student developers) to evaluate how these three rankings contribute to the quality of the search results from Exemplar. The results of our studies show that the combined ranking of application descriptions and API documents yields the most-relevant search results. We released Exemplar and our case study data to the public.","0098-5589;00985589","","10.1109/TSE.2011.84","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989838","Source code search engines;concept location;information retrieval;mining software repositories;open source software;software reuse","Cryptography;Data mining;Engines;Java;Search engines;Software;Vocabulary","application program interfaces;data flow analysis;document handling;natural language processing;project management;query processing;software management;software reusability;system documentation","API call;API document;Exemplar;application description ranking;application programming interface;dataflow;development task;executable examples archive;natural-language query;search quality;software application;software project;software reuse;source code search engine","","21","1","52","","20110818","Sept.-Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Keywords Retrieval Based on Ontology Inference","G. Chen; P. Zhang","Commun. Univ. of China, Beijing, China","2012 International Conference on Industrial Control and Electronics Engineering","20121004","2012","","","1750","1753","As a conception modeling tool, ontology can describe the information system in the semantic and the knowledge level, it can also express the relations of concepts, the inheritance hierarchy of concepts, potential relationships and axioms precisely, and so on. Meanwhile, it provides a solution for many problems of massive information caused by the rapid development of the Internet, such as how to organize, manage and maintain vast amounts of knowledge information, and provide users with efficient services to access them, also an effective way of sharing and representing knowledge. This paper proposes a keyword retrieval method based on thesaurus and ontology, to solve vary problems between user's keywords and words used by domain experts to describe the ontology, in order to improve the efficiency and accuracy of retrieval, aiming at combining the general retrieval system and domain ontology effectively.","","Electronic:978-1-4673-1449-7; POD:978-1-4673-1450-3","10.1109/ICICEE.2012.463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322753","Ontology;information retrieval;semantic web;thesaurus","Cognition;Information retrieval;Information systems;Ontologies;Semantics;Standards","Internet;inference mechanisms;information retrieval;ontologies (artificial intelligence);thesauri","Internet;concept inheritance hierarchy;concept relation;conception modeling tool;domain ontology;general retrieval system;information system;keywords retrieval method;knowledge level;ontology inference;semantic level;thesaurus","","0","","11","","","23-25 Aug. 2012","","IEEE","IEEE Conference Publications"
"Query Profile Obfuscation by Means of Optimal Query Exchange between Users","D. Rebollo-Monedero; J. Forné; J. Domingo-Ferrer","Universitat Polit&#x00E8;cnica de Catalunya, Barcelona","IEEE Transactions on Dependable and Secure Computing","20120719","2012","9","5","641","654","We address the problem of query profile obfuscation by means of partial query exchanges between two users, in order for their profiles of interest to appear distorted to the information provider (database, search engine, etc.). We illustrate a methodology to reach mutual privacy gain, that is, a situation where both users increase their own privacy protection through collaboration in query exchange. To this end, our approach starts with a mathematical formulation, involving the modeling of the users' apparent profiles as probability distributions over categories of interest, and the measure of their privacy as the corresponding Shannon entropy. The question of which query categories to exchange translates into finding optimization variables representing exchange policies, for various optimization objectives based on those entropies, possibly under exchange traffic constraints.","1545-5971;15455971","","10.1109/TDSC.2012.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6138865","Profile obfuscation;entropy;information theory.;privacy via user collaboration;private information retrieval","Entropy;Forgery;Histograms;IP networks;Optimization;Privacy;Protocols","data privacy;information theory;query processing;statistical distributions;user modelling","Shannon entropy;exchange policies;exchange traffic constraints;information provider;mutual privacy gain;optimal query exchange;optimization variables;partial query exchanges;privacy protection;probability distributions;query categories;query profile obfuscation","","1","","55","","20120124","Sept.-Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Inverted index compression using Extended Golomb Code","V. Glory; S. Domnic","Department of Computer Applications, National Institute of Technology, Tiruchirappalli, India","IEEE-International Conference On Advances In Engineering, Science And Management (ICAESM -2012)","20120614","2012","","","20","25","Web Search Engines use inverted index structures for efficient query processing. But the size of the inverted index is extremely large due to rapid growth in the size of the text data in the web. In order to reduce the index size and increase the accessing speed, compression techniques are used. In this paper, we make use of a new integer compression technique, Extended Golomb Code (EGC), to reduce the size of the inverted index. We have tested the performance of EGC with other existing techniques. Experimental results show that EGC performs better than other existing techniques in compressing inverted index.","","Electronic:978-81-909042-2-3; POD:978-1-4673-0213-5","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6215567","D-Gap;Information Retrieval System;Inverted File;Inverted Index Compression;Search Engines","Indexes","Internet;data compression;indexing;query processing;search engines;text analysis","EGC;Web search engine;accessing speed;extended Golomb code;index size;information retrieval system;integer compression technique;inverted index compression;inverted index structure;query processing;text data size","","0","","17","","","30-31 March 2012","","IEEE","IEEE Conference Publications"
"A hybrid method based on WordNet and Wikipedia for computing semantic relatedness between texts","R. Malekzadeh; J. Bagherzadeh; A. Noroozi","Islamic Azad University, Shabestar Branch, Iran","The 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP 2012)","20120927","2012","","","107","111","In this article we present a new method for computing semantic relatedness between texts. For this purpose we use a tow-phase approach. The first phase involves modeling document sentences as a matrix to compute semantic relatedness between sentences. In the second phase, we compare text relatedness by using the relation of their sentences. Since Semantic relation between words must be searched in lexical semantic knowledge source, selecting a suitable source is very important, so that produced accurate results with correct selection. In this work, we attempt to capture the semantic relatedness between texts with a more accuracy. For this purpose, we use a collection of tow well known knowledge bases namely, WordNet and Wikipedia, so that provide more complete data source for calculate the semantic relatedness with a more accuracy. We evaluate our approach by comparison with other existing techniques (on Lee datasets).","","Electronic:978-1-4673-1479-4; POD:978-1-4673-1478-7","10.1109/AISP.2012.6313727","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6313727","Wikipedia;WordNet;information retrieval;lexical semantic knowledge;semantic relatedness;semantic similarity","Electronic publishing;Encyclopedias;Internet;Measurement;Semantics;Vectors","Web sites;information retrieval;matrix algebra;text analysis","Wikipedia;WordNet;document sentences;hybrid method;lexical semantic knowledge source;semantic relatedness;text relatedness;tow-phase approach","","0","","14","","","2-3 May 2012","","IEEE","IEEE Conference Publications"
"Defining and retrieving themes in nuclear regulations","N. Sannier; B. Baudry","EDF R&D - STEP, 6 Quai Watier BP49, 78401 Chatou cedex, France","2012 Fifth IEEE International Workshop on Requirements Engineering and Law (RELAW)","20121110","2012","","","33","41","Safety systems in nuclear industry must conform to an increasing set of regulatory requirements. These requirements are scattered throughout multiple documents expressing different levels of requirements or different kinds of requirements. Consequently, when licensees want to extract the set of regulations related to a specific concern, they lack explicit traces between all regulation documents and mostly get lost while attempting to compare two different regulatory corpora. This paper presents the regulatory landscape in the context of digital Instrumentation and Command systems in nuclear power plants. To cope with this complexity, we define and discuss challenges toward an approach based on information retrieval techniques to first narrow the regulatory research space into themes and then assist the recovery of these traceability links.","","Electronic:978-1-4673-4382-4; POD:978-1-4673-4380-0","10.1109/RELAW.2012.6347797","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6347797","Regulatory requirements;domain practice;information retrieval;requirements traceability;theme organization","Context;IEC standards;IEEE standards;Regulators;Safety;Software","fission reactor design;fission reactor safety;nuclear facility regulation;nuclear power stations","command systems;defining theme;digital Instrumentation;information retrieval techniques;multiple documents;nuclear industry;nuclear power plants;nuclear regulations;regulatory corpora;regulatory landscape;retrieving theme;safety systems","","1","","25","","","25-25 Sept. 2012","","IEEE","IEEE Conference Publications"
"Comparative evaluations of various harmonic/percussive sound separation algorithms based on anisotropic continuity of spectrogram","H. Tachibana; H. Kameoka; N. Ono; S. Sagayama","Graduate School of Information Science and Technology, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656, Japan","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","465","468","In this paper, we explore several algorithms to find the best performing algorithm for harmonic and percussive sound separation (HPSS) based on anisotropic continuity of spectrogram through comparative evaluation of their experimental performance. Separating harmonic and percussive sounds is useful as a preprocessor for many music analysis purposes including chord estimation, rhythm analysis, and other music information retrieval tasks. We have introduced a method called “Harmonic/Percussive Sound Separation” (HPSS), that decomposes a music signal into two components by separating the spectrogram into horizontally-continuous and vertically-continuous components, which roughly correspond to harmonic and percussive sounds, respectively. Many possible ways exist to realize the HPSS algorithm based on this concept while it has been unknown which algorithm performs best. This paper describes the details of five different HPSS algorithms and compares their performances over real music signals.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6287917","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6287917","Harmonic/percussive sound separation;Music information retrieval;Source Separation","Estimation;Harmonic analysis;Linear programming;Multiple signal classification;Signal processing algorithms;Spectrogram;Time frequency analysis","music;source separation","anisotropic continuity;chord estimation;experimental performance evaluation;harmonic-percussive sound separation algorithm;horizontally-continuous component;music analysis;music information retrieval task;music signal decomposition;rhythm analysis;spectrogram separation;vertically-continuous component","","2","","11","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Content-Based Microscopic Image Retrieval System for Multi-Image Queries","H. C. Akakin; M. N. Gurcan","Department of Biomedical Informatics , The Ohio State University, Columbus, USA","IEEE Transactions on Information Technology in Biomedicine","20120628","2012","16","4","758","769","In this paper, we describe the design and development of a multitiered content-based image retrieval (CBIR) system for microscopic images utilizing a reference database that contains images of more than one disease. The proposed CBIR system uses a multitiered approach to classify and retrieve microscopic images involving their specific subtypes, which are mostly difficult to discriminate and classify. This system enables both multi-image query and slide-level image retrieval in order to protect the semantic consistency among the retrieved images. New weighting terms, inspired from information retrieval theory, are defined for multiple-image query and retrieval. The performance of the system was tested on a dataset including 1666 imaged high power fields extracted from 57 follicular lymphoma (FL) tissue slides with three subtypes and 44 neuroblastoma (NB) tissue slides with four subtypes. Each slide is semantically annotated according to their subtypes by expert pathologists. By using leave-one-slide out testing scheme, the multi-image query algorithm with the proposed weighting strategy achieves about 93% and 86% of average classification accuracy at the first rank retrieval, outperforming the image-level retrieval accuracy by about 38 and 26 percentage points, for FL and NB diseases, respectively.","1089-7771;10897771","","10.1109/TITB.2012.2185829","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6142100","Content-based image retrieval (CBIR);information retrieval (IR);microscopy multi-image queries;weighting scores","Databases;Diseases;Feature extraction;Image color analysis;Microscopy;Semantics;Vectors","cancer;computerised tomography;content-based retrieval;feature extraction;image classification;image retrieval;medical image processing;semantic networks","computerised tomography;content-based microscopic image retrieval system;disease;expert pathologists;follicular lymphoma;high power field image extraction;image classification;information retrieval theory;multiimage queries;neuroblastoma tissue slides;reference database;semantic consistency;slide-level image retrieval;tissue slides","Algorithms;Databases, Factual;Histocytochemistry;Humans;Image Processing, Computer-Assisted;Lymphoma, Follicular;Microscopy;Neuroblastoma","31","","46","","20120130","July 2012","","IEEE","IEEE Journals & Magazines"
"Efficient selection of access control systems through multi criteria analytical hierarchy process","A. Azhar; M. Amin; M. Nauman; S. U. Shah","National University of Computer and Emerging Sciences, (FAST), Peshawar, Pakistan","2012 International Conference on Emerging Technologies","20121206","2012","","","1","8","Access control is the process by which the system grants or denies a request made to it, by the user, for the data it maintains. Often the systems providing the services are open ended and face the access control dilemma. If the beneficiaries of the system are too restricted, then the servicing nature of the system loses flexibility. Otherwise the system with lenient access control policy posses threats to the existence of the system itself. As a remedy several access control models like ACL, DAC, MAC, RBAC and other have been proposed and each of which comes with its own baggage of pros and cons. These models protect only the data against unauthorized access until some access decision is made. On the other hand as the computer systems advance, they present new challenges and the traditional access models do not respond to them effectively. In this paper we have analyzed the existing access control models, compared them and finally provided the statistical criteria for selecting the best model depending upon the users' needs and requirements.","","CD-ROM:978-1-4673-4450-0; Electronic:978-1-4673-4451-7; POD:978-1-4673-4452-4","10.1109/ICET.2012.6375419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375419","ACL;Access Control;Information Retrieval;RBAC","Analytical models;Authorization;Computational modeling;Operating systems;Organizations","analytic hierarchy process;authorisation","ACL;DAC;MAC;RBAC;access control systems;computer systems;efficient selection;multicriteria analytical hierarchy process;unauthorized access","","0","","21","","","8-9 Oct. 2012","","IEEE","IEEE Conference Publications"
"Condorcet Fusion for Blog Opinion Retrieval","S. Wu; X. Zeng","Sch. of Comput. & Telecommun., Jiangsu Univ., Zhenjiang, China","2012 23rd International Workshop on Database and Expert Systems Applications","20121011","2012","","","156","160","Blogs have been popular social networking platforms in recent years. Blog opinion retrieval is one of the key issues that needs to be solved. In this paper, we investigate if the Condorcet fusion and the weighted Condorcet fusion can be used for effectiveness improvement of blog opinion retrieval. The experiments carried out with the data set from the TREC 2008 Blog track show that the Condorcet fusion is effective and the weighted Condorcet fusion, with its weights trained by linear discriminant analysis, is very effective. Both of them outperform the best component result by a clear margin.","1529-4188;15294188","Electronic:978-0-7695-4801-2; POD:978-1-4673-2621-6","10.1109/DEXA.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327419","condorcet fusion;data fusion;information retrieval","Analytical models;Blogs;Educational institutions;Training;USA Councils","information retrieval;search engines;sensor fusion;social networking (online);statistical analysis","TREC 2008 Blog track;blog opinion retrieval;data set;linear discriminant analysis;search engines;social networking platforms;weighted Condorcet fusion","","0","","14","","","3-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Different Strokes of Different Folks: Searching for Health Narratives in Weblogs","A. S. Gordon; C. Wienberg; S. O. Sood","Inst. for Creative Technol., Univ. of Southern California, Los Angeles, CA, USA","2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing","20130110","2012","","","490","495","The utility of storytelling in the interaction between healthcare providers and patients is now firmly established, but the potential use of large-scale story collections for health-related inquiry has not yet been explored. In particular, the enormous scale of storytelling in personal web logs offers investigators in health-related fields new opportunities to study the behavior and beliefs of diverse patient populations outside of clinical settings. In this paper we address the technical challenges in identifying personal stories about specific health issues from corpora of millions of web log posts. We describe a novel infrastructure for collecting and indexing the stories posted each day to English-language web logs, coupled with user interfaces designed to support targeted searches of these collections. We evaluate the effectiveness of this search technology in an effort to identify hundreds of first person and third person accounts of strokes, for the purpose of studying gender differences in the way that these health emergencies are described. Results indicate that the use of relevance feedback significantly improves the effectiveness of the search. We conclude with a discussion of sample biases that are inherent in web log storytelling and heightened by our approach, and propose ways to mitigate these biases.","","Electronic:978-0-7695-4848-7; POD:978-1-4673-5638-1","10.1109/SocialCom-PASSAT.2012.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6406391","health;information retrieval;storytelling;weblogs","Blogs;Boring;Educational institutions;Filtering;Internet;Medical services","Web sites;health care;indexing;medical information systems;relevance feedback;text analysis;user interfaces","English language Weblogs;Weblog storytelling utility;clinical settings;gender differences;health narrative search;health-related inquiry;healthcare providers;indexing;large-scale story collection;patient populations;personal Weblogs;personal story identification;relevance feedback;strokes;user interfaces","","1","","17","","","3-5 Sept. 2012","","IEEE","IEEE Conference Publications"
"Exploring the development of a web-based archive retrieval system: A case study at the institute of Modern History, Academia Sinica","S. H. Chang; Hsin-Ke Lu; Chia-Hui Lo","Graduate Institute of Information Management, Chinese Culture University, Taipei, Taiwan","2012 8th International Conference on Computing Technology and Information Management (NCM and ICNIT)","20120816","2012","2","","873","877","Web-based archive retrieval system (ARS) is gaining its importance for the convenient access, and how to have it effective is worth paying attentions. The study aims at presenting and analyzing critical viewpoints during the planning and implementing processes of a web-based historical ARS. In-depth interviews were conducted with librarians in charge of the Digital Archives of the Diplomatic and Economic Records in Modern History Project, and with IT personnel of the Computer Center of Academia Sinica participating in the construction of the ARS. A comparative study on viewpoints among archivists, IT personnel and the requirements of users has been conducted to identify relevant content of a web-based ARS, including key players' requirements and concerns, system functions, and system characteristics. By the research findings, communications between users and system developers are improved, and agreements can be made for future web-based ARS construction reference.","","Electronic:978-89-88678-68-8; POD:978-1-4673-0893-9","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268624","archive retrieval systems;archives;information retrieval;requirement analysis","Computers;Personnel","","","","0","","21","","","24-26 April 2012","","IEEE","IEEE Conference Publications"
"The Relational Database and the Concept of the Information System","D. A. Grier","George Washington University","IEEE Annals of the History of Computing","20121121","2012","34","4","9","17","E.F. Codd developed his relational database concept within a community that was attempting to create a general-purpose machine for retrieving and reasoning with data. Rather than just making progress toward that goal, this article argues that Codd's accomplishment marked the end of that effort and traces the heritage of the relational database system as it relates to the concept of an information system.","1058-6180;10586180","","10.1109/MAHC.2012.70","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359705","E.F. Codd;history of computing;information retrieval system;information system;relational databases;software industry","Database systems;History;Information systems;Relational databases","data handling;information retrieval;information systems;relational databases","Codd accomplishment;data reasoning;data retrieval;information system;relational database","","0","","43","","","Oct.-Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Improving health records search using multiple query expansion collections","D. Zhu; B. Carterette","Department of Computer and Information Sciences, University of Delaware, Newark, DE 19716, USA","2012 IEEE International Conference on Bioinformatics and Biomedicine","20121224","2012","","","1","7","The increasing prevalence of electronic health records (EHR), along with the needs for enhanced clinical care, presents new challenges to information retrieval (IR). Many clinical decision-making tasks following the philosophy of Evidence-Based Medicine (EBM) rely on the ability to find relevant health records and gather sufficient clinical evidence under severe time constraints. In this work, we present a system built upon statistical IR methods for searching flat-text health records (i.e. the doctors' notes sections of EHR) for patients with particular conditions specified via a keyword query. In particular, we use multiple external repositories for query expansion, and introduce two novel model weighting methods. Cross-validation results show that our system improves a strong baseline by 30% on mean average precision (MAP), and has a promising overall performance when compared with a manual system doing the same task.","","Electronic:978-1-4673-2560-8; POD:978-1-4673-2559-2","10.1109/BIBM.2012.6392667","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392667","electronic health records;information retrieval;query expansion","Auditory system;Electronic publishing;Encyclopedias;Internet;Medical diagnostic imaging","biomedical engineering;health care;medical computing;medical information systems;query formulation;query processing;search problems;statistical analysis","electronic health records;enhanced clinical care;evidence-based medicine;flat-text health records;health record search improvement;information retrieval;keyword query;model weighting methods;multiple external repositories;multiple query expansion collections;precision performance;severe time constraints;statistical IR methods","","5","","20","","","4-7 Oct. 2012","","IEEE","IEEE Conference Publications"
"A method for prioritizing end-user feedback for requirements engineering","S. Gärtner; K. Schneider","Software Engineering Group, Leibniz Universit&#x00E4;t Hannover, Hannover, Germany","2012 5th International Workshop on Co-operative and Human Aspects of Software Engineering (CHASE)","20120625","2012","","","47","49","Today's software-intensive systems exhibit an increasing complexity due to a broad spectrum of technical and sociotechnical aspects leading to rapid changes in requirements. To monitor these changes, we developed the ConTexter feedback system that enables end-user feedback submitted as narrative text enriched with multimedia attachments. Analyzing received end-user feedback is a work-intensive task. Thus, problems and changes in end-users' needs reach responsible requirements engineers after a significant delay. Automatic techniques are required to support this tasks. In this paper, we investigate whether end-user feedback can be prioritized automatically by combining keyword-based information retrieval and descriptive statistics. Moreover, we show in an evaluation that the obtained results are reasonable.","","Electronic:978-1-4673-1824-2; POD:978-1-4673-1823-5","10.1109/CHASE.2012.6223020","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6223020","feedback analysis;information retrieval;user involvement","Airports;Business;Equations;Mathematical model;Medical services;Multimedia communication;Software engineering","computational complexity;information retrieval;multimedia computing;statistical analysis;systems analysis","ConTexter feedback system;complexity;descriptive statistics;end-user feedback;keyword-based information retrieval;multimedia attachments;narrative text;requirements engineering;socio-technical aspects;software-intensive systems","","5","","9","","","2-2 June 2012","","IEEE","IEEE Conference Publications"
"Material Hub: A Semantic Search Engine with Rule Reasoning","S. Ma; W. Zhao; S. k. Zhang; H. Zhang","Nat. Eng. Res. Center for Software Eng., Peking Univ., Beijing, China","2012 IEEE 36th Annual Computer Software and Applications Conference Workshops","20121110","2012","","","38","44","For some special domains, if search engines only take advantage of keywords, the searchers need to mater lots of professional terms. Moreover, to refine the search interests, the professional rules and reasoning of those rules should be used. To resolving above problems, this paper focuses on extending search engines via ontology extraction and modeling, semantic rules reasoning algorithm, and feature-based ordering algorithm and related semantic technologies. A semantic search engine-Material Hub has been set up based on above research points and applied in industry. Four experiments are conducted which reveal the improvements of the accuracy and efficiency for retrieval as well as semantic rules reasoning algorithm satisfyingly contribute to an improvement in the responding time compared to other semantic reasoning algorithms.","","Electronic:978-0-7695-4758-9; POD:978-1-4673-2714-5","10.1109/COMPSACW.2012.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341547","ontology;semantic information retrieval;semantic ordering;semantic rule reasoing","Cognition;Inference algorithms;Knowledge based systems;Materials;Ontologies;Search engines;Semantics","inference mechanisms;information retrieval;ontologies (artificial intelligence);search engines","feature-based ordering algorithm;information retrieval;material hub;ontology extraction;ontology modeling;professional rules;search interests;semantic rules reasoning algorithm;semantic search engine","","0","","14","","","16-20 July 2012","","IEEE","IEEE Conference Publications"
"A text inference based answer extraction for Chinese question answering","W. Sun; C. Fu; Q. Xiao","Department of Information Technology, Qiongtai Teachers College, Haikou, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","2870","2874","Answer Extraction is the core problem of question answering and determines the performance of the Question Answering to a large extent. In this paper, we propose a text inference based answer extraction approach that can recognize the inferable relations automatically. In the inference model, lexical, syntactic and semantic inference relations are taken into account. We also build a voting system of inference to make the judgment if the question can be inferred from the answer sentence. Experimental results show that the text inference-based method for answer extraction achieve an increasing 8.5% accuracy and 9.6% MRR performance of the QA system for only supported documents.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234145","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234145","answer extraction;information retrieval;natural language processing;question answering;text inference","Accuracy;Data mining;Games;Measurement;Semantics;Syntactics;Text recognition","natural language processing;question answering (information retrieval);text analysis","Chinese question answering system;MRR performance;QA system;answer sentence;inferable relations;inference model;lexical inference relations;semantic inference relations;syntactic inference relations;text inference-based answer extraction approach;voting system","","0","","12","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Search of Web Service Based on Community","L. Wang; F. Liu; J. Yu; X. Li","Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2012 IEEE 12th International Conference on Computer and Information Technology","20121224","2012","","","1072","1075","With the rapid growth of web services, how to efficiently locate the desired web services has become a very important problem. We observe that under different contexts the descriptions of services vary in their level of semantic ambiguity. So the traditional keyword search is insufficient in the very small text fragments in web services, and semantic of the web services is not exploited. We describe the algorithms based on the complex networks for web services. Firstly with the communities discovered from the complex networks, services sharing the similar context could be clustered into same groups. Then by targeting the users' queries to the relevant group, utilize similarity metric in this group to search services. The experiment shows the approach can improve the accuracy of service search.","","Electronic:978-0-7695-4858-6; POD:978-1-4673-4873-7","10.1109/CIT.2012.219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392055","Web-based service;community;information retrieval","Communities;Complex networks;Context;Libraries;Measurement;Semantics;Web services","Web services;search engines","Web service semantic;complex network;keyword search;semantic ambiguity;similarity metric","","0","","17","","","27-29 Oct. 2012","","IEEE","IEEE Conference Publications"
"VIQI: A new approach for visual interpretation of deep web query interfaces","R. Boughammoura; L. Hlaoua; M. N. Omri","Department of Sciences of Data Processing, Faculty of Sciences of Monastir, Research Unit MARS, Tunisia","2012 8th International Conference on Computing Technology and Information Management (NCM and ICNIT)","20120816","2012","1","","344","349","Deep Web databases contain more than 90% of pertinent information of the Web. Despite their importance, users don't profit of this treasury. Many deep web services are offering competitive services in term of prices, quality of service, and facilities. As the number of services is growing rapidly, users have difficulty to ask many web services in the same time. In this paper, we imagine a system where users have the possibility to formulate one query using one query interface and then the system translates query to the rest of query interfaces. However, interfaces are created by designers in order to be interpreted visually by users, machines can not interpret query from a given interface. We propose a new approach which emulates capacity of interpretation of users and extracts query from deep web query interfaces. Our approach has proved good performances on two standard datasets.","","Electronic:978-89-88678-68-8; POD:978-1-4673-0893-9","10.1109/ICITeS.2012.6216656","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268520","Information Retrieval;Query Extraction;Query Model;Web","Automobiles;Noise;Servers;Visualization","Internet;query processing;visual databases","VIQI;deep Web databases;deep Web query interfaces;deep Web services;visual interpretation","","0","","20","","","24-26 April 2012","","IEEE","IEEE Conference Publications"
"Visual Classifier Training for Text Document Retrieval","F. Heimerl; S. Koch; H. Bosch; T. Ertl","Universoty of Stuttgart","IEEE Transactions on Visualization and Computer Graphics","20121008","2012","18","12","2839","2848","Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.","1077-2626;10772626","","10.1109/TVCG.2012.277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327290","Visual analytics;active learning;classification;human computer interaction;information retrieval;user evaluation","Classification;Human computer interaction;Information retrieval;Learning systems;Performance evaluation;Training data;Visual analytics","data visualisation;interactive systems;iterative methods;learning (artificial intelligence);pattern classification;query processing;text analysis","classification methods;filter criteria;interactive classifier training;interactive visualization;iterative feedback loops;labeled documents;machine learning;search queries;text document retrieval;text search;user controlled classification methods;visual classifier training","1","24","","48","","","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Automated Tagging for the Retrieval of Software Resources in Grid and Cloud Infrastructures","I. Katakis; G. Pallis; M. D. Dikaiakos; O. Onoufriou","","2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)","20120614","2012","","","628","635","A key challenge for Grid and Cloud infrastructures is to make their services easily accessible and attractive to end-users. In this paper we introduce tagging capabilities to the Miner soft system, a powerful tool for software search and discovery in order to help end-users locate application software suitable to their needs. Miner soft is now able to predict and automatically assign tags to software resources it indexes. In order to achieve this, we model the problem of tag prediction as a multi-label classification problem. Using data extracted from production-quality Grid and Cloud computing infrastructures, we evaluate an important number of multi-label classifiers and discuss which one and with what settings is the most appropriate for use in the particular problem.","","Electronic:978-0-7695-4691-9; POD:978-1-4673-1395-7","10.1109/CCGrid.2012.66","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6217475","classification;cloud;grid;information retrieval;machine learning;mining;software;tagging","Cloud computing;Indexes;Libraries;Machine learning;Tagging;Training","cloud computing;grid computing;identification technology","Miner soft system;application software;automated tagging;cloud computing infrastructures;multilabel classification problem;multilabel classifiers;production quality grid computing infrastructures;software resource retrieval;software resources;software search;tag prediction;tagging capability","","0","","16","","","13-16 May 2012","","IEEE","IEEE Conference Publications"
"Enhancing personalized web search re-ranking algorithm by incorporating user profile","K. Veningston.; R. Shanmugalakshmi","Department of Computer Science and Engineering, Government College of Technology Coimbatore, India","Computing Communication & Networking Technologies (ICCCNT), 2012 Third International Conference on","20121231","2012","","","1","6","In order to solve the problems of information overload on the web when searching for concrete information, the current information retrieval algorithms need to be improved. It is difficult to find satisfactory information that accurately matches user information needs even if it is present in the web database. Hence, much more ""intelligence"" should be embedded to retrieval algorithms to provide better search, retrieval, filtering and present relevant information according to individual needs. This paper presents an analysis and overview of the next generation search and retrieval in the context of personalization which is going to bring a new dimension in the field of information technology by giving a better search and retrieval facility on the web. Current web search engines are designed in such a way that the needs of any individual user are not understood and it satisfy users without considering the particular needs. Personalization of web search enables the users to obtain relevant information by incorporating individual interests and preferences. An enhanced web search re-ranking algorithm is proposed by incorporating user information obtained from various sources. The proposed algorithm is implemented in java and experimented with real time datasets and proved that the retrieval quality is improved and individual needs are addressed.","","Electronic:978-1-5090-4669-0; POD:978-1-4673-5693-0","10.1109/ICCCNT.2012.6396036","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6396036","information retrieval;personalization;re-ranking algorithm;web search","Engines;Information filters;Matched filters","Internet;Java;information retrieval;search engines","Java;Web database;Web search engines;Web search personalization;concrete information;information overload;information retrieval algorithms;personalized Web search reranking algorithm;retrieval quality;satisfactory information;user profile","","1","","25","","","26-28 July 2012","","IEEE","IEEE Conference Publications"
"Cross-lingual document similarity","A. Muhič; J. Rupnik; P. Škraba","A.I. Laboratory, Jozef Stefan Institute, Jamova 39, 10000 Ljubljana, Slovenia","Proceedings of the ITI 2012 34th International Conference on Information Technology Interfaces","20120920","2012","","","387","392","In this paper we investigated how to compute similarities between documents written in different languages based on a weekly aligned multi-lingual collection of documents. Computing the cross-lingual similarities is based on an aligned set of basis vectors obtained by either latent semantic indexing or the k-means algorithm on an aligned multi-lingual corpus. We evaluated the methods on two data sets: Wikipedia and European Parliament Proceedings Parallel Corpus.","1334-2762;13342762","Electronic:978-953-7138-26-4; POD:978-1-4673-1629-3","10.2498/iti.2012.0467","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6308038","LSI;Wikipedia;cross-lingual;information retrieval;k-means;similarity","Electronic publishing;Europe;Information services;Internet","Web sites;document handling;indexing;pattern classification","European parliament proceedings parallel corpus;Wikipedia;aligned multilingual corpus;basis vectors;cross-lingual document similarity;k-means algorithm;latent semantic indexing;multilingual document collection","","1","","15","","","25-28 June 2012","","IEEE","IEEE Conference Publications"
"Recovering Traceability Links between Code and Documentation for Enterprise Project Artifacts","S. Nagano; Y. Ichikawa; T. Kobayashi","Cyber Solutions Lab., Nippon Telephone & Telegraph, Yokosuka, Japan","2012 IEEE 36th Annual Computer Software and Applications Conference","20121110","2012","","","11","18","Recovering traceability is an important software goal in the reverse engineering process. Conventional methods based on the information retrieval model have recovered traceability links for supporting software engineers. In such methods, the call relations in the source code directly impact the accuracy of traceability links in large projects, e.g. enterprise projects. This paper uses a source code parser to create a syntax tree as a preprocessing step for information retrieval to recover traceability links between source code and documents. The effectiveness of our proposal is confirmed by a comparison with real product data obtained from an enterprise project.","0730-3157;07303157","Electronic:978-1-5090-5637-8; POD:978-1-4673-1990-4; USB:978-0-7695-4736-7","10.1109/COMPSAC.2012.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6340249","Information retrieval;Natural language processing;Software engineering;Traceability link","Conferences;Dictionaries;Encryption;Natural languages;Software;Syntactics","information retrieval;program diagnostics;project management;reverse engineering;system documentation","call relation;documentation;enterprise project artifact;information retrieval model;reverse engineering process;software goal;source code parser;syntax tree;traceability link recovery","","1","","19","","","16-20 July 2012","","IEEE","IEEE Conference Publications"
"Genre Classification for Musical Documents Based on Extracted Melodic Patterns and Clustering","B. S. Lin; T. C. Chen","Dept. of Inf. Manage., Nat. Taiwan Univ. of Sci. &amp; Technol., Taipei, Taiwan","2012 Conference on Technologies and Applications of Artificial Intelligence","20130110","2012","","","39","43","Genre classification for musical documents is conventionally based on keywords, statistical features or low-level acoustic features. Such features are either lack of in-depth information of music content or incomprehensible for music professionals. This paper proposed a classification scheme based on the correlation analysis of the melodic patterns extracted from music documents. The extracted patterns can be further clustered, and smoothing techniques for the statistics of the patterns can be utilized to improve the performance effectively. The accuracy of 70.67% for classifying five types of genre, including jazz, lyric, rock, classical and others, can be achieved, which outperforms an ANN-based classifier using statistical features significantly. The patterns can be converted into symbolic forms such that the classification results are meaningful and comprehensible for most music workers.","2376-6816;23766816","Electronic:978-0-7695-4919-4; POD:978-1-4673-4976-5","10.1109/TAAI.2012.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395003","Automatic Tagging;Genre Classification;Music Information Retrieval;N-gram Melodies;Repeated Melodic Patterns","Accuracy;Artificial neural networks;Correlation;Feature extraction;Filtering;Rocks;Smoothing methods","document handling;music;pattern classification;pattern clustering;statistical analysis","extracted melodic clustering;extracted melodic patterns;genre classification;music content;music professionals;musical documents;statistical features","","0","","11","","","16-18 Nov. 2012","","IEEE","IEEE Conference Publications"
"Semantic query expansion method for food safety domain","Bowei He; Yuehua Yang; Junping Du","School of Computer Science, Beijing University of Posts and Telecommunications, China","2012 IEEE International Conference on Computer Science and Automation Engineering","20120816","2012","","","47","50","This paper presents a ontology-based semantic query expansion method. This method takes the food safety domain as a background and combines concepts similarity computation model. Firstly, the ontology-based representation method for food safety domain knowledge is proposed. Then, the expansion of queries is realized by the semantic relationships in food safety ontology and the expansion of the lexicon for words segmentation. Finally, concepts similarity computation model is applied to set the expansion range of domain concepts. Experimental results show that this method can not only obtain the search results consistent with the search conditions in the grammatical form, but also obtain the results semantically consistent with the search conditions. Besides, the retrieval results have been sorted according to the relevance.","2327-0586;23270586","Electronic:978-1-4673-2008-5; POD:978-1-4673-2007-8","10.1109/ICSESS.2012.6269402","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6269402","domain ontology;food safety;information retrieval;semantic query expansion","Dairy products;Handheld computers;OWL;Ontologies;Powders;Toxicology","food safety;ontologies (artificial intelligence);query processing;word processing","concepts similarity computation model;food safety domain knowledge;information retrieval;lexicon expansion;ontology-based representation method;ontology-based semantic query expansion method;retrieval results;search conditions;semantic relationships;word segmentation","","0","","9","","","22-24 June 2012","","IEEE","IEEE Conference Publications"
"A Topic-based Document Retrieval Framework","X. Jia; Z. Ma","School of Computer Science, Guangdong Polytechnic Normal University, Guangzhou, China","2012 9th International Conference on Fuzzy Systems and Knowledge Discovery","20120709","2012","","","860","864","A Topic-based Document Retrieval Framework (TDRF) is proposed in this paper to resolve the topic-based document retrieval. The TDRF includes nine parts, of which Corpus Topic Learning, Query Topic Learning and Relationship Sorting are the core. Experiments on similar document retrieval showed that TDRF's instance outperforms the Vector Space Model (VSM) in average precision, recall and f-measure. The value of TDRF may lie in that it provides a simple, universal and novel methodology for document retrieval.","","Electronic:978-1-4673-0024-7; POD:978-1-4673-0025-4","10.1109/FSKD.2012.6234372","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6234372","NLP;document retrieval;information retrieval;topic learning","Computational modeling;Correlation;Educational institutions;Indexing;Information retrieval;Sorting;Vectors","document handling;information retrieval;learning (artificial intelligence)","TDRF;VSM;average precision;corpus topic learning;query topic learning;relationship sorting;topic based document retrieval framework;vector space model","","0","","9","","","29-31 May 2012","","IEEE","IEEE Conference Publications"
"Aggregated search in XML documents: What to retrieve?","N. Naffakhi; R. Faiz","University of Tunis, ISG, LARODEC, 41, Liberty Street, Bouchoucha City, 2000 Le Bardo, Tunis, Tunisia","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","In this paper, we are interested in aggregated search in XML documents. Our goal is to retrieve the best set of XML elements to be returned. We present a structured information retrieval model based on the Bayesian networks theory. The networks structure provides a natural representation of links between a document, its elements, and its contents. In this model, the user's query starts a propagation process to recover the XML elements. Thus, instead of retrieving a whole document or a list of disjoint elements that are likely to answer partially the query, we attempt to build a virtual document that aggregates a set of elements that are relevant and complementary. We evaluated our approach using the INEX 2009 collection and presented some empirical results for evaluating the impact of the aggregation approach.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216614","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216614","Aggregated search;Bayesian networks theory;Information Retrieval;XML documents;complementarity;redundancy","Aggregates;Bayesian methods;Information retrieval;Joints;Query processing;Redundancy;XML","Bayes methods;XML;document handling;query processing;search engines","Bayesian networks theory;INEX 2009 collection;XML documents;XML elements;natural representation;propagation process;search aggregation;structured information retrieval model;user query;virtual document","","0","","23","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"Practical assessment of remotely communicated end-point servers of leading web crawlers","I. A. Shoukat; W. S. Ansari; M. Iftikhar; J. Taheri; A. Y. Zomaya","Coll. of Comput. &amp; Inf. Sci., King Saud Univ., Riyadh, Saudi Arabia","2012 Ninth International Conference on Computer Science and Software Engineering (JCSSE)","20120809","2012","","","219","224","Exploration of future dreams inclined us in information quest over the global literature. Web crawlers enriched with technological phenomena for such purpose to millions of seekers. The usage of crawling tools implicates justification for their consequences as searching technology that facilitates initiative passion to target new information. Several web crawlers are available with different technological mechanism of remotely communicated servers; but their efficiency in terms of different performance metrics has been an open question. Previous studies provide inadequate comparison with limited analysis factors against these servers. Here we put an effort and provided new results by considering several performance metrics under practical estimation of technical factors with maximum capacity to evaluate foremost crawling technology based end-point servers. We extensively studied remote servers running behind Google, Yahoo, MSN, Gigablast, Mamma and Excite. We reflected their performance in terms of response time, load, health status, down time, uptime, availability and reliability. These new results would provide a deep insight to every researcher regarding to searching usages and related technological enhancement in future.","","Electronic:978-1-4673-1921-8; POD:978-1-4673-1920-1","10.1109/JCSSE.2012.6261955","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6261955","Information Retrieval and Filtering;Performance Evaluation;QoS;Search Engines;Web Crawlers","Availability;Crawlers;Google;Measurement;Search engines;Servers;Time factors","Internet;computer network performance evaluation;computer network reliability;information filtering;search engines","Excite;Gigablast;Google;MSN;Mamma;Web crawlers;Yahoo;availability;down time;health status;load;performance metrics;reliability;remotely communicated end-point servers assessment;response time;searching technology;technical factor estimation;uptime","","0","","18","","","May 30 2012-June 1 2012","","IEEE","IEEE Conference Publications"
"Multi-layer partition for query location anonymization","S. L. Wang; C. Y. Chen; I. H. Ting; T. P. Hong","Department of Information Management, National University of Kaohsiung, Taiwan","2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20121213","2012","","","378","383","Due to the proliferation of Global Position System (GPS) and smart phone technology, Location-Based Service (LBS) has attained tremendous growth in recent years. Spatial queries retrieving nearest Point-Of-Interests (POI) require actual user locations for services. However, sharing such sensitive personal location information with potentially malicious servers may cause concerns about user privacy. The current obfuscation-based approach addressing this problem cannot provide binding privacy guarantees as a trusted third-party anonymizer is required. On the other hand, the data-encryption-based and cPIR-based approaches incur costly computation overheads. Recently, the secure hardware-aided PIR-based technique has been shown to be superior to formers, but it did not consider the characteristics of data distribution of searching domain. In this work, we propose two schemes: MSQL, NSQL, based on flexible multi-layer grids and non-empty lookup table for efficient storage and retrieval on non-uniform distribution of POI data, so that improved performance of PIR-based techniques could be achieved. Numerical experiments demonstrate that the proposed techniques indeed deliver better efficiency under various criteria.","1062-922X;1062922X","Electronic:978-1-4673-1714-6; POD:978-1-4673-1713-9; USB:978-1-4673-1712-2","10.1109/ICSMC.2012.6377730","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377730","anonymization;location privacy;location-based service;private information retrieval;spatial query","Cryptography;Databases;Hardware;Mobile radio mobility management;Organizations;Privacy;Servers","data privacy;information services;query processing;table lookup","GPS;Global Position System;LBS;MSQL;NSQL;POI;POI data retrieval;POI data storage;cPIR-based approach;data-encryption-based approach;location-based service;multilayer partition;nonempty lookup table;obfuscation-based approach;personal location information;point-of-interest;privacy guarantee;query location anonymization;smart phone technology;spatial query;trusted third-party anonymizer;user location;user privacy","","0","","19","","","14-17 Oct. 2012","","IEEE","IEEE Conference Publications"
"Automatic Results Identification in Software Engineering Papers. Is it Possible?","J. A. S. Torres; D. S. Cruzes; L. d. Nascimento","Regional Center of Telematics, DPRF, Salvador, Brazil","2012 12th International Conference on Computational Science and Its Applications","20120806","2012","","","108","112","This paper provides an analysis of the main methods for sentence classification in scientific papers and evaluates the feasibility of this technique in unstructured papers in Software Engineering area, in order to automatically find the study results in this area. Tests conducted with the existing methods using unstructured Test Software papers showed results far below those reported by the authors with input sets composed by structured health papers. Therefore, there is a need for new approaches to identify results in unstructured papers.","","Electronic:978-0-7695-4710-7; POD:978-1-4673-1691-0","10.1109/ICCSA.2012.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6257618","Information Retrieval;Scientific Paper Analisys;Systematic Review","Abstracts;Classification algorithms;Context;Software;Software algorithms;Software engineering;Systematics","classification;medical information systems;software engineering","automatic results identification;scientific papers;sentence classification;software engineering papers;structured health papers;unstructured papers;unstructured test software papers","","1","","23","","","18-21 June 2012","","IEEE","IEEE Conference Publications"
"The Personal User Interface Based on Multi-agent and System Construction","X. Lijun; Y. Xianfeng","Inst. of Comput. & Inf. Eng., Xinxiang Univ., Xinxiang, China","2012 International Conference on Industrial Control and Electronics Engineering","20121004","2012","","","954","957","Without personalization is a serious limitation of today's information service, in view of which and the advantage of the agent technology, a kind of user interface profile based on multi-agent has been designed in order to make information retrieval easy, and its concrete description has also been given. The agent technology has provided us a kind of completely different information service pattern, which probably can improve the efficiency of information retrieval significantly.","","Electronic:978-1-4673-1449-7; POD:978-1-4673-1450-3","10.1109/ICICEE.2012.253","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6322542","Agent;Information Retrieval;Personalization;User Interest Profile;User Interface","Analytical models;Computational modeling;Computers;Context modeling;Data models;Information services;User interfaces","information retrieval;information services;multi-agent systems;user interfaces","agent technology;information retrieval;information service;multi agent;personal user interface;system construction","","0","","6","","","23-25 Aug. 2012","","IEEE","IEEE Conference Publications"
"Stemming for Arabic words similarity measures based on Latent Semantic Analysis model","H. Froud; A. Lachkar; S. A. Ouatik","L.S.I.S, E.N.S.A, University Sidi Mohamed Ben, Abdellah (USMBA), Fez, Morocco","2012 International Conference on Multimedia Computing and Systems","20121004","2012","","","779","783","One of the major problems of modern Information Retrieval (IR) systems is the vocabulary problem that concerns the discrepancies between terms used for describing documents and the terms used by the researchers to describe their information need. In this paper, we propose to use the well known abstractive model -Latent Semantic Analysis (LSA)- with a wide variety of distance functions and similarity measures to measure the similarity between Arabic words, such as the Euclidean Distance, Cosine Similarity, Jaccard Coefficient, and the Pearson Correlation Coefficient. LSA statistically analyze distribution of terms belonging to a large textual corpus to elaborate a semantic space in which each term is represented by a vector. In our experiments, we compare and analyze the effectiveness of this model with the different measures above in two cases: with and without Stemming, for two testing data: the first is composed of 252 documents from several categories (Economics, Politics, and Sports), and the second contains 257 politics documents only to test the influence of the variety of the used corpus. The obtained results show that, on the one hand, the variety of the corpus gives more accurate results; on the other hand, the use of the Stemming gives us more accuracy in some cases and the opposite in the others.","","Electronic:978-1-4673-1520-3; POD:978-1-4673-1518-0","10.1109/ICMCS.2012.6320289","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320289","Arabic Language;Information Retrieval Systems;Latent Semantic Analysis (LSA);Similarity Measures;Stemming","Euclidean distance;Information retrieval;Matrix decomposition;Semantics;Singular value decomposition;Vectors","document handling;information retrieval;natural language processing","Arabic words similarity measures;Euclidean distance;Jaccard coefficient;Pearson correlation coefficient;cosine similarity;distance functions;information retrieval;latent semantic analysis model","","2","","14","","","10-12 May 2012","","IEEE","IEEE Conference Publications"
"Reinforced Similarity Integration in Image-Rich Information Networks","X. Jin; J. Luo; J. Yu; G. Wang; D. Joshi; J. Han","University of Illinois at Urbana Champaign, Champaign","IEEE Transactions on Knowledge and Data Engineering","20121220","2013","25","2","448","460","Social multimedia sharing and hosting websites, such as Flickr and Facebook, contain billions of user-submitted images. Popular Internet commerce websites such as Amazon.com are also furnished with tremendous amounts of product-related images. In addition, images in such social networks are also accompanied by annotations, comments, and other information, thus forming heterogeneous image-rich information networks. In this paper, we introduce the concept of (heterogeneous) image-rich information network and the problem of how to perform information retrieval and recommendation in such networks. We propose a fast algorithm heterogeneous minimum order k-SimRank (HMok-SimRank) to compute link-based similarity in weighted heterogeneous information networks. Then, we propose an algorithm Integrated Weighted Similarity Learning (IWSL) to account for both link-based and content-based similarities by considering the network structure and mutually reinforcing link similarity and feature weight learning. Both local and global feature learning methods are designed. Experimental results on Flickr and Amazon data sets show that our approach is significantly better than traditional methods in terms of both relevance and speed. A new product search and recommendation system for e-commerce has been implemented based on our algorithm.","1041-4347;10414347","","10.1109/TKDE.2011.228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081863","Information retrieval;image mining;information network;ranking","Complexity theory;Image edge detection;Information networks;Information retrieval;Mathematical model;Ranking systems;Semantics;Visualization","Internet;electronic commerce;information retrieval;learning (artificial intelligence);recommender systems;social networking (online)","Amazon data sets;Flickr data sets;HMok-SimRank;IWSL;Internet commerce Websites;content-based similarity;e-commerce;feature weight learning;global feature learning methods;heterogeneous minimum order k-SimRank algorithm;hosting Websites;image-rich information networks;information retrieval;integrated weighted similarity learning;link-based similarity;local feature learning methods;network structure;product search;product-related images;recommendation system;reinforced similarity integration;social multimedia sharing;social networks;user-submitted images;weighted heterogeneous information networks","","10","","48","","20111115","Feb. 2013","","IEEE","IEEE Journals & Magazines"
"Automatic Transcription of Polyphonic Piano Music Using Genetic Algorithms, Adaptive Spectral Envelope Modeling, and Dynamic Noise Level Estimation","G. Reis; F. Fernandez de Vega; A. Ferreira","Department of Computer Science, Polytechnic Institute of Leiria, Portugal","IEEE Transactions on Audio, Speech, and Language Processing","20120810","2012","20","8","2313","2328","This paper presents a new method for multiple fundamental frequency (F0) estimation on piano recordings. We propose a framework based on a genetic algorithm in order to analyze the overlapping overtones and search for the most likely F0 combination. The search process is aided by adaptive spectral envelope modeling and dynamic noise level estimation: while the noise is dynamically estimated, the spectral envelope of previously recorded piano samples (internal database) is adapted in order to best match the piano played on the input signals and aid the search process for the most likely combination of F0s. For comparison, several state-of-the-art algorithms were run across various musical pieces played by different pianos and then compared using three different metrics. The proposed algorithm ranked first place on Hybrid Decay/Sustain Score metric, which has better correlation with the human hearing perception and ranked second place on both onset-only and onset–offset metrics. A previous genetic algorithm approach is also included in the comparison to show how the proposed system brings significant improvements on both quality of the results and computing time.","1558-7916;15587916","","10.1109/TASL.2012.2201475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205337","Acoustic signal analysis;automatic music transcription;fundamental frequency (F0) estimation;music information retrieval;pitch perception","Adaptation models;Estimation;Gain;Genetic algorithms;Harmonic analysis;Noise;Noise level","","","","5","","44","","20120525","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Towards ontology based health information search in Portuguese — A case study in neurologic diseases","R. Mendonça; A. F. Rosa; J. L. Oliveira; A. Teixeira","DETI/IEETA, University of Aveiro 3810-193 Aveiro, Portugal","7th Iberian Conference on Information Systems and Technologies (CISTI 2012)","20120830","2012","","","1","4","Health related information is spread across different locations, making difficult gathering, structuring and managing all this data to make it available through search and navigation to health professionals, students, researchers or even general public. In this paper, we present a workflow to support enhanced search, comprising the development of an ontology for the domain, entity annotation, advanced queries to the created knowledge base and a search interface to explore this information. The aim was to build a searching platform that would be able to present the most relevant documents as response to advanced user's queries. A proof of concept was implemented for neurologic diseases domain, demonstrating how the workflow can be used to obtain a functional ontology-based information extraction tool.","2166-0727;21660727","Electronic:978-989-96247-7-1; POD:978-1-4673-2843-2","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6263120","Information Retrieval;Neurological diseases;Ontology;Semantic annotation","Alzheimer's disease;Knowledge based systems;Navigation;Ontologies;Semantics","diseases;information retrieval;knowledge based systems;medical information systems;neurophysiology;ontologies (artificial intelligence)","Portuguese;enhanced search;general public;health professionals;health related information;knowledge base;neurologic diseases domain;ontology based health information search;ontology-based information extraction tool;researchers;students","","1","","14","","","20-23 June 2012","","IEEE","IEEE Conference Publications"
"OpenTrace: An Open Source Workbench for Automatic Software Traceability Link Recovery","E. Angius; R. Witte","Dept. of Comput. Sci. & Software Eng., Concordia Univ., Montreal, QC, Canada","2012 19th Working Conference on Reverse Engineering","20121220","2012","","","507","508","Research in automatic trace ability link recovery typically involves running a large number experiments on various datasets in order to compare the performance of different approaches in different configurations. Each experiment comprises a number of steps, including data preparation, artifact preprocessing, link generation, and filtering. Additionally, evaluation metrics need to be computed on the obtained results. We present Open Trace, the first extensible open source workbench that facilitates reproducible experiments in trace ability research through a plug gable component framework.","1095-1350;10951350","Electronic:978-0-7695-4891-3; POD:978-1-4673-4536-1","10.1109/WCRE.2012.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385149","Information Retrieval;OpenTrace;evaluation;reproduce;tool;traceability","Conferences;Logic gates;Pipelines;Reverse engineering;Software;Software engineering;Vocabulary","data handling;program compilers;public domain software;software performance evaluation","OpenTrace;artifact preprocessing;automatic software traceability link recovery;data preparation;evaluation metrics;filtering;link generation;open source workbench;performance comparison;pluggable component framework","","0","","11","","","15-18 Oct. 2012","","IEEE","IEEE Conference Publications"
"Exploiting Distributional Semantic Models in Question Answering","P. Molino; P. Basile; A. Caputo; P. Lops; G. Semeraro","Dept. of Comput. Sci., Univ. of Bari Aldo Moro, Bari, Italy","2012 IEEE Sixth International Conference on Semantic Computing","20121025","2012","","","146","153","This paper investigates the role of Distributional Semantic Models (DSMs) in Question Answering (QA), and specifically in a QA system called Question Cube. Question Cube is a framework for QA that combines several techniques to retrieve passages containing the exact answers for natural language questions. It exploits Information Retrieval models to seek candidate answers and Natural Language Processing algorithms for the analysis of questions and candidate answers both in English and Italian. The data source for the answer is an unstructured text document collection stored in search indices. In this paper we propose to exploit DSMs in the Question Cube framework. In DSMs words are represented as mathematical points in a geometric space, also known as semantic space. Words are similar if they are close in that space. Our idea is that DSMs approaches can help to compute relatedness between users' questions and candidate answers by exploiting paradigmatic relations between words. Results of an experimental evaluation carried out on CLEF2010 QA dataset, prove the effectiveness of the proposed approach.","","Electronic:978-0-7695-4859-3; POD:978-1-4673-4433-3","10.1109/ICSC.2012.53","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337098","Distributional Semantic Models;Information Retrieval;Question Answering;Semantics","Context;Engines;Pipelines;Pragmatics;Search engines;Semantics;Vectors","information retrieval;natural language processing;text analysis","DSM;English language;Italian language;distributional semantic models;exploiting distributional semantic models;geometric space;information retrieval models;mathematical points;natural language processing algorithms;natural language questions;question answering;question cube framework;search indices;unstructured text document","","0","","54","","","19-21 Sept. 2012","","IEEE","IEEE Conference Publications"
"A regressive boosting approach to automatic audio tagging based on soft annotator fusion","R. Foucard; S. Essid; M. Lagrange; G. Richard","TELECOM ParisTech, CNRS-LTCI, 37, rue Dareau, 75014, France","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","73","76","Automatic tagging of music has mostly been treated as a classification problem. In this framework, the association of a tag to a song is characterized in a “hard” fashion: the tag is either relevant or not. Yet, the relevance of a tag to a song is not always evident. Indeed, during the ground-truth annotation process, several annotators may express doubts, or disagree with each other. In this paper, we propose to fuse annotators' decisions in a way to keep information about this uncertainty. This fusion provides us continuous scores, that are used for training a regressive boosting algorithm. Our experiments show that regression with this soft ground truth leads to a more accurate learning, and better predictions, compared to traditionally used binary classification.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6287820","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6287820","Autotagging;Boosting;Machine learning;Music information retrieval;Regression analysis","Boosting;Databases;Mel frequency cepstral coefficient;Prediction algorithms;Tagging;Training;Uncertainty","audio signal processing;information retrieval;learning (artificial intelligence);music;regression analysis;signal classification","automatic audio tagging;binary classification;ground-truth annotation process;machine learning;music automatic tagging;music information retrieval;regressive boosting approach;soft annotator fusion","","1","","13","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Semantic-Based Composite Document Ranking","C. Liu; J. Li","NEC Labs. China, Beijing, China","2012 IEEE Sixth International Conference on Semantic Computing","20121025","2012","","","126","129","The traditional information retrieval techniques mainly employ statistics of words in document text and/or the link structures of document sets to rank, which have been used successfully in the global web search. However, they produce unsatisfied results for Enterprise search (ES), because ES is very different from Web search. This paper proposes a novel rank approach fitting for the ES environment. With the support of an ontology describing prior knowledge about the target domain, we first mine semantic information (concepts and relations between them) from queries (documents) with which to understand the query intentions (document contents) and exploit them for evaluating the query-document relevance, and then the semantic linkages between documents are built and consumed for evaluating the document importance, finally, the above two evaluations are integrated to produce the final ranking list. Experiments show that our approach results in significant improvements over existing solutions.","","Electronic:978-0-7695-4859-3; POD:978-1-4673-4433-3","10.1109/ICSC.2012.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337094","document ranking;enterprise information retrieval;enterprise search;semantic information","Accuracy;Computational modeling;Couplings;Knowledge based systems;Motion pictures;Ontologies;Semantics","Internet;document handling;information retrieval","ES;Web search;document importance;document query;document text;enterprise search;information retrieval techniques;link structures;query intentions;semantic based composite document ranking;semantic information","","0","","11","","","19-21 Sept. 2012","","IEEE","IEEE Conference Publications"
"Semantic similarity measure based on multiple ressources","I. Akermi; R. Faiz","LARODEC, ISG Tunis, University of Tunis, Tunis, Tunisia","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","The ability to accurately judge the semantic similarity between words is critical to the performance of several applications such as Information Retrieval and Natural Language Processing. Therefore, in this paper we propose a semantic similarity measure that uses in one hand, an online English dictionary provided by the Semantic Atlas project of the French National Centre for Scientific Research (CNRS) and on the other hand, a page counts based metric returned by a social website whose content is generated by users.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216610","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216610","Information Retrieval;Semantic similarity;Similarity measures;User-generated content;Web search","Dictionaries;Engines;Phase measurement;Semantics;Taxonomy;Web search","information retrieval;natural language processing;semantic Web;social networking (online)","French national centre for scientific research;information retrieval;multiple ressources;natural language processing;online English dictionary;page counts based metric;semantic atlas project;semantic similarity measure;social website","","1","","30","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"An ontology-based approach for semantics ranking of the web search engines results","A. Bouramoul; M. K. Kholladi; B. L. Doan","Computer Science Department, Misc Laboratory, University of Mentouri Constantine. B.P. 325, Constantine 25017, Algeria","2012 International Conference on Multimedia Computing and Systems","20121004","2012","","","797","802","This work falls in the areas of information retrieval and semantic web, and aims to improve the evaluation of web search tools. Indeed, the huge number of information on the web as well as the growth of new inexperienced users creates new challenges for information retrieval; certainly the current search engines (such as Google, Bing and Yahoo) offer an efficient way to browse the web content. However, this type of tool does not take into account the semantic driven by the query terms and document words. This paper proposes a new semantic based approach for the evaluation of information retrieval systems; the goal is to increase the selectivity of search tools and to improve how these tools are evaluated. The test of the proposed approach for the evaluation of search engines has proved its applicability to real search tools. The results showed that semantic evaluation is a promising way to improve the performance and behavior of search engines as well as the relevance of the results that they return.","","Electronic:978-1-4673-1520-3; POD:978-1-4673-1518-0","10.1109/ICMCS.2012.6320318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320318","Information Retrieval;Ontology;Results Ranking;Semantic Web;Web Search Engines","Communities;Engines;Google;Semantics","online front-ends;ontologies (artificial intelligence);query processing;relevance feedback;search engines;semantic Web;word processing","Bing search engine;Google search engine;Web content browsing;Web search engine result semantics ranking;Yahoo search engine;document words;information retrieval system semantic evaluation;ontology-based approach;query terms;relevance improvement;search engine behavior improvement;search engine performance improvement;search tool selectivity enhancement;semantic Web search tool evaluation improvement","","2","","10","","","10-12 May 2012","","IEEE","IEEE Conference Publications"
"Structural Segmentation of Multitrack Audio","S. Hargreaves; A. Klapuri; M. Sandler","Centre for Digital Music, Department of Electronic Engineering, Queen Mary University of London, London, UK","IEEE Transactions on Audio, Speech, and Language Processing","20120928","2012","20","10","2637","2647","Structural segmentation of musical audio signals is one of many active areas of Music Information Retrieval (MIR) research. One aspect of this important topic which has so far received little attention though is the potential advantage to be gained by utilizing multitrack audio. This paper gives an overview of current segmentation techniques, and demonstrates that by applying a particular segmentation algorithm to multitrack data, rather than the usual case of fully mixed audio, we achieve a significant and quantifiable increase in accuracy when locating segment boundaries. Additionally, we provide details of a structurally annotated multitrack test set available for use by other researchers.","1558-7916;15587916","","10.1109/TASL.2012.2209419","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6243190","Audio;multitrack;music information retrieval (MIR);structural segmentation","Feature extraction;Indexes;Music information retrieval;Signal processing algorithms;Timbre","","","","1","","37","","20120718","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"InfoMaps : A Session Based Document Visualization and Analysis Tool","S. Kolman; A. S. Dufilie; S. K. Anbalagan; G. Grinstein","Inst. for Visualization & Perception Res., Univ. of Massachusetts Lowell, Lowell, MA, USA","2012 16th International Conference on Information Visualisation","20120906","2012","","","274","282","InfoMaps is an information visualization tool designed for personal information management and for supporting data analysis. In this paper we briefly discuss the design of InfoMaps and explain its role in finding relevant information. InfoMaps is tightly coupled with Weave, an open source framework, providing a set of data analysis and visualization tools. Weave's framework is built with session states as its core and this provides InfoMaps the ability to store the entire user's interactions as well as visualization layouts. We discuss the implications of using the Weave framework with InfoMaps and its relevance to the field of information retrieval and visual analytics.","1550-6037;15506037","Electronic:978-0-7695-4771-8; POD:978-1-4673-2260-7","10.1109/IV.2012.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6295826","infomaps;information retrieval;viri;visual information retrieval interface","Browsers;Data visualization;Image color analysis;Layout;Servers;Visualization;Weaving","data analysis;data visualisation;design engineering;document handling;public domain software","InfoMaps design;Weave framework;data analysis;information retrieval;information visualization tool;open source framework;personal information management;session based document analysis tool;session based document visualization;visual analytics","","0","","29","","","11-13 July 2012","","IEEE","IEEE Conference Publications"
"CompoPHC: An ontology-based component for primary health care","E. Moraes; K. Brito; S. Meira","Federal Institute of Alagoas, Informatics Center, University of Pernambuco, Brazil","2012 IEEE 13th International Conference on Information Reuse & Integration (IRI)","20120917","2012","","","592","599","Nowadays there is a real need for knowledge management in healthcare field due the explosion of information. Primary Health care is a rich domain in semantic relationships between entities and it often needs expressivity in modelling knowledge. The Brazilian Primary Health care has raised the number of professionals over the last decade, and there is a vast knowledge spread that needs to be recovered. It is difficult to keep specialized professionals in faraway areas. Most of the professionals working on these places are novice and face the need to constantly update their professional knowledge base that enables them to face the diversity and “adversity” of the health process in the daily routine. But there is not explicitly organized and documents. Ontologies nowadays play a central role knowledge representation, especially in biomedical field. Ontology is an abstraction of the reality providing relations and constraints, and can be understood by humans and processed by computers; Even so the use of ontologies in medical field is not new and is rising, the primary health care has few related works applying approach. This paper proposes a web component that enables the access of specialized knowledge applied to primary health care and creates a semantic layer that enhances the user queries with an ontology representing part of the Brazilian knowledge in Primary Health Care.","","Electronic:978-1-4673-2284-3; POD:978-1-4673-2282-9; USB:978-1-4673-2283-6","10.1109/IRI.2012.6303063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6303063","Information Retrieval;Knowledge Engineering;Ontology;Primary Health Care;Semantic Web","Computers;Medical services;Ontologies;Proposals;Semantic Web;Semantics","health care;knowledge management;medical computing;ontologies (artificial intelligence);professional aspects;query processing","Brazilian knowledge;Brazilian primary health care;CompoPHC;biomedical field;health process adversity;health process diversity;healthcare field;information explosion;knowledge management;knowledge representation;knowledge spread;modelling knowledge;ontology representation;ontology-based component;professional knowledge base;semantic layer;semantic relationship;specialized knowledge;specialized professionals;user query enhancement","","0","","","","","8-10 Aug. 2012","","IEEE","IEEE Conference Publications"
"On-Line Melody Extraction From Polyphonic Audio Using Harmonic Cluster Tracking","V. Arora; L. Behera","Dept. of Electr. Eng., Indian Inst. of Technol., Kanpur, Kanpur, India","IEEE Transactions on Audio, Speech, and Language Processing","20121231","2013","21","3","520","530","Extraction of predominant melody from the musical performances containing various instruments is one of the most challenging task in the field of music information retrieval and computational musicology. This paper presents a novel framework which estimates predominant vocal melody in real-time by tracking various sources with the help of harmonic clusters (combs) and then determining the predominant vocal source by using the harmonic strength of the source. The novel on-line harmonic comb tracking approach complies with both structural as well as temporal constraints simultaneously. It relies upon the strong higher harmonics for robustness against distortion of the first harmonic due to low frequency accompaniments, in contrast to the existing methods which track the pitch values. The predominant vocal source identification depends upon the novel idea of source dependant filtering of recognition score, which allows the algorithm to be implemented on-line. The proposed method, although on-line, is shown to significantly outperform our implementation of a state-of-the-art offline method for vocal melody extraction. Evaluations also show the reduction in octave error and the effectiveness of novel score filtering technique in enhancing the performance.","1558-7916;15587916","","10.1109/TASL.2012.2227731","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6353544","Music information retrieval;pitch tracking;spectral Harmonics;vocal melody estimation","Estimation;Harmonic analysis;Hidden Markov models;Instruments;Power harmonic filters;Real-time systems;Speech","acoustic signal processing;harmonic distortion;identification;information filtering;music;tracking","computational musicology;first harmonic distortion;harmonic cluster tracking;harmonic clusters;low frequency accompaniments;music information retrieval;on-line harmonic comb tracking approach;online melody extraction;pitch values;polyphonic audio;predominant melody extraction;predominant vocal melody estimation;predominant vocal source;predominant vocal source identification;recognition score;source dependant filtering;source harmonic strength;state-of-the-art offline method;temporal constraints simultaneously;vocal melody extraction","","7","","40","","20121115","March 2013","","IEEE","IEEE Journals & Magazines"
"Highly Adaptive and Context-Aware Intelligent System of Urban Events for Mobile Devices","S. Misó; M. J. Hornos; M. L. Rodríguez","Dept. de Lenguajes y Sist. Informaticos, Univ. of Granada, Granada, Spain","2012 Eighth International Conference on Intelligent Environments","20120806","2012","","","122","129","This paper presents a system that provides the users information about cultural, training and leisure activities that they could probably be interested in. These activities shown on the screen of a mobile device will take place in the user's environment. We intend to make information more accessible to the users so that they can take advantage of the cultural opportunities that are developed in their environment as well as facilitating their social interaction. Our proposal consists of an automatic information system that dynamically retrieves data from the Internet and a context-aware recommender system that provides information on the mentioned activities to the users taking into account their location and preferences. To anticipate user's tastes and needs, we also propose a feedback system that learns user's interests while s/he is using the application.","","Electronic:978-0-7695-4741-1; POD:978-1-4673-2093-1","10.1109/IE.2012.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6258512","ambient intelligence;context-awareness;high adaptability;information retrieval;mobile devices;recommender system;urban intelligence;user model","Decision support systems","Internet;mobile computing;recommender systems","Internet;adaptive intelligent system;automatic information system;context-aware intelligent system;context-aware recommender system;cultural opportunities;mobile devices;social interaction;urban events","","0","","28","","","26-29 June 2012","","IEEE","IEEE Conference Publications"
"Query Expansion Based on Mongolian Semantics","N. Liu; J. Wang; G. Liu","Coll. of Comput. Sci., Inner Mongolia Univ., Hohhot, China","2012 Third World Congress on Software Engineering","20130110","2012","","","25","28","Accurately and effectively measuring the similarity between terms is one way to enhance the performance of information retrieval systems. At present, the extended data source which is used for Mongolian semantic query expansion is still not perfect. A new query expansion method based on Mongolian semantics is proposed for expressing the user's intention more precisely. This query expansion method includes two steps. The first step is to build an associated-dictionary by associated term rearrangement algorithm. The second step is to expand the original query by the associated-dictionary. The core of the method adopted in this paper is associated term rearrangement algorithm and re-weight expansion terms algorithm. Experiments with Lemur tools show that the retrieval results have been greatly improved by this method.","","Electronic:978-0-7695-4863-0; POD:978-1-4673-4546-0","10.1109/WCSE.2012.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6394918","Associated Degree;Information Retrieval;Semantic Query Expansion;Weights Distribution","Animals;Dictionaries;Educational institutions;Internet;Semantics;Training","performance evaluation;query processing","Lemur tools;Mongolian semantic query expansion;associated-dictionary;extended data source;information retrieval systems;re-weight expansion term algorithm;term rearrangement algorithm;user intention","","0","","14","","","6-8 Nov. 2012","","IEEE","IEEE Conference Publications"
"Revealing Trends Based on Defined Queries in Biological Publications Using Cosine Similarity","H. Mohammadzadeh; O. Paknia; F. Schweiggert; T. Gottron","Inst. of Appl. Inf. Process., Univ. of Ulm, Ulm, Germany","2012 23rd International Workshop on Database and Expert Systems Applications","20121011","2012","","","218","222","Extracting valuable information in terms of number and content of published papers in any field of research will simplify decision making for future researches and investments. A novel and simple text mining approach, called TrendFinder, has been developed in this paper to reveal the content-based trends of expert-defined queries in selected biological published papers during the last five decades. So, in order to evaluate the results, three different data sets were collected and four vectors of selected keywords were considered as the four queries. ""Title"", ""Published date"" and the ""Abstract"" were downloaded for three series of journals namely, ""Conservation Biology"", ""Ecology"", and ""The American Naturalist"" as data sets, including total number of 19,010 papers. In order to show the trend between each query and the Abstract of each paper, Cosine similarity method was used by TrendFinder. Afterwards, three diagrams were demonstrated content-based trends of the four defined queries on the three provided data sets.","1529-4188;15294188","Electronic:978-0-7695-4801-2; POD:978-1-4673-2621-6","10.1109/DEXA.2012.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6327429","Cosine Similarity;Information Retrieval;Queries;Trends in Biological Publications;Vector Space Model","Abstracts;Biodiversity;Environmental factors;Evolution (biology);Market research;Vectors","biology computing;content-based retrieval;data mining;decision making;electronic publishing;pattern matching;query processing;text analysis;vectors","Conservation Biology;Ecology;The American Naturalist;TrendFinder;abstract downloading;biological publications;content-based trends;cosine similarity;data sets;decision making;defined queries;expert-defined queries;keywords;published date downloading;published papers;text mining;title downloading;valuable information extraction;vector space model","","0","","7","","","3-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"A semantic relatedness approach for traceability link recovery","A. Mahmoud; N. Niu; S. Xu","Dept. of Computer Science and Engineering, Mississippi State University, Mississippi State, MS","2012 20th IEEE International Conference on Program Comprehension (ICPC)","20120716","2012","","","183","192","Human analysts working with automated tracing tools need to directly vet candidate traceability links in order to determine the true traceability information. Currently, human intervention happens at the end of the traceability process, after candidate traceability links have already been generated. This often leads to a decline in the results' accuracy. In this paper, we propose an approach, based on semantic relatedness (SR), which brings human judgment to an earlier stage of the tracing process by integrating it into the underlying retrieval mechanism. SR tries to mimic human mental model of relevance by considering a broad range of semantic relations, hence producing more semantically meaningful results. We evaluated our approach using three datasets from different application domains, and assessed the tracing results via six different performance measures concerning both result quality and browsability. The empirical evaluation results show that our SR approach achieves a significantly better performance in recovering true links than a standard Vector Space Model (VSM) in all datasets. Our approach also achieves a significantly better precision than Latent Semantic Indexing (LSI) in two of our datasets.","1092-8138;10928138","Electronic:978-1-4673-1216-5; POD:978-1-4673-1213-4; USB:978-1-4673-1215-8","10.1109/ICPC.2012.6240487","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240487","automated tracing;experimentation;information search and retrieval;semantic relatedness","Electronic publishing;Encyclopedias;Humans;Internet;Semantics;Strontium","relevance feedback;software performance evaluation","automated tracing tools;browsability;candidate traceability links;human intervention;human judgment;human mental model;information retrieval;performance measures;result quality;semantic relatedness approach;semantic relations;traceability link recovery;true link recovery;true traceability information determination","","13","","49","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"Improving Retrieval Performance with Wikipedia's Category Knowledge","Y. Zeng; W. Lin; K. Lei; L. Huang","Shenzhen Key Lab. for Cloud Comput. Technol. & Applic. (SPCCTA), Peking Univ., Shenzhen, China","2012 Fourth International Conference on Computational and Information Sciences","20120913","2012","","","449","452","For text search systems, the ambiguity of short queries often leads to poor performance. To solve this problem, relevance feedback via query-expansion is considered as one effective technique. However, many methods of relevance feedback barely use the knowledge of search results and the improvement of effectiveness is limited because the knowledge used is limited. In this paper we try to include Wikipedia's category knowledge to improve the poor retrieval performance. A method of category feedback is proposed, which is based on the information of Wikipedia categories. Categories instead of terms and documents are provided to users for feedback. Finally, an experimental search system is developed which demonstrates the effectiveness of our method.","","Electronic:978-0-7695-4789-3; POD:978-1-4673-2406-9","10.1109/ICCIS.2012.174","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6299999","Wikipedia;category feedback;information retrieval;query expansion","Database languages;Electronic publishing;Encyclopedias;Information retrieval;Internet;Standards","Web sites;query processing;relevance feedback;text analysis","Wikipedia category knowledge;category feedback;document handling;information retrieval;query expansion;query retrieval;relevance feedback;text search systems","","0","1","11","","","17-19 Aug. 2012","","IEEE","IEEE Conference Publications"
"Enriching Children's Experiences During and After a Museum Visit","A. Lingnau; B. van Dijk; H. Kockelkorn; J. Schmuch; I. Ruthven","Dept. of Comput. &amp; Inf. Sci., Univ. of Strathclyde, Glasgow, UK","2012 IEEE 12th International Conference on Advanced Learning Technologies","20120816","2012","","","288","292","This paper presents a scenario to enrich children's experiences during a museum visit by implicitly guiding them through the exhibition space via a collaboratively created, topic related questionnaire. At the end of the visit, a personalised virtual museum catalogue can be created. This allows children to access data about the subjects they were most interested in during their visit and re-use it either at home or in the classroom, e.g. to search for further information on-line.","2161-3761;21613761","Electronic:978-0-7695-4702-2; POD:978-1-4673-1642-2","10.1109/ICALT.2012.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268100","collaboration;information retrieval;multi-touch interfaces;museum;tangible interfaces","Buildings;Collaboration;Computers;Databases;Educational institutions;Software;USA Councils","Internet;cataloguing;information retrieval;museums;virtual reality","children experiences;data access;exhibition space;museum visit;online information search;personalised virtual museum catalogue;topic related questionnaire","","0","","8","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"Investigating the value of retention actions as a source of relevance information in the software development environment","R. Iqbal; A. Grzywaczewski; A. James; F. Doctor; J. Halloran","Applied Computing Research Centre, Coventry University, UK","Proceedings of the 2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20120621","2012","","","121","127","Even though there exists a number of search solutions targetted at software engineers the literature suggests that they are not widely used by the people engaged in code delivery [26]. Moreover, current code focused information retrieval systems such as Google Code Search (discontinued), Codeplex or Koders produce results based on specific keywords and therefore they do not take into account user context such as location, browsing history, previous interaction patterns and domain expertise. In this paper we discuss the development of task-specific information retrieval systems for software engineers. We discuss how software engineers interact with information and information retrieval systems and investigate to what extent a domain-specific search and recommendation system can be developed in order to support their work related activities. We have conducted a user study: a questionnaire and an automated observation of user interactions with the browser and software development environment. We discuss factors that can be used as implicit feedback indicators for further collaborative filtering and discuss how these parameters can be analysed using Computational Intelligence based techniques.","","Electronic:978-1-4673-1212-7; POD:978-1-4673-1211-0","10.1109/CSCWD.2012.6221807","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6221807","Personalised information retrieval;copy and paste;information seeking behaviour;pseudo-relevance;retention actions;software development","Browsers","collaborative filtering;data mining;recommender systems;relevance feedback;search engines;software engineering","Codeplex;Google Code Search;Koders;code delivery;collaborative filtering;computational intelligence based techniques;domain-specific search system;feedback indicators;recommendation system;relevance information sources;retention actions;search solutions;software development environment;software engineers;task-specific information retrieval systems","","0","","34","","","23-25 May 2012","","IEEE","IEEE Conference Publications"
"Optimal Parameters for Locality-Sensitive Hashing","M. Slaney; Y. Lifshits; J. He","Yahoo! Research, Sunnyvale, CA , USA","Proceedings of the IEEE","20120816","2012","100","9","2604","2623","Locality-sensitive hashing (LSH) is the basis of many algorithms that use a probabilistic approach to find nearest neighbors. We describe an algorithm for optimizing the parameters and use of LSH. Prior work ignores these issues or suggests a search for the best parameters. We start with two histograms: one that characterizes the distributions of distances to a point's nearest neighbors and the second that characterizes the distance between a query and any point in the data set. Given a desired performance level (the chance of finding the true nearest neighbor) and a simple computational cost model, we return the LSH parameters that allow an LSH index to meet the performance goal and have the minimum computational cost. We can also use this analysis to connect LSH to deterministic nearest-neighbor algorithms such as <formula formulatype=""inline""><tex Notation=""TeX"">$k$</tex> </formula>-<formula formulatype=""inline""><tex Notation=""TeX"">$d$</tex></formula> trees and thus start to unify the two approaches.","0018-9219;00189219","","10.1109/JPROC.2012.2193849","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6242372","Database index;information retrieval;locality-sensitive hashing;multimedia databases;nearest-neighbor search","Database systems;Histograms;Indexing;Multimedia communication;Nearest neighbor searches;Optimization;Quantization","","","","13","","27","","20120717","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Joint Optimization of Index Freshness and Coverage in Real-Time Search Engines","Y. Shin; J. Lim; J. Park","Seoul National University, Seoul","IEEE Transactions on Knowledge and Data Engineering","20121019","2012","24","12","2203","2217","Real-time search engines are increasingly indexing web content using data streams, since a number of web sources including news and social media sites are now delivering up-to-date information via streams. Accordingly, it is a crucial challenge for a real-time search engine using data streams to improve index freshness that primarily depends on the latencies involved during fetching and indexing processes. Retrieval latency is a time lag between document publication and fetching while indexing latency is a delay required for a fetched document to be indexed, which is caused by finiteness of indexing capacity. The problem of retrieval latency can be satisfactorily addressed by use of appropriate fetching scheduling or recent real-time content notification protocols. However, as the entire volume of real-time content rapidly grows, the indexing latency becomes a challenging problem. Furthermore, the need for maximizing index coverage makes it more difficult to reduce the indexing latency under the limited indexing capacity. We consider a problem of jointly optimizing the indexing latency as well as indexindexing latency coverage, in which their relative importance can be adjusted, and propose an optimization model based on inventory control theory. Extensive experiments have been conducted to validate the proposed model, and suggest that the proposed approach outperforms the other alternatives.","1041-4347;10414347","","10.1109/TKDE.2011.144","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5936066","Feed;index coverage;index freshness;information retrieval;real-time search;search engine","Indexing;Inventory control;Real time systems;Search engines","Internet;document handling;indexing;information retrieval;optimisation;protocols;real-time systems;scheduling;search engines","Web content indexing;data streams;document fetching;document publication;fetching process;fetching scheduling;index coverage;index freshness;indexing capacity finiteness;indexing latency;inventory control theory;joint optimization;optimization model;real-time content notification protocols;real-time search engines;retrieval latency","","1","","35","","20110630","Dec. 2012","","IEEE","IEEE Journals & Magazines"
"A decision data support mode suited to commander's associative think pattern","Xin Jin; Jing-Jing Yan; Wei-Tal Liang; You-Jiang Li","Science and Technology on Information System Engineering Laboratory, Nanjing Research Institute of Electronics Engineering, 210007, China","2012 International Conference on Machine Learning and Cybernetics","20121124","2012","3","","913","919","Military decision is a highly complicated process, in which commander needs to find relations from great amount of data so as to realize the situation. On decision data support, traditional taxonomy and keyword based modes depend on user skills and provide poor support to human associative think pattern. As a complement, a relation-based mode and its realization methods are proposed. Data relations are extracted in a semi-automatic method and stored as RDF (Resource Description Framework) triples, then visualized on user interface as hyperlinks. It is shown that this mode suits better to commander's associative think pattern, and has lower user skill requirement.","2160-133X;2160133X","Electronic:978-1-4673-1487-9; POD:978-1-4673-1484-8","10.1109/ICMLC.2012.6359475","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359475","Data relation mining;Decision data support;Information retrieval;Linked Data;Semantic Web","Abstracts;Humans;Manganese;Servers;Weapons","decision support systems;military computing;user interfaces","RDF;Resource Description Framework;commander associative think pattern;data relation extraction;decision data support mode;human associative think pattern;hyperlink;keyword based mode;military decision;relation-based mode;taxonomy based mode;user interface","","0","","12","","","15-17 July 2012","","IEEE","IEEE Conference Publications"
"Learning Content Similarity for Music Recommendation","B. McFee; L. Barrington; G. Lanckriet","Department of Computer Science and Engineering, University of California at San Diego, La Jolla, CA, USA","IEEE Transactions on Audio, Speech, and Language Processing","20120808","2012","20","8","2207","2218","Many tasks in music information retrieval, such as recommendation, and playlist generation for online radio, fall naturally into the query-by-example setting, wherein a user queries the system by providing a song, and the system responds with a list of relevant or similar song recommendations. Such applications ultimately depend on the notion of similarity between items to produce high-quality results. Current state-of-the-art systems employ collaborative filter methods to represent musical items, effectively comparing items in terms of their constituent users. While collaborative filter techniques perform well when historical data is available for each item, their reliance on historical data impedes performance on novel or unpopular items. To combat this problem, practitioners rely on content-based similarity, which naturally extends to novel items, but is typically outperformed by collaborative filter methods. In this paper, we propose a method for optimizing content-based similarity by learning from a sample of collaborative filter data. The optimized content-based similarity metric can then be applied to answer queries on novel and unpopular items, while still maintaining high recommendation accuracy. The proposed system yields accurate and efficient representations of audio content, and experimental results show significant improvements in accuracy over competing content-based recommendation techniques.","1558-7916;15587916","","10.1109/TASL.2012.2199109","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6213086","Audio retrieval and recommendation;collaborative filters (CFs);music information retrieval;query-by-example;structured prediction","Collaboration;Equations;Histograms;Measurement;Mel frequency cepstral coefficient;Training;Vectors","audio signal processing;collaborative filtering;content-based retrieval;music","answer queries;audio content;collaborative filter data;collaborative filter methods;collaborative filter techniques;content-based recommendation techniques;content-based similarity optimization;historical data;learning content similarity;music information retrieval;music recommendation;musical items;online radio;optimized content-based similarity metric;query-by-example setting","","16","","58","","20120606","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"A study of measures for document relatedness evaluation","E. Pyshkin; V. Klyuev","Saint-Petersburg State Polytechnical University Department of Computer Systems and Software, Engineering, 21 Politekhnicheskaya st., St.-Petersburg, 194021, Russian Federation","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20121120","2012","","","249","256","In this review paper we classified and described measures and approaches for document relatedness evaluation. For the reviewed measures we pointed out the reasons of their construction and usage limitations. We concluded this research with a discourse on challenges of the day in estimating document appropriateness in the domain of information retrieval.","","Electronic:978-83-60810-48-4; POD:978-1-4673-0708-6; USB:978-83-60810-51-4","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354356","document relatedness;information retrieval;informational search;semantic measures;semantic similarity","Electronic publishing;Encyclopedias;Internet;Measurement;Semantics;Taxonomy","document handling;information retrieval","document appropriateness;document relatedness evaluation measurement;information retrieval","","0","","36","","","9-12 Sept. 2012","","IEEE","IEEE Conference Publications"
"Mobile music modeling, analysis and recognition","P. Golik; B. Harb; A. Misra; M. Riley; A. Rudnick; E. Weinstein","Human Language Technology and Pattern Recognition, Computer Science Department, RWTH Aachen University, 52056, Germany","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","2353","2356","We present an analysis of music modeling and recognition techniques in the context of mobile music matching, substantially improving on the techniques presented in [1]. We accomplish this by adapting the features specifically to this task, and by introducing new modeling techniques that enable using a corpus of noisy and channel-distorted data to improve mobile music recognition quality. We report the results of an extensive empirical investigation of the system's robustness under realistic channel effects and distortions. We show an improvement of recognition accuracy by explicit duration modeling of music phonemes and by integrating the expected noise environment into the training process. Finally, we propose the use of frame-to-phoneme alignment for high-level structure analysis of polyphonic music.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6288387","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6288387","Music;modeling;music information retrieval;signal analysis","Accuracy;Hidden Markov models;Music;Speech recognition;Training;USA Councils","acoustic signal processing;audio signal processing;information retrieval;mobile computing;music;speech recognition","channel-distorted data;duration modeling;frame-to-phoneme alignment;high-level structure analysis;mobile music analysis;mobile music matching;mobile music modeling;mobile music recognition quality improvement;music information retrieval;music phonemes;noisy data;polyphonic music;recognition accuracy improvement","","1","","","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Sign language parameters classification from 3D virtual charactarers","K. Jaballah; M. Jemni","High School of sciences and techniques, Tunisia, LaTICE research Lab, BP56, Bab mnara, 1002, Tunis","2012 International Conference on Information Technology and e-Services","20120614","2012","","","1","6","Deaf and hard of hearing individuals are facing lot of barriers that prevent them from accessing to information. Signing avatars help them to overcome these barriers. These virtual characters are able to “speak” Sign language and subsequently able to translate any kind of information into Sign language. Recently, thanks to the advances in virtual reality and human modeling techniques, signing avatars are increasingly used by deaf communities. Moreover, thanks to the apparition of new standards, 3D signing avatars are constantly exchanged and uploaded to the World Wide Web. Unfortunately, current search engines and catalog systems that deal with signing avatars are not indexing them efficiently. In this paper, we present a new approach to recognize and index 3D signed contents based on the recognition and classification of sign language parameters. Our approach uses an adaptation of the Longest common subsequence algorithm combined with Minkowski similarity measures.","","Electronic:978-1-4673-1166-3; POD:978-1-4673-1167-0","10.1109/ICITeS.2012.6216662","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216662","3D virtual characters;Information Retrieval;Machine Translation;Sign Language","Animation;Auditory system;Avatars;Dictionaries;Educational institutions;Handicapped aids;Three dimensional displays","Internet;avatars;gesture recognition;handicapped aids","3D signed content indexing;3D signed content recognition;3D signing avatars;3D virtual character;Minkowski similarity measures;World Wide Web;deaf communities;human modeling techniques;longest common subsequence algorithm;sign language parameter classification;sign language parameter recognition;virtual reality","","0","","23","","","24-26 March 2012","","IEEE","IEEE Conference Publications"
"Activity-Enriched Computing: Capturing and Mining Activity Histories","J. D. Hollan","University of California, San Diego","Computer","20121012","2012","45","10","84","87","Ubiquitous data capture and visualization technologies make it possible to exploit histories of computer-mediated activity to develop activity-enriched computing.","0018-9162;00189162","","10.1109/MC.2012.331","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6329884","Activity Trails;ChronoViz;activity-enriched computing;data mining;information retrieval;invisible computing;ubiquitous capture","Data mining;Data visualization;IEEE standards;Information retrieval;Ubiquitous computing","computer mediated communication;data mining;data visualisation;ubiquitous computing","activity history capture;activity history mining;activity-enriched computing;computer-mediated activity;ubiquitous data capture technology;ubiquitous data visualization technology","","0","","","","","Oct. 2012","","IEEE","IEEE Journals & Magazines"
"Using IR methods for labeling source code artifacts: Is it worthwhile?","A. De Lucia; M. Di Penta; R. Oliveto; A. Panichella; S. Panichella","University of Salerno, Via Ponte don Melillo - 84084 Fisciano (SA), Italy","2012 20th IEEE International Conference on Program Comprehension (ICPC)","20120716","2012","","","193","202","Information Retrieval (IR) techniques have been used for various software engineering tasks, including the labeling of software artifacts by extracting “keywords” from them. Such techniques include Vector Space Models, Latent Semantic Indexing, Latent Dirichlet Allocation, as well as customized heuristics extracting words from specific source code elements. This paper investigates how source code artifact labeling performed by IR techniques would overlap (and differ) from labeling performed by humans. This has been done by asking a group of subjects to label 20 classes from two Java software systems, JHotDraw and eXVantage. Results indicate that, in most cases, automatic labeling would be more similar to human-based labeling if using simpler techniques - e.g., using words from class and method names - that better reflect how humans behave. Instead, clustering-based approaches (LSI and LDA) are much more worthwhile to be used on source code artifacts having a high verbosity, as well as for artifacts requiring more effort to be manually labeled.","1092-8138;10928138","Electronic:978-1-4673-1216-5; POD:978-1-4673-1213-4; USB:978-1-4673-1215-8","10.1109/ICPC.2012.6240488","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6240488","Empirical Studies;Information Retrieval;Latent Dirichlet Allocation;Topic Extraction","Context;Humans;Java;Labeling;Large scale integration;Matrix decomposition;Software","Java;information retrieval;program compilers;source coding","IR;IR methods;JHotDraw;Java software systems;automatic labeling;clustering based approaches;eXVantage;human based labeling;information retrieval;labeling source code artifacts;latent dirichlet allocation;latent semantic indexing;software artifacts;software engineering;source code elements;vector space models","","18","","43","","","11-13 June 2012","","IEEE","IEEE Conference Publications"
"Efficient Multidimensional Fuzzy Search for Personal Information Management Systems","W. Wang; C. Peery; A. Marian; T. D. Nguyen","Rutgers University, Piscataway","IEEE Transactions on Knowledge and Data Engineering","20120723","2012","24","9","1584","1597","With the explosion in the amount of semistructured data users access and store in personal information management systems, there is a critical need for powerful search tools to retrieve often very heterogeneous data in a simple and efficient way. Existing tools typically support some IR-style ranking on the textual part of the query, but only consider structure (e.g., file directory) and metadata (e.g., date, file type) as filtering conditions. We propose a novel multidimensional search approach that allows users to perform fuzzy searches for structure and metadata conditions in addition to keyword conditions. Our techniques individually score each dimension and integrate the three dimension scores into a meaningful unified score. We also design indexes and algorithms to efficiently identify the most relevant files that match multidimensional queries. We perform a thorough experimental evaluation of our approach and show that our relaxation and scoring framework for fuzzy query conditions in noncontent dimensions can significantly improve ranking accuracy. We also show that our query processing strategies perform and scale well, making our fuzzy search approach practical for every day usage.","1041-4347;10414347","","10.1109/TKDE.2011.126","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5887334","Information retrieval;multidimensional search;personal information management system;query processing","Indexing;Information management;Information retrieval;Optimization;Query processing;XML","","","","1","","31","","20110616","Sept. 2012","","IEEE","IEEE Journals & Magazines"
"Reusability assessment of test collections with multi-levels of judgments","M. Khodabakhsh; S. Araban","Department of Computer, Ferdowsi University of Mashhad, Mashhad, Iran","2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE)","20121231","2012","","","215","220","Constructing good test collection is an expensive and time-consuming process. Traditionally, test collections contain binary judgments. In recent years, however, there has been increasingly interest in test collections with Multi-levels judgments and of certain qualities. Such collections are even more expensive to construct. Therefore, ability to reuse test collections can not only save construction costs, but also boosts our confidence in their quality. This paper proposes a method for assessing reusability of a test collection with multi-level judgments. The proposed method can help IR researchers to determine whether an existing test collection with a set of multi-level judgments is suitable for evaluating a new IR system or not. Results of our experiments (on MAHAK test collection) suggest that this method can help assessing reusability of a test collection.","","Electronic:978-1-4673-4476-0; POD:978-1-4673-4475-3","10.1109/ICCKE.2012.6395381","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6395381","confidence interval;evaluation;information retrieval (IR) system;multi-level judgments;reusability;test collection","Computers;Logistics;Measurement;Support vector machines;Testing;Uncertainty;Vectors","data handling;information retrieval systems","IR system;MAHAK test collection;binary judgment level;information retrieval;multilevel judgment;reusability assessment;test collection","","0","","16","","","18-19 Oct. 2012","","IEEE","IEEE Conference Publications"
"Ranking application software retrieval results using application attributes and context","A. Leelaphattarakij; N. Prompoon","Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand","2012 Ninth International Conference on Computer Science and Software Engineering (JCSSE)","20120809","2012","","","231","235","Nowadays, various search engines provide an easy way to search an application that meets the user requirements. However, there are an increasing number of similar feature applications or a large number of applications that are intentionally implanted popular keywords in their information. Thus, search results may have the tendency not to satisfy the user needs. In this paper, we present a new method to rank application search results focusing on two criteria: application attributes and application context. Using application attributes and its context, we propose three ranking scores; rating score, content relevant score and context score. From our experiment, applying all three scores for application retrieval, significantly gives a better search quality results than the baseline and the selected combined scores using r-precision and normalized discounted cumulative gain score metric.","","Electronic:978-1-4673-1921-8; POD:978-1-4673-1920-1","10.1109/JCSSE.2012.6261957","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6261957","application software;information storage and retrieval;mobile application;pagerank;popularity;ranking","Androids;Context;Google;Humanoid robots;Internet;Mobile communication;Smart phones","information retrieval;mobile computing;search engines;user modelling","application attributes;application context;application software retrieval results ranking;content relevant score;context score;intentionally implanted popular keywords;ranking scores;rating score;search engines;search results;user needs;user requirements","","1","","14","","","May 30 2012-June 1 2012","","IEEE","IEEE Conference Publications"
"Query and Topic Sensitive PageRank for general documents","S. Hatakenaka; T. Miura","Dept.of Elect. and Elect. Engineering, HOSEI University, Tokyo, Japan","2012 14th IEEE International Symposium on Web Systems Evolution (WSE)","20121004","2012","","","97","101","In this work, we discuss both Query-Sensitive and Topic-Sentive Ranking algorithm, called Topic-Driven PageRank (TDPR), to inquire general documents based on a notion of importance. The main idea is that we extract knowledge from training data for multiple classification and build characteristic feature for each topic. By this approach, we get documents reflecting queries and topics within so that we can improve query results and to avoid topic-drift problems.","1550-4441;15504441","Electronic:978-1-4673-3056-5; POD:978-1-4673-3057-2","10.1109/WSE.2012.6320539","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320539","Information Retrieval;Ranking;Topic Sensitive and Query Sensitive PageRank","Economics;Feature extraction;Games;Training;Training data;Vectors","classification;document handling;query processing;search engines","TDPR;classification;general document;information retrieval;query result;query-sensitive ranking algorithm;topic-driven PageRank;topic-sentive ranking algorithm","","0","","9","","","28-28 Sept. 2012","","IEEE","IEEE Conference Publications"
"Polyphonic piano note transcription with recurrent neural networks","S. Böck; M. Schedl","Department of Computational Perception, Johannes Kepler University, Linz, Austria","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","121","124","In this paper a new approach for polyphonic piano note onset transcription is presented. It is based on a recurrent neural network to simultaneously detect the onsets and the pitches of the notes from spectral features. Long Short-Term Memory units are used in a bidirectional neural network to model the context of the notes. The use of a single regression output layer instead of the often used one-versus-all classification approach enables the system to significantly lower the number of erroneous note detections. Evaluation is based on common test sets and shows exceptional temporal precision combined with a significant boost in note transcription performance compared to current state-of-the-art approaches. The system is trained jointly with various synthesized piano instruments and real piano recordings and thus generalizes much better than existing systems.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6287832","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6287832","music information retrieval;neural networks","Accuracy;Hidden Markov models;Instruments;Recurrent neural networks;Spectrogram;Training","information retrieval;music;musical instruments;recurrent neural nets;regression analysis;signal classification;spectral analysis","bidirectional neural network;common test sets;erroneous note detections;exceptional temporal precision;long short-term memory units;music information retrieval;note transcription performance;one-versus-all classification approach;piano recordings;polyphonic piano note onset transcription;polyphonic piano note transcription;recurrent neural networks;single regression output layer;spectral features;synthesized piano instruments","","16","","12","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Automated quality assessment of web pages from textual content","Xiao-Lin Wang; Hai Zhao; Bao-Liang Lu","Center for Brain-Like Computing and Machine Intelligence Department of Computer Science and Engineering, Shanghai Jiao Tong University, 800 Dong Chuan Rd., 200240, China","2012 International Conference on Machine Learning and Cybernetics","20121124","2012","5","","2000","2006","Given the vastness of Internet, search engines have to find not only relevant but also high-quality web pages to satisfy users' information need. At present, most quality assessing methods for web pages are based on link analysis and user feedbacks. Considering that users acquire information from web pages mainly through reading their text, this paper addresses automated quality assessment of web pages from textual content. This paper surveys related works on assessing text's quality, summarizes quality-related features, and examines them with a real-word data set. Experimental results show that features based on the length of text are the most effective, while combining length features with other features such as part-of-speech tags and readability can further improve the accuracy.","2160-133X;2160133X","Electronic:978-1-4673-1487-9; POD:978-1-4673-1484-8","10.1109/ICMLC.2012.6359683","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359683","Quality assessment;information retrieval;supervised learning","Abstracts;Catalogs;Electronic publishing;Information services;Internet;Web pages","Internet;Web sites;information needs;quality management;search engines","Internet;Web page;automated quality assessment;information need;link analysis;part-of-speech tags;search engine;textual content;user feedback","","0","","16","","","15-17 July 2012","","IEEE","IEEE Conference Publications"
"Similarity calculation of fusion sentence surface information and the syntax structure","Hai-Yan Kang; Qing-Hua Li; Xiao-Jiao Yuan; Jun-Ling Ren","Beijing Key Laboratory of Internet Culture and Digital Dissemination, Beijing Information Science and Technology University, 10092, China","2012 International Conference on Machine Learning and Cybernetics","20121124","2012","2","","773","778","Similarity calculation is an important issue in the fields such as the question answering system, information retrieval and so on. This paper designs a model which fuses sentence surface information and the syntax structure for similarity calculation. In the calculation of the sentence similarity, firstly, it considers sentence surface information with two factors of the number of the same keywords and keywords order. Then it considers the similarity of syntactic structure. Finally, the two are combined to calculate the similarity of the sentence for answer extraction. Based on the above algorithms, a facing web intelligent QA system/retrieval system is developed in Java EE platform, Experiments show that the algorithm can effectively improve the performance of the system.","2160-133X;2160133X","Electronic:978-1-4673-1487-9; POD:978-1-4673-1484-8","10.1109/ICMLC.2012.6359023","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6359023","Similarity calculation;answer extraction;information retrieval;question answering system","Abstracts;Accuracy;Mice","Internet;Java;question answering (information retrieval)","Java EE platform;Web intelligent QA system;answer extraction;fusion sentence surface information;information retrieval;question answering system;similarity calculation;syntax structure","","0","","9","","","15-17 July 2012","","IEEE","IEEE Conference Publications"
"Entropy based locality sensitive hashing","Q. Wang; Z. Guo; G. Liu; J. Guo","Beijing University of Posts and Telecommunications, China","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","1045","1048","Nearest neighbor problem has recently been a research focus, especially on large amounts of data. Locality sensitive hashing (LSH) scheme based on p-stable distributions is a good solution to the approximate nearest neighbor (ANN) problem, but points are always mapped to a poor distribution. This paper proposes a set of new hash mapping functions based on entropy for LSH. Using our new hash functions the distribution of mapped values will be approximately uniform, which is the maximum entropy distribution. This paper also provides a method on how these parameters should be adjusted to get better performance. Experimental results show that the proposed method will be more accurate with the same time consuming.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6288065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6288065","Locality sensitive hashing (LSH);approximate nearest neighbor (ANN);entropy;information retrieval;large-scale","Acceleration;Accuracy;Entropy;Indexes;Mel frequency cepstral coefficient;Quantization;Vectors","maximum entropy methods","approximate nearest neighbor problem;entropy based locality sensitive hashing;hash mapping functions;maximum entropy distribution;p-stable distributions","","4","","","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Building and Retrieval of 3D Objects in Cultural Heritage Domain","F. Amato; A. Mazzeo; V. Moscato; A. Picariello","Dipt. di Inf. e Sist., Univ. of Naples Federico II, Naples, Italy","2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems","20120723","2012","","","816","821","Nowadays Augmented Reality (AR) is an emerging technology that promises significant results in a variety of applications. Despite the great advances in computer graphics and multimedia technologies, there is still a lack in the definition and building of a complete 3D object management system, in order to efficiently store, manage and retrieve such objects. In this paper a novel data model and a building and querying language for 3D objects are presented. This preliminary environment has been properly designed to be sufficiently powerful for including the functionalities and characteristics of modern 3D description languages, such as X3D and Collada, and at same time provides a formalism for optimization aims. Several examples from real Italian Cultural Heritage sites are provided and preliminary results are commented and discussed, showing the main advantages of the proposed system for both creation and information retrieval goals.","","Electronic:978-0-7695-4687-2; POD:978-1-4673-1233-2","10.1109/CISIS.2012.172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6245781","3D Languages;Information Retrieval","Algebra;Buildings;Computer architecture;Cultural differences;Data models;Databases;Solid modeling","augmented reality;history;image retrieval;optimisation;query languages;solid modelling","3D object building;3D object retrieval;Collada;Italian cultural heritage sites;X3D;augmented reality;complete 3D object management system;computer graphics;information retrieval;modern 3D description languages;multimedia technologies;novel data model;optimization;querying language","","1","","6","","","4-6 July 2012","","IEEE","IEEE Conference Publications"
"The Computational Materials Repository","D. D. Landis; J. S. Hummelshøj; S. Nestorov; J. Greeley; M. Dułak; T. Bligaard; J. K. Nørskov; K. W. Jacobsen","Technical University of Denmark","Computing in Science & Engineering","20121110","2012","14","6","51","57","The possibilities for designing new materials based on quantum physics calculations are rapidly growing, but these design efforts lead to a significant increase in the amount of computational data created. The Computational Materials Repository (CMR) addresses this data challenge and provides a software infrastructure that supports the collection, storage, retrieval, analysis, and sharing of data produced by many electronic-structure simulators.","1521-9615;15219615","","10.1109/MCSE.2012.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143910","information filtering;information search and retrieval;information storage and retrieval;scientific computing;storage repositories","Database systems;Graphical user interfaces;Materials processing;Quantum physics;Taxonomy","information retrieval;information storage","computational data;computational materials repository;data analysis;data collection;data retrieval;data sharing;data storage;electronic structure simulators;quantum physics calculation;software infrastructure","","30","","4","","20120131","Nov.-Dec. 2012","","IEEE","IEEE Journals & Magazines"
"Cluster aware normalization for enhancing audio similarity","M. Lagrange; L. G. Martins; G. Tzanetakis","IRCAM CNRS, 1, place Igor Stravinsky, 75004 Paris, France","2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","20120830","2012","","","1969","1972","An important task in Music Information Retrieval is content-based similarity retrieval in which given a query music track, a set of tracks that are similar in terms of musical content are retrieved. A variety of audio features that attempt to model different aspects of the music have been proposed. In most cases the resulting audio feature vector used to represent each music track is high dimensional. It has been observed that high dimensional music similarity spaces exhibit some anomalies: hubs which are tracks that are similar to many other tracks, and orphans which are tracks that are not similar to most other tracks. These anomalies are an artifact of the high dimensional representation rather than actually based on the musical content. In this work we describe a distance normalization method that is shown to reduce the number of hubs and orphans. It is based on post-processing the similarity matrix that encodes the pair-wise track similarities and utilizes clustering to adapt the distance normalization to the local structure of the feature space.","1520-6149;15206149","Electronic:978-1-4673-0046-9; POD:978-1-4673-0045-2; USB:978-1-4673-0044-5","10.1109/ICASSP.2012.6288292","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6288292","distance normalization;information retrieval;kernel-based clustering","Accuracy;Educational institutions;Indexes;Kernel;Measurement;Speech;Vectors","audio signal processing;information retrieval;matrix algebra;music","audio feature vector;audio similarity;cluster aware normalization;content-based similarity retrieval;distance normalization;feature space;high dimensional music similarity spaces;high dimensional representation;local structure;music information retrieval;musical content;pairwise track similarities;similarity matrix","","0","","12","","","25-30 March 2012","","IEEE","IEEE Conference Publications"
"Proposed method to build an ontology based on Folksonomy","R. Binzabiah; S. Wade","University of Huddersfield, UK","International Conference on Information Society (i-Society 2012)","20120827","2012","","","441","446","This paper discusses recent work on developing an ontology that can be used to represent the knowledge inherent in filmed materials. The ontology is intended to be used as the semantic basis for a retrieval system. The focus of the paper is on the method used to develop the ontology. The method is influenced by success that has been achieved in developing Folksonomies.","","Electronic:978-1-908320-05-6; POD:978-1-4673-0838-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6285012","Folksonomy;Information retrieval;Knowledge representation;Ontology;Taxonomy","Manuals;Ontologies;Taxonomy;Terminology;Thesauri;World Wide Web","humanities;information retrieval;knowledge representation;ontologies (artificial intelligence)","filmed materials;folksonomy;knowledge representation;ontology;retrieval system","","0","","18","","","25-28 June 2012","","IEEE","IEEE Conference Publications"
"Multi-Spectro-Temporal Analysis of Hyperspectral Imagery Based on 3-D Spectral Modeling and Multilinear Algebra","S. Hemissi; I. R. Farah; K. Saheb Ettabaa; B. Solaiman","University of Manouba, Laboratory RIADI, ENSI National School of Computer Sciences Engineering, Manouba, Tunisia","IEEE Transactions on Geoscience and Remote Sensing","20121219","2013","51","1","199","216","Multitemporal hyperspectral images are gaining an ever-increasing importance revealed by the ambition of the remote sensing community to develop new generation of sensors. Therefore, multitemporal images classification and change detection issues are greatly relevant in several research topics. In this paper, we propose a novel approach for modeling the temporal variation of the reflectance response as a function of time period and wavelength; summarizing the spectral signature of hyperspectral pixels as a 3-D mesh. This approach is adopted for hyperspectral time series analysis leading to the main following contribution: an advanced form of the temporal spectral signature defining the reflectance at each pixel as a congregation of the spatial/spectral/temporal dimensions. Afterward, by formulating the temporal data set in an adequate multidimensional feature space of contextual data, an innovative processing scheme exploiting the theoretical backgrounds of 3-D surface reconstruction and matching is adopted for data interpretation. Finally, an improved method for multitemporal endmember extraction and spectral unmixing based on multilinear algebra methods is introduced. A case study, in a region located in southern Tunisia, is conducted on a multitemporal subset of Hyperion images. Up to 89.86% of sampling sites have been correctly predicted by the proposed approach, outperforming conventional classifiers. The good performances obtained, on simulated multitemporal images and over various real experimental scenarios, illustrate the effectiveness and the generalization capacities of the proposed approach.","0196-2892;01962892","","10.1109/TGRS.2012.2200486","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227347","3-D modeling;3-D spectral library;3-D spectral matching;Content-based information retrieval (CBIR);hyperspectral data;multilinear algebra;time series images interpretation","Accuracy;Data models;Hyperspectral imaging;Sensors;Solid modeling;Time series analysis","geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;remote sensing","3-D mesh;3-D spectral modeling;3-D surface reconstruction;hyperion image multitemporal subset;hyperspectral pixel spectral signature;hyperspectral time series analysis;innovative processing scheme;multilinear algebra;multilinear algebra methods;multispectro-temporal analysis;multitemporal endmember extraction;multitemporal hyperspectral images;multitemporal images classification;reflectance response temporal variation;remote sensing community;simulated multitemporal images;southern Tunisia;spatial dimension;spectral dimension;spectral unmixing;temporal dimension;temporal spectral signature","","6","","50","","20120628","Jan. 2013","","IEEE","IEEE Journals & Magazines"
"Query by Humming by Using Locality Sensitive Hashing Based on Combination of Pitch and Note","Q. Wang; Z. Guo; G. Liu; J. Guo; Y. Lu","Pattern Recognition & Intell. Syst. Lab., Beijing Univ. of Posts & Telecommun., Beijing, China","2012 IEEE International Conference on Multimedia and Expo Workshops","20120816","2012","","","302","307","Query by humming (QBH) is a technique that is used for content-based music information retrieval. It is a challenging unsolved problem due to humming errors. In this paper a novel retrieval method called note-based locality sensitive hashing (NLSH) is presented and it is combined with pitch-based locality sensitive hashing (PLSH) to screen candidate fragments. The method extracts PLSH and NLSH vectors from the database to construct two indexes. In the phase of retrieval, it automatically extracts vectors similar to the index construction and searches the indexes to obtain a list of candidates. Then recursive alignment (RA) is executed on these surviving candidates. Experiments are conducted on a database of 5,000 MIDI files with the 2010 MIREX-QBH query corpus. The results show by using the combination approach the relatively improvements of mean reciprocal rank are 29.7% (humming from anywhere) and 23.8% (humming from beginning), respectively, compared with the current state-of-the-art method.","","Electronic:978-0-7695-4729-9; POD:978-1-4673-2027-6","10.1109/ICMEW.2012.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6266272","locality sensitive hashing;music information retrieval;query by humming;recursive alignment","Feature extraction;Indexing;Music information retrieval;Robustness;Vectors","information retrieval;music","MIDI files;MIREX-QBH query corpus;content-based music information retrieval;humming errors;index construction;mean reciprocal rank;note-based locality sensitive hashing;pitch;query by humming;recursive alignment","","3","","15","","","9-13 July 2012","","IEEE","IEEE Conference Publications"
"Fuzzy clustering of web documents using equivalence relations and fuzzy hierarchical clustering","S. Kumar; M. Kathuria; A. K. Gupta; M. Rani","Department of Computer Science & Engineering, YMCA University of Science and Technology, Faridabad-121006, India","2012 CSI Sixth International Conference on Software Engineering (CONSEG)","20121110","2012","","","1","5","The conventional clustering algorithms have difficulties in handling the challenges posed by the collection of natural data which is often vague and uncertain. Fuzzy clustering methods have the potential to manage such situations efficiently. Fuzzy clustering method is offered to construct clusters with uncertain boundaries and allows that one object belongs to one or more clusters with some membership degree. In this paper, an algorithm and experimental results are presented for fuzzy clustering of web documents using equivalence relations and fuzzy hierarchical clustering.","","Electronic:978-1-4673-2177-8; POD:978-1-4673-2174-7","10.1109/CONSEG.2012.6349496","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6349496","Clustering;Document Clustering;Fuzzy Clustering;Information Retrieval;Search Engine;Web Mining","Algorithm design and analysis;Clustering algorithms;Clustering methods;Euclidean distance;Information retrieval;Web mining","Internet;data mining;document handling;fuzzy logic;learning (artificial intelligence);pattern clustering","Web documents;Web mining;equivalence relations;fuzzy hierarchical clustering;uncertain boundaries;unsupervised learning","","1","","17","","","5-7 Sept. 2012","","IEEE","IEEE Conference Publications"
"Revisiting concepts of topicality and novelty - A new simple graph model that rewards and penalizes based on semantic links","F. Yu; E. Santos","Thayer School of Engineering, Dartmouth College, Hanover, N.H., U.S.A","2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20121213","2012","","","2656","2663","Research in Information Retrieval (IR) experienced a paradigm shift from first having too few documents to search from to now having way too many of them. When users have trouble finding relevant documents, they tend to become frustrated and give up searching. Scholars have attempted to reduce instances of search frustration via query expansion, information filtering, and incorporating user feedback. However, these approaches are not effective as users still experience a period of frustration before getting more relevant results. The aim of this conceptual paper is to explore possible improvements to the field by revisiting two fundamental concepts: topicality and novelty. First, we elaborate various issues with existing IR models in capturing these two concepts. Second, we illustrate a potential improvement to these issues: namely, a new simple graph space model with new topicality and novelty measures that can better capture these features of a document based on rewards and penalties for corresponding matching and missing semantic links. Lastly, we demonstrate a walk-through example using the new graph-based IR model.","1062-922X;1062922X","Electronic:978-1-4673-1714-6; POD:978-1-4673-1713-9; USB:978-1-4673-1712-2","10.1109/ICSMC.2012.6378148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6378148","diversity;graph space model;information retrieval;novelty;topicality;vector space model","Bridges;Computational modeling;Current measurement;Humans;Redundancy;Semantics;Vectors","document handling;feedback;graph theory;information filtering;query processing;semantic Web","IR model;document retrieval;information filtering;information retrieval;matching semantic link;missing semantic link;paradigm shift;query expansion;simple graph space model;user feedback","","0","","19","","","14-17 Oct. 2012","","IEEE","IEEE Conference Publications"
"A novel approach for indexing Arabic documents through GPU computing","N. N. Sophoclis; M. Abdeen; E. S. M. El-Horbaty; M. Yagoub","Ain Shams University, Cairo, Egypt","2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","20121022","2012","","","1","4","In contrast to English search engines, Arabic search engines did not have their fair share in modern studies despite the continuous growth of Arabic Internet users and data. Towards bridging the gap, this paper presents a novel indexing algorithm customized for Arabic documents. Our algorithm exploits the characteristics of the Arabic language to enhance indexing and lookup. Additionally, the algorithm utilizes the highly parallel architecture of the graphics processing unit to speed-up the indexing. Finally, we discuss some of the synchronization challenges we faced and the techniques we used to overcome them. The preliminary tests of our GPU-accelerated Arabic indexer show promising speed-up factors.","0840-7789;08407789","Electronic:978-1-4673-1433-6; POD:978-1-4673-1431-2","10.1109/CCECE.2012.6334963","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6334963","Arabic Indexer;Distributed/Parallel Information Retrieval;GPGPU;GPU synchronization","Graphics processing unit;Indexing;Internet;Kernel;Search engines;Synchronization","Internet;graphics processing units;indexing;natural language processing;search engines;synchronisation;text analysis","Arabic Internet data;Arabic Internet users;Arabic document indexing;Arabic language characteristics;Arabic search engine;GPU computing;GPU-accelerated Arabic indexer;graphics processing unit;indexing algorithm;indexing enhancement;indexing speed-up;lookup enhancement;parallel architecture;synchronization challenge","","0","","15","","","April 29 2012-May 2 2012","","IEEE","IEEE Conference Publications"
