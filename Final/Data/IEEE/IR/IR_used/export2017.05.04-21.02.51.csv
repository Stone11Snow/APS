"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=4812565,4812771,4813810,4812495,4812905,4813705,4812576,4812491,4813845,4813579,4812394,4812498,4813542,4812501,4812792,4813746,4812598,4812476,4812574,4812477,4813819,4812560,4813575,4812744,4812562,4811795,4811329,4811495,4811878,4811318,4811251,4811477,4811875,4811478,4811257,4811345,4811317,4811701,4811826,4811794,4811423,4811699,4811834,4810662,4809521,4809918,4809689,4809960,4809990,4809956,4809647,4810681,4810664,4809472,4810514,4810672,4810567,4810058,4809151,4809239,4808979,4809246,4808887,4808383,4809219,4809128,4809223,4809070,4806894,4808902,4809172,4808990,4806441,4806451,4806708,4806753,4806804,4806705,4806662,4806420,4806745,4806461,4804953,4804988,4802979,4803885,4802985,4803974,4802706,4803884,4731251,4801863,4802293,4802161,4800587,4802463,4777411,4799011,4799016,4028315",2017/05/04 21:02:51
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"FLOSSMetrics: Free/Libre/Open Source Software Metrics","I. Herraiz; D. Izquierdo-Cortazar; F. Rivas-Hern√°ndez","GSyC, LibreSoft Univ. Rey Juan Carlos, Madrid","2009 13th European Conference on Software Maintenance and Reengineering","20090410","2009","","","281","284","This paper presents FLOSSMetrics, a European Commission 6th Framework Programme- funded research project. The main objective of FLOSSMETRICS is to construct, publish and analyse a large scale database with information and metrics about libre software development coming from several thousands of software projects, using existing methodologies, and tools already developed. The project also provides a public platform for validation and industrial exploitation of results. The project is in its final stage, and some results and databases are already available, as is shown in this paper.","1534-5351;15345351","POD:978-1-4244-3755-9","10.1109/CSMR.2009.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812771","floss;flossmetrics;framework programme;free software;libre software;open source","Data visualization;Feeds;Information analysis;Information retrieval;Large-scale systems;Open source software;Programming;Software maintenance;Software tools;Visual databases","database management systems;public domain software;software engineering","European Commission 6th Framework gramme-funded research project;FLOSSMetrics;large scale database;libre software development;open source software metrics;software projects","","14","","6","","","24-27 March 2009","","IEEE","IEEE Conference Publications"
"BugTracer: A system for integrated circuit development tracking and statistics retrieval","T. N. C. Cardoso; J. A. Nacif; A. O. Fernandes; C. N. Coelho","Computer Science Department, Universidade Federal de Minas Gerais, Brazil","2009 10th Latin American Test Workshop","20090410","2009","","","1","4","Verification is one of the most critical stages in integrated circuit development. Given the current market conditions, a wise manner to improve verification results would be concentrating resources in error-prone modules. In this paper a novel method of attaching information to commit messages is introduced. Through the use of a simple and parseable language, important and more accurate statistics can be retrieved. Tools were developed in order to make commits faster and prevent erroneous data analysis.","2373-0862;23730862","POD:978-1-4244-4207-2","10.1109/LATW.2009.4813810","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813810","","Computer errors;Computer science;Data analysis;Data mining;Databases;File servers;Information retrieval;Joining processes;Resource management;Statistics","electronic engineering computing;integrated circuit design","error-prone modules;integrated circuit design;integrated circuit development tracking;parseable language;statistics retrieval","","2","","7","","","2-5 March 2009","","IEEE","IEEE Conference Publications"
"Using co-presence communities to enhance social recommendation","L. Tokarchuk; K. Shoop; A. Ma","Queen Mary University of London, School of Electronic Eng. and Computer Science, Mile End Road, London E1 4 NS England","2009 Sixth International Conference on Wireless On-Demand Network Systems and Services","20090316","2009","","","169","172","This paper proposes a social recommendation algorithm for use in a research social network environment. The social recommendation algorithm proposed combines the concepts of a relationship ontology and item-based collaborative filtering (CF). While the network setup in social networking sites can accurately reflect the social landscape of its users, it is much harder to detect the importance or strength of any one link. We therefore propose an extension to our recommendation algorithm which makes use of the idea of co-presence communities to increase the relevance of the recommendations. A co-presence community can be detected from with data collected from Bluetooth-enabled mobiles. Detection of a co-presence community can help determine the nature and importance of the social links between participating members.","","CD-ROM:978-1-4244-3375-9","10.1109/WONS.2009.4801863","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4801863","Mobile Social networks and Bluetooth;Recommender Systems;item-item recommendation;relationship ontology;social networks;social recommendation","Aggregates;Collaboration;Computer science;Filtering;Information retrieval;Information systems;Joining processes;Ontologies;Paper technology;Social network services","Bluetooth;Internet;information filtering;information filters;mobile computing;ontologies (artificial intelligence);social networking (online)","Bluetooth-enabled mobile;co-presence community;item-based collaborative filtering;relationship ontology;social networking site;social recommendation algorithm","","0","","9","","","2-4 Feb. 2009","","IEEE","IEEE Conference Publications"
"Data integration issues in IT organizations and a need to map different data formats to store them in relational databases","H. N. Kuchibhotla; D. Dunn; D. Brown","School of Technology, NC A&T State University, Greensboro, USA","2009 41st Southeastern Symposium on System Theory","20090327","2009","","","1","6","Today's organizations are dealing with the consequences of exploding IT growth in terms of data integration. The ability to seamlessly connect with its users, business customers, and coworkers is vital for success of any organization in this competitive world. Most organizations still store and exchange data in different formats, such as Spreadsheets, EDI formats, databases, text files, Mails, and increasingly XML files. The ability to map these different formats in various applications and datawarehouses is mission-critical and challenging in the day-to-day activities of all IT organizations. There is a need to develop an interface tool for mapping any combination of data from spreadsheets, EDI formats, databases, XML, and text files and store them in the relational databases.","0094-2898;00942898","POD:978-1-4244-3324-7","10.1109/SSST.2009.4806804","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806804","","Application software;Business;Communications technology;Data handling;Information retrieval;Mission critical systems;Postal services;Relational databases;Space technology;XML","business data processing;relational databases","EDI format;IT growth;IT organization;XML;data format;data integration;datawarehouse;interface tool;relational database;spreadsheet;text file","","0","","13","","","15-17 March 2009","","IEEE","IEEE Conference Publications"
"Semantic representation of text captions to aid sport image retrieval","K. Kesorn; S. Poslad","School of Electronic Engineering and Computer Science, Queen Mary University of London, Mile End Rd, E1 4NS, United Kingdom","2008 International Symposium on Intelligent Signal Processing and Communications Systems","20090327","2009","","","1","4","Image captions represent manual semantic annotation of images. These act as essential cues to represent the semantics of an image. This paper describes the process of representing, discovering, storing the semantics in a knowledge base, and then applying the semantics to aid the retrieval of visual information. We exploit a Natural Language Processing (NLP) framework in order to extract the knowledge from image captions and to transform those unstructured data into a semantic model. The novelty of the proposed framework is to use a semantic model to find implicit relationships among the concepts of photographs which are not mentioned directly in text captions. Latent Semantic Indexing (LSI) is deployed to handle ontology imperfections. Experiments tested and validated the major hypotheses of this approach.","","POD:978-1-4244-2564-8","10.1109/ISPACS.2009.4806708","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806708","","Bridges;Content based retrieval;Data mining;Image analysis;Image retrieval;Indexing;Information retrieval;Ontologies;Signal processing;Thesauri","image retrieval;knowledge acquisition;natural language processing;ontologies (artificial intelligence);sport;text analysis","NLP framework;knowledge base;natural language processing;semantic representation;sport image retrieval;text captions;visual information retrieval","","0","","4","","","8-11 Feb. 2009","","IEEE","IEEE Conference Publications"
"A Concise Representation of Range Queries","K. Yi; X. Lian; F. Li; L. Chen","Dept. Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1179","1182","With the advance of wireless communication technology, it is quite common for people to view maps or get related services from the handheld devices, such as mobile phones and PDAs. Range queries, as one of the most commonly used tools, are often posed by the users to retrieve needful information from a spatial database. However, due to the limits of communication bandwidth and hardware power of handheld devices, displaying all the results of a range query on a handheld device is neither communication efficient nor informative to the users. This is simply because that there are often too many results returned from a range query. In view of this problem, we present a novel idea that a concise representation of a specified size for the range query results, while incurring minimal information loss, shall be computed and returned to the user. Such a concise range query not only reduces communication costs, but also offers better usability to the users, providing an opportunity for interactive exploration. The usefulness of the concise range queries is confirmed by comparing it with other possible alternatives, such as sampling and clustering. Then we propose algorithms to find a good concise representation.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.195","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812495","","Bandwidth;Communications technology;Handheld computers;Hardware;Information retrieval;Mobile communication;Mobile handsets;Personal digital assistants;Spatial databases;Wireless communication","query processing;user interfaces;visual databases","concise representation;handheld devices;range queries;spatial databases","","2","","12","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"An adaptive wrapper algorithm for file transfer applications to support optimal large file transfers","A. Ghobadi; C. Eswaran; N. Muthuvelu; I. K. T. Tan; Yong Lee Kee","Faculty of Information Technology, Multimedia University, Cyberjaya, 63100 Selangor, Malaysia","2009 11th International Conference on Advanced Communication Technology","20090403","2009","01","","315","320","The overall file transmission time between peer machines is affected by network conditions, file dispatching and retrieval systems, error detection and the processing capabilities of the peers. Improving the network condition or the peers processing capabilities for speedup will incur higher cost. We introduce a wrapper algorithm for the dispatching and retrieval systems at the peers. The algorithm performs file compression-decompression, file split-merge and file chunk scheduling processes to speedup the file transfer time of large files. The wrapper algorithm is wrapped around RSYNC and the results reveal an overall reduction of file transfer time of up to 66%.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809960","File transmission time;Wrapper Algorithm;file transfer application;large files","Bandwidth;Costs;Dispatching;Globalization;Information retrieval;Information technology;Job shop scheduling;Phase detection;Quality of service;Scheduling algorithm","computer communications software;information retrieval;peer-to-peer computing;scheduling","adaptive wrapper algorithm;chunk scheduling processes;file dispatching;file transfer applications;peer machines;peers processing capabilities;retrieval systems","","8","","28","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Bug Mining Model Based on Event-Component Similarity to Discover Similar and Duplicate GUI Bugs","N. K. Nagwani; P. Singh","Department of Computer Sci. & Engg., National Institute of Technology, Raipur, India, nknagwani.cs@nitrr.ac.in","2009 IEEE International Advance Computing Conference","20090331","2009","","","1388","1392","All most all of the bugs related to graphical user interface (GUI) module of applications and are described in terms of events associated with GUI components. In this paper, a bug mining model for discovering duplicate and similar GUI bugs is presented and approach for detecting the similar and duplicate GUI bugs is described. Resolution of similar and duplicate bugs are almost identical, so if similar and duplicates are identified it will optimize the time for fixing reported GUI bugs and it can also help in achieving the faster development. A GUI bug can be transformed into a sequence of events, components and expected implementation requirements for each GUI event. This transformation is used in this paper to discover the similar and duplicate GUI bugs. First all the GUI bugs are transformed into events, components and requirements sequence, then these sequences are pair wise matched and common subsequence is generated which will indicate the similarity for the GUI bugs.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809219","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809219","duplicate bugs;event component similarity;similar bugs","Application software;Computer bugs;Databases;Documentation;Graphical user interfaces;Image retrieval;Information retrieval;Software performance;Terminology;Testing","graphical user interfaces;program debugging","GUI bugs similarity;GUI components;GUI event;bug mining model;duplicate GUI bugs;event-component similarity;graphical user interface module","","1","1","11","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Bayesian Networks Model for Xml Documents Ranking","H. y. Wang; S. y. Yang","Institute of Systems Engineering, Tianjin University, Tianjin 300072, China. E-MIAL: tjwangheyi@163.com","2006 International Conference on Machine Learning and Cybernetics","20090304","2006","","","1570","1574","As more and more data are described, stored, exchanged and represented by XML, the abilities of information retrieval for XML documents become increasingly important. However, the retrieval results to users are quite large. To text-rich XML documents' retrieval, a structured index method is designed at first, which accounts for the structure and content of each document. Then each XML document is modeled through a Bayesian network to handle both structure and content for the document. This paper also presents the inference process for computing the probability of each document on the given query. Finally documents are ranked according to the probabilities in descent. The experiments indicate that this framework can reduce the workloads and the complications, and also improve the recall and precision","2160-133X;2160133X","POD:1-4244-0061-9","10.1109/ICMLC.2006.258831","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4028315","XML document;belief network;document ranking","Bayesian methods;Computer networks;Content based retrieval;Cybernetics;Data engineering;Design methodology;Finance;Information retrieval;Machine learning;Systems engineering and theory;Web pages;XML","XML;belief networks;inference mechanisms;information retrieval;probability","Bayesian network;Bayesian network model;XML document ranking;inference process;information retrieval;probability;structured index method;text-rich XML document retrieval","","0","","9","","","13-16 Aug. 2006","","IEEE","IEEE Conference Publications"
"Classification of web resident sensor resources using Latent Semantic Indexing and ontologies","W. Majavu; T. van Zyl; T. Marwala","Meraka Institute, CSIR, P.O. Box 395, Pretoria 0001, South Africa","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","518","523","Web resident sensor resource discovery plays a crucial role in the realisation of the Sensor Web. The vision of the Sensor Web is to create a web of sensors that can be manipulated and discovered in real time. A current research challenge in the sensor web is the discovery of relevant web sensor resources. The proposed approach towards solving the discovery problem is to implement a modified Latent Semantic Indexing by making use of an ontology for classifying Web Resident Resources found in geospatial Web portals. The paper presents the use of Latent Semantic Indexing, an information retrieval mechanism, biased by combining ontology concepts to the terms and objects, for improving the knowledge extraction from web resident documents. The use of an ontology, before indexing of terms, to create a semantic link between documents with relevant content improves automatic content extraction and document classification.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811329","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811329","Document clustering;Latent Semantic Indexing;Ontolgies;Resource Classification;Sensor Web","Data mining;Indexing;Information retrieval;Ontologies;Portals","classification;data mining;indexing;information retrieval;ontologies (artificial intelligence);portals","Latent Semantic Indexing;Web resident documents;automatic content extraction;document classification;geospatial Web portals;information retrieval;knowledge extraction;ontologies;sensor web;web resident resource classification;web resident sensor resource discovery","","1","","22","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"RFID tags: Positioning principles and localization techniques","M. Bouet; A. L. dos Santos","Laboratoire d'Informatique de Paris 6, Universit&#233; Pierre et Marie Curie, France 75016","2008 1st IFIP Wireless Days","20090410","2008","","","1","5","RFID is an automatic identification technology that enables tracking of people and objects. Both identity and location are generally key information for indoor services. An obvious and interesting method to obtain these two types of data is to localize RFID tags attached to devices or objects or carried by people. However, signals in indoor environments are generally harshly impaired and tags have very limited capabilities which pose many challenges for positioning them. In this work, we propose a classification and survey the current state-of-art of RFID localization by first presenting this technology and positioning principles. Then, we explain and classify RFID localization techniques. Finally, we discuss future trends in this domain.","2156-9711;21569711","CD-ROM:978-1-4244-2829-8; POD:978-1-4244-2828-1","10.1109/WD.2008.4812905","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812905","RFID;localization;positioning algorithm","Batteries;Circuits;Indoor environments;Informatics;Information retrieval;RFID tags;Radio frequency;Radiofrequency identification;Supply chains;Wireless networks","indoor radio;radio direction-finding;radio tracking;radiofrequency identification","RFID tags;automatic identification technology;indoor services;localization techniques;positioning principles;state-of-art of RFID localization","","98","3","16","","","24-27 Nov. 2008","","IEEE","IEEE Conference Publications"
"A hybrid hyper tag anti-collision algorithm in RFID system","Tae Hee Kim; Seong Joon Lee","Department of Computer Engineering, Kyungpook National University, 1370, Sankyuk-dong, Buk-gu, Daegu, 702-701, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","02","","1276","1281","A tag collision arbitration algorithm for RFID passive tags is one of the important issues for fast tag identification, since reader and tag have a shared wireless channel in RFID system. This paper suggests hybrid hyper query tree algorithm to prevent the tag-collisions. The suggested algorithms determine the specified point in time for tag to transfer ID to reader by using value 1 of the upper 3 bit based on QT. Also, because the transferred upper 3 bits of tag is different depending on the time of transfer, it is possible to predict in the suggested Algorithm. In the performance evaluation through simulation, it shows the suggested algorithm has higher performance in the number of queries compared to other Tree-based protocols.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809647","Anti-collision;Query Tree;RFID;Tag","Automation;Fires;Food technology;Information retrieval;Passive RFID tags;Production;Protocols;RFID tags;Radiofrequency identification;Roads","radiofrequency identification;trees (mathematics);wireless channels","RFID system;hybrid hyper query tree algorithm;tag collision arbitration algorithm;wireless channel","","0","","12","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Analysis of the impact of background traffic on the performance of 802.11 power saving mechanism","Y. He; R. Yuan; X. Ma; J. Li","Tsinghua University, Beijing, China","IEEE Communications Letters","20090310","2009","13","3","164","166","In our previous work, we have identified the issue that the performance of 802.11 power saving mechanism degrades significantly with the presence of background traffic. In this letter, we propose a simple model to theoretically analyze the impact of background streams on the power performance of an individual mobile station in power saving mode (PSM). By reasonable assumptions on medium access details, we develop a set of mathematical formulas which gives the ratio of prolonged data retrieval time under condition of background traffic within a beacon period. Simulation results demonstrate the validity of the proposed model for analysis of 802.11 PSM.","1089-7798;10897798","","10.1109/LCOMM.2009.081803","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4799011","IEEE 802.11;background traffic;multiple access;power saving mechanism","Analytical models;Computational modeling;Degradation;Helium;Information retrieval;Performance analysis;Power system modeling;System analysis and design;Telecommunication traffic;Traffic control","computer network performance evaluation;mobile radio;telecommunication traffic;wireless LAN","802.11 power saving mechanism;background traffic;data retrieval time;mobile station;power saving mode","","7","","6","","","March 2009","","IEEE","IEEE Journals & Magazines"
"A New Cryptographic Hash Function based on Latin Squares and Non-linear Transformations","S. K. Pal; D. Bhardwaj; R. Kumar; V. Bhatia","Scientific Analysis Group, DRDO, Metcalfe House, Delhi - 110054, INDIA, skptech@yahoo.com","2009 IEEE International Advance Computing Conference","20090331","2009","","","862","867","In this paper, we propose a new and efficient cryptographic hash function based on random Latin squares and non-linear transformations. The developed scheme satisfies basic as well as desirable properties of an ideal hash function. Use of repeated lookup on Latin squares, non-linear transformations and complex shift operations further increase the strength of our cryptographic hash function at a low computational overhead. It also ensures pre-image resistance and collision resistance as required for the present day lightweight cryptographic applications.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809128","Hash function;Latin square;computational overhead;non-linear transformations","Computer science;Cryptography;Data structures;Databases;Error correction codes;Fingerprint recognition;Indexes;Information retrieval;Information security;Turning","cryptography","collision resistance;cryptographic Hash function;latin squares;lightweight cryptographic applications;nonlinear transformations;pre-image resistance","","2","","10","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Architecture of Knowledge Retrieval Based on Multi-Agent Systems","C. Deng; Y. Lan","Department of Control Engineering, Chengdu University of Information Technology, Chengdu, Sichuan, 610225, China. chenglidcj@cuit.edu.cn","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","1083","1086","Agent methodology represents a new way of analyzing, designing, and implementing complex software applications. Multi-agent systems (MAS) refer to all types of systems composed of multiple (semi-) autonomous components. To retrieval the knowledge in the fields of distributed fault detection or distributed fault tolerance, This paper have compared the characteristic of deliberative agent architectures with reactive agent architectures and hybrid agent architectures of MAS, proposed a hybrid intelligent agent model to solve the problem of fault learning. The MAS program language of Jade and Lygon are applied to accomplish the different kinds of knowledge learning.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810681","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810681","Jade;Multi-Agent Systems;distributed fault detection;hybrid agent architectures;knowledge learning","Computer architecture;Control engineering;Fault detection;Fault tolerant systems;Information retrieval;Information technology;Intelligent agent;Knowledge based systems;Multiagent systems;Standardization","distributed processing;knowledge acquisition;multi-agent systems;software architecture;software fault tolerance","agent methodology;deliberative agent architectures;distributed fault detection;distributed fault tolerance;knowledge retrieval;multiagent systems;reactive agent architectures","","0","","5","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Random Sensory Networks: A Delay Analysis","C. Florens; M. Sharif; R. J. McEliece","Dept. of Electr. Eng., California Inst. of Technol., Pasadena, CA","IEEE Transactions on Information Theory","20090316","2009","55","4","1650","1664","A fundamental function performed by a sensory network is the retrieval of data gathered collectively by sensor nodes. The metrics that measure the efficiency of this data collection process are time and energy. In this paper, we study via simple discrete mathematical models, the statistics of the data collection time in sensory networks. Specifically, we analyze the average minimum delay in collecting randomly located/distributed sensors data for networks of various topologies when the number of nodes becomes large. Furthermore, we analyze the impact of various parameters such as size of packet, transmission range, and channel erasure probability on the optimal time performance. Our analysis applies to directional antenna systems as well as omnidirectional ones. This paper focuses on directional antenna systems and briefly presents results on omnidirectional antenna systems. Finally, a simple comparative analysis shows the respective advantages of the two systems.","0018-9448;00189448","","10.1109/TIT.2009.2012999","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802293","Broadcasting;data collection;delay;directional antenna;sensor networks","Ad hoc networks;Directional antennas;Energy measurement;Information retrieval;Mathematical model;Military computing;Performance analysis;Statistical distributions;Time measurement;Wireless sensor networks","delays;sensor fusion;wireless sensor networks","channel erasure probability;data collection process;delay analysis;omnidirectional antenna systems;optimal time performance;random sensory networks","","4","","11","","","April 2009","","IEEE","IEEE Journals & Magazines"
"Summarization Based on Event-cluster","S. Lin; J. Liao","College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian, China. splin@fzu.edu.cn","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","1014","1017","Event-based summarization extracts and organizes summary sentences in terms of the events which stand for complete meaning of sentences. However, the basic event-based extracting method does not take the similarity of events into account, which leads to data sparseness. As a way to solve the problem, we explored a new method, what we call the shallow semantic pattern, which extracts a semantic representation of crucial information in the text. By employing shallow semantic pattern in event-based summarization, not only can we group up the similar events according to the acceptation of word, but also the similarity based on frequent application is detected. We chose four assessment methods in ROUGE to evaluate our system, and used the text sets in DUC 2005 as the inputs of our system to get the summaries. In order to do the comparison, the results of the experiments done on the other four systems are listed, and the outcome shows that our method achieves an encouraging level.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810664","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810664","event-based summarization;event-cluster;shallow semantic pattern","Computer science;Connectors;Data mining;Distributed computing;Educational institutions;Event detection;Frequency;Information retrieval;Mathematics;Text recognition","pattern clustering;text analysis","data sparseness;event similarity;event-based summarization extraction;semantic pattern;semantic representation;shallow semantic pattern","","0","","23","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Automatic audio segmentation using the Generalized Likelihood Ratio","D. Wang; R. Vogt; M. Mason; S. Sridharan","Queensland University of Technology, Brisbane, 4001 AUSTRALIA","2008 2nd International Conference on Signal Processing and Communication Systems","20090410","2008","","","1","5","This paper presents a novel technique for segmenting an audio stream into homogeneous regions according to speaker identities, background noise, music, environmental and channel conditions. Audio segmentation is useful in audio diarization systems, which aim to annotate an input audio stream with information that attributes temporal regions of the audio into their specific sources. The segmentation method introduced in this paper is performed using the Generalized Likelihood Ratio (GLR), computed between two adjacent sliding windows over preprocessed speech. This approach is inspired by the popular segmentation method proposed by the pioneering work of Chen and Gopalakrishnan, using the bayesian information criterion (BIC) with an expanding search window. This paper will aim to identify and address the shortcomings associated with such an approach. The result obtained by the proposed segmentation strategy is evaluated on the 2002 rich transcription (RT-02) Evaluation dataset, and a miss rate of 19.47% and a false alarm rate of 16.94% is achieved at the optimal threshold.","","CD-ROM:978-1-4244-4243-0","10.1109/ICSPCS.2008.4813705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813705","","Australia;Background noise;Bayesian methods;Costs;Indexing;Information retrieval;Radio broadcasting;Speech recognition;Streaming media;TV broadcasting","audio streaming;maximum likelihood estimation","2002 rich transcription evaluation dataset;Chen;Gopalakrishnan;RT-02;audio diarization systems;audio stream;automatic audio segmentation;background noise;generalized likelihood ratio;popular segmentation method;speaker identities","","5","","7","","","15-17 Dec. 2008","","IEEE","IEEE Conference Publications"
"A QoS-oriented management framework for reconfigurable mobile mashup services","H. Xu; M. Song; X. Luo","Beijing University of Posts and Telecommunications, 100876, China","2009 11th International Conference on Advanced Communication Technology","20090403","2009","03","","2001","2005","With the popularity of Web2.0, web has become to be a application programming platform where third parties can create new applications (mash-ups) mixing the functionality offered by others. Now this trend has extended to the domain of mobile networks. The combination of mashup and mobile networks would make the mashup more powerful and provide additional user value. This paper explores how to realize operational carrier-class mobile mashup services. A QoS-oriented service management framework is presented to dynamically select services which satisfy customers' QoS requirements and replace services during run-time. Feedback-enhanced QoS model and selection algorithm are detailed discussed. After that, combing the actual network condition of the mobile network, we illuminate how to deploy the framework. Finally, we implement a simplified prototype of the framework and verity the performance of this module. With the research and design of management framework, we can enhance the reliability, flexibility, and dynamic adaptability of mobile mashup applications.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809472","Mashup;QoS;Reconfiguration;Service management","Content based retrieval;Costs;Functional programming;Handheld computers;Information retrieval;Mashups;Probability distribution;Prototypes;Quality of service;Runtime","Internet;computer network management;mobile computing;mobility management (mobile radio);quality of service","QoS-oriented management framework;Web2.0;application programming platform;dynamic adaptability;feedback-enhanced QoS model;mobile networks;network reliability;quality of service;reconfigurable mobile mashup services;selection algorithm","","1","","16","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Ranking of Object Summaries","G. J. Fakas; Z. Cai","Dept. of Comput. & Math., Manchester Metropolitan Univ., Manchester","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1580","1583","A previously proposed keyword search paradigm produces, as a query result, a ranked list of object summaries (OSs); each OS summarizes all data held in a relational database about a particular data subject (DS). This paper further investigates the ranking of OSs and their tuples as to facilitate (1) the top-k ranking of OSs and also (2) the generation of partial size-l OSs (i.e. comprised of the l most important tuples). Therefore, a global Importance score for each tuple of the database (denoted as Im(t<sub>i</sub>)) is investigated and quantified. For this purpose, ValueRank (an extension of ObjectRank) is introduced which facilitates the estimation of scores for arbitrary databases (in contrast to PageRank-style techniques that are only effective on bibliographic databases). In addition, a variation of Combined functions are investigated for assigning an Importance score to an OS (denoted as Im(OS)) and a local Importance score of their tuples (denoted as Im(OS, t<sub>i</sub>)). Preliminary experimental evaluation on DBLP and Northwind Databases is presented.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.171","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812576","Keyword Search;Object Summaries","Data engineering;Data mining;Image databases;Image retrieval;Image storage;Information retrieval;Keyword search;Mathematics;Relational databases;Shape","database management systems;query processing","Northwind Databases;PageRank-style techniques;bibliographic databases;data subject;keyword search paradigm;object summaries;relational database","","6","","7","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Reachability Indexes for Relational Keyword Search","A. Markowetz; Y. Yang; D. Papadias","Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1163","1166","Due to its considerable ease of use, relational keyword search (R-KWS) has become increasingly popular. Its simplicity, however, comes at the cost of intensive query processing. Specifically, R-KWS explores a vast search space, comprised of all possible combinations of keyword occurrences in any attribute of every table. Existing systems follow two general methodologies for query processing: (i) graph based, which traverses a materialized data graph, and (ii) operator based, which executes relational operator trees on an underlying DBMS. In both cases, computations are largely wasted on graph traversals or operator tree executions that fail to return results. Motivated by this observation, we introduce a comprehensive framework for reachability indexing that eliminates such fruitless operations. We describe a range of indexes that capture various types of join reachability. Extensive experiments demonstrate that the proposed techniques significantly improve performance, often by several orders of magnitude.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.191","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812491","Keywoed Search;Reachability Indexing;Relational Databases","Computer science;Costs;Data engineering;Indexing;Information retrieval;Keyword search;Query processing;Relational databases;Space technology;Tree graphs","query processing;reachability analysis;relational databases;trees (mathematics)","graph traversals;intensive query processing;materialized data graph;reachability indexes;relational keyword search;relational operator trees","","5","","26","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"A model of shared grasp affordances from demonstration","J. D. Sweeney; R. Grupen","Laboratory for Perceptual Robotics, University of Massachusetts Amherst, USA","2007 7th IEEE-RAS International Conference on Humanoid Robots","20090410","2007","","","27","35","This paper presents a hierarchical, statistical topic model for representing the grasp preshapes of a set of objects. Observations provided by teleoperation are clustered into latent affordances shared among all objects. Each affordance defines a joint distribution over position and orientation of the hand relative to the object and conditioned on visual appearance. The parameters of the model are learned using a Gibbs sampling method. After training, the model can be used to compute grasp preshapes for a novel object based on its visual appearance. The model is evaluated experimentally on a set of objects for its ability to generate grasp preshapes that lead to successful grasps, and compared to a baseline approach.","2164-0572;21640572","CD-ROM:978-1-4244-1862-6; POD:978-1-4244-1861-9","10.1109/ICHR.2007.4813845","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813845","","Context modeling;Fingers;Grasping;Information retrieval;Laboratories;Neuroscience;Probability distribution;Robots;Sampling methods;Vocabulary","dexterous manipulators;position control;sampling methods","Gibbs sampling;grasp preshapes;hand orientation;hand position;shared grasp affordances;statistical topic model;teleoperation;visual appearance","","14","","14","","","Nov. 29 2007-Dec. 1 2007","","IEEE","IEEE Conference Publications"
"Content-based music retrieval with nonlinear feature space transformation using relevance feedback","S. Sakai; K. Kameyama","Graduate School of Systems and Information Engineering, University of Tsukuba, JAPAN","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","1379","1384","In recent years, studies of similar music retrieval have been conducted actively. However, because the similarity of music is based on subjective measures, the systems need to be adaptive to user preference. In this paper, we propose an effective method for adaptive similar music retrieval reflecting the user preference by nonlinear feature space transformation based on relevance feedback. The user's evaluation to initial retrieval ranking is used to train a neural network feature space transformation. Also, as the initial stage of retrieval, a coarse division is made to the set of music in the database, to reduce the retrieval computation. In the experiments, it was observed that in the retrieval after feature space transformation, the proposed method gave preferred retrievals according to objective measures when compared with the case without transformation.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811478","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811478","Music retrieval;coarse division;nonlinear transformation;relevance feedback","Content based retrieval;Data mining;Feature extraction;Feedback;Multiple signal classification;Music information retrieval;Neural networks;Neurofeedback;Spatial databases;Systems engineering and theory","content-based retrieval;learning (artificial intelligence);music;relevance feedback;transforms","content-based music retrieval;neural network;nonlinear feature space transformation;relevance feedback","","1","","16","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Rateless erasure resilient codes for content storage and distribution in P2P networks","S. Kim; S. Lee","Department of Computer Science and Engineering, Sogang University, Seoul, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","01","","444","446","In this paper, we investigate the performance of rateless erasure resilient codes for distributed file storage in P2P networks. While the key distinctive feature of the proposed codes is the scalability to an arbitrary number of peers in the P2P network, it will be shown that the proposed rateless erasure resilient codes also offer great improvement in increase in bandwidth and reliability of data retrieval compared to other erasure resilient coding schemes.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809990","Erasure resilient codes;P2P networks;distributed storage","Bandwidth;Computer science;Decoding;Encoding;File servers;Information retrieval;Network servers;Parity check codes;Peer to peer computing;Scalability","file organisation;information retrieval;peer-to-peer computing","P2P networks;content storage;data retrieval;rateless erasure resilient codes","","0","","9","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"An Efficient Histogram Algorithm for Retrieval from Lighting Changed-Images","N. Y. Kim; K. S. You; G. H. Yoo; H. S. Kwak","Dept. of Image Eng., Chonbuk Nat. Univ., Jeonju","2008 Second International Conference on Future Generation Communication and Networking Symposia","20090410","2008","3","","203","206","In this paper, we describe the Gaussian Weighted Histogram Intersection (GWHI) algorithm. The algorithm is able to provide positive results in image retrieval. But the histogram algorithm alters the histogram of an image using particular lighting conditions. Even two images with little differences in lighting are not easily matched. Therefore, we propose that the Histogram Matching Algorithm (HMA) is able to overcome the problem of an image being changed by the intensity or color in the image retrieval. The proposed algorithm is insensitive to changes in the lighting. From the experiment results, the proposed algorithm can achieve up to 30% more recall than the GWHI algorithms, respectively. Also, it can achieve up to 34% more precision than GWHI. Therefore, with our experiments, we are able to show that the proposed algorithm shows limited variation to changes in lighting.","","CD-ROM:978-0-7695-3546-3; POD:978-1-4244-3430-5","10.1109/FGCNS.2008.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813579","CBIR;GWHI;Histogram Matching Algorithm","Conferences;Content based retrieval;Digital images;Frequency;Histograms;Image databases;Image retrieval;Information retrieval;Pixel;Shape","Gaussian processes;image colour analysis;image matching;image retrieval;statistical analysis","Gaussian weighted histogram intersection algorithm;colour image retrieval;histogram matching algorithm;lighting changed-image","","0","","6","","","13-15 Dec. 2008","","IEEE","IEEE Conference Publications"
"Joint bitstream level identification and retrieval method of JPEG 2000 images for digital cinema","O. Watanabe; T. Fukuhara; H. Kiya","Takushoku University, Dpet. of Electronics & Computer Systems, 815-1, Tatemachi, Hachioji-shi, Tokyo, Japan","2008 International Symposium on Intelligent Signal Processing and Communications Systems","20090327","2009","","","1","4","A joint bitstream level identification and retrieval method for JPEG 2000 images is proposed in this paper. Although the main purpose is to identify a JPEG 2000 image, the proposed method simultaneously retrieves JPEG 2000 images from a certain query with the computation of similarity. The proposed method uses the number of zero bitplanes, which is obtained by parsing the header information without decoding JPEG 2000 codestream, to achieve joint identification and retrieving of JPEG 2000 image. Some experimental results on retrieving JPEG 2000 images are provided to evaluate the performance of the proposed method. The main advantage is not only accuracy but also fast processing. Since there is no need to decode JPEG 2000 images in the proposed method, averaged time consumption due to retrieving operation is about less than 1[ms] and is independent on image size. Moreover, the proposed method can be combined with the scalability of JPEG 2000 codestream to satisfy trade-off between accuracy and speed.","","POD:978-1-4244-2564-8","10.1109/ISPACS.2009.4806753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806753","","Decoding;Entropy;Image coding;Image retrieval;Information retrieval;Motion pictures;Scalability;Standardization;Transform coding;Wavelet coefficients","cinematography;image coding;image retrieval","JPEG 2000 image;digital cinema;joint bitstream level identification;query computation;retrieval method","","0","","11","","","8-11 Feb. 2009","","IEEE","IEEE Conference Publications"
"Decoupling data dissemination from mobile sink's trajectory in wireless sensor networks","A. C. Viana; A. Ziviani; R. Friedman","INRIA, France","IEEE Communications Letters","20090310","2009","13","3","178","180","We propose an efficient proactive data dissemination approach that allows a mobile sink to effectively gather a representative view of a monitored region covered by n sensor nodes by visiting any m nodes, where m << n. Moreover, the proposed strategy allows the mobile sink to follow any trajectory through the deployment region, thus decoupling the data dissemination management from the mobile sink's trajectory.","1089-7798;10897798","","10.1109/LCOMM.2009.081990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4799016","Random walks;proactive data dissemination","Information retrieval;Intelligent networks;Laboratories;Monitoring;Robustness;Routing;Scientific computing;Spread spectrum communication;Tracking;Wireless sensor networks","information dissemination;mobile radio;wireless sensor networks","decoupling data dissemination management;mobile sink trajectory;wireless sensor network","","11","","7","","","March 2009","","IEEE","IEEE Journals & Magazines"
"Color and Texture Features for Image Indexing and Retrieval","S. Murala; A. B. Gonde; R. P. Maheshwari","Department of Electrical Engineering, Indian Institute of Technology Roorkee, Roorkee-247 667, Uttarakhand, India. subbumurala@gmail.com","2009 IEEE International Advance Computing Conference","20090331","2009","","","1411","1416","The novel approach combines color and texture features for content based image retrieval (CBIR). The color and texture features are obtained by computing the mean and standard deviation on each color band of image and sub-band of different wavelets. The standard Wavelet and Gabor wavelet transforms are used for decomposing the image into sub-bands. The retrieval results obtained by applying color histogram (CH) + Gabor wavelet transform(GWT) to a 1000 image database demonstrated significant improvement in precision and recall, compared to the color histogram (CH), wavelet transform (WT), wavelet transform + color histogram (WT + CH) and Gabor wavelet transform (GWT).","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809223","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809223","","Content based retrieval;Feature extraction;Frequency;Histograms;Image databases;Image retrieval;Indexing;Information retrieval;Shape;Wavelet transforms","Gabor filters;content-based retrieval;feature extraction;image colour analysis;image retrieval;image texture;indexing;visual databases;wavelet transforms","Gabor filter;color feature extraction;content based image retrieval;image database;image indexing;mean standard deviation;texture feature extraction;wavelet transform","","15","","13","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"A Data Structure for Sponsored Search","A. C. K√∂nig; K. Church; M. Markov","Microsoft Corp., Redmond, WA","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","90","101","Inverted files have been very successful for document retrieval, but sponsored search is different. Inverted files are designed to find documents that match the query (all the terms in the query need to be in the document, but not vice versa). For sponsored search, ads are associated with bids. When a user issues a search query, bids are typically matched to the query using broad-match semantics: all the terms in the bid need to be in the query (but not vice versa). This means that the roles of the query and the bid/document are reversed in sponsored search, in turn making standard retrieval techniques based on inverted indexes ill-suited for sponsored search. This paper proposes novel index structures and query processing algorithms for sponsored search. We evaluate these structures using a real corpus of 180 million advertisements.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812394","Ad Retrieval;Computational Advertising;Indexing;Sponsored Search","Algorithm design and analysis;Data engineering;Data structures;Filters;Indexing;Information retrieval;Intrusion detection;Performance analysis;Query processing;Web search","data structures;query processing;search problems","broad-match semantics:;data structure;index structures;inverted files;inverted indexes;query processing algorithms;search query;sponsored search;standard retrieval techniques","","7","","26","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Searching Business Information with Hopfield Neural Network in Electronic Commerce Environment","Z. Wang; Q. Wang; D. Wang","Research Institute of System Engineering, Northeastern University, Shenyang, Liaoning, 110004, China. P. R. wangzhengdr@gmail.com","2007 Second International Conference on Bio-Inspired Computing: Theories and Applications","20090327","2007","","","159","163","In traditional commercial environment, business information retrieval is limited in searching scope and quality. As enterprise turns to electronic commerce (EC) environment, the quality of business information on supply and sale directly affects the level of enterprise operations. This paper analyses the problem of business information retrieval in EC environment, and proposes a Hopfield neural network based business information retrieval model using Internet information resources by means of Artificial Intelligence (AI) and Information Retrieval (IR) theory. Through generating extended query terms by Hopfield neural network and ranking the results, the proposed model can expand the searching scope and increase the precision of retrieval, so as to provide valuable business information for enterprises.","","CD-ROM:978-1-4244-4106-8; POD:978-1-4244-4105-1","10.1109/BICTA.2007.4806441","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806441","","Artificial intelligence;Business;Electronic commerce;Hopfield neural networks;Information analysis;Information retrieval;Internet;Marketing and sales;Search engines;Systems engineering and theory","Internet;electronic commerce;information retrieval;neural nets","Hopfield neural network;Internet information resource;artificial intelligence;business information retrieval;electronic commerce environment;enterprise operation;searching scope","","2","","12","","","14-17 Sept. 2007","","IEEE","IEEE Conference Publications"
"Image Semantic Classification algorithm Research On Kernel PCA support vector machine","L. Shi; G. Gu; H. Liu; J. Shen; L. Shi","School of Computer Science and Technology, Harbin Engineering University, Harbin, 150001, China. Shilei","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","422","424","The image semantic classification is new focus in the image classification field, the traditional classification algorithm is based on the low level visual features, but there is an enormous semantic gap problem between the low-level visual features and high-level semantic information of images. An image semantic classification approach is proposed based on Kernel PCA Support Vector Machines (KPCA SVM). The KPCA, which is investigated from the complexity of optimization problem and the generalization performance, is the explicit extension of the optimal separating hyper planes classifier. By using KPCA as a preprocessing step, we also generalize SVM. Consequently, conventional clustering algorithms can be easily kernelized in the linear feature space instead of a nonlinear one. To evaluate the newly established KPCA SVM algorithms, we utilized it to the problem of image semantic classification, and the experimental results show that the proposed approach is more accurate in image semantic classification than PCA SVM algorithm.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810514","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810514","Kernel PCA;image semantic classification;support vector machine","Classification algorithms;Computer science;Content based retrieval;Image classification;Image retrieval;Information retrieval;Kernel;Principal component analysis;Support vector machine classification;Support vector machines","image classification;principal component analysis;support vector machines","clustering algorithms;image semantic classification algorithm;kernel PCA support vector machine;optimization problem;semantic gap problem","","1","","11","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Localized generalization error based active learning for image annotation","B. Sun; W. W. Y. Ng; D. S. Yeung; J. Wang","Media and Life science Computing Laboratory, Shenzhen Graduate School, Harbin Institute of Technology, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","60","65","Content-based image auto-annotation becomes a hot research topic owing to the development of image retrieval system and the storing technology of multimedia information. It is a key step in most of those image processing applications. In this work, we adopt active learning to image annotation for reducing the number of labeled images required for supervised learning procedure. Localized Generalization Error Model (L-GEM) based active learning uses localized generalization error bound as the sample selection criterion. In each turn, the most informative sample from a set of unlabeled samples is selected by the L-GEM based active learning will be labeled and added to the training dataset. A heuristic and a Q value selection improvement methods are introduced in this paper. The experimental results show that the proposed active learning efficiently reduces the number of labeled training samples. Moreover, the improvement method improve the performances in both testing accuracy and training time which are both essential in image annotation applications.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811251","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811251","active learning;image annotation;localized generalization error model","Computer errors;Image retrieval;Information retrieval;Labeling;Laboratories;Learning systems;Multimedia computing;Multimedia systems;Sun;Supervised learning","content-based retrieval;image retrieval;learning (artificial intelligence)","active learning;content-based image autoannotation;image processing;image retrieval system;localized generalization error;multimedia information;supervised learning procedure","","12","","23","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"An adaptable Question-Answer System using match of multi-sphere knowledge","Su-Kyoung Kim; Ki-Hong Ahn; Ho-Jin Choi","Korea Information and Communication University, School of Engineering, 119, Moonji-ro, Yuseong-gu, Daejeon, 305-732, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","03","","2219","2224","For a performance enhancement of the current a QAS(Question-Answer System) and web search, the adaptable semantic decision is important which support expression of natural language and meaning of a input sentence about UIDD(User Information Demand Description) is a difficult situation natural language and adaptable semantic decision in a sentence up to now. For overcome these problems, a various research was attempted that decided for search result about UIDD based on information retrieval model, and a lot of a QAS and search engine like Google applied which was currently proposed, but it is difficult to provide the retrieval results that determine flexibly a similarity of meaning. Therefore, this study, match knowledge which use the semantic inference rule which expressed knowledge in multi-sphere knowledge, and inferenced knowledge combine with n-ary representation-based ontology by weight, then determine various semantic similarity about a vocabulary in UIDD. As decide on semantic similarity, we propose an approach which presented a most adaptable answer that input a question to a QAS. And a proposed approach-based, we implement a QAS which service a prescription regarding a symptom and inform a foot reflective point to user. An experiment result of implement system, determine adaptable to a semantic similarity of a vocabulary regarding input query sentence, and show a stable query result, and a proposal approach demonstrated that we were effective.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809521","","Foot;Information retrieval;Intelligent networks;Knowledge engineering;Natural languages;Ontologies;Proposals;Search engines;Vocabulary;Web search","Internet;information retrieval systems;natural languages;ontologies (artificial intelligence);query processing;search engines","Web search;adaptable question-answer system;adaptable semantic decision;foot reflective point;information retrieval model;input query sentence;multisphere knowledge;n-ary representation-based ontology;natural language;search engine;user information demand description","","0","","8","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Mobile Medicine: Providing Drug Related Information through Natural Language Queries via SMS","A. Langer; B. Kumar; A. Mittal; L. V. Subramaniam","Dept. of Electronics & Computer Engineering, Indian Institute Of Technology, Roorkee, India","2009 IEEE International Advance Computing Conference","20090331","2009","","","546","551","Although the idea of mobile medical information systems is not new, most of the current systems operate as standalone programs with intermittent connectivity on high end mobile phones or PDAs. In a rural setting however, few people possess such expensive devices. The information regarding drugs is available on various Web sites but this information does not reach people at the time of medical emergencies. Moreover lack of doctors often forces people to take advice from paramedics, who may not be very qualified. In such situations the information on drugs and diseases would allow both the patient and the medic to cross check the diagnosis and the prescribed medicines. In this paper we explore the viability and present our system implementation to handle drug information related queries via SMS. We identify various classes into which drug information questions can be broken and pass the query through various modules to retrieve answers from the drug knowledge sources.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809070","","Databases;Drugs;Information retrieval;Internet;Medical diagnostic imaging;Mobile computing;Mobile handsets;Natural languages;Personal digital assistants;Pharmaceutical technology","drugs;electronic messaging;medical information systems;mobile computing;natural languages;query processing;telemedicine","drug;mobile medical information system;mobile medicine;natural language query answering;short messaging service;standalone program","","1","","25","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"FRISK: Keyword Query Cleaning and Processing in Action","K. Q. Pu; X. Yu","Fac. of Sci., Univ. of Ontario Inst. of Technol., Oshawa, ON","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1531","1534","Keyword search provides a simple yet effective way for the users to query and explore the underlying documents. In the recent years, there have been a great deal of research and development activities on extending keyword search capabilities to handle relational data, the dominant form in which business data are stored. Algorithms and prototype systems, such as Discover, DBXplorer, BANKS, and SPARK, have been developed to support retrieving relevant information from relational databases using keyword queries.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.139","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812565","keyword query cleaning;keyword search","Books;Cleaning;Data engineering;Information retrieval;Information technology;Keyword search;Prototypes;Relational databases;Web sites;World Wide Web","query processing;relational databases","FRISK;information retrieval;keyword query cleaning;keyword query processing;keyword search;relational database handling","","2","","8","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Choosing Best Hashing Strategies and Hash Functions","M. Singh; D. Garg","Computer science and Engineering Department, Thapar University, Patiala","2009 IEEE International Advance Computing Conference","20090331","2009","","","50","55","The paper gives the guideline to choose a best suitable hashing method hash function for a particular problem. After studying the various problem we find some criteria has been found to predict the best hash method and hash function for that problem. We present six suitable various classes of hash functions in which most of the problems can find their solution. Paper discusses about hashing and its various components which are involved in hashing and states the need of using hashing for faster data retrieval. Hashing methods were used in many different applications of computer science discipline. These applications are spread from spell checker, database management applications, symbol tables generated by loaders, assembler, and compilers. There are various forms of hashing that are used in different problems of hashing like Dynamic hashing, Cryptographic hashing, Geometric hashing, Robust hashing, Bloom hash, String hashing. At the end we conclude which type of hash function is suitable for which kind of problem.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4808979","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4808979","Hashing;buckets;collision;cryptographic hashing;dynamic hashing;hash function;hash table;resolution","Application software;Computer science;Cryptography;Data structures;Databases;Dictionaries;Guidelines;Information retrieval;Scattering;Sorting","file organisation;information retrieval","computer science discipline;data retrieval;hash function;hashing method","","4","","21","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"A Subspace Symbolization Approach to Content-Based Video Search","X. Zhou; X. Zhou; A. Bouguettaya; J. A. Taylor","ICT Centre, CSIRO, ACT","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1191","1194","We propose a subspace symbolization approach, namely SUDS, for content-based search on very large video databases. The novelty of SUDS is that it explores the data distribution in subspaces to build a visual dictionary. With this dictionary, the video data are processed using string matching techniques with two-step data simplification. A compact video representation model is developed by transforming each keyframe into a word that is a series of symbols in the dominant subspaces. Then, we present an innovative similarity measure called ED, which draws from the concept of the edit distance on strings to conduct video matching. The experimental results demonstrate the high effectiveness of SUDS with optimal parameters.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.198","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812498","","Australia;Computational efficiency;Data engineering;Dictionaries;Information retrieval;Spatial databases;Video compression;Video sequences;Videoconference;Visual databases","content-based retrieval;image matching;image representation;string matching;very large databases;video databases;video retrieval","content-based video search;data simplification;edit distance;innovative similarity measure;string matching technique;subspace symbolization approach;very large video database;video matching;video representation model;visual dictionary","","1","","14","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Rational Interpolation of Analytic Functions From Real or Imaginary Parts of Frequency-Response Data: A Subspace-Based Approach","H. Akcay; S. Turkay","Center for Syst. Eng. & Appl. Mech., Catholic Univ. of Louvain, Louvain-la-Neuve","IEEE Signal Processing Letters","20090316","2009","16","5","350","353","In this letter, construction of analytic functions from evaluations of real or imaginary parts on finite subsets of the unit circle is studied. The points in the subsets are not necessarily uniformly spaced as in the most existing works. An algorithm exactly retrieving finite-dimensional systems from noise-free data is presented. This algorithm is based on a recent frequency-domain subspace algorithm to identify discrete-time power spectra from non-uniformly spaced measurements and inherits consistency and robustness properties of the latter with respect to inaccuracies in data.","1070-9908;10709908","","10.1109/LSP.2009.2016016","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802161","Conjugate function;Hilbert transform;rational interpolation;subspace-based identification","Digital signal processing;Discrete transforms;Frequency;Image analysis;Information retrieval;Interpolation;Mathematics;Power measurement;Signal processing algorithms;Transfer functions","Hilbert transforms;conjugate gradient methods;interpolation;signal processing","Hilbert transform;conjugate function;discrete-time power spectra;finite-dimensional systems;frequency-response data;noise-free data;rational interpolation","","1","","12","","","May 2009","","IEEE","IEEE Journals & Magazines"
"Collective Sort and Emergent Patterns of Tuple Distribution in Grid-Like Networks","M. Casadei; M. Viroli; M. Santarelli","Univ. di Bologna, Cesena","2008 IEEE 17th Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises","20090331","2008","","","70","75","A crucial aspect of managing data-centric and pervasive networks is the design of proper self-organizing data-distribution approaches, including aggregation, collection, diffusion, and so on.In this paper we introduce the collective sort problem for network environments that aims at collecting and segregating data by similarity. Data is collected and segregated in localized areas of the network selected by an emergent process.A solution to the problem is analyzed for a coordination scenario featuring a grid-like distributed set of Linda tuple spaces and a set of sorting agents executing a probabilistic protocol resembling brood collection in ant colonies.Based on simulation, we show how patterns of data collection emerge in spite of the very basic observation and computation abilities of sorting agents.","1524-4547;15244547","POD:978-0-7695-3315-5","10.1109/WETICE.2008.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806894","","Character generation;Clustering algorithms;Collaborative work;Computational modeling;Computer network management;Information retrieval;Protocols;Sorting;Technology management;Wireless sensor networks","data handling;grid computing;multi-agent systems;ubiquitous computing","Linda tuple spaces;ant colonies;data-centric networks;grid-like networks;pervasive networks;probabilistic protocol;self-organizing data-distribution;sorting agents;tuple distribution","","0","","10","","","23-25 June 2008","","IEEE","IEEE Conference Publications"
"Page Ranking Algorithms: A Survey","N. Duhan; A. K. Sharma; K. K. Bhatia","YMCA Institute of Engineering, Faridabad, India, E-mail: neelam","2009 IEEE International Advance Computing Conference","20090331","2009","","","1530","1537","Web mining is an active research area in present scenario. Web Mining is defined as the application of data mining techniques on the World Wide Web to find hidden information. This hidden information i. e. knowledge could be contained in content of Web pages or in link structure of WWW or in Web server logs. Based upon the type of knowledge, Web mining is usually divided in three categories: Web content mining, Web structure mining and Web usage mining. An application of Web mining can be seen in the case of search engines. Most of the search engines are ranking their search results in response to users' queries to make their search navigation easier. In this paper, a survey of page ranking algorithms and comparison of some important algorithms in context of performance has been carried out.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809246","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809246","Data mining;Page ranking;Search engine;WWW;Web mining","Data mining;Indexing;Information retrieval;Navigation;Search engines;Web mining;Web pages;Web server;Web sites;World Wide Web","Internet;Web sites;data mining;information retrieval;search engines","Web content mining;Web pages;Web server logs;Web structure mining;Web usage mining;World Wide Web;active research;data mining;hidden information;page ranking algorithm;search engines;search navigation","","18","6","17","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Video watermarking retrievable from MPEG data without specifying the location of embedding","Tadashi Yoshikura; Kaoru Arakawa","Department of Computer Science, Meiji University, 1-1-1 Higashimita, Tama-ku, Kawasaki, 214-8571 Japan","2008 International Symposium on Intelligent Signal Processing and Communications Systems","20090327","2009","","","1","4","A new method of blind watermarking for video is proposed for retrieving watermarks from MPEG bit streams directly without decoding. This method is based on Sakazawa's method which also aims at retrieving from MPEG bit streams, but realizes embedding and retrieval without specifying the location of the DCT blocks to be embedded. This method does not care about the location of the embedded block. Moreover, since our method embeds more redundantly than Sakazawa's method, the watermarks are less visible, even if the video is enlarged. Also the proposed method is robust, especially against cropping attacks, since the location of the embedded block is not fixed. Computer simulations show the high performance of this method and also show the robustness to various types of attacks.","","POD:978-1-4244-2564-8","10.1109/ISPACS.2009.4806705","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806705","","Computer simulation;Decoding;Discrete cosine transforms;Image reconstruction;Image retrieval;Information retrieval;Robustness;Streaming media;Video compression;Watermarking","data compression;data encapsulation;discrete cosine transforms;video coding;video retrieval;video streaming;watermarking","DCT block;MPEG bit stream;Sakazawa method;blind video watermarking retrieval;data embedding technique;discrete cosine transform","","0","","3","","","8-11 Feb. 2009","","IEEE","IEEE Conference Publications"
"Data Pre-define Storage of collaborative Bridge Design System","M. Chen","School of Civil Engineering and Safety, Shanghai Institute of Technology, Shanghai, China. chenmchen@21cn.com","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","1048","1051","The dataflow of an bridge design system is tightly coupled with expensive numerical computation. This is one of the main reasons for the lack of a generic purpose data management system for collaborative design system. In the effort of trying to alleviate some of the problems, we have introduced a pre-definition approach for data storage of collaborative design system. The main design principle of the system is to define data storage based on design knowledge, so that only the need data is stored during design process. Firstly, based on the analysis of bridge design system in data storage, a model for data representation of collaborative design system is presented. Secondly, two kinds of data pre-define storage mode including interactive mode and knowledge-based mode are studied. Lastly, pre-define model of data storage is validated through an bridge project.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810672","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810672","Collaborative design;bridge design;data storage","Bridges;Collaboration;Data analysis;Data engineering;Data models;Databases;Design engineering;Information retrieval;Memory;Systems engineering and theory","data flow computing;data handling;data structures;groupware","collaborative bridge design system;data management system;data predefine storage;data representation;dataflow;design knowledge","","0","","4","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Concise representations for approximate association rules","Y. Xu; Y. Li; G. Shaw","Faculty of Information Technology, Queensland University of Technology, Brisbane, 4001, Australia","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","94","101","The quality of association rule mining has drawn more and more attention recently. One problem with the quality of the discovered association rules is the huge size of the extracted rule set. Often for a dataset, a huge number of rules can be extracted, but many of them can be redundant to other rules and thus useless in practice. Mining non-redundant rules is a promising approach to solve this problem. In this paper, we firstly propose a definition for redundancy; then we propose a concise representation called reliable basis for representing non-redundant association rules for both exact rules and approximate rules. We prove that the redundancy elimination based on the reliable basis does not reduce the belief to the extracted rules. We also prove that all association rules can be deduced from the reliable basis. Therefore the reliable basis is a lossless representation of association rules. Experimental results show that the reliable basis significantly reduces the number of extracted rules.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811257","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811257","Association rule mining;certainty factor;closed itemsets;generator;redundant association rules","Association rules;Australia;Data analysis;Data mining;Information retrieval;Information technology;Itemsets;Redundancy","data mining;knowledge representation","approximate association rules;association rule mining;concise representations;nonredundant association rules;reliable basis","","3","","18","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Web document categorization by Support Vector Clustering","Daming Shi; M. H. Tsui; Jigang Liu","School of Computer Engineering, Nanyang Technological University, Singapore 639798","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","1483","1488","Search Engine has proven its effectiveness for retrieval of information from World Wide Web. Traditionally, the search results are arranged in an ordered list by popularity and relevancy. However, the enormous size of matched Web pages causes inefficiency for users to locate the most relevant Web pages. A proper organization of the search result is important to improve its browsability of Web searching. In this paper, we proposed by performing Support Vector Clustering (SVC) on the search result to reorganize results in groups of similar context to facilitate effective browsing of search result by the users. SVC is a nonparametric clustering algorithm that can group clusters with arbitrary shapes and without the need to specify the number of clusters. It is a kernel clustering method that maps via a nonlinear function to a high dimension feature space. To obtain the optimal clustering result, choosing of the accurate parameters (kernel width and penalty coefficient) for SVC is crucial. In this paper, it proposed an automatic tuning method for SVC parameters to obtain the optimal result. The results from the experiment have proven the effectiveness and usefulness of above mentioned method. The performance is comparable to other popular clustering techniques.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811495","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811495","Document clustering;simulated annealing;support vector clustering","Clustering algorithms;Clustering methods;Information retrieval;Kernel;Search engines;Simulated annealing;Static VAr compensators;Support vector machines;Web pages;Web sites","Internet;information retrieval;nonlinear functions;online front-ends;pattern clustering;search engines;support vector machines;text analysis","Web browsability;Web document categorization;automatic tuning method;information retrieval;nonlinear function;search engine;support vector clustering","","0","","17","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Building a semantic model of a textual document for efficient search and retrieval","E. Nyamsuren; Ho-Jin Choi","Intelligent Software Engineering and Robotics Lab, Information and Communications University, Daejeon, Republic of Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","01","","298","302","This paper describes a new approach of enhancing textual document search and retrieval. The approach tries to take advantage of structured query languages in search and retrieval. For this purpose the semantic model of the document is created. The semantic model of the document is an ontology-like structured semantic annotation of the document that can support structured querying. This paper discusses how semantic model can be created from textual document and how set of semantic models can be efficiently searched through structured query language.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809956","Semantic web;co-occurrence;document;keywords;ontology;relation analysis;semantic model","Database languages;Information retrieval;Intelligent robots;Intelligent structures;Ontologies;Prototypes;Semantic Web;Software engineering;Taxonomy;Text analysis","information retrieval;ontologies (artificial intelligence);query languages;semantic networks;text analysis","document retrieval;document search;ontology-like structured semantic annotation;semantic model;structured query languages;structured querying;textual document","","0","","13","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"3D Object Retrieval Using Reflective Symmetry","J. Song; S. Choi; J. Yoon; S. Shin; A. Kim; S. Kim; O. Gwun","Sch. of Liberal Arts, Jeonju Univ., Jeonju","2008 Second International Conference on Future Generation Communication and Networking Symposia","20090410","2008","3","","35","38","This paper proposes a retrieval system for three dimensional objects using reflective symmetry. For the retrieval method, a reflective symmetric axis with a projector is used. The symmetric plane is calculated by the reflection symmetry, and the depth buffer is calculated for the symmetric plane. Then, by applying the Fourier transform to the depth buffer, the feature vector for the object is generated and retrieved. Considering that most of the objects have symmetrical characteristics, the proposed method of retrieving three dimensional objects using a reflective symmetric surface is an outstanding retrieval system.","","CD-ROM:978-0-7695-3546-3; POD:978-1-4244-3430-5","10.1109/FGCNS.2008.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813542","","Ambient intelligence;Art;Computer networks;Computer science education;Computer vision;Conferences;Feature extraction;Fourier transforms;Information retrieval;Reflection","Fourier transforms;feature extraction;image retrieval","3D object retrieval system;Fourier transform;depth buffer;feature vector generation;reflective symmetric surface;symmetric plane","","0","","10","","","13-15 Dec. 2008","","IEEE","IEEE Conference Publications"
"Cooperative RoboCup agents using genetic case-based reasoning","J. Y. Kuo; He Zhi Lin","Department of Computer Science and Information Engineering, National Taipei University of Technology, Taiwan, R.O.C.","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","613","618","RoboCup soccer game is a competition game. Robots need good strategy and planning ability on different conditions to win the game. If robots act by prior rules, they cannot gain ground. In this paper, we proposed a hybrid approach to implement our RoboCup agent. It can provide good strategy for robots planning base on all kinds of conditions and saving experience for reusing. Robots will grow up by our hybrid approach without prior defining knowledge and complex math basis. They just learn by saving experience. The robots don't only grow up but also avoid to making the same mistakes. And we show the effectiveness of the proposed method through implement and comparing with another learning approach.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811345","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811345","Case- based Reasoning;Cooperative agents;RoboCup","Computer science;Expert systems;Genetic engineering;Helium;Humanoid robots;Humans;Information retrieval;Machine learning;Problem-solving;Strategic planning","case-based reasoning;mobile robots;multi-robot systems;path planning","RoboCup soccer game;cooperative RoboCup agents;genetic case-based reasoning;robot planning","","1","","9","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Improving Real-Time GPS by incorporating TelegraphCQ in Jamdroid Architecture","M. A. Qadeer; N. Akhtar; F. Khan; E. Baratte","Department of Computer Engineering, Aligarh Muslim University, Aligarh, India. maqadeer@zhcet.ac.in","2009 4th International Symposium on Wireless Pervasive Computing","20090316","2009","","","1","5","Data Stream Management System is a new class of stream handling with SQL-like queries & robustness at relatively high streams of data. TelegraphCQ is an open source DSMS tool developed towards handling live streams of data. Jamdroid, on the other hand, is a new collaborative project, developed on Android platform, that gathers road traffic reports from all its end-users, compiles the data and reports back to the navigation software of the users. It involves a data analysis algorithm running on the user device, and Internet servers that retrieve the data from the user, merge them, and send them back to the community. Such a system is meant to be accessed by a large number of users, and has to be fast-responsive enough to deal with all the requests; hence, provisions must be made for effective live stream handling. We will see how such a system can gain immensely by incorporating Data Stream Management System, using open-source TelegraphCQ, for data stream processing & querying.","","CD-ROM:978-1-4244-2966-0; POD:978-1-4244-2965-3","10.1109/ISWPC.2009.4800587","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4800587","DSMS;GPS;Jamdroid;Live Stream Processing;TelegraphCQ","Collaborative software;Data analysis;Global Positioning System;Information retrieval;Internet;Navigation;Open source software;Roads;Robustness;Web server","Global Positioning System;Internet;data analysis;public domain software;road traffic;traffic engineering computing","Internet servers;Jamdroid architecture;SQL-like queries;TelegraphCQ;data analysis;data stream management system;navigation software;open source DSMS tool;real-time GPS;road traffic reports","","0","1","13","","","11-13 Feb. 2009","","IEEE","IEEE Conference Publications"
"Semantic Chunk Annotation for questions using Maximum Entropy","Shixi Fan; Yaoyun Zhang; W. W. Y. Ng; X. Wang; X. Wang","Computer science and technology, Harbin Institute of Technology Shenzhen Graduate School, china","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","450","454","We present a ME (Maximum Entropy) model for Semantic Chunk Annotation in a Chinese Question and Answer (Q&A) system. The model was derived from a corpus of real world questions, which are collected from some discussion groups on the Internet. The questions are supposed to be answered by other people, so the questions are very complex. The semantic chunks were introduced. Feature for the model was described and MI (mutual information) was adopted for feature selection. The training data consists of 14000 sentences and the test data consists of 4000 sentences. The result: F-score is 90.68%.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811317","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811317","Maximum Entropy;Mutual information;Q&A;Semantic Chunk Annotation","Computer architecture;Computer science;Databases;Entropy;Information retrieval;Internet;Mutual information;Natural languages;Search engines;Testing","maximum entropy methods;query processing;search engines;semantic Web","Chinese Question and Answer system;Internet;Semantic Chunk Annotation;feature selection;maximum entropy model;mutual information","","0","1","15","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"A method for data embedding to printed images based on use of original images","T. Shono; M. Muneyasu; K. Nakanishi","Graduate School of Engineering, Kansai University, 3-3-35 Yamate-cho, Suita, 564-8680 Japan","2008 International Symposium on Intelligent Signal Processing and Communications Systems","20090327","2009","","","1","4","A data embedding to printed images has become an important issue for several applications. In this paper, we assume an original image to be known and the server based data retrieval model, and a new method for the data embedding to the printed images is proposed. For data embedding to printed image, a method using spread spectrum technique has already been proposed. However, there are two problems in this method. One is the small number of data bits and another is misdetection due to the distortion and noise by printing and image capturing. In this paper, we proposed the use of ldquoWalsh coderdquo for diffusion code to increase the number of data bits. This can be also applied to the improvement of the detection process. This technique gives the tolerance to some distortions and noises. In the detection processing, a captured image is forwarded to the server which holds the original image and the embedded data is detected in it. Therefore, the improvement of the detection process by using original image is proposed. As a result, more data embedding and more accurate detection becomes possible than the conventional method.","","POD:978-1-4244-2564-8","10.1109/ISPACS.2009.4806662","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806662","","Data engineering;Digital cameras;Discrete cosine transforms;Economic indicators;Image retrieval;Information retrieval;Printing;Robustness;Signal processing;Spread spectrum communication","data encapsulation;discrete cosine transforms;image coding;image retrieval;spread spectrum communication;watermarking","DCT;Walsh code;diffusion code;digital watermarking;embedded data detection;printed image coding;server-based data retrieval model;spread spectrum technique","","1","","6","","","8-11 Feb. 2009","","IEEE","IEEE Conference Publications"
"Towards contextual information based-approach to support software reuse system","H. B. Hadji; H. J. Choi","The School of Engineering, Information and Communications University, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","01","","132","136","In the last decades, various storage and retrieval systems have been introduced to help the user find the relevant information for which he/she seeks. The very recent trend is the integration of the contextual information. This technique has gained popularity in various fields, such as e-learning, ubiquitous computing, and artificial intelligent, but hardly exploited in software reuse where the storage and retrieval of reusable software constitute a critical issue. In this paper, we advocate that the integration of contextual information in software reuse systems can also render the retrieval of reusable software ldquointelligentrdquo and lead to a powerful solution. Such intelligent system is proposed and described below.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809918","contextual information;ontology;software assets;software retrieval;software reuse","Artificial intelligence;Communication system software;Context;Documentation;Information retrieval;Java;Programming;Software reusability;Software systems;Software testing","information retrieval;software reusability;ubiquitous computing","contextual information;software assests;software retrieval;software reuse system;ubiquitous computing","","0","","11","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Visible Reverse k-Nearest Neighbor Queries","Y. Gao; B. Zheng; G. Chen; W. C. Lee; K. C. K. Lee; Q. Li","Singapore Manage. Univ., Singapore","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1203","1206","Reverse nearest neighbor (RNN) queries have a broad application base such as decision support, profile-based marketing, resource allocation, data mining, etc. Previous work on RNN search does not take obstacles into consideration. In the real world, however, there are many physical obstacles (e.g., buildings, blindages, etc.), and their presence may affect the visibility/distance between two objects. In this paper, we introduce a novel variant of RNN queries, namely visible reverse nearest neighbor (VRNN) search, which considers the obstacle influence on the visibility of objects. Given a data set P, an obstacle set O, and a query point q, a VRNN query retrieves the points in P that have q as their nearest neighbor and are visible to q. We propose an efficient algorithm for VRNN query processing, assuming that both P and O are indexed by R-trees. Our method does not require any pre-processing, and employs half-plane property and visibility check to prune the search space.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812501","Query Processing;Spatial Database;Visible Reverse Nearest Neighbor Query","Conference management;Data engineering;Engineering management;Information retrieval;Nearest neighbor searches;Neural networks;Query processing;Recurrent neural networks;Resource management;USA Councils","query processing;tree data structures","R-trees;VRNN query processing;object visibility;obstacle influence;obstacle set;reverse k-nearest neighbor queries;search space;visible reverse nearest neighbor search","","4","","16","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"An assertion-based information acquisition system exploiting hierarchical structures of documents","K. Tabata; A. Hattori","Department of Information and Computer Sciences, Kanagawa Institute of Technology, 1030 Shimo-ogino, Atsugi, 243-0292, Japan","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","1373","1378","This paper presents a new kind of document-information acquisition system, which we call an information probe system. This system is intended to enable the user-centric acquisition of information in which authors and users may not have a common interpretation. The notion of the ldquoskeletonrdquo is devised to abstract the relations between terms that appear in the pairs of adjacent layers of hierarchical documents. The skeleton reflects the assertions made by authors, and its formal description is presented by applying the notation of conceptual graphs. This model has produced a scheme for the assertion-based acquisition of information. The assertions of authors and of users are represented as respective sets of terms and their relations; document information is then selectively acquired by comparing the assertions. Probing is intended to cater to the original interpretations of individual users, and uses assertions as clues in searching for document information.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811477","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811477","XML;assertion;document information acquisition;document structure;information probing;retrieval","Control systems;Dictionaries;Frequency;Indexing;Information retrieval;Paper technology;Probes;Skeleton;Vocabulary;XML","document handling;information retrieval","assertion-based information acquisition system;conceptual graphs;document-information acquisition system;hierarchical documents;information probe system;user-centric acquisition","","1","","17","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Handling very large numbers of messages in Distributed Hash Tables","F. Klemm; J. Y. Le Boudec; D. Kostic; K. Aberer","School of Computer and Communication Sciences, Ecole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), Switzerland","2009 First International Communication Systems and Networks and Workshops","20090331","2009","","","1","9","The principal service of distributed hash tables (DHTs) is route(id, data), which sends data to a peer responsible for id, using typically O(log(# of peers)) overlay hops. Certain applications like peer-to-peer information retrieval generate billions of small messages that are concurrently inserted into a DHT. These applications can generate messages faster than the DHT can process them. To support such demanding applications, a DHT needs a congestion control mechanism to efficiently handle high loads of messages. In this paper we provide an extended study on congestion control for DHTs: we present a theoretical analysis that demonstrates that congestion control for DHTs is absolutely necessary for applications that provide elastic traffic. We then present a new congestion control algorithm for DHTs. We provide extensive live evaluations in a ModelNet cluster and the PlanetLab test bed, which show that our algorithm is nearly loss-free, fair, and provides low lookup times and high throughput under cross-load.","2155-2487;21552487","POD:978-1-4244-2912-7","10.1109/COMSNETS.2009.4808887","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4808887","","Clustering algorithms;Control systems;Distributed computing;Information retrieval;Intrusion detection;Peer to peer computing;Routing;TCPIP;Throughput;Traffic control","data handling;distributed processing","ModelNet cluster;PlanetLab test bed;congestion control;distributed hash table;elastic traffic","","0","","20","","","5-10 Jan. 2009","","IEEE","IEEE Conference Publications"
"An efficient implementation scheme for multidimensional online analytical processing","N. Easmin; K. M. A. Hasan; N. Parvin","Department of Computer Science and Engineering, Khulna University of Engineering and Technology, 9203, Bangladesh","2008 11th International Conference on Computer and Information Technology","20090321","2008","","","536","541","Multidimensional online analytical processing (MOLAP) processes data that is already stored in a multidimensional array in which all possible combinations of data are reflected. It employs multidimensional array as their basic data structure. The intent of this paper is to develop a MOLAP model based on the scheme called extended Karnaugh map representation (EKMR) and evaluate it. The basic idea of EKMR scheme is to present multidimensional array by a set of two dimensional arrays. This reduces data access time from secondary storage if the tupple of subscripts are known. Effectiveness of this scheme over traditional multidimensional array is shown with sufficient analysis and experimental results.","","CD-ROM:978-1-4244-2136-7; POD:978-1-4244-2135-0","10.1109/ICCITECHN.2008.4802985","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802985","Dice;EKMR;MOLAP;Multidimensional Array;Slice","Data analysis;Data engineering;Data models;Data structures;Data warehouses;Information analysis;Information retrieval;Information technology;Multidimensional systems;Relational databases","data mining;data structures;database management systems","MOLAP database;data structure;extended Karnaugh map representation;multidimensional array;multidimensional online analytical processing","","0","","15","","","24-27 Dec. 2008","","IEEE","IEEE Conference Publications"
"Towards a Comprehensive Traceability Approach in the Context of Software Maintenance","H. Schwarz","Inst. for Software Technol., Univ. of Koblenz-Landau Koblenz, Koblenz","2009 13th European Conference on Software Maintenance and Reengineering","20090410","2009","","","339","342","Traceability plays an important role in software maintenance and reengineering. Among other applications, traceability deals with managing impacts of change, understanding interrelationships between different system components, and tracing source code to originating artifacts on higher abstraction levels, such as architecture or requirements. This PhD thesis aims at the development of a seamless approach supporting the whole breadth of traceability-related activities, ranging from modeling traceability information to keeping existing information up to date to making use of traceability information in software maintenance.","1534-5351;15345351","POD:978-1-4244-3755-9","10.1109/CSMR.2009.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812792","Maintenance;Modeling;Traceability","Application software;Computer architecture;Documentation;Information analysis;Information retrieval;Logic;Manuals;Natural languages;Ontologies;Software maintenance","software maintenance;systems re-engineering","comprehensive traceability;software maintenance;software reengineering;source code tracing;traceability information","","1","","28","","","24-27 March 2009","","IEEE","IEEE Conference Publications"
"Feature correspondence finding with vertical cylinder and epipolar geometry for indoor environments","Yu Fu; Tien-Ruey Hsiang; Sheng-Luen Chung","Dept. of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan","2009 4th International Conference on Autonomous Robots and Agents","20090321","2009","","","330","335","We introduce an improved approach, called FCVC, that finds accurate matches from two related images of indoor environments by matching corresponding vertical cylinders of features, then retrieves more matches by epipolar geometry. Feature matching is a critical technique for many vision-based applications. However, since the preliminary matching results obtained by SIFT sometimes are not accurate enough, and therefore, post processing methods, like RANSAC, have been proposed to increase the correctness of feature mappings. As RANSAC iteratively selects partial matches from preliminary matches and recovers the epipolar geometry to find correct matches, our method first finds accurate matches in vertical cylinders, based on three consistency properties which are common while two images are taken on a flat floor: (1) altitudinal order, (2) composition of features for each vertical cylinder, and (3) horizontal order of all vertical cylinders. Once some accurate matches are acquired, the epipolar geometry is recovered to retrieve matches that are not grouped into any vertical cylinder previously. Experiments in different indoor environments reveal that the proposed FCVC in general spends at most 6% of the time required by RANSAC, has at least 71% of the number of matches obtained by RANSAC, and yet with accuracy rate similar to that of RANSAC.","","POD:978-1-4244-2712-3","10.1109/ICARA.2000.4803974","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4803974","RANSAC;SIFT;feature matching","Computational geometry;Computer science;Computer vision;Engine cylinders;Image retrieval;Image sampling;Indoor environments;Information geometry;Information retrieval;Robots","computer vision;geometry;image matching;image sampling;random processes","epipolar geometry;feature correspondence vertical cylinder;feature mappings;feature matching;indoor environments;random sample consensus;vision-based applications","","0","","16","","","10-12 Feb. 2009","","IEEE","IEEE Conference Publications"
"A Web Document Retrieval Algorithm Based on Particle Swarm Optimization","Z. Wang; X. Sun; D. Zhang","School of Information Science and Engineering, Henan University of Technology, High New Technology Industries Development Zone, 450001 ZhengZhou, P. R. China. wzqagent@126.com","2007 Second International Conference on Bio-Inspired Computing: Theories and Applications","20090327","2007","","","203","206","With advances in the computer technologies and the rapid development of Internet, information on the Internet is increasing exponentially. To efficiently retrieve relevant documents from the explosive growth of the Internet and other sources of information access, a novel Web document retrieval algorithm based on particle swarm optimization (PSO) and linear discriminant analysis (LDA) algorithm is proposed to deal this problem. Experimental results clearly demonstrate its effectiveness and efficiency.","","CD-ROM:978-1-4244-4106-8; POD:978-1-4244-4105-1","10.1109/BICTA.2007.4806451","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806451","","Independent component analysis;Information retrieval;Internet;Linear discriminant analysis;Particle scattering;Particle swarm optimization;Pattern recognition;Principal component analysis;Radio frequency;Sun","Internet;document handling;information retrieval;particle swarm optimisation;statistical analysis","Internet;Web document retrieval algorithm;information access;linear discriminant analysis algorithm;particle swarm optimization","","0","","13","","","14-17 Sept. 2007","","IEEE","IEEE Conference Publications"
"A case study on host based data analysis & cyber criminal profiling in Honeynets","J. S. Bhatia; R. Sehgal; B. Bhushan; H. Kaur","CDAC-Mohali, India","2009 First International Communication Systems and Networks and Workshops","20090331","2009","","","1","2","The single detection component of Honeynet i.e. Snort is not sufficient to reasonably classify the total Honeynet malicious domain. The critical issue is the realization of detection layers for enhanced analysis of cyber threats. This paper presents significance & results obtained following integration of host layer in the form of open source HIDS (Host based Intrusion Detection System) to already existing network layer i.e. Snort in Gen 3 Honeynet architecture. The investigation is further carried out to extract the intelligence from the enhanced Honeynet system. The resultant Honeynet system enables the forensic profiling of the cyber criminal through the retrieval of critical parameters from Honeynet database. The various attributes for profile generation have been clearly indicated in terms of the Honeynet database key fields to establish a characteristic model of the attacker.","2155-2487;21552487","POD:978-1-4244-2912-7","10.1109/COMSNETS.2009.4808902","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4808902","","Assembly;Availability;Character generation;Computer aided software engineering;Data analysis;Deductive databases;Forensics;Information retrieval;Intrusion detection;Visualization","computer crime;data analysis","Gen 3 Honeynet architecture;Honeynet database;Honeynet malicious domain;Snort intrusion detection system;cyber criminal profiling;cyber threat analysis;host-based data analysis;open source HIDS","","1","","3","","","5-10 Jan. 2009","","IEEE","IEEE Conference Publications"
"Indexing and Retrieving Motions of Characters in Close Contact","E. S. L. Ho; T. Komura","University of Edinburgh, Edinburgh","IEEE Transactions on Visualization and Computer Graphics","20090316","2009","15","3","481","492","Human motion indexing and retrieval are important for animators due to the need to search for motions in the database which can be blended and concatenated. Most of the previous researches of human motion indexing and retrieval compute the Euclidean distance of joint angles or joint positions. Such approaches are difficult to apply for cases in which multiple characters are closely interacting with each other, as the relationships of the characters are not encoded in the representation. In this research, we propose a topology-based approach to index the motions of two human characters in close contact. We compute and encode how the two bodies are tangled based on the concept of rational tangles. The encoded relationships, which we define as TangleList, are used to determine the similarity of the pairs of postures. Using our method, we can index and retrieve motions such as one person piggy-backing another, one person assisting another in walking, and two persons dancing/wrestling. Our method is useful to manage a motion database of multiple characters. We can also produce motion graph structures of two characters closely interacting with each other by interpolating and concatenating topologically similar postures and motion clips, which are applicable to 3D computer games and computer animation.","1077-2626;10772626","","10.1109/TVCG.2008.199","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4731251","Animation;Face and gesture recognition","Animation;Concatenated codes;Content based retrieval;Databases;Euclidean distance;Humans;Indexing;Information retrieval;Legged locomotion;Neck","avatars;computational geometry;computer animation;content-based retrieval;database indexing;interpolation;visual databases","3D computer game;Euclidean distance;TangleList encoded relationship;avatars;computer animation;content-based retrieval;human character interaction;human character motion indexing;human character motion retrieval;interpolation method;motion database;motion graph structure;topology-based approach","Abstracting and Indexing as Topic;Algorithms;Computer Graphics;Computer Simulation;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Biological;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity","16","","27","","","May-June 2009","","IEEE","IEEE Journals & Magazines"
"Audio data retrieval and recognition using model selection criterion","K. Biatov; W. Hesseler; J. Koehler","NetMedia, Fraunhofer IAIS, Schloss Birlinghoven, 53754 Sankt Augustin, Germany","2008 2nd International Conference on Signal Processing and Communication Systems","20090410","2008","","","1","5","Model selection criterion is an unsupervised technique that can be used to compare statistical distributions of the data. In this paper a new application of model selection criterion is presented. The technique is applied for direct audio search in German broadcast news with the high variability in duration and loudness of the search patterns. Experiments for identification of 14 environmental sounds are carried out using model selection criterion as distance metric. For environmental sounds detection the decision is based on mutual similarity of compared events to the set of reference events. For audio events recognition Latent Semantic Indexing (LSI) is also tested. Approximately 500 audio segments from 14 sound types are used in the recognition test. The experiments show that the applications of model selection criterion for direct audio search, unsupervised environmental sounds analysis and sounds recognition using LSI are effective and accurate.","","CD-ROM:978-1-4244-4243-0","10.1109/ICSPCS.2008.4813746","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813746","Bayesian Information Criterion;Latent Semantic Indexing;direct audio search;environmental sounds;model selection criterion","Acoustic testing;Airplanes;Bayesian methods;Broadcasting;Event detection;Indexing;Information retrieval;Large scale integration;Road accidents;Statistical distributions","Bayes methods;acoustic signal processing;audio signal processing;statistical analysis","Bayesian information criterion;German broadcast news;audio data recognition;audio data retrieval;audio events recognition;direct audio search;environmental sounds analysis;latent semantic indexing;model selection criterion;recognition test;search patterns;sounds recognition;statistical distributions;unsupervised technique","","2","","17","","","15-17 Dec. 2008","","IEEE","IEEE Conference Publications"
"Information at your fingertips","P. Mcfedries","","IEEE Spectrum","20090331","2009","46","4","24","24","Examines the terminology that has developed around information retrieval.","0018-9235;00189235","","10.1109/MSPEC.2009.4808383","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4808383","","Information retrieval;Terminology","","","","0","","","","","April 2009","","IEEE","IEEE Journals & Magazines"
"Topic generation for web document summarization","Heng-Yao Hsu; Chun-Wei Tsai; Ming-Chao Chiang; Chu-Sing Yang","Department of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan, R.O.C.","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3702","3707","Over the past decade, more and more users of the Internet rely on the search engines to help them find the information they need. However, the information they find depends, to a large extent, on the ranking mechanism of the search engines they use. Not surprisingly, it, in general, consists of a large amount of information that is completely irrelevant. To help users of the Internet find the information they are looking for quickly, an efficient algorithm for building the summaries of a collection of documents found by a search engine in response to a user query, called DISCO (Distribution Scoring) is proposed. To demonstrate the performance of the proposed algorithm, Reuters-21578 text categorization collection and some search results from Google are used in our simulation. Moreover, several metrics such as coverage, overlap, and the computation time are employed in evaluating the quality and quantity of the proposed algorithm. All our simulation results indicate that the proposed algorithm outperforms all the existing algorithms in terms of not only the usefulness of the summaries but also the running time.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811875","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811875","","Computational modeling;Computer science;Continuous wavelet transforms;Data mining;Information filtering;Information retrieval;Internet;Search engines;Text categorization;Web pages","document handling;information retrieval;search engines;text analysis","Google;Internet users;Web document summarization;distribution scoring;ranking mechanism;search engines;text categorization;topic generation;user query","","2","","28","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Study on Semantic Knowledge Retrieval based Context","J. Wu; H. Wang","School of Economic and Management, Wuhan University of Science and Engineering, Wuhan, China. Wjh707@163.com","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","1006","1009","Being lack of the context around user, the retrieval results mostly do not fulfill user's expectation in traditional semantic retrieval applications. Rich semantic information is hidden in retrieval context. Context also contains much implicit logic relations between users and resources, which can help machines to understand users' demands better. Reasoning over contexts automatically can forecast user's search intentions and help improving retrieval efficiency greatly. In order to make full use of contexts, a model for semantic knowledge retrieval based on context (SKRC) is proposed in the paper. The mechanism of SKRC is to match between user context and resource context in retrieval. The user context ontology and information resource context ontology are discussed for describing context elements clearly and explicitly. And then the reasoning meta-rules and a matching algorithm between user context and information resource context are proposed as the foundation to refine results of knowledge retrieval.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810662","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810662","knowledge retrieval;semantic context;semantic retrieval","Context modeling;Context-aware services;Economic forecasting;Engineering management;Information resources;Information retrieval;Knowledge engineering;Knowledge management;Logic;Ontologies","knowledge acquisition;ontologies (artificial intelligence)","information resource context ontology;matching algorithm;semantic information;semantic knowledge retrieval based context;user context ontology","","0","","10","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"User-adaptive image clustering using relevance feedback for efficient content-based retrieval","M. Kobayashi; K. Kameyama","Department of Computer Science, Graduate School of Systems and Information Engineering, University of Tsukuba, 1-1-1 Tennoudai, Ibaraki 305-8573, Japan","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","2683","2688","In content-based image retrieval (CBIR), similarity measures vary according to the user, and it is difficult to build a retrieval system which reflects the user's similarity measures automatically. Regarding CBIR as consisting of feature extraction, coarse classification and detailed matching stages, this work aims at reflecting the user's similarity measures in coarse classification. After obtaining the user's evaluation to the initial retrieval, we transform the initial feature vectors using optimal linear associative memory (OLAM). This leads to the selection of important features from the user's relevance feedback. Experimental results show the effectiveness of the proposed method which reflects the user's similarity measures in the coarse classification.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811701","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811701","Content-based image retrieval;coarse classification;hierarchical clustering;optimal linear associative memory;principal component analysis;relevance feedback","Associative memory;Computer science;Content based retrieval;Feature extraction;Feedback;Image databases;Image retrieval;Information retrieval;Shape;Vectors","content-based retrieval;feature extraction;image classification;image matching;image retrieval;pattern clustering;relevance feedback","CBIR;coarse classification;content-based image retrieval;detailed matching stages;feature extraction;feature vectors;optimal linear associative memory;relevance feedback;user similarity measures;user-adaptive image clustering","","1","","13","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Image/ video's automatic annotation considering semantics' tolerance relation","Y. Dai","Faculty of Software and information science, Iwate Pref. University, Takizawa, Japan","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3417","3424","In this paper, an approach of image/video's automatic annotation considering semantics' tolerance relation between pre-defined classes is proposed. The image/videos' semantics is represented by a vector of associative values with the pre-defined classes, and eliminating the semantic gap induced in the process of automatically generating associative values is dealt with by using the constructed semantic tolerance relation model (STRM). Moreover, the method how to generating associative values with pre-defined classes regarding different dimensions is described. Image/videos' retrieval results based on the pre-defined classes shows the effectiveness of the proposed methods.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811826","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811826","associative value;automatic annotation;image/video representaion;image/video retrieval;semantic tolerance relation model","Database languages;Digital images;Humans;Image color analysis;Image resolution;Image retrieval;Information retrieval;Information science;Memory;Videos","image representation;video retrieval","image-video automatic annotation;image-videos retrieval;semantic tolerance relation model","","0","","7","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"FEAST - A Multistep, Feedback Centric, Freshness Oriented Search Engine","K. S. Kuppusamy; G. Aghila","Department of Computer Science, Pondicherry University, Pondicherry, India","2009 IEEE International Advance Computing Conference","20090331","2009","","","997","1001","This work aims at a multi-step feedback centric Web search engine ensuring the retrieval of relevant fresh live results instead of those existing in the indexes. The methodology is based on the new concept called ""micro search"" which in turn creates the ""micro indexes"". These micro-indexes are the key factors utilized in re-ranking the selected documents. A prototype of the system called FEAST (freshness enriched active searching technology) has been implemented. The results of experiments conducted on FEAST are encouraging and they confirm the improved quality of information retrieved.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809151","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809151","micro index;micro search;result freshness;user feedback;web search","Computer science;Content based retrieval;Crawlers;Feedback;Information retrieval;Prototypes;Search engines;Web pages;Web search;Web sites","document handling;indexing;information retrieval;search engines","freshness enriched active searching technology;freshness oriented search engine;micro-indexes;multistep feedback centric Web search engine","","1","","18","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Genre identification of Chinese finance text using machine learning method","Jun Xu; Yuxin Ding; X. Wang; Yonghui Wu","Department of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","455","459","Document genre information is one of the most distinguishing features in information retrieval, which brings order to the search results. What the genre classification concerned is not the topic but the genre of document. In this paper, we examine the effectiveness of using machine learning techniques to solve genre classification of Chinese text with the same topic, viz. finance. Based on the likelihood ratio test, we present a new method for selecting feature terms, which can improve the performance clearly and perform better than others with up to 80% terms removal. In empirical results with SVMs classifier on the real world corpora, we find that this method can gain a better selecting effect and likelihood ratio is a reliable measure for selecting informative features.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811318","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811318","Genre Classification;Likelihood Ratio Test;Support Vector Machines","Computer science;Finance;Gain measurement;IEEE news;Information retrieval;Learning systems;Machine learning;Performance evaluation;Search engines;Testing","financial data processing;learning (artificial intelligence);pattern classification;support vector machines;text analysis","Chinese finance text;SVMs classifier;genre classification;genre identification;likelihood ratio test;machine learning method;support vector machine","","1","","14","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"QoS testing of service-based applications","M. Driss; Y. Jamoussi; H. H. B. Ghezala","National School of Computer Sciences (ENSI), RIADI-GDL Laboratory, University of Manouba, Tunisia","2008 3rd International Design and Test Workshop","20090316","2008","","","45","50","Web services (WSs) are becoming increasingly popular because of their potential in several application domains including e-Enterprise, e-Business, e-Government, and e-Science. Based on open XML standards, WS technology allows the construction of massively distributed and loosely coupled applications. A service composition mechanism should satisfy not only functional properties but also non-functional quality of service (QoS) ones. In this paper, we introduce a discrete-events modeling approach for service-based applications (SBAs). This approach is oriented towards QoS evaluation through simulation.","2162-0601;21620601","POD:978-1-4244-3479-4","10.1109/IDT.2008.4802463","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802463","Discrete-Events Simulation;Evaluation;QoS;Service-Based Applications","Application software;Information retrieval;Laboratories;Network servers;Quality management;Quality of service;Service oriented architecture;Simple object access protocol;Testing;Web services","Web services;discrete event simulation;quality of service","QoS testing;Web services;discrete events modeling;service based applications;service composition mechanism","","0","","28","","","20-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Tag-based Artist Similarity and Genre Classification","J. Hong; H. Deng; Q. Yan","Institute of Acoustics, Chinese Academy of Sciences, Beijing, China. hongj@dsp.ac.cn","2008 IEEE International Symposium on Knowledge Acquisition and Modeling Workshop","20090403","2008","","","628","631","Social tags are becoming more and more popular in Web2.0 recently. Tags defined by users are of high-level semantic for music. In this paper, we present a similarity calculation and genre classification measure for music artists with the use-defined tags from Last.fm. Similarities between artists are calculated based on tag co-occurrence. The k-nearest neighbor algorithm (k-NN) has been used to classify the music genre. Experiments show that tags are effective to characterize similarities between artists and the proposed approach outperforms the previous web-based approaches in artist genre classification with the highest average accuracy of 95%, compared with 89.5% of Schedl et al. and 81.2% of Knees et al.","","CD-ROM:978-1-4244-3531-9; POD:978-1-4244-3530-2","10.1109/KAMW.2008.4810567","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810567","aritst similarity;co-occurrence;genre classification;music;social tag","Acoustic measurements;Availability;Data mining;Frequency;Music information retrieval;Performance evaluation;Signal analysis;Testing;Videos;Web pages","Internet;music;pattern classification;social networking (online)","Web2.0;genre classification;k-nearest neighbor algorithm;music artists;social tags;tag-based artist similarity","","1","","8","","","21-22 Dec. 2008","","IEEE","IEEE Conference Publications"
"Adaptive Parallelization of Queries over Dependent Web Service Calls","M. Sabesan; T. Risch","Dept. of Inf. Technol., Uppsala Univ., Uppsala","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1725","1732","We have developed a system to process database queries over composed data providing Web services. The queries are transformed into execution plans containing an operator that invokes any Web service for given arguments. A common pattern in these query execution plans is that the output of one Web service call is the input for another, etc. The challenge addressed in this paper is to develop methods to speed up such dependent calls in queries by parallelization. Since Web service calls incur high-latency and message set-up costs, a naive approach making the calls sequentially is time consuming and parallel invocations of the Web service calls should improve the speed. Our approach automatically parallelizes the web service calls by starting separate query processes, each managing a parameterized sub-query, a plan function, for different parameter tuples. For a given query, the query processes are automatically arranged in a multi-level process tree where plan functions are called in parallel. The parallel plan is defined in terms of an algebra operator, FF_APPLYP, to ship in parallel to other query processes the same plan function for different parameters. By using FF_APPLYP we first investigated ways to set up different process trees manually. We concluded from our experiments that the best performing query execution plan is an almost balanced bushy tree. To automatically achieve the optimal process tree we modified FF_APPLYP to an operator AFF_APPLYP that adapts a parallel plan locally in each query process until an optimized performance is achieved. AFF_APPLYP starts with a binary process tree. During execution each query process in the tree makes local decisions to expand or shrink its process sub-tree by comparing the average time to process each incoming tuple. The query execution time obtained with AFF_APPLYP is shown to be close to the best time achieved by manually built query process trees.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.148","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812598","","Algebra;Costs;Data engineering;Databases;Delay;Information retrieval;Information technology;Marine vehicles;Query processing;Web services","Web services;database management systems;query processing;trees (mathematics)","Web service calls;adaptive parallelization;binary process tree;database queries;message set-up costs;query execution plans;query processes","","5","","19","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"A Web Intrusion Detection Mechanism based on Feature based Data Clustering","D. Das; U. Sharma; D. K. Bhattacharyya","Department of Computer Science & Engineering, Tezpur University, Tezpur, INDIA, ddas@tezu.ernet.in","2009 IEEE International Advance Computing Conference","20090331","2009","","","1124","1129","Web is one of the most popular internet services in today's world. In today's world, web servers and web based applications are the popular corporate applications and become the targets of the attackers. A Large number of Web applications, especially those deployed for companies to e-business operation involve high reliability, efficiency and confidentiality. Such applications are written in script languages like PHP embedded in HTML allowing establish the connection to databases, retrieving data and putting them in WWW site. In order to detect known attacks, misuse detection of web based attacks consists of attack rules and descriptions. As misuse detection considers predefined signatures for intrusion detection, here we have proposed two phases of intrusion detection mechanism. In the first phase we have used web host based intrusion detection with matching mechanism using 'Hamming Edit Distance'. We have considered here. the web layer log file for matching. This phase has been tested with our university intranet web server's log file. We have tested successfully the SQL injection for unauthorized access. We proposed a 'Query based projected clustering' for unsupervised anomaly detection and also a 'packet arrival factor' for intrusion detection in the second phase. We tested the scheme in this phase using KDD CUP99. In this phase while testing our scheme, we have extracted the feature dataset with protocol 'tcp' and services 'http'. Both the phases of our scheme found working successfully and an evaluated threshold has been proposed for better result.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809172","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809172","Web intrusion;attack labeling;query based projected clustering;sql injection;web layer log matching","Databases;Feature extraction;HTML;Information retrieval;Intrusion detection;Phase detection;Testing;Web and internet services;Web server;World Wide Web","Internet;SQL;Web sites;hypermedia markup languages;pattern clustering;security of data","'packet arrival factor';HTML;Internet services;KDD CUP99;PHP;SQL;WWW site;Web based attacks;Web intrusion detection mechanism;Web layer log file;attack rules;data clustering;data retrieving;e-business operation;hamming edit distance;misuse detection;query based projected clustering;script languages;unauthorized access","","2","","6","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Efficient Processing of Warping Time Series Join of Motion Capture Data","Y. Chen; G. Chen; K. Chen; B. C. Ooi","Sch. of Comput., Nat. Univ. of Singapore, Singapore","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1048","1059","Discovering non-trivial matching subsequences from two time series is very useful in synthesizing novel time series. This can be applied to applications such as motion synthesis where smooth and natural motion sequences are often required to be generated from existing motion sequences. We first address this problem by defining it as a problem of l-epsiv-join over two time series. Given two time series, the goal of l-epsiv-join is to find those non-trivial matching subsequences by detecting maximal l-connections from the epsiv-matching matrix of the two time series. Given a querying motion sequence, the l-epsiv-join can be applied to retrieve all connectable motion sequences from a database of motion sequences. To support efficient l-epsiv-join of time series, we propose a two-step filter-and-refine algorithm, called warping time series join (WTSJ) algorithm. The filtering step serves to prune those sparse regions of the epsiv-matching matrix where there are no maximal l-connections without incurring costly computation. The refinement step serves to detect closed l-connections within regions that cannot be pruned by the filtering step. To speed up the computation of epsiv-matching matrix, we propose a block-based time series summarization method, based on which the block-wise epsiv-matching matrix is first computed. Lots of pairwise distance computation of elements can then be avoided by applying the filtering algorithm on the block-wise epsiv-matching matrix. Extensive experiments on l-epsiv-join of motion capture sequences are conducted. The results confirm the efficiency and effectiveness of our proposed algorithm in processing l-epsiv-join of motion capture time series.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812476","motion capture data;motion synthesis;subsequence join;warping time series join","Application software;Computer science;Data engineering;Databases;Educational institutions;Filtering algorithms;Humans;Information retrieval;Joining processes;Sparse matrices","data mining;image matching;image motion analysis;image sequences;matrix algebra;query processing;time series;visual databases","block-based time series summarization method;block-wise epsiv-matching matrix;maximal l-connection detection;motion capture data synthesis;motion sequence database querying;nontrivial matching subsequence discovery;pairwise distance computation;two-step filter-and-refine algorithm;warping time series l-epsiv-join algorithm","","1","","27","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Watermarking Based on the Classification of Cracks in Paintings","R. Sinduja","Dept. of Comput. Sci., V.L.B Janakiammal Coll. of Eng. & Technol., Coimbatore","2009 International Conference on Advanced Computer Control","20090316","2009","","","594","598","This system presents a methodology for watermarking by detection of cracks in images of old statues of temples and old paintings. The cracks are detected by thresholding the output of the morphological top-hat transform. Afterwards, the thin dark brush strokes, which have been misidentified as cracks are removed using a semi-automatic procedure based on region growing. The cracks are classified using an unsupervised approach, which incorporates fuzzy clustering of the patterns. This system classifies cracks using the fuzzy k-means technique. The watermarked information is stored on the specific category of cracks. The user gives the input of the category of crack. The resulting image is the watermarked image. While retrieving the watermark information, the above procedure for identifying cracks is conducted and the watermark information is retrieved from the same category of cracks specified during the hiding stage.","","POD:978-0-7695-3516-6","10.1109/ICACC.2009.135","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777411","crack detection;top-hat transform;watermarking","Computer science;Educational institutions;Image restoration;Information retrieval;Information security;Noise robustness;Painting;Paints;Pixel;Watermarking","crack detection;fuzzy systems;image classification;pattern clustering;watermarking","crack classification;crack detection;crack identification;dark brush strokes;fuzzy k-means;fuzzy pattern clustering;morphological top-hat transform;old paintings;old statues;temples;watermark information;watermarked image;watermarking","","0","","4","","","22-24 Jan. 2009","","IEEE","IEEE Conference Publications"
"Anatomy of peak current mode control in a monolithic dc/dc converter","Li Li","Texas Instruments, 12500 TI Boulevard, Dallas, TX 75243 USA","2009 Twenty-Fourth Annual IEEE Applied Power Electronics Conference and Exposition","20090321","2009","","","509","520","Monolithic dc/dc converters provide a small solution size for the power management industry by integrating power switches with pulse width modulation (PWM) controllers. On the other hand, partial or all key control loop design parameters are hidden inside a black box. A practical way to identify the values of those parameters not only provides an effective tool for a system designer to retrieve information from an unknown converter, but also gives an insight of the control loop design of a monolithic dc/dc converter. This paper proposes a procedure of identifying the key parameters in a peak current mode control monolithic converter as well as an insight of debugging a monolithic dc/dc converter.","1048-2334;10482334","POD:978-1-4244-2811-3","10.1109/APEC.2009.4802706","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802706","","Anatomy;DC-DC power converters;Electrical equipment industry;Energy management;Industrial control;Information retrieval;Power system management;Pulse width modulation;Pulse width modulation converters;Size control","DC-DC power convertors;PWM power convertors;electric current control;power distribution","control loop design;monolithic dc/dc converter;peak current mode control;power management industry;power switches;pulse width modulation controllers","","1","","7","","","15-19 Feb. 2009","","IEEE","IEEE Conference Publications"
"Fuzzy query results ranking over autonomous web databases","Xiangfu Meng; Z. M. Ma","College of Information Science and Engineering, Northeastern University, Shenyang 110004, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3232","3237","Users often have vague or imprecise ideas when searching the Web database, thus they might like to issue fuzzy queries that consist of fuzzy terms or fuzzy relations for possibly retrieving. To deal with the problem of too many results returned from a Web database in response to a user fuzzy query, this paper proposes a novel approach to rank the fuzzy query results. Based on database workload, we firstly speculate the importance of each attribute and assign a corresponding weight to it. And then, based on fuzzy sets theory, a membership degree ranking method, which ranks the query results according to the tuple's satisfaction degree to the fuzzy query, is presented. Next, based on data and workload statistics and correlations, we present a relevance degree ranking method, which assigns a relevance score for each unspecified attribute value according to its corresponding attribute weight and its desirableness to the user. Results of preliminary experiments demonstrating the efficiency and efficacy of the ranking approach are presented.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811794","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811794","Web database;fuzzy query;query results ranking","Cities and towns;Data engineering;Educational institutions;Feedback;Fuzzy set theory;Fuzzy sets;Information retrieval;Information science;Relational databases;Statistics","database management systems;fuzzy set theory;query processing","autonomous Web databases;fuzzy query results ranking;fuzzy sets theory;membership degree ranking method;relevance degree ranking method;satisfaction degree;workload statistics","","0","","19","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Information-Seeking Support Systems [Guest Editors' Introduction]","G. Marchionini; R. W. White","University of North Carolina at Chapel Hill","Computer","20090321","2009","42","3","30","32","Seeking information for learning, decision making, and other complex mental activities that take place over time requires tools and support services that aid people in managing, analyzing, and sharing retrieved information.","0018-9162;00189162","","10.1109/MC.2009.88","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4803884","ISSSs;information-seeking support systems;search","Biological system modeling;Decision making;Humans;Information analysis;Information retrieval;Predictive models;Prototypes;Research and development;Search engines;Web sites","","","","12","","4","","","March 2009","","IEEE","IEEE Journals & Magazines"
"Identification of artifacts in scenery images using color and line information","A. Tanbara; Y. Osana","School of Computer Science, Tokyo University of Technology, Japan","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","1065","1072","In this paper, we propose the identification method of artifacts in scenery images using color and line information. In the proposed method, the original image is divided into some areas based on color information, and whether or not artifacts are included for each divided area are judged using color and line information. The proposed method judges for each area in three level; (1) there is no artifacts, (2) there may be artifacts, and (3) it has a high possibility containing artifacts. We carried out a series of computer experiments and confirmed that the proposed method can identify the area including artifacts in 91.3%.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811423","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811423","Identification of Artifacts;Scenery Images","Associative memory;Chaos;Clouds;Computer science;Image retrieval;Image segmentation;Information processing;Information retrieval;Neural networks;Roads","image colour analysis;image retrieval","image color information;image line information;image retrieval;scenery image artifact identification","","3","","13","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Subspace Index Method for 3D Human Motion","J. Xiang; H. Zhu","School of Information and Electronic Engineering, ZheJiang University of Science and Technology, Hangzhou 310015, China. freexiang@gmail.com","2007 Second International Conference on Bio-Inspired Computing: Theories and Applications","20090327","2007","","","67","69","Along with the development of motion capture technique, more and more large-scale 3D motion databases become available. In this paper, a novel approach is presented for motion retrieval based on a novel index method. Due to high dimensionality of Motion's features, the dimension reduction is used. Then an index system is built based on s the low-dimensional subspace tree. So we can reduce the number of costly similarity measure significantly. Experiment results show that the approaches are effective for motion data retrieval in large-scale databases.","","CD-ROM:978-1-4244-4106-8; POD:978-1-4244-4105-1","10.1109/BICTA.2007.4806420","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806420","","Animation;Data engineering;Educational institutions;Humans;Indexes;Information retrieval;Large-scale systems;Principal component analysis;Spatial databases;Timing","computer animation;content-based retrieval;motion estimation","3D human motion;low-dimensional subspace tree;motion capture technique;motion retrieval;subspace index method","","0","","7","","","14-17 Sept. 2007","","IEEE","IEEE Conference Publications"
"An ontology oriented region-based image retrieval strategy","T. W. Chang; Y. P. Huang; F. E. Sandnes","Dept. of Computer Science and Information Engineering, De Lin Institute of Technology, Tucheng, Taipei County, Taiwan 236","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","2671","2676","A novel and more effective region-based image retrieval strategy is presented based on semantic ontology. An unsupervised segmentation algorithm splits images into regions that are subsequently used as basis by the ontology-based strategy. The approach comprises three stages, namely automatic region generation, categorization and ontology construction. When receiving a query for a specific object, the search engine will, in addition to conventionally matched images, also find candidates through the semantic ontology using low level features. The proposed approach can thus find a richer set of related candidate images than traditional image retrieval approaches. This strategy is particularly useful for vague queries encountered by inexperienced users that are not trained in searching for images by the means of low-level features. The experimental results demonstrate the effectiveness of the proposed approach.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811699","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811699","image region;image retrieval;image segmentation;semantic ontology","Computer science;Content based retrieval;Discrete cosine transforms;Feature extraction;Image retrieval;Image segmentation;Image storage;Information retrieval;Ontologies;Search engines","feature extraction;image matching;image retrieval;image segmentation;ontologies (artificial intelligence)","automatic region generation;image matching;low-level features;ontology oriented region-based image retrieval strategy;semantic ontology;unsupervised segmentation algorithm","","2","","18","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Continuous Skylining on Volatile Moving Data","M. W. Lee; S. w. Hwang","Dept. of Comput. Sci. & Eng., POSTECH, Pohang","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1568","1575","A dynamic skyline query retrieves the moving data objects that are not spatially dominated by any other object with respect to a given query point. Existing efforts on supporting such queries, however, supports location as a single dynamic attribute and one or more static dimensions. In a clear contrast, this paper focuses on the continuous skyline computation on moving data with an arbitrary number of dynamic queriable dimensions, e.g., to model both location and its volatility, with and without static dimension. Toward the goal, we investigate the relative positions and velocities of the initial skyline points with respect to the query, to derive a search region for skyline candidates. After retrieving these candidates, we further prune out some candidates and examine their spatial relations to monitor the changes in the skyline.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.162","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812574","","Aggregates;Computer science;Costs;Data engineering;Data mining;Dispatching;Euclidean distance;Information retrieval;Monitoring;Query processing","query processing;visual databases","continuous skyline query processing;dynamic attribute;static dimension;volatile moving data object","","7","","13","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Quantitative Analysis of a Common Audio Similarity Measure","J. H. Jensen; M. G. Christensen; D. P. W. Ellis; S. H. Jensen","Dept. of Electron. Syst., Aalborg Univ., Aalborg","IEEE Transactions on Audio, Speech, and Language Processing","20090324","2009","17","4","693","703","For music information retrieval tasks, a nearest neighbor classifier using the Kullback-Leibler divergence between Gaussian mixture models of songs' melfrequency cepstral coefficients is commonly used to match songs by timbre. In this paper, we analyze this distance measure analytically and experimentally by the use of synthesized MIDI files, and we find that it is highly sensitive to different instrument realizations. Despite the lack of theoretical foundation, it handles the multipitch case quite well when all pitches originate from the same instrument, but it has some weaknesses when different instruments play simultaneously. As a proof of concept, we demonstrate that a source separation frontend can improve performance. Furthermore, we have evaluated the robustness to changes in key, sample rate, and bitrate.","1558-7916;15587916","","10.1109/TASL.2008.2012314","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804953","Melody;musical instrument classification;timbre recognition","Bit rate;Cepstral analysis;Councils;Frequency;Instruments;Music information retrieval;Nearest neighbor searches;Source separation;Speech processing;Timbre","Gaussian processes;cepstral analysis;information retrieval;music;pattern classification","Gaussian mixture models;Kullback-Leibler divergence;audio similarity measure;melfrequency cepstral coefficients;music information retrieval tasks;nearest neighbor classifier;quantitative analysis","","10","","38","","","May 2009","","IEEE","IEEE Journals & Magazines"
"Content aware image segmentation for region-based object retrieval","Chi-Han Chuang; Chin-Chun Chang; Shyi-Chyi Cheng","Department of Computer Science and Engineering, National Taiwan Ocean University, 2 Pei-Ning Road, Keelung 20224, Taiwan","2008 International Symposium on Intelligent Signal Processing and Communications Systems","20090327","2009","","","1","4","It is desirable and yet remains as a challenge for querying multimedia data by finding an object inside a target image. The effectiveness of region-based representation for content-based image retrieval is extensively studied in the literature. One common weakness of the region-based approaches only in terms of regions' low-level visual features is that the homogeneous image regions have little correspondence to the semantic objects, thus, the retrieval results are often far from satisfactory. In addition, the performance is also ruled by the consistency of the segmentation result of the region of the target object in the query and target images. Instead of solving these problems independently, in this paper, a region-based object retrieval using the generalized Hough transform (GHT) and content aware image segmentation is proposed. The proposed approach has two phases. First, the learning phase finds and stores the stable parameters for segmenting each database image, and then sorts the database images according to the found segmentation parameters. In the retrieval phase, an incremental image segmentation process based on the stored segmentation parameters is performed to segment a query image into regions for retrieving visual objects inside database images through the GHT with a modified voting scheme for locating the target visual object under the geometry transformation. With the learned parameters for image segmentation, the segmentation results of query and target images are more stable and consistent. Computer simulation results show that the proposed method gives good performance in terms of retrieval accuracy, robustness, and execution speed.","","POD:978-1-4244-2564-8","10.1109/ISPACS.2009.4806745","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806745","","Computer simulation;Content based retrieval;Geometry;Image databases;Image retrieval;Image segmentation;Information retrieval;Spatial databases;Visual databases;Voting","Hough transforms;content-based retrieval;image representation;image retrieval;image segmentation;learning (artificial intelligence);object recognition;visual databases","content aware image segmentation;generalized Hough transform;geometry transformation;image database;learning phase;multimedia data querying;region-based object retrieval;region-based representation;target visual object location","","0","","12","","","8-11 Feb. 2009","","IEEE","IEEE Conference Publications"
"Efficient discovery technique of distributed KML data in mobile ad hoc network","T. Tsunoda; K. Sezaki","Institute of Industrial Science, the University of Tokyo, 4-6-1 Komaba, Meguro-ku, 153-8505 Japan","2009 11th International Conference on Advanced Communication Technology","20090403","2009","01","","751","756","The research topics of mobile ad hoc network are drawing attention for flexibly exchanging any data between local users. If we can apply the nature of ad hoc network to LBS systems, exchanging spatial data like KML between local users, we can easily retrieve data about any locations at any time. To realize such environment, we have to invent a more efficient query routing technique than conventional P2P ones. In this paper, we propose a novel routing method that utilizes R-Tree structure for arranging routing tables for users' queries. Using the tables, we can share KML data with low overheads.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810058","GPSR;KML;Mobile ad hoc network;R-Tree;peer to peer","Ad hoc networks;Information retrieval;Information science;Mobile ad hoc networks;Navigation;Proposals;Query processing;Routing protocols;Telecommunication traffic;Wireless networks","ad hoc networks;mobile radio;telecommunication network routing;trees (mathematics)","KML data sharing;LBS systems;Location Based Service;R-Tree structure;data exchange;data retrieve;distributed KML data discovery technique;mobile ad hoc networks;query routing technique","","0","","12","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"Probabilistic Skyline Operator over Sliding Windows","W. Zhang; X. Lin; Y. Zhang; W. Wang; J. X. Yu","NICTA, Univ. of New South Wales, NSW","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1060","1071","Skyline computation has many applications including multi-criteria decision making. In this paper, we study the problem of efficient processing of continuous skyline queries over sliding windows on uncertain data elements regarding given probability thresholds. We first characterize what kind of elements we need to keep in our query computation. Then we show the size of dynamically maintained candidate set and the size of skyline. We develop novel, efficient techniques to process a continuous, probabilistic skyline query. Finally, we extend our techniques to the applications where multiple probability thresholds are given or we want to retrieve ""top-k"" skyline data objects. Our extensive experiments demonstrate that the proposed techniques are very efficient and handle a high-speed data stream in real time.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.83","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812477","","Cleaning;Computer applications;Computer network management;Data analysis;Data engineering;Decision making;Identity management systems;Information retrieval;Monitoring;Portable computers","data analysis;decision making;query processing","continuous skyline queries;multi-criteria decision making;probabilistic skyline operator;probability thresholds;query computation;skyline computation;sliding windows","","28","","28","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Execution time reduction of Differential Power Analysis experiments","G. Di Natale; M. L. Flottes; B. Rouzeyre","Laboratoire d'Informatique, de Robotique et de Micro&#233;lectronique de Montpellier, Universit&#233; Montpellier II / CNRS UMR 5506, 161 rue Ada, 34392 Cedex 5, France","2009 10th Latin American Test Workshop","20090410","2009","","","1","5","Cryptographic devices can be subject to side-channel attacks that consist in retrieving secret data by observing physical properties of the device. Among those attacks, differential power analysis (DPA) has proven to be very effective and easy to perform. Several countermeasures have been proposed in the literature and one of the most promising is based on power balanced design. There are still not known methods for manufacturing test of power balanced circuits, aside from performing full DPA. This paper proposes a novel method that allows to drastically reduce the number of input vectors used for the DPA, thus reducing the overall test time.","2373-0862;23730862","POD:978-1-4244-4207-2","10.1109/LATW.2009.4813819","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813819","","Circuit faults;Circuit testing;Cryptography;Data security;Energy consumption;Information retrieval;Logic design;Logic devices;Performance evaluation;Protection","cryptography","cryptographic devices;differential power analysis;secret data;side-channel attacks","","0","","10","","","2-5 March 2009","","IEEE","IEEE Conference Publications"
"Online Near-Duplicate Video Clip Detection and Retrieval: An Accurate and Fast System","Z. Huang; L. Wang; H. T. Shen; J. Shao; X. Zhou","Sch. of Inf. Technol. & Electr. Eng., Univ. of Queensland, Brisbane, QLD","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1511","1514","Video search has become a compelling research topic in recent years, due to the proliferation of online video uploading/sharing sites and the exponential explosion of video data. In this demonstration, we showcase a Web-based integrated platform which performs online detection of near-duplicate occurrences over continuous video streams, as well as retrieval of near-duplicate clips from segmented video collections. In particular, our method to detect relevant subsequences in a streaming video is characterized by a novel one-dimensional distance trajectory capturing the changes of consecutive frames. Such a trajectory is further represented by a sequence of compact signatures. An effective similarity measure is devised to compare the trajectory with multiple query videos. This system shows a number of new features compared with our previous prototype.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812560","","Content based retrieval;Data engineering;Databases;Information retrieval;Information technology;Monitoring;Streaming media;Video sequences;Video sharing;Videoconference","Web sites;image segmentation;image sequences;object detection;video retrieval","Web-based integrated platform;continuous video stream;online near-duplicate video clip detection;online near-duplicate video clip retrieval;online video uploading/sharing sites;segmented video collection;similarity measure","","14","","9","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"KEA - applications of ontology engineering on mathematical natural language texts","S. Jeschke; N. Natho; M. Wilke","Center of Information Technologies (RUS) and Institute of Information Technology Services (IITS), University of Stuttgart, Germany, 70553","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3238","3243","Digital media in general and the Internet in particular play a ever growing role in the storage, dissemination and retrieval of information and knowledge. Semantic annotation of the provided information is necessary to support the user in retrieving and filtering requested information. Wide-spread tools like Google have shown both the power and the limitations of statistical methods based on correlations between terms within texts. The KEA system uses a different approach. Natural language processing techniques, taking advantage of characteristic linguistic structures defined by the language used in mathematical texts, are utilized in the automatic extraction of ontologies from mathematical texts. As a result, the system creates a base of the mathematical relations and concepts by mapping the extracted ontologies on the structure of a data base. To support the retrieval and further refinement of the data stored within this mathematical knowledge base, KEA implements a number of Web 2.0 technologies in a desktop style interface. The following article presents the technology and applications of the KEA system.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811795","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811795","","Data mining;Information retrieval;Information technology;Knowledge engineering;Knowledge management;Mathematics;Natural language processing;Natural languages;Ontologies;Semantic Web","information dissemination;information retrieval;information storage;mathematics computing;natural language processing;ontologies (artificial intelligence);text analysis;user interfaces","Google;Internet;KEA;Web 2.0 technologies;automatic extraction;characteristic linguistic structures;digital media;information dissemination;information filtering;information retrieval;mathematical natural language texts;mathematical texts;ontology engineering;statistical methods","","0","","40","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Powers of 10: Modeling Complex Information-Seeking Systems at Multiple Scales","P. Pirolli","Palo Alto Research Center","Computer","20090321","2009","42","3","33","40","New models of information-seeking support systems offer two advantages: They move us from prescientific conceptual frameworks about information seeking to more rigorous scientific theories and predictive models while, at the same time, expanding the kinds of things we study and develop.","0018-9162;00189162","","10.1109/MC.2009.94","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4803885","cyberinfrastructure initiative;information-seeking support systems;rational analysis;search","Information analysis;Information retrieval;Libraries;Navigation;Power system modeling;Predictive models;Problem-solving;Search engines;Shape;System testing","cognitive systems;human computer interaction;information retrieval","cognitive science;human-computer interaction;information-seeking support systems;predictive models;scientific theories","","20","","12","","","March 2009","","IEEE","IEEE Journals & Magazines"
"Automatic Image Annotation using Colour Entropy and Region Contours","G. Sureshkumar; R. Baskaran; M. Sathya; M. Deivamani","Department of Information Technology Easwari Engineering College Chennai, India. mgsureshkumar@gmail.com","2009 IEEE International Advance Computing Conference","20090331","2009","","","109","113","Semantic Image Annotation is a difficult task in Annotation Based Image Retrieval (ABIR) systems. Several techniques proposed in the past were lagging in efficiency and robustness. In this paper we are proposing a novel technique for automatically annotating multi-object images with higher accuracy. The colour entropy is used to eliminate the image background, and then we applied normalized cut principle for object separation. Our experimental results proved that the multi-class n-SVM performs better with colour feature extracted using histogram and shape feature extracted using Region Contours.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4808990","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4808990","Automatic Image Annotation;Colour Entropy;Image Segmentation;Support Vector Machines","Color;Computer science;Educational institutions;Entropy;Feature extraction;Histograms;Image segmentation;Information retrieval;Information technology;Shape","entropy;image colour analysis;image retrieval;image segmentation;object detection","annotation-based image retrieval system;automatic semantic image annotation;colour entropy;normalized cut principle;object separation;region contour","","0","","17","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Performance maximization for question classification by subset tree kernel using support vector machines","M. A. Rahman; V. Scurtu","Department of Physics, Jahangirnagar University, Dhaka, Bangladesh","2008 11th International Conference on Computer and Information Technology","20090321","2008","","","230","235","Question answering systems use information retrieval (IR) and information extraction (IE) methods to retrieve documents containing a valid answer. Question classification plays an important role in the question answer frame to reduce the gap between question and answer. This paper presents our research work on automatic question classification through machine learning approaches. We have experimented with machine learning algorithms Support Vector Machines (SVM) using kernel methods. An effective way to integrate syntactic structures for question classification in machine learning algorithms is the use of tree kernel (TK) functions. Here we use SubSet Tree kernel with Bag of words. Trade-off between training error and margin, Cost-factor and the decay factor has significant impact when we use SVM for the mentioned kernel type. The experiments determined the individual impact for Trade-off between training error and margin, Cost-factor and the decay factor and later the combined effect for Trade-off between training error and margin, Cost-factor. Depending on these result we also figure out some hyperplanes which can maximize the performance. Based on some standard data set outcomes of our experiment for question classification is promising.","","CD-ROM:978-1-4244-2136-7; POD:978-1-4244-2135-0","10.1109/ICCITECHN.2008.4802979","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4802979","Precision;Question Answering;Question Classification;Recall;SST;SVM;kernel","Classification tree analysis;Computer interfaces;Information retrieval;Kernel;Machine learning;Machine learning algorithms;Optical computing;Support vector machine classification;Support vector machines;Text categorization","classification;error statistics;information retrieval;learning (artificial intelligence);optimisation;support vector machines;trees (mathematics)","automatic question classification;cost-factor;decay factor;document retrieval;information extraction;information retrieval;machine learning approach;maximisation;question answering system;subset tree kernel function;support vector machine;training error statistics","","0","","12","","","24-27 Dec. 2008","","IEEE","IEEE Conference Publications"
"Alignment-Independent Chip-to-Chip Communication for Sensor Applications Using Passive Capacitive Signaling","Y. S. Lin; D. Sylvester; D. Blaauw","Univ. of Michigan, Ann Arbor, MI","IEEE Journal of Solid-State Circuits","20090324","2009","44","4","1156","1166","We propose a capacitive coupling based method for sensor data retrieval that can be easily integrated with miniature sensor nodes of sub-mm scale. To enable passive operation of the sensor chip, the data retrieval chip sends power to/receives signal from the sensor chip simultaneously. An alignment detection and pad reconfiguration mechanism is implemented to allow convenient read-out without precise positioning. A test chip was fabricated in 0.13 mum CMOS technology. The silicon measurement results demonstrate <15% difference in achievable data rate can be obtained when the sensor chip is randomly dropped on the data retrieval chip regardless of alignment.","0018-9200;00189200","","10.1109/JSSC.2009.2014024","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4804988","Capacitive coupling;proximity communication","Bandwidth;CMOS technology;Capacitive sensors;Energy consumption;Hardware;Information retrieval;Radiofrequency identification;Silicon;Testing;Transponders","CMOS integrated circuits;microsensors;signalling","CMOS technology;alignment-independent chip-to-chip communication;miniature sensor nodes;passive capacitive signaling;sensor applications;sensor data retrieval","","6","","19","","","April 2009","","IEEE","IEEE Journals & Magazines"
"A Branch and Cut Algorithm for DNA Encoding","Z. Wang; Z. Shao","Department of Control Science and Engineering, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, 430074, P. R. China. wangzch@mail.hust.edu.cn","2007 Second International Conference on Bio-Inspired Computing: Theories and Applications","20090327","2007","","","249","253","Encoding of information in DNA molecular is a crucial issue in DNA computing, and the coding problem plays an important role in DNA computation. In this paper, we consider the problem of DNA coding, and propose a branch and cut algorithm(BCA) to generate satisfactory single DNA sequences. Based on BCA, DNA sequences with length 20 are generated and compared with sequences produced by two existing algorithm. The comparison results show that the quality of DNA sequences generated by BCA is greatly improved.","","CD-ROM:978-1-4244-4106-8; POD:978-1-4244-4105-1","10.1109/BICTA.2007.4806461","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4806461","","Algorithm design and analysis;Computer architecture;Concurrent computing;DNA computing;Encoding;Hamming distance;Information retrieval;NP-complete problem;Sequences;Thermodynamics","biocomputing","DNA computing;DNA encoding;DNA molecular;DNA sequences;branch and cut algorithm","","1","","23","","","14-17 Sept. 2007","","IEEE","IEEE Conference Publications"
"Content-Based Color Image Retrieval System Using Color Difference Features","C. C. Chang; W. C. Wu; Y. C. Hu","Dept. of Inf. Eng. & Comput. Sci., Feng Chia Univ., Taichung","2008 Second International Conference on Future Generation Communication and Networking Symposia","20090410","2008","3","","181","184","In this paper, we propose a new color image retrieval scheme based on color features. The goal of this scheme is to effectively retrieve images similar to a query image in a color image database. In this scheme, a color image is first divided into three planes. Then the local features of the given image can be found by calculating the color difference of each plane. Thereafter, the color difference co-occurrence matrix (CDCOM) of each color image can be derived through these local features. The CDCOM is regarded as the global feature of the color image. Consequently, CDCOM is used to find images similar to the query image. Experiment results show that the proposed scheme can effectively retrieve the desired and similar images.","","CD-ROM:978-0-7695-3546-3; POD:978-1-4244-3430-5","10.1109/FGCNS.2008.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813575","","Color;Computer science;Content based retrieval;Histograms;Image databases;Image retrieval;Information retrieval;Pixel;Spatial databases;Visual databases","content-based retrieval;feature extraction;image colour analysis;image retrieval;matrix algebra","co-occurrence matrix;color difference feature extraction;color image database;content-based color image retrieval system","","3","","11","","","13-15 Dec. 2008","","IEEE","IEEE Conference Publications"
"Semantic feature reduction in chinese document clustering","Xianjun Meng; Qingcai Chen; Xiaolong Wang","ICRC Lab, Shenzhen Graduate School, Harbin Institute of Technology, China","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3721","3726","Text clustering techniques were usually used to structure the text documents into topic related groups which can facilitate users to get a comprehensive understanding on corpus or results from information retrieval system. Most of existing text clustering algorithm which derived from traditional formatted data clustering heavily rely on term analysis methods and adopted vector space model (VSM) as their document representation. But because of the essential characteristic underlying text such as high dimensionality features vector space, the problem of sparseness has a strong impact on the clustering algorithm. So feature reduction is an important preprocess step for improving the efficiency and accuracy of clustering algorithm by removing redundant and irrelevant terms from corpus. Even the clustering is considered as an unsupervised learning method, but in text, there is still some priori knowledge we can use from NLP analysis based approach. In this paper, we propose a semantic analysis based feature reduction method which used in Chinese text clustering. Our method bases on a dedicated Part-of-Speech tags selection and synonyms consolidation and can reduce the feature space of documents more effectively compared with traditional feature reduction method tfidf and stopwords removal; meanwhile it preserves or sometimes even improves the accuracy of clustering algorithm. In our experiment, we tested our feature reduction method using bisecting k-means algorithm which was proved be efficient in text clustering. The results show that our method can reduce the feature space significantly, and meanwhile have a better clustering accuracy in terms of the purity.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811878","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811878","feature selection;part-of-speech;synonym;text clustering","Algorithm design and analysis;Clustering algorithms;Clustering methods;Functional analysis;Information retrieval;Navigation;Search engines;Testing;Text mining;Unsupervised learning","information retrieval;natural language processing;text analysis;unsupervised learning","Chinese document clustering;document representation;information retrieval system;natural language processing;part-of-speech tags;semantic feature reduction;term analysis;text clustering;unsupervised learning;vector space model","","1","1","27","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
"Improving the Dataflow-Based Concern Identification Approach","M. Trifu","FZI Forschungszentrum Inf., Karlsruhe","2009 13th European Conference on Software Maintenance and Reengineering","20090410","2009","","","109","118","Concern identification aims to identify the implementation of a functional concern in existing source code. The dataflow-based concern identification approach starts from a set of concern seeds and uses static dataflow information to extract the data skeleton of a functional concern. This paper builds upon previous work on dataflow-based concern identification and presents three improvements to the identification approach: the reduction of the search space for manual identification of concern seeds, the introduction of information sources as a mechanism to explicitly define concern boundaries and the separation of superimposed class roles. The paper also shows the impact of these improvements by comparing the results of the improved identification approach with previously published results on the JHotDraw open-source case-study.","1534-5351;15345351","POD:978-1-4244-3755-9","10.1109/CSMR.2009.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812744","concern identification;concern seed;dataflow information","Computer languages;Data mining;Humans;Information retrieval;Java;Open source software;Skeleton;Software maintenance;Software systems","data flow computing;program diagnostics","JHotDraw open-source case study;data skeleton extraction;dataflow-based concern identification;dataflow-based concern identification approach;search space reduction;static dataflow information;superimposed class roles","","2","","25","","","24-27 March 2009","","IEEE","IEEE Conference Publications"
"A multi-level metadata structure for image archiving","Hyowon Kim; Y. Yoon","Dept of Multimedia Science, Sookmyung Women's University, Korea","2009 11th International Conference on Advanced Communication Technology","20090403","2009","02","","1449","1452","As the development of the society, the amount of information increases. So, the need is proposed to classify and arrange information systematically in order to delivery information to user and use efficiently through the information maintain and preserve. For this, construction of digital archiving is necessary. The current research has weakness of metadata adaptation related with archiving for image because the research structures for extensive contents. As the standard of digital archiving is OAIS(open archival information system) reference model that defined ISO standard in 2002 and this model has the structure that stores step by step organizing. In this paper, we find out digital archiving workflow based on OAIS(open archival information system) and define XML schema of metadata. For digital archiving of image, the addition of metadata needs to express based on not only simple fact but also semantic information about the picture. Therefore, we propose metadata management model based on multi-level classes.","1738-9445;17389445","POD:978-89-5519-138-7","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809689","Digital Archiving;DublinCore;Image;Image Archiving;MPEG-7;Metadata;Workflow","Digital systems;ISO standards;Information retrieval;Information systems;Internet;MPEG 7 Standard;Management information systems;Organizing;Printing;XML","image retrieval;information retrieval systems;meta data","digital archiving workflow;image archiving;image object;multi level metadata management model;open archival information retrieval;open archival information system","","0","","15","","","15-18 Feb. 2009","","IEEE","IEEE Conference Publications"
"V*-kNN: An Efficient Algorithm for Moving k Nearest Neighbor Queries","S. Nutanong; R. Zhang; E. Tanin; L. Kulik","Dept. of Comput. Sci. & Software Eng., Univ. of Melbourne, Melbourne, VIC","2009 IEEE 25th International Conference on Data Engineering","20090410","2009","","","1519","1522","This demonstration program presents the V*-kNN algorithm, an efficient algorithm to process moving k nearest neighbor queries (MkNN). The V*-kNN algorithm is based on a safe-region concept called the V*-Diagram. By incrementally maintaining the V*-Diagram, V*-kNN continuously provides accurate MkNN query results and supports dynamically changing values of k. Our approach exploits information regarding the current location of the query point and the search space in addition to the data objects. As a result, the V*-kNN has much smaller IO and computation costs than existing methods.","1063-6382;10636382","POD:978-1-4244-3422-0","10.1109/ICDE.2009.63","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4812562","","Computational efficiency;Computer science;Data engineering;Information retrieval;Laboratories;Nearest neighbor searches;Neural networks;Software algorithms;Software engineering;USA Councils","pattern clustering;query processing","MkNN query;V*-Diagram;V*-kNN algorithm;moving k nearest neighbor queries;search space","","2","","3","","","March 29 2009-April 2 2009","","IEEE","IEEE Conference Publications"
"Evaluation of Partition-Based Text Clustering Techniques to Categorize Indic Language Documents","D. A. Meedeniya; A. S. Perera","Department of Computer Science and Engineering, Faculty of Engineering, University of Moratuwa, Sri Lanka, dulanim@uom.lk","2009 IEEE International Advance Computing Conference","20090331","2009","","","1497","1500","Wide availability of electronic data has led to the vast interest in text analysis, information retrieval and text categorization methods. To provide a better service, there is a need for non-English based document analysis and categorizing systems, as is currently available for English text documents. This study is mainly focused on categorizing Indic language documents. The main techniques examined in this study include data pre-processing and document clustering. The approach makes use of a transformation based on the text frequency and the inverse document frequency, which enhances the clustering performance. This approach is based on latent semantic analysis, k-means clustering and Gaussian mixture model clustering. A text corpus categorized by human readers is utilized to test the validity of the suggested approach. The technique introduced in this work enables the processing of text documents written in Sinhala, and empowers citizens and organizations to do their daily work eficiently.","","POD:978-1-4244-2927-1","10.1109/IADCC.2009.4809239","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809239","","Availability;Computer science;Data engineering;Frequency;Humans;Information retrieval;Natural languages;Testing;Text analysis;Text categorization","Gaussian processes;natural languages;pattern clustering;text analysis","Gaussian mixture model clustering;Indic language document categorization;data pre-processing;document clustering;information retrieval;inverse document frequency;k-means clustering;latent semantic analysis;partition-based text clustering technique;text categorization;text frequency","","1","","10","","","6-7 March 2009","","IEEE","IEEE Conference Publications"
"Robust regression to varying data distribution and its application to landmark-based localization","S. Choi; J. H. Kim","U-Robot Research Division, Electronics and Telecommunications Research Institute, Daejeon, Republic of Korea","2008 IEEE International Conference on Systems, Man and Cybernetics","20090407","2008","","","3465","3470","Data may be wrongly measured or come from other sources. Such data is a big problem in regression, which retrieve parameters from data. Random sample consensus (RANSAC) and maximum likelihood estimation sample consensus (MLE-SAC) are representative researches, which focused on this problem. However, they do not cope with varying data distribution because they need to tune variables according to given data. This paper proposes user-independent parameter estimator, u-MLESAC, which is based on MLESAC. It estimates variables necessary in probabilistic error model through expectation maximization (EM). It also terminates adaptively using failure rate and error tolerance, which can control trade-off between accuracy and running time. Line fitting experiments showed its high accuracy and robustness in varying data distribution. Its results are compared with other estimators. Its application to landmark-based localization also verified its performance compared with other estimator.","1062-922X;1062922X","CD-ROM:978-1-4244-2384-2; POD:978-1-4244-2383-5","10.1109/ICSMC.2008.4811834","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811834","","Application software;Computer errors;Data engineering;Electric variables measurement;Error correction;Information retrieval;Maximum likelihood estimation;Parameter estimation;Robustness;Sampling methods","expectation-maximisation algorithm;information theory;maximum likelihood estimation;regression analysis","MLE-SAC;RANSAC;expectation maximization;landmark-based localization;maximum likelihood estimation sample consensus;probabilistic error model;random sample consensus;robust regression;varying data distribution","","6","","19","","","12-15 Oct. 2008","","IEEE","IEEE Conference Publications"
