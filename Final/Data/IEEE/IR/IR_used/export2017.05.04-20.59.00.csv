"http://ieeexplore.ieee.org/search/searchresult.jsp?ar=5255219,5255009,5255384,5255103,5255274,5255165,5255319,5254243,5255134,5254884,5246859,5246104,5250734,5246842,5250753,5246877,5236283,5236400,5236350,5236202,5236379,5236208,5236307,5235716,5236206,5236207,5236323,5234971,5234384,5234574,5235165,5234481,5234534,5234861,5234590,5234839,5234881,5234544,5234782,5234451,5234922,5234132,5234079,5234085,5233612,5234156,5234127,5233320,5230771,5231769,5231693,5231199,5231866,5231911,5233161,5232462,5232157,5232473,5231889,5232458,5232254,5232500,5232251,5231021,5232127,5231190,5231966,5230781,5231247,5231592,5232435,5231237,5231053,5231764,5231605,5232412,5232494,5231238,5231215,5231171,5231846,5228080,5228052,5230471,5227855,5228030,5228228,5228049,5228026,5229972,5228328,5228064,5228076,5228277,5228089,5228072,5228095,5230161,5228043,5230209",2017/05/04 20:59:00
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A segmentation-based method for 3D model retrieval","M. l. Qin; H. Liu","College of Information Science and Engineering, Shandong Normal University, Jinan 250014, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","896","902","A novel 3D model segmentation and retrieval method was introduced in this paper that is based on the topological information and partial geometry features of 3D mode. The proposed algorithm extracts feature for every triangular piece using flatness of a triangular, and partitions the 3D model into a set of triangular pieces with different flatness. Then, a watershed-based algorithm is developed and followed by an efficient region merging scheme to get a meaningful segmentation of the 3D model. And also a characteristics topology graph is constructed for the model in accordance with the topological relations between the blocks. To simplify the computational complexity of the similarity of two models, spanning trees of the topography graph is constructed firstly and then the similarity between the spanning trees is calculated. Experimental results show that this segmentation and retrieval algorithm is efficient and robust.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236202","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236202","","Computational complexity;Data mining;Feature extraction;Information geometry;Information retrieval;Merging;Partitioning algorithms;Solid modeling;Topology;Tree graphs","computational complexity;feature extraction;image retrieval;image segmentation;trees (mathematics)","3D model;3D model retrieval method;characteristics topology graph;computational complexity;partial geometry feature extraction;region merging scheme;segmentation-based method;spanning trees;topography graph;topological information;triangular piece;watershed-based algorithm","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Comparative Study of PCA, LDA and Kernel LDA for Image Classification","F. Ye; Z. Shi; Z. Shi","Key Lab. of Intell. Inf. Process., Chinese Acad. of Sci., Beijing, China","2009 International Symposium on Ubiquitous Virtual Reality","20090904","2009","","","51","54","Although various discriminant analysis approaches have been used in content-based image retrieval (CBIR) application, there have been relatively few concerns with kernel-based methods. Furthermore, these CBIR applications still applied discriminant analysis to face images as face recognition did. In this paper we concerns images with general semantic concepts. We use our presented symmetrical invariant LBP (SILBP) texture descriptor to extract image visual features. We then explored effectiveness of principal component analysis (PCA), fisher linear discriminant analysis (LDA), and kernel LDA algorithms in providing optimal discrimination features. Following it, we present an LDA based framework to carry out kernel discrimiant analysis in our application. By taking advantage of the efficiency in nonlinear condition of kernel-based methods and the simplicity of LDA, the proposed approach can improve the retrieval precision of CBIR. The experimental results validate the effectiveness of the proposed approach.","","POD:978-1-4244-4437-3","10.1109/ISUVR.2009.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232254","Kernel LDA;LDA;PCA;image classification;subspace method","Content based retrieval;Face recognition;Feature extraction;Image analysis;Image classification;Image retrieval;Information retrieval;Kernel;Linear discriminant analysis;Principal component analysis","content-based retrieval;face recognition;feature extraction;image classification;image retrieval;principal component analysis","applied discriminant analysis;content-based image retrieval;face recognition;fisher linear discriminant analysis;image classification;image visual feature extractor;kernel LDA algorithm;kernel discrimiant analysis;kernel-based method;principal component analysis;symmetrical invariant LBP texture descriptor","","3","","20","","","8-11 July 2009","","IEEE","IEEE Conference Publications"
"Concept Based Query Expansion Using WordNet","J. Zhang; B. Deng; X. Li","Dept. Electron. Eng., Tsinghua Univ., Beijing, China","2009 International e-Conference on Advanced Science and Technology","20090904","2009","","","52","55","Query expansion is a widely studied technique for improving information retrieval effectiveness. In this paper we proposed a new query expansion technique using the comprehensive thesaurus WordNet and its semantic relatedness measure modules. Word sense disambiguation are performed on original query sentence, yielding the concept of each term in the query. Based on those recovered concepts, expanded query terms are generated from WordNet lexical database. The proposed method has been evaluated in document retrieval on the Web using query sentence. Our extensive experimental results demonstrate a 7% precision improvement over retrieval methods not employing query expansion techniques.","","POD:978-0-7695-3672-9","10.1109/AST.2009.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231693","","Books;Databases;Information retrieval;LAN interconnection;Manuals;Natural languages;Robustness;Speech;Thesauri","document handling;query processing","WordNet lexical database;comprehensive thesaurus;concept based query expansion;document retrieval;expanded query terms;information retrieval;query sentence;recovered concepts;semantic relatedness measure modules;word sense disambiguation","","10","","11","","","7-9 March 2009","","IEEE","IEEE Conference Publications"
"Research and Design of Internet Public Opinion Analysis System","Q. Guan; S. Ye; G. Yao; H. Zhang; L. Wei; G. Song; K. He","Network & Educ. Technol. Center, Jinan Univ., Guangzhou, China","2009 IITA International Conference on Services Science, Management and Engineering","20090904","2009","","","173","177","Internet is becoming a spreading platform for the public opinion. It is important to grasp the Internet public opinion in time and understand the trends of their opinion correctly. Text classification plays a fundamental role in a number of information management and retrieval tasks. But Web-page classification is much more difficult than pure-text classification due to a large variety of noisy information embedded in Web pages. In this paper, we propose a system scheme for the analysis of the Internet public opinion (IPO). We apply Web-page classification through summarization to extract the most relevant content from the Web pages and then pass them to standard text classification algorithms (NB or SVM). We comprehensive use text classification and text clustering algorithms, which have been shown to be efficient and effective for singly using. Through the result of the experiment,we have proved the superiority of the system systempsilas architecture in the system design.","","POD:978-0-7695-3729-0","10.1109/SSME.2009.62","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5233320","Internet public opinion;Web-page summarization;text classification;vector space model","Classification algorithms;Clustering algorithms;Data mining;Information management;Information retrieval;Internet;Niobium;Support vector machines;Text categorization;Web pages","Internet;classification;information retrieval;pattern clustering;text analysis","IPO;Internet public opinion analysis system;Web-page classification;Web-page summarization;information management;information retrieval;text classification algorithm;text clustering algorithm","","5","","12","","","11-12 July 2009","","IEEE","IEEE Conference Publications"
"A Spatial Correlation Model for Visual Information in Wireless Multimedia Sensor Networks","R. Dai; I. F. Akyildiz","Broadband Wireless Networking Lab., Georgia Inst. of Technol., Atlanta, GA, USA","IEEE Transactions on Multimedia","20090911","2009","11","6","1148","1159","Wireless multimedia sensor networks (WMSNs) are interconnected devices that allow retrieving video and audio streams, still images, and scalar data from the environment. In a densely deployed WMSN, there exists correlation among the visual information observed by cameras with overlapped field of views. This paper proposes a novel spatial correlation model for visual information in WMSNs. By studying the sensing model and deployments of cameras, a spatial correlation function is derived to describe the correlation characteristics of visual information observed by cameras with overlapped field of views. The joint effect of multiple correlated cameras is also studied. An entropy-based analytical framework is developed to measure the amount of visual information provided by multiple cameras in the network. Furthermore, according to the proposed correlation function and entropy-based framework, a correlation-based camera selection algorithm is designed. Experimental results show that the proposed spatial correlation function can model the correlation characteristics of visual information in WMSNs through low computation and communication costs. Further simulations show that, given a distortion bound at the sink, the correlation-based camera selection algorithm requires fewer cameras to report to the sink than the random selection algorithm.","1520-9210;15209210","","10.1109/TMM.2009.2026100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235165","Camera selection;spatial correlation;visual information;wireless multimedia sensor networks","Algorithm design and analysis;Cameras;Computational efficiency;Cost function;Image retrieval;Image sensors;Information analysis;Information retrieval;Streaming media;Wireless sensor networks","correlation methods;entropy;information retrieval;media streaming;video cameras;video streaming;wireless sensor networks","audio stream retrieval;correlation-based camera selection algorithm;entropy-based analytical framework;spatial correlation model;video retrieval;visual information;wireless multimedia sensor network","","62","1","20","","","Oct. 2009","","IEEE","IEEE Journals & Magazines"
"Medical image retrieval from distributed environment","M. S. Anbarasi; S. Sandhya; K. M. Mehata; V. Suganya","Department of Information Technology, Ponicherry Engineering College, Puducherry, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","8","Image retrieval from distributed database is one of the challenging tasks in recent researches. Unlike text retrieval through SQL, MYSQL, etc, image retrieval is not an easy task because of its storage space, color, shape and texture factor. We propose a technique of retrieving images from a distributed database environment by giving a region of an image as an input query. By applying segmentation techniques while retrieval, the efficiency of retrieval is enhanced. This can be applied in medical field to locate tumors and other pathologies, measure tissue volumes, computer-guided surgery, diagnosis, treatment planning and study of anatomical structure.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228026","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228026","Segmentation;edge detection;feature organization;feature representation;filters","Biomedical imaging;Distributed databases;Image databases;Image retrieval;Image segmentation;Image storage;Information retrieval;Medical diagnostic imaging;Neoplasms;Shape","biological tissues;content-based retrieval;distributed databases;image colour analysis;image retrieval;image segmentation;image texture;medical image processing;medical information systems;surgery;tumours","MYSQL;SQL;anatomical structure;computer-guided surgery;content-based image retrieval;distributed database environment;image color factor;image shape factor;image texture factor;input query;medical diagnosis;medical image retrieval;pathology;segmentation technique;storage space;text retrieval;tissue volume measurement;treatment planning;tumor location","","1","","10","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Multiple watermark embedding scheme in wavelet-spatial domains based on ROI of medical images","E. F. Badran; M. A. Sharkas; O. A. Attallah","Arab Academy for Science & Technology, Alexandria, Egypt","2009 National Radio Science Conference","20090909","2009","","","1","8","Watermarking in medical images is a new area of research. It has the potential of being a value-added tool for medical confidentiality protection, patient-related information hiding, and information retrieval. Medical image watermarking requires extreme care when embedding additional data within the medical images because the additional information must not affect the image quality as this may cause misdiagnosis. In this paper we present a scheme that depends on the extraction of the ROI (region of interest) and its use as a watermark to be embedded twice; first as a robust watermark in the RONI (region of non interest) in the wavelet domain and again as a fragile watermark in the ROI in the spatial domain. Moreover multiple watermarks such as the physician's digital signature and EPR (Electronics Patient Record) are embedded in the RONI in wavelet domain depending on a private key. We compare this scheme by another one that we presented before to show the robustness of new scheme. In our work we use MRI brain images with a brain tumor as the ROI. The experimental results showed that the watermarked image is robust to JPEG compression, ROI removal, and addition of an additional tumor to the image and some geometrical attacks; lowpass and median filtering and some types of noise as; Gaussian, Poisson, Salt and Pepper and finally Speckle.","1110-6980;11106980","POD:978-1-4244-4214-0","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234079","","Biomedical imaging;Brain;Data mining;Image quality;Information retrieval;Neoplasms;Protection;Robustness;Watermarking;Wavelet domain","biomedical imaging;information retrieval;watermarking","image watermarking;information retrieval;medical confidentiality protection;medical images;multiple watermark embedding scheme;patient-related information hiding;region of interest;wavelet-spatial domains","","2","","16","","","17-19 March 2009","","IEEE","IEEE Conference Publications"
"User-adaptive interface based on mental model and symbol matching","S. Kim; K. Sekiyama; T. Fukuda","Department of Micro-Nano Systems Engineering, Nagoya University, Furo-cho, Chilkusa-ku, 464-8603, Japan","2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics","20090901","2009","","","457","462","We design a user-adaptive interface that is adapted to a driver considering his/her personal differences. This paper deals with the interactive adaptation interface based on probability model of hidden Markov model and symbol matching for in-vehicle information systems. This interface builds a user's navigation pattern model by navigation data and recommends symbols or clues which are affected by the user model. User's intention is inferred by the interactive behavior between the driver and the interface which is symbol matching. As an application example, we present a car navigation system and experiments were performed to confirm the effectiveness on the reduction of the response time.","2159-6247;21596247","POD:978-1-4244-2852-6","10.1109/AIM.2009.5229972","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5229972","","Cognitive science;Delay;Graphical user interfaces;Hidden Markov models;Information retrieval;Information systems;Intelligent transportation systems;Navigation;Vehicle driving;Vehicle safety","automated highways;computerised navigation;hidden Markov models;interactive systems;user modelling","Intelligent Transportation System;car navigation system;hidden Markov model;in-vehicle information system;interactive adaptation interface;mental model;response time reduction;symbol matching;user navigation pattern model;user-adaptive interface","","0","","14","","","14-17 July 2009","","IEEE","IEEE Conference Publications"
"Query Intensive Interface Information Extraction Protocol for deep web","D. K. Sharma; A. K. Sharma","Dept. of Computer Science & Engineering, G L A Institute of Technology and Management, Mathura, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","5","A new query intensive interface information extraction protocol (QIIIEP) for deep Web retrieval process is proposed. Auto query word extraction and auto form unification procedure are newly proposed in order to comprehend various functions of the proposed protocol. Proposed protocol offers great advantages in deep Web crawling without over burdening the requesting server. However, conventional deep web crawling procedures result in heavy communication processing loads and procedural complexity for applying either schema matching or improper otology based query. This makes it difficult to crawl entire contents of deep web. In the proposed protocol, the tradeoff between correct query response and communication loads is solved by generating knowledge base at QIIIEP server. Therefore, the proposed protocol can realize flexible and highly efficient data extraction mechanism after deploying QIIIEP server on deep web domain. It enables not only the one stop information retrieval process but also provides auto authentication mechanism for supplied domain.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228052","Deep web;HTTP;QIIIEP;query interface analysis;relevance ranking;response analysis and navigation;values allotment","Classification tree analysis;Clustering algorithms;Computer science;Crawlers;Data mining;Decision trees;Information retrieval;Navigation;Protocols;Web server","Internet;protocols;query processing","QIIIEP server;auto form unification procedure;auto query word extraction;data extraction mechanism;deep Web crawling;deep Web retrieval process;information retrieval process;otology based query;query intensive interface information extraction protocol","","4","","27","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"A unified study on human and Web granular reasoning","N. Zhong","Department of Life Science and Informatics, Maebashi Institute of Technology, Japan","2009 8th IEEE International Conference on Cognitive Informatics","20090918","2009","","","3","4","In this talk, we will describe studying on granular reasoning of human and Web in a unified way from the viewpoint of brain informatics. We consider Web granular reasoning as an application of human-inspired granular reasoning. As for human granular reasoning, based on the previous studies about basic-level advantage and its reversal effect, we use fMRI/ERP to investigate how the neural system cooperates and coordinates with each other when the starting point locates in the basic level and how the brain modulates and adapts to the change when the starting point switches to a more general level. The key question is ldquocan we find a new cognitive model for developing human-level Web based granular reasoning and problem-solving?rdquo In order to answer this question, we investigate the cognitive mechanism and neural basis of human problem solving and reasoning, for developing new cognitively inspired Web intelligence models. Based on the above results, we will implement Problem Solver Markup Language (PSML) for representing, organizing, retrieving, and selecting Web information sources with multiple levels of granularity, and develop PSML based Web inference engines for personalized wisdom Web problem solving and services.","","POD:978-1-4244-4642-1","10.1109/COGINF.2009.5250734","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5250734","","Artificial intelligence;Engines;Humans;Informatics;Information retrieval;Markup languages;Organizing;Problem-solving;Switches;World Wide Web","Internet;Web services;inference mechanisms;page description languages;problem solving","PSML based Web inference engines;Problem Solver Markup Language;Web granular reasoning;Web information sources;brain informatics;cognitively inspired Web intelligence model;fMRI/ERP;human-inspired granular reasoning;personalized wisdom Web problem solving;personalized wisdom Web services","","0","","","","","15-17 June 2009","","IEEE","IEEE Conference Publications"
"Research and design on corpus-informed vocabulary instruction (CIVI) under web condition","P. Yang; Q. Chen","College of Foreign Languages, Guizhou University, Guiyang China","2009 4th International Conference on Computer Science & Education","20090901","2009","","","1545","1548","Corpus-informed vocabulary instruction approach (CIVI) is a novelty in teaching method in China and makes it possible to improve the college English vocabulary teaching. Based theoretically on constructivism and Krashen's Input Hypothesis, this paper searches for the combination of college English network teaching and corpus, and attempts to design a corpus-informed vocabulary instruction (CIVI) mode aiming at improving students' autonomy vocabulary learning.","","POD:978-1-4244-3520-3","10.1109/ICCSE.2009.5228328","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228328","Input Hypothesis;constructivism;corpus-informed vocabulary instruction","Communications technology;Computer science;Computer science education;Educational institutions;Information retrieval;Innovation management;Monitoring;Natural languages;Technological innovation;Vocabulary","Internet;computer aided instruction;linguistics;teaching;vocabulary","China;Krashen input hypothesis;Web condition;college English network teaching;college English vocabulary teaching;constructivism;corpus-informed vocabulary instruction;language learning;teaching method","","0","","11","","","25-28 July 2009","","IEEE","IEEE Conference Publications"
"Web search personalization: A fuzzy adaptive approach","M. S. Norouzzadeh; A. Bagheri; M. H. Saraee","Data Mining Lab, Department of Electrical and Computer Engineering, Isfahan University of Technology, Iran","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","143","148","Today the growing rate of Web data has become so large and this is the reason for turning search engines into the major decision support systems for the Internet. In this paper, a novel and simple approach is proposed to improve Web search. The approach is a client-side method towards personalization of web search which adapts the results based on user interests. In addition we define a fuzzy variable to clarify the relevance of each document. In real world, notion of relevance is a fuzzy concept and certainly the relevancy ratios of some relevant documents are not equal. By applying our approach to the Google's datasets the result shows that this approach can improve performance in search.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234590","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234590","Adaptive Search;Fuzzy Theory;Search Personalization;Web Search","Data mining;Decision support systems;Information filtering;Information filters;Information retrieval;Internet;Search engines;Turning;Web pages;Web search","Internet;decision support systems;document handling;search engines","Google datasets;Internet;Web data;Web search personalization;client-side method;decision support systems;fuzzy adaptive approach;search engines;user interests","","0","","33","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Local fractallity as a feature in database image retrieval","D. A. Crisan; C. Coculescu; J. L. Stanica; A. N. Altar Samuel","Faculty of Computer Science for Business Management, Romanian-American University, Bucharest, Romania","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","114","117","An important aspect encountered in archaeological field consists in the identification of the broken pieces part of an object. A preliminary analysis presupposes the grouping of the articles by material, but this is not enough. A second analysis will be done, this time considering the shape of the frontier of the broken piece. In order to describe the shape of an object's border, the evaluation of some local fractal features is proposed. The algorithms for extracting fractal features were implemented into an original software. The final purpose consists in building a component for a content-based image retrieval (CBIR) which uses a classifier based on fractal properties.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234839","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234839","content-based image retrieval;fractal dimension;image processing;image retrieval;local fractallity","Content based retrieval;Feature extraction;Fractals;Geometry;Image analysis;Image databases;Image retrieval;Information retrieval;Shape;Spatial databases","archaeology;content-based retrieval;feature extraction;fractals;image classification;image retrieval;visual databases","CBIR;archaeological field;classifier;content-based image retrieval;database image retrieval;fractal feature extraction;local fractallity;object border shape","","0","","10","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Ambiguity Discovery Algorithm on Chinese Word Segmentation Based Dictionary","T. Sun; Y. Liu; L. Yang; Z. Li; Z. Liu","Dept. of Comput. Sci., Northeast Normal Univ., Chang Chun, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","39","42","Chinese word segmentation is a basic research issue on Chinese information processing tasks such as information extraction; information retrieval; machine translation; text classification; automatic text summarization; speech recognition, natural language understanding and So on. And the ambiguity problem is one of the most difficult problems in Chinese word segmentation .The paper introduced several normal ambiguity discovery algorithm, and proposed a new method of ambiguity discovery that can discover many crossing ambiguity fields and covering ambiguity fields at the same time.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232462","Chinese information processing;Chinese word segmentation;ambiguity discovery algorithm;covering ambiguity;crossing ambiguity","Computer science;Data mining;Dictionaries;Electronic mail;Information processing;Information retrieval;Natural languages;Speech recognition;Text categorization;Vocabulary","dictionaries;natural language processing;word processing","Chinese information processing;Chinese word segmentation;ambiguity discovery algorithm;dictionary","","1","","20","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Web Document Categorization Algorithm Using LDE and MA","X. Sun; Z. Wang","Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","197","200","Document categorization is one of the most crucial techniques to assign the documents of a corpus to a set of previously fixed categories. To efficiently deal with document categorization problem, an efficient document categorization algorithm based on local discriminant embedding (LDE) and memetic algorithm (MA) is proposed in this paper. Extensive experiments on Reuter-21578 demonstrate that the proposed algorithm performs much better than other conventional document categorization algorithms.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232500","","Classification algorithms;Evolutionary computation;Information filtering;Information retrieval;Information science;Internet;Pattern classification;Scheduling;Sun;Supervised learning","Internet;document handling;pattern classification","Reuter-21578;Web document categorization algorithm;local discriminant embedding;memetic algorithm","","0","","10","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"CAMAR Tag Framework: Context-Aware Mobile Augmented Reality Tag Framework for Dual-reality Linkage","H. Kim; W. Lee; W. Woo","GIST U-VR Lab., Gwangju, South Korea","2009 International Symposium on Ubiquitous Virtual Reality","20090904","2009","","","39","42","In this paper, we propose a novel tag framework for sharing information in dual-reality space, which is based on context-aware mobile augmented reality (CAMAR). When a user selects a target object to be tagged onto dual-reality, the proposed framework and procedures create CAMAR Tag with a userpsilas mobile device to be registered in virtual space. CAMAR Tag is able to play a role as a reference point, a sharing point and a key of contextual searching. We present a concept behind CAMAR Tag and how it can be generated, implemented and deployed in dual-reality.","","POD:978-1-4244-4437-3","10.1109/ISUVR.2009.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232251","CAMAR Tag;Tag framework;dual-reality;mobile augmented reality","Augmented reality;Content management;Context modeling;Couplings;Data models;Information retrieval;Joining processes;RFID tags;Target recognition;Virtual reality","augmented reality;ubiquitous computing","CAMAR;context-aware mobile augmented reality tag;contextual searching;dual-reality linkage;virtual space","","2","2","7","","","8-11 July 2009","","IEEE","IEEE Conference Publications"
"Document Classification Algorithm Using Kernel LPP","Z. Wang; X. Qian","Coll. of Mech. Electron. & Inf. Eng., China Univ. of Min. & Technol.(Beijing), Beijing, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","2","","100","102","With the explosive increase in document data on the Internet, classifying documents from document database has become one of the hottest research fields.To efficiently deal with this problem, an efficient document classification algorithm based on kernel locality preserving projection (Kernel LPP) is presented in this paper. Experimental results show that the proposed algorithm outperforms other related document classification algorithms.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.54","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231021","document classification;kernel machine;locality preserving projection (LPP)","Classification algorithms;Data mining;Educational institutions;Explosives;Information retrieval;Internet;Kernel;Large scale integration;Linear discriminant analysis;Pattern recognition","Internet;document handling","Internet;document classification algorithm;document database;kernel LPP;kernel locality preserving projection","","0","","10","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Cascade Chinese Potential Name Recognition","L. Hongjian; G. Defeng; Z. Quan; N. Kenji; S. Qinghua","Hitachi (China) R&D Corp., Shanghai, China","2009 International Forum on Information Technology and Applications","20090904","2009","3","","329","333","In this paper, cascade Chinese potential name recognition is proposed. Internal information of a person like family name, first name do not needed for name recognition while context keywords is used for name guessing. Some conceptions such as bidirectional potential name recognition, rough confirmation of potential name, segmentation word, cascade recognition and final person name confirmation is proposed. Experiment proves that the method presented in this paper have a special advantage in recognition on foreign translation name, special name, combinational name, ambiguity name, irregular name etc. The method can be taken as a pre-processing method of other person name recognition method with using internal name information. The method in the paper is not limit to Chinese name recognition but also can be generalized to other named entity identification.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.85","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232127","context keywords;named entity identification;potential name;segmentation word","Information analysis;Information retrieval;Information technology;Laboratories;Speech recognition;Speech synthesis;Statistical analysis;Statistics;Sun;Viterbi algorithm","computer vision;image recognition;natural languages","bidirectional potential name recognition;cascade Chinese potential name recognition;foreign translation name;named entity identification;preprocessing method","","1","","9","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Automatic Tamil Content Generation","S. Kohilavani; T. Mala; T. V. Geetha","Department of Computer Science & Engineering, Anna University, College of Engineering, Guindy, Chennai, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","6","Automatic content generation aims on developing an intelligent tutoring system in Tamil language. This system focuses on delivering personalized content in Tamil language to an individual user needs based on their learning abilities and interests. This paper deals with automatic classification of Tamil documents and also the information extraction from those documents to construct the knowledge base. Documents are repositories of knowledge. There are numerous documents available and effective search in documents is time consuming. To make document search a simpler task, we need to perform document categorization. Document category can be found out using various techniques. In this paper, naive Bayes (NB) algorithm is used to classify Tamil documents to one of predefined categories. Experiments are used to evaluate the naive Bayes categorizer. The experimental results show that the naive Bayes classifier performs well and its effectiveness is achieved with 89.8% accuracy. Informational words or sentences of the documents are then extracted using heuristic rules to fill up the predefined templates. An individual user's interests are identified and recorded to create a user profile. A user profile is specific to a user and is subjected to change over time. The topic categorizer is used to categorize the topic based on user's query. The topic analyzer is used to analyze the user's profile and evaluate the user's knowledge using intelligent evaluator system. Based on the user's knowledge, intelligent evaluator system makes a decision to suggest the location or to suggest a new topic retrieved from the knowledge base. Then the personalized content will be generated based on the knowledge level of the user. The experimental results show that the content generator performs well and its effectiveness is achieved with 82.35% accuracy.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228064","Document Categorization;Naïve Bayes;Stopwords;classifier;information extraction;preprocessing","Computer science;Data mining;Educational institutions;Indexing;Information retrieval;Intelligent systems;Machine learning algorithms;Natural languages;Niobium;Text categorization","Bayes methods;knowledge acquisition;pattern classification;query processing;text analysis;user interfaces;word processing","Tamil documents classification;Tamil language;automatic content generation;intelligent tutoring system;naive Bayes algorithm;user profile","","4","","13","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"A Proposal of P2P-Based Resource Discovery Mechanism for the Grid","K. Kokubo; K. Ichikawa; Y. Ishi; S. Date","Cybermedia Center, Osaka Univ., Suita, Japan","2009 Ninth Annual International Symposium on Applications and the Internet","20090904","2009","","","288","289","Resource discovery is a fundamental service of the grid to find out resources suitable for executing user jobs. Traditional resource discovery services of the grid have static structure and centralized or hierarchized, such as Globus MDS. However, with the number of resources composing the grid increased, this approach has two problems, namely, on dynamic changes of the structure in the grid and obtaining the latest resource information. To solve these problems, we have been seeking for the possibility of a resource discovery mechanism adopting peer-to-peer approach, which is characterized by real-time retrieval of information using an overlay network spanned on physical computational resources. In this paper, we present the preliminary results of our research activities so far.","","POD:978-1-4244-4776-3","10.1109/SAINT.2009.68","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230771","Grid;P2P;Resource Discovery","Aggregates;Availability;Computer architecture;Grid computing;Information retrieval;Internet;Peer to peer computing;Proposals;Prototypes;Web server","grid computing;information retrieval;peer-to-peer computing;resource allocation","P2P-based resource discovery mechanism;grid computing;overlay network;peer-peer computing;real-time information retrieval","","2","","2","","","20-24 July 2009","","IEEE","IEEE Conference Publications"
"Ontology based approach for retrieval intention analysis in e-Learning system","J. Yue; Z. Li; Y. Duan; Z. Fu","College of Management, Ludong University, Yantai, 264025, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","450","453","Knowledge management and retrieval are important parts of an e-learning system. The retrieval intention is hard to express by traditional keywords based retrieval mode. In this paper, based on analyzing keywords in semantic layer, semantic similarity is calculated to catch the user's retrieval intention. Finally, the proper semantic mapping from keywords to concepts in knowledge base is realized. The semantic retrieval approach in this paper is significant for the individualized e-learning system construction.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236379","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236379","","Artificial intelligence;Computer science;Educational institutions;Electronic learning;Information retrieval;Internet;Knowledge management;OWL;Ontologies;Resource description framework","computer aided instruction;human factors;information retrieval;knowledge based systems;ontologies (artificial intelligence);semantic Web","e-learning system;keyword analysis;knowledge base;knowledge management;ontology based approach;semantic mapping;semantic similarity;user retrieval intention analysis","","0","","13","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"The Case Retrieval Strategy Based on Hierarchical Clustering","S. Ma; J. Li; D. Liu","Henan Mech. & Electron. Eng. Coll., Xinxiang, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","81","85","Case-based reasoning technology has been widely applied in many areas. This study first clustered the case base according to hierarchy, then on the foundation of which designed a retrieval strategy based on non-isomorphic case base, analyzed the hierarchal clustering rules of case base, and mainly discussed the case retrieval strategy based on clustering. The results of the experiment show that this method can efficiently improve the utilization rate of cases in case base as well as the success rate of the case retrieval.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232473","Case-Based Reasoning(CBR);case retrieval strategy;feature item's weight;hierarchical clustering;similarity","Accuracy;Artificial intelligence;Educational institutions;Information retrieval;Libraries","case-based reasoning;information retrieval;pattern clustering","case retrieval strategy;case-based reasoning;hierarchical clustering","","0","","6","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Description logic representation for semantic concepts of feature","Y. Zhang; X. Luo","School of Mechanical Engineering, Dalian University of Technology, China","2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics","20090918","2009","","","544","547","In order to make the semantic information of feature be shared and understood by computer, this paper discusses and analysis the semantic information of features, presents a semantic concept of feature. Based on description logic representations for semantic concepts of features and hierarchy structures are given. Based on the description logical reasoning of concept, a solution to realize automatic classification and mapping of concepts is discussed. Description logic representation for semantic concepts of feature creates a basis for ontology representation of feature information.","","POD:978-1-4244-3699-6","10.1109/CADCG.2009.5246842","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5246842","","Application software;Automatic logic units;Computer aided manufacturing;Information analysis;Information retrieval;Knowledge representation;Manufacturing processes;Mechanical engineering;Ontologies;Shape","CAD/CAM;computer aided production planning;inference mechanisms;knowledge representation languages;ontologies (artificial intelligence);pattern classification","CAM;CAPP;automatic classification;description logic representation;description logical reasoning;heterogeneous CAD system;hierarchy structure;knowledge representation language;ontology representation;semantic feature concept mapping","","0","","6","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"Concept similarity analysis in Ontology's automatic extraction","Li Peng","School of Information, Linyi Normal University, Linyi China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","253","259","Ontology's automatic extraction is a core problem of information integration in electronic government affair. In the process of ontology's automatic extraction, FCA method is used in analyzing relationships between concepts automatically. But this method's ability is insufficient in the analysis of the synonym relationship. This paper optimizes the FCA method and brings forward a new algorithm - SFCA. SFCA sets the weight for the attribute based on the importance of it. It computes the similarity degree using the weights and judges whether the concepts are synonymous. Through the analysis of the experiment's result, the algorithm is validated to be effective. And its correctness proof is proved.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234574","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234574","Automatic extraction;FCA;Information Integration;Ontology;SFCA","Algorithm design and analysis;Data mining;Electronic government;Inference algorithms;Inference mechanisms;Information analysis;Information retrieval;Ontologies;Optimization methods;Wrapping","government data processing;information retrieval;matrix algebra;ontologies (artificial intelligence)","SFCA;automatic ontology extraction;concept similarity analysis;electronic government affair;incidence matrix;information integration;information retrieval;synonym formal concept analysis;synonym relationship","","0","","11","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Novel Method for XML Scheme Matching","Z. Jiuzhen; Z. Shidong; Y. Zhongmin","Sch. of Comput. Sci. & Technol., Shandong Univ., Jinan, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","332","335","XML Schema is becoming a critical technology for e-business applications and the emergence of web services. With its widespread adoption and its web accessibility, XML Schema matching is becoming imperative. This paper presents an approach to elements matching between two XML Schemas using similarity measure and constraint optimization. In our method, we first transform the schema matching problem into a tree matching problem by transforming schemas to be matched into labeled (including node label and edge label) trees. The similarity measure considers element categories and properties. In order to get an optimal matching, we compute the structural similarity value based on the neighbors of each element (ancestor, children, and sibling). We test our method experimentally on three groups of XML Schemas. The experiments show that the proposed method has a high degree of accuracy.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.452","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231190","XML Schema;schema matching;similarity measure","Application software;Computer science;Constraint optimization;Information retrieval;Information technology;Optimal matching;Optimization methods;Testing;Web services;XML","XML;pattern matching;tree data structures","Web services;XML schema;XML scheme matching;constraint optimization;e-business application;edge label;elements matching;node label;optimal matching;similarity measure;structural similarity value;tree matching problem","","0","","8","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Central Anti-Money Laundering control system using agents technology","G. Hemalatha; R. Mathews","Dept. of Computer Science & Engg., Karunya University, Coimbatore, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","3","The criminal individuals and organizations in today's world including terrorists have taken advantage of the available financial systems, to launder money from illegal proceeds and for their illegal activities. India is particularly under threat from terrorists and it also has been difficult to track down the finance of criminal elements. There have been some proposals in the past for anti money laundering [AML] solutions. However none of them were able to be very effective in India, as our country's vastness, and lack of AML compliance by banks was not taken to consideration. In our approach, after considering the fact that the government in India plays a significant role in regulating the economy and financial practices, we propose a system in which there is central monitoring system, controlled by an independent central agency, which in turn is connected to many regional centres throughout the country, using agents technology. Each of these regional centres will be connected to banks within their given areas. The regional centres will monitor the transactions of all the different banks in a given area and report the suspicious customers back to the central monitoring system. Then central monitoring system reports to the officials concerned and it is investigated into. This is novel agent based approach for a national framework, which is India specific, will ensure the enforcement of AML laws in our country, as every bank will be required to register themselves with a regional monitoring system.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228076","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228076","","Centralized control;Computer science;Control systems;Finance;Government;Information retrieval;Monitoring;Proposals;Terrorism;Transaction databases","bank data processing;computerised monitoring;criminal law;financial management;government data processing;software agents","AML solution;India government;agents technology;anti money laundering;bank transactions monitoring;central anti money laundering control system;central monitoring system;criminal organisation;financial system;illegal activity;independent central agency;terrorist","","0","","","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"3D model feature extraction method based on the projection of principle plane","Y. Liu; X. Zhang; Z. Li; H. Li","School Of Computer Science And Communication Engineering, China University Of Petroleum, Dongying 257062, China","2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics","20090918","2009","","","463","469","With the development of computer techniques, 3D model has been used more and more widely and content-based 3D model retrieval has been a hotspot in the area of multimedia information retrieval. How to extract 3D models' feature effectively is still a difficulty. Projection based 3D model feature extraction is an important kind in feature extraction, because of its robustness against noise, simplification and its simplicity of feature extraction. Based on the theory of principle plane, a feature extraction method based on the projection of principle plane is proposed and applied to 3D model retrieval. The experiments show that the method performs well.","","POD:978-1-4244-3699-6","10.1109/CADCG.2009.5246859","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5246859","","Biological system modeling;Content based retrieval;Distributed computing;Feature extraction;Harmonic analysis;Histograms;Information retrieval;Noise robustness;Shape;Solid modeling","content-based retrieval;feature extraction;image retrieval;multimedia systems;solid modelling","3D model feature extraction;computer technique;content-based 3D model retrieval;multimedia information retrieval;principle plane projection","","0","","21","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"On hierarchical content-based image retrieval by dynamic indexing and guided search","J. You; Q. Li","Department of Computing, The Hong Kong Polytechnic University, China","2009 8th IEEE International Conference on Cognitive Informatics","20090918","2009","","","188","195","This paper presents a new approach to content-based image retrieval by using dynamic indexing and guided search in a hierarchical structure, and extending data mining and data warehousing techniques. The proposed algorithms include: a wavelet-based scheme for multiple image feature extraction, the extension of a conventional data warehouse and an image database to an image data warehouse for dynamic image indexing, an image data schema for hierarchical image representation and dynamic image indexing, a statistically based feature selection scheme to achieve flexible similarity measures, and a feature component code to facilitate query processing and guide the search for the best matching. A series of case studies are reported, which include a wavelet-based image color hierarchy, classification of satellite images, tropical cyclone pattern recognition, and personal identification using multi-level palmprint and face features.","","POD:978-1-4244-4642-1","10.1109/COGINF.2009.5250753","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5250753","Content-based image retrieval;data mining;image classification;image data warehouse;image indexing;similarity measures;wavelet transform","Content based retrieval;Data mining;Data warehouses;Feature extraction;Image databases;Image representation;Image retrieval;Indexing;Information retrieval;Warehousing","content-based retrieval;data mining;data warehouses;feature extraction;image colour analysis;image matching;image retrieval;wavelet transforms","best matching;data mining;data warehousing;dynamic indexing;guided search;hierarchical content-based image retrieval;hierarchical structure;image database;multiple image feature extraction;query processing;wavelet-based image color hierarchy;wavelet-based scheme","","1","2","24","","","15-17 June 2009","","IEEE","IEEE Conference Publications"
"An investigation of functions and some optimizing strategies of thesauri with web interface","Li Si; Hongyan Chen","School of Information Management, Wuhan University, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","580","584","Based on investigation of the interfaces of 37 thesauri online, analyzing these thesaurus's browsing interface and browse method, thesaurus's searching interface and search method, display format of query results, language, subject fields covered and so on, according to the principles of accessibility, easiness and use-friendliness, this article puts forward some optimizing strategies about thesauri with Web interface involving creating rich and well-round homepage interface, building complete and ease-use search function, offering multi-path browsing assistant index method, improving website function, positioning rationally interface framework and developing multilingual thesauri.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234881","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234881","function;optimizing strategy;thesauri with Web interface","Art;Databases;Displays;Indexing;Information management;Information retrieval;Optimization methods;Search methods;Thesauri;Transportation","Web sites;search engines;thesauri","Web interface;display format;multilingual thesauri;multipath browsing assistant index method;query results;search method;thesauri online;thesaurus searching interface;website function;well-round homepage interface","","0","","7","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"The research of network information filtering model based on genetic algorithm","Y. Liu; Z. Zhu; Z. Lina","School of Computer Science and Technology, Shandong University, Ji'Nan 250014, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","928","932","The technology of information filtering is the hotspot in current study. This paper analyses three models of information filtering: Boolean logical model, vector space model, latent semantic indexing model, and points out their defects.In order to purify the information of the Internet, this article introduces the genetic algorithm to the network information filtering system and establishes the network information filtering model based on genetic algorithm. At last it compares the network information filtering model based on genetic algorithm with the three commonly used models. Through the result of the experiments, it is easy to see that the information filtering model based on genetic algorithm is a predominant model.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236208","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236208","","Biological system modeling;Evolution (biology);Filtering algorithms;Genetic algorithms;Indexing;Information filtering;Information filters;Information retrieval;Internet;Space technology","Boolean functions;Internet;genetic algorithms;indexing;information filtering","Boolean logical model;Internet;genetic algorithm;latent semantic indexing model;network information filtering model;vector space model","","1","","14","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Accessibility for the blind: An automated audio/tactile description of pictures in digital documents","Y. B. Issa; M. Mojahid; B. Oriola; N. Vigouroux","Institut de Recherche en Informatique de Toulouse, Universit&#233;s de Toulouse, 118 Route de Narbonne, 31062, France","2009 International Conference on Advances in Computational Tools for Engineering Applications","20090901","2009","","","591","594","In this paper we present our work in the field of accessibility to visual information in digital documents for the blind people. Our method consists in detecting the significant visual information in a picture/document, extracting their properties and rearrange them for the specified accessible output. Our approach relies on the efforts made in the field of digital documents accessibility along with image processing and content-based image retrieval. Our system provides then two possibilities of outputs: tactile/oral or a combination of the two.","","POD:978-1-4244-3833-4","10.1109/ACTEA.2009.5227855","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5227855","","Content based retrieval;Data mining;Displays;Graphics;Guidelines;Image processing;Image retrieval;Information retrieval;Speech synthesis;Web pages","content-based retrieval;handicapped aids;haptic interfaces;image retrieval","automated audio picture description;automated tactile picture description;blind people;content-based image retrieval;digital documents accessibility;image processing;visual information","","0","","13","","","15-17 July 2009","","IEEE","IEEE Conference Publications"
"Rapid access to digital library resources: Application of knowledge maps in e-Learning environment in graduate education","Y. Mu; X. y. Wang","Institute of Scientific&Technical Information, Shandong University of Technology, Zibo, China","2009 4th International Conference on Computer Science & Education","20090901","2009","","","1769","1771","How to use the information resources is a very important part of graduate education. Meanwhile digital libraries can provide instructors and students with a repository of digital resources that have been peer reviewed and checked for accuracy and authenticity. We take the knowledge maps as a tool to combine the digital resources and the e-Learning environment. Knowledge maps can integrate the related digital resources, which will make the way of looking for the resources and the relationship of knowledge turn to the form of map so that the learners can better understand it. In this process we use the RDF, ontology language, XML etc. standards and technology and digital library can provide API to the knowledge maps. The application of knowledge maps can construct the macrostructure of knowledge and help the graduates form their knowledge system and obtain knowledge. With the help of the knowledge maps, the graduates' innovation ability will be trained well.","","POD:978-1-4244-3520-3","10.1109/ICCSE.2009.5228277","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228277","digital library;e-Learning;knowledge maps","Books;Computer science education;Databases;Educational technology;Electronic learning;Information resources;Information retrieval;Internet;Software libraries;Technological innovation","XML;application program interfaces;computer aided instruction;digital libraries;further education;information resources;knowledge representation languages","API;RDF;XML;digital library resource;e-Learning environment;graduate education;information resources;innovation ability;knowledge map;ontology language","","0","","8","","","25-28 July 2009","","IEEE","IEEE Conference Publications"
"Data-Sharing P2P Networks with Semantic Approximation Capabilities","F. Mandreoli; R. Martoglia; W. Penzo; S. Sassatelli","University of Modena and Reggio Emilia","IEEE Internet Computing","20090909","2009","13","5","60","70","The synergy between peer-to-peer systems and semantic Web technologies supports large-scale sharing of semantically rich data, usually represented through schemas such as RDF. Peers rarely share the same vocabulary, so the resulting heterogeneity of data representations introduces new challenges for the efficient and effective retrieval of relevant information. The authors leverage the presence of semantic approximations between peers' schemas to improve query routing by identifying the peers that best satisfy the user's requests, and to inform users of the relevance of the returned answers through a ranking mechanism that promotes the most semantically related results.","1089-7801;10897801","","10.1109/MIC.2009.105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5233612","P2P data sharing;fuzzy models;query processing;semantics","Information retrieval;Large-scale systems;Peer to peer computing;Query processing;Resource description framework;Semantic Web;Vocabulary","approximation theory;peer-to-peer computing;semantic Web","P2P network;data-sharing;large-scale sharing;peer-to-peer system;query routing;ranking mechanism;semantic Web technology;semantic approximation","","7","","6","","","Sept.-Oct. 2009","","IEEE","IEEE Journals & Magazines"
"Research on the Technology of Game Data Caching","S. Wu","Sch. of Comput. Sci. & Eng., WuHan Inst. of Technol., Wuhan, China","2009 Pacific-Asia Conference on Circuits, Communications and Systems","20090904","2009","","","651","653","In massive multiplayer online role playing game, in order to make the virtual world simulate the real world, the server should associate all the events of the virtual roles in the game. The technology of game data caching has been researched. Through the technology the game goods and game events in each client end can be searched rapidly and the massive game goods data in server end can be also retrieved quickly.","","POD:978-0-7695-3614-9","10.1109/PACCS.2009.127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231966","data caching;exclusive retrieve;game;load balancing","Auditory system;Circuit simulation;Computational modeling;Computer science;Computer simulation;Data engineering;Discrete event simulation;Filters;Information retrieval;Load management","computer games;data handling","game data caching;massive multiplayer online role playing game;virtual world","","0","","3","","","16-17 May 2009","","IEEE","IEEE Conference Publications"
"Function design for search engine on “Personal Search History” —based on the theory of knowledge architecture","J. Dai; W. Zhang","School of information management, Wuhan University, 430072, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","355","359","Although personal search history is the important information for search engine users, it is not stored and used well. This paper starts with the experience of general users to find and analyze problems, further investigates users subdivision, selects teachers in universities as the representatives of knowledge workers to analyze their demands. Base on the theory of cognition viewpoint, knowledge architecture and man-machine interface, we present function design recommendation of ldquopersonal search historyrdquo by complete storage process of effective search event, management of retrieval expression, annotation and visualization, which can also can support of personal knowledge architecture.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236400","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236400","","Cognition;Context modeling;Displays;History;Information management;Information retrieval;Knowledge management;Search engines;User interfaces;Web pages","educational computing;educational institutions;information retrieval;search engines","cognition viewpoint theory;function design;knowledge architecture theory;man-machine interface;personal search history;retrieval expression management;search engine","","0","","18","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"From Social Networks to Behavioral Networks in Recommender Systems","I. Esslimani; A. Brun; A. Boyer","LORIA, Univ. Nancy 2, Villers-Les-Nancy, France","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","143","148","Recommender systems are widely used for personalization of information on the web and information retrieval systems. Collaborative Filtering (CF) is the most popular recommendation technique. However, classical CF systems use only direct links and common features to model relationships between users. This paper presents a new Collaborative Filtering approach (BNCF) based on a behavioral network that uses navigational patterns to model relationships between users and exploits social networks techniques, such as transitivity, to explore additional links throughout the behavioral network. The final aim consists in involving these new links in prediction generation, to improve recommendations quality. BNCF is evaluated in terms of accuracy on a real usage dataset. The experimentation shows the benefit of exploiting new links to compute predictions. Indeed, BNCF highly improves the accuracy of predictions, especially in terms of HMAE.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231911","behavioral networks;collaborative filtering;recommender systems;social networks;transitivity","Accuracy;Collaboration;Filtering;Information analysis;Information resources;Information retrieval;Navigation;Recommender systems;Social network services;Voting","Internet;groupware;information filtering;information filters;social networking (online)","behavioral networks;collaborative filtering;dataset;information retrieval systems;navigational patterns;prediction generation;recommender systems;social networks","","5","","25","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"Binary Comparative Search for SLCA problem","S. y. Zang; X. g. Hong; L. Liu","School of Computer Science and Technology, Shandong University, 250100, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","1214","1217","Nowadays, searching information exactly from XML data has become more and more important. SLCA (smallest lowest common ancestors ) is a method of getting information from XML data. The method is that we are requested to find all the nodes corresponding to the tightest subtrees in XML data, which involves the given keywords. It's a convenient method to retrieve data from XML documents for searcher,especially who is not familiar with XML knowledge. There have been many proposed algorithms solving SLCA problem through transforming XML documents into XML trees labeled with Dewey codes, such as LISA and LISA II.This paper proposes a new solution, binary comparative search (BCS), targeted to XML data retrieval. Compared with LISA II, which has been proven to be better than ILE and SE. The new method dose more efficiently. In the end, LISA II and BCS are tested analytically and experimentally on data generated by XMark.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236283","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236283","","Bibliographies;Computer science;Frequency;Information retrieval;Keyword search;Standards development;Testing;Web services;XML","XML;information retrieval;search problems;tree data structures","BCS;Dewey code;LISA II;SLCA problem;XML data retrieval;XML tree;binary comparative search;information searching;smallest lowest common ancestor;tightest subtree","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Multi agent based approach for analyzing spatial image data","J. M. Chandra; M. Siddhartha","Dept of Information Technology Gayatri Vidya Parishad College of Engineering Visakhapatnam , India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","4","Scientists and intelligence analysts are interested in quickly discovering new results from the vast amount of available geospatial data. The key issues that arise in this pursuit are how to cope with new and changing information and how to manage the steadily increasing amount of available data. This paper describes a novel agent architecture that has been developed and tested to address these issues by combining innovative approaches from three distinct research areas: software agents, geo referenced data modeling, and content-based image retrieval (CBIR). The overall system architecture is based on a multi-agent paradigm where agents autonomously search for images over the Internet, then convert the images to a vector used for use in searching and retrieval. Results show that this system is capable of significantly reducing the time and management effort associated with large amounts of image data.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228030","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228030","agent;spatial image data","Computer architecture;Content based retrieval;Data analysis;Image analysis;Image retrieval;Information retrieval;Intelligent agent;Internet;Software agents;Software testing","content-based retrieval;image retrieval;multi-agent systems;software agents;visual databases","Internet;content-based image retrieval;geo referenced data modeling;geospatial data;multiagent based approach;software agent;spatial image data","","0","","12","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Natural language interaction-based document retrieval","Dang Tuan Nguyen; Tuyen Thi-Thanh Do; Quoc Tan Phan","Department of Computer Science, University of Information Technology Ho Chi Minh, Vietnam","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","544","548","Our research aims at building a specific document retrieval system using for searching eBooks in e-libraries. This model has some characteristics: processing queries in English, interacting with users and the users can correct the queries which the system does not understand. We also develop a semantic representation model for simple English queries. From semantic representation of queries, the system can automatically generate database queries to search the relevant information. The initial results may only be a relatively good, but we realize that the system model has great promise. Our system model can be improved to raise its effect. Besides, it can be applied to the similar applications.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234481","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234481","Document Retrieval;Natural Language Processing;Question Answering","Books;Computer science;Databases;Information retrieval;Information technology;Libraries;Natural language processing;Natural languages;Query processing;Software engineering","digital libraries;natural language interfaces;natural language processing;query processing","English query processing;database query;e-book search;electronic library;natural language interaction-based document retrieval;semantic representation","","4","","14","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Computing regularities in strings","W. F. Smyth; M. Yusufu","Department of Computing and Software, McMaster University, Hamilton, Ontario, Canada","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","298","302","Regularities in strings model many phenomena and thus form the subject of extensive mathematical studies . Perhaps the most conspicuous regularities in strings are those that manifest themselves in the form of repeated subpatterns. In this paper, we study several forms of regularities of strings, that is, repeats, multirepeats, repetitions and runs. We present their similarities and differences by discussing their forms and properties and we explore the existing computation algorithms. We also discuss several data structures useful for computing regularities.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234544","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234544","","Application software;Cloning;Data structures;Ecosystems;Information retrieval;Mathematical model;Pattern recognition;Software engineering;Software maintenance;Software systems","data structures;string matching","computing regularities;data structures;multirepeats;repeats;repetitions;runs;strings model","","0","","41","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Knowledge sciences in services automation: Integration models and perspectives for service centers","R. Akella; Z. Xu; J. Barajas; K. Caballero","Department of Technology and Information Management, University of California at Santa Cruz, 1156 High St., 95064, USA","2009 IEEE International Conference on Automation Science and Engineering","20090909","2009","","","71","78","We provide an automation perspective on modeling knowledge services. We consider a service center as the atomic unit for building networks of enterprises, suppliers, and customers. We provide an approach to integrate knowledge and resource management in service centers. We describe specific models and solutions for optimized information and knowledge retrieval, relevance feedback and active learning and associated performance results. We also outline an approach for incorporating topic detection, context, social networks and collaboration, and combined document and expert ranking/identification. We also sketch an approach for combining knowledge retrieval with system resource optimization of the service engineers and experts to provide optimized responsiveness.","2161-8070;21618070","POD:978-1-4244-4578-3","10.1109/COASE.2009.5234085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234085","","Assembly;Context modeling;Decision making;Delay;Feedback;Humans;Information retrieval;Knowledge engineering;Knowledge management;Manufacturing automation","information services;knowledge management;relevance feedback;service industries","active learning;customer service;enterprise building network;expert ranking;knowledge retrieval;knowledge science;relevance feedback;resource management;service automation;service center;social network;supplier network;topic detection","","1","","37","","","22-25 Aug. 2009","","IEEE","IEEE Conference Publications"
"The design and implementation of online scoring system","P. Guo; H. y. Zhang; Y. w. Deng","School of Computer Science, Chongqing University, 400044, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","606","610","Online scoring system is one of important components in the examination system. The development of modern education technology has not only promoted the changes of examination pattern, but also the scoring pattern. This paper discusses the functions that the scoring system should have and provides the way how to design and implement the system. The system can adapt to scoring the online papers which is provided by the online examination system. And the traditional papers can use the system to score online, too. Moreover, the system can treat no matter the standard sheet or the non-standard sheet. Practical application shows that the system is satisfied with the requirement of network scoring papers well.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236350","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236350","","Computer science;Computer science education;Educational technology;IP networks;Information management;Information retrieval;Local area networks;Scheduling;Statistical analysis;System testing","educational technology;information retrieval","examination system;information retrieval;knowledge test;modern education technology;network scoring;online scoring system","","1","","9","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"RainWatch Project: Location-Awared Realtime Detection and Notification of Rain on Internet-Based Sensor Network","K. Sathita; H. Ochiai; H. Esaki","Univ. of Tokyo, Tokyo, Japan","2009 Ninth Annual International Symposium on Applications and the Internet","20090904","2009","","","259","262","This paper introduces RainWatch project which enable rain-sensitive users to monitor real time rain information in area of userspsila interest. Real-time detection and notification of rain situation will allow users to take appropriate preparation (e.g., evacuation from the area in case of disaster prevention), which can prevent loss of lives and damage on our properties. The RainWatch system stands on top of Live E! data platform, which is a wide-area sensor application testbed operated by multiple-organizations distributedly with about 100 Internet weather stations. The RainWatch system monitors the rain state around a certain geographical point and makes notifications or warnings (e.g., the rain is approaching) in real-time to the users that have interest in the point. Strong needs for this application will influence the design of the sensor networking infrastructure regard to location-awareness and real-time-ness.","","POD:978-1-4244-4776-3","10.1109/SAINT.2009.59","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230781","Internet-Based Sensor Network","Floods;IP networks;Information retrieval;Internet;Marketing and sales;Monitoring;Rain;Testing;Weather forecasting;Wind speed","Internet;geophysical techniques;geophysics computing;rain;real-time systems;weather forecasting;wide area networks;wireless sensor networks","Internet weather stations;Internet-based sensor network;RainWatch project;RainWatch system;location-awared realtime detection;location-awareness;real time rain information;sensor networking infrastructure;wide-area sensor application testbed","","1","","5","","","20-24 July 2009","","IEEE","IEEE Conference Publications"
"Mobile agent intercommunicating model based on message proxy","Z. w. Wang; W. d. Wang","Network Information Center, Shandong Jianzhu University, JiNan, 250101, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","826","831","Mobile agent is a new computing model that is more suitable for current distributed computing environment. In a mobile agent system, an agent needs to exchange some information with other agents continuously. During this process two problems have to be solved. The first is the agent location tracking, which is how to inform the current location of an agent to other agents. The second is the message storage and transfer, which is how to handle the information that is sent to an agent. To solve the two problems, a message communication mechanism between mobile agents based on message proxy is proposed, which combines with mobile agent location tracking mechanism and realizes the location transparent agent communication in a mobile agent system.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236307","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236307","","Broadcasting;Communication system control;Computer industry;Computer networks;Concurrent computing;Distributed computing;Information retrieval;Mobile agents;Mobile communication;Waste materials","message passing;mobile agents","distributed computing;location transparent agent communication;message communication mechanism;message proxy;message storage;message transfer;mobile agent intercommunicating model;mobile agent location tracking mechanism","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Novel Generalized SVM Algorithm with Application to Region-Based Image Retrieval","Z. Rui-zhe; Y. Jia-zheng; H. Jing-hua; W. Yu-jian; B. Hong","Inst. of Inf. Technol., Beijing Union Univ., Beijing, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","280","283","Support vector machines (SVM) has been widely applied in the area of content-based image retrieval in order to learn high-level concepts from low-level image features. Most existing SVM based image retrieval algorithms only rely on global-based features to represent the image content, which obviously can not well reflect the image semantic content. Region-based representations are far more close to the image content. However, such representations are of variable length and the Gaussian kernel is inappropriate in this situation. In this paper, a novel generalized SVM algorithm is proposed, which takes into account both low-level features and structural information of the image, in order to solve the problem of region-based image retrieval via SVM framework. Firstly, for a given image, salient regions are extracted and the concept of salient region adjacency graph is proposed to represent the image semantics. Secondly, based on the SRAG, a novel generalized structure kernel based SVM algorithm is constructed for content-based image retrieval. Experiments show that the proposed method shows better performance in image semantic retrieval than traditional method.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.489","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231199","SRAG;generalized SVM;region-based image retrieval;visual attention model","Content based retrieval;Data mining;Feedback;Image retrieval;Information retrieval;Information technology;Kernel;Pattern recognition;Support vector machine classification;Support vector machines","Gaussian processes;content-based retrieval;feature extraction;graph theory;image representation;image retrieval;support vector machines","Gaussian kernel;content-based image retrieval;generalized structure kernel;image semantic content;region-based image retrieval;region-based representations;salient region adjacency graph;salient region extraction;support vector machines","","3","","8","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Image Clustering Using Color and Texture","M. Maheshwari; S. Silakari; M. Motwani","Dept. of Comput. Sci. & Applic., Makhanlal C. Nat. Univ. of Journalism & Commun., Bhopal, India","2009 First International Conference on Computational Intelligence, Communication Systems and Networks","20090904","2009","","","403","408","With the advancement in image capturing device, the image data been generated at high volume. Grouping images into meaningful categories to reveal useful information is a challenging and important problem. Content based image retrieval address the problem of retrieving images relevant to the user needs from image databases on the basis of low-level visual features that can be derived from the images. Due to semantic gap between low-level image features and the richness of human semantics, a challenge with image contents is to extract meaning from the data they contain. Image mining deals with the extraction of implicit knowledge, image data relationship, or other patterns not explicitly stored in the images. Proposed framework focuses on color and texture as feature. Color moment and Gabor filter is used to extract features for image dataset. K-means and hierarchical clustering algorithm is applied to group the image dataset into various clusters.","","POD:978-0-7695-3743-6","10.1109/CICSYN.2009.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231889","Clustering;Color;Hierarchical;K-Means;Texture","Clustering algorithms;Content based retrieval;Data mining;Feature extraction;Gabor filters;Humans;Image databases;Image generation;Image retrieval;Information retrieval","Gabor filters;content-based retrieval;data mining;image colour analysis;image retrieval;image texture;pattern clustering","Gabor filter;K-means clustering algorithm;color moment;content based image retrieval;feature extraction;hierarchical clustering algorithm;image clustering;image data relationship;image databases;image grouping;image mining;implicit knowledge extraction;texture","","4","","18","","","23-25 July 2009","","IEEE","IEEE Conference Publications"
"Harnessing Wisdom of the Crowds Dynamics for Time-Dependent Reputation and Ranking","E. M. Daly","IBM Software Group, Dublin Software Lab., Dublin, Ireland","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","267","272","The ldquowisdom of the crowdsrdquo is a concept used to describe the utility of harnessing group behaviour, where user opinion evolves over time and the opinion of the masses collectively demonstrates wisdom. Web 2.0 is a new medium where users are not just consumers, but are also contributors. By contributing content to the system, users become part of the network and relationships between users and content can be derived. Example applications are collaborative bookmarking networks such as delicious and file sharing applications such as YouTube and Flickr. These networks rely on user contributed content, described and classified using tags. The wealth of user generated content can be hard to navigate and search due to difficulties in comparing documents with similar tags and the application of traditional information retrieval scoring techniques are limited. Evaluating the time evolving interests of users may be used to derive quality of content. In this paper, we propose a technique to rank documents based on reputation. The reputation is a combination of the number of bookmarkers, the reputation of the bookmarking user and the time dynamics of the document. Experimental results and analysis are presented on a large collaborative IBM bookmarking network called Dogear.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.69","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231866","Ranking;Reputation;Social Search;Social bookmarking","Collaboration;Information retrieval;Navigation;Peer to peer computing;Search engines;Social network services;Tagging;User-generated content;Web pages;YouTube","Internet;behavioural sciences computing;document handling;information retrieval;social networking (online)","Dogear;Web 2.0;bookmarking user;document ranking;group behaviour;information retrieval;large collaborative IBM bookmarking network;time-dependent reputation;user generated content;user opinion;wisdom-of-the crowds dynamics","","1","","13","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"Streaming audio retrieval based on fuzzy classification in MPEG-1 compressed domain","Miao Li; Jiqing Han","School of Computer Science and Technology, Harbin Institute of Technology, 150001, China","2009 International Conference on Mechatronics and Automation","20090918","2009","","","5035","5039","In this paper, a novel audio retrieval method based on fuzzy classification in MPEG-1 (Moving Pictures Experts Group 1) compressed domain is proposed to search information in steaming media on Internet. In order to avoid the huge decoding time cost, scalefactors are directly extracted from MPEG-1 audio frame as features. At the same time, a distance-based fuzzy classification method is put forward to solve the serious misclassification using traditional audio classification. Experimental results show that the recall rate and the precision of the proposed method are higher than the traditional audio retrieval method. And the computational time is dramatically reduced.","2152-7431;21527431","POD:978-1-4244-2692-8","10.1109/ICMA.2009.5246104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5246104","MPEG-1 audio;fast audio retrieval;fuzzy classification;scalefactor;streaming media","Costs;Data mining;Decoding;Feature extraction;Filter bank;Image retrieval;Information retrieval;MPEG standards;Streaming media;Transform coding","audio coding;audio streaming;fuzzy set theory","Internet;MPEG-1 Compressed Domain;Moving Pictures Experts Group 1;audio classification;distance-based fuzzy classification;scalefactor;streaming audio retrieval","","0","","11","","","9-12 Aug. 2009","","IEEE","IEEE Conference Publications"
"Retrieving design patterns by case-based reasoning and Formal Concept Analysis","W. Muangon; S. Intakosum","Software Systems Engineering Laboratory, Department of Mathematics and Computer Science, Faculty of Science, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","424","428","Design patterns are applied to solve the recurring software design problems. Unfortunately, choosing appropriate design patterns for the specific design problem is considered a difficult task. A search tool is, therefore, needed to supports selection. However, the existing design pattern searching methodologies generally have problems on keyword-search problem. In this paper, we proposed an initial model to solve the problem by using Case-Based Reasoning (CBR) and Formal Concept Analysis (FCA). For the proposed model, a case base is created to represent design patterns. FCA is used to be case organization that analyze case base for obtain knowledge embedded. The knowledge can suggest suitable indexes to use for new problem. This method is beneficial for learning index. This paper discusses the basis theoretical of representation and retrieval design patterns for this inprogress research, along with some preliminary result.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234534","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234534","Case Based Reasoning;Design pattern;Design pattern retrieval;Formal Concept Analysis;Knowledge representation","Computer science;Design engineering;Information retrieval;Laboratories;Mathematics;Pattern analysis;Problem-solving;Software design;Software systems;Systems engineering and theory","case-based reasoning;indexing;information retrieval;knowledge representation;learning (artificial intelligence);object-oriented programming","Knowledge representation;case-based reasoning;formal concept analysis;keyword-search problem;learning index;pattern search methodology;software design pattern","","4","","17","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"A Scalable Content-based Image Retrieval Scheme Using Locality-sensitive Hashing","W. Weihong; W. Song","Coll. of Software, Zhejiang Univ. of Technol., Hangzhou, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","1","","151","154","To develop a fast solution for indexing high-dimensional image contents, which is crucial to building large-scale CBIR systems, is one key challenge in content-based image retrieval (CBIR). In this paper, we propose a scalable content-based image retrieval scheme using locality-sensitive hashing (LSH), and conduct extensive evaluations on a large image test-bed of a half million images. To the best of our knowledge, there is less comprehensive study on large-scale CBIR evaluation with a half million images. Our empirical results show that our proposed solution is able to scale for hundreds of thousands of images, which is promising for building Web-scale CBIR systems.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.124","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231247","CBIR;Empirical;LSH;Large-scale","Application software;Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;Large-scale systems;Multimedia databases;Spatial databases;Testing","content-based retrieval;file organisation;image retrieval;indexing","content-based image retrieval;high-dimensional image content indexing;large-scale CBIR system;locality-sensitive hashing","","2","","14","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Application of ontology guided search for improved equipment diagnosis in a vehicle assembly plant","R. Chougule; S. Chakrabarty","India Science Lab, General Motors R&D, Bangalore, India","2009 IEEE International Conference on Automation Science and Engineering","20090909","2009","","","90","95","In the body shop of an automobile assembly plant, having access to correct and timely diagnostic information is very important for solving equipment and tooling maintenance problems. Variation Reduction Adviser (VRA) is an internal General Motors (GM) system that contains information related to the problems encountered in process, their root cause and possible solutions. This paper presents our work on ontology based diagnosis, where, a thesaurus (which is a simple form of ontology) has been used for retrieving diagnostic information. A thesaurus has been developed from existing problem descriptions and their solutions written in a natural language (such as English). A systematic methodology has been developed for the creation of a thesaurus. The results of ontology based diagnostic information retrieval have been compared with dasiaexact matchpsila information retrieval.","2161-8070;21618070","POD:978-1-4244-4578-3","10.1109/COASE.2009.5234132","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234132","","Assembly systems;Automation;Information retrieval;Knowledge management;Natural languages;Ontologies;Research and development;Thesauri;Vehicles;Welding","automobile manufacture;information retrieval;maintenance engineering;ontologies (artificial intelligence);production engineering computing;production equipment;thesauri","General Motors;diagnostic information;equipment diagnosis;equipment maintenance problems;information retrieval;ontology based diagnosis;thesaurus;tooling maintenance problems;vehicle assembly plant","","1","","9","","","22-25 Aug. 2009","","IEEE","IEEE Conference Publications"
"Virtual Reality in the Digital Olympic Museum","Z. Pan; W. Chen; M. Zhang; J. Liu; G. Wu","Zhejiang University","IEEE Computer Graphics and Applications","20090901","2009","29","5","91","95","This paper presents virtual reality in digital Olympic museum using animation and supporting cross-media information retrieval. The visitors use an avatar to navigate the DOM. DOM is a large-scale distributed 3D virtual environment for demonstrating the Olympics' history, culture and highlights.","0272-1716;02721716","","10.1109/MCG.2009.103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230471","Olympics;digital museum;sports simulation;virtual environment;virtual reality","Animation;Avatars;History;Information retrieval;Large-scale systems;Navigation;Virtual environment;Virtual reality","avatars;computer animation;exhibitions;human computer interaction;humanities;information retrieval;sport","Olympics culture;Olympics history;cross-media information retrieval;digital Olympic museum;distributed 3D virtual environment;virtual reality","","8","","3","","","Sept.-Oct. 2009","","IEEE","IEEE Journals & Magazines"
"A generic architecture for agent based E-learning system","K. Sakthiyavathi; K. Palanivel","Department of Computer Science, Pondicherry University, Puducherry, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","5","E-learning refers to the way by which the learning content is provided by means of electronic technology. E-learning system is classified as either synchronous or asynchronous. It is the effective learning process so that the Web-based learning system has become a promising paradigm in education. Agent based E-learning can manage the information overload, serve as academic experts, and create programming environments for the learners. There are several characteristics specific to E-learning system such as Interaction, Personalization, Adaptation, Intelligence, Interoperability, Accessibility and Security. Agent based architecture for E-learning system provides the above mentioned features to support instructional design, to retrieve relevant learning materials, to process and analyze data to enable meaningful E-learning recommendations to instructors and learners. But most of the existing E-learning architectures doesn't consider all the features in a single system. So there is a need for a generic architecture that should support all the features to make the E-learning system more efficient. In this paper, we provide a generic architecture for E-learning system. This architecture considers interactivity, personalization, adaptation, interoperability, collaboration, security to enhance the quality of learning process.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228089","Agent based learning;E-learning;Generic Architecture;Intelligent Tutoring System;Software Agents","Data analysis;Data security;Educational programs;Electronic learning;Environmental management;Information management;Information retrieval;Information security;Learning systems;Programming environments","computer aided instruction;software agents;software architecture","E-learning recommendations;Web-based learning system;agent based e-learning system;electronic technology;generic architecture;information overload;instructional design;learning content;learning materials;software collaboration;software interoperability;software personalization;software quality;software security","","6","","21","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"The Understanding between Two Agent Crawlers based on Domain Ontology","Y. Wang; Y. Du; S. Chen","Sch. of Math. & Comput. Eng., Xihua Univ., Chengdu, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","1","","47","50","Ontology is widely used in the computer domain to structure concepts that represent a view of world. In this paper, we present the coordination between two Agent Crawlers based on ontology and try to measure the understanding between them relying on Formal Concept Analysis instead of comparing terms only. Here we propose a novel method on concept similarity for computing the Concept-Concept similarity, the Concept-Ontology similarity and the Ontology-Ontology similarity, and at last we can deduce the understanding between two Agent Crawlers. Finally, we can guide the crawlers effectively in our Search Engine.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.204","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231592","Agent Crawlers;Concept similarity;Formal Concept Analysis;Ontology;the degree of understanding","Computational intelligence;Crawlers;Information analysis;Information retrieval;Information systems;Mathematics;Ontologies;Processor scheduling;Relational databases;Search engines","multi-agent systems;ontologies (artificial intelligence);search engines","agent crawlers;concept-concept similarity;concept-ontology similarity;domain ontology;formal concept analysis;ontology-ontology similarity;search engine","","0","","20","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Common design structure discovery from CAD models","L. Ma; Z. Huang; Y. Wang","CAD Center, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, Hubei 430074, China","2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics","20090918","2009","","","363","366","This paper presents a method to solve the problem of common design structure discovery from a large number of CAD models. First, a CAD model is transformed into a face adjacency graph (FAG) and each node of FAG is mapped to a point in two-dimensional plane after representing face shape information with two coordinates. So the shapes of models are directly compared through the point coordinates of FAGs' nodes. Thus, the common design structures are just the frequent appearing subgraphs of FAGs. Second, we develop an algorithm to discovery frequent subgraphs of FAGs. The main steps of the algorithm include: (1) frequent candidate subgraph generation based on merging of last discovered frequent subgraphs; (2)subgraph matching with graph descriptive code. The experiment shows a reasonable result of the discovered common design structures with our approach.","","POD:978-1-4244-3699-6","10.1109/CADCG.2009.5246877","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5246877","","Data compression;Design automation;Design engineering;Frequency;Information analysis;Information retrieval;Libraries;Mathematical model;Merging;Shape","CAD;computational geometry;data mining;engineering graphics;graph theory;merging;pattern matching;solid modelling;structural engineering computing","3D CAD model;CDSD;FAG;common design structure discovery;computer-aided design;engineering structure;face adjacency graph;frequent candidate subgraph generation;frequent subgraph discovery algorithm;frequent subgraph merging;graph descriptive code;knowledge discovery;mechanical design;subgraph matching;two-dimensional plane","","0","","9","","","19-21 Aug. 2009","","IEEE","IEEE Conference Publications"
"The Method of Query Expansion Based on Domain Ontology","B. Zhang; Y. Du; H. Li; L. Jia","Sch. of Math. & Comput. Sci., Xihua Univ., Chengdu, China","2009 Pacific-Asia Conference on Circuits, Communications and Systems","20090904","2009","","","755","758","An ontology is an explicit specification of a conceptualization. In this paper, A domain ontology is build based on Google page directory, used the relation among the concepts. We search the domains which the match concepts of the query terms belong to or include in the domain ontology. And we build a new domain ontology based on these domains and the match concepts. Two concepts of domain subordinate degree and domain inclusion degree are proposed. They are used to describe the degree of a domain belong to another domain and the degree of a domain includes another domain, respectively. And the domains which the domain belongs to or the domain includes can be confirmed by computing these two concepts. These domains are the results of the domain expansion or the domain reduction. In this method, the domain expansion and the domain reduction of the domain are completed. At the present time, the rdquorelation searchrdquo function of the search engineers (SE) can not precisely satisfy the userspsila need. In this paper, we propound a new method to realize the function of rdquorelation searchrdquo. We expand the user query terms using the results of the domain expansion and the domain reduction. This method can improve the precise of query expansion results by enhance the thematic of the user query terms.","","POD:978-0-7695-3614-9","10.1109/PACCS.2009.201","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232435","","Circuits;Computer science;Control systems;Information retrieval;Intelligent control;Knowledge engineering;Machinery;Ontologies;Petroleum;Terminology","ontologies (artificial intelligence);query formulation;query processing;search engines","Google page directory;domain inclusion degree;domain ontology;domain subordinate degree;query expansion;search engineers","","0","","8","","","16-17 May 2009","","IEEE","IEEE Conference Publications"
"The Specific Designation and Technology of Online Information Literacy Platform","S. Linlin; L. Haitao","Sch. of Inf. Manage., Wuhan Univ., Wuhan, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","169","173","This paper first designs the entire framework of OILP, and then it constructs some specific modules of OILP, such as searching module, online testing modules and teaching pack. It also introduces the user-level, the resource database and the technologies for realization. At last, it concludes that OILP is the perfective choice for information literacy education in academic libraries.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.400","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231237","Information literacy education;e-learning;information technology","Databases;Education;Floors;Information management;Information resources;Information retrieval;Information technology;Libraries;Modular construction;Testing","Internet;academic libraries;information science education;teaching","academic library;information literacy education;online information literacy platform;online testing;resource database;searching;teaching","","0","","3","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Intent based clustering of search engine query log","A. Veilumuthu; P. Ramachandran","Department of Management Studies, Indian Institute of Science, Bangalore 560012 INDIA","2009 IEEE International Conference on Automation Science and Engineering","20090909","2009","","","647","652","The keyword based search technique suffers from the problem of synonymic and polysemic queries. Current approaches address only the problem of synonymic queries in which different queries might have the same information requirement. But the problem of polysemic queries, i.e., same query having different intentions, still remains unaddressed. In this paper, we propose the notion of intent clusters, the members of which will have the same intention. We develop a clustering algorithm that uses the user session information in query logs in addition to query URL entries to identify cluster of queries having the same intention. The proposed approach has been studied through case examples from the actual log data from AOL, and the clustering algorithm is shown to be successful in discerning the user intentions.","2161-8070;21618070","POD:978-1-4244-4578-3","10.1109/COASE.2009.5234156","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234156","Clickthrough data;Query Clustering;Query intent","Automation;Clustering algorithms;Couplings;Feedback;Humans;Information retrieval;Manuals;Quality management;Search engines;Uniform resource locators","pattern clustering;query processing;search engines","clustering algorithm;intent based clustering;keyword based search;polysemic queries;search engine query log;synonymic queries;user session information","","2","2","18","","","22-25 Aug. 2009","","IEEE","IEEE Conference Publications"
"Towards natural language interface framework for automated medical analysis","Y. Sebastian; B. C. S. Loh; P. H. H. Then","School of Computing and Design, Swinburne University of Technology, Sarawak Campus, Kuching, Malaysia","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","5","9","Constructing a practical medical data analysis system for real-life scenario remains challenging. While the development of various medical data analysis algorithms is rapidly advancing, it has not been matched by the development of a feasible, practical application framework for their implementation. In this paper, we introduce a medical data analysis framework based on natural language QA interface to structured medical data sources. We demonstrate that the complexities of performing medical data analyses can be simplified into question answering framework. Utilizing standard medical vocabularies, two hypothetical clinical questions are interpreted and the required analytics are automatically performed to produce textual and non-textual data for clinicians.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234782","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234782","Restricted-domain question answering system;UMLS concept mapping;automated medical data analysis;natural language interface to database","Availability;Cardiology;Data analysis;Databases;Head;Information retrieval;Natural languages;Performance analysis;Unified modeling language;Vocabulary","data analysis;data structures;database management systems;medical administrative data processing;natural languages","automated medical analysis;medical data analysis system;medical data source structure;natural language interface;standard medical vocabularies","","0","","9","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Approaches to Decision Inference Rules Based on Concept Lattices","G. F. Qiu","Sch. of Manage., Xi'an Univ. of Archit. & Technol., Xi'an, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","2","","52","55","Four kinds of basic decision rule sets are respectively produced from the formal concept lattice, the dual formal concept lattice, the object-oriented concept lattice and the attribute-oriented concept lattice in a formal context. Based on these sets, two types of decision inferences are established via an inclusion degree. The corresponding decisions by inferences are proved to be the lower and the upper approximated decisions. Thus total decision rules described as the lower and the upper approximated decision rules are obtained. And they are accordant and consistent with the basic decision rule sets.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.181","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231053","concept lattice;decision rule;inclusion degree;inference","Computational intelligence;Computer architecture;Conference management;Data analysis;Electronic mail;Home computing;Information retrieval;Lattices;Machine learning;Technology management","decision theory;inference mechanisms;object-oriented methods","attribute-oriented concept lattice;decision inference rules;dual formal concept lattice;inclusion degree;object-oriented concept lattice","","0","","8","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"An Optimized Image Retrieval Method Based on Hierarchal Clustering and Genetic Algorithm","H. Min; S. Bo; X. Jianqing","Sch. of Software Eng., South China Univ. of Technol. (SCUT), Guangzhou, China","2009 International Forum on Information Technology and Applications","20090904","2009","1","","747","749","Image search on Web is very familiar to various users, and improving the efficiency and accuracy of image search has become more and more a hotpot in this research field. For different commercial image engines use different retrieval techniques respectively, the coverage area and accuracy of each individual search engine await development. An improved method based on multi-optimization techniques of image retrieval is presented in the paper. On the base of relevance feed-back principle, the method does some work of the vectorization and weights adjusting to the images generated by commercial image engines, and then adopts hierarchal clustering and genetic algorithm techniques to optimize the results further. Finally, by developing a prototype of image retrieval engine based on the method presented and doing some tests, the advancing in accuracy of image retrievals of the method has been proved.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.429","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231764","Genetic Algorithm;Hierarchal clustering;Image retrieval;Multi-Optimization;Relevance feed-back;Search engine","Application software;Gaussian processes;Genetic algorithms;Image databases;Image generation;Image retrieval;Information retrieval;Information technology;Optimization methods;Search engines","Internet;genetic algorithms;image retrieval;search engines","Web;commercial image engines;genetic algorithm;hierarchal clustering;image search;multioptimization techniques;optimized image retrieval method;relevance feedback principle","","1","","8","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"On the Influence of Region Mismatch at Training and Testing in Region-Related Concept Detection","Z. Gao; Z. Zhao; T. Liu; X. Nan; A. Cai","Sch. of Inf. & Commun. Eng., BUPT, Beijing, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","1","","42","46","A great deal of region-related concept detection algorithms have been proposed so far, but there are few of them concerning about the problem of mismatched regions at training and testing stages. In order to investigate the mismatch problem in region-related concept detection, we introduce three kinds of methods to annotate the datasets, and then conduct experiments on differently annotated training and testing datasets. We find from these experiments that the detection performance is the best when the regions of a region-related concept are well defined and matched during training and testing, or the detection performance will be decreased. Based on these observations, we propose a fusion scheme to combine the results of classifiers trained with datasets which are annotated by different methods. Experiments on Trecvid-2007 test corpus show that the proposed fusion scheme can obtain performance improvement up to 6~12%.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231605","Annotation;Concept;Detection;Fusion;Region-mismatch;SVM;Trecvid","Computational intelligence;Concrete;Detection algorithms;Feature extraction;Information retrieval;Support vector machine classification;Support vector machines;Telephony;Testing;Video sequences","feature extraction;image matching;sensor fusion","Trecvid-2007 test corpus;annotated training;fusion scheme;region mismatch;region-related concept detection;testing datasets","","0","","21","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"An e-Map Navigation System: Provide Region Search and Visualize Landmark Information","D. Y. Wang; C. K. Hsu","Dept. of CSCE, Providence Univ., Taichung, Taiwan","Advances in Electrical and Electronics Engineering - IAENG Special Edition of the World Congress on Engineering and Computer Science 2008","20090904","2008","","","219","223","In this paper, a new e-map navigation system is designed to provide users with regional navigation services. It provided users keyword search, multiple classification search, and region search, so that userspsila need for diversified searches can be satisfied. Besides, this system applies chromatology to visualize search results, using colors to present landmarks and different degrees of chroma to describe landmark information. It is expected that through improvement of the system design and the information retrieval interface, userpsilas search cost can be reduced and better navigation services can be provided in a more efficient manner.","","POD:978-0-7695-3555-5","10.1109/WCECS.2008.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5233161","e-map;landmarks;navigation;visualization","Computer science;Databases;Design engineering;Displays;Electronic mail;Graphics;Information retrieval;Keyword search;Navigation;Visualization","cartography;data visualisation;navigation","chromatology;e-map navigation system;information retrieval;landmark information visualization;regional navigation services","","0","","8","","","22-24 Oct. 2008","","IEEE","IEEE Conference Publications"
"OCS — A system for optimizing, clustering and summarizing web search results using intelligent agents","Y. N. A. Khan; B. Raman; S. Hariharan","Department of Information Technology, School of Computer and Information Sciences, B.S.Abdur Rahman University, Chennai-48, Tamilnadu, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","6","Internet has brought a major revolution in social community especially among researchers. Number of commercial search engines has emerged with lots of information available online to end user. A Web surfer who wishes to surf the contents available online faces quite large number of problems. This paper in turn addresses three aspects, which we call term as OCS system. The proposed system or study analyzes the duplicates occurring in the content and link levels at first step, there by producing an optimized result. At second level, the optimized contents are clustered using top frequent clustering approach by identifying an optimal threshold. Finally the clustered contents are summarized using extraction process at query level and anchor text level. We take Google search engine and the results given by them for our case study to implement the system effectively.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228072","Link mining;clustering;content mining;google search engine;search result;similarity and optimization;summarization","Clustering algorithms;Humans;Image databases;Information retrieval;Information technology;Intelligent agent;Metasearch;Search engines;Web search;Web sites","Internet;data mining;multi-agent systems;pattern clustering;query processing;search engines","Google search engine;Internet;Web search summarization;Web surfing;anchor text level;data mining;information extraction;intelligent agent;optimal threshold;optimisation;query level;social community;top frequent clustering approach","","0","","19","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Design of Overlapping Block FM-Index Based on Distributed Environment","J. Liang; Z. Hu; H. Bao; D. Zhang; Y. Zhang","Training Center of Electron. Inf., Beijing Union Univ., Beijing, China","2009 International Forum on Information Technology and Applications","20090904","2009","1","","766","769","With the development of networks and database, the rapid growth of information and data, data files pose a challenge to information retrieval. Compression technology archived the query in the compressed state. Compression enquiries index FM-index is an advanced algorithm in the field, but FM-index must consume great memory in process of construct index. The overlapping block FM-index in occupation of memory has been improved, but it must further improve performance for the GB-level data. In this paper, based on overlapping block FM-index and grid computing technology, comparison of various parameters and programs to transfer results, to combine the characteristics of grid computing and overlap block FM-index, given the design and realization, moreover analysis improved performance of algorithms.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.524","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231769","distributed system;grid computing;overlap block FM-index","Algorithm design and analysis;Application software;Distributed databases;Grid computing;Information retrieval;Information technology;Linearity;Parallel processing;Performance analysis;Performance evaluation","data compression;grid computing;information retrieval","advanced algorithm;compression technology;data files;distributed environment;grid computing technology;index FM-index;information retrieval;overlapping block FM-index","","0","","10","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"The design and implementation of ontology based image retrieval for Xu Beihong Museums","Liang Ye; Bao Hong; Liu Hong-zhe; Li Guofeng","College of Information, Beijing Union University, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","191","195","Ontology is formal shared conceptualization of domains of interest providing common vocabularies and used more and more for information retrieval system. In the paper, ontology is used in XuBeihong Museums retrieval system. A framework based on ontology is proposed. How to create knowledge base and supplement it, how to retrieve are dissertated. In addition, the virtues of retrieval based on ontology are compared with retrieval based on keywords.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234384","CIDOC CRM;digital museums;image retrieval;ontology","Artificial intelligence;Content based retrieval;Educational institutions;Image retrieval;Information retrieval;Knowledge representation;Logic;Ontologies;Scattering;Vocabulary","exhibitions;humanities;image retrieval;ontologies (artificial intelligence)","XuBeihong museums;common vocabularies;formal shared conceptualization;information retrieval system;ontology based image retrieval","","0","","5","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"An Efficient LDE-Based Document Classification Algorithm","Z. Wang; X. Sun","Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China","2009 Pacific-Asia Conference on Circuits, Communications and Systems","20090904","2009","","","571","574","To efficiently cope with document classification problem, an efficient document classification algorithm based on local discriminant embedding (LDE) and SVM classifier is proposed in this paper. The high-dimensional document space are first projected into the lower-dimensional feature space by using LDE algorithm, the SVM classifier is then applied in the reduced document feature space. Extensive experiments show that the proposed algorithm achieves much better performance than other traditional document classification algorithms.","","POD:978-0-7695-3614-9","10.1109/PACCS.2009.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232412","SVM;dimensional reduction;document classification;local discriminant embedding (LDE)","Classification algorithms;Data mining;Feature extraction;Information retrieval;Information science;Large scale integration;Linear discriminant analysis;Space technology;Support vector machine classification;Support vector machines","document handling;support vector machines","SVM classifier;document feature space;high-dimensional document space;local discriminant embedding document classification algorithm","","0","","9","","","16-17 May 2009","","IEEE","IEEE Conference Publications"
"Research on Text Clustering Algorithm Based on Improved K_means","L. Xinwu","Electron. Bus. Dept., Jiangxi Univ. of Finance & Econ., Nanchang, China","2009 ETP International Conference on Future Computer and Communication","20090915","2009","","","19","22","Text clustering is one of the difficult and hot research fields in the Internet search engine research. Using and improving K-means clustering techniques, a new text clustering algorithm is presented. Firstly, texts are preprocessed to satisfy succeed process. Secondly, the paper improves the gravity centers calculation method and algorithm flow of K-means cluster algorithm to improve efficiency and stability of original K_means algorithm. The experimental results indicate that the improved algorithm has a higher accuracy compared with the original algorithm, and has a better stability.","","POD:978-0-7695-3676-7","10.1109/FCC.2009.65","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235716","K-means;Text clustering;algorithm flow;gravity centers calculation","Business communication;Clustering algorithms;Finance;Gravity;Information retrieval;Internet;Iterative algorithms;Partitioning algorithms;Search engines;Stability","Internet;pattern clustering;search engines;text analysis","Internet search engine research;K-means clustering techniques;gravity centers calculation;text clustering algorithm","","0","","8","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Agent-based autonomous Examination Systems","R. D. Gawali; B. B. Meshram","Dept. of Computer Engineering, Lokmanya Tilak College of Engineering, Navi Mumbai (M.S.), 400614, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","7","Online computerized examination systems is developed using software agent technology. Multi-agent system containing main agent, mobile agent and stationery agent is developed to support the functionality of examination systems in Aglet environment. All these agents in the system communicate with each other to process the operations requested by the user. Authentication of the examinee for valid user name and password is done by the stationary agents at user authentication module and database with the help of mobile agent. After successful authentication and selection of subject by examinee, mobile agent collects questions, their alternatives and correct answer retrieved by stationary agent from the database. These questions are displayed to the examinee. As examinee goes on answering these questions, main agent stores the answer given by examinee in database and updates the score. When the examination gets over, the main agent processes the result and displays result.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228095","agent;aglet;mobile agent","Authentication;Computer networks;Databases;Displays;Educational institutions;Information retrieval;Marine vehicles;Mobile agents;Software agents;Testing","multi-agent systems;query processing","Aglet environment;agent-based autonomous examination systems;correct answer retrieval;main agent;mobile agent;multi-agent system;online computerized examination systems;software agent technology;stationery agent;user authentication module","","0","","6","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"RACK: RApid clustering using K-means algorithm","V. K. Garg; M. N. Murty","Department of Computer Science and Automation (CSA), Indian Institute of Science, Bangalore, India","2009 IEEE International Conference on Automation Science and Engineering","20090909","2009","","","621","626","The k-means algorithm is an extremely popular technique for clustering data. One of the major limitations of the k-means is that the time to cluster a given dataset D is linear in the number of clusters, k. In this paper, we employ height balanced trees to address this issue. Specifically, we make two major contributions, (a) we propose an algorithm, RACK (acronym for RApid Clustering using k-means), which takes time favorably comparable with the fastest known existing techniques, and (b) we prove an expected bound on the quality of clustering achieved using RACK. Our experimental results on large datasets strongly suggest that RACK is competitive with the k-means algorithm in terms of quality of clustering, while taking significantly less time.","2161-8070;21618070","POD:978-1-4244-4578-3","10.1109/COASE.2009.5234127","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234127","","Automation;Clustering algorithms;Computer science;Data engineering;Data mining;Decision making;Information retrieval;Machine learning;Pattern analysis;Pattern recognition","pattern clustering;trees (mathematics)","clustering quality;data clustering;height balanced trees;k-means algorithm;rapid clustering","","0","","20","","","22-25 Aug. 2009","","IEEE","IEEE Conference Publications"
"Web-based Music Lecture Database Framework with Aligned MIDI Score and Real Performance Audio","H. T. Lin; H. Y. Chen; T. Y. Ma","National ChiNan University, NanTou County","IEEE MultiMedia","","2009","PP","99","1","1","This paper presents a framework for authoring, storing, retrieving, and presenting music lectures on the Web. For a synchronized presentation between score and recorded performance audio, we propose a dynamic programming-based algorithm for MIDI-to-Wave alignment to explore the temporal relations between MIDI and the corresponding performance recording. With rapid advances in music transcription technology, it had become more possible to align MIDI and wave in a symbolic domain. However, transcription errors usually occur when transcribing polyphonic music or multi-instruments music because the complex harmonic of different instruments. The proposed alignment algorithm works in the symbolic domain even if many transcription errors have occurred. The aligned MIDI and wave can be attached to many kinds of teaching materials. With a synchronized presentation, learners can read music scores and get instructional information when listening to certain sections of music pieces. We built an evaluation system for doing a subjective evaluation. The percentage of bars which were regarded as aligned perfectly and aligned within acceptable limits is 97.08&#x0025;. The questionnaire in the evaluation system also reported positive opinions from both engineers and musicians.","1070-986X;1070986X","","10.1109/MMUL.2009.73","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255219","Algorithm design and analysis;Data mining;Feature extraction;H.3.5.e Web-based services;H.5.4.b Navigation;H.5.5 Sound and Music Computing;Heuristic algorithms;Hidden Markov models;I.4 Image Processing and Computer Vision;I.5 Pattern Recognition;J.5.g Music;Multimedia;Multimedia communication;Multimedia databases;N.2.a Web lectures and notes;Semantics;Synchronization;Web technolgies","Art;Audio databases;Audio recording;Computer aided instruction;Electronic learning;Instruments;MPEG 7 Standard;Multimedia databases;Music information retrieval;Software libraries","","","","0","","13","","20090922","0","","IEEE","IEEE Early Access Articles"
"Web Text Knowledge Fusion","S. Hu; Y. Cao","Sch. of Comput. Sci. & Technol., Beijing Inst. of Technol., Beijing, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","171","174","There is still no complete and unified theoretical model for studying the research issues such as redundancy, localization, and fuzziness existed in the fusion of Web text knowledge. To this end, this paper proposes a fusion framework, called Web Pages Knowledge Fusion Framework (WPKFF). It presents the semantic description of attribute fusion rules, description information fusion rules and attribute-value and description information fusion rules. These rules provide a feasible model and a knowledge base for succeeding induction and reasoning.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.61","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232494","formal semanteme;fusion framework;fusion rules;knowledge acquisition;web text","Computer science;Distributed computing;Explosions;IP networks;Information retrieval;Knowledge acquisition;Natural languages;Network synthesis;Statistical distributions;Web pages","Web sites;knowledge engineering","Web pages knowledge fusion framework;Web text knowledge fusion;attribute fusion rules;description information fusion rules;induction;reasoning","","0","","6","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Get what you want from Internet using fuzzy k-means clustering algorithm","D. S. Zhu; M. Q. Zhou","College of Physical Science and Technology, Yangtze University, Jinzhou, China, 434000","2009 IEEE International Conference on Granular Computing","20090922","2009","","","814","817","This paper proposed a new method of getting what you want from Internet using fuzzy k-means clustering algorithm. It used search engine to obtain relevant documents content, then adopted efficient Fuzzy k-means clustering algorithm to cluster all the sentences. The summary sentences were extracted by turns from the clusters. Experimental result shows that the proposed method can improve the performance of summary.","","POD:978-1-4244-4830-2","10.1109/GRC.2009.5255009","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255009","","Clustering algorithms;Clustering methods;Data mining;Educational institutions;Electronic mail;Frequency estimation;Information retrieval;Internet;Prototypes;Search engines","Internet;fuzzy set theory;pattern clustering;search engines","Internet;fuzzy k-means Clustering Algorithm;search engine","","0","","12","","","17-19 Aug. 2009","","IEEE","IEEE Conference Publications"
"Comparative study of spine vertebra shape retrieval using learning-based feature selection","H. Guan; S. Antani; L. R. Long; G. R. Thoma","U.S. National Library of Medicine, National Institutes of Health, Bethesda, MD, USA","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","7","Feature extraction and selection are two important steps for shape retrieval. Given a data set, a set of features which describe the shape property from different aspects are extracted. Our goal is a learning-based methodology to select the features for improving retrieval performance. Our approach uses both global and local feature descriptors. The global shape features include geometric ones (elongation, eccentricity, roughness, and compactness), Fourier descriptors with complex coordinates, Fourier descriptors with Centroid Contour Distance Curve, Coefficients of Fourier Expansion of Bent function, moment invariants, and local shape features that include turn angle and Distance Across the Shape. We propose a learning-based feature selection algorithm as a strategy for optimizing retrieval performance. We provide results from the vertebra shape dataset created from our database containing spine X-rays from the National Health and Nutrition Examination Survey (NHANES II). Finally, we compare the retrieval performances of feature descriptors on ldquowhole shaperdquo and ldquocorner shaperdquo datasets. The experimental results show that various feature descriptors perform differently on different datasets, and that feature selection schemes improve the retrieval performance significantly.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255384","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255384","","Data mining;Feature extraction;Image databases;Image retrieval;Image segmentation;Information retrieval;Libraries;Shape measurement;Spine;X-rays","bone;diagnostic radiography;feature extraction;image retrieval;learning (artificial intelligence);medical image processing;neurophysiology;orthopaedics","Fourier descriptor;feature extraction;image retrieval performance;learning-based feature selection;spine X-ray image database;spine vertebra shape retrieval;vertebra shape dataset","","1","","20","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"The study on network information filtering model","R. Lu; F. Hua; P. Liu; F. Xie","School of Information Science and Technology, Shandong Normal University, Ji'Nan 250014, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","919","923","Information filtering technology is a hot research. In this paper we analyze three information filtering models, namely Boolean logical model, vector space model and latent semantic indexing model, also point out their defects. We, thereafter, put forward an information filtering model based on fuzzy set by introducing the fuzzy pattern recognition. At last, we do experiments to compare it with the commonly used vector space model. The result shows that the fuzzy set model is more efficient.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236206","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236206","","Data mining;Educational institutions;Fuzzy sets;Information analysis;Information filtering;Information filters;Information retrieval;Internet;Navigation;Space technology","fuzzy set theory;information filtering;pattern recognition","Boolean logical model;fuzzy pattern recognition;fuzzy set model;latent semantic indexing model;network information filtering model;vector space model","","0","","15","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Rough set methods based on discernibility relationship in IIS","Y. Li; L. Wei","School of Electrical Engineering, Hunan University of Technology, Zhuzhou, 412008, China","2009 IEEE International Conference on Granular Computing","20090922","2009","","","377","380","Classical rough set theory based on indiscernibility relationship rarely concerns discernibility relationships. However discernibility relationship deserves more attention because of its higher efficiency. In this paper a new kind of discernibility relationship is defined for studying incomplete information system. To demonstrate the validity of discernibility relationship, first we give a precise definition of discernibility relationship before the corresponding lower and upper approximations can be computed. Next the major properties of the lower and upper approximations can be obtained and proved. Finally the rough set model based on discernibility relationship is so easily constructed.","","POD:978-1-4244-4830-2","10.1109/GRC.2009.5255103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255103","","Data analysis;Information analysis;Information retrieval;Information systems;Physics;Set theory","approximation theory;data analysis;rough set theory","discernibility relationship;incomplete information system;knowledge discovery;lower approximations;rough set theory;upper approximations","","0","","12","","","17-19 Aug. 2009","","IEEE","IEEE Conference Publications"
"Text Processing in Video Frames with Complex Background","S. Shi; T. Cheng; S. Xiao; X. Lv","Chinese Inf. Process. Res. Center, Beijing Inf. Sci. & Technol. Univ., Beijing, China","2009 International Forum on Information Technology and Applications","20090904","2009","3","","450","454","Information deficiency is a huge problem when researching on video indexing and retrieval. On the other hand, text in video frames implies lots of semantics inherently, and can provide supplemental but important information for video data processing. In this paper, we present a fast and robust approach for text detection, localization, extraction, and reorganization in video frames with complex background. Here, block change rate (BCR for short) is imported to realize text detection and localization, smoothness model is used to narrow the scope of the text stroke, element image division in Lab color space is implied in binary text extraction, and Langue model is imported to evaluate the text extraction results. Experiments based on a large amount of video frames from different sources show that this approach is robust, effective and compatible for variety videos with complex background.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.128","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232157","block change rate;element image division;langue model;smoothness model","Character recognition;Data mining;Indexing;Information retrieval;Information technology;Optical character recognition software;Pixel;Robustness;Text processing;Text recognition","feature extraction;image colour analysis;indexing;object detection;text analysis;video retrieval;video signal processing;word processing","binary text extraction;block change rate;complex background;element image division;information deficiency;lab color space;langue model;text detection;text localization;text processing;text reorganization;text stroke;video data processing;video frames;video indexing;video retrieval","","1","","12","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Uyghur noun suffix Finite State Machine for stemming","A. Wumaier; P. Tursun; Z. Kadeer; T. Yibulayin","School of Information Science and Engineering, Xinjiang University, Urumqi, China, 830046","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","161","164","In this paper, we report on the generation of Uyghur noun suffix DFA generation for a stemming algorithm. Because of the agglutinative nature of Uyghur language, stemming is an essential task for Uyghur language processing applications. In Uyghur, the suffixes are affixed to the stem according to definite ordering rules. The agglutinative and rule-based nature of word formations in Uyghur allows modeling of the morphological structure of language in Finite State Machines (FSMs). In this study, FSM is formed by using the morphotactic rules in reverse order. This paper describes the steps of forming the reverse ordered Uyghur language noun suffix FSM.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234451","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234451","component;finite state machine;stemming;uyghur","Asia;Automata;Dictionaries;Doped fiber amplifiers;Educational institutions;Eyes;Information retrieval;Information science;Instruments;Natural languages","finite state machines;natural language processing","Uyghur language processing applications;Uyghur noun suffix DFA generation;Uyghur noun suffix finite state machine;morphological structure;morphotactic rules;rule-based nature;stemming algorithm;word formations","","2","","11","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Automatic text summarization based on sentences clustering and extraction","P. y. Zhang; C. h. Li","College of Computer & Communication Engineering, China University of Petroleum, Dongying, Shandong, China","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","167","170","Technology of automatic text summarization plays an important role in information retrieval and text classification, and may provide a solution to the information overload problem. Text summarization is a process of reducing the size of a text while preserving its information content. This paper proposes a sentences clustering based summarization approach. The proposed approach consists of three steps: first clusters the sentences based on the semantic distance among sentences in the document, and then on each cluster calculates the accumulative sentence similarity based on the multi-features combination method, at last chooses the topic sentences by some extraction rules. The purpose of present paper is to show that summarization result is not only depends the sentence features, but also depends on the sentence similarity measure. The experimental result on the DUC 2003 dataset show that our proposed approach can improve the performance compared to other summarization methods.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234971","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234971","sentence extractive technique;sentences clustering;similarity measure;text summarization","Clustering algorithms;Data mining;Educational institutions;Information retrieval;Natural language processing;Petroleum;Text categorization;Volume measurement;Web sites","classification;information retrieval;pattern clustering;text analysis","automatic text summarization;document sentence;information overload problem;information retrieval;multifeature combination method;sentence clustering;sentence extraction;text classification","","6","","18","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Using ontologies for annotating and retrieving protein-protein interactions data","M. Cannataro; P. H. Guzzi; P. Veltri","Bioinformatics Laboratory, Department of Clinic and Experimental Medicine, University Magna Graecia, Catanzaro, Italy","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","5","Protein-protein interaction (PPI) databases store the whole set of protein interactions in organism. In spite of the availability of much biological information spread on different sources (e.g. Gene Ontology), neither proteins nor interactions are generally annotated in PPI databases. This results in very poor querying capabilities of PPI databases that enable very simple queries. The annotation of proteins and interactions stored in PPI databases may allow the implementation of more powerful querying interfaces. The paper presents a software architecture for the annotation of existing PPI databases with information extracted from Gene Ontology. A simple extension of the query interface of an existent PPI database is discussed.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255274","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255274","Annotations;Gene Ontology;PPI Interactions","Bioinformatics;Data analysis;Data mining;Databases;Information retrieval;Laboratories;Ontologies;Organisms;Protein sequence;Standards organizations","bioinformatics;molecular biophysics;ontologies (artificial intelligence);proteins;query processing;software architecture;user interfaces","PPI database;biological information;data retrieval;gene ontology;information extraction;ontologies;protein-protein interaction database;querying interface;software architecture","","1","","18","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"Story Segmentation and Topic Classification of Broadcast News via a Topic-Based Segmental Model and a Genetic Algorithm","C. H. Wu; C. H. Hsieh","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","IEEE Transactions on Audio, Speech, and Language Processing","20090901","2009","17","8","1612","1623","This paper presents a two-stage approach to story segmentation and topic classification of broadcast news. The two-stage paradigm adopts a decision tree and a maximum entropy model to identify the potential story boundaries in the broadcast news within a sliding window. The problem for story segmentation is thus transformed to the determination of a boundary position sequence from the potential boundary regions. A genetic algorithm is then applied to determine the chromosome, which corresponds to the final boundary position sequence. A topic-based segmental model is proposed to define the fitness function applied in the genetic algorithm. The syllable- and word-based story segmentation schemes are adopted to evaluate the proposed approach. Experimental results indicate that a miss probability of 0.1587 and a false alarm probability of 0.0859 are achieved for story segmentation on the collected broadcast news corpus. On the TDT-3 Mandarin audio corpus, a miss probability of 0.1232 and a false alarm probability of 0.1298 are achieved. Moreover, an outside classification accuracy of 74.55% is obtained for topic classification on the collected broadcast news, while an inside classification accuracy of 88.82% is achieved on the TDT-2 Mandarin audio corpus.","1558-7916;15587916","","10.1109/TASL.2009.2021304","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230161","Genetic algorithm (GA);segmental model;story segmentation;topic classification","Biological cells;Broadcasting;Decision trees;Entropy;Genetic algorithms;Hidden Markov models;Image segmentation;Information retrieval;Speech;Streaming media","decision trees;genetic algorithms;maximum entropy methods;speech recognition","boundary position sequence;broadcast news;decision tree;genetic algorithm;maximum entropy model;story segmentation;topic classification;topic-based segmental model;two-stage paradigm","","7","","33","","","Nov. 2009","","IEEE","IEEE Journals & Magazines"
"Appending mining data of spatial object for query","J. K. Chen; W. T. Chien","Department of Information Management, Chaoyang University of Technology, Taiwan","2009 IEEE International Conference on Granular Computing","20090922","2009","","","53","56","Object-area related mining is an important topic in the application of spatial data. In this paper, we propose ten fundamental mining items for R-tree data access. To reflect the overlap characteristic of spatial object, we add three advanced mining items to R-tree. The values of these proposed items are pre-calculated and distributed to each entry of node of R-tree in advance. The time of searching and computing for aggregating data in lower-level objects can be reduced because each entry of node at higher-level in R-tree have these data already.","","POD:978-1-4244-4830-2","10.1109/GRC.2009.5255165","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255165","","Chaos;Customer relationship management;Data mining;Electronic commerce;Image analysis;Image retrieval;Information analysis;Information management;Information retrieval;Web pages","data mining;query processing;spatial data structures;tree data structures","R-tree data access;data mining;object-area related mining;query;spatial object","","1","","10","","","17-19 Aug. 2009","","IEEE","IEEE Conference Publications"
"A system for searching uterine cervix images by visual attributes","Z. Xue; S. Antani; L. R. Long; G. R. Thoma","National Library of Medicine, National Institutes of Health","2009 22nd IEEE International Symposium on Computer-Based Medical Systems","20090922","2009","","","1","5","Content-based indexing and retrieval is gaining increasing interest in the medical domain with the growing size of medical image databases. We present here a Web-accessible retrieval system for searching for similar uterine cervix images based on their visual characteristics. The system operates on a subset of a large database created for archiving patient records collected by two key projects in cervical cancer research. It was developed to bridge the ldquogapsrdquo that hold back the practical adoption of most CBIR systems. This collaboration between engineers and gynecological experts promises to provide a new biomedical resource beyond current text-based searching tools.","1063-7125;10637125","POD:978-1-4244-4879-1","10.1109/CBMS.2009.5255319","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255319","","Back;Biomedical imaging;Bridges;Cervical cancer;Content based retrieval;Image databases;Image retrieval;Indexing;Information retrieval;Visual databases","cancer;content-based retrieval;database indexing;gynaecology;image retrieval;medical information systems;search engines;visual databases","CBIR system;Web-accessible retrieval system;biomedical resource;cervical cancer research;content-based indexing;content-based retrieval;medical image database;patient record;text-based searching tool;uterine cervix image;visual attributes","","0","","15","","","2-5 Aug. 2009","","IEEE","IEEE Conference Publications"
"Traceability ReARMed","J. David; M. Koegel; H. Naughton; J. Helming","Inst. of Comput. Sci. II, Tech. Univ. Munich, Garching, Germany","2009 33rd Annual IEEE International Computer Software and Applications Conference","20090922","2009","1","","340","348","Traceability links connect artifacts in software engineering models to allow tracing in a variety of use cases. Common to any of these use cases is that one can easily find related artifacts by following these links. Traceability links can significantly reduce the risk and cost of change in a software development project. However, finding, creating and maintaining these links is costly in most cases. In any real-world project of significant size the creation and maintenance of traceability links requires tool support. In this paper, we propose a novel approach to support the automation of traceability link recovery based on association rule mining and operation-based change tracking. Traceability link recovery is the activity of finding missing or lost traceability links. Our approach automatically generates a list of candidate links based on the project history along with a score of support and confidence for every candidate link. We transformed the data from an operation based change tracking system to sets of frequent items, which serve as input for association rule mining (ARM). We applied our approach to data from a software development project with more than 40 developers and assessed the quality of the candidate links in interviews.","0730-3157;07303157","POD:978-0-7695-3726-9","10.1109/COMPSAC.2009.52","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254243","Association Rule Mining;Traceability;Unified Model","Association rules;Content based retrieval;Data mining;Guidelines;History;Indexing;Information retrieval;Large scale integration;Programming;Software engineering","data mining;project management;software development management;software quality","ReARMed;association rule mining;operation-based change tracking;project history;software development project;software engineering model;software quality;tool support;traceability link recovery;use case","","1","","29","","","20-24 July 2009","","IEEE","IEEE Conference Publications"
"An Efficient Rate Blackbox Algorithm","T. Nianqing; L. Yihe","Dept. of Comput. & Inf. Sci., Neijiang Normal Univ., Neijiang, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","174","177","Agent is a computer software procedure, it works in the dynamic environment and has the high autonomous ability, but also it has many merits: the independency, the cooperation, the adaptability to the tendency and the flexibility of the environment, the reduction of correspondence expenses and the support for fault-tolerant and so on. Time limited blackbox algorithm can not protect input and output of agent, for example, malicious host may refuse the transfer of agent or return wrong result; It is very difficult to choose a mechanism of conversion for protecting host; agent must realize the clock synchronization with the running environment, which reduces the security of blockbox algorithm. Because time limited blackbox algorithm exists shortage, the paper puts forward an efficient rate blackbox algorithm, which is without time restriction, more safe valid and higher practical value.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.212","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231238","Blackbox Algorithm;Limited Time;Malicious Agent;PKI;Security","Application software;Data security;Fault tolerance;Information retrieval;Information science;Information security;Information technology;Parallel processing;Protection;Software algorithms","security of data;software agents;software fault tolerance","clock synchronization;computer software procedure;efficient rate blackbox algorithm;fault-tolerant;software agent","","0","","8","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Web Mining Based Patent Analysis and Citation Visualization","Z. Liu; D. Zhu","Sch. of Manage. & Econ., Beijing Inst. of Technol., Beijing, China","2009 Second Pacific-Asia Conference on Web Mining and Web-based Application","20090904","2009","","","19","23","Patent data is one of the most valuable reservoir of technical and commercial knowledge. However, patent data of different countries and organizations has been stored separately, which added to the difficulty for patent analysis with these free patent data. By using Web mining method, we can retrieve the related patent information of a certain field from several patent Website as data source. From web pages to structural patent database, we can use these free patent sources to obtain professional patent analysis result and useful knowledge. A citation structure visualization method is introduced, which helps reveal the citation relationships among patents.","","POD:978-0-7695-3646-0","10.1109/WMWA.2009.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232458","","Citation analysis;Data visualization;Frequency;Information analysis;Information retrieval;Internet;Knowledge management;Text mining;Visual databases;Web mining","Internet;Web sites;citation analysis;data mining;data visualisation;patents","Web mining;citation structure visualization;patent Web site;patent analysis;patent data;patent information retrieval;structural patent database","","0","","16","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Optimization of text feature subsets based on GATS algorithm","P. p. Jiang; P. y. Liu; Z. f. Zhu; L. n. Zhao","Department of Information Science and Engineering, Shandong Normal University, Jinan, 250014, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","924","927","For feature subset optimization problems in text categorization, the GATS strategy which combines the genetic algorithm with taboo search algorithm is proposed in this paper to be applied to text categorization to realize the dimensionality reduction of the feature space. The experiments show that the application of this method to select the characteristics of the text can not only maintain the advantages of the GA and the TS algorithm themselves, but also improve the classification accuracy of the text.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236207","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236207","","Approximation algorithms;Data mining;Genetic algorithms;Guidelines;Information retrieval;Internet;Machine learning algorithms;Optimization methods;Space technology;Text categorization","combinatorial mathematics;genetic algorithms;mathematical operators;pattern classification;search problems;text analysis","GATS algorithm;dimensionality reduction;feature subset optimization problems;genetic algorithm with taboo search algorithm;text categorization;text feature subsets","","0","","7","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Macro Semantic Relations in Services Computing","Q. P. Yang; G. L. Pu; Y. H. Qiu","Dept. of Comput. Sci., Sichuan Univ. of Arts & Sci., Dazhou, China","2009 International Forum on Information Technology and Applications","20090904","2009","2","","254","258","We state the macro semantic relations (MSR) in services computing from four courses-services discovery, services composition, services selection and services recommendation. We analyze the MSR through black box-details are ignored, and the characters of I/O are stressed. First, describe Web services with IOPEs and QoS. Secondary, describe the semantics of each course. In the description of composite services, we present the composite semantics through sequence, selection and concurrent relation, etc. For enhancing the accuracy of matchmaking requirement service and registered service, a matrix model of services composition based on complex network is imported. In the process of services selection, we propose select the service depending on the performance-price ratio. And analyze user information from three parts-basic information, access history information, and act information.","","POD:978-0-7695-3600-2","10.1109/IFITA.2009.522","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231215","OWL-S;QoS;Services Composition;Services Discovery;Services Selection;services recommendation","Application software;Availability;Costs;Grid computing;Information retrieval;Information technology;Ontologies;Packaging;Quality of service;Web services","Web services;quality of service","QoS;Web service;access history information;act information;basic information;complex network;composite semantics;macro semantic relations;matrix model;performance-price ratio;registered service;requirement service;service composition;service discovery;service recommendation;service selection;services computing","","0","","10","","","15-17 May 2009","","IEEE","IEEE Conference Publications"
"Text Mining for Bioinformatics: State of the Art Review","Y. Qi; Y. Zhang; Min Song","Department of Information Systems, New Jersey Institute of Technology, Newark, 07102, USA","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","398","401","Biomedical literatures have been increased at the exponential rate. To find the useful and needed information from such a huge data set is a daunting task for users. Text mining is a powerful tool to solve this problem. In this paper, we surveyed on text mining in Bioinformatics with emphasis on applications of text mining for bioinformatics. In this paper, the main research directions of text mining in bioinformatics are accompanied with detailed examples. This paper suited the need for the state-of-the-art of the field of text mining in Bioinformatics because of the rapid development in both text mining and bioinformatics. Finally, the problems and future way are identified at last.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234922","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234922","bioinformatics;gene annotation;gene expression;mirco array analysis;named entity recognition;systems biology;text mining","Bioinformatics;Biology computing;Computer science;Data mining;Gene expression;Information retrieval;Information systems;Relational databases;Systems biology;Text mining","bioinformatics;data mining;text analysis","bioinformatics;biomedical literatures;data set;main research directions;text mining","","1","","29","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Data mining techniques to analyze the risks in stocks/options investment","A. Surendran","Dept of Comput. Sci., Cochin Univ. of Sci. & Technol., Cochin, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","3","Data mining is one of the most optimal methods to analyze the data. Nowadays most of the people will be reluctant to invest money in shares and options because of the global economic crisis. In this research paper, a proposal is made in order to analyze the stocks/sectors and options based on various financial parameters using data mining techniques. The neuro-fuzzy logic technique is proposed to use in this proposal, to develop this work and the mining technique is applied to classify the result obtained.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228043","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228043","DPS;Data mining;EPS;Neuro-Fuzzy logic;Options","Computer science;Data analysis;Data mining;Fuzzy logic;Information retrieval;Investments;Neural networks;Performance analysis;Proposals;Risk analysis","data mining;fuzzy logic;fuzzy neural nets;investment;learning (artificial intelligence);risk analysis","data mining techniques;global economic crisis;neuro-fuzzy logic technique;risk analysis;stocks-options investment","","0","","7","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Ocean Color Atmospheric Correction Method with Multi-Angles Data in Case II Waters","Z. Ke; Y. Ma; H. Wang; H. Wang","Dept. Electr. & Info. Engn., Huazhong Univ. Sci.& Tech., Wuhan, China","2009 Symposium on Photonics and Optoelectronics","20090901","2009","","","1","3","The atmospheric correction for the ocean color remote sensing is the most important technique to retrieve the water- leaving radiance, which is less than about 10% of the satellite radiance. In Case II waters, the standard atmospheric correction method embedded in SeaDAS frequently yields negative water- leaving radiance, and its major uncertainties are occurred by the estimation error of atmospheric aerosols that is highly variable in both space and time. In this paper, a modified atmospheric correction method was proposed to correct the atmospheric aerosol effect in Case II waters. The aerosol information derived from multi-angles data in Case II waters and then modify the standard atmospheric correction algorithm to retrieve the water- leaving radiance. From the comparison of the standard atmospheric correction algorithm and the modified atmospheric correction algorithm, the results showed that the modified atmospheric correction method could be effective in Case II waters.","2156-8464;21568464","POD:978-1-4244-4412-0","10.1109/SOPO.2009.5230209","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5230209","","Aerosols;Atmospheric modeling;Color;Information retrieval;MODIS;Oceans;Optical scattering;Rayleigh scattering;Remote sensing;Satellites","aerosols;atmospheric optics;oceanographic techniques;remote sensing","atmospheric aerosols;ocean color atmospheric correction;remote sensing;satellite radiance;water-leaving radiance","","0","","8","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"Ontology based digital library search model research","L. Guo; Y. Zhou","College of Information Science and Technology, Drexel University, PA, USA","2009 IEEE International Conference on Granular Computing","20090922","2009","","","184","187","Ontologies, as sets of concepts and their interrelations in a specific domain, have proven to be a useful tool in the areas of digital libraries, semantic web, and the like. But large-scale analysis of ontology usage is constrained primarily in specific domain, like medical, scholarly artifact, biosciences, where knowledge presentation is structured and easier to understand. The application of ontologies in the domain of humanities, especially history, however, is rare since the extraction from knowledge of history is hard. In the current paper, we introduce an ontology based visualization model to integrate ontology in historical knowledge searching. Particularly, this period of history is related with Kuomintang and Early Communist Periods of China. The objective is assisting knowledge representation and knowledge inference for the purpose of knowledge management.","","POD:978-1-4244-4830-2","10.1109/GRC.2009.5255134","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5255134","","Educational institutions;Hidden Markov models;History;Information retrieval;Knowledge management;Ontologies;Search methods;Semantic Web;Software libraries;Visualization","digital libraries;knowledge representation;ontologies (artificial intelligence)","digital library search model research;historical knowledge searching;knowledge inference;knowledge management;knowledge representation;ontologies;visualization model","","0","","17","","","17-19 Aug. 2009","","IEEE","IEEE Conference Publications"
"VSM-RF: A method of relevance feedback in Keyword Search over Relational Databases","Z. h. Peng; J. Zhang; S. Wang; C. l. Wang; L. z. Cui","School of Computer Science and Technology, Shandong University, Jinan, 250101, China","2009 IEEE International Symposium on IT in Medicine & Education","20090915","2009","1","","738","744","In keyword search over relational databases (KSORD), retrieval of user's initial query is often unsatisfying. User has to reformulate his query and execute the new query, which costs much time and effort. In this paper, a method of automatically reformulating user queries by relevance feedback is introduced, which is named VSM-RF. Aimed at the results of KSORD systems, VSM-RF adopts a ranking method based on vector space model to rank KSORD results. After the first time of retrieval, using user feedback or pseudo feedback just as user like, VSM-RF computes expansion terms based on probability and reformulates the new query using query expansion. After KSORD systems executing the new query, more relevant results are produced by the new query in the result list and presented to user. Experimental results verify this method's effectiveness.","","POD:978-1-4244-3928-7","10.1109/ITIME.2009.5236323","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236323","","Computer science;Computer science education;Costs;Data engineering;Feedback;Information retrieval;Keyword search;Knowledge engineering;Laboratories;Relational databases","probability;query formulation;relational databases;relevance feedback","KSORD;VSM-RF;initial query retrieval;keyword search;probability;pseudo feedback;query expansion;query reformulation;ranking method;relational database;relevance feedback;vector space model","","0","","19","","","14-16 Aug. 2009","","IEEE","IEEE Conference Publications"
"A study of local component library based on UCDL","Xu Shoukun; Chu Xiaomei; Ma Zhenghua","School of Information Science and Engineering, Jiangsu Polytechnic University, Changzhou, China","2009 4th International Conference on Computer Science & Education","20090901","2009","","","904","907","This article proposes a model of local component library based on the Universal Component Description Language (UCDL). A certain improvements are made for the UCDL criterion. Hierarchical structure is used to organize and manage components based on multi-facet classification scheme. The classification of storage and organization of component are also expounded. A method how to retrieval and fabricate the component based on local component library to realize software reuse is also introduced.","","POD:978-1-4244-3520-3","10.1109/ICCSE.2009.5228228","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228228","Component;Local Component library;UCDL","Computational Intelligence Society;Computer science;Computer science education;Feedback;File systems;History;Information retrieval;Internet;Radiofrequency interference;Software libraries","information retrieval;libraries;pattern classification;software reusability","hierarchical structure;local component library;multifacet classification;software reuse;universal component description language","","0","","8","","","25-28 July 2009","","IEEE","IEEE Conference Publications"
"Shape Representation and Recognition in High Dimensional Feature Space","H. Gu; G. Zhao; H. Wang","Coll. of Electr. Eng., Zhejiang Univ., Hangzhou, China","2009 International Conference on Computational Intelligence and Natural Computing","20090904","2009","1","","186","189","We present a novel approach for shape representation using support vector domain description (SVDD). The shape contour of an object is mapped to spherical surface in high dimensional feature space, where similar contours with different size look like concentric spheres in the learned feature/kernel space. Shape matching in cluttered image, therefore, can be seen as finding the corresponding super spherical surface after the nonlinear transformation. The shape model, which consists of several support vectors (SVs), is partially invariant to contour scaling and rotation. A coarse-to-fine strategy is then adopted for shape matching in the forward matching process. Experimental results show that the approach is robust and suitable for shape-based image retrieval. In addition, our approach enables the user to fast construct the template shape by a small quantity of points which represent the shape roughly. The precise shape contour is not needed. It can greatly improve the human-machine interaction friendliness of practical image retrieval systems. Though our analysis is based on 2D shapes, this idea can be easily extended to the 3D shapes.","","POD:978-0-7695-3645-3","10.1109/CINC.2009.48","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231171","image retrieval;kernel method;shape representation;support vector data description","Computational intelligence;Content based retrieval;Educational institutions;Image retrieval;Information retrieval;Kernel;Man machine systems;Object recognition;Robustness;Shape","image matching;image recognition;image retrieval;support vector machines","coarse-to-fine strategy;forward matching process;human-machine interaction;image recognition;nonlinear transformation;shape matching;shape representation;shape-based image retrieval;super spherical surface;support vector domain description","","0","","17","","","6-7 June 2009","","IEEE","IEEE Conference Publications"
"Probabilistic model for a distributed feature selection method","Z. Berenyi; I. Vajk","Budapest University of Technology and Economics, Department of Automation and Applied Informatics, 1111, Goldmann Gyrgy t&#233;r 3. IV. em., Hungary","2009 3rd International Workshop on Soft Computing Applications","20090922","2009","","","27","32","When building topic based document classifiers, feature selection is a key step: features not holding any information about the topic of a document introduce only unnecessary noise during the classification. In a distributed environment, when the nodes are interacting, the locally retrieved features and the their attributes must be shared to have at every node a more accurate estimation of the global classifier. When expanding the knowledge of the local classifiers, to reduce costs, the network traffic should be kept to a minimum. We propose a probabilistic model for a keyword selection method which makes a more thorough analysis possible and can be used as a baseline when sharing information in a distributed environment. It can be used for incrementally building up the distributed classifiers ensuring minimal network traffic. This model can be refined later on by sending more content-related information to achieve higher performance. This probabilistic model together with experimental results are presented in this paper.","","POD:978-1-4244-5054-1","10.1109/SOFA.2009.5254884","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254884","","Automation;Environmental economics;Informatics;Information analysis;Information retrieval;Mobile communication;Noise reduction;Peer to peer computing;Telecommunication traffic;Traffic control","document handling;feature extraction;minimisation;mobile computing;pattern classification;probability","distributed feature selection method;distributed mobile environment;document classifier;information sharing;keyword selection method;network traffic minimisation;probabilistic model","","1","","16","","","July 29 2009-Aug. 1 2009","","IEEE","IEEE Conference Publications"
"Improved search technique using wildcards or truncation","S. Mishra; S. K. Satapathy; D. Mishra","Department Of Computer Science & Engineering, Institute of Technical Education & Research, Under S'O'A University, Bhubaneswar, Orissa, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","4","Search engine technology plays an important role in web information retrieval. However, with Internet information explosion, traditional searching techniques cannot provide satisfactory result due to problems such as huge number of result Web pages, unintuitive ranking etc. Therefore, the reorganization and post-processing of Web search results have been extensively studied to help user effectively obtain useful information. This paper has basically three parts. First part is the review study on how the keyword is expanded through truncation or wildcards (which is a little known feature but one of the most powerful one) by using various symbols like * or! .The primary goal in designing this is to restrict ourselves by just mentioning the keyword using the truncation or wildcard symbols rather than expanding the keyword into sentential form. Second part consists of the review on subdivision based on wildcards. It is based on the observation that documents are often found to contain terms with high information content which summarize their subject matter. The third part consists of a proposed algorithm based on the above two. The main goal of this paper is to develop a very efficient search technique by which the information retrieval will be very fast, reducing the amount of extra labor needed on expanding the query.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228080","Search Engine;Truncation;Wildcard","Computer science;Computer science education;Databases;Educational technology;Explosions;Information retrieval;Internet;Keyword search;Search engines;Web pages","Internet;information retrieval;search engines","Internet information explosion;Web pages;Web search;information content;search engine technology;search technique;truncation symbols;web information retrieval;wildcard symbols","","1","","10","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
"Using frames to infer numerical extracted answers","F. Nadi; B. Ranaivo-Malancon","School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","2009 2nd IEEE International Conference on Computer Science and Information Technology","20090911","2009","","","14","18","Question answering (QA) systems and their undeniable usefulness become more and more obvious nowadays. There are situations where the QA systems are not able to extract a concise and salient answer to a given question. A long descriptive answer instead of a concise one can affect the efficiency of the system. The main aim of this research is on producing a concise answer from the set of retrieved answers given by any QA system. We particularly focus on the situations when the correct answer has to be a numerical value. In this paper, we will demonstrate a nearly new data structure called frame. A frame will be constructed for each of the numerical values that are within the answer set. Our method uses natural language processing techniques in addition to information extraction techniques to fill in the frames. The evaluation of the constructed frames shows acceptable results.","","POD:978-1-4244-4519-6","10.1109/ICCSIT.2009.5234861","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5234861","Information Extraction;Numerical answer;extracted answer;frame;inference;question answering","Data mining;Data structures;Heart;Information retrieval;Information technology;Multimedia systems;Natural language processing;Natural languages;Rail transportation","data structures;information retrieval;natural language processing","QA systems;data structure;frame;information extraction techniques;natural language processing techniques;question answering systems","","0","","7","","","8-11 Aug. 2009","","IEEE","IEEE Conference Publications"
"Search Results Clustering Using Nonnegative Matrix Factorization (NMF)","H. D. Abdulla; M. Polovincak; V. Snasel","Dept. of Comput. Sci., VSB Tech. Univ. of Ostrava, Ostrava, Czech Republic","2009 International Conference on Advances in Social Network Analysis and Mining","20090904","2009","","","320","323","There are many search engines in the Web and when asked, they return a long list of search results, ranked by their relevancies to the given query. Web users have to go through the list and examine the titles and (short) snippets sequentially to identify their required results. In this paper we present how usage of Nonnegative Matrix Factorization (NMF) can be good solution for the search results clustering.","","POD:978-0-7695-3689-7","10.1109/ASONAM.2009.58","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5231846","Clustering Data;Nonnegative Matrix Factorization (NMF);Search results clustering","Computational linguistics;Computer science;Data analysis;Data mining;Information filtering;Information filters;Information retrieval;Search engines;Social network services;Text mining","matrix decomposition;pattern clustering;query processing;search engines","Web user;nonnegative matrix factorization;search engine;search result clustering","","0","","10","","","20-22 July 2009","","IEEE","IEEE Conference Publications"
"Text detection in color images","J. Sushma; M. Padmaja","Dept. of Electronics & Communication Engg, DMS SVH College of Engineering, Machilipatnam-521001, Andhra Pradesh, India","2009 International Conference on Intelligent Agent & Multi-Agent Systems","20090901","2009","","","1","6","Content-based multimedia database indexing and retrieval tasks require automatic extraction of descriptive features that are relevant to the subject materials i.e., images, video etc. The typical low-level features that are extracted in images and video include measures of color, texture, or shape. Although these features can easily be obtained, they do not give a precise idea of the image content. Extracting more descriptive features and higher level entities, such as text and human faces is important. Text embedded in images and video, especially captions provide brief and important content information, such as the name of players or speakers, the title, location, date of an event, etc. Besides, text-based search has been successfully applied in many applications, while the robustness and computation cost of feature matching algorithms based on other high-level features is not efficient enough to be applied to large databases. The objective of this paper is to compare two basic approaches of text extraction in natural (non-document) images namely; edge-based and connected-component based. These algorithms are implemented and evaluated using a set of images of natural scenes that vary along the dimensions of lighting, scale and orientation. Accuracy, precision and recall rates for each approach are analyzed to determine the success and limitations of each approach. Recommendations for improvements are given based on the results.","","POD:978-1-4244-4710-7","10.1109/IAMA.2009.5228049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5228049","Detection;Dilation;Enhancement;Localization;Text Extraction;Variance","Color;Content based retrieval;Data mining;Feature extraction;Humans;Image retrieval;Indexing;Information retrieval;Multimedia databases;Shape measurement","content-based retrieval;feature extraction;image colour analysis;indexing;multimedia databases;object detection;text analysis","color images;content-based multimedia database indexing tasks;content-based multimedia database retrieval tasks;descriptive feature extraction;text detection;text extraction","","3","","10","","","22-24 July 2009","","IEEE","IEEE Conference Publications"
